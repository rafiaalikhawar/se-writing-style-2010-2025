prada prioritizing android devices for apps by mining large scale usage data xuan lu1xuanzhe liu1 huoran li1t ao xie2qiaozhu mei3dan hao1gang huang1feng feng4 1key laboratory of high confidence software t echnologies peking university ministry of education prc 2university of illinois at urbana champaign 3university of michigan 4wandoujia lab beijing china luxuan xzl lihuoran pku.edu.cn taoxie illinois.edu qmei umich.edu haodan hg pku.edu.cn jackfeng wandoujia.com abstract selecting and prioritizing major device models are critical for mobile app developers to select testbeds and optimize resourcessuchasmarketingandquality assuranceresources.
theheavilyfragmenteddistributionofandroiddevicesmakesit challenging to select a few major device models out ofthousands of models available on the market.
currentlyapp developers usually rely on some reported or estimated general market share of device models.
however these estimates can be quite inaccurate and more problematically can be irrelevant to the particular app under consideration.
to address this issue we propose prada the first approach to prioritizing android device models for individualapps based on mining large scale usage data.
prada adapts the concept of operational profiling popularly usedin software reliability engineering for mobile apps the us age of an app on a specific device model reflects the impor tance of that device model for the app.
prada includes acollaborative filtering technique to predict the usage of anapp on different device models even if the app is entirelynew without its actual usage in the market yet based onthe usage data of a large collection of apps.
we empiricallydemonstrate the effectiveness of prada over two popularapp categories i.e.
gameandmedia c o v e r i n go v e r3 .
million users and device models collected through aleading android management app in china.
categories and subject descriptors d. .
software quality assurance sqa keywords mobile apps android fragmentation prioritization usagedata xuan lu and xuanzhe liu are both first authors and contributed equally to the work.
corresponding author.
permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
copyrights for components of this work owned by others thanacm must be honored.
abstracting with credit is permitted.
to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
request permissions from permissions acm.org.
icse may austin tx usa c circlecopyrt2016 acm.
isbn .
.
.
.
introduction the wide adoption of smartphones and tablet computers has triggered a surge of developing mobile applications a.k.a apps in recent years.
as of millions of apps havebeendevelopedandmadeavailableinappmarketplacessuchas the apple store and google play which have received bil lions of downloads.
numerous app developers have profitedfrom the revenues generated by the downloads and usagesof their apps.
compared to the ios and windows platforms which have a rather fixed set of device models the android platform is adopted by a diverse set of device manufacturers and mod els.
indeed the openness and flexibility of the android plat form have greatly contributed to its popularity the androidplatform holds more than of the smartphone market share.
famous brands such as samsung htc motorola and lenovo have developed numerous device models usingandroid.
meanwhile most small and medium device manufacturers also adopt android as their platforms.
the heavily fragmented distribution of android device models is noticeable.
it is reported by opensignal that there have been more than android device models on the market up to the year .
such a fragmentation brings significant challenges to software engineering practices formobile apps such as the design development maintenance quality assurance and revenue generation .
a recentstudy in shows that of app developers who avoid the android platform cited fragmentation as the main reason.
developers have to take into account device specific factorssuchasscreensizes resolutionlevels andotherhardware specifications.
an app especially a game app can runsmoothly on high end device models which have powerfulcomputation power and high resolution but may run slug gishly or improperly on lower end devices.
developers needto conduct extensive testing and other quality assurance ac tivities to validate the functionality and usability such asthe gui effects of their apps on multiple device models.the fragmentation also influences the revenue of which in app advertisement or ads is an important channel especially for some types of apps e.g.
game and media apps .to more accurately target the audience device specific adsare often preferred.
for example facebook customizes mo bile ads according to device model types since .
developers would like to know through which device models they can gain more users and more ads clicking opportunities so that they can invest their effort in customizing the 1a device model refers to the specific model of devices that share the same hardware specification.
ieee acm 38th ieee international conference on software engineering ieee acm 38th ieee international conference on software engineering ieee acm 38th ieee international conference on software engineering ads on those models e.g.
designing banners of proper sizes or placing videos at proper positions on the screen.
as itis unrealistic to customize for every android device model selecting the major device models to focus on is quite important to android app development.
a suboptimal selection may cause to waste money and human effort miss potential bugs or even lose revenue etc.
most developers prioritize a small number of device models normally less than ten based on their market shares.these developers rely on the widely accessible market sharereportsorpredictions suchasthoseprovidedbyappbrain .
however the market share of a device model is usually calculated based on how many devices are sold instead of how they are used which is what the developers really careabout.
more importantly the market share of a devicemodel may not be relevant to particular apps.
indeed itis not uncommon that an app is heavily installed on lesspopular device models and less preferred by those who use a majority model.
even if an app is installed on a device it may be frequently or barely used .
to make the right decision the developers need an accurate estimate of how their apps are actually used on different device models.
to address this issue we propose a novel approach named prada prioritizing android devices for apps to prioritizing major device models of a given app.
rather than counting the number of devices installing an app prada utilizes a different signal how the app is actually used onthedevices.
thekeyintuitionofpradaisderivedfromtheconcept of operational profile a concept popularly used in software reliability engineering which is a quantitative representation of how a system is used.
prada assumes that a device model is of a higher priority for an app if the app is consumed more intensively by the users using that device model.
prada then builds a data mining model thataccurately predicts the major device models for every app even if it is newly launched on the market and the actual us age data is unavailable.
based on the predictions pradarecommends a ranked list of device models that should beprioritized for an app.
we evaluate the effectiveness of prada through a real world data set collected by a leading android app market place in china wandoujia .
wandoujia provides its na tive management app to facilitate searching downloading and updating apps.
in addition the management app alsoprovides an interface to monitor the daily usage of the appsinstalled on a device.
we choose the top popular apps in two app categories i.e.
gameandmedia.
these apps apps from each category cover users and devicemodels.
weadopt browsing time asthetypicalmetric of usage data as it indicates the total time that users interact with a specific app under network.
we then evaluatethe significance of prada selected device models account ing for the actual browsing time.
empirical results show that compared to the baseline of marketshare prada selects device models with top browsing time i.e.
device models that can maximize the coverage of browsing time m o r e accurately.
in summary we make the following main contributions we propose the first approach to prioritizing androiddevice models by mining app usage data collected fromandroid devices.
wedevelopacollaborativefilteringtechniquethatpre dicts major device models for a newapp based on the usage of other apps with similar functionalities.
we present the largest study to date on prioritizingdevice models using a real world data set.
we conduct experiments to evaluate the effectivenessof prada and its related approaches.
the rest of this paper is organized as follows.
section describes the related work of android device prioritization.
section presents the overview of prada including its key ideas and workflows.
section illustrates prada throughan example case and section presents an evaluation.
sec tion presents the findings and implications for developers.section discusses threats to validity of our study.
section concludes the paper with future work.
.
related work wenextpresenta summaryof existing studiesonandroid device fragmentation operational profiles and analyses of app usage data.
.
android fragmentation compared to software development for pc one unique challenge of developing android apps is how to cope withthe heavy fragmentation of android devices.
halpern et al.
make a careful analysis of the market fragmentation caused by hardware specifications and os versions andpropose a capture and replay approach for testing.
park et al.
propose two approaches to handle android fragmen tation at the code level and the api level.
han et al.
analyze the bug reports related to the two popular mobiledevice vendors htcandmotorola and propose an approach for tracking fragmentation using feature analysis on project repositories.
khalid et al.
leverage user reviews to focus on proper android devices for app testing.
they collect about thousand user reviews of free game apps ongoogle play.
however google play has recently shut downthe api of browsing user reviews for all device models except for the user reviews from specific device models associated with a user s google account such constraint mayintroduce a considerable bias when leveraging user reviews.another concern is the potential subjectiveness and biases in user reviews.
for example it is reported that users from different countries may behave very differently in writingreviews .
some existing industrial cloud based testing services such as testin and appthwack provide remote servicesand offer a sufficient coverage of device models.
however the cost ranges from approximately one dollar per every minute use of a device leading to a very high expense if onewants to test many device models.
.
operational profiles the concept of operational profile is widely used in software engineering especially software reliability engineeringand software testing .
musa defined an opera tional profile as a quantitative representation of howas y s t e mw i l lb eu s e d .
it models how users execute a system specifically the occurrence probabilities of functioncalls and the distributions of parameter values.
such a de scription of the user behavior can be used to generate testcases and to direct testing to the most used functions.
for example with a software system if operation a occurs in percent of the time b occurs in percent and c oc curs in percent then the profile is .
descriptions of the user behavior as in an operational 4profile can also be used for other purposes besides software testing .
the performance and correctness of the systemcan be analyzed and the system can be effectively adaptedto specific user groups.
for example mobahser et al.
use operational profiles of web based systems for personalization.
an operational profile helps improve the communication between customers and developers and make the developers think more deeply about the features of interest and theirimportance to the customers.
in contrast if developed early an operational profile may be used to prioritize operations under development so that more resources are invested on more important operations.
.
app usage data analysis from the perspective of software engineering usage data of apps is a typical operational profile.
understanding how an app is used by real world users is also important to im prove the development of the app.
one common approach istoconductafieldstudywithtypicallyasmallgroupofusers as proposed in livelab .
many other studies have been conducted in a similar fashion for reporting the diver sity of cellular usage from different user groups differentapp categories etc.
.
to collect usagedata some researchers develop third party apps and deploy them as system level services such as appinsight and appjoy .
the app usage data can include detailed infor mation such as the total launch time the traffic volume and the session lengths to investigate user preferences and interests in depth.
however these apps are not widely adoptedand their users are usually at the scale of hundreds.
com paredtothesefieldstudies ourapproachreliesonacommer cial app wandoujia which has been widely deployed amongover million users.
although most wandoujia users are from china our recent work conducts a series of studies of understanding user behaviors from multiple dimensions such as app popularity network usage and price sensitiv ity and validates the general findings from previous effortsmade over other popular app stores and the traces attier cellular network in us .
the results show that con ducting studies using wandoujia data can reduce the threatscaused by user selection bias.
in addition such a longitudinal data set collected from about million anonymized users can make many more comprehensive analyses feasible.
.
the prada approach in this section we present the prada approach of prioritizing device models by using large scale usage data.
the key idea of prada is that a device model should be given higher priority for an app if the device model accounts for more user activities.
naturally when an app is already used by many users on many devices estimating the length oftime it is used or the number of user interactions is an easytask.
we are motivated however to explore whether we can make accurate estimates for a new app which has not yet reached a critical mass of users or even has not yet released.market targeting and prioritized testing at this stage are particularly important and challenging for the developers.
prada relies on the usage data of apps on specific devicemodels collected by wandoujia.
.
wandoujia the app usage data are collected through a commercial android app management tool developed by a leading anfigure screenshots of advanced settings in the chinese version of the wandoujia management app the advanced settings are not supported in the current english version .
a is the homepage of the wandoujia management app w h e r eu s e r sc a nn a v i g a t et o settings b yc l i c k i n go nt h e text circled by red b refers to the setting of background management services highlighted by the red rectangle c refers to the option of allowing wandoujia to collect the dataof network activities or not.
droid marketplace in china called the wandoujia.
wandoujia was founded in and has grown into one of the largest android app marketplaces in the world with over million users and .
million free android apps 2as of the year .
each user is associated with at least one android device either a smartphone or a tablet computer.
wandoujia provides a native management app through which users can manage the apps on their devices e.g.
downloading searching updating and uninstalling apps.
users can also rate review apps.
beyond these basic features the wandoujia management app is developed withsomeoptionalfeaturesthatcanmonitorandoptimizesystem wideactivities.
thesefeaturesincludenetworkactivitystatistics permission monitoring content recommendation etc.
all features are developed upon android system apis anddo not require the root privilege.
users can opt in and out these features.
for example as shown in figure tracking the network statistics is an explicit option for end users andtherefore our analysis is made on only those users who agreeto share and upload their usage data.
however it should benoted that these features are supported in only the chinese version of wandoujia.
we obtain three months of app usage data collected from july 1st to september 30th .
the data cover4 unique users device models and 231apps.
every device has a unique imeiidentifier and the corresponding information of the device model is also cap tured.
user privacy protection.
we take a series of steps to preserve the privacy of involved users in our data set.first all raw data collected for this study are kept on thewandoujiadata warehouseservers whichlivebehindacom pany firewall .
second our data collection logic and analy2most apps released on wandoujia can also be found on other app stores such as google play.
5figure overview of the prada approach.
sis pipelines are governed by wandoujia employees3to ensure compliance with the commitments of wandoujia privacy stated in the term of use statements.
third and the most significantly wandoujia employees anonymize the useridentifiers before any data analysis.
only aggregated statis tics are produced for the users covered in our study period.
finally we obtain the approval from the research ethnics committee of school of electronics engineering and computer science in peking university to conduct this research.
.
prada in a nutshell based on the collected data prada aims to recommend the device models that should be prioritized for a new app which has not been used by many users and therefore its usage data is either unavailable or untrustable.
the basicidea is to predict the expected usage of this new app basedon the characteristics of the device models of existing apps that are similarto the new app.
we assume that the usage data of this new app cannot be attained or is not informativeto use.
we describe the key components and workflows of prada as illustrated in figure .
usage data collection.
prada is general by leveraging various usage data from an operational profile.
currently prada employs the wandoujia management app which provides the interface for collecting multiple types ofusage data of an app on a device such as the lengths ofin app network sessions the volume of network traffic the energy drain and the user reviews.
developers can choose one or more types of usage statistics of their interest as fea tures for prioritizing device models.
for example some de velopers may want to know which device models accountfor longer time of network usage and design device specific ads to target that audience some developers may distribute moretestingeffortsondevicemodelsthatcontributetomore negative user reviews etc.
similar app selection.
prada employs the idea of collaborative filtering for an app whose major device models need to be predicted prada relies on the usage datafrom a set of existing similar apps.
in practice prada is compatible to different types of app similarity measurement e.g.
the name textual description code library and category.
in this paper we adopt the category of wan3the last author is the co founder and cto of wandoujia.
he supervises the process of data collection and deidentification.doujia s classification system4.
for each new app we choose some existing apps with usage data from the same category and perform the following steps.
although the category may be conceptually coarse grained using the category can help achieve sufficient effectiveness as shown in our evaluation.
device model clustering .
given the selected type s of usage statistics prada conducts an offline analysis of the device model distribution of each app from the selectedsimilar apps.
in this step prada summarizes all devicesthat have ever produced the selected usage data of the app andclustersthemaccordingtotheirdevicemodels specified in their identifiers .
for example assuming that there are 000samsung galaxy s3 smartphones using a specific app weaggregatetogethertheselectedusagedatageneratedover them.
device model prioritization.
as the core component of prada device model prioritization produces a ranked list of device models based on predicting the selected type of usage statistics.
to prioritize the device models pradais designed based on the following two rationales.
pareto distribution.
it is well known that in many situations a larger portion of effects comes from asmaller percentage of the causes or roughly rule known as the pareto distribution .
we hypothesize that a similar distribution is still valid inthe distribution of usage data contributed by devicemodels.
if such a hypothesis holds we can remove alarge portion of device models to significantly reducethe space of prioritization.
collective intelligence.
thesecondrationaleisthat similar apps may share similar distributions of devicemodels.
hence we can leverage the knowledge derived from a large number of existing similar apps to predict the to be prioritized device models for a new app.
this rationale is shared by collaborative filtering which is a major approach underlying most rec ommender systems .
various collaborative filteringtechniques adopt different notions of similarity .
basedontheprecedingtworationales thegoalofprada is to recommend a small set of device models that accountfor a desired coverage of usage data of a new app given bythe distribution of usage data of existing similar apps.
.
effectiveness metrics before presenting the details of prada we introduce some metrics to evaluate the effectiveness of any concretealgorithm that prada incorporates.
the first metric is the device model hit which is the number of recommended device models by prada for anapp that are actually among the top device models of theapp observed after the app is deployed and used by users .
definition given the number of device models denoted as n to be recommended and the number of the existing similar apps denoted as k the device model hitis the size of the overlap between the recommended n device models d prime d prime .... d prime n and the actual top ndevice models d1 d2 .... d n .
formally we can define device model hit n k dnrecommended intersectiondisplay dnactual 4wandoujia s classification system is based on criteria including the developer s annotation textual description and some code level analytics.
the details of the classificationsystem is out of the scope of this paper.
6supposetheactualtop5devicemodelsare d1 d2 d3 d4 d5 .
ifpradarecommends d2 d3 d1 d5 d6 th edevice model hitis .
thedevice model hit measures how many recommended device models are valid but does not distinguish among these recommended items.
in practice the ranking of the recommendations is usually important so that the develop ers can prioritize on any number of device models based ontheir budget.
we use the metric of average precision abbreviated as api nt h er e s to ft h i sp a p e r t oe v a l u a t et h e effectiveness of the ranking of device models such metric h a sb e e nw i d e l yu s e di ne v a l u a t i n gs e a r c he n g i n e s .
definition average precision ap of the selected ndevice models d prime d prime .... d prime n is the average precision ofd prime i lessorequalslanti lessorequalslantn against the actual top ndevice models selectedfortheirtoprankinginthecontributionoftheusage data ap n summationdisplay i 1precision d prime i n precision d prime i denotes the precision at cut off position i where the device model d prime istays in the ranked device model list.precision d prime i is equal to when d prime iis not found in the actual top ndevice model list.
we take a simple example to illustrate ap.
suppose that the actual top device models the ground truth with themost usage data are d d2 d3 d4 d5 where each device model is ordered according to its contribution to us age data.
when the set of ground truth is fixed the order of the device models is no longer concerned.
assume that the top device models recommended by prada are d d2 d3 d4 d6 then the apis computed as .
.
note that two sets of device models that have the same device model hit m a yv a r ym u c hi nt e r m so fap.
consider another list of device models d6 d1 d2 d3 d4 w h o s e device model hit is still .
however its apis .
.
the third metric that we use is the usage data coverage which measures how much the recommended device modelscover the entire set of usage by the actual top ndevices of the app.
such a metric can reflect how much the recommended device models can contribute to the usage data of interest and therefore has an indication of the potential opportunity of revenue.
definition usage data coverage is the percentage of aggregated usage statistics of recommended ndevice models over the aggregated usage statistics of actual top n device models.
formally we can define usagedatacoverage n k usage data d nrecommended usage data dnactual asuccessfulinstantiationofpradaisexpectedtoachieve high scores of the three metrics.
next we illustrate how to use prada to prioritize device models.
.
time share driven prioritization in this section we illustrate prada through an example case focusing on the in app browsing time collected fromwandoujia while using the category to determine similar apps.
.
browsing time on an app as shown in figure the wandoujia management app provides a system wide service for recording daily network activity statistics of each app for both wi fi and cellular 2g 3g lte .
the wandoujia management app does not record the details of each interaction session.
instead itrecords the total daily access time generated from both wi fi and cellular network by aggregating the time across tcpflowsgeneratedbyanapp.
thewandoujiamanagementapp treats the network access time generated from foreground and background respectively.
foreground access time is computed only when a user browses an app i.e.
the app is currently active on screen.we can roughly measure how long a user is really online when she interacts with the app by aggregating the foreground access time of wi fi and cellular.
we call such aggregated time as browsing time unless stated otherwise we exchangeably use time and browsing time in the rest of this paper .
such a type of operational profile could be a useful indicator for app developers.
for example in app advertisement is an important revenue for mobile appdevelopers .
furthermore as suggested by facebook it becomes popular to customize device specific ads .
a common rationale used by online advertisement is that the longer a user stays on the site the more probably she willclick through the ads.
although the browsing time cannotcapture the offline usage of an app such metric is valuable as apps with online app usage are increasingly widespread and important.definition formally we define the browsing time for an appacontributed by device model das follows time d a summationdisplay time d i a here ddenotesaspecificdevicemodeland diisaparticular device that belongs to device model d i .
e .
d i d. to reflect the importance of device models that account for browsing time we introduce the metric time share as the indicator of ranking.
the time share of a device model is the percentage of browsing time consumed by the specific model to that consumed by all the models that use the app.
definition formally we define the time share as follows time share dj a time dj a summationtexttime dk a here time dj is the time spent on a specific device model and summationtexttime dk is the total time spent on all device models i.e.
all users of the app.
the higher time share a device modeldjholds the more time users use the app on dj.
suppose that we select ndevice models we can use the metric of time share coverage to concretize the usage data coverage defined in equation to measure the effectiveness of prada.
time share coverage ti m e dnrecommended summationtextti m e dk a ti m e dnautual summationtextti m e dk a time share dnrecommended time share dnactual .
collaborative filtering by time share recall that the prada approach accepts inputs as the target app and na st h en u m b e ro fd e v i c em o d e l s 7that app developers would take into account.
we predict the rank of time share from device models for this target appbased on the known similar top k apps in the same app category.
then the collaborative filtering technique outputs the topnmajor device models.
more specifically we derive dmas the set of device models that at least one app of the k apps uses.
then across all apps in the k apps we compute the aggregated browsing time for each device model in dm.
finally we sort the device models in dmby their aggregated browsing time and recommend the top ndevice models as output for the target app.
to evaluate the effectiveness of the collaborative filtering technique we then perform the process of leave one out cross validation loocv .
loocv uses one observation as the validation set and the remaining observationsas the training set and then repeats as each observation hasserved as the validation set.
thus for each of the kapps we use the browsing time of the remaining k apps to predict the top device models for the app.
in particular we use loocv rather than hold out cross validation since most apps have far less browsing time than popular apps.
for each app category we select kapps and run the algorithm dhas a list of angbracketleftapp device model hit angbracketright tc as a list of angbracketleftapp time share coverage angbracketright andapas a list of angbracketleftapp ap angbracketright.
for the inputs we take a list of kapps al a total set of angbracketleftdevice model time angbracketright for all the kapps.
in each iteration of the algorithm the app ais treated as a new app validation set and the remaining k apps as the existing apps training set .
for each app a w e first obtain the angbracketleftdevice model time angbracketright set a from to find the actual top ndevice models td .
then we use the other k apps to recommend napps td prime for app a.u s i n g tdandtd primeofa we can calculate the intersection results as device model hit and calculate apusing equation .
finally for each device model dintd prime w e update the timewith the timefrom aand calculate the time share coverage using equation .
to better illustrate the algorithm we present an example ofgameapps.
suppose that nis and kis in our example respectively.
we instantiate aas app modoomarble5 a popular game from tencent .
by aggregating thebrowsing time of device models from the other popular 99gameapps we obtain top device models as the recommendations for modoomarble.
comparing the device models with the actual top device models of modoomarble we find that the first device models are overlapped and thus the apis .
.
the actual top device models account for .
time share of the total time of modoomarble while our selected device models account for .
.more specifically the two distinct device models selectedby our technique xiaomi 2s andxiaomi d on o to c c u r in the actual top device models of modoomarble a n d these two device models actually contribute .
and .
time share respectively.
in contrast the two device modelsmissed by our technique htc one andnexus a c c o u n t for .
and .
time share respectively.
however thetime share coverage of our technique against the time sharefrom actual top device models can reach .
i.e.
.
.
.
device model hit dh time share coverage tc and average precision ap against top n device models with kapps in the same category input al n k output dh tc ap foreach app ainaldo a a get angbracketleftdevice model time angbracketright for all device models using app a td a max n a get top ndevice models most used by a al prime al a al primeis the list of apps except a prime uniontext a prime al prime a prime get angbracketleftdevice model time angbracketright for all device models using apps in al prime timeof samedevice model is added up td prime max n prime get top ndevice models most used by al prime as the prediction for a dh a td a intersectiontexttd prime the intersection of predicted ndevice models and the actual ones ap a summationtextn i td a top i intersectiontexttd prime i n get the apof the prediction a td a top imeans the subset constituted of the top i items in set td a foreach device model dintd primedo td prime d a d get the time that d intd prime s p e n to na end tc a summationtext dtd prime d summationtext dtd a d get the time share coverage of the recommended device models for a end .
ev aluation in this section we evaluate the prada approach over two typical types of apps that care about browsing time gameandmedia.
more specifically we intend to answer two research questions rq1 how many device models account for the majority of the browsing time?
to demonstrate the pareto distribution underlying prada we perform a characteristic analysis of the time share distribution of alldevice models for apps from two popular categories.
rq2 how effectively can prada identify major device models for a new app given that developers have noknowledge about this app s actual usage?
to demonstrate how the collective intelligence c a nh e l pd e v i c e model prioritization we explore the utility of the timeshare to help app developers select nmajor device models of a new app whose time share usage is en tirely unknown.
here we apply our collaborative fil tering technique to predict the time share of the appbased on the browsing time of top k apps from the same app category.
.
device model distribution we first address rq1 i.e.
how many device models account for the majority of the browsing time?
this question 8corresponds to the pareto principle of the time share distribution of all device models for an app and can indicate the number of major device models for an app.
in our three month dataset we have a total of distinct android device models.
it would seem to be quite challenging and time consuming for app developers to work acrossthewholesetofexistingandroiddevicemodels.
hence prada first summarizes the distribution of device modelsof an app according to the browsing time.
in our current approach we take the apps from the same category as similar apps.
there are categories defined by wandoujia such as communication tools media a n d game.
we aggregate the browsing time of all apps belonging to the same category.
this clustering process can better organize a large number of apps and identify which cate gories contribute more browsing time.
results show thatapps from some categories take up a lot of browsing time.we refer to such apps as networked apps .
wetheninvestigatethetimesharedistributionatthelevel of every individual app.
we choose two networked app categoriesgameandmedia.
table number of device models and users that use top apps from each of the two categories.
category of device models o fu n i q u eu s e r s game media table shows the number of device models and unique users that use top apps from each of the two categories.
each category has millions of recorded users.
such a scale of data can promise a comprehensive analysis.
for each category we choose the top apps by their aggregated browsing time from all device models using the app.
fig ure shows the maximum median and minimum numberof device models that can account for x time share of apps of each category where xvaries from to .
although the maximum and minimum varies a lot for a specific app themedian number of device models that account for timeshare is generally around .findings.
theprecedingresultof rq1validatesthepareto principle of the distribution of device models contributing tobrowsing time.
although the distribution does not strictlyfollow the rules in the pareto principle it still showsthat a quite small percentage of device models can accountfor a quite large portion of browsing time.
it indicates that developers of apps in these app categories can significantly narrow their selection space.
meanwhile developers can approximately estimate how many device models they should use to reach a desired time share.
time sharenumber of device models maximummedianminimum a game time sharenumber of device models maximummedianminimum b media figure the maximum median and minimum numbers of device models covering x time share for each app in the two categories.
.
predicting top device models based on the distribution of device models derived from rq1 we can help reduce a large number of device models from the fragmented android markets.
however such a finding is based on the assumption that the usage data is already known.
for a new app that is to be put on shelf andis not associated with informative knowledge of usage data how can we leverage the findings of rq1to predict the device models to prioritize?
thus we next address rq2 i.e.
how effectively can prada identify major device models given that developers have no usage knowledge about this app?
such an evaluation is done by applying the collaborative filtering algorithm .
we still investigate the apps of the two categories gameandmedia.
for an app ain one category we assume that its usage data is unknown.
we then apply the collaborative filtering algorithm to find the set ofndevice models with the most time share by leveraging the browsing time from the remaining k apps in the same category.
here we assign nas while kas .
we then report the distribution of device model hit time share coverage a n daverage precision against the ground truth of a. we repeat the process for all apps for each category.
in particular to evaluate the overall precision ofall apps we consider the widely used metric mean average precision map w h i c hi su s e dt or a n kt h er e s u l t sf o r a large number of queries .
hence we also compute map for apps from each category as follows map n k summationdisplay j 1ap j k .
.
results we report the results of device model hit time share coverage a n dapoftop10devicemodelsthatarepredicted by prada for apps in each category i.e.
n and k .
it is observed that prada works quite well for both categories.
for apps in the gamecategory the device model hitis with as the median as the maximum and as the minimum shown in figure a .
correspondingly theboxplot of figure b illustrates the time share coverage from the selected device models against the actual top device models with .
as the median up to .
asthe third quartile and not less than .
as the first quartile.
the median of apcan reach .
as median and the mapforgameapps is .
which is a satisfactory score.
similar to the gamecategory the device model hit results for mediaare shown in figure a with as the median.
in terms of time share coverage a ss h o w ni n figure b our technique can reach .
as the median .
as the third quartile and .
as the first quartile respectively.
the median of apis .
and the mapfor mediaapps is .
.
although the core of prada is to leverage usage data it is quite common that developers usually choose the device models from the most market share.
however such a selection is too coarse grained as it relies on only the number of active device models that have been on the market.
more seriously such selection may be inaccurate with respect to a specific metric of the developers interest.
wemake a simple comparison study between the top devicemodels that are predicted by prada and that are directly 9table top device models with the most time share for two apps temple run and xunlei movie and the selected device models by appbrain wandoujia and prada.
top device models in market top device models for temple run top device models for xunlei movie appbrain wandoujia ground truth prada ground truth prada galaxy s3 galaxy note galaxy note galaxy note galaxy note galaxy note galaxy s4 galaxy s4 galaxy note galaxy note galaxy note galaxy note galaxy note galaxy note galaxy s4 galaxy s4 galaxy s4 galaxy s4 galaxy s5 galaxy s3 mx mx mx mx motorola moto g galaxy win galaxy s5 galaxy s5 mx galaxy mega .
galaxy s3 mini xiaomi 2s xiaomi galaxy mega .
galaxy s5 galaxy s5 galaxy tab .
xiaomi xiaomi 2s mx galaxy mega .
mx galaxy note mx galaxy mega .
galaxy s3 htc one galaxy s3 galaxy s duos galaxy mega .
mx xiaomi 2s galaxy s3 xiaomi 2s galaxy s2 galaxy s2 galaxy s3 xiaomi lg nexus galaxy s2 appbrain wandoujia our approach top device models from appbrain wandoujia and our approachdevice model hit a device model hit appbrain wandoujia our approach top device models from appbrain wandoujia and our approachtime share coverage b time share coverage c average precision figure comparison of device model hit time share coverage a n dapby using market share and prada to recommend top device models for gameapps.
obtained from the market share respectively.
the goal of such a comparison is two folds.
first we aim to demonstrate that simply relyingon the marketshareis toocoarse grained and even inaccurate for prioritization with respect to a specific metric of interest.
second we aim to demonstrate thatprada can achieve a satisfactory accuracy to help selectdevice models.
to align with the time of our collected dataset we choose the market share reports of android device models of the 3rdquarter2014 fromthewell knownappbrainwebsite .
appbrain provides a global market share of device models.
due to the lack of detailed local market share of device mod els we derive a local market share by aggregating the active users of a specific device model from wandoujia.
we also compute the three metrics device model hit time share coverage a n d ap by using the device models with the most market share of appbrain in short asusing appbrain and the ones with the most market shareof wandoujia in short as using wandoujia respectively.from figure a we can observe that for the gameapps the device models selected by using appbrain reach asthe median of the device model hit .t h es i t u a t i o no fu s i n g wandoujia is a bit better than using appbrain reaching a st h em e d i a no ft h edevice model hit.
in other words device model hit by market share is worse than using prada considering time share.
in figure b the median of time share covered by the device models by prada is .
.
incontrast the value by using market share of wandoujia is92.
while the median of using appbrain is .
whichis the lowest.
additionally the mapv a l u ei s0 .
9b yu s i n g appbrain .
by using wandoujia which is far away from0.
by using prada.
similar observations can be made formediaapps.we show an example by two typical apps which are also popular on google play the temple run 6and xunlei movie7.w el i s tt h et h ed e v i c em o d e l s w i t ht o p1 0m a r ket share from appbrain and wandoujia descending orderof market share in columns and respectively with the most actual browsing time for the given apps descending order of time share in columns and ranked byprada columns and in table .
the top device models with the most market share by appbrain can cover only out of the top devicemodels for temple run and xunlei movie compared to the ground truth of browsing time.
more specifically app brainmisses5ofthetop10devicemodelsfor temple run .
the device models missed by appbrain are mx xiaomi xiaomi 2s galaxy mega .
a n d mx .
in contrast prada can hit all of the top device models.
for thexunlei movie appbrain misses device models i.e.
mx mx galaxy mega .
htc one a n d lg nexus w h i l e prada misses only htc one and lg nexus .
the device models with the most market share from wandoujia canhave higher device model hit for temple run and for xunlei movie but the hit ratio is still lower than prada.
as fortime share coverage it is .
for temple run 2and .
for xunlei movie by using the top device models from appbrain.
in contrast prada can achieve100 and .
.
using wandoujia market share performsbetter than appbrain but still worse than prada whichachieves .
and .
for the two apps respectively.
theapvalues by device models of appbrain of the two apps are both less than .
.
the apis unsatisfactory .
fortemple run and .
for xunlei movie b yt h et o pd e imangi.templerun2 xunlei.cloud appbrain wandoujia our approach top device models from appbrain wandoujia and our approachdevice model hit a device model hit appbrain wandoujia our approach top device models from appbrain wandoujia and our approachtime share coverage b time share coverage c average precision figure comparison of device model hit time share coverage a n dapby using market share and prada to recommend top device models for mediaapps.
vice models from wandoujia s market share.
prada can reach the apof .
and .
respectively.
such result illustrates that relying on only the market share is not accurate to predict the top device models against the actual opera tional profile of an app.
.
.
findings when addressing rq2 we have some findings.
when prioritizing device models using the market share is not always sufficient or even accurate with respect to a specific usage data e.g.
browsing time.
in contrast prada canmore accurately identify device models on which users spendmost browsing time.
another finding is that the results derived from the wandoujia market share are usually better than those from app brain.
such result indicates that the localization plays animportant role of device model prioritization.
even relyingon the market share app developers targetingdifferent areas would need to treat device models differently.
in both categories there are some apps not well supported by our technique.
for example in mediaapps we find apps whose time share coverage is or close to e.g.
htc album umi media player .
and android music player .
.
indeed all top devices of htc album are d e v e l o p e db yh t c .m o s to ft h et o pd e v i c em o d e l so f umi media player and android music player are local manufacturers from china.
these two apps are also customized for these manufacturers and preloaded on their devices.
in summary prada can accurately predict top device models even if no informative usage data is given.
.
discussion the key idea of prada is to predict top device models of an app based on the usage of similar apps and the measurementofsimilarity isquitegeneralinprada.currently the selected similar apps are based on the app category.
indeed generally assuming that apps from the same categoryto be similar is a bit simplistic and coarse grained but the classification system of wandoujia has some effective criteria to categorize the apps.
our evaluation has already shown effective results achieved by using the app category.
indeed someexistingcomplexmetricsproposedintheliterature can be integrated into prada.
although we choose only two popular app categories as illustrating examples evidence actually supports that thetop device models can vary a lot among different app cate gories.
there are categories defined by wandoujia i.e.
business communication finance game lifestyle media mother andbaby news productivity reading andstudy shopping social tools a n dtravel.
we perform the pair wise comparison of top device models between categories and the overlap is quite low.
for example the device modelxiaomi 2s is ranked as in the top list of game but does not appear in the top lists of other app cat egories.
xiaomi which is ranked as in the top list of game isnotrankedasinthetop 10lists of13other appcategories.
thus it is important to conduct category specificrecommendation of device models as done in prada.
.
implications based on a large scale dataset collected from real world users on interacting with android apps we have evaluatedthat operational profiles such as browsing time can accurately prioritize device models in the app categories of game andmedia.
although the specific results e.g.
which specific device models were top for an app or app category from this study are useful for developers device models andtheir usage are constantly evolved and more recent usage data shall be used to re apply prada in practice.
hence we should focus on our general findings and methodologies beyond the specific results.
relying on the market share is not always accurate with respect to a specific metric of interest.
in other words more users do not always lead to more usage.
therefore develop ers need to carefully explore and avoid uninformed invest mentonpopulardevicemodels whichmaynotbesignificantwith respect to the metrics of their interest.
theideaofleveragingthecollectiveknowledgefromlargescale usage data is feasible.
by using the time share frommajor device models of other apps in the same app category developers of new apps can accurately select major devicemodels even when the developers do not know which devicemodels would heavily use their apps in the future.
in addi tion such idea can be extended to other types of usage data of an app such as reported bugs user reviews traffic and energy drain over a specific device model.
indeed applying an approach such as prada requires a sufficient usage dataset that is legallycollected from users.
we plan to release a sample anonymized dataset to otherresearchers for further study.
in addition we plan to makeprada available as an analytic service for assisting android developers who publish or plan to publish their apps on wandoujia.
.
threats to v alidity we have evaluated our approach in two main networked app categories.
this section discusses the threats to validityin our evaluation.
a threat to validity includes the localization using only wandoujia primarily in the china market .
all users and 11usage data are from wandoujia because other marketplaces such as google play do not release their usage data exter nally.
we cannot validate the time share based techniqueover users and apps that are not included in the wandoujia dataset.
although the large scale of dataset could provide comprehensive results to developers in china developers from other regions cannot directly use the results asreference to predict device models for their apps used intheir regions.
however the general idea of prada couldbe applicable if developers have other published usage datasuch as appjoy and livelab .
however the data should be at scale to enable comprehensive analysis.
in future work we plan to alleviate this threat by applying prada on other usage data beyond the wandoujia dataset.
we apply prada based on a specific usage data i.e.
the browsing time that comes from foreground network accesstime in an app indicating how long users interact with theapp.
the metric of time share can measure the importance of a device model for a specific app.
although most of these apps need the network connection some of them do not always produce foreground network activities.
instead their network activities are often performed in the background such as downloading or updating.
some apps are mainlyused offline such as pdf readers.
therefore our approachcould not be generalized to all kinds of apps if only the browsing time is used.
however the significance of using browsing time still remains because apps with online appusage are increasingly widespread and important.
in addi tion as long as using online app usage allows to preservethe ranking of device models it can still achieve effective results.
thetimesensitivityalsoimpactstheeffectivenessofprada.
we limit only months of data to evaluate our approach i.e.
from july to september.
one reason for such studysetup is that we want to compare the effectiveness of thetime share and market share where the latter is usuallymade quarterly.
however it is well known that the upgradeof smartphones is quite frequent and users may buy newdevices.
hence the number of users for a device model maykeepchanging correspondinglyleadingtothechangeoftimeshare for an app.
therefore for app developers using our 3months of dataset could not well predict the currently major device models.
to alleviate this threat possible solutionsinclude performing our approach online by using the latesttime share collected from the wandoujia management app or exploiting wandoujia data covering a longer time span e.g.
year or longer to learn how user behaviors impact time share and improve the effectiveness of our approach.
to this end we need the server side support of wandoujia such as exposing online data retrieval apis and avoid po tential side effects and interferences to other online servicesof wandoujia.
the release date of a device model can also impact the effectiveness of prada.
prada relies on the real usagecollected from substantial users within a reasonable period.if a device model is recently released and no enough usagedata can be collected from this device model the application scope of prada may be limited.
such a limitation cannot be completely overcome as the device model is entirely new.however the situation can be alleviated.
one promising solution is to reduce the latency between the release date of the device model and the collection of usage data.
to thisend prada can be deployed over the wandoujia server being timely sensitive to the usage data collected from thisnew device model.
to predict device models we use only the category of apps defined by wandoujia to obtain similar k apps for the collaborative filtering in prada.
therefore the performance of prada currently relies on the accuracy of wandoujia s category taxonomy of apps.
as found in our pre vious work a lot of apps from different categories mayalso have very high similarity.
besides the category infor mation more profiles of apps such as the vendor information user reviews app requirements and libraries can be further leveraged to collect those apps sharing similar fea tures with the given app under consideration.
some existing metrics are under consideration to be plugged into prada.
.
conclusion and future work to address the challenges caused by android device fragmentation inthispaper wehavepresentedthenovelpradaapproach by using real world usage data collected from alarge number of users.
prada includes a collaborative fil tering technique to accurately predict major device modelsfor a new app given the usage data from existing apps withsimilar functionalities.
we have evaluated prada by using the in app browsing time which indicates how much users interact with an app on a specific device model.
in our study we used apps from two app categories gameand media spanning three months and covering .
mil lion users and .
thousand device models.
implicationsderived from our findings provide useful guidelines for an droid app developers.
since most of the data collected from wandoujia is from china a great deal of localization issues may account fordifferences compared to the global market.
we plan to in vestigate the impact of localization on device model prioritization in future work.
we also plan to further explore how to cluster device models at different granularities.
an other ongoing effort is to measure the fragmentation impact caused by the great diversity of android os versions when applying prada.
acknowledgment this work was supported by the high tech research and development program of china under grant no.2015aa01a203 the natural science foundation of china grant no.
.
tao xie s work wassupported in part by national science foundation under grantsno.
ccf ccf cns ccf andcns andagooglefacultyresearchaward.
qiaozhumei s work was supported in part by the national science foundation under grant no.
iis .
the authors would like toappreciate le lian for valuable suggestions on the application context of this work.
.