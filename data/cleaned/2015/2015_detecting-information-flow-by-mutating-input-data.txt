detecting information flow by mutating input data bj orn mathis vitalii avdiienko ezekiel o. soremekun marcel b ohme and andreas zeller saarland university saarbr ucken germany mathis avdiienko soremekun zeller st.cs.uni saarland.de national university of singapore singapore marcel.boehme nus.edu.sg abstract analyzing information flow is central in assessing the security of applications.
however static and dynamic analyses of information flow are easily challenged by non available orobscure code.
we present a lightweight mutation based analysis that systematically mutates dynamic values returned by sensitive sources to assess whether the mutation changes the values passed to sensitive sinks.
if so we found a flow between source and sink.in contrast to existing techniques mutation based flow analysis does not attempt to identify the specific path of the flow and is thus resilient to obfuscation.
in its evaluation our m uta flow prototype for android programs showed that mutation based flow analysis is a lightweightyet effective complement to existing tools.
compared to the popular f low droid static analysis tool m uta flow requires less than of source code lines but has similar accuracy on tested real world apps it is able to detect flows that flow droid misses.
i. i ntroduction when assessing the security of applications information flows play an essential role which information sources does the application access and to which sinks does it send these to?
consequently static analysis tools that detect such information flows see a substantial interest both in practiceas in research for the android operating system tools like f low droid or i ccta represent the state of the art.
static flow detection tools are effective but they suffer from the principal limitations of static analysis notably that allcode must be available for analysis.
this problem is illustrated inthe example app in figure .
the application first accessessensitive information a namely the user s phone numberviagetline1number .
this information is then sent via sms to some third party b .
the flow between a and b can be easily detected by static analysis and is properly reported by f low droid and i ccta.
however obfuscated flows cannot be detected so easily.
the example app contains a native method a piece of code that runs directly on the processor and whose source is written inc or c in contrast to the dalvik byte code derived from the java source.
the devid method d simply takes a string and returns it.
after the sensitive id passes through devid xis set and passes into c however f low droid and i ccta will miss the flow from a to c because it passes through native code which these tools cannot analyze.
in principle one could extend static analysis to also consider machine code and a simple identity function like devid would be easy to recognize.
at the machine instruction level public class hellojni extends appcompatactivity override protected void oncreate bundle savedinstancestate super.oncreate savedinstancestate setcontentview r.layout.activity hello jni textview tv textview findviewbyid r.id.hello textview smsmanager sms smsmanager.getdefault string id mgr.getline1number asms.sendtextmsg id b ...string x devid id tv.settext x ... sms.sendtextmsg x c public native string devid string id dstatic system.loadlibrary hello jni fig.
.
the hellojni android app uses the java native interface jni to obfuscate a flow.
the flow from getline1number a to sms.sendtextmsg b can be detected statically as well as dynamically.
however the flow from a to c can only be found by m uta flow because idflows through the native method devid d .
though it is even easier to obfuscate flows since there is virtually no limit to what the function can do and any prediction isultimately thwarted by the halting problem.
a static analysercan then either be optimistic and assume nothing bad will happen as with runtime functions or be pessimistic and assume anything may happen.
neither resolution is completelysatisfactory.
in contrast to static analysis dynamic analysis allows to analyze concrete executions rather than abstract code.
dynamic tainting for instance tracks data throughout the execution and would just as well detect a flow from a to b. finding theflow from a to c via d though would require to track datathrough the hardware or a hardware interpreter which is nosimple feat.
developers wishing to conceal what devid is can also resort to implicit information flow turning data flow dependencies into control flow dependencies andagain requiring static analysis to identify the alternative controlflows.
since existing dynamic and static tools need to analyzethe concrete path along which the information travels theycannot detect deliberately hidden flows such as from a to c. in this paper we investigate a lightweight mutation based alternative to detect information flows.
rather than staticallyanalyzing application code or dynamically tracking data flow we use an experimental approach we systematically mutate the information sources of a program to assess whether .
c circlecopyrt2017 ieeease urbana champaign il usa t echnical research263 authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
the mutation impacts its information sinks.
specifically our muta flow prototype takes an android app as well as a set of test cases given or generated instruments sensitive data sources and sinks in the app tomutate input values at sources and track output values at sinks executes tests on unmutated and mutated app versions records the values passed to sensitive sinks reporting a flow if the value changes due to a mutated sink value.
in our example figure m uta flow runs the app twice the first time unmodified and the second time injecting a different input value for getline1number a .
it then detects that this change causes a change in the calls to sms.sendtextmsg b as well as sms.sendtextmsg c .
the previous problem that id flows through a native method d has no consequences for m uta flow i t only cares about how changes in sources affect sinks without having to track the path.
all changes made by m uta flow simulate changes in the external input data the actual program functionality is never altered.
the advantage of m uta flow over static analysis approaches is that it hardly overapproximates it is sound in the sense that if it detects a flow this flow is most likely real.
however as any dynamic approach it is also incomplete as there may always be executions which exercise flows notpreviously detected.
hence m uta flow could be seen as a complement to static analysis approaches focusing on problem areas such as non analyzable code.
however mutation based flow analysis can also be seen as an alternative analysis should static analysis not be available or possible.
this is because as we show in this paper the accuracy of muta flow in detecting flows is similar if not superior to static analysistools such as f low droid oriccta.this poses mutationbased flow analysis as a new and promising alternative in our portfolio of program analysis techniques.
in summary this paper makes the following contributions we introduce mutation based flow analysis a lightweight program analysis technique to detect information flows.
we introduce m uta flow as a prototype implementation for analyzing android apps section ii .
m uta flow is less than of the size of f low droid .
in its evaluation against f low droid section iii we find that m uta flow shows comparable performance as f low droid in terms of precision and recall and is able to detect several flows that f low droid misses section iv .
after discussing related work section v we close with conclusion and consequences section vi .
to facilitate repli cation m uta flow and all data from the experiments are available as open source.
ii.
a pproach and implementa tion mutation based flow analysis attempts to detect information flow between a source aand a sink b. both fundamentals aswell as implementation are illustrated using the example infigure .
a. prerequisites we start with a program pand an execution e the execution can either be given e.g.
from a given test case or generated e.g.
from a test generator .
m uta flow starts with an application package apk that contains the app binary as well as all resources to execute it.
astests m uta flow can use supplied tests as well as leverage the monkey testing tool to generate executions.
a largernumber of executions with high coverage of functionality increases the chances of detecting flows.
in our example figure the method oncreate is invoked automatically as the app starts which is actually a plausibleattack vector for a malware in order to collect as much information from as many users as possible.
b. logging given a source aand a sink b within the execution e w e log the concrete values of aandb denoted as a 0andb0.
muta flow instruments the apk as follows.
the instrumenter gets the apk the user wants to analyze and converts it from the compiled code to jimple code with soot .
jimplecode is a meta representation of java code and is used by soot a framework with which one can also iterate over the code andinject method calls.
in a second step a log caller and mutation class file we created is compiled with soot to jimple code and injected into the decompiled apk.
now we can iterate over the source code line by line and inject methods from this classto write values to the log or mutate source values.
the soot framework converts the apk into classes the containing methods and for each method a chain of statements.now we can iterate over those chains of statements and injectmethod calls for logging and mutating at each source and sink.these sources and sinks were originally defined by susi atool that detects lines of code where private information flowsin or out of the application.
we use the pre computed lists ofsources and sinks from susi .
in our example figure the method telephonymanager.getline1number is listed by susi as a sensitive source hence m uta flow can inject the code log.write to log telephony.getline1number log.write to log id right after the assignment to id a .
likewise m uta flow can identify the existing logging as sensitive information sinks and insert the code log.write to log sms.sendtextmsg log.write to log id 1muta flow currently handles only java primitive types and string thus some sources and sinks in the susi set originally used by f low droid are not considered by m uta flow .
specifically we excluded sources and sinks from the susi set which do not return basic types or are not privacy invasive i.e.
these sources do not read private information or these sinks cannot be used by malware to send private information from the device.
we also added sources that we deem privacy invasive.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
public class hellojni extends appcompatactivity override protected void oncreate bundle savedinstancestate super.oncreate savedinstancestate setcontentview r.layout.activity hello jni textview tv textview findviewbyid r.id.hello textview string id mgr.getline1number aid mutator.mutate string id log.write to log telephony.getline1number log.write to log id ...log.write to log sms.sendtextmsg log.write to log id sms.sendtextmsg id b ...string x devid id tv.settext x ... log.write to log sms.sendtextmsg log.write to log x sms.sendtextmsg x c public native string devid string id dstatic system.loadlibrary hello jni fig.
.
the hellojni program in figure instrumented by m uta flow .
and log.write to log sms.sendtextmsg log.write to log x before locations b and c respectively.
c. mutation we now generate alternative executions by mutating the source value.
this is done by interposing mutation code into the assignment of atoa0such that a0is changed to a prime .
muta flow uses instrumentation not only for logging values but also for mutating source values.
to this end it injects mutation code after each information source which mutates the external input value returned.
in most susi meth ods sensitive information is either passed as a string or a number.
hence m uta flow provides a mutator class that allows to mutate all java base types including strings mu tate strings and numbers e.g.
mutate int .
the string mutator replaces the middle character in the string by another one the number mutator replaces the numeric valuewith a random one.
however m uta flow does not prevent violating input pre conditions.
for instance our mutator class may produce a random source value that violates an input validation condition such violation could lead to falsepositives or reveal exceptional flows to error handling methods.
in our example figure m uta flow would inject the mutation code id mutator.mutate string id after a and before the also injected logging.
the fullyinstrumented program is shown in figure .
2susi methods are privacy relevant api calls found by susi.d.
detecting flows during the subsequent logging of sinks we check each sink b for whether its value has changed from b0tob prime .
if so we have shown that there is a flow from atob.
muta flow creates multiple versions of the apk one p with mutation disabled providing reference values for b0 and for each sensitive source a one pawith mutation enabled for this source providing potential values b prime0 .
it then runs the mutated variants paand checks for differences between the b0reference values and the b prime 0values found in the mutated apps p prime.
if a value b prime 0for some padiffers from the reference value b0 then the mutation in ahas caused a value change in b in other words there was information flow from atob.
muta flow then reports this flow including the concrete values witnesses a0 a prime0 b0andb prime0.
e. soundness in the absence of non determinism mutation based flow analysis is conceptually sound it shows that a change in a can cause a change in b a sa precedes band changing aalso changes b a counterfactual causality that also proves the existence of information flow from atob.
this is in contrast to static analysis or dynamic tainting where most relationships are possible flows rather than causal relationships in b zero a where zero always returns both techniques would detect a possible flow whereas our approach would fail to find a flow that changes a a true negative.
note that in our setting causality and thus soundness requires perfect reproducibility only if we can ensure that no other input value has changed can we be sure that itwas athat caused the change to b. in practice such perfect reproducibility is hard to achieve due to non determinism in executions timing thread schedules load randomness .
m uta flow reduces non determinism by two means.
first muta flow runs the original app pat least twice.
if the values b0in the sink bvary across executions then bis excluded.
second if m uta flow runs an app variant pa the source a is not triggered but we still observe a difference between b prime andb0forb then bis excluded.
f .
completeness mutation based flow analysis is incomplete in the sense that if it fails to detect a flow this does not mean the absence of flows.
in the code if hash input 0xdeadbeef output sensitivedata for instance generating an input that fulfills the condition is computationally hard hence it is unlikely that m utaflow will ever report the flow from sensitivedata tooutput.
an analysis that is both sound and complete for real world apps reporting all possible flows without false positives isprevented by the halting problem.
in the above example astatic or symbolic analysis can also not know whether thecondition can be fulfilled hence possibly issuing a false alarm.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
the halting problem as well as general issues of scale are the reasons why static analysis tools like f low droid or i ccta cannot claim completeness either.
in practice ways to address the limitations of incompleteness include have a suite of test cases.
in our experiments on real world apps section iii c we had a student assistant record comprehensive interactions with the apps which wecould replay at will.
such an interaction which need nottake more than minutes per app may already be partof the investigation process .
also the effort is easily offset by the modest false positive rate in m uta flow note that the manual investigation of reported flows caneasily take hours per app.
integrate with static analysis.
our mutation based analysis can easily be complemented with static analysis such thatboth sets of reported flows are joined as we do in theevaluation section iv .
further integration might guidetest generation and thus m uta flow towards locations in the code that static analysis has determined to accessand propagate sensitive information.
use run time sandboxing.
if one has a good source of tests one could easily apply run time checks to disable behavior not seen during testing.
during production the box ma te sandboxing approach for instance wouldprohibit access to all sensitive sources not accessed duringtesting e.g.
sensitivedata above and thus disable its originating flows.
a combination of m uta flow and sandboxing could make m uta flow complete by construction but may also limit desirable functionality.
g. implementation complexity from the previous description it should be obvious that muta flow is a much simpler approach than a full fledged static analysis for android let alone full fledged symbolicreasoning and checking .
to put things into perspective the full f low droid framework soot infoflow android develop and soot infoflow develop currently sports loc not counting an additional loc for the required soot heros and jasmin frameworks.5in contrast m uta flow sports only lines of java code which only is of f low droid .
iii.
e v alua tion design to evaluate the effectiveness of m uta flow we compared our tool with f low droid .
a static taint analysis tool for detecting information flows in android apps.
for our 3this process is similar to apple s manual app review .
this review process can be recorded for the application and the recorded review can then be used as input for the m uta flow evaluation.
4there are many opportunities to optimize m uta flow .
for instance muta flow currently monitors the covered sources and sinks for each run but does not use this information while running the mutated versions.
muta flow also completely rebuilds the application for each mutation.
5java source code only omitting test code determined using cloc find f heros develop src f jasmin develop src f soot develop src f soot infoflow android develop src f soot infoflow develop grep .
.java retrieved .evaluation we used android apps in three benchmarks two micro benchmarks with small apps designed to evaluate information flow detection tools and one macro benchmark with real world apps from the google play store.
our evaluation addresses three research questions rq1 effectiveness for micro benchmarks.
compared to the state of the art how does m uta flow perform in terms of precision recall and f measure for the micro benchmarks?
rq2 effectiveness for macro benchmark.
compared to the state of the art how does m uta flow perform in terms of precision recall and f measure for real world appsfrom the google play market place?
recall that weestablished the ground truth for real world apps by crossvalidation rather than by exhaustive means.
rq3 performance and scalability.
what is the runtime performance of m uta flow in comparison to the state ofthe art for both benchmarks?
a. baseline flow droid is a highly influential static analysis tool for android apps gathering more than citations since itsinitial release in .
v ersion .
was released in october and represents the state of the art in information flow detection for android apps .
like m uta flow flow droid works directly at the bytecode level and does not require accessto the app source code.
b. micro benchmarks table i micro benchmarks d roid bench and droid ra category apps flows avg.
size droidbench .0aliasing loc android specific loc arrays and lists loc callbacks loc emulator detection loc field and object sensitivity loc general java loc implicit flows loc inter app communication loc inter component communication loc lifecycle loc reflection loc threading loc droidra reflection loc loc as micro benchmarks we chose droidbench and droidra.
droidbench .
is a collection of small android apps with several categories of information flows that are obfuscated in one way or another.
v ersion .
ofdroidbench significantly extends the micro benchmark that was originally published with f low droid .
droidra provides more information flows in the reflection categories.
information flows via java reflection are particularly hard todiscover because functions are not called directly but in a 6taintdroid is also a highly influential dynamic analysis tool for android apps however it is no longer supported since it was designed for an outdated android os version .
thus it does not work on the android os version of our real world apps android marshmallow .
.
.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
convoluted manner using java specific internals such as class loaders.
the average size of an app in the micro benchmarkis lines of code loc .
from droidbench we excluded18 test subjects.
nine apps would crash when executed dueto bugs or missing permissions.
for the other nine apps therespective sources and sinks were excluded because they arenot in the susi set we used i.e.
they do not use basic types .so in total we analyze apps in the micro benchmark.
forthe remaining test subjects the categories and the number ofinformation flows are listed in table i. ground truth.
the actual information flows from a specific source to a specific sink are determined manually by investigating the small programs.
this establishes the ground truth.as true positive we consider a reported flow that actually exists.
as false positive we consider a reported flow that does not actually exist.
as true negative we consider an unreported flow that does also not actually exist.
as false negative w e consider an unreported flow that does actually exist.
executions.
to generate executions for droidbench we leverage google s ui exerciser monkey .
monkey takes an android app and generates a random sequence of user eventssuch as clicks touches or gestures as well as a number of system level events.
in our experiments we fix the length ofa sequence at user events and run one test sequencefor each variant of an app.
since monkey is essentially a random test generation tool we repeat each experiment times with different random seeds to gain statistical power.
however within one experiment we use the same test sequence for all mutated variants of the app.
for droidbench monkey demonstrates that m uta flow does not depend on pre existing test cases.
however for more complicated usagescenario e.g.
log in scenario sophisticated input generatorswould be required to reveal flows.
table ii macro benchmark a pps from the google pla y store name jimple loc size in bytes mysugr kloc .
mb ab workouts kloc .
mb adidas micoach kloc .
mb fitness at home kloc .
mb minute workout kloc .
mb fast calorie counter kloc .
mb water drink reminder kloc .
mb abs workout minutes kloc .
mb bmi and weight tracker kloc .
mb fabulous motivate me!
kloc .
mb test diabetes sugar joke kloc .
mb kegel trainer exercises kloc .
mb fitness recipe of the day kloc .
mb lifesum healthy lifestyle kloc .
mb calorie carb fat counter kloc .
mb day butt challenge free kloc .
mb blood pressure log bpresso kloc .
mb day fit challenges workout kloc .
mb calorie counter fddb extender kloc .
mb runkeeper gps track run walk kloc .
mb sum kloc .
mb c. macro benchmark asmacro benchmark we chose random apps from the google play store by first randomly selecting a category decompile app with jadx open the code in android studio so we can use features like finding the usage of methods find the source and the sink reported from the log the logs provide information about containing class and method for each source a if the value flows into the return of a method the method usages have to be checked b if the value flows into a call parameter the called method has to be checked c if the value flows into a field the read usages of the field have to be checked for each sink a if the value comes from the methods parameter the usage of the method has to be checked b if the value comes from a field the write usages of the field have to be checked a flow is found if a feasible path between source and sink is found e.g.
there must not be any checks that prevent the path to be taken for m uta flow the log can also be consulted a if a value occurs only once in the mutated execution but the api method is still called in all execution the flow is also categorized as true positive b if the mutated value is found in plain text in the sink the flow is categorized as true positive fig.
.
policy for manual classification health fitness and then randomly selecting apps from this category.
table ii provide more details about these real world apps in the absence of source code loc refers tothe length of the decompiled jimple code.
ground truth .
unlike for the micro benchmark for the realworld apps we cannot obtain the absolute ground truth but wecan cross validate.
if there are only sources and sinks we would need to manually check potential flows to identify the complete set of true informationflows for all apps.
this is clearly impractical.
however on abest effort basis we manually checked all reported information flows in order to distinguish true from false positives.
to mitigate experimenter bias we follow a strict coding protocol involving the independent classification by two researchers r1 and r2 r1and r2agree on a policy how to classify the reported flows into true and false positives.
r1classifies all flows and refines the coding policy.
r1and r2discuss the refined policy.
r2 independently classifies all flows.
r1and r2check the rate of agreement.
if the rate is too low they discuss policy and recode.
otherwise they proceed to resolve any contentions.
the final policy used is listed in figure .
to retrieve the source code from the android apps we used the dex to java decompiler jadx .
we consider as false negatives all flows that are true positives for one technique but not reported by the other.
for instance if f low droid reported an information flow from source ato sink b w e first manually checked whether there really does exist an 7coding is a methodology from grounded theory that is used in sociology and psychology to evaluate qualitative properties .
in the context of software engineering this methodology is also referred to as open card sort .
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
information flow from atoband then checked whether muta flow also reports the same information flow.
if it did not the flow was marked as false negative for m uta flow .
the manual validation was done by inspecting the source code of each app.
if the path of a reported flow was not feasible forinstance due to constants dynamic types or other influences then the flow was categorized as false positive.
executions.
almost all health apps require sign up log in or otherwise entering specific data which cannot be synthesizedby the monkey test generator.
we therefore had a user generate test sequences.
specifically we hired a student assistant whose task was to click through the app with the intention to exploremost of its features while his interaction would be recorded.the student would sign up and log in as needed and enter thedata that was required to proceed to the next user dialog.
therecorded test sequences can be replayed deterministically atwill.
for each app there is one sequence with a length of upto user interactions.
d. physical setup and infrastructure being a static analysis f low droid can execute on an arbitrary machine that has access to the app byte code in contrast m uta flow executes the app on an android device emulated or real we execute f low droid on one of our compute servers with cores and gb of ram.
for m uta flow running the micro benchmarks we use the android emulator on a pc 9emulating a nexus running android marshmallow .
.
we only ran onesingle emulator on the machine as we found parallel emulators interfering with each other.
for m uta flow running the macro benchmarks we use a single android device with six cores and 2gb of ram 10controlled by a server via the android debug bridge adb .
we use a real device instead of anemulator for two reasons.
first real world apps oftencannot be installed on an emulator as it lacks featuressuch as the google play store second real devices reportrealistic values for all sources and sinks.
as a core compute server is way more powerful than anandroid device let alone an emulated one the increase incomputing power might seem generous towards f low droid however it corresponds to a realistic setting where a usermight have a lot of computing power but access to only oneandroid device during the execution of m uta flow .
iv .
e v alua tion results a. effectiveness for micro benchmarks we start with rq1 how effective are m uta flow and flow droid on our set of micro benchmarks?
8specifically a intel r xeon r cpu e7 v4 .40ghz with virtual cores intel hyperthreading running debian .
linux.
9specifically an intel i7 4770s with virtual cores with gb ram running ubuntu .
lts.
10specifically a a nexus 5x that has a bit adreno gpu and a qualcomm snapdragon processor .8ghz with cores and 2gb of main memory running android marshmallow .
.
.
accuracy table iii shows the results for f low droid whereas table iv shows the results for m uta flow .
note that the m uta flow results are averaged over runs.
table iii accuracy of flow droid on micro benchmarks classified as input flow no flow total precision flow tp fn recall no flow fp tn accuracy total f measure table iv accuracy of muta flow on micro benchmarks classified as input flow no flow total precision flow tp .
fn .
recall no flow fp .
tn .
.
accuracy total .
.
.
f measure we see that on average m uta flow reports only .
false positives11 whereas f low droid reports false positives times as many .
with a precision of almost all flows reported by muta flow are actual flows.
interestingly the recall of m uta flow is higher too muta flow detects of all flows whereas f low droid detects .
the higher accuracy of m uta flow over f low droid is also indicated by the measures of accuracy and fmeasure.
muta flow exhibits a better precision recall and accuracy than the state of the art flow droid .
so why is the precision of m uta flow only if in principle it should be ?
the reason again is the nondeterminism as discussed in section ii e. some tests are flaky in the sense that executing the same test case twice might givedifferent results.
this flakyness stems from the randomnessthat is inherent to the android environment.
for instance whena time stamp is appended to a message it might seem as if the monitored sink that receives the message is impacted by a mutated source while it is not.
complementarity the aim of m uta flow is not to be an alternative to f low droid but rather complement it and this makes perfect sense as each technique can find flows theother does not.
as shown in figure without m uta flow flow droid would find only of the existing flows.
using both techniques of all existing flows would be detected.averaged over ten runs m uta flow finds .
actual flows that f low droid does not find while f low droid reports .
flows that m uta flow does not find.
strengths of flow droid over muta flow what are the strengths and weaknesses of each technique?
figure sum marizes the detection rates for the individual categories.
wesee that m uta flow detects fewer flows than flow droid in the categories 11for applications m uta flow had at least one false positive.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
flowdr oid .
.
.
muta flow10.
remaining undetected fig.
.
v enn diagram showing the intersection of found flows true positives for flowdroid and m uta flow on the micro benchmark.
override 2protected void oncreate bundle savedinstancestate super.oncreate savedinstancestate acquire a reference to the system location manager locationmanager locationmanager getsystemservice context.location service register the listener with the location manager to receive location updates locationmanager.requestlocationupdates locationmanager.gps provider locationlistener fig.
.
the anonymousclass1 benchmark uses callbacks to send out location changes.
f low droid detects the associated flow but m uta flow misses it because the emulator takes too long to report the changed location.
callbacks emulator detection and inter app communication.
we explain the reduced effectiveness by the fact that m utaflow requires test cases that actually trigger the flow.
for instance to detect the flows in the callbacks category monkey would need to click a specific sequence of buttons in a specific order.
the probability that our random testing tool makesthe right sequence of clicks decreases exponentially with thelength of the required sequence.
to detect the inter application flows monkey would need to open one app trigger the source close the app open the other app and trigger the sink.
with monkey as automated test generation tool m uta flow can detect only one of six inter application flows.
again we illustrate the strength of one tool over the other using an example.
in the droidbench app anonymousclass1 figure shows the essential function registering a callback handler for changed locations.
in the m uta flow setting the emulator does change the location of the device during testing but the emulator takes too long to report the change to the app hence the callback is never called and m uta flow cannot detect the dynamic flow.
strengths of muta flow over flow droid let us now go back to figure .
we see that m uta flow detects more flows than f low droid for implicit flows inter component communication and the reflection category.
we explain the improved performance with f low droid s difficulty to analyze indirect flows along convoluted paths.unlike f low droid m uta flow is ignorant of the specific path along which an important information travels.
if there isa test case that exercises both the source and the sink thenit is quite likely that m uta flow detects the flow.
hence android specificarrays and listscallbacksemulator detectiongeneral javaimplicit flowsinter app comm.inter comp.
comm.lifecycleobject sensitivityreflectionthreading detected flows tool flowdroid mutaflow fig.
.
histogram showing the number of detected flows as percentage of the total number of flows per category for both m uta flow and flowdroid.
16private string obfuscateimei string imei string result for char c imei.tochararray switch c case result a break case result b break case result c break case result d break case result e break case result f break case result g break case result h break case result i break case result j break default return result fig.
.
the implicitflow1 benchmark obfuscates a sensitive device identifier.
the implicit flow is missed by f low droid but detected by m uta flow .
muta flow performs well for implicit flows i.e.
where the data is modified or obfuscated along the path for intercomponent communication i.e.
where intents or activities are used to communicate between different components of thesame app and for reflection where java specific calls to the reflection framework are used to construct and send messages.
as a typical example of a data flow ignored by f low droid but detected by m uta flow consider the droidbench app implicitflow1.
figure shows the essential function obfuscating a sensitive device identifier.
since there isno explicit flow i.e.
a direct assignment of any data inimei toresult f low droid misses the flow.
note that dynamic tainting approaches such as taintdroid would also miss such implicit flows for the same reason.
m uta flow however easily detects the flow since any change to imei also results in a change in result this change then propagates to the sensitive sink where m uta flow can detect it.
b. effectiveness for real world apps let us now turn to real world applications and address rq2 how effective are m uta flow and f low droid on our set of macro benchmarks?
in the remainder of this section we discuss our results listed in table v. authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
table v analysis results on the macro benchmark analysis time seconds number of flows flow droid muta flow flow droid muta flow name analysis instr exec sum tp fp unknown sum tp fp unknown mysugr crash lightning ab workouts .
.
adidas micoach fitness at home minute workout crash lightning .
.
fast calorie counter water drink reminder timeout lightning .
.
abs workout minutes crash lightning bmi and weight tracker out of mem lightning fabulous motivate me!
timeout lightning test diabetes sugar joke kegel trainer exercises fitness recipe of the day lifesum healthy lifestyle crash lightning calorie carb fat counter .
.
day butt challenge free blood pressure log bpresso day fit challenges workout calorie counter fddb extender crash lightning runkeeper gps track run walk12crash lightning timeout lightning sum .
.
.
average w o lightningin m uta flow average w o lightningin f low droid running f low droid and m uta flow on the macrobenchmark not only took considerable time we also encountered a large number of crashes and timeouts.13when flow droid crashes it does not report any flows hence the respective set of flows found is empty.
following our process for establishing ground truth manually section iii c it took us between one and two hours perapp and person to validate the reported flows by f low droid or m uta flow for m uta flow validation was easier as we had an execution with concrete values to examine.
for a significant number of flows reported by f low droid we could not determine whether they were true positives orfalse positives due to their complexity.
sixty uncategorizableflows where reported by f low droid for the day butt challenge free app.
these flows went through a very large hashmap that is used throughout the app.
if a singletainted value flows into a hashmap f low droid marks the complete hashmap as tainted spreading the taints throughoutthe program.
we believe that most flows are false positivesbut conservatively mark them as uncategorizable.
the runkeeper app is special in that it drove tools and humans to their limits.
f low droid crashed on it and m utaflow was not done after hours of testing.
for m utaflow we would make use of the flows found until the timeout.
in runkeeper m uta flow detected flows that originated from a sensitive source ended in a sql database and later impact a sensitive sink here we assumed that the 12unlike the other apps in our macro benchmark runkeeper was executed only once due to changes in the back end login authentication of the app.
after our first execution we discovered that our human generated test cases for this version of runkeeper could no longer be executed because we could no longer login into this version of the app.
13all bugs encountered in f low droid have been reported.flows went through the database.
all numbers are reported in table v. accuracy table vi summarizes the results for f low droid whereas table vii summarizes the results for m utaflow .
note that m uta flow results are averaged over four runs in order to account for the inherent non determinismin the android environment.
table vi accuracy of flow droid on macro benchmark classified as input flow no flow total precision flow tp fn .
.
recall no flow fp tn .
.
accuracy total .
.
f measure flows could not get categorized flows arise from app table vii accuracy of muta flow on macro benchmark classified as input flow no flow total precision flow tp .
fn .
recall no flow fp .
tn .
accuracy total .
.
f measure the results are in line with those already seen for the microbenchmark section iv a most notably m uta flow sports a precision of whereas with f low droid only of flows reported are true positives.
given the effort it takesto manually identify a flow as true or false positive a highprecision is definitely an important goal.
on our set of real world apps of all flows reportedbym uta flow are actual flows.
considering the total set sof true positives reported by either tool and manually classified as actual flow m uta flow authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
reports of these whereas f low droid reports only here the low recall of f low droid is easily explained by completing the analysis only for out of the apps.
however one can see that the high precision of m uta flow is not offset by a low recall as indicated by the high overallf measure.
in our macro benchmark m uta flow does not report any flow for apps because of the following reasons the use of a small set of susi sources and sinks inability to trigger certain sources e.g.
due to lack of sophisticated testcases and non determinism at certain sinks.
complementarity as already indicated by the false negative numbers again each tool misses flows that wouldbe reported by the other one.
figure shows the found flowsfor each of the tools and again we see how both approachescomplement each other in their respective strengths.
flow droid .
muta flow fig.
.
v enn diagram showing the intersection of found flows true positives for flowdroid and m uta flow on the macro benchmark.
c. performance and scalability let us now close the evaluation with rq3 what is the performance of m uta flow and how does it compare to f low droid ?as already discussed in section iii d the machines we use for m uta flow a single android device real or emulated and f low droid a core compute server are very different so we may well compare peanuts and pumpkins here.
still as compute servers are still waymore common than large farms of android devices such asetting may well represent the typically available distributionof computing power.
performance on the micro benchmark on our microbenchmark f low droid takes an average time of .9s per application.
in contrast m uta flow takes .9s per application.
the longer time of m uta flow is attributed to the overhead it takes to instrument install and execute an application aswell as the performance penalty of the emulator f low droid need only analyze the very short byte code of each app.
on our micro benchmark both flow droid and mutaflow are very fast with an average time of .9s and .9s per app respectively.
performance on the macro benchmark on our macrobenchmark performance is a more interesting story.
table v lists the time taken by f low droid first column vs. the time taken by m uta flow whose time is split into instrumentation second column and actual test execution third column .looking at the times let us only consider the appswhere f low droid could determine the flows.
for these apps f low droid is very fast with an average running time of seconds or .
minutes m uta flow is about slower taking on average seconds minutes for creatingthe mutated app versions and hour seconds per app for running the tests on the individual mutants.
over all apps including the hour timeout for runkeeper muta flow takes an average of seconds or hours.
on our set of real world apps the muta flow analysis takes hours of analysis per app and device.
however keep in mind that f low droid is running on a core compute server whereas m uta flow runs on a single android device.
both mutant creation and test executionare embarrassingly parallel problems and easily distributed across multiple devices.
a rack of android devices wouldreduce the average m uta flow testing time down to minutes and thus easily catch up with f low droid and still be a much smaller investment than a compute server.
again for the practical analysis of information flows we would recommend to have both compute servers for static analysisas well as testing devices for checking concrete flows andmutations.
mutation based flow analysis is embarrassingly parallel.
d. threats to v alidity like any empirical investigation our evaluation is subject to threats to validity.
the first concern is external validity and notably generality.
first the efficiency of mutation based flow analysis and static analysis respectively is dependent on a large set of factors including analyzability of the code the effort it takes to identify sources and sinks the ability toautomatically test the code the effort it takes to create a test the time it takes to run a test the value of true positives and thecost of false positives.
hence our results do not generalize toarbitrary programs and the choice of which method s to usewill always be left to the user.
the aim of this work is simplyto point out mutation based flow analysis as a relatively simplealternative that enriches the portfolio of program analysis.
regarding internal validity our investigation of the flows may be subject to researcher bias that is we may consciously or unconsciously favor the results of our own tool overthe f low droid alternative.
for the macro benchmark w e counter this threat by following a strict coding policy asdetailed in section iii c for the micro benchmark this threat is countered by having the benchmark as well as its groundtruth all being constructed by the f low droid team who if at all would have a bias towards demonstrating the powerof their tool.
both tools are provided with the same set ofsensitive sources and sinks.
all our data and assessments areavailable for replication and scrutiny section vi .
v. r ela ted work work related to mutation based flow analysis falls into three categories.
static analysis.
static information flow analysis attempts to detect sensitive information flows from static code authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
analysis.
f low droid is the most influential representative in the android area and the gold standard for detecting flows notable extensions include i ccta to analyze inter process communication and droidra to handle reflection.
the recent dflow system is aflow detection alternative that focuses on scalability andprecision.
in contrast to all these static code analyses m uta flow is a dynamic experimental approach and thus can detect flows that static code analysis cannot as discussed in section ii e soundness and vice versa section ii f completeness .
this is also the subject ofour evaluation section iii and section iv .
dynamic analysis.
dynamic information flow analysis tracks data as it is being processed through an execution.the most influential representative in the android areais taintdroid .
its dynamic tainting tags sensitiveinput data with a label taint which is passed alongto further variables in each computation that involvesa tainted variable if tainted data reaches a sensitivesink the tool reports a flow.
as dynamic flow anal ysis can considerably slow down program execution researchers also have searched for correlations betweeninputs and outputs .
in contrast to these approaches m uta flow is an experimental approach which shows true counterfactual causality and thus soundness by construction section ii e .
experimental analysis.
experimental program analysis techniques introduce a change in the program execution and determine its impact.
m uta flow as its name suggests is inspired by mutation analysis where artificial defects are introduced into the code to determinewhether they will be caught by a test it is most relatedto the ja v alanche approach which determinesthe impact of the change in the remaining execution.given a specific statement s ens a modifies the statements during test execution in order to determineand quanitify the impact of this statement on the originalexecution.
the orbs approach selectively removesprogram statements to determine a reduced programthat observationally behaves the same as the originalprogram w.r.t.
to a slicing criterion.
however all of thesetechniques substantially change the original execution byaltering the program rather than the input coming froman information source which is arguably minimallyinvasive.
moreover none of these approaches is gearedtowards detecting the existence of flows at analysis time as mutation based flow analysis is.
vi.
c onclusion to detect information flows it can already suffice to mutate an input from a sensitive source and to see whether whilekeeping everything else unchanged this change impacts somevalue passed to some sensitive sink.
mutation based flowanalysis may seem annoyingly simple but it is very effective it can reveal flows that static analysis cannot detect and wherea static analysis tool is not available not possible or crashes it may even serve as a simple alternative.
mutation basedflow analysis thus complements and augments state of the artanalysis tools.
in contrast to static analysis mutation based flow analysis requires an execution and thus input data either generated ormanually crafted.
this requirement is offset by having to spendlittle to no effort on false positives by construction mutation based flow analysis achieves near perfect precision meaningthat close to of reported flows are actual ones.
in thelong run we see static analysis and mutation based analysistools work hand in hand such that they further strengthen theirrespective findings.
besides general improvements such as performance or stability our future work will focus on the interplay betweenstatic analysis and mutation based analysis focused test generation.
rather than using a pure random testing tool such as monkey one could guide a directed test generator towards code where static analysisalready has determined the existence of potential flows.static analysis could also tell a test generator whichvalues to provide for which source and which code toexecute in order to reach a particular sink.
mutations at function level.
the impact of mutations at sensitive sources can also be tracked at other locations in the program code not only sensitive sinks.
in figure this can help to establish the information flow within thedevid function in figure this shows that there is information flow through the obfuscateimei function.
such information at the function level not onlygives more detail about the actual information flow italso provides important function summaries for static analysis if f low droid knows from m uta flow that obfuscateimei has information flow from input to its return value f low droid need no longer miss the overall flow.
intertwined analyses.
the future of program analysis lies in the integration of several techniques static analysis dy namic analysis test generation experimental approachesas well as symbolic approaches all must work handin hand to mitigate their respective weaknesses andturn their integration into strength.
only with a broadknowledge and an open mind can we defeat today s andtomorrow s challenges of program analysis.
m uta flow and all experimental data referred to in this paper are available as open source see our package at acknowledgment our utmost thanks go to siegfried rasthofer steven arzt eric bodden and the entire f low droid team for making all of their tool chain and benchmark data available and keepingit up to date for application replication and assessment.
theirsupport has been exemplary in every aspect.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.