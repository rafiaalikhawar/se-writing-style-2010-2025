fixing recurring crash bugs via analyzing q a sites qing gao hansheng zhang jie wang yingfei xiong lu zhang hong mei key laboratory of high confidence software technologies peking university moe institute of software school of electronics engineering and computer science peking university beijing p. r. china fgaoqing11 zhanghs12 wangjie14 xiongyf04 zhanglu meih g sei.pku.edu.cn abstract recurring bugs are common in software systems especially in client programs that depend on the same framework.
existing research uses human written templates and is limited to certain types of bugs.
in this paper we propose a fully automatic approach to fixing recurring crash bugs via analyzing q a sites.
by extracting queries from crash traces and retrieving a list of q a pages we analyze the pages and generate edit scripts.
then we apply these scripts to target source code and filter out the incorrect patches.
the empirical results show that our approach is accurate in fixing real world crash bugs and can complement existing bug fixing approaches.
i. i ntroduction many bugs are recurring bugs.
recurring bugs are bugs that occur often in different projects and are found common accounting for of the bugs .
one important reason for bugs to recur is that many modern programs depend on a certain framework e.g.
android spring and hadoop.
problems may occur when certain constraints in these frameworks are violated.
for example one framework may require calling a specific method to initialize an object before using it otherwise a crash may occur.
programmers of different applications may all forget to call the specific method leading to recurring crash bugs.
the recurrence of bugs gives us opportunities to fix them automatically.
recently different approaches are proposed to fix bugs automatically by exploiting the recurrence.
one of the most influential approaches is genprog which copies code pieces from other parts of the software project to fix the current bug.
however this approach does not work if a correct fix cannot be formed from the current project.
par uses ten manually defined fix templates to fix bugs and thus is not confined by the code in the current project.
however since the templates are extracted manually only limited types of bugs can be fixed.
in real world programs bug fixing patterns can be numerous and can vary from one framework to another.
it is impractical to write every such template manually.
to overcome the problem of manual fix pattern extraction in this paper we aim to infer fixes automatically via analyzing q a sites.
we observe that many recurring bugs have already been discussed over the q a sites such as stack overflow and we can directly obtain the fixes from the q a sites.
furthermore it is common for programmers to search the q a sites when they encounter a bug with respect to a certain yingfei xiong is the corresponding author.framework which indicates that q a sites are more or less a reliable source for obtaining fixes for a large portion of bugs.
as the first step of fixing recurring bugs via analyzing q a sites we focus on a specific class of bugs crash bugs.
crash bugs are among the most severe bugs in real world software systems and a lot of research efforts have been put into handling crash bugs including localizing the causes of crash bugs keeping the system running under the presence of crashes and checking the correctness of fixes to crash bugs .
however despite the notable progress in automatic bug fixing there is no approach that is designed to directly fix crash bugs within our knowledge.
it is not easy to automate the bug fixes via q a sites.
first we need to locate a suitable q a web page that describes a bug of the same type and contains a solution.
it is easy for humans to come up with a few keywords query a web search engine and read through the returned pages to find the most suitable one.
however it is not easy to do it automatically.
second even if we can locate a correct q a web page it is still difficult to extract a solution from a page where questions and answers are described in a natural language.
to overcome the first problem we utilize the fact that a q a page discussing a crash bug usually has a crash trace which contains certain information about the bug such as an error message and a call stack.
we could construct a query using such information and ask a web search engine to locate suitable pages.
however it is not feasible to directly construct such a query from a crash trace because texts in a crash trace usually contain a lot of project specific information such as a project method name and the name of a problematic variable.
the project specific texts would not match the bug appearing in the q a web site.
to overcome this problem we further filter out project specific texts.
to overcome the second problem we utilize a fact obtained by studying q a web pages many q a pages contain code snippets and it is enough to fix many bugs by only looking at the code snippets on the pages.
in this way we can avoid complex natural language processing and use almost only program analysis.
for example a developer asking a question about a bug may post his her source code snippet and a reply answering the question may contain a fixed version of the code snippet.
by comparing the two code snippets we can directly obtain a fix.
however even only analyzing code snippets is not easy.
due to the fuzzy nature of q a pages there may not be a clear correspondence between the buggy and fixed versionsof the code.
furthermore we cannot directly apply the fix described in the web page to the target project as the code in the web page is usually different from the source code in the target project.
to overcome these difficulties we systematically combine a set of existing techniques including partial parsing tree based code differencing and edit script generation .
these techniques together allow us to deal with the fuzzy nature of the web code as well as the gap between the project and the web page.
in summary our contributions are as follows we propose an approach to fixing recurring crash bugs via analyzing q a sites.
to our knowledge this is the first approach for automatic program repair using internet resources.
we demonstrate that fixes in q a sites can be obtained and applied by combining a set of fuzzy program analysis techniques without complex natural language processing.
we evaluate our approach with real world crash bugs from github and manually verify the correctness of the generated patches.
our evaluation shows that our approach is effective in fixing real world recurring crash bugs and can complement existing bug fixing approaches.
ii.
a pproach overview we first introduce the general structure of our approach in section ii and then introduce each step in section iii.
our current approach is implemented in java but is not limited to a specific programming language.
when a program crashes it has a crash trace.
our approach uses the source code and the crash trace as input and consists of four steps q a page extraction edit script extraction patch generation and patch filtering.
fig.
shows the overview of our approach.
the number on each arrow is the step number.
the first step of our approach is q a page extraction.
given a crash trace we extract keywords and give it to a search engine.
the search engine then returns a list of q a pages.
in the second step we isolate code snippets from each q a page and combine them to buggy fixed code pairs in which a fixed code snippet may contain a fix to a buggy code snippet.
after reducing code size in each code pair we build mappings between code snippets in each pair and generate edit scripts that indicate how to transform the buggy code to the fixed code.
in the third step we extract source code snippets by using the crash trace and buggy code snippets and apply each edit script to each source code snippet.
in the last step we filter generated patches and report the fixing result.
in the following section we will describe each step in detail.
iii.
a pproach detail we now explain our approaches in detail.
we use a running example taken from a real world crash bug1in an android application and the crash trace is shown in fig.
.
in the crash trace line and line are two error messages that describe the crash.
line and line represent two call stacks.
fig.
shows a source code snippet in this example and we use the word location to indicate the line number of an statement.
in this example line in fig.
is the faulty location of the source code.
the root cause of the bug is that the method onreceive passes context to the method level ofbatteryhelper .
the method level makes the parameter register a receiver.
however for context this is not allowed.
we describe q a page extraction in section iii a edit script extraction in section iii b patch generation in section iii c and patch filtering in section iii d. public void onreceive final context context final intent intent final int action intent.getextras .getint key action final float bl batteryhelper.level context log.i alarmreceiver invoked action s bl s. action bl switch action ... ... fig.
the source code snippet a. q a page extraction to fix the bug our approach begins with q a page extraction.
in this step we generate a query and give the query to a web search engine to obtain a list of q a pages.
based on our observation the first line of the crash trace can be used as the query as it usually contains the exception type and an error message about the crash.
both are information unique to the current bug.
for example line in fig.
indicates the exception is a runtimeexception and the cause of the problem is that intentreceiver components are not allowed to register to receive intents .
however we cannot directly use the whole first line because some words in the error message are project specific and if we include these words the search engine will hardly return any answer.
in the example the word com.vaguehope.onosendai.update.alarmreceiver is a class name defined in the target project.
to overcome this problem we observe that project specific items are usually reported in full qualified names and thus we can filter out such items using the root package of the project.
basically we filter out all words which contain a substring equal to the name of the root package.
in our example we generate the query java.lang.runtimeexception unable to start receiver intentreceiver components are not allowed to register to receive intents .
we give the query to a search engine and obtain a ranking list of q a pages.
b. edit script extraction the second step of our approach is edit script extraction.
an edit script is a sequence of edit operations that describes how to transform one code snippet to another.
in our work we use a tree based edit script generation algorithm in which an edit script describes operations on the abstract syntax tree ast .
we can add delete update or move a node in an ast in one edit operation.
we extract edit scripts in three steps buggy fixed code pair extraction buggy fixed code reduction and edit script generation.bug fixbuggy source code bug fixbug fixbug fixfixed source code1 bug fixupdateaq a aqq deletecode codecode delete updatebug44 23exception at at bug fixcrash trace q a pagescode snippets in source codepatch candidates code snippets in q a pagesbuggy fixed code pairsreduced code pairs edit scriptsfig.
overview of our approach java.lang.runtimeexception unable to start receiver com.vaguehope.onosendai.update.alarmreceiver android.content.receivercallnotallowedexception intentreceiver components are not allowed to register to receive intents at android.app.activitythread.handlereceiver activitythread.java at android.app.activitythread.access activitythread.java at android.app.activitythread h.handlemessage activitythread.java at android.os.handler.dispatchmessage handler.java at android.os.looper.loop looper.java at android.app.activitythread.main activitythread.java at java.lang.reflect.method.invokenative native method at java.lang.reflect.method.invoke method.java at com.android.internal.os.zygoteinit methodandargscaller.run zygoteinit.java at com.android.internal.os.zygoteinit.main zygoteinit.java at dalvik.system.nativestart.main native method caused by android.content.receivercallnotallowedexception intentreceiver components are not allowed to register to receive intents at android.app.receiverrestrictedcontext.registerreceiver contextimpl.java at android.app.receiverrestrictedcontext.registerreceiver contextimpl.java at com.vaguehope.onosendai.update.alarmreceiver.onreceive alarmreceiver.java at android.app.activitythread.handlereceiver activitythread.java ... more fig.
an example of a crash trace a part of a question post b part of an answer post fig.
part of a q a page for the crash trace in fig.
buggy fixed code pair extraction in the ranking order of the q a pages we first extract code snippets in each page.
fig.
shows part of a q a page returned from a search engine given the above query.
in this figure there are three code snippets one in the question post and the other two in the answer post.
to extract buggy fixed code pairs we first need to isolate code snippets from natural language descriptions in each post.
we isolate code snippets by taking the snippets from inside the html tag pair code and code grey in stack overflow as shown in fig.
.
this may miss some code snippets which are not tagged but according to our observation most of the code snippets are in this type of tag pairs.
then we combine different code snippets to buggy fixed code pairs.
a buggy fixed code pair may be either of the following both buggy code and fixed code are in the same answer post.
buggy code is in the question post and fixed code is in the answer post.
to identify the first type of code pairs we identify answer posts that have more than one code snippets and use keyword matching to distinguish the buggy code and the fixed code.the keywords are commonly used by humans to explain comparison relationship such as instead of and change...to... .
if such keywords exist we combine the two code snippets into one code pair and distinguish buggy and fixed code snippets according to the keywords.
to identify the second type of code pairs we take each code snippet in the question post and each code snippet in the answer post as a buggy fixed code pair.
because the first type of code pairs is more likely to be a buggy and fixed code pair we rank this type of code pairs before the second type of code pairs.
as a result we obtain three code pairs for the running example one taken from only the answer post and two taken from both the question and the answer posts.
the fixed code snippet in the answer post suggests inserting getapplicationcontext tocontext which fixes the buggy code snippet.
buggy fixed code reduction the buggy and fixed code snippets are often not similar in size.
in fig there are more than ten lines in the buggy code snippet of the question post while only one line in the fixed code snippet of the answer post.
the big difference in the code will influence the correctness of the generated edit script.
therefore before analyzing the code pair we reduce the size of both buggy code and fixed code according to their similarities.
first we parse a buggy fixed code pair and get two abstract syntax trees asts .
each node in the ast has a label which indicates the type of the node e.g.
method invocation and for each leaf node it also has a value e.g.
the name of a variable .
the code snippets are usually not complete.
therefore we use partial parsing techniques to parse the code snippets into asts.
then we calculate the similarities between each statements in the code pair and filter out those statements that has only low similarity scores.
here we consider two types of similarities text similarity.
we calculate the edit distance between each line and denote the length of buggy code aslenbuggy and the length of fixed code as lenfixed .
we use the following formula sim text edit distanceplenbuggy len xed structure similarity.
we calculate the ast similarity using the ratio of common ast leaf nodes among all the leaf nodes in two asts.
we denote the number of common leaf nodes as num common and the total number of leaf nodes in two asts as num total.
we use the following formula sim structure num common num total in both cases we only take code elements with one of the similarity scores more than a pre defined threshold.
in this way we can reduce the size of each code snippet in the code pair greatly.
the reduced code pairs are shown in fig.
.
each code snippet above the line is a considered as a buggy code snippet and each code snippet under the line is considered as a fixed code snippet.
context.registerreceiver ... context.getapplicationcontext .registerreceiver ... a code pair from the same answer post intent intent context.registerreceiver ... context.registerreceiver ... intent intent context.registerreceiver ... context.getapplicationcontext .registerreceiver ... b code pairs from both the question and answer post fig.
reduced code pairs from fig.
edit script generation we leverage a state of art edit script generation technique gumtree to generate edit scripts for buggy code snippets.
by applying the edit script to a buggy code snippet we shall get the corresponding fixed code snippet.
given two asts gumtree works in two steps.
first it builds mappings between the nodes of the asts.
a leaf or inner node of one ast can be mapped to a leaf or inner node of the other ast and each node can only be mapped once.
there may be nodes that do not have any mapping.
second it generates exactly one edit script using an existing linear optimal algorithm .
the edit script contains four types of edit operations on a node including leaf and inner of an ast namely add delete update and move.
here we explain these operations using the definitions in the corresponding paper add t tp i l v add a new node tin the ast.
if tp is not null and iis specified then tis theithchild oftp.
otherwise tis the new root node and has the previous root node as its only child.
finally lis the label oftandvis the value of t. delete t delete a leaf node tof the ast.
update t vn replace the old value of a node tby the new value vn.
move t tp i move a node tand make it the ithchild oftp.
note that all children of tare moved as well and therefore this actions moves a whole subtree.
let us denote the ast of the buggy code snippet as buggyast and the ast of the fixed code snippet as fixedast .
we use the code pair in fig.
a for explanation.
the mappings generated by gumtree between buggyast and fixedast for this code pair is shown in fig .
long dotted and short dotted lines indicate mappings built by gumtree in its different steps and are considered the same in our approach.
suppose in buggyast the node corresponding to context is c and the parent node of cisp while in fixedast the node that is mapped to cisc0 the node corresponding to getapplicationcontext isg0 and the parent node of c0and g0ism0 which is labeled as methodinvocation corresponding to context.getapplicationcontext .
the edit script is as follows.
for simplicity we omit the last two parameters of addoperations and use equivalent to indicate that the label and value of a newly added node are the same as those of an existing node.
add m p wheremis equivalent to m0block expressionstatement methodinvocation methodinvocation simplename registerreceiver nullliteral null classinstancecreation simplename context simplename getapplicationcontext simpletype qualifiedname simplename intentfilter simplename intent simplename action battery changedblock expressionstatement methodinvocation simplename context simplename registerreceiver nullliteral null classinstancecreation simpletype qualifiedname simplename intentfilter simplename intent simplename action battery changedbuggy code context.registerreceiver null new intentfilter intent.action battery changed fixed code context.getapplicationcontext .
registerreceiver null new intentfilter intent.action battery changed c m cp p g buggyast fixedastfig.
the mappings between buggyast andfixedast built by gumtree move c m add g m wheregis equivalent to g0 the above edit script aims to reflect the changes of two asts rather than to apply the changes to new code context.
consider a new code snippet line in fig.
.
in the ast of this code snippet the parent node of context denoted as p00 has three children which are batteryhelper level and context .
if we directly apply the above edit script to this ast p00will have the following three children context.getapplicationcontext batteryhelper and level .
the corresponding source code fails to compile.
this is a result of differences in two code snippets containing the same recurring bug although the fix pattern is the same.
the differences are mainly in two cases changed position and renamed variable.
suppose we apply an add operation to the ast of a new code snippet denoted as newast .
in the changed position case as the example shows the position of the added node should be changed from the 1stchild to the 3rdchild of the parent node.
in the renamed variable case the variable should be renamed to match the context of newast .
if we do not consider these cases we may fail to generate many fixes.
to overcome this problem our solution is to add two more operations in edit scripts defined as follows.
replace tn tp t add a new node tnequivalent to t to the position of tp.
then remove tpfrom the ast.
note thattpis not destroyed and keeps its children and its mapping if any .
copy tn tp i t add a new leaf node tnequivalent tot to theithchild oftp.
this operation requires that tis a leaf node and already exists in the ast.the aim of using replace andcopy operations is to handle the case of changed position and renamed variable respectively.
we generate replace and copy operations along with the generation of other operations.
gumtree leverages an algorithm that builds edit scripts via two passes of traversal.
the first pass of traversal is on fixedast in which update add and move operations are generated in order for each node.
the second pass of traversal is on buggyast in which delete operations are generated.
we check whether to generate replace andcopy operations for a node of fixedast between the checking for generating update andadd operations.
the generated replace orcopy operation shall replace the original addormove operation on the same node since there is at most only one operation for each node.
as soon as an operation is generated gumtree first apply the operation to buggyast and then continue to generate new operations if any .
therefore we can still ensure the correctness of the generated edit script.
suppose gumtree is visiting a non root node n0in the first pass of traversal in fixedast andn0isithchild ofp0.
first we check whether to generate a replace operation for n0.
the algorithm is shown in alg.
.
we check whether n0or p0is mapped to a node in buggyast and whether the labels are different.
if a corresponding mapping exists and the labels are different we generate a replace operation.
second we check whether to generate a copy operation forn0.
we begin with checking whether n0is mapped to a node in buggyast .
if so we do not create a copy operation.
otherwise we scan fixedast and find whether there is any leaf nodef0that has the same value as n0 whetherf0is mapped to a node in buggyast denoted as f and whether p0is mapped to a node in buggast denoted as p .
if all the three conditions are satisfied we generate a copy operation algorithm generating a replace operation n0 the non root node of fixedast p0 the parent node of n0 i the index of n0inp0 newnode a newly added node n mappednode the mapped node of ninbuggyast ifn0 hasmapping then ifn0 label6 n0 mappednode label then returnreplace newnode n0 mappednode n0 else ifp0 hasmapping then p p0 mappednode ifp childnum i then n p getchild i foreache0 p0 children do ife0 mappednode nthen return null ifn label6 n0 label then returnreplace newnode n n0 return null copy newnode p i f wherenewnode is a newly added node.
for the running example we generate a replace operation.
the edit script is shown below.
we use it instead of the original edit script generated by gumtree.
replace m c m0 move c m add g m wheregis equivalent to g0 c. patch generation we first extract source code snippets from the target project and combine them with buggy code snippets from q a pages to obtain a list of buggy source code pairs.
then we apply each edit script of the buggy code snippet to the corresponding source code snippet to obtain patches.
buggy source code pair extraction we extract buggy source code pairs as follows.
first we perform filelevel fault localization.
we take all files in the project that appear in the call stacks of the crash trace from top down and obtain a list of candidate files.
in fig.
the call stacks suggests that there is only one candidate file alarmreceiver.java .
second we extract buggy source code pairs.
the buggy code snippets come from existing buggy fixed code pairs while the source code snippets come from candidate files just extracted.
if a buggy code snippet is a method we search for a method with the same name in the candidate files and combine these two methods as a buggy source code pair.
if the buggy code snippet is a block which is in most of the occasions the algorithm consists of three steps explained below.
first we use call stacks and the buggy code snippet to pinpoint faulty locations.
a call stack already contains a list of line numbers and thus we take each line number of the corresponding candidate file in the call stack from top down.
the buggy code snippet may also help us find a faulty location.
we first calculate similarity scores between each statement in the candidate files and each statement in the buggy code snippet using the formulae in section iii b2.
then we filterout statements in candidate files with similarity scores less than the same pre defined threshold and sort faulty locations indicated by the rest of the statements in descending order of similarity scores.
we rank the faulty locations obtained from call stacks before those obtained from the buggy code snippet.
second according to the size of the buggy code snippet we expand each faulty location inside the candidate files and combine them to obtain a buggy source code pair.
specifically we expand each faulty location forward in the corresponding candidate file to obtain a possible block whose size is the same as the size of the buggy code block.
now we have a list of buggy source code pairs.
third since the faulty location for a crash is not necessarily the exact line number identified for the source code snippet in each buggy source code pair we also choose the previous location and the next location with the same block size as two additional source code snippets.
therefore for each buggy code snippet we obtain two additional buggy source code pairs.
in the source code fragment in fig.
we extract buggy source code pairs for the buggy code snippet in fig a .
the source code snippet in these pairs are line line and line in order.
edit script application we denote the ast of a source code snippet as srcast .
given a buggy source code pair we use gumtree again to build mappings between buggyast andsrcast .
according to the mappings each operation in the edit script on a node of buggyast is now effective on the mapped node of srcast .
if there is an unmapped node in the edit script we do not generate a fix.
in the example gumtree mapscinbuggyast tocontext insrcast denoted as c00 in fig .
the edit script is transformed to the following to operate nodes of srcast replace m00 c00 m0 move c00 m00 add g00 m00 whereg00is equivalent to g0 for each buggy source code pair in order we apply each transformed edit script to srcast and transform the edited ast back to code.
finally we obtain a ranking list of generated patches.
the patches are naturally sorted as our analysis proceeds.
therefore it is sorted by the q a page ranking and code pairs in the same answer post is ranked higher than those in both question and answer post.
in addition faulty locations identified by the call stack is ranked higher than those identified by the buggy code.
d. patch filtering in previous steps we may generate multiple patches for one bug.
however some of them may be incorrect.
we filter out the patches using the following two rules merging.
our approach may generate multiple patches that are equivalent.
we check the equivalence at the ast level and merge them as one patch.
compiling.
if there is a compilation failure we filter out the patch.
in the end we report the first kpatches in the list to the programmer.
if there is no patch generated it means that our approach fails to fix the crash bug.
our experiment shows that we have high accuracy in generating the first patch as a correct patch.
therefore we set k .in the running example the project compiles successfully and the code becomes the following.
final float bl batteryhelper.level context.getapplicationcontext therefore we get one fix for this crash bug.
iv.
e valuation our evaluation aims to answer two questions rq1 effectiveness.
how effective is our approach in fixing real world recurring crash bugs?
rq2 usefulness.
can our approach complement state ofart fixing approaches?
a. experiment setup we have implemented our approach in java as an open source tool qacrashfix2.
we used google as the search engine to obtain q a pages and added a constraint site stackoverflow.com into the keywords to retrieve only the web pages in stack overflow.
we used eclipse ast parser to parse code snippets to asts and re implemented gumtree to build mappings and to generate edit scripts.
through our experiments we set sim text to .
and sim structure to .
to achieve the best results.
different threshold may lead to different size of reduced code snippets or introduce different number of source code snippets.
in both cases we may have more false positives or false negatives.
to evaluate our approach we need a set of crash bugs as evaluation subjects.
here we focus on a specific framework android because android is one of the most widely used framework and on github there are a large number of android projects.
to collect the subjects we looked into the android projects on github.
github provides four rankings for projects best match most stars most forks and recently updates.
we obtain the top android projects from each ranking and get in total projects containing issues.
then we filter the issues based on three criteria the issue contains a crash trace which indicates that it is a crash bug the issue has an associated patch so that we can evaluate the generated patches by comparing them with developers patch and the exception causing the crash is thrown from android framework which indicates that the crash is a recurring bug related to android.
after filtering we got projects with issues.
next we manually examined these issues to determine which crash bugs can be fixed by humans via searching stack overflow i.e.
we identified those bugs whose recurrences existed at stack overflow.
our rule for judging this is to use the same method as our approach to generate a query and manually examine top q a pages at stack overflow.
for each page we checked whether we could fix the bug using the information on the page.
in the end we got issues whose recurrences exist on stack overflow.
the recurrence ratio is .
which is less than but similar to the recurring bug rate in recent research .
this is because in repositories there are sufficient resources.
by only searching in stack overflow we found a large number of recurring bugs which also indicates the effectiveness of using q a sites.
2available at each issue we downloaded and deployed the project version before the patch was applied and wrote building scripts for automating the compilation process.
because we cannot compile one project we only chose the remaining issues corresponding to bugs as our final benchmark.
finally we used our approach to generate a patch for each bug.
then we manually verified the correctness of the patches by comparing each generated patch with each patch written by developers.
note that a lot of existing research on bug fixing adopted passing all tests as a criterion for evaluating the correctness of generated patches.
however we did not adopt this method because recent research found that although test cases are effective in filtering out many erroneous patches many test suites in practice are weak and are not enough to guarantee the correctness of patches.
all our experiments were executed on windows with a dual core .50ghz intel core5 processor and 8gb memory.
in the following subsections we discuss the result in detail with respect to our research questions.
b. rq1 effectiveness the details of the benchmark and the experimental results are summarized in table i sorted by the number of lines of code.
column project shows the project name.
column issue no.
shows the issue number in github.
column loc shows the total number of lines of code in the respective project.
column edit scripts shows the number of edit scripts i.e.
how many buggy fixed code pairs we generated from each web page.
column initial shows patches initially generated on the target project without any filtering.
column equivalent shows the number of patches that are equivalent.
column compile error shows the number of patches that fail to compile.
column remaining shows the number of the remaining patches which are the final patches of our approach.
column correct shows whether the first filtered patch can fix the bug or not.
column total shows the time used to generate all the patches and column compilation shows the time used for compilation.
we also recorded the time to obtain the first filtered patch shown in column first .
we make the following observations.
first the column of remaining fixes shows that for of bugs we did not generate any fixes.
for the resting bugs our tool generated at least one fix.
second our tool generated a relative large number of initial fixes which shows that there are a good number of code snippets in stack overflow pages that lead to fix generation.
third our tool may generate equivalent patches.
this is because stack overflow pages may contain the same answer several times.
since the code snippets in the page are the same we generate equivalent patches.
fourth a large number of patches can be filtered out by compilation.
for example in textsecure we generated initial fixes for each bug and filtered out all of them by compilation.
in total we filtered out patches by compilation accounting for among all the generated patches.
fifth many edit scripts did not lead to a patch to the source code.
this is because no mapping was built between the buggy code in the web page and the original source code for many edit scripts.table i details of generated fixes project issue no.
loc edit scripts patches time sec initial equivalent compile error remaining correct first total compilation calligraphy .
.
screen notifications .
.
.
tucanmobile y .
.
.
openiab y .
.
.
android universal image loader .
.
couchbase lite android .
.
.
onosendai y .
.
.
lnreader android y .
.
.
the blue alliance android .
.
.
open keychain y .
.
.
ushahidi android .
.
.
cgeo n .
.
.
cgeo y .
.
.
textsecure .
.
.
cgeo .
.
wordpress android .
.
.
wordpress android .
.
wordpress android y .
.
.
wordpress android .
.
wordpress android .
.
gnucash android .
.
cgeo y .
.
.
wordpress android n .
.
.
calabash android .
.
.
total .
.
.
dialog.dismiss if dialog.isshowing dialog.dismiss dialog.dismiss if dialog !
null dialog.isshowing dialog.dismiss fig.
patches for tucanmobile we further give some examples of generated patches3.
in each of the figures shown below the top one represents the original patch generated by the developers and the bottom one represents the first generated patch by our tool.
first for of the bugs our tool generated correct patches.
among them patches for bugs are identical to those written by humans and patches for bugs are not identical but are still correct.
for example in fig.
the generated patch has one more condition that checks dialog is not null.
this is a useful check that ensures no nullpointerexception before using dialog .
second for of bugs our tool generated a patch using tryandcatch blocks as suggested in the stack overflow page shown in fig.
.
the human patch invokes isfinishing and returns when finished.
in our patch we surround finish with try catch which deals with the same root cause.
however because the patch is different from the human patch we consider it as a correct but not acceptable patch.
third for the rest of the bugs our tool did not generate correct patches.
for example we generated a patch that deals with the same root cause as suggested by a stack overflow answer.
however the patch is in a different location from the human patch and in a different form and we cannot verify its correctness.
3full analysis of the generated patches can be found on the tool web site.
private void notifydatasetchanged this might get called asynchronically when the activity is shut down if isfinishing return try finish catch exception e e.printstacktrace return fig.
patches for cgeo in conclusion our approach can correctly fix out of bugs where can be directly accepted with only potential false positives.
note that existing bug fixing approaches usually generate a large number of patches and rely on the test cases to filter out the incorrect patches.
based on the newest result since the test suites in practice are usually weak many incorrect patches cannot be filtered out and thus many existing approaches generate a large number of false positives in practice.
therefore our approach is promising under the circumstances where the test suites are weak.
we also did a manual analysis to evaluate the performance of our approach in each step.
the result is shown in table ii.
table ii performance of each step step bugs unable to handle total bugs in this stepratio edit script extraction .
patch generation patch filtering .
first we fail to generate an edit script for bugs because there are no appropriate code pairs.
besides answers may contain descriptions like check null pointer and add try catch which could not be processed by our approach.
second for of the remaining bugs we fail to generate a patch because we cannot locate the buggy code as a result of incompletecrash trace.
sometimes a crash trace contains a very long list of method invocations and the buggy file may be omitted in the bug report.
third the remaining bugs cannot be fixed because of compilation errors.
for example a buggy code snippet has a method declaration which should return an integer while in the question post it is actually a void method.
developers could do a manual transformation while our approach cannot.
the time used is shown in the last three columns of table i. we did not include the time to query google because such time greatly depends on the network condition and varies from locations to locations and the query time is very small compared to the total time and can be neglected.
in our experiment the time for querying google for each bug is around several hundred milliseconds.
as column total in table i shows the longest time spent on a bug is 230s and the time for each bug is .2s on average.
compilation accounts for .
of the time and costs .39s for each compiled patch on average.
in addition if we report the result as soon as we generate the first filtered patch we can reduce the total time by .
to 900s about .5s for each bug on average.
although compilation time does increase with respect to project size project size is not the main deciding factor of the total executing time.
the main deciding factor is how many generated patches need to be tested.
this is mainly related to the number of code snippets in q a pages and the number of project files in call stacks.
these factors are not directly related to the size of the source code.
therefore our approach is able to scale to very large applications.
c. rq2 usefulness to answer the second research question we did a qualitative analysis to check whether we can complement stateof art automatic bug fixing approaches.
we examine existing approaches for bug fixing and identify four approaches that apply to our case genprog rsrepair par and spr .
other approaches either cannot scale to the projects in our experiment or have special requirements such as contracts .
existing search based techniques such as genprog and rsrepair assume that patches already exist in the project code.
par uses human written templates and to instantiate templates it also searches in the project code.
spr uses condition synthesis to repair defects and in other occasions the search space is also within the project code.
we did not generate any patches that can be synthesized using only existing templates in par or condition forms in spr and therefore for each bug that our approach successfully fixed we first used a representative substring in both the human patch and our patch to check if there is any match in the source code using the grep command and then manually analyzed the returned search list to see whether a patch can be synthesized.
the result is shown in table iii.
the first column shows each issue with at least one filtered patch generated by our approach.
the second column shows the grep command we use.
the third column shows whether a patch can be synthesized.
there is only one case where an identical patch can be synthesized.
for cgeo we got a large number of try andcatch blocks which indicates that genprog rsrepair and spr can fix the bug by inserting the blocks.
in addition partable iii keyword matching in source code issue grep command result tucanmobile grep isshowing r .
n openiab grep super.ondestroy r .
n onosendai grep context.getapplicationcontext r .
n open keychain grep dismissallowing r .
n cgeo grep image jpeg r .
n cgeo grep image n r .
n lnreader android grep super.ondestroy r .
n wordpress android grep commitallowingstateloss r .
n cgeo grep isfinishing r .
n cgeo grep nbtrynb r .
y cgeo grep nbcatchnb r .
y does not contain the try catch template and cannot create a patch of this form.
the result indicates that our approach can complement existing bug fixing approaches.
note that a bug can be fixed in many different ways so being unable to synthesize the patches in the above procedure does not necessarily indicate that they cannot fix the bug.
therefore we are not concluding that our approach is better than other approaches but showing that our approach can complement them.
in essence we are dealing with a defect class different from other approaches.
d. threats to validity the main threat to external validity is that the benchmark we use is small and may not be representative of real world benchmarks.
however all bugs we use are real world bugs are from different projects and throw different exceptions which may cover a large class of real world bugs.
note that many existing studies use generated bugs to evaluate their approaches and many evaluated on real world bugs have benchmarks whose sizes are similar to or much smaller than ours.
the main threat to internal validity is that our manual validation of the patches may be wrong.
to alleviate this threat three authors mutually checked the result and any patch with a slight doubt was not considered as correct.
v. d iscussion the number of crash bugs that can be fixed by humans via exploring q a sites are relatively small in github .
this is due to two reasons.
first in open repositories like github issues are not well maintained in many projects and we only investigate bugs that contain patches.
this greatly reduces the number of investigated bugs.
second developers may encounter crash bugs during development and may fix them immediately instead of creating an issue.
while our approach can fix crash bugs that can be found in issue repositories our approach can be used by developers in the development stage or can be deployed to automatically fix crash bugs newly founded by testing.
our approach is limited to situations that humans can fix the bug via looking into q a sites.
as a result if there are no correct patches in q a sites we cannot generate a correct patch.
however because recurring bugs are common and the resources on q a pages continuously increase our approach has the potential to fix more bugs than can be fixed currently.
in our experiment we did not run the projects.
however in the presence of test cases our approach can be run automatically to filter out more erroneous patches which can further increase the accuracy of our approach.vi.
r elated work automatic bug fixing recently there has been much progress on fixing general types of bugs.
existing research uses specifications or test cases to evaluate the correctness of patches and guide the process of patch generation.
genprog and rsrepair assume that patches exist in the current project and use search based techniques to find the patches.
par uses humanwritten templates to generate patches.
autofix e and autofix e2 rely on contracts present in the software to generate fixes.
semfix and directfix use componentbased program synthesis techniques to synthesize a correct patch.
spr instantiates transformation schemas to repair program defects by using condition synthesis.
prophet uses machine learning over a large code database to learn a probabilistic model that characterizes successful human patches and uses this model to prioritize the search for correct patches.
fischer et al.
propose a semantics based approach that turns a given program into one whose evaluations under the error admitting semantics agree with those of the given program under the error compensating semantics.
gopinath et al.
use behavioral specifications to generate likely bug fixes.
wautorepair reduces patch validation time by only recompiling the altered components of a program.
minthint is a semi automatic approach that generates repair hints to help developers complete a repair and it uses statistical correlation analysis to identify expressions that are likely to appear in the patches.
our work is different from these approaches in that we handle the defect class of recurring bugs whose fixes can be found in q a sites and can complement the above approaches.
nguyen et al.
also study recurring bug fixes for object oriented programs but they do not analyze q a sites like us.
automatic approaches to fixing specific types of bugs also exist.
jin et al.
automate the whole process of fixing concurrency bugs.
xiong et al.
propose a new language to support the fixing of mof models.
wang et al.
propose a dynamic priority based approach to fixing inconsistent feature models.
rangefix generates range fixes for software configuration.
caramel generates nonintrusive fixes for performance bugs.
leakfix generates safe fixes for memory leaks.
our work aims to fix crashes different from the existing research.
fault localization before fixing the bugs it is essential to locate where the bug occurs.
a typical technique is spectrabased fault localization which uses program spectrum collected during execution.
because crash bugs have crash traces which contain location information in our work we use this information to locate crash bugs statically.
crashlocator locates faulty functions by using crash traces and expanding the stack in a static call graph.
similar to spectra based approaches it calculates the suspiciousness score for each function and return a ranking list.
however this approach only ranks functions instead of statements and thus cannot be used in our approach.
another main line of fault localization research is bugreport oriented fault localization which aims to find a small subset of source files that is related to a bug report among the entire code base.
because we focus on using only call stacks instead of bug reports for file level fault localization we do not leverage these approaches.
q a site retrieval and analysis q a sites contain rich resources for software engineering.
regarding retrieval from q a sites seahawk and prompter construct queries based on the code context and retrieve api names and code like words from stack overflow.
however for crash bugs it is difficult to retrieve q a pages with code context query.
rigby et al.
extract essential code elements from informal documentation such as stackoverflow.
because q a pages related to bug fixes often contain code snippets in html tab pairs we only use heuristics to extract code snippets.
cordeiro et al.
process crash traces and use it to retrieve q a resources.
this approach uses exceptions and