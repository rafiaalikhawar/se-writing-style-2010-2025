characterizing and detecting anti patterns in the logging code boyuan chen1 zhen ming jack jiang2 software construction analytics and evaluation scale lab york university toronto canada fchenfsd1 zmjiang2g cse.yorku.ca abstract snippets of logging code are output statements e.g.
log.info or system.out.println that developers insert into a software system.
although more logging code can provide more execution context of the system s behavior during runtime it is undesirable to instrument the system with too much logging code due to maintenance overhead.
furthermore excessive logging may cause unexpected side effects like performance slow down or high disk i o bandwidth.
recent studies show that there are no well defined coding guidelines for performing effective logging.
previous research on the logging code mainly tackles the problems of where to log andwhat to log .
there are very few works trying to address the problem of how to log developing and maintaining high quality logging code .
in this paper we study the problem of how to log by characterizing and detecting the anti patterns in the logging code.
as the majority of the logging code is evolved together with the feature code the remaining set of logging code changes usually contains the fixes to the anti patterns.
we have manually examined pairs of independently changed logging code snippets from three well maintenance open source systems activemq hadoop and maven.
our analysis has resulted in six different anti patterns in the logging code.
to demonstrate the value of our findings we have encoded these anti patterns into a static code analysis tool lcanalyzer.
case studies show that lcanalyzer has an average recall of and precision of and can be used to automatically detect previously unknown anti patterns in the source code.
to gather feedback we have filed representative instances of the logging code anti patterns from the most recent releases of ten open source software systems.
among them instances have already been accepted by their developers.
keywords anti patterns logging code logging practices empirical studies software maintenance i. i ntroduction logging is a common programming practice that developers use to record the runtime behavior of a software system.
logs have been used widely in industry for a variety of tasks e.g.
monitoring debugging remote issue resolution test analysis security and legal compliance and business decision making .
logs are generated by the logging code that developers insert into the system.
there are typically four components in a snippet of logging code a logging object a verbosity level static texts and dynamic contents.
figure 1shows an example.
the logging object is log the verbosity level is debug the static texts are replaced scanner readers at row and dynamic contents are bytes.tostring viablerow.getrow .
unlike other aspects in the software development process e.g.
code refactoring and release management recent hbase public void updatereaders throws ioexception this.lock.writelock .lock try the keys are currently lined up at the next row to fetch.
pass in the current row as first row and readers will be opened and cue d up so future call to next will start here.
viablerow viablerow getnextviablerow openreaders viablerow.getrow log.debug replaced scanner reader s at row bytes.tostring viablerow.getrow finally this.lock.writelock .unlock public void updatereaders throws ioexception this.lock.writelock .lock try the keys are currently lined up at the next row to fetch.
pass in the current row as first row and readers will be opened and cue d up so future call to next will start here.
viablerow viablerow getnextviablerow openreaders viablerow.getrow log.debug replaced scanner readers at row bytes.tostring viablerow.getrow finally this.lock.writelock .unlock public void updatereaders throws ioexception this.lock.writelock .lock try ... viablerow viablerow getnextviablerow openreaders viablerow.getrow log.debug replaced scanner readers at row bytes.tostring viablerow.getrow finally this.lock.writelock .unlock fig.
an example of low quality logging code which caused crash of the hbase server due to a nullpointerexception .
empirical studies show that there are no well established logging practices in industry .
developers usually need to rely on their common sense to perform their logging actions.
in general there are three challenges associated with establishing effective logging practices the problem of where to log is about deciding the appropriate logging points.
snippets of logging code can be inserted at various locations in the source code e.g.
inside the try catch exception blocks inside the condition blocks etc.
to provide insights into the system s runtime behavior.
however excessive logging can bring additional maintenance overhead and cause performance slow downs .
hence developers need to be selective when choosing the logging points.
the problem of what to log is about providing sufficient information in the logging code.
the static texts provide a short description of the execution context and the dynamic contents indicate the current execute state.
when composing a snippet of logging code the static texts should be clear and easy to understand and the dynamic contents should be coherent and up to date .
the problem of how to log is about developing and maintaining high quality logging code.
logging is a cross cutting concern as the logging code is scattered across the entire system and tangled with the feature code .
although there are language extensions e.g.
aspectj to support better modularization of the logging code many industrial and open source systems still choose to inter mix the logging code with the feature code .
hence it is difficult to ieee acm 39th international conference on software engineering ieee acm 39th international conference on software engineering .
ieee authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
develop and maintain high quality logging code while the system evolves.
existing log characterization studies focus on addressing the challenges of where to log and whatto log .
there are very few works tackling the problem of how to log except partially in where yuan et al.
developed a verbosity level checker to detect inconsistent verbosity levels.
as there are already many lines of logging code in the open source and industrial systems low quality logging code can hinder program understanding and cause unexpected system failures .
figure 1shows a real world bug in the logging code that caused the crash of the hbase system.
since the object viablerow or the return value of the method call viablerow.getrow can be null hbase was crashed once the nullpointerexception was thrown.
hence in this paper we study the problem of how to log by focusing on characterizing and detecting antipatterns in the existing logging code.
similar to the design and performance anti patterns we define anti patterns in the logging code as recurrent mistakes which may hinder the understanding and maintainability of the logs.
in this paper we have conducted a comprehensive study on characterizing anti patterns in the logging code by manually going through more than six years of the logging code changes of three popular open source software systems activemq hadoop and maven .
our study has resulted in six antipatterns in the logging code.
to demonstrate the usefulness of our findings we have developed a static analysis tool called lcanalyzer which can automatically detect these antipatterns.
the contributions of this paper are this is the first systematic study on providing guidelines on developing and maintaining high quality logging code.
case studies show that the characterized six antipatterns in the logging code are general and exist in the ten studied open source software systems.
our static analysis tool lcanalyzer yields an average recall of and precision of and can automatically reveal many previously unknown instances of the anti patterns in the logging code.
to gather developers perceptions on whether the antipatterns are worth fixing we have filed a total of representative anti pattern instances from the most recent releases of ten different open source software systems.
so far instances have already been confirmed or fixed by their developers.
this has demonstrated the importance and the impact of our work.
to support independent verification or replication of our study we have provided a replication package in this paper.
this package which contains the lcanalyzer tool and the verified anti pattern instances from realworld systems can be useful for other researchers who are interested in studying the logging practices.
paper organization the rest of the paper is organized as follows.
section ii introduces the our process of characterizing the anti patternsin the logging code.
section iiiexplains the resulting antipatterns and discusses our static analysis tool lcanalyzer.
section ivevaluates the performance of lcanalyzer.
sectionvdescribes the results after applying lcanalyzer on the most recent releases of ten different open source software systems and the initial developer feedback.
section vipresents the threats to validity.
section viidiscusses the related work.
section viii concludes this paper.
ii.
o urprocess of characterizing anti patterns in the logging code we follow a grounded theory fashion to characterize anti patterns in the logging code since there are no prior works in this area.
the majority of the logging code is changed together with the feature code for various software maintenance tasks e.g.
renaming of functions or class attributes changing condition expressions etc.
.
the independent logging code changes are likely the fixes to the anti patterns.
hence in order to characterize the anti patterns in the logging code we focus on isolating and analyzing the logging code changes which occur independently of the feature code changes.
figure 2shows our process.
first we extract the fine grained code changes from the historical code repositories.
second we apply heuristics to automatically identify the extracted code changes which contain changes to the logging code.
then we use program analysis techniques to automatically categorize the logging code changes into two types logging code changes due to co changes in the feature code and independent logging code changes.
finally we conduct manual analysis on the independent logging code changes to characterize the anti patterns in the logging code.
in this paper we will analyze the independent logging code changes from three popular open software systems activemq hadoop and maven as shown in table i. these systems are from different application domains activemq is a message broker middleware hadoop is a distributed bigdata compute platform and maven is a client application used for build management and build automation.
we pick these systems as our study subjects because of their popularity used by millions of people worldwide and rich development history six to ten years .
each of the changes has been carefully peer reviewed and discussed before they are accepted into the repository .
we have built a local mirror of the three systems using the online data dumps .
a. extracting fine grained code changes first we run j rex on the historical code repository of these three systems to extract the source code and the meta information of each commit e.g.
commit id commit logs etc.
.
different revisions of the same source code files are recorded separately.
for example the source code of the first and the second commits of foo.java are recorded asfoo v1.java foo v2.java respectively.
then we use changedistiller cd to extract the fine grained source code changes between each pair of the adjacent revisions e.g.
code changes between foo v1.java and foo v2.java .
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
code repositoryfine grained code changeslogging code changes anti patterns in the logging codej rex changedisitllerheuristicsdependency analysis manual analysisco changed logging code indept .
changed logging codefig.
our process of characterizing anti patterns in the logging code.
table i the three studied systems used in our characterization process.
system code history total logging indep.
begin end revisions changes logging changes activemq .
hadoop .
maven .
cd first parses the two file revisions into two abstract syntax trees asts then compares them using the tree differencing algorithm.
the output from cd is a list of fine grained code changes e.g.
a method invocation in a function is updated or a class attribute is renamed .
b. identifying logging code changes similar to we apply heuristics to automatically identify the code revisions containing logging code changes.
our approach uses regular expressions to identify logging code using keywords e.g.
log trace debug etc.
in the code snippets.
after the initial regular expression matching the resulting dataset is further filtered to remove code snippets that contain mismatched words like login dialog etc.
we then remove the logging code e.g.
the code snippets for logging object initializations which do not generate logs.
we achieve this by excluding code snippets that contain assignments .
the fourth column in table ishows the total number of logging code changes for the three systems.
for example there are snippets of logging code changes in activemq.
c. categorizing logging code changes in general there are two types of logging code changes changes in the logging code due to co changes in the feature code and independently changed logging code.
we have developed a program to automatically identify the co changed logging code.
our program which uses jdt identifies the logging code and the feature code co changes using program dependency analysis.
we will explain our technique using a running example shown in figure .
first the program analyzes the changed feature code to identify the modified entities e.g.
updates to function foo co changed logging code testbackpressure.java revision revision revision independent logging code change activemqsession.java revision revision testbackpressure.java revision revision revision a an e xample of the logging code co changed with feature code activemqsession.java revision revision b an e xample of the independently changed logging code long bytespersec long.valueof stat.split sleep sec system.out.println data rate was bytespersec kb second log.debug getsessionid transaction rollback log.debug getsessionid transaction rollback txid transactioncontext.gettransactionid long kbytespersec long.valueof stat.split test duration secs system.out.println data rate was kbytespersec kb second long bytespersec long.valueof stat.split sleep sec system.out.println data rate was bytespersec kb second log.debug getsessionid transaction rollback log.debug getsessionid transaction rollback txid transactioncontext.gettransactionid long kbytespersec long.valueof stat.split test duration secs system.out.println data rate was kbytespersec kb second fig.
an example of co changed and independently changed logging code.
or renaming of local variable bar etc.
.
for example the variable bytespersec is updated to kbytespersc in figure a .
then the program categorizes various changed components of the logging code.
in figure a only the dynamic content variable bytespersec is updated.
finally the program tries to match the categorized changed components in the logging code to the modified entities in the feature code.
if all the changed components in a snippet of logging code can be matched to the modified entities in the feature code this snippet of logging code is considered as being cochanged with the feature code.
for changes in the static texts after filtering out the common words e.g.
the a etc.
we tokenize the changes into an array of words.
if we can match all the changed words in the static texts and all the changed components in the dynamic contents to modified feature code entities we consider this code snippet as co changed logging code.
for the logging code example show in figure a as the only change in the logging code is a variable update and we can find the matching modified entity in the feature code it is considered to be a snippet of co changed logging code.
the remaining set of logging code changes are independently changed logging code as one or multiple changed components cannot be matched with corresponding modified feature code entities.
in figure b method invocation transactioncontext.gettransactionid and static text txid are added to provide more execution context.
as there is no corresponding feature code changes it is a snippet of independently changed logging code.
we have randomly sampled instances of logging code changes authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
which corresponds to a confidence level and confidence interval.
our method achieves a precision of .
the reason for the misclassification is mainly due to some co changed textual changes cannot matched exactly word byword to the modified changed entities.
for example the words resizable and array in the static texts cannot be exactly matched with the updated variable resizeablearray .
the last column in table ishows the number of independently changed logging code and their percentage with respect to the total number of logging code changes.
for example there are only instances of independently changed logging code in hadoop.
this corresponds to .
of the total logging code changes.
d. manual analysis our hypothesis is that such independently changed logging code is usually for addressing anti patterns issues.
to validate our hypothesis we have manually gone through pairs of independently changed logging code.
this corresponds to a confidence level of with a confidence interval of .
we use the stratified sampling technique to ensure representative samples are selected and studied from each project.
the portion of the sampled code snippets from each project is equal to the relative weight of the total number of independently changed logging code for that project.
for example there are snippets of independently changed logging code in maven out of a total of from all three projects.
hence snippets are selected for maven.
for each of the selected code snippet we have carefully compared the selected and the previous revisions to understand the rationales behind the logging code changes.
table iishows the results of our manual analysis.
it contains a total of nine reasons for independently changing the logging code.
each row in the table corresponds to one particular type of rationale.
it contains the description and the number of instances found in the three studied systems.
if we cannot find any instances of one rationale for that system we indicate that cell as .
the nine different rationales belong to two different categories what to log and how to log .
as this dataset only contains the changes to the existing logging code there are no logging code changes in the category of whereto log .
there are a few instances in the row of others as we cannot find the reasons for those changes.
we have found four rationales of logging code changes in the category of whatto log .
they take up more than of the sampled code snippets.
this shows the importance of studying the problem of what to log .
since this is not the focus of this paper we will not further expand our analysis in this category.
there are five rationales in the category how to log .
each corresponds to the different fixes to the anti patterns in the logging code.
among these three systems hadoop has the largest number of instances in each rationale.
this is not an indication of lower quality logging code in hadoop as the logs from hadoop are actively being monitored and analyzed .table ii our manual analysis results on the independently changed logging code.
category rationale hadoop activemq maven what to logadding more context clarifying correcting contents fixing typos in the static texts removing redundant info how to logchecking nullable variables removing object casting correcting logging levels refactoring logging code changing output format others total rather it is because the size of loc and lloc1in hadoop is much bigger than activemq and maven.
in section v we have investigated in more details on the relation among loc lloc and the number of anti pattern instances.
log refactoring is a common rationale among all three systems.
this shows that developers from all three systems are making an effort to improve the maintainability of their logging code.
to characterize the anti patterns in the logging code we have analyzed the code revisions before the independently changed logging code.
we will describe the details of these anti patterns in the next section.
iii.
a nti patterns in the logging code in the previous section we have found five different rationales dedicated for fixing and improving the maintainability of the logging code how to log .
in this section we will describe the anti patterns in the logging code by studying the source code before these fixes.
in general as shown in figure there are five categories of anti patterns in the logging code corresponding to the five rationales that we have found.
for each category of anti patterns we show an example code snippet extracted from real world systems.
there is one anti pattern in each category except in logging code smells as there are two different types of logging code smells found in our manual analysis.
hence in total there are six anti patterns in the logging code.
in sections iii a iii b iii c iii d and iii e we will describe the symptoms the impacts and the fixes of each antipattern.
to ease explanation we will use the code snippets shown in figure 4as our running examples.
in section iii f we will discuss about our logging code analysis tool lcanalyzer which can automatically detect the six anti patterns.
a. nullable objects in the logging code the dynamic contents are generated during runtime.
however in some cases the objects used in the dynamic contents can be null.
if not being careful such snippet of logging code would cause a nullpointerexception 1in this paper loc means lines of code and lloc means lines of logging code .
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
name example nullable objects a rpc.java in hadoop revision a rpc.java revision explicit cast b fsdataset.java revision wrong verbosity level c fifoscheduler.java revision logging code smells duplication with a method s definition dup d sockettransceiver.java revision duplication with a local variable s definition dup e dataxceiver.java revision malformed output f htable.java revision protected clientscanner final byte columns final byte startrow ... ... log.debug creating scanner over bytes.tostring tablename startin g at key startrow ... if proxy !
null invocationhandler !
null invocationhandler instanceof closeable ... else log.error could not get invocation handler invocationhandler for proxy proxy or invocation handler is not closeable.
... log.info debug container finished containerid datanode.log.warn ad ded missing block to memory block diskblockinfo remoteaddress s.getremotesocketaddress .tostring ... log.warn invalid access token in request from s.getremotesocketaddress for replacing block block public string getremotename return channel.socket .getremotesocketaddress .tostring ... public so ckettrans ceiver socketchannel channel this.channel channel log.info open to channel.socket .getremotesocketaddress fig.
code snippet examples of anti patterns in the logging code.
and cause the system to crash.
in the else block of figure a the object proxy can be null.
although this example will not cause a nullpointerexception the logging code is not informative regarding nullablity of proxy .
the fix in this case is to check the nullability of proxy and handle the output differently.
b. explicit cast explicit casting informs the system to forcibly convert an object into a particular type.
it might cause runtime type conversion errors and system crash.
in figure b diskblockinfo was explicitly casted as the block type.
the fix is to remove the explicit cast and let the system decide during runtime the type of diskblockinfo .c.
wrong verbosity level many systems use verbosity level to control the types of information recorded into log files.
for example the log4j framework provides multiple verbosity levels fatal error warn info debug and trace.
each of these verbosity levels can be used for different software development activities.
for example if the verbosity level is set to be info all the logs instrumented with info and higher levels a.k.a.
fatal error warn are printed whereas lower level logs a.k.a.
debug and trace are discarded.
although there are recommended guidelines on what types of information to record at each verbosity level they are not strictly followed by developers.
this anti pattern may cause logging overhead and large volumes of redundant logs during log authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
analysis.
in figure c although the verbosity level is set to be info the static texts suggest that this snippet of logging code is used for debugging purposes.
the fix is to change the logging level to debug .
d. logging code smells code smells are symptoms of bad design and implementation choices .
in addition to code smells researchers define test smells to be poor design and implementation choices when developing test cases .
in a similar fashion as code smells and test smells in this paper we define logging code smells to be poor design and implementation choices when developing the logging code.
as one snippet of effective logging code contains clear and easy to understand static texts and coherent and up to date dynamic contents the resulting logging code can be very long.
long logging snippets would hinder understanding and increase maintenance overhead.
hence efforts are made to reduce the length of some long logging code snippets.
below we describe two particular anti patterns duplication with the definition of another method dup1 in figure d the method call channel.socket .getremotesocketaddress is functionally equivalent as getremotename .
the fix is to replace this method call sequences with a shorter method call getremotename .
duplication with the definition of a local variable dup2 in figure e the local variable remoteaddress and the method call s.getremotesocketaddress point to the same contents in memory.
the fix here is to replace the method call sequences with the local variable remoteaddress .
the result after the change is functionally equivalent but shorter logging code.
e. malformed output some objects do not have a human readable format defined.
if they are printed directly the logs can be malformed.
in figure f the variable startrow is a byte array which does not have human readable format defined.
the fix is to callbytes.tostring method to properly format the variable startrow before printing.
f .
lcanalyzer to evaluate the usefulness of our findings we have implemented a tool called lcanalyzer which automatically scans the source code to detect the six aforementioned anti patterns in the logging code.
lcanalyzer which is a static code analyzer implemented using jdt flags the anti patterns in the logging code using asts.
for example to check whether one logging code snippet contains the dup2 anti pattern we first identify the method which contains this logging code.
then in this method we extract all the variable declaration statements and variable assignment statements before this logging code.
if there are at least one method invocation sequences in this logging code snippet matched with one of .
.
.
.
.
.
.
.
.
.
.
dup1 dup2 explicit cast malformed output nullable objects wrong verbosity levelaveragerecall precisionfig.
the recall and precision of lcanalyzer.
the variable declarations or assignments this code snippet will be flagged as containing the dup2 anti pattern.
we have conducted two different case studies in this paper.
in section iv we evaluate the performance of lcanalyzer.
in section v we have applied lcanalyzer on the most recent releases of ten different open source software systems to evaluate the generalizability of our anti patterns and to gather developer feedback.
iv.
e valuating the performance of lca nalyzer here we present our first case study which is to evaluate the performance of lcanalyzer.
sections iv a andiv b describe our process of evaluating the recall and the precision of lcanalyzer respectively.
a. evaluating the recall of lcanalyzer constructing the oracle dataset unfortunately there is no readily available oracle dataset which contains the verified instances of the anti patterns in the logging code.
to evaluate the performance of lcanalyzer we have built an oracle dataset by ourselves.
the first author of this paper randomly selected a set of files from historical releases of three studied projects activemq hadoop and maven .
some of these files contain snippets of the verified anti patterns fixed by developers in the later revisions .
in addition to these verified code snippets the first author also manually went through every line of logging code in case there are any missing anti patterns instances that are not addressed by the open source developers.
the process was repeated until there are at least three verified instances of each type of anti patterns.
this process lasted for weeks.
then this set of files were handed over to a master student msc1 who has no prior knowledge of logging code antipatterns.
before msc1 started examining the content of these files he was only presented with the definitions of six antipatterns of logging code.
the anti pattern detection algorithm and the goal of the experiment were not disclosed to him.
the results between the first author and the msc1 were compared and reconciled.
the final resulting oracle dataset contains over verified instances of anti patterns.
recall results we have applied lcanalyzer on the oracle dataset.
the blue dotted bars in figure 5show the recall results.
in general lcanalyzer can detect anti pattern authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
log.info caught an amazonclientexception which means the client encountered a serious internal problem while trying to communicate with s3 such as not being able to access the network.
fig.
an example code snippet that is a logging anti pattern but lcanalyzer fails to flag.
name example data flow context analysis a jobimpl .java intentional printing b backupimage.java a unexpected variable update b intentional logging of byte arrays jobstate oldstate getstate try getstatemachine .dotransition event.gettype event catch invalidstatetransitonexception e ... log.info jobid job transitioned from oldstate to getstate private void logeditslocally long firsttxid int numtxns byte data ... editlog.logedit data.length data ... jobstate oldstate getstate try getstatemachine .dotransition event.gettype event catch invalidstatetransitonexception e ... log.info jobid job transitioned from oldstate to getstate private void logeditslocally long firsttxid int numtxns byte data ... editlog.logedit data.length data ... fig.
code snippets that lcanalyzer mistakenly flags as logging anti patterns.
instances as the recalls among all types of anti patterns are and above.
in particular lcanalyzer can detect all the anti pattern instances in dup2 explicit cast malformed output and nullable objects.
in one logging code snippet it includes a function call from one external library.
as lcanalyzer cannot extract the definition of that function it misses two instances of dup1.
the reason for recall in wrong verbosity level is because lcanalyzer uses an ast based detection approach and it cannot understand the sentiment of the logging code.
figure 6shows one such example.
although the verbosity level is info the static texts a serious internal problem suggest that the verbosity level should be warn error or fatal instead.
we have also calculated the average recall of lcanalyzer by averaging the recall values across six anti patterns.
the overall average recall for lcanalyzer is .
b. evaluating the precision of lcanalyzer to calculate the precision we have manually examined all of our detected anti pattern instances from our oracle dataset.
the bars with red diagonal lines in figure 5show the precision results.
there are two main reasons for the relative low precision for lcanalyzer unexpected variable update although some variables are defined in the same way as the method invocation sequences contained in the logging code the values of these variables were modified.
figure a shows a falsely identified case of dup2.
oldstate is defined as getstate at the beginning.
however it was later modified by the method sequences getstatemachine .dotransition event.
gettype event .
hence getstate cannot be replaced by oldstate in the logging code.
intentional logging although some snippets of logging code contain the symptoms of the anti patterns devel table iii the ten studied open source systems and their release information.
domain name version loc lloc aspectj?
servercloudstack .
.
yes hadoop .
.
no hbase .
.
no tomcat .
.
no argouml .
.
yes client jedit .
.
no maven .
.
no middleware activemq .
.
no framework camel .
.
yes gwt .
.0rc2 no opers perform these actions intentionally.
figure b shows an example of falsely identified instances of malformed output.
although data is a byte array developers intend to output binary data in this case.
we have also calculated the average precision of lcanalyzer in a similar manner as the average recall.
the average precision for lcanalyzer is .
the case study on a verified dataset shows that our static logging code analysis tool lcanalyzer can be used to successfully detect anti pattern instances in the logging code.
to further improve the performance of our tool researchers can look into other techniques e.g.
data flow analysis or natural language processing to encode and detect the antipatterns.
v. d etecting anti patterns in the open source software systems as the case study in the previous section shows satisfactory performance of lcanalyzer we apply this tool on the latest releases of ten different open source software systems.
our goal is to see how generalizable our characterized anti patterns are.
table iiishows the list of studied releases and their details.
all these systems are actively maintained and used by millions of users worldwide.
we have included the three studied systems in section ii as we want to check whether the six anti patterns still exist in their latest releases.
in addition we have also included other systems especially systems not from apache software foundation to check the generalizability of our anti patterns.
among these ten selected systems four systems belong to the server domain three systems are from theclient domain and the remaining three systems are from themiddleware framework domain.
the last two columns in table iiishow the total lines of source code loc and lines of logging code lloc for each system.
in general the systems in the server and themiddleware framework domains contain more loc and lloc than systems in the client domain.
in addition there is a strong correlation a spearman correlation value of .
between loc and lloc indicating that larger code base implies more logging code.
three cloudstack argouml and camel out of the ten studied systems also use aspectj as part authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
of their logging solutions.
however these systems still contain hundreds or thousands of lines of logging code.
there is no relation between the amount of logging code and whether the systems use aspectj or not.
we have applied lcanalyzer on the latest releases of the aforementioned ten systems.
our detection results are tabulated in table iv.
each row corresponds to one system and each column refers to the number of instances for that antipattern.
for example hadoop contains instances of wrong verbosity level which is .
of the total number of detected anti patterns instances .
in general all ten systems contain anti pattern instances.
in particular the two anti patterns dup1 and dup2 in the category of logging code smells contain the biggest number of instances in nine out of ten systems except maven .
although developers have already addressed many of the past anti pattern instances in hadoop activemq and maven there are still many instances in their latest releases.
the systems in the server andmiddleware framework domains contain more anti pattern instances than systems in the client domain.
however these systems also contain more lines of code.
hence in order to investigate the relation between the amount of anti pattern instances and the size of systems we have calculated the spearman correlation values between the total number of anti pattern instances for each type of anti pattern and lloc.
we denoted this as corr lloc x in the second last row of table iv in which x refers to a particular type of anti pattern.
for example the correlation between lloc and dup1 is .
.
this correlation value is bolded due to its statistical significance a.k.a.
p value .
.
similar calculations are done between the anti patterns and loc.
the results are shown in the last row of table iv.
there are medium to strong correlations between the number of anti pattern instances and lloc in five out of the six antipatterns.
this means that the larger the amount of logging code is the harder it is to maintain.
however we do not see a clear connection between the anti pattern instances and the overall system sizes loc .
our characterized anti patterns are general as we can find their instances across various types of systems.
there is a medium to strong correlation between the amount of logging code and the number of anti pattern instances.
as many industrial and open source systems contain large volumes of logging code this motivates the needs of further research into best practices of developing and maintaining high quality logging code.
initial feedback from developers we have selected representative instances from ten open source systems mentioned above and filed online issue reports to gather developer feedback.
so far instances .
have been accepted by their developers .
are under discussion and .
are rejected.
there are two main reasons for the rejected instances dump out contents of cwd and the environment to stdout for debugging private void dumpoutdebuginfo ... log.info dump debug output ... fig.
lcanalyzer considers this snippet of logging code as an anti pattern instance.
but the hadoop developer considered it as intentional logging and rejected the issue .
intentional logging figure 8shows one such example from hadoop.
the info level logging code contains the debug message.
however the developer rejected this instance as she indicated this was done intentionally not sure if this should change to debug level since the function is called intentionally ... .
developer s openness the developer of jedit rejected all the filed anti patterns instances due to his negative perceptions on the static analysis tools please do not submit code analysis tool results as bug.
.
of the reported instances have been accepted confirmed by their open source developers.
this has clearly demonstrated the importance and the value of this research.
vi.
t hreats to validity in this section we will discuss the threats to validity.
a. internal validity we characterize the anti patterns in the logging code by focusing on independently changed logging code as these changes are likely the fixes to the existing logging code.
our approach may miss some instances of logging code fixes as some of the co changed logging code may be logging code fixing and feature code co evolution in one commit.
however this might be a minor case as previous studies show that most of the logging code co changes are for co evolution with feature code.
we have developed a dependency based approach to automatically select independently changed logging code.
if we can find corresponding modified entities in the feature code for all the changed components in the logging code in one code commit this snippet of logging code is considered as co changed with the feature code.
otherwise it is a snippet of independently changed logging code.
as our approach has yield a relatively high precision we believe that we have obtained most of the independently changed logging code.
b. external validity we have focused on characterizing and detecting logging anti patterns in java based systems.
some of our derived findings and code anti patterns may not be directly applicable to systems implemented in other programming languages.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
table iv our detection results on the latest release of ten open source software systems.
the spearman correlation numbers in the last two rows are shown in bold if they are statistically significant p .
category system wrong dup1 dup2 nullable malformed explicit total total verbosity level objects outputs cast anti patterns log lines servercloustack .
.
.
.
.
.
.
hadoop .
.
.
.
.
.
.
hbase .
.
.
.
.
.
.
tomcat .
.
.
.
.
.
.
clientargouml .
.
.
.
.
.
jedit .
.
.
.
.
.
.
maven .
.
.
.
.
.
.
middleware activemq .
.
.
.
.
.
.
framework camel .
.
.
.
.
.
.
gwt .
.
.
.
.
.
.
corr lloc x .
.
.
.
.
.
corr loc x .
.
.
.
.
.
however we feel that our history based approach to characterize logging anti patterns is generic and can be used to study the anti patterns in the logging code developed in other programming languages e.g.
c or .net .
we have characterized six different anti patterns in the logging code by studying the historical changes in three popular open source systems activemq hadoop and maven in apache software foundation.
we have picked these systems due to the following two reasons they come from different application domains middleware server andclient and these three systems are actively maintained.
all the committed source code has been carefully peer reviewed .
we start our anti pattern characterization process from hadoop and then move on to activemq and maven.
we have noticed that no additional anti patterns have been identified in activemq and maven.
furthermore the case study in section vshows that these anti patterns also exist in many other non apache open source systems.
this gives us some confidence in terms of the generalizablility of the anti patterns.
however our catalog of anti patterns may not be complete.
we plan to address this problem by looking into other analysis approaches and studying more systems in the future.
c. construct validity as there is no existing benchmarking dataset for antipatterns in the logging code we have built an oracle dataset ourselves to evaluate the performance of lcanalyzer.
the dataset which has been compiled and verified by two different persons contains the verified instances of anti patterns in the logging code.
these two persons include the first author of the paper and another master student who has no prior knowledge of logging code anti patterns.
our process of building the oracle dataset is similar to many other papers e.g.
.
however we acknowledge that our oracle dataset may be incomplete a.k.a.
missing some anti pattern instances .
vii.
r elated work there are three areas of research related to this paper empirical studies on the existing logging practices toolsfor understanding developing and maintaining logging code and code smells and refactoring.
a. empirical studies on the existing logging practices industry studies show that there are no well defined best practices to guide developers on developing and maintaining the logging code .
hence it is worthwhile to study the logging practices of existing systems and learn from them.
yuan et al.
conducted a quantitative study on the logging code of several large scale open source software systems.
they have found that developers are constantly making an effort to improve the quality of their logging code.
shang et al.
studied the relation between the spread of the logging code and system quality.
they found that log related metrics e.g.
log density were strong predictors of post release defects.
kabinna et al.
performed a quantitative study on the rationale of logging code changes.
they built a data mining classifier to model the historical logging code changes.
their study showed that file ownership developer experience log density and sloc are important factors for deciding whether a snippet of logging code needs to be changed.
kabinna et al.
studied the migrations of logging libraries of several systems.
they found that systems migrate their logging libraries to gain additional functionalities to improvement maintainability and to enhance performance.
over of the migrated systems suffer from migration bugs afterwards.
our work is different from the above works as we focus on studying the rationales behind independently changed logging code.
our qualitative study on the logging code has resulted in six anti patterns in the logging code which can be used to detect and improve the quality of existing logging code.
b. tools for better understanding developing and maintaining logging code we further divide this area of research into three categories where to log tackles the problem of where to place the logging points.
yuan et al.
proposed a program analysis based approach to inferring additional logging authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
points to assist debugging.
fu et al.
used a data mining based approach to automatically identifying the important factors impacting the locations of the logging points.
ding et al.
used a constraint solving based method to determine during runtime the optimal logging points which incur minimum performance overhead but maximum runtime information.
what to log tackles the problem of adding sufficient runtime execution information.
yuan et al.
proposed a program analysis based approach to suggesting additional variables to be added into the existing logging points to facilitate error diagnosis.
how to log tackles the problem of developing and maintaining high quality logging code.
kiczales et al.
proposed aspect oriented programming aop to automatically develop and maintain the logging code.
however there are still many open source and industry systems which place the logging code along side with the feature code.
in this aspect only yuan et al.
partially studied this problem in .
they used a clone detection based approach to automatically identifying inconsistent verbosity levels.
our paper is the first work which systematically studies the problem of how to log by characterizing and detecting the anti patterns in the logging code.
c. code smells and refactoring code smells are symptoms of bad design and implementation choices .
code smell can increase change fault proneness and decrease program understandability .
there are various approaches to automatically detecting code smells in the source code e.g.
ast based approach history based approach and text mining based approach .
in addition to code smells researchers define test smells to be poor design and implementation choices when developing test cases .
studies also show that test smells have a strong negative impact on program comprehension and software maintenance .
van rompaey et al.
proposed a metricbased technique to detect test smells.
in this paper we have found that one of the top rationales of independently changed logging code is about log refactoring.
hence we define the logging code smells as poor design and implementation choices when developing the logging code.
we have proposed two symptoms of the logging code smells dup1 and dup2.
both symptoms are to address the problems of duplication in logging code and long logging code.
this paper is the first work which proposes the idea of logging code smells and their symptoms.
viii.
c onclusions and future work developers instrument their systems with logging code to gain insights about the systems runtime behaviour.
it is challenging to develop and maintain high quality logging code due to the lack of well defined coding guidelines.
in this paper we have characterized six anti patterns in the logging code by carefully studying the development history ofthree open source software systems from different application domains activemq hadoop and maven.
to demonstrate the usefulness of our findings we have developed lcanalyzer which statically scans through the source code searching for anti pattern instances.
case studies show that lcanalyzer which has a high recall and a satisfactory precision can detect many anti pattern instances in ten different open source software systems.
we have filed a few selective instances to their issue tracking systems.
so far we have received very positive feedback from the hadoop and the tomcat developers.
verifiability we have provided a data package to support independent verification or replication of our study .
the package consists of three sets of data the characterization dataset contains the set of manually examined independently changed logging code snippets and our analysis results.
the oracle dataset contains the list of source code files and our verified instances of anti patterns in the logging code.
the anti pattern instances dataset contains the list of anti pattern instances detected by lcanalyzer for the recent releases of ten open source software systems.
in addition the filed anti pattern instances the issue ids and their current status are also included.
in the future we want to improve the precision of lcanalyzer by incorporating additional analysis techniques e.g.
data flow or natural language processing .
in addition we plan to expand our anti pattern catalog of logging code by studying the development history of other systems e.g.
smartphone applications or industry systems .
finally we also want to solicit more feedback from developers in terms of what are other good bad logging code practices.