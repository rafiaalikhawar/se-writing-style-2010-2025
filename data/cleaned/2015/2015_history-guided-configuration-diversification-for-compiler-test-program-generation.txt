history guided configuration diversification for compiler test program generation junjie chen1 guancheng wang2 dan hao2 yingfei xiong2 hongyu zhang4 lu zhang2 1college of intelligence and computing tianjin university tianjin china junjiechen tju.edu.cn 2key laboratory of high confidence software technologies peking university moe 3department of computer science and technology eecs peking university beijing china guancheng.wang haodan xiongyf zhanglucs pku.edu.cn 4the university of newcastle nsw australia hongyu.zhang newcastle.edu.au abstract compilers like other software systems contain bugs and compiler testing is the most widely used way to assure compiler quality.
a critical task of compiler testing is to generate test programs that could effectively and efficiently discover bugs.
though we can configure test generators such as csmith to control the features of the generated programs it is not clear what test configuration is effective.
in particular an effective test configuration needs to generate test programs that are bug revealing i.e.
likely to trigger bugs and diverse i.e.
able to discover different types of bugs.
it is not easy to satisfy both properties.
in this paper we propose a novel test program generation approach called hicond which utilizes historical data for configuration diversification to solve this challenge.
hicond first infers the range for each option in a test configuration where bug revealing test programs are more likely to be generated based on historical data.
then it identifies a set of test configurations that can lead to diverse test programs through a search method particle swarm optimization .
finally based on the set of test configurations for compiler testing hicond generates test programs which are likely to be bug revealing and diverse.
we have conducted experiments on two popular compilers gcc and llvm and the results confirm the effectiveness of our approach.
for example hicond detects .
.
and .
more bugs than the three existing approaches respectively.
moreover hicond has been successfully applied to actual compiler testing in a global it company and detected bugs during the practical evaluation.
index t erms compiler testing configuration history search i. i ntroduction compilers are one of the most important software systems since almost all software systems are built from them.
however like other software systems compilers also contain bugs .
due to their crucial roles buggy compilers could cause unintended behaviors even disasters for all software systems built from them.
moreover compiler bugs also increase the debugging difficulty for software developers.
for example when a software system built from a compiler crashes it this work is supported by the national key research and development program of china under grant no.2017yfb1001803 and the national natural science foundation of china under grant no.
.
this work was mainly done when junjie chen was at peking university.
dan hao yingfei xiong and hongyu zhang are sorted in the alphabet order of the last names.
corresponding authors.is very hard for the developers to determine whether the crash is caused by the software they are developing or the compiler they are using.
therefore guaranteeing the quality of compilers is very essential.
compiler testing is the most widely used way to assure compiler quality and has attracted extensive attention over the years .
in the area of compiler testing automated test program generation is an important aspect since it is the initial step in the testing process and its performance has large impacts on the following testing process .
to support the generation of test programs several test program generators such as csmith or clsmith have been developed.
these tools generate a random set of test programs based on a test configuration consisting of many options to control what features these test programs are likely to include.
for example the test configuration of csmith consists of options such as the probability of the occurrence of return statement and int type to control the generation of test programs where each option directly reflects the probability of a specific program feature an element of a language grammar to be included.
an important goal for automated test program generation is to discover bugs as many as possible.
however it is not easy to achieve this goal and there are two major challenges.
first as shown in the existing studies compiler bugs are not evenly distributed across the whole input space and thus it is more important to generate test programs that are more likely to trigger bugs.
however although we can control the testprogram generation through a test configuration it is not clear what configuration would lead to such test programs.
second it is important to improve the diversity of the generated test programs to cover a wide range of compiler bugs.
as justified by the state of the art random compiler test program generation approach swarm testing randomizing the configuration options could lead to more bugs being discovered.
in this paper we propose hicond history guided con figuration diversification a novel test program generation approach for compilers.
hicond consists of two stages the first stage is to produce a set of test configurations and the second stage is to generate test programs using this set of test configurations.
to address the above mentioned two 34th ieee acm international conference on automated software engineering ase .
ieee authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
challenges the test configurations produced by our approach hicond should be able to generate both bug revealing and diverse test programs.
to address the first challenge hicond utilizes the historical data of compiler testing.
more specifically hicond collects test programs that have triggered or have not triggered compiler bugs mines the associations between program features and compiler bugs and infers the range for each configuration option to generate test programs with bug revealing features.
to address the second challenge hicond measures the diversity of test programs generated under different test configurations based on their program features and then uses the particle swarm optimization pso a heuristic search algorithm to find a set of test configurations that both are able to generate diverse test programs and are within the bug revealing range of each option.
for the ease of presentation we call such a set of test configurations a set of bug revealing and diverse test configurations in this paper.
we conducted an empirical study to evaluate the effectiveness of our compiler test program generation approach hicond using two most popular c compilers five versions in total i.e.
gcc and ll vm based on the most widely used test program generator csmith .our experimental results show that during the given testing period hicond performs significantly better than three comparison approaches i.e.
testprogram generation with the default test configuration and the state of the art random testing techniques swarm testing and its variant for each compiler subject in terms of the number of detected bugs the number of unique bugs and the time spent on detecting each bug.
for example hicond detects .
.
and .
more bugs than the three comparison approaches for all the used compiler subjects and .
out of bugs detected by hicond cannot be detected by the other three approaches.
moreover hicond spends shorter time than the other three approaches on detecting almost every bug.
furthermore hicond has been successfully applied to the practical compiler testing in a global it company a1 and detected bugs in a private benchmark containing compilers with real bugs developed in a whereas csmith with the default configuration detected a subset of bugs during the same testing period.
our work makes the following major contributions a novel test program generation approach for compilers through searching a set of bug revealing and diverse test configurations for existing test program generators based on testing history.
experimental results on gcc and ll vm demonstrating that hicond significantly outperforms all the three existing approaches e.g.
detecting .
and .
more bugs than them.
practical effectiveness evaluation of hicond for testing the compilers in a global it company a detecting bugs during one week testing.
1due to the company policy we hide the name of the company.our tool and experimental data are publicly available at .
ii.
b ackground a. compiler test program generation over the years various compiler testing techniques have been proposed such as rdt randomized differential testing dol different optimization levels and emi equivalence modulo inputs .
these techniques tend to be used by first randomly generating test programs via certain compiler test program generator like csmith and then using their own test oracles to determine whether compiler bugs are detected by these test programs.
for example rdt first uses a generator to randomly generate a test program and then compares the outputs of several comparable compilers for the test program.
if the produced results are different a compiler bug is detected.
as the initial step of compiler testing compiler test program generation has attracted extensive attention .
many efforts focus on creating test program generators.
these test program generators typically provide a set of configuration options for the users to configure the features of the generated programs.
for example csmith the most widely used c program generator randomly generates c programs according to a test configuration with options.
it generates a c program by conducting a series of decisions i.e.
determining whether a program feature e.g.
areturn statement is produced at a decision point.
in particular csmith introduces some heuristics and safety checks to avoid undefined behaviors.
afterwards clsmith a test program generator for opencl compilers is developed by adapting csmith.
clsmith contains six modes and can generate different types of opencl kernels under different modes.
some research efforts focus on finding effective test generation methods based on these generators.
for example groce et al.
proposed an interesting idea called swarm testing to generate diverse test programs by randomizing test configurations of test program generators.
b. test configuration a typical random test program generator uses a test configuration to randomly generate valid test programs.
a test configuration consists of a set of options each of which directly reflects the probability of a specific program feature to be included.
more specifically during the generation of a test program there are many decision points for each feature and at each point the option is used to decide whether the feature is produced here with the corresponding probability.
for example the test configuration used in csmith includes the following options i.e.
options in total the generation probability of various kinds of statements e.g.
return statement and if statement the generation probability of various kinds of types e.g.
int char and struct the generation probability of various kinds of operators e.g.
logical operators and arithmetical operators authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
the generation probability of various kinds of modifiers e.g.
const andvolatile some specific options e.g.
the probability to produce more structs and unions and the probability to produce an inline function under a test configuration a test program generator randomly generates a large number of new test programs for compiler testing.
currently there are two existing ways to set the test configuration default a test program generator has a default test configuration each option in which has a default value.
the default test configuration is heavily tuned according to the experience and knowledge of developers which tends to be regarded as an optimal test configuration .
swarm testing swarm testing aims to generate diverse test programs by randomizing test configurations .
more specifically swarm testing randomly sets the value of each option in a test configuration.
in this case a test program generator generates test programs by first randomly constructing a test configuration and then using the test configuration to generate test programs.
to sum up the default way is to use a fixed test configuration for a test program generator to generate test programs while the swarm testing way is to randomize test configurations to generate test programs.
iii.
a pproach an important goal for automated compiler test program generation is to generate test programs that could lead to more bugs being discovered.
for illustration we shall call the space of test programs that trigger bugs as the bug space and the goal is to generate diverse test programs within the bug space.
as demonstrated by the existing swarm testing work it is hard to use one uniform test configuration to generate test programs to thoroughly explore bug space.
to sufficiently explore bug space we need a set of test configurations to generate test programs.
since a test configuration can explore only a portion of bug space and there are still many test configurations that even do not enter into bug space at all each test configuration in the desired set should be able to generate test programs exploring a large portion of bug space which is the first criterion for the desired set.
however it is impossible to enumerate each test configuration that can generate bugrevealing test programs to thoroughly explore bug space.
a more efficient way is to make different test configurations in the desired set be able to explore different portions of bug space.
that is the set of test configurations should have diversity for bug detection which is the second criterion for the desired set.
to achieve this goal we propose hicond a novel compiler test program generation approach via history guided configuration diversification which explores the whole bug space as much as possible by finding such a set of test configurations for compiler test program generation.
to satisfy the first criterion hicond determines the range of each option in a testconfiguration where the bug revealing test programs are more likely to be generated.
here we utilize the statistics on the basis of historical data to infer the range for each option.
to satisfy the second criterion hicond considers their diversity when constructing the set of test configurations.
here we first propose a method to measure the diversity of test programs generated under different test configurations based on their program features.
then we use the pso algorithm to search such a set of test configurations within the bug revealing range of each option.
figure shows the overview of hicond.
in the following we present the history based range inference in section iii a the diversity measurement in section iii b and the pso based searching in section iii c. a. history based range inference in this step we need to find a range for each option that has a high probability of triggering bugs.
to do this we assume the existence of an optimal setting for each option and try to deduce a range to include the setting.
we first introduce the background of options and data collections then describe three properties that we assume to hold for the optimal setting and finally give our formula utilizing the three properties.
background.
as presented in the existing work each option in a test configuration controls a specific program feature during test program generation.
an option is usually a probability i.e.
a floating point number ranging from to which refers to the possibility that the corresponding program feature is successfully produced at each decision point during test program generation.
that is there exists a mapping between an option in a test configuration and a program feature.
therefore we can analyze the features in the generated test programs for testing historical bugs to infer the range of each option.
in testing history there are a huge number of test programs that trigger compiler bugs and those that do not trigger compiler bugs.
here we call the former failing test programs denoted as pf pf1 pf2 ... p fm and the latter passing test programs denoted as pp pp1 pp2 ... p pn where mandnare the size of the failing and passing program set respectively.
for each test program we can record the decisions for all program features during test program generation.
then a test program can be represented as a feature vector denoted as p e1 e2 ... e r whereei i r i st h e number of times the ithfeature is successfully produced at all its decision points and rrefers to the number of features.
based on these feature vectors we compute the probability that a feature is produced during the generation of all the failing and passing test programs respectively.
the computation is shown as formula where nis the size of the test program set eijrefers to the number of times the ithfeature is produced at all its decision points during the generation of thejthtest program and tijrefers to the total number of decision points for the ithfeature during the generation of the jthtest program.
here we denote prin the formula on the failing test programs as prf and denote pron the passing test programs as prp .
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
fig.
overview of hicond pr i summationtextn j 1eij summationtextn j 1tij properties of optimal setting.
now we assume that for each feature there is an optimal setting that maximizes the probability of producing failing programs and the further we move away from the optimal setting the lower the probability of producing failing programs is.
given two features i j we denote the initial setting of the corresponding options for featuresi j aspi pj and the optimal settings of the options for feature i j asqi qj.
it is easy to see that the following properties hold.
in the following properties we ignore the statistical errors and assume prf and prp to be the precise probabilities.
a1 qi piiffprf i pi qi p iiffprf i p i. whenqi pi it means that a program where more instances of feature iare produced at decision points has a higher probability to fail and thus prf i will be within i.e.
prf i pi.
same for the case qi p i. a2 suppose pi pj.w eh a v e qi pi qj pj iff prf i pi prf j pj .
following the above analysis the further the optimal setting deviates the initial setting the further the prf value deviates from the initial setting.
also we assume the initial setting reflects the confidence of the developer.
by default the developer would set the initial setting to the even distribution.
the more the developer changes it away from the even distribution the higher their confidence is.
therefore we have the following property.
a3 i f pi pj then qi pi qj pj .
in other words the closer the initial setting is to the smaller the confidence about the feature is indicating that the distance between the optimal setting and the initial setting is larger.
calculating ranges.
based on the above three properties we now propose a formula to calculate the ranges for options.
our formula borrows the calculation method of big support difference for identifying emerging patterns and utilizes the three properties to include the optimal setting as much as possible.
more specifically the range of the ithoptionr i is inferred as follows where pirefers to the initial setting of the option for generating these historical data and diff i prf i prp i .
r i braceleftbigg diff i diff i now we analyze how the formula utilizes the above three properties.
regarding a1 it is easy to see that diff i impliesprf i p i and thus we set the range to be smaller thanpi.
the same for the other direction.
regarding a2 the size of the range depends on diff i so when qideviates more from pi the range also becomes large to include qi.
regarding a3 prf and prp are calculated based on the generated programs under pi so the closer to or pi is the more difficult for prf and prp to deviate from pi and thus diff becomes smaller.
b. diversity measurement measuring the diversity of test configurations actually refers to measure the diversity of generated test programs under these test configurations.
as presented in section iii a each generated test program can be represented as a feature vector and thus hicond uses the distance between these feature vectors to measure the diversity of test programs.
more specifically assuming a set of test configurations are denoted asc c1 c2 ... c g where gis the number of test configurations and ci oi1 oi2 ... o ir and the generated test programs under ciare denoted as pi pi1 pi2 ... p is wheresis the number of generated test programs under each test configuration hicond computes the diversity among pi i g to measure the diversity of test configurations.
intuitively the generated test programs under a test configuration tend to concentrate on an area of input space.
with this intention hicond first sets a group center for these generated test programs and then computes the distance between different group centers.
for test program set pi generated under test configuration ci hicond sets the group centerpciby computing the mean of each feature on all the generated test programs.
then for a test configuration hicond computes all the distances between the group center authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
and other group centers and uses the minimum distance among them as the distance between this test configuration and all other test configurations.
the computation is shown in formula where hicond uses the manhattan distance asthe distance formula for dist pci pc j .
diversity ci min j j negationslash i dist pci pc j c. pso based searching to construct a set of test configurations exploring bug space as much as possible hicond adopts the particle swarm optimization pso algorithm to search for an optimal set of test configurations.
the reason why we choose pso is that pso is very effective to search in a continuous space which aligns to our problem where we search the floating point probability of each option also in continuous space.
in our problem each particle in pso is a test configuration ci and our expected output is a set of diverse test configurations exploring the whole bug space.
therefore we hope particles to fly to different portions of bug space during the searching process.
according to this intention we define the fitness function of the pso based searching as the diversity among test configurations which is computed based on section iii b. the larger the fitness value of a test configuration is the larger diversity the test configuration has with other test configurations.
during the pso based searching process hicond first initiates a set of particles i.e.
test configurations .
since hicond should search the test configurations under which the generated test programs are more likely to trigger compiler bugs it sets the search space for each option based on the inferred range in section iii a. in particular each particle has its own velocity for each moment vt i vt i1 vt i2 ... vt ir wheretrefers to the tthmoment.
also we denote a particle for thetthmoment as ct i ct i1 ct i2 ... ct ir .
in each moment hicond utilizes the fitness function to evaluate the quality of each particle and then updates each particle including its velocity.
formula shows the updating of the velocity.
in this formula 1 and 2are three weights where refers to the inertia weight and the other two weights refer to the acceleration factors 1and 2are two random numbers between and bt ijrefers to the jthoption of the personal optimum test configuration that the ithtest configuration has reached before moment t andbt gjrefers to the jthoption of the global optimum test configuration that all test configurations have reached before moment t please note that optimum here refers to the largest fitness values.
then the test configuration can be updated as shown in formula .
vt ij vt ij 1 1 bt ij ct ij 2 2 bt gj ct ij ct ij ct ij vt ij each particle i.e.
test configuration keeps changing as above and finally when reaching the terminating condition i.e.
the pre defined number of iterations moments a set of bug revealing and diverse test configurations are found.
finally hicond utilizes the set of test configurations to generate test programs for testing compilers.
since only one test configuration can be used when generating a test program hicond randomly selects a test configuration from the set every time to generate a test program.
iv .
e xperiment al study design in the study we address the following research questions rq1 how does hicond perform compared with existing compiler test program generation approaches?
rq2 does hicond perform well in different scenarios including cross version and cross compiler scenarios ?
rq3 does each component contribute to hicond?
a. subjects and test programs in the study we used two popular c compilers as subjects i.e.
gcc and ll vm following the existing compiler testing research .
more specifically we used three versions of gcc compilers and two versions of ll vm compilers for the x86 linux platform i.e.
gcc4.
.
gcc .
.
gcc .
.
ll vm .
and ll vm .
.
.
on average the size of gcc is 411k sloc source lines of code and the size of ll vm is 470k sloc.
in particular these used compiler versions include both old release versions and a recent release version.
the reason is that the older releases usually contain more bugs and give more statistically significant results while we also used a recent release of ll vm to investigate whether hicond still works well for a new release version.
besides hicond relies on historical data.
in the study we collected historical data on gcc .
.
which is released before all the subjects in our study.
here the collected historical data include the test programs triggering bugs and the test programs not triggering bugs on gcc .
.
.
please note that all the used historical bugs on gcc .
.
were fixed before all the used subjects in our study are released.
b. tools and implementations in our study we used csmith the most widely used c program generator as the studied random test program generator.
as described in section ii b csmith uses a test configuration with options to control the test program generation.
it takes a test configuration file as input and then generates test programs based on the given test configuration in the file.
when collecting the historical data on gcc .
.
we used csmith with its default test configuration to generate test programs which are divided into two sets i.e.
failing test program set and passing test program set according to their testing results.
here we used the dol technique to test compilers which is one of the most widely used compiler testing techniques .
that is if a test program produces different outputs under different optimization levels of a compiler given the same test inputs a compiler bug is detected and this test program is a bug revealing test program.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
to record all the decisions of program features during test program generation for hicond we adapted csmith to output all the decisions when generating a test program.
for the pso algorithm used in hicond we set 1and 2 to be to be the number of particles to be the times of iterations to be and the number of generated test programs under each test configuration sto be .
in particular we investigated the impact of main parameters in pso on hicond in section viii.
in addition we set the testing period to be days in our study.
we implemented hicond and all experimental scripts using c python and perl.
our study was conducted on a workstation with four core cpu 120g memory and ubuntu .
operating system.
c. comparison approaches hicond is a compiler test program generation approach which searches a set of bug revealing and diverse test configurations of random test program generators.
therefore we chose the comparison approaches that also utilize test configurations of random test program generators to control compiler test program generation.
as described in section ii b there are two ways to set a test configuration for test program generation i.e.
default and swarm testing .
for swarm testing its original version proposed in the paper randomly sets the value of each configuration option to be or .
in this paper we also consider a natural variant of swarm testing that randomly sets the value of each option to be a floating point number ranging from to .
for the ease of presentation we call the approach utilizing the default way defaulttest that utilizing the original swarm testing way oriswarm and that utilizing the variant swarm testing way varswarm in this paper.
there are two key components in hicond i.e.
range inference and pso based searching.
to investigate whether each component contributes to hicond we have two variants of hicond.
the first variant is hicond global which removes range inference from hicond and conducts psobased searching globally i.e.
ranging from to for each option .
the second variant is hicond random which removes pso based searching from hicond and conducts random searching within the inferred range for each option.
to answer rq3 we compared hicond with the two variants.
d. application scenarios here we consider two application scenarios of hicond including cross version scenario and cross compiler scenario.
cross version scenario hicond searches a set of bugrevealing and diverse test configurations based on the historical data of a compiler version and then uses the set of test configurations to generate test programs for a later version of the compiler.
in our study hicond used the data of gcc4.
.
to search test configurations and then used the searched test configurations to generate test programs for gcc .
.
gcc .
.
and gcc .
.
respectively.
here we considered a series of later versions to investigate the stability of the test configurations searched by hicond.cross compiler scenario hicond searches a set of bugrevealing and diverse test configurations based on the historical data of a compiler and then uses the set of test configurations to generate test programs for another compiler.
in our study hicond also used the data of gcc .
.
to search test configurations and then used the searched test configurations to generate test programs for ll vm .
and ll vm .
.
respectively.
in this way we can evaluate the generality of hicond cross different compilers.
e. metrics in our study we used two metrics to measure the effectiveness of compiler test generation approaches.
the first one is the number of bugs detected during the given testing period.
we adopted correcting commits a method commonly used in existing studies to identify the number of detected bugs from a set of failing test programs.
more specifically for each failing test program the correcting commits method is to find the first commit correcting the bug i.e.
the committed version makes the test program pass.
if two failing test programs have the same correcting commit they are regarded as triggering the same bug.
the number of correcting commits is approximately regarded as the number of detected bugs.
the accuracy of this method has been demonstrated in the existing study .
the second one is the time spent on detecting a compiler bug.
this metrics can reflect the performance of hicond on detecting each bug.
f .
experimental process first we collected historical data on gcc .
.
by running test programs generated by the adapted csmith with the default test configuration.
in this way we collected a set of failing test programs around and a set of passing test programs around .
also we recorded all the decisions of program features during the generation of each test program.
second we applied hicond hicond global and hicond random to search a set of test configurations and fed the set of test configurations to generate test programs to test gcc .
.
gcc .
.
gcc .
.
ll vm .
and ll vm .
.
for days respectively.
we recorded the testing result and execution time for each test program.
third we also applied defaulttest oriswarm and v arswarm to test each subject for days and recorded the testing result and execution time for each test program.
finally we measured the number of detected bugs for each test program generation approach.
in particular it took us over half of a year to run our experiments.
v. r esul ts and analysis a. overall effectiveness of hicond we analyzed the overall effectiveness of hicond compared with the three comparison approaches from three aspects including the number of detected bugs the number of unique bugs and the time spent on detecting each bug.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
hicond defaulttest oriswarm varswarm16 a gcc .
.0hicond defaulttest oriswarm varswarm6 b gcc .
.0hicond defaulttest oriswarm varswarm2 c gcc .
.0hicond defaulttest oriswarm varswarm5 d ll vm .6hicond defaulttest oriswarm varswarm30 e all fig.
number of unique bugs t able i number of detected bugs within days subject hicond defaulttest oriswarm varswarm gcc .
.
gcc .
.
gcc .
.
ll vm .
ll vm .
.
total number of detected bugs table i shows the number of detected bugs during the given day testing period.
from this table for each subject hicond detected the largestnumber of bugs among the four approaches demonstratingthe effectiveness of hicond.
in particular the total numberof detected bugs by hicond is which is much larger than that by defaulttest i.e.
oriswarm i.e.
and v arswarm i.e.
achieving .
.
and .
improvements respectively.
from the results of ll vm .
.
a recent release version of ll vm hicond also detects thelargest number of bugs and defaulttest and v arswarm donot detect any bug during the given day testing period indicating that hicond still works on the new release version.therefore hicond does significantly outperform all thecomparison approaches.
although oriswarm and v arswarm also consider the diversity of test configurations they perform worse thanhicond.
we analyzed the reason behind this phenomenon.for oriswarm it uses or to replace a floating point num ber for each option which makes all the decisions of a featurethe same during the generation of a test program.
although itincreases the diversity of test configurations it actually limitsthe diversity of generated test programs to some degree.
forv arswarm due to its random mechanism of test configurationconstruction it often produces test configurations that outsideour inferred ranges.
a small experiment on configurations show that in of the time the generated options are outside the range inferred by hicond.
as our experiment forrq3 will show later ignoring the ranges lead to significantlylower performance.
number of unique bugs these v enn diagrams in figure show various relations among the bugs detected bythe four approaches e.g.
the unique bugs and the commonbugs detected by only two approaches.
here we do notshow the results of ll vm .
.
since only hicond andoriswarm detected bugs on this subject and there is onecommon bug for them and one unique bug for hicond.figure 2e shows the overall results on all the subjects.
fromthis figure each approach is able to detect some unique bugs but hicond always detects the largest number of unique bugs.
in particular from figure 2e the total number of unique bugs detected by hicond is which is much larger thanthat by defaulttest i.e.
that by oriswarm i.e.
andthat by v arswarm i.e.
.
also .
out of bugsdetected by hicond are unique.
that demonstrates that thefour approaches are able to complement each other to somedegree and hicond has the largest unique value among them.
interestingly although oriswarm and v arswarm detected fewer bugs more than half of these bugs are not detectedby the other approaches.
the reason is that oriswarm andv arswarm have the ability to explore a larger portion of input space than the other approaches due to their random mechanisms of test configuration construction.
therefore theycan reach a certain bug space that is not explored by the otherapproaches respectively.
although hicond aims to explorethe whole bug space in fact it is very hard to perfectly achievethis goal within the given testing period.
therefore it maymiss a portion of bug space to explore.
that also means thatthere is still room for further improving hicond.
furthermore there is also some unique bugs detected by defaulttest.
the reason is that defaulttest always focuses oncertain small portion of bug space and thus it is more likely tosufficiently explore this portion during the given testing period.however the other three approaches have larger explorationspace and thus they may not sufficiently explore the portionfocused by defaulttest causing to miss the detection of somebugs.
to sum up there exists a trade off between the deepexploration for a small portion of bug space and the wideexploration for the whole bug space and hicond seems toreach a good balance for it.
time spent on detecting each bug table ii shows the time spent on detecting each bug for each approach.in this table column bug refers to each bug e.g.
refers to the first detected bug and refers to the seconddetected bug column hicond refers to the time spent ondetecting each bug by hicond columns defaulttest oriswarm and v arswarm refer to the difference of authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
the time spent on detecting each bug between the comparison approach and hicond where a positive value means the comparison approach spent longer time on detecting the bug than hicond while a negative value means it spent shorter time on detecting the bug.
note that since different approaches detected different number of bugs we used to align them in the table.
for example for the 15thbug in gcc .
.
it is only detected by hicond and thus we marked in the cells of defaulttest oriswarm and v arswarm.
from this table for almost all of bugs hicond spent the shortest time on detecting the bug.
there are only four bugs that hicond spent longer time than defaulttest to detect and only one bug that hicond spent longer time than oriswarm and v arswarm to detect respectively.
that demonstrates that hicond is able to detect almost every bug more efficiently indicating the stably good effectiveness of hicond.
b. effectiveness on different application scenarios we analyzed the effectiveness of hicond in different application scenarios according to tables i ii and figure .
since the used historical data by hicond is from gcc .
.
the results of the three gcc versions reflect the effectiveness of hicond in cross version scenario and the results of the two ll vm versions reflect the effectiveness of hicond in cross compiler scenario.
through analyzing the effectiveness of hicond on three gcc versions we found that hicond always performs the best among the four approaches demonstrating its stably good effectiveness cross different versions.
that means that it is not necessary to re search test configurations using hicond for each new version.
also we found that the improved effectiveness of hicond compared with the other approaches is reduced with the gap between the historical version and testing version increasing.
the reason may be either the number of bugs in new versions becomes smaller or the capability of the searched test configurations becomes weaker due to larger gap.
assuming the latter is the reason we may boost the capability of hicond by adding some new data on the versions that are closer to the testing version.
through analyzing the effectiveness of hicond on two ll vm versions hicond also achieves better results than the other approaches.
that demonstrates the cross compiler ability of hicond.
that is hicond is able to be generalized to different compilers even though it is based on the historical data on only one compiler.
in summary hicond does perform well in both of crossversion and cross compiler scenarios.
c. contributions of each component in hicond table iii shows the comparison results among hicond hicond global and hicond random in terms of the number of detected bugs during the day testing period.
from this table hicond significantly outperforms hicond global demonstrating the contribution of the range inference component in hicond.
when conducing pso based searching globally hicond global can find a set of diverse test configurations forthe whole input space.
however it is very difficult to ensure these test configurations to be bug revealing since the bug space tends to be only a small part of the whole input space.
in addition hicond performs better than hicond random demonstrating the contribution of the pso based searching component in hicond.
when randomly searching a set of test configurations it is hard to ensure the diversity of these test configurations.
that is some test configurations searched by hicond random may explore the similar portion of the bug space leading to the worse effectiveness.
to sum up both of the components significantly contribute to hicond and the range inference component makes more contributions.
vi.
i ndustrial ev alua tion hicond has been successfully applied to the practical compiler testing in a global it company a. this company has several their own compilers and a lot of products in company aare built from them.
therefore guaranteeing the quality of these compilers is very important and efficient compiler testing is in demand.
hicond aims to efficiently explore the whole bug space as much as possible which admirably serves their needs.
in company a before integrating a new tool into the practical testing infrastructure an effectiveness evaluation of the tool is necessary.
in the practical evaluation of hicond they used six widely used compilers developed by company awith several known real bugs as subjects.
in particular these compilers are in different application areas and different platforms the total size of them is over million sloc and these bugs have different characteristics.
hicond achieved great effectiveness for these diverse industrial compilers.
more specifically hicond detected bugs for each of these compilers and detected bugs in total during one week testing.
during the same testing period csmith with the default configuration detected bugs all of which were also detected by hicond.
the results demonstrate that hicond is effective in practice.
also hicond is largely appreciated by the compiler testing team of company aaccording to the practical evaluation.
vii.
d iscussion a. generality of hicond hicond is a general approach.
first hicond is able to be generalized to compilers of other programming languages.
although in our study we evaluated the effectiveness of hicond on only c compilers there is no part in hicond specific to c. the input of hicond is a random test program generator that can be controlled by a test configuration.
if a compiler of certain programming language contains such a random test program generator it is easy to apply hicond to it by running the generator to collect a collection of historical data.
therefore hicond can facilitate testing of any compiler with such a random test program generator.
besides hicond is also able to be generalized to other software systems taking structurally complex test inputs such as operating systems and browsers.
there are two conditions authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
t able ii time spent on detecting each compiler bug 103seconds subject bug hicond defaulttest oriswarm varswarm subject bug hicond defaulttest oriswarm varswarm gcc .
.
.
.
.
.
gcc .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
gcc .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
ll vm .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
ll vm .
.
.
.
.
.
.
.
.
t able iii comparison among hicond hicond global and hicond random subject hicond hicond global hicond random gcc .
.
gcc .
.
gcc .
.
ll vm .
ll vm .
.
total applying hicond to other software systems the software system has such a random test generator the test inputs of the software system have features relevant to the options of the test configuration.
there are a large number of software systems e.g.
operating systems and browsers taking structure complex test inputs which tend to contain many features and thus hicond can be applied to them to improve their testing.
b. limitation of hicond our study has demonstrated the effectiveness of hicond for compiler testing but there exists a limitation in hicond.
hicond currently treats each option individually.
however there may exist various constraints among program features and thus different options may have interactions.
also as presented in the existing work various combinations of program features may be also related to compiler bug detection.
therefore neglecting the coupling effect may affect the effectiveness of hicond.
even though hicond does not explicitly consider interactions of options hicond measures diversity based on the generated test program under constraints which can be regarded as an implicit way.
in fact the constraints of various program features may be very complex and thus it is challenging to consider all of them.in the future we will first consider the constraints formed by two program features.
viii.
t hrea ts to validity the internal threat to validity mainly lies in our implementations including hicond swarm testing and the experimental scripts .
for swarm testing we re implemented it based on the description in the paper .
to reduce this threat the first two authors carefully checked all the code.
the external threats to validity mainly lie in the subjects the studied random test program generator and the used technique for compiler testing .
regarding the subjects we used five versions of two compilers as subjects and these subjects may not be representative enough for different compilers.
to reduce this threat we selected the two most popular c compilers following the existing studies .
more specifically we considered different versions of different compilers and both old and recent release versions to evaluate the effectiveness of hicond from various aspects.
furthermore our industrial evaluation indicates that our results hold on other compilers.
regarding the studied random test program generator we only used csmith in our study which may not represent other random test program generators.
however this threat may not be serious due to the following reasons.
first csmith is recognized as the most effective c program generator and has been widely used to test c compilers .
second all recent c compiler testing studies used only the csmith test program generator .
third many other random test program generators are adapted from the csmith generator .
regarding the used technique for compiler testing we used the dol technique in our study.
however we believe that hicond can be generalized to various compiler testing techniques such as rdt and emi .
this is because all these compiler authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
testing techniques first utilize a test program generator like csmith to generate test programs and then use their testoracle mechanisms to detect compiler bugs.
hicond is a novel test program generation approach that is orthogonal to these compiler testing techniques.
therefore hicond can be combined with any compiler testing technique and improve their performance.
the construct threats to validity mainly lie in the metrics randomness the given testing period the collected historical data the used comparison approaches and the setting of parameters in hicond .
regarding the used metrics we adopted the correcting commits method to estimate the number of detected bugs.
this method may not be perfectly precise but it is the only metric which can automatically measure the number of bugs with some precision so far .
regarding randomness since these test program generation approaches generate test programs randomly based on a test configuration the randomness may impact the effectiveness of these approaches.
to reduce the threat we use a long testing period instead of repeating the testing process several times.
regarding the testing period we set the period to be days which is relatively long compared with the existing work .
also we analyzed the time spent on detecting each bug so that we can learn whether hicond performs well during various testing periods within days.
regarding the collected historical data we ran test programs on gcc .
.
to collect historical data and the used historical compiler and the number of test programs may impact the effectiveness of hicond.
in the future we will scale up our historical data to evaluate the effectiveness of hicond and investigate the impact of different historical data on hicond.
regarding the used comparison approaches we adopted three existing approaches and two variants of hicond.
in the future we will try to use other search based algorithms to investigate the impact of our used pso algorithm.
regarding the parameter setting we set them following existing work .
however the setting may impact the effectiveness of hicond.
to reduce this threat we evaluated the impacts of two main parameters i.e.
the number of particles and the times of iterations for pso on hicond by using gcc .
.
.
here we changed the value of one parameter each time and remained the values of all other parameters unchanged.
figure shows the impacts of the two parameters where the x axis represents the various used parameter values.
first of all hicond can always detect more bugs than the three comparison approaches under all these studied parameter values during the day testing period demonstrating the stable effectiveness of hicond.
from figure the default setting in hicond indeed performs better than the other settings indicating the good choice of parameter values in hicond.
also when the value is set to be the smallest for the two parameters hicond performs the worst since hicond cannot sufficiently explore the bug space in these cases.
200number of detected bug s a times of iterations b number of particles fig.
impact of parameters on hicond ix.
r ela ted work a. compiler testing in the area of compiler testing test program generation attracts the most attention all the time and our work also targets at this topic.
the most related work to ours is swarm testing which facilitates test program generation by randomizing test configuration of a test program generator.
different from it our work utilizes historical data to search a set of bug revealing and diverse test configurations for test program generation.
afterward alipour et al.
proposed directed swarm testing to generate test programs focusing on a given compiler code element making the targeted code element be tested more frequently which also uses historical data.
however our work has a different goal with it.
our work aims to explore the whole bug space while the latter focuses on the testing of the given code element.
besides test program generation from scratch some other test program generation is to mutate existing test programs.
for example emi is to generate an equivalent program variant with the original test program given a set of test inputs by mutating the original test program and then use the program pairs to test compilers.
emi has three instantiations including orion athena and hermes .
furthermore some existing work focuses on prioritizing test programs .
chen et al.
proposed a text vector based test prioritization approach for compilers.
their approach transforms each test program to a text vector by extracting a set of characteristics of programs and then ranks them based on their distances between vectors.
afterwards chen et al.
proposed a machine learning based test prioritization approach called let.
let first learns two models based on historical data including a capability model and a time model.
then let prioritizes test programs based on the two models.
our work is also based on historical data.
different from let our work targets at compiler test program generation rather than compiler test program prioritization .
more specifically our work aims to search a set of bug revealing and diverse test configurations for test program generation.
b. history based and search based software testing history information has been used to solve software testing problems .
for example kim and porter proposed to prioritize tests in resource constrained environments based on test execution history.
different from them hicond uses program features of historical passing and authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
failing test programs to infer ranges of configuration options where it is more likely to generate test programs triggering compiler bugs.
search based software testing refers to transform the problem of software testing to a search problem and then use a search algorithm to solve it .in the literature there are many search based test generation approaches .
for example fraser and arcuri proposed evosuite a search based unit test generation tool for java projects based on evolutionary search.
different from them our work targets attest program generation for compilers where we proposed hicond to search a set of bug revealing and diverse test configurations for better test program generation.
x. c onclusion in this paper we propose a novel test program generation approach via history guided configuration diversification called hicond.
hicond first utilizes historical data to infer the range of each configuration option of a test program generator where bug revealing test programs are more likely to be generated.
it then utilizes the pso algorithm to search a set of diverse test configurations within the inferred ranges.
finally hicond generates test programs using the identified test configurations for compiler testing.
in this way we can obtain test programs that are more likely to explore the whole bug space.
we conducted experiments to evaluate the effectiveness of hicond in testing gcc and ll vm.
the results show that hicond significantly outperforms the existing approaches.
furthermore hicond has been successfully applied to actual compiler testing in company a and detected bugs in production environment.