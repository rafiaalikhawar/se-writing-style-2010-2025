developer targeted analytics supporting software development decisions with runtime information j rgen cito software evolution architecture lab university of zurich switzerland cito ifi.uzh.ch .uzh.ch seal people cito.html abstract runtime information of deployed software has been used by business and operations units to make informed decisions under the term analytics .
however decisions made by software engineers in the course of evolving software have for the most part been based on personal belief and gutfeeling.
this could be attributed to software development being for the longest time viewed as an activity that is detached from the notion of operating software in a production environment.
in recent years this view has been challenged with the emergence of the devops movement which aim is to promote cross functional capabilities of development and operations activities within teams.
this shift in process and mindset requires analytics tools that speci cally target software developers.
in this research i investigate approaches to support developers in their decision making by incorporating runtime information in source code and provide live feedback in ides by predicting the impact of code changes.
ccs concepts software and its engineering !software performance general and reference !metrics keywords developer targeted analytics software analytics performance engineering .
problem statement the widespread availability of broadband internet has enabled many aspects of computing to move online as an asa service model.
many di erent types of software ranging from enterprise to end user applications are delivered as software as a service saas .
this modern type of software often comes with high velocity of releases with push of more frequent but smaller changes often deployed on cloudinfrastructure.
as a consequence in modern software development the boundaries between building software and operating it in production are blurring.
this has been further underlined by the larger devops movement which aims on achieving cross functional capabilities of development and operations in teams.
the movement is also slowly leading to a shift in mindset of development teams when it comes to operability of newly produced pieces of their systems.
decisions made during software development cannot be considered isolated from their implications in production environments.
this shift in mindset and process requires developers be able to anticipate runtime issues before they occur and leverage data driven decision making based on runtime information observed from software in production.
however production infrastructures speci cally in the cloud are complex distributed systems .
if an issue has occurred within a production environment we have to able to leverage information on the evolution of the whole stack and the ability to establish links from di erent aspects of runtime information back to code.
.
motivating example to provide a frame for further discussion let us imagine a team centric voip chat client similar to slack1or hipchat2 where users log in and interact with multiple teams over chat and voip.
this application is based on a microservice architecture where each service is deployed as a scalable unit in the cloud.
scenario.
one of the microservices of the application is the login that retrieves information from a 3rd party provider e.g.
pro le pictures from facebook .
in the development and test environment 3rd parties are mocked out to provide isolation in testing scenarios.
a new change requests asks to enable the login for all teams of a user at once instead of logging in for one team at a time .
the code change implementing this change request passed all tests and went live in the production environment.
there it lead to signi cant performance regressions that were reported by end users.
after careful inspection of operational logs in production and version control history it turned out that the change introduced a new blocking loop that incorporated the request to the 3rd party service.
as a single operation the request did not cause any performance degradations in the past.
however when the method needed to scale to multiple teams it lead to a severe performance degradation.
permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
copyrights for components of this work owned by others than acm must be honored.
abstracting with credit is permitted.
to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
request permissions from permissions acm.org.
ase september singapore singapore c acm.
... .
problem.
data combinatorics in production environments are so di erent to what pro lers and tests can simulate either locally or in staging environments.
especially in the cloud scalable infrastructure requires approaches to leverage information gathered at production runtime and provide feedback to software engineers during development.
.
proposed research the objective of my research is to enable data driven decision making during development of software for the cloud.
to achieve this objective the following research questions are examined rq1 how is software being developed for the cloud and what kind of tools and data are being leveraged for decisionmaking?
rq2 how can we support data driven decision making for software engineers during software development?
to answer these research questions we either conduct empirical studies or develop approaches as proof of concept implementations.
approaches are evaluated through case studies and controlled experiments of these implementations.
.
software development for the cloud this research started out by conducting a mixed method empirical study semi structured interviews and survey on how software developers build applications for the cloud .
the results of this study enabled us to understand how software developers make decisions when confronted with runtime problems.
runtime information delivered in the form of centralized and external dashboards are not actionable for software developers .
they are struggling to incorporate this information in their daily work ow.
when solving problems that have occurred at runtime they rather rely on beliefs and intuition than utilize metrics .
the problem statement brie y characterizes the shortcomings in existing cloud analytics approaches.
data collected on application services in production operational data is usually sent to monitoring and management services and surfaced in a way that helps to make operating decisions .
in this study we have observed that operational data is not made available in a manner that supports making software development decisions .
to counter this scenario and answer the remaining research questions i propose an approach called developer targeted analytics where runtime information is integrated in the software developer s daily work ow to support software development decisions.
.
developer targeted analytics a central theme in a software developer s daily work ow is reading and writing program code .
the aim of developer targeted analytics is to support developers in making data driven decisions in the process of writing code.
we achieve this by tightly integrating the collection and analysis of runtime information observed from production deployments with the environment developers utilize work on new versions of the applications ides .
while the approach is not limited to speci c types of runtime information the use cases presented in this thesis focus on supporting decisions to improve software performance.
.
.
feedback mapping prediction in a process called feedback mapping the static view of code artifacts depicted as a graph structure is combined with the dynamic view of runtime information .
more speci cally we map a series of operational data points to nodes of existing artifacts in the source code.
the resulting code view allows developers to examine their code artifacts annotated with data from real production traces e.g.
method calls with execution times or collections with size distribution .
given a feedback annotated graph we can derive the impact of code changes during software development.
a code change introduces a di erence between the originally annotated graph and the new graph.
feedback for unknown new nodes in is derived using the existing feedback of its child nodes as parameters for a statistical inference model.
in a last step all derived feedback from changes are propagated in the nodes of the graph following its dependency edges.
this kind of prediction allows us to warn developers about possible issues of their code changes prior to running the application in production.
figure illustrates a proof of concept implementation of this approach tool performancehat within the eclipse ide.
figure eclipse plugin performancehat as an implementation of developer targeted analytics .
.
uncertainty a major concern when providing predictions to aid decisionmaking is uncertainty .
in devising this approach we have think about di erent sources of variation.
speci cally we have to consider both model uncertainty and system uncertainty.
we investigated part of system uncertainty in depth in an empirical study on performance variability in cloud instances .
the results of this study need to be factored into the prediction model to properly address uncertainty in software performance prediction for the cloud.
.
validation strategy to validate the concept of developer targeted analytics we built a proof of concept implementation called performancehat3.
we already validated part of our approach through case studies with industrial partners .
we further plan to validate the end to end approach through a qualitative user study with professional software developers to determine whether it improves decision making capabilities in tasks concerning software performance.
further we need to evaluate how the mapping and propagation of feedback approach scales to larger code bases.
we 893plan to conduct a study with the code base of an industrial partner.
.
expected contribution the goal of this research is to enable data driven decision making based on runtime information during software development.
working on approaches and solutions by exploring the research questions i expect to make the following contributions .
a better understanding of how cloud software is being built and identi cation of shortcomings in cloud software development.
given the insights derived in this research new research directions can be properly motivated and guided.
.
initial evidence through an empirical study with software developers that they struggle with incorporating runtime information in their decision making process.
.
a conceptual framework of attaching runtime information to source code artifacts.
further a reusable framework that incorporates runtime information into the daily work ow of software developers to support decision making.
.
a model and understanding of system uncertainty in cloud infrastructures.
.
related work work related to this research can be broadly categorized in the following categories software analytics visualization of runtime behavior change impact analysis for performance and decision making uncertainty.
software analytics.
researchers have extensively investigated methods and approaches to mine software repositories for a variety of reasons and stakeholders under the term software analytics .
often these analytics approaches provide prediction models to support software managers to make decisions within their teams .
one of the focus points of software analytics is bug and defect prediction.
however a study by lewis et al.
found that after deploying bug prediction techniques there was no identi able change in developer behavior.
zhang et al.
also investigated the impact of software analytics approaches from the research community in practice.
in contrast to our work most of the work in software analytics mines static information e.g.
source code repositories issue trackers mailing lists to build prediction models.
we want to focus on analytics based on runtime information speci cally software performance in cloud systems.
visualization of runtime behavior.
work both from software engineering and systems research has investigated di erent ways to understand runtime behavior through visualization.
sandoval et al.
present an approach they call performance evolution blueprint to understand the impact of software evolution on performance.
meyer et al.
visualize the process runs of stored procedures in database systems.
senseo is an approach embedded in the ide that augments the static code viewperspective with dynamic metrics of objects in java.
bezemer et al.
investigated di erential ame graphs to understand software performance regressions.
cornelissen et al.
showed that trace visualization in the ide can signi cantly improve program comprehension.
explorviz provides live trace visualization in large software architectures.
similarly to our work in developer targeted analytics beck et al.
provide augmented code views with information retrieved from pro lers.
our work di ers rst in the use of data retrieved through instrumentation in production cloud systems.
further our approach goes beyond displaying information on existing traces by providing live prediction on performance of newly written code.
change impact analysis performance prediction.
change impact analysis supports the comprehension evaluation and implementation of changes in software .
most of the work that is related to change impact analysis and performance prediction operates on an architectural level and is not supposed to be triggered during software development.
recent work by luo et al.
uses a genetic algorithm to investigate a large input search space that might lead to performance regressions.
in previous work we applied changepoint analysis to detect distribution shifts in performance data .
our approach for change impact analysis is applied live during software development and leverages an analytical model consisting of the immediate software change and the existing runtime information to provide early feedback to software developers.
decision making uncertainty.
every decision is based on information that comes with its own set of assumptions and uncertainties.
several works in decision theory but also computing have argued that considering uncertainty of systems and models is a basis for decision making .
in areas such as performance modeling and engineering uncertainty and error modeling has been been examined .
firoz et al.
show how including uncertainty as standard deviations in performance models improves insight from data.
researchers have also considered interval parameters to depict model uncertainty .
other work considers di erent dimensions of model uncertainty .
.
progress and outlook the study for the rst research question has been already conducted and our results have been published and presented at esec fse .
part of second research question has also been investigated the conceptual framework and model for developer targeted analytics have been published and presented at splash onward!
.
cloud system uncertainty and variability have also been investigated and published in transactions on internet technology toit .
we will also improve our performance prediction model to incorporate better notions of uncertainty.
further we want to conduct a controlled user study to evaluate our approach.
this work is supposed to be submitted to a systems conference in .
.
acknowledgment this work is advised by prof. harald gall and dr. philipp leitner from the university of zurich.
the research leading to these results has received funding from the european community s seventh framework programme fp7 under grant agreement no.
cloudwave .
.