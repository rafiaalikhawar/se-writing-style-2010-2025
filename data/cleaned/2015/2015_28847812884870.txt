antminer mining more bugs by reducing noise interference bin liang1 pan bian1 yan zhang1 wenchang shi1 wei you1 yan cai3 key laboratory of data engineering and knowledge engineering renmin university of china moe beijing china school of information renmin university of china beijing china liangb bianpan annazhang wenchang youwei ruc.edu.cn state key laboratory of computer science institute of software chinese academy of sciences beijing china ycai.mail gmail.com abstract detecting bugs with code mining has proven to be an effective approach.
however the existing methods suffer from reporting serious false positives and false negatives.
in this paper we developed an approach called antminer to improve the precision of code mining by carefully preprocessing the source code.
specifically we employ the program slicing technique to decompose the original source repository into independent sub repositories taking critical operations automatically extracted from source code as slicing criteria.
in this way the statements irrelevant to a critical operation are excluded from the corr esponding sub repository.
besides various semantics equivalent representations are normalized into a canonical form .
eventually the mining process can be performed on a refined code database and false positives and false negatives can be significantly pruned.
we have implemented antminer and applied it to detect bugs in the linux kernel .
it reported violations that have been either confirmed as real bugs by the kernel development community or fi xed in new kernel versions.
among them cannot be dete cted by a widely used representative analysis tool coverity .
besides the result of a comparative analysis shows that our approach can effectively improve the precision of code mining and detect subtle bugs that have previously been missed .
ccs concept s software and its engineering automated static analysis .
keywords bug detection code mining program slicing .
introduction in recent years various code mining approaches have been proposed to automatically extract implicit programming rules from source code repositories .
in particular such approaches on bug detection have been proven to be very effective .
for example pr miner has detected many real bugs in large scale systems including linux kernels apache http server and postgresql database .
most of these bugs violate complex implicit programming rules which are hard to be detected by traditional approaches as they need well documented rul es .
currently some commercial bug detection systems have also employed the idea of programming rules extraction.
for example coverity one of the most widely used bug detection tools leverages the statistical approach to automatically extract implicit programming rules and detects related bugs in some of its checkers e.g.
the null returns checker .
generally detecting bugs with code mining involves three steps preprocessing the source code rep ository to generat e a database called code database in this paper suitable for mining in which each record is mapped from a program unit e.g.
a function definition .
applying data mining algorithms to extract frequent patterns in the code database as programming rules.
detecting any violations to the extracted programming rules often on the code database as potential bugs .
among three steps the first one is the key step.
it to a large extent determin es whether a set of precise programming rules could be mined in the second step and how many false positives and false negatives are reported in the third step.
like traditional bug detection approaches detecting bugs with code mining also su ffers from reporting false positives and false negatives and may produce worse result s than traditional ones .
although some works could be adapted to reduce these false positives and false negatives they mainly focus on reducing the imprecisions of the second and third steps.
however few works focus on the first step.
according to our empirical investigation see section for some examples a large number of false positives and false negatives are introduced in the first step due t o the following two reasons.
first in a program that involves a certain implicit programming rule there often exist statements that are irrelevant to the rule except those implementing it.
if such statements are not excluded in the first step they may confuse the data mining algorithms adopted in the second step.
as a result rules that contain irrelevant statements may be mined but such rules are usually useless in practical coding.
more seriously if the irrelevant statements have similar forms with those in the rule the detection algorithm in the third step may be misled.
therefore real violations to the rule may be missed see .
resulting in false negatives.
permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies a re not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
copyrights for components of this work owned by others than acm must be honored.
abstracting with credit is permitted.
t o copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
request permissions from permissions acm.org.
icse may austin tx usa acm.
isbn ... .
ieee acm 38th ieee international conference on software engineering second programmers may adopt different ways to implement a same logic.
if we do not transform them into a same form when generating the code database the mining and detecting algorithms may mistake them as different programming patterns.
therefore the supports and confidences of the mined rules may be improperly calculated.
some interested rules may even be ignored if their supports and confidences are much lower tha n that they are deemed to have.
previous works have noticed this problem.
but their solutions are insufficient and may also result in some other problems see section .
to ease our presentation we refer to the statements that are either irrele vant to interest ed programming rules or semantics equivalent but are implemented in different forms as noise .
in this paper we propose an approach called antminer to address the above issues .
antminer carefully preprocess es the source code to eliminate the two kinds of noise s in the code database as much as possible.
first it employs a divide and conquer code mining approach to reduce noise introduced by irrelevant statements.
specifically the whole program is decomposed i nto different subrepositor ies according to a set of critical operations misusing them tends to cause bugs .
as a result program statements irrelevant to the critical operations are excluded that is all remaining statements in each sub repository are h ighly relevant to certain rules.
on mining programming rules antminer only works on each sub repository rather than on the whole repository.
however how to effectively identify critical operations is not a trivial task.
in this paper we propose a method to automatically extract them from the source code see .
.
second when converting a sub repository to a code database antminer carefully normalize s program statements such that different implementation forms of the same logic are normalized.
current ly it focuses on the variants of basic elements of a program including variable names expressions and control structures.
hence most common semantics equivalent representation form s that might interfere with the mining algorithms are normalized into a same canonical representation form and the precision of code mining could be significantly improved accordingly .
we have implemented antminer as a prototype tool to evaluate its bug detection ability.
we applied it to the linux kernel v2.
.
and compared it with a widely used bug detection tool coverity .
although the linux kernel has been heavily analyzed previously for bug detections antminer is still able to detect a set of real bugs violations .
among these bugs of them were directly confirmed as unknown bugs by kernel developers see table and table and of them have been fixed in new kernel versions before we submitted these bugs to the bugzilla .
in addition to the above confirmed bugs there are also suspects waiting for confirmation by linux kennel developers.
as a compariso n there are out of the confirmed bugs cannot be detected by coverity whose checkers also adopt the implicit rules extraction technique to detect bugs in addition to this based on well defined bug detection rules .
besides it should be noted that among those bugs confirmed by kernel developers there are bugs having existed in linux kernel for more than years one was introduced in v2.
.
and the other was introduced in v2.
.
and other bugs have existed since linux kernel .
.
released in may .
we further conducted a comparative evaluation and the result shows that without o ur method about out of bugs were not detected and the imprecision of the mined rules increased from .
to .
.
the evaluation result shows that our approach can effectively improve the precision of code mining and detect subtle bugs that have previously been missed .
this paper makes the following main contributions.
a divide and conquer code mining method.
the program slicing technique is employed to decompose the source code repository into a series of independent sub repositories.
rule mining and violation detecting on a sub repository can survive from the noise items caused by irrelevant statements.
a simple but effective statement normalization method.
with this method the most common semantics equivalent representations that might in terfere with the mining algorithms can be transformed to a canonical representation form.
a bug detection prototype system.
it can be applied to real world large systems.
the evaluation result shows that the system c an effectively detect a number of subtl e bugs that have previously been missed .
.
motivating example s in this section we demonstrate the necessity on eliminat ing noise items from the code database by some program samples collected from the linux kernel .
.
.
.
noise introduced by irrelevant statements in linux kernel programs there is an implicit programming rule that the return value of the function snd pcm new should be checked to make sure that a new snd pcm instance is created successfully before passing it to the functi on snd pcm set ops .
figure shows a program that violate the above rule.
that is right after line there is no checking on the returned value .
using a mining algorithm e.g.
frequent itemset mining the frequent pattern err snd pcm new if err snd pcm set ops can be extracted from the kernel code .
the pattern are taken as a programming rule to detect related bug s as done in .
unfortunately the program in figure actually contains all elements of the rule.
as a result the program will be mistaken as a support rather tha n a violation to the rule.
this false negative is actually caused by the conditional statement at line linux .
.
sound pci lx6464es lx6464es.c static int devinit lx pcm crea te struct lx6464es chip ...... err snd pcm new chip card char card name pcm if err ... return err is neglected there !
pcm private data chip snd pcm set ops pcm ... ...... err snd pcm lib preallocate pages for all pcm ... snd dma pci data chip pci size size if err return err ...... return figure .
a violation to the implicit rule err snd pcm new if err snd pcm set ops lacking a necessary checking for the return value of the call to snd pcm new .
as the statement is irrelevant to both function snd pcm new at line and snd pcm set ops called at line .
methods based on order sensitive data mining techniques e.g.
frequent subsequence mining may detect such a bug.
however if the irrelevant statement s err f if err appear between line and which is quite possible in practice the methods would fail to detect the bug .
besides such order sensitive methods have higher time complexity than itemset mining methods on extracting programming rules.
to make them scalable to mine rules from large scale software e.g.
the linux kernel which has tens of millions lines of code a bigger minimum support threshold should be set.
however this would miss rules with relatively small supports.
the root cause of the false negative is that the statement at line irrelevant to the rule confuses the mining algorithm.
therefore w e can detect the bug by actively removing the irrelevant statements before mapping the program into a code database.
to achieve this goal we have to identify which statements we do care about and which we do not care about.
note that a bug often occurs because of incorrectly performing some critical operations such as calling a function e.g.
strcpy without satisfying its preconditions or returning an improper value under certain conditions.
from this observation we only care about statements that either directly perform a critical operation or impact the execution of a critical operation and the other statements are regarded as irrelevant ones and are removed.
given a critical operation the program slicing techniques can help achieve this go al.
on the example in figure assuming that the call to function snd pcm set ops is a critical operation act as a slicing criterion the conditional statement at line can be excluded from the corresponding slic e hence the detection algorithm is able to catch this violation.
.
noise introduced by relevant statements in some cases the interference can also be introduced by statements that are relevant to the critical operations .
in practice a statement may have no effect on the logic of a programming rule even when there is a control or data dependence relationship between it and the critical operation .
for example in linux kernel code there is another implicit programming rule that the return value of the func tion nla reserve should be checked against null before it is passed to the function nla data .
figure shows a violation to this rule where a necessary validation on the return value right after line is missing.
however the call to the critical operation nla data at line is directl y control dependent on the statement at line .
that is the statement at line is reserved even after program slicing .
this also confuses the mining algorithms in a way similar to the example in figure resulting in a false negative.
in essence this false negative can be reduced if the mining algorithm could distinguish the variable na used at line from the one in the frequent pattern na nla reserve if !
na nla data .
in a previous work variables are represented with their data types.
however to address the above problem more semantic information nee ds to be introduced when renaming variables.
in fact the variable na in the above patter n keeps the return value from nla reserve whereas the variable na used at line keeps the value of an array element .
if a variable is renamed with a new canonical name which can reflect where its value comes from see .
the confusion will be avoided to a large extent .
therefore the detection algorithm would not be interfered and can then detect the bug in figure .
.
noise introduced by inconsistence the validation to the sensitive data is usually implemented with conditional statements.
in general missing effective validations may result in programming bugs.
for example the program shown in figure a illustrate s an effective validation to the actual parameter of function tty hangup .
however in the prog ram shown in figure b an incorrect condition al expression i.e.
c clocal tty rather than !c clocal tty is used to enforce the validation.
t his will result in a bug.
on the other hand programmers can use different or even opposite condition al expressions to enforce the same validation.
for example there are two validations for the return value of function dev alloc skb shown in figure a and b respectively.
although the two validations employ completely opposite condition al expressions considering the contexts both of t hem effectively guarantee that the return value is not null before passing to skb reserve .
for these programs if the mining algorithm is directly applied to them we may miss the bug in figure b or receive a false alarm on one of the two programs in figure .
a previous work also noticed this problem and proposed a method to simply make the similar expressions identical e.g.
replacing !
with in the control points without consideri ng the semantics of related control structures.
however this method is not suitable for processing the above samples .
a better solution is to normaliz e the control structure to a canonical form ensuring that the predicate which must be satisfied when executing a critical operation is explicitly specified in its linux .
.
net bluetooth rfcomm tty.c if dev tty !c clocal dev tty tty hangup dev tty a e ffective validation linux .
.
drivers tty moxa.c tty tty port tty get p port if tty c clocal tty !dcd tty hangup tty b in effective validation figure .
two validation samples to the actual parameter of function tty hangup linux .
.
kernel tasksta ts.c static int cgroupstats user cmd ... struct genl info info ...... struct nlattr na ...... na info attrs if !na return einval ...... rc prepare reply info cgroupstats cmd new rep skb size if rc goto err na nla reserve rep skb cgroupstats type cgroup stats sizeof struct cgroupstats if !na ... return emsgsize is neglected there!
stats nla data na memset stats sizeof stats ...... figure .
a violation to the rule na nla reserve if !
na nla data lacking a necessary checking for the return value of the call to nla reserve .
condition al expressio n see .
.
for example for the program shown in figure b the condition al expression at line can be standardized to skb dev alloc skb ... to explicitly specify that the return value has been checked against null before passing it to the function skb reserve .
on the other hand the control structures in figure remain their original forms.
as a result the bug in figure b can be detected and no false positives are produced for the programs in figure .
.
antminer approac h .
overview compared with most traditional code mining approaches antminer does not directly handle the whole source code of the target system.
instead it decomposes the source repository into a set of independent sub repositories on preprocessing source code.
the code mining is then independently performed on these subrepositories one by one.
figure shows an overview of antminer .
first t he source code is parsed into parse trees and a program dependence graph pdg is generated for each function definition .
second it extracts critical operations from the source code itself without human involvement .
third according to the critical operation s the program slicing technique is employed to generate a series of subrepositor ies.
a sub repositor y consists of the program slices associated wi th a specific type of critical operation s. fourth the program slices are normalized and then every sub repositor y is converted to an itemset database .
fifth a frequent sub itemset mining algorithm is applied to the databases one by one to extract frequent patterns and generate programming rules.
final ly violations to these rules are detected and reported as potential bugs.
.
parsing source code antminer uses a modifie d gcc compiler frontend to parse the source code.
the source code is parsed and represe nted in gimple which is a language independent tree based representation.
it should be noted that complex expressions are split into a three address code in gimple .
the rest of this subsection reviews the preliminary knowledge mainly about the pdg .
readers who are familiar with it may skip the rest of this subsection.
a pdg is computed for each function definition by using a n improved algorithm proposed in .
in a pdg a node represents a gimple statement and an edge represents the dependency information between two nodes.
a pdg consists of a contro l dependence subgraph cds and a data dependence subgraph dds the cds describes the control dependencies among statements.
in cds if a statement s2 is control dependent on a condition statement s1 there is a control dependence edge from s1 to s2 labeled with either t or f indicating that s2 is execute d on the true or false branch of s1 respectively.
they are denoted as s1 s2 t or s1 s2 f respectively .
the dds describes the data dependencies among statements.
a statement s2 is data dependent on a statement s1 if there is a variable x defined in s1 used at s2 and an executable path from s1 to s2 along which there is no intervening definitions of x. in the dds there is a data dependence edge from s1 to s2 labeled with x to indicate the dependence relationship denoted as s1 s2 x .
in our implementation a variable is regarded to be defined at a statement if it is explicitly assigned to a value or it is passed to a function by reference.
for example in figure both variables err and pcm are defined at the statement at line .
variable pcm is used at line .
thus the data dependence edge pcm is added in the dds.
.
extracting critical operations bugs or vulnerabilities often stem from incorrectly performing some critical operations.
currently without loss of generality antminer mainly concerns two types of critical operations.
bug prone function calls .
a function can be regarded as bug prone if an inappropriate invocation to it tends to cause a program bug.
in practice the call to a bug prone function often acts as the key element of a programming rule.
i n fact in the common weakness enumeration cwe a list of software weaknesses the sink s of many weaknesses are calls to some secur ity sensitive function s. for example the call to function strcpy is a bug prone operation .
note that many bug prone functions are not well known like strcpy .
in many cases they may even be undocumented.
it is unreasonable to take all function calls as critical operations because some functions may hardly cause a bu g. for example the subrepositoryparsing slicing mining rules detecting violations violations pdgs parse trees programming rulescritical operations ...source repository subrepositorysubrepository itemset databaseitemset databaseitemset databasenormalizing hashing ... figure .
an overview of antminer .
linux .
.
drivers isdn i4l isdn v110.c if skb dev alloc skb v framelen v skbres skb reserve skb v skbres memcpy skb put skb v framelen ... a e ffective validation linux v2.
.
drivers media dvb dvb core dvb net.c if !
skb dev alloc skb pkt len snap do something return skb reserve skb longword align l3 header b another e ffective validation with different condition expression figure .
two effective validations for the return value of function skb reserve .
call to function isdigit a function in c language to check whether a charact er is a decimal digit should not be treated as a bug prone operation.
one way to collect bug prone functions is to identify them by manually analyzing the system documents or even the source code.
however it is very difficult and tedious if not impossib le to manually identify the undocumented application specific bug prone functions from a larg e scale system e.g.
the linux kernel .
to address this issue we design a heuristic method to automatically extract potential bug prone operations from source c ode.
in practice a bug prone function call usually produces an error when one or more of its parameters hold illegal values.
in a practical system to make sure that the system works correctly these sensitive parameters are often validated before passing them to the bug prone function.
in programming a valid ation to sensitive data is generally implemented as a conditional comparison.
to this end our approach to identify ing bug prone functions is based on the intuition before a bug prone function is called one or more of its parameters should be directly or indirectly checked by a conditional statement and the function should not be executed if the check fails.
specifically we perform a dependence flow analysis on the pdgs see .
to identif y potential bug prone functions .
first a set of validated variables vvs is computed for each conditional statement.
a vvs contains all variables that are directly or indirectly checked by a certain conditional statement.
to compute vvs the dds of the p dg is backward traversed starting from the conditional statement and labels i.e.
variables of edges visited during the traversal are added into the vvs.
second every function call is examined to see whether it is control dependent on a conditional statement by backward traversing the cds of the pdg .
if there exists such a conditional statement we further examine whether there are parameter s protected by the conditional statements.
a variable v is protected by a conditional statement if either it belongs to the vvs of the conditional statement or there is another variable v used in the definition statement of v and v is protected by the conditional statement.
if there exists such a parameter p the function is identified as a bug prone function candid ate and a protected counter for p each parameter with a protected counter is increased by one.
finally for every candidate a simple statistical method is applied to determine whether it is bug prone.
assuming that the function f is called for t times and the protected counter of one of its parameter p is t. if the ratio t t is larger than a predefined threshold e.g.
in this paper function f is then considered as a bug prone function on p. for example in figure a the vvs of the conditional statement at line is skb v framelen v skbres v .
the function call to skb reserve at line is control dependent on the conditional statement at line and its two actual parameters skb and v skbres belong to the vvs of the conditional statement .
therefore function skb reserve is taken as a bug prone function candidate and the protected counter s of its two parameter s are increased by one respectively .
after scanning the whole kernel code we find that skb reserve is called times in total among which times its first parameter is checked by conditional statements and the corresponding t t is about .
.
consequently the function skb reserve is identified as a bug prone function with respect to its first parameter .
based on the above method antminer automatically collect s potential bug prone functions without requiring any prior knowledge on the target system .
in our empirical study it find s thousands of bug prone functions from the linux kernel in about minutes which saves a great deal of human effort s. function returns .
function return statements are very common in programming but very subtle bugs ma y be caused if they return improper values.
when the return value cannot correctly reflect the execution result of a function on a certain path its callers is no way to know what actually happens in the callee.
for example in linux kernel programmers ma y incorrectly set the error code to zero rather than enomem when a function fails to allocate a requested memory.
the callers may believe an allocated memory space is ready for subsequent operations.
this may cause memory access errors and even crash the system.
in practice how to correctly set the return values is often undocumented.
as a result it is very difficult to detect improper return bugs with traditional tools.
the return value may be improperly set at every return point of a program.
hence al l return statements are directly selected as potential critical operations.
.
slicing source code the o riginal definition of program slicing was proposed by weiser .
by introducing the notion of pdg ottenstein et al.
converted the slicing problem into a reachability problem in a dependence graph representation of the program .
based on their study several algorithms are proposed for effective slices computing .
based on these algorithm s a program slice consist s of all statements which may affect the values at some point s of interest i.e.
slicing criter ion or determine whether it should be executed.
identifying slicing criteria .
to compute program slices for a critical operation the corresponding slicing cri teria should be identified firstly.
for a bug prone function nodes that call this function in the pdg can be directly taken as slicing criteria.
for example in figure b the function skb reserve is bug prone on its first parameter and is called at line .
therefore skb is used as a slicing criterion where skb is the interested parameter at line .
for the return statements i.e.
the second type of our critical operations they are not directly taken as the slicing criteria.
it is because a return statement is usually a merging point of multiple execution paths of a function.
and the retu rn value may also represent multiple execution results of the function.
in practice different execution results often represent different runtime logics.
to reduce the noise introduced by such runtime logics that are irrelevant to a certain return value a s much as possible the program points where the return values are actually determined are taken as the slicing criteria.
however the slicing result may not be what we desire when the return value is implicitly defined.
for example in figure a variable err keeps the return value and is initialized with zero at err x malloc if !x err enomem else do something return err err x malloc if !x err enomem else err err do something return err a b figure .
an example of inserting dummy statements .
line .
when the call to malloc at line fails checked at line err is set to enomem at line .
otherwise the value of err remains zero.
the logic of this program is enomem should be returned when the call to malloc fails otherwise zero should be returned .
when directly taking statements that explicitly set the value of err i.e.
line and line a s the slicing criteria the slicing result is no way to capture the logic zero should be returned when the call to malloc succeeds .
to address the above issue we insert dummy statements that reset return values into the original program.
for every con ditional statement if the return value e.g.
kept in variable err is only explicitly defined on one of its two branches a dummy statement i.e.
err err will be added to the beginning of the other branch.
then on the pdg of the modified program a backward dataflow analysis can be performed to identify desirable slicing criteria.
a statement may be a dummy one is regarded as a slicing criterion if there exists a data dependence edge from it to a return statement.
for example in figure a the dummy statement err err is inserted into the else branch of the conditional statement if !x at line because the return value is only explicitly defined on the other branch.
the modified program is shown in figure b and in the pdg of it there exists two data dependence edges to the return statement at line one from the statement at line and the other from the statement at line .
therefore the statements at line and line are identified as slicing criteria.
slicing for every criterion .
for each slicing criterion of return statements the pdg is traversed backward from it and the encountered nodes are marked.
all the marked nodes make up the program slice of the slicing criterion.
the above slicing algorithm is suitable for slicing criteria of return statements.
however when a slicing criterion is a call to a bugprone function the traversing strategy should be slightly adapted .
otherwise some statements causing noise may not be thoroughly excluded from the slice .
for example in figure taking x bug prone function sensitive op is called at line with x as a slicing criterion the conditional statement at line i.e.
if len max len remains in the obtained slice.
this is because the function call is control dependent on it.
however this conditional statement does check the input to the call to sensitive op y at line rather than that to sensitive op .
if the statement remains in the slice it may be incorrectly taken as a check ing for sensitive op x by the mining algorithm .
in essence this issue is caused by the fact that t he semantic relationship between two statements may still be weak even if there is a control dependence relationship between them.
to address this issue we design a more aggressive s licing algorithm for slicing criteria that call bug prone functions .
our algorithm also backward travers es the pdg paths starting from the statement invoking the bug prone function e.g.
sensitive op and marks the encountered statements to compute the program slice.
the difference is that a conditional statement is not marked if it is not homologous to the statement of the slicing criterion.
two statements s1 and s2 are homologous if either s1 and s2 are data dependent on the same statement s3 or s1 or s2 is control dependent on statement s3 and s2 or s1 and s3 are homo logous.
in this way the conditional statement that has only control dependence relationship with the slicing criterion is not taken as a potential validation to the function and hence is not added into the slice.
for example in figure the co nditional statement at line i.e.
if len max len is homologous to the statement at line but not the statement at line .
a s a result statement is marked for the slicing criterion y but is not marked for x .
constructing sub repositories .
the program slices for a bug prone function make up an independent sub repository for it.
for return statements program sl ices with the same return type are clustered into a sub repository.
.
normalizing and hashing statements every sub repository is converted to an itemset database suitable for the adopted data mining algorithm .
every statement is converted to a string and h ashed to a number using an existing hash function hashpjw .
the hash numbers of the statements in a program slice will constitute an itemset a bag of numbers .
before that statements are normalized by the following three methods renaming variable s. in practice names of variables in similar contexts may vary greatly.
to reduce the differences in naming variables in every statement are given new canonical names.
specifically for each variable that either accepts a retu rn value of a function or is taken as a reference parameter of a function is renamed as the function name plus a suffix .
the string ret is used as a suffix for the former case and an integer i is used for the latter case where the integer i indicates th at the variable is taken as the i th parameter of the function.
in other cases each variable is renamed as its data type.
for example in figure in the statement at line i.e.
if a b variable a keeps the return value of foo called at line and variable b is a reference parameter of foo .
thus variable a is renamed as foo ret while variable b is renamed as foo b is the first parameter of foo .
because the value of variable c in d c a is not assigned by a function it is renamed as its data type i.e.
int .
rewriting expressions .
expressions in different forms may represent the same semantics.
for example a b is equivalent to b a in semantics.
in theory it is impossible to recognize and normalize all kinds of semantics equivalent representations .
in this paper considering the significance of conditional statements and assignment statements for identifying programming rules we mainly concern with the normalization of them .
thanks to the gimple representation this work can be focused on how to normalize binary expressions.
for a binary expression v1 op v2 if the operator op has a commutative property i.e.
!
and the data type name of operand v1 is lexicographically after that of v2 the expression is trans1 c a foo b if a b return d c a bugprone op d figure .
an examp le for illustrating statements normalizing x get input y get input len get length x len get length y if len max len return sensitive op x sensitive op y figure .
a noise example that may remain in the slice.
formed into v2 op v1 .
for example for a n expression int char because int is lexicographically after char the resulting expression is char int .
if the operator op is a non commutati ve relational operator i.e.
and and the data type name of operand v1 is lexicographically after that of v2 the positions of the two operands are exchange d and the operator op is synchronously changed to op i.e.
the complement operation of op to preserv e the semantic .
for example for a given expression int char the resulting expression is char int .
rearranging control structures .
the same program logic may be implemented in different control structures.
for example programs in figure a and figure b are different in form but they both follow the constraint that the first parameter of skb reserve should not be null .
to reduce the differences in form the control structures are rearranged as follows if a critical operation is called only when a predicate p evaluates to false it is negated to p e.g.
the negation of a b is a b accordingly the two branche s of the control structure are exchanged such that the critical operation is called only when predicate p evaluates to true.
in this way the validation modes about critical operations are unified without alerting the original validation logic.
for exampl e in figure b the critical operation skb reserve is executed only when the predicate at line evaluates to false .
the related control structure is rearranged as shown in figure .
by so all conditional predicates which determine whether the bug prone operation is executed or not will be normalized to a standard form as far as possibl e making the mining algorithm more likely to be able to extract potential frequent programming patterns.
.
mining rules and detecting violations antminer adopts the data mining a lgorithm fpclose to discover closed frequent sub itemsets from the itemset database.
for a given sub itemset the number of itemsets that contain all its items is called the support of it.
a sub itemset is considered to be frequent if its support is bigger than or equal to a specified threshold min support .
a frequent sub itemset a is closed if there is no frequent sub itemset b where b is a proper subset of a and support a support b where the function support p computes the support of p. we then mine association rules as programming rules from the extracted closed frequent sub itemsets.
an association rule has the form a b where a and b are closed frequent sub itemsets and support b support a i.e.
confidence of the rule is larger th an or equal to a given threshold min confidence .
the association rule a b indicates if a n itemset in the database contains all statements in a it should also contain all statements in b. and a violation to the rule is an itemset that contains all the items in a but not all the items in b. detecting violations is straightforward .
a trivial method to detect the violations is to inspect all itemsets in the database and examine which is a superset of a but not of b. however given a database with a large number of itemsets this method might be timeconsuming.
to speed up violation detecting we slightly modified fpclose such that when it discovers a closed frequent sub itemset x the itemsets that support x are also recorded denoted as supporter x .
by so any violations to an association rule a b can be easily computed via supporter a supporter b .
before reporting any violations to programmers they are ranked by an empirical method .
in our experience the violation that miss conditional statements is more likely to be a bug than those that miss function call statements.
besides the fewer statements a violation misses the more likely it is a bug.
for that all violations are firstly categorized into three categories missing conditional statements missing function call statements and the others.
among these three categories v iolations in the first category are ranked with a h ighest priority followed by violations from the second categor y and violations from the third category have a lowest priority.
within each category a violation that misses fewer statements is ranked with a higher priority and if any two violations miss the same number of statements they are ranked by the confidences of their violated rules i.e.
violations with higher confidences are ranked with higher priority .
.
evaluation .
experiment setup we implemented antminer based on gcc compiler v4.
.
and evaluated it on the linux kernel .
.
.
the kernel includes about c files and functions.
the linux kernel has been scanned by dozens of bug detection tools .
the main reason for choosing the linux kernel as the evaluation target is that we want to demonstrate the effectiveness of our approach by revealing some new bugs that are difficult to detect previously on real world large scale systems .
in our experiment antminer runs on a machine with a core i5 2520m .5ghz intel processor and 4gb memory.
t hree parameters need to be specified min support and min confidence .
in our evaluation we empirically determine reasonable parameters by performing a sampling analysis to the results of several experiments with different parameters settings .
specifically w e set to min support to and min confidence to respectively .
.
experiments in the evaluation we firstly performed two independent experiments to automatically extract programming rules and detect related bugs for the two types of critical operations i.e.
bug prone function calls and function returns .
the results of the two experiments are shown in .
.
and .
.
respectively.
as a compa rison we also applied coverit y to detect bugs in the linux kernel .
.
to determine whether antminer can effectively discover the bugs missed by coverity .
for highlighting the effectiveness of antminer on reducing noise introduced by irrelevant statements and inconsistent implementations we further evaluated antminer by disabling its program slicing and normalizing to perform a comparative analysis.
the result is illustrated in .
.
.
table .
classification of violations detected by antminer of total violations already fixed .
real bugs confirmed as unknown bugs.
real bugs regarded as false positives.
false positives waiting for confirmation.
unknown if skb dev alloc skb pkt len snap skb reserve skb longword align l3 header else do something return figure .
rearranged program of the one in figure b .
.
.
detecting misusa ges of bug prone function s this experiment ran about minutes .
in total bug prone functions were automatically extracted from the source code.
for all these bug prone functions programming rules are generated.
violations to these rules were detected.
similar to all other static analysis tools violations detected by antminer also need to be identified manually .
in this study f or each bug prone function the top ranke d rules at most and the violations to th ese rules were manually audited .
it spent one of us about hours to audit the results .
the cost of manual work is acceptable on large scale systems like the linux kernel.
eventually we found violations that were most likely to be real bugs.
table summarizes these violations.
to verify these violations we firstl y checked the kernel archive and found that of them have already been fixed in the new kernel versions e.g.
v3.
.
this means that these violations shown in table are real bugs.
we then reported the other violations to linux kernel bugzilla the kernel development community .
and so far of them have been confirmed as previous ly unknown bugs i.e.
real bugs as shown in table .
among the rest violations are regarded as false positives by kernel developers and the other are still waiting for confirmation.
we fu rther surveyed when the confirmed bugs were introduced in the linux kernel.
we found of them were introduced before kernel .
.
released in may .
to our surprise the bug was introduced in kernel .
.
released in april it has b een latent for years until it is detected by antminer .
this bug has been fixed now after we reported it.
it should be noted that antminer can successfully detect some deeply hidden bugs with the help of program slicing and statement normalization such a s the three bugs presented in .
.
and .
respectively bugzilla id and .
we also applied coverity on the same kernel source code.
coverity can only reported of above real bugs i.e.
found by antminer .
in other words coverity neglected real bugs.
among the bugs hit by coverity of them were detected by the null returns checker and the rest one was detected by the checked return checker.
both of the two checkers can automatically infer the implicit program rules for the unmodeled function e.g.
alloc skb to detect related bugs.
for example the null returns checker can infer the rule alloc skb may return null and its return should be checked against null before dereferencing by s canning the code and computing how frequently the function return is checked against null .
according to the rule coverity can detect a real bug bugzillaid in function st int recv .
because coverity directly infers the implicit programming rules from the original source code its precision is heavily interfere d by the noise statements as discussed in section .
as a result some implicit programming rules and related bugs may be neglected.
for example it can t discover all the three subtle bugs presented in section which should be covered by its corresponding checkers e.g.
null returns checker .
.
.
detecting improper return values as mentioned in .
program slices with the same return type are clustered into a sub repository .
in kernel when an unexpected event occurs in a function an error code should be returned.
in the kernel development a number of subtle bugs caused by incorrect error code assigning .
in practice an error code is often represented by an intege r. therefore we are especially interested in the sub repository consists of program slices involving error code returns .
the experiment ran about minutes and programming rules were mined.
considering the sub repository about error codes consists of much more slices than those sub repositories about bug prone functions we manual ly inspected the top rules and their violations.
eventually we found violations were most likely to be real bugs.
table summarizes these v iolations.
by checking the kernel archive we found of them have been fixed in the new kernel versions e.g.
v3.
.
this means table .
classification of violations detected by antminer of total violations already fixed .
real bugs confirmed as unknown bugs.
real bugs waiting for confirmation.
unknown table .
this table describes the profile of the found bugs that have been fixed in the new versions.
the first column shows the function that contains the bug the second shows the bug prone function and the last labels whether the bug is detected by coverity .
function bug prone function coverity btrfs real readdir btrfs next leaf btrfs insert dir item btrfs release path picolcd init framebuffer framebuffer release pstore mkfile d add nl80211 remain on channe l genlmsg end nl80211 tx mgmt genlmsg end nl80211 get key genlmsg end l2tp nl session send genlmsg end l2tp nl tunnel send genlmsg end l2tp nl cmd noop genlmsg end efs iget unlock new inode bfs iget unlock new inode table .
this table describes the profile of the confirmed bugs.
the first column lists the bug s id in the linux kernel bugzilla the second shows name of the function that contains the bug the third shows the bug prone function that the bug violates a rule about and the last labels whether the bug is detected by coverity .
bugzilla id function bug prone function coverity st int recv skb reserve ldisc open register netdevice sfb dump nla nest end tmiofb probe ioremap setup isurf pnp port start lx pcm create snd pcm set ops poseidon audio init snd pcm set ops pcf50633 probe platform device add dcbnl ieee set nla parse nested cgroupstats user cmd nla data ocfs2 create refcount tree ocfs2 set new buffer upt odate ocfs2 create xattr block ocfs2 set new buffer upt odate lkdtm debugfs read free pages ipw packet received skb skb reserve wl1271 debugfs update st ats wl1271 ps elp sleep omninet read bulk callba ck tty flip buffer push moxa new dcdstate tty hangup btree write block logfs put write page that these violations are real bugs.
we submitted the rest suspected bugs to the kernel development community and so far of them have been confirmed to be real bugs and will be fixed in later versions.
these bugs are shown in table .
the other su spects are still waiting for confirmation however none has been confirmed as a false positive .
for example in figure when the call to registe r netdev at line fails the returned error code should be further propagated upward to the callers of function mkiss open .
however the programmer forgot to set the value of err when register netdev fails and zero is returned.
this misleads the callers into believing mkiss open runs normally even some unexpected events have occurred.
antminer successfully extracted the rule that when a call to register netdev fails its return value rather than zero should be propagated upward .
according to the rule antminer successfully detected this bug that has been confirmed by kernel developers bugzillaid .
again compared to the results of coverity none of these real bugs were reported by coverity .
in fact inferring this kind of rules is not supported by coverity .
note that of the confirmed bugs were introduced before kernel .
.
.
in particular the bug was introduced in the kernel .
.
released in october it has been latent for almost years until it is detected it by antminer .
.
.
comparative analysis to highlight the effect iveness of antminer in reducing false negatives and false positives we conducted another experiment to directly mine rules for bug prone functions from the original source repository.
we refer to this experiment as antminer .
as suggested by its name antminer is based on antminer but without program slicing and statement normalizing.
this experiment ran about minutes and programming rules were mined.
to evaluate antminer we manually inspected the reported violations and found that of the real bugs were not re ported.
that is bugs were missed .
for example the bug id shown in figure is detected by antminer but missed by antminer where the reason was explained in .
.
note that theoretically antminer may fail to report some bugs detected by antminer however we have not found such an instance in the experiment.
that is all confirmed real bugs detected by antminer were detected by antminer .
to evaluate the ability of antminer on reducing false positives we collected and further analyzed the mined rules for the bugprone functions listed in table and table respectively .
as shown in table antminer mined rules related to these bug prone functions .
for each function its top ranked rules at most were manually verified to see whether they are correct.
a rule is correct if it should be followed and if violated bugs may occur.
for example antminer mined rules related to the bug prone function nla nest end .
we inspected the top of these rules manually and found only one of them was a correct rule.
in total rules were inspected and only of them were confirmed to be correct ones .
the false positive rate is up to .
.
in most cases we found that elements of incorrect rules are irrelevant or weakly relevant to each othe r. violations to such rules are always false positives.
similar analysis was performed on the result of the experiment in .
.
.
from table it can be seen that the false positives were greatly reduced by applying our method i.e.
.
.
at the same time more correct rules were extracted by antminer i.e.
vs .
by antminer .
.
summary from the first two experiments antminer successfully finds bugs from the kernel .
.
.
it is well demonstrated that antminer can detect a number of subtle bugs that are difficult to be found by other detection tools e.g.
coverity .
the third experiment further illustrates that introducing program slicing and statement normalizing is significant for reducing both false negatives and false positives.
.
discussion while antminer is effective in revealing bugs that may be missed previously there are still some limitations that we need to consider in our future works.
critical operations .
currently antminer mainly concerns two types of critical operation s. however other operations may also be critical to detecting bug such as reading or overwriting some fields of a specific type structure.
how to cover such operations is an important problem that we need to address in the future.
intuitively a direct solution is to transform such operations into a special type of function call.
to this end it may be helpful to introtable .
statistics of extracted rules related to the bug prone functions listed in table and .
approach related rules analyzed rules correct rules false positive rate antminer .
antminer .
linux .
.
drivers net hamradio mkiss.c static int mkiss open struct tty struct tty ...... if err ax open ax dev goto out free netdev if register netdev dev forgot to set err to the return of register netdev !
goto out free buffers ...... return out free buffers kfree ax rbuff kfree ax xbuff out free netdev free netdev dev out return err figure .
an examp le that returns improper values.
table .
this table describes the profile of the confirmed bugs that return improper values .
the first column lists the bug s id in the linux kernel bugzilla the second shows name of the function that contains the bug the last labels whether the bug is detected by coverity .
bugzilla id function coverity atl2 probe mptfc probe mkiss open r592 probe mantis dma init myri10ge probe duce a little prior knowledg e to identify which types of operations are critical ones as done in .
data mining algor ithms .
in this study we adopt the frequent itemset mining algorithm to extract programming rules considering its scalability .
for some types of programming patterns others mining a lgorithm s may be more suitable.
programming logics can be repre sented in forms of sequences or even graphs .
note that our approach is compatible with other mining a lgorithm s. applying them on a refined code database will produce better results.
this will be one of our future works.
normalization .
in theory even for a simple expression completely recogniz ing all semantics equivalent forms of it is not a trivial task.
in this study antminer can handle some most common semantics equivalent representations.
in fact more bugs can be found if more se mantics equivalent representations are covered.
in the future we plan to employ deeper semantics analysis to normalize complicated semantics equivalent representations that cannot be handled in the current version of antminer .
concurrency bugs .
detecting concurrency bugs in multithreaded programs is both significant and challenging .
there are two main obstacles to finding concurrency bugs statically .
first it is difficult to statically determine concurrent code s. second prior knowledge about locks are not always available .
we will try to address above issues from the perspective of code mining.
.
related work engler et al.
proposed a method to detect programming bugs by employing statistical analysis to infer temporal rules from rule templates such as a must be paired with b .
they have developed six checkers and detected hundreds of bugs in real systems.
the study proposes a promising direction to detect bugs without specifying concrete rules .
kremenek et al.
propo sed a more general method that uses factor graphs to infer specification from programs by incorporating disparate sources of information.
while these two approaches are inspiring the types of inferred rules are restricted to predetermined templates.
this require s users to specify some specific knowledge about the target.
data mining technique s are introduced to extract more general rules from real large systems .
all mining based methods along with tho se statis ticalbased methods accept the reasonable assumption in a practical system the coding is correct in most cases and a small number of anomalies are likely to be bugs.
these methods firstly infer frequently appeared patterns in the source code s uch patterns specify the implicit programming rules that should be followed in coding.
then programs that violate these rules are detected and regarded as potential bugs.
code mining methods can be categorized into four groups.
frequent sub itemset based methods represent a rule as an itemset indicating that when a program executes some operations e.g.
call one or more functions it should simultaneously execute the other operations in the same itemset e.g.
verify the function parameters .
frequent sub sequence based methods represent a rule as a sequence of events indicating that these events should be executed in order.
frequent sub graph based method s represent a rul e as a graph indicating that the control flow and data flow should also be correctly implemented.
and template based methods adapt the mined rules to templates provided by traditional static analysis tools e.g.
klocwork an d then utilize these tools to detect bugs.
among various mining methods the frequent itemset mining is most practical due to its scalability.
currently antminer mines frequent sub itemset as programming rules but it can be easily extended to mine rules represent ed in sequences or graphs.
in theory mining based methods can detect many types of bugs.
however in practical two types of bugs are often detected one or more necessary function calls are missed and some prereq uisite conditions are neglected .
antminer can detect both of them.
in the studies of gunawi et al.
and rubio gonz lez et al.
they found that error codes are often incorrectly propagated in file systems and such bugs are very hard to detect both statically and dynamically.
antminer provides an effective way to detect this kind of bugs by mining the function return patterns.
if some domain knowledge can be introduced into mining rules better results may be produce d. some approaches have been specially designed to infer rules for critical apis or security sensitive functions and have gained great results.
antminer also mines rules for specific operations .
however it does not require users to s pecify the interested operations which are automatically extracted from the source code.
it is noticed that code mining can be applied to not only the source code but also other forms of software engineering data.
rules can be mined from revision historie s execution paths program comments or even documentations written in natural language .
the natural language processing nlp technique is employed when extract ing rules from comments and documentations.
nlp is also helpful for methods mining rules from source code .
we will leverage nlp to discover the semantic information behind the names of program elements e.g.
variables functions .
the information can be used to further improve the statements normalization.
program slicing was originally proposed by weiser and chen and cheung extended it to make the slicing process effective in some circumstances known as dynamic program slicing.
program sl icing is mainly used to help debugging or simplifying testing .
agrawal et al.
applied program slicing to locate known faults while we employ program slicing to help mining unknown bug in this study .
.
conclusion many efforts have been paid to use various code mining methods to extract programming rules and detect bugs.
however less attention has been given to exclude the noise items from the code database.
this paper presents a novel approach antminer to improve the precision of code mining.
i t reduces noises in code database by excluding statements that are irrelevant to certain critical operations and transforming statements with the same logic into a same canonical representation form.
we have implemented antminer and applied it to s ome large scale systems.
the evaluation results show that antminer effectively improved the precision of code mining and detected a number of subtle bugs that have been missed previously.
.