parsimony an ide for example guided synthesis of lexers and parsers alan leung sorin lerner university of california san diego usa aleung lerner cs.ucsd.edu abstract we present parsimony a programming by example development environment for synthesizing lexers and parsers by example.
parsimony provides a graphical interface in which the user presents examples simply by selecting and labeling sample text in a text editor.
an underlying synthesis engine then constructs syntactic rules to solve the system of constraints induced by the supplied examples.
parsimony is more expressive and usable than prior programming by example systems for parsers in several ways parsimony can synthesize lexer rules in addition to productions solve for much larger constraint systems over multiple examples rather than handling examples one at a time and infer much more complex sets of productions such as entire algebraic expression grammars by detecting instances of well known grammar design patterns.
the results of a controlled user study across participants show that users are able to perform lexing and parsing tasks faster and with fewer mistakes when using parsimony as compared to a traditional parsing workflow.
index terms lexer parser program synthesis programmingby example.
i. i ntroduction despite over four decades of research on parsing building parsers remains a difficult task.
widely used parser generators such as bison demand detailed understanding of their underlying algorithms for effective use.
more modern tools such as antlr and packrat parsers are arguably more user friendly but even still have their own subtle gotchas such as restrictions against prefix matches or left recursion .
even generalized parsers which allow specification of any context free grammar present subtle difficulties as they allow specification of ambiguous grammars.
programming by example pbe is a programming paradigm that improves user friendliness by allowing users to construct programs by supplying examples demonstrating the result of an intended computation rather than writing code manually.
in this paper we present parsimony a novel application of pbe for constructing parsers the user selects text in a file the user wishes to parse then supplies a label for that selection.
under the hood parsimony infers productions to parse those selections.
as the user provides more examples in this way parsimony successively constructs a more complete implementation.
as will be discussed in detail in related work compared to parsify our prior work on pbe for parsers parsimony is more expressive more usable and has been evaluated more extensively in particular through an end user study.
the key to parsimony s expressiveness and usability lies in several novel technical contributions which we now discuss.lexer by example parsimony provides new facilities for synthesizing lexer definitions from example tokens.
our key insight is to exploit a large corpus of useful curated regular expressions regexes that already exist the lexers for existing programming languages.
we frame the task of synthesizing lexers as queries to a data structure called an r dag built from this corpus.
in contrast to previous approaches our approach guarantees that any synthesized rule will be realistic rather than synthetic in the sense that it is known to be useful in the context of a real world language implementation.
insensitivity to order to make parsimony insensitive to the order in which the user presents examples we develop a fresh perspective on a classical parsing algorithm first described over years ago the cocke younger kasami cyk parsing algorithm .
we propose a a novel graph data structure built from cyk tables called the cyk automaton that efficiently tracks a large set of candidate productions rather than just one.
crucially because the number of candidates can explode with the length of the example cyk automata efficiently encode an exponential number of candidates with space only quadratic in the length of the example.
we then frame synthesis as graph transformations on automata in which candidates are only removed from consideration when no longer applicable thus avoiding premature loss of candidates.
principled generalization to allow parsimony to generalize from examples we make the key insight that many important design patterns can be encoded by specially constructed cyk automata.
detecting an instance of a design pattern then reduces to a standard graph intersection between two cyk automata one representing the pattern and one representing the example.
we demonstrate the generality of this approach by implementing the repetition patterns from parsify along with new patterns such as infix algebraic expressions simply by defining an automaton for each pattern along with a schema for the productions to generate based on that pattern.
finally we perform a thorough evaluation of parsimony s effectiveness via a controlled study in which programmers previously unfamiliar with parsimony performed a series of tasks using experimental and control variants of parsimony.
our results show that parsimony improves user outcomes as measured by both time to completion and number of mistakes.
in summary we make the following contributions a novel data structure the r dag for synthesizing lexer rules by example section iii .
.
c ieeease urbana champaign il usa technical research815 authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
fig.
.
the parsimony user interface.
another novel data structure the cyk automaton and corresponding algorithms for synthesizing productions by example section iv .
an extensible framework for generalizing from examples of common parser design patterns section iv .
the results of a controlled user study demonstrating the effectiveness of our approach section v .
ii.
o verview parsimony s user interface is shown in figure .
its basic functionality includes standard features ubiquitous amongst integrated development environments a customizable workspace consisting of resizable panes and tabs a file browser for managing project contents and text editors for viewing and editing files.
parsimony also borrows graphical features from parsify such as tree visualizations and coloring of text files based on grammar changes.
unique to parsimony however are two tabs for the lexer and parser synthesis engines the token labels tab allows the user to synthesize lexer rules from example tokens.
the solver tab provides rich functionality for synthesizing and previewing grammar productions derived from strings labeled with syntactic categories i.e.
nonterminals .
in the remainder of this section we illustrate the parsimony workflow and its salient features by walking through a series of scenarios demonstrating how we might employ parsimony to develop the lexer and parser for a toy language called fuyu.
a sample fuyu program .fuyu is shown below.
def a def alpha a def gamma1 a a .
def delta keywords we start by synthesizing a lexer rule for the defkeyword via following three steps click the token labels tab to activate it select the substring def in .fuyu then add it as an example token by clicking the blue plus sign that appears.
the token labels tab then updates its contents as shown at right.
in particular the lefthand drop down shows the list of examples added only one so far and the right hand side shows a candidate rule that parsimony has inferred from that example def def .
this rule meets our requirements so we add it to our lexer definition by clicking the button labeled add to token definitions .
parsimony immediately recompiles the lexer and colors .fuyu in response.
the coloring shown at right tells us two important facts.
first the colored box surrounding def tells us that def matches the lexer rule we just defined as indicated by the legend.
just like a chart legend the legend gives the correspondence between colors and names.
second the red error box tells us that no lexer rule yet matches the character a .
intuitively the error box s location tells us how far into the file the lexer was able to construct the token stream.
to fix this error we will need to define a rule for identifiers like a .
identifiers thedef rule we have just defined is the simplest sort of rule it matches exactly the string def which is easy enough to write without synthesizing it.
identifiers however are a more challenging sort of token.
suppose our language specification dictates that identifiers consist only of alphanumerics and hyphens additionally the first character must be alphabetical.
we want parsimony to automatically synthesize a lexer rule that meets that specification.
we start by adding the example identifier a to the token labels tab.
based on this single example parsimony infers the candidate rulealc a which is disappointingly specific because one example is not enough for parsimony to make a good inference.
to ask parsimony to infer a rule from a group of examples rather than just one we drag and drop multiple samples into their own folder.
shown below is a folder labeled ident into which we have added the four identifiers from .fuyu the right hand side of the figure shows that parsimony has inferred two different candidates from the examples in that folder.
to gain more intuition we click the example strings buttons to ask parsimony to show us examples of strings matched by each rule.
parsimony then updates the view with the strings shown in gray.
it is clear from them that the first rule permits underscores which violates our specification.
the second rule however seems correct by inspection of the example strings and the rule s definition so we accept the inference.
as before parsimony recompiles the lexer and colors .fuyu .
at this point based on the coloring we can proceed as before synthesize a new rule for the next failing token which happens to be the token.
since the basic scenario is the same as for keywords let us assume for the sake of exposition that lexer rules for the remaining basic symbols e.g.
etc.
have been defined in the remainder of this section.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
numeric literals numeric literals in fuyu take the form of integers or floating point numbers specified in decimal or scientific notation.
the desired lexer should assign such literals the token name number .
the six numeric literals from .fuyu are .
1e12 .022e and .2e .
numeric literals are the most complex lexical forms in fuyu.
it would likely take a seasoned veteran of lexical analysis to correctly implement its regex on the first try ?
.
?
?
?
parsimony synthesizes this regex from just those six examples.
in fact it is the only candidate parsimony shows the user because there exists no other expression of equivalent or better quality in its corpus of training data.
parsimony uses a notion of quality based on how specifically the candidate matches the examples for instance the pattern .
also matches the examples but it is much more general and thus inferior we define this notion of quality formally in section iii.
after accepting the inference our lexer is complete.
.fuyu with all tokens properly colored is shown below.
with lexer in hand we proceed to the parser.
in this section we successively augment fuyu.g with productions for the various syntactic constructs of fuyu.
simple assignments we start the process by posing an example of an assignment statement.
we do this by selecting def a typing assign into the text box that appears then clicking the solve button.
the solver tab responds by presenting the following stylized candidate production that parsimony has synthesized from the example the production is close to correct but it has the token number hardcoded in the fourth position which precludes other kinds of non numeric expressions.
to fix this suppose we pose another example def alpha a .
the solver tab now responds with a pair of candidates at this point it should be clear that parsimony needs to be taught that number andident are instances of a common syntactic category nonterminal representing expressions expr .
to do this we pose to the solver both and a as examples of expr .
the result is a set of three candidates shown at right.
the first two candidates match our expectation to parse number andident tokens as expressions add the two productions expr!number andexpr!ident .
the third candidate has a special form.
it indicates that the we can choose between two options for the second position either ident orexpr.
parsimony gives us this option because it has determined that either choice is consistent with the examples we have provided.
to help us make a decision parsimony shows us parse tree visualizations corresponding to each option shown at right.
in particular if we choose expr we will get the top parse tree.
if we chooseident we will get the bottom parse tree.
suppose that according to our specification only variable names i.e.
ident tokens can appear on the lefthand side of an assignment.
to achieve this we choose the ident option before accepting the solution.
all our interactions with the solver thus far have the net effect of augmenting fuyu.g with the three productions expr!
number expr!ident andexpr!def ident eq expr semi .
parsimony automatically recompiles the parser then colors .fuyu accordingly the result is shown below.
note that the first two assignments are now surrounded by colored boxes corresponding to the nonterminal assign .
algebraic expressions from the appearance of line we know that our parser cannot yet handle the right hand side of the assignment to gamma1 so we pose a new expr example a a .
.
because algebraic expressions are ubiquitous in programming languages parsimony contains a powerful heuristic mechanism for detecting such syntactic constructs.
based on this heuristic parsimony presents the user with a graphical wizard that asks if this is indeed an algebraic expression for each operator whether that operator is left or right associative and what should be the order of precedence for those operators.
based on the answers to these questions parsimony constructs an idiomatic subgrammar for parsing expressions of this kind.
suppose we answer using the standard mathematical order of operations.
the synthesized subgrammar then comprises four productions with associativity annotations expr!expr expr left expr!expr expr left expr!expr expr right andexpr!
expr .
additionally parsimony synthesizes the following precedence annotation priorities expr !expr expr expr !expr expr expr !
expr expr !expr expr .
under the hood these annotations compile to disambiguating filters that enforce a policy in the parser such that parse trees obey the specified associativity and precedence hierarchy.
parsimony recolors .fuyu in accordance with this new set of inferences array literals the last syntax left to handle is the array literal shown on line .
we pose 1e12 .022e .2e as an example of an array .
parsimony contains a built in heuristic to detect delimited repetitions another ubiquitous language design pattern.
based on this heuristic authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
parsimony presents a graphical wizard confirming whether each element of the list is a number orexpr the separator between elements is a comma and the list is surrounded by a pair of square brackets.
after confirming parsimony synthesizes an idiomatic subgrammar for delimited lists of exprs array!
array inner!expr array inner!expr comma array inner .
the new coloring shows that the array literal parses correctly.
however the parent assignment is still not surrounded by a box for assign we haven t told parsimony that an array literal is also a form of expr .
the fix is simple we pose 1e12 .022e .2e as an example of an expr then accept the inference expr!array shown at right.
fuyu program finally we define a start symbol for the parser.
we simply pose the entirety of .fuyu as an example of aprogram .
parsimony detects that this is yet another example of a ubiquitous pattern this time an undelimited list of assign instances.
when we confirm this inference parsimony generates two productions program!assign andprogram!
assign program .
our parser is now complete.
iii.
l exer synthesis in this section we formalize parsimony s algorithm for synthesizing lexers.
the core of our approach is the r dag a novel data structure for representing sets of regexes.
we first define the r dag the precursor to an r dag.
an r dag is a poset r such that ris a set of regexes r r is the language containment relation over r such that8r1 r22r l r1 l r2 r1 r2 rcontains a designated regex dsuch thatl d is the set of all strings and 8r1 r22r l r1 l r2 r1 r2.
an r dag can be viewed equivalently as a directed acyclic graph such that ris its vertex set and is its edge set.
for ease of exposition we will view r dag s as graphs or posets interchangably as is convenient in the sequel.
we now define the r dag via reduction from an r dag .
letd r be an r dag .
we define its corresponding r dagd r to be the transitive reduction of d .
that is dis the graph with the same vertex set rasd but with edge set the unique minimum size relation whose transitive closure is .
from a practical perspective we can view an r dag as a database of regexes such that the language containment relationship between regexes is stored explicitly in the form of graph edges.
in our implementation this database contains 3k regexes scraped from open source lexer implementations .
we exploit this structure via a specially designed graph query to answer the question what is the most specific set of regexes that match strings s1 s2 ...?
in this instance most specific informally means that there exists no other regex in the database with smaller language that could also match thosestrings.
we additionally would like this set to be the largest set with this property so we know we are not missing out.
the remainder of this section discusses the query algorithm.
a. regular expression inference via r dag queries we now define the horizon query on r dags the purpose of this query is to discover the largest yet most specific set of regexes that match a set of example strings.
we start with some intuition.
suppose we have an r dag d r and a string s. first we wish to find a set of regexesh rsuch that every regex in hmatchess.
second we requirehto be succinct no two regexes in hshould be related by .
third we require hto be as large as possible without compromising quality adding any regex would violate succinctness and replacing any regex would make it worse i.e.
closer to d .
these three conditions are captured by the notions of consistency succinctness and maximality which we now define formally.
letsbe a set of strings and let d r .his consistent withsiff8r2h s2s s2l r .his succinct with respect todiff8r r02 h r6 r0.his maximal with respect to d s iff no regex r2rexists such that r 2h 8s2s s2l r and 8r02h r r0 r06 r .
his a horizon of d s iffhis consistent with s succinct with respect tod and maximal with respect to d s .
we now define the query horizon d s which computes the horizon of d s 1function horizon d s 2w f dg h 3whilejwj letr removeany w letrp fr02predecessors d r j8s2s s2l r0 g if rp 7w w r rp elsew w r h h frg 9returnh intuitively horizon maintains a worklist wof vertices to inspect.
the worklist initially contains only d the topmost regex that matches any string and is thus guaranteed to be reachable from any other vertex of d. in each iteration we remove a regex rfrom the worklist and compute the set of predecessors of rthat match all strings in s. if such predecessors are found we then add them to the worklist and proceed to the next iteration.
however if no such predecessor exists then we have gone as far down the graph as possible i.e.
we have found the most specific regex so we add the current vertex to output set h. we continue this process until the worklist is exhausted.
at completion his a set of regexes that is consistent with s succinct with respect to d and maximal with respect to d s .
in other words it is the horizon of d s .
because each constituent regex is known to match every string ins it is a candidate for the body of a lexer rule for s. becausehis succinct with respect to dand maximal with respect to d s we know there are no better candidates that we have missed.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
iv.
p arser synthesis in this section we formalize parsimony s algorithms for synthesizing parsers.
we begin with a preliminary overview of context free grammars and parsers.
a. preliminaries acontext free grammar is a tupleg n p s where nis a set of nonterminals is a set of terminals sis a designated start nonterminal and p n v is a set of productions where vis the setn called the vocabulary ofg.
for convenience productions a 2pare written equivalently as a!
.
string indexing string indices begin at .
we write to mean the symbol at index iof string .
by we denote the suffix of starting at index i and by we denote the substring of starting at index iwith lengthj i. we writej j to denote the length of and we write for concatenation of and .
derivations we say derives in a single step written ifpcontains a production a!
such that a and .
equivalently is the single step derivation relation such that iff derives in a single step.
let be the transitive closure of .
we say derives iff and a derivation of from is a sequence that witnesses .
asentential form is a string 2v such thats asentence is a sentential form containing only terminals and l g the language of g is the set of all its sentences.
cyk algorithm the cocke younger kasami cyk parsing algorithm is a classical dynamic programming algorithm for computing whether a string is derivable via a grammar g. for our purposes the crucial feature of the algorithm is that it constructs a 2d table m called a cyk table that records for every substring 0of the set of nonterminals that derive a2mi l a .
for a description of the algorithm itself we refer the reader to grune and jacobs .
in the remainder of this paper we assume without definition that we have a function cyk g that returns a cyk table given a grammar gand string .
b. parser synthesis constraint systems we now make precise the parser synthesis problem by framing it as constraint satisfaction.
a parser synthesis constraint system is a tuple c g f l where gis a grammar f f f1 f2 fkgis a set of strings called files with unique labels f1 f2 f kcalled file names and lis a set of parse constraints of formha i lifdenoting a lengthlselection starting at index iinto file f2f labeled with nonterminal a. let the notation g pmean the grammar gaugmented with additional productions p. a solution to constraint system cis a set of productions pthat satisfies the formula 8ha i lif2l m cyk g p f a2mi lifpsatisfies the above formula we say psatisfies c. intuitively then the parser synthesis problem is the task of findingp a set of productions that allow us to derive every constrained substring encoded by l. c. a data structure for large sets of candidate productions in this section we describe the cyk automaton a data structure for efficiently representing large sets of candidate productions.
this data structure is a central component of parsimony s parser synthesis engine.
intuition intuitively a cyk table is simply a static record of the nonterminals that derive each piece of a string being parsed.
for example m2 5is the set of nonterminals that derive the substring .
however this is only one interpretation of the table.
an alternate perspective is that the table contains predictions about the set of productions that we might add to our grammar to grow the language.
consider for instance that we have the string aband grammar with productions a!a andb!b.
we would then have cyk table msuch that m0 fag m1 fbg andm0 .
suppose that we wish forabto also belong to the language we are designing.
what production should we add to make it so?
the cyk table has almost all the information we need to answer that question.
we could combine one element of m0 1with one element ofm1 1to create the production body ab.
if we add the productions!ab we will have augmented the language to include exactly the string ab.
note however that there are other productions we could have added instead s!ab s!ab ors!ab.
even in this trivial case we see that there can be many such candidate productions.
a cyk automaton is a data structure for making explicit what the candidates are and for providing efficient queries to compute those candidates.
definition a cyk automaton is a directed graph y i e i s if u wherei z is a set of vertices e i i is a set of edges is2iis a designated start vertex if iis a designated set of final vertices uis a set of symbols and is a map from edges in eto sets of symbols in u. we use the notation for the map x ifx ethenxelse x .
given a grammar gand string we construct a cyk automaton via algorithm build cyk automaton below.
1function build cyk automaton g i s if 2let n g 3letm cyk g i e f0 i j jg x 5foriin is if 6e e f i i g g 8foriin is if forlin if i ifmi l6 11e e f i i l g 13return i e i s fifg n intuitively each vertex of a cyk automaton corresponds to a position between tokens e.g.
indicates the position between the 0thand 1sttoken .
an edge between vertices j andkcorresponds to the cyk table entry mj k j that is the set of nonterminals of gthat derive the substring .
this authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
set is recorded via map entry j k .
additionally for every singleton edge j j i.e.
those that correspond to length substrings we also add to the terminal occurring at that position.
by construction any path between vertex 0and vertexj jcorresponds to a set of candidate production bodies that derive as will be illustrated in the following section.
d. parser synthesis via cyk automata in this section we progress through several descriptions of successively more sophisticated mechanisms for solving parser synthesis constraint systems via cyk automata building from simple cases up to more complex cases.
we motivate each augmentation with an example demonstrating the limitation it overcomes.
at the end of this section we will have arrived at the full algorithm used by parsimony dubbed parsynth .
case one parse constraint we first consider synthesis constraint systems with only one parse constraint.
let us revisit the example from section iv c in which we have the string ab a partially implemented grammar g1with productions a!a andb!b but wish for abto derive from a new nonterminal sthat has yet to be implemented.
as we saw in section ii to do this using parsimony we simply highlight the text ab type the label sinto the solver text box then run the solver.
under the hood this sequence of user operations constructs the following parser synthesis constraint system c1 g1 f1 l1 f1 fabf1g l1 fhs 2if1g to solve this constraint system our strategy will be to construct a cyk automaton for the parse constraint in l1 then generate productions corresponding to the shortest path through the automaton.
specifically we construct the automaton for constraint hs 2if1with parameters ab is if f2g a a b b the shortest and only path is .
taking the n ary cartesian product of edge attributes along the path we havefa ag fb bg f a b a b a b a b g. each constituent tuple when read from left to right is the body of a production for sthat derives ab.
that is any such production is a solution to c1.
to succinctly represent the space of choices parsimony uses a graphical representation called a candidate matrix an example of which is shown below.
s a b a b the semantics of a candidate matrix is straightforward the kthcolumn of the matrix shows all the symbols that may possibly occur at positionkin the corresponding production body.
the user must enable exactly one such symbol per column.
the sequence of enabled symbols when read from left to right gives us the corresponding production.
a candidate matrix succinctly visualizes a potentially large set of productions that grows exponentially in the number of columns a candidate matrix withkcolumns and nsymbols per column encodes nk productions.
we denote by xjn1n2 nkkthe candidate matrix with kcolumns such that njis the set of symbols in columnj andxis the left hand side symbol.each production encoded by a candidate matrix mis called a valuation ofm.
to construct candidate matrices we define the following constructor function x which given a path through a cyk automaton constructs the corresponding candidate matrix x i0 i n xj i0 i1 in in k. case non overlapping parse constraints we now consider systems of multiple parse constraints.
as a first step we consider the simplest case in which no two parse constraints overlap i.e.
they reference disjoint substrings .
to handle this in the straightforward way we could construct one candidate matrix per parse constraint.
suppose we have the following constraint system c2 which models a grammar where identifiers idand numbers 1are forms of expressions e and the user has selected and labeled two substrings id id and id with the nonterminal s statements .
the synthesis task is to infer one or more productions for s. g2 fe sg fid g fe!id e!1g s c2 g2 f2 l2 f2 fid idf1 id 1f2g l2 fhs 3if1 hs 3if2g the computed solution is the set of two candidate matrices fm1 m2gwhere m1 sjfe idgf gfe idgkandm2 sjfe idgf gfe 1gk.
in this situation parsimony would display both candidate matrices in the solver tab and allow the user to interact with each.
there are two problems in this scenario a since the user provided parse constraints for only one kind of syntactic construct namely statements s it may be confusing for the user to see two distinct candidate matrices when only one was expected and b it may lead the user to accept a solution of two productions one for m1and one for m2 which is subpar because the more economical solution to c2consists of only a single production namely s!id e. clearly our algorithm needs to be improved to handle such cases and avoid computing more candidate matrices than necessary.
case non overlapping parse constraints with sharing as we have just seen m1andm2are redundant we need only one of the two since both share the desired valuation s!id e. to eliminate such redundancies our strategy is to find a way to partition the constraints l2into disjoint sets called classes such that the constraints in each class can be satisfied by the same productions.
by producing as few classes as we can then computing only a single candidate matrix for each such class we seek to produce an economical solution.
to do this we will first need to define an operation for the intersection of two cyk automata.
intersection lety i e i s if u andy0 i0 e0 i0 s i0 f u0 .
the intersection of yandy0 written ye y0 is defined as follows ye y0 i i0 e is i0 s if i0 f u u0 x x0 y y0 x y x0 y0 e n x x0 y y0 j x y 2e x0 y0 2e0o e e2e j e we say that cyk automata yandy0are compatible written compatible y y0 if and only if the intersection ye y0 authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
1function partition y 2letays f a1 y1 a2 y2 j a1 y1 a2 y2 2y2 a1 a2 compatible y1 y2 g 4if ays6 let ay1 ay2 first sortdescby score y ays let a1 y1 a2 y2 ay1 ay2 lety12 y1e y2 return partition y fay1 ay2g f a1 y12 g 9else return y 10function score y a1 y1 a2 y2 11if a16 a2 return 12returnx a3 y3 2ys.t.a3 a1score one triplet y1 y2 y3 13function score one triplet y1 y2 y3 14if compatible y1 y3 compatible y2 y3 compatible y1e y2 y3 return 16else return fig.
.
algorithm partition .yis a set of pairs a y whereyis a cyk automaton and ais its corresponding nonterminal.
contains a path from the start vertex is i0 s to a final vertex inif i0 f. intersection of cyk automata is similar to the standard product construction for intersection of finite automata however we additionally intersect edge attributes such that each resulting edge attribute is the set of symbols shared by both originating edges.
with this construction any path through the intersection ye y0corresponds to a common set of candidates shared by bothyandy0.
if compatible y y0 then there exists no such shared candidate.
partitioning our partitioning algorithm is shown in figure .
we describe the algorithm informally here.
we first compute for each parse constraint a tuple a y whereais the nonterminal of the constraint and yis the cyk automaton constructed from that constraint.
this set of tuples denoted y serves as the input to partition .
we then iteratively intersect automata until no more intersection is possible.
in each iteration we greedily intersect only the highest scoring pair of automata where our scoring function score ygives preference to the pair that is maximally compatible with all the other automata.
the idea is to intersect those pairs whose intersection has the most opportunity to intersect again in a future iteration.
at termination the output of partition should be a set y0such that y0 jyj and each constituent tuple a0 y0 2y0contains a cyk automaton y0that is possibly the intersection of multiple automata from the original input y. most importantly any path in y0from start to final vertex gives us a solution to all the parse constraints that gave rise toy0.
in other words each element of y0corresponds to the class of parse constraints that it solves .
for illustration consider the constraint system c2from case .
the cyk automata before and after partitioning are shown below where y1andy2correspond to the two constraints in l2 andy12is the intersection of y1andy2due to partitioning.
e id e id e e id e id e y1 y2y12by incorporating partitioning the computed solution becomes the single candidate matrix m3 sjfe idgf gfegk.
there are two key features of this solution to note.
first there is only one candidate matrix not two.
second the last column of m3 contains only e notidor because idand were excluded from edge iny12during intersection.
the two possible valuations of m3ares!e eands!id e. in fact these are the only possibilities there exists no other single production that would also satisfy c2.
in this sense this computed solution is as good as possible.
case overlapping parse constraints a complication occurs when constraints can overlap.
suppose we have the following constraint system c4 which represents a situation in which we have the same grammar g2as before but the user has created overlapping parse constraints like so id id idse .
c4 g2 f4 l4 f4 fid id idf1gl4 fhs 5if1 he 3if1g the user s intention is to specify that the enclosing context id id id is an example of a statement s and that nested within it id id is an example of an expression e. unfortunately our algorithm sketched so far ignores this nested relationship and would compute the solution fm4 m5g where m4 sjfe idgf gfe idgf gfe idgkandm5 ejfe idgf gfe idgk.
to see the problem examine the cyk automaton for m4 ignore the dotted edge for now e id e id e id e the subpath corresponds to the substring id id that the user has constrained with nonterminal e but the automaton ignores that constraint and faithfully retains the underlying cyk table information for edges and .
thus the synthesized candidate matrix m4is overly specific and contains columns corresponding to those edges.
our strategy is to replace such subpaths with summary edges that summarize the effect of nested constraints.
for example we replace the subpath with a single edge whose edge attribute fegreferences the nonterminal of the nested constraint.
the dotted edge is such a summary edge.
after this transformation the revised candidate matrix m0 sjfe idgf gfegkcorrectly encodes only those productions where the right hand side of the assignment statementsmust be an expression e. the candidate matrix m5 remains untouched.
together m0 4andm5represent a solution of two interrelated productions one for eand one for sthat referencese .
for example one possible valuation for m0 4and m5iss!id eande!e e. the algorithm for inserting summary edges is shown in figure .
the function apply nesting takes as input constraint system cand returns a set ywith summary edges inserted.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
1function apply nesting c 2let g f fjgn j l c 3y 4forl ha i lifk2l letl0 fl02ljlcontainsl0g 6y build cyk automaton g fk i i l forl02l0 8y summarize y l0 9y y a y 10return y fig.
.
algorithm apply nesting .summarize takes an automaton and parse constraint and returns the automaton with constrained paths replaced by a summary edge.
case constrained patterns consider the constraint system c5 which models the scenario in which the user has selected and labeled the string with the nonterminal a arrays .
g5 feg f idg fe!
e!idg e c5 g5 f5 l5 f5 f f1gl5 fha 7if1g plausibly the user s intention is that the constrained substring is an example of literal array syntax permitting repetition of the elements within square brackets.
however our algorithm sketched so far has no special handling of such patterns.
it simply infers that the literal array must contain exactly elements m6 ajf gk.
our strategy for handling this case is two fold.
first we detect instances of common grammar design patterns using the machinery for intersection of cyk automata.
second for each pattern we predefine carefully crafted schema for productions the schema contain holes to be instantiated with symbols that have been resolved during pattern detection.
pattern detection supposey6is the cyk automaton shown below from which we computed m6.
e e e id we wish to detect whether y6represents an enclosed delimited repetition that is the repetition of two or more instances of a symbol each separated by a delimiter symbol and surrounded by a matching pair of enclosing symbols.
our key insight is that it is possible to precisely specify such a pattern with a specially constructed cyk automaton y edlist ndelimnelemnopennclosenelemnelem wherenopen nclose nelem ndelim are sets of opening enclosers closing enclosers element symbols and delimiter symbols respectively.
we set nopenandncloseto statically predefined values for common encloser terminals while we setnelemandndelim to be the vocabulary and terminals of the current grammar respectively.
then to detect whether y6matches the pattern we simply intersect y6andy edlist.
if compatible y6 y edlist then we have detected a match.
the intersection y6e y edlist is shown below where edges corresponding to array elements nelem are bold and edgescorresponding to delimiters ndelim are dashed.
e e e id the set intersection of all dashed edge attributes is f gand gives us the set of possible delimiters n delim.
analogously the set intersection of all bolded edge attributes is fegand gives us the set of possible elements n elem.
finally the first and last edge attributes are f g which give us the sets of possible open and closing enclosers n openandn close.
schema instantiation the last step is to instantiate productions.
parsimony contains the following predefined schema named p edlist for enclosed delimited lists where each hole subscripted is a placeholder to be instantiated by a nonterminal or terminal and afreshis a fresh nonterminal.
p edlist lhs!
openafresh close afresh!
elem a fresh!
elem delimafresh the valid instantiations for each placeholder are restricted to the symbols edge attributes captured during intersection open2n open close2n close elem2n elem delim2n delim additionally lhsis a special placeholder instantiated witha the nonterminal from the originating parse constraintha 7if1.
fully instantiated our solution is a!
afresh!e a fresh!e afresh .
as already discussed in section ii parsimony s interface for pattern detection and schema instantiation comes in the form of a wizard in the solver tab the user can graphically select instantiations for each hole or reject the inference altogether if the detected pattern is spurious.
parsimony also implements pattern detection and schema instantiation for infix algebraic expressions undelimited lists and unenclosed lists.
in each case we simply define a cyk automaton paired with a corresponding production schema.
their specification is similar in principle to that already shown so we omit their details here.
we encapsulate pattern detection and schema instantiation in procedure heuristic y which returns a tuple p l where pis a set of instantiated production schemas i.e.
a set of productions and lis the set of originating parse constraints.
the algorithm parsynth 1function parsynth c g f l 2g0 g l0 l em change?
true 3while change?
change?
false 5y partition apply nesting g0 f l0 let p l00 heuristic y ifp6 8g0 g0 p l0 l0 l00 change?
true 9foriin 10y partition apply nesting g0e em f l0 em for a y is fifg 2y 12em em a shortest path y is if 13return g0 em lines repeatedly attempt to match patterns accumulating all instantiated schema until no more matches are found.
lines accumulate candidate matrices from any parse constraints not handled by the first loop.
we perform two passes of the authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
loop such that solutions computed in the second pass take advantage of those produced by the first.
in particular the operationg0e emon line inserts into g0productions of the formx!
a1j jam z1j jzn for each candidate matrix xjfa1 a mg fz1 z ngkinem.
to see why this is valuable recall section ii in which we synthesized the following candidate matrices expr jfidentgk expr jfnumbergk andassign jfdefgfexpr identgfeqgfexprgfsemigk.
the underlined nonterminal expr is computed in the second pass by making use of the candidate production expr!ident which was computed in the first pass.
v. e valuation to evaluate the effectiveness of parsimony we conducted a user study in which subjects without previous experience using parsimony were asked to complete a series of tasks using one of two interfaces either parsimony with all its features enabled or a stripped down version with no synthesis or visualization features at all.
we test the following hypotheses hypothesis .
parsimony helps users construct parsers more quickly than with a traditional parsing workflow.
hypothesis .
parsimony leads users to make fewer mistakes than with a traditional parsing workflow.
we targeted our user study at programmers who had some familiarity with parsing but who were not experts as determined by self rating.
our sample pool consisted of computer science students who were split by random assignment into control and experimental groups.
the interface seen by the experimental group contained all features described in this paper.
the interface seen by the control group retained only a workspace with file browser and text editors but no synthesis or visualization features the interface modeled a traditional parsing workflow in which the user employs a text editor and relies on command line compiler feedback.
both groups first read a brief introduction then followed a tutorial introducing them to the features of their interface.
subjects then had two hours to complete tasks asking them to implement lexers and parsers for two toy languages fuyu and hachiya designed specifically for the experiment.
we chose synthetic languages to prevent bias that might stem from users prior familiarity with existing languages although synthetic these languages contain syntactic constructs that occur commonly in real languages such as literal primitives and data structures loops branches and various statements.
due to lack of space we provide reference definitions online at .
the first seven tasks asked subjects to implement the lexer and parser for the fuyu language.
each task asked the subject to implement one syntactic construct in isolation e.g.
numeric literal or expression in each case the subject was given a file with positive examples of that construct.
the final two tasks asked subjects to write a parser for hachiya given a sample source file and informal language specification subjects were free to implement syntactic constructs in any order they wished.
to finish any task subjects ran a test suite provided by us tocheck their solution.
subjects were not allowed to skip tasks or to proceed without passing all tests.
hypothesis we find that parsimony significantly improves users speed at constructing parsers.
we focus on two measures of time based performance average completion time per task and total progress made.
we discuss total progress first.
figure left shows the number of subjects completing each of tasks .
in the time alotted five experimental subjects progressed through all tasks but only two control subjects completed all tasks.
the dropoff in the control group begins at task which was one of the more complex tasks as it involved construction of a grammar for algebraic expressions built from variables and literals.
by contrast the dropoff in the experimental group begins much later at task .
figure center shows average completion time for each task.
we average across only subjects who successfully completed that task.
the figure shows that parsimony either matches or improves performance in the three most difficult tasks for the fuyu language and .
task required constructing a lexer rule for numeric literals recall section ii .
task as already mentioned covered algebraic expressions.
task required writing productions for literal arrays.
in all three cases control subjects took approximately twice as long.
we do note however that our results appear to show no significant speed advantage in tasks and the averages for those tasks are biased toward the control group as they contain only a high performing minority of the control group compared against a larger subset of experimental group.
hypothesis we find that parsimony significantly reduces the number of mistakes made.
we measure two kinds of mistakes compile errors when the user specifies a bad rule that causes a compile failure and reasoning errors when the user specifies a rule that is later deleted or modified .
compile errors figure right shows the per user average number of compile errors.
in lexer tasks the experimental group significantly outperformed the control group as evidenced by the first three columns of the figure.
the experimental group also significantly outperformed the control group in parsing tasks .
to more finely distinguish the contributing factors for this trend we classify parser compile errors into two kinds syntax and semantic errors.
syntax errors are self explanatory.
semantic errors occur when the compiler fails a semantic check a the user specifies a production that