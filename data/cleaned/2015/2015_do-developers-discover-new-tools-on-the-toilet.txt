do developers discover new tools on the toilet?
emerson murphy hill google llc emersonm google.comedward k. smith bloomberg tedks riseup.netcaitlin sadowski google llc supertri google.comciera jaspan google llc ciera google.comcollin winter waymo collinwinter waymo.com matthew jorde google llc majorde google.comandrea knight google llc aknight google.comandrew trenk google llc atrenk google.comsteve gross google llc stevegross google.com abstract maintaining awareness of useful tools is a substantial challenge for developers.
physical newsletters are a simple technique to inform developers about tools.
in this paper we evaluate such a technique called testing on the toilet by performing a mixed methods case study.
we first quantitatively evaluate how effective this technique is by applying statistical causal inference over six years of data about tools used by thousands of developers.
we then qualitatively contextualize these results by interviewing and surveying developers from authors to editors to readers.
we found that the technique was generally effective at increasing software development tool use although the increase varied depending on factors such as the breadth of applicability of the tool the extent to which the tool has reached saturation and the memorability of the tool name.
i. introduction tools can help increase developer productivity by increasing velocity and code quality.
for instance tools can find concurrency bugs reduce the effort to analyze customer feedback and help configure caching frameworks .
with an increasing number of tools becoming available for developers to use the opportunity to improve productivity by increasing tool usage is enormous.
however as the number of tools increases so does the difficulty for developers to gain awareness of relevant tools.
as campbell and miller argue tools in major development environments suffer from deep discoverability problems .
the problem extends beyond software development in grossman and colleagues survey of autocad users a typical problem was that users were not aware of a specific tool or operation which was available for use .
the problem is compounded at large companies like microsoft where developers create in house tools and wish to share them with peers.
to increase awareness and adoption of software tools and practices google uses a technique called testing on the toilet or tott for short figure .
the tott episodes are page printed newsletters written by developers and posted in restrooms .
while originally aimed at promoting testing tools and practices hence the research performed while at google.
ttesting on the toilet presents... healthy code on the commode !
!
!
!
!
!
!
fig.
tott episode promoting clang format .
name over the years tott has become more inclusive of other kinds of software development practices and tools.
throughout the period of our study episodes were distributed by volunteers more recently facilities staff have taken up distribution.
episodes are posted in restrooms for about a week until the next episode is posted.
software developers have posted episodes at google since may and other organizations have invested in similar efforts.
one such example is the schibsted group s testing on the toilet which uses a format very similar to our own .
similarly both johns hopkins univer4652019 ieee acm 41st international conference on software engineering icse .
ieee authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
sity and harvard law school publish restroom newsletters that occasionally contain tips about features of universityrelevant software .
to our knowledge none of these efforts have been evaluated.
the main contribution of this paper is the first evaluation of the effectiveness of tott for distributing knowledge about software development tools.
while the approach has garnered media attention little is known about tott s overall effectiveness.
to this end we performed a case study a research methodology appropriate for investigating a contemporary phenomenon within its real life context especially when the boundaries between the phenomenon and context are not clearly evident .
our study analyzed the usage of command line development tools before and after the publication of a corresponding episode to evaluate the following hypothesis hypothesis testing on the toilet increases usage of advertised developer tools.
we apply causalimpact a bayesian statistical technique that was developed to evaluate the impact of advertising on website traffic to determine whether tott had a statistically significant impact on tool usage.
we then provide context for each tool s usage over time by interviewing and surveying software developers who read edit and author episodes.
our results suggest that the technique is generally effective at increasing tool awareness although this increase varies depending on each software development tool and its context such as the breadth of applicability of the tool the extent to which the tool has reached saturation and the memorability of the tool name.
ii.
related work studies of tool adoption.
diffusion of innovations seeks to understand how people adopt new ideas .
in our study we measure only the first phases of the diffusion of innovations from knowledge to implementation where developers gain awareness of the tool and begin to employ the tool.
we assume that while developers may gain awareness and some knowledge about the tool through tott their decisions about whether to fully adopt a tool are driven by properties of the tool and the developers work context rather than by tott.
thus we do not expect that tott itself drives long term tool adoption beyond inspiring developers to try the tool.
several researchers have investigated diffusion of innovations in the field of software development.
in earlier work using surveys fichman and kemerer found that for database management systems programming languages and computer aided software engineering tools that are purchased use of purchasing data is a poor predictor of actual adoption with companies .
iivari s surveys found that lack of management support is a significant contributor for non adoption of software engineering tools .
more recently witschey and colleagues surveyed developers about their adoption of security tools they found that the strongest predictor of a developer s likelihood to use atool was their ability to observe their peers using tools .
murphy hill and colleagues interviewed software developers about how they first discovered tools finding that the most effective way developers learned about new tools was through their peers .
in contrast to these studies we rely on tool usage logs and statistical analysis to understand tool usage which avoids the pitfalls of relying exclusively on self reported data.
studies of restroom advertising.
outside of software engineering several previous research studies have evaluated restroom advertising.
hoffman found that men could more often recall fliers placed above restroom urinals than in a study area .
kaltenbaugh and colleagues found that survey respondents reported that sports advertisements placed above restroom paper towel dispensers were easy to read and placed in an appropriate location .
lehmann and shemwell found that the majority of survey respondents recalled features of an advertisement placed above urinals and near mirrors in restroom bars even though respondents might be somewhat impaired due to alcohol consumption .
our study goes beyond such self reported perception and recall data collected in these prior studies and instead relies on actual usage of the product.
like our study mackert and colleagues evaluated the effect of advertisements on objective outcomes.
in that study researchers concealed for hours in bathroom stalls observed the handwashing behavior of people before and after introducing pro handwashing lobby and restroom posters .
the posters did not significantly increase handwashing.
in contrast we studied several software engineering posters introduced at different points in time and did not use covert restroom surveillance.
approaches to improving tool usage.
singer found that gamification can increase use of features of the git version control system .
cockburn and williams found that pair programming can influence the tools that developers discover .
some systems recommend new tools by observing current tool use .
in the context of software development tools murphy hill and colleagues used collaborative filtering and other techniques to automatically recommend ide commands .
other recommender systems for software engineering have taken a task oriented approach.
viriyakattiyaporn and murphy s spyglass system used patterns of tool non usage to recommend program navigation tools .
similarly witchdoctor and benefactor can recognize when a developer is refactoring without a tool and then recommend completing the refactoring using the tool .
while studies of these systems evaluate personalized recommender systems ours evaluates a substantially different approach that of non personalized newsletters.
our study also investigates tool usage with an order of magnitude more developers than in those studies.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
iii.
methodology to investigate testing on the toilet s effectiveness for promoting software development tools we synthesized data from both quantitative and qualitative sources.
we first analyzed the logs of command line software development tools section iii a before and after twelve episodes appeared section iii b .
we then contextualized these results with qualitative data from three perspectives that of episode authors section iii c episode editors section iii d and episode readers section iii e .
blank surveys and interview scripts are available online to increase the replicability of our study.
a. analysis of tool logs google collects log data of how employee software developers use command line tools.
most development at google occurs on linux workstations using a uniform centrally built toolchain every binary built for the workstation fleet creates a syslog entry on start.
this data provides the number of developers per day using each tool.
we use a statistical package called causalimpact which analyzes time series data to determine whether an intervention had an impact on that data .
for our analysis we used daily unique users as the time series and the date on which the episode was released as the intervention.
causalimpact creates a model of the counterfactual of tool usage that is the expected usage of the tool had the intervention not occurred.
we used three sources of data for the model first we used the usage of the tool before the episode was published.
intuitively for example if a tool gains one user per week before the episode is published one would naturally expect the tool to continue gaining one user per week.
causalimpact then uses this data as an empirical hyperparameter to its bayesian model.
a second empirical hyperparameter is a set of control groups for which the intervention did not occur.
here we used other tools that were not promoted in an episode that is every other command line tool used at google more than tools in total.
although many of these tools bear little resemblance to our tott tools causalimpact accounts for this by reducing the weights of dissimilar tools effectively discarding them.
third because usage across days is not uniform especially on weekends we included a day seasonal hyperparameter into causalimpact s model.
for each tool causalimpact needs a pre period from which to measure trends in baseline tool usage and a post period against which to compare counterfactual tool use.
to help establish these periods we re ran a sensitivity analysis by generating causalimpact models with preand post periods of between one week and more than two years using a dozen control tools to enable sufficiently fast analysis.
the results were largely consistent across pre periods of differing lengths consequently for the mainanalysis reported in this paper we chose six months to balance being long enough to reasonably establish baseline usage but short enough to exclude potentially confounding factors such as other interventions like social media posts about the tool.
for varying post period lengths tool usage rates were substantially different.
inspecting the data there were two reasons tools whose usage showed an initial uptick that later subsided and tools whose usage is influenced by some later intervention.
consequently we need to intelligently choose a post period duration.
since we expect the effect of tott itself to last only a short amount of time section ii we chose three weeks as a reasonable period because each episode is scheduled to be posted for one week but may linger for some time afterwards.
b. episodes we next gathered all episodes describing command line software development tools for which we could gather sufficient data to draw conclusions.
to achieve this goal we used the following criteria the episode must have been published during the six the years for which we had tool log data available.
episodes met this criterion.
the episode must introduce a development tool that can be invoked on the command line so that we could capture tool log data.
episodes met this criterion.
the episode must not have been published during a gap in the tool log data.
such gaps occurred three times lasting between several weeks and several months and affected all tool data.
one tool had only six weeks of data between the start of the tool logs and publication of its episode so we excluded this tool as well.
a total of seven episodes were excluded using this criterion.
the tool must have had at least daily users at some point during the pre or post period.
we excluded such tools because we found their data too sparse to reason about either statistically or intuitively.
six episodes were excluded using this criterion.
the episode author still worked at google and agreed to be interviewed to provide context.
two episodes were excluded using this criterion.
twelve suitable episodes remained after this process.
c. author perspectives to understand the context of usage for each software development tool we characterized the process from the perspective of developers familiar with each tool the episode authors.
these authors are developers who write the content of an episode and refine it with feedback from domain subject matter experts editors and any other interested developers.
in many but not all cases these were developers who were involved with creating the tool.
we additionally talked to one developer who authored four episodes that coincidentally were all published during the tool log gaps while we don t discuss his episodes specifically we include his interview data.
we first asked in467 authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
terviewees about their expectations before publishing the episode and their recollection of whether it was successful.
we then showed them a plot of their tool s usage before and after the episode including causalimpact s counterfactual predictions we then asked them for explanations of trends in the tool s usage.
the first author analyzed this data by transcribing audio interviews one author declined audio recording here we used handwritten notes then open coded the transcripts.
a secondary source of data we use were surveys of episode authors which asked respondents for feedback about the publishing process and included questions about process satisfaction and how the developers measured the impact of their episode.
d. editor perspectives to understand editors perspectives on the effectiveness of tott we used two sources of data.
first we used documentation about the tools and the history of the tott initiative.
second we interviewed four developers involved in editing episodes.
these editors are responsible for choosing which episodes are appropriate for publication providing feedback on episodes soliciting feedback from subject matter experts and managing the publication process.
we used the same qualitative methodology as we used with author interviews.
we selected two developers who were involved in tott during its inception and two developers who are currently involved in tott editing.
we asked editors about their general expectations about the effect of publishing episodes about tools.
we then named the tools we analyzed allowed them to select a tool or two of interest showed them the usage plots for those tools and asked whether the plots matched their expectations.
e. reader perspectives to understand the tott reader perspective we turned to several sources of data.
to determine how many engineers actually encounter episodes we surveyed developers on a general mailing list about their office location and viewing habits we received responses.
because episode authors and editors may provide an especially positive view on the effectiveness of tott we specifically sought out countervailing viewpoints from authors in two ways.
first we analyzed internal communications on a channel that is known google wide for jokes about developer frustrations searching for internal jokes that contained tott .
second to determine why developersdo not learn about a tool from tott we chose a tool with substantial usage after the episode then surveyed developers who a became employees at least months before the episode was published b used the tool but only started to do so months or more after the episode was published and c have invoked the tool at least times.
we inferred that these developers found the tool useful then asked them why they didn t start using the tool immediately after the episode was published.
developers responded out of surveyed.f.
threats to validity before we discuss the results of our study it s worth discussing the major issues regarding validity of our methods.
we assume that the number of unique users of a tool per day is good measure of software development tool discovery but other measures of discovery could be used such as developer self reports.
how well tott would work at another company depends on the extent to which google is similar to that company.
google is large multi site software focused founded about years ago and based in silicon valley.
google uses a substantial amount of shared infrastructure used by most developers in the form of a monolithic repository .
we focused on command line tools but tools invoked differently may experience distinct usage patterns when communicated through tott.
a post tott tool usage increase might not be caused by the episode.
for example the effects of co occurring promotions of a tool will be conflated with the effects of the episode.
because causalimpact has no way to control for this effect we attempt to mitigate this by asking interviewees about other tool advertisements and pointing them out to the reader in the relevant plots.
authors were asked about episodes that were up to six years old authors may have difficulty remembering the events surrounding the episode.
to mitigate this we brought the relevant episode for the author s reference.
tool usage may be influenced by fluctuations in distribution which may vary from week to week.
for example volunteers who post episodes in the bathroom may go on vacation in a given week.
likewise the quality of the writing in the episode may vary from episode to episode but we did not attempt to measure quality.
our analysis of jokes is opportunistic but incomplete because some benefits or drawbacks may not be amenable to jokes.
thus the joke analysis cannot be expected to identify all benefits and drawbacks of tott.
we used member checking to improve validity overall by inviting editors and authors to comment on drafts of this paper.
fourteen interviewees provided comments on our results ranging from minor wording to reinterpretation of existing plots.
we adjusted our wording and interpretation sometimes after a back and forth discussion.
iv.
tools studied we next provide brief descriptions of the tools we studied.
with the exception of clang format and iblaze we have renamed the tools in this paper for confidentiality reasons.
a code formatters.
clang format is an open source code formatter for c c objective c javascript java and protocol buffers .
google has a strictly enforced coding style for each of these languages.
pythonformatter is similar to clang format but is authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
targeted at python.
pythonformatter is an internal tool that removes python lint errors and reformats the source code.
b build and integration tools.
iblaze is a wrapper around blaze our centralized build tool blaze is used by most developers at google.
iblaze re runs blaze whenever a dependency of any target affected by the command is modified.
this allows a developer to see build or test results without having to manually re run a command.
verifydetermbuild is a tool designed to debug long builds.
the build system reuses cached build results when possible but if binaries change between builds e.g.
if a timestamp is included in the binary the new binary causes a cache miss.
the tool verifydetermbuild runs two builds then reports any outputs that differ.
the developer then diagnoses and fixes the problem.
emulatorsettings is a wrapper script on top of the standard emulator for the android mobile operating system using default settings designed for interactive development and debugging optimized for our internal development environment.
c quality assurance tools.
sandboxmanager is a framework for describing launching and tearing down full system stacks or sandboxes for end to end and exploratory testing.
uidiff is a tool used to evaluate changes to web application user interfaces.
users are able to take screenshots showing how their application appears in different web browsers both before and after a proposed change the resulting images are shown side by side together with a visual diff.
coverage is a test coverage tool the real name of this tool is a german word that may be difficult to remember for those who do not speak german .
while coverage is typically run automatically here we analyze the manual invocations which are useful when the a developer wants to try the tool or check code coverage before sending a change for review.
d production tools.
estimateresources analyzes changes to the configuration of production server jobs to see if the job will still fit into the resources e.g.
memory available on the machines and clusters on which they run.changetimezone can assist developers who go on call so that they can quickly respond to problems in deployed software.
developers specify on call periods in those files using the time zone of google s headquarters for historical reasons.
consequently developers not in that time zone must do the conversion manually.
changetimezone automates this conversion by letting the developer specify times in any time zone.
e other tools.
generatedoc is an documentation generator for source code packages.
it uses the number of imports to rank source files by their popularity and generates a readme file in markdown that includes the most popular source files the number of