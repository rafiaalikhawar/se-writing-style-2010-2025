modify enhance select co evolution of combinatorial models and test plans rachel tzoref brill school of computer science tel aviv university and ibm research israelshahar maoz school of computer science tel aviv university israel abstract the evolution of software introduces many challenges to its testing.
considerable test maintenance efforts are dedicated to the adaptation of the tests to the changing software.
as a result over time the test repository may inflate and drift away from an optimal test plan for the software version at hand.
combinatorial testing ct is a well known test design technique to achieve a small and effective test plan.
it requires a manual definition of the test space in the form of a combinatorial model and then automatically generates a test plan design which maximizes the added value of each of the tests.
ct is considered a best practice however its applicability to evolving software is hardly explored.
in this work we introduce a first co evolution approach for combinatorial models and test plans.
by combining three building blocks to minimally modify existing tests to enhance them and to select from them we provide five alternatives for co evolving the test plan with the combinatorial model considering tradeoffs between maximizing fine grained reuse and minimizing total test plan size all while meeting the required combinatorial coverage.
we use our solution to co evolve test plans of real world industrial models with version commits.
the results demonstrate the need for co evolution as well as the efficiency and effectiveness of our approach and its implementation.
we further report on an industrial project that found our co evolution solution necessary to enable adoption of ct with an agile development process.
ccs concepts software and its engineering software testing and debugging keywords combinatorial testing software evolution acm reference format rachel tzoref brill and shahar maoz.
.
modify enhance select coevolution of combinatorial models and test plans.
in proceedings of the 26th acm joint european software engineering conference and symposium on the foundations of software engineering esec fse november lake buena vista fl usa.
acm new york ny usa pages.
permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
copyrights for components of this work owned by others than acm must be honored.
abstracting with credit is permitted.
to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
request permissions from permissions acm.org.
esec fse november lake buena vista fl usa association for computing machinery.
acm isbn .
.
.
.
introduction software systems continuously change during development and maintenance to support evolving requirements and design.
software evolution is intensified by modern paradigms such as agile development and continuous delivery which advocate incremental software changes within shorter development cycles and frequent deliveries.
evolving software imposes challenges for its testing procedures.
tests designed for a certain version of the system under test sut might be invalidated following software changes and have to be either repaired or discarded.
new tests need to be created for newly added functionality.
when test generation is manual discarding tests as well as creating new ones is expensive.
test repair involves manual analysis and might be labor intensive as well.
over time incremental test accumulation creates a technical debt both because it involves continuous manual test maintenance effort and because the test repository inflates and drifts further away from an optimal set of tests for the sut version at hand.
combinatorial testing ct is a well known testing technique to achieve a small and effective test plan .
the rationale behind ct and the key for its effectiveness is the empirical observation that in most cases the occurrence of a bug depends on the interaction between a small number of features of the sut .
for example according to all possible pairs of parameter values can typically detect to of the bugs in an sut.
ct translates this observation to a coverage criterion as follows.
it requires a manual definition of the test space in the form of a combinatorial model consisting of a set of parameters their respective values and constraints on the value combinations.
a valid test in the test space is defined to be an assignment of one value to each parameter that satisfies the constraints.
a ct algorithm automatically constructs a subset of the set of valid tests termed atest plan which covers all valid value combinations of every t parameters where tis usually a user input.
such a test plan is said to achieve t way interaction coverage .
a significant combinatorial reduction is achieved in the size of the resulting test plan compared to manually designed test plans for example because the tests generated by the ct algorithm are very different from each other maximizing their added value each of them covers as many unique t way value tuples as possible.
note that tests produced by the algorithm are parameter value assignments.
generating executable tests from them is often a manual effort.
while there is much evidence for the effectiveness of ct on a single version of an sut with a single combinatorial model its applicability to evolving software is hardly explored.
moreover while many academic and industrial tools for ct exist e.g.
pict acts casa and aetg none supports model and test plan evolution.
indeed applying ct to an evolving sut is nontrivial.
straightforward naive approaches will typically not work esec fse november lake buena vista fl usa rachel tzoref brill and shahar maoz best due to the tradeoff between the total test plan size and the number of new tests that need to be developed.
specifically on the one hand repeated application of ct that accumulates the resulting tests from one version to the next will unnecessarily inflate the total test plan size.
on the other hand discarding all tests from previous versions and starting each time from scratch is wasteful since it avoids test reuse and thus unnecessarily increases test generation effort.
a middle ground approach is called for.
in this work we present a first approach for co evolution of combinatorial models and test plans.
our approach is based on the observation that in ct software evolution translates into model definition updates and these updates together with the structured tabular form of the combinatorial test plan consist a unique opportunity to assist in efficient test plan evolution.
given a combinatorial model and an existing combinatorial test plan from a previous version of the model as input our solution to co evolution consists of three main building blocks modifying existing tests to match the new model version while maximizing the gain in t way interaction coverage enhancing the existing test plan with a small set of new tests to reach t way interaction coverage of the new model version and selecting a subset of the resulting test plan that retains t way interaction coverage by eliminating redundant tests that no longer contribute to the coverage.
to achieve efficient modification of tests we apply an algorithm that automatically locates minimal value combinations in the existing tests that are invalidated by the changes made in the new model version.
after identification the algorithm replaces these values with new values that are consistent with the new model version and maximize the overall t way coverage of the test plan.
finally the modification algorithm appends new values to existing tests for parameters that were added in the new model version to represent newly added sut functionality.
test plan enhancement computes the t way coverage of the existing tests and creates new tests that augment them to reach overall t way coverage.
to achieve this it uses a variant of a ct algorithm that receives a seed of tests as its input.
seeding was suggested in as a way for the engineer to specify tests that must appear in the solution.
we provide the existing tests from the previous model version as the seed to the ct algorithm.
finally for test plan selection we use interaction based test suite minimization itsm .
given a test plan itsm selects a subset of the tests that preserves the same t way interaction coverage as the original test plan.
itsm was suggested in in the context of a single model version where it was used to eliminate redundancy from manually created test plans.
we observe that itsm is also very useful in the context of evolution to eliminate redundancy originating from model modifications especially functionality removal .
thus after modification and enhancement we apply the itsm algorithm to the resulting test plan to select a subset that preserves t way coverage.
considering that different sut settings have different pain points the efforts associated with test generation and total test plan size vary and depend on various factors such as sut complexity test execution time and the extent of automation embedded into the test procedures.
to accommodate for this variability we use the above three building blocks modify enhance and select to present the engineer with five different alternatives for co evolving thetest plan with the model.
we note that each of these alternatives produces a test plan with t way coverage of the current model version.
the alternatives are as follows.
ct from scratch ct results in potentially minimal test plan size but in a maximal number of new tests as there is no reuse of existing ones.
enhancement en maximizes the number of reused tests but results in the largest test plan size.
tests that are invalidated by model changes are discarded and new tests are created to replace the lost functionality as well as to cover newly added functionality.
enhance select es is similar to enhancement but also applies selection to the resulting test plan hence its total size is potentially smaller it typically contains the same number of new tests as enhancement but with fewer existing ones.
modify enhance select mes applies all three building blocks of the solution and results in potentially the least number of new tests to create.
invalidated tests are repaired in a way that maximizes the gain in t way interaction coverage.
modify enhance select without repair mesw is a variant of modify enhance select which allows to discard invalidated tests instead of repairing them hence the modification algorithm only appends new values to existing tests for added parameters.
we implemented our co evolution solution within the industrialstrength commercial ct tool ibm functional coverage unified solution ibm focus .
to scale the computation to realworld model sizes we use an efficient representation of the sets of valid tests based on binary decision diagrams a compact data structure for representing and manipulating boolean functions.
thanks to our efficient implementation focus can compute the different co evolution alternatives almost instantaneously.
therefore the engineer does not have to a priori decide which alternative to use.
rather she can examine the resulting alternative test plans and choose the one that best suits the current needs.
note that there are rules of thumb suggesting which alternative to use in which settings e.g.
if executing each single test takes much time then total test plan size is most important to minimize if generating executable tests out of ct abstract tests is manual laborintensive task then maximizing reuse while paying in total size may be the target.
however we deliberately do not present explicit rules because our tool can easily show all alternatives engineers should consider the tradeoffs per their setting.
the question of oracle definition in ct without addressing model evolution is surveyed in .
approaches for test oracles in ct are categorized as non automated implicit derived and specified.
the latter allows the engineer to specify rules in a formal specification language to determine the expected results for each test case this is the approach used by most ct tools as well as by ours.
ibm focus supports defining test snippets and their expected results and associating them with specific parameter value combinations.
the complete oracle for each test is combined from the relevant test snippets according to its value combinations.
this allows also for reuse of snippets between different tests.
in our present work the cost of defining and updating oracles is included in the cost of defining new and modified tests and thus in the 236modify enhance select esec fse november lake buena vista fl usa corresponding tradeoff with total number of tests to maintain and execute.
to evaluate the applicability of our work to real world model evolution we applied our co evolution technique to real world industrial models with a total of versions and commits versions per model .
the models and their versions were obtained from ibm.
our analysis shows that the modify enhance select alternative achieves a significant reduction in the number of new tests that are required yet pays very little in total test plan size.
hence it is an efficient middle ground approach between the two extreme alternatives.
performance wise our approach provides excellent running times in most cases and acceptable ones in all cases.
we further report on experience from a real world industrial project where our co evolution technique was used by engineers working in agile development mode.
since in this project the tests automatically generated by ibm focus are manually translated into test automation scripts test reuse is of high priority.
the feedback from the engineers following their experience with our coevolution technique is that the modify enhance select alternative is the most valuable one and in fact was necessary to enable their adoption of ct in conjunction with their agile process.
background we provide background on combinatorial models and test plans and their semantics and on the use of binary decision diagrams to represent models and generate test plans.
combinatorial models and test plans .
a combinatorial model is defined as follows.
let p p1 .
.
.
pn be a labelled set of parameters v v1 .
.
.
vn a labelled set of finite value sets where viis the set of values for pi and ca set of boolean propositional constraints over p. a test v1 .
.
.
vm where i vi vi is a tuple of assignments to the parameters in p. the semantics used in practice by ct tools is boolean semantics.
in this semantics a valid test is a test that satisfies all constraints in c. the semantics of the model is the set of all its valid tests denoted by s p v c .
a combinatorial test plan tis a set of valid tests so that t s p v c .
the interaction level tis an integer so that t p .
the t way interaction coverage of tis defined as the percentage of parameter value tuples of length tthat appear in at least one test intout of all valid tuples of length tins p v c .
the definition of t way interaction coverage can be naturally extended to variable strength generation which allows requesting different interaction levels for different subsets of the parameters.
alternative interaction coverage definitions appear in .
given a model s p v c and an interaction level t a ct algorithm automatically produces a small as possible test plan that achieves t way interaction coverage.
the construction of such a minimal test plan is an np complete problem .
numerous ct algorithms exist and none is superior in general to all others.
using binary decision diagrams to represent combinatorial models and generate test plans .
in segall et al.
presented a compact representation of combinatorial models using binary decision diagrams bdds .
bdds are a compact data structure for representing and manipulating boolean functions commonly used in formal verification and in logic synthesis .
utilizes the efficient computation of boolean operations onbdds such as negation conjunction and disjunction to compute the bdd representing the set of valid tests from the user specified constraints.
the set of invalid tests in the model is represented using the conjunction of the bdds for each of the constraints.
multi valued parameters are handled using standard boolean encoding and reduction techniques to bdds .
the set of valid tests is represented by the negation of the bdd for the invalid tests conjunct with a bdd that represents the legal multi valued to boolean encodings of the parameter values.
this bdd based representation of the combinatorial model is the basis for the implementation of our co evolution solution.
further presents a bdd based algorithm to generate a test plan with t way coverage.
since the implementation of our coevolution solution relies on a variant of this algorithm we present in algorithm relevant excerpts of the original algorithm from .
input coverage requirements given as a set crof tuples of parameters to cover.
the bdd valid of all valid tests.
1init forc crdouncov c proj c valid 2while cr do collected valid sortcrin decreasing order of sat uncov c forc crdo if collected uncov c false then collected collected uncov c end end chosen randsat collected appendresult chosen forc crdo uncov c uncov c chosen ifuncov c false then cr cr c end end 17end algorithm bdd based ct excerpt of the original algorithm from in each iteration the algorithm selects a single test to add to the test plan as follows.
it conjuncts the bdd valid representing the set of valid tests with the bdds in crrepresenting the sets of uncovered parameter value tuples in descending order of the bdd sizes line .
it then randomly selects a satisfying assignment chosen out of the resulting bdd and adds it to the test plan line .
chosen represents a test that covers as many new tuples as possible.
the tuples covered by chosen are removed from the bdds of the uncovered tuples line .
the algorithm proceeds until no uncovered tuples are left.
in section we will refer to the above algorithm and describe the changes we made to it in order to adapt it to support co evolution.
running example and overview we start off with an example and overview of our work.
the presentation here is semi formal.
formal definitions appear in section .
237esec fse november lake buena vista fl usa rachel tzoref brill and shahar maoz table example on line shopping model parameter values itemstatus is instock outofstock nosuchproduct ordershipping os air ground deliverytimeframe dt immediate oneweek onemonth constraints dt immediate os air dt onemonth os ground figure a pairwise test plan for on line shopping model version v1.
table shows the parameters values and constraints of a combinatorial model for an on line shopping system which we use as a running example borrowed from .
the model defines the test space and which tests in it are valid.
for example the test is instock os air dt immediate is valid while the test is instock os ground dt immediate is invalid.
a pairwise test plan one of many possible for this model appears in figure .
the test plan is automatically generated by ibm focus.
it contains tests and achieves pairwise coverage of the model because every pair of values for every pair of parameters that is not excluded by the constraints appears in at least one of the tests.
let us assume that a engineer manually translated these tests into executable tests.
below we follow a series of updates to the model inspired by similar updates we have seen in the evolution of real world models.
these updates account for changes in the sut following evolving requirements or design.
we describe the updates and demonstrate how our co evolution solution handles them to co evolve the test plan.
the updates are relatively small and local.
we use them to demonstrate the basic principles of our technique.
from v1 to v2.
following the addition of a built in payment function to the system a engineer added a new parameter named paymentmethod pm with values creditcard paypal and giftvoucher and committed a second model version model version v2.
once the model was updated the pairwise test plan needs to co evolve with it in order to be up to date with the test space changes.
figure depicts the result of our co evolution technique as produced by ibm focus on the pairwise test plan from figure and the on line shopping model version v2.
on the left most column we see that the pairwise test plan from model version v1 achieves only .
pairwise coverage in model version v2.
this is because all the interactions of the newly added payment function with the other parameters are not covered by the figure co evolution alternatives for pairwise test plan version v1 with on line shopping model version v2.
existing test plan.
to evolve the test plan and reach pairwise coverage in model version v2 while optimizing the gain in pairwise coverage we present alternatives in order from left to right ct from scratch.
if we discard the entire test plan from v1 we need to create new tests.
they are detailed in the ct from scratch tab.
enhancement.
if we keep the entire test plan from v1 as is we need to add new tests to reach pairwise coverage.
the total size of the test plan is new existing .
the new tests are detailed in the test plan enhancement tab.
enhance select.
after enhancement by new tests we can remove tests from the original v1 test plan and still reach pairwise coverage.
this leads to a test plan of size new existing .
the tests are detailed in the enhance select tab.
modify enhance select.
if we modify the existing tests and add to them the payment function we need to create only one new test.
the total size of the test plan is modified new .
the tests are detailed in the modify enhance select tab.
the values that were added to the existing tests are marked with red as depicted in figure .
when examining the different alternatives it seems that in this case the modify enhance select alternative is the most costeffective since it results in the smallest number of tests in total similarly to ct from scratch however with only one new test compared to new tests in ct from scratch .
let us assume that the engineer decided to choose this alternative and transform it into an executable test plan by modifying the existing tests and creating one new test as instructed by ibm focus.
from v2 to v3.
following a change in the system s policy gift vouchers are accepted as a payment method only when the delivery time frame is immediate.
to reflect this policy change the engineer added a new constraint to the model pm giftvoucher dt immediate and committed a third model version v3.
when trying to co evolve the test plan from v2 ibm focus informs that some tests are invalidated in the new model version v3.
three options are provided view invalidated tests discard invalidated tests 238modify enhance select esec fse november lake buena vista fl usa figure the modify enhance select alternative for pairwise test plan version v1 and on line shopping model version v2.
added values are marked with red.
the is selected column indicates whether the test is a new one or an existing one.
figure tests from the test plan produced in version v2 that were invalidated by changes made to version v3.
minimal invalidated combinations are automatically detected and marked with red.
figure co evolution alternatives for pairwise test plan version v2 with on line shopping model version v3 when existing invalidated tests are repaired.
and continue without them and fix invalidated tests to match current model version.
if the engineer chooses to view the invalidated tests opt.
she will see the results as in figure .
note that ibm focus automatically detects the reason for invalidity of each test and presents it together with minimal invalidated combinations marked with red .
such combinations may be easy to manually identify in a simple toy model however it quickly becomes labor intensive and error prone to manually detect them in a more complex model with many constraints hence automated detection is of much value.
if the engineer decides to discard the invalid tests and perform the co evolution without them opt.
then the invalid tests are figure the modify enhance select alternative for pairwise test plan version v2 and on line shopping model version v3.
repaired values are marked with red.
discarded leaving the existing test plan with tests that achieve .
pairwise coverage in model version v3.
ct from scratch results in new tests however if the existing tests are kept only new tests are needed by all other alternatives.
the price for keeping the existing tests is low a total of tests instead of .
finally if the engineer opts to repair the invalidated tests opt.
then as shown in figure the existing test plan now contains all tests and achieves .
pairwise coverage.
the modifyenhance select alternative now results in only tests and only of them are new.
the other tests are repaired according to the new value assignments that appear in the modify enhance select tab marked with red as shown in figure .
ct from scratch still results in the same tests as before since it does not consider the existing test plan.
as the other alternatives do not involve modifications to the existing test plan they are not shown in this case.
co evolution of combinatorial models and test plans we now formally present our co evolution solution for combinatorial models followed by a description of our algorithm for computing it.
we use the notations defined in section and demonstrate the ideas on the running example presented in section .
.
co evolution definitions definition .
.
a combinatorial co evolution problem receives an old combinatorial test plan t s p v c a new combinatorial model s p v c and a set of interaction coverage requirements crwhich includes tuples of parameters to cover1.
a solution is a new test plan t s p v c so that t achieves interaction coverage of crins p v c .
we address the co evolution problem defined above by providing several alternative solutions each using a different series of basic transformations on t. we now define the set of basic transformation functions that we compose later to define our co evolution alternatives.
to this end tis treated as a two dimensional matrix where t j refers to test number jint and t j i refers to the value assignment to parameterpiint j .
for a set of indices k k1 .
.
.
km t j k refers to the value assignment of t j to the parameters pk1 .
.
.
pkm .
1this is the more generic form of coverage requirements which supports variablestrength test generation rather than only a single interaction level t. 239esec fse november lake buena vista fl usa rachel tzoref brill and shahar maoz we also define a special character representing an uninitialized value i.e.
if t j i then piis not assigned with any value in t j .
we term t j as a partial test if j t j .
we term it as a complete test if j t j .
since the new model s p v c and coverage requirements crare inputs common to all functions for simplicity we omit them from the formal definitions.
definition .
enhancement function .
fen s p v c s p v c .
this function creates a small as possible test plan fen t so that t fen t andfen t achieves interaction coverage ofcrins p v c .
definition .
selection function .
fsel s p v c s p v c .
this function selects a small as possible subset fsel t tso thatfsel t achieves the same interaction coverage of crastin s p v c .
definition .
projection function .
fpro j s p v c s p p v c .
this function eliminates from tthe set of parameters p p by projecting tonp p .
definition .
discard function .
fdis s p v c s p v c .
this function discards invalid tests from tas follows fdis t t t i t i s p v c .
definition .
repair function .
frep s p v c s p v v c .
this function eliminates from tthe sets of values vi vi as follows.
if t j i vi vi thent j i .
in addition it eliminates from tvalue combinations that are invalid in s p v c as follows.
for each t j j .
.
.
t for each k .
.
.
p if sat t j k c false then k k t j k .
definition .
modify function .
fmod s p v c s p p v c .
this function modifies tas follows.
it first extends tby appending the to each t j ktimes where k p p .
next for each t i j ift i j then t i j v where v vj.
the selection of vaims at maximizing the overall interaction coverage offmod t w.r.t.
s p p v c andcr.
finally we define the co evolution alternatives that we provide.
the inputs to our solution are an old test plan t s p v c a new model s p v c and interaction coverage requirements cr.
definition .
combinatorial co evolution solution alternatives .
ct from scratch ct is defined as fen .
enhancement en is defined as fen fdis fpro j t .
enhance select es is defined as fsel fen fdis fpro j t .
modify enhance select mes is defined as fsel fen fmod frep fpro j t .
modify enhance select without repair mesw is defined asfsel fen fmod fdis fpro j t .
for example in our example in section when moving from v1 to v2 the mes alternative first applies the projection and repair functions that in this case do not change tbecause no parameters values or value combinations were removed in the second model version.
it then applies the modification function which appends a value to the tests in tfor the new pmparameter followed by replacement of the values with values out of creditcard paypal giftvoucher while aiming at increasing the overall pairwise coverage of the tests w.r.t model version v2.next the enhancement function adds one new test so that the tests collectively reach pairwise coverage w.r.t model version v2.
finally the selection function does not remove any tests since all of them are needed to achieve pairwise coverage.
we note that removing an entire parameter from the model a case which does not appear in our example corresponds to functionality that was removed from the sut.
this functionality needs to be removed from the tests as well.
since removal is a simple action compared to repair or addition of functionality all our co evolution alternatives except for the ct alternative apply it via the fpro jfunction to tas a first basic transformation action.
.
computing the co evolving test plans we use a bdd based implementation for our co evolution solution.
we adapt the bdd based ct algorithm from described in section as algorithm .
we also use the itsm algorithm for test plan minimization .
in addition we introduce a new bddbased algorithm for identifying minimal invalid combinations in a combinatorial test.
in the implementation of the different basic transformation functions each of the functions is given the following inputs the new combinatorial model s p v c a bdd valid representing the set of valid tests in s p v c the interaction coverage requirements cr and the old test plan tin the form of a two dimensional matrix where t j i is the value assigned to existing test number jfor parameter pi.
each function returns a transformed test plan t which is given as part of the input list to the next function in the composition.
projection implementation .
to implement fpro j we skip the columns iintfor which pi p .
discard implementation .
to implement fdis we iterate over the values of t j .
if we identify a t j i not in vi we remove t j from t. otherwise we create a bdd t bjfort j by conjuncting the bdds of each of its parameter value assignments.
if t bj valid false we remove t j from t. enhancement implementation .
to implement fenwe use seeding a well known concept in ct to initialize a solution set with tests that must appear in it.
in this case since we only enhance the seed with new tests and do not modify it the required adaptation of algorithm is straightforward.
first we compute an array of bdds covso that for each parameter tuple c cr cov c represents the set of value tuples of ccovered by t. then we replace line with the line forc crdouncov c proj c valid cov c thus combinations that are covered by tare excluded from the coverage requirements.
the ct algorithm then proceeds as usual to produce a small set of tests sthat achieve coverage of the modified coverage requirements.
the resulting test plan is s t. repair implementation .
to implement frep we first eliminate invalid values by iterating over the values of t j and uninitializing every t j i that is not in vi .
we then create a bdd t bjfort j by conjuncting the bdds of each of its parameter value assignments.
ift bj valid false we iteratively call algorithm to locate a minimal invalid value combination in t j and then randomly choose an entry from the combination and uninitialize it in t j 240modify enhance select esec fse november lake buena vista fl usa thus turning the combination into a valid one.
we then check again whether the modified t j is valid and proceed until all minimal invalid value combination are removed from t j .
algorithm works as follows.
first it initializes two bdd arrays with prefixes and suffixes of t j i.e.
entry iin the prefix array contains the bdd representing the prefix of t j up to entry i and entry iin the suffix array contains the bdd representing the suffix of t j starting from entry t j i line .
next for each i it creates a bdd representing t j excluding t j i line .
if the bdd is invalid the algorithm proceeds recursively to find a minimal invalid combination in t j t j i line .
if no subsets are invalid then t j is a minimal invalid combination line .
the algorithm is based on the observation that if a combination of size kis a minimal invalid one then each of its ksubsets of size k 1are valid.
hence it is enough to check the validity of these k subsets.
note that since the algorithm is greedy the found invalid combination is only locally minimal and other smaller invalid combinations may exist in the test.
these combinations will be found in subsequent calls to the algorithm if they still remain in the test after removing values from the found combination.
the complexity of algorithm is o t j .
note that the bdd conjunctions are performed between tiny bdds hence constant time can be assumed for them.
the complexity of frepcomb is o t j t .
as we will show in section in practice the running time of the repair is negligible.
input an array of bdds tcrepresenting the invalid test.
the bdd valid of all valid tests.
1ifsize tc 1then return tc 2prefix tru e suffix tru e 3fori .
.
.
size tc do prefix i prefix i tc i suffix i suffix i tc size tc i 6end 7fori .
.
.
size tc do exci prefix i suffix size tc i if valid exci false then return findminimal tc tc i valid end 12end 13return tc algorithm find minimal invalid combination modify implementation .
to implement fmod we use seeding again as in fenimplementation however in this case since all partial tests in the seed have to be extended to complete ones the modification to algorithm is more complex.
we describe it below.
in addition to the modification to line as presented in the implementation of fen we also maintain a set tpof partial tests from the seed that have not been extended yet to complete ones.
we initialize tpwith all partial tests that appear in tby adding after line the line tp extractpartialtests t then in each iteration as long as tpis not empty we conjunct the bdd collected from which tests are chosen with tp to ensurethat the chosen test will be an extension of a partial one from tp.
this is performed by adding after line the lines ifsize tp 0then collected collected buildbdd tp end once a test is indeed chosen we remove from tpall the partial tests which it extends by adding after line the lines ifsize tp 0then chosenfromseed getcontained tp chosen tp tp chosenfromseed end we also record which values are added to each partial test so that we can later mark them to the user as shown in section .
once tpis empty the algorithm proceeds with enhancement.
note that by defining two separate steps for fixing invalid tests repair and modify rather than defining a single replace operation we can easily perform a reduction of the fixing problem to a seeding problem.
this is because following the repair operation the resulting partial test plan complies with the model constraints and can be used as a seed to a ct algorithm.
selection implementation .
to implement fsel we use the itsm algorithm from .
this algorithm first calculates the set cof t way tuples covered by t and then greedily iterates over the existing tests.
in each iteration it chooses a test that adds the most uncovered t way tuples out of c and adds it to the solution set s. it stops when all tuples from care covered.
the complexity of the algorithm is o s c t .
to reduce the constant factor it avoids unnecessary calculations by remembering the number of uncovered tuples from previous iterations and lazily updating it and performs efficient bit operations while counting uncovered combinations.
to reduce the size of s it prioritizes tests by giving higher weights to less frequent tuples.
the implementation of the five different co evolution alternatives follows directly from definition .
.
evaluation we present an evaluation of our work in terms of the results of our co evolution technique when applied to real world model and test plan evolution.
we then continue with a case study demonstrating the viability and necessity of our technique in achieving efficient co evolution when using ct for test design.
.
real world evidence the research questions guiding our evaluation are rq1 when the sut and therefore the model evolve to what extent can existing tests be reused as is and how much coverage will they provide?
rq2 are the co evolution alternatives we suggest effective in reducing the required number of new tests and how do they affect the total test plan size?
rq3 how much effort may be involved in modifying tests in the mes and mesw alternatives and what is the impact on their effectiveness?
rq4 how does our co evolution computation perform in terms of running time on real model and test plan versions in practice?
241esec fse november lake buena vista fl usa rachel tzoref brill and shahar maoz table corpus model version and test plan sizes percentile params aver.
values constr.
test plan per param size .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
to answer these questions we applied our co evolution technique to the evolution of a large corpus of real world models and their test plans which we have obtained from ibm.
.
.
model corpus used and setup.
we applied our co evolution technique to the evolution of real world industrial models with versions and version commits.
models have versions models have versions models have versions and one model has versions.
anonymized files of all model versions are available at according to ibm the models were written by different ct engineers over a period of years and originate from different domains firmware paas iaas file system operating system database storage analytics banking telecom security networking and software applications email document management finance etc.
.
the models also capture different levels of testing such as function test system test etc.
we did not select the models according to any criteria and they represent all data available to us from ibm.
all runs of our co evolution computation were performed on a windows dual core machine with .
and .
ghz cores and gb ram.
only one core was used in our experiments.
the bdd package used was jdd .
table presents the model and test plan sizes across the entire corpus in terms of number of parameters average number of values per parameter number of constraints and the size of the test plan as generated by the ct alternative .
we report percentiles for each of these metrics and .
for example of the model versions have or more parameters.
only of the model versions have .
or more values per parameter on average.
the percentiles show high variability in all aspects of model and test plan sizes.
they also show that many real world models and test plans are complex and large.
for evaluation purposes we treated each commit separately i.e.
for each model commit we first generated the existing test plan by running ct on the previous model version and then computed the five co evolution alternatives for the resulting test plan and the model commit.
we used pairwise coverage requirements for most of the models with the exception of several models where the engineers who originally created and used the model specified other requirements in two cases the requirements were way for a subset of the parameters and way for the others and in one case they were way for a subset of the parameters and way for the others.
.
.
results.
rq1 table shows the percentage of existing tests that were invalidated by model changes in our corpus and the interaction coverage achieved by the ones that were still valid in the new model version.
the results show that for of the commits all tests are invalidated and for of the commits moretable percentage of invalidated tests and coverage of the remaining tests in all commits.
invalidated tests invalid of commits up to to over 32coverage of tests coverage of commits up to to to to table reduction in number of new tests of each alternative and increase in total test plan size relative to the ct from scratch alternativereduction in new tests increase in total size percent.
en es mes mesw en es mes mesw .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
than of the tests are invalidated.
the results further show that for of the commits the existing tests achieve a coverage of less than of the interactions in the new model version.
to answer the results show that many of the existing tests are invalidated and that the remaining ones achieve inadequate interaction coverage in new model versions.
thus reuse as is is insufficient.
this evidence motivates the development of test evolution operations such as modification and enhancement.
rq2 table compares all alternatives to the ct from scratch alternative in terms of number of new tests and total test plan size for each of the commits.
the ct alternative potentially represents the highest number of new tests and the lowest test plan size.
note that in ct from scratch there will typically be no reuse of old tests because real world models test spaces are huge there are slim chances the algorithm will produce one of the old tests.
table left presents for each of the four alternatives its ratio of reduction in the number of new tests compared to the number achieved by ct. table right presents for each of the other four alternatives its ratio of total test plan size to the size achieved by ct. as before we report percentiles for each of these metrics.
the results show that the mes alternative achieves a very significant reduction in the number of new tests compared to the other alternatives.
for example the median reduction for mes is while it is only for en and es and for mesw.
on the other hand the price mes pays in increase in total test plan size is rather low.
for example the median increase for mes is only .
we also observe that mesw achieves the lowest overall increase in total test plan size and that es achieves a lower test plan size than en.
mesw performs better than mes because it discards invalidated tests it reuses less tests than mes so the ct algorithm has more freedom to optimize the final test plan size.
typically en and es achieve the same number of new tests because the selection building block removes only old tests as they are the only ones it may eventually find to be redundant in the new model.
242modify enhance select esec fse november lake buena vista fl usa table average number of values per test to change for mes and number of new parameter values to add for mes and mesw.
percentile aver.
changed values added values per test per test .
.
.
.
.
.
.
.
.
.
table running time for all alternatives on all model commits.
each cell represents the percentage of commits for which the coevolution computation running times was within the time frame on the left most column.
time ct en es mes mesw 1sec 10sec 1min .5min to answer the results show that the mes alternative achieves a very significant reduction in the number of new tests compared to all other alternatives while paying very little in increase in total size.
in addition mesw achieves the lowest total size increase and is always better than es in reduction in number of new tests.
es is better than en in terms of increase in total test plan size.
rq3 we estimate the effort of modification by reporting the average number of values to change per test in mes and the number of new values to add per test in mes and in mesw .
table presents these two metrics.
on the left we show the average number of values per test to change in the mes alternative for each of the commits where tests were invalidated.
the average number was calculated out of all invalidated tests only2.
on the right we show the number of new values to add per existing test in mes and mesw for each of the commits.
note that this is a single number per commit which is equal to the number of parameters added in the commit.
as above we report percentiles for each of these metrics.
the results show that a relatively low effort may be involved in modifying existing tests.
in of the commits only up to .
values per test on average need to be modified and in of the commits only up to .
.
we note that this is only a weak proxi of the actual effort as some parameters and or values may require more effort to change than others and the relative number of parameters whose values need to change out of all parameters may also affect the modification effort.
see table for the number of model parameters across commits.
for example it shows that only of the commits have or less parameters hence have more than parameters .
in addition the number of new values to add to existing tests is rather small.
in of the commits only up to new values are added.
we note that as opposed to changed values which occur in mes only new values should be added in all alternatives since any 2calculating the average value change size out of the entire test plan would further decrease it.
see figure for the percentage of invalidated tests across commits.new test plan must cover the functionality of the new parameters as well as their interaction with the old parameters.
the difference is that in mes and mesw values for new parameters may be added both to existing tests and to new tests while in the other alternatives they are added in new tests only.
to answer the results show that a rather low effort is involved in modifying existing tests in terms of number of changed values and number of added values.
hence the mes and mesw approaches are effective in practice.
rq4 table shows the running time achieved by all five alternatives on all commits.
for the vast majority of the commits the running time was almost instantaneous in up to one second in up to seconds and reached up to .
minutes in only two commits.
in addition though overall ct and en were slightly faster than the others and es slightly slower than the others there were no significant differences between the alternatives.
we note that repair time for the mes alternative was negligible in all but one case it took less than .
second and in all cases it ranged between and of the overall mes running time.
to answer the results show that all alternatives achieve excellent and similar running times in practice.
since computation is efficient there is no need for the engineer to a priori select the co evolution method instead she can choose the best alternative from the test plans produced by the tool.
.
.
threats to validity.
internal our implementation of the co evolution alternatives may not be free of bugs.
we mitigated this by extensive testing.
external first the models and versions used in the analysis might not be representative of real world model evolution.
to mitigate this threat we chose all real world models and versions available to us from ibm as described in section .
.
.
second the average number of values to change may not be a perfect proxi for the modification effort as some parameters may be more difficult to change than others.
we currently have no better means to estimate this effort on the large corpus.
.
real world industrial project we report on a real world industrial project in which our co evolution solution was used as part of the deployment of ct for test design.
maas360 is a commercial security product.
the agile development mode of maas360 dictates a release every weeks with many new features.
several qa teams consisting of more than engineers are responsible for testing different parts and aspects of maas360.
to speed up test time tests are automatically run but generating the automation scripts is a manual effort.
hence there is a clear motivation to maximize reuse of tests and their scripts.
when the qa teams of maas360 started adopting ct in order to reduce their test plan sizes to a manageable size while achieving a better sense of their test coverage they quickly stumbled upon the evolution challenge due to their frequently evolving test spaces.
their goal was to continue optimizing their test plans also during 243esec fse november lake buena vista fl usa rachel tzoref brill and shahar maoz evolution while on the one hand keeping the existing tests untouched as much as possible and on the other hand pushing into the test plan as many new changes as possible.
as they explored our co evolution solution it was obvious that running ct from scratch was not an option due to the huge automation effort wastage it will cause.
they estimated that in the long run the en approach would end up with a large bulky unoptimized set of tests.
they considered the es alternative however it did not demonstrate enough reuse of their existing tests.
thus mesw and even more so mes were the clear middle ground approaches they were looking for.
specifically for the majority of cases a change in a single model parameter amounted to a change in only one or two lines in the automation script.
test steps and expected results oracles were defined in the ct model based on parameter values and were changed together with them.
the team considered this to be a reasonable effort especially given that not many values were invalidated and had to change between different test plan versions.
thus the qa teams of maas360 adopted the modification based alternatives.
moreover they explicitly stated to us that these alternatives were necessary for them to continue using ct in their agile development process and achieve efficient test plan evolution.
we demonstrate the use of our co evolution solution for testing of maas360 on one of the many models they created which captures a specific function of maas360.
one version of the model contained parameters constraints and values per parameter on average.
the first parameters described different payload configurations.
each of the remaining parameters described specific settings related to one of the first parameters.
there were pairwise coverage requirements on the first parameters and way requirements on the others.
the initial test plan had tests.
the next version of the model contained parameters constraints and values per parameter on average.
payload configuration parameters were added along with their associated settings parameters.
in addition one value was removed from one of the original settings parameters.
this removal invalidated out of the existing tests and the other tests achieved only .
coverage in the second model version.
the ct alternative resulted in tests all of them new.
en and es resulted in tests of them new.
mesw resulted in tests similarly to ct where all existing tests were modified and new tests were required.
lastly mes resulted in only tests all of them existing modified tests no new tests were required.
the modification involved adding the new payload configurations and settings to the existing tests and changing the single invalid value in the invalidated tests.
clearly the mes alternative provided the best tradeoff in this case.
related work we discuss related work on test plan evolution in general and in the context of ct in particular.
different aspects of test plan evolution have been studied with regard to java and c code.
pinto et al.
investigated how test plans evolve specifically how tests are added removed and modified in practice.
given two versions of a program and its test plan their tool automatically computes differences in the behavior of the test plans on the two program versions classifies the actual repairs performed between the versions and computes the codecoverage attained by the tests on the two program versions.
mirzaaghaei et al.
focus on automating test plans updates.
they identify scenarios that allow either to repair tests or to use tests to generate new ones and propose algorithms that automatically repair and generate tests by adapting existing ones.
marinescu et al.
present a framework to analyse code test and code coverage evolution.
automated incremental repair of ui and web based test suites was investigated in respectively.
none of these works deals with evolution in the context of ct. qu et al.
empirically examined the effectiveness of ct on regression testing in evolving programs with multiple versions.
co evolution of the test plan and the model is not discussed in .
most recently we have presented syntactic and semantic differencing for combinatorial models using bdd based algorithms.
this work is limited to differencing between model versions.
coevolution of the test plan and the model is not discussed.
finally seeding suggested by cohen et al.
as a means for the engineer to specify tests that must appear in the solution is related to our work.
czerwonka suggests the use of seeding in the context of evolution.
we use a form of seeding based on existing tests in our enhancement and modification building blocks.
conclusion and future work in this work we propose a first co evolution approach for combinatorial models and test plans accompanied with an efficient implementation.
our approach consists of five alternatives to evolve a test plan following changes in the model from which it was derived all meeting the coverage requirements while considering tradeoffs between the total test plan size and number of new tests.
to achieve efficient co evolution they are based on three building blocks minimally modifying tests enhancing them and selecting from them.
we implemented our technique within a commercial ct tool and evaluated it on real world models with versions demonstrating the need for evolution techniques and our excellent performance times.
our results show that using all three building blocks provides an effective middle ground approach that balances between the co evolution tradeoffs.
we further report on an industrial project which adopted our solution and found it necessary to enable the use of ct in an agile development process.
we suggest the following future research.
first consider code coverage and fault finding effectiveness in the assessment of each of the alternatives provided that one has access to such data as in .
second evaluate our approach to co evolution on multiple versions over time possibly with higher interaction levels to examine the accumulated effect of our technique if such exists.
third incorporate user input about the expected effort to modify individual parameters into the algorithms to prioritise the modification of parameters that are easier to change in the test implementations.