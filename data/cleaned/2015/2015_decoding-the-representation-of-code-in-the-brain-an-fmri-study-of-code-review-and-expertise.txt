decoding the representation of code in the brain an fmri study of code review and expertise benjamin floyd university of virginia bef2cj virginia.edutyler santander university of virginia ts7ar virginia.eduwestley weimer university of virginia weimer virginia.edu abstract subjective judgments in software engineering tasks are of critical importance but can be difficult to study with conventional means.
medical imaging techniques hold the promise of relating cognition to physical activities and brain structures.
in a controlled experiment involving participants we examine code comprehension code review and prose review using functional magnetic resonance imaging.
we find that the neural representations of programming languages vs. natural languages are distinct.
we can classify which task a participant is undertaking based solely on brain activity balanced accuracy p .
.
further we find that the same set of brain regions distinguish between code and prose near perfect correlation r .
p .
.
finally we find that task distinctions are modulated by expertise such that greater skill predicts a less differentiated neural representation r .
p .
indicating that more skilled participants treat code and prose more similarly at a neural activation level.
keywords medical imaging code comprehension prose review i. i ntroduction subjective human judgments are found in all stages of the software engineering lifecycle.
indeed even when automated tools are available humans must still choose to employ them.
because of their importance many models and analyses have been proposed for such human judgments e.g.
of software readability maintainability or debugging tool output etc.
.
the number of user evaluations and human studies at top venues has grown since the year fig.
.
despite this we have almost no understanding of how the human brain processes software engineering tasks.
we propose to use medical imaging techniques to understand code comprehension and review.
functional magnetic resonance imaging fmri is a noninvasive technique for probing the neurobiological substrates of various cognitive functions in vivo .
technically fmri provides indirect estimates of brain activity measuring metabolic changes in blood flow and oxygen consumption as a result of increased underlying neural activity.
this signal is termed the blood oxygen level dependent bold response it is formally defined as the ratio of deoxygenated to oxygenated hemoglobin each of which have markedly different magnetic properties that can be detected by the mr scanner following excitation by a radio frequency pulse .
this quantifies differences in activity under various conditions both task related and at rest.
functional mri was first prototyped on humans in and has since enjoyed a meteoric rise in popularityamong both clinical and psychological researchers.
unlike other cognitive neuroscience methods e.g.
eeg or pet fmri allows for rapid sampling of neural signal across the whole brain seconds and offers high spatial resolution scale of millimeters with regard to localizing signal sources.
thus fmri arguably provides the best available measure of online neural activity in the living working human brain.
we present an fmri study of software engineering activities.
we focus on understanding code review its relationship to natural language and expertise.
we note that the use of fmri in software engineering is still exploratory to the best of our knowledge this is only the second paper to do so and is the first to consider code review and expertise.
we explore these tasks because developers spend more time understanding code than any other activity .
a nasa survey for example ranked understanding as more important than functional correctness when making use of software .
similarly with companies such as facebook and google mandating code review for new check ins code review has found an even greater practical and research prominence .
in our experiment participants are presented with three types of visual stimuli each with an associated judgment task.
in the code comprehension task participants are shown a snippet of code and asked a software maintenance question about it .
in the code review task participants are shown a github pull request i.e.
code a patch to that code and a comment and asked whether they would accept it or not.
in the prose review task participants are shown english prose with simple editing markups and asked whether they would accept the proposed edits or not.
we designed our experiment in this manner because fmri analyses are typically based on contrasts comparisons between at least two task conditions.
through our experimental controls we can isolate one feature of the tasks and observe differences in brain activation.
for example the primary difference between the prose review and code review tasks is whether the subject is english prose or a computer program any difference in observed brain activity corresponds to a task difference.
similarly a simple model might posit that code review is code comprehension followed by a code judgment i.e.
understanding what the patch will do and then deciding if it is acceptable contrasting code review to code comprehension focuses on the judgment aspect since code understanding is present in both.
mathematically the analyses ieee acm 39th international conference on software engineering ieee acm 39th international conference on software engineering .
ieee authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
we employed involved generalized linear models and gaussian process classification.
ultimately we find that the neural representations of programming and natural languages are distinct.
we can construct classifiers that distinguish between these tasks based solely on brain activity.
we observe that the same set of brain locations is relevant to distinguishing all three tasks.
in addition expertise matters greater skill accompanies a less differentiated neural representation.
the contributions of this paper are as follows we find that the neural representations of programming languages and natural languages are distinct.
this claim is supported by a model that classifies participant tasks based on brain activity in a statistically significant manner e.g.
code comprehension vs. prose review at balanced accuracy with p .
.
we find that the same set of brain locations distinguish between all of these tasks.
this claim is supported by regional importance maps e.g.
code vs. prose yields near perfect correlation r .
p .
.
we find that the neural representations of programming languages and natural languages are modulated by expertise.
greater skill predicts less differentiated representation.
that is expert brains treat code and prose tasks more similarly.
this claim is supported by an analysis revealing a statistically significant correlation r .
p .
.
we make available our study materials and de identified dataset of raw participant brain scans from participants and discuss the barriers in conducting such a study.
ii.
b ackground and motiv a tion in this section we present some relevant background on the software engineering tasks considered as well as results related to expertise and imaging.
a. code review static program analysis methods aim to find defects in software and often focus on discovering those defects very early in the code s lifecyle.
code review is one of the most commonly deployed forms of static analysis in use today well known companies such as microsoft facebook and google employ code review on a regular basis .
at its core code review is the process of developers reviewing and evaluating source code.
typically the reviewers are someone other than author of the code under inspection.
code review is often employed before newly written code can be committed to a larger code base.
reviewers may be tasked to check for style and maintainability deficiencies as well as defects.
numerous studies have affirmed that code review is one of the most effective quality assurance techniques in software development .
while it is a relatively expensive practice due to high developer input it is successful at identifying defects early in the development process.
this benefit is valuable because the cost to fix a defect often increases with the time it goes unnoticed .b.
code comprehension much research both recent and established has argued that reading and comprehending code play a large role in software maintenance .
a well known example is knuth who viewed this as essential to his notion of literate programming .
he argued that a program should be viewed as a piece of literature addressed to human beings and that a readable program is more robust more portable more easily maintained.
knight and myers argued that a source level check for readability improves portability maintainability and reusability and should thus be a first class phase of software inspection .
basili et al.
showed that inspections guided by reading techniques are better at revealing defects .
an entire development phase aimed at improving readability was proposed by elshoff and marcotty who observed that many commercial programs were unnecessarily difficult to read .
more recently a survey of over managers at microsoft found that of responders desire understandability of code as a software analytic feature placing it among the top three in their survey .
c. expertise and medical imaging as early as researchers began to measure productivity differences in computer science.
sackman et al.
reported individual differences in programming performance both in terms of programming and debugging person hours to write the program and also in terms of the resulting cpu time taken by the program of about an order of magnitude on average and up to in some cases .
while hardware performance can play a role as in doherty and thadani s influential study it does not explain all observed differences.
more recent studies have explored the relationship between personality and performance in technical roles e.g.
.
while many studies report the impact of expertise on performance in various software engineering tasks e.g.
students with at most three years of experience are less accurate at fault localization than are those with at least five since medical imaging research is so new to software engineering to the best of our knowledge there are no published results that attempt to relate performance differences to physical patterns of brain activation or anatomy.
other fields have seen more direct inquiry.
for example chi et al.
examined the role of expertise in solving and classifying physics problems .
they report a productivity difference between experts and novices but also summarize methodological explanations both expert and novice proceed to solution by evoking the appropriate physics equations and then solving them.
the expert often does this in one step however and another interesting aspect of novice problem solving is not only that they commit more errors than experts but that even when they do solve a physics problem correctly their approach is quite different .
they also describe a study in which participants classify physics problems.
while experts categorize based on the underlying solution novices focused on surface similarity e.g.
a pulley problem about force and a pulley problem about energy are similar to authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
novices .
in their view this suggests that with learning there is a gradual shift in organization of knowledge .
if so how is this shift in knowledge organization reified in the brain?
this question has been more thoroughly studied via medical imaging in the context of motor skills where differences in functional plasticity differentiate novices and experts.
experts in a specialized motor skill show increased levels of activation in regions of the brain that control fine tuned motor movements suggesting that progress from acquisition to automatization stages of motor skill learning is characterized by concomitant reduced demands on externally focused attention and executive function .
imaging studies have been conducted on monkeys humans playing golf and even humans juggling finding similar physical explanations e.g.
at the level of the functional organization of neural networks during motor planning of expertise.
maguire et al.
found via fmri that the navigation demands of being a london taxi driver stimulated brain development drivers have largerthan average relevant memory centers in their brains and the intensive training is responsible for that growth .
while psychology and neuroscience have made great strides using fmri to relate and explain expertise in terms of the brain no such investigation has been made for computing.
d. computer science and medical imaging siegmund et al.
presented the first publication to use fmri to study a computer science task code comprehension .
the focus of their work was more on the novelty of the approach and the evaluation of code comprehension and not on controlled experiments comparing code and prose reasoning.
their analyses focused on standard generalized linear models to implicate relevant brain regions by contrast we carry out a data driven approach focusing on task classification and expertise.
our work was directly inspired by theirs.
some researchers have begun to investigate the use of functional near infrared spectroscopy fnirs to measure programmer blood flow during code comprehension tasks.
in smaller studies involving eleven or fewer participants nakagawa et al.found that programmers show higher cerebral blood flow when analyzing obfuscated code and ikutani and uwano found higher blood flow when analyzing code that required memorizing variables .
fnirs is a low cost non invasive method to estimate regional brain activity but it has relatively weak spatial resolution only signals near the cortical surface can be measured the information that can be gained from it is thus limited compared to fmri.
these studies provide additional evidence that medical imaging can be used to understand software engineering tasks but neither of them consider code review or address expertise.
understanding mental processing in computer science is important for a number of reasons although this paper focuses on code comprehension review and expertise we briefly highlight six general motivations for pursuing medical imaging research related to computer science.
first to replace unreliable self reporting .
for example in human studies of maintainability three of the top four features humans self reportas relevant to their performance are actually irrelevant tab.
.
the unreliability of self reporting is not specific to computer science and has been widely studied in psychology e.g.
.
medical imaging can give accurate objective explanations of subjective processes.
second to inform pedagogy .
medical imaging has already shown patterns of brain activation to predict learning rates and memory tasks in other domains.
even something as simple as whether certain activities are processed like math or like language by the brain would help provide foundational justification for certain introductory exercises.
third to help retrain aging engineers .
medical imaging studies have found different patterns of activation across ages for other tasks.
older participants display more diffuse activation recruiting nearby brain regions to help solve problems .
knowing whether or to what degree this holds true for engineering could guide workforce retraining or allocation a growing issue e.g.
.
fourth toguide technology transfer .
since the decision to use a tool or not is made by a human subjectivity matters cf.
.
for example many developers avoid using tools with high false positive rates but humans and tools may not agree on what is a false positive .
as a concrete example a number of fault localization approaches present their output as ranked lists a form that humans dislike in this context .
better models of how and why humans make such judgments would allow researchers to focus tool design cf.
sec.
.
.
fifth to help understand expertise .
psychology and imaging studies have helped illuminate how brain structures change with expertise for other tasks including chess golf swings and taxi driving .
imaging may help us understand the long reported order of magnitude productivity gap between experienced and novice programmers e.g.
.
finally and unabashedly to provide foundational fundamental understanding .
for example given that software is statistically akin to natural language one may wonder how and when code is processed by the brain like language.
iii.
e xperimental setup and method in this section we describe our experimental protocol.
a. participants thirty five students at the university of virginia were recruited for this study.
solicitations were made via fliers in two engineering buildings and brief presentations in a third year advanced software development techniques class and a fourth year language design implementation class.
data from six individuals were removed from the present analyses either due to technical difficulties at the imaging center yielding an incomplete dataset or excessive head motion during the fmri task.
thus the final sample was comprised of individuals men women .
additional objective e.g.
gpa and subjective e.g.
self reported computing experience information was gathered about each participant.
two of the participants were computer science graduate students nine were undergraduates in the college of arts and sciences and were undergraduates in the college of engineering.
all authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
a code comprehension b code review c prose review fig.
task stimuli.
code comprehension stimuli feature true and false claims in the style of sillito et al.
.
code review stimuli include the code difference in color and with symbols as well as the git pull request message.
prose review stimuli are english paragraphs with proposed changes presented in a microsoft word track changes style.
participants were right handed native english speakers had normal or corrected to normal vision and reported no history of neuropsychological disorder.
they were also screened for basic experience in the programming language of interest.
prior to beginning the study each individual provided written informed consent for a protocol approved by the university of virginia institutional review board hsr .
monetary compensation and course extra credit were offered.
b. materials and design the experiment consisted of three tasks with unique stimulus sets code review code comprehension and prose review.
all stimuli were presented as images on a screen in the back of the mri scanner normalized to the native resolution of the projector .
items were viewed through a mirror mounted atop the head coil.
c. procedure the full experimental protocol was completed over a single session per participant.
participants first viewed an instructional video detailing task requirements and were given further verbal instruction prior to entering the mri scanner.
following an initial anatomical scan participants completed four 11minute runs of the code prose task.
in each run stimuli were presented in alternating blocks of code review code comprehension and prose review the blocks were ordered quasi randomly across runs.
all stimuli were presented for a fixed time s for prose s for code and required an accept or reject response made on an mr compatible button box held in the right hand.
participants were encouraged to respond as quickly and accurately as possible within the time allotted for each trial neural responses were considered from the start of the trial until a decision was made.
interstimulus intervals ranged from seconds and consisted of a white fixation cross displayed in the center of the screen.
after completing the fmri task participants were given a chance to review the final run outside of the scanner and offer any verbal explanations for their responses.d.
stimulus type code comprehension a code comprehension stimulus consists of a snippet of code and a candidate assertion about it figure 1a .
judging whether the assertion is true or not about the code requires comprehending the code.
for comparability with previous research we used the same code snippets as fry et al.
.
some samples were reduced slightly in size to fit the fmri projection screen and colors were inverted for readability.
nineteen total stimuli were used.
the candidate questions were also taken from fry et al.
and as thus ultimately adapted from sillito et al.
s study of questions asked by actual programmers during software evolution tasks .
for each snippet a question type appropriate to the snippet was selected at random.
assertions were inducted from questions by including the correct answer or an incorrect answer random coin flip .
assertions were used because the fmri installation only allowed yes or no answers not free form responses.
e. stimulus type code review a code review stimulus consists of an historical github pull request including the code difference and the developer comment figure 1b .
participants are asked to review the change and indicate whether they would accept it or not.
a pool of candidate pull requests were selected by considering the top c repositories on github as of march and obtaining the most recent pull requests from each.
we considered the pull requests in a random order and filtered to consider only those with at most two edited files and at most modified lines as well as those with non empty developer comments the first twenty valid requests were used.
code was presented using the github pull request web interface simplified and inverted for readability.
f .
stimulus typ e3 p r o s er e v i e w a prose review stimulus consists of a snippet of english writing marked up with candidate edits figure 1c .
participants are asked to review the changes and indicate whether they would accept them or not.
we included two sources of english writing.
first we selected random chapters from an authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
english writing textbook that provides explicit correct and incorrect versions of candidate sentences and created examples based on grammar rules contained in those chapters.
we created stimuli of this type.
second we selected random exercises in paragraph improvement from the college board s sa t study guide .
each such exercise has a paragraph and a series of questions about how to improve various parts of it we created stimuli by applying or reversing all of those changes.
prose review edits are shown via microsoft word track changes .
iv .
fmri a nalysis approach in this section we describe fmri data capture and the mathematical analyses and modeling applied.
since this sort of analysis is less common in software domains we describe all steps in significant detail.
however our key areas of novelty are the overall experimental design the use of binary gaussian process classification to distinguish between code and prose tasks section iv d and our construction of interpretable weights for brain regions section iv i .
by contrast the majority of individual steps taken e.g.
correcting for anatomy denoising cross validation etc.
are all well established best practices for fmri.
in essence this multi step analysis is necessary because of the high dimensionality of medical imaging data the timeseries nature of the tasks the lag inherent in the bold signal and our desire to both classify tasks and implicate brain regions.
a. data acquisition we employed state of the art imaging techniques using protocols obtained from the human connectome project hcp a massive multi site effort to uncover the brain networks underlying human cognition .
these enabled rapid parallel sampling of the bold signal across the whole brain offering higher temporal resolution than standard protocols.
they are also typically more robust to other artifacts that plague data quality e.g.
small head movements .
mr signals are acquired in 3d voxels volumetric pixels that define a grid like matrix over the brain.
however a full fmri dataset is truly four dimensional 3d spatial time .
all mr data were collected on a 3t siemens magnetom tim trio mri system using a channel head coil.
our functional mr scans employed a t2 weighted multi band echo planar imaging mbepi sequence sensitive to the bold contrast tr s te ms fa acceleration factor .
whole brain coverage was collected in interleaved slices mm slice thickness 3mm in plane resolution .
a total of volumes were acquired for each of the four task runs.
as a result of this process a single participant completing four minute runs produces floating point numbers of data voxels volumes runs .
highresolution anatomical images strictly 3d by contrast were collected using a t1 weighted magnetization prepared rapid gradient echo mprage sequence tr .
s te .
ms fa slices mm thickness .b.
data preprocessing prior to any statistical analysis fmri data must be extensively preprocessed which serves to correct systematic noise in the data e.g.
due to head motion and align brains to a standard spatial template.
this allows for straightforward comparison across subjects.
here preprocessing and initial statistical modeling were performed using the statistical parametric mapping software in matlab.
standard preprocessing procedures were employed.
first functional data were realigned and unwarped to correct for participant head motion.
high res anatomical images were coregistered to the functional scans all data were subsequently normalized to the montreal neurological institute mni template cf.
.
no spatial smoothing was applied to the functional data.
c. generalized linear models following preprocessing it is conventional to estimate within subject general linear models glms to determine how the bold signal changes across various task related events conditions.
typically all trials for a given condition are collected in a single regressor yielding an average bold response.
however here we isolated unique neural responses by estimating a single glm per trial.
this procedure described by mumford et al.
was necessary to avoid confounds related to hemodynamic lag when applying machine learning models to trials in an fmri timeseries.
for each glm one regressor modeled the bold response for the current trial of interest event duration was curtailed at the participant s response time and a nuisance regressor modeled all other trials within the run.
the bold timeseries were high pass filtered s and convolved with the canonical hemodynamic response function to estimate the unique neural response to each stimulus.
as an additional denoising step we estimated models using robust weighted least squares rwls this approach optimizes our measurement of trialwise bold responses by giving less weight to images with large noise variance.
the end result of this process is a pseudo timeseries of parameter estimate images beta images where each voxel s value describes the extent to which it is activated on a given trial accounting for hemodynamic lag .
these were subsequently used as training examples for withinsubject machine learning models.
missed trials i.e.
where no response was given were excluded.
d. multivariate pattern analyses we used gaussian process classification gpc to determine the extent to which code and prose tasks elicited similar patterns of brain activity.
if code and prose are processed using highly overlapping brain systems classifier accuracy would be low reflecting entangled patterns of activity.
these so called multivariate pattern analyses were implemented in matlab using the gaussian processes for machine learning software v3.
.
classification is performed in a two step procedure the machine is first trained to identify patterns of activity corresponding to two stimulus types code or prose authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
and learning performance is then tested using new images without class labels.
e. inputs and feature selection the extremely large dimension of fmri data is a major obstacle for machine learning we commonly have tens of thousands of voxels but only a few dozen training examples.
this can be solved using a simple linear map a kernel function that reduces the dimensionality of the feature space .
to begin training inputs features were given as a set of vectors xn n n with corresponding binary class labels yn n n where nis the number of beta images for a given participant across both classes .
because any given beta image is a 3d matrix of voxels we can easily reshape it into an input vector xn.
the dimensionality of the feature vector is equal to the number of voxels used for pattern identification for these analyses we reduced the feature set to voxels contained across regions of the cerebrum defined by the automated anatomical labeling aal atlas .
the aal atlas allowed us to probe whole brain patterns across the same voxels for all participants.
for additional feature reduction we computed a simple n nlinear kernel whose elements indicated the degree of similarity between all pairs of input images.
f .
gaussian process classification gaussian processes treat the classification problem as an extension of the multivariate gaussian defined by a covariance function that is used to make predictions for new data conditioned on a training set .
we elected to use gpc over other common methods e.g.
the support vector machine for several reasons predictions are made by integrating over probability distributions vs. hard linear decisions model hyperparameters and regularization terms are learned directly from the data vs. costly nested cross validation routines and maximum likelihood is robust to potential imbalances in class size which otherwise bias linear classifiers toward predicting the more common class.
gps have also been successfully used in previous neuroimaging work to decode distinct cognitive states as we do here to distinguish healthy individuals from clinical populations and even to predict subjective experiences of pain .
the technical minutiae of gpc analysis have been described in detail previously .
prior to training a gp is defined entirely by its mean vector and covariance function k. the covariance function is parameterized as k l2xxt where l2is a learned scaling parameter and xxtgives the linear kernel.
the goal of gp based machine learning is then to identify optimal covariance parameters that allow for accurate predictions of new data.
however because binary classification is by nature non gaussian all y we adopt a function space view of gps that models a latent distribution over functions f x given the data d x y .this distribution is used to estimate relationships between the training data and make predictions for new examples.
to learn such a mapping we employ a cumulative gaussian orprobit likelihood and specify the posterior conditional over fusing bayes rule p f d n f k p d n productdisplay n 1 ynfn where n f k is a zero mean prior ynfn is a factorization of the likelihood over training examples and p d gives the model evidence or the marginal likelihood of the data given a vector of hyperparameters .
training therefore involves finding the optimal form of k by scaling model hyperparameters and maximizing the log model evidence.
g. expectation propagation class predictions for new images were made using expectation propagation ep .
this was necessary because the probit likelihood and the posterior are both non gaussian making exact inference analytically intractable.
ep algorithms allow us to reformulate the posterior as a gaussian and approximate the distribution of the latent function at a new test point x p y d x integraldisplay f q f d x df parenleftbigg radicalbig 2 parenrightbigg where q f d x gives the ep approximation to a gaussian.
importantly we still obtain a true probabilistic inference by integrating over the latent posterior.
the obtained class probability is converted to a binary class label by inverting the logarithm t ep braceleftbigg t .
y t .
y the .
threshold is non arbitrary owed to the symmetry of the cumulative gaussian.
h. testing and training we mitigated overfitting via careful cross validation and estimated unbiased measures of classification performance.
together these offered a robust means of testing the extent to which gpc could distinguish between code and prose related patterns of activity.
ultimately three binary gpc models were trained and tested for each participant code review vs. prose review code comprehension vs. prose review and code review vs. code comprehension.
predictive performance was assessed using a leave one run out cross validation lorocv procedure.
for each fold of loro cv the data from one scanning run were removed from the kernel.
the kernel was then centered according to the remaining training examples the model was fit and class predictions were made for the leftout data.
given that all participants did not necessarily have equal numbers of code prose examples average performance across all cv folds was estimated as the balanced accuracy bac or the arithmetic mean of the two class accuracies.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
a code comprehension vs. prose review b code review vs. prose review fig.
average weight maps for task classifiers.
when regions of the brain colored hot are active the decision is pushed toward code.
the left and right subfigures show a high degree of concordance r .
p .
quantifying how both code tasks are distinguished similarly compared to the prose task.
i. regional inference we next sought to determine which regions of the brain were most involved in discriminating between code and prose.
this involved projecting kernel weights back onto the 3d brain for display purposes we present weight maps that were averaged across cv folds and participants.
it is worth emphasizing however that such multivariate maps do not lend themselves to simple regional inference because the final classification decision depends on information across all voxels it is incorrect to assume voxels with high weight are the most important.
nevertheless we may estimate a posteriori the total contribution of each anatomical area in the aforementioned aal atlas .
in this procedure the absolute values of all voxel weights within a brain region were summed and divided by the total number of voxels in the region.
then each region s contribution strength was divided by the sum of strengths for all regions yielding a proportion that is directly interpretable as regional importance a larger value indicates more total weight represented within a region .
these importance maps are also presented as a group average.
v. r esults and analysis in this section we present our experimental results focusing on the analysis of the raw participant data obtained from the experimental protocol in section iii.
we focus our analysis on three research questions rq1 can we classify which task a participant is undertaking based on patterns of brain activation?
rq2 can we relate tasks to brain regions?
rq3 can we relate expertise to classification accuracy?
a. rq1 task classification we assess if our learned models can classify which task a participant is performing based solely on patterns of brain activity.
we consider the three tasks code review code comprehension and prose review pairwise.
since not all participants completed the same number of trials e.g.
some participants completed more prose trials than others we first sought to ensure that this difference was not biasing classifier accuracy.
median bac was compared for each of the three models using nonparametric wilcoxon rank sum tests .
there were no significant differences in classification performance for either review vs. prose models z .
p .
or comprehension vs. prose models z .
p .
suggesting that gpc s ability to discriminate between code and prose tasks was not driven by the number of prose trials completed.
this also held when considering only prose class accuracy in both review vs. prose models z .
p .
and comprehension vs. prose models z .
p .
.
a full set of summary statistics for classifier performance are displayed in table i. with regard to overall classifier performance we employed nonparametric wilcoxon signed rank tests to compare model bac against a null median accuracy of chance for a binary classifier .
for all models gpc performance was highly significant.
the classifiers accurately discriminated between review vs. prose trials bac .
z .
p .
comprehension vs. prose trials bac .
z .
p .
and even review vs. comprehension trials bac .
z .
p .
.
these results suggest that code review code comprehension and prose review all have largely distinct neural representations.
inspection of the average weight maps for each code vs. prose model figure revealed a similar distribution of classifier weights across a number of brain regions here hot voxels push the decision function towards code with greater activation while cool voxels indicate the reverse .
correlating the voxelwise values confirmed a high degree of concordance r .
p .
indicating that on average similar patterns of activity distinguished between code and prose regardless of which code task was being performed.
in addition to the average classifiers our highestperforming code vs. prose models also conserved the weight distributions across tasks.
for space reasons we only present averages across all participants showing the similarity in weight distributions.
this general similarity helps explain why code review and code comprehension less separable than code vs. prose indicated by lower classification accuracy .
b. rq2 regional inference we investigate the relationship between tasks and particular brain regions.
compared to rq1 which investigated whether classification was possible rq2 looks at the brain areas most involved in that classification and examines their traditional roles and importance.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
class class overall model accuracy zp accuracy zp b a c zp review vs. prose .
.
.
.
.
.63e .
.
.34e comprehension vs. prose .
.
.
.
.
.94e .
.
.38e review vs. comprehension .
.
.32e .
.
.
.
.
.70e table i summary statistics for classifier performance.
median accuracies are given across participants test statistics and probabilities are derived from nonparametric wilcoxon signed rank tests.
a code comprehension vs. prose review b code review vs. prose review fig.
average regional importance maps for task classifiers.
hot colors indicate areas containing a greater proportion of the total classification weight over all aal defined regions .
these proportions are directly interpretable such that extreme red regions are twice as important as light green regions.
the left and right subfigures show a near perfect correlation r .
p .
highlighting the same brain regions as important for both code tasks in general vs. the prose task.
fig.
negative relationship between classifier performance x axis and expertise gpa shaded confidence interval.
as with the average multivariate weight maps average regional importance maps for both code vs. prose classifiers demonstrated remarkable overlap figure .
a correlation between importance maps yielded a near perfect correspondence r .
p .
.
for both classifiers a wide swath of prefrontal regions known to be involved in higher order cognition executive control decision making language conflict monitoring etc.
were highly weighted indicating that activity in those areas strongly drove the distinction between code and prose processing.
we also observed fairly large contributions from voxels near wernicke s area in temporoparietal cortex a region classically associated with language comprehension.
together these results suggest that language sensitive areas of the brain were differentially recruited when processing code versus english prose.
thus on average programming and natural languages exhibit unique neural representations.c.
rq3 expertise we examine the relationship between classifier accuracy and participant expertise.
in light of the observed variability in classification performance across individuals coupled with stark differences in multivariate weight maps between the highest and lowest performing models not shown we tested whether bac predicted one s programming expertise.
as a proxy for expertise we obtained undergraduate gpas counting only courses from the computer science department.
these were corrected by the total number of cs credits taken a .
gpa with credits presumably does not indicate equal expertise to a .
gpa with credits a simple linear regression was specified predicting computer science gpa from completed credits and the residualized gpas were extracted for subsequent analysis.
this allowed us to consider gpa as a skill indicator independent of the number of credits completed.
we then computed the correlation between expertise and classifier accuracy for both of the code vs. prose models.
discriminability performance in code review vs. prose models was not related to expertise r .
p .
.
however the extent to which classifiers distinguished between code comprehension and prose significantly predicted expertise r .
p .
see figure .
the inverse relationship between accuracy and expertise suggests that as one develops more skill in coding the neural representations of code and prose are less differentiable.
that is programming languages are treated more like natural languages with greater expertise.
d. analysis summary we employed a data driven machine learning approach to decode the neural representations of code and prose from multivariate patterns of brain activity.
this technique is advantageous because it allows us to probe spatially correlated authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
activations across the whole brain simultaneously.
binary gaussian process classifiers significantly predicted when a participant was performing code related tasks relative to prose review it also distinguished between the two code tasks though to a lesser extent.
this latter observation is consistent with the remarkable spatial overlap both qualitatively and quantitatively between multivariate classifier weights in code vs. prose models suggesting that the code tasks were largely represented similarly on average.
this was confirmed by nearly identical a posteriori estimates of regional importance a number of prefrontal regions reliably distinguished between the code and prose tasks accounting for most of the weight in the whole brain classification models.
importantly however the extent to which these tasks were separable depended on one s expertise in programming in the brains of experienced programmers code and prose were nearly indistinguishable.
vi.
t hrea ts to validity although our analyses show that neural representations of programming and natural languages are distinct and this distinction reduces with expertise this may not generalize.
one threat to validity associated with generalizability is that our code comprehension code review and prose review stimuli may not be indicative.
for example all code stimuli were in c and all prose stimuli were in english.
while our examples are not multi language we approach generality by choosing code changes at random from real world projects and using established standardized test questions.
another potential threat relates to construct and content validity whether or not our tests measure what they claim to be measuring e.g.
code comprehension or code review .
we mitigate this threat by posing types of questions known to be asked by programmers during software evolution tasks and presenting code review as it would appear to a remote github user.
however there are aspects of these tasks not covered by our current experiments e.g.
code review may also contain a back and forth conversational component .
our use of gpa as a proxy for expertise introduces an additional threat to validity.
measuring participant expertise is difficult and the metrics used are often domain specific.
for example in specification mining the number of edits to version control repositories has been used as a proxy for expertise while research related to community question answering sites may proxy of expertise based on counting or profiling .
gpa has been shown to be a correlate of learning and academic aptitude e.g.
.
finally the high dimensionality of fmri images and the complex mathematical methods required to analyze them often necessitate conservative corrections for false positives and or strong assumptions about the underlying data that may or may not be met by reality .
for example in standard glmbased analyses of fmri data tens of thousands of statistical tests are run across the brain in a voxelwise fashion requiring careful correction for multiple comparisons.
in a highlypopularized article eklund et al.
found that fmri data oftenfail to meet the assumptions required for a certain clusterbased approach to multiple comparisons correction this method offered by nearly all common software packages for fmri analysis can therefore result in false positive rates of up to .
a key advantage to our multivariate approach is that all voxels are considered simultaneously precluding the need for voxelwise multiple comparisons correction.
however this approach does preclude the sort of directed regional inference of standard glm based tests cf.
.
vii.
c osts and reproducible research while we believe fmri studies in software engineering are quite important they remain rare i.e.
to the best of our knowledge this is only the second published instance .
in this section we frankly discuss the actual costs of carrying out this study in the hope that other researchers may carry out similar studies in the future.
we note that of the four most common perceived barriers reported by software engineering researchers against the use of human studies fmri experiments heavily involve all four recruiting experiment time phrasing research questions and the irb.
a recruiting fmri constrains recruiting.
most directly remote participation such as via amazon s mechanical turk crowdsourcing cf.
is not possible.
in addition there are fmri specific filters such as the exclusion of pregnant women nearsighted people with glasses but not contacts and the left handed because the location of language processing in the brain strongly depends on handedness .
despite this we found recruiting to be quite easy.
with brief advertisements in two cs classes reimbursements and offering participants high resolution scans of their brains that can possibly be 3d printed we found participants.
b time and cost experiment time and cost are significant concerns for fmri studies.
one hour is about the maximum time that a participant can comfortably remain in the device.
with pre and post screening each participant thus takes about minutes and each participant must be separately supervised by one or two researchers i.e.
researchers listening to the participant via the intercom cannot leave the room during a scan .
in addition fmri scan time is expensive about per hour at our institution.
while both the fmri costs and participant reimbursement can be paid for by an nsf grant with the appropriate budget justification and program manager permission this is a significantly higher monetary cost than the usual software engineering human study.
the data acquisition in this paper represents a participant and machine cost of and .
hours of graduate student time.
in addition while most fmri setups include a projectorand mirror display they may not be sufficient to show multiple lines of code clearly.
we purchased an additional lens to present indicative multi line coding stimuli clearly.
c research questions the nature of the bold signal measured by fmri influences experiment design.
notably tasks in which participants are performing the same activities at the same time intervals are favored.
similarly the contrasting subtractive nature of fmri analysis forces certain authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
experimental controls.
informally fmri cannot illuminate x directly researcher must formulate tasks yandzsuch that x is the difference between them.
in addition the limited range of participant actions available restricts the range of tasks for example without a keyboard no new coding is possible but see section viii .
in general however we found research question design to be fairly direct given consultations with psychology researchers who had fmri experience.
d irb an institutional review board or ethics board governs acceptable human study research at a university.
irbs often distinguish between medical research and other e.g.
social or behavioral research fmri studies fall into the heavily regulated medical category.
at the university of virginia the non medical irb protocol form involves six questions with responses those questions plus potentially a few others involving compensation comprise what is normally meant by the burden of irb approval .
the medical irb paperwork necessary for this study involved questions in the cover sheet alone and the main protocol was pages compared to for non medical .
in addition since brain scans are hipaa protected data a four page data protection and privacy plan was required.
e reproducible research to mitigate these costs we have made our irb protocol experimental materials and raw de identified scan data publicly available at virginia.edu fmri .
this allows other researchers to conduct alternate analyses or produce more refined models without the expense of producing this raw data.
there are instances of new papers published from archived human study data e.g.
from we hope that the same will happen here.
f lessons learned one of the more difficult aspects of our experimental design was balancing ecological validity i.e.
are the code review and code comprehension activities undertaken by the subjects indicative of the real world with the constraints of fmri scanning.
the available button press device precluded scrolling requiring all stimuli to fit on one screen.
the scan duration and data analysis precluded multi minute tasks.
we were also surprised by the number of mechanical difficulties in the fmri apparatus that resulted in discarded participant runs i.e.
six out of .
on a positive note we were surprised by the number of willing students interested in obtaining a personal 3d printed brain model.
viii.
f uture work in this section we briefly describe three avenues for future research both to give a sense of possible extensions and also to encourage collaboration from interested researchers.
first one could adapt this protocol to study the impact of social relationships and patch provenance on code review.
we propose to present patches as being written by for example a long time co worker an offshore subcontractor an automated tool a recent hire a deceptive adversary or the experimenter in the room.
results in psychology suggest that perception of authority is enough to sway judgment in such cases .
similarly medical imaging research has shown that humans use different brain circuitry for social processing and cheatingthan for other types of reasoning .
on the software engineering side there is significant interest in the judgment of patch quality from various sources .
however the extent and mechanism of mental biases in code review are not fully understood.
this experiment also has the advantage that portions of it can be conducted without medical imaging.
second we are interested in a more thorough study of expertise.
we envision collaboration with a research lab interested in mirroring our current protocol one set of participants would be undergraduate and graduate university students another would be industrial researchers with years of experience.
such a study might also explore code familiarity by drawing stimuli from codebases the experts or students had worked on.
the small performance differences observed between students with two additional years of experience do not equal the order of magnitude reported in general .
an imaging experiment involving actual expert programmers would allow us to determine in what way programming expertise changes the brain cf.
.
finally our current experiments involve only reading code.
this constraint is largely pragmatic standard keyboards cannot be deployed near fmri magnets.
however with minor cable modifications we were able to adapt a silicone and plastic keyboard and obtain approval for its use in our fmri.
this would allow for the direct observation of patterns of brain activation while participants are writing code both from scratch and to patch existing software.
ix.
s ummary this paper presents the result of a controlled experiment in which code comprehension code review and prose review tasks are contrasted against each other using functional magnetic resonance imaging.
siegmund et al.
asked whether following dijkstra good programmers need good native language skills and explored code but not language or expertise .
hindle et al.
found that most software admits the same statistical properties and modeling as natural language .
the work presented here in some sense bridges that gap explicitly relating software natural language and expertise.
we argue at a high level that medical imaging studies in computer science have the potential to shed light on multiple unresolved problems e.g.
unreliable self reporting pedagogy retraining aging developers technology transfer expertise and the relationship between software and natural language .
we acknowledge that the work presented here is still quite exploratory a full quantitative theory relating code prose and expertise remains distant.
we also acknowledge the time and material costs of such studies and make our materials and data available inviting collaboration on future work.
empirically we find that the neural representations of programming and natural languages are distinct.
our classifiers can distinguish between these tasks based solely on brain activity.
we find that the same set of brain locations is relevant to distinguishing all three tasks.
finally we find that expertise matters greater skill accompanies a less differentiated neural representation.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.