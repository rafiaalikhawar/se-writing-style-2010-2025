distance based sampling of software configuration spaces christian kaltenecker alexander grebhahn norbert siegmund jianmei guo sven apel university of passau germany university of weimar germany alibaba group china abstract configurable software systems provide a multitude of configuration options to adjust and optimize their functional and non functional properties.
for instance to find the fastest config uration for a given setting a brute force strategy measures theperformance of all configurations which is typically intractable.addressing this challenge state of the art strategies rely on ma chine learning analyzing only a few configurations i.e.
a sampleset to predict the performance of other configurations.
however to obtain accurate performance predictions a representative sample set of configurations is required.
addressing this task different sampling strategies have been proposed which comewith different advantages e.g.
covering the configuration spacesystematically and disadvantages e.g.
the need to enumerateall configurations .
in our experiments we found that mostsampling strategies do not achieve a good coverage of theconfiguration space with respect to covering relevant performancevalues.
that is they miss important configurations with distinctperformance behavior .
based on this observation we devise a newsampling strategy called distance based sampling that is based on a distance metric and a probability distribution to spread theconfigurations of the sample set according to a given probabilitydistribution across the configuration space.
this way we coverdifferent kinds of interactions among configuration options in thesample set.
to demonstrate the merits of distance based sampling we compare it to state of the art sampling strategies such ast wise sampling on 10real world configurable software systems.
our results show that distance based sampling leads to moreaccurate performance models for medium to large sample sets.
i. i ntroduction modern software systems can be configured by users to adapt them to specific devices operating systems and requirements.configuration options often have a significant influence onnon functional properties such as performance or energy con sumption.
despite the benefits of configurability identifyingthe performance optimal configuration for a given setting isoften a non trivial task due to the sheer size of configurationspaces and potential interactions among configuration op tions .
to identify the performance optimal configura tion of a configuration space one can measure the performanceof every valid configuration of the software system in a brute force manner which usually does not scale.
to avoid measuring all configurations machine learning techniques such as multiple linear regression and classi fication and regression trees have been used to learna performance model based on a set of valid configurations called the sample set.
a performance model allows us to predict the performance of a configuration and it can be usedby an optimizer to determine the performance optimal con figuration .
to create an accurate performance model the sample set must be well chosen which is a non trivialtask especially when no domain knowledge is available.
inessence selecting a small valid and representative sample setis key to efficiency and accuracy of performance prediction asperformance measurements are usually costly in practice .
several sampling strategies have been proposed which differ in their methods of selecting the sample set atrandom by using an off the shelf constraintsolver or by aiming at a certain coverage criterion e.g.
selecting each configuration option at least once .
naturally all sampling strategies come with advantagesand disadvantages as we will discuss in section ii.
the mainidea is often to cover the configuration space such that oneobtains a representative sample set which ideally includes both influential configuration options and interactions amongoptions relevant to performance so that accurate performancemodels can be learned.
in general a uniform coverage of the configuration space is desirable to obtain a representative sample set when noprior knowledge is available since it tends to be unbiasedwhen covering the configuration space.
however it is far fromtrivial to ensure unbiased uniformity if there are non trivialconstraints among configuration options.
to achieve the goal ina light weight way we propose a new sampling strategy calleddistance based sampling that addresses the shortcomings ofexisting strategies as we will discuss next.
random sampling strives for covering the configuration space uniformly but current strategies do not scale whenconstraints exist .
in fact randomly selecting indi vidual configuration options to retrieve a valid configu ration is often impractical 1due to complex constraints among configuration options.
alternatively one can usea constraint solver to enumerate all valid configurationsand randomly draw from this whole population which is intractable either due to the sheer number.
coverage oriented strategies focus on specific areas or properties of the configuration space such as specifickinds of interactions as in t wise sampling .
this mightbe the optimal way to sample if we would know in 1when randomly selecting options of the linux kernel there was not a single valid configuration even after one million trials .
ieee acm 41st international conference on software engineering icse .
ieee authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
performance frequencywhole population c a performance frequency b wise s performance frequency c distance based s performance frequency d solver based s fig.
the performance distribution of a the whole population of ll vm see section iv c the sample set selected b by3 wise sampling c by distance based sampling and d by solver based sampling.
in wise sampling some high performance values are missed leading to a skewed distribution whereas distance based sampling resembles the distribution from the whole population better.
advance where to sample but this is usually not the case for large software systems.
for example figure a shows the distribution of performance values x axes for the whole population of ll vm whereas figure b shows the distribution of a sample set obtained by wise sampling.
we observe a left skewed distribution of the sample set that does not match the distribution of the whole population well.
in contrast our distance based sampling shown in figure c tends to maintain the original distribution which eases learning a performance model.
a better coverage of the performance distribution increases the representativeness of the sample set .
some strategies use an off the shelf satisfiability solver for sampling without enumerating all configurations.
as we show in figure d this results in sample sets that seem to maintain the original distribution but the produced configurations tend to be locally clustered which may miss relevant interactions .
though simple and efficient this strategy provides no guarantees regarding spread of the sample across the configuration space.
the key idea behind distance based sampling is to produce a sample set that covers the configuration space as uniformly as possible or following another given probability distribution .
to this end distance based sampling relies on a distance metric and assigns each configuration a distance value .i t further relies on a discrete probability distribution to select configurations according to their distance values from the configuration space.
it differs from other sampling strategies in that it spreads the selected configurations across the configuration space according to a given probability distribution and is able to resemble the performance distribution of the whole population it does not require an analysis on the whole population and it uses internally a constraint solverfor efficiency while avoiding locally clustered sample sets.
in summary our contributions are as follows we define a new distance based sampling strategy that is based on a given discrete probability distribution and a distance metric for configurations of software systems.
we perform an empirical study to compare our sampling strategy with other widely used sampling strategies learning performance models for popular real world software systems.
we find that distance based sampling achieves better results in terms of prediction accuracy and robustness than other sampling strategies.
to further improve the diversity of the sample set we devise an optimization of distance based sampling by iteratively forcing the selection of the least frequently selected configuration option for configurations with the same distance.
the optimization leads to a significantly higher robustness and significantly better prediction accuracy of distance based sampling.
we show that our strategy incurs a lower computing effort than other sampling strategies and that it is more flexible in that the probability distribution it relies on can be exchanged on demand.
all experiment and replication data are available on a supplementary website2.
ii.
p reliminaries in this section we introduce basic concepts of configurable software systems.
furthermore we provide an overview of state of the art sampling strategies from which we derive the motivation for distance based sampling.
a. configurable software systems a configurable software system offers a set oof configuration options.
in this work we concentrate on binary configuration options which take only the values deselected and selected .
the set of all valid configurations is denoted as c which we will refer to as whole population .
a configuration c c is a function c o which assigns either if option ois selected or if option ois not selected to each configuration option o o .
we call a configuration option o o mandatory if c c c o that is the configuration option is selected in every configuration.
in practice not all combinations of configuration options are valid i.e.
c o due to constraints among configuration options.
constraints can be expressed in terms of propositional formulas over the set of configuration options.
for instance in a compression library offering two compression algorithms rar and zip exactly one of these compression algorithms has to be selected to obtain a valid configuration.
the corresponding boolean expression would be zip rar zip rar .
the constraints among configuration options are often combined in a variability model .
for complex systems such constraints are the reason that the acquisition of the whole population is time consuming.
hence selecting only few instead of all configurations is advisable as we describe next.
data authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
b. sampling sampling is the process of selecting a subset s c of all valid configurations cof a given configurable software system.
there are different strategies for this random sampling solverbased sampling and coverage oriented sampling.
random sampling one way to create a sample set is by randomly assigning either 0or1to each configuration option for each configuration .
however it is very likely that many invalid configurations are selected this way due to unsatisfied constraints which makes this strategy inefficient.
chakraborty et al.
use hash functions to split the configuration space recursively in multiple regions and they select configurations from each of the regions.
still this strategy produces many invalid configurations.
chen et al.
use a distance metric to find different test inputs for methods to uniformly cover the configuration space.
however they do not consider constraints among the input variables and thus produce many invalid configurations.
oh et al.
encode a system s configuration space using a binary decision diagram.
this way they can represent and enumerate all configurations in a compact way such that they can randomly draw configurations.
however construction time and memory consumption of binary decision diagrams are high and they do not scale to the largest configurable software systems .
gogate and dechter propose a random sampling strategy that uniformly selects configurations without enumerating all configurations using the monte carlo method.
this strategy also selects invalid configurations though.
solver based sampling many strategies use an off the shelf constraint solver such as sa t4j3 for sampling.
naturally these strategies do not guarantee true randomness as in random sampling.
often the sample set consists only of the first ksolutions provided by the constraint solver and the internal solver strategy is typically to search in the neighborhood of an already found solution.
hence the result is a locally clustered set of configurations.
to weaken the locality drawback of solver based sampling henard et al.
change the order of configuration options constraints and values in each solver run.
this strategy which we call henceforth randomized solver based sampling increases diversity of configurations but it cannot give any guarantees about randomness or coverage.
as we will show in our evaluation this strategy requires to rebuild the entire solver model from scratch at each solver call i.e.
selection of one configuration which is computationally expensive.
coverage oriented sampling coverage oriented sampling strategies optimize the sample set according to a specific coverage criterion.
one prominent example is t wise sampling .
this sampling strategy selects configurations to cover all combinations of tconfiguration options being selected.
for instance pair wise t sampling covers all pairwise combinations of configuration options being selected.
to identify the influence of pairs of configuration options featuresperformance whole population c featuresperformance t wise featuresperformance distance based featuresperformance solver based t t t s s s a b c d fig.
distribution of configurations of ll vm see section iv c based on their distance value and their performance for a the whole population a sample set selected b by t wise sampling c by distance based sampling and d by solver based sampling with the same sample size as t wise with t t and t respectively.
and not to be affected by influences of other configuration options siegmund et al.
improves t wise sampling by additionally minimizing the number of other selected configuration options in each configuration.
another strategy aims at a balanced selection and deselection of all configuration options in the sample set.
sarkar et al.
showed that such a frequency based sampling further improves the accuracy of performance models learned based on the sample set .
other coverage oriented sampling strategies are for example statement coverage sampling or most enabled disabled sampling .
statement coverage sampling is a white box strategy in which the configurations are selected such that every block of optional code from the software system is selected at least once whereas most enabled disabled sampling selects just one configuration where all configuration options are selected and one where all configuration options are deselected.
the main problem of these strategies is that they require prior knowledge to select a proper coverage criterion.
thus depending on the coverage criterion specific regions of the configuration space are emphasized as shown in figure we see that a higher number of selected configuration options leads to higher performance values and contains information from interactions among multiple configuration options.
since t wise sampling focuses only on a specific part of the configuration space e.g.
configurations with distances between 2and5 we miss certain performance values in the sample set e.g.
greater than seconds .
by contrast a sample set that covers all performance values is more representative as it resembles the whole population better.
moreover not every configuration option interacts with any other so not all pairs are relevant.
so the sample set is likely unnecessarily large.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
iii.
d ist ance b ased sampling distance based sampling aims at covering the configuration space by uniformly or according to another given probability distribution selecting configurations with different distance values and therewith interaction degrees without relying on a whole population analysis.
in section iii a we describe the basic algorithm in section iii b we present an optimization that further increases the diversity of the sample set.
a. basic algorithm the key idea to spread the sample set across the configuration space to increase diversity in the sample set is to use a distance metric in combination with a discrete probability distribution e.g.
a uniform distribution or a binomial distribution .
algorithm distance based sampling input vm numsamples probabilitydistr output sampleset 1sampleset 2while othersolutionsexist vm sampleset and size sampleset numsamples do d selectdistance probabilitydistr c searchconfigwithdistance vm d search for configuration cwith exactlydconfiguration options selected ifc negationslash then sampleset sampleset c end 8end 9return sampleset in algorithm we describe the algorithm behind distancebased sampling.
it receives three parameters as input the variability model vm the number of configurations to be selected numsamples and the probability distribution to use probabilitydistr .
internally we use a constraint solver that uses the variability model to determine the valid configurations.
we assume that the solver is globally available to the algorithm.
the algorithm selects a distance dbased on the probability distribution probabilitydistr .
the distance is passed as an additional numeric constraint i.e.
in addition to the constraints of the variability model to the constraint solver which searches for a solution with exactly dconfiguration options selected line .
if a solution i.e.
a valid configuration is found it is included into the sample set line .
if not another distance dis selected until a valid configuration with this distance is found.
this process is repeated until the sample set contains the desired number of valid configurations or there are no more solutions line .
in what follows we define the distance metric and the discrete probability distribution that we use and we describe the selection of a valid configuration in more detail.
distance metric selectdistance figure illustrates that t wise sampling covers only specific intervals in the range of possible distances.
in fact t wise sampling misses information on interactions among more than tconfiguration options.
by using a distance metric to diversify the sample set we cover more regions of the configuration space which leads to a more diverse sample set.
in what follows we use themanhattan distance of a configuration to the origin of the configuration space c0 o o c0 o as distance another reference point would be possible though.
so let dist c nbe the distance metric defined as follows dist c summationdisplay o oc o where c c is a valid configuration.
let dbe the set of all distances d dist c c c note that in the case of having only binary configuration options and using the manhattan distance the distance is just the number of selected configuration options of the configuration.
for instance for d we will search for a configuration that has exactly two configuration options selected and all remaining configuration options deselected.
abc c000 c001c010 c100c011c111 c101c110 a distancefrequency2 c000 c100 c010 c001 c110 c101 c011 c111 b fig.
example for applying the distance function to a software system with three configuration options a b and cwithout any constraints.
in a we show the configuration space and in b we illustrate the distribution of distances.
probability distribution probabilitydistr in figure we show the distances and the number of configurations frequency per distance for a system with three configuration options a b and c without any constraints.
in this small example the distance distribution is easy to compute we derive all valid configurations and apply the distance metric to each of them.
however deriving all valid configurations i.e.
the whole population is infeasible for complex systems.
fortunately it turns out that we do not need a data set following an exact probability distribution.
instead we use pre defined discrete probability distributions e.g.
uniform geometric binomial to define the desired distribution of our sample set.
these discrete probability distributions probabilitydistr are used to express the likelihood of choosing a certain value u u. in every discrete probability distribution p w eh a v e summationtext u up x u where x is a random variable.
in what follows we use the discrete uniform distribution.
so we uniformly draw a distance d d to derive a configuration with dconfiguration options selected.
thus we obtain p x d d in other words each distance dequally likely to be picked.
while it is possible to use another discrete probability distribution such as the geometric distribution or the binomial distribution we fix this degree of freedom for now to keep authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
the discussion focused and the experiment design tractable.
nevertheless we performed experiments with different distributions which we discuss in section v c. without computing the whole population or understanding all constraints in the variability model we have no knowledge about the value domain of dand thus about p x d .w e can approximate the lower and the upper bound for d though by using the number of mandatory configuration options and the number of all configuration options respectively.
max d card o o o min d card o o o ois mandatory where card is the cardinality function.
mandatory configuration options can be easily computed based on the given constraints of the variability model .
configuration selection searchconfigwithdistance after choosing a certain distance d we select a configuration that has a distance of d doptions selected in our setting for which we use a constraint solver.
to this end we add an additional constraint to the solver describing that exactly doptions have to be selected in the configuration.
if there is no more configuration with exactly dselected configuration options another distance dis selected.
this process is repeated until the sample set contains a given number of configurations or no further configurations are found.
in cases where we select several times the same distance value the constraint solver could generate locally clustered solutions.
to address this problem we propose an optimization to further increase diversity of our sample set as we describe in section iii b. note that we do not minimize the number of selected configuration options as in t wise sampling which would be computationally expensive and does not pay off see section v .
time complexity the most costly function in algorithm is searchconfigwithdistance whose complexity is dominated by the time of computing a feasible solution by the constraint solver.
theoretically a constraint solver such as a sa t solver has an exponential time complexity to solve a satisfiability problem .
practically state of the art constraint solvers are able to handle thousands of variables and constraints efficiently .
in our experiments the constraint solver considered up to variables and up to constraints which resulted in less than .3seconds to find a solution i.e.
a valid configuration .
b. increasing diversity in preliminary experiments with algorithm we noticed that the produced sample sets may lack diversity in that some configuration options are selected in many configurations and some only in few or even none.
hence to increase diversity of the sample set we refine the configuration selection procedure of distance based sampling by adding configurations that contain the least frequently selected configuration options.
this way we reduce the possibility of missing or underrepresenting certain configuration options in the sampling process.technically we determine a ranking over the frequency of configuration options which is defined as follows o o card c c s c o if there is no valid configuration with the given configuration option and distance we select the next option in the ranking and so on.
algorithm diversified distance based sampling input vm numsamples probabilitydistr output sampleset 1candidates getalloptions vm generates a list of candidates one candidate for each configuration option 2sampleset 3while othersolutionsexist vm sampleset and size sampleset numsamples do d selectdistance probabilitydistr c while candidatesexist candidates d and c do candidate getleastfrequentcandidate candidates d c searchconfigwithdistance vm candidate d ifc then removecandidate candidates candidate d end ifc negationslash then sampleset sampleset c updatecandidatemap c d candidates end end return sampleset in algorithm we show the optimized version of distancebased sampling which we call diversified distance based sampling .
the novelty here is that we count the number of selections of each configuration option for each distance d d .
to this end we define one map in line for each distance d d and update the map in line when a new configuration is added to the sample set.
the least frequent configuration option of the current distance dis selected using the map in line and used to retrieve the next configuration in line .
if there is no more configuration with the given distance dthat contains the candidate this candidate is removed from the distance s candidate map in line and the next configuration option is used.
as we show in line another least frequent candidate is repeatedly chosen until a valid configuration is found.
iv .
e xperiment setup in this section we introduce our research questions regarding the comparison of distance based sampling with other stateof the art sampling strategies.
furthermore we describe how we attempt to answer the research questions and the software systems we use for the comparison.
a. research questions the prediction accuracy of machine learning techniques largely depends on the data set which is defined by the sampling strategy in our setting.
naturally some sampling strategies such as random sampling are affected by randomness which can have a considerable influence on the sample set and consequently on the prediction accuracy.
hence we consider both the prediction accuracy and its robustness when comparing sampling strategies.
to this end we aim at answering two research questions authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
rq what is the influence of using distance based diversified distance based random solver based randomized solver based and t wise sampling on the accuracy of performance predictions?
rq what is the influence of randomness of using distance based diversified distance based solver based randomized solver based and random sampling on the robustness of prediction accuracy?
note that we have excluded t wise sampling from rq a si t is deterministic in our setting and does not lead to variations.
b. operationalization to answer our research questions we apply a state of the art machine learning technique that relies on multiple linear regression and feature forward selection to learn performance models based on the sample sets defined by the different sampling strategies.
to answer rq we use the resulting performance models to predict the performance of the whole population of each of our subject systems.
we quantify the difference between the predicted performance and the measured performance by means of the error rate for all configurations c c as follows errorc measured c predictedc measured c where predictedcis the predicted performance of configurationcandmeasured cthe measured performance of configurationc.
lower error rates indicate a higher prediction accuracy and thus are better.
we further determine the mean error rate of the whole population error summationtext c cerrorc c note that we compute the error rate based on predictions for the whole population including configurations from the sample set.
the background is that we use regression learning as machine learning technique which may produce imperfect predictions even for configurations from the sample set and we would like to take that into account.
further note that initially we compared the performance distributions of the sample sets and the whole population.
but as the similarity of distributions of a sample set and the whole population does not necessarily imply good predictions we refrain from this evaluation method and decided for the more definitive method of comparing error rates.
to answer rq we perform the sampling and machinelearning procedures times per experiment run using different seeds for the random number generator and we compute the variance across the error rates tildewideerror var errorc c c a lower variance indicates a higher robustness i.e.
is better .
so in our experiments the independent variables are the subject systems the sample sizes the sampling strategies and the random seeds for the random number generator.
to rule out influences of different sample sizes we selected the same sample sizes for diversified distance based randomized solver based and random sampling such that their size equals the size for t wise sampling with t t and t .
the dependent variables are for rq the mean error rates of the performance predictions i.e.
error and for rq the variance of the error rates of the performance predictions on the whole population i.e.
tildewideerror .
for both research questions we perform a standardization on the error rates when considering different subject systems to be able to answer the research questions without considering each subject system separately.
for rq we use a kruskalwallis test to identify for every sample size t t andt if the error rates of at least two sampling strategies differ significantly p .
.
as proposed by arcuri and briand we then perform pair wise and one sided mannwhitney u tests to identify which sampling strategy leads to significant lower error rates than others.
in addition to testing for statistical significance we determine the effect size using the a12measure by v argha and delaney .
v alues of a12of more than .
.
and0.71indicate small medium and large effect sizes respectively.
to answer rq we use levene s test to identify whether the variances of at least two sampling strategies differ significantly from each other.
if this is the case we perform a pair wise comparison using one sided f tests to identify the sampling strategy with the lower variance.
technically we implemented the diversified distance based sampling strategy on top of the tool spl c onqueror5and compared it with the implementations of t wise sampling randomized solver based sampling and random sampling of spl conqueror .
t wise sampling corresponds to the optimized t wise strategy by siegmund et al.
.
for random sampling spl c onqueror selects randomly distributed configurations from the whole population which guarantees a uniform distribution of configurations across the configuration space.
that is for the purpose of computing a baseline for error and tildewideerror we follow the non scalable random sampling we derive the whole population i.e.
all valid configurations first which is necessary to answer rq1.
then we randomly draw configurations from the whole population to the sample set.
other random sampling strategies such as the monte carlo method or bdd based sampling are not suitable because of the disadvantages mentioned in section ii b. this design decision allows us to maximize internal validity but requires to acquire the whole population.
for larger subject systems we required in total more than a week of measurement per subject system.
for randomized solver based sampling we used the z3 solver which allows us to set a random seed.
specifying different random seeds influences the variableselection heuristics and thus determines the location of the sample set in the configuration space.
we performed each sampling times with different random seeds from 1to .
4in t wise sampling the size can be chosen only by using t whereas in distance based solver based and random sampling any positive number in can be used for the specification of the sample size.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
t able i overview of the subject systems including domain number of valid configurations c number of configuration options o and the performance metric to be predicted.
domain c o performance 7z file archive utility compression time bdb c embedded database response time dune multigrid solver solving time hip accimage processing solving time java gc garbage collector time llvm compiler infrastructure compilation time lrzip file archive utility compression time poll y code optimizer runtime vp9 video encoder encoding time x264 video encoder encoding time c. subject systems in our experiments we consider real world configurable software systems from different domains and of different sizes.
we measured all configurations of all subject systems i.e.
the whole population between 5to10 times until reaching a standard deviation of less than to control measurement bias.
in total the measurements took multiple years of cpu time.
in table i we provide an overview of the subject systems.
note as we needed the whole population for every subject system to perform random sampling the sizes of configuration spaces of potential subject systems was limited which is not a limitation of distance based sampling.
we provide the variability models and the measurements of the subject systems on our supplementary website.
next we describe the subject systems in more detail.
z ip 7z is a file archiver written in c .
configuration options include different compression methods different sizes of the dictionary and the use of single or multithreading.
we used version .
of z ipand measured the compression time of the canterbury corpus6on an intel xeon e5 and gb ram ubuntu .
.
berkeley db c bdb c is an embedded database engine written in c. we consider configuration options defining for example the page and cache size or the use of encryption.
we measured the time of version .
.
to answer different read and write queries on a machine with an intel core quad cpu .
ghz and 4gb ram windows vista .
dune mgs d une is a geometric multigrid solver for partial differential equations based on the d une framework .
as configuration options we consider different algorithms for smoothing and different numbers of pre smoothing and postsmoothing steps to solve poisson s equation.
we performed all measurements with version .2on an intel i5 and gb ram ubuntu .
.
hip accsol ver hip acc is an image processing framework written in c .
we included for instance different numbers of pixels calculated per thread and different types of memory e.g.
texture local as configuration options.
we measured the runtime for solving partial differential equations on an nvidia tesla k20 with 5gb ram and cores ubuntu .
.
gc is the garbage collector of the java vm which provides several configuration options such as disabling the explicit garbage collection call modifying the adaptive garbage collection boundary and modifying the policy size.
we measured the garbage collection time of java .8to execute the dacapo benchmark suite7on a cluster with an intel xeon e5 and gb ram ubuntu .
.
llvm is a popular compiler infrastructure written in c .
configuration options that we considered concern code optimization such as enabling inlining jump threading and dead code elimination.
we measured the compile time using the clang frontend of version .7for executing the opt tool benchmark on an amd athlon64 dual core 2gb ram debian gnu linux .
lrzip is a file compression tool.
we consider configuration options that define for instance the compression level and the use of encryption.
we used the uiq28generator to generate a file mb and we measured the time for compressing this file with version .
on a machine with amd athlon64 dual core 2gb ram debian gnu linux .
poll y is a loop optimizer that rests on top of ll vm.
poll y provides various configuration options that define for example whether code should be parallelized or the choice of the tile size.
we used p oll y version3.
llvm version .
.
and clang version .
.
.
as benchmark we used the gemm program from polybench and measured its runtime on an intel xeon e5 and gb ram ubuntu .
.
vpxenc vp9 is a video encoder that uses the vp9 video coding format.
it offers different configuration options such as adjusting the quality the bitrate of the coded video and the number of threads to use.
we measured the encoding time of seconds from the big buck bunny trailer on an intel xeon e5 and gb ram ubuntu .
.
x264 is a video encoder for the h. compression format.
relevant configuration options included the number of reference frames enabling or disabling the default entropy encoder and the number of frames for ratecontrol and lookahead.
we have measured the time to encode the sintel trailer mb on an intel core q6600 with gb ram ubuntu .
.
v. r esul ts in section v a we present the results regarding rq 1and in section v b the results regarding rq .
in section v c we discuss further findings the computation effort and our optimization.
in section v d we discuss threats to validity.
a. results rq prediction accuracy in table ii we show the mean error rates for the different sampling strategies.
we show the results of random sampling in the rightmost column.
again random sampling requires the computation of the whole population and does not scale but it serves as a base line for our experiments.
we mark for each sample set size the lowest statistically significant error rate in green.
that is if two strategies perform similarly and have authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
t able ii error rates of t wise randomized solver based diversified distance based and random sampling for all 10subject systems.
the bottom row contains the mean value across all subject systems.
the best results per subject system and sample set size are highlighted in bold and green iff the mann whitney u test reported a significant difference p .
.
coverage based solver based randomized solver based distance based diversified distance based random t t t t t t t t t t t t t t t t t t 7z .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
bdb c .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
dune .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
hipacc .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
javagc .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
ll vm .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
lrzip .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
polly .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
vp9 .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
x264 .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
mean .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
no statistically significant difference we do not mark them.
additionally we provide the mean error rate bottom row over all subject systems.
there are several observations diversified distance based sampling performs best or similar to all other sampling strategies for t andt .
distance based sampling without optimization produces partially good results for some systems e.g.
for zand llvm but is outperformed for other systems e.g.
j ava gc lrzip and vp9 .
solver based sampling results in inaccurate performance models for most subject systems and sample set sizes.
randomized solver based sampling performs overall better than solverbased sampling t wise sampling perform best when only a very limited number of samples are considered i.e.
t .
when we compare the results to random sampling we make two observations.
first it seems that a diverse coverage of the configuration by random selection yields most accurate performance models especially for systems with many configurations e.g.
z java gc and vp9 .
second we observe that the error rates of diversified distance based sampling often come close to the base line of random sampling especially when the size of the sample set increases.
when performing kruskal wallis tests for all sample sizes t t and t we observe pvalues less than .
shown on our supplementary website indicating that at least two sampling strategies differ significantly for each sample size.
to identify these sampling strategies we apply onesided mann whitney u tests pair wisely and if significant p .
report the effect sizes in table iii.
specifically we test whether the sampling strategy of the row in table iii has a significantly lower error rate than the sampling strategy of the column.
the first row shows that t wise sampling leads to significantly lower error rates than solver based sampling with a small effect size for all sample sizes and to significantly lower error rates than distance based sampling for t .i n the fourth row we see that distance based sampling leads to lower error rates than t wise sampling for t andt with a small effect sizes.
distance based sampling has also lower error rates than solver based sampling for t andt witha small effect size and t with a medium effect size.
solverbased sampling performs significantly better than distancebased sampling for t which is also negligible due to the small effect size.
randomized solver based sampling performs significantly better than distance based sampling for t with small effect size.
when comparing the error rates of diversified distance based sampling with t wise sampling randomized solver based sampling and solver based sampling we see that t wise sampling solver based sampling and randomized solver based sampling lead to higher error rates for t andt .
the effect size in comparison to t wise sampling is large for diversified distance based sampling.
moreover diversified distance based sampling performs better than solver based and randomized solver based sampling with large effect sizes.
comparing diversified distance based sampling to random sampling we see that random sampling has significantly lower error rates with small to medium effect sizes.
this result indicates that we can reach nearly the same low error rates using distancebased sampling as the computationally intractable random sampling.
summary diversified distance based sampling outperforms all other sampling strategies for t and t almost reaching the accuracy of the base line of random sampling but without relying on the whole population.
for small sample sets t t wise sampling is superior.
b. results rq robustness based on runs per experiment we obtained a distribution of mean error rates for each sampling strategy which we further aggregated to compute their variances tildewideerror .
we compared the variances as follows first we performed levene s test shown on our supplementary website which checks the existence of significantly different variances between at least two sampling strategies over all sampling sizes.
then we performed pair wisely one sided f tests.
we show the results in table iv.
in the second row we can see that randomized solver based sampling has a significantly lower variance than authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
t able iii pvalues from a one sided pair wise mann whitney u test where we tested pair wisely whether the population from the row is smaller than the population from the column for different sample sizes after standardization.
the effect size is included for every significant result p .
where we consider differences as small medium and large when a12is over0.
.
and0.
respectively.
mann whitney u test coverage based solver based randomized solver based distance based diversified distance based random t 1t 2t 3t 1t 2t 3t 1t 2t 3t 1t 2t 3t 1t 2t 3t 1t 2t 28coverage based .
.
.
.
.
.
.
.
04solver based .
05randomized solver based .
.
.
.
.
25distance based .
.
.
.
.
.
49diversified distance based .
.
.
.
.
.
.
.
.
10random .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
t able iv pvalues from a one sided pair wise f test where we tested pair wisely whether the variances of the population from the row is smaller than the one from the column for different sample sizes after standardization.
f test pvalue solver based randomized solver based distance based diversified distance based random t t t t t t t t t t t t t t t solver based randomized solver based distance based diversified distance based random distance based sampling.
in the third row we can see that distance based sampling has a significantly lower variance than solver based sampling on all sample sizes.
the last row shows that random sampling has the lowest variance.
when it comes to the diversified variant of distance based sampling it leads to a significantly lower variance compared to plain distance based sampling.
the optimization has a significantly lower error rate than random sampling for t which requires however a whole population analysis.
regarding randomized solver based sampling the variance of diversified distancebased sampling is significantly lower for all sample sizes.
we explain these observations as follows solver based sampling either relies also on a random seed or produces a deterministic set of configurations not considered here .
in the case of random seeds the seed defines the first solution found by the solver.
since neighboring solutions are produced very likely in subsequent solver calls the sample set will be locally clustered around the first solution.
hence for different seeds different clusters are sampled such that high variations occur in the error rate depending on the representativeness of the cluster.
randomized solver based sampling avoids building clusters and thus the variance is significantly lower than solverbased sampling.
distance based sampling uses also a solver to obtain configurations but only with a certain distance.
having multiple configurations with the same distance mightlead to clusters similar to solver based sampling.
this is why we observe a lower variance than for solver based sampling we might obtain one cluster per distance but not a single cluster in total but a higher variance than random sampling randomized solver based sampling and diversified distancebased sampling.
reducing clustering diversified distancebased sampling yields even lower variances.
as diversified distance based sampling avoids clusters such as randomized solver based sampling the variances are rather similar.
hence we conclude that our optimization of distance based sampling is effective to increase the variety of configurations and thus lowers the variance of the prediction error.
summary diversified distance based sampling is more robust than other sampling strategies except for random sampling but at the benefit of lower computational effort.
c. discussion computational effort the computational effort of distancebased sampling and its diversified variant is lower than the effort of random sampling because we include every configuration found by the solver into the sample set instead of enumerating all valid configurations and discarding later a large part i.e.
configurations not used in the sample set of it see section ii b .
moreover to reduce computational effort authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
we do not perform an expensive optimization as in t wise sampling i.e.
minimizing the set of selected configuration options that are not of interest in the current configuration but rather include additional constraints to the constraint solver that define for example the number of selected configuration options.
the computational effort of randomized solver based sampling is high since the solver has to be reinitialized from scratch to permute the constraints the literals and initial assignment.
whereas random sampling and the randomized solver based sampling need more than 10hours to acquire the sample set the other sampling strategies are some orders of magnitude faster.
we provide all times for computing all sample sets on the supplementary website.
probability distributions in our experiments we used exclusively the discrete uniform distribution for selecting distances but our algorithm can be parameterized probabilitydistr .
preliminary experiments with binomial and geometric distributions suggest that a uniform coverage of the configuration space is superior though see the supplementary website .
testing further distributions is an avenue of further work.
diversity comparing plain distance based sampling with diversified distance based sampling we observe that optimizing for diversity indeed pays off in terms of prediction accuracy and robustness.
aiming at diversity is optimal in a black box strategy where no domain knowledge is available.
however diversified distance based sampling only pays off with larger sample sizes because the smaller sample sizes do not suffice to cover all configuration options at least once for each distance.
d. threats to v alidity internal validity to rule out errors in our implementation of diversified distance based sampling we have thoroughly tested it.
we verified that the produced sample set follows the given distribution of the configuration distances.
we found deviations only when all configurations of a specific distance were already selected which occurred only in few cases.
external validity to increase external validity we have selected software systems from different domains.
we consider software systems ranging from systems with configurations to systems with configurations.
we have excluded larger systems because it would be computationally infeasible for t wise sampling and random sampling .
the selection of the machine learning technique to learn a performance model may threaten external validity.
we used deliberately the same machine learning technique for all experiments to increase internal validity.
but other machinelearning techniques have other strategies to derive information from the sample set and thus may lead to different results.
in a parallel line of experiments we compared six different machine learning techniques and observed that multiple regression is often as accurate as classification and regression trees and random forests9 which are often used for learning performance models of configurable software systems.
so we data are confident that our results generalize to other machinelearning techniques.
another threat to validity is the choice of the constraint solver as different solvers adopt different search heuristics.
this however might represent a further reason not to rely on solverbased sampling as this way the generation of the sample set remains intransparent.
for instance we observed even worse results for solver based sampling when using the solver of the microsoft solver foundation.
vi.
c onclusion measuring every configuration of a software system to identify the performance optimal configuration is often unfeasible due to the sheer size of the configuration space.
addressing this problem machine learning is used to predict the performance of individual or all configurations by deriving information from a small and representative sample set.
finding a tractably small and representative set of configurations is an important but difficult task.
to this end different sampling strategies such as t wise sampling solver based sampling and random sampling have been proposed which focus on different aspects with different strengths and weaknesses.
to address the weaknesses we propose distance based sampling which is based on a user defined discrete probability distribution and a distance metric.
the key idea is that distance based sampling spreads the selected configurations across the configuration space based on a given probability distribution while not relying on an expensive analysis of the whole population.
to compare distance based sampling with the state of the art we learn performance models for real world software systems using6different sampling strategies and compare the accuracy of the performance models.
our results demonstrate that distance based sampling when used in combination with a diversity optimization leads to significantly lower error rates than state of the art strategies especially for larger sample sizes t t and the predictions are more stable than solver based sampling with respect to multiple runs using different random seeds.
our results demonstrate that based on a distance metric and a probability distribution we can effectively sample diverse configurations across the configuration space and without the need for a whole population analysis which makes random sampling unfeasible for highly configurable software systems.
this work provides a new view on sampling based on probability distributions and paves the way for further research in this area.
for instance using other metrics or distributions could lead more accurate predictions or improve the prediction robustness.
vii.
a cknowledgments grebhahn s work is supported by the dfg under the contract ap .
apel s work is supported by the dfg under the contracts ap ap and ap .
siegmund s work is supported by the dfg under the contracts si and si .
guos work is supported by nsfc shanghai pujiang talent program 17pj1401900 shanghai nsf 17zr1406900 and alibaba group.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.