discovering unknown known security requirements awais rashid security lancaster research centre lancaster university uk a.rashid lancaster.ac.uksyed asad ali naqvi security lancaster research centre lancaster university uk s.naqvi lancaster.ac.ukrajiv ramdhany security lancaster research centre lancaster university uk nirish777 gmail.com matthew edwards security lancaster research centre lancaster university uk m.edwards7 lancaster.ac.ukruzanna chitchyan dept.
of computer science university of leicester uk rc256 leicester.ac.ukm.
ali babar school of computer science university of adelaide australia alibabar.m gmail.com abstract security is one of the biggest challenges facing organisations in the modern hyper connected world.
a number of theoretical security models are available that provide best practice security guidelines and are widely utilised as a basis to identify and operationalise security requirements.
such models often capture high level security concepts e.g.
whitelisting secure con gurations wireless access control data recovery etc.
strategies for operationalising such concepts through speci c security controls and relationships between the various concepts and controls.
the threat landscape however evolves leading to new tacit knowledge that is embedded in or across a variety of security incidents.
these unknown knowns alter or at least demand reconsideration of the theoretical security models underpinning security requirements.
in this paper we present an approach to discover such unknown knowns through multi incident analysis.
the approach is based on a novel combination of grounded theory and incident fault trees.
we demonstrate the e ectiveness of the approach through its application to identify revisions to a theoretical security model widely used in industry.
categories and subject descriptors d. .
requirements speci cations k6.
management of computing and information systems security and protection keywords security requirements incident analysis grounded theory .
introduction modern organisations operate as part of a complex hyperconnected eco system comprising other organisations and a permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
copyrights for components of this work owned by others than the author s must be honored.
abstracting with credit is permitted.
to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
request permissions from permissions acm.org.
icse may austin tx usa c copyright held by the owner author s .
publication rights licensed to acm.
isbn .
.
.
.
range of third party technologies and services.
such an eco system poses challenging security requirements.
for instance opening up the infrastructure through internetand web based interfaces to support employee mobility and interactions with other organisations e.g.
through software as a service results in many additional entry points that can be attacked by mal actors.
similarly bring your own device cultures whereby end users utilise new personal technologies or software services from partially trusted third parties in their day to day working practice introduce new security challenges and attack vectors.
furthermore an organisation s it infrastructure is often a patchwork of systems software services and technologies procured from third party providers which can be harbingers of latent vulnerabilities.
identifying and operationalising security requirements in such a complex landscape is non trivial.
consequently security models exist e.g.
that provide best practice guidelines to identify and operationalise security requirements.
such models o er high level security concepts that can be used as a basis for security requirements.
examples include whitelisting of devices and software secure con gurations for hardware and software for mobile and desktop devices continuous vulnerability assessment and remediation data recovery planning controlled use of administrative privileges etc.
such models also include detailed guidelines on how to operationalise such requirements through particular security controls.
thus they represent our theoretical understanding of the current threat landscape and the resultant security requirements.
however the threat landscape is increasingly dynamic leading to emergence of new security requirements that demand revision or at least reconsideration of these theoretical models.
such emergent requirements are often implicit within or across a variety of security incidents.
we refer to such requirements as unknown knowns1 they represent knowledge that is unknown to the requirements engineer and so does not make its way into requirements but is known in that it exists in known security breaches.
discovering such unknown knowns is challenging because incidents are usually separated from one another in terms of 1sawyer et al.
adapt donald rumsfeld s classi cation of known knowns known unknowns and unknown unknowns to requirements and argue that there is a fourth category of unknown known requirements.
ieee acm 38th ieee international conference on software engineering both time and space.
it is rare for two or more incidents to be closely co located in time and space investigated jointly and a common causal analysis conducted.
quantitative approaches such as statistical and data mining analyses most commonly used for knowledge aggregation reveal the correlations and patterns only within the data attributes.
these correlations and patterns tell us what is going on in the data but not howorwhythese patterns appear.
the analysts still have to use their domain knowledge to hypothesise about the how and why.
in the absence of aggregation and internalisation of common cause e ect knowledge across incidents these hypotheses often remain conjectural.
we present an approach to discover such unknown knowns through qualitative analysis of security incidents across space and time.
our approach is based on a novel combination of the grounded theory method and incident fault trees to identify new concepts and relationships that need to be integrated into existing theoretical security models leading to updated or new models that provide a more e ective basis for identifying and operationalising security requirements.
the novel contributions of our work are as follows we propose a novel synthesis of incident fault trees and the grounded theory method to aggregate and internalise common cause e ect knowledge across incidents pertaining to unknown known security requirements.
while the grounded theory method enables the iterative analysis and synthesis of patterns across incidents separated by space and time use of incident fault trees ensures that explanation is not traded o in favour of documentation the analyst has to actively search for relevant events their causes enablers consequences and mitigation measures.
our approach is not based on a static structure or process.
instead it provides the means to control the depth of the analysis through explicit procedures for deriving a hierarchy of concepts across di erent levels of abstraction.
this allows the analyst to express and explore in detail all three what howandwhy levels of understanding.
we demonstrate the e ectiveness of our approach through its application to identify revisions to a theoretical security model widely used in industry.
we discuss related work in section .
section brie y introduces grounded theory and incident fault trees.
section presents our approach for discovering unknown knowns.
section evaluates our approach through analysis of major security incidents and identi es unknown knowns with respect to the twenty critical security controls widely recommended in industry.
section discusses insights from the analysis while section concludes the paper.
.
related work several researchers have focused on identi cation of security requirements before the system has been implemented using for instance misuse cases goal and anti goal analysis abuse frames and patterns of security goals .
others have proposed the use of creativity techniques such as workshops and goal analysis to identify potential threats and incidents at the outset of system development.
however these various works have not addressedthe consequences of an evolving threat landscape and related requirements change.
researchers have also highlighted the limitations of security modelling languages e.g.
umlsec securetropos koas and i with respect to relating security requirements and dynamic elements of a system .
consequently more recently adaptive security has become a lively research topic.
for instance franquera et al.
advocate the need for an agile security evaluation framework due to expected changes in security requirements throughout the development process.
yet they do not detail construction of such a framework.
tsigkanos et al.
focus on security threats that arise due to physical proximity of potentially malicious agents and valuable assets.
such proximity requirements are known ahead.
when the physical locations of threats assets change at runtime the pre speci ed requirements on security are used to adjust the security models.
here only the physical topology changes not the security requirements themselves.
elahi et al.
propose to extend the i modelling technique with vulnerability concepts in order to reason about vulnerability and threat propagation in requirements models.
this framework is much more considerate of the change in threats and security requirements.
however it does not provide any guidelines for nding emergent threats and vulnerabilities.
instead it focuses on linking such knowledge to the requirements models.
in contrast our work provides such guidelines along with clearly identi able strategies for revising existing models underpinning security requirements.
salehie et al.
present a qualitative approach using a causal network to evaluate the current state of a system s security and adapt the relevant countermeasures when secured assets change.
since assets are linked into the causal network changes to the asset model propagate to change in the security preferences inferred from the network.
all models are constructed a priori with assumptions about the intended application and its environment.
our approach complements this by providing a posteriori evidenced information on the origin of changes to the asset model and rich content for threat model construction.
multi incident analysis tools and approaches have been developed in the context of speci c industries to undertake post hoc analysis of faults and failures.
such methods often take a quantitative approach either based on statistical correlational techniques e.g.
or more recently data mining approaches e.g.
.
such approaches su er from inappropriate abstraction i.e.
each incident is described in terms of a nite number of speci ed attributes which have to be reasonably generic so as to accommodate a large number of incidents.
the distinct details of each incident are thus abstracted away.
such abstraction also does not allow for the representation of semantic di erences owing to the changing de nitions of attributes across time and space and also the di erent purposes of the data and collection methods used.
consequently the correlations and patterns identi ed can only reveal what is going on in the data but not how or why these patterns appear.
a number of general purpose single incident analysis approaches can also facilitate multi incident analysis.
approaches such as mort and hpip often express the accumulated insights about hazards in a particular eld by means of a limited number of concepts that can be used to describe an incident.
these concepts may include taxonomies of incident types their potential causes and pre867figure symbols used in incident fault trees scribed questions to guide the incident analysis.
this enables the results from di erent incident analyses to be integrated by means of a common incident vocabulary.
however this integrative ability generally comes at the cost of accuracy as these techniques struggle to accurately represent the peculiar and idiosyncratic characteristics of each incident.
similar to quantitative multi incident analysis approaches these techniques also cannot mitigate the problem of semantic di erences between various incident attributes across time and space.
thus there is a need for approaches such as ours that capture and integrate new cause e ect knowledge into an evolving security model while preserving the contextual richness of incidents.
.
background concepts .
grounded theory method the grounded theory method gtm is an approach for deriving theories based entirely on data.
it works by breaking the data down into small portions such as individual lines and then assigning labels called codes to each portion.
each code should represent the concept expressed in its corresponding portion of data.
the codes are then compared to one another and based on similarities and differences grouped under more abstract concepts called categories .
this constant comparison between and across codes and categories continues even as new codes are integrated into the analysis and new categories discovered.
the derived categories their relationships and dependencies and re ections on the analysis are recorded in memos .
through this iterative abductive approach where data analysis and collection are both simultaneous and interdependent a theory emerges which is fully grounded in the available data.
gtm is used in our approach to aggregate the results of the various individual security incident analyses augmented through incident fault trees ifts to produce an abductive theory that captures unknown known security requirements.
.
incident fault trees an incident fault tree ift is a modelling tool for the retrospective documentation and analysis of incidents and accidents.
it is used to explain an incident in terms of the various causes that contributed to it.
ift is based on and thus uses the graphical symbols see fig.
of the fault tree analysis fta method.
an ift comprises of two broad types of notations events and gates.
events may describe speci c discrete events or other conditions that are relevant in terms of causing an incident.
gates are symbols that represent various ways in which the events need to combine in order to cause another event.
we next describe those symbols that are used for ift modelling in our approach basic event cannot be explained in terms of othercausal events or has no known causes.
intermediate event can be explained in terms of other causal events or there are known causes for it.
undeveloped event can be explained in terms of other causal events but we have chosen not to do so because such causal elaboration serves no analytical purpose.
and gate and or gate respectively represent the conjunction or disjunction of causal events.
inhibit gate is placed between an event and its causes to stop an event from occurring unless the condition in the conditioning event is satis ed.
in practice this combination is used in our approach to model mitigating or remedial actions that may act as barriers to the progress towards a security breach.
ifts support our gtm based approach by providing a framework for explicitly structuring the codes categories and their causal relationships.
such a framework is well suited to gtm based qualitative analysis as it is descriptive and scalable it can grow in detail as the investigation proceeds and more information comes to light.
further the process of deriving a basic ift that describes an incident may be augmented through the change analysis and barrier analysis methods .
these methods encourage the analyst to think about the speci c departures from normal operating procedures and the failed barriers that led to the incident.
this leads to consideration of not only the errors of commission i.e.
factors that contributed to an incident but also the errors of omission i.e.
what was notdone that led to the security breach.
ifts facilitate exibility in analysis because the analyst can explore di erent hypotheses by elaborating and developing di erent paths in the tree to investigate various causal dependencies.
furthermore conventional gtm can be e ort intensive as all information is indiscriminately coded and categorised.
in contrast in our approach this coding is facilitated and directed by ifts.
.
approach our method for discovering unknown known security requirements is qualitative it is a synthesis of gtm with ifts.
it is both an analysis and an investigation method.
the method evolved from our desire to nd an e ective way to deal with the implicitness of domain knowledge when conducting a multi incident analysis of security breaches2.
in order to manage the large amount of unstructured and semistructured data we started organising it using ifts.
eventually the ift became the pivotal model in the method which honed and guided both the analysis and investigation aspects of the method.
just like conventional grounded theorists use interviews to extract the relevant pieces of information for their analysis from the life story of the subject interviewee our method uses the ift model to extract the relevant pieces of information for the purpose of causal analysis from the documentation of an incident.
the nature of ift means that the analyst is actively prompted to search for the breach events their enabling contexts resulting consequences and preventative measures.
fig.
presents an overview of our method.
the ovals represent processes and 2we use the term incident and breach interchangably to maintain consistency with the terminology of ifts.
868figure overview of the method the rectangles represent the artefacts or products of these processes.
the method is aimed at analysts e.g.
in organisations such as certs interested in distilling new classes of security problems through analysis of otherwise isolated security incidents.
we next discuss the various steps of the method.
note that for retrospective analysis as is the case with our method raw data mostly consists of second hand data in the form of breach incident reports studies analyses and other archived information.
drawing trees the analysis usually begins by rst reading the incident investigation document s to identify the interesting events or conditions that we would like to analyse and explain.
after one or more of these events or conditions have been identi ed each of them may become root nodes for ifts.
next we search for and identify concepts and factors from the documentation that caused the root incident.
this process continues recursively with further searches to identify the causes of each of the previously identi ed causal factors.
this search may be informed bybarrier analysis i.e.
actions and countermeasures that were either unused or inadequate in preventing the incident and change analysis i.e.
deviations from normal operating procedures or abnormal working practices that contributed to the incident .
fig.
represents the fault tree as produced by our analysis for one of the incidents we analysed.
open coding we can see in fig.
that the drawing trees process is part of a larger process that also contains open coding and identifying remedial actions .
this larger process signi es that the three activities are interdependent and essentially happen in parallel.
open coding is the process of annotating small portions of text with codes that indicate important concepts from these texts.
when we identify an interesting event from the documentation that we would like to analyse we also select the text related to that event and open code that text.
the choice of the rele vant events texts and the coding itself can be carried out by two or more independent researchers to counter potential bias.
the codes identi ed from the coding process may in turn inform the tree building process by indicating the causes for the event under consideration.
this process can become cyclical where building the ift may lead to selecting the material for open coding and open coding may lead to building and modifying the ift.
the data selected for open coding though centred on the ift may contain some additional details as well.
thus the codes created during open coding may not be strictly restricted to the event that we were trying to explain.
these additional codes may be valuable in that they may produce insights that would result in modifying or adding data to the ift in ways that we had not anticipated before.
they also provide information about the context in which incidents take place.
consequently these peripheral codes may lead to the discovery of important concepts and new directions for investigation during the constant comparison process because they may also be present in other incidents.
identifying remedial actions the structure of the ifts provides us with the opportunity to identify the areas where remedial actions might be taken.
the areas are identi ed in the form of the paths going from the leaf nodes to the root of the tree.
the remedial actions are essentially those activities that try to disrupt the progression of causes from the leaves to the root.
a remedial action on a causal path is represented by a combination of an inhibit gate and a conditioning event.
it describes the actions that can mitigate the e ects of the events described along the causal path below the inhibit gate.
these solutions may come from recommendations in the incident report subsequent follow up reports or from news sources after the incident describing how the state has changed and improved since the incident.
the process of deriving remedies may also help to re ne ifts.
while thinking about barriers and recommendations associations may appear between di erent causal paths allowing us to aggregate them under a common parent node or category.
during constant comparison the remedial measures from di erent failures are compared and can result in identi cation of unknown known security requirements.
memo writing generalities in the data in the form of concepts and relationships are discovered and recorded during memo writing.
the processes of drawing trees open coding and identifying remedial actions will produce an ift and a set of codes related to that tree.
during memo writing these codes are compared with one another and based on similarities and di erences aggregated into more abstract concepts called categories.
further comparisons between and across codes and categories may lead to the discovery of more abstract categories.
these categories and their relationships are recorded in memos.
all hypotheses and suppositions are also recorded in memos.
memos can be written at any stage of the analysis.
the aggregation and extrapolation of concepts during memo writing informed by the causal relationships in the ifts may point to gaps in existing analysis and thus provide direction to the emerging theory.
for example a memo may reveal a new possible causal factor about an incident thus prompting a search for evidence to substantiate this hypothesis.
if this evidence is found then the revealed causal factor may be added to the ift for the incident thus enriching it.
new insights may also be discovered because writing memos can expli869cate tacit ideas.
figs.
show excerpts from various memos summarising the derivation of several categories in terms of ner grained concepts.
during the constant comparison process where faults3are compared to other faults their memos are also compared to one another in order to discover unknown known security requirements.
constant comparison in this phase the insights obtained from an incident analysis are integrated into the evolving theory by constantly comparing its artefacts ift and memos describing categories and their relationships with similar artefacts from previously analysed incidents as well as the concepts of the evolving theory.
this comparison integrates knowledge across various incidents where both causes and remedies identi ed for one incident may inform and instigate further analysis of other incidents in order to discover unknown known security requirements.
sorting memos and distilling theory the sorting and writing process mainly consists of selecting and arranging the relevant information from the memos and comparing it against the existing theoretical security model in order to distill a theory representing unknown known security requirements.
this theory as nally presented comprises a number of security concepts and their associations.
the remedial measures are also classi ed into categories and related to causal factors with the aim of providing guidance for operationalising the security requirements.
.
ev aluation in order to evaluate the e ectiveness of our approach we apply it to discover unknown known security requirements with respect to a real world security model the council on cyber security top critical security controls csc20 .
we focus on a particular class of security threats data ex ltration i.e.
data theft .
this is because as systems become increasingly open security models need to evolve beyond traditional castle defences of rewalls and intrusion detection systems.
furthermore the increasing frequency of data breaches despite awareness of and compliance with models such as csc20 alludes to the possibility of unknown known security requirements with respect to such models.
by applying our approach to a corpus of security incidents that exhibit a diversity of attack traits we show that it is possible to keep the corpus of incidents relatively small and still saturate data ex ltration attack concepts and countermeasures.
we then present a comparative analysis of our discovered security requirements with csc20.
the analysis was conducted with reference to version .
of csc20 the latest version at the time of the analysis.
this analysis reveals disparities unknown known security requirements in the coverage of data ex ltration threats in the theoretical security model represented by csc20.
we note that the unknown known security requirements discovered through our analysis were passed on to the council for cyber security for consideration in revisions to csc20.
version .
subsequently released re ects a number of our recommendations.
though the council for cyber security does not provide direct traceability between any recommendations submitted and revisions released this nevertheless demonstrates the utility of our approach.
3we use the term faults to refer to vulnerabilities or actions leading to security violations in order to maintain consistency with the terminology of ifts.we next illustrate our analysis in detail initially describing the analysis process for the rst incident in our corpus in terms of its ift and gtm analysis artefacts sec.
.
.
we then describe the various intermediate stages in our analysis process and show how the various security concepts and requirements were discovered sec.
.
.
finally we summarise the unknown known security requirements with respect to csc20 sec.
.
.
the full analysis and the comprehensive ifts are available at lancaster researchdata .
.
analysis of nitro attacks the nitro attacks were a targeted campaign jul sept. against fortune companies in the chemical sector and another in various other sectors primarily the defence sector.
the attackers sought to steal intellectual property such as design documents chemical formulae and manufacturing processes for chemicals and advanced materials.
we model the chain of events leading to the nal outcome using an ift.
for the sake of brevity a simpli ed ift is shown in fig.
.
the tree o ers insight into the way the ex ltration attack panned out and where security controls can be deployed to detect prevent or mitigate the attack.
as illustrated event .
the rootkit program i.e.
the malware authenticated with a command and control c2 server via tcp port and upon success received binary code containing poison ivy a common remote access trojan rat .
using the c2 server the attackers then instructed the rat instance event .
to provide the infected computer s ip address the names of all other computers in the workgroup or domain and dumps of windows cached password hashes.
using various tactics such as pass the hash attacks or cracked windows password hashes the attackers proceeded to gain access to other computers with the same network logon user rights event .
.
as attackers needed more elevated access rights they performed privilege escalation event .
on non administrative users and then moved on to gain access to key high value targets which included process experts and server administrators.
this enabled them to traverse the network with ease and nd servers hosting the desired intellectual property and gain access to the sensitive materials.
once the attackers identi ed the desired intellectual property they established access to staging servers at key aggregation points on the network this was done to prepare the data for ex ltration.
the data was copied to these internal staging servers where it was aggregated compressed and encrypted for ex ltration events .
and .
.
depending on the volume of data to be ex ltrated and the degree of stealth required the attackers used di erent ex ltration channels such as ftp http and email all of which are high bandwidth channels available to users on most networks.
open coding and the constant comparison of codes enables the requirements analyst to organise the above understanding of the causes of the incident and produces insights that result in re ning the ift.
codes are grouped into hierarchies leading to the formation of categories.
the comparison of codes and categories for the nitro attacks produced the following main categories target identi cation reconnaissance attack staging network intrusion concealment persistence data ex ltration attack consequences countermeasures.
from this re ned understanding the ift was modi ed to include these super nodes.
us870figure simpli ed ift for nitro attacks ing the ift the data ex ltration concept was recursively developed into concepts and factors that may have contributed to it.
our re nement of the data ex ltration concept led to the selection of new material about data ex ltration schemes utilised within the incident.
this new material was open coded and the codes constantly compared to introduce new concepts sub categories recorded in memos.
as seen in fig.
the data ex ltration concept is broken further into the concepts data capture data staging preparation ex ltration channels and c2 infrastructure communications.
further iterations of this analytical process enabled for example the di erent modalities of the data capture concept to be de ned and the identi cation of overt covert types of ex ltration channels.
whenever possible insights gained from the memos were used to modify the tree to introduce new causal factors e.g.
events .
and .
.
additional insights about countermeasures were obtained through barrier analysis.
fig.
shows a memo excerpt summarising such remedial actions uncovered.
our memos not only recorded the concepts representing various stages and remedies of attacks produced through the comparisons of codes and categories.
they also identied and summarised the classes of exploits used during the attack the conditions within the organisation that made the use of these exploits favourable and the types of channels used to ex ltrate data in the incident.
they were also used to hypothesise on various other possible data ex ltration channels that could have been used in the attack.
since our ift analysis indicated a combination of network intrusionand ex ltration causes that led to the theft of intellectual property the memos re ected both the intrusion defences to defeat the exploits used in the attack as well as postintrusion measures to prevent data ex ltration.
.
iteratively building the theory our method for discovering unknown known security requirements involves re ning our theory by iteratively applying the analysis approach to several other incidents.
this involves integrating the insights obtained from the current analysis with those from previous analyses by constantly comparing their ifts as well as categories recorded in memos.
as the new categories identi ed in the current analysis are compared with the extant set of categories existing categories are potentially modi ed or aggregated or new categories created to augment existing ones.
such new categories indicate new patterns of attacks new classes of data exltration channels and countermeasures identi ed from the barrier analysis within the ift.
we used insights obtained from our rst analysis to select the next incidents for analysis.
in particular after the rst incident analysis we became cognisant of the di erent modalities in which data assets are prevalent in organisations namely see fig.
a data at rest i.e.
inactive data stored in databases le servers archives etc.
that is not accessed or changed frequently data in use i.e.
active data processed by applications and held in computer memory cpu caches registers or operational tables in databases and data in motion i.e.
data in transit in 871figure summary of the subcategories of the data ex ltration category from the nitro attacks figure summary of the countermeasures categories derived from the nitro attacks the form of packets transported by communication protocols and data traversing the network temporarily residing in memory bu ers to be forwarded .
we used this insight to guide our incident selection process to i discover concepts across the breadth of incident classes and ii within each figure sample countermeasures identi ed through the iterations class to attempt to saturate concepts by considering further variants of the ex ltration attacks of the same class.
to select data ex ltration incidents that exhibited the data in motion and data in use modalities we considered the range of attacks that targeted the consumer payment chain which includes actors such as merchants and their payment processing partners.
for data in motion class exltration incidents we selected attack campaigns that used various point of sale pos memory scraping malware such as the dexter malware based breaches of pos systems in retail hospitality and fast food outlets and the target data breach incident.
amongst the incidents we considered the heartland payment systems data breach embodied ex ltration strategies where attackers targeted both data in motion card data at the merchants pos terminals and data in use card data within payment processing systems .
as in our previous iteration incident trees were created to facilitate the analysis of causal factors barrier analysis used to determine the e ectiveness of mitigation measures open coding and constant comparison used to discover exltration concepts and re ne our collection of categories.
the addition of new categories to the data capture subcategory see fig.
a shows our improved understanding of the di erent data capture modalities that can be exercised in a data breach incident.
new ex ltration concepts uncovered in our analysis led to a reorganisation of channels into overt overt encrypted covert and covert encrypted sub categories fig.
b .
in addition by probing further into the identi ed ex ltration channels our understanding about the inherent characteristics of ex ltration channels such as bandwidth and covertness was reinforced.
by comparing the ex ltration channel concepts across the incidents already analysed we also started to develop insight into the recurrence of such channels.
finally memos were written to elaborate on possible other preventive remedial techniques.
fig.
presents an excerpt from a memo summarising some of the countermeasures identi ed through this process.
872figure a sample of re ned data capture categories during iterations b sample of data ex ltration channel categories during iterations .
identified unknown knowns the analysis of data ex ltration incidents and re selection of new attack incidents was continued till no new incident considered exhibited major variances to properties identied in previous iterations.
this saturation was clear during the analysis of the 9th incident with the 10th and 11th incidents producing categories that were minor variances on existing categories.
the body of memos rei ed the tacit knowledge embedded within every incident about the causes of the incident classes of exploits used during the attack conditions within the organisation that made the use of those exploits favourable the types of data channel used and other possible data ex ltration methods.
crucially the summative memos also contained in the form of speci c measures to detect and mitigate data ex ltration attacks a crude representation of our identi ed security unknown knowns.
to develop a theory encapsulating the data ex ltration security requirements the memos were sorted and reorganised in terms of data ex ltration method types and for each method in terms of measures for detection and mitigation and associations to organisational conditions practices and relative unpreparedness that increased susceptibility to breaches.
in so we formulated our theory to rst include a taxonomy of data ex ltration methods grounded in the security concepts empirically collected from the data breach incidents.
the countermeasures were then associated with these classes and subclasses of data ex ltration methods.
this enabled particular groups of security requirements to be readily selected when relevant traits were identi ed in a data ex ltration incident under analysis.
in order to facilitate the operationalisation of the security requirements the security model based on our theory was formulated to include controls in a fashion similar to csc20.
these controls represent a prioritised and empirically grounded set of security actions that organisations can take to assess and improve their current security state i.e.
their resilience to data ex ltration.
our model renement produced data ex ltration detection and mitigation controls listed in fig.
and sub controls renement of the security model represented by the configure ex ltration detection and mitigation controls trols .
a small subset of the security requirements associated with tra c restriction known channel inspection and channel tra c ltering concepts is reproduced in fig.
.
a further re nement described importance of the control in blocking or identifying presence of attacks and classi ed security requirements on the same lines as used in csc20 i quick wins ii visibility and attribution measures to improve the security capabilities within an organisation iii security con guration and hygiene i.e.
best practice guidelines and iv advanced sub controls i.e.
detailed guidelines representing latest breakthroughs in countermeasures .
such an alignment enabled comparison of our derived security model with csc20 in order to identify unknown known security requirements.
to evaluate the pertinence of our security model the security requirements were compared and contrasted with csc20.
each requirement was assessed as to whether it was fully or partially covered by csc20 or if it were a new requirement.
as shown in fig.
tra c restriction through perimeter rewalls proxy servers and protocol whitelisting is fully covered by the following controls within csc20 csc csc .
requirements .
.
.
.
.
.
and .
.
are on the other hand partially or not supported at all by csc20.
fig.
shows the various csc20 for which revisions were identi ed through our analysis.
i.e.
they provided only partial coverage of the security requirements identi ed through 873figure tra c restriction channel inspection and tra c ltering requirements our analysis.
the gures in paranthesis indicate the number of revisions identi ed.
the revisions are summarised below deployment of automated tools to monitor network perimeters csc csc is overly simplistic as it does not de ne the notion of typical ex ltration channels.
nor does it describe the provision of content analysers for speci c channels.
in contrast a known channel inspection sub control from our security model req.
.
.
in fig.
identi es the need for proxy servers in high risk overt ex ltration channels to inspect the content of messages for sensitive information.
dns query logging mechanisms csc csc in its current form focuses only on logging and log review as a detection mechanism.
our partiallymatched actuated detection system sub control req.
.
.
fig.
in contrast proposes more advanced measures e.g.
detecting anomalous dns queries outside an access control list through rules speci ed in the perimeter intrusion detection system ids and automatic quarantining of the query sender to a vlan.
use of data loss prevention dlp systems csc csc currently recommends using networkbased dlp tools to monitor tra c patterns without any precision about the type of patterns to detect c2 activity.
our revision proposes new requirements such as detecting disparities between the volume of inbound and outbound packets.
we also suggest measures to reduce false positives legitimate tra c also falls into the data in out disparity category e.g.
analysing historical network ows to create a baseline.
cloud provider security practices for data protection csc csc is vague and simply states that cloud provider security practices should be considered.
our revision to csc identi es requirements to review provisions for the isolation of virtual machines and mechanisms to restrict interactions between cohosted virtual machines.
fig.
also shows that nine new requirements were identied for csc which focuses on data protection and for csc which pertains to secure con gurations for hardware and software .
examples include the need for countermeasures against use of steganographic techniques and protocol tunnels for covert ex ltration figure proposed amendments to the ccs critical security controls v5.
monitoring connection patterns between endpoints for anomalous behaviour e.g.
suspect endpoint access or hosts acting as staging servers during attack preventing memory scraping operation of malware by adopting solutions for rapid erasure of data from memory or timely encryption of sensitive data e.g.
adding diversity or randomisation to data address spaces data at rest protection via automatic encryption in le systems databases and through negative databases .
.
discussion .
towards more effective security models security models such as csc20 embody a theoretical understanding of the threat landscape and the resultant security requirements at a particular instant in time.
they provide key domain knowledge about the known known security threats and associated requirements and can reasonably extrapolate to the known unknowns based on this knowledge.
the constantly mutating nature of security threats however poses a problem to the pertinence of such security models.
while unknown unknowns such as zero days will always pose a key security threat unknown knowns result in the security models being superseded by the relative mutation pace of existing threats and the sophistication of new threats.
this presents a key challenge as what is unknown known from the perspective of the requirements engineer may not be so from the perspective of the attacker.
furthermore while the attacker only needs to identify one unknown known the requirements engineer must seek to understand all possible unknown knowns or at least as many as possible.
while we do not claim completeness of the unknown knowns identi ed through our method such completeness is impossible given the diversity of security challenges in contemporary settings our analysis shows that we can saturate the identi cation of unknown knowns in a particular class of threats in our case data ex ltration with a manageble number of incidents .
our analysis identi ed partial and fully unknown known security requirements in a widely adopted security model.
this demonstrates both the e ectiveness of our approach and the scale of the challenge in order to keep security models in step with tacit knowledge embedded in incidents across space and time.
our approach provides a means for security models to evolve as this tacit knowledge does leading to richer models that aggregate and internalise cause e ect patterns across incidents.
.
partial vs. fully unknown known our experience highlights a further categorisation of unknown known security requirements.
partially unknown knowns capture mutations of existing threats leading to re nement 874or revision of existing domain knowledge underpinning security requirements.
the evolution of the covertness of c2 communication channels provides a good example of mutations of existing threats.
in response to c2 server domain names being blacklisted and c2 tra c showing as outliers on tra c ow analysis attackers are adapting their approaches e.g.
using social networks as a c2 server resolution service or blending c2 tra c with packets destined for cloud services.
fully unknown knowns on the other hand capture new and emergent threats and represent new domain knowledge that needs to be integrated into existing security models.
for instance novel ex ltration methods are continuously making the transition from the lab to the wild and the gestation period of a vulnerability exploit from its inception to its availability in popular exploit kits is now relatively short.
for example the once novel dns tunneling tools were made available in popular exploit kits such as metasploit and blackhole within months of their discovery.
new ex ltration schemes such as voip steganography concealing secret messages data within voip streams without severely degrading the quality of calls and use of timing channels are emerging threats for which existing security models have no control in place.
our approach also enables the identi cation of relevant points within an existing security model where such updates need to be applied.
its exible nature enabled us to structure the security model emerging from our analysis along the same classi cation as that utilised in csc20.
this in turn allowed a direct comparison across key concepts and controls in the two models to identify the various points at which re nements revisions or additions are needed.
.
ift as a linchpin for knowledge capture and aggregation because of the wealth of data contained within incident documentation the conventional grounded theory guidelines of describing and elaborating concepts in terms of their properties put the analysis process at risk of drifting too far into the description of an incident at the cost of its explanation.
ifts as the atomic model facilitate the causal explanations of incidents by enabling the selection and organisation of pertinent information which may otherwise be scattered in the documentation.
use of ift requires the analyst to actively search for the relevant incident event its causes enablers consequences and preventions.
this ensures that the analysis remains focused on drawing out explanations for the incident rather than documenting the incident s description.
the emphasis on causal relationships within an ift ensures that explanation is not traded o in favour of documentation.
furthermore the populated ifts provide a source of richly expressed domain knowledge otherwise scattered across raw data from a variety of incidents.
for instance the inhibit gates make it possible to pinpoint potential requirements with respect to speci c threats.
these in turn can be mapped to misuse cases describing sequence of actions taken by the attacker with respective remedial actions.
similarly the higher levels of an ift can be mapped to anti goals with lower levels mapping to goal re nements and tasks.
the remedial actions thus correspond to solutions to these anti goals tasks.
.
data and model quality as our work is based on a data driven method i.e.
themodel is rst and foremost extracted from the available data the quality of the input data is clearly critical.
of course the analyst should not choose a source that is irrelevant clearly mis directed or otherwise unsuitable.
the concerns about the quality of a given data source are further mitigated by using a number of di erent input sources and the key role of the analyst who systematically processes and questions the data by eliciting cause action result and e ect and lling in missing information through various iterations.
furthermore peer coding and feedback can also be used whereby more than one analyst independently processes the given data with the results of such independent work critically reviewed by peers in the team and then integrated and harmonised into an agreed upon model.
.
where do unknown knowns hide?
our experience shows that unknown known security requirements are implicit in patterns of cause e ect prevention relationships across a range of security incidents.
analysis of a single incident using an ift can reveal tacit knowledge relevant to that particular breach but not the patterns that can lead to identi cation of gaps in a prevalant conceptual model.
while the majority of unknown knowns hide in patterns across incidents we did identify instances e.g.
the vagueness of csc cloud provider security practices where typical patterns of imprecision can identify a lack of knowledge or the need to discover further knowledge to plug the gaps in the model.
identi cation of such gaps can guide the analyst in chosing incidents for analysis and or the search for particular unknown known security requirements.
.
conclusion and future work our method for discovering unknown known security requirements is aimed at re ning theoretical security models so that they remain pertinent in the face of a continuously changing threat landscape.
ifts enable the requirements engineer to perform causal analysis of the security incidents under consideration.
the rigorous and iterative processes of open coding and memo writing force the requirements engineer to rstly rationalise the creation of categories for new exploit threat and countermeasure concepts.
secondly by selecting incidents to analyse in an attempt to saturate the categories recorded in memos the requirements engineer ensures that requirements derived from these memos are as near complete as possible.
furthermore memo writing enables one to aggregate identi ed concepts extrapolate on them e.g.
consider the applicability of countermeasures to di erent threats and correlate various patterns of attacks and solutions across the analysed incidents.
thus the method ensures sophistication of coverage a orded by the coded countermeasures.
our evaluation in a real world context demonstrates that the rich picture resulting from the method indeed leads to identi cation of security requirements that may be partially or fully unknown known.
our future work will explore this distinction further aiming to derive a taxonomy of partially and fully unknown known security requirements to guide the analyst.
the qualitative nature of our method makes it possible to structure our derived model in a format that should enable comparison with any pre existing conceptual model to discover unknown knowns with respect to that model.
such investigation is another avenue for future work along with our method s potential to discover unknown knowns in domains other than security.
.