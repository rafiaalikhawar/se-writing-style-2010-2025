on essential configuration complexity measuring interactions in highly configurable systems jens meinicke 2chu pan wong 2christian k astner 2thomas th um 3gunter saake1 1university of magdeburg germany 2carnegie mellon university usa 3tu braunschweig germany abstract quality assurance for highly con gurable systems is challenging due to the exponentially growing con guration space.
interactions among multiple options can lead to surprising behaviors bugs and security vulnerabilities.
analyzing all congurations systematically might be possible though if most options do not interact or interactions follow speci c patterns that can be exploited by analysis tools.
to better understand interactions in practice we analyze program traces to characterize and identify where interactions occur on control ow and data.
to this end we developed a dynamic analysis for java based on variability aware execution and monitor executions of multiple small to medium sized programs.
we nd that the essential con guration complexity of these programs is indeed much lower than the combinatorial explosion of the con guration space indicates.
however we also discover that the interaction characteristics that allow scalable and complete analyses are more nuanced than what is exploited by existing state of the art quality assurance strategies.
ccs concepts software and its engineering !feature interaction reusability keywords feature interaction con gurable software variability aware execution .
introduction highly con gurable systems challenge program analyses and quality assurance.
fault detection through testing becomes problematic as the additional dimension of con gurability has to be considered a test case that succeeds in many con gurations may fail in others when con guration options interact .
con guration faults are common in practice but identifying interactions is di cult and challenging as the con guration space grows up to exponentially with the number of options .
unanticipated interactions can have consequences ranging from surprising behavior to security vulnerabilities and safety issues .
in practice the con guration space is rarely analyzed systematically ad hoc permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
copyrights for components of this work owned by others than acm must be honored.
abstracting with credit is permitted.
to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
request permissions from permissions acm.org.
ase september singapore singapore c acm.
isbn .
.
.
.
of few or only one con guration is still common and testing of other con gurations is often left to users at best combinatorial interaction testing is used to check for interactions among pairs of options .
as a consequence con guration faults are often only discovered by users .
despite their exponential growth there is hope for systematic or even complete analysis of con guration spaces.
investigations of bug reports have shown that most con guration faults are caused by interactions among only few options and several analysis tools have successfully demonstrated exploitable redundancies among con gurations to share commonalities while analyzing many con gurations at once .
our goal is to identify whether interactions occurring during program execution have characteristics that allow a complete analysis of the con guration space despite exponential surface complexity.
in contrast to prior work that focused primarily on interaction faults observable incorrect behavior reported in practice biased toward more popular con gurations we investigate all interactions in data andcontrol ow to measure what we call essential con guration complexity the con guration related di erences in an execution that actually need to be explored given an optimal execution strategy.
we designed a dynamic analysis tool called varexj that executes all con gurations simultaneously and allows us to inspect di erences in data and control ow at runtime.
in particular we use the tool to quantify the e ort required for analyzing all interactions assuming near optimal sharing.
analyzing executions of several medium sized con gurable java applications including jetty and checkstyle we nd that essential con guration complexity is indeed low enough to make a con guration complete analysis feasible but we also nd that some common and important characteristics of interactions are not exploited by state of the art analysis tools.
we show that the driver for the complexity is not how many options interact but how they interact on data.
our results help to understand the important characteristics for building e cient analyses for complete con guration spaces and our dynamic analysis can help developers to understand how options interact within their system possibly guiding their implementation toward reduced con guration complexity that is easier to understand and assure.
overall we contribute the following we implement a dynamic analysis for java that tracks interactions on data and control ow during executing.
we develop three measures that characterize essential con guration complexity measuring how options interact within an execution.
we design ve benchmarks to study how state of the art analysis approaches exploit interaction characteristics in exponential permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
copyrights for components of this work owned by others than acm must be honored.
abstracting with credit is permitted.
to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
request permissions from permissions acm.org.
ase september singapore singapore c acm.
... .
1boolean statistics smiley weather fahrenheit secure login 3void createhtml string c wpgetcontent if smiley c c.replace getsmiley if weather string weather getweather c c.replace weather string head initheader print html head head head body if statistics long time getcurrenttime printstatistics time print div c div string foot wpgenfooter print hr foot body html 21string getweather float temparature getcelsius if fahrenheit return temparature .
f return temparature c line number c it is true c wpgetcontent c choice it is weather img.. it is smiley choice true false weather choice true false fahrenheit choice true false statistics choice true false secure login choice true false c c.replace img.. true if smiley true if wheather weather getweather weather choice f c c chioce it is weather img.. choice choice it is f it is c it is c c.replace weather head hello world true print htmt .. head .. body true initheader figure feature interactions modeled after worldpress.
example source left a measurement of feature interactions middle and the start of a corresponding variability aware execution trace right descriptions at arrows display the executed statement with the corresponding context boxes show changes on the state.
con guration spaces exposing why certain approaches do not scale for certain kinds of interactions.
we measure the con guration complexity for medium sized systems nding that essential con guration complexity is low enough to enable con guration complete analyses.
we discuss common characteristics of interactions providing more nuanced variants of current assumptions which can among others encourage more e cient analyses for con guration spaces.
the tool and further information can be found on our website .
feature interactions a feature interaction describes the situation in which features modify or in uence another feature in describing or generating the system s overall behavior typically observable when the combined behavior of two features differs from the individual behaviors of both features .
for example one feature can interfere with or overwrite the e ects of another feature.
when both features are developed independently it can be di cult to predict such interactions.
the concept of feature interactions has gained attention in 90s when studied in the context of telecommunication systems .
in general a feature interaction is a failure of compositionality in the sense that the developers of features did not anticipate the interaction when combining them.
feature interactions are a common problem in software systems with con guration options and systems that are composed of di erent modules e.g.
plugins components they can lead to often behavior bugs and security vulnerabilities .
in the remainder of the paper we refer to features optional modules and options in a software system uniformly as con guration options and refer to a speci c combination of those as a con guration .
interactions may occur only in speci c con gurations and are thus di cult to detect a product working ne in one con gurationmay exhibit unexpected behavior when changing an unrelated option or installing a new plugin.
the exponentially growing con guration space challenges quality assurance.
at the same time isolating options to prevent interactions is often not possible because some options are designed to interact e.g.
intentionally exchanging speci c kinds of data among plugins or apps .
the challenge is to allow intended interactions but prevent or detect accidental ones.
as example of interactions among multiple options consider the code excerpt in figure modeled after the wordpress blogging software that is extensible by thousands of independently developed plugins.
options weather and fahrenheit interact purposefully to show the weather information in desired format.
however options smiley and weather can interact on the blog post s content in unintended ways such that the smiley code breaks weather s expansion of a tag rewriting it into weather .
there are di erent de nitions of what constitutes an interaction depending on what characteristics can be observed.
interaction faults tend to refer to issues in which we can observe a fault e.g.
a crash in an execution if and only if options are combined in speci c ways .
for the purpose of our discussion we understand as an interaction any trace or state di erence in the program that depends on two or more options even if it does not result in a crash or even observable behavior.
for instance in our wordpress example whether and how statistics are printed depends only on option statistics not an interaction but the value of cdepends on smiley weather and fahrenheit data interaction and whether line is executed depends on both weather and fahrenheit controlow interaction .
we consider interactions at the low level of data and control ow because they are measurable even without a speci cation of intended behavior.
with the degree of an interaction we refer to the number of options involved in the interaction typically interactions of higher degree occur in fewer con gurations and are harder to detect.
484our goal is to understand which interactions exist at all in software systems to inform the demands on quality assurance and speci cation techniques that can be used to detect interactions and to distinguish expected behavior from faults.
surface vs. essential con guration complexity.
on the surface analyzing the entire con guration space seems unrealistic because it grows exponentially with the number of con guration options.
a brute force approach executing each con guration separately is conceptually con guration complete .
that is it explores all variations but it is only feasible in practice for the smallest con guration spaces.
fortunately the amount of variability that actually induces di erences and interactions in the execution may be small enough to handle with a suitable analysis strategy.
we distinguish between surface con guration complexity exponential explosion with the number of options in the system and essential con guration complexity describing the actual di erences caused by options and their interactions.1for instance in our example only three of ve options a ect the blog post content and no option ever a ects the header.
we aim to capture essential con guration complexity with a con guration complete dynamic analysis that allows us to analyze which options really interact and how.
in addition we look for common characteristics of interactions that can be exploited by quality assurance strategies and developers.
quality assurance for large con guration spaces.
several quality assurance strategies have been developed for detecting interactions in large con guration spaces .
we focus on execution level approaches that can assure a speci c execution with given inputs over many con gurations for example checking whether a test case for an option s behavior such as replacing smilies by images passes independently of other options.
state of the art quality assurance strategies for large conguration spaces typically use one of two strategies to scale sampling based strategies execute the program only in selected con gurations and are thus not con guration complete .
that is they may miss interactions.
systematic sampling strategies such as combinatorial interaction testing can explore all interactions up to a given degree but may miss interactions with a higher degree .
their underlying assumption is that the essential complexity is much lower than the surface complexity in that most con guration options are orthogonal and most interactions are of a low degree .
sharing based strategies exploit lower essential complexity more directly through the observation that many executions in di erent con gurations are similar or even identical.
they attempt to reduce redundancies by sharing part of the execution.
in the simplest case identifying that an option is not used e.g.
option secure login in our example a con guration with and without that option will have identical traces .
more sophisticated approaches often build on top of heavy weight infrastructures such as model checkers and may share a pre x of the execution and fork it only once a computa1our notion of surface and essential con guration complexity is inspired by brook s discussion of accidental and essential complexity in software engineering in which essential complexity describes the unavoidable complexity of the problem overshadowed by accidental complexity from suboptimal languages tools and processes.tion depends on variability possibly even joining again to share subsequent executions .
sharingbased strategies tend to reduce unnecessary surface complexity often while remaining con guration complete .
the e ectiveness of both sampling based and sharing based strategies depend on the essential con guration complexity as well as the e ectiveness of the sampling and sharing mechanisms.
di erent approaches exploit di erent characteristics of interactions but there is little knowledge of actual characteristics.
the prevalence of low degree interactions is supported by observations of reported interaction faults but such results are potentially biased because faults in more popular con gurations are more likely to be reported.
in addition incomplete sampling based strategies are more readily available in practice and may primarily nd faults supporting their assumptions of low interaction degrees.
redundancy during execution has been successfully exploited by several approaches but scalability has been limited and it is unclear whether that is due to the essential con guration complexity or insu cient exploitation of redundancies.
.
measuring config.
complexity to assess con guration complexity and nd interaction characteristics we need a way to identify interactions in a software system s execution.
using a brute force approach we could attempt to record traces and state of the system in all con gurations and subsequently compare traces to assign di erences to options or interactions but scalability concerns would restrict us to systems with only few options.
similarly a sampling strategy is not suitable because we might not nd rare high degree interactions that could be part of the essential con guration complexity.
instead we designed a dynamic analysis that tracks all interactions during an execution using a sharing based strategy.
our dynamic analysis coordinates the execution of all con gurations which allows us to observe which statements and values actually di er among con gurations during the execution.
our analysis aggressively exploits sharing but has a high constant overhead and high engineering costs modifying an interpreter to track state and control ow of multiple con gurations at once giving up features such as just in time compilation .
ideally our results can inform the design of future tools that can exploit the important characteristics of interactions in a simpler and faster way.
our dynamic analysis is built on the idea of variabilityaware execution .
speci cally we have implemented varexj a variability aware interpreter for java bytecode and instrumented it to record interactions.
in the following we discuss how variability aware execution works and how we use it to assess essential con guration complexity.
.
variability aware execution a variability aware interpreter aims to maximally share redundant executions using conditional values and variability contexts at the cost of additional overhead for each computation .
a conditional value is a multi value that may have di erent concrete values in di erent partial conguration spaces .
a variability context is a formula that describes a partial con guration space.
let us illustrate conditional values by example choice x y is the representation of two alternative concrete values xfor all con gurations in variability context andyfor all others.
choice x choice x y choice x y illus485trates how choices can be nested to represent more than two alternative values and how they can be compressed to store only distinct values.
to compute with conditional values we have to apply operations to all alternative values.
that is we need to consider all valid combinations of values i.e.
the cross product in the worst case .
for example we compute the sum of two conditional values and compress the result as follows choice choice choice choice choice choice choice some computations may be performed only within selected con gurations.
to this end a variability aware interpreter keeps track of the variability context in which each instruction is executed similar to path conditions in symbolic execution .
the interpreter keeps track of all data using conditional values which enables a ne grained representation of shared data.
if for example the value of a eld di ers among congurations the values are stored as a choice in the eld but other elds of the same object are shared for the entire con guration space.
instead of splitting the entire heap variations are stored locally.
when computing with data we only have to compute with distinct values of all inputs of which there are typically much fewer than con gurations in the con guration space.
furthermore the compact representation using variability contexts in choices provides us with a way to track where options interact.
note how options occur only in variability contexts of choices but all values are concrete.
in contrast to symbolic execution symbolic con guration decisions do not intermix with concrete values.
hence all computations are performed with concrete values.
this separation of concrete and symbolic values enables computations without the undecidability issues from abstractions in symbolic execution therefore we rely on variability aware execution in our study.
we illustrate how a variability aware interpreter executes all program con gurations of our example with the partial trace in figure right .
the ve con guration options are initialized to both true andfalse with a condition.
subsequently the statement in line is executed once for all con gurations context true .
the ifstatement splits the execution such that line is executed in a restricted context forsmiley creating a choice in the heap for variable c. after the if block the statements can be shared again for all con gurations.
in line the method getweather is called returning a choice depending on the option fahrenheit .
variability aware execution only needs to invoke the method once returning a choice as result.
by applying the calculated weather to c the string replacement needs to be performed four times creating a choice that depends on three options with four distinct values.
finally the code from line can be shared again for all con gurations until code depends on conditional data again as in line and respectively.
a variability aware interpreter maximizes sharing of redundant calculations in two ways first variability aware execution moves on from one instruction to the next instruction sequentially only when every possible concrete value has been computed for the corresponding con guration space.
in other words variability aware execution achieves instruction level sharing among control ows of all possible con gurations.
second the di erence between program states is represented compactly using choices such that small di erences in local variables or heap objects can be represented without splittingthe entire program state.
in this way a variability aware interpreter achieves ne grained sharing among all executions.
implementation.
we implemented our variability aware interpreter varexj on top of javapathfinder s interpreter for java bytecode.
to implement variability aware execution we modi ed all bytecode instructions to handle conditional data we extended all shared data structures e.g.
the heap the method frame to store choices and we implemented a specialized scheduling mechanism.
those changes and the fact that varexj itself is written in java creates a high runtime overhead for each instruction a constant slowdown compared to a jvm of a factor in our experience .
as we build on top of javapathfinder we inherit the same limitations such as incomplete support for native methods and limited support for concurrency.
this overhead and these limitations might forbid using varexj for practical testing but it is acceptable for our explorations of con guration complexity.
the advantage of extending an interpreter is that we can monitor each java bytecode instruction to observe interactions during runtime.
to ensure the correctness of the implementation we compared the executed instructions to the execution of all single con gurations for several of our subject systems cf.
section .
more detailed descriptions of variability aware execution and our implementation can be found in the rst author s master s thesis and on our website.
.
measuring with varexj sharing executions and compactly representing data di erences our dynamic analysis can directly collect data about interactions.
our execution overapproximates essential interaction complexity where sharing is suboptimal.
technically we instrumented the execution of each java bytecode instruction to collect data on interactions to measure three metrics the controlow interaction degree the data interaction degree and the interaction overhead.
we exemplify the measurements for our running example in figure center .
with controlow interaction degree we measure con guration complexity on the control ow by assessing how many options need to be selected or deselected to execute the instruction at this point of the trace.
the degree increases at control ow decisions that depend on a con guration option in our example the instruction in line is executed with context weather fahrenheit thus this instruction s controlow interaction degree is two.
as our analysis already tracks the variability context during execution we merely need to log the number of options in the context for each executed instruction.
in our plots we visualize the controlow interaction degree as a red line along the trace.
a high value indicates part of an execution that is only triggered in few con gurations.
with data interaction degree we measure con guration complexity on data by assessing on how many options the resulting value of an instruction depends.
considering variability an instruction may need to be computed with alternative values and the result of the instruction may depend on one or multiple options of which we report the number of distinct options a ecting the value.
for example the expression computing cin line results in four alternative values depending on three di erent options resulting in a data interaction degree of three.
we measure the degree by inspecting the result of every instruction during execution and plot it as a green bar along the trace.
a high value indicates that some di erent results from a computation might be observable in few speci c con gurations only.
486finally with interaction overhead we measure the e ort required to execute an instruction considering data variability in the instruction s inputs.
if all inputs of an instruction have the same value in all con gurations we need to execute the instruction only once baseline overhead .
if one input has nalternative values in di erent con gurations we need to execute the instruction ntimes overhead n .
for instructions with multiple inputs e.g.
addition or method invocation we need to consider all combinations of alternatives of all inputs worst case overhead n mfor an instruction with two inputs withnandmalternatives respectively .
in contrast to interaction degree measures interaction overhead assesses the essential computational e ort from alternative values not how many options are involved.
for example in line the two values of weather are combined with the two values of c overhead .
we compute the interaction overhead by inspecting the variability in all inputs of each instruction and plot it as blue bars along the trace.
the interaction overhead is useful to compare essential complexity to the e ort for executing a single con guration comparing the aggregated overhead of all instructions with those of a single execution allows us to assess how many additional instructions have been executed and how many instructions need to be repeated due to variability.
all three measures assess di erent aspects of con guration complexity.
the interaction degree measures characterize interactions in control ow and data whereas interaction overhead approximates the e ort required for a con gurationcomplete analysis considering maximal sharing.
the trace for our example in figure illustrates how the measures peak every time data from interactions is created or accessed.
.
interaction benchmarks after introducing how we measure con guration complexity technically we illustrate how certain kinds of interactions a ect essential con guration complexity with a series of benchmarks.
the benchmarks provide a sanity check for our measures of con guration complexity before we collect and interpret the measures on real world systems.
additionally they allow us to study how well existing sharing based analysis tools exploit redundancies and which interaction characteristics they exploit.
this enables us later to extrapolate which analysis strategies can cope with characteristics found in real world software systems.
we designed ve benchmarks shown in table that each exhibit di erent interaction characteristics in a short execution.
in the second column we plot the measured con guration complexity.
additionally we compare execution time executed instructions and memory consumption of ve stateof the art analysis tools splat jpf core jpfbdd jpf se and varexj .
we do not evaluate sampling based strategies as our benchmarks are speci cally designed to produce high degree interactions.
speci cally we address the following research question rq what are the e ects of di erent kinds of interactions on the scalability and performance of state of the art execution mechanisms?
.
experimental setup evaluated analysis tools.
we compare ve state of theart analysis tools that have been designed to e ciently execute a program over con guration spaces by ghting surface complexity through di erent kinds of sharing.
some of these tools have been designed originally for di erent purposes such as model checking safety properties but they have been suggested also for analyzing interactions or testing highly con gurable systems.
we selected tools that represent di erent analysis and sharing strategies identifying unnecessary options software model checking and symbolic execution.
in addition we use the uninstrumented version of our variability aware interpreter varexj as a representative for variability aware execution.
the tools are comparable in the sense that they all target java and are mostly based on the same infrastructure namely javapathfinder .
jpf core javapathfinder is a model checker for java bytecode that handles bytecode instructions as transitions between states .
jpf core can be used to split execution paths for boolean options and explore all possible paths.
if all values of elds and variables are equivalent jpf core can join separated paths and share subsequent executions.
jpf bdd extends jpf core by separating tracking of boolean options .
by taking options out of the state states can be merged if they di er only by options increasing the chance for joining and thus sharing.
jpf se is a symbolic extension of javapathfinder designed for test generation.
if a variable is assigned with a symbolic value the search tree splits but due to challenges in matching symbolic states states are never merged.
finally splat instruments a program to dynamically detect which con guration options are used in an execution .
it reexecutes the program until all combinations of used options are explored.
although splat does not share any actual executions it can narrow down the con guration space if only a subset of con gurations have an e ect on the execution trace e.g.
for unit tests .
as the tool is not publicly available we reimplemented it for java.
benchmarks and metrics.
we design ve small benchmark programs characterizing favorable and critical cases for interactions among con guration options.
we show all benchmarks in table and explain them and their rationale together with the results.
all benchmarks are reduced to distill the interaction e ect in a very concise setting.
each benchmark can be scaled in the number of involved con guration options such that we can observe scalability with regard to the exponentially growing surface con guration complexity.
we plot the complexity measures for an execution with options to illustrate the general trend.
for each tool we report the performance measures time instructions and memory consumptions for executing the benchmark with di erent numbers of options to .
we measured them all using internal metrics of javapathfinder and built a separate harness for splat .
as we face an exponential problem we terminate executions that exceed two minutes.
to reduce measurement bias we report the average of three runs.
.
sharing potential for each benchmark we discuss the interaction characteristic it simulates reasons for the con guration complexity and the performance measures indicating which tools scale.
b1 explosion.
we start with the worst case of interactions in which all options interact on the same value and yield a different result in every con guration.
in such case every exhaustive technique needs to track an exponential number of alternative values.
as visible from the complexity measures early and some later instructions e.g.
if statements in the benchmark are a ected by fewer con gurations and can be shared.
487table benchmarks to simulate di erent kinds of interactions left .
the diagrams in the second column illustrate interactions for each program measured using variability aware execution.
the three diagrams on the right show the performance results for time executed instructions and memory consumptions for ve analysis tools.
performance measures benchmark complexity measures time in seconds instructions in memory in mbb1 explosionboolean o1 o2 ... void method int i if o1 i if o2 i ... 2000200400600interaction degree data interaction overhead interaction degree control flow 020406080100120jpf core jpf bdd jpf se splat varexj 0200400600800b2 deep nestingboolean o1 o2 ... void method int i if o1 i if o2 i ... 01020304050b3 distinct valuesboolean o1 o2 ... void method int i if o1 i if o2 i ... 0100200300400500600b4 separate valuesboolean o1 o2 ... int i1 i2 ... void method if o1 i1 if o2 i2 ... 0200400600800b5 no data int.boolean o1 o2 ... void method if o1 print if o2 print ... options options options however no tool can be expected to scale as they all face essential con guration complexity growing exponentially with the number of options as visible in all performance measures.
if these kinds of interactions are common in practice there would be little hope for con guration complete analyses.
b2 deep nesting.
next we explore the e ect of dependencies among options leading to a lower essential con guration complexity with a linear number of distinct execution traces.
whereas b1 had independent decisions for each option resulting in 2nexecution traces b2 models nested decisions resulting in n 1execution traces for noptions.
the complexity measure shows the linear increase in overhead as additions are performed on values with increasingly many alternative values.
also the interaction degree measures grow linear as more and more options need to be selected.
again we can see that several instructions that do not manipulate variableicould be shared.
our performance measures show that this kind of interaction is well supported by all approaches.
as all tools only split lazily where necessary there are nearly linear increases with more options in all performance measures.
simpler tools outperform tools with higher constant overhead as exploiting additional sharing has only marginal e ects.
b3 distinct values.
sharing becomes feasible if interactions on a variable produce a small number of distinct values.
in benchmark b3 each option increases a value by resulting inn 1distinct values for noptions.
therefore essential con guration complexity grows linearly with the number of con gurations.
our performance measurements indicate thatjpf core andjpf se require exponential e ort as they need to split the execution on every ifstatement but cannot join them again jpf se never joins and jpf core cannot join as the values representing the options have dif488ferent values in di erent states.
without data sharing also splat requires exponential e ort because all options have an independent e ect on the execution trace.
jpf bdd and varexj both track the n 1distinct values separately from the variations in con guration options which enables them to perform closer to the linear growing essential con guration complexity.
varexj executes fewer instructions and requires less memory than jpf bdd by exploiting additional sharing which however has no bene ts for the execution time due to the additional overhead.
b4 interactions on separate values.
if options a ect disjoint parts of the state essential con guration complexity can be very low.
benchmark b4 exhibits an interaction in which each option a ects a di erent variable without any data interaction.
despite an exponential number of execution traces and distinct states each variable has only two alternative values and and as such the essential con guration complexity is low.
as the performance measures show jpf core jpf se jpf bdd and splat all require exponential e ort as they do not exploit sharing for this interaction characteristic.
all approaches split on each if statement and none can join the states again.
even jpf bdd cannot join as non option values di er across con gurations.
only varexj approaches the low essential complexity.
b5 no interactions on data.
finally we eliminate all data interactions such that only controlow interactions remain i.e.
an exponential number of di erent execution traces all with the same states .
essential con guration complexity is low as in b4.
jpf bdd andvarexj both execute each instruction on a single state without interaction overhead as all variability of options is handled separately.
in contrast splat still needs to explore all execution traces and jpf core andjpf se track di erent con guration values as part of their split state resulting in exponential behavior.
lessons learned.
even when essential con guration complexity is low missing to exploit suitable forms of sharing for certain characteristics of interactions can result in exponential execution e orts.
a program with negligible essential complexity e.g.
without any data interaction as in b4 can cause exponential behavior in state of the art approaches.
finding such kind of interaction characteristics in real world programs would be a great opportunity for quality assurance as it indicates a high potential for con guration complete analysis with sharing based approaches.
.
real world interactions to assess essential con guration complexity of executions in real world software we applied variability aware execution to eight con gurable systems shown in table .
we selected four con gurable medium sized systems from di erent domains the http server jetty the in memory database prevayler the static analysis tool checkstyle and the academic evaluation framework for database index structures queval .
in addition we included systems previously used as benchmarks in research on con gurable systems the systems minepump e mail and elevator are small academic java programs that were designed with many interacting options gpl is a small scale con gurable graph library often used for evaluations in the product line community.
all these systems are executable with varexj .
to investigate interactions in con gurable systems we pose the following research question rq what is the essential con guration complexity of real world software?table subject systems analyzed for con guration complexity and their sizes in lines of code number of options and con gurations number of instructions executed with varexj the aggregated interaction overhead pio the average number of instructions for single con gurations inst.
and lower bound for line coverage reached with the sample method.
system loc opt.
conf.
inst.vapio inst.
cov.
jetty 12m 12m 12m checkstyle 2135407m 421m 198m prevayler 28m 29m 15m queval 81m 94m 1m elevator 89k 100k 29k gpl 17m 17m 9m e mail 48k 55k 16k minepump 14k 16k 14k particularly we are interested in whether our measures for con guration complexity con rm current assumptions based on error reports and program outputs or whether they provide additional insights.
experimental setup.
we execute all subject systems over all con gurations with varexj .
for each system we measure con guration complexity for a xed standard input a sample input distributed with queval a source le with lines for checkstyle and a sample application provided with prevayler.
for jetty we deploy a web application that is capable of serving static content as well as running simple servlets.
as the traces often contain several million instructions we aggregate max subsequent instructions in our plots.
we share the evaluation setup together with our implementation.
interactions in real world software.
we show ve representative traces in figure the remaining traces can be found on our website.
in all systems we can observe a small average interaction overhead throughout most of the trace and usually small interaction degrees i.e.
most instructions can be shared in large con guration spaces .
the traces also show that options do not interact increasingly across the entire executions.
some individual results are noteworthy first the elevator system was speci cally designed to exhibit many interactions .
its trace shows that several interactions on data cause an interaction overhead of up to .
however most instructions in the trace have an overhead of at most two.
many instructions are executed in restricted contexts though requiring up to ve options.
second gpl is a common system for evaluations in the product line community including prior studies of sharing and veri cation .
the system has only some minor interactions with an interaction overhead of mostly two and a interaction degrees of mostly one option.
options do not interact at all for most parts of the trace.
however at the end of the execution up to eight options interact on the same data.
third we observed the strongest data interactions in queval .
queval implements several database index structures which can be customized with several options signi cantly changing the behavior of the entire system.
the trace shows that there are long sequences with similar overhead in the execution.
this is caused by separate processing of each index structure.
some values interact strongly causing an overhead of among con gurations .
however the trace still shows that high interaction degrees are rare and many instructions can be shared after and between them.
in queval there are multiple interactions that cause high a elevator b gpl c queval d prevayler e checkstyle figure traces and interaction overhead of variability aware execution for larger software.
each bar represents the highest value per instructions per for elevator .
interaction degrees on data and control ow.
especially in the last part of the execution data interactions similar to benchmark b1 can be observed for a subset of the options.
fourth checkstyle is a good example for a trace with particularly few interactions.
the system implements many optional and independent checks that are not supposed to interact.
however the trace shows that there are still high degree interactions in checkstyle mostly caused by optional caching resulting in a similar behavior as in the benchmark b3 in a subset of the trace.
also in jetty trace not shown we similarly observe that most options have only minimal inuences on the trace we found no interactions on data at all.
throughout all systems we observe essential con guration complexity that is far lower than surface complexity may indicate.
the amount of essential con guration complexity di ers by system though from almost negligible checkstyle jetty gpl to medium elevator prevayler to signi cant queval .
comparing the aggregated interaction overhead with the average number of instructions executed without variability shown in table cf.
sec.
.
we can see that a system executing close to essential con guration complexity would usually only have to execute times more instructions than an average execution of a single con guration.
only queval had a signi cant interaction overhead compared to an average execution of individual con gurations but that can be explained largely by executions for alternative options.
in general the overhead is much lower than the overhead of factor to 2135a brute force approach would require and could potentially even beat some sampling strategies that reexecute each sampled con guration.
in its current form due to the high overhead per instruction varexj cannot achieve this speedup compared to a standard jvm.2however our results indicate that essential 2when compared to executing a single con guration with varexj s own interpreter we observe performance overheads between .0x jetty and .7x gpl for most systems and 190x for queval in line with the measured interaction over complexity is low and there is hope for the community to develop e cient con guration complete analysis techniques.
threats to validity.
concrete results from our measurements should be generalized only carefully our focus is on establishing metrics for con guration complexity not on proving characteristics of programs in general practice.
external validity is limited by the number and size of our subject systems.
as described we selected the small programs representing critical and paradigmatic cases whereas we used convenience sampling for the medium sized systems primarily due to current technical limitations of our interpreter and the high engineering e ort to execute further and larger systems.
our subject systems are diverse but their characteristics may not generalize for other systems.
as described we executed each system with only one input.
thus we potentially miss interactions that occur only with other inputs.
nonetheless we execute each program s main method with a representative input which in each system covers all con guration options and a large amount of its code as the measured line coverage in table indicates.
to interpret our results it is important to remember as discussed in sec.
that we de ne interactions as any di erences during the execution triggered by options not just externally visible di erences or defects.
this decision is deliberate to study interactions and execution methods in general independent of defects they may cause.
.
discussion characteristics of interactions in section we have shown that despite exponential surface complexity many kinds of interactions actually have low essential complexity which can be exploited by suitable sharing based analyses.
in section we have subsequently shown that also real world systems typically have a much lower essential complexity than it may appear on the surface.
head.
detailed performance measurements are outside the scope of this paper but can be found on our website.
490however we have also seen that interactions in real world systems have characteristics that are more nuanced than expected by existing approaches.
therefore we conclude with a discussion of observed characteristics that may inform the design of future analysis approaches and may also be informative for developers concerned about interactions in their code.
we identify three main characteristics that are exploited though not always explicitly by existing analyses irrelevant variability orthogonal variability and local variability.
irrelevant variability.
some options may not have any e ect on an execution at all.
even when a program has a large con guration space some executions such as test cases may not even read certain con guration options.
if no con guration of an execution ever reads a con guration option we call such execution una ected by the option e.g.
option secure login in our example of figure .
in addition some options may never be read unless another option is de activated in which the rst option depends on the second e.g.
fahrenheit depends on weather in our example .
in both cases the number of distinct executions is smaller than the exponential surface complexity indicates.
all sharing based approaches exploit irrelevant variability as shown with benchmark b2.
although irrelevant variability was attributed with signi cant speedups for test cases in prior work none of our real world executions bene ted from una ected variability without rewriting the system to initialize options lazily all options were always read and initialized .
dependencies reduced the search space but never close to essential con guration complexity.
orthogonal variability.
many options may not interact with each other.
although potentially every option could interact with every other option resulting in exponential surface complexity a common assumption is that most options do not interact.
we say two options are orthogonal if combining both options does not yield any new behavior that could not be explained by either option alone.
some options may be strictly orthogonal and not interact with any other option e.g.
option statistics is strictly orthogonal to all other options in our example but it is more common to assume low interaction degrees where each change can be explained by the interaction of at most two or three options e.g.
options smiley weather and fahrenheit all interact on the blog post but not with any other options .
the e ectiveness of sampling strategies typically hinges on low interaction degrees see sec.
whereas most existing sharing based approaches are rather ine cient in exploiting orthogonality especially when options a ect data as apparent from benchmarks b4 and b5.
our real world executions con rm that many options are orthogonal but also show that one should not rely on low interaction degrees alone we found high interaction degrees e.g.
in checkstyle in most systems but also found that those involve some options while others remain mostly orthogonal.
we argue that rare high interaction degrees is a more accurate characterization of interactions in real world systems encouraging research into con guration complete analyses.
local variability.
an option may a ect control ow and data during an execution but its e ects might not spread across the entire execution trace resulting in much lower essential con guration complexity than surface complexity.
with locality we might need to invest more e ort to execute part of the trace repeatedly for di erent con gurations but we can share e ort in other parts.
in our example optiontable interaction characteristics exploited by di erent analysis approaches.
exploited partially exploited.
una ecteddependingstrictly orthogonallow interaction d.high interaction d.pre x sharingstrictly localscattered localeng.
runtime ov.
combinatorial testing very low splat low jpf high jpf se very high jpf bdd high varexj very high statistics produces additional output but does not a ect earlier or subsequent instructions neither through control ow nor through data in stack or heap.
many sharing based approaches exploit locality by sharing executions before the option s e ect and possibly also after see sec.
.
existing sharing based approaches di er in what forms of locality can be exploited though.
many approaches can share a common pre x of the execution trace pre x sharing and split late on the rst instruction depending on an option.
some approaches can join after local instructions if those instructions do not a ect the state as option statisticsin our example and in benchmark b5 strictly local .
interactions that a ect some state that is however not read again subsequently see benchmark b4 are rarely supported.
a much more common pattern in the observed real world executions is what we call scattered local options a ect the trace locally and cause some changes to the program s state but many subsequent instructions can be shared before that changed state is accessed again.
in our example multiple options a ect the value of c but subsequent instructions can be shared until cis read again at the end of the method.
this is an e ect which we observed as gaps between peaks in the measures of our benchmarks and the real world executions.
in all cases we see strong evidence of locality in that essential con guration complexity always returns to lower values after peaks.
outlook.
we observed that essential con guration complexity is often low and exploiting irrelevant variability orthogonal variability and local variability is a promising avenue to scale analysis approaches.
however we also found that supporting the more nuanced characteristics of rare high interaction degrees andscattered local e ects are essential for scaling sharing based approaches to large con guration spaces.
we summarize which properties are supported by each of the discussed tools in table .
currently the tools that exploit more characteristics are also based on a more heavy weight infrastructure i.e.
higher engineering e ort for the analysis and higher runtime e ort to execute individual instructions .
we hope that our analysis infrastructure helps to identify a sweet spot for exploiting the most relevant interaction characteristics without the overhead of our current dynamic analysis implementation in varexj .
in several traces we measured interactions of which not all might be intended.
we conjecture that our dynamic analysis might be useful for developers to understand the sources of interactions and to build maintainable and assurable software.
.
related work characteristics of interactions.
despite much research on highly con gurable systems the nature of con gurationrelated interactions is not well understood especially at the code level.
in studying bug reports many studies found that the majority of reported con guration related bugs are caused by individual options or interactions among only few options with only few defects at higher degrees but none of these studies is based on a con gurationcomplete analysis.
manual search for feature interactions in requirements in telecommunications and electronic mail has focused primarily on pairwise interactions .
the few studies that systematically analyzed entire con guration spaces found also interactions among more options such as a linker fault in busybox that involved options .
where prior work primarily focused on the degree of interaction faults we de ne and monitor measures for interaction degrees and interaction overhead to assess con guration complexity of both data and control ow interactions.
closest to our analysis of interactions at the execution level reisner et al.
used symbolic execution to explore di erent paths of test cases in three c programs 14kloc options and found interactions among of options in one system .
executing con gurations separately they measured the e ect of interactions on control ow only with the goal of increasing test coverage whereas we speci cally monitor the e ect of interactions on data to measure con guration complexity to assess whether a con guration complete approach is feasible especially regarding the di erent notions of local variability e.g.
using benchmarks b3 b5 and the complexity measure of interaction overhead.
analyses for con gurable systems.
as already discussed in sec.
analysis strategies for con guration spaces are usually based on sampling or sharing.
combinatorial interaction testing is a state of the art sampling strategy to guarantee coverage of all combinations among con guration options .
researchers have explored many other sampling strategies for con guration spaces using machine learning or optimizing code coverage that all exploit similar assumptions of irrelevant or orthogonal variability.
the software product line community has extensively investigated strategies to analyze large con guration spaces through sharing .
although the sharing techniques di er in details they often follow similar ideas of analyzing the entire system at once splitting where necessary and joining at ne granularity.
many techniques have been explored for e cient representation and reasoning about partial con guration spaces .
our dynamic analysis based on variability aware execution adopts many of those insights from static analyses to dynamic execution of programs.
several researchers have recently explored forms of variability aware execution that aggressively exploit sharing during the execution of alternatives of a program particularly exploiting locality of options in control ow and data by storing variations locally with choices.
variability aware interpreters for the while language and a subset of php have demonstrated signi cant possible speedups over a brute force approach.
kim s shared execution also based on javapathfinder exploits sharing within functions though not across function boundaries evaluated on small scale java programs .
austin and collaborators have explored the same concepts for javascript and a subset of python framed in the context of secure information ow analysis .
our dynamic analysis in varexj is built onthe same ideas and is the rst variability aware interpreter that supports a full mainstream programming language and can analyze existing programs of signi cant size.
some researchers have additionally explored static strategies to identify the scope of options and other changes as well as their potential interactions based on slicing or dataow analysis .
while such analyses can identify potential interactions without the need of speci c inputs static analyses are conservative and tend to signi cantly over approximate potential interactions.
instead of detecting interactions some approaches aim to identify the cause of a con guration fault once it occurs or automatically resolve interactions with a default strategy .
such approaches are orthogonal to our analysis.
analyses beyond con gurable systems.
addressing exponentially growing search spaces through some form of sharing is common for analyses in many domains.
for example even in nite models the search space in model checking often exceeds the available memory known as the state space explosion problem .
symbolic model checking approaches increase sharing by representing states more compactly with symbolic techniques .
other techniques have been explored to further reduce redundancies in state representations such as separation of frequently changing values and compact encoding and manipulation of multiple states .
our results can indicate the expected e ectiveness of each sharing strategy when applied to conguration spaces based on the expected characteristics of interactions as discussed in sec.
and .
our dynamic analysis monitors di erences among multiple executions similar to concepts of multi execution .
most multi execution approaches execute variants separately and use external synchronization mechanisms though some approaches explicitly share redundancies but only for a small number of variants usually two .
in contrast we explicitly monitor interactions among multiple options in an exponential con guration space.
.
conclusion undesired interactions challenge quality assurance for highlycon gurable software as they are typically unknown and can result in faults and security vulnerabilities.
their detection is a challenge as the con guration space of such systems grows up to exponentially in the number of con guration options.
existing analyses try to scale with assumptions about interactions.
however whether these assumptions are valid and how much we can speed up analyses in future is not well understood.
with varexj we implemented a dynamic analysis for java to quantify di erent characteristics of interactions with benchmarks and to analyze real world programs.
we found that essential con guration complexity induced by real world interactions is usually low making con guration complete analyses feasible.
based on our insights we discussed typical characteristics of interactions which can be exploited by future approaches for quality assurance of con gurable systems.
.