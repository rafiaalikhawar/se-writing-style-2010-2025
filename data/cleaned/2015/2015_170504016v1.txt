auto completing bug reports for android applications kevin moran mario linares v squez carlos bernal c rdenas denys poshyvanyk college of william mary department of computer science williamsburg va usa kpmoran mlinarev cebernal denys cs.wm.edu abstract the modern software development landscape has seen a shift in focus toward mobile applications as tablets and smartphones near ubiquitous adoption.
due to this trend the complexity of these apps has been increasing making development and maintenance challenging.
additionally current bug tracking systems are not able to e ectively support construction of reports with actionable information that directly lead to a bug s resolution.
to address the need for an improved reporting system we introduce a novel solution called fusion that helps users auto complete reproduction steps in bug reports for mobile apps.
fusion links userprovided information to program artifacts extracted through static and dynamic analysis performed before testing or release.
the approach that fusion employs is generalizable to other current mobile software platforms and constitutes a new method by which o device bug reporting can be conducted for mobile software projects.
in a study involving participants we applied fusion to support the maintenance tasks of reporting and reproducing defects from real world bugs found in open source android apps while qualitatively and qualitatively measuring the user experience of the system.
our results demonstrate that fusion both e ectively facilitates reporting and allows for more reliable reproduction of bugs from reports compared to traditional issue tracking systems by presenting more detailed contextual app information.
categories and subject descriptors d. .
distribution maintenance and enhancement general terms experimentation design keywords bug reports android reproduction steps auto completion1.
introduction smartphones and mobile computing have skyrocketed in popularity in recent years and adoption has reached nearubiquitous levels with over .
billion active smartphone users in .
an increased demand for high quality robust mobile applications is being driven by a growing user base that performs an increasing number of computing tasks on smart devices.
due to this demand the complexity of mobile applications has been increasing making development and maintenance challenging.
the intense competition present in mobile application marketplaces like google play and the apple app store means that if an app is not performing as expected due to bugs or lack of desired features of users are less likely to use the app again and will abandon it for another one with similar functionality .
software maintenance activities are known to be generally expensive and challenging .
one of the most important maintenance tasks is bug report resolution.
however current bug tracking systems such as bugzilla mantis the google code issue tracker the github issue tracker and commercial solutions such as jira rely mostly on unstructured natural language bug descriptions.
these descriptions can be augmented with les uploaded by the reporters e.g.
screenshots .
as an important component of bug reports reproduction steps are expected to be reported in a structured and descriptive way but the quality of description mostly depends on the reporter s experience and attitude towards providing enough information.
therefore the reporting process can be cumbersome and the additional e ort means that many users are unlikely to enhance their reports with extra information .
a past survey of open source developers conducted by koru et al.
has shown that only of developers believe bug reports are always complete .
previous studies have also shown that the information most useful to developers is often the most di cult for reporters to provide and that the lack of this information is a major reason behind nonreproducible bug reports .
di culty providing such information especially reproduction steps is compounded in the context of mobile applications due to their complex event driven and gui based nature.
furthermore many bug reports are created from textual descriptions of problems in user reviews.
according to a recent study by chen et al.
only a reduced set of user reviews can be considered useful and or informative.
also unlike issue reports reviews do not refer to app implementation details.
the above issues point to a more prominent problem for bug tracking systems in general the lexical gap that nor arxiv .04016v1 may 2017mally exists between bug reporters e.g.
testers beta users and developers.
reporters typically only have functional knowledge of an app even if they have development experience themselves whereas the developers working on an app tend to have intimate code level knowledge.
in fact a recent study conducted by huo et al.
corroborates the existence of this knowledge gap as they found there is a di erence between the way experts and non experts write bug reports as measured by textual similarity metrics .
when a developer reads and attempts to comprehend or reproduce a bug report she has to bridge this gap reasoning about the code level problems from the high level functional description in the bug report.
if the lexical gap is too wide the developer may not be able to reproduce and or subsequently resolve the bug report.
to address this fundamental problem of making bug reports more useful and reproducible for developers we introduce a novel approach which we call fusion that relies on a novel analyze!generate paradigm to enable the autocompletion of android bug reports in order to provide more actionable information to developers.
in the context of this work we de ne auto completion as suggesting relevant actions screen shots and images of speci c gui components to the user in order to facilitate reporting the steps for reproducing a bug.
fusion rst uses fully automated static and dynamic analysis techniques to gather screen shots and other relevant information about an app before it is released for testing.
reporters then interact with the web based report generator using the auto completion features in order to provide the bug reproduction steps.
by linking the information provided by the user with features extracted through static and dynamic analyses fusion presents an augmented bug report to the developer that contains immediately actionable information with well de ned steps to reproduce a bug.
we evaluate fusion in a study comparing bug reports submitted using our system to bug reports produced using google code issue tracker involving participants reporting bugs for real world failures stemming from open source android apps.
our paper makes the following noteworthy contributions .
we design and implement a novel approach for autocompleting and augmenting android bug reports called fusion which leverages static and dynamic analyses and provides actionable information to developers.
the tool facilitates the reporting reproduction and subsequent resolution of android bugs.
the program analysis techniques of the apps can be run on both physical devices and emulators .
we design and carry out a comprehensive user study to evaluate the user experience of our approach and the quality of bug reports generated using fusion compared to the google code issue tracker.
the results of this study demonstrate that fusion enables developers to submit bug reports that are more likely to be reproducible compared to reports written entirely in natural language .
we make fusion and all the data from the experiments available for researchers in hope that this work spurs new research related to improving the quality of bug reports and bug reporting systems.
.
state of research and practice bug and error reporting has been an active area of research in the software engineering community.
however little work has been conducted to improve the lack of structure in the reporting mechanism for entering reproduction steps and adding corresponding support in bug tracking systems.
therefore in this section we brie y survey the features of current bug reporting systems and the studies that motivated this work.
then we di erentiate our work from approaches for reproducing in eld failures and explain how our work compliments existing research on bug reporting.
.
existing bug reporting systems most current issue tracking systems rely upon unstructured natural language descriptions in their reports.
however some systems do o er more functionality.
for instance the google code issue tracker gcit o ers a semistructured area where reporters can enter reproduction steps and expected input output in natural language form i.e.
the online form asks what steps will reproduce the problem?
.
nearly all current issue trackers o er structured elds to enter information such as tags severity level assignee x time and product program speci cations.
some web based bug reporting systems e.g.
bugzilla jira mantis usersnap bugdigger facilitate reporters including screenshots.
however current bug tracking systems do not integrate online suggestion of relevant reproduction steps with screenshots as fusion does.
.
bug reporting studies the problem facing many current bug reporting systems is that typical natural language reports capture a coarse grained level of detail that makes developer reasoning about defects di cult.
this highlights the underlying task that bug reporting systems must accomplish bridging the lexical knowledge gap between typical reporters of a bug and the developers that must resolve the bugs.
previous studies on bug report quality and developer information needs highlight several factors that can impact the quality of bug reports other than interbug dependencies i.e.
a situation where a bug was xed in a previous patch insu cient information is one of the leading causes of nonreproducible bug reports developers consider i steps to reproduce ii stack traces and iii test cases scenarios as the most helpful sources of information in a bug report information needs are greatest early in a bug s life cycle therefore a way to easily add the above features is important during bug report creation .
using these issues as motivation we developed fusion with two major goals in mind i provide bug reports to developers with immediately actionable knowledge reliable reproduction steps and ii facilitate reporting by providing this information through an auto completion mechanism.
it is worth noting that one previous study conducted by bhattacharya et al concluded that most android bug reports for open source apps are of high quality however in their study only of bug report contained steps to reproduce and even fewer contained additional information e.g.
bug triggering input or even an app version .therefore there is clearly room for improvement in terms of the type of information that is contained within open source android bug reports.
.
in field failure reproduction a body of work known as in eld failure reproduction shares similar goals with our approach.
these techniques collect run time information e.g.
execution traces from instrumented programs that provide developers with a better understanding of the causes of an in eld failure which will subsequently help expedite the xing of those failures.
however there are several key differences that set our work apart and illustrate how fusion improves upon the state of research.
first techniques regarding in eld failure reproduction rely on potentially expensive program instrumentation which requires developers to modify code and introduce overhead.
fusion is completely automatic our static and dynamic analysis techniques only need to be applied once for the version of the program that is released for testing.
furthermore the analysis process can be done without the need for instrumentation of programs in the eld.
second current in eld failure reproduction techniques require an oracle to signify when a failure has occurred e.g.
a crash .
fusion is not an approach for crash or failure detection it is designed to support testers during the bug reporting process.
third these techniques have not been applied to mobile apps and would most likely need to be optimized further to be applicable for the corresponding resource constrained enviornment.
.
bug and error reporting research a subset of prior work has focused on bug and crash triage .
the techniques associated with this topic typically employ di erent program analysis and machine learning or natural language processing techniques to match bug reports with appropriate developers.
our proposed research compliments developer recommendation frameworks as fusion can provide these frameworks with more detailed knowledge than current state of practice bug reporting systems.
a signi cant amount of research has been conducted concerning the summarization fault localization classication and detection of duplicate bug reports .
again the work presented in this paper compliments these categories of research as bug reports created with fusion can provide more detailed information easily linking the bug back to source code allowing for better localization summarization and potentially duplicate detection.
it is worth noting that work by bettenburg et al on extracting structural information from bug reports is also related however we aim at helping auto complete the structured reproduction steps at the time of report creation rather than extracting it after the fact .
.
the fusion approach fusion s analyze!generate work ow corresponds to two major phases.
in the analysis phase fusion collects information related to the gui components and event ow of an app through a combination of static and dynamic analysis.
then in the report generation phase fusion takes advantage of the gui centric nature of mobile apps to both auto complete the steps to reproduce the bug andaugment each step with contextual application information.
the overall design of fusion can be seen in figure .
we encourage readers to view videos of our tool in use complete with commentary available in our replication package outlined in section and online at .
.
analysis phase the analysis phase collects all of the information required for the report generation phase operation.
this rst phase has two major components static analysis primer and dynamic program analysis engine of a target app.
the analysis phase must be performed before each version of an app is released for testing or before it is published to end users.
both components of the analysis phase store their extracted data in the fusion database fig.
.
.
.
static analysis primer the goal of the primer fig.
is to extract all of the gui components and associated information from the app source code.
for each gui component the primer extracts i possible actions on that component ii type of the component e.g.
button spinner iii activities the component is contained within and iv class les where the component is instantiated.
thus this phase gives us a universe of possible components within the domain of the application and establishes traceability links connecting gui components that reporters operate upon to code speci c information such as the class or activity they are located within.
the primer is comprised of several steps to extract the information outlined above.
first it uses the dex2jar and jd cmd tools for decompilation then it converts the source les to an xml based representation using srcml .
we also use apktool to extract the resource les from the app s apk.
the ids and types of gui components were extracted from the xml les located in the app s resource folders i.e.
res layout and res menu of the decompiled application or src .
using the srcml representation of the source code we are able to parse and link the gui component information to extracted app source les.
.
.
dynamic analysis engine the engine fig.
is used to glean dynamic contextual information such as the location of the gui component on the screen and enhance the database with both run time gui and application eventow information.
the goal of the engine is to explore an app in a systematic manner ripping and extracting run time information related to the gui components during execution including i the text associated with di erent gui components e.g.
the send text on a button to send an email message ii whether the gui component triggers a transition to a di erent activity iii the action performed on the gui component during systematic execution iv full screen shots before and after each action is performed v the location of the gui component object on the test device s screen vi the current activity and window of each step vii screen shots of the speci c gui component and viii the object index of the gui component to allow for di erentiation between di erent instantiations of the same gui component on one screen .
the engine performs this systematic exploration of the app using the uiautomator framework included in the android sdk.
this systematic execution of the app is similar to existing approaches in gui ripping analysis phasereport generation phase dynamic program analyzer engine .apk1 static app analyzer primer fusion databaseapktooldex2jarjd cmd decompilerorapp srcsrcmlstatic extraction of components and associated attributes systematic dfshierarchy viewer uiautomatorstep by step execution enginescreenshot capturegui component information extractiongoogle google application developers auto completionengine physical device or emulator5 report entry fusion ui generated reports fusion ui figure overview of fusion work ow .
using the uiautomator framework allows us to capture cases that are not captured in previous tools such as pop up menus that exist within menus internal windows and the onscreen keyboard.
to e ectively explore the application we implemented our own version of a systematic depth rst search dfs algorithm for application traversal that performs click events on all the clickable components in the gui hierarchy reachable using the dfs heuristic.
during the ripping before each step is executed on the gui the engine calls uiautomator subroutines to extract the contextual information outlined above regarding each currently displayed gui component.
we then execute the action associated with each gui component in a depth rst manner on the current screen.
our current implementation of dfs only handles the click tap action however as this is the most common action it is still able to explore a signi cant amount of an application s functionality.
in the dfs algorithm if a link is clicked that would normally transition to a screen in an external activity e.g.
clicking a web link that would launch the chrome web browser app we execute a back command in order to stay within the current app.
if the dfs exploration exits the app to the home screen of the device emulator for any reason we simply re launch the app and continue the gui traversal.
during the dfs exploration the engine captures every activity transition that occurs after each action is performed e.g.
whether or not a new activity is started resumed after an action to launch a menu .
this allows fusion to build a model of the app execution that we will later use to help track a reporter s relative position in the app when they are using the system to record the steps to reproduce a bug.
.
report generation phase we had two major goals when designing the report generation phase component of fusion .
allow for traditional natural language input in order to give a high level overview of a bug.
.
auto complete the reproduction steps of a bug through suggestions derived by tracking the position of the reporter s step entry in the app eventow.
figure fusion reporter interface during the report generation phase fusion aids the reporter in constructing the steps needed to recreate a bug by making suggestions based upon the potential gui state reached by the declared steps.
this means for each step s fusion infers online the gui state gui sin which the target app should be by taking into account the history of steps.
for each step fusion veri es that the suggestion made to the reporter is correct by presenting the reporter with contextually relevant screen shots where the reporter selects the screen shot corresponding to the current action the reporter wants to describe.
.
.
report generator user interface after rst selecting the app to report an issue for a reporter interacts with fusion by lling in some identifying information i.e.
name device title and a brief textual description of the bug in question in the top half of the ui.
next the reporter inputs the steps to reproduce the bug using the auto completion boxes in a step wise manner starting from the initial screen of a cold app launch1 and proceeds until the list of steps to reproduce the bug is exhausted.
let us consider a running example where the user is lling out a report for the document viewer bug in table .
according to the various elds in figure the reporter would rst ll in their i name field ii device field iii screen orientation field iv a bug report title field and v a brief description of the bug field .
1cold start means the rst step is executed on the rst window and screen displayed directly after the app is launched.
.
.
auto completing bug reproduction steps to facilitate the reporter in entering reproduction steps we model each step in the reproduction process as an action component tuple corresponding to the action the reporter wants to describe at each step e.g.
tap long tap swipe type and the component in the app gui with which they interacted e.g.
name textview ok button days spinner .
since reporters are generally aware of the actions and gui elements they interact with it follows that this is an intuitive manner for them to construct reproduction steps.
fusion allocates auto completion suggestions to drop down lists based on a decision tree taking into account a reporter s position in the app execution beginning from a cold start of the app.
the rst drop down list see figure a corresponds to the possible actions a user can perform at a given point in app execution.
in our example with the document viewer bug let s say the reporter selects click as the rst action in the sequence of steps as shown in figure a. the possible actions considered in fusion are click tap longclick long touch type and swipe .
the type action corresponds to a user entering information from the device keyboard.
when the reporter selects the type option we also present them with a text box to collect the information she typed in the android app.
figure auto complete dropdown menus the second dropdown list see figure b corresponds to the component associated with the action in the step.
fusion presents the following information which can also be seen in figure i component type this is the type of component that is being operated upon e.g.
button spinner checkbox ii component text the text associated with or located on the component iii relative location the relative location of the component on the screen according to the parameters in figure and iv component image an in situ i.e.
embedded in the dropdown list image of the instance of the component.
the relative location is displayed here to make it easier for reporters to reason about the onscreen location rather than reasoning about pixel values.
in our running example fusion will populate the component dropdown list with all of the clickable components in the main activity since this is the rst step and the selected action was click.
the user would then select the component they acted upon in this case the rst option in the list the ok button located at the center of the screen see figure b .
one potential issue with component selection from the auto complete drop down list is that there may be duplicate components on the same screen in an app.
fusion solves this problem in two ways.
first it di erentiates each duplicate component in the list through specifying text option .second fusion attempts to con rm the component entered by the reporter at each step by fetching screen shots from the fusion database representing the entire device screen.
each of these screen shots highlights the representative gui component as shown in fig.
.
to complete the step entry the reporter simply selects the screen shot corresponding to both the app state and the gui component acted upon.
in our running example the reporter would select the full augmented screenshot corresponding to the component they selected from the dropdown list.
in our case an illustrative portion of the screenshot for the ok button is shown in figure .
after the reporter makes selections from the drop down lists they have an opportunity to enter additional information for each step e.g.
a button had an unexpected behavior in a natural language text entry eld.
for instance in our running example the reporter might indicate that after pressing the ok button the pop up window took longer than expected to disappear.
.
.
report generator auto completion engine the auto completion engine of the web based report generator figure uses the information collected up front during the analysis phase .
when fusion suggests completions for the drop down menus it queries the database for the corresponding state of the app event ow and suggests information based on the past steps that the reporter has entered.
since we always assume a cold application start the auto completion engine starts the reproduction steps entry process from the app s main activity.
we then track the reporter s progress through the app using predictive measures based on past steps.
the auto completion engine operates on application steps using several di erent pieces of information as input.
it models the reporter s reproduction steps as an ordered stream of steps swhere each individual step simay be either empty or full.
each step can be modeled as a ve tuple consisting offstep num action comp name activity history g. the action is the gesture provided by the reporter in the rst drop down menu.
the component name is the individual component name as reported by the uiautomator interface during the engine phase.
the activity is the android screen the component is found on.
the history is the history of steps preceding the current step.
the auto completion engine predicts the suggestion information using the decision tree logic which can be seen in figure .
fusion presents components to the reporter at the granularity of activities or application screens.
to summarize the suggestion process fusion looks back through the history of the past few steps and looks for possible transitions from the previous steps to future steps depending on the components interacted with.
if fusion is unable to capture the last few steps from the reporter due to the incomplete application execution model mentioned earlier then fusion presents the possibilities from all known screens of the application.
in our running example let s consider the reporter moving on to report the second reproduction step.
in this case fusion would query the history to nd the previous activity the ok button was located within and then present component suggestions from that activity in the case that the user stayed in the same activity and the components from possible transition activities in the case the user transitioned to a di erent activity.is steps history ?display components for the app s main activityis steps history ?noyesis steps history verified by fusion?is steps history and is steps history confirmed?noyes display components from previous activity and possible transition activities.is steps history verified by fusion?yesno display components from the activity in steps history and two stages of transition activities.display all possible app components.yesnodisplay components from previous activity and possible transition activities.display components from main activity and two stages of transition activities.yesnofigure decision tree utilized by autocompletion engine figure relative location enumeration and example augmented screenshot .
.
handling fusion s application model gaps because dfs based exploration is not exhaustive there may be gaps in fusion s database of possible app screens e.g.
a dynamically generated component that triggers an activity transition was not acted upon .
due to this a reporter may not nd the appropriate suggestion in the dropdown list.
to handle these cases gracefully we allow the reporter to select a special option when they cannot nd the component they interacted with in the auto complete drop down list.
in our running example let s say the reporter wishes to indicate that they clicked the button labeled open document but the option is not available in the auto complete component drop down list.
in this case the reporter would select the not in this list... option and manually ll in i the type of the component to limit confusion we present this option as a drop down box autocompleted with only the gui component types that exist in the application as extracted by the primer in our case the user would choose button ii any text associated with the gui component in this case open document and iii the relative location of the gui component as denoted in figure in this case top center .
.
.
report structure the auto completion engine saves each step to the database as reporters complete bug reports.
once a reporter nishes lling out the steps and completes the data entry process a screen containing the nal report with an automatically figure example fusion bug report assigned unique id is presented to the reporter and saved to the database for a developer to view later see figure for an example report from document viewer .
the report presents information to developers in three major sections first preliminary information including the report title device and short description shown in figure in blue .
second a list of the steps with the following information regarding each step is displayed highlighted in blue in figure i the action for each step ii the type of a component iii the relative location of the component iv the activity java class where the component is instantiated in the source code and v the component speci c screenshot.
third a list of full screen shots corresponding to each step is presented at the bottom of the page so the developer can trace the steps through each application screen this section is highlighted in green in figure .
.
design of the experiments the two major design goals behind fusion are to facilitate and encourage reporters to submit useful bug reports for android applications to provide developers with more actionable information regarding the bugs contained within these reports.
in order to measure how e ective fusion is at achieving these goals we have evaluated two major aspects of our approach the quality of the bug reports produced by the system and the user experience of reporters and developers using fusion .
to this end we investigated the following research questions rqs rq what information elds in bug reports are useful when reporting bugs in android apps?
rq is fusion easier to use for reporting bugs than traditional bug tracking systems?
rq are fusion reports easier to use for reproducing bugs than traditional bug reports?
rq do bug reports generated with fusion allow for faster bug reproduction compared to reports submitted using traditional bug tracking systems?
rq do developers using fusion reproduce more bugs compared to traditional bug tracking systems?
the ve rqs were investigated with empirical studies representing two maintenance activities involving reporting and reproduction of real bugs in open source apps.
in the following subsections we will describe the context of the two studies i.e.
android apps and bug reports and the details of each study.
.
context bug reports used in the studies in order to properly evaluate fusion when reporting and reproducing bug reports from real world bugs we manually selected bug reports from android open source apps at fdroid .
we crawled the links of the issue tracking systems of the apps and then manually inspected the bug reports for each project where f droid had a linked issue tracker.
the criteria for selecting the bug reports were the following bugs that are reproducible given the technical constraints of our fusion implementation bugs of varying complexity requiring at least three steps of user interaction in order to be manifested and bugs that are reproducible on the nexus tablets utilized for the user study.
details of these bug reports can be found in table and links can be found in our replication package outlined in section and available online at .
fusion targets bug reports that can be described in terms of gui events and are not context dependent.
for instance some bugs are triggered when changing the orientation of the device or are context dependent i.e.
the bug depends on the network signal quality gps location etc.
.
we do not claim that the fusion approach works for all types of android bugs but rather acknowledge and give examples of the current limitations in section .
.
.
evaluating user experience preferences and programming background for both studies in addition to collecting time information for the creation and reproduction of the bug reports we collected responses to a set of questions outlined in table .
the questions focused on three di erent aspects user preferences user experience and demographic background including programming experience.
the user preference related questions up questions in table were formulated based on the user experience honeycomb originally developed by peter morville and posed to participants as free form text entry elds.
the usability was evaluated by using statements based on the sus usability scale by john brooke .
these statements are labeled in table with ux.
programming experience was scored by the participant on an extended likert scale representing a strong disagreement and representing strong agreement .
the background information questions are based on the programming experience questionnaire developed by feigenspan et al .
for the analysis of the free form questions one of the authors analyzed and categorized the answers manually.
due to space limitations table presents a subset of the questions posed to study participants.
the full set of questions can be found online in the replication package for this work .table questions and statements for evaluating the user experience of the bug tracking systems and the bug reports generated with the analyzed systems.
id question up1 what information from this system did you nd useful for reporting reproducing the bug?
up2 what other information if any would you like to see in this system ?
up3 what elements do you like the most from this system ?
up4 what elements do you like the least from this system ?
ux1 i think that i would like to have this type of bug report system frequently.
ux2 i found this type of bug report system unnecessarily complex.
ux3 i thought this type of bug report system was easy to read use.
ux4 i found this type of bug report system very cumbersome to read use.
ux5 i thought the bug report system was really useful for reporting reproducing the bug.
.
study reporting bugs with fusion the goal of the rst study is to assess whether fusion s features are useful when reporting bugs for android apps which aims to answer rq rq .
in particular we want to identify whether the auto completion steps and in situ screenshot features are useful when reporting bugs.
to accomplish this we recruited eight students four undergraduate or non experts and four graduate or experts at the college of william and mary to construct bug reports using fusion and google code issue tracker gcit as a representative of traditional bug tracking systems for the real world bugs from the reports shown in table .
the four graduate participants had extensive programming backgrounds.
four participants constructed a bug report for each of the bugs in table using fusion prototype and four participants reported bugs using the google code issue tracker interface.
the participants were distributed to the systems such that two non experts and two programmers evaluated both systems.
in total the participants constructed bug reports using fusion and using gcit.
participants used a nexus tablet with android .
.
kitkat installed to reproduce the bugs.
one challenge in conducting this rst study is illustrating the bug to the participants without introducing bias from the original bug report.
to accomplish this we created short videos of the steps to reproduce every bug using the fewest number of actions possible.
after viewing the video each participant was asked to con rm their knowledge of the bug by reproducing it on a nexus tablet with a study proctor con rming the reproduction.
then the participants lled out a bug report for each of the bugs for the system to which they were assigned.
during the report collection the names of the bug reporting systems were anonymized to system a for fusion and system b for gcit.
the users were provided with a short tutorial regarding how to enter bugs for each system so as not to introduce bias towards any reporting system.
after the creation of the bug reports users were asked to answer the questions listed in table in an online survey.
results of this study and the corresponding rq rq 2are presented in section .
.
.
study reproducibility of bug reports the goal of study is to evaluate the usability and preferences of developers using fusion to report bugs as welltable summary of the bug reports used for the empirical studies.
gde gui display error c crash dic data input calculation error ne navigation error.
app bug iddescription min stepsbug type a time tracker dialog box is displayed three times in error.
gde aarddict scroll position of previous pages is incorrect.
gde acv app crashes when long pressing on sdcard folder.
c car report wrong information is displayed if two of the same values are entered subsequently dic document viewer go to page number requires two entries before it works ne droidweight weight graph has incorrectly displayed digits gde eshotroid bus time page never loads.
gde ne gnucash selecting from autocomplete suggestion doesn t allow modi cation of value dic gnucash cannot change a previously entered withdrawal to a deposit.
dic mileage comment not displayed.
gde dic netmbuddy some youtube videos do not play.
gde ne notepad crash on trying to send note.
c oi notepad encrypted notes are sorted in random when they should be ordered alphabetically gde dic olam app crashes when searching for word with apostrophe or just a space character c quickdic enter key does not hide keyboard gde as the ability of our proposed approach to improve the reproducibility of bug reports thus answering rq rq .
in particular we evaluated the following aspects in fusion and traditional issue trackers usability when using the bug tracking systems guis for reading bug reports time required to reproduce reals bugs by using the bug reports and number of bugs that were successfully reproduced.
both the reports generated during study using fusion and gcit and the original bug reports were evaluated by a new set of participants through attempted bug reproduction on physical devices.
the participants were graduate students from the computer science department at college of william and mary all of whom are familiar with the android platform and are experienced programmers.
all participants were compensated usd for their e orts.
each user evaluated bug reports six from fusion six from gcit and three original.
reports were evaluated from study plus the original bug reports and were distributed to the participants in such a way that each bug report was evaluated by two di erent participants the full design matrix can be found in our replication package .
each participant evaluated only one version of a bug report for a given bug because the learning e ect dictates that after a user reproduces a bug once they will be capable of reproducing it easily in subsequent attempts with other bug reports.
during the study the participants were sent links corresponding to the reports for which they were tasked with reproducing the bug.
each participant was loaned a nexus tablet with android .
.
kitkat installed the apps were preinstalled in the devices.
for each bug report the users attempted to recreate the bug on the tablet using only the information contained within the report.
the users timed themselves in the reproduction for each bug with a ten minute time limit.
if a participant was not able to reproduce a bug after ten minutes that bug was marked as notreproduced .
a proctor monitored the study to judge whether participants successfully reproduced a given bug.
after the users attempted to reproduce all bugs assigned to them they were asked to ll out an anonymous online survey for each type of the bug report they utilized containing the ux and up questions listed in tab .
for the analysis we used descriptive statistics to analyze the responses for the ux statements the time for reproducing the bugs and the number of successful reproductions.
results for rq rq are presented in section .
.
.
results and discussion in this section we report the results for both studies conducted in our evaluation and outline the major ndings.
for a complete dataset and overview of results including all statistics and user responses please see our replication package in section and online at .
.
bug reporting results from study first we present quantitative and qualitative information based on the time taken to create bug reports and responses from participants in study in order to answer rq rq .
in regard to the general usefulness of fusion as a reporting tool there are two clear trends that emerge from the user responses reporters generally feel that the opportunity to enter extra information in the form of detailed reproduction steps helps them more e ectively report bugs experienced reporters tended to appreciate the value and added e ort of adding extra information compared to inexperienced reporters.
these trends echo the bug creation time results and there are several statements made by participants that con rm these claims.
for instance one response from an experienced user to up1 was the following the gui component form and the action event form have been very useful to e ectively report the steps.
however a response to the same question by an inexperienced reporter was i liked the parts where you just type in the information.
one encouraging result during study is that fusion was able to auto suggest all of the reproduction steps without gaps i.e.
auto completion did not miss any steps in of bug reports generated.
this means that using the information for the steps contained with fusion database extracted during the dynamic execution of an app fusion was able correctly suggest all of the steps to the participant creating a report and a replayable script can be generated.
this would not be possible for gcit or any other bug tracking system.
in summary we can answer rq 1as follows while reporters generally felt that the opportunity to enter extra information using fusion increased the quality of their reports inexperienced users would have preferred a simpler web ui.
with regard to the time statistics reported in table it generally took experienced reporters a similar amount of time to create reports for both systems.
however inexperienced reporters reported bugs much more quickly with gcit compared to fusion.
these results are not surprising as experienced reporters understand the importance offigure answers to the ux related questions in rq figure percentage of bug reports reproduced by each participant left for rq and individual bug reproduction time right for rq .
providing detailed information in bug reports and thus are more likely to create detailed natural language bug reports using both gcit and fusion.
on the other hand the results show inexperienced reporters are more likely to create super cial reports using gcit.
while it did take inexperienced reporters a longer amount of time to create fusion reports the creation times were still reasonable and doesn t necessarily re ect poorly on the system.
in fact these results suggest that fusion forced even inexperienced reporters to create more detailed reproducible bug reports and this is con rmed in the reproduction results.
thus we can answer rq 2as follows fusion was about as easy to use as the gcit for experienced participants but was more di cult for inexperienced participants to use compared to gcit.
.
bug reproduction results from study the boxplots in figures and summarize the results forstudy .
in particular the gures depict the answers to the bug report usability statements figure percentage of bug reports reproduced successfully by the participants figure left and time required to reproduce the bug reports figure right .
in the case of reproduction time because some of the reports were not reproduced during a minute time slot we set the reproduction time to seconds for visualization and analysis purposes.
the usability scores in figure show that most users agree that they would like to use fusion s bug reports frequently however several users also found the bug reports to be unnecessarily complex and some users found the bug reports di cult to read comprehend.
most users agreed that they thought fusion bug reports were useful for helping to reproduce the bugs.
gcit had the best usability scores out of the three systems whereas the original bug reports had the lowest usability scores.
according to user preference feedback for up3 we received encouraging responses for instance the detail steps to nd where to nd the next steps was really useful and speeded up things.
the images of icons help a lot especially when you have a hard time locating the icons on your screen.
however users also expressed issues with the fusion report layout some table average bug report creation time ex experienced participant iex inexperienced participant times are reported in mm ss format.
participant ex participant ex participant iex participant iex fusion participant ex participant ex participant iex participant iex gcit times the steps were too overly speci c detailed.
the information while thorough was not always clear if there are steps missing it is confusing because it is otherwise so detailed.
based on these responses we can answer rq 3as follows according to usability scores participants generally preferred fusion over the original bug reports when reproducing bugs but generally preferred gcit to fusion by a small margin.
the biggest reporter complaint regarding fusion was the organization of information in the report.
figure details reproducibility results for bug reports written with fusion by experienced i.e.
fuse e and non experienced participants i.e.
fus i reports written in gcit by experienced i.e.
gcit e and non experienced participants i.e.
gcit i and original reports i.e.
orig .
according to figure the average time to reproduce for the two avors of fusion were .
and .
seconds respectively for fus e and fus i .
surprisingly the fus i reports had a smaller average reproduction time than the fus e reports.
gcit reports e i had an average time to reproduce of .
and .
seconds respectively.
while this result shows that participants took longer to reproduce fusion reports this is to be expected as they had to read and process the extra information regarding the reproduction steps.
however reproduction time of inexperienced reporters with fusion is lower than gcit.
while there is no strong correlation as to which system is more capable of creating reproducible reports for complex bugs we do see that the complex bugs generally have more instances where they are not reproducible which is to be expected.
based on these results we can answer rq 4as follows bug reports generated with fusion do not allow for faster reproduction of bugs compared bug reports generated using traditional bug tracking systems such as the gcit .
in terms of reproducibility overall the reports generated using fusion were more reproducible than the reports generated using gcit with only of the bug reports from fusion being non reproducible compared to of the reports from gcit being non reproducible.
the bug report type with the lowest number of non reproducible cases is fus e whereas the report type with the highest number of non reproducible cases is gcit i .
one encouraging result is that when inexperienced participants created bug reports in study participants in study seemed to have a much easier time reproducing the reports from fusion i which only had non reproducible cases compared to gcit i which had nearly twice as many non reproducible cases.
this means that for reporters classi ed as inexperienced fusion could greatly improve the bug report quality.
both of the individual fusion bug report types i and e had a lower number of non reproducible cases than the original bug reports as well.
however a direct comparison cannotbe made here as each original bug report was tested attempted reproduction four times compared to two times for fusion and gcit bug reports.
therefore based on these results we can answer rq 5as follows developers using fusion are able to reproduce more bugs compared to traditional bug tracking systems such as the gcit.
.
lessons learned the major lessons that can be gleaned from the results ofstudy which should be taken into account in future research and issue tracker design are intuitive ui design is extremely important to enhance the usability of issue trackers for reporters and presenting users with a structured reporting mechanism such as that in fusion can increase the quality of bug reports even for inexperienced participants .
if an issue tracker is able to successfully combine features that address both of these lessons the result will be a system that places less burden on the reporter and produces more useful bug reports.
there are two major lessons that emerge from the results ofstudy the design of the report should be speci cally suited to the maintenance task required .
several participants complained of overly speci c or detailed information during the second study and this information may have been more suited to a fault location task.
in our study we focused on reproduction to gauge bug report quality as it is well known that if a developer can reproduce a bug there is a much higher chance that they will be able to x and patch it .
however based on the user experience and preference results from study it may be bene cial to present information to developers in stages e.g.
rst present reproduction steps then more detailed code information for fault location .
lesson there is a clear trade o between time and bug reproduction ability in more detailed bug reports such as those produced by fusion .
fusion reports were generally more accurate but took slightly longer to reproduce however this is a tradeo developers would be willing to make in the competitive mobile app marketplace.
.
limitations currently the dfs implementation in fusion only supports the click tap action.
another option to gather runtime program information would be to record app scenarios and replay them while collecting program data or using language modeling based approaches for scenario generation .
however we forwent such an approach in favor of the fully automatic dfs application exploration and constructing a completely o device issue tracking system that may be able to describe bugs a record and replay approach might miss.
part of our immediate plan for future work includes adding support for more gestures to our dfs engine.
fusion is currently not capable of capturing certain contextual app information such as a change in device orientation or network state.
however this can be mitigated by the fact that reporters can enter such contextual information in the free form text eld associated with each step.
fusion is also limited in the types of bugs that it can report currently supporting functional bugs that can be uncovered using only gui gestures such as tap long touch swipe and type.
it is important to note that even though the systematic section engine is not able to perform and capture gestures other than tap these gestures can still be reported using fusion.
.
threats to validity threats to internal validity concern issues with the legitimacy of causal relationships inferred.
in the context of our studies threats come from potentially confounding e ects of participants.
first we assume that undergraduate students without a cs background but who have experience using android devices are representative of non expert testers.
we believe this is a reasonable assumption given the context as most non expert testers will only have a working knowledge of the app and platform.
we also assumed graduate students with android experience were reasonable substitutes for developers.
again we believe this is reasonable given that all four of the experienced participants in study 1indicated they had extensive programming backgrounds and reasonable android programming experience at least on the scale where represents very experienced .
likewise the participants in study indicated that they all had extensive programming backgrounds and of the participants had reasonable android programming experience.
threats to external validity concern the generalizability of the results.
the rst threat of this type relates to the bug reports and android apps used in our study.
we evaluated fusion on only bug reports from di erent applications from the f droid marketplace.
in order to increase the generalizability of the results we aimed at selecting bug reports of varying type and complexity from apps representing di erent categories and functions.
during our study we utilized only one device type a nexus tablet in order to standardize results across participants.
however there is nothing limiting fusion from being utilized on several di erent android devices from varied manufacturers.
we concede that fusion is not suited for reporting all types of bugs e.g.
nuanced performance bugs context dependent bugs however we conjecture that any type of bug that can be reported with a traditional issue tracking system can be reported with fusion.
.
conclusion and future work prior research highlights an inherent lexical gap that exists between reporters of bugs and developers.
to help overcome this we introduced fusion a novel bug reporting approach that takes advantage of program analysis techniques and the event driven nature of android applications in order to help auto complete the reproduction steps for bugs.
results from our comprehensive evaluation show fusion is able to produce more reproducible bug reports than traditional issue tracking systems.
we hope our work on fusion encourages a new direction of research aimed at improving reporting systems .
in future work we aim to improve our dfs engine through supporting more gestures to explore adding more speci c program information in reports for quicker automatic fault localization and to use fusion as a tool for reporting feature requests.
.