toward a framework for detecting privacy policy violations in android application code rocky slavin1 xiaoyin wang1 mitra bokaei hosseini1 james hester2 ram krishnan1 jaspreet bhatia3 travis d. breaux3 and jianwei niu1 1university of texas at san antonio san antonio tx usa 2university of texas at dallas dallas tx usa 3carnegie mellon university pittsburgh pa usa rocky.slavin xiaoyin.wang mitra.bokaeihosseini ram.krishnan jianwei.niu utsa.edu william.hester utdallas.edu jbhatia breaux cs.cmu.edu abstract mobile applications frequently access sensitive personal information to meet user or business requirements.
because such information is sensitive in general regulators increasingly require mobileapp developers to publish privacy policies that describe what information is collected.
furthermore regulators have fined companies when these policies are inconsistent with the actual data practices of mobile apps.
to help mobile app developers check their privacy policies against their apps code for consistency we propose a semi automated framework that consists of a policy terminologyapi method map that links policy phrases to api methods that produce sensitive information and information flow analysis to detect misalignments.
we present an implementation of our framework based on a privacy policy phrase ontology and a collection of mappings from api methods to policy phrases.
our empirical evaluation on top android apps discovered potential privacy policy violations.
categories and subject descriptors d. .
distribution maintenance and enhancement general terms documentation keywords privacy policies android applications violation detection .
introduction in early the android operating system android accounted for .
of the worldwide smartphone market share .
with this sizable market share comes an increase to end user privacy risk as mobile applications apps built for the android have access to sensitive personal information about users locations network information and unique device information.
to protect permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
to copy otherwise to republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
icse may austin texas usa copyright acm ... .
.privacy regulators such as the u.s. federal trade commission ftc have relied on natural language privacy policies to enumerate how applications collect use and share personal information.
recently the california attorney general kamela harris negotiated with the google play app store to require mobile app developers to post privacy policies .
despite this effort to produce these policies as with any software documentation there are opportunities for these policies to become inconsistent with the code.
these policies can be written by people other than the developers such as lawyers or the code can change while the policy remains static.
such inconsistencies regarding an end user s personal data intentional or not can have legal repercussions that can be avoided with proper consistency checks.
for example the ftc under their unfair and deceptive trade practices authority requires companies to be honest about their data practices in their privacy policies.
companies such as snapchat fandango and credit karma often settle with the ftc for inconsistent policies and practices by accepting years of costly privacy and security audits .
it is therefore good practice for mobile apps to clearly state in their privacy policies what data is collected and for what purpose.
for large companies this task is commonly assigned to a team of legal experts however mobile app developers are frequently small start ups with developers where such a task is not easily assigned.
it is important for software engineers to be aware of the data their code is collecting along with what their policy says they are collecting not only for legal reasons but for the production of quality apps.
as more data is entrusted to technology end users become more aware of the ramifications of mishandled private data .
thus software engineers are entrusted by end users to not only care for their data but disclose what exactly is being collected.
in this paper we present three contributions an empirically constructed mapping from policy phrases to private data producing android application program interface api methods that has been compiled from real world app policies and api documentation.
the many to many map links commonly used data collection phrases and their synonyms to android api method signatures.
we created an approach that identifies privacy promises in mobile app privacy policies and checks these against code using information flow analysis to raise potential policy violations.
as part of checking for data over collection violations within the app the approach uses information flow analysis to see if the data is sent outside the app.
we constructed an initial ontology of data collection phrases to use in conjunction with the api mappings.
the ontology provides a means to increase the phrase coverage of the mappings without the need for analysis on more apps and privacy policies.
ieee acm 38th ieee international conference on software engineering ieee acm 38th ieee international conference on software engineering this paper is organized as follows in section we review the background upon which we based our approach in section we describe the manual process used in the creation the framework section describes our automated method for privacy policy violation detection section describes the evaluation of our approach followed by discussion of the results and approach in section section includes related work section describes our plans for future work and we conclude in section .
.
background this section presents the background upon which our research is based.
.
android operating system android is an open source mobile operating system os based on more than open source projects including the linux kernel.
android is developed by google and has been reported more popular as a target platform for developers than ios in which makes it the most popular mobile operating system today .
apps made to run on android can be downloaded from multiple repositories the most popular being google play1.
in google revealed that there were more than one billion active monthly android users .
these characteristics make it attractive to startups and established companies alike.
android utilizes the linux security model and layers through a user based permission system .
apps can access resources through the permission system to gain access to resources such as the camera gps bluetooth telephony functions network connections and other sensors .
such permissions are granted to apps by users when they install an app.
all permissions not listed to and subsequently granted by the user are denied to the app .
although android applies this permission system and rigorous security management data leakage and misuse is still possible .
this can be due to problems with the current android permission system such as low granularity of the permissions and the ambiguity of the phrases presented to users when installing an app .
problems such as these can allow apps to access the sensitive data by calling android application program interface api methods in the app source code.
.
application program interface applications can interact with underlying android system using a framework api provided by the android platform.
the framework api contains set of packages classes and methods.
the android .
framework is comprised of about methods some of which are specifically used to retrieve insert update or delete sensor data through the android os .
the use of an api increases the level of security by not allowing apps to have direct access to all sensor data by default.
before an app can access specific methods from the api the required permissions must be requested by the app through a manifest file.
an app s manifest file enumerates the app s required permissions and is described to users when installing an app as well as on the app s download page on the google play store.
thus there is a direct relationship between the permissions granted to an application by a user at installation time and eligible api method calls in the application source code.
.
privacy policy besides the standard permissions for api access documented in files applications privacy policies are a source for identifying what information is collected and used by apps.
a privacy policy serves as the primary means to communicate with users regarding which and how sensitive personal information spi has been accessed collected stored shared app to app and to third party used processed and the purpose of the spi collection and processing.
privacy policies generally consist of multiple paragraphs of natural language such as the following excerpt from the indeed job search app s privacy policy2listed on google play indeed may create and assign to your device an identifier that is similar to an account number.we may collect the name you have associated with your device device type telephone number country and any other information you choose to provide such as user name geo location or e mail address.
we may also access your contacts to enable you to invite friends to join you in the website.
privacy policies are particularly important in the united states due to the notice and choice approach used to address privacy online .
under this framework app companies post their privacy policies and users read the policies to make informed decisions on accepting the privacy terms before installing the apps .
however most privacy policies prepared by policy authors are difficult to understand due to their verbose and ambiguous nature and this can lead to users to skip reading policies even if they have concerns about information collection practices.
more significantly the app developers might not be able to comply with privacy policies effectively.
to address this issue this work aims to provide a framework to achieve alignment between apps privacy policies and implementation code and better communication among software developers and policy writers.
a major hindrance in the understanding and analysis of privacy policies is that there is no canonical format for presenting the information.
the language organization and detail of policies can vary from app to app.
.
manual preparation the goal of this work is to discover information regarding the relationship between terminology used in privacy policies expressed in natural language and api method calls used in the corresponding code.
such a mapping would then provide semantic information regarding the natural language.
in turn an app s source code could more easily be checked for misalignment with its corresponding privacy policy.
before we can perform such an automated detection of privacy policy violations we must construct initial data sets and a mapping from which the knowledge can be used to detect violations in other apps.
the following subsections describe how we leveraged a small subset of android apps source code to implement a mapping from api methods to policy phrases.
this information is is then used to detect violations in a much larger set of android apps discussed in section .
in our approach we created a mapping between api method signatures in the android sdk and meanings shared between api documents and privacy policies.
the shared meanings are described in an ontology that provides support for comparing two technical terms we say that one term subsumes a second term when either the first term is more general than the second term called a hypernym or when the second term is part of the first term called a meronym.
for example mobile device model and sensors are parts of a mobile device whereas mobile device model is also a kind of mobile device information.
in addition we define two terms as synonyms when the meaning is equivalent for our purposes e.g.
when ip address is a synonym for internet protocol address .
because privacy policies tend describe technical information using more generic concepts the ontology allows us to map from low level technical terms to high level technical categories and vice versa.
once the ontology is constructed we can use tools to automatically infer which terms should appear in privacy policies based on the api method calls in a mobile application.
we now describe how we created the ontology and mapping by extracting terminology from the privacy policies and api documents respectively before we classified this terminology using subsumption and equivalence relationships.
in each step we employed research methods aimed at improving construct and internal validity and reliability which we discuss.
.
extracting the api terminology in our approach a subject matter expert who would typically be the maintainer of the application programmer interface api documentation annotates an api document.
the annotations map key phrases in the api documents to low level technical terminology in an api lexicon e.g.
scroll bar width or directional bearing are low level technical terms .
to bootstrap our approach we chose to annotate the entire collection of api documents in the android sdk which includes api documents containing over public method signatures here the term public refers to the java access modifier .
each api document consists of one or more method signatures which each consist of the method name input parameters the return type and a natural language description of the method s behavior.
the annotation procedure involves three steps a we extract the method names input parameters and natural language method descriptions from the api documentation to populate a series of crowd worker tasks b for each crowd worker task two investigators separately annotate the extracted fields by identifying which phrases correspond to a kind of privacy related platform information and c the resulting annotations are compiled into a mapping from the fully qualified method name including api package name onto each annotated phrase i.e.
each method name can map to one or more platform information phrases .
we only compiled mappings where the two investigators both agreed that the phrase was a kind of privacy related platform information.
in the first step the signatures were automatically extracted from the api documents which were themselves expressed in html generated using the javadoc toolset.
the signatures were then segmented into sets of signatures or less and each set was presented in a separate crowd worker task.
applying the segmentation to the api documents yields crowd worker tasks.
the crowd worker task employs a web based coding toolset developed by breaux and schaub for annotating text documents using coding theory a qualitative research method for extracting data from text documents .
in coding theory the annotators use a coding frame to decide when to code or not to code a specific item.
in our study to annotate the api documents our coding frame consisted of a single information code defined as information related to personal privacy and accessed through the platform api.
in the second step two investigators used this web based toolset to code the crowd worker tasks consuming .
and .
hours for each investigator to yield and annotations respectively.
figure shows an excerpt from the crowd worker task where a worker has annotated phrases in the location package of the anfigure api annotation crowd worker interface droid api.
the toolset has been validated in a prior case study to extract privacy requirements from privacy policies .
the toolset also includes analytics for extracting overlapping annotations where nor more workers agreed that the phrase should be annotated.
from the two investigator s combined annotations we produced unique annotations with duplicate annotations removed.
the total annotations were next compiled into a mapping between api method signatures and annotated phrases.
the phrases in the mapping were normalized by the two investigators by converting the annotated text into simple noun phrases described further in section .
.
this is necessary to reduce the variety of ways that method behaviors are described into a concise reusable api lexicon.
the resulting lexicon contains unique phrases and total mappings between phrases and api method names.
a total of methods were annotated based on the criteria that they produce privacy related information.
.
extracting the privacy policy terminology each app page on google play includes a link to the app s privacy policy if it is specified by the developer.
we created a python script to download the privacy policies from these links for the top free apps in each app category3.
we filtered theses policies based on their formatting language we only considered policies written in english and whether or not a privacy policy section was explicitly stated in the document and randomly selected from this pool for terminology extraction.
for our approach we determine which kinds of technical information should appear in privacy policies to describe privacyrelevant api method calls.
to bootstrap our method we developed a privacy policy lexicon in which six investigators annotated the mobile app privacy policies using our crowd worker task toolset .
unlike the api lexicon wherein we used only two investigators with programming experience we used six annotators for extracting terms from privacy policies because privacy policy terminology includes vague and ambiguous terms that span a broader range of expertise e.g.
taps corresponds to user input whereas analytics information includes web pages visited links clicked browser information and so on.
thus by increasing the number of annotators we increased our likely coverage of potentially relevant policy terms.
the crowd worker task employs the same web based coding toolset developed by breaux and schaub .
to prepare the policies for annotation we first removed the following content the introduction and table of contents contact us security u.s. safe harbor policy changes and california citizen rights.
this content generally appears in separate sections or paragraphs which 3the list of app categories is available at the google play website and the top apps for each category was fetched on may 19th .
27reduces the chance of inconsistency when removing these sections across multiple policies.
while these sections do describe privacyprotecting practices such as complying with the u.s. safe harbor we have never observed descriptions of platform information in our analysis of over privacy policies in our previous research .
next we manually split the remaining policy into spans of approximately words.
we preserve larger spans which either have an anaphoric reference back to a previous sentence e.g.
when this information... depends on a previous statement to understand the context of the information or when the statement has subparts e.g.
a b etc.
that depend on the context provided by earlier sentence fragments.
on average we need minutes per policy to complete the preparation.
the coding frame for the privacy policy terminology extraction consists of two codes platform information which we define as any information that company or another party accesses through the mobile platform which is not unique to the app and other information which we define as any information that company or another party collects uses shares or retains.
we replace the company variable with the name of the company whose policy is being annotated.
next we compiled the annotations where two or more investigators agreed that the annotation was a kind of platform information we excluded non platform information from this data set.
we applied an entity extractor to the annotations to itemize the platform information types into unique entities which were then included in the privacy policy lexicon.
among the policies we constructed crowd worker tasks with an average word count of .
the average words per policy was .
.
these tasks produced a total of annotations across the policies which yielded a total of unique platform information entities.
the total time required to collect these annotations was .
hours across six annotators all of whom are authors of this paper.
we now discuss how we created a platform information ontology from this lexicon.
.
constructing the ontology a common phenomena in natural language description is generalization in which a more general phrase can be used to imply a number of sub concepts of the phrase.
for example the phrase technical information may imply a wide range of technical data while the phrase device identifier is more specific but its concept is still covered by phrase technical information .
since phrase generalization is often used to describe information collected it is important to be able to distinguish these relationships between phrases in order to identify cases where a concept is represented in another phrase.
to handle this we created an ontology of privacyrelated phrases to be used as a cross reference during the identification of methods not represented in privacy policies.
an ontology is a formal description of entities and their properties relationships and behaviors and is described with formal languages such as owl based on description logic .
in the context of phrase mapping we use an ontology to represent a hierarchical classification of phrases.
for example in figure ip address is a decedent of network information indicating that ip address is a type of network information.
the hierarchical nature of an ontology allows for transitive relationships that can be used for mapping api methods to phrases indirectly based on relationships between the phrases themselves.
the ontology is used to formally reason about the meaning of terminology found in the api documents and privacy policies.
for an api lexicon aand a privacy policy lexicon pconsisting of unique terms or concepts the ontology is a description logic dl knowledge base kb that consists of axioms cvd which figure abbreviated ontology example with mapped api methods means concept cis subsumed by concept d orc d which means concept cis equivalent to concept d for some concepts c d2 a p .
using our api lexicon our aim is to map a method name mfrom an api document to a concept a2 a. next we aim to infer in a forward direction all policy concepts fpjp2 p kbj pva kbj p ag.
in this respect we can extract method names from method calls in a mobile app then infer corresponding policy terms among which at least one should appear in the mobile app s privacy policy.
similarly we can reason in the backward direction to check which policy terms mentioned in the app s policy map to which method names corresponding to method calls in the app.
we constructed the ontology following a method developed by wadkar and breaux .
first we generated a basic ontology consisting of one concept for each term in the privacy policy lexicon each concept was subsumed by the concept and no other relationships among concepts existed.
second for two copies of the basic ontology kb 1andkb two investigators separately performed pairwise comparisons among term pairs c din each ontology respectively if two terms were near synonyms the first investigator created an equivalence relation kb 1j c d else if one term subsumed the other term the first investigator created a subsumption relationship kb 1j cvd.
due to the number of pairwise comparisons it s not unreasonable to expect that a single investigator would produce an incomplete ontology or an ontology that is inconsistent with another investigator s ontology.
to check for completeness and consistency between two investigators we compared all relationship pairs between kb 1andkb including cases were a relationship did not exist in one of the ontologies.
both investigators met to reconcile any differences recognizing that classification differences can persist forward into our analysis of mobile app violations.
for two investigators the resulting ontologies kb 1andkb consisted of and axioms respectively.
the first comparison yielded differences and was evaluated using cohen s kappa to measure the degree of agreement above chance alone which was .
.
after the reconciliation process the investigators were left with differences and a cohen s kappa of .
.
.
constructing the mapping with the ontology constructed from the privacy policy lexicon 28figure mapping process individual api methods could then be mapped to one or more terms in the ontology based on their annotations from the api lexicon as well as their return types.
figure shows how intermediate noun phrases were created as a canonical representation of the method s description and then mapped directly to terms in the ontology based on their relationships.
this canonicalization process made explicit the domain knowledge about the methods i.e.
canonical terms and the natural language used to describe the method in privacy policies i.e.
terms in the ontology .
as exemplified in the figure the documentation describes dynamic information about the current wi fi connection as the data it produces.
in cases such as this where the description did not explicitly describe the information returned we analyzed the object returned by the method.
here the object of type wifiinfo provided multiple public fields and methods from which we were able to assign the canonical terms in the figure as seen in the white circle .
from there the canonical terms were associated with related terms in the ontology based on their relationships.
this effectively produces a mapping between each of the api methods and one or more terms in the ontology assuming the method is privacy relate and vice versa.
we refer to this many to many mapping relation of which each element is a pair policyterm api method as mappings in the following sections.
.
automated violation detection to detect potential privacy policy violations we first identify api method invocations that produce data covered by a known policy term from the privacy policy lexicon.
next we use information flow analysis to check whether that data flows to a remote server via a subsequent network api method invocation.
data collected by a method is considered a potential privacy policy violation if the method is not represented in the app s privacy policy through mappings.
an overview of the full process is in figure .
.
weak and strong violations as discussed in section .
privacy policies serve to inform users about how their personal information is collected and used.
these policies cover a wide range of practices including in store client side and server side practices and they may describe all of a company s practices or be limited to only those practices of a single product or service.
in this paper we are only concerned about client side practices affecting mobile applications.
in addition privacy policies are not complete they generally describe a subset of the company s practices.
therefore in our approach we only detect errors of omission in which the app collects a kind of information that is not described in the policy.
errors of omission are potential policy violations because the collection may be unintended by the app developer.
moreover because privacy includes notifying users about how their information is collected and used errors of omisfigure violation detection sion represent potential privacy violations.
we detect two kinds of violations resulting from errors of omission strong violations that occur when the policy does not describe an app s data collection practice and weak violations that occur when the policy describes the data practice using vague terminology.
other kinds of policy errors such as direct conflicts in which a conflict occurs because the policy states that an app does not collect a kind of information and the app does indeed collect that kind of information are out of scope of this paper.
.
detection of suspicious method invocations to begin the process we preprocess the app s privacy policy to generate a set of method related phrases that represent what the privacy policy states it collects.
first all words in each policy paragraph are converted to their base dictionary form i.e.
lemmatization .
if the lemmatized paragraph contains a collection verb4 the paragraph is kept for further analysis.
next the intersection of the lemmatized words in the paragraphs and the phrases in the privacy policy ontology is calculated to produce the set of existing policy phrases .
we use and the many to many relation mappings to generate a list of method names arepresented arepresented f j 2map g wherearepresented denotes the set of methods that are directly represented within the privacy policy based on the mapping and map produces all the methods to which is mapped.
the set of omitted api method names can then be defined as the following where amapped represents the set of api method names that appear in mappings i.e.
all methods in the android api for which at least one mapping to a policy phrase exists .
aomitted amappednarepresented the app s source code can now be scanned for any instances of 2aomitted .
such instances would then be flagged as a suspicious invocation !.
to determine information about the invocation the offending api method name !
is cross referenced withamapped to determine all phrases to which it is mapped !.
the ontology is then used to determine the set of terminological ancestors !
of all !
equation which are those phrases that include in their interpretation the data accessed by the api method invocation.
the phrases !semantically subsume i.e.
are more generally descriptive of at least one member of !according to the ontology.
the relationships 4the collection verbs used in this study are the result of the manual annotation by two investigators of random privacy polices from the set of privacy policies described in section .
.
29between !
and can be seen in figure where an becomes an !if it is a suspicious invocation.
due to the nature of an ontology the set of nodes of highest level hnodes f information software technology gis generally descriptive of all of their subterms and thus not useful.
therefore we use equation to describe the ontology.
o0 onhnodes !
f j !
v g the members of !represent terminological ancestors of !that relate to!through a subsumption relationship.
these ancestors may include other interpretations that are not associated with !
e.g.
technical information includes location information and usage information which are distinct and different kinds of information .
thus we check !for matches in the privacy policy to determine if !is described in the policy through a more general term.
if a match is found then a resulting violation is flagged as a weak violation i.e.
the policy contains a phrase transitively mapped to an api method name .
otherwise the violation is flagged as a strong violation which means there is no relationship between any phrase in the policy the ontology and the corresponding api method invocation.
while a strong violation is obviously harmful to the protection of the users privacy due to the lack of notice a weak violation is still potentially harmful because it indicates the lack in sufficient detail about the data practice and it can be used as a guide for improving the clarity of the privacy policy .
.
information flow analysis as explained above an api method invocation becomes a violation only if the information it fetches is sent to remote servers.
therefore we need to further check the destination of the fetched data and existing information flow analysis tools provide the technique needed for this goal.
we also require a list of sink methods that send information to remote servers.
it should be noted that our framework works with any information analysis tool and sink methods list for network data transfer.
in our implementation we leveraged flowdroid the state ofart technique for android information flow analysis to track the information flow within android byte code.
we also used the list of sink methods for network data transfer described by s usi a machine learning tool for classifying android sources and sinks.
.
empirical evaluation in this section we present an empirical evaluation of our framework by applying it to top android apps and their privacy policies.
in the evaluation we try to answer the following research questions.
rq1 is our framework able to detect violations of privacy policies in real world android apps?
rq2 how do the techniques in our framework affect its effectiveness on violation detection?
rq3 what are the major types of privacy information that are silently collected in detected privacy policy violations?
.
study setup in this subsection we introduce how we construct the data set for empirical evaluation the metrics used and the compared variants of our framework.
.
.
data collection the first step in our evaluation is to construct a data set of android apps with their corresponding privacy policies.
in particular from the official google play market we downloaded the top free apps5 as well as the top free apps for each app category6.
we combined all the downloaded apps and acquired an app data set of apps.
note that although most android apps have privacy policies the app owners may put the policy at different places such as their portal site at google play market or a link in the main page of their company organization.
the privacy policy can also be in different formats such as html pdf or windows word document.
based on our observation a large proportion of apps place their corresponding privacy policy at their portal websites at the google play market.
therefore we crawled these websites and tried to automatically download the privacy policies of these apps.
furthermore we considered only html privacy policies the most popular format of privacy policies in our evaluation for simplicity and avoiding potential noise in text extraction from various file formats.
note that with proper text extraction tools our framework can be applied to any format of privacy policies.
based on the automatic downloading and file format filtering we collected privacy policies for of the apps and thus generated a data set with apps and their corresponding privacy policies7.
.
.
evaluation metrics to answer research questions rq1 andrq2 we needed to measure the effectiveness of violation detection.
in our study we measured the effectiveness of our framework by the number of violations detected the number of true positives false positives and violations whose types strong violations or weak violations are mis identified.
it should be noted that the ground truth number of true violations in the entire data set is unknown and thus the number of false negatives can not be calculated.
in particular we determined whether a detected violation is a true violation by manual inspection and each violation was assigned to and inspected by two of the authors.
for disagreements a third author was assigned for reconciliation.
when counting violations we considered all invocations of the same api in an app as one violation.
.
.
evaluated techniques to answer research question rq2 we considered two variants of our framework and compared them with our default technique.
in our api mapping we leveraged the knowledge from android official documentation and crowd sourcing techniques to generate a fine grained mapping between api methods and phrases in privacy policies.
as a means to evaluate this fine grained mapping the first evaluation variant referred to as s usi only used the coarse grained s usiapi categorizations to map api methods to phrases.
specifically we assigned phrases in the ontology to their most relevant s usicategories e.g.
all descendants of the phrase unique identifiers in the ontology are assigned to the category of unique identifiers .
note that since we focus on the collection of platform information only the api methods in our mapping fall into one of the following categories in s usi unique identifiers location information network information bluetooth information and no category a s usicategory for api methods that are 5the ranking of top free apps is available at the google play website and was fetched on may 19th .
6the list of app categories is available at the google play website and the top apps for each category were fetched on may 19th .
7the data set is available at our project website 30number of apps percentage of apps .
.
.
.
.
number of detected violationsnumber of appsfigure distribution of apps on the number of detected violations difficult to categorize so we also assigned our policy phrases to these categories.
after the assignment of phrases we mapped all phrases in a category in s usicategories to all the api methods in the same category and thus generated a new coarse grained mapping based on s usionly.
a second variant referred to as keyword search was used to study the effectiveness of using light weight nlp techniques such as lemmatization to filter out irrelevant paragraphs in privacy policies described in section .
.
specifically this method did not use any filtering techniques and instead used a simple keyword searchbased strategy to extract phrases from the privacy policies.
.
study results overall results.
we applied our default technique to the pairs of apps and privacy policies in our data set.
for the apps with a minute time out limit for each app flowdroid successfully processed of them8.
from these apps our default technique detected violations in total including strong violations and weak violations.
our manual inspection revealed that among these detected violations were true violations including strong violations and weak violations note that our framework mistakenly classified strong violations as weak violations .
the detection of true weak violations shows that our privacy phrase ontology is helpful on differentiate weak violations from strong violations.
we further studied how these violations were distributed among the apps and the result is shown in the pareto chart in figure .
in the figure the blue bars represent the number of apps that have a certain number of violations and the red line represents the proportion of apps that have violations smaller or equal to a certain number.
from the figure we can observe that the violations are detected in apps and the majority of the apps had or fewer violations.
specifically the true strong violations are from apps and the true weak violations are from apps.
study on detection errors.
our default technique generated false positives for strong violations and false positives for weak violations.
from our manual inspection the cause for the majority of the false positives was that the privacy policies used phrases not in our ontology to describe the private information they collected.
for example a privacy policy used the phrase carrier provider to describe mobile network provider.
since the phrase is not in our ontology our technique mistakenly determined that network information is not mentioned in the privacy policy and reported a false vi8processing of the rest failed due to time out heap overflow or other exceptions.table evaluation of detected violations approach type de true mis fp default techniquestrong weak total susi onlystrong weak total keyword searchstrong weak total olation.
another relatively minor cause of false positives was that in some cases our nlp technique may have mistakenly filtered out paragraphs related to data collection.
in such a scenario the phrases in the removed paragraph would not be detected so their corresponding api methods would not be added to arepresented for the app and thus a violation would be raised.
overall our default technique was able to detect privacy policy violations in a significant number of top android apps and our false positive rate is relatively low suggesting that developers do not need to waste much effort on inspecting false violations.
comparison of variant techniques.
to answer rq2 we implemented the two variant techniques described in section .
.
and applied them to our data set.
the three techniques detected violations in total.
specifically the keyword search variant detected a proper subset of the violations detected by our default technique and the s usi only technique detected weak violations and strong violation that our default technique did not find.
our manual inspection found that of the weak violations and the strong violation were true positives.
in table columns presents the number of detected violations de the number of correctly classified true positives true the number of misclassified true positives mis and the number of false positives fp respectively.
from the table we make the following observations.
first among the techniques our default technique was able to detect the most violations and achieved the highest type classification accuracy .
.
therefore our default technique was more effective in general.
second the s usi only variant was only able to detect violations with strong violations misclassified as weak violations.
inspection of the missed violations showed that the major reason for missed violations was that the s usicategories are simply too coarsely grained.
this was apparent particularly for the category of network information where an api method may be mapped to a phrase that has not much relation with it.
for example the method getnetworkoperatorname should be mapped to carrier network but under the umbrella of network information it is also mapped to wifi access points mac address etc.
therefore an app that sends carrier network information through this api method may be interpreted as not having a related violation because of the mistakenly mapped phrases are in the privacy policy.
third the keyword search technique is able to detect slightly fewer violations but it cannot classify strong violations from weak violations.
the reason is that the more abstract a phrase is the more likely that it appears in a paragraph that is not related to data collection.
for example the phrase mac address is almost always used to describe data collected while the phrase network may be used for many different purposes e.g.
social network .
since the keyword search variant cannot filter out paragraphs that are not data collection related it can mistakenly extract many abstract phrases from irrelevant sections.
under the umbrella of these abstract phrases an api methods can easily find a map and thus a 31strong weak 60getnetworkoperatorname getlastknownlocation getnetworkcountryiso getlongitude getlatitude getuseragentstring getdeviceid getsimoperator getnetworkoperator getsimcountryiso number of detected true violationsapi namefigure apis with most detected violations strong weak 60carrier network mcc real time location longitude latitude browser type unique device id imei udid location tags number of detected violationsphrase figure terms with most detected violations strong violation is mistakenly identified as weak violation.
top privacy information types in detected violations.
to understand what types of private information are silently collected in privacy policy violations we studied the api methods and phrases that were associated with most detected true violations.
the results are presented in figure and figure respectively.
in the two figures the y axis shows the name of the api or phrase and the x axis shows the number of strong shown in gray violations and weak shown in black violations associated with the api method or phrase.
for brevity we present only the short name of apis in figure .
from figure we can observe that the top api methods associated with detected violations fall into major categories.
the api methods ranked 1st 3rd 8th 9th 10th in the list are all regarding mobile network information such as carrier network and mobile country code.
the api methods ranked 2nd 4th and 5th are about gps location information.
the other two relatively smaller categories are getuseragentstring browser information ranked the 6th and getdeviceid ranked the 7th.
similarly figure shows a similar trend in that mobile country code mcc and carrier network are the most common missing phrases.
the category of gps location is related to the phrases ranked the 3rd 4th and 5th.
the following two categories are different ways to describe device identifiers such as imei udid etc.
and the browser type.
it should be noted that location information is one of the most important types of information involved in detected violations since it is required to be explicitly stated in privacy policies .
.
threats to validity construction validity is the extent to which we have measured what we think we are measuring .
in this study we collected annotated phrases privacy policy terms and api terms that concern platform information.
to address this threat we provided annota tors with the same process and instructions for identifying relevant phrases and we selected only those policy terms where two or more workers agreed to the annotation.
when constructing the ontology the investigators employed heuristics to justify the classification and agreement was measured using a chance corrected statistic at each iteration to identify disagreements for reconciliation.
with respect to measuring violations we introduced two kinds of violations strong violations wherein the known policy terms were not found in the associated policies and weak violations in which the app s policy includes vague terms that are generally associated with the information accessed by the app.
internal validity refers to whether the causal inferences we derive from the dataset are valid .
when mapping policy terms to api terms the investigators made numerous inferences.
to reduce this threat the investigators decomposed the mapping process into multiple independent tasks annotating the policy excerpts to identify personal information accessed through the platform identifying ontological relationships between policy terms identifying canonical names for platform api and classifying those names by the policy terms in the ontology.
for each of these step the work was limited to small tasks in which each datum was individually reviewed by multiple investigators.
the entire process consumed more than hours however it reduced the likelihood that inferences would be missed for example by identifying relevant api method descriptions and aligning them directly with policies in an otherwise ad hoc fashion.
external validity refers to the extent to which our results generalize to other policies and domains.
in this study we manually examined policies to construct the ontology and policy api mapping.
to reduce this threat we selected the most frequently used apps from different app categories to enhance the representativeness of our data set.
however we only sampled from android apps thus it is possible that our results do not extend to ios based apps or further to web based applications.
however some of our apps only had a combined privacy policy for mobile and web based applications thus we are confident that our method could be extended to web based applications with further research.
.
discussion .
violation detection we have shown in section .
that the mapping helps to facilitate policy violation detection with a reasonable number of false positives.
this trait could be used to assist developers in verifying policy consistency for their own code.
in such a scenario the tool could bring to light potential violations between policy and code that may not be immediately or intuitively obvious to the end user or developer.
furthermore because the framework would be used as a quality assurance tool for developers false positives do not present a threat since by definition a falsely detected violation would be covered by the privacy policy.
violation detection is improved through the use of our ontology as relevant in the detection of strong and weak violations .
the ability for compliance to be implied through transitive relationships between terms allows for the improvement of the overall approach without the need for more method phrase maps.
an increase in coverage could be achieved by simply improving or adding phrases to the ontology resulting in the possible detection of more weak violations.
the relationships between methods and policy phrases also have the potential to be applied to new and existing api documentation to improve privacy risk awareness.
this could be used as a standard through which methods could be associated directly and indirectly to policy oriented phrases.
such annotations could 32then be used for violation detection and policy generation as well as an indication of the privacy relevant information types produced by the method.
the potential benefits to developers from our work imply a need for a tool.
we are currently working on an android studio ide plugin polidroid that takes an existing privacy policy and source code as input and notifies the developer of potential violations in a similar style to syntax error highlighting.
the tool works by scanning the privacy policy for phrases from our ontology and producing a list of permissible api method calls api represented .
the tool then scans through the source code for api method calls that exist in our entire mapping to produce a set of methods that both exist in the code and that we have data for api used.
ifapi used contains methods not present in api represented a notification is raised signifying a potential violation.
effectively the tool takes source code and a natural language policy to raise warnings about the terms used in the policy.
the tool would also be able to function without a policy as input and instead produce terms with which a policy can be created.
this would work by scanning the code for methods in our mapping and producing a minimum set of terms that would cover all of the methods.
we believe such a tool would be appropriate for android app developers due to their familiarity with the ide.
.
ontology learning system the ontology produced for this work was based only on phrases found in privacy policies owing to the time intensive nature of manually annotating the policies.
to enable the inclusion of related phrases from many more policies into our ontology we have developed an ontology learning system ols based on natural language processing nlp tools and the owl api.
using this learning system we have been able to extract phrases with subsumption relationships between them from privacy polices.
we ran this tool on a sample of privacy polices and we were able to extract sentences that are related to information collection.
moreover the subsumption relationship between the phrases in the same sentence were also identified.
currently we are working to improve the results of the tool through sanitization and enhancements to the parser.
as a next step we will use the owl api to automatically extend the initial ontology used in this study with extracted phrases and relationships from the ols.
.
web based applications during our analysis of the privacy policies we found that many of the policies were made to cover a wide range of apps not limited to androidos.
in most of these cases the text implied the relevance of web based applications.
we believe that our technique has the potential to be applied to such applications.
however since web based applications do not freely provide their implementation such as android s apk bytecode it would be difficult to mine their api method calls.
furthermore the wide variety of web application frameworks languages platforms and servers would add more layers of implementation to take into account.
this is out of our scope until there is enough data from web based applications with common components.
.
related work prior work exists on the factoring of privacy and privacy policies into source code.
to our knowledge ours is the only technique that works to bridge the gap between privacy policy and implementation through the use of natural language mappings to api methods.
.
privacy and permissions android has a permission system that is used for apps go to gain access to certain api methods.
an app must declare these permissions as part of its source code.
in turn the user is notified during installation as to what the app requests.
this permission system is related to privacy policies in that the methods that are accessed through the permissions are or should be represented in the app s privacy policy.
an app s privacy policy can be cross checked with an app s permissions but permissions are not necessarily defined at method level granularity.
there is existing research that explores both privacy policies and os permissions.
rowen et al.
have developed an ide plugin privacy policy auto generation in eclipse page for generating privacy policies along side the development of the app .
page works by guiding the user through a series of questions about the implementation of the app.
based on the answers page uses existing policy templates to generate a privacy policy for the app.
unlike our technique page does not take into account method calls or information flow and cannot be used for the detection of policy violations.
as described in section .
we are working on a tool that uses our mappings to both generate phrases for use in privacy policies and verify the accuracy of a policy with respect to its app.
the static analysis tool pscout was developed by au et al.
for the analysis of the android os permission system .
the android permission system helps policy consistency since it is used to show at a course grained level the data that the app can access.
pscout maps these permissions to method calls in order to evaluate their coverage.
pscout itself does not work as a tool for linking policies to code but its analysis of the android permission system shows a limited interconnection of method permission mappings with over of methods related to only one permission.
among our mappings of the methods mapped to only one phrase.
we believe this is due to how our approach uses canonicalization to expand a method s description to potentially associate it with more than one policy phrase.
this higher rate of interconnectivity is important for violation detection since methods can return objects from which more than one type of information can be collected.
existing work by petronella presents a tool that relates natural language in privacy policies to android permissions .
the tool works by providing the user with the list of permissions for an app along with the sentences from the privacy policy that are related to each permission.
this is similar to our work in that it maps natural language phrases to potential data collection actions in the app s implementation.
however it is limited to the granularity of the android permission system.
our work looks past permissions and related policy phrases directly to method invocations.
stoaway a tool created by felt et al.
detects over privilege in compiled android apps .
the tool found that among apps .
were over privileged.
analysis of the apps showed that copied code and testing artifacts were among the reasons for unnecessary privileges.
these kinds of defects can be brought to light with policy verification through the use of our violation detection framework.
vidas et al.
have created a tool permission check tool to assist developers in selecting minimal necessary permissions .
the tool uses static analysis to check the code for api