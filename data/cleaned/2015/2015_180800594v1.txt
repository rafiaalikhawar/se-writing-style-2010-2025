improving ir based bug localization with context aware query reformulation mohammad masudur rahman university of saskatchewan saskatoon canada masud.rahman usask.cachanchal k. roy university of saskatchewan saskatoon canada chanchal.roy usask.ca abstract recent findings suggest that information retrieval ir based bug localization techniques do not perform well if the bug report lacks rich structured information e.g.
relevant program entity names .
conversely excessive structured information e.g.
stack traces in the bug report might not always help the automated localization either.
in this paper we propose a novel technique blizzard that automatically localizes buggy entities from project source using appropriate query reformulation and effective information retrieval.
in particular our technique determines whether there are excessive program entities or not in a bug report query and then applies appropriate reformulations to the query for bug localization.
experiments using bug reports show that our technique can localize the buggy source documents with higher hit higher map and higher mrr than the baseline technique.
comparison with the state of the art techniques and their variants report that our technique can improve in map and in mrr over the state of the art and can improve of the noisy queries and of the poor queries.
ccs concepts software and its engineering software verification and validation software testing and debugging keywords debugging automation bug localization bug report quality query reformulation information retrieval graph based term weighting acm reference format mohammad masudur rahman and chanchal k. roy.
.
improving irbased bug localization with context aware query reformulation.
in proceedings of the 26th acm joint european software engineering conference and symposium on the foundations of software engineering esec fse november lake buena vista fl usa.
acm new york ny usa pages.
introduction despite numerous attempts for automation software debugging is still largely a manual process which costs a significant amount of development time and efforts .
one of the permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
copyrights for components of this work owned by others than acm must be honored.
abstracting with credit is permitted.
to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
request permissions from permissions acm.org.
esec fse november lake buena vista fl usa association for computing machinery.
acm isbn .
.
.
.
steps of debugging is the identification of the location of a bug in the source code i.e.
bug localization .
recent bug localization techniques can be classified into two broad families spectra based andinformation retrieval ir based .
while spectra based techniques rely on execution traces of a software system ir based techniques analyse shared vocabulary between a bug report i.e.
query and the project source for bug localization .
performances of ir based techniques are reported to be as good as that of spectra based techniques and such performances are achieved using a low cost text analysis .
unfortunately recent qualitative and empirical studies have reported two major limitations.
first ir based techniques cannot perform well without the presence of rich structured information e.g.
program entity names pointing to defects in the bug reports.
second they also might not perform well with a bug report that contains excessive structured information e.g.
stack traces table .
one possible explanation of these limitations could be that most of the contemporary ir based techniques use almost verbatim texts from a bug report as a query for bug localization.
that is they do not perform any meaningful modification to the query except a limited natural language pre processing e.g.
stop word removal token splitting stemming .
as a result their query could be either noisy due to excessive structured information e.g.
stack traces or poor due to the lack of relevant structured information e.g.
table .
one way to overcome the above challenges is to a refine the noisy query e.g.
table using appropriate filters and b complement the poor query e.g.
table with relevant search terms.
existing studies that attempt to complement basic ir based localization with costly data mining or machine learning alternatives can also equally benefit from such query reformulations.
in this paper we propose a novel technique blizzard that locates software bugs from source code by employing context aware query reformulation and information retrieval.
our technique first determines the quality i.e.
prevalence of structured entities or lack thereof of a bug report i.e.
query and classifies it as either noisy richorpoor then applies appropriate reformulation to the query and finally uses the improved query for the bug localization with information retrieval.
unlike earlier approaches it either refines a noisy query or complements a poor query for effective information retrieval.
thus blizzard has a high potential for improving ir based bug localization.
to illustrate the capability of our technique in improving bug localization we provide two examples in which it outperforms the baseline.
the baseline technique that uses all terms except punctuation marks stop words and digits from a bug report returns its first correct result for the noisy query containing stack traces in table at the 53rdposition.
on the contrary our technique refinesarxiv .00594v1 aug 2018esec fse november lake buena vista fl usa mohammad masudur rahman and chanchal k. roy table a noisy bug report eclipse.jdt.debug field content title should be able to cast null description when trying to debug an application the variables tab is empty.
also when i try to inspect or display a variable i get following error logged in the eclipse log file java.lang.
nullpointerexception at org.eclipse.jdt.internal.debug.core.
model.
jdivalue .tostring jdivalue.java at org.eclipse.jdt.internal.debug.eval.ast.
instructions.
cast .execute cast.java at org.eclipse.jdt.internal.debug.eval.ast.engine.
........................................ more ....................................... the same noisy query and returns the first correct result at the first position of the ranked list which is a significant improvement over the baseline.
similarly when we use a poor query containing no structured entities such as in table the baseline technique returns the correct result at the 30thposition.
on the other hand our technique improves the same poor query and returns the result again at the first position.
buglocator one of the well cited irbased techniques returns such results at the 19thand 26thpositions respectively for the noisy and poor queries which are far from ideal.
we evaluate our technique in several different dimensions using four widely used performance metrics and bug reports i.e.
queries from six java based subject systems.
first we evaluate in terms of the performance metrics contrast with the baseline and blizzard localizes bugs with higher accuracy i.e.
hit higher precision i.e.
map and and higher result ranks i.e.
mrr than the baseline section .
.
second we compare our technique with three bug localization techniques and our technique can improve in map and in mrr over the state of the art section .
.
third we also compare our approach with four state of the art query reformulations techniques and blizzard improves the result ranks of of the noisy queries and of the poor queries which are and higher respectively than that of the stateof the art section .
.
by incorporating report quality aspect andquery reformulation into ir based bug localization we resolve an important issue which was either not addressed properly or otherwise overlooked by earlier studies which makes our work novel .
thus the paper makes the following contributions a novel query reformulation technique that filters noise from and adds complementary information to the bug report and suggests improved queries for bug localization.
a novel bug localization technique that locates bugs from the project source by employing quality paradigm of bug reports query reformulation and information retrieval.
comprehensive evaluation of the technique using bug reports from six open source systems and validation against seven techniques including the state of the art.
a working prototype with detailed experimental data for replication and third party reuses.
graph based term weighting term weighting is a process of determining relative importance of a term within a body of texts e.g.
document .
jones first introduced tf idf i.e.
term frequency inverse document frequency as a proxy to term importance which had been widely usedtable a poor bug report eclipse.jdt.ui field content title mark occurences pref page description there should be a link to the pref page on which you can change the color.
namely general editors text editors annotations.
it s a pain in the a to find the pref if you do not know eclipse s preference structure well.
by information retrieval community for the last couple of decades.
unfortunately tf idf does not consider semantic dependencies among the terms in their importance estimation.
mihalcea and tarau later proposed textrank as a proxy of term importance which was adapted from google s pagerank and was reported to perform better than tf idf.
in textrank a textual document is encoded into a text graph where unique words from the document are denoted as nodes and meaningful relations among the words are denoted as connecting edges .
such relationships could be statistical e.g.
co occurrence syntactic e.g.
grammatical modification or semantic i.e.
conceptual relevance in nature .
in this research we identify important terms using graph based term weighting from a bug report that might contain structured elements e.g.
stack traces and unstructured regular texts.
blizzard proposed technique fig.
shows the schematic diagram of our proposed technique blizzard.
furthermore algorithm shows the pseudo code for blizzard.
we make use of bug report quality query reformulation and information retrieval for localizing bugs in source code from bug reports of any quality as shown in the following sections .
bug report classification since our primary objective with this work is to overcome the challenges posed by the different kinds of information bug reports may contain we categorize the reports prior to bug localization.
in addition to having natural language texts a bug report typically may contain different structured elements stack traces reported active stack frames during the occurrence of a bug e.g.
table and program elements such as method invocations package names and source file names.
having consulted with the relevant literature we classify the bug reports into three board categories steps 2a 2b and 2c fig.
as follows brst ststands for stack traces.
if a bug report contains one or more stack traces besides the regular texts or program elements it is classified into br st. since trace entries contain too much structured information query generated from such a report is generally considered noisy .
we apply the following regular expression to locate the trace entries from the report content.
.
?
.
.
.
.
.java d unknown source native method brpe pestands for program elements.
if a bug report contains one or more program elements e.g.
method invocations package names source file name but no stack traces in the texts then it is classified into br pe.
queries generated from such report are considered rich.
we use appropriate regular expressions to identify the program elements from the texts.
brnl nlstands for natural language.
if a bug report contains neither any program elements nor any stack traces it is classifiedimproving bug localization with context aware query reformulation esec fse november lake buena vista fl usa bug report initial query bug report classification brst brpe brn l exception traces trace graph text preprocessing text graph pseudo relevance feedback source token graph graph based term weighting term ranking reformulated query bug localization buggy entities a b c12a 2b 2c3a 3b 3c4a 4b 4c5 figure schematic diagram of the proposed technique a bug report classification b query reformulation and c bug localization into br n l. that is it contains only unstructured natural language description of the bug.
queries generated from such reports are generally considered poor in this work.
we adopt a semi automated approach in classifying the bug reports i.e.
the queries .
once a bug report is provided we employ each of our regular expressions to determine its class.
if the automated step fails due to ill defined structures of the report the class is determined based on manual analysis.
given the explicit nature of the structured entities human developers can identify the class easily.
the contents of each bug report are considered as the initial queries which are reformulated in the next few steps.
.
query reformulation once bug reports i.e.
queries are classified into three classes above based on their structured elements or lack thereof we apply appropriate reformulations to them.
in particular we analyse either bug report contents or the results retrieved by them employ graphbased term weighting and then identify important keywords from them for query reformulation as follows trace graph development from br st according to existing findings bug reports containing stack traces are potentially noisy and performances of the bug localization using such reports i.e.
the queries are below the average.
hence important search keywords should be extracted from the noisy queries for effective bug localization.
in this work we transform the stack traces into a trace graph e.g.
fig.
steps 3a 4a fig.
lines algorithm and identify the important keywords using a graph based term weighting algorithm namely pagerank .
to the best of our knowledge to date graph based term weighting has been employed only on unstructured regular texts and semi structured source code .
on the contrary we deal with stack traces which are structured and should be analysed carefully.
stack traces generally comprise of an error message containing the encountered exception s and an ordered list of method invocation entries.
each invocation entry can be considered as a tuple t p c m that contains a package name p a class name c and a method name m. while these entities are statically connected within a tuple they are often hierarchically connected e.g.
callercallee relationships to other tuples from the traces as well.
hill et al.
consider method signatures and field signatures as salient entities from the source code and suggest keywords from them for code search.
similarly we consider class name and method name from each of the ntuples as the salient items and represent themcast access interpreter jdivaluetostring run runevaluationdoevaluationevaluationthread execute jdithreadthreadevaluationthread tostring jdivaluerun execute figure trace graph of stack traces in table as the nodes and their dependencies as the connecting edges in the graph.
in stack traces the topmost entry i.e.
i has the highest degree of interest which gradually decreases for the entries at the lower positions in the list.
that is if ti pi ci mi is a tuple under analysis and tj pj cj mj is a neighbouring tuple with greater degree of interest then the nodes viand edges eiare added to the trace graph gstas follows vi ci mi ei ci mi ci cj mi mj j i v n i vi e n i ei gst v e for the example stack traces in table the following connecting edges jdivalue tostring cast execute cast jdivalue execute tostring interpreter execute andinterpreter cast are added to the example trace graph in fig.
.
text graph development from br pe bug reports containing relevant program entities e.g.
method names are found effective as queries for ir based bug localization .
however we believe that appropriate keyword selection from such reports can further boost up the localization performance.
existing studies employ textrank and posrank on natural language texts and identify search keywords for concept location and information retrieval .
although bug reports i.e.
from br pe might contain certain structures such as program entity names e.g.
class name method name and code snippets besides natural language texts the existing techniques could still be applied to them given that these structures are treated appropriately.
we thus remove stop words and programming keywords from a bug report split the structured tokens using samurai i.e.
a state of the art token splitting tool and then transform the preprocessed report rpp into a set of sentences s rpp .
we adopt rahman and roy that exploits co occurrences andsyntactic dependencies among the terms for identifying important terms from a textual body e.g.
esec fse november lake buena vista fl usa mohammad masudur rahman and chanchal k. roy change request .
we thus develop two text graphs steps 3b 4b fig.
lines algorithm using co occurrences and syntactic dependencies among the words from each report as follows text graph using word co occurrences in natural language texts the semantics i.e.
senses of a given word are often determined by its contexts i.e.
surrounding words .
that is co occurring words complement the semantics of each other.
we thus consider a sliding window of size k e.g.
k capture co occurring words and then encode the word co occurrences within each window into connecting edges eof a text graph .
the individual words wi v are denoted as nodes in the graph.
thus for a target word wi the following node viand two edges ei will be added to the text graph g peas follows vi wi ei wi wi wi wi s v s rpp wi s vi e s rpp wi s ei gpe v e thus the example phrase source code directory yields two edges source code and code directory while extending the text graph with three distinct nodes source code and directory .
text graph using pos dependencies according to jespersen s rank theory parts of speech pos from a sentence can be divided into three ranks primary i.e.
noun secondary i.e.
verb adjective and tertiary i.e.
adverb where words from a higher rank generally define i.e.
modify the words from the same or lower ranks.
that is a noun modifies only another noun whereas a verb modifies another noun verb or an adjective.
we determine pos tags using stanford pos tagger and encode such syntactic dependencies among words into connecting edges and individual words as nodes in a text graph.
for example the sentence annotated using penn treebank tags open v bthedtsource n n code n ndirectory n n has the following syntactic dependencies source code code directory source directory open source open code and open directory and thus adds six connecting edges to the text graph.
source term graph development for br nl bug reports containing only natural language texts and no structured entities are found not effective for ir based bug localization .
we believe that such bug reports possibly miss the right keywords for bug localization.
hence they need to be complemented with appropriate keywords before using.
a recent study provides improved reformulations to a poor natural language query for concept location by first collecting pseudo relevance feedback and then employing graph based term weighting.
in pseudo relevance feedback top k result documents returned by a given query are naively considered as relevant and hence are selected for query reformulation .
since bug reports from br n lclass contain only natural language texts the above study might directly be applicable to them.
we thus adopt their approach for our query reformulation collect top k e.g.
k source code documents retrieved by a br n l based query and develop a source term graph steps 3c 4c fig.
lines algorithm .
hill et al .
consider method signatures and fields signatures from source code as the salient items and suggest keywords for code search from them.
in the same vein we also collect these signatures from each of the kfeedback documents for query reformulation.
in particular we extract structured tokens from each signature algorithm bug localization with query reformulation and ir procedure blizzard r r a given bug report q reformulated query terms classifying and preprocessing the bug report r cr getbugreportclass r rpp preprocess r representing the bug report as a graph switch crdo case brst st getstacktraces r gst gettracegraph st case brpe gpe gettextgraphs rpp case brn l rf getpseudorelevancefeedback rpp gn l getsourcetermgraph rf getting term weights and search keywords ifclasskey ck st pe n l then prck getpagerank gck q gettopkterm sortbyweight prck end if constructing the reformulated query q switch crdo case brst ne getexceptionname r me geterrormessage r q ne me q case brpe q q case brn l q rpp q bug localization with q from codebase corpus return lucene corpus q end procedure split them using samurai and then generate a natural language phrase from each token .
for example the method signature getcontextclassloader can be represented as a verbal phrase get context class loader .
we then analyse such phrases across all the feedback documents capture co occurrences of terms within a fixed window i.e.
k from each phrase and develop a source term graph.
thus the above phrase adds four distinct nodes and three connecting edges get context context class and class loader to the source term graph.
term weighting using pagerank once each body of texts e.g.
stack traces regular texts source document is transformed into a graph we apply pagerank to the graph for identifying important keywords.
pagerank was originally designed for web link analysis and it determines the reputation of a web page based on the votes or recommendations i.e.
hyperlinks from other reputed pages on the web .
similarly in the context of our developed graphs the algorithm determines importance of a node i.e.
term based on incoming links from other important nodes of the graph.
in particular it analyses the connectivity i.e.
connected neighbours and their weights of each term viin the graph recursively and then calculates the node s weight tw vi tw vi j in vi tw vj out vj improving bug localization with context aware query reformulation esec fse november lake buena vista fl usa here in vi refers to nodes providing incoming links to vi out vj refers to nodes that vjis connected to through outgoing links and is the damping factor.
brin and page consider as the probability of staying on the web page and as the probability of jumping off the page by a random surfer.
they use .
which was adopted by later studies and we also do the same.
we initialize each node in the graph with a value of .
and recursively calculate their weights unless they converge below a certain threshold i.e.
.
or the iteration count reaches the maximum i.e.
.
once the calculation is over we end up with an accumulated weight for each node step fig.
lines algorithm .
such weight of a node is considered as an estimation of relative importance of corresponding term among all the terms i.e.
nodes from the bug report i.e.
graph .
reformulation of the initial query once term weights are calculated we rank the terms based on their weights and select the top k k fig.
terms for query reformulations.
since bug reports i.e.
initial queries from three classes have different degrees of structured information or lack thereof we carefully apply our reformulations to them steps fig.
lines algorithm .
in case of br st i.e.
noisy query we replace trace entries with the reformulation terms extract the error message s containing exception name s and combine them as the reformulated query.
for br n l i.e.
poor query we combine preprocessed report texts with the highly weighted source code terms as the reformulated query.
in the case of br pe only top k weighted terms from the bug report are used as a reformulated query for bug localization.
.
bug localization code search once a reformulated query is constructed we submit the query to lucene .
lucene is a widely adopted search engine for document search that combines boolean search and vsm based search methodologies e.g.
tf idf .
in particular we employ the okapi bm25 similarity from the engine use the reformulated query for the code search and then collect the results step fig.
lines algorithm .
these resultant and potentially buggy source code documents are then presented as a ranked list to the developer for manual analysis.
working examples table shows our reformulated queries for the showcase bug reports in table i.e.
br st table i.e.
brn l and another example report from br peclass.
baseline queries from these reports return their first correct results at the 53rd for br st 27th for br pe and 30th for br n l positions of their corresponding ranked lists.
on the contrary blizzard refines the noisy query from br streport selects important keywords from br pereport and enriches the poor query from br n lreport by adding complementary terms from relevant source code.
as a result all three reformulated queries return their first correct results i.e.
buggy source files at the topmost i.e.
first positions which demonstrate the potential of our technique for bug localization.
experiment we evaluate our proposed technique in several different dimensions using four widely used performance metrics and more than 5k bug reports the queries from six different subject systems.
first we evaluate in terms of the performance metrics and contrast with thetable working examples technique group query terms qe baselinebrst127 terms from table after preprocessing bug id eclipse.jdt.debug53 blizzard nullpointerexception bug should be able to cast null jdivalue tostring execute evaluationthread run baselinebrpe195 terms after preprocessing from bug id eclipse.jdt.core27 blizzard astvisitor post postvisit previsit pre file post pre astnode visitor baselinebrn l32 terms from table after preprocessing bug id eclipse.jdt.ui30 blizzard preprocessed report texts compliance create preference add configuration field dialog annotation qe query effectiveness rank of the first returned correct result baseline for different classes of bug reports queries section .
.
second we compare our approach with three state of the art bug localization techniques section .
.
third and possibly the most importantly we also compare our approach with four state of theart query reformulations techniques section .
.
in particular we answer four research questions using our experiments as follows rq1 a how does blizzard perform in bug localization and b how do various parameters affect its performance?
rq2 do our reformulated queries perform better than the baseline search queries from the bug reports?
rq3 can blizzard outperform the existing bug localization techniques including the state of the art?
rq4 can blizzard outperform the existing query reformulation techniques targeting concept feature location and bug localization?
.
experimental dataset dataset collection we collect a total of bug reports from six open source subject systems for our experiments.
the dataset was taken from an earlier empirical study .
table shows our dataset.
first all the resolved i.e.
marked as resolved bug reports of each subject system were collected from the bugzilla and jira repositories given that they were submitted within a specific time interval .
then the version control history of each system at github was consulted to identify the bug fixing commits .
such approach was regularly adopted by the relevant literature and we also follow the same.
in order to ensure a fair evaluation we also discard such bug reports from our dataset for which no source code files e.g.
java classes were changed or no relevant source files exist in the collected system snapshot.
goldset development we collect changeset i.e.
list of changed files from each of our selected bug fixing commits and develop a goldset .
multiple changesets for the same bug were merged together.
replication package our working prototype and experimental data are publicly available for replication and reuse.
.
performance metrics we use four performance metrics for the evaluation and comparison of our technique.
since these metrics were frequently used byesec fse november lake buena vista fl usa mohammad masudur rahman and chanchal k. roy table experimental dataset system time period brst brpe brnl brall system time period brst brpe brnl brall total ecf oct jan eclipse.jdt.ui oct jun brst .
eclipse.jdt.core oct sep eclipse.pde.ui oct jun brpe .
eclipse.jdt.debug oct jan tomcat70 sep aug brn l .
total brst bug reports with stack traces brpe bug reports with program entities but no stack traces brn l bug reports with only natural language texts the relevant literature they are also highly appropriate for our experiments in this work.
hit k it is defined as the percentage of queries for which at least one buggy file i.e.
from the goldset is correctly returned within the top k results.
it is also called recall top k and top k accuracy in the literature.
mean average precision k map k unlike regular precision this metric considers the ranks of correct results within a ranked list.
precision k calculates precision at the occurrence of each buggy file in the list.
average precision k ap k is defined as the average of precision k for all the buggy files in a ranked list for a given query.
thus mean average precision k is defined as the mean of average precision k ap k of all queries as follows ap k d k 1pk bu y k s map k q qap k q q here function bu y k determines whether kthfile or result is buggy i.e.
returns or not i.e.
returns pkprovides the precision at kthresult and drefers to the number of total results.
s is the gold set for a query and qis the set of all queries.
the bigger the map k value is the better a technique is.
mean reciprocal rank k mrr k reciprocal rank k is defined as the multiplicative inverse of the rank of first correctly returned buggy file i.e.
from gold set within the top k results.
thus mean reciprocal rank k mrr k averages such measures for all queries in the dataset as follows mrr k q q q q1 f irstrank q here f irstrank q provides the rank of first buggy file within a ranked list.
mrr k can take a maximum value of and a minimum value of .
the bigger the mrr k value is the better a bug localization technique is.
effectiveness e it approximates a developer s effort in locating the first buggy file in the result list .
that is the measure returns the rank of first buggy file in the result list.
the lower the effectiveness value is the better a given query is i.e.
the developer needs to check less amount of results from the top before reaching the actual buggy file in the list.
.
experimental results we first show the performance of our technique in terms of appropriate metrics rq a then discuss the impacts of different adopted parameters upon the performance rq b and finally show our comparison with the baseline queries rq as follows selection of baseline queries and establishment of baseline technique and baseline performance existing studies suggest that text retrieval performances could be affected by query quality underlying retrieval engine or even text preprocessing steps .
hence we choose the baseline queries and baseline technique pragmatically for our experiments.
we conducttable performance of blizzard in bug localization dataset technique hit hit hit map mrr brstbaseline .
.
.
.
.
blizzard .
.
.
.
.
brpebaseline .
.
.
.
.
blizzard .
.
.
.
.
brn lbaseline .
.
.
.
.
blizzard .
.
.
.
.
allbaseline .
.
.
.
.
blizzard .
.
.
.
.
significantly higher than baseline emboldened comparatively higher a detailed study where three independent variables bug report field e.g.
title whole texts retrieval engine e.g.
lucene indri and text preprocessing step i.e.
stemming no stemming are alternated and then we choose the best performing configuration as the baseline approach.
in particular we chose the preprocessed version i.e.
performed stop word and punctuation removal split complex tokens but avoided stemming of the whole texts i.e.
title description from a bug report as a baseline query.
lucene was selected as the baseline technique since it outperformed indri on our dataset.
the performance of lucene with the baseline queries was selected as the baseline performance i.e.
table for ir based bug localization in this study.
in short our baseline is preprocessed whole texts splitting of complex tokens lucene search engine .
answering rq a performance of blizzard as shown in table on average our technique blizzard localizes .
of the bugs from a dataset of bug reports with mean average precision and a mean reciprocal rank of .
which are and higher respectively than the baseline performance measures.
that is on average our technique can return the first buggy file at the second position of the ranked list almost half of returned files are buggy i.e.
true positive and it succeeds three out of four times in localizing the bugs.
furthermore while the baseline technique is badly affected by the noisy i.e.
br st and poor queries i.e.
br n l our technique overcomes such challenges with appropriate query reformulations and provides significantly higher performances.
for example the baseline technique can localize of the bugs from br stdataset i.e.
noisy queries with only precision when top results are considered.
on the contrary our technique localizes of the bugs with precision in the same context which are and higher respectively than the corresponding baseline measures.
such improvements are about for br n l i.e.
poor queries.
in the cases where bug reports contain program entities i.e.
br pe and the baseline performance measures are already pretty high our technique further refines the query and provides even higher performances.
for example blizzard improves both baseline mrr and baseline map for br pe dataset by which is promising.
fig.
further demonstrates the comparative analyses between blizzard and the baseline technique for various top k results in terms of a precision and b reciprocal rank in the bug localization.improving bug localization with context aware query reformulation esec fse november lake buena vista fl usa figure comparison of blizzard with baseline technique in terms of a map k and b mrr k figure impact of query reformulation length on the map of our technique blizzard table query improvement by blizzard over baseline queries dataset query pair improved mrd worsened mrd preserved brstblizzard vs. bl t .
.
.
blizzard vs. bl .
.
.
brpeblizzard vs. bl t1 .
.
.
blizzard vs. bl .
.
.
brn lblizzard vs. bl t .
.
.
blizzard vs. bl .
.
.
allblizzard vs. bl t2 .
.
.
blizzard vs. bl .
.
.
preserved query quality unchanged mrd mean rank difference between blizzard and baseline queries blt title bl title description figure quality improvement of a noisy and b poor baseline queries by our technique blizzard from fig.
a we see that precision reaches to the maximum pretty quickly i.e.
at k for both techniques.
while the baseline technique suffers from noisy i.e.
from br st and poor i.e.
from br n l queries blizzard achieves significantly higher precision than the baseline.
our non parametric statistical tests mann whitney wilcoxon and cliff s delta reported p values .05with a large effect size i.e.
.
.
.
although the baseline precision for br peis higher blizzard offers even higher precision.
from fig.
b we see that mean reciprocal ranks of blizzard have a logarithmic shape and whereas the baseline counterparts look comparatively flat.
that is as more results from the top of the ranked list are considered more true positives are identified by our technique than the baseline technique does.
statistical tests also reported strong significance i.e.
p values .
and a large effect size i.e.
.
.
of our measures over the baseline counterparts.
that is blizzard performs a good job in reformulating the noisy and poor queries and such reformulations contribute to a significant improvement in the bug localization performances.answering rq b impact of parameters and settings we investigate the impacts of different adopted parameters query reformulation length word stemming and retrieval engine upon our technique and justify our choices.
blizzard reformulates a given query i.e.
bug report for bug localization and hence size of the reformulated query is an important parameter.
fig.
demonstrates how various reformulation lengths can affect the map of our technique.
we see that precision reaches the maximum for three report classes at different query reformulation lengths i.e.
r l .
for brst we achieve the maximum precision at r l and for br n l such maximum is detected with r lranging between and .
on the contrary precision increases in a logarithmic manner for br pe bug reports.
we investigated up to reformulation terms and found the maximum precision.
given the above empirical findings we chose r l for br st rl for br peand r l for r n las the adopted reformulation lengths and our choices are justified.
we also investigate the impact of stemming and text retrieval engine on our technique.
we found that stemming did not improve the performance of blizzard i.e.
reduced localization accuracy.
similar finding was reported by earlier studies as well .
we also found that lucene performs better than indri on our dataset.
besides lucene has been widely used by relevant literature .
given the above findings and earlier suggestions our choices on stemming and retrieval engine are also justified.
blizzard outperforms baseline in accuracy precision and reciprocal rank by and respectively across three report groups and our adopted parameters are also justified.
answering rq comparison with baseline queries while table contrasts blizzard with the baseline approach for top to results we further investigate how blizzard performs compared to the baseline when all results of a query are considered.
we compare our queries with two baseline queries title i.e.
bl t title description i.e.
bl from each of the bug reports.
when our query returns the first correct result at a higher position in the result list than that of corresponding baseline query we call it query improvement and vice versa query worsening .
when result ranks of the reformulated query and the baseline query are the same then we call it query preserving .
from table we see that our applied reformulations improve of the noisy queries i.e.
br st and of the poor i.e.
br n l queries both with worsening ratios.
that is the improvements are more than two times the worsening ratios.
fig.
further demonstrates the potential of our reformulations where improvement worsening and preserving ratios are plotted for each of the six subject systems.
we see that noisy queries get benefited greatly from our reformulations and on average their query effectiveness improve up to positions i.e.
mrd of br st table in the result list.
such improvement of ranks can definitely help the developers in locating the buggy files in the result list more easily.
the poor queries also improve due to our reformulations significantly i.e.
p value .
.
cliff s .
large and the correct results can be found positions earlier than the baseline in the result list starting from the top.
quantile analysis in table also confirms that noisy and poor queries are significantly improved by our provided reformulations.
besides the benefits of query reformulations are also demonstrated by our findings in table and fig.
.esec fse november lake buena vista fl usa mohammad masudur rahman and chanchal k. roy table comparison with ir based bug localization techniques rg technique hit hit hit map mrr brstbuglocator .
.
.
.
.
bluir .
.
.
.
.
amalgam bro .
.
.
.
.
blizzard .
.
.
.
.
blizzard bro .
.
.
.
.
amalgam .
.
.
.
.
blizzard .
.
.
.
.
brpebuglocator .
.
.
.
.
bluir .
.
.
.
.
amalgam bro .
.
.
.
.
blizzard .
.
.
.
.
blizzard bro .
.
.
.
.
amalgam .
.
.
.
.
blizzard .
.
.
.
.
brn lbuglocator .
.
.
.
.
bluir .
.
.
.
.
amalgam bro .
.
.
.
.
blizzard .
.
.
.
.
blizzard bro .
.
.
.
.
amalgam .
.
.
.
.
blizzard .
.
.
.
.
allbuglocator .
.
.
.
.
bluir .
.
.
.
.
amalgam bro .
.
.
.
.
blizzard .
.
.
.
.
blizzard bro .
.
.
.
.
amalgam .
.
.
.
.
blizzard .
.
.
.
.
rg report group bro bug report only significantly higher table components behind existing ir based bug localization techniquebug report only external resourcesmrrbrt brs st qr brh vch ah baseline .
buglocator .
bluir .
amalgam bro .
blizzard .
blizzard bro .
amalgam .
blizzard .
brt bug report texts brs bug report structures st stack traces qr query reformulation brh bug report history vch version control history ah authoring history bro bug report only feature used our applied reformulations to the bug localization queries improve of the noisy queries and of the poor queries and return the buggy files closer to the top of result list.
such improvements can reduce a developer s effort in locating bugs.
.
comparison with existing techniques answering rq comparison with existing ir based bug localization techniques our evaluation of blizzard with four widely used performance metrics shows promising results.
the comparison with the best performing baseline shows that our approach outperforms the baselines.
however in order to further gain confidence and to place our work in the literature we also compared our approach with three ir based bug localization techniques including the state of the art .
zhou et al .
first employ improved vector space model i.e.
rvsm and bug report similarity for locating buggy source files for a new bug report.
saha et al .
employ structured information retrieval where a bug report is divided into two fields title description and asource document is divided into four fields class method variable andcomments and then eight similarity measures between these two groups are accumulated to rank the source document.
we collect authors implementations of both techniques for our experiments.
while the above studies use bug report contents only the later approaches combine them and add more internal or external information sources such as version control history and author information .
in the same vein wang and lo recently combine five internal and external information sources similar bug report structured ir stack traces version control history and bug reporter s history for ranking a source document and outperform five earlier approaches which makes it the state of the art in ir based bug localization.
given that authors implementation is not publicly available we implement this technique ourselves by consulting with the original authors.
since blizzard does not incorporate any external information sources to ensure a fair comparison we also implement a variant of the state of the art namely amalgam bro.
it combines bug report texts structured ir and stack traces i.e.
table for source document ranking.
from table we see that amalgam performs the best among the existing techniques.
however its performance comes at a high cost of mining six information contents i.e.
table .
besides for optimal performance amalgam needs past bug reports version control history and author history which might always not be available.
thus to ensure a fair comparison we develop two variants of our technique blizzard bro and blizzard .
blizzard bro combines query reformulation with bug report only features whereas blizzard combines query reformulation with all ranking components of amalgam i.e.
details in table .
we then compare both blizzard and blizzard bro with amalgam bro and blizzard with amalgam respectively.
as shown in table blizzard outperforms amalgam bro in terms of all three metrics especially for br pereports while performing moderately high with other report groups.
for example blizzard provides higher mrr and higher map than amalgam bro for br pe.
when all report only features are complemented with appropriate query reformulations our technique blizzard bro outperforms amalgam bro in terms of all three metrics hit k map and mrr with each report groups.
such findings suggest that blizzard bro can better exploit the available resources i.e.
bug report contents than the state of theart variant and returns the buggy files at relatively higher positions in the ranked list.
furthermore blizzard outperforms the state of the art amalgam by introducing query reformulation paradigm.
for example blizzard improves hit and hit over amalgam for each of the three query types e.g.
and respectively for noisy queries br st .
it also should be noted that none of the existing techniques is robust to all three report groups simultaneously.
we overcome such issue with appropriate query reformulations and deliver hit irrespective of the bug report quality.
from table we see that blizzard bro provides higher mrr than amalgam bro by consuming equal amount of resources i.e.
bug report only.
all these findings above suggest two important points.
first earlier studies might have failed to exploit the report contents and structures properly for bug localization.
second query reformulation has a high potentialimproving bug localization with context aware query reformulation esec fse november lake buena vista fl usa table comparison of query effectiveness with existing query reformulation techniques technique rgimprovement worsening preserving improved mean q1 q2 q3 min.
max.
worsened mean q1 q2 q3 min.
max.
preserved rocchio .
.
.
rsv .
.
.
sisman and kak brst .
.
.
strict .
.
.
baseline blizzard .
.
.
rocchio .
.
.
rsv .
.
.
sisman and kak brn l .
.
.
strict .
.
.
baseline blizzard .
.
.
figure comparison of a map k and b hit k with the stateof the art ir based bug localization techniques figure comparison of hit across all subject systems for improving the ir based bug localization.
fig.
demonstrates a comparison of blizzard with the existing techniques in terms of a map k and b hit k for various top k results.
our statistical tests report that blizzard blizzard bro and blizzard outperform amalgam bro and amalgam respectively in map k by a significant margin i.e.
p values .
and large effect size i.e.
.
.
.
similar findings were also achieved for hit k. fig.
and fig.
focus on subject system specific performances.
from fig.
we see that blizzard outperforms amalgam bro with four systems in hit and falls short with two systems.
however blizzard bro and blizzard outperform amalgam bro and amalgam respectively for all six systems.
as shown in the box plots of fig.
blizzard has a higher median in mrr and map than amalgam bro across all subject systems.
amalgam improves both measures especially map .
however blizzard provides even higher mrr and map than any of the existing techniques including the state of the art.
our technique outperforms the state of the art from ir based bug localization in various dimensions.
it offers higher precision and reciprocal rank than that of state of the art variant i.e.
amalgam bro by using only query reformulation rather than costly alternatives e.g.
mining of version control history answering rq comparison with existing query reformulation techniques while we have already showed that our figure comparison of a mrr and b map with existing techniques across subject systems approach outperforms the baselines and the state of the art irbased bug localization approaches we also wanted to further evaluate our approach in the context of query reformulation.
we thus compared blizzard with four query reformulation techniques including the state of the art that were mostly used for concept feature location.
we use authors implementation of the state of the art strict and re implement the remaining three techniques.
we collect query effectiveness i.e.
rank of the first correct result of each of the reformulated queries provided by each technique and compare with ours using quantile analysis.
from table we see that of the noisy i.e.
br st queries are improved by strict and of the poor i.e.
br n l queries are improved by sisman and kak .
neither of these techniques considers bug report quality i.e.
prevalence of structured information or lack thereof and each technique applies the same reformulation strategy to all reports.
on the contrary blizzard chooses appropriate reformulation based on the class of a bug report and improves of the noisy queries and of the poor queries which are and higher respectively.
when compared using quantile analysis we see that our quantiles are highly promising compared to the baseline.
our reformulations clearly improve the noisy queries and of the improved queries return their first correct results within top i.e.
q positions whereas strict needs top positions for the same.
in the case of poor queries quantiles of blizzard are comparable to that of sisman and kak.
however blizzard worsens less and preserves higher amount of the baseline queries which demonstrate its high potential.
blizzard outperforms the state of the art in query reformulation using context aware i.e.
responsive to report quality query reformulation.
whatever improvements are offered to noisy and poor queries by the state of the art our technique improves more of noisy queries and more of the poor queries.esec fse november lake buena vista fl usa mohammad masudur rahman and chanchal k. roy threats to validity threats to internal validity relate to experimental errors and biases .
replication of existing studies and misclassification of the bug reports are possible sources of such threats.
we use authors implementation of three techniques and re implement the remaining four.
while we cannot rule out the possibility of any implementation errors we re implemented them by consulting with the original authors and their reported settings and parameters .
while our technique employs appropriate regular expressions for bug report classification they are limited in certain contexts e.g.
ill structured stack traces which require limited manual analysis currently.
more sophisticated classification approaches could be applied in the future work.
threats to external validity relate to generalizability of a technique .
we conduct experiments using java systems.
however since we deal with mostly structured items e.g.
stack traces program entities from a bug report our technique can be adapted to other oop based systems that have such structured items.
related work bug localization automated bug localization has been an active research area for over two decades .
existing studies from the literature can be roughly categorized into two broad families spectra based and information retrieval ir based .
we deal with ir based bug localization in this work.
given that spectra based techniques are costly and lack scalability several studies adopt ir based methods such as latent semantic indexing lsi latent dirichlet allocation lda and vector space model vsm for bug localization.
they leverage the shared vocabulary between bug reports and source code entities for bug localization.
unfortunately as existing evidences suggest they are inherently subject to the quality of bug reports.
a number of recent studies complement traditional ir based localization with spectra based analysis machine learning and mining of various repositories bug report history version control history code change history and bug reporter history .
recently wang and lo combine bug report contents and three external repositories and outperform five earlier ir based bug localization techniques which makes it the state of the art.
in short the contemporary studies advocate for combining multiple localization approaches e.g.
dynamic trace analysis deep learning learning to rank and multiple external information sources with classic ir based localization and thus improve the localization performances.
however such solutions could be costly i.e.
multiple repository mining and less scalable i.e.
dependency on external information sources and hence could be infeasible to use in practice.
in this work we approach the problem differently and focus on better leveraging the potential of the resources at hand i.e.
bug report and source code which might have been underestimated by the earlier studies.
in particular we refine the noisy queries i.e.
containing stack traces and complement the poor queries i.e.
lacks structured items and offer an effective information retrieval unlike the earlier studies.
thus issues raised by low quality bug reports have been significantly addressed by our technique and our experimental findings support such conjecture.
we compare withthree existing studies including the state of the art and the detailed comparison can be found in section .
i.e.
rq .
a few studies analyse stack traces from a bug report for bug localization.
however they apply the trace entries to boost up source document ranking and superfluous trace entries were not discarded from their stack traces.
learning to rank and deep learning based approaches might also suffer from noisy and poor queries since they adopt classic ir without query reformulation in their document ranking.
recent studies employ distributional semantics of words to address limitations of vsm.
since noisy terms in the report could be an issue our approach can complement these approaches through query reformulation.
query reformulation there exist several studies that support concept feature concern location tasks using query reformulation.
however these approaches mostly deal with unstructured natural language texts.
thus they might not perform well with bug reports containing excessive structured information e.g.
stack traces and our experimental findings also support this conjecture .
sisman and kak first introduce query reformulation in the context of ir based bug localization.
however their approach cannot remove noise from a query.
recently chaparro et al .
identify observed behaviour ob expected behaviour eb and steps to reproduce s2r from a bug report and then use ob texts as a reformulated query for bug localization.
however they only analyse unstructured texts whereas we deal with both structured and unstructured contents.
since we apply query reformulation we compare with four recent query reformulation techniques employed for concept location rocchio rsv strict and bug localization scp .
the detailed comparison can be found in section .
i.e.
rq .
in short existing ir based techniques suffer from quality issues of bug reports whereas traditional query reformulation techniques arenot well adapted for the bug reports containing excessive structured information e.g.
stack traces .
our work fills this gapof the literature by incorporating context aware i.e.
report quality aware query reformulation into the ir based bug localization.
our technique better exploits resources at hand and delivers equal or higher performance than the state of the art at a relatively lower cost.
to the best of our knowledge such comprehensive solution was not provided by any of the existing studies.
conclusion and future work traditional ir based bug localization is inherently subject to the low quality of submitted bug reports.
in this paper we propose a novel technique that leverages the quality aspect of bug reports incorporates context aware query reformulation into the bug localization and thus overcomes such limitation.
experiments using bug reports from six open source systems report that blizzard can offer up to and higher precision than the best baseline technique and the state of the art respectively.
our technique also improves more of noisy queries and more of the poor queries than that of state of the art.
in future we plan to apply our learned insights and our technique to further complex activities during debugging such as automatic bug fixing.
acknowledgement this research was supported by saskatchewan innovation opportunity scholarship and the natural sciences and engineering research council of canada nserc .improving bug localization with context aware query reformulation esec fse november lake buena vista fl usa