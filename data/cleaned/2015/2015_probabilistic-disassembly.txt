probabilistic disassembly kenneth miller y onghwi kwon y is u n zhuo zhang xiangyu zhang zhiqiang lin department of computer science purdue university west lafayette usa department of computer science university of virginia charlottesville usa department of computer science and engineering ohio state university columbus usa abstract disassembling stripped binaries is a prominent challenge for binary analysis due to the interleaving of code segments and data and the difficulties of resolving controltransfer targets of indirect calls and jumps.
as a result mostexisting disassemblers have both false positives fp and falsenegatives fn .
we observe that uncertainty is inevitable indisassembly due to the information loss during compilation andcode generation.
therefore we propose to model such uncertaintyusing probabilities and propose a novel disassembly technique which computes a probability for each address in the code space indicating its likelihood of being a true positive instruction.the probability is computed from a set of features that arereachable to an address including control flow and data flowfeatures.
our experiments with more than two thousands binariesshow that our technique does not have any fn and has only3.
fp .
in comparison a state of the art superset disassemblytechnique has fp .
a rewriter built on our disassemblycan generate binaries that are only half of the size of thoseby superset disassembly and run faster.
while many widely used disassemblers such as ida and bap suffer from missingfunction entries our experiment also shows that even without anyfunction entry information our disassembler can still achieve 0fn and .
fp .
i. i ntroduction analyzing and transforming commercial off the shelf and legacy software have many applications such as bug finding security hardening reverse engineering code clone detection and refactoring.however they are highly challenging due to the lack of sourcecode.
the first fundamental problem is to precisely disassem ble the software.
the seemingly simple task is indeed highlychallenging due to the diversity and complexity of compilationand optimizations.
there are two popular kinds of disassemblytechniques.
the first one disassembles instructions followingthe address order called linear sweep disassemblers and the other disassembles instructions by following control flowedges e.g.
jumps and calls called traversal disassemblers.
both have well known limitations.
in particular code and datacan interleave causing a large number of false positives andeven false negatives in linear sweep disassemblers traversaldisassemblers suffer indirect control flow caused by functionpointers virtual tables and switch case statements whichmake recognizing control transfer targets highly difficult.
eventhe state of the art disassemblers such as those in bap ida pro ollydbg jakstab secondwrite and dyninst have difficulty fully disassembling complexbinaries .
some may miss up to of the code .
there are machine learning based methods that aimto recognize function entries by instruction patterns e.g.
starting with push ebp .
however such methods haveinevitable false positives and false negatives e.g.
the entriesof many library functions do not follow specific patterns .recently superset disassembly was proposed to address these limitations.
it disassembles at each address to produce asuperset of instructions.
a rewriter is built on the disassemblerto instrument all superset instructions.
while it has a criticalguarantee of no false negatives that other binary rewriting toolscannot provide the rewritten binaries have substantial codesize blow up and nontrivial runtime overhead e.g.
sizeoverhead and runtime overhead on spec programs .
we argue that the capabilities of reasoning about uncertainty is critical for binary analysis since it is inherent due to thelack of symbolic information.
our overarching idea is henceto use probabilities to model uncertainty and then performprobabilistic inference to determine the appropriate way ofdisassembling subject binaries.
in particular our disassemblercomputes a posterior probability for each address in the codesection to indicate the likelihood of the address denoting atrue positive instruction i.e.
an instruction generated by the compiler .
specifically our technique disassembles the binaryat each address just like superset disassembly.
we call theresult the superset instructions orvalid instructions which may or may not be true positives.
we then identify correlations between these superset instructions such as one being the transfer target of another and one defining a register that is later accessed by another.
these relations denote semanticfeatures that only the real code body would likely demonstrate.we call them hints.
they are uncertain because instructions decoded from random bytes may by chance possess suchfeatures.
for each kind of hint we perform apriori probabilityanalysis to determine their prior probabilities.
we develop an algorithm to aggregate these hints and compute the poste rior probabilities.
the resulting disassembler has probabilisticguarantees of no false negatives e.g.
the likelihood of missinga true positive instruction is lower than .
in our empirical study with binaries it never misses any true positive instruction with an appropriate setting.
it also has a muchsmaller number of false positives and much lower overheadin rewriting compared with superset disassembly.
our contributions are summarized as follows.
we propose an innovative idea of probabilistic disas sembling.
the capabilities of reasoning about uncertaintyprovides unique benefits compared to existing techniques.
we identify a set of features for use as disassembly hints ieee acm 41st international conference on software engineering icse .
ieee authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
disassembler false negative false positive linear sweep some substantial traversal substantial none superset none bloated our method none some with probabilistic guarantees t able i comparison of different kinds of disassemblers and perform static probability analysis to determine their likelihood iii b .
we develop a novel inference algorithm that leverages a number of key characteristics of x86 instruction design iv to aggregate uncertain hints.
our experiments on binaries demonstrate that our technique does not have any false negatives and the false positive rate is .
meaning that it disassembles .
additional instructions that are not true positives.
it does not miss any instructions even when function entries are not available with .
fp .
our evaluation on spec windows pe binaries shows that objdump misses instructions due to code and data interleavings whereas our tool misses none with .
fp .
we also use our disassembler in supporting binary writing.
when compared with the state of the art superset rewriting technique our technique reduces the size of rewritten binary by about and improves the runtime speed of the rewritten binary by .
ii.
b ackground and motiv a tion in this section we use a real world example to explain binary code disassembly the limitations of existing work ii a and how we advance the state of the art ii b .
a. binary code disassembly figure a presents a snippet from libubuntucomponents.so in ubuntu .
.
in this piece of code data is inserted in between the code bodies of two functions.
in a the bytes from 0xbbf72 to0xbbf8f in blue denote data.
address 0xbbf90 denotes the entry of a function.
another function omitted from the figure precedes the data bytes.
while the binary is stripped we acquire the ground truth through debug symbols from a separate unstripped instance.
linear sweep disassembly.
linear sweep disassemblers disassemble the next instruction from the bytes right after the current instruction.
here we use objdump .
without symbolic information objdump cannot recognize the data bytes.
as a result after it disassembles the body of the preceding function it proceeds to disassemble the data bytes to instructions 0xbbf72 0xbbf8b and so on as in figure b .
specifically in the shaded area it considers the three bytes starting at 0xbbf8f an instruction.
consequently it misses the true function entry 0xbbf90 .
note that the instruction sequences in figure are horizontally aligned by their addresses.
in addition objdump disassembles the wrong instruction at 0xbbf92 .
this illustrates that linear disassemblers cannot properly handle inter leavings of data and instructions .
note that embedding data such as constantvalues and jump tables in between code segments is a common practice in compilers .
as presented in table i linear sweep disassemblers have some false negatives i.e.
missing instructions and a lot of false positives i.e.
incorrectly disassembling data bytes as instructions .
false negatives are particularly problematic for binary rewriting as missing even a single instruction could have catastrophic consequences.
false positives can cause unnecessary overhead in rewriting ambiguity in type reverse engineering and so on.
traversal based disassembly.
some other diassemblers such as ida and bap disassemble by following control flow edges starting from function entries.
a prominent challenge is to recognize function entries.
missing an entry means the entire function body may not be properly disassembled.
the presence of indirect calls makes function entry identification difficult as the precise call targets are only known at runtime.
in our example there is no direct invocation to the function entry 0xbbf90 inlibubuntucomponent and the function is not exported either.
as a result ida misses the entire function body.
furthermore the first instruction of the function entry is a rarely used instruction mov 0x19b978 rip rax .
as such ml based techniques e.g.
likely miss it.
there are also nonlearning techniques to recognize functions in binaries .
they are based on heuristics such as the matching of push and pop operations at the entry and exit of a function.
however a systematic way to handle the inherent uncertainty in such heuristics is still in need.
as illustrated by table i traversal disassemblers have no false positives but potentially substantial false negatives .i n fact bao et al.
show that traversal disassemblers such as ida may miss .
function entries.
superset disassembly.
a state of the art technique particularly for rewriting instrumentation is called superset disassembly .
the idea is to consider that every address starts an instruction called superset instruction .
as such consecutive superset instructions may share common bytes.
rewriting is performed on all superset instructions.
it can be easily inferred that the superset disassembler has no false negatives but must have a bloated code body due to the large number of superset instructions that are not true positives table i .figure c presents the results for superset disassembly.
observe that a superset instruction is generated by disassembling the bytes starting at each address.
hence we have instructions at 0xbbf72 0xbbf73 ... 0xbbf91 0xbbf92 and so on.
observe that consecutive instructions share common byte values e.g.
the body of 0xbbf91 8b b9 is the suffix of 0xbbf90 .
also observe that all the true positive instructions i.e.
those in figure a are part of the superset.
as such the rewritten binary can properly execute as all possible jump call targets must be instructions in the superset and hence instrumented.
note that the bloated instructions cause not only substantial size overhead but also runtime slowdown because executing each authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
eei fv ud ud eei i fv ud eei fv ud eei e do ud eei f do ud eei g do ud eei h do ud eei i e fo ud eei e uls ud eei e e uls hd eei hd eei e eei ieei e hf eei u eei uvl eeie ug ugl eeie hg ugl eeied ii ugl ugl eeig hi eeif eei h i i gdwd eei i i gdwd eei e e e uls ud eei u eeid g ud ug eeid ud eeidf ud ugl eeie ug ugl eeied ii ugl ugl eeieg eeif eeig hi eeif eei fv ud ud eei e do ud eei g do ud eei i e fo ud eei hd eei u eeid ud ug eeid ud eeidf ud ugl eeie ug ugl d urxqg wuxwk e lqhdu vzhhs f 6xshuvhw glvdvvhpeo f 2xu v fig.
example from libubuntucomponent.so.
instructions are horizontally aligned by their addresses.
the code is slightlymodified for demonstration purposes.
in instructions with two operands the first one is source and the second one is destination.
superset instruction requires a table lookup to determine the location of the instrumented version.
b. our technique we aim to inherit the advantages of superset disassembly i.e.
no false negatives while substantially reducing the false positives and achieving much lower overhead.
the idea isthat true positives have lots of hints indicating that theyare true instructions.
for example they often have a lot ofdefinition and use def use relations caused by registers andmemory that is a register memory location is defined at anearlier instruction and then used in a later one.
in figure a hint circlecopyrt indicates a def use relation caused by register rax between instructions 0xbbf90 and0xbbfa2 circlecopyrt byrdx circlecopyrt indicates a def use by the flag bit.
note that false positive instructions are less likely to induce def use relations due totheir random nature.
for example instructions at 0xbbf8b0xbbf8f figure c define some memory indexed by rax but there are no corresponding uses.
furthermore two jumpsto the same target are likely true positives e.g.
hint circlecopyrt a s the chance that random jumps have the same target is small.more hints are discussed in iii b. however hints are uncertain meaning that false positives instructions have a small chance of exhibiting such features.for example according to iii b false positive instructions may have 16chance to have def use relation caused by some register.
hence the essence of our technique is to associate these hints with prior probabilities that are derived fromapriori probability analysis and then perform probabilisticinference to fuse these evidences to form strong confidenceabout true positives.
intuitively the inference procedure thataggregates prior probabilities is based on the following reason ing if a superset instruction is likely to be a true positive itscontrol flow descendants are likely to be true positives and thedifferent superset instructions that share common bytes withit are unlikely true positives.
note that we aim to disassemblebinaries generated by regular compilers so that instructionsdo not have overlapping bodies.
for example the instructionsinvolved in hints circlecopyrt circlecopyrt have reachability along control flow e.g.
those in circlecopyrtcan reach circlecopyrt allowing their probabilities to be progagated and aggregated.
intuitively while individually circlecopyrt circlecopyrt have certain probability e.g.
to be random the chance of all of them randomly happening together is verylow.
after inference the posterior probabilities indicate thelikelihood of superset instructions being true positives.
figure d shows the probabilities computed by our techniquefor each superset instruction.
observe that the true positives highlighted ones have large probabilities some of them arealmost certain such as 0xbbfb0 and0xbbfba whereas false positives have very small probabilities.
fig.
occlusion does not cascade iii.
p robabilistic characteristics of x a. observing instruction occlusion in x86 part of a valid instruction may be another valid instruction and two valid instructions may have overlapping authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
bodies.
we call them occluded instructions.
w es a yaf e w bytes form a valid instruction if they can be decoded to an instruction.
a valid instruction may not be a true positive instruction.
therefore if the starting point e.g.
function entry is not properly recognized we may have an occluded instruction sequence that differs from the true positive sequence.
consider an example in figure .
column one shows the continuous addresses column two shows the byte values and the remaining columns show different instructions sequences when disassembling starts at different addresses.
note that each instruction box aligns horizontally with its addresses and byte values in the first two columns.
column three shows the ground truth instruction sequence in which the first four bytes from 0x400597 to0x40059a form a mov instruction whereas the following five bytes form another mov instruction followed by a call instruction.
however if we start disassembling in the middle of the first instruction we could acquire sequences of valid instructions that occlude with the ground truth as shown in the remaining columns i.e.
occluded instructions are in grey .
observe that in columns four and five part of the mov instruction is decoded to a different mov instruction and a conditional jump instruction respectively.
in the last column the last byte 0xe0 of the mov instruction even groups with the first byte 0xbf of the next ground truth instruction to form a valid loopne instruction.
a concern about occlusion is that it may be cascading meaning that when we start at a wrong place a large number of following instructions are consequently occluded.
however researchers have the following observation .
occlusion rule cascading occlusion is highly unlikely occluded sequences tend to quickly agree on a common suffix of instructions.
if one of the sequences is the true positive sequence occluded sequences quickly converge with the true positive.
consider the example in figure .
the three occluded sequences all converge to the ground truth sequence after one or two instructions.
intuitively cascading occlusion is unlikely because two occluded instructions have a good chance to agree on their rears .
in other words the suffix of an instruction is likely to be another instruction.
consider figure .
the occluded instructions in columns and are the suffices of the ground truth mov instruction.
the only exception is that when an occluded instruction i0 e.g.
the loopne instruction infigure last column starts at the very end of a valid instruction j0 e.g.
the first mov in the 3rd column i0may go beyondj0and cause occlusion in the instruction following j0 sayj1 e.g.
the second mov in the 3rd column .
in this case i0likely ends in the middle of j1.
as such the instruction s following i0 e.g.
the sub andadd instructions in the last column agree with j1at the their rear ends.
we did a study on elf binaries and found that .
occluded instruction sequences converge within four instructions.
we have also conducted a formal probability proof from the encodings of x86 instructions.
our proof shows that for instructions i0 ... ikwithn0 ... nkbytes respectively.
the probability of fig.
control flow convergence an occluded sequence starting inside i0and not agreeing with the rear of ikis at most1 n0 ... nk .
with a sequence of instructions each having bytes the probability that an occluded sequence does not converge at all is1 .
intuitively it is analogous to that if two parties cannot settle on a dispute with a small probability pin one round of negotiation.
the probability that they cannot resolve within nrounds is pn.
the details are elided.
b. observing probabilistic hints for disassembling without knowing the appropriate entries of code segments we could disassemble at each address and acquire a set of all valid instructions or superset instructions with only some being true positives.
next we discuss a number of correlations between valid instructions that indicate that the corresponding bytes are not data bytes with high probabilities.
we call them probabilistic hints .
the occlusion rule and the probabilistic hints are the two corner stones of our technique.
hint i control flow convergence.
as shown in the middle offigure b if there are three potential instructions instr instr 2andinstr 3withinstr 3being the transfer target of bothinstr 1andinstr there is a good chance that they are not data bytes but rather instruction bytes .
figure a shows an example.
the bytes starting at 0x804a634 and at0x804a646 are disassembled to two conditional jumps a circlecopyrt and b circlecopyrt respectively whose target is a same valid instruction c circlecopyrt.
intuitively since it is highly unlikely data bytes can form two control transfer instructions and both by chance point to the same target they are likely instruction bytes.
this control flow relation is often induced by high level language structures such as conditional statements e.g.
figure c .
probability analysis.
assume data byte values have uniform distribution.
given two valid control transfer instructions instr 1andinstr letinstr s transfer target be t which has the range of and for relative near and long jumps respectively.
the likelihood that instr 2has the same transfer target is hence1 and1 .
in other words when we see two control transfer instructions having the same target the likelihood that they are data bytes is very low.
hint ii control flow crossing.
as shown in the middle offigure b if there are three valid instructions instr instr 2andinstr withinstr 2andinstr 3next to each other instr 3being the transfer target of instr andinstr 2having authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
fig.
control flow crossing a control transfer target different from instr and hence crossing control flow edges there is a good chance that they are not data bytes but rather instruction bytes .
figure a shows an example.
since it is highly unlikely data bytes can form two control transfer instructions with one jumping to right after the other they are likely instructions.
this control flow relation is often induced by loopy language structures e.g.
figure c with instr 1the loop head instr 2the last instruction of the loop body and instr 3the loop exit .
the probability analysis is similar to that of control flow convergence and hence elided.
there are also other control flow related hints.
for example if a valid control transfer instruction i e.g.
a jump has a target that does not occlude with the sequence starting from i the chance of idenoting data bytes is1 n withnthe average instruction length.
this is because a false positive jump disassembled from random data bytes may likely jump to the middle of an instruction.
although this hint is not as strong as the convergence and crossing hints a large number of such hints can be aggregated to form strong indication through an algorithm described in iv.
hint iii register define use relation.
we say a pair of instructions instr 1andinstr 2have a register define use defuse relation if instr 1defines the value of a register or some flag bit and instr 2uses the register or the flag bit .
in figure c there are two def use relations denoted by the arrows one induced by register rdx and the other by eax .
another example is that a flag bit is set by a comparison instruction and then used by a following conditional jump instruction.
given two valid instructions if they have def use relation they are unlikely data bytes.
note that false positive instructions often do not have register def use although they may demonstrate bogus memory def use relations.
figure a presents a snippet of jump table disassembled to a sequence of instructions.
observe that the first instruction adds al to the memory location indicated by rax whereas the second instruction adds cl to the same location.
there is a memory def use between the two instructions as the second instruction first reads the value stored in the location and then performs the addition.
however as we will show in later probability analysis register defuse is hardly random but rather caused by register allocation by compiler .
figure b presents a snippet of string.
it is disassembled to a sequence of valid instructions too.
observe that there are no register def use relations.
probability analysis.
assume data byte values have uniform distribution.
to simplify our discussion we further assumean arbitrary valid instruction has1 2chance to write to some register or some flag bit and the other1 2chance writing only to memory .
in contrast an arbitrary valid instruction reading some register is much more likely.
note that even a read from memory often entails reading from register.
for example the instruction at 0x4005ce infigure c performs a memory read which entails reading rbp .
hence we make an approximation just for the sake of demonstrating our probability analysis assuming the likelihood that an instruction reads some register is .
.
each instruction has three bits to indicate which register is being read written to according to the x86 instruction reference.
as such given two valid instructions instr 1andinstr they have register def use with the chance of1 .
in other words when we observe def use between two valid instructions the chance that they denote data bytes is1 .
we need to point out these hints only indicate the corresponding bytes are not data bytes they do not suggest the valid instructions are indeed true positives .
in other words they may be occluded instructions that are part of some ground truth instructions.
this is because occluded instructions often share similar features such as the same register operand s .
for instance bytes c2 which is the suffix of the first instruction in figure c is disassembled to mov eax edx which also has a register def use with the second instruction.
however observing these hints strongly suggests that the corresponding bytes are instruction bytes.
fortunately the aforementioned occlusion rule dictates that even there is occlusion it will soon be automatically corrected.
our disassembly technique is hence built on this observation.
besides the register def use hint we have other hints that denote data flow related program semantics.
for example an instruction saving a register to a memory location followed by another instruction that defines the register corresponds toregister spilling which can hardly be random.
we also consider memory def use between instructions of different opcodes.
details are elided.
iv .
p robabilistic disassembling algorithm as discussed in the previous section when a probabilistic hint is observed we have certain confidence that the corresponding bytes are not data bytes but rather instruction bytes although we are still uncertain if they are true positive instructions as their occluded peers may have similar properties as well.
the occlusion rule dictates that a sequence that starts with some occluded instruction can quickly correct itself and converge on true positive instructions.
therefore in our method we consider an instruction is likely a true positive if multiple sequences with a large number of hints converge on the instruction.
here a sequence starting from an instruction iis acquired by following the control flow e.g.
ifiis a unconditional jump the next instruction in the sequence would be the target of the jump .
we say multiple sequences converge on an instruction if it occurs in all of them.
specifically let a hint hhave a prior probability pbeing data byte with pcomputed by the analysis in the previous section.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
fig.
register definition use relation fig.
example for the algorithm the code snippet in foo corresponds to a statement for i i i ... since the following instructions are acquired strictly following the control flow semantics they inherit the probability p. intuitively if jis the next instruction of halong control flow j s probability of being some data byte is equal to or smaller thanp.
when the sequences starting with multiple hints h1 h2 ...hnconverge on an instruction i the probability of irepresenting data byte is d p p2 ... pn.a s such when a large number of hints converge on i iis highly unlikely a data byte.
however a small d does not necessarily denote that i is a true positive instruction.
we then leverage the exclusion property of a true positive instruction that is ifiis a true positive instruction all the other valid instructions occluding withimust not be true positive instructions1.therefore we compute the likelihood of ibeing a true positive instruction by conducting normalization with all the instructions occluded withi.
intuitively if iis the only one that has a very small d compared to all the occluded instructions iis highly likely true positive.
if there are occluded instructions whose dvalues are comparable to d we cannot be certain that iis true positive.
in this case we keep all these instructions just likesuperset disassembly.
however the key point is that due to the occlusion rule sequences quickly converge on true positivessuch that the occluded peers of the converged true positives arenot reachable by any sequences and hence receive no hints.
as such the true positives stand out in most cases the exceptionbeing very short and featureless code segments.
according toour experiments see v our technique never misses any true 1this property may not hold in manually crafted binaries in which the developer purposely introduces occlusion between true positive instructions.
however we focus on binaries generated by compilers in this paper.positive and has as low as .
false positives.
in comparison the false positive rate of superset disassembly is .
algorithm details.
algorithm 1takes as input a binary b which is an array of bytes indexed by address a list of hints h withh pmeaning that iis a hint with a prior probability p of being data bytes .
it produces posterior probabilities p withp the likelihood that ibeing a true positive instruction.
within the algorithm we use d to denote the probability i being a data byte and rh to denote the set of hints that reachi each hint represented by its address.
in lines the algorithm initializes all the dvalues and all therh values.
if the bytes starting at idenote invalid instruction d is set to .
otherwise to denote that we do not have any knowledge.
note that some byte sequences cannot be disassembled to any valid instruction.
due to the loopy structures in binary the algorithm is overall iterative and terminates when a fix point is reached.
theiterative analysis is in lines with variable fixed point used to determine termination.
the analysis consists of threesteps forward propagation of hints lines local propagation within occlusion space lines and backward propagation of invalidity lines .
the first step traverses from the beginning of bto the end propagating collecting hints and computing the aggregated probabilities.
it leveragesthe following forward inference the control flow successor of a likely instruction is also a likely instruction.
otherwise the program is invalid because its execution would lead toexception caused by the invalid instruction following thecontrol flow.
the second step is to propagate the computedprobability for each instruction itoits occlusion space consisting of all the other addresses that can be decoded into authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
algorithm probabilistic disassembling input b binary indexed by address h probabilistic hints denoted by a mapping from an address to a prior probability output p posterior probability of an address idenoting a true positive instruction v ariable d probability of address ibeing data byte rh the set of hints denoted by a set of addresses that reach an address i for each address iinbdo ifinvalidinstr i then d .
else d rh fixedpoint false while !fixedpoint do fixedpoint true f orward propagation of hints step i for each address ifrom start of bto end do ifd .0then continue ifh negationslash andi negationslash rh then rh rh i d h rh h for eachn the next instruction of ialong control flow do ifrh rh negationslash then rh rh rh d h rh h ifn i then fixedpoint false propagation to occlusion space step ii for each address ifrom start of bto end do ifd and joccluding with i s.t.
d negationslash then d min joccludes with i d backward propagation of invalidity step iii for each address ifrom end of bto start do for eachp the preceding instruction of ialong control flow do ifd ord d then d d ifp i then fixedpoint false compute posterior probabilities by normalization for each address ifrom start of bto end do ifd .0then p continue s d for each address j representing an instruction occluded with ido s s d p d s instructions occluding with i. it is to leverage the following local inference an instruction being likely renders all the other instructions in its occlusion space unlikely .
the third step traverses each address from the end to the beginning and propagates invalidity of instructions.
it leverages the following backward inference when an instruction iis unlikely all the instructions that reach ithrough control flow are unlikely .
intuitively it is the logical contrapositive of the forward inference rule .
the first step can be considered to identify instruction bytes whereas the second and third steps are to identify data bytes.
step i. in lines if idenotes a hint and ihas not been added to rh it is added to rh andd is updated tothe product of the prior probabilities of all the hints in rh line .
in lines the algorithm propagates the hints in rh toi s control flow successor s .
particularly if rh has some hint that the successor ndoes not have line the hints ofiare propagated to rh by a union operation line andd is updated.
in lines if the successor nhas a smaller address so that it has been traversed in the current round the analysis needs another round to further propagate the newly identified hint s .
step ii.
in lines the algorithm traverses all the addresses and performs local propagation of probabilities within occlusion space of individual instructions.
particularly for each addressi it finds its occluded peer jthat has the minimal probability i.e.
the most likely instruction .
the likelihood ofibeing data is hence computed as d line .
step iii.
lines traverse from the end to the beginning.
for each address i if its control flow predecessor pdoes not have any computed probability or has a smaller probability line which intuitively means that we have more evidence thatiis data instead of instruction then we set pto have the same level of confidence of denoting data bytes line .
in the extremal case if d .
d must be .0too.
ifphas a larger address than iand hence pmust have been traversed variable fixedpoint is reset and the analysis will be conducted for another round lines .
note that the control flow successors and predecessors are implicitly computed along the analysis.
our analysis does not require correctly recognizing indirect jump and call targets which is a very difficult challenge.
in other words even though such control flow relations are missing our technique can still collect enough hints from disconnected code blocks to disassemble correctly.
in v d we show that our technique can disassemble without any function entry information with false negatives and only .
false positives.
after the iterative process lines compute the posterior probabilities for true positive instructions by normalization.
if an instruction starting at iis invalid p is set to lines .
otherwise it sums up the inverse of probability dfor all the instructions occluded with i including iitself to s thenp is computed as the ratio between1 d ands.
example.
consider an example in figure .
it is much simpler than the one in iiand allows easy explanation.
the large box on the left shows a code snippet denoting the beginning of a function foo from 0x40058c to0x400594 and part of the function body from 0x4005c0 to0x4005e1 corresponding to a simple loop for i i i ... .
the code snippet is preceded by data bytes that stand for constant strings from 0x40057b to0x40058b .
the strings are disassembled to valid instructions.
note that symbolic information is not available we mark the function entry and strings just for explanation purpose.
boxes a circlecopyrt f circlecopyrt on the right stand for sequences starting from some occluded instructions.
the instructions in the grey background denote occlusions whereas instructions without background denote the converged ones which are horizontally aligned with the authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
corresponding instructions in the leftmost box.
for example in box a circlecopyrt disassembling at 0x40057c causes occlusion up to0x400583 .
in the following we show how our algorithm computes the probabilities for true positives.
during preprocessing our technique collects the hints and their prior probabilities.
each circled number denotes such a hint only part of the hints are shown .
for example circlecopyrt is a register def use hint hint iii in iii b due to rdi .
according to iii b the prior probability is1 being a data byte .
note that this hint actually occurs in the data bytes.
in addition circlecopyrtand circlecopyrtstand for the register spilling i.e.
backup and then update hint due to rbp andrsp respectively circlecopyrt stands for register def use circlecopyrt stands for control flow crossing hint ii in iii b and circlecopyrt stands for memory def use.
none of the occluded sequences provide any additional hints.
initially d d .0and all otherd values are .
in step i hints are collected and probabilities are computed in a forward fashion.
hint circlecopyrt cannot be propagated to address 0x400584 due to the bad instruction at 0x400583 and the sequences in a circlecopyrt and d circlecopyrt do not provide any hint hence d .
its occluded peers in 0x400585 0x400588 have the same dvalue.
in contrast d 16due to the hint circlecopyrt.
similarly d 3due to the three hints it is involved in.
as shown in boxes b circlecopyrt its occluded peer 0x40058e cannot be reached from 0x40058c .
as a result it gets no hint and d .
similarly d .
let us skip a few instructions and consider 0x4005db .
due to the loop with the backedge 0x4005df 0x4005c2 hints circlecopyrt circlecopyrt all reach 0x4005db .
as such d is a tiny value smaller than1 .
in contrast as shown in c circlecopyrtand f circlecopyrt no hints can reach its occluded peers 0x4005dc and0x4005dd and theirdvalues remain .
through step ii of local propagation in occlusion space d d andd d similarequal1.
in step iii the invalidity information is propagated backward.
that is if an address has a larger d value than its predecessor the predecessor inherits that d value.
specifically 0x400583 being invalid invalidates all its control flow predecessors including 0x400582 0x400581 0x40057f and0x40057b .
that is their dvalues equal to .
.
in contrast 0x40058d has two possible predecessors 0x40058b 4c rex.wr push rbp not shown in the code snippet and 0x40058c push rbp shown in the code snippet .
the former has the prefix rex that is only used in the long mode and hence does not form any hint with other instructions.
furthermore it occludes with 0x40058c .
as a result d d 16after steps i and ii.
however since d which is smaller than d there is no backward propagation.
although d 163is a large value it does not have any control flow predecessor that is it cannot be reached by disassembling at any preceding addresses.
after the iterative process the d values are normalized to compute the posterior probabilities.for example since 0x40058c only occludes with 0x40058b andd d .
p .
andp .
.
the other true positive instructions have higher than .
probabilities.
for instance p similarequal0.
and p p similarequal0.
.p similarequal1.
andp p are negligible.
v. i mplement a tion and ev alua tion we have implemented a prototype on top of bap using ocaml.
our implementation has loc.
to evaluate our technique we use two sets of benchmarks.
the first set contains x86 elf binaries collected from the bap corpora .
the size of these binaries ranges from 100kb to 3mb.
they come with symbolic information from which we derive the ground truth.
we stripped the binaries before applying our disassembler.
the second set is the spec2006int programs.
we used spec for the comparison with super set disassembly .
all the experiments were run on a machine with intel i7 cpu and gb ram.
our evaluation addresses the following research questions rq .
rq1 can our technique disassemble binaries with accuracy completeness and efficiency v a ?
rq2 how does our technique compare with a state of the art super set disassembly v b ?
rq3 how does our technique perform when data and code are interleaved in comparison with linear sweep disassembly v c ?
rq4 how does our technique perform when no function entry information is available e.g.
for indirect functions that are one of the most difficult challenges for traversal disassemblers in ida and bap v d ?
a. rq1 effectiveness and efficiency to answer rq1 we perform four experiments measure false negatives missing true positive instructions and false positives bogus instructions on the binaries measure the disassembling time analyze the contributions of each individual kind of hints study the effect of different probability threshold settings.
fp and fn.
we report the results with the probability threshold ofp .
meaning that we are very conservative and hence keep all the valid instructions with more than .
computed posterior probability.
in this setting our technique does not have any false negatives.
figure shows the correlations between binary size and the fp rate.
observe that most cases cluster at bottom left.
most medium to large binaries have lower than false positives.
the a few largest on the right are even lower than .
the ones with larger fp rates tend to be small binaries which have fewer hints.
the average fp rate is only .
.
this strongly suggests the effectiveness of our technique.
disassembling time.
figure shows the distribution of time.
observe that it has a close to linear relation with the binary size.
the largest ones take about minutes to disassemble.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
fig.
binary size and fp rate fig.
size and processing time the medium ones take minutes.
our algorithm is not as fast as other disassemblers because it is an iterative algorithm based on probabilistic inference.
also we have not optimized implementation.
we argue that since disassembling is one time effort the cost is justifiable.
contributions of different kinds of hints.
figure shows the results for three settings using only the control flow hints only the data flow hints e.g.
def use and register spilling and using all hints.
the xaxis denotes intervals of the fp rate and theyaxis represents the number of binaries that fall into an interval.
for example with only control flow hints about binaries have less than fps with only data flow hints about binaries have less than fps with all hints the number is .
in other words both types of hints are critical for getting the best results.
effects of different probability thresholds.
as mentioned !
fig.
distribution of different kinds of hints fig.
tradeoffs of threshold setting earlier we retain instructions whose computed probability p .figure shows how the fp fn rates on the right yaxis and the percentage of precisely disassembled functions on the left yaxis change with thexaxis .
for example at the starting point on the left is .
i.e.
we keep instructions with p .
fp is about and fn is and .
of the functions in the corpora are precisely disassembled.
with the growth of fp drops fn and the rate of precisely disassembled functions rise.
at the other end on the right is fp is .
whereas fn is .
.
almost of functions are precise.
b. rq2 comparison with superset disassembly linear sweep and traversal disassemblers suffer false negatives which may cause serious problems in binary rewriting.
superset disassembler is a state of the art that does not have false negatives.
however it introduces lots of false positives leading to size blowup in rewriting and unnecessary runtime overhead.
table ii shows the comparison with superset disassembly.
to compare the effects on binary rewriting we integrate our disassembler with their rewriter.
we use the same spec programs in column one .
columns present the fp rate the code size blowup after rewriting and the execution time variation after rewriting respectively.
here we do not add any instructions during rewriting.
columns present the same information for our technique.
observe that we reduce the size blowup from to and improve the execution time by .
note that it is normal that rewritten binaries may execute faster than the original code due to the cache behavior changes caused by rewriting.
note that although our technique still has size inflation it is because the rewriter uses a huge lookup table to translate each address in the code space.
while all the entries are necessary in superset rewriting majority of these entries are not needed in our rewriter and therefore empty.
we plan to remove the empty table entries and replace it with a cost effective hash table in the future.
the fp rate differences columns and indicate the large number of these redundant entries.
c. rq3 handling data and code interleavings a prominent challenge in disassembly is to handle data and code interleavings i.e.
the presence of read only data in between code segments which could cause false negatives authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
superset disassembly probabilistic disassembly program fp size rewritten orig exec.
time rewritten orig fp size rewritten orig exec.
time rewritten orig .perlbench .
.
.
.
.bzip2 .
.
.
.
.gcc .
.
.
.
.mcf .
.
.
.
.gobmk .
.
.
.
.hmmer .
.
.
.
.sjeng .
.
.
.
.libquantum .
.
.
.
.h264ref .
.
.
.
.omnetpp .
.
.
.
.astar .
.
.
.
avg .
.
.
.
t able ii superset disassembly vs probabilistic disassembly fig.
fp rates in the absence of function entries in linear sweep disassembly.
in this experiment we compile specint benchmark by visual studio with different optimization levels to generate a set of binaries.
we extract ground truth from pdb files.
we use both objdump a linear sweep disassembler and our disassembler to disassemble the stripped binaries.
the comparison between the disassembled results and the ground truth shows that objdump misses instructions in total whereas our tool misses none.
the average fp rate of our tool is .
.
.
.
and .
for optimization levels o1 o2 od and ox respectively .
the fp rate is higher than elf binaries as data and code interleavings are more common in pe binaries.
d. rq4 handling missing function entries another prominent challenge especially for traversal disassembly is missing function entries due to indirect calls.
to simulate such challenges we eliminate all the function related hints such as call edges that have the same target part of the hint i .
in other words we only leverage the intra procedural hints to disassemble.
figure presents the results with x axis the fp interval and yaxis the number of binaries.
the average fp rate is .
slightly higher than that of using both inter and intra procedural hints.
fn is still .
this indicates that in the cases where traversal disassemblers such as ida and bap have troubles due to missing function entries our technique has substantial advantages.
vi.
r ela ted work we have discussed existing disassembly techniques in ii.
in this section we discuss other related works.
probabilistic inference has been used in program analysis such as locating software faults inferring explicit information flow and recognizing memory objects .
but to our best knowledge we are the first one to use it in binarydisassembly.
machine learning has been used for binary analysis.
for instance wartell et.
al.
used a statistical compression technique to differentiate code and data.
shingled graph disassembly leverages graph model based learning on a large corpus of binaries to recognize data bytes.
our technique does not require training.
its formalization of using a random variable to represent each address the introduction of hints and the fusion of these hints are unique.
dynamic disassembly e.g.
disassembles during execution.
these approaches impose extra runtime overhead.
in addition they can hardly serve downstream static analysis such as dependence analysis.
disassembly has many applications such as binary hardening deobfuscation reassemble disassembling reverse engineering and exploitation .
our work is particularly suited in rewriting and hardening.
vii.
t hrea ts to validity although we used the corpus from bap and spec in our experiments the benchmarks may not represent all features of real world binaries.
we will test our technique on more binaries.
we focus on binaries generated by compilers.
it is unclear how our technique will perform on obfuscated code although we believe semantic hints still exist in such code.
viii.
c onclusion we propose a novel probabilistic disassembling technique that can properly model the uncertainty in binary analysis.
it computes a probability for each address in the code space indicating the likelihood of the address representing a true positive instruction.
the probability is computed by fusing a set of uncertain features that can reach the address.
the results show that our technique produce no false negatives and as low as .
false positives and it substantially outperforms a state of the art superset disassembly technique.
acknowledgment the authors were supported in part by onr n000141410468 n000141712947 and n000141712995 darp a fa8650 c nsf and afosr fa95501410119 and sandia national lab under award .
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.