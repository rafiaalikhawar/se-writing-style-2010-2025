retracer triaging crashes by reverse execution from partial memory dumps weidong cui microsoft research wdcui microsoft.commarcus peinado microsoft research marcuspe microsoft.comsang kil cha kaist sangkilc kaist.ac.kr y anick fratantonio uc santa barbara yanick cs.ucsb.eduvasileios p .
kemerlis brown university vpk cs.brown.edu abstract many software providers operate crash reporting services to automatically collect crashes from millions of customers and file bug reports.
precisely triaging crashes is necessary and important for software providers because the millions of crashes that may be reported every day are critical in identifying high impact bugs.
however the triaging accuracy of existing systems is limited as they rely only on the syntactic information of the stack trace at the moment of a crash without analyzing program semantics.
in this paper we present retracer the first system to triage software crashes based on program semantics reconstructed from memory dumps.
retracer was designed to meet the requirements of large scale crash reporting services.
retracer performs binarylevel backward taint analysis without a recorded execution trace to understand how functions on the stack contribute to the crash.
the main challenge is that the machine state at an earlier time cannot be recovered completely from a memory dump since most instructions are information destroying.
we have implemented retracer for x86 and x86 native code and compared it with the existing crash triaging tool used by microsoft.
we found that retracer eliminates two thirds of triage errors based on a manual analysis of bugs fixed in microsoft windows and office.
retracer has been deployed as the main crash triaging system on microsoft s crash reporting service.
ccs concepts software and its engineering !software testing and debugging keywords triaging backward taint analysis reverse execution .
introduction many software providers including adobe apple google microsoft mozilla and ubuntu operate permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
copyrights for components of this work owned by others than acm must be honored.
abstracting with credit is permitted.
to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
request permissions from permissions acm.org.
icse may austin tx usa acm.
isbn .
.
.
.
reporting services that automatically collect crashes from millions of customers and file bug reports based on them.
such services are critical for software providers because they allow them to quickly identify bugs with high customer impact to file bugs against the right software developers and to validate their fixes.
recently apple added crash reporting for apps in the ios and mac app stores to help app developers pinpoint top issues experienced by their users .
crash reporting is not only being relied upon by traditional desktop platforms but also by more recent mobile platforms.
one of the most critical tasks in a crash reporting service is triagingsoftware crashes i.e.
grouping crashes that were likely caused by the same bug.
large services may receive millions of crash reports every day.
it is not possible to have developers inspect more than a small fraction of them.
good triaging can cluster together a potentially large number of crash reports belonging to the same software bug and thus reduce the number of crash reports that have to be inspected.
it can also help prioritize the most critical bugs by user impact i.e.
those bugs for which the largest numbers of crash reports arrive and file them against the right software developers.
precise crash triaging is a hard problem.
a single bug may manifest itself in a variety of ways and give rise to large numbers of dissimilar looking crash reports.
this difficulty is exacerbated by the limited information contained in a crash report.
a typical report or core dump or memory dump contains at most the context of the crash thread stack and processor registers and a subset of the machine s memory contents at the moment of the crash.
a variety of constraints ranging from minimizing overhead on customer machines to protecting customer privacy prevent software providers from including richer information in their reports.
in particular there is no information about the program execution leading up to the crash.
the sheer volume faced by large scale crash reporting services adds a further problem because there is usually a time budget for analyzing a crash.
given these challenges crash reporting services have been limited to triaging crashes by using stack traces in a syntactic way.
ubuntu groups crashes by using a crash signature computed based on the top five functions on the stack of the crash thread we will refer to it as the stack in the rest of this paper unless specified otherwise .
microsoft s windows error reporting wer service uses a tool called !analyze bang analyze to group crashes based on a blamed function identified on the stack.
!analyze picks the top function as the blamed function by default but uses a large whitelist of functions and modules and additional heuristics to pick a different function down the stack.
such triaging approaches do not consider the semantics of functions that is how they contribute to the crash.
this significantly limits their triaging accuracy ieee acm 38th ieee international conference on software engineering and the overall effectiveness of crash reporting services.
in this paper we present retracer the first system to triage software crashes based on program semantics reconstructed from a memory dump.
retracer was designed to meet the requirements of large scale crash reporting services.
conceptually retracer mimics developers which usually debug crashes by reversely analyzing the code and the stack to find out how a bad value such as a corrupted pointer was passed.
retracer automates this debugging process by realizing binary level backward taint analysis based only on memory dumps.
backward taint analysis begins with tainted data items e.g.
a corrupted pointer at the end of an execution and analyzes instructions reversely to propagate taint backwards and determine where the tainted data originated at an earlier time.
it is straightforward to perform this analysis on a recorded execution trace .
however recording execution traces is not an option for crash triaging services because it imposes significant tracing overhead during normal execution .
backward taint analysis without an execution trace is challenging.
the machine state at an earlier time cannot be recovered completely since most instructions are information destroying.
for example after executing xor eax eax the original value of register eaxis lost.
with an incomplete machine state backward taint propagation may have to stop prematurely when the address of a tainted memory location cannot be recovered.
retracer is the firstsystem to successfully perform binary level backward taint analysis without an execution trace for crash triaging.
to recover memory addresses it combines concrete reverse execution and static forward analysis to track register values.
given a backward data flow graph inferred from the backward taint analysis it is not obvious how to find the blamed function.
we design an intuitive algorithm to solve this problem.
retracer blames the function where the bad memory address was derived for the first time.
the intuition behind it is that the function that was the first one to obtain a bad value should be the one to ensure the value s correctness.
we have developed retracer into a working system for triaging crashes of x86 and x86 native code and compared it with !analyze the existing crash triaging tool used by wer.
we manually analyzed crashes of bugs fixed in microsoft windows and office .
retracer correctly identified the blamed function for all but bugs while !analyze failed for bugs.
retracer thus reduces the number of triage errors by two thirds.
we evaluated retracer on randomly selected crashes and found that its median average and maximum run time is .
.
and .
seconds.
retracer has been deployed as the main crash triaging system on wer.
a study of the deployment data shows that retracer is being used to analyze about half of the reported x86 and x86 crashes in microsoft s software.
in summary we make the following contributions we have designed a new approach to triaging crashes that performs backward taint analysis without requiring execution traces and identifies blamed functions based on backward data flow graphs section .
we have implemented retracer for triaging crashes of x86 and x86 native code section .
we have compared retracer with !analyze the existing crash triaging tool used by wer on fixed bugs and studied retracer s deployment on wer.
section .
.
overview in this section we present an overview of retracer s design and discuss its design choices.
retracer can analyze all crashes caused by access violations except for those due to stack overflows i.e.
out of stack space unloaded modules and bit flips .
these three exceptions are not a serious limitation because there are effective solutions for each of them.
for stack overflows a straightforward solution is to blame the function that takes up the most stack space.
for unloaded modules a straightforward solution is to blame the function that calls the unloaded module.
a solution for detecting bit flips was proposed in .
crashes that are being analyzed by retracer make up about half of the x86 and x86 crashes in microsoft s software see section .
retracer performs backward taint analysis to triage crashes.
this essentially mimics how developers analyze crashes.
the first question developers often ask is where the corrupted pointer came from.
to answer this question they usually follow the code and the stack backward to find out how the corrupted pointer was passed.
the backward taint analysis in retracer automates this debugging process.
similar to existing triaging solutions retracer focuses on the stack of the crash thread it will blame one of the functions on the stack.
a common question is what happens if a crash involves multiple threads.
the answer has two aspects.
first a large fraction of bugs involves only the crash thread.
for example an empirical study on the eclipse project showed that more than of bugs were fixed in a function on the crash stack.
second the triaging goal of retracer is to group crashes caused by the same bug together which does not require finding the root cause.
for example assume function a in thread writes a bad value to a pointer.
function b in thread reads the bad pointer and dereferences it causing an access violation.
in this case the root cause is function a. but if function b is the only one or one of a few functions that use the bad pointer then grouping crashes based on function b meets the triaging goal.
backward data flow analysis can in principle be performed on source code e.g.
or on binaries.
source code analysis has a number of desirable properties including being unencumbered by the complications of processor instruction sets.
however our only source of information about crashes are crash reports.
the data they contain cpu register values values stored at raw virtual addresses can be consumed directly by binary level analysis.
while one could consider translating this information into a form that is amenable to source level analysis such translation would have to overcome a variety of complications.
registers and memory locations in the crash report would have to be mapped to variables in the source code.
the challenge is that there is no debug information for temporary variables.
for example given varb vara fieldb fieldc there is no debug information indicating in which register or stack location the value of vara fieldb is stored.
furthermore compiler optimizations may make the mapping from machine state to source code even harder.
given these complications we made the design choice to perform our analysis at the binary level.
this choice has the additional benefit of making retracer independent of the original programming language.
this allows us to use a single analysis engine to analyze crashes of both native code e.g.
compiled from c c and jitted code e.g.
compiled from c or javascript .
in this paper we focus on analyzing crashes of native code.
taint analysis assigns meta data taint to data items registers or memory locations .
given a sequence of instructions and an initial set of tainted data items taint analysis will propagate any taint as8211f t p p.f null retracer blames this function!
g p 8g t q int t q f h t 14h int r r crash!!
listing this sample code demonstrates how retracer makes use of backward taint analysis to blame functions.
the crash occurs in function h line .
retracer blames function fbecause it originally sets the bad value to pointer r line .
sociated with the source operands of an instruction to its destination operand.
backward taint analysis begins with tainted data items at the end of an execution and tries to determine where the tainted data originated at an earlier time.
it analyzes instructions reversely to propagate the taint backward.
this technique has been applied to recorded execution traces where the complete sequence of executed instructions and a large amount of state that can be derived from it are available.
retracer is the first system to perform binary level backward taint analysis without execution traces.
the input to retracer is the memory dump of a crash binaries of modules identified in the memory dump and their debug symbols.
on windows a binary is a pe file and its debug symbols are stored in a corresponding pdb file.
retracer does not require the memory dump to be complete.
instead it only requires the stack memory and the cpu context of the crash thread at the moment of crash.
additional memory information in the dump may improve its analysis but is not necessary.
retracer begins with the corrupted pointer that caused the crash and uses backward taint analysis to find the program location s where the bad value originated.
the limited amount of information in a memory dump when compared to an execution trace is a significant complication that retracer must overcome.
the result of the backward taint analysis is a backward data flow graph that shows how the corrupted pointer was derived.
retracer analyzes the graph to identify the blamed function where the corrupted pointer was derived for the first time.
retracer s backward taint analysis uses concrete addresses rather than symbolic expressions to represent memory locations.
the main limitation of using concrete addresses is that taint cannot be propagated if the address of a tainted memory location cannot be recovered.
the main limitation of using symbolic expressions is that taint will be propagated too far if the alias set of the symbolic expression of a tainted memory location is an over approximation.
in retracer we choose concrete addresses over symbolic expressions because we would rather blame a function close to the crash than a totally irrelevant function.
to recover concrete addresses of memory locations retracer combines concrete reverse execution with forward static analysis to track values of registers and memory locations.
a simple example is shown in listing .
in this case the crash occurs in function hat line .
with its backward taint analysis retracer can find out that the bad pointer rwas originally set infunction fat line .
therefore retracer blames function ffor this crash.
.
design in this section we describe the design of retracer in detail.
first we will present the basic scheme of the backward taint analysis.
then we will describe how we use static forward analysis to mitigate the problem of missing register values caused by irreversible instructions.
finally we will present the algorithm for identifying blamed functions from backward data flow graphs.
retracer s analysis is performed at the binary level.
we describe the design in terms of a very simple assembly language.
this allows us to describe retracer without being encumbered by the idiosyncrasies of any concrete processor.
section will describe how we implemented retracer for x86 processors.
a program in our language is a sequence of instructions of the formopcode dest src where opcode specifies the instruction type e.g.
mov orxor and src anddest are the source and destination operands.
an operand is an immediate a constant a processor register numbered r0 r1 or a memory address specified as where c2f0 8gis a constant dis a constant displacement rbandriare arbitrary registers.
we refer to rbas the base register and to rias the index register.
.
backward taint analysis for taint analysis we need to answer two questions how to introduce taint and how to propagate taint.
we maintain taint information on both registers and concrete memory locations.
for memory locations we keep the taint at byte granularity.
for registers we keep the taint at register granularity.
next we first describe taint introduction taint propagation and concrete reverse execution.
we then explain how the backward analysis is performed inside a function and across functions.
.
.
taint introduction the crash report logs both the crash instruction and the access violation type i.e.
read write or execution .
for write violations we examine the destination operand of the crash instruction.
if it is a memory operand we taint its base and index registers because the base register may contain a corrupted pointer value and the index register may contain a corrupted array index.
for read violations we proceed similarly for the source operand.
for execution violations we check the caller to see if it was caused by calling a function pointer.
if so we taint the base and index registers of the memory operand for the function pointer.
.
.
taint propagation starting at the instruction that triggered the crash we move backward instruction by instruction.
section .
.
will explain how we incorporate the program s control flow into this analysis.
for each instruction we propagate taint depending on the semantics of the instruction.
by default we first check if the destination operand is tainted.
if so we first untaint the destination operand and then taint the source operand.
for example the mov instruction copies the value of its source operand to its destination operand and can be handled by the default rule.
section contains examples of x86 instructions that require more complex tainting rules.
when propagating taint to registers we do not require knowing their values.
when propagating taint to memory locations we must know their addresses.
even when the memory address is unknown we always propagate taint to the base and index registers of the memory operand if they exist.
by tainting these registers we can track how the pointer to a corrupted value was derived recursively 822and construct a backward data flow graph of multiple dereference levels.
in section .
we describe how we use such a backward data flow graph to identify a function to blame for the crash.
.
.
concrete reverse execution to compute the address of a memory location we need to know the values of the base and index registers of the memory operand.
in retracer we perform concrete reverse execution to track values of registers and memory locations.
similar to taint tracking we keep values at register granularity for registers and at byte granularity for memory locations.
we can think of an instruction as a function fsuch that dst f src e.g.
mov dst src or such that dst f src dst e.g.
add dst src .
in the former case the concrete reverse execution of the instructions attempts to compute the value of src f dst .
this succeeds if we know the value of dstand if fis reversible i.e.
if f dst is a single value .
in the latter case we attempt to determine the value of dstbefore the instruction.
this is possible if we know the values of srcand of dstafter the instruction and if fis reversible.
in either case if we can obtain the value we update the register or memory location associated with the operand and proceed backwards to the next instruction.
the problem is complicated by the fact that many instructions are irreversible.
examples include xorr0 r0and movr0 .
in these cases we set the register or memory location s value to be unknown.
in cases like movr0 we also cannot propagate taint to the memory location because the value of r0is unknown.
it is worth noting that instructions on stack and frame pointers are mostly reversible.
this allows retracer to track taint on stack memory locations almost completely.
on the other hand the problem of missing register values significantly affects taint propagation to memory locations not controlled by stack or frame pointers.
the next subsection describes how we use static forward analysis to mitigate this problem.
.
.
static forward analysis the key idea of our static forward analysis is to perform a binary analysis of individual functions to identify how register values are derived.
movr0 r1 movr0 in the above two instruction example our forward analysis will find that after executing the first instruction we establish the value relation thatr0has the same value as r1.
when we perform backward analysis on the second instruction we can use this value relation to compute r0 s original value assuming r1 s value is known and propagating taint to .
this lookup is done recursively.
for example if we do not know r1 s value we will check if it can be computed from another register or memory location.
this is similar to traditional use def analysis.
but there is an important difference.
our goal is to find value relations that depend on the current register values.
movr0 r1 movr1 r2 movr0 in the above three instruction example after executing the second instruction we will invalidate all the value relations based on r1 because its value is changed.
we then add a new value relation for r1andr2.
thus we will not use r1to recover r0 s value at the third instruction.
in contrast traditional use def analysis would maintain that r0was defined by r1 in the first instruction .
our static forward analysis is conservative in the sense that we invalidate value relations with all memory locations if the desti nation of a memory write cannot be decided.
to decide the destination of a memory write to the stack we track how the stack pointer is updated.
specifically we use two symbolic expressions to represent the values of registers pointing to the stack.
the first symbolic expression is stack0 which represents the stack pointer s value at the entry of a function.
the second symbolic expression is stack1 which represents the stack pointer s value after stack alignment e.g.
to bytes .
we need the second symbolic expression because the effect of a stack alignment instruction cannot be determined statically.
in our static forward analysis the stack pointer and other registers derived from it are all represented by stack0 or stack1 plus an offset.
another advantage of tracking registers based on stack0 andstack1 is that we can directly tell if a register in a memory operand points to the stack.
if so we do not propagate taint to this register since retracer does not triage stack overflows .
without this incorrect taint could eventually propagate to the stack pointer.
while this problem could be fixed it would complicate our backward taint analysis.
.
.
intra procedural analysis we have presented the basic ideas of backward taint analysis and static forward analysis.
next we describe how they are being done within a function.
given a function we first divide it into basic blocks and construct a control flow graph.
static forward analysis is done only once before we perform backward taint analysis on a function.
our goal is to compute the value relations for all registers before each instruction.
for each block we first initialize the value relations by merging them from all its preceding blocks in the control flow graph.
then we analyze each instruction in the basic block to update the value relations as described in section .
.
.
we repeat this process by iterating through all blocks until the value relations converge.
when we merge value relations from multiple blocks we mark a register s value to be invalid if its value relations have a conflict.
this ensures that the static forward analysis will converge.
in the concrete reverse execution we maintain the current values of registers and memory locations for every instruction.
we start from the crash instruction in its function.
we use the crash report to obtain initial values of registers and memory locations.
then we execute backward from the crash instruction in its block.
for each instruction we update the concrete values of registers and memory locations as described in section .
.
.
we also leverage the value relations inferred from the static forward analysis to recover register values if necessary.
for each block we first merge the values and taint from all its succeeding blocks in the control flow graph.
if the concrete values of a register or memory location do not agree we set its value to unknown.
we repeat this process by iterating through all blocks that are backward reachable from the crash instruction until the values converge.
if the block of the crash instruction is in a loop the analysis above will merge values from multiple iterations.
this may overwrite the original values that led to the crash.
to better capture these important values we create a new block that contains the instructions up to the crash instruction in its block.
we reverse execute this new block and propagate the values to its preceding blocks only once at the beginning.
in the backward taint analysis we maintain the currently tainted registers and memory locations.
we start from the crash instruction in its function.
as discussed in section .
.
we set the initial taint on the base and index registers of one of the operands of the crash instruction.
then we execute backward from the crash instruction in its block.
for each instruction we propagate the taint 823as described in section .
.
.
for each block we first merge the taint from all its succeeding blocks in the control flow graph.
since a register or memory location may be tainted at multiple places we keep its taint as a setof program locations where it was tainted.
when merging the taint of a register or memory location we simply update this set.
we repeat this process by iterating through all blocks that are backward reachable from the crash instruction until the taint converges.
we also apply the same optimization to the block of the crash instruction as in the concrete reverse execution to capture the original taint propagation right before the crash.
after completing the analysis of the crash function we use its values and taint at the function entry as the initial values and taint for its caller on the stack.
then we perform the backward taint analysis on the caller function from the call instruction where the caller calls the crash function.
we apply the optimization described previously to the block of the call instruction to better capture the values and taint right before the function call.
after we are done with this function we continue the analysis to its caller on the stack.
.
.
inter procedural analysis we have just described how we perform backward taint analysis and static forward analysis within a function.
next we present the details on how we handle function calls in these two analyses.
our static forward analysis is an intra procedural analysis.
we do not analyze callee functions in this analysis.
instead given a call instruction we invalidate value relations for volatile registers which can be modified by the callee based on the calling convention as well as memory locations.
we also update the stack pointer if the callee is responsible for cleaning up the stack under the function s calling convention.
our backward taint analysis is inter procedural.
in addition to analyzing the functions along the stack as described previously we apply backward taint analysis to functions called by them.
our inter procedural analysis is by necessity incomplete because we may not be able to find the target functions for all indirect calls during reverse execution.
furthermore the key difference between functions on the crash stack and those that are not is that the stacks of the latter functions are unavailable since they were already popped.
without the stack it is difficult to recover lost register values when they are popped off the stack at the end of typical functions.
this means that we have limited ability to track memory taint in functions that are not on the crash stack.
for these two reasons we perform the backward taint analysis only for callee functions that either have a tainted return value or change the stack pointer e.g.
exception handling code .
before performing the backward taint analysis on a callee function we run our static forward analysis on it.
we begin the analysis of callee functions at their return instruction s .
for call instructions whose targets we do not analyze because we could not find the target or because the target does not meet our conditions we check if its return value and parameters are tainted based on the function s definition.
since in general we have no specification for how a function may change its parameters our parameter check is only an approximation.
specifically we assume a callee function may modify the target data structure pointed to by a parameter and check if any memory covered by the data structure is tainted.
if the return value or a parameter is tainted we untaint it and mark that its value was set by the callee function.
.
blamed function identification in this section we describe how we construct a backward data flow graph based on our backward taint analysis and how we identify a blamed function based on this graph.
figure a sample backward data flow graph.
each node is a three tuple consisting of the frame level the instruction s address and the tainted operand.
assignment edges are solid and dereference edges are dotted.
the graph is simplified to improve readability.
.
.
backward data flow graph a node in our backward data flow graph is created when a register or memory location is tainted.
a node is also created when the taint is stopped at a constant or a call to a callee function.
to differentiate instances of the same registers and memory locations at different instructions or at different invocations of the same instruction we define a node to be a three tuple consisting of the frame level of the function on the stack the instruction s address and either a register or memory location or constant or a symbol representing a call to a callee function.
the crash function has the frame level of zero because it is at the top of the stack.
when going down the stack the frame level increases by one when moving by one frame.
for a callee function that is not on the stack we use the frame level of its caller function on the stack.
a sample backward data flow graph is shown in figure .
our backward data flow graph has two kinds of edges assign824ment anddereference.
an assignment edge is added when we propagate taint from a destination operand to a source operand.
a dereference edge is added when we propagate taint from a memory location to its base and index registers i.e.
the base memory address and the array index .
both assignment and dereference edges are directed.
for assignment edges the direction is from the destination operand to the source operand.
for dereference edges the direction is from the memory location to the base and index registers.
we add a special node called the crash node to the graph.
we also add dereference edges from the crash node to the base and or index registers which received the initial taint.
we define the dereference level of a node to be the minimum number of dereference edges on any path from the crash node to this node.
the crash node s dereference level is .
.
.
blamed function identification our identification algorithm works in two steps.
the first step is to identify nodes that have badvalues.
the second step is to find a blamed function that is the source of these bad values.
for the first step we pick the nodes of the base and index registers at the crash site to be the nodes of bad values by default.
these are the nodes that are connected by dereference edges to the crash node.
there is a single bad value node in figure .
we make two exceptions to this rule.
one is related to array operations.
the other is related to whitelisted modules.
an array operation is usually realized by a compiler as rb c ri d and we look for operands of this type.
if the crash instruction does not have an index register and its base register i.e.
the corrupted pointer was derived from an array operation we pick the nodes of the base and index registers of the array operation to be the nodes of bad values.
the intuition behind this exception is that if a corrupted pointer was obtained from an array access a problem in the array access due to a bad array base or a bad array index is more likely than the array containing incorrect values.
weconditionally whitelist library modules such as ntdll.dll.
on one hand a crash in such a module is usually caused by a bug in its caller outside the module.
on the other hand simply ignoring functions from a whitelisted module is problematic because it prevents developers from detecting bugs in library modules.
such bugs often have high impact due to the wide use of library modules.
missing them may result in a large number of unresolved crashes.
we solve this dilemma with the help of the backward data flow graph.
if all the nodes in the graph are from functions of whitelisted modules the crash is likely due to a bug in a whitelisted module because the caller outside the whitelisted modules did not pass a parameter that is directly related to the crash.
in this case we handle the whitelisted modules as regular modules.
otherwise we pick the nodes that are outside whitelisted modules and have the minimum dereference level to be the nodes of bad values.
they essentially represent the tainted parameters passed to a whitelisted module.
in the second step of our algorithm we identify a blamed function as follows.
we first identify nodes that are reachable from nodes of bad values by following only assignment edges.
all these nodes are at the same dereference level.
then we pick the function that contains such nodes and has the maximum frame level as the blamed function.
the intuition behind this algorithm is that the function that was the first one to obtain a bad value should be the one to ensure the value s correctness.
a bug fix of a bad parameter in a call can either be done in the caller before passing it or in the callee before using it.
for this type of bugs our algorithm always blames the caller.
we made this choice for two reasons.
first the majority of bug fixes we have observed in practice are in the caller.
second the call site in thecaller function reveals more information than the callee function.
a developer can leverage the richer information to decide where the actual fix should be.
by default we use the name of the blamed function and its module name for triaging.
there is an exception.
if our analysis stops at a stack frame for which we do not have symbol information we do not have a function name.
in this case we only use the module name.
this allows retracer to correctly blame third party modules that passed a wrong parameter instead of correct first party code.
in the example shown in figure retracer correctly blames a function in the module mshtml.dll while the crash is in a function in another module gdi32.dll three frames above on the stack.
the bad value was first obtained from .
.
implementation we have implemented retracer for crashes of native x86 and x86 windows binaries.
retracer consumes windows crash dump .dmp files and is implemented as a windbg extension .
the prototype consists of roughly lines of c and c code.
retracer does not support crashes caused by unhandled exceptions and access violations caused by stack overflows unloaded modules and bit flips.
it identifies unhandled exceptions by simply checking the exception code.
it identifies stack overflows by checking if the stack pointer passes the stack limit.
retracer identifies unloaded modules by checking if a stack frame is from an unloaded module.
it relies on an existing implementation of to detect bit flips.
retracer uses windows libraries msdia and msdis for extracting debug information from windows symbol .pdb files and for disassembling machine instructions in windows portable executable pe files.
msdia and msdis are released in microsoft visual studio .
given an offset in a pe file retracer implements its own logic based on msdia and msdis to identify the function containing that offset find the code ranges of the function disassemble them into instructions and construct a control flow graph of basic blocks.
retracer currently relies on the debug information stored in pdb files to reliably disassemble binaries.
there exist good disassemblers such as ida that can disassemble a binary without the debug information based on heuristics.
although perfect disassemly may not be achievable without the debug information retracer can potentially work well with such disassemblers if they can correctly disassemble most binaries.
such integration is for a future exploration.
for each instruction retracer parses it into an intermediate representation that specifies the opcode and the source and destination operands.
retracer can parse allx86 x86 instructions.
this allows retracer to apply its default operations in its analysis to all instructions.
the default operation for the backward taint analysis is to clear the taint of the destination operand and propagate it to the source operand.
the default operation for the concrete reverse execution is to set the value of the destination operand to be unknown.
the default operation in the forward static analysis is to invalidate all the value relations based on the destination operand.
in figure we show the x86 x86 instructions that individually handled by retracer based on their special semantics.
recall that the main goal of retracer is to recover how a corrupted pointer or array index was derived.
this is why retracer only applies the default operations to bit and floating point instructions e.g.
sal and fld .
some instructions like cmov are conditional.
we handle such 825category instructions copy mov lea movsx movzx cmov movs arithmetic add sub mul div inc dec sbb logic and or xor neg stack push pop pusha popa pushf popf exchange xchg cmpxchg control call ret misc cld std setcc figure instructions individually handled by retracer based on their special semantics.
instructions in a way similar to branches.
we assume both conditions are possible analyze the instruction under each condition and merge their results.
in the case of cmov we take the following actions.
for the backward taint analysis we keep the taint of the destination operand and propagate the taint to the source operand if the destination operand is tainted.
for the concrete reverse execution we set the destination operand to be unknown and do not update the source operand.
for the static forward analysis we mark the destination operand s value to be invalid.
for function calls that follow the stdcall calling convention we need to unwind the stack on behalf of the callee if we do not analyze it.
this is critical for correctly keeping track of the stack.
to unwind the stack we need the call site information to know if we need to unwind the stack and if so how much we should adjust the stack pointer.
however pdb files do not contain this information forallindirect calls.
to mitigate this problem we developed the following heuristics to infer the stack size to unwind.
first for an indirect call to a function in a different module we identify the module that implements the function and use that module s pdb file to retrieve the function information.
second for an indirect call to a virtual function we construct the virtual function table based on the debug information in the pdb file and use binary analysis to infer which function in the virtual function table is being called.
third if both approaches fail we analyze the push instructions right before the indirect call to infer the stack size to unwind.
tail call is a common compiler optimization to avoid adding a new stack frame to the call stack.
the simple stack walk based on the frame pointers cannot recognize tail calls correctly.
if tail calls are not recognized retracer s backward analysis will miss the important data flow of parameter passing before the jump to the called subroutine.
in retracer we detect tail calls by checking if the callee function based on the call instruction in the caller is matched with the callee function on the stack.
if not we further check if the first callee function has a jmpinstruction at the end of the function or the first and second callee functions are contiguous even the jmpinstruction is saved in this case .
if so we recognize it as a tail call and analyze the two callee functions together.
in retracer we currently whitelist eleven windows modules and all the functions in the namespace std since they are statically linked into each module.
this is far less than the hundreds of whitelisted modules and functions used by !analyze.
more importantly retracer handles whitelists conditionally as described in section .
.
which allows us to catch rare bugs in the whitelisted modules.
.
ev aluation in this section we evaluate retracer.
we first present the results on its accuracy.
after presenting the results on its performance we report results from its deployment on windows error reporting wer as well as two case studies.
.
accuracy .
.
identified blamed functions to evaluate retracer s accuracy in identifying blamed functions we searched for fixed bugs to use the bug fix as a ground truth.
weexhaustively searched the bug databases of windows windows .
and office and the database of wer to identify allfixed bugs with associated crash reports that meet the following conditions the crash was an access violation in native x86 or x86 code.
the crash was not caused by a stack overflow an unloaded module or a bit flip .
the crash report as well as the pe and pdb files for the module in which the crash occurred are available.
conditions and restrict the search to the domain that our prototype is designed to handle.
condition accounts for the fact that retracer needs the crash report as well as the pe and pdb files to operate.
our search identified bugs.
this is only a small fraction of the total number of bugs in the databses we searched because our search only includes bugs that were filed due to crash reports and that were fixed.
more importantly wer retains crash reports only for a short period of time.
pe and pdb files will also be missing if the crash occurred in a third party module.
thus condition eliminates a very large fraction of the eligible bugs.
figure shows the evaluation results for the bugs.
the figure also lists the number of different modules in which these bugs were fixed.
the large module count shows that these bugs cover a broad set of code bases.
the total module count in figure is less than the sum of the line items due to overlap.
we manually evaluated the correctness of the blamed functions identified by retracer and !analyze for each of the bugs using the following criterion.
an identified blamed function is correct if the bug fix modified the function or another member function of itsclass or its callee function.
we take into account member functions in the same class because they are usually owned by the same developer.
a bug filed on the identified blamed function would have been sent to the same developer who made the bug fix.
we consider callee functions because caller functions reveal more information from which a developer can decide to fix the bug in the caller or callee.
it is worth noting that !analyze handles a wider range of software failures than retracer.
for instance !analyze analyzes program hangs.
our comparison between retracer and !analyze is focused on the kind of crashes supported by retracer.
we list the number of bugs for which the identified blamed functions are either correct by function orclass orcallee or wrong in figure .
retracer is significantly more accurate than !analyze.
it reduces the number of triage errors by two thirds.
we also evaluated the impact of our static forward analysis by running retracer without it.
this configuration made triage errors or more than full retracer.
we examined the bugs for which retracer failed to identify a correct function.
for of them the bug fixes are in functions that are not on the crash stack.
most of these bug fixes corrected errors in the global program logic.
for of the bugs the fixes are in functions below the identified function on the stack i.e.
higher frame levels .
higher dereference levels and loss of taint were the main reasons for retracer s failure in these cases.
for the remaining two bugs the fixes are in functions above the function blamed by retracer.
in both cases a pointer check was added right before the bad pointer dereference.
in figure we show the histogram of the frame levels of functions blamed by !analyze and retracer.
the function at the top of a stack has frame level .
we can see that !analyze blames the crash 826software bugs modules bugs !analyze bugs retracer function class callee wrong function class callee wrong windows user mode windows .
user mode office windows kernel mode windows .
kernel mode total figure accuracy based on fixed bugs in different code bases.
the counts under class do not include bugs that are counted under function orcallee.
15number of bugs frame level!analyze retracer figure histogram of the frame levels of blamed functions.
36number of bugs number of edges figure histogram of the shortest distance from the crash node to the blamed function in the backward data flow graph.
function which is at the top of the stack for out of the bugs we studied.
on the other hand retracer blames a function that is down the stack for bugs.
for one bug !analyze blames the 11th function with frame level on the stack because it whitelists ntdll.dll.
this function is wrong.
in contrast retracer correctly identifies the 8th function on the stack.
for three bugs retracer blames the 7th function on the stack.
it is correct in all three cases.
retracer blames the 16th function on the stack for one bug.
while this is correct in the sense that the corrupted pointer was returned from a call in the 16th function it is not correct by our criterion as the developer chose to add a check right before dereferencing the potentially corrupted value.
.
.
backward taint analysis next we evaluate how well retracer can recover concrete memory addresses in its backward taint analysis.
in figure we show a histogram of the shortest distance from the crash node to the blamed function in the backward data flow graph.
the shortest distance is measured by the minimum number of edges from the crash node to any node in the blamed function.
8number of bugs number of tainted memory operandsfigure histogram of the number of memory operands in the shortest path from the crash node to the blamed function in the backward data flow graph.
operand type count constant global variable dynamic memory location call site figure operand types of the final nodes of taint paths.
we can see that for the majority of the bugs retracer needs to track the taint in less than edges.
we checked the two bugs for which retracer tracks the taint in and edges.
!analyze blames the wrong function for the first bug and the correct function for the second bug after ignoring four functions based on its whitelist.
for both bugs retracer blames the correct function.
interestingly for the second bug retracer reversely traverses of the edges in whitelisted modules to find that the corrupted pointer was passed from a module not in the whitelist.
in figure we show the histogram of the number of memory operands in the shortest path from the crash node to the blamed function in the backward data flow graph.
since the crash node itself is a memory operand the number of memory operands is at least one.
for the majority of the bugs retracer needs to propagate taint over at most four memory operands.
we checked the two bugs for which retracer propagates taint over eight memory operands.
for both of them !analyze is wrong and retracer is correct.
next we examine the taint paths from crash nodes to blamed functions and attempt to analyze why retracer did not extend the paths beyond the blamed functions.
the taint propagation paths may end at a constant a global variable a dynamic memory location or a call site.
the last one means that the tainted value was returned from a callee function that retracer did not analyze.
figure displays counts for the operand types of the final nodes for the bugs.
for the seven bugs with constant operands retracer has found the actual end of the path.
retracer found the concrete memory address for of the bugs associated with dynamic .
.
.
.
50cumulative distribution run time s figure the cumulative distribution of retracer s run times over randomly picked crashes.
memory locations.
for these bugs and the global variable bugs the taint path ended because retracer did not observe any further write operations to the memory location.
this can happen if the memory location was written to by another thread or in a function that completed on the crash thread before the crash and that retracer did not analyze.
the latter is also the explanation for the bugs associated with call sites.
we examined the ten bugs for which retracer stopped the backward taint propagation at a dynamic memory location without finding a concrete memory address.
the values of the registers for computing the memory addresses were missing mainly for one of three reasons branches a register may have different values for different branches self dereference e.g.
mov eax and incomplete memory information a register s value is from a memory location whose value is not stored in the crash report .
.
performance to evaluate the performance of retracer we randomly picked crashes reported to wer in one day.
our experiments were performed on an hp z420 workstation with a quad core cpu at .6ghz 16gb ram and an ocz vector150 480gb ssd.
we show the distribution of run times over the crashes in figure .
the median average and maximum run time is .
seconds .
seconds and .
seconds.
the run time is at most seconds for crashes and at most seconds for crashes.
.
deployment on wer retracer has been deployed on wer as the main crash triaging solution since february .
if retracer can analyze a crash and return a blamed function wer uses it for triaging.
otherwise wer uses the output from !analyze for triaging.
for a sample period of time wer received a total of x86 and x86 crash reports in microsoft s software i.e.
the pe and pdb files for the crash module exist .
crash reports were for an unhandled exception that is not access violation.
retracer returned a blamed function for crash reports.
the rest of them were due to stack overflows unloaded modules or bit flips.
for the crashes for which retracer found a blamed function the function differed from !analyze s function in cases .
next we present two case studies from retracer s deployment.
.
.
srwlock with retracer we found that a top bug in x86 internet explorer is in the function rtlpwakesrwlock in the module ntdll.dll the core user level module in windows.
this bug was ignored previously because ntdll.dll was in the whitelist of !analyze and othermodules on the crash stack were blamed for the crashes.
though ntdll.dll is in retracer s whitelist retracer still blames it because the nodes in the backward data flow graph were all from ntdll.dll.
after some investigation we found that the root cause of the crashes was due to a wide spread malware not the code of srwlock .
when the malware tries to unload itself it modifies the return address on the stack to avoid the return to itself after its module win64cert.dll is unloaded.
when manipulating the stack the malware misaligns the stack by mistake.
this causes the data structure allocated on the stack by srwlock to notbe aligned at the byte boundary.
this may lead to a crash non deterministically because srwlock requires the data structure to be byte aligned.
the crash may happen on any thread that was using srwlock when the malware was trying to unload itself because srwlock uses a linked list to connect its data structures allocated on stacks.
therefore before retracer millions of crashes caused by this malware were wrongly scattered into a large number of groups and were treated as unsolvable.
with retracer we were able to put all the crashes into one group correctly and revealed it as a top bug in x86 internet explorer.
more importantly the focus on srwlock led us to check stack alignment of all threads in the crash process and discover the root cause.
.
.
ntfs with retracer we found a high impact bug in ntfs.sys in windows preview.
the root cause of the bug is that a pointer field used in the crash function may be null and should be checked before being used for dereference.
the driver ntfs.sys is the key file system driver in windows.
this bug affected a large number of windows s beta users.
the bug was previously ignored by !analyze because the ntfs driver is in its whitelist.
instead !analyze scattered the crashes into multiple groups by blaming the third party drivers that called the ntfs driver.
the ntfs driver is also in retracer s whitelist but retracer treated it as a regular module in this case because the backward data flow was contained in the ntfs driver.
this allowed retracer to correctly put all the crashes into a single group under the crash function in ntfs.
this raised the priority of the bug and led to the proper fix.
.
threats to v alidity anexternal threat to validity is that our implementation and evaluation were focused on the windows platform running on x86 and x86 architectures.
however our design was general to operating systems and machine instruction sets.
so we expect retracer to work on other architectures such as arm and other operating systems such as linux with reasonable engineering efforts.
aconstruct validity threat is that we define our blamed function to be correct if it was modified or it was in the same class as a function that was modified in a bug fix.
this definition may not truly reflect the actual correctness.
the ultimate criteria should be determined by a developer that a blamed function is correct if it helps isolate and fix the bug by grouping related crashes based on the blamed function.
however it is hard to find the relevant developers to verify each bug.
therefore we used bug fixes as an objective approximation.
aninternal threat to validity is that we evaluated retracer on 140fixed bugs.
this data set may not be representative.
it is possible that we may have different results on open bugs.
we made this choice mainly because we need the source code fix as the ground truth.
to mitigate this threat we did an exhaustive search to find all bugs that we can experiment with.
.
related work there is a rich collection of literature on software debugging.
in this section we relate retracer s design to previous approaches in software debugging including failure classification fault localization and failure reproduction.
.
automated failure classification the goal of failure classification is to group failure reports of the same bug together.
this is important for large scale crash reporting services including microsoft apple google adobe ubuntu mozilla to prioritize bugs and validate their fixes.
previous work has considered three different types of information that may be included in a failure report memory dumps execution logs and failure descriptions.
we group our discussion of previous work by these categories.
memory dump.
in practice memory dumps are the main source of information used in failure classification.
in contrast to execution logs they do not entail overhead during regular execution.
the main disadvantage of memory dumps lies in the limited information they contain.
this line of work has focused on using the crash stack to group failures because it is easy to collect and useful for debugging .
we have discussed the approaches used in wer and in ubuntu s crash reporting service .
molnar et al.
proposed another kind of stack hash for aggregating crashes.
the main limitation of stack hashes is that a fixed stack level does not work well with all kinds of crashes.
the choice of the crash function of !analyze can be treated as a stack hash of a single stack frame.
wuet al.
proposed to leverage information retrieval techniques to identify blamed functions for a crash.
another line of work proposed to cluster crash reports based on the similarity of crash stacks.
the main limitation of these approaches is that they require a training set and thus are not effective for newly added functions.
furthermore they approximate a function s relevance based on syntactic indirect measures such as a function s depth on the crash stack which may not correctly reflect the function s involvement in a crash.
the main advantage of retracer over previous work is that it triages crashes based on an approximated execution history the backward data flow graph without requiring execution logs.
this enables it to achieve better triaging accuracy by leveraging function semantics as if an execution log were available.
execution log.
this line of work leverages recorded execution logs and or checkpoints to classify failures.
runtime recording provides much more information than memory dumps but also introduces unacceptably high overhead on end user machines during normal operation.
failure description.
this line of work treats failure classification as a text categorization problem.
it relies on the bug description manually written by various users to classify bugs.
however in most realistic end user scenarios such descriptions are not available or not meaningful.
in contrast retracer works directly on memory dumps that are automatically generated.
.
software fault localization software fault localization is a technique that locates one or more possible root causes of a bug.
the main difference between software fault localization and failure classification is that the former focuses on finding the exact root causes while the latter focuses on grouping failures.
there has been a large volume of research on software fault localization .
next we summarize previous work that is most relevant to retracer in terms of backward analysis.postmortem symbolic execution pse uses static backward data flow analysis to reconstruct blamed execution traces from a failure site.
pse was the first to use typestate to analyze program failures.
thin slicing is another backward analysis technique that is related to retracer s design.
unlike traditional slicing that requires all program statements for reaching a seed statement thin slicing consists only of producer statements for the seed i.e.
those statements that help compute and copy a value to the seed.
unlike retracer these approaches do not analyze crash reports but try to find bugs by means of static analysis.
they are not suitable for triaging crashes in a large scale crash reporting service.
.
failure reproduction reproducing failures is important for software debugging.
existing failure reproduction techniques cannot be directly used for failure classification on practical services because of path explosion and their overhead on normal execution.
zamfir et al.
proposed reverse execution synthesis to address the limitation of path explosion faced by execution synthesis .
instead of finding an input reverse execution synthesis aims at constructing intermediate memory state near the failure site that can lead to the failure.
it does not do instruction level reverse execution as retracer.
instead it analyzes basic blocks backwards and uses forward symbolic execution to analyze each basic block.
evaluations of reverse execution synthesis on three small synthetic concurrency bugs are reported in .
it is not clear if it can scale to large programs for crash analysis and triaging.
.
conclusion we have presented retracer the first system that triages crashes based on program semantics extracted from a memory dump.
without requiring an execution trace retracer performs backward taint analysis to find out how a bad value such as a corrupted pointer was derived and use it to identify a blamed function for triaging.
it combines concrete reverse execution with static forward analysis to track concrete values of registers and memory locations for taint propagation.
we have implemented retracer and deployed it on windows error reporting.
our experiments show that retracer reduces triage errors by two thirds and triages crashes in just six seconds on average.
.