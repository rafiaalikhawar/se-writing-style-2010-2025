context aware conversational developer assistants nick c. bradley department of computer science university of british columbia v ancouver canada ncbrad cs.ubc.cathomas fritz department of informatics university of zurich zurich switzerland fritz ifi.uzh.chreid holmes department of computer science university of british columbia v ancouver canada rtholmes cs.ubc.ca abstract building and maintaining modern software systems requires developers to perform a variety of tasks that span various tools and information sources.
the crosscutting nature of these development tasks requires developers to maintain complex mental models and forces them a to manually split their high level tasks into low level commands that are supported by the various tools and b to re establish their current context in each tool.
in this paper we present devy a conversational developer assistant cda that enables developers to focus on their high level development tasks.
devy reduces the number of manual often complex low level commands that developers need to perform freeing them to focus on their high leveltasks.
specifically devy infers high level intent from developer s voice commands and combines this with an automatically generated context model to determine appropriate workflows for invoking lowlevel tool actions where needed devy can also prompt the developer for additional information.
through a mixed methods evaluation with industrial developers we found that devy provided an intuitive interface that was able to support many development tasks while helping developers stay focused within their development environment.
while industrial developers were largely supportive of the automation devy enabled they also provided insights into severalother tasks and workflows cdas could support to enable them to better focus on the important parts of their development tasks.
ccs concepts software and its engineering integrated and visual development environments keywords conversational development assistants natural user interfaces acm reference format nick c. bradley thomas fritz and reid holmes.
.
context aware conversational developer assistants.
in proceedings of icse 40th international conference on software engineering gothenburg sweden may june icse pages.
https .
.
permission to make digital or hard copies of part or all of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
copyrights for third party components of this work must be honored.
for all other uses contact the owner author s .
icse may june gothenburg sweden copyright held by the owner author s .
acm isbn .
.
.
.
https .
.
introduction software development is hard.
empirical studies have shown that developers have to perform a broad variety of development tasks frequently switching applications and contexts .
to successfully complete these higher level tasks developers must performa series of low level actions workflows and maintain mental models that combine data from a variety of disparate sources including the source code of the system version control issue trackers test executions and discussion threads .
while it would benefit developers to automate these workflows it is challenging for three reasons.
first it is hard to determine a prioriall the tasks and workflows developers will need to complete.
second these workflows consist of various low level actions that often span across tool boundaries and require a diverse set of parameters that depend on the current context and developer intent.
third even if there are scripts configured for automating workflows the developerneeds to remember their existence and how to invoke them manually in the current context.
in this paper we explore the potential of conversational agents to support and automate common development workflows.
we designed a conversational developer assistant cda that a provides aconversational interface for developers to specify their high level tasks in natural language b uses an intent service to automatically map high level tasks to low level development actions and c automatically tracks developers actions and relevant state in a context model to automate the workflows and specification of parameters.
the cda allows developers to express their intent conversationally eliminating the need for learning and remembering rigid syntax while promoting discoverability and task flexibility.
the automatic mapping and execution of workflows based on the developer s highlevel intent augmented by the context model reduces developers cognitive effort of breaking down high level intents into low level actions switching context between disparate tools and parameterizing complex workflows.
in order to conduct a meaningful industrial evaluation of the feasibility usability and potential use cases of cdas in software development we implemented devy a prototype voice controlled cda with a pre defined set of automated git and github tasks.devy s primary goal is to help developers maintain their focus on their development tasks enabling them to offload low level actions to an automated assistant.
we performed a mixed methods study a combination of an interview and an experiment with industrial software engineers using devy as a technology probe.
participants had the opportunity to interact with our devy prototype so they could o ffer concrete feedback about alternative applications of cdas to their industrial workflows.
each engineer performed multiple experimental tasks acm ieee 40th international conference on software engineering authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
icse may june gothenburg sweden nick c. bradley thomas fritz and reid holmes table steps for the common share changes workflow.
a manual steps.
a open a web browser for the issue tracker and check the issue number for the current work item.
b open a terminal and run the tests against the changed code to ensure they work e.g.
npm run tests .
c open a terminal and commit the code tagging it with the current work item number e.g.
git commit m see issue .
d pull any external changes from the remote repository e.g.
git pull .
e push the local change to the remote repository e.g.
git push .
f open the commit in the version control system using the github web interface and open a pull request.
g determine a set of reviewers and assign them to the pull request with the github web interface.
b literal cda steps.
cda create a branch issue1223 in the frontend repo.
branch created.
cda run all the tests in the frontend repo.
tests executing.
cda commit with fix in the frontend repo.
commit made.
cda pull the frontend repo.
pulled.
cda push the frontend repo.
pushed.
cda open github for the frontend repo and create a pull request for branch issue1223.
pull request created.
cda open github for the frontend repo and add alice79 as a reviewer for the issue1223 pull request.
reviewer added.
with devy and answered a series of open ended questions.
the evaluation showed that engineers were able to successfully use devy s intent based voice interface and that they saw promise in this type of approach in practice.
this feedback provides evidence of the potential and broad applicability of both conversational developer assistants and developer s interest in increased automation of their day to day workflows.
the primary contributions of this paper are a context model and conversational agent to support automated development assistants.
devy a prototypical voice activated cda that infers developer intent and transforms it into complex workflows.
a mixed methods study demonstrating the value of this approach to industrial developers and providing insight into how cdas can be used and extended in the future.
we describe a concrete scenario in section our approach in section and our experiment in sections and .
related work discussion and conclusions follow in sections .
scenario development projects often use complex processes that involve integrating numerous tools and services.
to perform their high level tasks developers need to break down their intent into a list of atomic actions that are performed as part of a workflow.
while the intentmay be compact and simple workflows often involve interacting with a variety of different tools.
consider a developer whose task is to submit their source code changes for review which requires using version control issue tracking and code review tools.
at a low level the developer needs to commit their changes push them to a remote repository link thechange to the commit in the issue tracker and assign reviewers inthe code review system.
our context model is able to track what project the developer is working on what issue is currently active and who common reviewers for the changed code are in order to enable the developer to just say devy i m done to complete thisfull workflow without having to change context between different tools.
to perform this task manually the developer must follow a workflow similar to that shown in table 1a for simplicity we illustrate this workflow using github .
in this scenario developers use three tools github table 1a a f g the test runner table 1a b and git table 1a c d e .
they also performed four overlapping subtasks running the tests table 1a b linking the commit table 1a a c managing version control table 1a c d e and configuring the code for review table 1a f g .
in addition they relied on several pieces of implicit contextual knowledge the repository being used the current issue how to run the tests the project s commit linking protocol and the project s code review assignment protocol.
providing a voice activated cda for this workflow without any additional abstraction or context model offers little benefit as shownby the transcript in table 1b which has been aligned with the manual steps in table 1a.
grey rows are the developer s speech white rows are the cda s responses.
this implementation has obvious shortcomings it provides no meaningful benefit over just accessing the commands directly as the developer must say all of the commands with the right names in the right order with the right parameters and it would no doubt be faster if they performed the actions directly.
automating this workflow would require knowing the five pieces of the contextual information along with knowledge of how to use the three tools employed by the developer.
fortunately these are all pieces of information that are tracked directly by the context model of our conversational developer assistant devy.
the same workflow can be completed using devy s verbal natural language interface dev devy i m done.
devy y ou have uncommitted changes.
should i commit them?
dev ok. devy ok i m about to open a pull request should i assign alice?
dev y eah.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
context aware conversational developer assistants icse may june gothenburg sweden during this interaction the developer did not need to use any other tools or switch their context away from their source code.
the context model automatically tracked the project being worked on the files being changed and the current issue number.
to show the results of the tests table 1a b devy appends the output of the test execution as a comment to the pull request thread when it is complete.
to identify the list of appropriate reviewers table 1a g devy is able to query a simple service that examines past reviewers for the code involved in the developer s change.
while the developer s intent submitting changes is simple it can only be realized through the indirect process listed above that involves interacting directly with the version control system issue tracker test execution environment and code review system.
each of these systems incurs their own mental and temporal costs and provides opportunities for a team s workflow to be ignored e.g.
if new team members are not aware of all steps or an experienced one skips a step .
ultimately this task involves four context switches between the issue tracker the version control system the pull request interface and the code review system devy abstracts away this minutiae so the developer can focus on their high level intent.
approach devy our conversational developer assistant cda has three main components a conversational user interface a context model and an intent service.
developers express their intent using natural language.
our current prototype uses amazon echo devices and the amazon alexa platform to provide the conversational interface this interface converts developer sentences into short commands.
these commands are passed to our intent service which runs on the developer s computer.
the context model actively and seamlessly updatesin the background on the developer s computer to gather information about their activities.
using the context model and the short commands from the conversational interface the intent service infers a rich representation of the developer s intent.
this intent is then converted to a series of workflow actions that can be performed for the developer.
while the vast majority of input to the intent service is derived from the context model in some instances clarification is sought via the conversational interface from the developer.
devy s architecture is shown in figure .
.
conversational interface devy skill the conversional interface plays a crucial role by allowing developers to express their intents naturally without leaving their development context.
the devy skill has been implemented for the amazon alexa platform apps on this platform are called skills .
to invoke the devy skill a developer must say alexa ask devy to ... they can then complete their phrase with any intent they wish to express to devy.
the amazon microphones will only start recording once they hear the alexa word and the devy skill will only be invoked once devy has been spoken.
the amazon natural language apis translate the developer s conversation into a json object to do this the devy skill tells the amazon alexa platform what kinds of tokens we are interested in.
we have provided the platform with a variety of common ver sion control and related development utterances we identified in conversation layer developer s computer natural language standard development behaviour echoamazon nlpdevy skill context model... workflow actionsintent service figure devy s architecture.
a developer expresses their intention in natural language via the conversational layer.
the intent service translates high level language tokens into low level con crete workflows which can then be automatically executed forthe developer.
dotted edges predominantly communicate in thedirection of the arrow but can have back edges in case clarifica tion is needed from the user.
the literature and from discussions with professional developers many utterances also have synonyms e.g.
for push we also include submit and send .
for a sentence like alexa tell devy to push.
the amazon json object would contain one primary field intent.name with the value pushchanges .
while alexa has been useful for constructing our prototype it imposes two restrictions that hinder our approach the requirement to use two names alexa and devy is cumbersome.
more technically alexa doesn t allow push notifications and requires the client app to respond within ten seconds both of which cause issues for long running commands.
while our current approach uses the amazon apis for voice input using a text based method e.g.
a chatbot would also be feasible for scenarios where voice based input is not appropriate.
.
context model the context aware development model represents the secret sauce that enables advanced voice interactions with minimal explicit developer input.
the differences between manual cda and context aware cda devy approaches are exemplified in section .
the model acts as a knowledge base allowing the majority of the parameters required for performing low level actions to be automatically inferred without developer intervention.
in cases where required information is not present in the context model it can be prompted from the developer using the conversational interface.
the context model for our prototype system is described in table .
the current model supports version control actions and online code hosting actions.
our prototype tool includes concrete bindings for git and github respectively for these two roles but also supports other semantically similar systems such as mercurial and bitbucket.
while other sets of information can be added to the model these were sufficient for our current prototype.
theactivefile model parameter is the most frequently updated aspect of the model.
as the developer moves from file to file authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
icse may june gothenburg sweden nick c. bradley thomas fritz and reid holmes table context model elements.
current focus activefile each local repository path version control typeoriginurlusernamecurrentbranchfilestatus each remote repository openassignedissues collaborators other services blameservicetestservicereviewerassignmentservice in any text editor or ide the full path of the active file is noted and persisted in the activefile field.
the context model is also populated with information about all version control repositories it finds on the developer s machine.
from these local repositories using theoriginurl it is also able to populate information about the developer s online code hosting repositories.
the path component ofactivefile lets the model index into the list of version control repositories to get additional details including the remote onlinerepository if applicable.
our prototype also allows developers toexclude specific repositories and paths from being tracked by the context model and only minimal information about the state of the command is exchanged with amazon to ensure the privacy of the user.
we designed our context model to pull changes from a developer s computer when they interact with devy.
due to the limited size of ourcontext model the pull based architecture is sufficient.
however for more advanced models a push based architecture where the model is initialized at startup and continuously updated by external change events would be preferable to avoid delaying the conversational interface.
extending the model is only required if the developer wishes to support workflows that require new information.
model extensions can be either in terms of pre populated entries push based above or pointers to services that can be populated on demand pull based .
for example the testservice which takes a list of files and returns a list of tests that can run can be pointed to any service that conforms to this api to enable easy customization of test selection algorithms .
if developers wanted more fine grained informationsuch as the current class method or field being investigated they could add a relevant entry to the model and populate it using some kind of navigation monitor for their current text editor or ide.
.
intent service the intent service does the heavy lifting of translating the limited conversational tokens and combining it with the context model to determine the developer s intent.
this intent is then executed for thereadypull stashcommitpush commit?commit?stash?
pull pull pushbehind pull firstlistingissuesgettingowner creatingprlistingusers owner pull request get issue branching branchlist issuescreate pull requestcreate pull request pushget issue committingpushingstashingpullingruntests testreport on prrun testsassign reviewers figure devy s finite state machine for handling workflows.stack push transitions are shown with solid lines while stackpop transitions are shown with dotted lines.
for readability some arrows do not connect with their state.
however all linesare labelled with the action that causes the state transition andcorrespond to the next state.
edges between the fsm and thecontext model are elided for clarity.
developer in the form of workflow actions.
the context model is updated as the actions execute since their outcomes may influence subsequent steps of the workflow.
the conversational layer provides the intent service with extremely simple input commands e.g.
a single verb or noun .
the intent service uses a stack based finite state machine fsm to reason about what the input command means in this context.
while more constrained than plan based models fsms are simple to implement and are sufficient for the purposes of evaluating the potential of cdas.
the complete fsm for our version control intent service is shown in figure .
within the fsm transitions between states define workflow steps while states contain the logic needed to prepare and execute low level actions.
each state is aware of other states that may need to be executed before they can successfully complete e.g.
a pull may be required before a push if the local repository is behindthe remote repository .
we use a stack based fsm because workflow actions frequently depend on each other.
by using a stack we are able to just push commands on the stack and allow the execution to return to the right place in an understandable way.
these potential re turn edges are denoted by the dotted arrows in figure for example stashing can be accessed either directly by the developer from the ready state or as a consequence of a pulling precondition.
the states in the fsm make heavy use of the context model to provide values for their parameters.
study method the long term objective of our research is to enable intent based workflows without software developers having to continuously map their intents to low level commands.
therefore we are investigating authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
context aware conversational developer assistants icse may june gothenburg sweden when and how software developers would use a conversational developer assistant that supports intent based workflows.
specifically we are examining the following research questions rq1 how well can a conversational developer assistant approach support basic development tasks related to version control?
rq2 for which workflows would a conversational developer assistant be useful to developers and why?
to answer our research question we developed the voice enabled cda devy as a prototype see section piloted it with several student developers and then conducted a mixed methods study with professional software developers.
the study was a combination of an experiment with devy and semi structured interviews.
.
participants we recruited professional software developers female male from local software companies of varying size.
participants had an average of years of professional development experience and an average of years1of programming experience.
participants were classified as either junior developers or senior developers based on job title.
all participants had experience using version control systems and all but had experience with git.
participants were recruited through personal contacts and recruiting emails.
to pique interest and foster participation we included a short video2introducing devy and demonstrating it with the use case of determining the owner of an open file.
in addition we incentivized participation with a lottery for two amazon echo dots amongst all participants.
to participate in our study subjects had to be software developers and be familiar with some version control system.
.
procedure the study consisted of three parts a brief semi structured interview to ask about developers tasks and workflows as well as about the possible value of a conversational assistant to support these an experiment with devy comprised of two study tasks and afollow up semi structured interview on the experience and use ofa cda.
we piloted our study and adapted the procedure based onthe insights from our pilots.
we chose this three step procedure to stimulate developers to think about a broad range of workflows and how a cda might or might not help as well as to avoid priming the participants too much and too early with the functionality that ourcurrent devy prototype provided.
the order and sample questionsof the parts of our study are illustrated in table .
the study was conducted in quiet meeting rooms at the participant s industrial site.
interview part one .
to have participants reflect upon their work and workflows we started our first semi structured interview byasking general questions about participants work days and then more specifically about the tasks they are working on as well as the specific steps they perform for these tasks see table for sample questions .
we then introduced amazon s alexa to participants.
to get participants more comfortable with interacting with alexa we had them ask alexa to tell them a joke.
next we asked participants 1missing data for two participants.
order sample questions and tasks from our mixed methods study.
interview part one .
walk me through typical development tasks you work on every day.
.
how do you choose a work item what are the steps to complete it?
.
how do you debug a failed test?
to help you get familiar with alexa ask alexa to tell us a joke.
can you think of any tasks that you would like to have magically completed by either talking to alexa or by typing into a natural language command prompt?
experiment interaction task t1 complete the following tasks launch devy by saying alexa launch devy t1.
using devy try to get the name of the person whom you might contact to get help with making changes to this readme file.
t1.
next make sure you are on branch iss2 and then make a change to this readme file and save those changes .
t1.
finally make those changes available on github.
experiment demonstration task t2 complete the following tasks t2.
say alexa tell devy to list my issues.
to list the first open issue on github.
list the second issue by saying next then stop by saying stop .
notice that the listed issues are for the correct repository.
t2.
say alexa tell devy i want to work on issue .
to have devy prepare your workspace for you by checking out a new branch.
t2.
resolve the issue comment out the debug console.log on line of log.ts by prepending it with .
save the file.
t2.
say alexa tell devy i m done.
to commit your work and open a pull request.
devy will ask if you want to add the new file say y es .
next devy recommends up to reviewers.
y ou choose any you like.
when completed devy will say it created the pull request and open a browser tab showing the pull request.
notice the reviewers you specified have been added.
also notice that tests covering the changes were automatically run and the test results were included in a comment made by devy.
interview part two1 imagine that devy could help you with anything you would want what do you think it could help you with and where would it provide most benefit?
are there any other tasks goals workflows that you think devy could help with maybe not just restricted to your development tasks but other tools you or your team or your colleagues use?
when you think about the interaction you just had with devy what did you like and what do you think could be improved.
did devy do what you expected during your interaction?
what would you change?
do you think that devy adds value?
why or why not?
about the possible tasks and workflows that a conversational assistant such as alexa could help them with in their workplaces.
experiment.
to give participants a more concrete idea of a cda and investigate how well it can support basic workflows we conducted an experiment with devy on two small tasks.
for this experiment we provided participants a laptop that we configured for the study.
we connected the amazon echo dot to the laptop for power and we connected the laptop and the echo dot to the participant s corporate wireless guest network.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
icse may june gothenburg sweden nick c. bradley thomas fritz and reid holmes the tasks were designed to be familiar to participants and included version control testing and working with issues.
the objective for the first task interaction task was to examine how well developers interact with devy to complete a task that was described on a highlevel intent level in natural language.
this first task focused on finding out who the owner of a specific file is and making a change to the file available in the repository on github.
the task description see also table was presented to the participants in a text editor on the laptop.
for the task we setup a repository in github with branches and the file to be changed for the task.
the objective for the second task demonstration task was to have participants use devy for a second case and demonstrate its power and potential of mapping higher level intents to lower level actions e.g.
from telling devy that one is done to devy committing and pushing the changes running the relevant tests automatically and opening the pull request in a web browser tab see table for the task description .
interview part two .
after the experiment we continued our interview.
interacting with devy and seeing its potential might have stimulated participants thinking so we asked them further about which scenarios an assistant such as devy would be well suited and why.
we also asked them about their experience with devyduring the two experimental tasks see table for the questions .
finally we concluded the study by asking participants demographic questions and thanking them for their participation.
.
data collection and analysis the study including the interviews and experiment lasted an average of minutes.
we audio recorded and transcribed the interviews and the experiment and we took written notes during the study.
to analyze the data we use grounded theory methods in particular open coding to identify codes and emerging themes in thetranscripts .
for the open coding two authors coded five randomly selected transcripts independently and then discussed andmerged the identified codes and themes.
in a second step we validated the codes and themes by independently coding two additional randomly selected transcripts.
for the coding of all transcripts we used the rqda r package.
in this paper we present some of the most prominent themes notably those that illustrate the most common use cases the benefits and the shortcomings of cdas.
from the experimental task t1 we derived a count based on the number of times a participant had to speak to devy before they were able to complete a subtask.
we adjusted this count by removing55 attempts out of that failed due to technical issues i.e.
connectivity problems or unexpected application failures of alexa due to a participant speaking too quietly and due to participants trying to invoke devy without using the required utterance of alexa ask tell devy... .
results in this section we present the results for our two research questions that are based on the rich data gathered from the experimental study tasks and the interview.
first we report on the participants inter action and experience with our cda devy.
then we report on the workflows and tasks that a cda might support as well as its benefits and challenges.
1xpehu ri wwhpswv gmxvwhg loh 2zqhu udqfk 1dph 6xeplw kdqjhv figure adjusted number of attempts required to completeeach task of t1 across participants.
.
completing development tasks with devy overall all participants were able to complete all subtasks of t1and t2 successfully with devy.
many participants expressed that devy was neat p17 and cool p18 and some also stated that devy did more than they expected.
for instance p9 explicitly stated exceeded my expectations while p8 surprised at how much it did it actually did more than expected .
for the first experimental task t1 we examined if participants were able to interact with devy and complete specific subtasks that were specified on the intent level rather than on the level of specific and executable git commands.
figure shows the number of devy interactions attempts that it took each participant to complete each of the three subtasks of t1.
the numbers in the figure are based on participants one participant completed t2 before t1 and wasexcluded due to learning effects the values were adjusted by removing attempts that failed due to technical issues see section .
.
across all three subtasks participants used very few attempts to complete the subtasks with an average of two attempts for t1.
and t1.
and a single attempt for t1.
.
subtask t1.
required getting the name of the person who made the most changes to an open file.
this task had the highest variance with one participant taking attempts since he had never used git before.
six participants required some guidance.
this was largely due to devy only being trained with three utterances that all focusedon file ownership and none that focused on the number of changes.
in fact seven participants used an utterance similar to who has made changes p1 p2 p3 p4 p14 p17 p19 on their first attempt.
this shows that either developers require training to learn the accepted utterances or better yet that devy should support a broad set of utterances .
one participant compared it to the specific and rigid syntax of command oriented approaches multiple ways you can tell it to do the same thing it might be advantageous where might forget the exact terminology.
p10 authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
context aware conversational developer assistants icse may june gothenburg sweden in their first interactions with devy most participants out of did not take advantage of its automatic context tracking and instead included the specific file name in their utterances.
this was due to participants thinking of devy as a traditional tool making the assumption would work just like the command line client p19 and they expected to be kind of simple and dumb p7 .
as their sessions progressed participants started to express their intentions more naturally and more vaguely for instance by replacing the file name with this o r this file and participants appreciated the automated context tracking i was just thinking it knows the context about what i m talking about.
that s kind of cool.
p2 subtask t1.
required getting the checked out branch and only took one attempt on average.
all but two participants were ableto complete the subtask without guidance.
thereby participants used various utterances to interact with devy from ones that were close to the git commands alexa tell devy to checkout branch iss2 p15 to less command oriented phrases alexa ask devy to get onto branch iss2 p8 .
the two participants that did not complete this task accidentally skipped it.
the one participant that took attempts paused between starting devy and issuing the command.
subtask t1.
focused on submitting changes to github.
participants took an average of attempts to complete this and had a lower variance than for t1.
.
while participants followed the git command line interaction closely by first committing the changes and then pushing them the other participants took advantage of some of devy s automation and for example directly said alexa tell devy to push to github p15 which resulted in devy committing and pushing the changes.
also for this subtask most partici pants took advantage of devy s context model and omitted some of the specifics from their phrases such as what exactly should be committed or pushed.
the second experimental task t2 was to demonstrate devy s potential.
since all utterances were specified in the task description and no participants had problems following the steps we will not include any further analysis of this task.
observation.
participants were able to use our conversational developer assistant to successfully complete three common development tasks without explicit training with very few attempts and by taking advantage of the automatic context tracking.
.
cda benefits scenarios participants reported a myriad of scenarios and situations in which a cda could enhance their professional workflow.
one common workflow supports multi step and cross application tasks .
several development tasks require a certain process p8 or sequence of steps to be completed that oftentimes require developers to switch between di fferent applications.
an example referred to by several participants was the sharing of changes once i ve committed everything locally i ll push it to github.
i ll go to github in my web browser create a new pull request writeout a description of the change and how i tried to accomplish that once the pull request is created i ll go to slack and post a message on our channel and say there is a new pr p15 participants indicated the cost and effort of these multi step and cross application tasks and how a conversational assistant would reduce the necessary application context switches and allow developers to not lose concentration on the thing i m looking at p6 and stay more focused if you could do some automatically just by talking i d be really happy because i usually have a ton of consoles and switching over really confuses me when you have so many screens open.
just alt tabbing between them consistently even if you do that like out of times successfully at the end of the day you startgetting sloppy and holding those trains of thought in mind would probably be simpler if you weren t changing screens so often p7 today i think i had like emails all related to my pull request and it was all just single comments and i have to link back to the pull request.. and then come back and then delete and then go back and .
so there s a lot of back and forth there.
those are the main things that i feel oh these are taking time and it shouldn t... p3 a cda is also considered particularly beneficial for the automatic mapping of higher level tasks to commands anything that helps you stay in the flow is good so if i can do these higher level tasks with a brief command to some place rather than break them down into a sequence of git commands plus switching to the browser plus yet another thing interspersed with some manual reading it would be a win.
p19 this automatic aggregation of multiple steps is seen as a simplification p7 by participants we have a bot tell me the ip of my deployed aws container rather than a step ssh based process to get it that would be very simple interacting with a voice assistant to get information out of the development ecosystem would be useful.
p18 by abstracting the specific low level actions the automatic mapping reduces the need for memorization of the commands which reduces errors and saves time there are too many command line steps that you can get wrong p18 a lot of the time you know what it is in your head but you still gotta find it.
so that s the stuff this would be really helpful for .
p8 participants mentioned that this can be valuable for infrequent but recurring once in a while p11 tasks since they do often enough to want a better interface but seldom enough that can t remember all the right buttons p10 or they can t remember the crazy flags that you ve gotta remember every single time p8 .
by continuously switching between applications developers have to frequently re establish their working context.
for instance after committing and pushing a code change using a command line tool developers often have to go to the browser open a new tab go to github and find the pull request p15 which can be a a pain in the arse p8 .
in general when switching between applications participants need to do a lot of admin work p14 just to ensure that the applications are in sync p14 .
therefore a major benefit of a cda that automatically tracks context in the background is that itreduces the explicit specification of context.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
icse may june gothenburg sweden nick c. bradley thomas fritz and reid holmes by automatically aggregating multiple steps and keeping track of the current context participants also thought that a cda can support information retrieval especially when there isn t really a good interface p1 for querying and it can speed up the process so looking at the context of what i m and then like highlighting an error text and then copying it and pasting it into google and looking for it.
and then looking down for some of the best matches.
even just devy look this up for me .
p2 right now you need to do two or three commands and know what all the change list numbers are look up all the information .
p20 instead of just automating and aggregating tasks participants suggested that a cda that tracks a developer s steps and context could help to enforce workflows and make sure that nothing is forgotten there are certain flows that often go together .
when i start a day i often need to check the same things not easy to check offthe top of my head so i forget to do that sometimes so that type of thing would be great to do all in one shot.
so where am i what is my status do i need to rebase and if i need to rebase do it p3 in case a developer does not follow the usual workflow the context tracking can come in handy and allow her to go back in history sometimes i just go too far down a path.
and i ve gone through three or four of those branches in my mind and i know i need to go back but because i only want to go part way back that just becomes really di fficult.
so if there was some simple way it could recognize that i m far enough down a path would be amazing if i could then realize that i have screwed up rewind minutes commit and then come back to where i am now.
p21 several participants noted that the additional communication channel offered by devy could be utilized to parallelize tasks that would otherwise require a switch in context and focus.
the archetypal case of this was setting reminders yeah i think of them like if i m coding and i have an idea of another approach i could take but i want to finish the current one i m i ll throw myself in a little slack reminder and then i get a notification in the time i specified.
p21 however this idea is more general and can be particularly useful in cases where the secondary task may take some time to complete where it d be useful is where i m in the middle of one task and i want another being done.
if i m working on one part of it eitherdebugging or editing some code and i want something to go on in the background... like we ve got a build system so maybe i want to start the build for another tool that i will be using soon and i don t want to switch over to start that.
p11 if i have a pull request and i m waiting for it to be approved and i have nothing else to do in the meantime i m going to make lunch.
i could just be cooking and i could just be like has it been approved yet?
and if it has then merge it before someone else gets their stuff in there.
oh that would be great.
p3 seven participants explicitly mentioned that a voice activated assistant provides an alternative to typing that allows tasks be performedwhen the developer s hands are busy p11 or injured p16 p20 and that as intuitive as typing is talking is always going tobe more intuitive p12 .
similarly it provides an alternative to interacting with guis that waste a lot of time just by moving the mouse and looking through menus p7 or to navigate code with context for example by asking where s this called from p10 or what classes are relevant to this concept p13 .
observation.
there are a large number of development tasks in participants workflows that are currently inefficient to perform due to their multi step and cross application nature.
a conversationaldeveloper assistant might be able to support these scenarios by reducing application switches the need for context specification and memorization and by supporting parallelization of tasks.
.
cda challenges participants also raised several concerns about their interaction with devy and conversational developer assistants more generally.
the predominant concern mentioned by several participants was the disruptiveness of the voice interface in open office environments i work in a shared workspace so there would have to be a way for us to have these dialogs that are minimally disruptive to other people.
p19 i imagine a room full of people talking to their computers would be a little chaotic.
p2 further concerns of the voice interaction are its accuracy p11 and that the verbal interaction is slow i didn t really enjoy the verbal interaction because it takes longer .
p2 it feels weird to interrupt .
that s probably more of a social thing it s a voice talking and you don t want to interrupt it and then you have to end up waiting p15 while devy was able to automate several steps participants were concerned about the lack of transparency and that it is important to know which low level actions devy is executing the downside is i have to know exactly what it s behind the scenes which is why i like the command line because it only does exactly what i tell it to do.
p8 this can be mitigated by providing more feedback possibly through channels other than audio i think for me when is changing branches or something i d probably want to see that that has happened in there.
just some indication visually that something has happened.
i mean it told me so i d probably get used to that too.
p6 however there is some disagreement on exactly how much feedback is wanted i liked that there was definitely clear feedback that something is happening even for things that take a bit of time like git pushes.
p1 for a conversational developer assistant completeness the number of intents that the cda is able to understand is important.
participant p14 made the case that the breadth of commands needs to be big enough to make it worthwhile.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
context aware conversational developer assistants icse may june gothenburg sweden this completeness is also related to challenges in understanding the intent of all possible utterances a developer could use it s frustrating to talk to something that doesn t understand you.
regardless of how much more time it takes then another method it would still be more frustrating to argue with a thing that fundamentally doesn t feel like it understands me.
p12 finally since developers use a diverse set of tools in a variety of different ways and everyone s got a little bit of a different workflow p2 it is necessary for cdas to support customization .
for this one could either create macros p2 or have some other means for adapting to each developer s particular workflow so that devy could learn how using it p9 .
this aspect is related to completeness but emphasizes altering existing functionality to suit the individual or team.
observation.
participants raised several concerns for conversational developer assistants related to disruptiveness of voice interactions the need for transparency completeness and customization.
.
summary ultimately industrial developers were able to successfully perform basic software development tasks with our conversational developer assistant providing positive evidence for rq1 .
in terms of rq2 cdas appear to be most useful for simplifying complex workflows that involve multiple applications and multiple steps because of their unnecessary context switches which interfere with developer concentration.
related work we build upon a diverse set of related work in this paper.
to support developers in their tasks researchers have long tracked development context in order to provide more e ffective analyses and to surface relevant information.
the emerging use of bots for software engineering also shows promise for automating some of the tasks improving developers effectiveness and efficiency.
finally natural language interfaces show increasing promise for reducing complexity and performing specific development tasks.
.
development context our model of task context is fundamental to enabling devy to provide a natural interface to complex workflows.
previous work has looked at different kinds of context models.
kersten and murphy provide a rich mechanism for collecting and filtering task contextdata specifically about program elements being examined as developers switch between different tasks .
our context model is more restrictive in that we mainly track the current task context past contexts are not stored.
concurrently our context model includes much more detail about non code aspects relevant to the developer their project and their teammates.
other systems have looked at providing richer contextual information to help developers understand their systems.
for example teamtracks uses the navigation information generated by monitoring how members of a team navigate through code resources to build a common model of related elements .
masterscope provides additional context about code elements as they are selected in an ide .
the similarity between task contexts can also be used tohelp identify related tasks .
each of these systems demonstrates the utility context models can confer to development tasks.
our work extends these prior efforts by providing a context model appropriate for conversational development assistants.
.
bots for se in their visions paper storey and zagalsky propose that bots act as conduits between users and services typically through a conversational ui .
devy clearly sits within this context the natural language interface provides a means for developers to converse with their development environment while the provided workflows provide an effective means for integrating multiple different products within a common interaction mechanism.
further to their botmetaphor devy is able to interpret the conversation to perform much more complex sequences of actions based on relatively little input only checking with the developer if specific clarification is required.
as storey and zagalsky point out there is a clear relationship between bots and advanced scripts.
we firmly believe that the conversational interface combined with the context model moves beyond mere scripting to enable new kinds of interactions and workflows that could not be directly programmed.
one study participant also pointed out that it s nice to have the conversation when there are things that are not specified or you forgot to do that s whenyou want to get into a dialog.
and when you re in the zone then you can just tell it what to do p19 showing further benefit of the conversational ui beyond scripting itself.
acharya et.
al.
also discuss the concept of code drones in which all program artefacts have their own agent that acts semiautonomously to monitor and improve its client artefact .
one key aspect of these drones is that they can be proactive instead of reactive.
while devy is not proactive in that it requires a developer to start a conversation it can proactively perform many actions in the background once a conversation has been started if it determinesthat this appropriate for the given workflow.
devy also takes a differ ent direction than code drones in that rather than attaching drones to code artefacts devy primarily exists to improve the developer s tasks and experience directly rather than the code itself.
.
natural language tools for se a number of tools have been built to provide natural language interfaces specifically for software engineering tasks.
the notion of programming with natural language is not new having first been described by sammet in .
begel further described the diverse ways in which spoken language can beused in software development .
more recently wachtel et.
al.
have investigated using natural language input to relieve the developer of repetitive aspects of coding .
their system provides a mechanism for users to specify algorithms for spreadsheet programs using natural language.
in contrast devy does not try to act as a voice front end for programming it works more at a workflow level integrating different services.
others though have looked at natural language interfaces as a means for simplifying the complex tools used for software devel opment.
one early relevant example of this by manaris et.
al.
investigated using natural language interfaces to improve the abilities of novice users to access unix tools in a more natural way .
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
icse may june gothenburg sweden nick c. bradley thomas fritz and reid holmes nlp2code provides a natural language interface to a specific task finding a relevant code snippet for a task .
nlp2code takes a similar approach to devy in that supports a specific development task but unlike devy does not use a rich context model nor does it involve more complex development workflows.
discussion in this section we discuss threats to the validity of our study and future work suggested by our study participants.
.
threats to validity the goal of our study was to gain insight into the utility of conversational developer assistants in the software engineering domain.
as with any empirical study our results are subject to threats to validity.
internal validity.
we elicited details about participants workflows before they interacted with our prototype to mitigate bias and again after using devy to capture more detail.
despite this it is possible that participants did not describe all ways devy could impact their workflows given more time and a wider variety of sample tasks participants may have described more scenarios.
while we followed standard open coding processes other coders may discern alternative codes from our interview transcripts.
external validity.
though our interviews with industrial developers yielded many insights this was a limited sample pulled from our local metropolitan region.
while participants had differing years of experience and held various roles at six different organizations each with a different set of workflows our findings may not generalize to the wider developer community.
.
future work the feedback we received from industrial developers was broadly positive for our prototype conversational developer assistant.
thankfully our participants had many great suggestions of ways to extend and improve devy to make it even more effective in the future.
the most pressing piece of future work is to implement alternative conversational layers for devy specifically a text based chatbot like interface.
participants mentioned this would be especially beneficial in open plan offices which all participants used .
it also avoids requiring devy specific hardware.
currently devy can be extended through the intent service by wiring up new states in the fsm.
this requires the same amount of work as creating scripts although enables better integration with existing states than simple scripting.
based on participant feedback supporting a more parameterized view of how the states are con nected to form custom workflows seems like a reasonable tradeoff between complete scripting and a fully autonomous agent.
participants were also forthcoming with suggestions for a diverse set offuture workflows that could define the out of box workflows for version control debugging testing collaboration task management and information retrieval.
a large step beyond this would be for the cda to support generic workflows out of the box that can self adapt to better enable userspecific custom workflows without user intervention but based on their own usage patterns.several participants also wished for tighter source code integration .
the intent of this integration was to perform more query based questions of the specific code elements they were looking at without interrupting their current task.
for example the thing people want the most...are abstract syntax trees.
i think it is something that would offer a lot of power if you also had assistive technology layered on top.
p8 using lightweight notes and reminders cdas might enable semantic undos that could be further maintained using the context model to rollback changes to meaningful prior states.
enabling cdas to proactively take action in terms of awareness or in response to external events was widely requested influence the output of what i m working on...by me about getting off my regular pattern that would be the most valuable.
p8 this could also help by preventing mistakes before they happen if i tell it to commit and it should confirm.
p15 next extending support for industrial tools to those commonly used by industrial teams will enable devy to be deployed in a wider variety of practical contexts.
participants were also enthusiastic about the potential for support forenhanced cross application workflows that otherwise cause them to context switch or copy and paste between independent systems.
we will further investigate extending support for these kinds of tasks that force developers to context switch.
finally we built our prototype using the alexa service and our intent service to handle the natural language discourse and map it to workflow actions.
to support further workflows and ease the natural language discourse with developers we will examine whether and how to extend the underlying discourse representation structure.
conclusion in this paper we have explored the potential of conversational agents to support developer workflows.
in particular we have described devy a conversational development assistant that enables developers to invoke complex workflows with only minimal interaction using a natural language conversational interface.
through its contextaware model devy supports rich workflows that can span multiple independent tools this frees the developer to offload these low level actions and enables them to focus on their high level tasks.
using our devy prototype as a technology probe we evaluated our approach in a mixed methods study with industrial software engineers.
these engineers were able to use devy successfully and appreciated that they did not need to specify and memorize multi step workflows and that it reduced context switches.
they additionally identified a concrete set of challenges and future directions that will improve the utility of future cdas.
ultimately the devy prototype demonstrates that developers can successfully launch complex workflows without interrupting their current tasks while reducing developer effort.
we believe that that future conversational developer assistants will have the ability to improve developer s productivity and or effectiveness by allowing them to focus on their core development tasks by offloading meaningful portions of their workflows to such automated agents.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
context aware conversational developer assistants icse may june gothenburg sweden