singapor e management univ ersity singapor e management univ ersity institutional k nowledge at singapor e management univ ersity institutional k nowledge at singapor e management univ ersity resear ch collection school of computing and information systems school of computing and information systems how pr actitioners p erceive the rele vance of softwar e how pr actitioners p erceive the rele vance of softwar e engineering resear ch engineering resear ch david l o singapor e management univ ersity davidlo smu.edu.sg nachiappan n agapp an micr osoft resear ch thomas zimmerm ann micr osoft resear ch follow this and additional works at https ink.libr ary.smu.edu.sg sis r esear ch part of the softwar e engineering commons citation citation david l o n agapp an nachiappan and zimmerm ann thomas.
how pr actitioners p erceive the rele vance of softwar e engineering resear ch.
.
esec fse pr oceedings of the 10th joint meeting on f oundations of softwar e engineering ber gamo italy august september .
.
available at available at https ink.libr ary.smu.edu.sg sis r esear ch this conf erence pr oceeding ar ticle is br ought t o you for fr ee and open access b y the school of computing and information systems at institutional k nowledge at singapor e management univ ersity .
it has been accepted for inclusion in resear ch collection school of computing and information systems b y an authoriz ed administr ator of institutional k nowledge at singapor e management univ ersity .
for mor e information please email cher ylds smu.edu.sg .
how practitioners perceive the relevance of software engineering research david lo school of information systems singapore management university singapore davidlo smu.edu.sg nachiappan nagappan microsoft research redmond wa usa nachin microsoft.com thomas zimmermann microsoft research redmond wa usa tzimmer microsoft.com abstract the number of software engineeri ng research papers over the last few years has grown significantly.
an important question here is how relevant is software engineeri ng research to practitioners in the field?
to address this question we conducted a survey at microsoft where we invited industry prac titioners to rate the relevance of research ideas contained in icse esec fse and fse papers that were published over a five year period.
we received ratings by practitioners w ho labelled ideas as essential worthwhile unimportant or unwise.
the results from the survey suggest that practitioners are positive towards studies done by the software engineering research community of all ratings were essential or worthwhile.
we foun d no correlation between the citation counts and the relevance scores of the papers.
through a qualitative analysis of free text resp onses we identify several reasons why practitioners considered certain research ideas to be unwise.
the survey approach described in this paper is lightweight on average a participant spent only .
minutes to respond to the survey.
at the same time the results can provide useful insight to conference organizers authors a nd participating practitioners.
categories and subject descriptors d. general terms measurement experimentation keywords software engineering research survey industry .
introduction the number of published software engineering papers has been growing over the past few years.
for example the number of papers published in icse almost doubled in the last years from in to papers in .
other conferences in software engineering have observed a similar growth.
does this mean that the rele vance of software engineering has grown as well?
for any community it is important to reflect on successes and failures and to assess if it is moving in the right direction.
the impact project by acm sigsoft investigated if and in what areas software engineering research had an impact on practice.
areas that were identified as part of the pr oject included modern programming languages software configuration management and inspections.
in addition to impact other health aspects of software engineering research have been analyzed such as the health of conferences or novel peer review models .
the question of impact and relevance of software engineering research has been raised by practitioners in industry funding organizations and researchers themselves.
a complicating issue is that the actual impact of some research in practice is often only known after many years.
researchers typically have to speculate what will have the most impact in the future.
in this paper we propose a lightw eight technique to gather rapid feedback on how practitioners perceive the relevance of software engineering research.
the process is as follows as part of a survey present short summaries of research papers which succinctly capture research ideas contained in th em to a panel of practitioners and ask them to rate how important each research idea is for their work in your opinion how important are the following pieces of research?
in the survey participants can rate research as essential worthwhile unimportant unwise or state i don t understand .
to keep the time investment low for practitioners we keep the summaries short shorter than an abstract and limit the number of summaries to be rated by each par ticipant by selecting a given number of summaries randomly for each participant .
to demonstrate the feasibility of the technique we invited engineers in microsoft to mark research papers from five years of the icse esec fse and fse conferences.
we received ratings from practitioners response rate .
su ch data can be used to empirically answer several important que stions to guide software engineering research how do microsoft practitioners view software engineering research as a whole?
what research ideas do microsoft practitioners consider to be most important?
why microsoft practitioners view some research ideas as unwise?
while the answers to these three questions may not generalize beyond the context of microsoft engineers they highlight the potential of what insight we can obtain if as a community we repeat this experiment for other populations e. g. with practitioners from multiple companies.
to be more specific the answer to the first question could serve as a health indicator e.g.
is software engineering research relevant and does it remain relevant.
the answer to the second question could help researchers to prioritize their research efforts .
and the answer to the third question could help researchers avoid pitfalls that can make research less appealing to practitioners.
permission to make digital or hard copi es of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
conference month city state country.
copyright acm ... .
.
published in esec fse proceedings of the 10th joint meeting on foundations of software engineering bergamo italy august september pp.
.
be very upfront the goal of our study is to not rank papers based on relevance.
we do not intend or envision this paper to play a role in ranking papers which we think is contrary to the spirit of fundamental research.
our goal is to provide a new perspective on how to assess the perceived relevanc e of today s software engineering research as viewed by practitioners.
this paper makes the following contributions .
we propose a survey based framework to assess the relevance of software engineering research by involving practitioners.
.
we present findings from a study with engineers at microsoft and point out opportunities on how to improve it with a community wide effort.
.
we identify reasons why practitioners perceive certain highlevel research ideas as unwise .
the remainder of this paper is stru ctured as follows.
first we describe the experimental design of our study in section .
we then describe the results of our study in section .
in section we discuss the implications of our results as well as limitations of our findings.
in section we describe related work.
in section we conclude the paper and describe our future work plans.
.
experimental design to help assess the relevancy of so ftware engineering research we propose a framework which includes the following steps .
select and summarize the papers of interest.
there are many possible ways that papers can be selected for example based on conferences e.g.
icse esec fse fse based on topic e.g.
testing pr ogram analysis or based by year.
the summarization step reduces each paper into a short text summary of limited size.
it is needed so that practitioners can understand the paper well enough to provide feedback without the need to spend much time to understand the technical ities.
rather they should be able to focus on how the research idea can help their day to day activities.
.
select the participants.
it is important to select a representative set of participants for the survey.
practitioners typica lly have different needs depending on their roles developers test ers etc.
and it is important to capture the viewpoints of a diverse set of practitioners.
the number of participants to in vite depends on several factors assuming we have p papers to rate and we want each paper to receive r ratings on average we require p x r ratings.
each participant can rate k papers an d the expected response rate to a survey is s. then we need to invite p x r k x s practitioners to the survey.
.
run the survey and collect feedback.
the following information can be collected as part of a survey demographics the ratings of th e papers as well as additional feedback to follow up on previous responses.
.
analyze the data.
the responses can be analyzed using a set of metrics.
for free form answers qualitative techniques such as open card sort can be used.
several of the above decisions s ummaries instead of abstract a random paper selection for each pa rticipant were made with the goal to keep the time investment low for practitioners.
.
paper selection and summarization we selected full research track papers published in the icse esec fse and fse conferences during a time period of years.
this includes papers from the meetings of esec fse and fse and papers from icse for a total of papers.
we believe that this is a representative sample of software engineering research as icse esec fse and fse are general conferences as opposed to speci alized conferences such as issta for testing to icsme for main tenance and evolution.
we did not include journal publications because they often extend previous conference papers.
as participants would not have th e time to read long abstracts or the entire paper itself we created for each paper a short descriptive summary that contains the key ideas of the paper.
the first author read the abstract of each paper and constructed a summary a few sentences to capture the gist of the paper.
if the abstract was unclear the first author also downloaded and read the paper.
to improve the paper summaries the second author verified the quality of the initial summary created by the first author and provided suggestions for improvement .
after these suggestions were incorporated into an updated summary we piloted the summaries to a small set of practitioners to ge t their feedback as suggested by kitchenham and pfleeger .
we further improved our summaries based on the practitioners feedback.
.
participant selection we selected full time employees of microsoft as participants whose job roles included development test and program management.
for the selection we followed kitchenham and pfleeger s advice on the need to understand whether the respondents had enough knowledge to answer the questions in an appropriate manner.
for this we restricted the people invited to participate in the survey to people in technical roles no sa les or marketing employees .
with p papers r ratings per paper k ratings per participant and response rate of s .
estimated based on response rates from previous surveys we estimated the number of practitioners that we need to invite to be which we rounded up to .
we then randomly picked full time employees from the microsoft employee database who were working in technical roles.
since microsoft has more employees working in development roles the random selection naturally has a higher proportion of participants working in development roles than participants working in the test and pr ogram management roles.
respondents were anonymous but as a thank you for the participants time they could enter their name separate from their survey responses into a raffle of three amazon gift certificates at the end of the survey.
.
feedback elicitation in order to elicit feedback from a wide range of participants in a scalable way we used an online survey.
we designed the survey such that participants required as little effort as possible to complete it e.g.
it was self contained and in cluded all relevant information.
we limited the response types to num erical likert scale and short free form answers as suggested by kitchenham and pfleeger .
the survey we used within microsoft is shown in figure see our technical report for the full survey .
we piloted the survey with a small set of practitioners to get their feedback and improve the survey.
we captured the following information as part of the survey demographics .
answers were required primary work area development test program manager other role individual contributor lead architect manager executive others experience in years decimal value major in computer science boolean value has advanced i.e.
postgraduate degree boolean value collecting some basic information a bout the participants allowed us to break down the results by groups e.g.
developers testers etc.
ratings of research ideas see figure .a .
for each participant we randomly selected papers from the collection of papers.
at least one paper had to be rated to complete the survey.
we then present summaries of those papers to the participants and ask them to rate how important each paper is for their work in your opinion how important are th e following pieces of research?
following the rating categories used by begel and zimmermann participants can label a research idea as essential worthwhile unimportant unwise and i don t understand .
the last category was included to address the diverse background of participants not all participants will understand all technologies.
we chose to ask the question in your opinion how important are the following pieces of research?
to allow practitioners to provide feedback based on their pers onal experience.
we decided not to ask about the willingness to adopt because other research has shown that adoption depends on many diffe rent factors social cultural and educational factors exposure and many more which are often external to the actual research.
a reliable assessment of the adoptability would require a significant time commitment by practitioners.
lastly adoption also heavily depends on the type of research e.g.
tools and techniques are adopted differently than say empirical studies.
follow up rational behind specific ratings see figure .b .
one limitation of ratings is their inability to capture reasons why participants viewed a certain research idea in a particular way.
to capture the reasons behind some ratings we included follow up questions.
more specifically if there was one or more summaries that a participant labeled as unwise we randomly selected one of those summaries and asked participants to elaborate the reasons why they felt that the high level research idea was unwise to pursue.
participants could enter free text to express their thoughts the follow up question was optional.
.
data analysis we compute several statistics to characterize the overall perspectives that practitioners have on software engineering research.
we measure the proportion of ratings that are essential best response essential or important positive f eedback or unwise worst response respectively.
more formally let e w ui and uw denote the number of essential worthwh ile unimportant and unwise ratings received.
e score the percentage of ratings that are essential e score ew score the percentage of ratings that are essential or worthwhile .
ew score u score the percentage of ratings that are unwise u score the statistics can be computed for different groups e.g.
all ratings ratings by certain demographics ra tings for specific conferences or ratings for individual papers.
figure .
some questions in our survey.
on the first page of the survey we asked for demographics and rating of research ideas figure .a .
on the second page we asked a follow up quest ion to gather additional qualitative free text feedback when participants rated a research idea as unwise figure .b to group the reasons why research ideas were selected as unwise we use an open card sort .
card sorting is widely used to create mental models and derive taxonomi es from data.
our card sort consisted of two phases in the preparation phase we create one card for each response to the follow up question to why a research idea is unwise.
in the execution phase cards are sorted into meaningful groups with a descriptive title.
our card sort was open meaning we had no predefined groups instead we let the groups emerge and evolve during the sorting process.
by contrast a closed card sort has predefined groups which is typi cally used when the themes are known in advance.
all three authors jointly sorted the cards.
.
results we invited randomly selected practitioners who were working in a technical role to take the survey participants respond response rate .
among the part icipants .
of them work as developers .
as testers and .
as program manager.
the participants collectively provided ratings.
each paper was rated by to participants since we randomly picked papers to show to survey respondents the number of ratings per papers follows a hype rgeometric distribution .
participants rated at least one paper as unwise of them .
provide their reasons for a randomly selected paper.
of the ratings .
were i don t understand which demonstrates the need of having a way for participants to not provide a rating if they don t have enough knowledge or context to assess a research idea.
to show the potential of practitioner feedback we consider three questions .
how relevant is software engineering research in the practitioner s perspectives?
section .
.
what are highly rated research topics that practitioners deem essential?
section .
.
what are the reasons why practitioners consider certain research topics to be unwise?
section .
.
relevance of software engineering research figure shows the percentage of ratings across the various categories for different demographics all participants all participants that are developers dev participants that are testers test participants that are program managers pm participants with low experience which we define as the with the least experience in years explow participants with medium experience expmed participants with most experience which we define as the with the most experience in years exphigh participants with advanced degree adv participants without a dvanced degree nonadv participants with cs degree cs participants without cs degree noncs participants who are individual contributors ic and participants who are managers mgr .
figure .
percentage of rati ngs of various demographics.
figure .
relevancy scores from icse figure .
relevancy scores from esec fse fse all dev test pm explow expmed exphigh adv nonadv cs noncs ic mgrratings demographicsessential worthwhile unimportant unwise 2014ratingsessential worthwhile unimportant unwise ew score 2013ratingsessential worthwhile unimportant unwise ew scorefrom the figure we can observe th at all demographics give more essential and worthwhile ratings as compared to unimportant or unwise .
the ew score for all participants is and the e score is .
this is an encouraging finding as it shows that practitioners do value work done in the software engineering research community.
however it also shows that there is room for improvement.
we observed several differences between the demographics all statistically significant at a p level of .
testers were more positive about the relevance of software engineering research ew score of e score of than developers or program managers.
as experience increased participants were more critical and considered more studies as unim portant as well as less studies as essential.
for the participants with low experience explow the ew score is an d the e score is in contrast for participants with high experience exphigh the ewscore drops to and the e score to .
participants who were in mana gement roles mgr were more critical than individual contributors ic .
they had an ew score of and e score of .
we did not observe any statistically significant difference in ratings between participants with and wit hout advanced degree.
similarly there was no statistically significant difference between participants with and without cs degree.
in addition to demogr aphics we can break down relevance scores by conference and year.
this can help organizers to ensure that the conference program matters for practitioners.
figures and show the changes in the relevance scores for papers published in icse esec fse and fse in the last years.
over time the ew scores are close to or above which shows that the practitioners who we surveyed found that the majority of software engineering research presented at icse esec fse and fse worthwhile to be pursued.
we also notice that except for a drop for esec fse and fse from ew score of to ew score of the scores for icse esec fse and fse are relatively stable.
this shows the health of the conference series in general is good along the years.
it would be great if their health co uld improve further in the years ahead.
monitoring health of conferences is one example of how the approach in this paper could be us ed.
a conference could poll a representative set of practitioners o r attendees for that matter every year to see if relevance scores of the conference are improving and to ensure that the presented work matters for practitioners.
.
highly rated research ideas table highlights the ten paper summaries rated the highest by the participants in our survey.
the papers are sorted in terms of their e score scores descending followed by ew scores descending followed by u scores ascending .
among the top summaries at least half of the re spondents agreed that the work is essential.
these papers cover a di verse set of topics including improving system perform ance debugging tools adaptive systems testing multithreaded programs and collaboration conflict detection among others.
some readers may be surprised with summary p10 about a new algorithm for bayesian inference over probabilistic programs.
this idea had a high number participants choosing i don t understand which suggests that it may be a specialized topic that is highly relevant to some participants but not to the ones who are unfamiliar with the topic.
table .
highly rated research ideas.
total is the number of people who rated a pa per and did not select i don t understand paper summary total e score ew score u score p1 an approach to help developers identify and resolve conflicts early during collaborative software development before those conflicts become severe and before relevant changes fade away in the developers memories.
.
.
.
p2 technique that clusters call stack traces to he lp performance analysts effectively discover highly impactful performance bugs e.g.
bugs impacting many users with long response delay .
.
.
.
p3 symbolic analysis algorithm for buffer overflow detection that scale to millions of lines of code mloc and can effectively handle loops and complex program structures.
.
.
.
p4 automatic generation of efficient multithread ed random tests that effectively trigger concurrency bugs.
.
.
.
p5 debugging tool that uses objects as key abstr actions to support debugging operations.
instead of setting breakpoints that refer to source code one sets breakpoints with reference to a particular object.
.
.
.
p6 technique to make runtime reconfiguration of distributed systems in response to changing environments and evolving requirements safe and being done in a low disruptive way through the concept of version consistency of distributed transactions.
.
.
.
p7 a new technique that not only det ects leaks but also points developers to the locations where the underlying errors may be fixed.
.
.
.
p8 an approach which automatically prevents database deadlocks which happen when a database is being accessed by multiple database intensive applications which hold locks to different tables.
.
.
.
p9 a technique to engineer applications with a self healing layer for service oriented systems that dynamically reveals and fixes interoperability problems.
.
.
.
p10 a new algorithm for bayesian inference over pr obabilistic programs based on data flow analysis techniques from the program analysis community to deal with loops.
inference refers to the process of calculating the posterior distribution specified by the probabilistic program.
.
.
.
in addition we ranked summaries by the job role developer tester and program manager .
we required a paper summary to be rated by at least five people to be incl uded in a role specific ranking.
we show the list of top papers for each role in our technical report .
we made the following observations developers are highly intere sted on improving system performance detecting collaboration conflicts debugging techniques and detecting concurrency bugs.
testers are highly interested in system monitoring adaptive systems finding linkages betw een bug reports to the fixing commits and lightweight verification tools.
program managers are highly interested in a diverse set of topics including building agile teams team awareness software product line construction bug fi nding and debugging tools among others.
figure shows a boxplot of the distribution of ew scores computed on a per paper basis.
we can observe that practitioners rate most papers favorably.
for the ma jority of papers the ew score is higher than .
.
again we can obse rve that testers are more positive than developers and program managers.
these findings can direct research into areas that are considered to be relevant by practitioners.
.
reasons why certain research is considered unwise in a few cases .
of all votes pra ctitioners rated research ideas as unwise .
in those cases we asked a follow up question for why respondents think the research idea is unwise.
to identify common reservations we took the responses and clustered them into groups.
we performed an open card sort to create the groups.
first we printed each response on a card we then discussed the comments and iteratively sorted them into groups.
our card sort identified eight cate gories that are discussed below.
we ignored cards that contained no rationale doesn t sound wise to me or when participants rejected an idea solely because it was not using microsoft technology i think we should focus on windows first .
a tool is not needed.
this group consists of comments where the practitioner perceived a tool as not useful to their daily work e.g.
the tool cannot help make their ta sks being performed easier or with higher quality.
the respondent deem ed the current state of practice good enough and believed that no additional support is necessary.
the tool that would result would not be something i would use or can imagine anyone else using i don t know how it could be used for daily work i don t believe that a framework will make the design and maintenance of such systems any easier the proposed tool is already available in the form of tfs or sharepoint list an empirical study is not actionable.
the practitioners perceived that the subject analyzed by an empirical study was not relevant and or the findings of the study were deemed to be not actionable or of little benefit.
i wouldn t expect anything actionable or relevant to come out of this study i don t see what s the value to study the difference between these two development methodologies don t see any need for this study since enough is known about common fallacies of this type don t know why there would be any benefit of knowing the answer to the propos ed question etc.
generalizability issue.
practitioners criticized that a study was limited to a few systems and findings found by analyzing these systems might not be applicable to real systems that matter to them.
empirical study on this platfo rms may not be reusable on others case study for a project is al ways less useful than researching around a topic.
lessons learned from one project can be very specific to this project might want to consider bugs in same applications over different platforms developers are not alike a subcategory of generalizability was scalability.
practitioners deemed a technique to be unlikely to cope with the size complexity and variability that characterize systems that practitioners are working on.
i don t see this being used for large scale systems the set of software update that needs testing is not a small number and new software updates happen almost every week.
and it is not the same set of software installed by different users energy consumption characteristic s will vary from device to device and over time from past attempts too many states too many false positives for a complex program there will be too much info and the developer will not be able to understand as the complexity of the bug goes up the solution may or may not go up cost outweighs benefit.
practitioners deemed the cost of using and maintaining a particular tool to be higher than the benefit gained by using the tool.
development cost of this approach will overkill the gain it gives huge time investment for little return i believe the cost of implementing and maintain such a solution would be greater than the cost of developers fixing bugs manually figure .
distribution of ew scores per paper i have experience with similar systems and i ve never seen one where i thought they were of net value questionable assumptions about inputs or conditions.
practitioners deemed a particular input condition crucial towards the success of a research might not hold in practice.
the whole research assumes that there are requirement documents and design documents in software development... which is false in most software projects nowadays such a tool makes it easier for people to focus on test coverage state coverage.
which doesn t really help detect bugs description is often not filled correctly.
hence it is unwise to rely on it analyzing documentation written by humans seems inherently risky.
engineers are not known for writing good documentation and i suspect that will only get worse as we accelerate our deliverables disbelief in a particular technology or methodology.
some practitioners had strong disbelief in a particular technology or methodology on top of which a research work is based.
i don t believe in design patterns force fitting something into a pattern is not wise uml is half dead!
multi threading is to be avoided at all cost i don t think uml is a good tool to use in the development process another solution problem se ems better more important.
practitioners believed that it is better to work on an alternative solution problem that will also solve the need addressed by some research work.
not sure if this is the best or the easiest way to find new uses.
usually i look at forums books tools for that making yet another language isn t really solving anything.
instead give me more functionality within my language and or give me tools to do these types of things better organization of how linux is packaged and distributed would solve this issue without the need of deep analysis and investigations i don t think natural language is that important.
instead helping users find the keywords or t ags is should be the focus proposed solution has side effects.
practitioners perceived that although a research work can solve a problem it might cause other problems as side effects.
it seems that there could be potentially disastrous results if the automation does not fix the issue it detects correctly.
it could induce laziness or uncaring attitude of devel opers e.g.
it doesn t matter if we introduce bugs the repair app will fix them design patterns ... derive their flexibility at the expense of comprehensibility of the interacting parts of a system this approach can introduce false exception bug conditions increasing the cost and time to ma rket while introducing the opportunity to over engineer the code specific techniques to rank devs can lead to devs not working together and lower productivity morale drag and drop solutions have always seemed to me as a quick and easy way to write inefficient code it can easily lead to group think with our competition.
we need to think outside the box not just copy .
discussion we discuss several aspects of this work the relationship between citation counts and perceived rele vance section .
the cost of practitioner feedback section .
how feedback could be integrated into conferences section .
and limitations of this work section .
.
.
citation count vs. perceived relevance we analyzed the relationship between citation counts and the practitioner s perspectives as captured by e ew and u scores.
citation counts are often used in academia as a measure of importance and impact.
for the analysis we used the citation counts from esec fse and icse .
we collected the citation counts from google scholar on aug .
we ignored more recent instances of the conferences because citations need time to be built up.
it would be unfair to compare papers from icse with papers from icse as authors had four more years to read and cite work from icse .
figure shows scatter plots between citations received by papers published in esec fse and icse with their relevance scores computed from practitioners ratings.
from the regression lines we find that the number of citations is not necessarily positively correlated with the three relevance scores.
we also computed spearman correlations.
the correla tion between the citation count a e score a ew score c u score figure .
citation count vs .
relevancy scores esec fse and icse and e score is .
with a p value of .
not significant the correlation between the citation count and ew score is .
with a p value of .
not significant the correlation between the citation count and u score is .
with a p value of .
again not significant .
thus we can conclude that there is no correlation between the citation count and relevance scores of papers.
some papers were cited only a fe w times but practitioners considered the work to be solving a problem that is essential to their needs.
to illustrate such cases table shows the top studies that were favored by practitioners but less so by academia and vice versa.
to get this list we divided the rank of a paper based on citation counts with the rank based on e scores.
papers favored by academia have high citation counts and relatively low e scores and for papers favored by practitioners vice versa.
the absence of a correlation shows that the relevance scores introduced in this paper add extra information to the assessment of research that cannot be captured by citation counts.
.
fast lightweight and inexpensive assessment of perceived relevance we want to stress that the survey based approach presented in this paper is a fast lightweight and inexpensive way to assess perceived relevance of research ideas and to collect feedback.
most participants of our survey responded within the first days.
we closed the survey after days and collected more than ratings.
this process is faster than a typical conference review process that can take months.
surveys with likert scales are a lightweight way to collect feedback.
the survey tool used for this study surveygizmo.com provides optimized views for mobile devices which gives participants the freedom to take the survey at any time they like for example while waiting in line for lunch.
the fatigue and the accessibility scores of the survey were estimated to be low by the survey tool.
the cost of running the survey is also low summarizing the papers and implementing the survey took approximately hours.
the survey participants took .
minutes on average1 to complete the survey for a total of hours .
setting up the analysis framework for the survey took another hours.
the monetary cost were a license of the survey tool enter prise plan month for and amazon gift certificates as incentive to participate in the survey each total .
we would like to emphasize that survey based practitioner feedback as proposed in this paper is different and by no means meant to replace the work of program committees pcs .
in addition to checking papers for relevance pc members must check papers for many other criteria such as originality presentation correctness etc.
this requires reading the full paper a larger time commitment and often travel to a physical pc meeting to discuss papers with other experts in person.
.
towards feedback driven conferences we believe that embedding practiti oner feedback into conferences and maybe even journals can provide great value to the software engineering community.
for example this could work as follows .
the program committee pc reviews the submitted papers and selects the accepted papers.
.
after notification the authors of each paper provide a short summary that is used in the surv ey.
while this is extra work in return the authors would get feedback from practitioners.
an alternative is to ask the pc members to provide a summary and have the authors validate the summary.
.
the summaries are then used to for the survey that is sent to the practitioners.
to increase the representativeness the survey should be sent to multiple companies or even better a representative panel of industry practitioners covering different companies and parts of the software industry who are willing to regularly provide feedback on software engineering research.
we recommend using a similar scale as in our survey.
instead of following only for research ideas that were rated as unwise we suggest to have a feedback option for any research idea.
in addition the survey should pr ovide a way for the practitioner to trace back a research idea to the actual paper after they have completed the survey.
such a survey design has advantages for many stakeholders conference organizers can use the practitioner feedback to assess the perceived relevance of their conference for industry.
they can monitor the scores over time as illustrated in section .
for icse and fse and take st eps to increase the relevance driven by actual data.
the survey can also serve as publicity for table .
top studies favored by academia and practitioners favored by practitioners a new technique that not only detects leaks but also points developers to the locations where the underlying errors may be fixed.
a technique to engineer applications with a self healing layer for service oriented systems that dynamically reveals and fixes interoperability problems.
a technique to monitor if a system fulfils its requirements expressed as probabilistic properties e.g.
perform ance reliability safety and availability requirements at runtime automatically detecting security vu lnerabilities in client side self contained components that interact with one another.
failure to release unneeded system resources results in resource leaks which can lead to performance degradation and system crashes.
the paper presents a new tool that performs static analysis to find code tha t causes resource leaks in java programs.
favored by academia empirical study on whether the bug fixe s recorded in these historical datasets is a fair representation of the full population of bug fixes.
technique to verify the correctness of a family of programs in a software product line against a set of properties.
empirical study of using software de fect data from one project to predict defects in another project.
a graph model based on markov chains which captures bug tossing history to better assign developers to bug reports over years ago the preprocessor cpp was developed to extend the programming language c by lightweight metaprogramming capabilities.
the paper describes a study that analyzes c projects to investigate how cpp preprocessor is em ployed to implement variability.
the survey tool records start and end times of people taking the survey the average time to complete the survey was .
minutes.
when compu ting the average we ignored durations longer than two hours because participants likely got interrupted and comp leted the survey at a later point in time.
the conference and possibly attr act extra attendees if done before the conference.
authors can take the text based feedback to improve their research and make it more relevant to practitioners if they want.
they also get additional visibility for their work.
practitioners get an overview of the latest research which several participants appreciated in our study e.g.
thanks for that summary it is actually interesting by itself or reading through just the titles was a fascinating read some really interesting work going on!
we believe that the approach introduced in this paper is an effective means to help reduce the gap betw een practitioner needs and software engineering research efforts.
lastly feedback does not have to be limited to practitioners.
a conference could survey its attendees to get a sense how happy they were with the paper selection.
.
limitations we acknowledge the following limita tions of findings presented in this paper.
the limitations could ea sily be addressed through a community driven move to feedback driven conferences.
the statistics reported in this work depend on the summaries that were created by ourselves.
we have followed a process to help improve the quality of the summaries th at we generated.
it is possible that some participants had poor understanding of some of the summaries.
to reduce the impact of th is issue we included an i don t understand option in the survey and ignored responses marked as such.
note summaries are needed because it is not practical to ask survey participants to read entire papers and many abstracts are not concise enough.
ideally summaries w ould be created by the authors of the papers and or pc members as outlined in the previous section.
the findings in this paper are based on practitioner feedback from one company.
we acknowledge that perspectives of practitioners in other companies and or industrie s such as automotive aerospace or banking may be different.
as we discussed in section .
ideally the survey would be send to a representative panel of practitioners.
even though the statistics and insi ghts in this paper come only from one company we believe that they are still useful because we surveyed a large number of practitioners more than with diverse backgrounds.
while some projects are larger in size at microsoft most development practices in the company are adapted from the general software engineering comm unity and also used outside microsoft.
microsoft is a large organization that produces a wide range of software and hardware produc ts such as operating systems productivity software web browsers video games search engines game consoles tablets phones a nd many more.
technical employees at microsoft come from many different schools countries with many different cultural backgrounds and we argue that they are thus highly representative of develope rs all over the world .
in this work we focused on assessing research work s perceived relevancy in the eyes of microsoft e ngineers.
perceived relevancy does not mean that a research work will be adopted by practitioners.
in the survey we did not ask developers to answer whether they are willing to adopt a research idea.
asking about adoption assumes the availability of tools which is not always the case e.g.
for empirical papers.
in addition adoption typica lly depends on different factors e.g.
social culture education exposure and many more which often are external to the actual research.
these issues make it difficult for developers to provide objective assessments of the adoptability.
in reality an actual decision whether a research con tribution can be adopted would re quire a significant time commitment by practitioners.
with this work and the question about relevance we wanted to explore li ghtweight feedback techniques.
.
related work related work falls into three areas papers related to the sigsoft impact project retrospective studies and attempt to rank the software engineering community.
acm sigsoft impact project .
our work is partly inspired by the impact project performed by acm sigsoft.
the goal of the project is to assess the importance of software engineering research among the practitioners.
this is done by a series of studies and briefings each involving literature searchers and where possible personal interviews .
several research studies under the impact project has resulted in a numbe r of publications including ryder and soffa investigated how exception handling is used today and traced back current state of the practice to studies in software engineering that helped shape the current state of thepractice .
ryder et al.
analyzed modern programming languages and documented past studies in softwa re engineering and programming languages that have impact on f eatures in these modern programming languages .
estublier et al.
investigated how software configuration management systems have evolved along the years and the impact of research performed in uni versities and industries .
clarke and rosenblum reported th e historical development of runtime assertion checking and described how it has been used in some industries as reported in a number of publications .
emmerich et al.
investigated a number of successful middleware technologies and showed th at findings in the research community have impact on the development of these technologies .
rombach et al.
investigated successes in the practice of software inspections reviews a nd walkthroughs and reported how these have been impacted by software engineering research .
studies under the impact project l ooked at the current state of thepractice and documented how this state of the practice has been affected influenced by previously done research work.
different from these studies in our work we are interested in a complementary approach for evaluating a research work early based on its potential to address developers need when it matures in the future.
rather than starting with the state of practice and looking back in this work we start with the state of research and look forward to see if these studies can potentially impact how developers do things in the future.
both the retrospective impact project and our future looking project are important pieces of information to assess the health of software engineering research.
retrospective studies in software engineering.
lavall e and robillard performed a restrospective study by systematically reviewing existing studies in th e field of software process improvement .
they obtained a se t of research papers to review from representative venues that publish software process improvement studies grouped thes e papers and reported their findings.
other systemat ic review studies for example on fault prediction analyzed papers p ublished in an area over several years to review the current state of the art.
these papers neither spanned research topics nor did they use practitioner input on the relevance of papers.
misirli et al.
shared their experience in deploying software analytics solutions in particular effort estimation and defect prediction solutions in the industry by interviewing practitioners and obtaining their feedback .
other work has focussed on how practitioners perceived specific software enginerring concepts such as coupling bad smells and productivity .
our study investigates a wider range of topics and involves a much larger number of practitioners.
ranking studies.
ranking schemes like the work published in the journal of systems and software ranked individuals and institutions based on their publicati ons in various venues typically several journals .
the ranking di d not account for any views from practitioners.
similarly ren and tayl or provided a ranking of organizations and individuals usi ng papers published in two journals tse and tosem and two conferences icse and fse where all papers were weighted similarly.
ren and taylor summarized the various steps in the ranking process as follows quoted directly from source choose a field select representative publication venues for the field and optionally assign a weight to each venue set the time range for consideration assign a score to each published paper possibly biased by the venue s weight divide the score among multiple authors if the paper has more than one author sum the scores for each scholar and each institution and finally rank the scholars and institutions based on sums of their scores .
our study is significantly differ ent from these ranking studies our goal is not to rank papers but to understand the perceived relevance of the research ideas to the broa der practitioner community to help advance the state of the art in software engineering research.
the ranking of papers discussed above ha s also been subject to criticism .
.
conclusion in this paper we proposed to co llect practitioner feedback through surveys as a fast and lightweight way to get input on what matters for industry.
such data can help conference organizers to assess and improve the relevance of their m eetings authors to improve their research and practitioners to discover the latest software engineering research.
as a proof of concept we performed such a survey at microsoft.
we invited practit ioners working in various technical roles to provide feedback on software engineering research.
from engineers response rate we received in total ratings and comments on res earch ideas.
we used this data to assess the health of software engineering research identify important research topics and common reservations against research results.
our experiment at microsoft suggests that practitioners are generally positive to studies done by the software engineering research community of all ratings were positive but there is room for improvement.
the next step for this work is to replicate our feedback surveys in other companies based in various countries.
this is important to get a broader view on software engineering research not just from one company as relevance of research ideas could vary by domain and geography .
replicating the surveys for open source developers is important too as they often have a different motivation than practitioners in the commercial software industry.
as part of the replication we believe that there is an opportunity and need to assemble a representative panel of practitioners who are willing to provide feedback to software engineering research.
panels are often used in market and user research for surveys.
a requirement for such a panel would be that it includes practitioners from different companies domains countries genders etc.
at representative proportions.
once assemb led the panel could also be used for other research surveys.
lastly we are interested in repeat ing the survey by partnering with conference organizers on an ongoing basis to have industry accessible vetted sentences summar ies of se research papers which can then be rated by a wide range of practitioners to assess the relevance of papers at the conference.
repeating this process regularly will help improve the relevance of software engineering research in the years to come.
.