correct code reviewer recommendation at github for vendasta technologies mohammad masudur rahman?chanchal k. roy?jesse redlxjason a. collinsy university of saskatchewan?
canada vendasta technologiesx canada google inc.y usa masud.rahman chanchal.roy usask.ca?
jredl vendasta.comx jasonco google.comy abstract peer code review locates common coding standard violations and simple logical errors in the early phases of software development and thus reduces overall cost.
unfortunately at github identifying an appropriate code reviewer for a pull request is challenging given that reliable information for reviewer identi cation is often not readily available.
in this paper we propose a code reviewer recommendation tool correct that considers not only the relevant crossproject work experience e.g.
external library experience of a developer but also her experience in certain specialized technologies e.g.
google app engine associated with a pull request for determining her expertise as a potential code reviewer.
we design our tool using client server architecture and then package the solution as a google chrome plug in.
once the developer initiates a new pull request at github our tool automatically analyzes the request mines two relevant histories and then returns a ranked list of appropriate code reviewers for the request within the browser s context.
demo ccs concepts software and its engineering !software notations and tools code review recommendation collaboration in software development !programming teams keywords code reviewer recommendation cross project experience specialized technology experience github pull request .
introduction peer code review is reported to be highly e ective for locating coding standard violations or for performing simple logical veri cations .
it also helps identify source code issues e.g.
vulnerabilities in the early phases of development and thus reduces overall cost for the softwareproject .
github promotes a distributed and collaborative software development through pull requests and code reviews respectively.
in github a developer forks from an existing repository i.e.
project works on certain module of her interest and then submits the changed les to the repository using a pull request .
during pull request submission the developer is expected to choose one or more code reviewers who would review the code carefully before accepting the changes as a contribution.
unfortunately choosing an appropriate reviewer for a pull request is a signi cant challenge and to date github does not provide any support for this.
reliable information on reviewers expertise e.g.
technology skill is often not readily available and it needs to be carefully mined from the codebase.
thus the task of identifying appropriate reviewers is even more challenging and time consuming for novice developers since they are neither familiar well with the codebase nor are aware of the skills of the hundreds of fellow potential reviewers.
such challenge is prevalent not only in open source development but also in the industrial environment where a company e.g.
vendasta technologies strives to maintain code quality in the commercial software development and encourages collaborations among the developers in the form of peer code reviews.
fortunately there have been several studies that recommend code reviewers by analyzing past code review history e.g.
line change history review comments project directory structure and developer collaboration network .
in short the existing studies mostly rely on the work history of a developer i.e.
potential reviewer within a particular project and her collaboration history with other developers for determining her expertise.
however no studies consider the cross project experience or the experience in various specialized technologies of a developer and thus they fall short in handling certain challenges.
first in industry software developers often reuse software components e.g.
libraries that were previously developed by themselves for cost e ective and faster development.
thus their contributions scatter throughout different projects in the code repositories of the organization.
such contributions are a great proxy to their experience.
unfortunately the existing studies on code reviewer recommendation completely ignore such information in expertise determination and their recommendations are merely based on the contribution details within a particular project.
second underlying tools and technologies of software projects are rapidly changing and modern projects often involve different specialized and cutting edge technologies such as mapreduce task queues urlfetch memcache andpipeline .
permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
copyrights for components of this work owned by others than acm must be honored.
abstracting with credit is permitted.
to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
request permissions from permissions acm.org.
ase september singapore singapore c acm.
... .
hence code reviewers for a pull request are expected to have expertise in such technologies.
however neither mining of the revision history of changed les nor mining of the developer collaboration history as the existing studies do might be su cient enough to ensure that.
thus a technique that can analyze both relevant cross project experience and specialized technology experience of a developer for a pull request is likely to overcome the above challenges.
in this paper we present a novel code reviewer recommendation tool correct for pull requests at github.
the tool determines eligibility of a developer as code reviewer for a pull request by analyzing her past work experience with external software libraries and specialized technologies used by the pull request.
reference to the external libraries i.e.
software units external to the working project in the code generally suggests one s working experience with such libraries and we call it cross project experience .
our key idea is if a past pull request uses similar external software libraries or similar specialized technologies to the current pull request then the past request is relevant to the current request and thus its reviewers are also potential candidates for the code review of the current request .
we rst mine the external library and technology information from current pull request using static analysis and then identify the relevant i.e.
similar requests in terms of library and technology similarities from the recently submitted pull request collection.
we then propagate the similarity score for each relevant request to its corresponding code reviewers as a proxy to the shared experience in external libraries and specialized technologies with the current request.
thus each of the candidates accumulates scores for all relevant requests and nally the technique returns a ranked list of code reviewers.
we adopt a client server architecture for our recommendation system where the client module is packaged as a google chrome plug in i.e.
as per the specication of vendasta technologies and the server module is hosted as a web service.
to summarize our proposed tool provides the following features to support vendasta software developers in the selection of appropriate code reviewers a automatically analyzes the technical details of a given pull request and recommends a ranked list of appropriate reviewers for its code review b automatically captures and leverages two expertise dimensions of a developer cross project experience and specialized technology experience for determining her expertise eligibility as a code reviewer c o ers customized recommendations for the developers using open authentication of github d complements the existing pull request submission utility of github through a google chrome plug in and e provides a client server architecture for seamless integration of our code reviewer recommendation service.
while this paper focuses on the tool aspect of our code reviewer recommendation approach we refer the readers to the original paper for further details.
.
modern code review mcr code review refers to a manual assessment of source code that identi es potential defects e.g.
logical errors and quality problems e.g.
coding standard violations in the code .
in recent years code review has been assisted with various tools which is less formal and more popular than the traditional review techniques .
such code review is called figure code review interface at github modern code review mcr .
it is widely adopted both by the commercial organizations e.g.
microsoft and by the open source communities e.g.
android libreo ce .
as an example developer jrans va i.e.
green box fig.
requests a development team cashlab i.e.
red box fig.
for code review during the submission of the pull request .
the request contains two commits associated with ve changed source les.
two developers cgooding va and cberenik va i.e.
blue boxes from the team analyze the commits from the pull request perform the code review and then post their feedback using comments i.e.
orange boxes fig.
.
unfortunately despite assistance from the static analysis tools e ective code review still remains a challenge and identifying appropriate reviewers for the code review is even more challenging.
to date both reviewer selection and code review are performed manually at github.
our tool recommends appropriate developers e.g.
cgoodingva for such code review task e.g.
fig.
at github.
.
correct proposed tool fig.
shows the user interface of correct where we contribute in d browser s tool bar e f recommendation panel and g pull request body panel.
this section discusses di erent technical features provided by our tool.
use cases correct provides automatic recommendation supports for two use cases of pull request based collaborative software development as follows i submission of a new pull request during the submission of a new pull request a user i.e.
developer compares her project branch e.g.
aa fig.
a with the base repository e.g.
develop fig.
a and then looks for potential code reviewers.
our tool analyzes the changed source code les e.g.
fig.
b using static analysis and then suggests a ranked list of appropriate code reviewers in the recommendation panel e.g.
fig.
e .
ii update of an existing pull request correct can also recommend code reviewers for an already submitted pull request for which either no reviewers were assigned or inappropriate reviewers were assigned.
this could be really helpful since inappropriate assignment of code reviewers often costs precious development time .
our tool analyzes the changed source les from the pull request using static analysis and then suggests the code reviewers.
793figure user interface of correct tool automatic mining of relevant artifacts our tool automatically mines both version control history and code review history of a software project for identifying appropriate code reviewers for a given pull request as follows i analysis of changed source code files once either a branch i.e.
rst use case or a pull request i.e.
second use case is selected the tool collects all the changed les from each of their commits from the version control history.
it accesses github api end points for collecting the changed les and uses github api1 a popular github client library for the api access.
since each request or branch might involve a number of source code les the tool only collects the path of the changed les from the api and then applies that information to a local mirror of the github repository for performing further static analysis.
ii analysis of code review history our tool learns to recommend from past code reviews as was also learnt by existing literature .
it thus collects code review details of the most recently submitted pull requests using github api .
since online api access could be time consuming and could hurt the tool s performance we adopt parallelization in the api access.
in particular we apply java multi threading to api access and further analysis for each of the past pull requests from the history.
automatic recommendation of code reviewers correct returns a ranked list of ve code reviewers for any given pull request i.e.
fig.
e .
the size of this recommendation is customizable and the recommendation generally takes seconds on average.
the tool also provides additional insights to assist the user i.e.
developer in the selection of appropriate code reviewers for her pull request.
in particular it provides relative expertise estimates i.e.
estimated by our original technique of the recommended reviewers on the external software libraries and specialized technologies used by the pull request.
our tool also provides several usability features as follows i automated use of recommendation once code reviewers are recommended in the recommendation panel user can copy and paste the reviewers in pull request body panel i.e.
fig.
g by simply clicking copy reviewersbutton i.e.
fig.
f .
then she can submit the request by using create pull request button i.e.
fig.
h .
the tool also provides a refresh button i.e.
fig.
f to help the user start over the reviewer recommendation cycle.
ii caching of recommendation since we use a stateless protocol http caching is a convenient way to improve the performance i.e.
response time of the tool.
our tool uses localstorage a storage feature of google chrome and other html5 capable browsers to store the most recently collected recommendation result.
in the case of repeated requests from the same page i.e.
branch or pull request correct displays previously stored result from localstorage database.
the cache can also be cleared using therefresh button i.e.
fig.
f if the user desires.
personalization optimization correct uses open authentication for github api access and thus it has the potential not only for personalized reviewer recommendation but also for performance optimization as follows i personalized recommendation our tool captures a user s identity from the open authentication step and then customizes the code reviewer recommendation for her.
in particular correct discards self reference i.e.
tool user herself as reviewer from the recommendation list at present.
however other social aspects i.e.
developer collaboration history could also be leveraged for further personalization of the reviewer recommendation.
ii performance optimization github restricts api access of an average registered user to a rate limit of calls per hour.
this restriction is likely to introduce denial of service issue with a tool i.e.
accessing github api if it is con ned to one user account only especially in an industrial context that involves frequent api access.
our tool overcomes that challenge using open authentication where the tool accesses the github api on behalf of the logged in tool user and thus the access rarely exceeds the rate limit.
.
working methodology fig.
shows the schematic diagram of our proposed tool correct.
our tool analyzes both version control history and code review history of a software project and then suggests a ranked list of potential code reviewers for any given pull request.
this section discusses the internal structures and working methodologies of the tool in brief while we refer the readers to the original paper for further details.
working modules correct adopts client server architecture and it has two working modules recommendation engine and client module .
we package the client module as a google chrome plug in and the recommendation engine as a web service.
once the plug in is installed successfully it appears as a user icon at the web browser s tool bar e.g.
fig.
d .
while the plug in captures the technical details of a pull request from the web browser the web service analyzes both the request and other relevant artifacts from the histories and derives code reviewer recommendation for the request.
both modules communicate using rest and ajax on top of http.
historical data collection correct collects past closed pull requests and their corresponding review details from a project for recommending code reviewers for a new pull request.
we rst identify each of those pull requests and extract their corresponding commits.
each of these commits can be identi ed using their sha based id and they generally contain one or more source les that were changed together.
we collect such changed les from each of the selected past pull requests using github api access and local repository analysis.
we repeat the same steps for the new pull request and collect the changed source les to be submitted to the base repository.
we then analyze the code review details of each of the past pull requests and collect their corresponding reviewers using github api access.
in particular we collect both the reviewers who were referred to during the submission e.g.
rwiebe va fig.
g and the reviewers who actually reviewed the pull request e.g.
cgooding va fig.
.
such historical information provides the foundation i.e.
ground truth for the learning and evaluation of our tool.
code review skill reviewer ranking our key idea is the developers who have reviewing experience on similar i.e.
relevant past pull requests are suitable candidates for reviewing the current pull request to be submitted .
once changed source code les and review details from the past pull requests are collected we determine their relevance to the current request based on their shared external libraries e.g.
vapi vform and adopted specialized technologies e.g.
taskqueue ndb in the changed les.
in particular we extract the external library or specialized technology names from each pull request and determine cosine similarity between the current request and each of the past requests.
we then propagate the similarity estimates as a proxy to review expertise to the corresponding code reviewers of the past requests.
thus according to correct the software developers who have more experience on the attached external libraries i.e.
cross project experience and the adopted specialized technologies in the changed les of the current pull request are more appropriate for the code review than the ones having less experience.
example let us consider r3 is a pull request to be submitted and the submitter is looking for one or more code reviewers for the request.
r1andr2are two figure working methodology of correct taken from the original paper past requests similar to r3containing one or more changed les.
from fig.
we see that each of r1andr2includes three libraries adopts three specialized technologies and is reviewed by a di erent set of developers.
similarly r3also includes three external libraries and adopts three specialized technologies in the changed les.
in order to recommend reviewers for r3 correct rst determines the cosine similarity between libraries and technologies of r3and those of r1andr2.
it then applies those scores to the corresponding reviewers of r1andr2.
thus the developers who have the most review experience with similar past requests bubble up in the ranked list for code reviewers.
from fig.
we see that reviewer ascores the top i.e.
.
within all the reviewers according to our ranking algorithm and thus reviewer ais recommended as the code reviewer for the current request r3.
we recommend the top ve code reviewers from such a ranked list for any given pull request.
.
a use case scenario by means of a use case scenario we attempt to explain how our tool correct can help a software developer in choosing appropriate code reviewers for her pull request from within the context of a web browser.
suppose a developer alice has started to collaborate on a new software project sr of vendasta technologies.
she rst forks from the base project which provides her a local copy of the project with complete access for code editing and committing.
she then starts to x a reported bug with id sr where she deletes lines of code and adds lines of code to the local project.
when she is done with the xation it is found that the changes were made to ve source code les bundled into two commits i.e.
fig.
.
then she attempts to submit the changes to the base repository using a pull request.
modern software companies like vendasta often have a mandatory requirement for code review in order to maintain the code quality.
hence she is also concerned about submitting the changes of higher code quality.
during the pull request submission she thus attempts to choose a list of expert developers who would review the changes before accepting them as a contribution to the base project.
to date github does not provide any support for this task and thus she faces several challenges at this stage who is the most appropriate code reviewer for these changes?
how to determine the code review skill of a developer?
and 795figure example use case commits changed source code les to be submitted table libraries technologies of use case external library specialized technology vapi vtax vbcsdk google.appengine.ext vautil vbcsdk.keys ndb search vautil.validators.email google.appengine.api.search can we possibly identify appropriate reviewers from the past code reviews or version control history after all?
she might consider the original authors of the changed les as reviewer candidates.
however this might not be practical since the changed les might be authored by a number of developers over the years who might not be even with the company anymore.
for this use case we note that nine developers authored the changed les.
alice still needs to identify the most appropriate reviewers from those authors by herself with little or no helpful insights about them which is a challenging task.
the task is even more challenging for alice if she is novice and or non familiar with the fellow developers or the code repositories of the company.
now let us assume that alice has installed correct plug in on her chrome web browser and she initiates a pull request for submission.
our tool automatically collects the changed source les from the forked project using github api access.
then it suggests her a ranked list of potential code reviewers by analyzing the most recently submitted similar pull requests i.e.
with code reviews from the version control history of the base project.
in particular the tool automatically extracts external library and specialized technology information e.g.
table from each of the changed source les from each pull request and then leverages the extracted information for code reviewer recommendation section .
besides ranking the tool also provides additional insights on the library and technology related experience of the code reviewers i.e.
table which help alicechoose the right reviewers.
for example the top three reviewers cberenik va cgooding va andywang va in the recommended list have the maximum expected experience and she can con dently choose them as the reviewers for her changes.
thus to overcome the challenges she faced previously our tool automatically suggests her a ranked list of appropriate code reviewers for the pull request to be submitted automatically captures and leverages external library experience as well as specialized technology experience of the developers as suitable proxies to their code review skills and automatically mines both version control history and code review history using github api access for deriving the recommendation.
in short our tool does all the heavy lifting for alice in the background and she can just get the recommendation by simply clicking a button during the pull request submission.
more interestingly correct provides the recommendation within the context of the web browser which helps her maintain the usual work ow i.e.
within github and avoid the unexpected context switching.
in the context of vendasta technologies we chose google chrome as the web browser.
however anytable recommended reviewers for use case reviewer total score library score technology score cberenik va cgooding va ywang va sgryschuk va ksookoche va browser plug in capable of http access can easily consume our recommendation service.
.
evaluation validation one of the most e ective ways for evaluating a code reviewer recommendation system is to consult with actual code reviews and the reviewers assigned for them from a codebase.
we evaluate our technique using the real code review data from vendasta codebase.
in particular we use pull requests and their code review details from vendasta as our oracle in evaluating correct against a number of popular performance metrics.
in order to further validate our ndings and demonstrate its superiority we experiment using pull requests from six open source systems of three di erent programming languages and compare with the state of the art technique.
while we discuss our evaluation and validation in brief as follows the details can be found in the original paper .
evaluation using vendasta systems we evaluate our recommendation technique using a collection of pull requests from subject systems of vendasta technologies and four state of the art performance metrics top k accuracy mean reciprocal rank mean precision and mean recall.
correct provides a top accuracy of .
and a mean reciprocal rank of .
with .
precision and .
recall which are highly promising according to relevant literature .
comparison with the state of the art we validate the performance of our technique by comparing with thongtanunam et al.
the state of the art technique for code reviewer recommendation which outperformed the earlier techniques.
our technique correct provides .
improvement in top accuracy and about improvement in both precision and recall over the state of the art.
three statistical tests mwu cohen s d andglass4 also suggest that such improvements are statistically signi cant.
experiments with open source projects although correct was su ciently evaluated using python systems from vendasta we conduct another experiment with six open source projects from github written in three di erent programming languages java python and ruby to generalize our ndings.
in this case correct recommends with a top accuracy of .
a mean reciprocal rank of .
a mean precision of .
and a mean recall of .
.
comparison demonstrates that our technique outperforms the state of the art with statistically signi cant margin.
further investigations also con rm that correct does not show bias to any programming languages or any project types open source and closed source .
evaluation plan with user study while correct is found promising based on empirical evaluation we plan to evaluate the tool using a user study involving professional developers from vendasta.
the goal of the study is to determine the usability and usefulness of the tool based on actual developers feedback.
in the user study we plan to involve at least developers working on di erent run796ning projects.
each participant will install the tool use it for two controlled tasks i.e.
code reviewer assignment and then will evaluate the recommendation provided by the tool with a prede ned rating scale.
we would then collect the numerical ratings as well as their qualitative feedback to triangulate them with our empirical ndings.
.
related work code reviewer recommendation existing studies recommend code reviewers by analyzing mostly code review or version control history and developer collaboration networks .
balachandran proposes reviewbotthat analyzes line change history of the a ected source lines from a given review request and then identi es code reviewers from that history for the request.
however existing ndings suggest that most of the lines are generally changed only once which makes the line change history really scarce and thus the performance of reviewbot is limited.
thongtanunam et al.
propose revfinder that identi es relevant review requests using file path similarity fps and then recommends reviewers from those requests for a review request at hand.
revfinder also outperformed earlier techniques including reviewbot .
on the other hand correct identi es relevant pull requests using external library similarity and specialized technology similarity which are found to be more e ective than file path similarity for estimating relevance between pull requests and thus for reviewer recommendation.
in our earlier work we show that our technique outperformed revfinder with statistically signi cant performance improvements.
another recent work applies machine learning on past code reviews and combines textual similarity with file path similarity .
thus it su ers from similar issues as of revfinder such as pull request relevance issue and that the learned models could be biased to the subject systems under study.
the remaining technique yu et al.
analyzes past review comments and developer collaboration networks for reviewer recommendation.
while we use library and technology similarity between pull requests for determining relevant past requests they use review comment similarity i.e.
textual similarity for the same purpose.
besides their idea is still not properly evaluated or validated.
expert recommendation kintab et al.
identify expert developers on a code fragment of interest by exploitingcode similarity with other segments.
similar technique is applied by da trindade et al.
where they develop a communication network among documents source code and developers and then recommend dominant developers as experts.
yang studies the developer network using code review relationship and identi es core and peripheral developers using di erent network properties.
there exist several studies in the domain of bug triaging that analyze duplicate bug reports or apply ir based traceability techniques for recommending appropriate developers for bug xation.
several studies are also conducted on expert user recommendation at stack over ow that analyze cross domain contributions or question di culty for expertise estimation.
while these expert recommendation techniques are somewhat similar to ours their context of recommendation is di erent and thus comparing ours with them is not feasible.
of course we introduced two novel and e ective expertise paradigms cross project experience and specialized technology experience which were not exploited by anyof the recommendation systems.
this makes our proposed tool correct signi cantly di erent from all of them.
.
conclusion to summarize we propose a novel tool correct for code reviewer suggestion for pull requests at github for vendasta technologies.
it automatically captures the experience of a developer with the external libraries i.e.
cross project experience and specialized technologies used in a given pull request applies such experiences as proxies to code review skill of the developer and then suggests a ranked list of appropriate code reviewers.
our recommendation technique is substantially evaluated and validated using empirical data.
we package our solution as a web service and a plug in for google chrome browser.
the tool can assist a developer in choosing appropriate code reviewers during the submission of a new pull request or during the update i.e.
reviewer assignment of an existing pull request.
.