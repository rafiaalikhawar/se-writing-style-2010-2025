tell them apart distilling technology differences from crowd scale comparison discussions yi huang australian national university australia u6039034 anu.edu.auchunyang chen faculty of information technology monash university australia chunyang.chen monash.
eduzhenchang xing australian national university australia zhenchang.xing anu.edu.
autian lin yang liu nanyang technological university singapore yangliu ntu.edu.sg abstract developers can use different technologies for many software developmenttasks intheirwork.however whenfacedwith several technologies with comparable functionalities it is not easy for developers to select the most appropriate one as comparisons among technologies are time consuming by trial and error.
instead developerscanresorttoexpertarticles readofficialdocumentsorask questions in q a sites for technology comparison but it is opportunistictoget acomprehensivecomparisonas onlineinformation isoftenfragmentedorcontradictory.toovercometheselimitations we propose the difftechsystem that exploits the crowdsourced discussionsfromstackoverflow andassiststechnologycomparison with an informative summary of different comparison aspects.
we first build a large database of comparable software technologies by miningtagsinstackoverflow andlocatecomparativesentences aboutcomparabletechnologieswithnlpmethods.wefurthermine prominentcomparisonaspectsbyclusteringsimilarcomparative sentences and represent each cluster with its keywords.
the evaluation demonstrates both the accuracy and usefulness of our model and we implement a practical website for public use.
ccs concepts information systems data mining software and its engineering software libraries and repositories keywords differencing similar technology stack overflow nlp acm reference format yi huang chunyang chen zhenchang xing tian lin and yang liu.
.
tellthemapart distillingtechnologydifferencesfromcrowd scalecomparison discussions.
in proceedings of the 33rd acm ieee international conference on automated software engineering ase september montpellier france.
acm new york ny usa 11pages.
co first and corresponding author.
permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation on the first page.
copyrights for components of this work owned by others than acmmustbehonored.abstractingwithcreditispermitted.tocopyotherwise orrepublish topostonserversortoredistributetolists requirespriorspecificpermissionand ora fee.
request permissions from permissions acm.org.
ase september montpellier france association for computing machinery.
acm isbn ... .
figure1 acomparativesentenceinapost thatis not explicitly for technology comparison introduction a diverse set of technologies e.g algorithms programming languages platforms libraries frameworks concepts forsoftwareengineering is available for use by developers and that set continuesgrowing.byadoptingsuitabletechnologies itwillsignificantly accelerate the software development process and also enhance the software quality.
but when developers are looking for propertechnologiesfortheirtasks theyarelikelytofindseveral comparable candidates.
for example they will find bubble sort and quicksort algorithmsforsorting nltkandopennlplibrariesfornlp eclipseandintellijfor developing java applications.
faced with so many candidates developersare expected to have a good understanding of different technologies in order to makea proper choice for their work.
however even for experienceddevelopers it can be difficult to keep pace with the rapid evolutionof technologies.developerscantry eachofthe candidatesin theirworkforthecomparison.butsuchtrial and errorassessment is time consuming and labor extensive.
instead we find that the perceptions of developers about comparable technologies and the choicestheymakeaboutwhichtechnologytouseareverylikely tobeinfluencedbyhowotherdevelopers seeandevaluatethetechnologies.
so developers often turn to the two information sources on the web to learn more about comparable technologies.
first theyreadexperts articlesabouttechnologycomparison like intellij vs. eclipse why idea is better .
second developers can seek answers on q a websites such as stack overflow orquora e.g.
apache opennlp vs nltk .
these expert articles and community answers are indexable by search engines thus enablingdeveloperstofindanswerstotheirtechnologycomparison inquiries.
however therearetwolimitationswithexpertarticlesandcommunity answers.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
ase september montpellier france yi huang chunyang chen zhenchang xing tian lin and yang liu fragmentedview anexpertarticleorcommunityanswerusually focusesonaspecificaspectofsomecomparabletechnologies and developers have to aggregate the fragmented information into a completecomparisonindifferentaspects.forexample tocomparemysqlandpostgresql onearticle contraststheirspeed whileanother comparestheirreliability.onlyafterreading both articles developers can have a relatively comprehensive overview of these two comparable technologies.
diverse opinions one expert article or community answer is basedontheauthor sknowledgeandexperience.however the knowledge and experience of developers vary greatly.
for example onedevelopermayprefer eclipseoverintellijbecauseeclipse fitshisprojectsettingbetter.butthatsettingmaynotbeextensible to other developers.
at the same time some developers may preferintellijovereclipseforotherreasons.suchcontradictory preferences among different opinions may confuse developers.
theabovetwolimitationscreateahighbarrierfordevelopers to effectively gather useful information about technology differences on the web in order to tell apart comparable technologies.
althoughdevelopersmaymanuallyaggregaterelevantinformation by searching and reading many web pages that would be veryopportunistic and time consuming.
to overcome the above limitations wepresentthe difftechsystemthatautomaticallydistills andaggregatesfragmentedandtrustworthytechnologycomparison information from the crowd scale q a discussions in stack overflow andassiststechnologycomparisonwithaninformativesummary of different aspects of comparison information.
oursystemismotivatedbythefactthatawiderangeoftechnologieshavebeendiscussedbymillionsofusersinstackoverflow and users often express their preferences toward a technology and compare one technology with the others in the discussions.
apart frompostsexplicitlyaboutthecomparisonofsometechnologies manycomparativesentences hideinpoststhatareimplicitlyabout technology comparison.
fig.
shows such an example the answer accidentally comparesthesecurityof postandget whilethe question how secure is a http post?
does not explicit ask for thiscomparison.inspiredbysuchphenomenon wethenpropose our system to mine and aggregate the comparative sentences in stack overflow discussions.
as shown in fig.
we consider stack overflow tags as a collection of technology terms and first find comparable technologies by analyzing tag embeddings and categories.
and then our system distillsandclusterscomparativesentencesfromq adiscussions whichhighlylikelycontainsdetailedcomparisonsbetweensome comparable technologies and sometimeseven explains why users like or dislike a particular technology.finally we use word mover distance and community detection to cluster comparative sentences into prominent aspects by which users compare the two technologies and present the mined clusters of comparative sentences for user inspection.
asthereisnogroundtruthfortechnologycomparison wemanuallyvalidatetheperformanceofeachstepofourapproach.the experiment results confirm the the accuracy of comparable technology identification .
and distilling comparative sentences .
from q adiscussions.
by manually buildingthe ground truth weshowthatourclusteringmethod wordmoverdistance figure the overview of our approach and community detection for comparative sentences significantly outperforms the two baselines tf idf with k means and doc2vec withk means .finally wefurtherdemonstratetheusefulnessof oursystemforansweringquestionsoftechnologycomparisonin stack overflow.
the result show that our system can cover the semantics of comparative sentences in five randomly selected technology comparisonquestions and alsoinclude some unique comparisonsfromotheraspectswhicharenotdiscussedinoriginal answers.
our contributions in this work are four fold this is the first work to systematically identify comparable software engineering technologies and distill crowd scale comparative sentences for these technologies.
our method automatically distills and aggregates crowdopinions into different comparison aspects so that developers can understand technology comparison more easily.
ourexperimentsdemonstratetheeffectivenessofourmethod by checking the accuracy and usefulness of each step of our approach.
weimplementourresultsintoapracticaltoolandmakeit public to the community.
developers can benefit from the technology comparison knowledge in our website1.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
tell them apart distilling technology differences from crowd scale comparison... ase september montpellier france word embedding of t t t t a continuous skip gram modelword embedding of b continuous bag of words model figure3 thearchitectureofthetwowordembeddingsmodels.
the continuous skip gram model predicts surrounding wordsgiventhecentralword andthecbowmodelpredicts thecentralwordbasedonthecontextwords.notethedifferences in arrow direction between the two models.
mining similar technology studies show that stack overflow tags identify computer programming technologies that questions and answers revolve around.
they cover a wide range of technologies from algorithms e.g.
binarysearch mergesort programminglanguages e.g.
python java libraries and frameworks e.g.
tensorflow django anddevelopmenttools e.g.
vim git .inthiswork weregardstack overflowtagsasacollectionoftechnologiesthatdeveloperswould like to compare.
we leverage word embedding techniques to infer semanticallyrelatedtags anddevelopnaturallanguagemethodsto analyzeeachtag stagwikitodeterminethecorrespondingtechnology s category e.g.
algorithm library ide .
finally we build a knowledge base of comparable technologies by filtering the same category semantically related tags.
.
learning tag embeddings word embeddings are dense low dimensional vector representationsofwordsthatarebuiltontheassumptionthatwordswithsim ilar meanings tend to be present in similar context.
studies show that word embeddings are able to capture rich semantic and syntactic properties of words for measuring word similarity.
in ourapproach givenacorpusoftagsentences weusewordembedding methods to learn the word representation of each tag using the surrounding context of the tag in the corpus of tag sentences.
there are two kinds of widely used word embedding methods the continuous skip gram model and the continuous bag of words cbow model.
as illustrated in fig.
the objective of the continuous skip gram model is to learn the word representationofeachwordthatisgoodatpredictingtheco occurringwords inthesamesentence fig.
a whilethecbowistheopposite that is predicting the center word by the context words fig.
b .
note that word order within the context window is not important for learning word embeddings.
specifically givenasequenceoftrainingtextstream t1 t2 ... tk theobjectiveofthecontinuousskip grammodelistomaximizethe following average log probability l kk summationdisplay.
k summationdisplay.
n precedesequalj precedesequaln j nequal0logp tk j tk tag wiki matplotlib is a plotting library for python part of speech nnp vbz dt jj nn in nnp figure pos tagging of the definition sentence of the tagmatplotlib while the objective of the cbow model is l kk summationdisplay.
k 1logp tk tk n tk n ... tk n wheretkis the central word tk jis its surrounding word with the distancej andnindicatesthewindowsize.inourapplicationof thewordembedding atagsentenceisatrainingtextstream and each tag is a word.
as tag sentence is short has at most tags weset nas5inourapproachsothatthecontextofonetagisallother tags in the current sentences.
that is the context window contains allothertagsasthesurroundingwordsforagiventag.therefore tagorderdoesnotmatterinthisworkforlearningtagembeddings.
to determine which word embedding model performs better in our comparable technology reasoning task we carry out a comparison experiment and the details are discussed in section .
.
.
.
mining categorical knowledge instackoverflow tagscanbeofdifferentcategories suchasprogramminglanguage library framework tool api algorithm etc.
todetermine thecategoryofatag we resorttothetagdefinition inthetagwikiofthetag.thetagwikiofatagiscollaboratively edited by the stack overflow community.
although there are no strictformattingrulesinstackoverflow thetagwikidescription usually starts with a short sentence to define the tag.
for example the tagwiki of the tag matplotlib starts with the sentence matplotlib is a plotting library for python .
typically the first noun justafterthe beverbdefinesthecategoryofthetag.forexample fromthetagdefinitionof matplotlib wecanlearnthatthecategory ofmatplotlib islibrary.
based on the above observation of tag definitions we use the nlp methods to extract such noun from the tag definition sentenceasthecategoryofatag.giventhetagwikiofataginstack overflow we extract the first sentence of the tagwiki description and clean up the sentence by removing hyperlinks and bracketssuch as .
then we apply part of speech pos tagging to the extracted sentence.
pos tagging is the process of marking up a word in a text as corresponding to a particular part of speech such asnoun verb adjective.nlptoolsusuallyagreeonthepostags ofnouns andwefindthatpostaggerinnltk isespecially suitableforourtask.innltk thenounisannotatedbydifferent postags includingnn noun singularormass nns noun plural nnp propernoun singular nnps propernoun plural .
fig.4showstheresultsforthetagdefinitionsentenceof matplotlib.
based on the pos tagging results we extract the first noun libraryinthisexample afterthebeverb is inthisexample asthecategory of the tag.
that is the category of matplotlib islibrary.
note that if thenounissomespecificwordssuchas system development w e willfurthercheckitsneighborhoodwordstoseeifitis operating systemorindependent development environment.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
ase september montpellier france yi huang chunyang chen zhenchang xing tian lin and yang liu withthismethod weobtain318categoriesforthe23 658tags about67 ofallthetagsthathavetagwiki .wemanuallynormalizethese318categorieslabels suchasmerging appandapplications asapplication librariesandlibaslibrary andnormalizinguppercase andlowercase e.g.
apiandapi .asaresult weobtain167categories.furthermore wemanually categorizethese167categories into five general categories programming language platform library api and concept standard .
this is because the meaning of the fine grained categories is often overlapping and there is no consistent rule for the usage of these terms in the tagwiki.
this generalization step is necessary especially for the library tags that broadly refer to the tags whose fine grained categories can belibrary framework api toolkit wrapper andsoon.forexample instackoverflow stagwiki junitisdefinedasaframework google visualization isdefinedasanapi and wxpython isdefined as a wrapper.
all these tags are referred to as library tags in our approach.
although the above method obtains the tag category for the majority of the tags the first sentence of the tagwiki of sometags is not formatted in the standard tag be noun phrase form.for example the first sentence of the tagwiki of the tag itextis librarytocreateandmanipulatepdfdocumentsinjava orfor markermanager thetagdefinitionsentenceis agooglemapstool orforghc pkg thetagdefinitionsentenceis thecommandghcpkgcanbeusedtohandleghcpackages .asthereisno beverbin this sentence the above nlp method cannot return a noun phrase as the tag category.
according to our observation for most of such cases the category of the tag is still present in the sentence but ofteninmanydifferentways.itisverylikelythatthecategoryword appearsasthefirstnounphrasethatmatchtheexistingcategory words in the definition sentence.
therefore we use a dictionary look upmethodtodeterminethecategoryofsuchtags.specially we use the categories obtained using the above nlp method as adictionarytorecognizethecategoryofthetagsthathavenotbeencategorizedusingthenlpmethod.givenanuncategorizedtag we scanthefirstsentenceofthetag stagwikifromthebeginning and search for the first match of a category label in the sentence.
if a match is found the tag is categorized as the matched category.
for example thetag itextiscategorizedas libraryusingthisdictionary look upmethod.usingthedictionarylook upmethod weobtain the category for more tags.
note that we cannot categorize some less than of the tags usingtheabovenlpmethodandthedictionarylook upmethod.
this is because these tags do not have a clear tag definition sentence forexample thetagwikiofthetag richtextbox statesthat therichtextboxcontrolenablesyoutodisplayoreditrtfcontent .
this sentence is not a clear definition of what richtextbox is.
or no category match can be found in the tag definition sentence of some tags.
for example the tagwiki of the tag carousel statesthat arotatingdisplayofcontentthatcanhouseavariety ofcontent .unfortunately wedonothavethecategory display inthe167categorieswecollectusingthenlpmethod.whenbuilding comparable technologies knowledge base we exclude these uncategorized tags as potential candidates.table examples of filtering results by categorical knowledge in red source top recommendations from word embedding nltk nlp opennlp gate language model stanford nlp tcp tcp ip network programming udp packets tcpserver vim sublimetext vim plugin emacs nano gedit swift objective c cocoa touch storyboard launch screen bubble sort insertion sort selection sort mergesort timsort heapsort .
building similar technology knowledge base givenatechnologytag t1withitsvector vec t1 wefirstfindmost similar library t2whose vector vec t2 is most closed to it i.e.
argmax t2 tcos vec t1 vec t2 wheretisthesetof technologytagsexcluding t1 andcos u v is the cosine similarity of the two vectors.
note that tags whose tag embedding is similar to the vector vec t1 maynotalwaysbeinthesamecategory.forexample tag embeddingsofthetags nlp language model aresimilartothevector vec nltk .thesetagsarerelevanttothe nltklibraryastheyreferto somenlpconceptsandtasks buttheyarenotcomparablelibraries to thenltk.
in our approach we rely on the category of tags i.e.
categoricalknowledge toreturnonlytagswithinthesamecategory as candidates.
some examples can be seen in table .
in practice there could be several comparable technologies t2 to the technology t1.
thus we select tags t2with the cosine similarity in eq.
3above a threshold thresh.
take the library nltk a nlp library in python as an example.
we will preserve several candidates which are libraries such as textblob stanford nlp.
mining comparative opinions foreachpairofcomparabletechnologiesintheknowledgebase weanalyzetheq adiscussionsinstackoverflowtoextractplausiblecomparativesentencesbywhichstackoverflowusersexpresstheir opinions on the comparable technologies.
we may obtain manycomparative sentences for each pair of comparable technologies.
displaying all these sentences as a whole may make it difficult for developerstoreadanddigestthecomparisoninformation.therefore we measure the similarity among the comparative sentences andthenclusterthemintoseveralgroups eachofwhichmayidentify a prominent aspect of technology comparison that users are concerned with.
.
extracting comparative sentences therearethreestepstoextractcomparativesentencesofthetwo technologies.
we first carry out some preprocessing of the stack overflowpostcontent.then welocatethesentencesthatcontain thenameofthetwotechnologies andfurtherselectthecomparative sentences that satisfy a set of comparative sentence patterns.
.
.
preprocessing.
to extract trustworthy opinions about the comparisonoftechnologies weconsideronlyanswerpostswith positive score points.
then we split the textual content of such answer posts into individual sentences by punctuations like .
!
?
.weremoveallsentencesendedwithquestionmark aswewant authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
tell them apart distilling technology differences from crowd scale comparison... ase september montpellier france table the comparative sentence patterns no.pattern sequence example original sentence 1tech vbz jjr innodb has higher innodb has higher performance than myisam on average.
2tech vbz rbr postgresql is a more postgresql is a more correct database implementation while mysql is less compliant.
3jjr cin tech faster than coalesce isnull is faster than coalesce.
4rbr jj cin tech more powerful than velocity freemarker is more powerful than velocity.
5cv cin tech prefer ant over maven i prefer ant over maven personally.
6cv vbg tech recommend using html5lib i strongly recommend using html5lib instead of beautifulsoup.
table examples of alias tech term synonyms abbreviation visual studio visualstudio visual studios visual studio msvs beautifulsoup beautiful soup bs4 objective c objectivec objective c objc obj c depth first search deep first search depth first search depth first search dfs postgresql postgre sql posgresq postgesql pgsql to extract facts instead of doubts.
we lowercase all sentences to makethesentencetokensconsistentwiththetechnologynames because all tags are in lowercase.
.
.
locating candidate sentences.
tolocate sentences mentioning a pair of comparable technologies using only the tag names is notenough.aspostsinstackoverflowareinformaldiscussionsabout programming related issues users often use alias to refer to the same technology .
aliases of technologies can be abbreviations synonymsandsomefrequentmisspellings.forexample javascript are often written in many forms such as js abbreviation java script synonym javascrip misspelling inthe discussions.
thepresenceofsuchaliaseswillleadtosignificantmissingof comparative sentences if we match technology mentions in a sentence with only tag names.
chen et al.
s work builds a large thesaurus of morphological forms of software specific terms includingabbreviations synonymsandmisspellings.table 3shows some examples of technologies aliases in this thesaurus.
based on this thesaurus we find differentalias for software technologies.
these aliases help to locate more candidate comparative sentences that mention certain technologies.
.
.
selecting comparative sentences.
to identify comparative sentencesfromcandidatesentences wedevelopasetofcompar ative sentence patterns.
each comparative sentence pattern is a sequence of pos tags.
for example the sequence of pos tags rbr jjin is apatternthat consistsofacomparative adverb rbr an adjective jj andsubsequentlyapreposition in suchas moreefficientthan lessfriendlythan etc.weextendthelistofcommon pos tags to enhance the identification of comparative sentences.
more specifically we create three comparative pos tags cv comparative verbs e.g.
prefer compare beat cin comparative prepositions e.g.than over and tech technologyreference including the name and aliases of a technology e.g.
python eclipse .
basedondataobservationsofcomparativesentences wesummarise six comparative patterns.
table 2shows these patterns and thecorrespondingexamplesofcomparativesentences.tomakethe patternsmoreflexible weuseawildcardcharactertorepresenta listofarbitrarywordstomatchthepattern.foreachsentencementioningthetwocomparabletechnologies weobtainitspostags and checkif it matches anyone of six patterns.
if so thesentence will be selected as a comparative sentence.
figure5 anillustrationofmeasuringsimilarityoftwocom parative sentences .
measure sentence similarity to measure the similarity of two comparative sentences we adopt thewordmover sdistance whichisespeciallyusefulforshorttext comparison.
given two sentences s1ands2 we take one word ifroms1and one word jfroms2.
let their word vectors be vi andvj.
the distance between the word iand the word jis the euclidean distance between their vectors c i j vi vj .t o avoid confusionbetweenword and sentencedistance we will refer toc i j asthecostassociatedwith traveling fromonewordto another.oneword iins1maymovetoseveraldifferentwordsinthe s2 but its total weight is .
so we use tij to denote how much of wordiins1travels to word jins2.
it costs summationtext.
jtijc i j to move one word ientirely into s2.
we define the distance between the twosentencesastheminimum weighted cumulativecostrequired to move all words from s1tos2 i.e.
d s1 s2 summationtext.
i jtijc i j .
this problem is very similar to transportation problem i.e.
how to spend less to transform all goods from source cities a1 a2 ... totargetcities b1 b2 ....gettingsuchminimumcostactuallyisa well studied optimization problem of earth moverdistance .
tousewordmover sdistanceinourapproach wefirsttraina wordembeddingmodelbasedonthepostcontentofstackoverflow sothatwegetadensevectorrepresentationforeachwordinstack overflow.wordembeddinghasbeenshowntobeabletocapture rich semantic and syntactic information of words.
our approach doesnotconsiderwordmover sdistanceforallwordsinasentence.
instead for each comparative sentence we extract only keywords with pos tags that are most relevant to the comparison including adjectives jj comparativeadjectives jjr andnouns nn nns nnp and nnps not including the technologies under comparison.
then wecomputetheminimalwordmovers distancebetweenthe keywordsinonesentenceandthoseintheothersentences.base on the distance we further compute the similarity score of the two sentences by similarityscore s1 s2 d s1 s2 authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
ase september montpellier france yi huang chunyang chen zhenchang xing tian lin and yang liu figure communities in the graph of comparative sentences the similarity score is in range and the higher the score the more similar the two sentences.
if the similarity score between thetwosentencesislargerthanthethreshold weregardthemas similar.
the threshold is .
in this work determined heuristically by a small scale pilot study.
we show some similar comparative sentences by word mover s distance in table .
tohelpreaderunderstandwordmovers distance weshowan exampleinfigure 5withtwocomparativesentencesforcomparing postgresql andmysql postgresqloffersmoresecurityfunctionality thanmysql and mysqlprovideslesssafetyfeaturesthanpostgresql .
the keywords in the two sentences that are most relevant to the comparison are highlighted in bold.
we see that the minimumdistance between the two sentences is mainly the accumulation ofworddistancebetweenpairsofsimilarwords offers provides more less security safety and functionality features .
as the distance between the two sentences is small the similarity score is higheventhoughthetwosentencesuseratherdifferentwordsand express the comparison in reverse directions.
.
clustering representative comparison aspects foreachpairofcomparabletechnologies wecollectasetofcomparativesentencesabouttheircomparisoninsection .
.within thesecomparative sentences wefindpairsof similarsentencesin section3.
.
we take each comparative sentence as one node in the graph.
if the two sentences are determined as similar we add an edge between them in the graph.
in this way we obtain a graph of comparativesentencesforagivenpairofcomparativetechnologies.
although some comparative sentences are very different in words or comparison directions examples shown in fig.
5and table4 they may still share the same comparison opinions.
in graph theory a set of highly correlated nodes is referred to as a community cluster in the network.
based on the sentence similarity we cluster similar opinions by applying the community detection algorithm to the graph of comparative sentences.
in this work weusethegirvan newmanalgorithm whichisahierarchicalcommunitydetectionmethod.itusesaniterativemodularitymaximizationmethodtopartitionthenetworkintoafinitenumber of disjoint clusters that will be considered as communities.
eachnode must be assigned to exactly one community.
fig.
6shows the graph of comparative sentences for the comparison of tcpand udp twonetworkprotocols inwhicheachnodeisacomparative sentence and the detected communities are visualized in the same color.
asseeninfig.
eachcommunitymayrepresentaprominent comparisonaspectofthetwocomparabletechnologies.butsome communities maycontain toomany comparativesentences tounderstandeasily.therefore weusetf idf termfrequencyinverse documentfrequency toextractkeywordsfromcomparativesentence in one community to represent the comparison aspect of this community.tf idfisastatisticalmeasuretoevaluatetheimportance of a word to a document in a collection.
it consists of two parts termfrequency tf thenumberoccurrencesofatermina document and inverse document frequency idf the logarithm of thetotalnumberofdocumentsinthecollectiondividedbythenumberofdocumentsinthecollectionthatcontainthespecificterm .
for each community we remove stop words in the sentences and regardeachcommunityasadocument.wetakethetop 3words withlargesttf idfscoresastherepresentativeaspectforthecommunity.table 5showsthecomparisonaspectsoffourcommunities for comparing postgresql withmysql.
the representative keywords directlyshowthatthecomparisonbetween postgresql withmysql mainly focuses on four aspects s peed security popularity and usability.
implementation .
dataset wetakethelateststackoverflowdatadump releasedon13march asthedatasource.itcontains14 834questions answers 812uniquetags.withtheapproachinsection wecollect in total pairs of comparable technologies.
among these technologies we extract comparative sentences for pairsofcomparabletechnologies.weusethesetechnologiesand comparativesentencestobuildaknowledgebasefortechnology comparison.
.
tool support apart from our abstract approach we also implement a practicaltool2fordevelopers.withtheknowledgebaseofcomparable technologies and their comparative sentences mined from stack overflow our site can return an informative and aggregated view of comparative sentences in different comparison aspects for comparable technology queries.
in addition thetool provides the link of each comparative sentence to its corresponding stack overflow post so that users can easily find more detailed content.
experiment in this section weevaluate each step of our approach.
asthereis no ground truth for technology comparison we have to manually checktheresultsofeachsteporbuildthegroundtruth.andasitisclear to judge whether a tag is of a certain category from its tag de scription whethertwotechnologiesarecomparable andwhetherasentenceisacomparativesentence werecruittwomasterstudents authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
tell them apart distilling technology differences from crowd scale comparison... ase september montpellier france table examples of similar comparative sentences by word mover s distance comparable technology pair comparative sentences vmware virtualboxvirtualbox is slower than vmware.
in my experience i ve found that vmware seems to be faster than virtualbox.
strncpy strcpyin general strncpy is a safer alternative to strcpy.
so that the strncpy is more secure than strcpy.
google chrome safarisafari still uses the older webkit while chrome uses a more current one.
google chrome also uses an earlier version of webkit than safari.
quicksort mergesortmergesort would use more space than quicksort.
quicksort is done in place and doesn t require allocating memory unlike mergesort.
nginx apacheserving static files with nginx is much more efficient than with apache.
there seems to be a consensus that nginx serves static content faster than apache.
table the representative keywords for clusters of postgresql and mysql.
representative keywords comparative sentences speed slo wer fasterin most regards postgresql is slower than mysql especially when it comes to fine tuning in the end.
i did a simple performance test and i noticed postgresql is slower than mysql.
according to my own experience postgresql run much faster than mysql.
postgresql seem to better than mysql in terms of speed.
security safety functionalitytraditionally postgresql has fewer security issues than mysql.
postgresql offers more security functionality than mysql.
mysql provides less safety features than postgresql.
popularwhile postgresql is less popular than mysql most of the serious web hosting supports it.
though mysql is more popular than postgresql but instagram is using postgresql maybe due to these reasons.
it s a shame postgresql isn t more popular than mysql since it supports exactly this feature out of the box.
easier simplicitymysql is more widely supported and a little easier to use than postgresql.
postgresql specifically has gotten easier to manage while mysql has lost some of the simplicity.
however people often argue that postgresql is easier to use than mysql.
tomanuallychecktheresultsofthesethreesteps.onlyresultsthat they both agree will be regarded as ground truth for computing relevant accuracy metrics and those results without consensus will be given to the third judge who is a phd student with more experience.
all three students are majoring in computer scienceand computer engineering in our school and they have diverse research and engineering background with different software tools and programming languages in their work.
in addition we release all experiment data and results in our website3.
.
accuracy of extracting comparable technologies this section reports our evaluation of the accuracy of tag category identification the important of tag category for filtering out irrelevant technologies and the impact of word embedding models and hyperparameters.
.
.
the accuracy of tag ccategory.
from33 306tagswithtag category extractedby ourmethod werandomly sample1000 tags whosecategoriesaredeterminedusingthenlpmethod andthe other tags whose categories are determined by the dictionary look up method see section .
.
among the sampled tag categories by the nlp method categories of .
tags are correctly extracted by the proposed method.
for the sampled by the dictionary look up method categories of .
tags are correct.
accordingtoourobservation tworeasonsleadtotheerroneous tag categories.
first some tag definition sentences are complex which can lead to erroneous pos tagging results.
for example the tagwikiofthetag rpy2statesthat rpyisaverysimple yetrobust pythoninterfacetotherprogramminglanguage .thedefaultpostaggingrecognizes simpleasthenounwhichisthenregardedasthe category by our method.
second the dictionary look up method sometimesmakesmistakes asthematchedcategorymaynotbethe real category.
forexample the tagwiki ofthe tag honeypot states a trap set to detect or deflect attempts to hack a site or system .
our approach matches the systemas the category of the honeypot.
.
.
the importance of tag category.
tochecktheimportanceof tagcategoryfortheaccuratecomparabletechnologyextraction we set up twomethods i.e.
one isword embedding and tagcategory filtering and the other is only with word embedding.
the word embedding modelin twomethods areboth skip grammodel with thewordembeddingdimensionas800.werandomlysample150 technologiespairsextractedfromeachmethod andmanuallycheck the if the extracted technology pair is comparable or not.
it shows thattheperformanceofmodelwithtagcategory .
ismuch better than that without the tag category filtering .
.
.
.
the impact of parameters of word embedding.
there are two important parameters for the word embedding model and we authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
ase september montpellier france yi huang chunyang chen zhenchang xing tian lin and yang liu table the accuracy of comparative sentences extraction no.
pattern right wrong accuracy 1tech vbz jjr 2tech vbz rbr 3jjr cin tech 4rbr jj cin tech 5cv cin tech 6cv vbg tech total .
test its impact on the the performance of our method.
first we comparetheperformanceofcbowandskip grammentionedin section2.1byrandomlysampling150technologypairs extracted byeachmethodunderthesameparametersetting thewordembeddingdimensionis400 .theresultsshowthatskip gram .
outperforms the cbow .
but the difference is marginal.
second we randomly sample technologies pairs by the skipgram model with different word embedding dimensions and manually check the accuracy.
from the dimension to with the step as the accuracy is .
.
.
.
.
.
we can see that the model with the word embedding dimension as achieves the best performance.
finally we take the skip gram modelwith800word embeddingdimensionasthewordembedding model to obtain the comparable technologies in this work.
.
accuracy and coverage of comparative sentences we evaluate the accuracy and coverage of our approach in finding comparative sentences from the corpus.
we first randomly sample sentences sentences for each comparative sentence pattern intable2 whichareextractedbyourmodel.wemanuallycheck theaccuracyofthesampledsentencesandtable 6showstheresults.
theoverallaccuracyofcomparativesentenceextractionis83.
and our approach is especially accurate for the first patterns.
the lasttwo patterns donot workwelldue tothe relatively loose conditions.
wefurthercheckthewrongextractionofcomparativesentences and find that most errors are caused by wrong comparable technologiesextractedinsection .forexample implodeandexplode are not comparable technologies but they are mentioned in sen tence i m not sure why you d serialize it in php either becauseimplodeandexplodewould be more appropriate .
in addition although some sentences do not contain the question mark they are actuallyinterrogativesentencesuchas ialsowonderifpostgresql will be a win over mysql .
.
accuracy of clustering comparative sentences we evaluate the performance of our opinion clustering method by comparing it with the baseline methods.
.
.
baseline.
we set up two baselines to compare with our comparative sentence clustering method.
the first baseline is the traditionaltf idf with k means and thesecondbaselineis basedonthedocument to vectordeeplearningmodel i.e.
doc2vec table ground truth for evaluating clustering results no.
technology pair comparative sentences clusters 1compiled interpreted language 2sortedlist sorteddictionary ant maven pypy cpython 5google chrome safari 6quicksort mergesort 7lxml beautifulsoup awt swing jackson gson swift objective c jruby mri 12memmove memcpy with k means.
both methods first convert the comparative sentencesforapairofcomparabletechnologiesintovectorsbytf idf anddoc2vec.thenforbothmethods wecarryoutk meansalgorithms to cluster the sentence vectors into nclusters.
to make the baseline as competitive as possible we set nat the cluster number of the ground truth.
in contrast our method specifies its cluster numberbycommunitydetectionwhichmaydifferfromthecluster number of the ground truth.
.
.
ground truth.
asthereisnogroundtruthforclusteringcomparative sentences we ask two master students mentioned before to manually build a small scale ground truth.
we randomly sample15pairsofcomparabletechnologieswithdifferentnumberof comparative sentences.
for each technology pair the two students read each comparative sentence and each of them will individually create several clusters for these comparative sentences.
note some comparativesentencesareuniquewithoutanysimilarcomparativesentence andweputallthosesentencesintoonecluster.thenthey will discuss with the ph.d student about the clustering results and changetheclustersaccordingly.finally theyreachanagreement for 12pairs ofcomparable technologies.wetake these12 pairsas the ground truth whose details can be seen in table .
.
.
evaluation metrics.
giventhegroundtruthclusters many metricshavebeenproposedtoevaluatetheclusteringperformance in the literature.
in this work we take the adjusted rand index ari normalizedmutualinformation nmi homogeneity completeness v measure and fowlkes mallows index fmi .forallsixmetrics highervaluerepresentsbetterclusteringperformance.foreachpairofcomparabletechnologies wetake all comparative sentences as a fixed list and gas a ground truth cluster assignment and cas the algorithm clustering assignment.
adjustedrand index ari measuresthe similaritybetween twopartitionsinastatisticalway.itfirstcalculatestherawrand index ri by ri a b cn 2whereais the number of pairs of elements that arein thesame cluster in gand alsoin thesame cluster in c andbisthenumberofpairsofelementsthatareindifferentclusters ingand also in different clusters in c.cn 2is the total number of possible pairs in the dataset without ordering where nis the number of comparative sentences.
to guarantee that random label assignments will get a value close to zero ari is defined as ari ri e max ri e authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
tell them apart distilling technology differences from crowd scale comparison... ase september montpellier france wheree is the expected value of ri.
normalizedmutualinformation nmi measuresthemutual information betweenthe groundtruth labels gand thealgorithm clustering labels c followed by a normalization operation nmi g c mi g c radicalbig h g h c whereh g istheentropyofset gi.e.
h g summationtext.
g i 1p i log p i andp i gi nis the probability than an objet picked at random fallsintoclass gi.themi g c isthemutualinformationbetween gandcwheremi g c summationtext.
g i summationtext.
c j 1p i j log p i j p i p j homogeneity hom is the proportion of clusters containing only members of a single class by h h g c h g completeness com istheproportionofallmembersofagiven class are assigned to the same cluster by c h c g h c whereh g c istheconditionalentropyoftheground truthclasses given the algorithm clustering assignments.
v measure v m is the harmonic mean of homogeneity and completeness v h c h c fowlkes mallows index fmi is defined as the geometric mean of the pairwise precision and recall fmi tp radicalbig tp fp tp fn wheretpisthenumberoftruepositive i.e.thenumberofpairs of comparativesentences that belong tothe same clustersin both thegroundtruthandthealgorithmprediction fpisthenumber of false positive i.e.
the number of pairs of comparative sentences that belong to the same clusters in the ground truth labels but not inthealgorithmprediction and fnisthenumberoffalsenegative i.ethenumberofpairsofcomparativesentencesthatbelongsin the same clusters in the algorithm prediction but not in the ground truth labels .
.
.
overall performance.
table8showstheevaluationresults.
tf idfwithk meanshassimilarperformanceasthedoc2vecwith k means but our model significantly outperforms both models in all six metrics.
according to our inspection of detailed results we find two reasonswhyourmodeloutperformstwobaselines.first ourmodelcan capture the semantic meaning of comparative sentences.
tf idf canonlyfindsimilarsentencesusingthesamewordsbutcountsimilar words like secure and safe as unrelated.
while the sentence vector from doc2vec is easily influenced by the noise as it takes all words in the sentence into consideration.
second constructing the similar sentences as a graph in our model explicitly encodes the sentence relationships.
the community detection based on the graph can then easily put similar sentences into clusters.
in contrast for the two baselines the error brought from the tf idf andtable clustering performance method ari nmi hom com v m fmi tf idf kmeans .
.
.
.
.
.41doc2vec kmeans .
.
.
.
.
.43our model .
.
.
.
.
.
doc2vecisaccumulatedandamplifiedtok meansintheclustering phase.
usefulness evaluation experimentsinsection 5haveshowntheaccuracyofourapproach.
in this section we further demonstrate the usefulness of our approach.
according to our observation of stack overflow there are some questions discussing comparable technologies such as whatis the difference between swing and awt .
we demonstrate the usefulness of the technology comparison knowledge our approach distills from stack overflow discussions by checking how well the distilled knowledge by our approach can answer those questions.
.
evaluation procedures weusethenameofcomparabletechnologieswithseveralkeywords suchascompare vs difference tosearchquestionsinstackoverflow.
wethenmanuallycheckwhichofthemaretrulyaboutcomparable technologycomparison andrandomlysamplefivequestionsthat discusscomparabletechnologiesindifferentcategoriesandhave at least five answers.
the testing dataset can be seen in table .
wethenaskthetwomasterstudentstoreadeachsentencein all answers and cluster all sentences into several clusters whichrepresent developers opinions in different aspects.
to make thedata as valid as possible they still first carry out the clusteringindividually and then reach an agreement after discussions.
foreach comparative opinion in the answer we manually check ifthat opinion also appears in the knowledge base of comparativesentences extracted by our method.
to make this study fair our method does not extract comparative sentences from answers of questions used in this experiment.
.
results table10showstheevaluationresults.wecanseethatmostcomparison aspectscanbecoveredbyourknowledgebase.for two questions and the technology comparison knowledge distilled by our method can cover all of comparison aspectsintheoriginal answerssuch asspeed r eliability data size for comparing postandget.
while for the other three questions our model can still cover more than half of the comparison aspects.
we miss some comparison aspects for the other three questions such as one psychologicalreason that hasnot been givenis simply that quicksort is more cleverly named i.e.
good marketing.
the vmwareworkstationclientprovidesanicerend userexperience subjective iknow... and anotherstatementwhichisawisthatswingis mvc based and awt is not.
.
such opinions are either too subjective ortoodetailed whichrarelyappearagainin otherstackoverflow discussions leading to not having them in our knowledge base.
apartfromcomparisonaspectsappearedintheoriginalanswers ourtoolcanprovidesomeuniqueopinionsfromotheraspects such authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
ase september montpellier france yi huang chunyang chen zhenchang xing tian lin and yang liu table comparative questions question id question title tech pair tech category answers why is quicksort better than mergesort?
quicksort mergesort algorithm difference between tcp and udp tcp udp protocol benchmark vmware vs virtualbox vmware virtualbox ide what is the difference between swing and awt?
swing awt library when do you use post and when do you use get?
post get method table distilled knowledge by our approach versus original answers question id aspects covered unique in our model .
.
total as inmyexperience udpbasedcodeisgenerallylesscomplexthantcp basedcode forcomparing tcpandudp howeverifoundthatvmware is much more stable in full screen resolution to handle the iphone connectionviausb forcomparing vmwareandvirtualbox and get would obviously allow for a user to change the value a lot easier than post for comparing postandget.
as seen in table our model canprovidemore thanoneuniquecomparativeaspects whichare not in the existing answers for each technology pair.
therefore our knowledge base can be a good complement to these existing technology comparison questions with answers.
furthermore our knowledge base contains the comparison knowledge of pairs ofcomparabletechnologies manyofwhichhavenotbeenexplicitlyaskedanddiscussedinstackoverflow suchas swiftandobjective c nginxandapache.
related works findingsimilarsoftwareartefactscanhelpdevelopersmigratefromonetooltotheotherwhichismoresuitabletotheirrequirement.butitisachallengingtasktoidentifysimilarsoftwareartefactsfromthe existinglargepoolofcandidates.therefore muchresearcheffort hasbeenputintothisdomain.differentmethodshasbeenadopted to mine similar artefacts ranging from high level software mobile applications github projects to low level third partylibraries apis codesnippets or q a questions .
compared with these research studies the mined software technologies in this work has much broader scopeincludingnotonlysoftware specificartefacts butalsogeneral software concepts e.g.
algorithm protocol tools e.g.
ide .
givenalistofsimilartechnologies developersmayfurthercompare and contrast them for the final selection.
some researcherinvestigate such comparison the comparison is highly domain specific such as software for traffic simulation regression models x86 virtualization etc.
michail and notkin assess different third party libraries by matching similar compo nents such as classes and functions across similar libraries.
but it can onlywork for library comparisonwithout the possibility to beextendedtootherhigher lower leveltechnologiesinsoftwareengineering.
instead we find developers s preference of certain software technologies highly depends on other developers usage experienceandreportofsimilartechnologycomparisons.there fore uddinandkhomh extractapiopinionsentencesin differentaspectstoshowdevelopers sentimenttothatapi.liet al.
adoptnlpmethodstodistillcomparativeuserreviewabout similar mobile apps.
different from their works we first explicitly extract a large pool of comparable technologies.
in addition apart fromextractingcomparativesentences wefurtherorganizethem into different clusters and represent each cluster with some keywordstohelpdevelopersunderstandcomparativeopinionsmore easily.
finally it is worth mentioning some related practical projects.
similarweb isawebsitethatprovidesbothusersengagementstatisticsandsimilarcompetitorsforwebsitesandmobileapplications.
alternativeto isasocialsoftwarerecommendationwebsitein which users can find alternatives to a given software based on user recommendations.
similartech isa siteto recommendanalogicalthird partylibrariesacross differentprogramming languages.
thesewebsitescanhelpusersfindsimilaroralternativewebsites or software applications without detailed comparison.
conclusion and future work inthispaper wepresentanautomaticapproachtodistillandaggregatecomparativeopinionsofcomparabletechnologiesfromq a websites.wefirstobtainalargepoolofcomparabletechnologiesby incorporating categorical knowledge into word embedding of tags in stack overflow and then locate comparative sentences about these technologies by pos tag based pattern matching and finally organizecomparativesentencesintoclustersforeasierunderstanding.
the evaluation shows that our system covers a large set of comparable technologies and their corresponding comparative sentences with high accuracy.
we also demonstrate the potential of our system to answer questions about comparing comparable technologies because the technology comparison knowledge mined usingoursystemlargelyoverlapwiththeoriginalanswersinstack overflow.
apartfromcomparativesentencesexplicitlymentioningboth comparable technologies some comparative opinions may hide deeper.forexample onedeveloperexpresseshisopinionsaboutonetechnologyinoneparagraphwhilediscussingtheothertechnology in the next paragraph.
therefore we will improve our system to distilltechnologycomparisonknowledgefromthecurrentsentence leveltopostlevel.inaddition wealsoplantosummarizehigherlevelopinionsorpreferencesfromseparatedindividualcomparative sentences for easier understanding.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
tell them apart distilling technology differences from crowd scale comparison... ase september montpellier france