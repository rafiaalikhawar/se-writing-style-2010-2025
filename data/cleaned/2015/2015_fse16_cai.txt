a deployable sampling strategy for data race detection yan cai1 jian zhang1 lingwei cao1 and jian liu2 state key lab oratory of computer science institute of software chinese academy of sciences beijing china institute of information engineering chinese academy of sciences beijing china ycai.mail gmail.com zj ios.ac.cn lingweicao gmail.com liujian6 iie.ac.cn abstract dynamic data race detection incurs heavy runtime overhead s. recently many sampling techniques have been proposed to detect data races.
however some sampling techniques e.g.
pacer are based on traditional happens before relation and incur a large basic overhead.
others utilize hardware to reduce their sampling overhead e.g.
datacollider and they however detect a race only when the race really occurs by delaying program executions.
in this paper we study the limitation s of existing techniques and propose a new data race definition named as clock races for low overhead sampling purpose .
the innovation of clock races is that the detection of them does not rely on concrete locks and also avoid s heavy basic overhead from tracking happens before relation.
we further propose crsampler clock race samp ler to detect clock races via hardware based sampling without direct ly delaying program execution s to further reduce runtime overhead.
we evaluated crsampler on dacapo benchmarks.
the results show that crsampler incur red less than overhead on average at sampling rate.
whereas pacer and datacollider incurred larger than and overhead respectively .
besides at the same sampling rate crsampler detected significantly more data races than that by pacer and datacollider .
ccs concepts software and its engineering software testing and debugging theory of computation program verification .
keywords data race sampling concurrency bugs data breakpoints.
.
introduction a data race or race for short occurs when two or more threads access the same memory location at the same time and at least one of these accesses is a write .
race occurre nces may lead to occurrences of other concurrency bugs and may result in real world disasters .
on race detection s tatic techniques could scale up to a whole program but may report many fa lse positives .
dynamic techniques report fewer false positives.
they are mainly based on either the lockset discipline or the happens before relation .
the l ockset discipline requires that all accesses to a shared memory location should be protec ted by a common set of locks.
however e ven violating such a discipline no data race may occur .
the happens before relation is usually implemented via vector clocks .
each vector clock contains n clock elements where n is the number of threads.
they are used to track status es of th reads lock s and memory location s. race detectors implementing vector clocks incur high er overhead than the lockset based ones .
fasttrack further improves th e overhead of the happens before based race detectors to be the same level as that of lockset based ones by avoid ing most of o n operations on memory accesses .
however fasttrack still incurs from to overhead .
to reduce runtime overhead sampling techniques were introduc ed to only monitor a small set of memory accesses .
they could be deployed at the program user sites if they incur a n enough low overhead e.g.
less than .
literace targets to sample memory accesses from cold i.e.
not frequently called functions.
however it fully monitors synchronization operations even those in non sampled functions and maintains data structures for threads locks and memory locations needed by happens before based race detect ors .
as a result the overhead of literace varies from several percentages to .
besides literace needs to log various events for offline race detection which may further prevent it from being deploy ed at user site s. pacer introduces periodical sampling strategy.
it only tracks memory accesses and synchronization operations in full during its sampl ing period s. in non sampl ing period s it only checks race occurr ences.
however pacer is based on dynamic sampling i.e.
making sampling decision online and has to maintain basic data structures like literace incurring certain basic overhead.
for example with and sampling rates pacer incurs and overh ead respectively .
such overhead makes pacer impractical to be deployed at user sites as an acceptable overhead at user site s is usually .
the latest sampling strategy datacollider completely discards both the monitoring on synchronization operations and the maintenance on data structures.
it utilizes code and data breakpoints of hardware archite ctures to support its sampling for race detection .
a code breakpoint is s et to a program instruction and is fired if the instruction is executed.
a data breakpoint is set to a memory address and is fired if a memory access to the address is executed .
datacollider firstly sets a code breakpoint on a random instruction.
if this code breakpoint fires it further sets a data breakpoint on the target address of this instruction and delays the execution of the instruction until the data breakpoint fires or a certain time limit is reached .
if a data breakpoint fires there must exist another access to the same address.
then a data race is reported i f at least one of the two accesses is a write .
datacollider could incur a low runtime overhead by only focusing on memory accesses via hardware supports .
however by discardthis is the author s version of the work.
it is posted here for your personal use.
not for redistribution.
the definitive version was published in the following publication fse november seattle wa usa acm.
... ing the da ta structures of memory locations it can only detect data races actually occurr ing in a run but may miss those races that do not occur but could be detected by happens before based detectors like pacer and literace .
besides with a slight increas e in sampling rate its overhead increase s quickly as it direct ly delay s program execution .
this increase is significantly larger than the increase by pacer .
as a result datacollider also become s ineffective and could only work at user site s at an extremely low sampling rate which further makes it ineffective .
in this paper we firstly analyze the limitations of existing sampling approaches on race detection.
we then propose a light but novel definition of data races called clock races based on thread local clocks without the need of vector clock s and concrete locks .
clock races are provable to be also happens before races i.e.
those detectable by happens before based detectors hb race for short .
the benefit of clock races is that the detection of them does not require heavy tracking on concrete locks .
this result s in o rather than o n operations on synchronization events and hence further avoids memory maintenance overhead on the involved locks .
we then propose crsampler a novel sampling approach for detection of clock races based on hardware support .
compared to pacer crsampler does not rely on heavy tracking of happens before relation avoid ing basic tracking overhead.
compared to datacollider crsampler does not directly delay program execution to trap a second access which not only reduce s runtime overhead but also achieve s a bigger capability on race detection .
follow ing pacer we have implemented datacollider and crsampler within jikes rvm and compared crsampler with both datacollider and pacer on six benchmarks from dacapo including a large scale eclipse .
the experiment al results show that at sampling rate crsampler only incurred less than overhead on average but pacer incurred more than overhead on average and datacollider incurred more than overhead on average.
crsampler also detected significantly more races i.e.
races in total than that by pacer and datacollider and races respectively .
besides with the increas e in sampling rate from .
to .
with step .
crsampler not only incurred the least overhead increase but also detected an obviously increasing number of races.
however with the same increase on sampling rate both datacollider and pacer incurred a larger overhead increase than that by crsampler they almost detect ed a constant number of races on most of the benchmark s. in summary the main contribution s of this paper are it presents a novel definition of data races named as clock races.
clock races are proved to be also happens before races.
detection of clock races only requires o operations in time on synchronization events without the need of concrete synchronization objects .
it presents crsampler framework to sample clock races based on hardware supports.
unlike existing techniques crsampler does not directly delay program execution and hence incurs much lower overhead than existing ones.
we have implemented crsampler as a prototype tool see yancai cr cr.html .
the experiments confirm that compared to state of the art happens before based pacer and the hardware based datacollider crsampler is significantly much more effective and efficient .
in the rest of this paper section gives the background followed by motivations in section .
section present s our clock races definition and crsampler .
the evaluation is in section .
section discusses related works and section concludes this paper .
.
background a multithreaded program p consists of a set of threads t t a set of locks or lock synchronization objects l l and a set of memory locations m m. each thread t t has a unique thread identifier tid denoted as t.tid.
during an execution of a multithreaded program p each thread t performs a sequence of events including memory access events read or write to a memory location m and synchronization events acquire or release a lock l. other synchronization e vents can be similarly defined .
we define a non sync block nsb for short during an execution as a sequence of consecutive memory accesses between two synchronization events such that no other synchronization event exists between the two synchronization events.
the happens before relation denoted as hbr for short is defined by the following three rules if two events and are performed by the same thread and appear s before then .
if is a lock release event and is a lock acquire event on the same lock and appear s before then .
if and then .
hbr is typically represented by vector clocks .
a vector clock c is an array of thread local clocks.
a clock is an integer one for each thread t denoted as t.clock .
during program execution one vector clock is allocated for each thread t for each lock l and for each memory location m denoted as ct cl and cm respectively.
the i th element in any vector clock c i.e.
c represent s the last known clock of the thread t with t.tid i. specially for a thread t ct is equal to t.clock .
for a thread t t.clock is only incremented right after its value is distributed to others e.g.
locks on synchronization events .
therefore during an execution we always have t.clock ct for any thread .
ct cany where cany is a vector clock of any thread but not thread t or any lock and ct cm where cm is a vector clock of any memory location m. .
motivations .
how to define and detect data races?
a data race occurrence involves two accesses from different threads includ ing at least one write access .
however there is no gold standard to define data races .
existing technique s usually rely on either the locking discipline or the happens before relation .
the l ocking discipline defines a data race on a memory location if all access es to the memory location is not protected by a common set of locks.
approaches based on l ocking discipline may report false positives as discussed in section .
.
.
happens before based approaches the h appens before relation hbr defines a race on two memory accesses e1 and e2 with a write on the same memory location if neither e1 e2 nor e2 e1.
such kind of races is known as hb races .
hbr requires ful l tracking of synchronizations from all threads.
algorithm shows a simplified basic hb race detector.
the functions onacquire and onrelea se lines track synchronization events acquire and release respectively to maintain vector clocks for threads and locks.
during tracking the vector clocks of the involved threads and locks are firstly fetched i.e.
ct and cl lines and respectively .
then an o n operation as noted is performed to update the vector clock of the thread i.e.
ct cl ct at line or the vector clock of the lock i.e.
ct cl ct at line .
after that the updated vector clock hold s the latest thread local clocks from the two vector clocks.
the functions onread and onwrite check whether a data race occurs when a read or a write occurs.
still the vector clocks of the thread and the memory location are firstly fetched line .
then the algorithm checks whether the last access to m by thread lastthd happens before the current access line .
if no happens before relation exist s from the last access to the current one a data race is reported if one of two accesses is a write omitted in algorithm .
the check is also o n as noted .
in figure we also show an example to illustrate the heavy tracking of hb based approache s. figure a shows a java program p. the program p contains a data race on x accesses to x from two threads t1 and t2 i.e.
x ... and x ... could occur concurrently.
figure b shows how each synchronization is instrumented to track hbr in algorithm for each synchronization a call onacquire ... or onrelease ... is inserted and the lock object i.e.
lock l or lock k is taken as an argument.
and on each read or write an onread or a n onwrite is also invoked.
as a result the tracking of hbr itself i.e.
without race detection incurs high overhead.
for example pacer reports overhead which already includes various optimizations.
in our practice we also experienced about overhead on tra cking hbr.
according to our experience there are two factors contributing to the overhead the fetching of vector clocks of locks and threads lines and in algorithm accounting for more than overhead on average and operations on vector clocks of locks and threads lines and in algorithm contributing more than overhead on average.
therefore hbr via vector clocks is unlikely suitable for data race sampling as its tracking overhead without race detection is already larger than even with various optimizations .
although other existing works target to track a subset of hbr to reduce the tracking overhead to be low enough i.e.
less than their tracking is only desig ned to check two known memory accesses in a production run .
.
.
hardware based approaches recently datacollider defines a race on two accesses with a write on the same memory location if they are executed at the same physical time.
in this paper w e call such races collision races which are also hb race s .
algorit hm shows the datacollider algorithm.
given a sampling rate r and a time limit timelimit discussed in section .
datacollider randomly chooses a set of instructions to sample lines .
for each sampled instruction ins it delay s the execution of ins and at the same time waits for a second access line .
the trapping of a second access is done by setting up a hardware data breakpoint on th e target address of ins line .
if the data breakpoint fire s lines a data race occurs lines .
the map m at line is used to check whether any data breakpoint fires on the address from the instruction of the delayed thread lines a nd .
for example figure c shows how datacollider detects the race on x. suppose that the write to x by thread t1 is sampled then datacollider sets a data breakpoint on the address of x and then delays the write to x for a certain time.
during the delayed period if thread t2 reads or writes to x the data breakpoint fires.
then the algorithm simplified basic hb race detector .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
onacquire lock l l let t be the current thread fetch vector clocks of l and t as cl and ct respectively.
ct cl ct i.e.
for each i ct max cl ct o n onrelease lock l l let t be the current thread fetch vector clocks of l and t as cl and ct respectively.
cl cl ct ct ct o n simplified do not distinguish read or write clock of m. onread onwrite memory location m m let t be the current thread fetch vector clock of t and m as ct and cm respectively .
lastt hd m.lastaccessedthread if not cm ct o n note that some o n operations could be eliminated report a race on m. algorithm datac ollider .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
input r a static sampling rate .
input p a multithreaded program .
input timelimit the max time on a data breakpoint.
let be a set of sampled instructions in p w.r.t r. let m be an empty set.
for each ins static sampling insertcall sample ins sample ins event e1 addr size iswrite parse ins if iswrite setdatabreakpointrw addr size else setdatabreakpointw addr size delay timelimit wait for an event e2 cleardatabreakpoint addr if addr m reportdatarace ins m m addr ondatabreakpointfired addr event e2 m m addr thread t1 acquire l x ... ... release l thread t2 acquire k ... release k x ...thread t1 acquire l onacquire l x ... onwrite x ... onrelease l release l thread t2 acquire k onacquire k ... onrelease k release k tmp x... onread x x tmp onwrite x a b thread t1 acquire l delay x ... ... release l thread t2 acquire k ... release k x ... c figure .
a a program p with a race on x b an instrumentation on p in bold by hb race detectors e.g.
pacer c a delay inserted by datacollider .
race on x is detected and datacollider resumes the execution o f thread t1.
as the hardware breakpoint mechanism supported as debug utilizations on modern cpus incurs almost no overhead datacollider is able to limit a lmost all its overhead to be that caused by its delay .
as the delay of datacollider directly contributes to its overhead the overhead of datacollider could also be large .
and with increasing sampling rate it s overhead increases quickly see our experiments in section .
.
of course datacollider could be configured to incur much lower overhead e.g.
by limiting i ts sampling rate to be much lower but this also results in an extremely lower race detection rate and makes datacollider much more ineffective.
besides the detection of collision races suffers the follow ing limitations.
first if a collision race is detected the race has actually occurred .
therefore once deployed at user sites the occurrences of harmful collision races may cause unexpected results to users .
second not all races could be easily detected in such a way especially on large scale programs e.g.
the e clipse program in our experiment .
as a result datacollider loses certain race detection ability compared to hbr based race detectors .
theref ore our first two insight s are for a lightweight sampling technique in section we present our definition o f data races with respect to the above two requirements.
.
dynamic sampling vs. static sampling dynamic sampling as well as dynamic full race detection requires fully instrumenting program instructions even many instructions may not be sampled during executions.
for example in figure b every access to x incurs onread x or onwrite x calls of course these calls could be inlined but the sampling decision is made within these two functions.
in other words for dynamic sampling to sample or not to sample an instruction is unknown until the instruction is about to be executed .
and at th at time the instrumented function calls have been executed .
as a result additional overhead is incurred due to these per instruction instrumentation s prior to the sampling decision making .
that is part of reasons contributing to large overhead of pacer i.e.
at sampling rate.
however static sampling only requires to instrument exact instructions that are to be sampled as adopted by datacollider .
that is the sampling decision could be made offline or during program loading time and no additional overhead is introduced on those instruction s not to be sampled.
dynamic sampling incurs some basic overhead for all instructions related to memory accesses as well as potential hbr maintenance while static sampling only incurs overhea d for those to besampled instructions.
from this point static sampling is more suitable for lightweight sampling techniques.
therefore our third insight is that .
crsampler .
clock races as discussed in section the detection of hb race s requires instrumentation on synchronization oper ations.
such operations involve fetching vector clocks of locks and threads as well as o n operations on them .
the resultant overhead is already more than in previous experiment .
however the definition of hb races is able to predict races that did not really occur in the monitored executions but may occur in other executions which is more powerful than datacollider that detects a race only when it really occurs.
therefore we only consider a subset of hb r to define data races .
our definition of data races only relies on thread local clocks.
formally we define our clock race s as follows definition .
two memory ac cesses e1 by thread t1 and e2 by thread t2 form a clock race if the two accesses e1 and e2 operate on the same memory location and at least one of them is a write access and at time that e2 occurs t1.clock remains the same as that when t1 performs e1.
the first condition is the basic requirement of a race definition.
the second one is depicted in figure .
it requires that between the occurrences of two accesses e1 and e2 in physical time i.e.
the period from time to time in figure the thread local clock of t1 remains unchanged .
that is during the period thread t1 either case does not execute any event including sleep wait event s that involve two incremen ts on a thread s local clock resulting three non sync blocks or case only executes memory accesses in the same non sync block.
therefore datacollider only defines a subset of our clock races corresponding to case where a thread t1 does not execute any event due to delay ing by datacollider see theorem below .
we present two theorems to show that c lock races are also hb races as the second condition is a subset of hbr i.e.
the correctness of clock races and all races detected by datacollider are also clock race s corresponding to the above case .
theorem .
if two event s e1 and e2 form a clock race they also form a n hb race.
proof sketch.
firstly it is impossible that e2 e1 as e2 appears after e1 occurs which is implied by the second point of definition .
suppose that e1 e2 is true .
let cme1 be the vector clock of m when e1 occurs.
when e2 occurs from e1 e2 we have ct2 cme1 eq1 otherwise an hb race already occurs and hence e1 e2 does not hold .
however as t1.clock is not changed since e1 occurs by definition of clock races in section we then have cme1 ct1 t1.clock eq2 it should not define a race according to the full hbr involving vector clock operations it should not directly delay executing an instruction .
a lightweight sampling technique should adopt static sampling strategy to reduce its overhead per execution .
thread t1 e1thread t2 e2 t1.clock is not changed between time1and time2.
time1 time2 time elapse figure .
illustration of clock races.
from eq1 and eq2 we know that thread t1 does not own a large st clock of itself as ct2 t1.clock which contradicts the fact that a thread always has the largest clock of itself than any other thread .
therefore the assumption e1 e2 is not true.
from and neither e1 e2 nor e2 e1 holds.
as e1 and e2 operate on the same memory locat ion and one of them is a write by definition of the hb race e1 and e2 form an hb race.
hence a clock race is also a n hb race.
theorem .
if two event s e1 and e2 are detecte d by datacollider as a collision race they also form a clock race.
proof sketch .
firstly by definition of collision race both events e1 and e2 operate on the same memory location and one of them is a write access.
secondly s uppose that the event e1 is the event delayed by datacollider the other case can be proved similarly .
when the event e2 occurs the thread say t1 performing e1 does not execute any other event as it is delayed therefore the thread local clock of thread t1 is not changed .
according to the definition of clock race the two events e1 and e2 also form a clock race.
detection of clock races requires only thread local clocks to identify nsb non sync blocks .
therefore it is enough to perform a light instrumentation .
figure shows how the example program is instrumented i.e.
onsync .
compared to instrumentation for hb races as shown in figure b on synchronization event no concrete lock is required i.e.
onsync but not onacquire l or onrelease l and hence no vector clock of locks or threads is operated avoiding o n operations .
therefore a call onsync is enough for each synchronization event which only increment s thread local clock s of the involved thread s see lines in algorithm for details .
figure also shows how a clock race on x is detected.
let the initial clocks of two threads t1 and t2 be and or any two other integers respectively.
for both threads on their acquisitions of lock l and lock k their clocks are incremented by via calls onsync .
then t heir clocks become and respectively.
suppose that the write to x by thread t1 is sampled i.e.
sample x .
next suppose th at before thread t1 release s lock l thread t2 releases lock k followed by its read and writ e to x. at this time the clock of thread t1 is still which is the same as that when its write to x is sampled.
therefore a clock race on x is detected.
note that if thread t1 first releases lock l before thread t2 reads from and write s to x no clock race is then detected.
it is because the clock of thread t1 is changed to which is different from that when the write to x by thread t1 is sampled.
a lthough in both cases full hbr based race detectors e.g.
fasttrack are able to detect the race on x hbr based sampling detectors also suffer from the similar limitations.
for example pacer is able to detect the race on x only if the two accesses by two t hreads occur in the same sampling period or one occurs in a sampling period and the second occurs in the right followed non sampling period.
for other cases pacer is unable to detect this race e.g.
both accesses occur in a non sampling period or one acc ess occurs in a non sampling period and the second one occurs in a sampling period .
for datacollider it is able to detect the race by delaying the write to x by thread t1 until thread t2 reads from and writes to x as shown in figure c .
however as discussed in section such del ays directly increase its overhead.
with increasing number of delays its overhead increases significantly fast see section .
.
.
discussion on definition of clock races.
in definition a clock race requires no change on t1.clock .
symmetrically we could also define a clock race by extending definition i.e.
the second bullet if at time when e2 occurs t2.clock is not changed since the event e1 occurs.
this extension could increase the detection rate of clock races.
how ever it requires tracking of all clocks of any other threads by thread t1 when e1 occurs.
this tracking is o n in time and increases sampling overhead.
in our preliminary experiment this extension slightly increased race detection rates however it d oubled sampling overhead making detection of clock races inefficient .
therefore we only follow definition to detect races by sampling avoiding incur ring any o n operations.
.
static and hardware based sampling crsampler adopts static sampling strategy to sampl e each static instruction based on our third insight discussed in section .
.
when a sampled instruction is being executed the access to the memo ry location i.e.
address in this instruction is taken as a first event e1.
crsampler further set s a data breakpoint on this memory location to trap an event e2.
if such an event e2 occurs and the clock of the thread perform ing e1 remains unchanged a clock race is detected.
note that unlike datacollider during the trap of an event e2 no thread is delayed .
however crsampler has to consider how much time is allowed to trap an event e2.
this is similar to datacollider that has to determine how long it should delay the execution of a thread .
it is because a short time may not be enough for a race to occur.
but a long time may make the usage of the data breakpoint s ineffective as the number of data breakpoints is limit ed.
for example popular x86 cpu support s only four data breakpoint s and others may only support one .
one strateg y is like datacollider to set a constant time limit .
once such a time limit is reached event e1 is discarded.
this strategy is simple and does not incur additional overhead .
the second one is to monitor the clock changes of all threads on ce the thread performing e1 increments its clock event e1 is then discarded and the taken data breakpoint is cleared .
the second strategy seems more effective than the first one.
however it requires additional overhead on synchronization events e.g.
a check on whether an event e1 is sampled from the exec ution of the current thread .
therefore crsampler adopts the first strategy and sets a time limit which is the same as that by datacollider .
.
crsampler algorithm algorithm shows the crsampler algorithm.
given a sampling rate r and a program p crsampler first selects a set of instructions randomly according to the given sampling rate r and instruments these instructions lines and to sample memory accesses at runtime.
the input timelimit is the max time for a data breakpoint to be valid f or a given address.
crsampler maintains a thread local clock for each thread t as t.clock and a data structure m. note that to simplify our presentation we use the notation thread t1 acquire l onsync x ... sample x ... onsync release l thread t2 acquire k onsync ... onsync release k x ...t1.clock 12t2.clock figure .
instrumentation of crsampler highlighted and detection of a clock race on x with thread local clocks.
mx to denote the mapping from x to m x .
the structure m maps from one address to a pair of a thread and a clock corresponding to the thread t performing event e1 in definition of clock race and the clock of t at that time.
note that the map m of algorithm is different from that in algorithm as the number of data breakpoints is limited operations over m are actually o operations in time implemented via a global unique index for each data breakpoint .
at runtime once an instrumented instruction ins is being executed the instrumented call sample ins fires .
crsampler then sets a data breakpoint lines to the memory address i.e.
addr that the instruction ins is about to access.
we use a funct ion parse to denote the extraction of the address addr and the size size in byte associated with the instruction ins as well as iswrite indicating whether this instruction is a write one.
there are two types of data breakpoints read write data breakpo int and write data breakpoint.
the former fires if either a read or a write to the target address occurs the latter fires only if a write to the target address occurs.
crsampler chooses either type of breakpoint according to whether the sampled access is a write or a read lines .
that is a read access only forms a data race with a write access while a write access forms a data race with either a read or a write access.
after setting the breakpoint the thread id and the clock of the current thread is mapped in m from the address addr lines and and a time limit for this addr is set line .
once a data breakpoint on an address addr fires corresponding to event e2 of the clock race definition a clock race on addr occurs if the current thread t is different from the last thread lastthd and the current clock of thread lastthd remains the same as that mapped in m lines .
a data breakpoint is cleared if either a second event e2 occurs as stated in the last paragraph lines or a time limit is reached lines i.e.
the function ontimer addr .
the function onsync is called whenever a synchronization event occurs to increment the thread local clock of the corresponding thread lines .
algorithm comparison .
compared to pacer that is based on hbr crsampler does not maintain full hbr tracking but only a thread local clock on synchronization events i.e.
t.clock t.clock instead of ct cl ct in algorithm .
therefore crsampler invokes onsync instrumentation call but not onacquire l or onrelease l .
thus crsampler is able to avoid heavy tracking incurred by fetching lock objects and their vector clocks as well as the corresponding o n operations.
compared to datacollider crsampler does not rely on direct delay s to actually trigger race occurrences .
instead it checks races according to thread local clocks if any data breakpoint fire s. such race detection avoids direct delay caused overhead.
besides with a longer time limit crsamp ler does not incur a larger overhead however for datacollider its overhead is increased by the same fold of the increase in its time limit .
this is also verified by our experiments see section .
.
.
of course given the same scheduling and the same set of sampled memory accesses crsampler guarantees to detect all races detected by datacollider as each collision race is a clock race see theorem .
in practic e crsampler is able to detect more races as it does not delay any execution resulting in more memory accesses sampled see our experiment in section .
.
limitations like existing sampling based techniques crsampler also misses data races as expected.
crsampler utilizes thread local clocks to detect hb races.
it then suffers limitations suffered by hb race detectors.
one of such limitation s is the report of false positives two accessed are reported as an hb race but they cannot occur at the same time.
and data dependency is one factor.
that is two accesses form an hb race but the secon d access may depend on the value of the memory location of the first access.
however datacollider does not suffer from such a limitation as it only detects those data races occurring at the same time.
.
experiments this section presents the evaluation on crsampler cr for short .
we compared it with pacer and datacollider dc for short and indirectly compare d it with literace via pacer .
.
implementation and benchmarks implementation .
we have implemented dc and cr in jike s rvm a widely used research jvm .
pacer has also been implemented in jikes rvm and is available online we used its downloaded implementation.
the static sampling o f dc and cr is performed at java class loading time .
algorithm crsampler .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
input r a static sampling rate .
input p a multithreaded program .
input timelimit the max time on a data breakpoint.
let be a set of sampled instructions in p w.r.t r. let m be a map from an address to a pair t clock .
for each ins static sampling insertcall sample ins sample ins event e1 addr size iswrite parse ins if iswrite setdatabreakpointrw addr size else setdatabreakpointw addr size let t be the current thread m m addr t t.clock settimer addr timelimit unlike datacollider no delay ondatabreakpointfired addr event e2 let t be the current thread lastt hd lastclock maddr check clock races if t lastt hd lastclock lastt hd.clock reportdatarace ins cleardatabreakpoint addr maddr ontimer addr cleardatabreakpoint addr maddr onsync synchronization event s let t be the current thread t.clock t.clock unlike hbr no o n operations for dc and cr the use of data breakpoint s is only allowed at linux kernel .
we implemented them for java programs as depicted in figure for each sampled access the target address of the access is extracted within jikes rvm i.e.
core of dc c r .
it is passed to a user site agent implemented in the interface extension of th e jikes rvm and is then sent to linux kernel site via netlink communication netlink com.
.
at linux kernel site a data breakpoint is set on the given address.
once a data breakpoint fires a message is sent from the kernel site to the usersite agent and is then sent to dc cr.
both dc and cr set at most four breakpoints at a time as our experiment environment supports four data breakpoints.
another challenge is that u nlike c c java offers reference types and primitive types with automatic garbage collection but not direct pointer types .
therefore an add ress is not only accessed by application threads i.e.
those created by java applications but also accessed by java vm threads e.g.
on objects moving and garbage collection .
the latter kind of accesses does not incur data race s with accesses from application threads .
however it is impossible to identify and skip such accesses from vm threads at hardware level .
therefore once a data breakpoint fires dc cr extracts the native thread id i.e.
pthread on linux and checks whethe r such a thread is a java application thread or a java vm thread.
it discards a ny access from java vm threads.
benchmarks .
we selected a set of six multithreaded benchmarks from dacapo benchmark suit e that could be run correctly by jikes rvm.
these benchmarks include avrora xalan xalan sunflow pmd and eclipse where the subscripts and indicate their version number i.e.
or the version respectively .
table shows the statistics of these benchmarks including the binary size the number of threads and the number of dynamically collected synchronizations for each benchmark .
the last five columns show the number of data races detected by each technique.
the last row also shows the total number of data races detected by each technique.
.
experimental setup our experiment was performed on a workstation with an i7 4710mq cpu four cores 16g memory and 250g ssd.
the workstation was installed with ubuntu .
x86 system.
to evaluate cr we run six benchmarks under pacer dc and cr times for each samplin g rate from .
to .
with step .
.
note that unlike dc and cr pacer adopts dynamic sampling strategy.
we set three techniques to work at relatively low sampling rate s. this is because the three sampling techniques target to detect races at user sit es and their overhead should be low enough to be accepted by users.
f or pacer its overhead at sampling rate is already much higher i.e.
in than .
for dc it incurred nearly overhead at sampling rates in our experiment to be presented below .
as dc and cr adopt time limit mechanism we selected two time limit options ms millisecond and ms. note that the first one is the default option of dc .
we refer to the two options of dc and cr as dc15 dc30 and cr15 cr30 respectively.
.
experimental results we compare three techniques at their runtime overhead s total number s of races detected and per race detection abilit ies.
.
.
overhead figure shows the average overhead y axis of three techniques on all six benchmarks with i ncreasing sampling rate from .
to .
x axis .
figure a and b shows the overhead of three techniques on six benchmarks in detail .
note in both figure and figure we do not count and show the overhead of pacer on sunflow as on which pacer incurred an overhead from to nearly with sampling rate from .
to .
.
no evaluation of pacer on sunflow was reported in .
jikesrvmuser site agentkernel sitecpu set breakpointson firing user space kernel spacenetlink com.
core of dc c rexecution figure .
architecture of crsampler and datacollider .
a average overhead of three techniques b average overhead of pacer and crsampler figure .
average runtime overhead.
y .0749x .
r2 .9397y .529x .
r2 .9851y .46x .
r2 .
.
.
.
.
.
.
.
.
.
.
avereage overhead sampling rateavg.
overhead of three trendlinespacer dc15 dc30 cr15 cr30y .0749x .
r2 .
y .6312x .
r2 .
y .0859x .
r2 .
.
.
.
.
.
.
.
.
.
.
avereage overhead sampling rateavg.
overhead of pacer and crsampler trendlinespacer cr15 cr30 table .
the statistics of each benchmark and the number of total races detected by each technique.
bench marks binary size kb of threads of sync.
pacer dc15 dc30 cr15 cr30 avrora xalan xalan sunflow pmd eclipse sum for pacer with sampling rate it was reported to have detected more races .
for example on eclipse pacer detected races out of known races and races and on xalan pacer detected races out of known races and races .
average overhead.
figure a shows the average overhead of each technique .
figure b further shows the overhe ad comparison on cr and pacer .
the two figures also show the linear trendlines with both equations y kx b and goodness of fit r2 to indicate their trend s of overhead increase.
figure b also shows a dotted line indicating the overhead.
the trendline equations in figure a and b show that statistically dc has the largest overhead increasing factors i.e.
.
of dc30 and .
of dc15 .
particularly the increasing factors of dc30 is about two times of that of dc15 .
this further validates the fact that fo r dc an increase in its delay time also incurs the same fold increase in its overhead.
although the increasing factor of pacer i.e.
.
is less than one tenth of dc15 it is still significantly more than times larger than that of cr i.e.
.
and .
for cr15 and cr30 respectively .
from the two factors of cr we observe that even with a longer time limit but at the same sampling rate the overhead of cr does not increase but slightly dec rease s see the second point of section .
.
another insight from figure a and b is that statistically hardware based sa mpling has a s maller basic overhead i.e.
.
.
.
and .
of dc15 dc30 cr15 and cr30 than that i.e.
.
of pacer by tracking hbr.
and the basic overhead s of cr15 and cr30 are also the two least one s. overhead on each benchmark.
figure a shows the detailed overhead of three techniques on each benchmark where the legend of the subfigure avrora applies to all other subfigures .
from figure a we observe that at .
sampling rate all three techniques incurred relatively small overhead.
and most of their overheads are below where one exception is that dc15 and dc30 incurred more than .
and .
overhead on xalan .
however with i ncreasing sampling rate from .
to .
both dc15 and dc30 incurred significantly larger overhead.
this is expected as the delayed time of dc is directly added into its overhead as discussed in section .
whereas pacer cr15 and cr30 incurred a slight overhead incre ase with increasing sampling rate except on eclipse by pacer .
this slower increase shows the advantage of pacer and cr by defining data race based on synchronization tracking i.e.
hb r tracking by pacer and thread local clock tracking by cr instead of direct delaying .
although pacer has a linear increase on its overhead with increasing sampling rate its basic overhead is much larger than that of cr.
figure b where the legend of cr15 applies to all other subfigures further shows the comparison of pacer cr15 and cr30 on their overhead with increasing sampling rate .
from figure b we observe that pacer usually incurred from .
to .
overhead with .
sampling rate except on avrora where the overhead was about .
.
however the .
to a runtime overhead of three techniques b runtime o verhead of pacer and crsampler figure .
runtime overhead of three techniques on each benchmark .
overhead sampling rateavrora pacer dc15 dc30 cr15 cr30 overhead sampling ratexalan overhead sampling ratexalan overhead sampling ratesunflow overhead sampling ratepmd overhead sampling rateeclipse overhead sampling ratecr15 avrora xalan xalan sunflow pmd eclipse overhead sampling ratecr30 overhead sampling ratepacer .
overhead of pacer is much larger than .
with sampling rate increased fr om .
to .
the overhead of pacer increased to more than or even up to .
i.e.
on eclipse at .
sampling rate .
compared to pacer with .
sampling rate both cr15 and cr30 incurred less than overhead i.e.
.
.
.
.
and .
of cr15 .
.
.
.
.
and .
by cr30 or slightly above i.e.
.
on avrora by cr15 .
with sampling rate increased from .
to .
the largest overhead by cr15 and cr30 is .
except on xalan and avrora .
on these two benchmarks the largest overhead is .
.
at .
sampling rate the largest overhead is .
i.e.
on avrora by cr15 .
in summary from figure and figure we can see that cr incurred a much lower overhead than that by pacer and dc.
at .
sampling rate cr incurred less than or slightly over overhead on average which makes cr practical to be deployed at user sites.
.
.
total races detected total races detected in runs.
the last five columns of table show the total number of data r aces detected by pacer dc15 dc30 cr15 and cr30 in all their runs runs sampling rates .
as shown in table cr detected significantly more races than that detected by both pacer and dc.
and dc detected more races on some benchmarks but fewer races on other s than that by pacer .
note that on eclip se06 and xalan pacer with sampling rate was reported to have detect ed more races see the note of table .
however we focus on their race detection abilities and run time overhead at low sampling rate in this paper.
among all races detected by three techniques both pacer and dc missed a larger number of races detected by cr as shown in table .
however cr only missed four races detected by pacer and three races detected by dc.
all these races were from eclipse .
this is not a surprise as eclipse is a large scale program e.g.
table shows that its binary size is nearly ten times larger than that of others .
hence it requires more runs to detect more races from eclipse .
distinct races per runs with different sampling rates.
in our experiment we run each technique times under sampling rates .
figure shows t he number of distinct races detected in every runs under each of sampling rates.
the x axis firstly shows the six benchmarks and then shows sampling rates from .
to .
for each benchmark.
the y axis shows the number of distinct races detecte d. the legend of pacer in figure also applies to other subfigures.
from figure we observe that cr detected significantly more races than pacer and dc among most of runs.
this indicates that cr has a stronger ability to detect races in each run on average than pacer and dc.
on eclipse and xalan pacer detected an increasing number of races with increasing sampling rate indicated by our manually added trend like arrows for reference and on avrora xalan and pmd one or both of dc15 and dc30 also detected an increasing number of races.
however on other benchmarks both pacer and dc detected almost the same number of races with increasing sampling rates.
whereas cr detected an increasing number of races among all benchmarks except on avrora .
on avrora there are totally races detected by cr pacer and dc.
on this benchmark only cr15 detected an increasing number of races .
.
more discussion on dc and cr both dc and cr adopt time limit mechanism although their usages are different.
it is interesting that whether a longer time limit is better.
in our experiment we set two time limit s ms and ms. in this subsection we analy ze how different time limits affect the ir race detection abilities and their runtime overhead s. race detection under different time limit .
in theory w ith a longer time limit there are two effects on both dc and cr the total sampled accesses were reduced due to limited number of data breakpoints which may result in fewer races to be detected on the other hand with a longer time limit dc and cr could detect those races needing a longer time to expose.
as shown in table when the time limit was ms dc detected more races on sunflow and eclipse by and respectively .
on other benchmarks dc detected the same number of races.
however for cr there i s no consistent result .
on avrora xalan sunflow cr with ms detected less races by and respectively on xalan pmd and eclipse cr with ms detected more races by and respectively .
therefore it is difficult to say that a longer time limit may result in a better race detection even for dc.
actually previous work has pointed figure .
comparisons on the number of distinct races detected in every runs under different sampling rate s. avrora09 xalan06 xalan09 sunflow09 pmd09 eclipse06 of racespacer .
.
.
.
.
.
.
.
.
.
avrora09 xalan06 xalan09 sunflow09 pmd09 eclipse06 of racesdc15 avrora09 xalan06 xalan09 sunflow09 pmd09 eclipse06 of racesdc300102030405060 avrora09 xalan06 xalan09 sunflow09 pmd09 eclipse06 of racescr15 avrora09 xalan06 xalan09 sunflow09 pmd09 eclipse06 of racescr30 out that it is impossible to predict the time limit of dc and timing operations e.g.
instrumentation calls may increase the probability of a race occurrence but may also decrease it .
overhead under different time limit .
although there is no conclusion on whether a longer time limit may produce better race detection it s effect on overhead is much clea rer.
from figure it is obvious that dc with a longer time limit incurred a larger overhead .
in our experiment the first time limit is ms and the second one is ms which is twofold of the first one .
from the equations of trendlines in figure we could observe that for dc the overhead increas ing factor i.e.
.
at time limit of ms is nearly two times of the former i.e.
.
.
however from figure for cr there is no o bvious difference between the two time limit s as the two trendlines almost overlap with increasing sampling rate.
in detail cr30 incurred a slightly less overhead.
this is reasonable as with a longer time limit the increased time is not added into the overhead of cr however the total number of sampled accesses could be reduced resulting in less maintenance overhead.
that is an increasing time limit has no bad effect on the overhead of cr.
this further provides flexibility for developers to set a time limit according to their programs without any worry on overhead increase .
.
threats to validity our benchmarks are java pr ograms.
the jvm contains other threads accessing application memory locations.
although we have carefully compared whether two accesses were both from application threads some scenarios might be ignored in our implementation.
a more careful implementation may produce more precise results.
besides hardware breakpoints can only be accessed within linux kernel space.
so we adopt ed the netlink communication approach between user space and kernel space.
other communication approaches may produce different p erformance results that may also affect the effectiveness of crsampler and datacollider in the evaluation.
.
related work concurrency bugs widely exist in multithreaded programs including data races atomicity violations and deadlocks .
both static techniques and dynamic techniques aim to detect data races .
static ones are able to analyze a whole program but are imprecise due to lack of runtime information .
dynamic ones detect data races from execution traces.
they either rely on the strict locking discipline i.e.
lockset or the relatively precise happens before relation including its improvement .
however dynamic detection usually incurs heavy overhead .
existing s ampling techniques aim to detect races at user site s by incurring much low er overhead w hich is the focus of this paper.
systematic scheduling techniques such as model checking are in theory able to exhaustively execute every schedule to achieve certain coverage .
however due to the state explosion problem enumerating each schedule is not practical for real world programs even with reduction techniques .
chess sets a heuristic bound on the number of pre emption s to explore the schedules.
also although systema tic approaches avoid executing previously explored schedules they usually incur large overhead s and fail to scale up to handle long running programs.
for example maple is a coverage driven tool to mine thread interleaving so as to expose unknown concurrency bugs.
pct randomly schedules a program to expose concurrency bugs which also requires large number of executions.
however it is diffi cult to apply these techniques to large scale prog rams e.g.
eclipse in our experiment .
rvpredict achieve s a strictly higher coverage than hbr based detectors .
it firstly predicts a set of potential races and then relies on a number of production executions to check against each predicted race.
racageddon aims to s olve races that could be predicted in one execution but require different inputs.
it still needs a larger number of execution s to ch eck against each predicted race .
both rvpredict and racageddon have to solve scheduling constraints for each predicted race which may fail.
a recent work drfinder tries to expose races hidden by the happens before relation.
it dynamically predicts and tries to reverse happens before relations from observed executions.
however it s active scheduling is also heavy e.g.
about .
racemob statically detect s data race warnings and distribut es them to a large number of user s to validate real races.
in such a run the schedules are guided by the set of data race warnings to trigger real data races.
this kind of approach is able to confirm real races but cannot eliminate false positives.
besides it may miss real races if such races are not predicted in the static prediction phase.
cci proposes cross thread sampling strategies to find causes of concurrency bugs based on randomized sampling .
unlike race sampling techniques e.g.
crsampler datacollider pacer and literace cci focuses on failure diagnosis.
however cci may cause heavy over head e.g.
up to although it targets on lightweight sampling .
carisma improves pacer by further sampling memory locations allocated at the same program locati on for java program.
carisma could be integrated into crsampler to improve its effectiveness.
recbulc also adopts thread local clocks time stamps to reproduce concurrency bugs.
unlike crsampler recbulc requires concrete objects and may still incur large overhead if applied to race sampling .
recently race detection ha s been extended to even driven applications concurrent librar y invocations and modified program codes .
crsampler could also be adapted to detect these races.
we leave it as future work.
.
conclusion existing sampling techniques for race detection still incur high overhead even with sampling rates and or detect races only when they occur by delay ing program executions.
we have proposed a new data race definition i.e.
clock races for race sampling purpose .
detection of clock races avoid s o n operations and concrete synchronization objects which hence incurs a much lower overhead.
we also propose d crsampler to sample clock races via hardware support.
the experiment on six benchmarks confirms that crsampler is both efficient and effective on race detection via sampling.
at sampling rate it only incurs nearly overhead indicating that crsample r is suitable to be deployed at user site for race detections .
.
acknowledgement we thank anonymous reviewers for their invaluable comments and suggestions on improving this work.
this work is supported in part by national program of china 2014cb340702 and national natural science foundation of china nsfc grant no.
and .
.
reference netlink communication between linux user space and kernel space.
pages man7 netlink.
.html jikes research archive.
jikes rvm .
.
.
j. jackson.
nasdaq s facebook glitch came from race conditions may .
it nasdaq sfacebook glitch came from race conditions .html last visited on march .
b. alpern c.r.
attanasio a. cocchi d. lieber s. smith t. ngo j.j. barton s.f.
hummel j.c. sheperd and m. mergen.
implementing jalape o in java.
in proc.
oopsla .
s. biswas m. zhang and m.d.
bond.
lightweight data race detection for production runs.
ohio state cse technical report osu cisrc tr01 january .
pages available at state.edu mikebond litecollider tr.pdf e. bodden and k. havelund.
racer effective race detection using aspect j. in proc .
issta .
m.d.
bond k. e. coons and k. s. mckinley.
pacer proportional detection of data races.
in proc.
pldi .
s.m.
blackburn r. garner c. hoffmann a.m. khang k.s.
mckinley r. bentzur a. diwan d. feinberg d. frampton s.z.
guyer m. hirzel a. hosking m. jump h. lee j. eliot b. moss a. phansalkar d. stefanovi t. vandrunen d. von dincklage and b. wiedermann.
the dacapo benchmarks java benchmarking development and analysis.
in proc .
oopsla .
a. bron e. farchi y. magid y. nir and s. ur.
applications of synchronization coverage.
in proc .
ppopp .
s. burckhardt p. kothari m. musuvathi and s. nagarakatte.
a randomized scheduler with probabilistic guarantees of finding bugs.
in proc .
asplos .
y. cai and l. cao.
effective and precise dynamic detection of hidden races for java programs.
in proc.
esec fse .
y. cai and w.k.
chan.
loft redundant synchronization event removal for data race detection.
in proc.
issre .
y. cai and w.k.
chan.
lock trace reduction for multithreaded programs.
ieee transactions on parallel and distributed systems tpds .
y. cai and w.k.
chan.
magiclock scalable detection of potential deadlocks in large scale multithreaded programs.
ieee transactions on software engineering tse .
d. di mitro v. raychev m. vechev and e. koskinen.
commutativity race detection.
in proc.
pldi .
j. erickson m. musuvathi s. burckhardt and k. olynyk.
effective data race detection for the kernel.
in proc.
osdi .
m. eslamimehr and j. palsberg.
race directed scheduling of concurrent programs.
in proc .
ppopp .
c. flanagan and s. n. freund.
fasttrack efficient and precise dynamic race detection.
in proc .
pldi .
c. flanagan and p. godefroid .
dynamic partial order reduction for model checking software.
in proc.
popl .
s. hong j. ahn s. park m. kim and m.j. harrold.
testing concurrent programs to achieve high synchronization coverage.
in proc .
issta .
s. hong y. park and m. kim.
detecting concurrency errors in client side java script web applications .
in proc .
icst .
c. hsiao y. yu s. narayanasamy z. kong c.l.
pereira g.a.
pokam p.m. chen and j. flinn.
race detection for event drive n mobile applications.
in proc.
pldi .
j. huang p.o.
meredith and g. rosu.
maximal sound predictive race detection with control flow abstraction.
in proc .
pldi .
g. jin a. thakur b. liblit and s. lu.
instrumentation and sampling strategies for cooperative concurrency bug isolation.
in proc .
oopsla .
v. kahlon y. yang s. sankaranarayanan and a. gupta.
fast and accurate static data race detection for concurrent programs.
in proc.
cav .
b. kasikci c. zamfir and g. candea.
racemob crowdsourced data race detection.
in proc .
sosp .
p. krishnan.
hardware breakpoint or watchpoint usage in linux kernel.
ibm linux technology center canada july .
l. lamport .
time clocks and the ordering of events.
communications of the acm .
z. letko t. vojnar and b. k rena.
coverage metrics for saturation based and search based testing of concurrent software.
in proc.
rv .
n.g.
leveson and c. s. turner.
an investigation of the therac accidents.
computer .
s. lu s. park e. seo and y.y.
zhou learning from mistakes a comprehensive study on real world concurrency bug characteristics.
in proc .
asplos .
b. lucia and l. ceze.
cooperative empirical failure avoidance for multithreaded programs.
in proc .
asplos .
.
p. maiya a. kanade and r. majumdar.
race detection for android applications.
in proc .
pldi .
d. marino m. musuvathi a nd s. narayanasamy.
literace effective sampling for lightweight data race detection.
in proc .
pldi .
m. musuvathi s. qadeer t. ball g. basler p. a. nainar and i. neamtiu.
finding and reproducing heisenbugs in concurrent programs.
in proc.
osdi .
m. naik a. aiken and j. whaley.
effective static race detection for java.
in proc.
pldi .
s. nagarakatte s. burckhardt m. m.k.
martin and m. musuvathi.
multicore acceleration of priority based schedulers for concur rency bug detection.
in proc .
pldi .
s. narayanasamy z. wang j. tigani a. edwards and b. calder.
automatically classifying benign and harmful data races using replay analysis.
in proc .
pldi .
e. pozniansky and a. schuster.
efficient on the fly data race detection in multithreaded c programs.
in proc .
ppopp .
p. pratikakis j.s.
foster and m. hicks.
locksmith context sensitive correlation analysis for race detection.
in proc.
pldi .
c.s.
park k. sen p. hargrove and c. iancu.
efficient data race detection for distributed memory parallel programs.
in proc.
sc .
k. poulsen.
software bug contributed to blackout.
feb. .
a.k.
rajag opalan and j. huang.
rdit race detection from incomplete traces.
in proc .
esec fse .
s. savage m. burrows g. nelson p. sobalvarro and t. anderson.
eraser a dynamic data race detector for multithreaded programs.
acm tocs .
k. sen. race directed random testing of concurrent programs.
in proc .
pldi .
k. serebryany and t. iskhodzhanov.
threadsanitizer data race detection in practice.
in proc.
wbia .
y. smaragdakis j. evans c. sadowski j. yi and c. flanagan.
sound predictive race detection in polynomial time.
in proc .
popl .
f. sorrentino a. farzan and p. madhusudan.
penelope weaving threads to expose atomicity violations.
in proc .
fse .
k. vineet and c. wang.
universal causality graphs a precise happens before model for detecting bugs in concurrent programs.
in proc .
cav .
j.w.
voung r. jhala and s. lerner.
relay static race detection on millions of lines of code.
in proc.
fse .
c. wang k. hoang.
precisely deciding control state reachability in concurrent traces with limited observabil ity.
in proc .
vmcai .
c. wang m. said and a. gupta.
coverage guided systematic concurrency testing.
in proc.
icse .
x.w.
xie and j.l.
xue.
acculock accurate and efficient detection of data races.
in proc .
cgo .
j. yu s. narayanasamy c. pereira and g. pokam.
maple a coverage driven testing tool for multithreaded programs.
in proc .
oopsla .
t. yu w. srisa an and g. rothermel.
simrt an automated framework to support regression testing for data races.
in proc .
icse .
y. yu t. rodeheffer and w. chen.
racetrack efficient detection of data race conditions via adaptive trac king.
in proc .
sosp .
x. yuan c. wu z. wang j. li p.c.
yew j. huang x. feng y. lan y. chen and y. guan.
recbulc reproducing concurrency bugs using local clocks.
in proc .
icse .
k. zhai b.n.
xu w.k.
chan and t.h.
tse .
carisma a context sensitive approach to race condition sample instance selection for multithreaded applications.
in proc .
issta .
w. zhang m. d. kruijf a. li s. lu and k. sankaralingam.
conair featherweight concurrency bug recovery via single threaded idempotent execution.
in proc .
asplos .
.