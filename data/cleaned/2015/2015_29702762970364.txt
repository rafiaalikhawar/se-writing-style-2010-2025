symbolic execution of complex program driven by machine learning based constraint solving xin li y ongjuan liang hong qian yi qi hu lei bu y ang yu xin chen and xuandong li state key laboratory for novel software technology department of computer science and technology nanjing university nanjing jiangsu p .r.china bulei yuy nju.edu.cn abstract symbolic execution is a widely used program analysis technique.
it collects and solves path conditions to guide the program traversing.
however due to the limitation of the current constraint solvers it is di cult to apply symbolic execution on programs with complex path conditions like nonlinear constraints and function calls.
in this paper we propose a new symbolic execution tool mlb to handle such problem.
instead of relying on the classical constraint solving in mlb the feasibility problems of the path conditions are transformed into optimization problems by minimizing some dissatisfaction degree.
the optimization problems are then handled by the underlying optimization solver through machine learning guided sampling and validation.
mlb is implemented on the basis of symbolic pathfinder and encodes not only the simple linear path conditions but also nonlinear arithmetic operations and even black box function calls of library methods into symbolic path conditions.
experiment results show that mlb can achieve much better coverage on complex realworld programs.
ccs concepts software and its engineering !software testing and debugging keywords symbolic execution machine learning complicated path condition constraint solving this work is supported by the joint nsfc isf research program jointly funded by the national natural science foundation of china and the israel science foundation no.
the national natural science foundation of china no.
no.
no.
jiangsu science foundation bk20160066 and the microsoft research asia collaborative research program.
.
introduction symbolic execution is a widely employed program analysis technique which executes programs with symbolic inputs.
in the process of symbolic execution a path condition which is a conjunction of symbolic constraints is maintained and gets updated whenever the program executes a branch instruction.
concrete inputs triggering the corresponding path can then be generated by constraint solving .
the processing capability of symbolic execution is heavily relied on the underlying constraint solver.
it is well known that even strong smt solvers like isat and z3 can not handle complex nonlinear constraints well not to mention the black box library methods or even native methods in real case codes.
the simple example shown in figure can be a typical representative of such programs.
to cover the path of line and symbolic execution needs to nd a solution that satis es the corresponding ifstatements in line z x and line x y y x x y .
however the nonlinear arithmetic operation x y y x x y may be di cult for most of the existing solvers.
besides the calculation of zwhich needs the function call long numberofleadingzeros x is also a great challenge since normal constraint solvers have no idea to deal with the uninterpreted item.
1public class programf 2public static void example long x double y f double z long.numberofleadingzeros x library method if z x if x y y x x y nonliner arithmetic operation assert false 7g 8public static void main string args f long parm1 long.parselong args double parm2 double.parsedouble args example parm1 parm2 12g 13g figure a simple java program with complicated path conditions to handle such programs with complicated constraints intensive investigations have been conducted.
concolic testing tries to go through the complex path conditions by replacing complicated symbolic terms of them with concrete values.
unfortunately such simpli cation also decreases the probability to nd more desired solutions.
heuristic search is a new trend.
it nds the solutions that satpermission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
copyrights for components of this work owned by others than acm must be honored.
abstracting with credit is permitted.
to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
request permissions from permissions acm.org.
ase september singapore singapore c acm.
... .
isfy the constraints with the help of heuristics like genetic algorithms ga tabu search etc.
these approaches perform well in dealing with certain problems revealing the potential of such direct search methods.
however the capacity of these heuristic methods is little understood and the con gurations of these approaches are hard to set to achieve stable performance.
in this paper we present a new symbolic execution tool mlb which is driven by machine learning based constraint solving to handle the complicate programs discussed above.
first mlb encodes all the di cult operations including nonlinear constraints mathematical methods e.g.
sin log oating point symbolic variables and the library method calls as uninterpreted symbolic constraints.
then di erent from existing tools mlb transforms the feasibility problems of the path conditions into optimization problems.
a recently introduced machine learning based optimization technique racos is adopted to solve the optimization problems.
racos has a solid theoretical foundation for complex optimization problems.
it basically samples solutions from a learning model updates the model from the feedback of the solutions and continues this iteration to nd better solutions.
mlb adapts racos by using the dissatisfaction degree as the feedback of the sampled solutions and thus racos converges to feasible path conditions as quickly as possible.
mlb is implemented on the basis of java symbolic execution engine symbolic pathfinder .
to evaluate the performance of mlb intensive case studies are conducted to generate test cases for real case programs with a total number of methods full of nonlinear operations oating point arithmetic and even native method calls.
the experimental results prove that our tool outperforms the other state of the art tools in terms of both e ectiveness and e ciency.
furthermore it is worth to note that unlike most of the existing tools mlb is fully automatic that users do not have to modify any single line of their code to use our tool which means great convenience.
the rest part of this paper is organized as follows.
the background of machine learning based constraint solving is introduced in section .
section introduces the symbolic execution architecture of mlb and presents how mlb encodes complex program behaviors as symbolic constraints and solves them by machine learning.
the implementation of mlb and the intensive case studies are introduced in section .
the related works are discussed in section .
section is the conclusion of the paper.
.
machine learning based optimization method as mentioned above the major obstacle in applying symbolic execution to real world programs is the capability of constraint solving which targets of nding solutions to make all constraints satis able.
the problem is closely related with the optimization problem nding solutions to minimize the dissatisfaction degree.
however the optimization problem for general complex constraints is usually quite complex too.
one kind of solving techniques suitable for complex optimization tasks are derivative free methods.
they use only the information of solution evaluations instead of the objective function gradients and thus are not misled by e.g.
gradients on complexoptimization tasks.
they commonly consist of an iteration of two key steps sample solutions from a model initially the uniform sampling from the solution space and update the model from the objective function values of the sampled solutions.
many derivative free methods have been proposed e.g.
.
unfortunately most of these methods have little theoretical foundation due to the di culty of analysis.
very recently a machine learning based optimization method named racos was developed with solid theoretical ground of which the required number of samples is well upper bounded in the approximation quality of the nal solution.
this new machine learning based algorithm employs a hyper rectangle classi er as its model.
better solutions can be distinguished from the worse ones by training the classier according to the objective function values of the sampled solutions through covering all better solutions within the hyper rectangle.
the classi er once been trained produces a hyper rectangle in the solution space which indicates the region that contains better solutions.
the solutions for the next iteration are then sampled from the hyper rectangle.
the simplicity of this hyper rectangle classi er model allows the algorithm to be well analyzed.
the analysis indicates that to achieve a high optimization e ciency the classi er should be highly randomized and the region of better solutions should be small .
the new algorithm racos is accordingly designed.
this new machine learning based algorithm has remarkable merits comparing with other derivative free optimization methods.
besides its solid theoretical foundation it has also been empirically veri ed to have high e cacy and high e ciency particularly in high dimensions ranged up to thousands with default algorithm parameters.
it supports optimization tasks with continuous discrete and mixed variables and it almost has no parameters to adjust.
.
technique under mlb to overcome the limitations of the classical symbolic execution mlb adapts the classical symbolic execution framework with a new sampling validation style machine learning based solving as reviewed in section .
the main work ow of mlb figure is as follows the underlying machine learning solver proposes a valuation sample.
the upper layer symbolic execution engine validates the guessed sample by direct execution.
the solver converges to the correct answer by analyzing the validation feedback using machine learning.
dissatisfaction functionsymbolic execution engine path condition samples feedbackevaluated result learning figure machine learning based solving under mlb 555in order to ful ll the work ow and take advantage of the new machine learning based optimization technique racos to handle more complex programs two main techniques underlying mlb are presented below transform the feasibility problem of the path condition to optimization problem to take advantage of the machine learning based method.
enrich the path condition by encoding library method calls as uninterpreted path conditions which can be handled in the sampling validation style.
.
dissatisfaction function oriented path condition optimization to apply the machine learning based optimization technique racos mlb transforms the feasibility problem of a path condition into an optimization problem through the dissatisfaction function so that a sampling validation style solving can be conducted.
given a path condition with the conjunction of nconstraints ci i n we de ne a dissatisfaction degree difor each ci.diis used to measure how badly a sample violates the constraint ci.
for example the most straightforward way for de ning diis that if ciis satis able by a valuation sample s then di otherwise di .
then we can generate a dissatisfaction function df n i 1di to measure the total distance from the evaluated valuation sample sto a correct solution of the path condition.
to accelerate the convergence speed mlb calculates the dissatisfaction degree as the formula shown below where opi is the comparator of ciandleft istands for the left expression value of it while right iis the right expression value.
in detail di if s satis es ci if s dissatis es ciandopiis6 jleft i right ij if s dissatis es ciandopiis not6 clearly when the dissatisfaction function result is the path condition is satis ed.
in this manner we transform the feasibility problem of the path condition into an optimization problem to minimize the dissatisfaction function so that the machine learning based optimization solving method reviewed in section can be used to analyze the complex path conditions in mlb.
.
library call related path condition generation to support the diverse and complex codes in the real world mlb generates more comprehensive path conditions during program analysis.
the details of the path conditions enhanced in mlb are described as follows.
in the classical symbolic execution the handling of thirdparty library method is always a big challenge.
the reason is that it is di cult to present the third party library method calls as simple mathematical constraints since the contents of the library methods are often uninterpreted.
luckily in our machine learning style solving the speci c contents are not indispensable.
actually all the constraints in the optimization program can be handled in a black box style.
the symbolic execution engine can validate them by executing the corresponding statements with the sample guessed directly without knowing the deep detail.therefore in mlb each library method call is presented as an uninterpreted constraint where the function name is treated as the uninterpreted operator in the constraint and the input arguments of the function call consistitue the symbolic variables in this library method pc.
take the code in figure for example statement z x needs a function call long numberofleadingzeros x .
mlb will generate a library method pc long numberof leadingzeros x xfor it.
suppose the sample is x we call the method with argument x directly and get the return value .
then the result is used to calculate the dissatisfaction degree value.
actually all the function calls in the program can be encoded as uninterpreted symbolic constraints and processed in such a black box manner.
as a result mlb can provide users black box options to mark speci c functions as blackbox.
then mlb will avoid going through the detail of the speci c functions and increase the e ciency.
besides of the library call related pc another special class of pc domain related pc is generated in mlb.
the main idea is that samples proposed by the underlying solver may violate the path condition s domain requirement and cause exceptions.
therefore mlb analyzes the basic constraint rst and adds special constraints to make sure the proposed sample does not violate the domain requirement.
for example mlb generates y6 for x y y x x y in statement figure .
due to the space limitation the detail of domain related pc generation is omitted here.
.
implementation and evaluation this section presents the implementation and performance evaluation of mlb.
the implementation and all the data used in the evaluation are available from github https github.com mlb se.
machine learning based solvinguser configurationoutput reporter jpf symbcjpf nhandler spf jpf core figure mlb tool architecture .
implementation mlb is implemented on the basis of symbolic pathfinder spf which is a java symbolic execution engine based on java pathfinder jpf .
the architecture of mlb is shown in fig.
.
the classical program traversing core in spf provides symbolic path condition generation for the execution semantics.
mlb adapts it with more comprehensive path condition generation including the library method call related pc and domain related pc as mentioned in section .
to make mlb easier to use we intergrate jpf nhandler into mlb to execute the complex path conditions with native methods more e ciently.
the jpf nhandler module delegates the execution of the native methods as it provides 556the necessary information of them for mlb to generate the uninterpreted constraints.
to solve the collected path conditions the classical constraint solving is replaced by a new sampling and validation style machine learning based constraint solving module.
a generic interface is created for the frequent interaction between the symbolic execution core and the machine learning based solver.
information required during the sampling and validation iterations is transmitted through the interface so that valid solutions can be quickly found and referred to the exploring process.
additionally we employed and updated the convenient publisher system of spf to provide the program analysis data and produce test cases from the solutions.
users can fetch these data easily and analyze them with the help of other o the shelf tools freely.
for example following the merits of mlb supports the automatic invoking of jacoco1coverage measuring library to demonstrate the coverage reached by the generated test cases.
.
tool usage .
target program target class under test .
classpath project main class file path of the target class .
symbolic.method program.example sym sym target method under test .
symbolic.dp csp default solver setting .
symbolic.mlpm default sample size .
using jpf nhandler call jpf nhandler .
nhandler.delegateunhandlednative true call jpf nhandler .
nhandler.spec.skip java.lang.long.numberofleadingzeros set the speci c function in the black box mode figure con guration of mlb for the example in fig.
except the special capability of handling complex programs with complicated constraints and library method calls another key feature of mlb is the user friendliness.
mlb is a fully automatic symbolic execution engine for java.
unlike most of the existing tools users only need to con gure our tool expediently before analysing their codes.
mlb does not require users to modify any single line of their codes.
figure presents an illustration of the con guration for the code shown in figure to use mlb.
as mlb is implemented on the basis of spf it shares the con guration style of spf.
line in figure show the necessary settings required by spf for declaring the target.
it points out the target under test is the method example in class program .
line sets the constraint solver under mlb to csp which implements racos algorithm .
line is the optional parameter for mlb to set the sample size of each round for csp to .
in another word csp guesses valuations each round and presents them to mlb to validate.
if users do not set the parameter the default value is .
it is worth to note that this is the only parameter that relates to the performance of the underlying machine learning solver.
for running the speci c function call java.lang.long.numbe rofleadingzeros line are added to call the extension jpf nhandler.
more speci cally line tells mlb to encode and analyze the function as an uninterpreted function in a black box mode.
benchmark for the experiments program operations method loc from coraltrigonometric functions logarithms polynomials86 dart polynomials required over ow hash polynomial shift bit wise xor opti exponentials square roots power exponential function ray polynomials dot product sine float to bit vector conversion stat mean and std.
dev.
computation tcas constant equality checks tsafe trigonometric functions airypolynomials square roots logarithms11 bess polynomials square roots caldatpolynomials trigonometric functions6 ellpolynomials square roots trigonometric functions31 gamlogarithms factorials exponentials21 ranpolynomials exponentials xor logarithms square roots13 furthermore as mentioned before mlb also provides template script les following the format of to automatically run the test cases and invoke jacoco to generates visualized coverage reports.
with the help of the script les and the con guration les users can get the detail coverage report with a push button style user experience.
more details can be found on the github link mentioned before.
.
evaluation setup to evaluate the performance of mlb a variety of programs are used mainly from sets of real case benchmarks.
the rst set of programs is from study consisting of di erent kinds of nonlinear operations in real tool distributions2.
the second set of the benchmarks is selected from the classical numerical computation book numerical recipes .
typical pointer free scienti c computing functions whose constraints contain nonlinear computation and function calls are chosen as benchmarks and divided into programs in accordance of the structure of the book.
the basic information of the benchmarks is listed in table.
.
in our experiments mlb and state of the art symbolic execution tools are used to conduct test case generation on all the benchmarks.
then we use the jacoco coverage measuring library to measure the instruction branch and line coverage achieved by every competitors.
each tool is repeated for times to eliminate the randomness.
to prevent small programs from dominating the mean coverage of the tools we weight each program s contribution with different metrics when computing the arithmetic mean on this speci c metric.
the competitors used in the experiments including jcute spf mixed spf coral and con2please refer to for the detail introduction of these programs.
also note that the line of codes loc listed in table is di erent from the table in as that the loc values reported here are counted by jacoco where useless lines like blank lines are not counted as valid lines by jacoco.
557colic walk cw .
these tools stand for di erent classes of symbolic execution methods for example concolic testing heuristic searching and so on.
all the experiments are conducted on a desktop running ubuntu .
lts with .10ghz intel core i5 and 4gb ram with time limit seconds per method.
.
experimental study mlb s performance is evaluated on the aspects of both e ectiveness and e ciency as follows.
e ectiveness analysis instr.
branch line jcute spf mixed spf coral concolic walk mlb figure weighted coverage reports as described above weighted coverage is used as the main indicator of e ectiveness analysis.
the data on all the programs with respect to di erent metrics is summarized in figure .
while computing the arithmetic mean over all the programs the respective metric weight factor is introduced to prevent small benchmarks dominating the coverage.
for example for line coverage we use the line of codes as weight while for branch coverage the number of branches is treated as the weight.
it is clear that mlb outperforms all the other competitors signi cantly on all the coverage metrics.
as seen from figure mlb s instruction coverage ranges from .
times of cw to .
times of spf mixed .
this set of experiments strengthens our belief that by the help of machine learning based solving technique mlb can handle the symbolic execution of complex nonlinear programs e ectively.
e ciency analysis .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
instr.
branch line jcute spf mixed spf coral concolic walk mlb figure weighted e ciency reports the second aspect evaluated in the experiment is e ciency.
to evaluate the e ciency of mlb we use the coverage including instruction branch and line achieved per unit of generation time as the metrics.
similar with figure wecompute the average e ciency over all the benchmarks of every tool and summary the results in figure .
overall mlb achieves better performance than other competitors.
in case of instruction e ciency mlb .
s ranges from .
times as e cient as cw .
s to .
times of spf mixed .
s .
the branch e ciency shares the similar results.
for line e ciency mlb is more e cient than other tools except for jcute.
though jcute .
s is as e cient as mlb .
s mlb achieves much higher line coverage than jcute vs .
processing of library method call as described in section mlb is able to handle library method calls in a black box mode by encoding them as uninterpreted constraints.
to assess this special capability of mlb we replace the mathematical methods in coral with the methods in the widely used mathematics and statistics library the apache commons math3.
then we use mlb to generate test cases for the modi ed coral in the black box mode.
as symbolic pathfinder can load the library method calls and execute the instructions one by one we conduct the classical whitebox analysis on this program as well.
the result is quite interesting.
mlb achieves branch coverage in .
seconds with black box mode.
however if we run mlb in the classical white box mode in another word traversing each line of instructions in the library method the branch coverage drops to with even much longer time seconds.
the reason is that in the classical white box mode we have to go through the complete structure of the methods called step by step.
while in the black box mode we compact the third party function calls as uninterpreted symbolic constraints and solve them directly.
thus we can put the resource in the traversing of the main program itself to achieve higher coverage.
.
related work in the areas of software engineering symbolic execution tools including klee spf pex and so on play an important role in many program analysis cases.
it is well recognized that the applicability and scalability of these tools rely heavily on the underlying constraint solver.
however it is di cult for existing constraint solvers like z3 to handle complex path conditions involving nonlinear operations and library method calls which appear commonly in real world programs.
for solving those complex path conditions several mitigation strategies are proposed.
as one typical representative of simpli cation based approaches concolic testing which has been used in jcute and spf mixed tries to handle complex path conditions by replacing complex terms with concrete values.
besides there are also other approaches which substitute nonlinear constraints by linear envelopes e.g.
to abstract the state space and make it solvable by linear constraint solvers.
unlike the simpli cationbased solving with the abstraction of the search space mlb encodes all the complex behaviors as they are and guides the solver to converge to the correct answer e ciently.
as used in coral solver and cw algorithm search based approaches perform symbolic execution in a heuristic search style.
for example particle swarm opti3 558mization and tabu search are used to solve complex path conditions in the above works.
however these heuristic search algorithms are commonly weak in their theoretical foundation which blocks the rational understandings of their optimization performance.
in contrast the machine learning based algorithm adapted in mlb is theoretically grounded ensuring the stable and great performance of the tool.
last but not least on the implementation level most of the existing tools e.g.
require users to modify their code according to certain regulations rstly before starting the analysis.
while in mlb users can feed their code to the tool directly which improves the ease of use signi cantly.
.
conclusions in this paper we propose a new java symbolic execution tool mlb which is supported by a machine learning based optimization solving technique.
di erent from existing works the solver under mlb works with the symbolic execution core in a sampling validation and learning style interaction loop.
in this manner mlb supports the symbolic execution of not only simple codes with linear path conditions but also complex real world programs with complicated nonlinear constraints and calls of library methods.
mlb is an automatic tool implemented on the basis of spf jpf nhandler and jacoco.
therefore mlb can be used to analysis complex java codes with library methods and can get the coverage report directly without changing any line of the code.
an intensive set of case studies on realworld case programs shows that mlb supports a wide range of well known di cult real world programs with outstanding e cacy and e ciency.
.