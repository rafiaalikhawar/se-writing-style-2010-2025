deeproad gan based metamorphic testing and input validation framework for autonomous driving systems mengshi zhang university of texas at austin usa mengshi.zhang utexas.eduyuqun zhang shenzhen key laboratory of computational intelligence department of computer science and engineering southern university of science and technology china zhangyq sustc.edu.cnlingming zhang university of texas at dallas usa lingming.zhang utdallas.edu cong liu university of texas at dallas usa cong utdallas.edusarfraz khurshid university of texas at austin usa khurshid utexas.edu abstract whiledeepneuralnetworks dnns haveestablishedthefundamentals of image based autonomous driving systems they may exhibit erroneous behaviors and cause fatal accidents.
to address the safetyissuesinautonomousdrivingsystems arecentsetoftesting techniques have been designed to automatically generate artificial drivingscenestoenrichtestsuite e.g.
generatingnewinputimages transformed from the original ones.
ho wever these techniques are insufficientduetotwolimitations first manysuchsyntheticimages oftenlackdiversityofdrivingscenes andhencecompromisetheresulting efficacy and reliability.
second for machine learning basedsystems a mismatch between training and application domain can dramaticallydegrade systemaccuracy suchthat itis necessaryto validate inputs for improving system robustness.
in this paper we propose deeproad an unsupervised dnnbasedframeworkforautomaticallytestingtheconsistencyofdnnbased autonomous driving systems and online validation.
first deeproad automatically synthesizes large amounts of diverse driving scenes without using image transformation rules e.g.
scale shearandrotation .inparticular deeproadisabletoproducedriving scenes with various weather conditions including those with ratherextremeconditions byapplyinggenerativeadversarialnetworks gans along with the corresponding real world weather scenes.
second deeproad utilizes metamorphic testing techniques this work was partially accomplished during visit to southern university of science and technology yuqun zhang is the corresponding author permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation on the first page.
copyrights for components of this work owned by others than acmmustbehonored.abstractingwithcreditispermitted.tocopyotherwise orrepublish topostonserversortoredistributetolists requirespriorspecificpermissionand ora fee.
request permissions from permissions acm.org.
ase september montpellier france association for computing machinery.
acm isbn ... .
third deeproad validates input images for dnn based systems bymeasuringthedistanceoftheinputandtrainingimagesusing their vggnet features.
we implement deeproad to test three wellrecognized dnn based autonomous driving systems in udacity self drivingcarchallenge.theexperimentalresultsdemonstrate that deeproad can detect thousands of inconsistent behaviors for thesesystems andeffectivelyvalidateinputimagestopotentially enhance the system robustness as well.
ccs concepts software and its engineering software testing and debugging keywords software testing test generation input validation deep neural networks acm reference format mengshi zhang yuqun zhang lingming zhang cong liu and sarfraz khurshid.
.
deeproad gan based metamorphic testing and input validation framework for autonomous driving systems.
in proceedings of the 33rd acm ieee international conference on automated software engineering ase september montpellier france.
acm new york ny usa 11pages.
introduction thetraincameoutofthelongtunnelintothesnow country.theearthlaywhiteunderthenightsky.the train pulled up at a signal stop.
yasunari kawabata snow country theabovequotationisfromthefirstparagraphoffiction snow country which describes the scene when the protagonist shimamura enters the snow country.
back to that time train was the major vehicle for long distance travels while people have more choices today.
now suppose shimamura takes a tesla in autopliot mode after coming out of the tunnel there raises a question authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
ase september montpellier france m. zhang y. zhang l. zhang c. liu and s. khurshid can the autopilot system operate safely on the snow covered road or the story just ends with a tragedy?
autonomous driving is expected to transform auto industry.
typically autonomous driving refers to utilizing sensors cameras radar lidar gps etc toautomaticallycontrolvehicleswithout humanintervention.therecentadvancesindeepneuralnetworks dnns enable autonomous driving systems to adapt their driving behaviorsaccordingtodynamicenvironments .inparticular an end to end supervised learning framework is made possible totrainadnnforpredictingdrivingbehaviors e.g.
steeringangles by inputing driving images using angbracketleftdriving image driving behavior angbracketrightpairs as training data.
for instance dave releasedbynvidiain2016 canaccuratelypredictsteeringangles basedononlyimagescapturedbyasinglefront centeredcamera of autonomous cars.
recenttestingtechniques demonstratethattheautonomous driving systems are error prone to synthetic images of driving scenes.
deepxplore applies differential testing technique to systematically generate images which disclose the inconsistent behaviors of multiple dnn systems.
specifically it formulates the image generation problem as a joint optimization problem which uses gradient based search techniques to find images for maximizing neuron coverage and the number of inconsistent behaviors of suchsystems.
deeptest designs systematicwaysto automaticallygeneratetestcases seekingtomimicreal worlddrivingscenes.
its main methodology is to transform labeled images of driving scenesbyapplyingsimpleaffinetransformationsandvariouseffectfilterssuchasblurring fog raintotheoriginalimages andcheckif theautonomousdrivingsystemsperformconsistentlyamongthe original and transformed scenes.
with large amounts of originaland transformed driving scenes deeptest can detect various erroneousdrivingbehaviorsforsomewell performedopen source autonomous driving models in a cheap and quick manner.
however we observe that the methodologies applied in deepxploreanddeeptesttogeneratetestcasesmaynotaccuratelyreflect the real world driving scenes which can rarely contain coloredpatch or black holes and sidelines the blurring fog rain effectsmade by simple simulation also appear to be unrealistic whichcompromises their efficacy and reliability.
for instance figure showsthesyntheticimageswhicharequotedfromthepapersof deepxplore and deeptest.
note that the colored arrows are attached to present the predicted steering angles.
from figure 1a 1b and1c itcanbeobservedthattheimagesofdrivingscenesinclude several artifacts patch holes and sidelines which significantlyhurt the image quality.
moreover for figure 1d it appears to be synthesizedbysimplydimmingtheoriginalimageandmixingit with the scrambled smoke effect and it violates the facts that the density of fog varies along depth.
similarly in figure 1e deeptest simplysimulatesrainbyaddingagroupoflinesovertheoriginal image.
this rain effect transformation is even more distorted because usuallywhen itrains the cameraor frontwindshield tends to be wet and the image is highly possible to be blurred.
these factsshowthatitisdifficulttodeterminewhethertheerroneous driving behaviorsare caused by theflaws of the dnn basedmodels or theinadequacy of the testing techniqueitself.
furthermore thesetransformations e.g.translation shearandrotation canonlygenerate similar images while they cannot sophisticatedly synthesize images with different styles and thus limit the diversity of testcases.forinstance thesnowyroadconditiondemandsdifferentcomplicatedtransformationsforrenderingthetextureofroad and roadside objects such as trees and it cannot be generated by simple transformation rules.
fortraditionalsoftware inputvalidation iv isanimportantstep before executing programs.
for instance in web applications iv checks and filters illegal or malicious inputs to prevent application level attacks such as buffer overflow and code injection attack .
however tothebestofourknowledge currentdnn basedsystems lack to validate inputs e.g.
images of driving scenes and thustends to cause system vulnerability.
specifically invalid inputssuch as outlier images of driving scenes can highly degrade the prediction accuracy and dramatically increase the risks of dnnbased systems.
for example suppose a dnn based autonomous drivingsystemistrainedonadatasetwhichonlyincludesimagesof sunnydrivingscenes.
forout of domaininputs e.g.
rainyimages ofdrivingscenes thatthesystemisnottrainedwith itishighly possible that the system outputs wrong control signals which lead to danger for drivers and passengers.
toaddressaboveissues inthispaper weproposeanunsupervised learning framework namely deeproad to systematically analyze dnn based autonomous driving systems.
deeproad is composed of a metamorphic testing module deeproad mtand an input validation module deeproad iv.
deeproad mtemploys a generativeadversarialnetwork gan basedtechnique to synthesize driving scenes with various weather conditions and develops a metamorphic testing module for dnn based autonomous driving systems.
specifically the metamorphic relations are definedsuchthatnomatterhowthedrivingscenesaresynthesized to cope with different weather conditions the driving behaviors are expected to be consistent with those under the corresponding originaldrivingscenes.atthispoint deeproad mtenablesusto testtheaccuracyandreliabilityofdnn basedautonomousdriving systems under different scenarios including heavy snow and hard rain whichcangreatlycomplementtheexistingapproaches e.g.
deepxplore deeptest .
for instance figure 2presents the snowy and rainy scenes generated by deeproad mt from sunny scenes whichcan hardlybedistinguishedfromgenuineonesand cannot be generated using simple transformation rules.
deeproad ivis designed to validate inputs for dnn based autonomous driving systemsbasedonimagesimilarity.firstly deeproad ivappliesa pre trained dnn model vggnet to extract high level features i.e.
contentsandstyles ofbothtrainingandtestinputimages.then theprinciplecomponentanalysis pca techniqueisappliedon thesefeaturesfordimensionreduction.finally deeproad ivvalidatesinputsbycomparingtheaveragedistancebetweentraining and input images with a preset threshold.
toevaluatetheeffectivenessofdeeproad wefirstsynthesize drivingscenesunderheavysnowandhardrain.inparticular based ongan wecollectimageswithtwoextremeweatherconditions fromyoutubevideostotransformreal worlddrivingscenes and deliver them with the corresponding weather conditions.
subsequently thesesyntheticscenesareusedtotestthreeopen source dnn based autonomous driving systems from udacity community .
the experimental results reveal that deeproad mtcan authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
deeproad gan based metamorphic testing and input validation framework for ... ase september montpellier france a patch b holes c translation d fog e rain figure driving scenes synthesized by deepxplore a b and deeptest c d e a snow b rain figure snowy and rainy scenes synthesized by deeproad effectivelydetectthousandsofinconsistentbehaviorsofdifferent levels for these systems.
furthermore we use deeproad ivto validatetheinputimagessampledfromdifferentdrivingscenes.the results demonstrate that in the embedding space the cluster of the rainyandsnowyimagepointsareseparatelydistributedtothecluster of training images however the training cluster is mixed with the majority of the sunny image points.
it indicates that given a properthreshold deeproad ivcaneffectivelyvalidateinput which potentially improve the system robustness.
the key contributions of this paper are as follows.
we propose the first gan based metamorphic testing approachtogeneratedrivingsceneswithvariousweatherconditions for detecting inconsistent behaviors of autonomous driving systems.
we propose a novel approach to validate inputs for dnnbasedautonomous drivingsystem.
we presentthat thedistancebetweenthehigh levelfeaturesoftrainingandinput images can be used for validating inputs.
weimplementtheproposedapproachesindeeproad which can generate images of diverse driving scenes e.g.
rain and snow andmeasurethesimilaritybetweenmultipleimage sets in embedding space.
we use deeproad to test wellrecognizeddnn basedautonomousdrivingmodelsandsuccessfully detect thousands of inconsistent driving behaviors.
additionally deeproadcanaccuratelydistinguishimages with extreme weather conditions to the training images whichiseffectivetovalidateinputforautonomousdriving systems.
background autonomous driving systems have been rapidly evolving in recent years .
for example many major auto manufacturers including tesla gm volvo ford bmw honda and daimler and it companies includingwaymo google uber andbaidu areworkingonbuildingandtestingvariousautonomousdrivingsystems.typically autonomous driving systems capture data from environmentviamultiplesensors e.g.camera radar lidar gpu imu etc.
as input and use deep neural networks dnns to process data and output control signals e.g.
steering and braking decisions .
in nvidia s work their autonomous driving system dave can fluently control cars only based on the images captured by a singlefront camera.in thiswork wemainlyfocus ondnn based autonomousdrivingsystemswithcamerainputsandsteeringangle outputs.
.
dnn architectures to date convolutional neural network cnn and recurrent neural network rnn are the most widely used dnns for autonomousdrivingsystems.typically cnnsaregoodatanalyzing visualimageryandrnnscaneffectivelyprocesssequentialdata.
in this work the evaluated models are built on cnn and rnn modules.
we briefly introduce the basic concepts and components ofeacharchitectureasfollows wheremoredetailsaboutdnnsare provided in .
.
.
convolutional neural networks.
convolutionalneuralnetworksaresimilartoregularneuralnetworks whichincludealarge amount of neurons and pass information in a feed forward way.
however since the input data are images several properties canbe applied to optimize the regular neural networks where convolutional layer is a key component in cnns.
instead of being fully connected a neuron in a layer only connects to some neurons in the previous layer and the computational process can be presented as a convolution with kernels.
figure 3ashows an exampleofcnn basedautonomousdrivingsystemthatconsistsof an input layer images and an output layer steering angles as well as multiple hidden layers.
convolution hidden layers allowweightsharingacrossmultipleconnectionsandcangreatlysave the training efforts.
.
.
recurrent neural networks.
regular neural networks and cnnsaredesignedtoprocessindependentdata suchasusingcnn to classify images.
however for sequential data like videos the neuralnetworksshouldnotonlycaptureinformationofeachsingleframe butarealsoexpectedtomodeltheconnectionsbetweenthem.
unlike regular nns and cnns rnn is a kind of neural network withfeedbackconnections.
asshowninthe leftpartoffigure 3b rnns use loops to forward the previous states to input whichmodel the connection of input data.
the right part of figure 3b showstheworkflowoftheunfoldedrnnforpredictingsteering angles based on a sequence of images.
at each step rnn takes authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
ase september montpellier france m. zhang y. zhang l. zhang c. liu and s. khurshid a cnn architecture b rnn architecture figure autonomous driving systems built on cnn and rnn the current input image and previous hidden states as input and predicts the steering angle.
dnn based autonomous driving systems are essentially software systems which are error prone and can lead to tragedies.
forexample onjanuary ateslamodelsplowedintoafire truckat65mphwhileusingautopilot .andonmar anautonomous uber failed to slow down and killed a pedestrian during roadtestatnight .toensurethequalityofsoftwaresystems many software testing techniques have been proposed in the lit erature where typically a set of specific test cases are generated to test if the software programs perform as expected.
the process of determining whether the software program performsasexpecteduponthegiventestinputsisknownasthe test oracleproblem .
despite the abundance of traditional software testing techniques they cannot be directly applied for dnn based systems since the logics of dnn based softwares are learned from datawithminimalhumaninterference likeablackbox whilethe logics of traditional software programs are manually created.
approach .
metamorphic testing for dnn based autonomous driving systems .
.
metamorphic dnn testing.
metamorphic testing mt has been widely used to automatically generate tests to detect softwarefaults.thestrengthofmtliesinitscapabilitytoautomatically solve the test oracle problem via metamorphic relations mrs .
in particular let pbe a program mathematical representation that mapsprograminputstoprogramoutputs e.g.
p dblbracketlefti dblbracketright o .assumingfiandfoaretwospecificfunctionsfortransformingtheinput and output domain respectively and they satisfy the following mr formulation i p dblbracketleftfi i dblbracketright fo p dblbracketlefti dblbracketright whereidenotes the input of program p. with such mrs we can test a specific implementation pofp bycheckingwhether p dblbracketleftfi i dblbracketright fo p dblbracketlefti dblbracketright forvariousinput i.a ccordingly mt is defined as testing a program implementation viacross checkinginputsandoutputswithmrs.forinstance given a program implementing function sine mt can be used to delineate test oracles and create various new tests.
for any existing inputito test function sine various facts can serve as mrs e.g.
sin i sin i andsin i 2 sin i .
thesefacts can beformulatedas1 fi x fo x x fi x x 2 andfo x x. withsuchmrs wecantransformtheexistingtestinputsaccording tofito generate additional tests and check the output based on fo.
for instance suppose the default test case of function sineis asserttrue sin .
pi .
.
based on above mrs we can generate two extra tests asserttrue sin .
pi .
and asserttrue sin .
pi .
.
inthiswork wefurtherapplymttotestdnn basedautonomous drivingsystems.formally denote dnnasadnn basedautonomous driving system that continuously maps each image into predicted steering angle signal e.g.
turning left for .
one mr can be definedasgiventheoriginalimagestream i variousimagetransformations tcansimplychangetheroadscenes detailedshown in section .
.
without impacting the predictions for each image i i e.g.
thepredicteddirectionshouldbeapproximatelythesame on the same road under different weather conditions .
this mr to test dnn with additional transformed inputs can be formalized as follows i i t dnn dblbracketleft i dblbracketright dnn dblbracketlefti dblbracketright .
.
dnn based road scene transformation.
the recent work deeptest also applied mt to test dnn based autonomous drivingsystems.however itonlyperformsbasicimagetransforma tions suchasaddingsimpleblurring fog raineffectfilters andthus has the following limitations deeptest may generate images whichviolatecommonscenes discussedinsection .
deeptest cannotsimulatecomplexroadscenetransformations e.g.
snowy scenes .
tocomplementdeeptestbyautomaticallygeneratingvarious real worldroadscenes inthiswork weleverageunit arecent published dnn basedmethod toperform unsupervised image toimagetransformationbasedongenerativeadversarialnetworks gans andvariationalautoencoders vaes .oneinsight of unit is that suppose two images contain the same contents but lieindifferentdomains theyshouldhavethesamerepresentations in a shared latent space.
accordingly given a new image from one domain e.g.
theoriginaldrivingscene unitcanautomatically generate its corresponding version in the other domain e.g.
rainy driving scene .
figure4 presents the structure of unit s1ands2denote twodifferentdomains e.g.
sunnyandrainydrivingscenes e1and e2denote two autoencoders which project the images from s1and s2to a shared latent space z. suppose x1andx2are paired images which share the same content.
ideally e1ande2would encode themtothesamelatentvector z anditcanbetranslatedbackto s1 ands2by two domain specific generators g1andg2 respectively.
d1andd2are two discriminators which detect whether the image belongs to s1ands2respectively.
specifically they are expected to differentiate whether the input image is sampled from target domain e.g.realimage orproducedbyawell trainedgenerator e.g.syntheticimage .basedontheautoencodersandgenerators authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
deeproad gan based metamorphic testing and input validation framework for ... ase september montpellier france unitcanbeusedtotransformimagesbetweentwodomains.for instance image x1can be transformed to s2byg2 e1 x1 .
figure structure of unit in unit all di eiandgiare incarnated as neural networks and the learning objective of unit can be decomposed to optimize the following costs vae loss minimizingthelossofimagereconstructionfor each angbracketleftei gi angbracketright.
gan loss achieving the equilibrium point in the minimax game for each angbracketleftgi di angbracketright wherediaims at discriminating the images to find out whether they are sampled from the domainsior produced by githat aims at fooling di.
cycle consistency loss minimizing the loss of cycle reconstructionforeach angbracketleftei gj ej gi angbracketright wherex1isexpected toequalto g1 e2 g2 e1 x1 andx2isexpectedtoequal tog2 e1 g1 e2 x2 .
the total loss can be summarized as follows min e1 e2 g1 g2max d1 d2lcc1 e1 g2 e2 g1 lcc2 e2 g1 e1 g2 lva e1 e1 g1 lva e2 e2 g2 lgan1 d1 g1 lgan2 d2 g2 and this loss function can be optimized using stochastic gradient descent algorithm.
figure framework of deeproad mt3.
.
framework of deeproad mt.figure5showstheoveralldesign of our metamorphic testing framework for dnn based autonomousdrivingsystems deeproad mt.infigure deeproad mt first takes unpaired training images from two target domains e.g.
datasetsofthedrivingsceneundersunnyandsnowyweatherrespectively and utilizes unit to project two domains to the same latent space by optimizing the loss functions presented in section3.
.
.whenthetraining processfinished deeproad mtuses the well trained model to transform the whole dataset of sunnydriving scenes to snowy weather.
specifically given any image under sunny weather i deeproad mtencodes it to vector zibye1 and synthesizes its corresponding version under snowy weather i usingg2.deeproad mtfeedseachpairofrealandsynthetic driving scene images to the autonomous driving systems under test i.e.
dnn and compare their prediction results dnn dblbracketleft i dblbracketright anddnn dblbracketlefti dblbracketrighttodetectanyinconsistentbehaviors.normally the transformeddrivingscenesareexpectednottosignificantlyimpact the predicted steering angles and any inconsistency may indicate correctness or robustness issues of the systems under test .
.
input validation for dnn based autonomous driving systems driving scenes synthesized by deeptest and deepxplore can be usedastestcasestotestdnn basedautonomousdrivingsystemsin an offline manner.
though these test cases are useful to expose the systemvulnerabilityandadvisedeveloperstocomplementtraining data from real world to improve the system robustness it is not sufficientforonlinetesting.forinstance adnn basedautonomous driving system can be well trained and perfectly function in sunny environments yet it might perform incorrectly at night or on a snow covered road because the lane marks it detected for guiding carsdisappearinsuchdrivingscenes.thisexamplesuggeststhat if the system can validate input images online and actively advise drivers to control the car when it cannot handle the invalid inputs theautonomousdrivingsystemscanbecomesaferandmorerobust.
in the following we first define the criteria of input validation for dnns especiallyimage orientedmodels andpresentourinput validation framework for dnn based autonomous driving systems.
.
.
input validation of dnns.
thegoalofinputvalidation iv is toensurethatonlyproperlyformeddatacanbeacceptedbysystems andmalformeddatashouldberejectedbeforeexecution.thereason is that an invalid input may trigger malfunction of downstream components whichmakesthesysteminsecure.generally thevalidinputofaprogramcanbeexplicitlydefinedsuchastheinputstring should not be null empty or the value of a certain input variable shouldbegreaterthan0.however itisnottrivialtoproperlydefine inputvalidityofadnn basedprogram.forexample wecandefine an iv criteria as the input data should be any rgb image with size oranyinputdatashouldexistinthetrainingdatasetto guaranteethecorrectness.however noneofthemarepropersince the first criteria is too weak to improve system robustness and the second is so strong that makes the system lack generalisability.
wedefinetheivcriteriaofdnn basedprogrambasedonthe probablyapproximatelycorrect pac learningtheory.according to the pac learning theory a machine learning model is expected to learn the distribution dfrom the training dataset authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
ase september montpellier france m. zhang y. zhang l. zhang c. liu and s. khurshid and predict the correct label with high probability.1this can be formulated as follows e d prx d x nequaly pr e informula edenotesthattheprobabilityof makesincorrect prediction x nequaly on input data xsampled from d and in formula4 and are two parameters between and such that it is highly possible greater that eis small less than whichmeans iseffectiveon d.basedontheaboveequations we firstdefineanabstractivcriteriaofdnn basedsystemsisthatthe inputdatashouldbesampledfrom d.asdiscussedbefore suppose theinputdataisnotsampledfrom d theivcriteriaisviolatedand thepredictionaccuracyisnotguaranteed.therefore itisnecessary tovalidateinputstoimprovetherobustnessofdnn basedsystems.
intuitively the iv criteria should be instantiated as prx d x i which means the probability of input ibeing sampled from d shouldbegreaterthan thepredefinedthreshold .otherwise the system refuses to predict on i. however this definition is not tractable for image data because image data is highly dimensional andtheirdistribution e.g.gaussianmixturemodel isdifficulttobe explicitly represented.
to address this issue we project image data to a low dimensional space and use the distance between inputsand training data to replace prx d x i .
in particular according to the manifold learning theory the images generated bydcan be embedded into a non linear low dimension manifold md.
suppose the input data iis sampled from d its projection ipshould be included by md.
furthermore we propose an extra constraint for the non linear embedding that suppose the input data are generated by a different distribution d prime their projections are expected to be included by another manifold md prime which is linearlyseparableto md.basedontheconstraint wecancompute theminimaldistanceof ipandtheprojectionsoftrainingdatato validateif ipbelongsto md.theivcriteriaisredefinedasfollows min j bardblh i h j bardbl2 prime where bardbl bardbl2denotesl2norm h denotes the required non liner projectionand primedenotespredefinedthresholdforinputvalidation.
iftheinputsatisfiesequation itwillbeprocessedbydnnsfor prediction otherwise it will be rejected.
.
.
framework of deeproad iv.we propose deeproad iv an inputvalidationframeworkforautonomousdrivingsystems.deeproad iv separatetheprojection h totwoparts non lineartransformation and dimension reduction.
for the first part deeproad ivapplies vggnet a widely used dnn to extract high level featuresfromeachimage.tobespecific theinputimageisencoded in each layer of vggnet by kernels.
suppose layer iincludesni distinctkernels itgenerates nifeaturemapseachofsize wi hi wherewiandhiarethewidthandheightofthefeaturemapsrespectively.
these feature maps can be stored as a feature matrix fi withsize ni mi whereeachrowof fiisthevectorflattenedfrom the corresponding feature map and miiswi hi.
deeproad ivalso 1forsimplicity here weonlydiscussdnnsforclassification thesameapproachcan be applied to explain dnns for other tasks such as regression.
figure framework of deeproad iv generates style information which are introduced in .
these style information aims at capturing the texture of images and itis defined by feature correlation which can be computed by the gram matrix gi fi ft i suppose we choose layer iandjto extract the feature and style matrixfiandgjrespectively therepresentationvectorofthegiven image is vectorv where vectorvf vectorvgare flattened vector of fiand gjreceptively.
further we apply principle component analysis pca technique to reduce feature dimension of input and training data as follows y x p xdenotes the input matrix with size n m wherenis the total number of input and training data and mis the length of feature vector vectorv.pdenotes the projection matrix with size m k wherek isthetargetdimensionlessthan m andpcanbecomputedusing x .
figure6shows the overall design of our input validation framework deeproad iv.deeproad ivfirsttakesthetrainingandonline driving images as input and uses vggnet to extract their content and style features.
as shown in figure deeproad ivinputs a snowyimagetovggnet andchoosestheconvolutionallayer conv 4 2andconv 5 3 to extract content and style features respectively.tobespecific thecoloredgrids f 4 2andf 5 3denotethe content features extracted from vggnet and the style feature g 5 3iscomputedbyequation .notethatthesecoloredgridsare just used to visualize results and their dimensions do not match therealoutputs.then matrix f 4 2andg 5 3areflattenedand concatenated to feature vector v. deeproad ivprocesses all image data using the same approach and the feature vectors compose matrix x.inthesecondstep deeproad ivappliespcatoreduce thefeaturedimension.infigure wesetthetargetdimensionto .
the processed data yare presented on a d plane where the blueandrednodesdenotethetrainingandonlinedrivingimages respectively.finally deeproad ivcomputestheminimaldistance betweentrainingdataandeachonlineimage andrefusestopredictfortheimageswhosedistancesaregreaterthanacertainthreshold.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
deeproad gan based metamorphic testing and input validation framework for ... ase september montpellier france table details of image sets dataset frame duration weather cond.
udacity training n.a.
sunshine udacity test ep1 n.a.
sunshine udacity test ep2 n.a.
sunshine youtube ep1 heavy snow youtube ep2 hard rain experiments .
data we useareal world dataset releasedby udacity as abaselineto check the inconsistency of autonomous driving systems.
from the dataset weselecttwoepisodesofhigh waydrivingvideowhere obviouschangesoflightingandroadconditionscanbeobserved amongframes.totrainunitmodel wealsocollectimagesofextremescenariosfromyoutube.intheexperiments weselectheavy snow and hard rain two extreme weather conditions to transform real world driving scenes.
to make the variance of collected images relatively large we only search for videos which is longer than20mins.inthescenarioofhardrain thevideorecordswipers swipingwindshield whichwouldpotentiallydegradethequality ofsyntheticimages.hence indatapreprocessingphase wemanually check and filter those images.
note that all images used in the experiments are cropped and resized to and we have performed down sampling for youtube videos to skip consecutive frames with close contents.
the detailed information is present in table1.
.
models we evaluate our metamorphic testing framework deeproad mton three dnn based autonomous driving models which are released byudacity autumn chauffeur and rwightman .we choosethesethreemodelsastheirpre trainedmodelsarepublicand canbeevaluateddirectlyonthesyntheticdatasets.tobespecific themodeldetailsof rwightman arenotpubliclyavailable however similar to black box testing our approach aims at detecting theinconsistencies of the model.
hence rwightman is still used for evaluations.
autumn.
autumniscomposedofadatapreprocessingmoduleand a cnn.
specifically autumnfirst computes the optical flow of raw imagesandinputsthemtoacnntopredictsteeringangles.the architectureof autumnis three5x5convlayerswithstride2pluses two 3x3 conv layers and followed by five fully connected layers withdropout.themodelisimplementedbyopencv tensorflow and keras.
chauffeur.
chauffeur consists of one cnn and one rnn with lstm module.
the workflow is that cnn first extracts the features of input images and then utilizes rnn to predict the steering angle from previous consecutive images.
this model is also implemented by tensorflow and keras.
.
metric metric of model inconsistency.
in this work an autonomous driving system is defined to act consistent if its steering angle prediction falls within certain error bounds after modifying theweather condition of driving images.
we define the number of inconsistent behaviors of autonomous driving systems as follows ib dnn i summationdisplay i if dnn dblbracketlefti dblbracketright dnn dblbracketleft i dblbracketright wherednndenotestheautonomousdrivingmodeland iisthe real worlddrivingdataset.
idenotesthe ithimagein i. denotes the image generator transformer which can change the weathercondition of the input image.
fis an indicator function which outputs or if and only if the input is trueorfalseand is the error bound.metric of input validation.
as introduced in section .
.
the inputvalidityofdnn basedautonomousdrivingsystemsisdefinedbytheminimaldistanceofinputandtrainingimagesintheembedding space.
this metric can reflect the similarity between the input and training data however it has the following limitations first generally thetrainingdatasetislarge e.g.10kimages .supposewe usetheabovemetrictovalidateasingleinputimage thenumerous trainingdatapointswilldominatepcaandtheresultsarebiased.
second usingtheminimaldistanceforinputvalidationisnotstable.
for example suppose thedistance ofinput iand trainingdata jis minimal and it is less than the threshold.
however jis far from othertrainingdataandactually iisnotsimilartothemajorityof the trainingdataset.
weaddress theselimitations inthe following ways first tobalancetheinputdata andtrainingdata we collect mimagesfromonlinedrivingscenesasinputdata andrandomly selectmimagesfromtrainingdatasetastrainingdata.second to estimatethedistancemorestable weaveragethetop nminimal distancesofeachimagetorepresenttheirsimilarities.themetric of input validity is defined as follow miv i st f n summationdisplay k n min j stk bardblh i h j bardbl2 wherenis a parameter less than m idenotes the image of the inputdatasetwithsize m.stdenotesthesetof mrandomlyselected training images mink denotes the k th minimal value among inputarray.function fisanindicatorfunctionand isthethreshold of input validation.
.
results .
.
results of deeproad mt.wefirstpresentseveralyoutube screenshotsasgroundtruthinfigure 7tohelpreaderscheckthe quality of synthetic images.
in figure we list real and gangeneratedimagespairs wherethetworowspresentthetransformation of udacity dataset to snowy and rainy scenes respectively andtheoddandevencolumnspresentoriginalandgan generated images respectively.
qualitatively the gan generated images are visuallysimilartotheimagescollectedfromyoutubevideosand they also can keep the major semantic information such as the shape of tree and road of the original images.
interestingly in the firstsnowyimageinfigure theskyisrelativelydarkandgancan successfullyrenderthesnowtextureandthelightinfrontofthecar.
in the second column the sharpness of rainy images are relatively low and this is consistent to the real scene showed in figure .
our resultsareconsistentwiththeoriginalunitwork andfurther demonstrate the effectiveness of unit for image transformation.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
ase september montpellier france m. zhang y. zhang l. zhang c. liu and s. khurshid a heavy snow b hard rain figure images collected from youtube figure real and gan generated images a autumn b chauffeur c rwightman figure inconsistency of steering angle prediction on real and synthetic images we further present examples for the detected inconsistent behaviors of autonomous driving models in figure .
in the figure each row shows the scenes of snow and rain respectively.
in each sub figure the blue caption indicates the model name while the red and green captions indicate the predicted steering angles onthe real and synthetic images respectively.
the curves visualize thepredictionswhichhelpcheckthedifferences.fromthefigure we can observe that model autumn the first two columns has the highestinconsistencynumberonbothscenes incontrast model rwightman thelasttwocolumns isthemoststablemodelunder differentscenes.thisfigureshowsthatdeeproad mtisabletofind inconsistentbehaviorsunderdifferentroadscenesforreal world autonomousdrivingmodels.forexample amodellike autumnor chauffeur theyarebothrankedhigherthan rwightman inthe udacitychallenge mayworkperfectlyinasunnydaybutcancrash into thecurbside oreven worse the oncomingcars in arainy or snowy day shown in figure .
table2presents the detailed number of detected inconsistent behaviors under different weather conditions and error bounds foreachstudiedautonomousdrivingmodelontheudacitydataset.for example whenusingtheerrorboundof andtherainyscenes deeproad mtdetects and inconsistent behaviors for autumn chauffeur and rwightman respectively.
from the table we can observe that the inconsistency number of autumnis the highest under both weather conditions.
we think one potential reason is that autumnis purely based on cnn and does not utilizehistoryinformation e.g.
viarnn andthusmaynotalways perform well in all road scenes.
on the other hand rwightman performsthemostconsistentlythantheothertwomodelsunder allerrorbounds.thisresultpresentsaveryinterestingphenomenon deeproad mtcan not only detect thousands of inconsistent behaviors of the studied autonomous driving systems but can also measuredifferentautonomoussystemsintermsoftheirrobustness.
forexample withtheoriginaludacitydataset itishardtofindthe limitations of autonomous driving systems like autumn.
.
.
results of deeproad iv.we use sunny rainy and snowy drivingscenestotestdeeproad iv.theexpectationofthisexperiment is in the embedding space the sunny images are close to authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
deeproad gan based metamorphic testing and input validation framework for ... ase september montpellier france a sunny b rainy c snowy d distribution of distances figure results of deeproad iv image embeddings and distance distributions.
table number of inconsistency behavior of three models under different weather conditions scene modelnum.
of inconsist.
behav.
snowyautumn chauffeur rwightman rainyautumn chauffeur rwightman thetrainingimages andtherainyandsnowyimagesarelinearly separable to them.
specifically sunny images are collected from the original test dataset and the rainy and snowy images are extracted from youtube videos.
note that to ensure the authenticity of input images we only choose real world instead of synthetic images.
moreover we choose convolutional layer conv 3 2 and conv 4 1 ofvggnettoextractthecontentandstylefeaturesfrom theinputimages andwesetthepcadimensionto3forvisualizing experimental results.
to reduce the computational complexity we resize all the images to 90and set the sampling number m of each dataset to .
furthermore we use the average of top100 minimal distances of each data point to reduce the variance of similarity estimation for each input image.
figure 10visualizes the resultsofdeeproad ivonsunny rainyandsnowydrivingscenes.
tobespecific thefirstthreefiguresoffigure 10presenttheresults of sunny rainy and snowy images respectively.
and the orangeand blue points present the sampled training and corresponding input images.
we first analyze the results of the image embedding.
from figure 10a we observe that the majority of the input images are mixed with the training samples and a few inputs are far from the cluster.
from figure 10band10c there are gaps between the input and training points and the clusters are linearly separable.
these results indicate that the distributions of sunny and training imagesareclosebuttherainyandsnowyimagesarenot.onthe other hand the cluster of rainy and snowy images are relativelycompact but the sunny images are scattered.
the reason may bethe texture of rainy and snowy images are unified and the con tent is relatively poor so that the distances between images are small.however thelightconditionandcontentofsunnyimages are more diverse hence the distances are large.
moreover fromfigure10d we find the distances of sunny images mainly lie between0and3 andalmostallofthedistancesofrainyandsnowy images are larger than .
suppose the threshold of input validationis .
deeproad ivcan detect of rainy of snowy images and outliers among sunny images as invalid inputs which effectively improve the system robustness.
furthermore we study if the non linear transformation of input images is necessary forinput validation.
figure 11visualizes the results of deeproad iv withoutfeatureextraction.fromfigure weobservethatallblue clusters are surrounded by the orange points which show thatinput images are not linearly separable to the training images inthe embedding space.
it implies in this case the distance is not a propermetricforinputvalidation andnon lineartransformation i.e.
feature extraction using vggnet is indeed needed.
threats to validity thereareseveralthreatstothevalidityoftheproposedapproach and its result which include the followings.
in this work the main threat to internal validity is potential defectsintheimplementationofourtechniques.toreducethese threats in implementing deeproad mt we used the original implementation of unit to ensure deeproad mt s performance.
furthermore in implementing of deeproad iv we downloaded the pre trained vggnet weights from pytorch website2instead of training it on imagenet.
the threats to external validity mainly lie in image quality dataset and autonomous driving models.
first we lack a good standard to evaluate image quality i.e.
realisticity .
in this paper we presentgan generatedimagestoletreaderschecktheirquality.
this approach is quite straightforward but less objective.
salimans et.al proposedinceptionscoretoevaluatethequalityofsynthetic images.
to be specific inception score uses an inception v3 network pre trained on imagenet to compute a statistic of thenetwork s outputs as the quality of generated images.
however barratt et.al demonstrate that inception score fails to provide useful guidance when comparing generative models e.g.
gans .
furthermore thegenerationprocessofgansisnotcontrollable thatsomesemanticcontent e.g.treesorcars maybemissingin syntheticimages andthismaythreatenthevalidityofmetamorphictesting.second theudacitydatasetisrelativesmallandthe autonomousdrivingmodelsarequitesimple.supposethedataset issufficientlylarge amorecomplicatedandrobustmodelisableto betrained andtheinconsistentbehaviorswouldbedramatically reduced.
moreover an autonomous driving system is complicated and its input and output are diverse.
in this work we only focus authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
ase september montpellier france m. zhang y. zhang l. zhang c. liu and s. khurshid a sunny b rainy c snowy figure results of deeproad iv without non linear transformation image embeddings and distance distributions.
on testing the accuracy of the steering angle instead of speeding adjustments.
related work metamorphic testing.
metamorphic testing is a classical softwaretestingmethodthatidentifiessoftwarebugs .its key idea is to detect violations of domain specific metamorphic relations defined across outputs from multiple runs of the program with different inputs.
metamorphic testing has been applied for testingmachinelearningclassifiers .inthispaper deeproad develops a specific gan based metamorphic testing module for dnn based autonomous driving systems where the metamorphicrelationsaredefinedsuchthatregardlessofhowthedriving scenesaresynthesizedtocopewithweatherconditions thedrivingbehaviorsareexpectedtobeconsistentwiththoseunderthe corresponding original driving scenes.
input validation.
input validation aims at ensuring that only properlyformeddatacanbeacceptedbyaninformationsystem andpreventingmalformeddataleadingsystemserrors.inputvalidationhasbeappliedtoenhancetherobustnessofwebapplication .
in this paper deeproad develops a distance based input validation framework for dnn based autonomous driving systems wherethe key idea is that a valid input image is similar to a part of the images in the training dataset and the similarity can be measured bythedistanceinanon linearlow dimensionspace.toenhance thesystems security theimageswillberejectediftheirdistanceis greater than a given threshold.
testingandverificationofdnn basedautonomousdriving systems.
differentfromtraditionaltestingpracticesfordnnmodels a recent set of approaches such as deepxplore anddeeptest utilizedifferentialandmetamorphictestingalgorithms for identifying inputs that trigger inconsistencies among differentdnnmodels oramongtheoriginalandtransformeddriving scenes.
although such approaches have successfully found various autonomous driving system issues there still lack approaches that can test dnn basedautonomous driving system with diverse and realisticsynthesized drivingscenes.
moreover deepsafe focusesonautomaticallyidentifyingsaferegionsoftheinputspace within which the network is robust against adversarial perturbations.gan based image translation.
gan based domain adaption has been recently shown to be effective in unsupervised image toimage translation .
cyclegan discogan and dualgan propose the similar idea that image to imagetranslation should satisfy the cycle consistency where an image fromdomainashouldbeidenticalwhenitistranslatedtodomain bandtranslatedbacktoa.theexperimentsshowthatthisextra constraintcanmakethetranslatedimagesmorerealistic.unit furtherassumesthattherepresentationsoftwodomainsmaybeprojected to the same vector space shared latent space and is constructed based on vaes and gans.
specifically they also apply cycle consistency to the gan model to regularize the translation.
moreover gan baseddomainadaptionisalsoappliedforvirtualto real and real to virtual driving scene adaption .
dudrive proposes an unsupervised real to virtual domain unification framework for end to end driving.
their key insight is the rawimagemaycontainnuisancedetailswhicharenotrelatedto thepredictionofsteeringangles andacorrespondingvirtualscene can ignore these details and also address the domain shift problem.
grad gan is designed to automatically transfer the scene annotationinvirtual worldtofacilitatereal worldvisualtasks.inthat work a semantic aware discriminator is proposed for validating the fidelity of rendered image w.r.t each semantic region.
conclusion in this paper we propose deeproad an unsupervised learningframework to synthesize realistic driving scenes to test inconsis tent behaviors of dnn based autonomous driving systems and validate online input images to improve the system robustness.
the experimental results on three real world udacity autonomous drivingmodelsindicatethatdeeproadcansuccessfullydetectthou sandsofinconsistentbehaviors.furthermore ourresultsalsoshow that deeproad can effectively validate input images to potentially enhance the system robustness.