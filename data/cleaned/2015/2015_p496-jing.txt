heterogeneous cross company defect prediction by unified metric representation and cca based transfer learning xiaoyuan jing1 fei wu1 xiwei dong1 fumin qi1 baowen xu3 1state key laboratory of software engineering school of computer wuhan university china 2school of automation nanjing university of posts and telecommunications china 3department of computer science and technology nanjing university china corresponding author jingxy 2000 .c om bwxu nju.edu.cn abstract cross company defect prediction ccdp learns a prediction model by using training data from one or multiple projects of a source company and then applies the model to the target company data.
existing ccdp methods are based on the assumption that the data of source and target compan ies should have the same software metrics .
however for ccdp the source and target company data is usually heterogeneous namely the metrics used and the size of metric set are di fferent in the data of two companies.
we call ccdp in this s cenario as heterogeneous ccdp hccdp task.
in this paper w e aim to provide an effective solution for hccdp .
we propose a unified metric representation umr for the data of source and target com panies.
the umr consists of three types of metrics i.e.
the common metrics of the source and target companies source company specific metrics and target company specific metrics .
to construct umr for source company data the target company specific metrics are set as zeros while for umr of the target company data the source company specific metrics are set as zeros.
based on the unified metric representation we for the first time introduce canonical correlation analysis cca an effective transfer learning method into ccdp to make the data distributions of source and target companies similar.
experiments on public heterogeneous datasets from four companies indicate that for h ccdp with partially different metrics our approach significantly outperforms state of the art ccdp methods for hccdp with totally different metrics our approach obtains comparable predicti on performance s in contrast with within project prediction results .
the proposed approach is effective for hccdp.
categories and su bject descriptors d. .
management software quality assurance sqa d. .
testing and debugging code inspections and walk throughs .
general terms experimentation measurement reliability verification keywo rds heterogeneous cross company defect prediction hccdp common metrics company specific metrics unified metric representation canonical correlation analysis cca .
.
introduction software defect prediction sdp is one of the most i mportant research to pics in software engineering which has attracted a lot of attention from both academic and industrial communities .
most prior studies on this issue attempt to train predictors based on historical data to detect the defect proneness of new software modules within the same company which is called within company defect prediction w cdp .
however for a new company or companie s with limited historical data there is no t enough training defect data to build a predi ction model .
in this case it is hard to perform within company defect prediction .
fortunately there are m any open source defect datasets available such as the promise repository .
a potential way of predicting defects in projects without historical data is to make use of these publ ic data sets.
in recent years several cross company defect prediction ccdp methods have been developed such as nearest neighbor filter nn filter transfer naive bayes tnb double transfer boosting dtb cliff morph etc.
they learn prediction model by using sufficient training data from existing source projects and then apply the model to the target project .
.
motivation existing ccdp methods are based on the assumption that the data of source and target compan ies should have the same software metrics.
in fact since different companies might select different programming languages develop software modules according to different user requirements and test software modules from different aspects there usually exist differe nt metrics in the data of different companies.
table tabulates the number s of metrics in defect data of companies including nasa softlab relink and aeeem .
table shows the numbers of common metrics between projects of these four companies.
figure illustrates the detailed metrics used in defect data of four companies .
in the figure we outline the common metrics shared by two different companies with rectangle boxes in different colors.
specifically t he red rectangle box outlines the common metrics of nasa and permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
conference august september city state country.
copyright acm ... .
.
permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
copyrights for components of this work owned by others than acm must be honored.
abstracting with credit is permitted.
to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
request permissions from permissions acm.org.
esec fse august september bergamo italy c acm.
... .
relation cm1 from nasa attribute loc blank numeric attribute branch count numeric attribute call pairs numeric attribute loc code and comment numeric attribute loc comments numeric attribute condition count numeric attribute cyclomatic complexity numeric attribute cyclomatic density numeric attribute decision count numeric attribute decision density numeric attribute design complexity numeric attribute design density nu meric attribute edge count numeric attribute essential complexity numeric attribute essential density numeric attribute loc executable numeric attribute parameter count numeric attribute halstead content numeric attribute halstead difficulty numeric attribute halstead effort numeric attribute halstead error est numeric attribute halstead length numeric attribute halstead level numeric attribute halstead prog time numeric attribute halstead volume numeric attribute maintenance severity numeric attribute modified condition count numeric attribute multiple condition count numeric attribute node count numeric attribute normalized cylomatic complexity numeric attribute num operands numeric attribute num operators numeric attribute num unique operands numeric attribute num unique operators numeric attribute number of lines numeric attribute percent comments numeric attribute loc total numeric relation ar from softlab attribute total loc numeric attribute blank loc numeric attribute comment loc n umeric attribute code and comment loc numeric attribute executable loc numeric attribute unique operands numeric attribute unique operators numeric attribute total operands numeric attribute total operators numeric attribute halstead vocabulary numeric attribute halstead length numeric attribute halstead volume numeric attribute halstead lev el numeric attribute halstead difficulty numeric attribute halstead effort numeric attribute halstead error numeric attribute halstead time numeric attribute branch count numeric attribute decision count numeric attribute call pairs numeric attribute condition count numeric attribute multiple condition count numeric attribute cyclomatic complexity numeric attribute cyclomatic density numeric attribute decision density numeric attribute design complexity numeric attribute design density numeric attribute normalized cyclomatic complexity numeric attribute formal parameters numeric relation apache from relink attribute avgcyclomatic numeric attribute avgcyclomaticmodified numeric attribute avgcyclomaticstrict numeric attribute avgessential numeric attribute avgline numeric attribute avglineblank numeric attribute avglinecode numeric attribute avglinecomment numeric attribute countline numeric attribute countlineblank numeric attribute countlinecode numeric attribute countlinecodedecl numeric attribute countlinecodeexe numeric attribute countlinecomment numeric attribute countsemicolon numeric attribute countstmt numeric attribute countstmtdecl numeric attribute countstmtexe numeric attribute maxcyclomatic numeric attribute maxcyclomaticmodified numeric attribute maxcyclomaticstrict numeric attribute ratiocommenttocode numeric attribute sumcyclomatic numeric attribute sumcyclomaticmodified numeric attribute sumcyclomaticstrict numeric attribute sumessential numeric relation eq from aeeem attribute ck oo numberofprivatemethods numeric attribute ldhh lcom numeric attribute ldhh fanin numeric attribute numberofnontrivialbugsfounduntil numeric attribute wchu numberofpublicattributes numeric attribute wchu numberofattributes numeric attribute cvswentropy numeric attribute ldhh numberofpublicmethods numeric attribute wchu fanin numeric attribute ldhh numberofprivateattributes numeric attribute cvsentropy numeric attribute ldhh numberofpublicattributes numeric attribute wchu numberofprivatemethods numeric attribute wchu numberofmethods numeric attribute ck oo numberofpublicattributes numeric attribute ck oo noc numeric attribute numberofcriticalbugsfounduntil numeric attribute ck oo wmc numeric attribute ldhh numberofprivatemethods n umeric attribute wchu numberofprivateattributes numeric attribute cvslogentropy numeric attribute wchu noc numeric attribute ldhh numberofattributesinherited numeric attribute wchu wmc numeric attribute ck oo fanout numeric attribute ck oo numberoflinesofcode numeric attribute ck oo numberofattributesinherited numeric attribute ck oo numberofmethods numeric attribute ck oo dit numeric attribute ck oo fanin numeric attribute ldhh noc numeric attribute wchu dit numeric attribute ck oo lcom numeric attribute wchu numberofattributesinherited numeric attribute ck oo rfc numeric attribute ldhh wmc numeric attribute ldhh numberofattributes numeric attribute ldhh numberoflinesofcode numeric attribute wchu fanout numeric softlab the green rectangle box outlines the common metrics of nasa and relink and the blue rectangle box outlines the common metrics of softlab and relink.
it is noted that only metrics of aeeem are listed in the figure.
from tables and figure we can see that the types of metrics and the sizes of metric set s are varied in these companies.
table .
number of metrics in projects of four companies company nasa softlab relink aeeem number of metrics table .
number of common metrics between projects of different companies company a company b nasa soft lab nasa reli nk nasa a eeem number company a company b softlab r elink softlab a eeem relink aeeem number if we want to detect the defect proneness of modules in nasa by regarding the defect data from softlab relink or aeeem as training data existing ccdp methods can only make use of the common metrics shared by nasa and softlab or relink .
however the size of common metric set across different companies may be very small like the common metric set between nasa and relink and the metrics except the common metrics might have favorable discriminant ability.
since no common metrics exist in nasa and aeeem existing ccdp methods cannot make use of defect data in aeeem .
we call ccdp in this s cenario as heterogeneous ccd p hccdp .
in this paper we answer the following t hree research questions rq how to design an effective approach for h ccdp?
rq is the h eterogeneous cross company defect data helpful for cross company defect prediction?
rq if the h eterogeneous cross company defect data can help prediction when it helps the most?
.
contribution the contributions of our study are summarized as the follo wing two points .
focusing on heterogeneous ccdp hcddp w e propose a unified metric representation umr for the data of source and target companies.
the umr consists of three types of metrics including the common metrics of the source and target companies source company specific metrics and target company specific metrics .
we set the target company specific metri cs as zeros when construct ing the umr for source company data and set the source company specific metrics as zeros when construct ing the umr for target company data .
.
based on the unified metric representation we for the first time introduce the transf er learning method named canonical correlation analysis cca into ccdp for mak ing the data distribution of targ et compan y similar to that of source compan y. cca is an effective machine learning method which can maximize the correlation of source and target data.
we call the proposed approach for hccdp as cca .
we conduct experiments on public datasets from four companies including nasa softlab relink and aeeem .
experimental results demonstrate that the proposed approach can obtain desirable prediction results for h ccdp .
.
organization the rest of this paper is organized as follows section reviews the related work .
section describes the proposed cca approach.
experimental results are reported in section and conclusions are drawn in section .
.
related work in this section we briefly review existing cross company defect prediction ccdp methods cross project defect prediction cpdp methods and canonical correlation analysis cca and transfer learning metho ds.
figure .
list of the metrics used in defect data of four companies.
.
cross company defect prediction ccdp methods ccdp refers to using data from other companies to build defect predictors.
there exist two mainstream ways for ccdp.
the first one is to f ind the best suitable training data for the target modules .
turhan et al.
found that defect predictors built on all available cross company data dramatically increase defect detection ability but with unacceptably high false alarm rates.
they reckoned that the irrelevancies in the cross company data lead to the false alarm s and presented a nearest neighbor filter nn filter method to select training data close to within company data.
peters et al.
developed the peters filter to select training data for ccdp.
the second mainstream way for ccdp is to design effective machine learning algorithms with high generalization ability for construct ing the defect predictor.
ma et al.
presented a cross company pr ediction algorithm named transfer naive bayes tnb which estimates the distribution of the test data tran sfers crosscompany data information into the weights of the training data and then builds defect prediction model on these weighted data.
recently chen et al.
developed the double transfer boosting dtb method for ccdp which firstly uses data gravitation for reshaping the whole distribution of cross company data to fit within company data and then designs the transfer boosting algorithm to remove negative samples in cross company data with a small ratio of labeled within company data.
however ex isting ccdp methods are based on the restrictive assumption that the software metrics used in source and target company data should be the same.
they do not apply to the scenario of heterogeneous ccdp.
.
cross project defect prediction cpdp methods cross project defect prediction cpdp refers to predicting defects in a project using prediction models trained from historical data of other projects .
when we only use one project in a specific company for training the prediction model ccdp can be considered as cpdp.
over the past recent years we have witnessed lots of i nterest in developing new cpdp methods.
using applications zimmermann et al.
performed cross project predictions.
the results indicate that cpdp is a serious challenge i.e.
simply using models from projects in the same domain or with the same process does not lead to accurate predictions.
careful selection of training data and the characteristics of data and process play important roles in successful cpdp.
he et al.
i nvestigated cpdp by focusing on training data selection.
they showed that the prediction results were related to the distributional attributes of datasets which is useful for training data selection.
rahman et al.
introduced the measure called area u nder the cost effectiveness curve aucec to investigate the feasibility of cpdp and drew a conclusion that cpdp is no worse than within project prediction in terms of aucec.
turhan et al.
introduced a mixed model for c pdp which uses both the within and cross project data as training data .
they concluded that the performance of the mixed model could be comparable to that of within project prediction .
recently nam et al.
applied transfer component analysis tca to cpdp which is a featurebased transfer learning method.
furthermore they extended tca to tca by using the normalization t echniques to preprocess data which exhibits good performance for defect prediction.
ryu et al.
developed the value cognitive boosting with support vector machine method for class imbalance issue of cpdp.
existing cpdp methods are also based on the assumption that the data of source and target compan ies should have the same software metrics.
if there exist partially different metrics between the source and tar get projects existing cpdp methods can only make use of common metrics.
when no common metrics exist between source and target projects existing cpdp methods cannot be used for defect prediction.
.
canonical c orrelation a nalysis cca and transfer learning methods canonical correlation analysis cca is a powerful tool in multivariate data analysis to find the correlation between two sets of variables.
the two sets of variables can be associated with two different objects or two different views of the same object.
cca aims to learn a pair of projective transformations corresponding to the two sets of variables such that the projected variables are maximally correlated.
cca has been applied in many areas such as signal processing pattern classific ation and multi view feature learning .
recently cca has been used for transfer learning.
wu et al.
addressed the heterogeneous transfer discriminant analysis of canonical correlations htdcc method for cross view action recognition which learn s a discriminative common feature space for linking source and target views to transfer knowledge between them.
zhang and shi presented the cross domain cca algorithm which attempts to learn a semantic space of multi view correspondences from different domains and transfer the knowledge by using dimensionality reduction in a multi view way.
yeh et al.
employed cca to deriv e a joint feature space for associating cross domain data and developed a new support vector machine svm algorithm that incorporates the domain adaptation ability observed in the derived subspace for cross domain pattern classification application.
the difference between our approach and the above cca based methods is that we for the first time introduce cca into the field of cross company software defect prediction and propose a novel metric representation for the heterogeneous source and target data with which we propose the cca approach.
.
our approach to answer the rq how to design an effective approach for hccdp we propose the cca approach for heterogeneous ccdp.
our approach includes two parts unified metric representation for heterogeneous source and target data and cca for transfer learning.
.
unified m etric r epresentation for heterogeneous s ource and t arge t data to effectively utilize the heterogeneous data from two domains li et al.
introduce d a common subspace for the source and target data so that the heterogeneous data can be compared.
specifically for any source sample sx and target sample tx the feature mapping functions s and t are defined as ts ss sdx px x and st tt tdx qx x where p and q are two projective matrices sd and td separately denote the 498dimensionalities of source and target data.
promising results have been shown in .
inspired by we design a unified metric representation umr for the heterogeneous source and target defect data.
assume that n s ss sx xx x and m t tt tx xx x separately denote the source and target company data where i sx denotes t he thi module in sx n and m represent the numbers of modules in sx and tx respectively.
a module in the source company can be represented as sid i ii s ss sx aa a and a module in the target company can be represented as tid i ii t tt tx aa a .
here ij sa represents the metric value corresponding to the thj metric of i sx sd and td are the numbers of metrics in source and target data respectively.
usually the metrics used in sx and tx are different and stdd .
considering the large difference in values of different metrics we firstly employ the z score normalization without using the pooled standard deviation to preprocess data which is similar to the n2 normalization in .
note that the normalization is applicable to either source or target company data.
we then search the common metrics from the metrics used in sx and tx.
we select row vectors that are associated with the common metrics from sx and tx to construct cdn c sx and cdm c tx .
it is noted that the thk rows in c sx and c tx correspond to the same common metric.
to make h eterogeneous data from source and target companies can be compared we define the unified metric representation umr as follows tcc s s ss dd nx xx and scc t t dd m s tx x x where s sx is the data in sx containing source company specific metrics that are metrics except the common metrics in sx and s tx is the data in tx containing target company specific metrics.
after obtaining the unified metric representation defect data from two companies can be readily compared.
figure illustrates the construction of umr for heterogeneous source and target data.
it is noted that when there exist no common metrics in the data from two companies the umr can be defined as ts s dnx x and sdm t tx x .
.
cca for transfer l earning based on the obtained umr for the heterogeneous source and target company data we can employ the effective transfer learning method cca to make the distributions of source and target company data similar.
cca is presented to find a common space for data from two domains such that the correlation between the projected data in the space is maximized.
cca seeks to obtain two projection directions sw and tw one for each company data to maximize the fo llowing linear correlation coefficient ttt ss tts st t t t tt s s t t s ss s t tt tc o vwx wx wc w var w x var w x w c w w c w where cov denotes the covariance function var denotes the auto variance function t refers to the transpose of a vector or a matrix.
with the projection directions sw and tw we can separately project sx and tx into a common space where the projected samples t sswx and t ttwx are maximally correlated that is their distributions can be made to be similar.
this is why cca can be used for ccdp.
ssc and ttc denote the within company covariance matrices of sx and tx respectively.
stc refers to the cross company covariance matrix of sx and tx.
ssc ttc and stc are separately defined as 11ntii s s ss ss ic xmxmn 11mtii t t tt tt ic xmxmm 111nmtij st s s t t ijc xmxmnm where i sx denotes the thi module vector with the unified metric representation in sx sm and tm are the mean modules of sx and tx 11n i ss imxn and 11m i tt imxm .
since formula is invariant with respect to scaling of sw and tw the objective function of cca can be defined as follows max .
.
1stt w w s st t tt s ss s t tt twc w s twc w wc w .
formula can be solved by generalized eigenvalue problem as follows st s ss s st t tt tc wcw c w cw .
is the generalized eigenvalue corresponding to the generalized eigenvector s tw w .
suppose that we get p pairs of projective vectors stww corresponding to the largest eigenvalues we can figure .
illustration of umr construction for heterogeneous source and target data.
source target constr uct umr zero data with common metrics data with company specific metrics 499construct the projective transformation s s spww w and t t tpww w .
when obtaining the projected samples t sswx and t ttwx we use the nearest neighbor nn classifier with the euclidean distance for prediction.
specifically for each projected target sample we predict label defective or defect free for it with the label of the projected source sample that is nearest to it according to euclidean distance.
algorithm realizes the proposed cca approach.
algorithm cca approach require source company data sx target company data tx and the class labels of sx.
output class labels for tx.
.
use the z score normalization to preprocess sx and tx.
.
search the common metric s from the heterogeneous sx and tx and construct the unified metric representation as formula or to obtain sx and tx.
.
construct the covariance matrices ssc ttc and stc.
.
obtain the projective transformations sw and tw by using formula .
.
based on the obtained t sswx and t ttwx use the nn classif ier with the euclidean distance for defect prediction.
.
experiments in this section we evaluate the proposed cca approach for heterogeneous ccdp empirically.
we firstly introduce the benchmark datasets and three commonly used evaluation measures .
then w e perform experiment of hccdp with partially different metrics followed by the experiment of hccdp with totally different metrics .
.
data set in the experiment we employ publicly available and commonly used datasets projects from four different companies including nasa softlab relink and aeeem as the test data.
table tabulates the details about the datasets we used and figure illustrates the detailed metrics used in these companies.
each dataset in nasa represents a nasa software system or sub system which contains the corresponding defect marking data and various static code metrics.
the nasa data was collected from across the united states over a period of five years from numerous nasa contractors working at dif ferent geographical centers .
static code metrics of nasa datasets include size readability complexity and etc.
which are closely related to software quality.
turkish software company softlab contains three datasets i.e.
ar3 ar4 and ar5 which are controller software for a washing machine a dishwasher and a refrigerator respectively.
the used datasets from softlab and those from nasa are obtained from promise repository .
there exist common metrics between these two companies.
although the defect data of these two companies are from the same repository these companies are very different from each other.
relink was collected by wu et al.
and the defect information in relink has been manually verified and corrected.
relink has com plexity metrics which are widely used in defect prediction .
among three used datasets the size of each one the number of modules ranges from to while the number of attributes is fixed to .
the aeeem data set was collected by d ambros et al.
.
aeeem consists of metrics source code metrics previous defect metrics entropy of change metrics entropy of source code metrics and churn of source code metrics .
in particular aeeem includes linearly decayed entropy ldh h and weighted churn wchu .
both ldhh and wchu have been verified as informative defect predictors .
figure lists part of the metrics used in aeeem.
.
evaluation measures in the experiment we employ three commonly used evaluation measures to evaluat e the performance of defect prediction models table .
details of dataset used in the experiment company project description number of metrics number of total modules number of defective modules percentage of defective modules nasa cm1 spacecraft instrument .
mw1 a zero gravity experiment .
pc1 flight software .
softla b ar3 embedded controller .
ar4 embedded controller .
ar5 embedded controller .
relink apache http server apache web server .
openintents safe safe security .
zxing bar code reader library .
aeeem equinox eq osgi framework .
eclipse jdt core jdt development .
apache lucene lc text search engine library .
mylyn ml task management .
eclipse pde ui pde development .
500including recall rate false positive rate and f measure.
these measures can be d efined by using a b c and d in table .
here a b c and d are the number of defective modules that are predicted as defective the number of defective modules that are predicted as defect free the number of defect free modules that are predicted as defective and the number of defect free modules that are predicted as defect free respectively.
table .
four kinds of defect prediction results predict as defective predict as defect free defective modules a b defect free modules c d the r ecall rate is defined as aab .
it denotes the ratio of the number of defe ctive modules that are correct ly classified as defect ive to the total number of defective modules.
this measure is very important for sdp b ecause prediction models intend to find out defective modules as much as possible.
the f alse positive rate is define d as cc d .
it denotes the ratio of the number of defect free modules that are wrongly classified as defective to the total number of defect free modules.
for sdp the prediction precision of a model denotes the ratio of the number of defective modules that are co rrectly classified as defect ive to the number of modules that are classified as defective.
the prediction precision evaluates the correct degree of prediction model and is defined as aac .
obviously a good prediction model desires to achieve high value of recall rate and preci sion.
however there exists trade off between the recall rate and precision.
therefore a comprehensive measure of recall rate and precision is necessary.
f measure is the harmonic mean of recall rate and precision which is de fined as recall precisionf measurerecall precision .
all the above evaluation measures range from to .
obviously an ideal defect prediction model should hold high values of recall rate and f measure and low value of false positive rate.
in the experiment we evaluate the performances of all defect prediction models in terms of recall pd false positive pf and f measure values.
it is noted that we do not specially report results with respect to the precision measure since it has been included in the comprehensive f measure.
.
heterogeneous ccdp with partially different metrics .
.
compared methods and experimental setting to validate the effectiveness of the proposed cca approach for heterogeneous ccdp where the metrics of sou rce and target data are partially different we compare cca with two state of the art cross company defect prediction methods namely nn filter and tnb and a state of the art cross project defect prediction method namely tca .
in these co mpared methods nn filter attempts to select suitable training samples to learn predictors.
and for nn filter each target sample selects nearest neighbors to construct the training set.
tca and tnb employ effective machine learning methods for predicti on.
we design the following two experiments to evaluate our approach one to one heterogeneous ccdp.
we conduct cross company prediction using all modules in only one project as the source company data which can also be called cross project defect prediction.
for example ar4 cm1 cm1 apache etc.
here the left side of denotes the source company data and the right side of represents the target company data.
many to one heterogeneous ccdp.
we conduct cross company prediction using all m odules in multiple projects as the source company data.
for example cm1 mw1 pc1 ar3 cm1 mw1 pc1 apache etc.
for both experiments we observe the prediction results when the number of common metrics is large and when the number of common metrics is very small.
note that all the compared methods can only use the common metrics in the source and target companies.
the evaluation of heterogeneous ccdp does not involve any randomness because all modules in a project or multiple projects from source company constitute the training set and all modules in a project from the target company constitute the test set.
.
.
one to one h eterogeneous ccdp table shows the pd and pf values of one to one heterogeneous ccdp when common metrics exist in source and targe t data.
m denotes the measure.
table tabulates the corresponding f measure values.
in these tables the numbers presented with boldface denote the best results in the corresponding prediction scenes.
from tables and we can see that cca can obtain better pd and pf values in most prediction scenes as compared with other competing methods and it always obtains the best fmeasure values.
the reason is that our approach uses all the metrics rather than only using the common metrics and the company specific metrics usually contain some useful discriminant information.
table .
pd and pf values of one to one heterogeneous ccdp with common metrics source target m tca nnfilter tnb cca ar4 cm1 pd .
.
.
.
pf .
.
.
.
cm1 ar4 pd .
.
.
.
pf .
.
.
.
ar4 mw1 pd .
.
.
.
pf .
.
.
.
mw1 ar4 pd .
.
.
.
pf .
.
.
.
ar4 pc1 pd .
.
.
.
pf .
.
.
.
pc1 ar4 pd .
.
.
.
pf .
.
.
.
cm1 ar3 pd .
.
.
.
pf .
.
.
.
cm1 ar5 pd .
.
.
.
pf .
.
.
.
pc1 ar3 pd .
.
.
.
pf .
.
.
.
pc1 ar5 pd .
.
.
.
pf .
.
.
.
average pd .
.
.
.
pf .
.
.
.
501table .
f measure values of one to one heterogeneous ccdp with common metrics source target tca nn filter tnb cca ar4 cm1 .
.
.
.
cm1 ar4 .
.
.
.
ar4 mw1 .
.
.
.
mw1 ar4 .
.
.
.
ar4 pc1 .
.
.
.
pc1 ar4 .
.
.
.
cm1 ar3 .
.
.
.
cm1 ar5 .
.
.
.
pc1 ar3 .
.
.
.
pc1 ar5 .
.
.
.
average .
.
.
.
ranksum .
.
.
table .
pd and pf values of one to one heterogeneous ccdp with common metrics source target m tca nnfilter tnb cca cm1 apache pd .
.
.
.
pf .
.
.
.
apache cm1 pd .
.
.
.
pf .
.
.
.
pc1 safe pd .
.
.
.
pf .
.
.
.
safe pc1 pd .
.
.
.
pf .
.
.
.
ar4 zxing pd .
.
.
.
pf .
.
.
.
zxing ar4 pd .
.
.
.
pf .
.
.
.
ar3 apache pd .
.
.
.
pf .
.
.
.
apache ar3 pd .
.
.
.
pf .
.
.
.
mw1 zxing pd .
.
.
.
pf .
.
.
.
zxing mw1 pd .
.
.
.
pf .
.
.
.
average pd .
.
.
.
pf .
.
.
.
to statistically analyze the f measure results given in table we perform the wilcoxon rank sum test which is one of nonparameter statistical significance test for comparison of two methods at a co nfidence level of and the rank sum values are shown in the last low of table .
according to the critical value the proposed approach makes a significant difference in comparison with other methods .
in following experiments tables and we also conduct the statistical test and the test results indicate the significant difference exists.
tables and show the pd pf and f measure values of one toone heterogeneous ccdp when only three common metrics exist in defect data from two compa nies.
we can see that when very few common metrics exist in source and target data three compared methods have unsatisfactory performances.
however cca can still achieve normal prediction results.
generally the average f measure of cca in table is significantly inferior to that in table .
the reason is that larger size of common metrics in fact means more useful information can be explored and the large common metric set can relieve the stress of good prediction model learning in aspect of metric difference.
.
.
many to one h eterogeneous ccdp in this subsection we perform the many to one heterogeneous ccdp experiments.
since tca is designed for cross project defect prediction we just take the nn filter and tnb methods as compared methods.
we fi rstly report the prediction results when the source and target company data have common metrics.
the pd pf and f measure values are shown in tables and .
in general as compared with the results in tables and all the compared methods gain some improvement with respect to three used evaluation measures especially pd and f measure.
in addition our cca always outperforms the other compared methods in terms of f measure.
table .
f measure values of one to one heterogeneous ccdp with common me trics source target tca nn filter tnb cca cm1 apache .
.
.
.
apache cm1 .
.
.
.
pc1 safe .
.
.
.
safe pc1 .
.
.
.
ar4 zxing .
.
.
.
zxing ar4 .
.
.
.
ar3 apache .
.
.
.
apache ar3 .
.
.
.
mw1 zxing .
.
.
.
zxing mw1 .
.
.
.
average .
.
.
.
ranksum .
.
.
table .
pd and pf values of many to one heterogeneous ccdp with common metrics source target m nn filter tnb cca cm1 mw1 pc1 ar3 pd .
.
.
pf .
.
.
cm1 mw1 pc1 ar4 pd .
.
.
pf .
.
.
cm1 mw1 pc1 ar5 pd .
.
.
pf .
.
.
ar3 ar4 ar5 cm1 pd .
.
.
pf .
.
.
ar3 ar4 ar5 mw1 pd .
.
.
pf .
.
.
ar3 ar4 ar5 pc1 pd .
.
.
pf .
.
.
average pd .
.
.
pf .
.
.
table .
f measure values of many to one heterogeneous ccdp with common metric s source target nn filter tnb cca cm1 mw1 pc1 ar3 .
.
.
cm1 mw1 pc1 ar4 .
.
.
cm1 mw1 pc1 ar5 .
.
.
ar3 ar4 ar5 cm1 .
.
.
ar3 ar4 ar5 mw1 .
.
.
ar3 ar4 ar5 pc1 .
.
.
average .
.
.
ranksum .
.
we also report the prediction results pd pf and f measure values corresponding to many to one heterogeneous ccdp with three common metrics existing in source and target companies as shown in tables and .
we can see that our approach performs the best in terms of f measure and sufficient source 502company data can improve the prediction performances as compared with the prediction results in tables and .
table .
pd and pf values of many to one heterogeneous ccdp with common metrics source target m nn filter tnb cca cm1 mw1 pc1 apache pd .
.
.
pf .
.
.
apache safe zxing cm1 pd .
.
.
pf .
.
.
cm1 mw1 pc1 safe pd .
.
.
pf .
.
.
apache safe zxing pc1 pd .
.
.
pf .
.
.
ar3 ar4 ar5 zxing pd .
.
.
pf .
.
.
apache safe zxing ar4 pd .
.
.
pf .
.
.
ar3 ar4 ar5 apache pd .
.
.
pf .
.
.
apache safe z xing ar3 pd .
.
.
pf .
.
.
cm1 mw1 pc1 zxing pd .
.
.
pf .
.
.
apache safe zxing mw1 pd .
.
.
pf .
.
.
average pd .
.
.
pf .
.
.
table .
f measure values of man y to one heterogeneous ccdp with common metrics source target nn filter tnb cca cm1 mw1 pc1 apache .
.
.
apache safe zxing cm1 .
.
.
cm1 mw1 pc1 safe .
.
.
apache safe zxing pc1 .
.
.
ar3 ar4 ar5 zxing .
.
.
apache safe zxing ar4 .
.
.
ar3 ar4 ar5 apache .
.
.
apache safe zxing ar3 .
.
.
cm1 mw1 pc1 zxing .
.
.
apache safe zxing mw1 .
.
.
average .
.
.
ranksum .
.
.
heterogeneous ccdp with totally different metrics .
.
experimental setting for heterogeneous ccdp where source and target companies have totally different metrics existing ccdp methods cannot be used for prediction.
in this part we perform within project target target prediction experiments and use the within project prediction results as