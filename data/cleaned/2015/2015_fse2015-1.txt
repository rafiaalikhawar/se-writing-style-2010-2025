rule based extraction of goal use case models from text tuong huan nguyen john grundy mohamed almorsy faculty of science engineering and technology swinburne university of technology melbourne australia huannguyen jgrundy malmorsy swin.edu.au abstract goal and use case modeling has been recognized as a key approach for understanding and analyzing requirements.
however in practice goals and use cases are often buried among other content in requirements specifications documents and written in unstructured styles.
it is thus a time consuming and error prone process to identify such goals and use cases.
in addition having them embedded in natural language documents greatly limits the possibility of formally analyzing the requirements for problems.
to address these issues we have developed a novel rule based approach to automatically extract goal and use case models from natural language requirements documents.
our approach is able to automatically categorize goals and ensure they are properly specified.
we also provide automated semantic parameterization of artifact textual specifications to promote further analysis on the extracted goal use case models.
our approach achieves precision and recall rates on average for model extraction and accuracy for the automated parameterization.
categories and subject descriptors d. .
requirement specifications languages methodologies tools.
general terms algorithms languages.
keywords goal use case modeling extraction semantic parameterization.
.
introduction requirements engineering re is an iterative process of eliciting structuring specifying analyzing and managing requirements of a software system .
the functionality and constraints of a target system identified in each re iteration are usually captured in a textual software requirements specification document srs .
goal use case integration modeling guim has been recognized as a key approach for understanding organizing justifying and analyzing requirements and facilitating early system designs .
guim helps capturing the underlining rationale and motivation of the system being developed while aligning the business objectives with the functionalities and constraints of system components.
the details of system user interactions use cases are also modeled and linked to system goals.
such a combination enables guim to provide a comprehensive view of the system .
however extracting and modeling goals and use cases from srss are not trivial tasks.
domain experts often find it difficult to formulate and express goals at the required abstraction levels .
in textual requirements documents goals are normally buried among other non goal sentences and written in unstructured styles.
furthermore frequently use cases descriptions are not clear in requirements documents.
multiple use case steps may be combined as one i.e.
by conjunctions .
moreover data or non functional constraints are often mixed up with use case steps making it hard to locate the information they need.
due to such complexities manual goals and use cases modeling can be a tedious time consuming and error prone process especially for inexperienced requirements engineers and large requirements documents.
in addition having goals and use cases embedded in natural language documents greatly limit the capability of the automatic requirements analysis for quality problems.
in fact such automated analysis support requires requirements to be expressed in formal specifications or semantically parameterized so that their contents can be processed by computers.
for these reasons we propose a novel approach with tool support named goal use case model extraction supporting tool guest to automatically extract goal and use case models from requirements specification documents.
guest is part of our goal and use case integration framework gui f that supports the elicitation and analysis of goal use case integration models.
our technique is based on a set of extendable extraction rules that help identify goals use cases and their relationships from texts.
moreover relying on our goal use case integration meta model that provides classification and specification rules of goals based on their levels of abstraction and quality attributes guest is able to automatically categorize goals and ensure they are properly specified.
furthermore guest provides automated semantic parameterization of textual artifact specifications to enable the automatic analysis of extracted goal use case models in our gui f framework.
this paper makes the following key contributions a rule based approach to automatically extract goal use case models from software requirements specifications.
the extraction carries out the identification of goals use cases including use case steps pre post conditions data or non functional constraints and their relationships from texts categorization of goals and the guaranty of proper artifact specifications in extracted goal use case models.
a technique to automate the semantic parameterization of textual artifact specifications to allow model analysis.
validating our approach with various requirements from both literature and industry.
we achieved the precision and recall rates of and on average respectively for goal use case model extraction and accuracy rate for the automated semantic parameterization of textual artifacts.
permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
esec fse august september bergamo italy.
copyright acm ... .
.
s1 this software system will be a web publishing system for a local editor of a regional historical society.
s2 this system will be designed to maximize the editor s work productivity by providing tools to assist in automating the article review and publishing process which would otherwise have to be performed manually.
s3 by maximizing the editor s work efficiency and productivity the system will meet the their needs while remaining easy to understand and use.
s4 more specifically this system is designed to allow an editor to manage and communicate with a group of reviewers and authors to publish articles to a public website....use case manage reviewerbrief descriptionthe editor enters a new reviewer or update information of the current reviewer.initial step by step descriptionbefore this use case can be initiated the editor has already accessed the main page of the article manager.
.the editor selects to manage a reviewer.
.the system presents manage options.
manage options include add reviewer or update reviewer .
.the editor selects an manage option.
.if the editor is updating a reviewer the system presents the information of the reviewer else the system presents a list of reviewers and presents information of a reviewer after the editor selects that reviewer.
.the editor fills in the information and submits the form.
.the system verifies the information and returns the editor to the article manager main page.after this use case is successfully finished the reviewer s information is storedbg2 maximise the editor s work productivityffg4 editors shall be able to manage a group of reviewersffg1 assist in automating the article review processffg2 assist in automating the article publishing processbg1 meet the editor s needsbg3 maximise the editor s work efficiencynpg1 the system shall be easy to understandnpg2 the system shall be easy to useffg5 editors shall be able to manage a group of authorsffg7 editors shall be able to communicate with a group of reviewersffg6 editors shall be able to communicate with a group of authorsffg3 editors shall be able to publish articles to a publish website use case uc1 manage reviewer actor editorpre condition the editor has already accessed the main page of the article managerpost condition the reviewer s information is storedsteps .
the editor selects to manage a reviewer2.
the system present manage options3.
the editor selects a manage option4.
if the editor is updating a reviewer the system presents the information of the reviewer5.
the editor fills in the information6.
the editor submits the form7.
the system verifies the information8.
the system returns the editors to the article manager main pageextension ext1 condition the editor is not updating a reviewer starting step extension steps .
.
the system presents a list of reviewers .
.
the editor selects a reviewer .
.
the system presents information of the selected reviewer resuming step fsg1 editors shall be able to add new reviewersfsg2 editors shall be able to update reviewers informationbusiness levelproduct levelfeature levelservice level b a dc1 manage options include add reviewer or update reviewer operationalize linkrefine linkconstrain link figure example of goal use case model extraction from text2.
motivation figure presents an example of a goal use case model extracted from textual requirements.
figure a shows some parts taken from a requirements document.
figure b presents a desired goal use case model to be extracted from the requirements.
bg1 bg2 etc.
are business goals.
ffg1 ffg2 etc.
are functional feature goals.
fsg1 fsg2 etc.
are functional service goals.
.
identification of artifacts from text identifying artifacts from text is a key challenge because not all sentences and not all parts of a sentence in a requirement document contain goal or use case descriptions multiple goals or use case steps maybe mixed up in a single sentence use case steps are often combined with constraints and alternative paths are often combined as a single step.
thus automatically filtering important information from text is needed.
so is the automatic separation of different artifacts mixed up together.
example sentence s1 does not contain a goal description it is rather an introduction to the system.
thus it should be ignored.
example in sentence s2 the part which would otherwise have to be performed manually has no significance regarding the objective functionality or quality of the system.
similarly this system will be designed to is unimportant.
in addition s2 contains multiple phrases that can be extracted to goals bg1 ffg1 and ffg2 in figure b .
note that the phrase assist in automating the article review and publishing process is split into two goals ffg1 and ffg2 as conjunctions i.e.
and are discouraged in textual requirements to avoid ambiguity .
example step of the use case figure a contains a use case step in the first part and a data constraint about manage options in the second part.
they need to be distinguished to guarantee a correct extraction of use cases.
additionally step number is a combination of two separated steps the editor fills in the information and the editor submits the form .
example step of the use case figure a combines a use case step with an extension specification.
it should be extracted into the extension ext1 in figure b .
.
identification of artifact relationships a goal use case model requires the relationships between the artifacts to be specified.
these relationships are often implicitly mentioned in requirements specifications.
example in sentence s2 the structure by providing... implies a refinement relationship between providing tools to assist in automating the article review and publishing process and maximize the editor s work productivity .
it is then extracted as showed between bg1 ffg1 and ffg2 in figure b .
.
classification of goals in goal modeling goals need to be classified to functional or non functional.
moreover they need to be classified based on how abstract or concrete they are.
both such classifications are important to understanding and analyze goal models.
example the goal bg1 meet the editor s needs should be classified as a business goal and placed on the business level since it describes a business objective not a functionality or quality.
example the goal npg1 the system shall be easy to understand should be classified as a non functional goal since it describes a usability quality that the system must meet.
moreover npg1 should be placed on the product level since it is concerned about the system as a whole rather than a specific feature.
.
ensure artifacts are properly specified when identifying artifacts relevant text in the requirements document is located.
however they are often fragments of the sentences they are in and thus in many cases cannot be used as descriptions for stand alone artifacts.
therefore we need to ensure those artifacts are rewritten in a sensible way after being extracted.
example in sentence s3 it is identified that remaining easy to understand contains a goal description.
however this phrase by itself is not a meaningful goal description.
the context of the whole sentence needs to be considered to obtain a proper specification.
as showed in figure b this phrase is rewritten as the system shall be easy to understand to specify npg1.
specificationcore predicatereferencelocationspatial orientationdestinationsource0.. .. .. ..1purpose0.. .. .. .. ..1additional participantbeneficiarycompanywaymeansmannerextended predicatetensenegation111duration0..1nuclear predicateverbtargetobjectquality110..1primary participantagentpositioner0..1frequency0..1proposition predicateconditionevent0.. .. .. figure the structure of a specification figure artifact layer example in sentence s3 meet their needs is identified as a potential goal description.
the context of the sentence is needed to recognize which noun phrase the possessive adjective their refers to.
a replacement of their by the editor is necessary for a proper goal specification bg1 .
this process is referred to as coreference resolution in the natural language processing field.
.
requirements model in this section we discuss functional grammar and present our goal use case integration meta model on which artifact classifications and specifications are based.
.
functional grammar functional grammar fg is a grammatical theory concerning the organization of natural languages .
in fg a sentence contains different components with unique semantic roles called semantic functions.
in our work fg is the underlining theory to parameterize artifact specifications i.e.
goals use case steps .
this provides a standard way to interpret the semantic role of each group of words in a specification and thus offers a means to interpret and analyze specifications.
figure presents the structure of a specification.
a specification consists of four predicates.
for instance nuclear predicate contains elements describing which action is conducted verb on what target object etc.
core predicate provides details about the beneficiary or how an activity is performed manner .
each semantic function is described by a term.
for instance nominal terms are used to describe entities while verbal terms describe activities.
example the specification of goal ffg1 in figure b is parameterized as verb maximize object nomterm head work productivity possessor editor .
example the use case uc1 s step is parameterized as agent system verb present object nomterm head inform ation possessor reviewer condition agent reviewer verb update object reviewer .
.
goal use case integration meta model our meta model contains two layers the artifact layer provides the classification of artifacts while the specification layer provides specification rule for each artifact class.
business goalnuclear predicatecore predicateverbtargetbeneficiarypossessive verbaction verbtobetransitive action verbintransitive action verbobjectqualityreferencemanner110..1extended predicatetensenegation111locationspatial orientationdestinationsource0.. .. .. ..1purpose0.. .. .. .. .. figure specification rule for business goals .
.
the artifact layer figure depicts the key components of artifact layer that defines the artifact classes across levels of abstractions.
for instance business goals describe the business objectives of the software system e.g.
maximize the editor s productivity .
functional feature goals list features the system should support in order to achieve business goals while offering no details as to what functions are needed to support a feature e.g.
assist in automating the article publishing process .
functional service goals provide the details of how a feature is achieved and thus contains the description of what function a user can perform e.g.
editors shall be able to add new reviewers .
non functional product goals are concerned with quality attributes of the product as a whole e.g.
system shall be easy to use .
non functional service goals specify quality constraints of associated service e.g.
editors shall be able to add new reviewers easily .
constraints i.e.
data constraint and various relationships between the artifacts i.e.
require refine... are also defined.
.
.
the specification layer this layer imposes rules on how each artifact should be specified.
it provides guidelines for writing artifacts as to which semantic functions should and should not be used for a certain artifact.
for example since business goals are usually high level strategic statements condition or duration should not be specified while other parameters i.e.
beneficiary are permitted.
figure shows the specification rule for business goal s specifications.
pre processingrequirements documentlinguistic analysisartifact relationship identificationartifact polishing transformationartifact clasisifcation goal use case model construction sections with artefact specsclassified artefactspolished textual specs formal specsraw artifact specs relationshipsparse trees dependency treesgoal use case modelguest guitar identified incompleteness inconsistency incorrectness figure process for goal use case model extraction figure example of section indicator list figure example of parse tree figure example of dependencies .
our approach figure presents an overview of our extraction approach supported by tool guest in the context of our goal use case integration framework gui f .
the extraction consists of six main steps.
first the requirements document is preprocessed to find the sections that contain goal and use case specifications.
in addition the text in these sections is analyzed to remove unnecessary information such as pictures brackets and multiple whitespaces.
secondly a linguistic analysis is done on the text to resolve coreference and obtain part of speech pos and typed dependencies of tokens words using the stanford parser .
in step our rule based engine analyzes the outcome of the parser to identify raw artifact specifications and relationships.
in step these raw specifications are polished to properly specify artifacts and then parameterized.
next the polished specifications are used to classify artifacts into different abstraction levels.
in the last step a goal use case model is constructed.
within our gui f framework the extracted goal use case model can then be analyzed by our guitar tool which supports the identification and resolution of inconsistency incompleteness and incorrectness.
in this paper we focus on guest.
.
requirements document pre processing guest currently accepts requirements documents in .doc or .txt formats.
although there is no specific constraint on the structure of such documents the sections in a document must be numbered in a strictly ascending order.
a list of section indicators also needs to be manually created by users at the beginning.
such list contains the specifications as to which sections should be ignored which sections should be considered as sources of goals or use cases we call such sections important sections .
figure presents an example of a simplified section indicator list in xml format.
given the indicators provided guest first automatically extracts plain text from the document i.e.
remove all figures .
it then analyzes the text to identify the important sections.
it then removes unneeded details from those sections to prepare for the linguistic analysis in step .
these include texts describing within brackets multiple whitespaces and symbols i.e.
ellipsis exclamation slashes .
.
linguistic analysis the linguistic analysis includes the resolution of coreference and parsing of texts for pos and dependency information.
.
.
coreference resolution coreference refers to cases in which a pronoun or possessive adjective is used to replace a noun phrase in the same or nearby sentence.
for instance in the sentence the editor fills in the form and submits it it replaces the form .
in our work we use the stanford coreference resolution system to resolve coreference.
for instance the resolved sentence would be the editor fills in the form and submits the form .
.
.
syntactic and dependency parsing to automate the identification of potential artifact specifications and relationships from a sentence it is important for computers to understand the composition of such a sentence.
specifically we need to identify its grammatical structure i.e.
what are the noun phrases verb phrases or adjectival phrases the roles of words in the sentence i.e.
which word is verb noun adjective or adverb and the relationships between words i.e.
a word is an object or adjectival modifier of another .
based on such understanding computers can be trained to recognize important parts while ignoring unimportant parts in the sentences in regard to goal descriptions and identify relationships between goals.
consider for example the sentence the system is designed to maximize the editor s work productivity by automating the article review process .
figure shows the parse tree that contains the identification of phrases i.e.
np noun phrase vp verb phrase and part of speech of words i.e.
in preposition vbn past participle verb in the sentence.
figure presents the typed dependencies between words.
for example productivity is the direct object dobj of maximize automating is the prepositional clausal modifier prepc by of maximize.
the parsing results of these structure and dependencies are critical for our rule based extraction technique which will be discussed in section .
.
.
in our work the linguistic parsing is done by using our extended version of stanford lexicalized parser .
we have retrained the stanford parser with requirements specifications data and enabled the parser to be incrementally trained with new data without the need to re train from scratch to accommodate new data.
.
artifact and relationship extraction the use of rules to extract artifacts and relationships is inspired by our observation that although requirements specification text is freely styled and unstructured the identification of unimportant phrases or goal relationships usually follow certain patterns.
for instance consider again the example sentence the phrase the system is designed to should be ignored because it contains no important information.
the role of this phrase is to introduce an intention following it in the sentence i.e.
maximize the editor s work productivity .
if this phrase were used in another sentence its role would not change and should still be ignored.
in addition the words in this phrase do not equally contribute to its unimportance.
in fact system is designed and to are more important than the .
this leads to the conclusion that the phrase system tobe designed to do something with tobe refers to the use of is are will be shall be ... should be ignored in any sentence containing it.
moreover in this sentence the refinement relationship between automate the article review process and maximize the editor s work productivity is recognized by the structure do something by something detected in the sentence.
our observation showed that refinement relationships could be extracted by this structure in most cases.
note that normal textual comparison cannot guarantee correct extractions.
for instance if we identify refinement relationships by looking for the exact match of verb object by verb ing then we would fail to reveal the relationship in maximize the editor s work productivity by efficiently automating the article review process because efficiently is now between by and verb ing making the structure unmatched.
it is the dependencies between the words that matter rather than the order they appear in the sentence.
in fact the most important factor in this example is the prepc by relationship between maximize and automating.
this relationship would still remained unchanged regardless of what details are added into the related verb phrases of maximize and automating the relationship between the two words would only change if the connector by is removed or either of them is changed or the sentence structure is modified .
therefore we rely on the dependencies between words to define extraction rules.
table terminologies of typed dependency term explanation node a word in a dependency tree link a dependency between two nodes i.e.
det system this universal root the node that has no incoming link i.e.
designed x sub tree sub tree of the dependency tree that has x as its root artifact goal or use case components i.e.
step condition .
.
extraction rules the discussion in this section is based on the examples in figure and .
table presents some typed dependency s terminologies.
table presents the syntax of our extraction rule with a list of representative rule execution actions1.
a rule contains two parts condition specified by a list of variables and dependencies and actions.
in the extraction a sentence s dependency tree is matched against the condition of a rule.
if they are matched the actions will be executed to generate a new dependency tree as the output.
since goals and use case specifications are normally located in separated sections in a requirements document and the extraction is done section by section the extractions of them are carried out separately except that a use case description sometimes contains information about the goal it operationalizes .
we thus developed separate sets of extraction rules for goals and use cases.
.
.
.
goal extraction rules there are four types of goal extraction rules as follows.
ignorance rule ignorance rules are used to recognize sentences or parts of a sentence that have no important information.
they thus should be ignored during the extraction process.
rule r1 in table implies that the word specifically which is used as an adverbial modifier of a verb in a sentence should be ignored.
navigation rule a navigation rule requires the dependency tree s root to be moved to a certain node which means every node which is not part of the new root s sub tree will be removed.
full reference of our rules can be found at consider rule r2 in table it can be seen that the dependency tree in figure matches this rule x is designed and y is maximize .
following this rule the root is at designed originally needs to be moved to maximize y .
this implies that the attention now is on the maximize sub tree maximize the editor s work productivity by automating the article review process .
relationship rule relationship rules are concerned with extracting goals while identifying relationships between them.
we support the specification of rules to identify sub goal refinement and relevant relationships.
goals are considered relevant when they are related but no additional information to infer more detailed relationship between them.
rule r3 can be used to identify the refinement relationship between automate the article review process and maximize the editor s work productivity .
splitting rule splitting rules are used in case coordinating conjunctions i.e.
and or are used in a sentence.
they allow a sentence to be split into two parts with sibling if and is used or alternative if or is used relationship between them.
for instance r4 can be used to extract two alternative goals reader can search articles by author names and reader can search articles by categories from the sentence reader can search articles by author names or categories .
.
.
.
use case extraction rules in a section that potentially contains use cases the use case components i.e.
use case name steps exceptions can normally be identified using a list of indicators similarly to the section indicator list presented in figure .
for instance the terms actor or primary actor indicate the actor specification of the use case the terms main scenario or basic path indicate the main list of use case steps.
these lists can be updated or extended depending on the needs of specific projects.
however in many cases such indicators are missing from the use case specification or the specification of a component contains extra information or the components are mixed up with each other.
thus we developed a list of extraction rules to reveal these components from texts.
below we discuss example use case extraction rules.
step extraction rule this type of rules is designed to extract use case steps combined in one single sentence i.e.
by and or or after before .
using a step extraction rule not only the steps are extracted but also their relationships i.e.
precede are identified.
in case two steps have an alternative relationship a new extension is then created to establish an alternative scenario.
rule r5 is an example of this type.
extension extraction rule is used to identify extensions embedded in step description.
rule r6 can help reveal the extension embedded in step in figure a .
specifically an extension with condition the editor is not updating a reviewer and a step the system presents a list of reviewers and presents information of a reviewer after the editor selects that reviewer is extracted.
this step is further extracted into three consecutive steps using our step extraction rules.
use case constraint extraction rule is used to identify non functional or data constraints that are combined together with use case steps.
for instance rule r7 can be used to recognize the data constraint the manage options include add reviewer and update reviewer in the motivating example cf.
figure .
use case relationship rule this is to identify use case relationships i.e.
extend include .
consider a use case step use case register for membership is performed rule r8 can be used to identify the include relationship between the currently processed use case and the register for membership use case.
table extraction rule syntax syntax explanation example s generic rule syntax variable declarations dependency declarations action declarations the syntax of a rule contains parts variables and dependencies specify the matching condition of the rule and a list of actions to be executed if the rule is matched.
variable declaration x a or x a b variable x has the value of a or one of the values in a b... example x designed aimed x ab or x ab cd variable x has the pos tag of ab or one of the pos tags in ab cd... example x nn nns dependency declaration root x specify that x is the root of the dependency tree a root has no dependency link pointing to it dep name x ?
there is a dep name dependency between x and any node.
example dobj x ?
dep name x y there is a dep name dependency between x and y. example xcomp x y dep name x ?
ab cd there is a dep name dependency between x and any node having one of the pos tags of ab cd ... example nsubj x ?
nn nns dep name x a b there is a dep name dependency between x and any node that has one of the values of ab cd ... example nsubjpass x system project not dep name x y there is no dep name dependency between x and y. example not xcomp x y action declaration ignore x ignore the x sub tree.
if x is the root of the entire dependency tree then the whole sentence is ignored root x move the root to node x consider only the sub tree whose root is x ignore the rest of the tree sub goal goal x goal y establish a sub goal relationship between goal extracted from the x sub tree and the one from y sub tree split sibling x y split alternative x y splitting the sentence into two separated ones based on the conjunction build goals based on these sentences and establish a sibling if and is used or alternative if or is used between these goals preceed statement x statement y specify that the statement extracted from the x sub tree is the preceding step of the one from y sub tree uc data constraint statement y specify the statement extracted from the y sub tree is a data constraint of the currently processed step table examples of goal extraction rules ignorance rule r1 navigation rule r2 relationship rule r3 splitting rule r4 x specifically advmod ?
vb vbz vbn x ignore x x designed aimed y vb root x nsubjpass x system project auxpass x be is are xcomp x y root y x vb vbd vbg vbn vbp vbz y vbg root x prepc by x y sub goal goal y goal x x nn nns nnp jj y nn nns nnp jj inferred conj or x y split alternative x y step extraction rule r5 extension extraction rule r6 constraint extraction rule r7 use case relationship rule r8 x vb vbd vbg vbn vbp vbz y vb vbd vbg vbn vbp vbz inferred conj and x y not prep between ?
nn nns x not prep between ?
nn nns y not mark x if not mark y if preceed statement x statement y x vb vbd vbg vbn vbp vbz y vb vbd vbg vbn vbp vbz z vb vbd vbg vbn vbp vbz mark x if nsubj x ?
nn nns nnp nnps advcl y x root y advmod z parataxis y z extension condition neg x extension step z uc step y x include contain y choices options alternatives z nn nns nnp w nn nns nnp root x nsubj x y dobj x z dobj x w conj and z w uc data constraint statement y x case y use z performed w vb vbd vbg vbn vbp vbz nn nnp nns nn x y nsubjpass z x ccomp z w auxpass z is be root z uc include w .
.
how are extraction rules used?
rules can conflict with each other.
for instance two rules specifying the same condition list of dependencies or the conditions of a rule is a sub set of the conditions of another rule but their actions are different.
guest is able to detect such rules and report them to end users for modification in some cases condition overlap is not a problem if there is a rule of higher priority than another .
in addition there exist cases that a single sentence matches multiple rules and executing a rule before another may lead to different results.
to solve this problem rules of different types are given different priorities.
for instance the goal extraction rules are prioritized in the following order ignorance rules navigation rules relationship rules and splitting rules.
in the case of having multiple matching rules of the same type guest executes all of them and produces alternative outputs.
the tool then reports this issue to users for their decisions.
to extract artifacts from sentences we use an iterative process to analyze each sentence in consideration of the rule ordering.
for instance the outcome may contain multiple goals if a relationship or splitting rule is used is then considered in the next iteration and so on.
the process ends when no matching rule is found.
.
polishing and parameterization in this step extracted text artifacts in the form of dependency trees are taken to produce polished textual specifications and functional grammar based parameterization.
.
.
artifact specification polishing specification polishing is used to ensure textual artifacts are expressed in a proper way.
the cases when polishing is required include the text extracted from a sentence and its tense i.e.
continuous tense is not suitable for a stand alone artifact specification the text is in passive voice and the text is incompatible with our meta model s specification rules.
the first two cases require algorithms to check the dependency tree for tense i.e.
the root is a verb with vbg pos tag or passive voice use i.e.
look for auxpass dependency link and making relevant modifications in the dependency tree.
however the third case requires deeper analysis.
in our work it is recommended that artifacts are specified using action verb whenever possible to enable better comparison and analysis of artifacts .
this view has also been adopted in many requirements engineering research i.e.
.
however there exist many cases in which functionalities or conditions are described in other forms i.e.
using adjective preposition phrases.
the examples below present some of these cases.
example editors are capable of entering new reviewers is re written as editors shall be able to enter new reviewers .
example readers without technical knowledge can search for articles should be re written as readers who do not have technical knowledge shall be able to search for articles .
example there is more than one reviewers in the list should be rewritten as more than one reviewers exist in the list .
to solve this problem we developed an extendable set of rewriting rules that share the same syntax with extraction rules.
a text is checked for a match with a rewriting rule that then triggers the execution of the rule actions to make necessary modifications.
the phrase shall be able to is added to goal specifications only.
the rewriting rule for the text in example can be found below.
x capable y nn nns nnp nnps z nn nns nnp nnps t be is are were was nsubj x y cop x t root x prep of x z replace adj root x add verbal root w do x z t true false z dobj w z .
.
artifact specification parameterization parameterization of specifications enables the understanding of artifacts because it identifies the semantic role of each single word in an artifact specification.
for instance given the goal specification of editors shall be able to add new reviewers easily parameterized as agent editor verb add object head reviewer attribute new manner easily .
from the parameterization it can be identified which function the system supports add new reviewers who the function is for editors how the function is accomplished easily what the function s object is reviewers what the object s attribute is new .
we term such representation as structured specification in our framework.
to generate structured specification from a textual one we need to identify the semantic role function each word or group of words plays.
the input for this process is the polished dependency tree from step .
.
.
this process starts with the investigation in the dependency tree to determine the value of the verb semantic function since it is the central function in our structured specifications.
normally universal root constitutes the value of verb except when to be verb is used.
the determination as to which semantic function a group of words should fall into depends on the relationship between the root of that group and the universal root.
for instance if x is the universal root then the relationship nsubj x y indicates that the y sub tree is the value of the agent semantic function.
similarly dobj x y may indicate y sub tree is the value of the object semantic function.
however due to the complexity of english there are always exceptions.
for instance in the sentence system notifies users about the changes although notifies is the root and there exist the relationship dobj notifies users users is not the object but instead beneficiary.
in addition there is no rule for prepositional phrases.
for instance in dependency tree of the sentence editors can login with their accounts has the prep with login account relationship and their accounts has the means semantic role in this case.
however in sentence editors can communicate with reviewers reviewers has the company semantic role although the relationship prep with communicate reviewers exists.
we overcome this problem by developing a set of semantic labeling rules based on an investigation on the common english verb adjective preposition combinations.
below we give labeling rules for the discussed examples.
the first one means that if prep with communicate y exists the y sub tree has the means semantic role.
the second one means that if prep of notify y and dobj notify z exist then y sub tree is reference and z sub tree is beneficiary semantic functions.
.
goal classification after the extracted dependency trees are polished textual specifications are generated from them.
in this step they are classified to determine whether they are functional or non functional goals and which levels of abstraction they are on.
although a number of techniques and tools have been proposed to automatically classify requirements in the literature i.e.
none of is currently available for download and use in our work.
we thus selected mallet one of the best general text classifiers that are available for artifact classification.
mallet can classify a text into a fixed set of classes such as functional vs. non functional based on labeled training examples.
it includes implementations of several classification algorithms including na ve bayes maximum entropy and decision trees.
mallet calculates the probability of each word for being classified into a certain class based on the labeled training data.
the probability of the whole text for being classified into a certain class is determined by the probabilities of the words it contains.
in this work we extended mallet by using text preprocessing to improve its accuracy to be discussed in section .
the improvements are discussed as follows removal of unimportant content mallet considers every word in a text for probability calculation.
however not all words are needed in this process.
in fact we modified it to remove unimportant details such as stop words i.e.
a the that shall symbols i.e.
coma and numbers since their existence does not determine the class of a text.
ensure the standard form of the word is used we updated mallet to consider only the standard form of words.
for instance the probability is calculated for present not presents or presented if they are used in the text.
use a set of classification keywords we developed a set of keywords that support the classification of artifacts.
for instance available and easy to use are non functional goal keywords.
productivity is a business goal keyword.
our classifier is composed of two separated classifiers.
the horizontal classifier is used to determine if a text is business functional or non functional goal specifications.
for a non functional goal it also provides the prediction as to which non functional category it belongs to i.e.
security usability .
currently we support the identification of non functional categories.
the vertical classifier is used to identify the abstraction level a goal should belong to product feature or service level .
the rationale for using two separated classifiers is that they can help reducing training data size.
for instance if a single classifier were used then we would need sufficient training data for 13x3 classes as opposed to only classes business goal functional goals and non functional goal categories for the horizontal classifier and classes for the vertical classifier.
additionally the training data can be shared between the two classifiers given they are appropriately labeled for each classifier.
up to now we have trained the classifiers with over requirements collected from multiple sources including online resources literature and books.
guest allows the classifiers to be further trained or re trained.
.
goal use case model construction after the artifacts are extracted and classified and relationships are identified the model can be constructed.
the following subsections describe the main issues to be addressed in this step.
identify duplicate artifacts sometimes goals are repeated in different sentences in requirements documents.
for instance the communicate with company notify of a1 beneficiary reference goal maximize the editor s productivity is repeated twice in the motivating example cf.
figure a .
repeated goals are merged into one in the model.
in guest not only exactly duplicate artifacts are identified highly overlapping artifacts are also reported to end users.
the identification of overlaps between artifacts is done using their parameterizations.
in fact we compare two specifications by matching their corresponding semantic functions i.e.
match agent of a specification with agent of another object with object .
partly overlapped artifacts are reported to users to decide if a merge of them is suitable.
report model construction problems other problems may occur during the model creating.
for instance a goal has the equivalent probabilities for two classes i.e.
feature and service .
another example is an inconsistency can exist if the goals fsg1 ffg1 are classified as functional service and functional feature goal respectively while an extraction rule infers that ffg1 is a sub goal of fsg1.
this situation is invalid since feature goals are on a higher level than service goals and thus a feature goal cannot refine a service goal.
all problems from the extraction process are reported to users for the decisions.
other problems the emphasis of this paper is on extracting goal use case models from what provided in requirement documents.
the problems related to the extraction are identified and reported to users.
however problems inherited from the requirements documents e.g.
the model is inconsistent due to some inconsistencies exists in the original requirement documents are beyond the scope of this paper.
such problems have been tackled in our previous work with the guitar tool which supports the analysis of goal use case models for incompleteness inconsistency and incorrectness.
since guest is integrated into guitar we can ensure the seamless support for the building and analysis processes of goal use case models.
guest is not aimed at fully automating the entire extraction process as this is almost impossible since requirements documents can be found in different structures and written in uncontrolled styles.
it is rather intended to assist requirements engineers in modeling goals and use cases from requirements documents.
thus there may be cases not all artifacts and relationships can be extracted i.e.
a necessary extraction rule may be missing .
to assist requirements engineers in verifying the extraction results and possibly continue the extraction manually guest provides features such as producing extraction logs that capture all steps during the extraction process mapping artifacts with original text where they are extracted from and allowing users to modifying the extracted models.
.
evaluation in this section we present three evaluations conducted to evaluate the effectiveness of guest in extracting goal use case models from requirements documents.
specifically we seek to answer the following research questions rq1 how accurately does guest classify artifacts by their textual specifications?
rq2 how accurately does guest parameterize textual specifications?
rq3 how accurately does guest extract goal use case models from requirement specifications documents?
table presents our formulas to calculate the metrics for each research questions.
our full experimental data can be found at table formulas for metrics formulas rq1 tp true positive number of artifacts are correctly classified fp false positive number of incorrectly classified artifacts rq2 rq3 tp true positive number of valid extracted artifacts or relationships fp false positive number of invalid extracted artifacts or relationships fn false negative number of artifacts or relationships not extracted training data size precision a casamayor our extended mallet original mallet training data size recall b casamayor our extended mallet original mallet figure classifier benchmark validation results .
rq1 artifact classification a benchmark validation was carried out to compare and contrast our requirements classifier with the existing state of the art classifiers casamayor et.al.
non functional requirements classifier we term it as casamayor and original version of mallet original mallet .
the reasons for this selection were fourfold.
first casamayor is among the classifiers developed recently and reportedly obtained high results in its evaluation.
second casamayor s experiment steps were described clearly and its data is available making it possible to reconstruct the exactly same validation.
thirdly no requirements classifier was available to download and lastly original mallet was selected to verify whether our improvements made to extend it were effective.
we followed casamayor s experiment steps to run a validation on promise dataset that consists requirements collected from software development projects.
among them items are marked as functional requirements and the remaining non functional requirements are classified into categories such as security performance and usability.
only the non functional requirements were used in this evaluation.
multiple experiments were run.
in each experiment a k portion of data i.e.
k was randomly selected as training data and the rest used as testing data.
each experiment is run in iterations to obtain the scores for the precision and recall metrics cf.
table .
experiments were run with k was ... .
figure a and b present the comparison graph between three classifiers for precision and recall.
all three classifiers obtained higher precision and recall rates when the training set size increased.
it can be noticed from this comparison that our classifier produced higher quality results than others when the training set was small.
this was due to the support of our non functional indicator keywords.
when the training set size increased casamayor s results raised with highest rates and surpassed our classifier when the training set was over of the entire data as showed in the graphs .
original mallet followed a very similar trend as our classifier that is due to the share of algorithms between the two classifiers.
however our classifier outperformed original mallet with at least difference in most experiments.
from these results the key benefit of our classifier is that it performs relatively well with a small training dataset.
table parameterization validation results round existing capability over round best achievable capability over table extraction validation results case study ops sps average artifact d fp fn precision recall relationship d fp fn precision recall polishing parameterization goal classification d total detected fp false positive fn false negative .
rq2 artifact parameterization promise data was pre processed before being used in this validation.
for instance we split a requirement into multiple ones if it contains more than one sentence.
in addition combined words such as his her himself herself were changed to single words i.e.
his .
moreover each sentence with coordinating conjunctions i.e.
and is split.
however if the split sentences have identical structure i.e.
readers can search articles and readers can download articles we only keep one of them to maintain the structural differences between requirements.
we have randomly selected requirements from all projects and requirements collected from the literature.
each requirement was parameterized by guest and the results were manually checked by us to determine the accuracy rates.
a two round validation was conducted.
firstly we parameterized the requirements based on our existing collection of rewriting and labeling rules to verify guest s existing parameterization capability.
we then identify the reason for errors found in the results.
if the reason was incorrect parsing or missing supporting rules we then trained the parser with a correct parse tree or attempted to write new rules using our defined syntax.
in round the failed parameterizations were re generated with new information.
the result of this round was the best achievable capability of guest in this validation.
table indicates that we obtained and of accuracy in round and respectively.
there were a number of requirements unsupported by guest because their grammatical structures were not recognized by our meta model.
for instance out of accesses to the system the system is available times .
.
rq3 goal use case model extraction we used the online publication system ops and split payment system sps industrial case studies in this validation.
ops case study comes with a requirements document with pages and sentences.
sps requirements document contains pages and sentences.
each requirements document follows the ieee requirements specification template and contains a number of sections for goals and use cases.
in each case study we manually modeled goals and use cases from the given requirements document and then compare that model with the one generated by guest.
we analyzed the results of each extraction phrase to provide detailed evaluation of the approach.
the phrases analyzed were extraction of raw artifacts and relationships polishing and parameterization of artifacts and goal classification.
the results are showed in table .
we achieved precision and recall rates for the artifact extraction and precision and recall rate for the relationship extraction.
a number of artifacts and relationships were not extracted due to the missing of relevant extraction rules.
in addition some relationships were not detected since detecting such relationships required the understanding of the entire contexts in which the artifacts were specified.
for instance this system is designed to allow an editor to communicate with reviewers and authors.
the software will facilitate communication between authors reviewers and the editor via e mail .
guest could not identify the relationship between these two goals.
however an alert regarding the possible overlap between them was generated.
we achieved accuracy rates of the polishing and parameterization of artifacts to be considered correct the artifact needed to be both correctly polished and parameterized .
the common errors were due to missing relevant rewriting rules.
for instance guest could not properly rewrite the goal include support for simultaneous bills to the desired form support simultaneous bills .
we achieved for goal classification in this validation.
these evaluation results indicate that the missing artifacts and relationships were due to missing extraction rules.
the incorrectness in artifact parameterization and classification came from invalid results produced by the linguistic parser and artifact classifier respectively.
results could be improved if our extraction rules set is extended and the parser and classifier further trained.
.
threats to validity threats to external validity include representativeness of the selected subjects and quality of our parser classifier and rules.
to reduce these we increased the variability of the data by selecting requirements from different sources.
for rq2 we carried our a second round of validation to evaluate the tool in case the parser and rules were perfect for the given set of requirements.
threats to internal validity include the human factors in determining the correctness of guest results in each validation.
in rq3 we manually extracted goals and use cases from the requirements documents.
in rq2 and rq3 we manually verified the tool s outputs for semantic parameterization goals use cases and their relationships and classifications.
to mitigate we reviewed all manual tasks twice.
using two or more people with relevant knowledge and experience in validation would further improve.
.
discussion and future work reduce effort for goal use cases modeling our approach can reduce the effort and time to model goals and use cases from requirements documents for analysts.
moreover guest can potentially be used to quickly gain understanding of natural language requirements documents.
guest rules can be used across different projects.
users can add new rules to improve the quality of extraction.
furthermore since guest s underlying techniques for natural language parsing and artifact classification provide support for multiple languages it is possible to adopt and apply our approach for requirements written in other languages.
however a new set of extraction rules that suits the grammars of each such language needs to be developed.
enable the analysis of goal use case models our automated semantic parameterization enables the seamless integration of guest and our tool guitar which provides automated analysis of goals and use cases .
this provides comprehensive support for the modeling and analysis on goal use case models.
possible application of our technique in other areas our technique of automated parameterization can be used for any textual sentences.
while our set of extraction rules was developed specifically for goals and use cases its underlining concept can still be applied to support the information extraction in other areas.
for instance extraction rules can be developed in a similar way i.e.
develop rule actions and algorithms to execute these actions to identify privacy or security policies from software documents.
our rule based technique can also provide a new approach in ontology learning .
specifically similar rules can be created to detect ontological concepts properties and their relationships to extract ontologies from natural language texts.
guest s extraction accuracy depends on the quality of the stanford parser and the artifact classifier a common issue for a statistical machine learning technique is that it may not produce correct results for what it has not been trained for.
therefore it is possible to have a sentence incorrectly parsed or a specification incorrectly classified in guest.
such problems can be resolved by training the parser and classifier with relevant data.
guest provides the incremental training of both the parser and classifier.
understanding of grammatical dependency required for rules writing in guest the extraction and rewriting rules need to be manually written.
this requires the rule writers to have knowledge of grammatical dependency and thus some training would be required for end users to be able to extend the rules repository.
we plan to overcome this problem by developing an algorithm that semi automates the generation of a rule from the associations between sentences and lists of desired information to be extracted from them.
in addition a visual rule editor would be developed.
unidentifiable artifact relationships a number of relationships between artifacts in different sentences are not detectable.
detecting such relationships requires the understanding of the entire context in which they are specified.
our future work will thus will focus on resolving these types of problems.
lack of evaluation of the approach s usefulness although having promising results in our case study based evaluation guest has not been validated for a real software project.
we thus plan to carry out an evaluation with our industry partners to evaluate the approach s usefulness in requirements engineering.
.
related work to the best of our knowledge no technique has been proposed to automatically extract goal use case models from natural language documents.
in this section we discuss existing techniques that extract requirements or use cases separately.
natural language requirements extraction and formalization rauf et.al.
proposed a technique to identify sections that contains logical structures lss such as requirements or use cases and logical components lcs such as actor or use case extensions in a requirements document.
their objective is to locate where requirements and use cases are located similar to what we achieved by using a list of section indicators.
this work however does not extract individual requirements use cases and their relationships.
niu and easterbrook semi automatically extract product line requirement asset from natural language requirements documents based on the use of functional requirement profile domain terminologies and heuristic rules.
however this only focuses on functional requirements in the format of verb direct object.
ghosh et.al.
transforms textual requirements into linear temporal logic based on the use of dependency parsing domain specific terminologies and a set of transformation rules.
it has no support for extracting requirements or goals from texts.
breaux et.al.
developed a semantic parameterization technique to formalize natural language goal specifications with description logics.
they provided a set of templates in which a statement contains a number of semantic components such as subject object and location.
this is similar to semantic functions in our work.
however we provide a larger set of semantic roles i.e.
our frequency duration roles are not supported in their work .
also this work does not automate the semantic parameterization.
extraction of use cases from natural language documents ilieva used linguistic analysis to extract use case paths model from uncontrolled natural language use case specifications.
this work is only concerned with identifying actor action a single verb and their ordering without considering other information i.e.
object target of a use case step pre post condition or data constraints .
drazan and mencl developed a technique to identify use case steps from textual use case descriptions.
similar to our work it is able to identify multiple steps combined using coordinating conjunctions.
the limitation of this work is that it assumes use case descriptions are written in a restricted natural language.
in addition it does not allow the extraction of other use case components i.e.
pre post condition or extensions .
sinha et.al.
developed a linguistic analysis engine to get the understanding of textual use case descriptions.
the engine is able to identify components in use case steps actor action and classify steps into a number of predefined classes i.e.
update input output using a domain dictionary.
this work however does not deal with the cases when multiple artifacts i.e.
step and constraint are mixed together.
in addition various use case components i.e.
conditions extensions constraints are not detectable.
rago et.al.
focused on extracting sequenced use case steps from textual use cases and identifying duplication among them.
it however does not support the identification of other use case components and relationships between use cases.
.
summary we have developed a semi automated rule based approach to extract goal use case models from unformatted textual requirements documents.
it incorporates various techniques to locate goals use cases and their relationships from text ensure they have proper textual specifications classify goals and provide semantic parameterization of their textual specifications.
evaluation results are very promising.
in two selected case studies guest achieved precision and recall rates for goals and use cases extraction and of precision and recall rates for relationships extraction.
it obtained accuracy for the automated parameterization with promise data.
the evaluation showed that our artifact classifier entirely outperformed mallet and was better than casamayor s classifier with smaller training datasets.
guest is integrated with our previous work on goal use case automated analysis guitar providing a comprehensive framework for goal use case extraction and analysis.
.