combining deep learning with information retrieval to localize buggy files for bug reports an ngoc lam anh tuan nguyen hoan anh nguyen and tien n. nguyen iowa state university usa email anlam anhnt hoan tien iastate.edu abstract bug localization refers to the automated process of locating the potential buggy files for a given bug report.
to help developers focus their attention to those files is crucial.
severalexisting automated approaches for bug localization from a bugreport face a key challenge called lexical mismatch in which the terms used in bug reports to describe a bug are differentfrom the terms and code tokens used in source files.
this paperpresents a novel approach that uses deep neural network dnn in combination with rvsm an information retrieval ir technique.
rvsm collects the feature on the textual similarity between bugreports and source files.
dnn is used to learn to relate the termsin bug reports to potentially different code tokens and terms insource files and documentation if they appear frequently enoughin the pairs of reports and buggy files.
our empirical evaluationon real world projects shows that dnn and ir complement wellto each other to achieve higher bug localization accuracy thanindividual models.
importantly our new model hyloc with acombination of the features built from dnn rvsm and project sbug fixing history achieves higher accuracy than the state of the art ir and machine learning techniques.
in half of the cases itis correct with just a single suggested file.
two out of three cases a correct buggy file is in the list of three suggested files.
i. i ntroduction in a project software developers spend a great deal of time and effort in debugging and fixing software defects.
those software defects also called bugs are reported by different stakeholders such as the end users testers or even developers.
the stakeholders often report the defects in the documents called bug reports.
they describe the scenarios in which the software does not perform as expected and provide relevant information regarding the reported defects.
after being assigned to repair the defect s reported in a bug report a developer will investigate and locate the source files that are relevant to the defects and potentially defective also called buggy .
this process is often referred to as bug localization .
the process of localizing the defective buggy files after analyzing the reported bugs is important for developers to quickly and efficiently fix them.
however this process could cost much time and effort.
for a large project developers might have to investigate a large number of source files make the logic connection from the description of the bug s in the bug report to the relevant source files and leverage their domainknowledge to locate the buggy files.
the manual process inorder to find and understand the cause of a bug can be timeconsuming.
thus it is desirable to have automated tools forbug localization that help developers focus their attention to the potential buggy files relevant to a given bug report.
several automated approaches have been proposed to help developers in bug localization process.
the approaches can bebroadly divided into two categories that complement to each other in localizing the bugs.
the first line of approaches is fault localization based on the statistics of program analysis information .
those approaches rely on analyzing the semantics of the program and or its execution information with test casessuch as passing failing execution traces.
in contrast the second line of approaches analyzes the content of a given bug report.
they use information retrieval ir o r machine learning ml to automatically search for the relevant potential buggy files by extracting important features from the given bug report and source files.
the ir based bug localization approaches share the same principle.
the given bug report is construed as a query.
thesource files in the project are viewed as a collection of doc uments.
the bug localization problem from a bug report is modeled by the searching ranking problem in ir.
latent dirichlet allocation was used to extract topic features for comparison.
zhou et al.
develop an advanced v ector space model which considers textual similarity between bug reports and files as well as the information on the similar bugs that were previously fixed.
a few bug localization approaches from bug reports have been based on machine learning .
bugscout is a special topic model that assumes that the technical topic s described in the given bug report are also those of thebuggy files.
the topic model is trained to link the topics of the reports and those of source files.
kim et al.
apply naive bayes using previously fixed files as classification labels and use the trained model to assign source files to each report.
ye et al.
use adaptive learning to rank via features from source files api description bug fixing and change history.
several researchers have identified lexical mismatch between natural language texts in bug reports and technical terms in source code as the key limitation of those aforementioned ir based bug localization methods.
those ml based approaches also face the lexical mismatch problem.
to improve accuracy ye et al.
and kim et al.
use the additional features from the metadata of the reports e.g.
version platform priority etc and the bug fixing histories on source files.
to bridge the lexical gap ye et al.
additionally use the texts from the documentation of the apis used in the source files.
however api documentation contains texts regarding moregeneral tasks than project specific buggy behaviors.
kim et al.
do not use the source files s contents to extract features.
they use only the names of the fixed files as classification labels on the reports.
thus they cannot suggest the files that have notbeen fixed before for a new bug report.
bugscout an ml approach uses only one level of abstraction in topics thus might not sufficiently link the terms in two spaces of the 30th ieee acm international conference on automated software engineering .
ieee bug reports and the source files.
in brief lexical mismatch is still an issue for existing ir and ml approaches.
in this work we build hyloc a model combining revised v ector space model rvsm an advanced ir technique with deep neural network dnn to recommend the potentially buggy files for a bug report.
rvsm extracts the feature to measure textual similarity between bug reports and source files.
dnn is used to measure the relevancy between them by learning to relate the terms in bug reports and potentially different code tokens and terms in source files if they appear frequently enough in the pairs of reports and corresponding buggy files.
dnn has been successfully used in other areas e.g.
pattern recognitions natural language processing nlp image and text processing with its capability to capture highlevel discriminative information on the input features.
we aim to empirically investigate that capability on code features and whether it could lead to bridge that lexical gap.
to extract feature for the relevancy between a bug report and a source file we use dnn as follows.
an dnn contains two separate spaces to handle the features of different nature in thebug reports text tokens and in the source files e.g.
identifiers apis comments .
after being projected into the spaces with a smaller number of dimensions the projected features are fed into two dnns an dnn to learn the relations between bug reports texts and the textual tokens in code i.e.
comments and another dnn to learn between bug reports texts and code tokens i.e.
identifiers apis .
we aim to investigate if dnn can emphasize the relations of the text features in bug reports and the related features in source files via its weights.
generally a key limitation of dnn is scalability.
in this problem the numbers of examples and features are in the range of hundreds of thousands.
to address that we adapted the dnn based autoencoder to reduce the dimensions of the feature spaces while maintaining important information and removing redundant one.
each counting feature in each space in the input is projected into a continuous valued feature space with a smaller number of dimensions.
in addition to gaining scalability we expect that the terms that are related in some abstraction will be mapped to nearby locations at least along some dimensions in the projected space as shown in nlp .
in addition to the textual similarity feature computed from rvsm and the relevancy feature from the above dnns we also integrate the third types of features called metadata features extracted from the bug fixing history as in the prior work by yeet al.
and kim et al.
.
for example a recently fixed file is more likely to still contain bugs than a file that was last fixedlong time ago.
thus we compute the bug fixing recency scorefor a file and use it as a metadata feature.
to combine those three types of features textual similarity relevancy and metadata we use another dnn as a non linear feature combinator to compute the final score of a file with respect to a bug report.
our empirical experiments on several projects showed that combining rvsm and dnn achieves higher accuracy than individual models.
hyloc with the combination of three above types of features improves .
.
top accuracy .
.
relatively over the state of the art approach in ye et al.
which has been shown to outperform ir based buglocator and the topic based bugscout .
it achieves .
.
higher top accuracy than the naive bayes approach in kim etal.
.
we also showed that dnn and rvsm complement well and dnn can link terms in bug reports and different terms and code tokens in relevant source files.
this paper contributes .
hyloc a model for bug localization combining ir and dnn.
we also introduce a dimension reduction technique and a feature combination technique using dnn and .
empirical studies on real world projects to show that the improvement of hyloc over the existing approaches.
ii.
a c ombining model for buglocalization a. key design ideas we propose hyloc a combination model with the key ideas .
using dnn to bridge the lexical gap in which features of different types in bug reports and source code arehandled in different spaces.
inspired by the success of dnn in capturing high level abstractions we expect dnn to bridge the lexical gap by learning to relate the terms in bug reports tothe code tokens or comments in source code that might notbe textually similar to one another.
to compute the relevancy between a bug report and a file we treat the reports as texts andextract the textual tokens.
in the source code space we extractthe following features identifiers apis api method calls and classes textual comments and textual descriptions of apis used in the code.
instead of putting them in the same feature space as in existing ir and ml approaches in our dnn we collect the features of different types into separate spaces and build the feature vectors.
moreover we use two dnns oneto learn the relations between bug reports texts and the textual tokens from source code and another dnn to learn between bug reports texts and the code tokens.
the rationale for two spaces is that we expect that the dnns can recognize such relations via the weights among the features of different nature in two spaces if they occurred frequently enough in the pairs of bug reports and the corresponding buggy files.
.
using another dnn for feature combination.
we aim to combine dnn to handle lexical mismatch and rvsm an ir model to measure textual similarity to complement each other.
moreover as in ye et al.
we also consider the features extracted from the bug fixing history of a project including therecency and frequencies of bug fixing files etc.
instead of usinga hill climbing algorithm for adaptive ranking as in ye et al.
we chose to combine the features via another dnn.
we expect that with sufficient training data the weights in the layers reflect the weights of features in the combination.
the combination via dnn with non linear function is expected to perform better than the linear combination in ir based adaptive learning.
dnn will combine types of features textual similarity relevancy and project s metadata .
.
using another dnn to perform dimension reduction for feature vectors.
the number of features extracted from bug reports and source code files during training can be very large.
thus to scale to real world projects inspired by autoencoder we built a dnn model to reduce the number of dimensions of the feature space while maintaining importantinformation.
the idea is to train the dnn model for projection in which it can encode the original feature vectors in a waythat maximizes the similarity between those original vectors and the decoded vectors from the encoded ones.
477file1.java bug report source filesfilen.javabrscore br file1 .
.
score br filen ranked files file2 file1 ... bugs code changes project s informationmetadata extractionfeature extractionprojection projectiondnn based relevancy estimationdnn based feature combinationranking 1feature extractiontext similaritymetadata scores fig.
hyloc bug localization model b. model architecture figure shows the architecture of the entire model.
for training we create a positive pair of a bug report and one of its corresponding buggy files.
the pairs are created for all corresponding buggy files and for all bug reports as well.
we also create the negative pairs by selecting for every bug report the non buggy files that are textually similar to the report.
for each pair of a bug report and a source file we extract the features from them and build the feature vectors.
each vector has its elements being the significance values of features in the feature types.
the feature vectors for each type of features are projected into a continuous space with smaller dimensions using the corresponding autoencoder dnn.
all vectors after projection are fed into a dnn to learn the relevancy of each file with respect to a bug report.
the output of the dnn relevancy estimator called relevancy score is fed into the dnn based feature combinator which learns the weights to combine three types of features relevancy computed from dnn textual similarity computed via rvsm and the metadata of the bugfixing history .
the weights of the feature combinator help to set the importance of the features in determining the buggy filesfor a bug report.
note that all the dnns for relevancy estimationand feature combination in our stack based architecture can be trained independently one layer at a time where each layer is treated as an unsupervised restricted boltzmann machine.
we take advantage of this key advance of multi layer architecture in dnn over regular ann in order to scale hyloc to largeprojects.
in an ann all the weights must be trained at the same time in the same model .
for prediction for a given bug report b we will pair it with each source file f. the features are extracted and feature vectors are built for each pair.
our model produces the final score for fwith respect to b. the higher score implies that the model estimates that fis more potentially buggy for b. all the scores for all the source files are used to rank them.iii.
dnn based relev ancy estimation figure shows the dnns for feature reduction and relevancy estimation between a bug report and a source file.
their feature vectors are fed into the projection dnns.
the outputs of those projection dnns are concatenated into larger vectors and used as the inputs of the dnn based relevancy estimator.
the estimator takes those inputs and outputs a relevant score for a bug report and a file.
in the relevancy estimator weuse two dnns to learn the relations between the features in the bug report and those in the source files.
more specifically the first dnn is used to learn the relations for the text features frombug reports and the source code features such as identifiers and api elements the names of api classes and methods .
we call this dnn bug report to code dnn .
the second dnn called bug report to t ext dnn is to learn the relations between the textual features in the bug reports and those in comments and apidescriptions.
the reason for the use of two dnns with the separation between the first group of identifiers and apis and the second group of comments and api descriptions is that theformer is source code while the latter is natural language texts.
the bug reports might contain both and should be matched with both groups.
the use of two dnns bug report to code dnn and bug report to t ext dnn is the key difference of our model from the existing approaches because we want to use dnn to learn the linking of the features with different nature.
for each dnn of the relevancy estimator we use the samednn architecture as the rbm machine except that we use only one hidden layer.
the formula to compute the output of the relevancy estimator is the same.
we expect that the two dnns for the relevancy estimator would relate the features in bug reports and those in source code and the features in bug reports and those in comments and api descriptions.
the relations are expected to be expressed via the weights from the input features to the nodes in the output of a dnn.
for example resource connection session ina bug report are expected to be strongly related to some hidden nodes that are also impacted much by the nodes representing getcounterrec ctx getpermission in the identifier group and by the nodes representing addlocalejb and sessionexpired in the api group.
the outputs of the two dnns of the estimator are fed into the dnn based relevancy output module.
in training its output is a score of or where indicates relevancy.
inpredicting the relevancy score can have any value between0 and .
the higher the score the higher the confidence the model estimates the relevancy between a bug report and a file.
iv .
e mpirical ev aluation we conducted several experiments aiming to evaluate the accuracy and time efficiency of hyloc in localizing buggy files from bug reports study the impacts on accuracy of hyloc s parameters components and features and compare hyloc to the existing ir and ml approaches for bug localization.
a. experimental setting and metrics benchmark dataset.
for comparison we used the same dataset provided by ye et al.
table i .
all the bug reports source code links and buggy files api documentation and the oracle of bug to file mappings are all publicly available at thanks to the authors.
478projection dnn resource connection ... session getcounterrec ctx getpermission addlocalejb sessionexpired close context locking property change session create accessrelevancy estimatorrelevancy output bug report texts identifiers apis classes methods comments api descriptions source code...br to code dnn br to text dnn projection dnn projection dnn projection dnn projection dnnoutputs inputs... ... inputsoutputsdnn fig.
dnns for projection and relevancy estimation table i subject projects project time range brs sourcefiles aspectj birt eclipse ui jdt swt tomcat for comparison we used the same procedure as in ye et al.
.
note that the number of all source files in a project is very large making the training time with all negative samples impossible.
thus for training they and we used text similarity measure to rank all the files and selected only the top similar files to the bug report as the negative samples.
for prediction we still compute the scores and rank all the files in a project.
we sorted the bug reports chronologically by their report timestamps.
for all projects except the smallest project aspectj we divided the bug reports into folds with equal sizes in which fo l d 1is the oldest and fo l d 10is the newest.
we trained a model on fo l d iand tested it on fo l d i .
for aspectj we divided the bug reports into folds since it has smaller number of reports and used the same testing strategy.
we used three metrics for evaluation.
top ranked accuracy is measured as follows.
if one of the buggy files of a givenbug report is within the topklist of files we count it as a hit.
otherwise we consider that as a miss.
the top kaccuracy is measured by the percentage of hits over the total numberof suggestions in all the folds.
to consider the cases of a bug report with multiple buggy files we also measured mean average precision map and mean reciprocal rank mrr .
b. impacts of components and parameters on accuracy in this experiment we evaluated the impact of different components and parameters of hyloc on its accuracy.
we chose tomcat one of the smaller subject systems in our dataset.
accuracy with different components in this experiment we varied different components and compared the accuracy of fig.
top k accuracy with different components newly configured models to learn their impacts on accuracy.
figure shows the result.
the lines marked with dnn shows for the accuracy of the model using only dnn to compute bug report to file relevancy as the sole feature.
as seen dnn by itself does not give high accuracy.
investigating further we see that due to projection to a new space with smaller dimensions more source files with the same technical topics are included but they are not buggy with respect to a given bugreport.
when using the relevancy feature via dnn and the bug fixing metadata features line dnn meta the accuracy is much improved top accuracy from to and top accuracy from to .
the model using text similarity rvsm i s equivalent to buglocator i.e.
without using dnn and bug fixing metadata features .
the top ranked accuracy ranges from .
however when we combined relevancy feature computed by dnn and textual similarity feature computed by rvsm see line dnn rvsm the accuracy is higher than those of both dnn and rvsm individually.
the absolute improvement values over dnn are from for top ranked accuracy.
the corresponding improvement values over rvsm are from relative improvement from .
.
to study further the results from the dnn rvsm and dnn rvsm models we drew their venn diagrams figure .
our goal is to evaluate how much overlapping between the 29top top 84top 150top 255top dnn rvsm dnn rvsm dnn rvsm vs vs fig.
venn diagrams for correct results of approaches correct result from the combining model dnn rvsm and those from the individual models dnn and rvsm .
we computed such overlaps for different top ranked resulting lists with and files .
that is if a buggy file was in a top ranked list of a model we consider that it is a correct case and vice versa.
the left column shows the overlapping between the results of the model dnn and the combining model dnn rvsm .f o r example at the first diagram on the top left corner of figure for a top list in a total of correct cases dnn rvsm is correct in cases.
only of them were correctly identified by dnn but not by dnn rvsm and of them were correctly identified by dnn rvsm but not by dnn .
in general across all top ranks the combining model covers a good percentage of the results by dnn while it correctly identified many more results that dnn did not.
the second column of figure displays the overlapping between the correct result of rvsm and that of the combining model dnn rvsm .
it is consistent across all top ranked accuracy that the correct result of dnn rvsm covers a large percentage of that of rvsm .
moreover the correct results of dnn rvsm rvsm are multiple times .
.2x more than those of rvsm dnn rvsm i.e.
.
.
of all total results .
interestingly there are cases in which both dnn and rvsm does not put the file in the top list but dnn rvsm does.
finally hyloc achieves highest accuracy with the combination of relevancy via dnn textual similarity via rvsm and the metadata features figure .
with a single suggestion it has the correct buggy file in almost of the cases.
two out of three cases a correct buggy file is in the list of suggested files.
with suggested files it is correct in of the cases.
example we examined the cases where dnn contributes to improve accuracy while the ir model rvsm does not put the actual buggy files in a top ranked list.
they correspond to the cases in dnn rvsm rvsm figure and or dnn ranks the actual files higher in the resulting list than rvsm.
we found acommon phenomenon in those cases that reporters described inthe bug reports the scenario s leading to failure or unexpectedbehaviors using texts without many code tokens.
in those cases the buggy files have few comments and do not contain many identifiers and terms that appear also in bug reports.table ii linking terms in reports and terms tokens in files br token token token token context authorization ctx envctx asynccontext resource virtualclasspath changesessid setsecureclass addlocalejb writer globalcachesize charset index charswritten read headerlength internalbuffer readbytes dir examples of linking terms in two spaces in nlp researchers have shown that dnn is able to project and link the words that are semantically or grammatically related into nearby locations at least along some dimensions in a continuousvalued feature space.
in this experiment we study the examples in which hyloc with its dnn machinery is able to learnthe relations between the terms in the bug reports and the terms tokens in the relevant source files.
we conducted an experiment on the dnn model in figure after training.
we used each of the textual tokens in all bug reports as the input.
we paired it with each of the code tokens insource files and the textual tokens in comments documentations.
we used that dnn to compute the score output for each of such pairs.
finally for each textual token in a bug report we produced the list of relevant tokens in source files ranked by the relevancy score between two tokens.
figure ii displays a few examples of related terms in the bug report with top scores computed by the dnn model.
as seen despite usingdifferent lexical terms e.g.
context versus ctxand envctx dnn is able to relate them in two spaces.
moreover the term resource does not appear in the buggy file standardcontext.java however dnn can relate it to the terms in that file such as virtualclasspath changesessid setsecureclass etc.
since they appear frequently in the pairs of bug reports and buggy source files.
therefore dnn is able locate and rank that buggy file highest.
feature combination comparison to compare feature combination by dnn and by learn to rank approach we built another experimental model in which all three types offeatures in our model is combined via learn to rank instead of dnn.
we then compared the accuracy of that newly built model called lrcombine and the model where all features are combined via dnn.
our result shows that at top accuracy with dnn our model achieves higher than lrcombine while the improvement at top is .
this shows that the non linear combination of those features is better than the linear one via learn to rank for this bug localization problem.
c. accuracy comparison our next experiment aims to compare hyloc to the stateof the art approaches including the naive bayes nb approach by kim et al.
the lr learn to rank approach by ye et al.
and buglocator by zhou et al.
.
while nb is an ml approach buglocator is ir based and lr is a hybrid one.
we used the same dataset provided by ye et al.
and conducted our experiment in the same procedure and metrics.
therefore we used the results reported in the paper by ye et al.
for comparison.
in their paper they also reported the result from running buglocator on the same dataset.
thus we also used that result for buglocator.
for the nb approach in kim et al.
which is not publicly available we followed their description for re implementation.
480table iii accuracy comparison system model mrr map tomcat hyloc .
.
.
.
.
.
.
.
.
.
lr .
.
.
.
.
.
.
.
.
.
bl .
.
.
.
.
.
.
.
.
.
nb .
.
.
.
.
.
.
.
.
.
aspectj hyloc .
.
.
.
.
.
.
.
.
.
lr .
.
.
.
.
.
.
.
.
.
bl .
.
.
.
.
.
.
.
.
.
nb .
.
.
.
.
.
.
.
.
.
birt hyloc .
.
.
.
.
.
.
.
.
.
lr .
.
.
.
.
.
.
.
.
.
bl .
.
.
.
.
.
.
.
.
.
nb .
.
.
.
.
.
.
.
.
.
eclipse hyloc .
.
.
.
.
.
.
.
.
.
lr .
.
.
.
.
.
.
.
.
.
bl .
.
.
.
.
.
.
.
.
.
nb .
.
.
.
.
.
.
.
.
.
jdt hyloc .
.
.
.
.
.
.
.
.
.
lr .
.
.
.
.
.
.
.
.
.
bl .
.
.
.
.
.
.
.
.
.
nb .
.
.
.
.
.
.
.
.
.
swt hyloc .
.
.
.
.
.
.
.
.
.
lr .
.
.
.
.
.
.
.
.
.
bl .
.
.
.
.
.
.
.
.
.
nb .
.
.
.
.
.
.
.
.
.
first as seen in table iii in comparison with buglocator at top accuracy hyloc achieves from .
higher relatively higher .
at top accuracy the improvement is from .
.
.
as explained in section iv b the relevancy feature computed by the dnn model helps to complement the textual similarity feature computed by rvsm in buglocator to bridge the lexical gap between bug reports and source files.
thus hyloc with an additional feature of project s metadata achieves even higher accuracy than buglocator.
second compared to the learn to rank lr approach at top accuracy hyloc achieves from .
.
higher relatively .
.
higher .
at top accuracy the improvement is from .
.
.
the key to bridge the lexical gap in the lr approach is to add to the feature set the terms in the api documentation for the apis used in the source files.
we foundthat such addition is not effective in the cases of popular apis such as java.util in java development kit.
those apis do not help in linking a bug report to source code because the report describes a more specific erroneous functionality in the system.
in contrast the dnn based relevancy estimator can handle the lexical mismatch in those cases since it connects a report to a buggy file if the terms appear frequently enough in the pairs of bug reports and files.
third we found that hyloc is able to correctly suggest several cases where nb approach in kim et al.
missed because their approach has not seen the fixed files before.
the key reason is that their approach uses the previously fixed files as labels for training but does not consider their contents.
at top amd top accuracy hyloc achieves from .
.
and .
higher respectively.
generally hyloc also consistently achieves highest accuracy in mrr and map.
its mrr values are from .
.
.
that is in the best scenario among cases it would rank an actual buggy file at the 2nd place in two cases and likely rankanother actual buggy file as the top candidate in the other case.
d. time efficiency table iv shows hyloc s training and predicting time.
all experiments were run on a computer with cpu intel xeon cputable iv training and predicting time in minutes systemtraining for one fold predicting for one report max average max average tomcat .
.
aspectj .
.
birt .
.
eclipse .
.
jdt .
.
swt .
.
e5 .00ghz cores gb ram.
since we need only one fold for training to predict the next fold we measuredthe training time for one fold.
we measured the predicting time for individual bug reports.
as expected training time is large for a solution involving one thread to run dnn.
however we could investigate parallel computing infrastructures for dnns or the incremental training techniques to update the model after getting more bug reports and fixed files over time.
predicting time is reasonable within a few minutes for one bug report .
v. c onclusion this paper presents a combining approach between rvsm an information retrieval technique and deep neural network dnn in which dnn is used to learn to connect the concrete terms in bug reports to the code tokens and terms in source files.
our empirical evaluation on several real world projects shows that dnn and ir complement well to each other to achieve higher bug localization accuracy than individual models.finally our new model hyloc achieves higher accuracy than state of the art ir and machine learning techniques.
acknowledgment this work was supported in part by the us nsf grants ccf1518897 cns ccf ccf ccf1349153 twc ccf and ccli .