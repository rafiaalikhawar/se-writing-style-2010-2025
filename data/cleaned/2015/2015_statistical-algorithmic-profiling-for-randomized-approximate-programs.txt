statistical algorithmic profiling for randomized approximate programs keyur joshi vimuth fernando sasa misailovic university of illinois at urbana champaign kpjoshi2 wvf2 misailo illinois.edu abstract many modern applications require low latency processing of large data sets often by using approximate algorithms that trade accuracy of the results for faster execution or re duced memory consumption.
although the algorithms provideprobabilistic accuracy and performance guarantees a softwaredeveloper who implements these algorithms has little supportfrom existing tools.
standard profilers do not consider accuracyof the computation and do not check whether the outputs ofthese programs satisfy their accuracy specifications.
we present a xprof an algorithmic profiling framework for analyzing randomized approximate programs.
the developerprovides the accuracy specification as a formula in a mathe matical notation using probability or expected value predicates.
a xprof automatically generates statistical reasoning code.
it first constructs the empirical models of accuracy time andmemory consumption.
it then selects and runs appropriatestatistical tests that can with high confidence determine if theimplementation satisfies the specification.
we used a xprof to profile approximate applications from three domains data analytics numerical linear algebra and ap proximate computing.
a xprof was effective in finding bugs and identifying various performance optimizations.
in particular wediscovered five previously unknown bugs in the implementationsof the algorithms and created fixes guided by a xprof .
i. i ntroduction modern applications such as machine learning data analytics computer vision financial forecasting and content search require low latency processing of massive data sets.
to meetsuch demands researchers have developed various approxi mate algorithms data structures and systems software thattrade accuracy for performance and or memory consumption.
many emerging approximate algorithms come with analytically derived specifications of accuracy.
the specificationsare typically probabilistic e.g.
an algorithm will return thedesired result with high probability.
as an example locality sensitive hashing algorithm can find nearest neighborsin a set of points by using smart hashing to group similarpoints.
it guarantees to return the most similar points with highprobability.
probabilistic specifications have been proposed forapplications in areas as diverse as theoretical computer sci ence numerical computing databases and compilersand hardware architectures .
despite many rigorous specifications a software developer who needs to implement test and tune these randomized pro grams and systems has virtually no tool support for this effort.standard profilers only track and build models of run timeand memory consumption for individual inputs or build performance models for multiple input sizes inthe case of algorithmic profiling .
researchers have also given guidelines for how to rigorously apply statisticaltesting in software engineering e.g.
but the process ismanual and the developer may end up with inflexible andoverly conservative choices of test parameters.
there are numerous tasks that the developer needs to perform manually infer the properties of the mathematical prob abilistic specification write code to check this specification decide on the appropriate statistical test and its parameters e.g.
confidence or power provide appropriate inputs andinterpret obtained statistical metrics.
frustrated by such man ual effort developers often resort to ad hoc testing.
moreover manually written test code can have various subtle errors thatprevent the discovery of errors in the implementation.
a morepromising alternative is to automate these tasks with profilingand testing frameworks.
our work.
we present a xprof an algorithmic profiling framework for analyzing accuracy execution time and memory consumption of approximate programs.
a xprof constructs statistical models of accuracy time and memory checks if any of them deviate from the algorithm specifica tion and if so warns the developer.
a xprof is available at the key novelty of a xprof is the automatic generation of the accuracy checking code from a high level probabilisticspecification section iv .
the developer written specificationhighly resembles the mathematical specification that algorithmdesigners provide as a part of their theoretical study.
a xprof supports two general probabilistic predicates probability predicate it specifies that the probability that the output returned by the approximate program satisfies acondition is below above or equal to a certain threshold.
expectation predicate it specifies that the output s expected value is below above or equal to a certain threshold.
these two predicates can capture the key properties of many representative randomized and approximate computations.
forinstance they are expressive enough to capture the majorityof the accuracy specifications of the randomized algorithmsfrom .
they can also model common accuracy specifica tions from other domains such as numerical linear algebraand approximate computing.
ieee acm 41st international conference on software engineering icse .
ieee authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
an important concern of a xprof s language design is to present the specifications in an unambiguous manner.
in general probabilistic specifications can be defined over different sets of events e.g.
runs or inputs which may require different sampling procedures.
in a xprof a developer explicitly writes if a probabilistic specification is over inputs items within an input or runs.
for each specification a xprof automatically selects a proper statistical test generates checking code that aggregates the outputs and applies the selected test and determines the number of samples to achieve a desired level of statistical confidence.
testing randomized programs often requires a large number of concrete inputs.
to automatically produce representative inputs we provide several input generators for scalars vectors and matrices that allow for various input properties to be modified the difference in the frequency of values order of data or various forms of correlations.
we present a dynamic analysis that infers which of these properties have a significant impact on the algorithm s accuracy section v .
results.
we evaluated a xprof on a set of programs that implement well known randomized approximate computations from the domains of data analytics numerical linear algebra and approximate computing.
each application has an analytically derived specification of accuracy performance and memory consumption.
we demonstrate that a xprof can help developers in two scenarios profiling to understand program behavior and identifying potential implementation errors.
moreover we demonstrate the effectiveness of the input generation analysis which discovers the parameters of the input generator that affect output accuracy section vii .
axprof helped us identify and fix previously unknown problems with five different implementations of these algorithms.
our analysis shows that these problems could not have been identified with standard profilers that track only memory or runtime.
the problems were caused by incorrect implementations of the algorithms or their key components like hash functions.
we prepared pull requests for each of these problems.
the implementation developers already accepted three of our pull requests.
axprof also identified some implementations that make additional optimizations in their resource consumption.
these optimizations may result in a different complexity of resource consumption than specified by the algorithm.
for instance the implementation developers may allocate resources dynamically only when needed or they may create polyalgorithms compose multiple algorithms that work better for different input sizes and switch algorithms dynamically.
these results demonstrate that a xprof s focus on accuracy analysis opens a new dimension in algorithmic profiling.
previous approaches for algorithmic profiling focused only on deriving models of performance.
as such they miss to characterize important accuracy related properties of the emerging data centric applications.contributions.
the paper makes the following contributions concept we present algorithmic profiling for accuracy performance and resource consumption of approximate computations.
we also present axprof a system that automates many algorithmic profiling tasks and pinpoints potential violations of algorithm specifications.
accuracy analysis we present an approach for automatically generating statistical testing procedures from highlevel probabilistic specifications in mathematical notation as proposed by the algorithm authors.
the generated procedures can pinpoint if the algorithm implementations significantly deviate from their specifications.
evaluation we present the evaluation of a xprof on a set of approximate benchmarks from three application domains data analytics numerical linear algebra and approximate computing .
our results show that a xprof can be effectively used to find errors in randomized approximate programs and check for the correctness of the fixes and a xprof can identify polyalgorithms and optimizations of resource usage.
ii.
e xample locality sensitive hashing lsh is an algorithm for finding points that are near a given query point in multidimensional space.
instead of directly computing the distance of the query point to every other point in the set lsh maintains a compact representation of the points and their locations using a set of hash maps.
the keys of the maps are hash signatures and the values are the list of points with that signature.
to obtain a hash signature of a point lsh calculates a locality sensitive hash of that point.
depending on the desired similarity metric between points such as lscript1distance lscript2distance or cosine similarity different locality sensitive hash function families exist which hash similar points to the same hash signatures with high probability.
when it receives a query lsh calculates the query point s signature and returns all stored points with that signature.
lsh can increase the number of similar points found by increasing the number of hash maps l .
lsh can also concatenate signatures from kdifferent hash functions as the keys in each hash map to increase the probability that dissimilar points will be mapped to different bins.
each of these hash functions must be drawn uniformly at random from the same hash family.
axprof specification.
we assign each point in the dataset an index.
one representation of lsh output is a list of pairs of indices.
the first index is the index of the query point and the second is the index of the detected neighbor.
we use the same set of points as both data points and query points.
suppose a hash function chosen uniformly at random from the desired hash function family puts a point din the dataset and the query point qin the same map bin with probability pd q. this probability is calculated from the distance between the dataset point and the query point.
then for all dandq the probability that lsh will return din the output for the query point qis1 pk d q l. authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
a before b after fix c after fix d after fix e after fix fig.
tarsoslsh comparison of accuracy of the implementation before and after bug fixes.
each point compares the expected and observed probability for a query datapoint pair.
ideally all points should lie on the diagonal line.
in a xprof we write the full specification as 1input list of list of real 2output list of list of real 3time k l datasize 4space l datasize 5acc forall di in indices input qi in indices input probability over runs in output l1hasheqprob input input k l lines and indicate the data types of the input andoutput respectively.
lines and give the time and memoryspecification of lsh.
as each point must be stored in eachhash table the memory usage is o ln wherenis the number of data points.
storing a point requires calculating lkhashes.
the total time required to construct the hash tables is o lkn .
the last three lines give the accuracy specification.
informally it specifies that for all possible pairs of indices overthe input di qi the probability that a particular run of lsh has in its output is equal to the return value ofl1hasheqprob which is a user defined function that calculates the expression p k d q l. axprof uses this specification to automatically generate code to check that the property holds.
the code aggregates the outputs of the implementation over multiple runs.
then for each pair of indices it calculates the fraction of runs forwhich the pair is in the output.
it compares this fraction againstthe return value of l1hasheqprob using the binomial test.
finally it combines the results of the binomial tests for eachpair of indices using fisher s method.
for time and memory a xprof generates code to perform statistical regression.
the full details of code generation are in section iv.
testing the implementation.
we tested tarsoslsh an implementation of lsh in java that has its own testing framework and over stars on github.
the algorithm canbe configured through two parameters kandl for which the developer specifies a list of values of interest.
the numberof points datasize can also be specified.
we instruct a xprof to uniformly generate random dimensional points with each coordinate in the range .
identifying and fixing bugs.
while profiling tarsoslsh for the lscript1distance metric a xprof indicated errors for several values of kandl.
we used the visualization feature of a xprof and observed that many points were not being considered similar at all as shown in figure 1a.
each pointrepresents a query datapoint pair.
the xandycoordinates of the point denote the expected and observed probabilityrespectively.
ideally all results should lie on the diagonal line.this prompted us to investigate the hash function used for lscript 1distance.
we found that there were several inaccuracies in the implementation and use of the hash function.
we fixed abug that occurred due to operator precedence followed by abug caused by incorrect assumptions about the rounding offloating point values in java.
fixing the first bug led to theresult shown in figure 1b and fixing the second bug led tothe result in figure 1c.
while the result in figure 1c seemedto conform with the diagonal line as expected a xprof s statistical tests reported that the number of outliers was stilltoo high indicating the presence of more bugs.
on further investigation we found a bug in the method by which the implementation chose a hash function from thehash function family and a bug in the method by which theoutputs of the kdifferent hash functions for a hash table were combined.
fixing the third bug led to the result shown infigure 1d and fixing the fourth led to the result in figure1e.
after fixing the fourth bug a xprof indicated that the implementation conformed with the accuracy specification.
an important point to note is that while the results in figures 1c and 1d seem to be visually correct a xprof was able to accurately conclude that there were still unfixed bugs in theimplementation via statistical testing.
the implementation included a test method which tested the algorithm with various parameters.
however there wasan error in the tester code that miscounted the number offalse negatives.
this led the tester to overestimate the recall ofthe implementation i.e.
the percentage of nearby points thatare correctly identified.
a user that depended on the resultsof this test would mistakenly believe that the algorithm wasimplemented correctly.
this further illustrates the need forautomated tools like a xprof .
iii.
a xprof overview figure presents the overview of the system.
inputs.
axprof takes the following inputs implementation and parameters axprof takes an implementation of the algorithm to test and a set of algorithmconfiguration parameter ranges to be tested.
property specification the user provides an accuracy time and memory specification in a high level language thatresembles the mathematical specifications usually providedby the algorithm authors.
a xprof automatically generates code to check these specifications.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
fig.
overview of a xprof input generator properties axprof provides several input generators for scalar vector and matrix data.
alternatively the user can provide a custom input generator.
the user can allow a xprof to infer interesting parameters that affect the output accuracy of the algorithm or fix some or all of the parameters to values that the user wants to test.
components.
axprof has multiple components checker generator takes an accuracy time and memory usage specification from the user and generates code to aggregate output data along with time and memory usage data and check that the data conforms to the specifications.
input generator generates inputs to test the program.
it can experiment with various input parameters to determine which ones affect the accuracy of the output.
runner executes the program on an a xprof provided input.
it returns the generated output and resource consumption statistics to a xprof .
analyzer uses the code generated by the checker generator to test whether the implementation conforms to the provided specifications and issues a warning otherwise.
a xprof s analyses provide statistical guarantees that a warning may signify a real discrepancy with high probability.
the developer can set parameters that influence how sensitive the statistical analyses are.
visualizer plots time memory and accuracy statistics for visual inspection by the user.
we present the statistical techniques for constructing models and checking whether they deviate from the ones provided in the specification for both accuracy and resource usage in section iv.
these techniques guide the checker generator before profiling begins and the analyzer as the profiler runs .
we describe input generators in section v. specification language.
the user writes specifications in a high level language.
figure presents its grammar.
specifications consist of type declarations time expression memory expression and accuracy expression.
the time and memory expressions are typical arithmetic expressions.
supported types are real numbers matrices of real numbers or collections lists or maps .
knowing the types helps our generators to produce the correct code for the checkers and connect them with the rest of the framework.
the accuracy specification encodes two common predicates probability comparison probabilityover qualif and expectation comparison expectation over qualif .
both predicates explicitly define the probability space via qualifiers .
the qualifier can be a list of items a set of executions runs or a set of inputs.
if the qualification isc constants x va r s input output f functions aop bop rop ... spec tdclrtime dexpr space dexpr acc aspec tdclr input type output type xtype ftype type real matrix list of type map from typeto type aspec probability over qualif rop dexpr expectation over qualif rop dexpr forall range aspec let x dexprin aspec qualif runs inputs range range xin dexpr xin uniques dexpr xin indices dexpr bexpr bexpr bop bexpr !bexpr dexprin dexpr dexpr rop dexpr dexpr c x x dexpr dexpr aop dexpr f dexpr fig.
a xprof specification language over items in the input each item has equal weight as used in average case analysis of algorithms .
the accuracy specification also allows quantification over a list of items.
we interpret these quantifiers as the requirement that the tests of the predicates inside the quantifiers should be correct for each item in the list.
these predicates are translated to corresponding statistical tests using the code generation process we describe in section iv b. the specification can contain the special variables input the input data and output the algorithm output .
additional variables may also be declared in range expressions and let expressions.
finally the specification can contain standard boolean and arithmetic expressions.
the boolean operator in checks whether an element is in a collection.
elements within a collection can be accessed using a key using typical array access notation.
the operator calculates the size of a collection.
we allow a developer to call helper functions written in python.
these functions may implement complicated testing conditions or compute exact solutions through an oracle.
individual parameters from the algorithm configuration can be accessed directly by their name.
multiple expressions of the same type can be composed into a list.
iv .
c hecker code genera tion we derive statistical hypotheses from a xprof s accuracy specifications test them with common statistical tests and calculate the number of executions or inputs necessary.
we also generate code to check resource utilization specifications.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
a. background on statistical testing a statistical hypothesis can be tested by observing samples of one or more random variables.
a tester forms two hypotheses a null hypothesis and an alternative hypothesis .
then they use an appropriate statistical test to calculate a p value the probability of obtaining a test statistic at least as extreme as the one observed assuming the null hypothesis is true.
if the p value is too low the null hypothesis can be rejected.
several statistical tests are available for various use cases.
these tests are either parametric they make some assumption about the population from which the data is drawn or nonparametric they make no such assumptions .
parametric tests are generally more powerful at detecting statistical anomalies while nonparametric tests can handle more types of data and small sample sizes.
we use several statistical tests in a xprof .
the binomial test is an exact nonparametric test used to compare the observed probability p1 of an event against an expected or threshold probability p0 .
for example to test specifications that state p1 p0we formulate a null hypothesis h0 p1 p0and test it against the alternative hypothesis h1 p1 p 0using the binomial test.
the greater one tailed lesser one tailed and two tailed variants of this test respectively check if the observed probability is too high too low or different to the expected probability.
the one sample t test is a parametric test used to compare the mean of one set of samples against an expected or threshold mean 0 .
for example to test specifications that state 0we formulate the null hypothesis h0 0 and test it against h1 negationslash 0using the t test.
this test too has one and two tailed variants.
although the t test requires that the sample mean is normally distributed when the sample size is large enough this requirement can be assumed to hold.
another approach to perform hypothesis testing is to use sequential testing where hypothesis testing is performed as samples are collected.
sequential probability ratio test sprt is often proposed as a technique to select between two hypotheses with a minimum number of samples.
sprt maintains a likelihood ratio updated after each sample that rates two hypotheses based on the observed samples.
based on this ratio one hypothesis is accepted or more samples are gathered until enough evidence is available to pick one.
fisher s method is a technique for combining the results of multiple statistical tests for the same null hypothesis.
each individual test produces a p value for the hypothesis.
fisher s method can then be used to calculate a single p value for the entire set of tests.
if this combined p value is too low then the null hypothesis can be rejected.
otherwise the null hypothesis cannot be rejected even if some of the individual tests failed.
fisher s method assumes that the results of the individual tests are independent which is not always true.
if the tests are dependent using fisher s method may result in a p value lower than the correct p value.
b. generating accuracy checker code based on the accuracy specification a xprof needs to select what statistical test to use and how many samples areneeded for the statistical test based on the required level of confidence.
in addition a xprof needs to decide how to aggregate output data over multiple executions or inputs and when to use the aggregated data to perform the statistical tests after every run after multiple runs for the same input or after runs on multiple inputs.
axprof supports three main types of accuracy specifications and selects the statistical test based on the type of aspec expression from the specification language and the comparison operator used in its predicate.
probability predicates.
specifications of the form probability over qualif rop dexpr require testing the probability of satisfying the inner boolean expression bexpr against the probability dexpr .
each element in the space defined by qualif can be treated as one sample drawn from a bernoulli distribution which is if bexpr is satisfied and otherwise.
this allows us to use the binomial test to compare dexpr with the probability of the bernoulli variable.
based on the probability space defined by the user in qualif we need to gather sample outputs of the program over multiple executions or inputs to calculate the fraction of elements that satisfy bexpr ifqualif isruns the accuracy specification defines a probability over a set of executions of the program on the same input.
therefore a xprof executes the program multiple times and calculates the fraction of executions that satisfy bexpr .
at profiling time a xprof sets the number of executions to the number of samples required for the binomial test section iv c .
if the developer provides multiple inputs then the implementation is expected to pass the test for each input separately.
ifqualif isinputs the accuracy specification defines a probability over the inputs of the program.
in this case for each configuration of algorithm parameters a xprof executes the program on multiple inputs and calculates the fraction of inputs that satisfy bexpr .
at profiling time axprof sets the number of inputs to the number of samples required for the binomial test section iv c .
a xprof generates inputs using its input generators section v and the implementation is executed once on each input.
ifqualif is a list of items range after each execution of the program we calculate the fraction of items in the list that satisfy bexpr .
the test is performed separately for each execution on each input.
the specification should be valid for each run of the implementation.
while we cannot prove this property with full certainty we can do so with high confidence.
in particular we formulate the null hypothesis that the program succeeds with very high probability e.g.
greater than .
and use the sprt to estimate the number of executions sufficient to check this weaker property section iv c .
in all cases the fraction of samples executions inputs or items that satisfy bexpr is compared against the value of dexpr using the binomial test.
if a xprof observes enough evidence to reject the null hypothesis it issues a warning to the authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
user.
depending on the comparison operator used rop we choose one of the three variants of the binomial test greater one tailed lesser one tailed o r two tailed .
expectation predicates.
specifications of the form expectation over qualif rop dexpr2 require comparing the value in expression dexpr1 against the expected value in expression dexpr2 .
we gather samples of the value of dexpr1 overqualif and calculate their mean.
for large enough sample sizes this sample mean value is an estimate of the real mean value and can be considered to be drawn from a normal distribution centered around the real mean value.
this allows us to use of the t test for comparing the sample mean against the expected value.
similar to the probability predicates depending on the comparison operator used rop we choose one of the three variants of the t test.
based on the sample space defined by the user in qualif we may have to gather sample outputs of the program over multiple executions or inputs as in the probability predicate case .
we calculate the value of dexpr1 for each sample and take the mean.
this mean is then compared against the expected mean dexpr2 using the appropriate t test.
the process of gathering samples is similar to the process used for probability predicates except that a xprof uses the t test instead of binomial test for calculating the number of samples.
universally quantified predicates.
specifications of the form forall range aspec require that each element in range satisfy the accuracy predicateaspec a probability or expectation specification .
we perform the statistical test required for the probability or expectation specification aspec as described in the previous paragraphs for each individual element in range .
the null hypothesis for each test is that the implementation satisfies aspec for all elements the alternative being that it does not satisfyaspec for that element.
this results in multiple pvalues one for each element in range .
next we combine these p values obtained from the individual tests into a single p value to test if the overall specification is satisfied.
a xprof uses fisher s method for this purpose.
c. determining the required number of samples for statistical tests the required number of samples depends on the test being used desired significance level the statistical power and other test specific parameters.
the user can specify these parameters to control false warnings risk of potentially missing a bug and run time of a xprof .
binomial test.
the number of samples required also depends on the size of the indifference region which determines the minimum deviation from the expected probability that the test will be able to detect .
the minimum number of samples required to achieve the required statistical confidence is parenleftbig parenleftbig zsig radicalbig p0 p0 z1 radicalbig pa pa parenrightbig parenrightbig2 where for any probability q zqis the critical value of the normal distribution for q. here zsig isz1 2for a two tailed test andz1 for a one tailed test.one sample t test.
the number of samples required also depends on the effect size d 0 1 the difference in the means corresponding to the null hypothesis 0 and an alternative hypothesis 1 divided by the standard deviation of the sample being tested.
the minimum number of samples required is tsig t d2 where for any probability q tqis the critical value of the t distribution for q. here tsig ist 2for a two tailed test and t for a one tailed test.
sprt.
to calculate the minimum number of runs n w e use sprt with the minimum success probability hand the maximum failure probability l a sn log log log h log l .w e ensure that each individual execution passes the test.
d. analyzing resource utilization to analyze the time and memory consumption of a computation a xprof employs curve fitting to build the most likely regression model and checks the quality of the fit.
as the first step a xprof generalizes specification expressions provided by the developer to capture the hidden constants in asymptotic notations.
for example if the specification of time memory is the expression x y z then a xprof will generate the general expression p0 x p1 p2 y p3 p4 z p5 p6.
for this expression a xprof searches for the values of the free variables p0...6that best fit the data using statistical curve fitting .
the curve fitting procedure computes the r2 metric which quantifies how well the model fits the observed data.
higher r2values indicate better fitting models.
a xprof triggers a warning if it cannot find a model with high r2.
v. i nput genera tion to generate random inputs to test the algorithms we developed a set of flexible input generators each of which can control different aspects of the generated data.
each input generator outputs a required number of data elements.
we developed three input generators integer real generator.
this generator can be used to generate a list of integers or reals.
the data can either be sampled uniformly from a range of valid values or can be drawn from a zipf distribution with a given skew which allows for the control of frequency of individual data items.
the generator also allows for the control of internal order of data items and the distance between individual data items.
matrix generator.
this generator can be used to generate a matrix of given dimensions with random elements.
in addition to the controllable parameters from the previous generator the sparsity of the matrix can be controlled.
the sparsity can be between fully dense to only zeros .
vector generator.
this generator can be used to generate a list of vectors with given number of dimensions.
the internal order of elements and the distance between individual vectors lscript2distance can be controlled.
automatically selecting input generator features.
identifying what input features affect the accuracy of a program is important to selecting a input generator and deciding what inputs to test.
each generator described above has input features that can be used to control the generated inputs.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
table i summary of the algorithms.
nis the size of the dataset in all unspecified cases name parameters informal accuracy specification time memory locality sensitive hashing k hash functions per table p pk linsertion o kl o ln l number of hash tables pdepends on similarity query o kl n bloom filter p max.
false pos.
probability p p insertion o log p o nlog p c capacity if number of inserted elements c query o log p count min sketch epsilon1 error factor p o log o epsilon12 l o g error probability hyperloglog k number of hash values p .
o for fixed k o k reservoir sampling s reservoir size p m i n s n o o s matrix multiply c sampling rate p a mxnmatrix c c a f b f o mcnp c m p o mcnp c m p b nxpmatrix where radicalbig log chisel blackscholes r reliability factor p r o o chisel sor r reliability factor mxn matrix dimensions p r o imn o mn i iterations chisel scale s scale factor e log10 r o s2mn o s2mn r reliability factor table ii accuracy specifications provided to the checker generator algorithm accuracy specification for a xprof lshforall i in indices input q in indices input probability over runs in output l1hasheqprob input input k l bloom filter probability over i in excluded config input p count min sketchprobability over i in uniques input epsilon input delta hyperloglog probability over inputs abs datasize output datasize .
sqrt 2 k .
reservoir sampling forall i in input probability over run s min ressize datasize matrix multiplyprobability over runs output eta delta samplingfactor frobenius input frobenius input delta chisel blackscholes probability over runs r chisel sor probability over runs r chisel scale expectation over runs log10 r we adapt a technique from to select important input features that need to be explored.
we use maximal information coefficient mic to identify relationships between input features and the accuracy of a program.
mic is commonly used to identify associations between a given pair of variables.
for each input feature available in a input generator we perform sample runs of the program and gather the accuracy of the runs.
we use this data to calculate a mic value.
if the mic value is beyond a threshold we accept that input feature as one that affects output.
vi.
m ethodology table i presents the summary of algorithms we analyze in this paper.
we chose these algorithms to represent common randomized and approximate tasks.
the table lists algorithmic parameters that can be controlled column and the accuracy time and memory specifications columns and .
table ii presents the accuracy specifications for each algorithm specified using a xprof s language.
a. tested algorithms locality sensitive hashing.
we presented it in section ii.
bloom filter.
bloom filter checks if an item was present in a data stream.
it starts with kdifferent hash functions andan all bit filter of length m. for each data item it calculates thekdifferent hash functions and sets the corresponding bits to .
to check if an item qwas in the stream the algorithm calculates all the hashes of qand checks that each corresponding bit is .
kandmare calculated from a specified capacity cand a maximum false positive rate p.i n the specification in table ii excluded calculates the set of items in the input that were not inserted into the filter.
count min sketch.
count min sketch counts the frequency of items in a dataset.
the algorithm maintains a set of uniform hash functions whose range is divided into a set of bins.
for every item in the dataset the hash functions are calculated and counters in the mapped bins are incremented.
the estimated frequency of an item is the minimum of all the counters in the corresponding bins.
the accuracy can be improved by increasing the number of hash functions and bins.
in the specification in table ii uniques calculates the set of unique items in the input as some items appear multiple times.
hyperloglog.
hyperloglog is an algorithm for calculating the number of distinct elements in a large dataset.
for each element in a dataset the algorithm calculates khash values.
the hash value with the maximum number of leading zeros is then used to estimate the cardinality of the dataset.
the variance of the result can be reduced by using more hashes.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
table iii controlled parameters algorithm parameters range lshhash functions per table number of hash tables input size performance step accuracy bloom filtermax.
false positive prob.
.
.
.
load fraction of capacity .
.
step .
capacity performance step accuracy step count min epsilon1 error factor .
.
.
error probability .
.
.
input size step hyperloglognumber of hash function unique items in input step reservoir samplingsize of reservoir step input size step matrix multiplysize of matrices sampling rate .
.
.
blackscholes load error rate .
.
.
sorsize of matrices iterations omega .
.
.
scaleinput image images scale factor reservoir sampling.
reservoir sampling uniformly samples a data stream.
for a reservoir of size s the first selements are directly inserted into the reservoir.
afterwards for the ith element to be inserted an integer pis chosen uniformly at random from .i fp sthen the item currently in the pth position in the reservoir is replaced with the new item.
randomized matrix multiplication.
randomized matrix multiplication methods reduce computation time and resource consumption of matrix multiplication by randomly sampling the matrices.
guarantees for accuracy are given as an upper bound on the frobenius norm of the errors.
the error can be controlled by changing the sampling rate.
chisel kernels.
chisel is a reliability aware optimization framework for programs that run on approximate hardware.
for a given reliability specification chisel minimizes energy consumption by utilizing approximate computations.
chisel programs run on an approximate hardware simulator that injects errors at runtime.
we look at three kernels from chisel scale scales an image by a specified scale factor sor performs jacobi sor for a given matrix blackscholes computes the price of a stock portfolio using the black scholes formula.
for blackscholes and sor chisel provides bounds on the probability that the output differs from the exact value.
for scale the authors provided the expression for the expected psnr value between the exact and approximate results.
b. algorithm implementations for most algorithms we selected two implementations from github.
we preferred implementations in java python or c c .
we took several factors into account when selecting implementations to profile such as the number of stars on github and how active the repository is.
all the selected implementations appear among the top search results in github for the name of the algorithm.
finally we chose three implementations of kernels from the evaluation of chisel .c.
experimental setup parameters and their ranges.
the parameter value choices offer a trade off between profiling time and the confidence in the algorithm s correctness.
we chose parameters across their valid range.
for each parameter in the time or memory specifications we used at least values across the range for curve fitting .
table iii presents the ranges in our experiments.
statistical tests.
for statistical tests we used a significance level .05and a statistical power .8when calculating the number of runs.
to get the number of runs for per run checkers we used sprt with an minimum acceptable probability of success of .
and a maximum probability of failure of .
.
based on these values a xprof calculated that runs were sufficient.
for the specifications requiring the binomial test we chose a probability deviation .
.f o r those that require the t test we chose an effect size d .
.
for both of these a xprof calculated using the formulae from section iv c that slightly less than runs were sufficient.
for identifying resource model discrepancies we used anr2threshold of .
.
environment.
we ran experiments on a xeon e5 v4 cpu gb ram ubuntu .
.
for time profiling we used a real time timer around the relevant functions.
for memory we used serialization in java and python and the time linux utility for c c programs.
for fitting the models we used the scipy.optimize module of scipy .
vii.
e v alua tion this section discusses the three main research questions rq1 how effective is a xprof in profiling accuracy of applications?
section vii a rq2 can the bugs found by a xprof be identified by performance only algorithmic profiling?
section vii d rq3 is a xprof effective in identifying input features that affect program s accuracy?
section vii e a. effectiveness of axprof in profiling accuracy table iv presents a summary of our findings using axprof .
column presents the algorithm and column the profiled implementation.
column presents the results for accuracy analysis for each benchmark implementation.
columns and present the analysis for time and memory.
in each column a check represents that a xprof did not find any issues.
w arn x y represents cases where a xprof issued a warning in x out of y configurations.
a indicates a false warning.
for accuracy analysis each configuration was tested independently.
for time and memory analysis data from all configurations are part of a single regression model.
out of the implementations that we profiled implementations matrix multiplication in mscs and all chisel kernels passed all tests for compliance with accuracy time and memory specifications.
a xprof detected conditions that trigger warnings in the remaining implementations.
we manually analyzed the implementations that caused warnings.
we found two causes for the real warnings authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
table iv summary of the results of profiling algorithm implementation accuracy time memory lsh tarsoslsh w arn check check lsh java lsh w arn check n.a.
bloom filter libbf check insertion check query w arn check bloom filter bloomfilter check insertion check query w arn check count min alabid w arn check check count min awnystrom w arn check w arn hyperloglog yahoo check w arn w arn hyperloglog ekzhu w arn check check reservoir sampling yahoo check check w arn reservoir sampling sample check w arn check matrix multiplication randmatrix w arn check check matrix multiplication mscs check check check blackscholes chisel check check check sor chisel check check check scale chisel check check check errors in implementations four implementations used hash functions with errors that caused higher than expected accuracy loss.
one implementation had a misconfigured random number generator that affected sampling section vii b .
performance optimizations that caused unexpected execution times or memory usage section vii c .
we observed false warnings w arn in the time specification check for sample and the memory check for awnystrom due to noise in measurements.
in hyperloglog when the input set cardinality is very low and close to a predefined threshold the estimate error is expected to be high.
this led to warnings for two configurations of ekzhu yahoo avoided the problem via a polyalgorithm .
b. errors in implementations lsh t arsoslsh .we discuss this benchmark in section ii.
lsh java lsh .this is a minhash lsh implementation in java for jaccard similarity metric .
we observed that sets were being considered similar to the query set more often than expected as shown in figure .
each point represents a querydatapoint pair.
the xandycoordinates of the point denote the expected and observed probability respectively.
results before and after the bugfix are shown.
the implementation used the simple hash function h x a x b m. this hash function is usable only when mis a prime.
however the implementation often chose a composite value for m.w e fixed the hash by setting mto a fixed large prime.
after this fix the observed results matched the expected values.
count min sketch awnystrom alabid .for each data item count min sketch calculates multiple hash functions chosen randomly from a family of hash functions.
the family of hash functions used in an implementation should be pairwise independent .
i.e.
ifhis a function chosen uniformly at random from the hash family for two values xandy h x andh y are uniformly distributed and pairwise independent.
axprof detected that the observed error rate was higher than expected for many configurations in both implementations.
by manual inspection we identified that the buggy implementation uses a hash function that does not satisfy the pairwise independence property.
figure presents theobserved errors in awnystrom .
the x axis shows the various input sizes and the y axis shows the fraction of runs that had errors beyond the specified threshold.
we observe that this fraction dropped significantly in both implementations after we fixed the bugs in the hash functions.
matrix multiplication randmatrix .the rows and columns of the matrices to be multiplied are subsampled to reduce their size.
the algorithm provides an optimum sampling method that was not implemented correctly wrong initialization of std discrete distribution in c in the implementation leading to wrong results.
developer provided tests.
in all cases tests written by the developers failed to catch the bugs identified through a xprof .
we observed three main reasons unit tests only partially check the algorithm functionality java lsh tests use fixed inputs that do not trigger bugs alabid awnystrom randmatrix bugs in the test framework itself tarsoslsh .
c. performance optimizations we also observed situations where warnings were issued in a xprof due to performance optimizations in implementations that were causing unexpected behavior which were not necessarily errors.
reservoir sampling.
the memory usage was unexpectedly low due to the implementation incrementally allocating memory.
figure plots the observed memory usage against the number of inserted elements for various reservoir sizes.
hyperloglog yahoo .axprof was unable to model the runtime of the algorithm against the input size due to the polyalgorithm implementation .
figure shows the runtime of the algorithm y axis against the size of the dataset x axis and the best linear model a xprof found.
bloom filter.
instead of checking the entire filter to search f o ra0v alue the programs return when the first is found.
this property is not encoded in the specification.
d. effectiveness of accuracy profiling we analyzed all of the accuracy bugs we identified and confirmed that they can not be detected through regular authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
fig.
java lsh accuracy fig.
awnystrom accuracy fig.
rs yahoo memory fig.
hll yahoo runtime table v input feature impact on accuracy algorithm order frequency distance sparsity count min x x check check x x hll x x x x check x bf x x check check x x matrix mul check check check check check check lsh x x x x check check profiling techniques that focus only on runtime and or resource consumption.
as can be seen from table iv in all situationsaccuracy bugs could not be detected through unexpected run time or memory consumption that could have been identifiedthrough usual algorithmic profiling methods.
the only casewhere accuracy warnings coincide with other warnings wasdue to noise in performance measurements for the memoryspecification check for awnystrom.
these results show the importance of including accuracy in algorithmic profiling.
e. effectiveness of input feature selection we studied four input features from a xprof s input generators and their effect on accuracy of the program.
table v shows the results of the analysis.
we only looked at thecorrect implementations of the programs.
we analyzed thebenchmarks manually to confirm the results of the mic based approach section v .
each column with the format auto matic manual has a check mark if a xprof s automatic and our manual analyses respectively show that the input featureaffects accuracy.
for reservoir sampling we were unableto derive an accuracy measurement due to the nature of thespecification.
for the chisel benchmarks the accuracy dependsonly on the underlying hardware therefore input features wechanged did not have any impact.
we observed one situation where the manual analysis differs from the results of the mic based approach.
in hyperloglog the distance between individual values is falsely identified as affecting accuracy even though it should not.
we attribute thisto randomized properties of the hash functions.
viii.
r ela ted work algorithmic profiling.
recently researchers explored techniques for advanced algorithm aware profiling and estimation.several approaches have been proposed to model performanceof programs as a function of workload .algorithmic profiling is a framework that focuses onautomating such profiling tasks by detecting algorithms and their inputs.
coz is a causal profiler that estimates the effect of potential optimization of subcomputations onthe performance of the whole program.
researchers proposedsimilar techniques for analyzing memory and recursive datastructures e.g.
.
a xprof s accuracy analysis is complementary to these existing approaches.
statistical debugging and profiling tools e.g.
use statistical models of programs to predict and isolatebugs.
this line of research is conceptually orthogonal to ours.
analysis of accuracy.
researchers have also looked at various dynamic approaches to empirically analyze the impact on accuracy from transformations thatchange program semantics.
in contrast a xprof uses theoretical specifications of approximate algorithms and checks fordiscrepancies in their implementations.
mayhap convertsprogram code to a bayesian network and uses chernoff boundsto check probabilistic assertions over a set of executions.in contrast a xprof operates on a program as a black box system supports a richer set of predicates including inputsand items and automatically selects the appropriate test.
statistical model checking.
statistical model checking is a general method to verify properties of blackbox stochastic systems using statistical hypothesis testing.
forinstance the framework of sen et al.
expresses propertiesin continuous stochastic logic csl and samples the outputs from the tested system.
csl s probability predicate like our probability over runs predicate estimates the probabilitythat the system satisfies a specified logical property.
however expressing the predicates over inputs and items would besignificantly more complicated in csl and it does not supportexpectation predicates or complex data structures like lists ormatrices.
in addition a xprof automatically generates code for collecting and aggregating data thus giving a developeran intuitive tool to simultaneously explore various aspects ofprogram s accuracy and resource consumption.
ix.
c onclusion we presented a xprof an algorithmic profiling framework for analyzing execution time memory consumption and ac curacy of randomized approximate programs.
our evaluationdemonstrated that a xprof helps developers to check that implementations of such algorithms conform to the algorithmspecifications and can help in fixing accuracy related bugs.with its ability to analyze accuracy specifications a xprof opens a new dimension in algorithmic profiling.