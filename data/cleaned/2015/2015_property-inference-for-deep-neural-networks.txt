property inference for deep neural networks divya gopinath hayes converse corina s. p as areanu and ankur taly carnegie mellon university and nasa ames email divgml gmail.com corina.pasareanu west.cmu.edu university of texas at austin email hayesconverse gmail.com google ai now at fiddler labs email ankur fiddler .ai abstract we present techniques for automatically inferring formal properties of feed forward neural networks.
we observe that a significant part if not all of the logic of feed forward networks is captured in the activation status on oroff of its neurons.
we propose to extract patterns based on neuron decisions as preconditions that imply certain desirable output property e.g.
the prediction being a certain class.
we present techniques to extract input properties encoding convex predicates on the input space that imply given output properties and layer properties representing network properties captured in the hidden layers that imply the desired output behavior .
we apply our techniques on networks for the mnist and acasxu applications.
our experiments highlight the use of the inferred properties in a variety of tasks such as explaining predictions providing robustness guarantees simplifying proofs and network distillation.
i. i ntroduction deep neural networks dnns have emerged as a powerful mechanism for solving complex computational tasks achieving impressive results that equal and sometimes even surpass human ability in performing these tasks.
however the increased use of dnns also brings along several safety and security concerns.
these are due to many factors among them lack of robustness .
for instance it is well known that dnns including highly trained and smooth networks are vulnerable to adversarial perturbations.
small imperceptible changes to an input lead to misclassifications.
if such a classifier is used in the perception module of an autonomous car the network s decision on an adversarial image can have disastrous consequences.
dnns also suffer from a lack of explainability it is not well understood why a network makes a certain prediction which impedes on applications of dnns in safety critical domains such as autonomous driving banking or medicine.
finally rigorous reasoning is obstructed by a lack of intent when designing neural networks which only learn from examples often without a high level requirements specification.
such specifications are commonly used when designing more traditional safetycritical software systems.
in this paper we present techniques for automatically inferring formal properties of feed forward neural networks.
these properties are of the form pre post .post isa postcondition stating the desired output behaviour for instance the network s prediction being a certain class.
pre is a precondition that we automatically infer and can serve as a formal explanation for why the output property holds.
we study input properties which encode predicates in the input space that imply a given output propertywe further study layer properties which group inputs that have common characteristics observed at an intermediate layer and that together imply the desired output behaviorthe intention is to capture properties based on the features extracted by the network.
there are many choices for defining network properties that are appropriate preconditions for network behavior.
in this work we infer properties corresponding to decision patterns of neurons in the dnn.
such patterns prescribe which neurons are onoroffin various layers.
for neurons implementing the relu activation function this amounts to whether the neuron output is greater than zero on or equal to zero off .
we focus on these simple patterns because they are easy to compute and have simple mathematical representations.
furthermore they define natural partitions on the input space grouping together inputs that are processed the same by the network and that yield the same output.
other obvious more complex properties e.g.
use a positive threshold rather than zero for the activation functions use linear combinations on neuron values are left for study in future work.
we define input properties based on patterns that constrain the activation status onoroff of all neurons up to an intermediate layer.
such patterns form convex predicates in the input space.
convexity is attractive as it makes the inferred properties easy to visualize and interpret.
furthermore convex predicates can be solved efficiently with existing linear programming solvers.
analogously we define layer properties based on patterns that constrain the activation status at an intermediate layer.
layer patterns define convex regions over the values at an intermediate layer and can be expressed as unions of convex regions in the input space.
another motivation for studying decision patterns is that they are analogous to path constrains in program analysis.
different program paths capture different input output be7972019 34th ieee acm international conference on automated software engineering ase .
ieee authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
haviour of the program.
similarly different neuron decision patterns capture different behaviours of a dnn.
it is our proposition that we should be able to extract succinct inputoutput properties based on decision patterns that together explain the behavior of the network and can act as formal specifications of networks.
we present two techniques to extract network properties.
our first technique is based on iteratively refining decision patterns while leveraging an offthe shelf decision procedure.
we make use of the decision procedure reluplex designed to prove properties of feed forward relu networks but other decision procedures can be used as well.
our second technique uses decision tree learning to directly learn layer patterns from data.
the learned patterns can be formally checked using a decision procedure.
in lieu of a formal check which is typically expensive one could empirically validate the learned patterns over a held out dataset to obtain confidence in their precision.
we consider this work as a first step in the study of formal properties of dnns.
as a proof of concept we present several different applications.
we learn input and layer properties for an mnist network and demonstrate their use in providing robustness guarantees explaining the network s decisions and debugging misclassifications made by the network.
we also study the use of patterns at intermediate layers as interpolants in the proof of given input output properties for a network modeling a safety critical system for unmanned aircraft control acas xu .
the learned patterns help decompose the proofs thereby making them computationally efficient.
finally we discuss a somewhat radical application of the learned patterns in distilling the behavior of dnns.
the key idea is to use the patterns that have high support as distillation rules that directly determine the network s prediction without evaluating the entire network.
this results in a significant speedup without much loss of accuracy.
we provide an extended version of this paper containing more details about the applications and all the proofs in .
ii.
b ackground a neural network defines a function f i rn irm mapping an input vector of real values x irnto an output vectory irm.
for a classification network the output defines a score or probability across mclasses and the class with the highest score is typically the predicted class.
afeed forward network is organized as a sequence of layers with the first layer being the input.
each intermediate layer consists of computation units called neurons .
each neuron consumes a linear combination of the outputs of neurons in the previous layer applies a non linear activation function to it and propagates the output to the next layer.
the output vectoryis a linear combination of the outputs of neurons in the final layer.
for instance in a rectified linear unit relu network each neuron applies the activation function relu x max x .
thus the output of each neuron is of the form relu w1 v1 ... wp vp b where v1 ...vpare the outputs of the neurons from the previous layer w1 ... w pare the weight parameters and bis the bias parameter of the neuron.
example.
we use a simple feed forward relu network shown in figure 1a as a running example throughout this paper.
the network has four layers one input layer two hidden layers and one output layer.
it takes as input a vector of size .
the output vector is also of size indicating classification scores for classes.
all neurons in the hidden layers use the relu activation function.
the final output is a linear combination of the outputs of the neurons in the last hidden layer.
weights are written on the edges.
for simplicity all biases are zero.
consider the input .
the output on this input is f .t o see this notice that the output of the first hidden layer is relu .
.
.
.
relu .
.
.
.
.
this feeds into the second hidden layer whose output then is relu .
.
.
.
relu .
.
.
.
.
this in turn feeds into the output layer which computes .
a feed forward network is called fully connected if all neurons in a hidden layer feed into all neurons in the next layer the network in figure 1a is such a network.
convolutional neural networks cnns are similar to relu networks but in addition to fully connected layers they may also contain convolutional layers which compute multiple convolutions of the input with different filters and then apply the relu activation function.
for simplicity we focus our discussion on relu networks but our work applies to all piece wise linear networks including relus and cnns and in experiments we describe an analysis for a cnn .
notations and definitions.
all subsequent notations and definitions are for a feed forward relu network f often referred to implicitly.
we use uppercase letters to denote vectors and functions and lowercase letters for scalars.
we usen n prime n1 ... to range over neurons and nfor the set of all neurons in the network.
for any two neurons n1 n2 the relation n1 n2holds if and only if the output of neuronn1feeds into neuron n2 either directly or via intermediate layers.
we define feeds n n prime n prime n and extend it to sets of neurons in the natural way.
the output of each neuron ncan be expressed as a function of the input x. we abuse notation and use n x to denote this function.
it is defined recursively via neurons in the preceding layer.
that is if n1 ... n pare neurons 1most classification networks based on relus typically apply a softmax function at the output layer to convert the output to a probability distribution.
we express such networks as f softmax g wheregis a pure relu network and then focus our analysis on the network g.a n y property of the output of fis translated to a corresponding property of g. authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
a example b input property for prediction figure example neural network and input contract from the preceding layer that directly feed into n then n x relu w n1 x ... w2 n2 x b .f o r relu networks n x is always greater than or equal to .
we say that the neuron is offifn x andon ifn x .
this essentially splits the cases when the relu fires and does not fire.
as we will see in section iii theon off activation status of neurons is our key building block for defining network properties.
iii.
n etwork properties our goal is to extract succinct input output characterizations of the network behaviour that can act as formalspecifications for the network.
the network itself providesan input output mapping but of course this is uninteresting.ideally we should group together inputs that lead to the sameoutput and express that in concise mathematical form.
tothis end we propose to infer input properties wrt a given output property p. an input property is a predicate over the input space such that all inputs satisfying it evaluate to anoutput satisfying the property p. in other words an input property is a precondition for postcondition p. together the input property and the post condition form a formal contract for the network.
an example of an output property for aclassification network is that the top predicted class is c i.e.
p y argmax y c .
such properties are called prediction postconditions.
in this work we infer input properties that characterize inputs that are processed in the same way by the network i.e.
they follow the same on off activation pattern up tosome layer and define convex regions in the input space.there may be many such convex regions for a particularoutput property say a particular prediction .
the union ofthese regions fully captures the behavior of the network wrtthe output property.
in practice it may be too expensiveto compute precisely this union but we show that evencomputing a subset of these regions can be useful for manyapplications.
we further study layer properties which encode common properties at an intermediate layer that imply the desiredoutput behavior.
neural networks work by applying layerafter layer of transformations over the inputs to extractimportant features of the data and then make decisions based on these features.
thus layer properties can potentiallycapture common characteristics over the extracted features allowing us to get insights into the inner workings of thenetwork.
similar to input properties we seek to infer layerproperties by studying the activation patterns of the network.unlike input properties layer properties do not map toconvex regions in the input space but rather to unions ofconvex input regions.
decision patterns.
we infer network properties based on decision patterns of neurons in the network.
a decision pattern specifies an activation status on oroff for some subset of neurons.
all other neurons are don t care.
we formalize decision patterns as partial functions n arrowrighttophalf on off and write on for the set of neurons marked on andoff be the set of neurons marked offin the pattern .
each decision pattern defines a predicate x that is satisfied by all inputs whose evaluation achieves thesame activation status for all neurons as prescribed by the pattern.
x logicalanddisplay n on n x logicalanddisplay n off n x a decision pattern is a network property wrt a postconditionpif x x p f x .
we seek minimal patterns which have the property that dropping which amounts to unconstraining any neuron from the pattern invalidates it.
minimality helps in gettingrid of unnecessary constraints and ensuring that more inputscan satisfy the property.
the support of a pattern denoted by supp i sa measure of the number of inputs that follow the pattern.formally it is the total probability mass of inputs satisfying under a given input distribution.
in the absence of an explicit input distribution support can be measured empiri cally based on a training or test dataset.
for large networksa formal proof for x x p f x may not be feasible.
in such cases one could aim for a probabilisticguarantee that the conditional expectation denoted e o f p f x given x is above a certain threshold i.e.
e p f x x .
a. input properties to build input properties we infer input properties that are convex predicates in the input space implying a given 2this is similar to the probabilistic guarantee associated with anchors which we discuss further in section vi.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
postcondition.
given that feed forward relu networks encode highly non convex functions the existence of input properties is itself interesting.
to identify input properties we consider decision patterns wherein for each neuron nin the pattern all neurons that feed into nare also included in the pattern.
we call such patterns closed.
we show that closed patterns capture convex predicates in the input space.
theorem for all closed patterns x is convex and has the form logicalanddisplay iin1.. on wi x bi logicalanddisplay ji n .. off wj x bj herewi bi wj bjare some constants derived from the weight and bias parameters of the network.
the proof is provided in the appendix in .
it is based on induction over the depth of neurons in the pattern .
it shows that the value of any neuron in the pattern can be expressed as a linear combination of the inputs and that each on off activation adds a linear constraint to the input predicate.
thus an input property can be obtained by identifying a closed pattern such that x x p f x .f o r convex postconditions p we show that an input property can be identified using any input xwhose output satisfies p. for this we consider the activation signature ofx which is a decision pattern xthat constrains the activation status ofallneurons to that obtained during the evaluation of x. definition given an input x the activation signature ofxis a decision pattern xsuch that for each neuron n n x n isonifn x andoffotherwise.
it is easy to see that xis a closed pattern.
thus following theorem xcan be used to obtain an input property i.e.
a property that implies a desired output behavior.
we state this result as a proposition which will be used in section iv.
proposition given a convex postcondition pand an inputxwhose output satisfies p i.e.
p f x holds the following holds.
there exist parameters w b such that a x prime x x prime f x prime w x prime b b the predicate x x prime p w x prime b is an input property.
example.
we illustrate input properties on the network shown in figure 1a introduced in section ii .
consider the postcondition that the top prediction is class i.e.
p y1 y .
letn1 n1 2be the neurons in the first hidden layer and n2 n2 2be the neurons in the second hidden layer.
consider the pattern n1 on n1 off .
we argue that this pattern is an input property wrt p. sincen1 1isonit must be the case that the values that feed into n1 which have the form x1 x2 are positive hence the inputs satisfy x1 x2 .
furthermore sincen1 2isoffit must be the case that the values that 3the theorem can also be proven by representing the network as a conditional affine transformation as shown in .feed into n1 which have the form x1 x2 are negative hence the inputs satisfy x1 x2 .
now notice that all the inputs that satisfy these two constraints also satisfy neuron n2 1is always onand neuron n2 2is always off.
this is because the value that feeds into n2 1is0.
x1 x2 which must be positive since x1 x2 .
similarly the value that feeds into n2 2is .
x1 x2 which must be negative.
consequently the output .
n2 x .
n2 x .
n2 x .
n2 x always satisfies y1 y whenx1 x2 making the pattern a precondition for the property p. the pattern is closed and therefore by theorem the predicate x is convex.
the predicate x n1 x n1 x see equation amounts to the convex region x1 x2 x1 x2 shown in blue in figure 1b and is minimal.
b. layer properties while inferred input properties may be easy to interpret they often have tiny support.
for instance a property defined based on the activation signature of an input xmay only be satisfied by x and possibly a few other inputs that are syntactically close to x. ideally we d like properties to group together inputs that are semantically similar in the eye of the network.
to this end we focus on decision patterns at an intermediate layer that capture high level features.
a layer property for a postcondition pencodes a decision pattern lover neurons in a specific layer lthat satisfies x l x p f x .
note that a layer property is convex in the space of values at that layer but not in the input space.
however it is simple to express a layer property as a disjunction of input preconditions.
this is achieved by extending a layer pattern with all possible patterns over neurons that feed into the layer directly or indirectly .
each such extended pattern is closed and therefore convex by theorem .
we formulate this connection between layer and input properties in the following proposition.
proposition let lbe a layer property for an output property p. letnlbe the set of neurons constrained by l and let 1 ... pbe all possible decision patterns over neurons in feeds nl .5then the following statements hold a for each i l x i x is an input property.
b l x logicalortext i l x i x .
thus layer properties can be seen as a grouping of several input properties as dictated by an internal layer.
we note that identifying the right layer is key here.
for instance if one picks a layer too close to the output then the layer property may span all possible input properties which is uninteresting.
in general the choice of layer would depend on the application.
we discuss it further in section v. 4for simplicity we restrict ourselves to computing properties with respect to a single internal layer but the approach extends to multiple layers.
5there are two feeds nl such patterns.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
example.
let us revisit the example in figure 1a for the postcondition that the top prediction is class i.e.
p y1 y .
a layer pattern for this property is n2 on n2 off .
it is easy to see that for all inputs satisfying this pattern the output .
n2 x .
n2 x .
n2 x .
n2 x will satisfy y1 y making the pattern a layer property wrt p. the pattern is satisfied by the input .
the execution of this input involves neuron n1 1beingonand neuron n1 2being off.
consequently by proposition part a the extended pattern n1 on n1 off n2 on n2 off is an input property wrt p. c. interpreting and using inferred network properties robustness guarantees and adversarial examples.
we first remark that provably correct input and layer properties defined wrt prediction postconditions characterize regions in the input space in which the network is guaranteed to give the same label i.e.
the network is robust.
inputs generated from counter examples of pattern candidates that fail to prove represent potential adversarial examples as they are close in the euclidean space to regions of inputs that are classified differently.
furthermore they are semantically similar to benign ones since they follow the same decision pattern yet are classified differently.
we show such examples in section v. explaining network predictions.
neural networks are infamous for being complex black boxes .
an important problem in interpreting them is to understand why the network makes a certain prediction on an input.
predictions properties that ensure that the prediction is a certain class can be used to obtain such explanations.
but such properties are useful explanations only if they are themselves understandable.
inferred input properties are useful in this respect as they trace convex regions in the input space.
such regions are easy to interpret when the input space is low dimensional.
for networks with high dimensional inputs e.g.
image classification networks input properties may be hard to interpret or visualize.
the conventional approach here is to explain a prediction by assigning an importance score called attribution to each input feature .
the attributions can be visualized as a heatmap overlayed on the visualization of the input.
in light of this we propose two different methods to obtain similar visualizations from input properties.
we note that in contrast to attributions which help explain predictions for individual inputs our proposed input properties help explain the predictions for regions of the input space.
furthermore and in contrast to existing attribution methods they provide formal guarantees as the computed explanations are themselves network properties that imply the given postcondition.
under approximation boxes.
as stated in theorem aninput property consists of a conjunction of linear inequations which can be solved efficiently with existing linear programming lp solvers.
we propose computing underapproximation boxes i.e.
bounds on each dimension as a way to interpret input properties.
specifically we use lp solving after a suitable re writing of the constraints 6to find solution intervals for each input dimension i such that summationtext i hii loi is maximized.
as there are many such boxes we constrain each box to include as many inputs from the support as possible.
these boxes provide simple mathematical representations of the properties and are easy to visualize and interpret.
note that the under approximating boxes are themselves network properties that formally imply the input properties and hence the given postcondition.
minimal assignments.
we also propose another natural way to interpret both input and layer properties through the lens of a particular input.
analogous to attribution methods we aim to determine which input dimensions or features are most relevant for the satisfaction of the property.
every concrete input defines an assignment to the input variables x1 v1 x2 v2 .. xn vnthat satisfies x .
the problem now is to find a minimal assignment that still leads to the satisfaction of the property i.e.
a minimal subset of the assignments such that xk1 vk1 xk2 vk2 .. xkn vkn x .
the problem has been studied in the constraint solving literature and is known to be computationally expensive .
we adopt a greedy approach that eliminates constraints iteratively and stops when x is no longer implied the checks are performed with a decision procedure.
the resulting constraints are also network properties that formally guarantee the corresponding postcondition.
layer patterns as interpolants.
for deep networks deployed in safety critical contexts one often wishes to a prove a contract of the form a b which says that for all inputs xsatisfying a x the corresponding output y f x satisfies b y .
for the acasxu application there are several desirable properties of this form wherein ais a set of constraints defining a single or disjoint convex regions in the input space and bis an expected output advisory.
formally proving such properties for multi layer feed forward networks is computationally expensive .
we show that the inferred network patterns in particular layer patterns help decompose proofs of such properties by serving as useful interpolants .
given a layer pattern l we propose the following rule to decompose a proof.
a l l b a b thus to prove a b we must first identify a layer pattern lthat implies output property b and then attempt 6we replace each occurrence of variable xiwithloiorhiibased on the sign of the coefficient in the inequalities.
see for details on the computation of under approximation boxes.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
the proof a lon the smaller network up to layer l. additionally once a layer pattern lis identified for a property b it can be reused to prove other properties involving b. in section v we show that this decomposition leads to significant savings in verification time for properties of the acasxu network.
distilling rules from networks.
distillation is the process of approximating the behavior of a large complex deep network with a smaller network .
the smaller network is meant to be favorable to deployment under latency and compute constraints while having comparable accuracy.
we show that layer patterns with high support provide a novel way to perform such distillation.
suppose lis a pattern at an intermediate layer lthat implies that the prediction is a certain class c. for any input x we can execute the network up to layer l and check if the activation statuses of the neurons in layer lsatisfy the pattern l. if they do then we can directly return the prediction class c. otherwise we continue executing the network.
thus for all inputs where the pattern is satisfied we replace the cost of executing the network from layer lonward possibly involving several matrix multiplications with simply checking the pattern l. the savings could be substantial if layer lis sufficiently far from the output and the layer pattern has high support.
notice that if the patterns are formally verified then this hybrid setup is guaranteed to have no degradation in accuracy.
having said this we also note that most distillation methods typically tolerate a small degradation in accuracy.
consequently instead of the expensive formal verification step one could perform an empirical validation of the patterns and select ones that hold with high probability.
this makes the approach practically attractive.
as a proof of concept we evaluate this approach on an eight layer mnist network in section v. interestingly we note that a network simplified in this manner satisfies the inferred properties by construction without any proof needed.
iv .
c omputing network properties we now describe two techniques to build input and layer properties from a feed forward network wrt convex output propertyp.
a. iterative relaxation of decision patterns this is a technique for extracting input properties.
it makes use of an off the shelf decision procedure for neural networks.
in this work we use reluplex but other decision procedures can be used too see section vi .
recall from section iii that an input property is a closed pattern that satisfies x x p f x .
ideally we would like to identify the weakest such pattern 7as discussed in the absence of a decision procedure empirical validation of properties can also used.
while we would lose the formal guarantee that the computed decision patterns imply the postcondition they may still be useful in practice.i.e.
one that constraints the fewest neurons.
computing such a property would involve enumerating all closed patterns o n and using a decision procedure to validate whether equation holds.
this is computationally prohibitive.
instead we apply a greedy approach to identify a minimal closed pattern meaning that there is no closed subpattern of that also satisfies equation .
we start with an inputxwhose output satisfies the postcondition p i.e.
p f x holds.
let xbe the activation signature see definition of the input x. by proposition part b we have that x x prime p f x prime is an input property recall thatpis assumed to be convex.
but this property may not be minimal.
therefore we iteratively drop constraints from it till we obtain a minimal property.
the algorithm is formally described in the appendix in see algorithm .
it is easy to see that the resulting pattern is closed minimal and it implies the output property f x prime y .
proposition algorithm see appendix in always returns a minimal input property and involves at most n mcalls to the decision procedure where nis the number of layers and mis the maximum number of neurons in a layer.
example.
consider the example network from figure 1a and the input x for which the network predicts class .
we apply algorithm to identify an input property for class .
the algorithm starts with the activation signature ofx which is the pattern x n1 on n1 off n2 on n2 off .
notice that x is already an input property for class .
the algorithm begins to unconstrain all neurons in each layer starting from the last layer and identifies layer 1as the critical layer i.e.
unconstraining neurons in layer 1violates the postcondition .
the algorithm then identifies n1 on n1 off as a minimal pattern that implies the postcondition.
b. mining layer properties using decision tree learning the greedy algorithm described in the previous section is computationally expensive as it invokes a decision procedure at each step.
we now present a relatively inexpensive technique that relies on data and avoids invoking a decision procedure multiple times.
the idea is to observe the activation signatures of a large number of inputs and learn decision patterns that imply various output properties.
in this work we use decision tree learning see appendix in for background to extract compact rules based on the activation statuses onoroff of neurons in a layer.
decision trees are attractive as they yield decision patterns that are compact and therefore have high support based on various information theoretic measures.
the resulting patterns are empirically validated layer properties which can be formally checked with a single call to a decision procedure.
our algorithm works as follows.
suppose we have a dataset of inputs d. consider a layer lwhere we would authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
like to learn a layer property wrt postcondition p.w e evaluate the network on each input x d and note the activation status of all neurons in layer l denoted by l x and the boolean p f x indicating whether the output f x satisfies property p. thus we have a labeled dataset of feature vectors l xmapped to labels p f x see for example figure 2a.
we now learn a decision tree from this dataset.
the nodes of the tree are neurons from layer l and branches are based on whether the neuron is onoroff.
each path from root to a leaf labeled tr u e forms a decision pattern for predicting the output property see figure 2b.
we filter out patterns that are impure meaning that there exists an input x d that satisfies x butp f x does not hold.
the remaining patterns are likely layer properties wrt the postcondition.
we sort them in decreasing order of their support and invoke the decision procedure dp x p f x to formally verify them.
this last step can be skipped for applications such as distillation see section v where empirically validated patterns may suffice.
we can refine the method for the case where the output property is a prediction postcondition i.e.
of the form p y argmax y c. in this case rather than predicting a boolean as to whether the predicted class is c w e train a decision tree to directly predict the class label.
this lets us harvest layer patterns for prediction postconditions corresponding to all classes.
specifically the path from the root to a leaf labeled class cis a likely layer property for the postcondition that the top predicted class is c. counter example guided refinement.
in verifying equation for a decision pattern using a decision procedure if a counter example is found we strengthen the pattern by additionally constraining the activation status of those neurons from layer lthat have the same activation status for all inputs satisfying the pattern .
if verification fails on this stronger pattern then we do a final step of constraining all neurons from layer lbased on the activation signature of a single input satisfying the pattern.
if verification still fails we discard the pattern.
one can also consider a different strategy for refinement were the counter examples are added back to the data set and the decision tree learning is re run obtaining new layer patterns that will no longer lead to those counter examples.
the drawback is that it may require too many calls to the decision procedure if many refinement steps are needed.
v. a pplications in this section we discuss case studies on computing input and layer properties and using them for different applications.
we implemented all our algorithms in python .
and tensorflow.
the python notebook is connected to python2 google compute engine backend with 12gb ram allotted.
our implementation supports analysis of both relu and cnn networks.
however for the proofs we use reluplex which is limited to relu networks.
toenforce a decision pattern we modified reluplex to constrain intermediate neuron values.
as more decision procedures for neural networks become available we plan to incorporate them in our tool thus extending its applicability.
the reluplex runs were done on a server with ubuntu v16.
core gb ram .
we use the linear programming solver pulp .
.
to solve for under approximation boxes.
we plan to make the implementation and the networks available with a final paper version.
a. analysis of acasxu we first discuss the analysis of acasxu a safetycritical collision avoidance system for unmanned aircraft control .
acasx is a family of collision avoidance systems for aircraft under development by the federal aviation administration faa .
acasxu is the version for unmanned aircraft.
it receives sensor information regarding the drone the ownship and any nearby intruder drones and then issues horizontal turning advisories aimed at preventing collisions.
the input sensor data includes range distance between ownship and intruder angle of intruder relative to ownship heading direction heading angle of intruder relative to ownship heading direction vown speed of ownship vint speed of intruder time until loss of vertical separation and aprev previous advisory.
the faa is exploring an implementation of acasxu that uses an array of deep neural networks from which we selected one network for discussion here.
the five possible output actions are as follows clear of conflict coc weak left weak right strong left and strong right.
each advisory is assigned a score with the lowest score corresponding to the best action.
the network that we analyzed consists of hidden layers and relu activation nodes per layer.
we used inputs with known labels.
acasxu networks were analyzed before with reluplex .
verification for acasxu is challenging taking many hours may even time out after 12h we give more details below.
property inference we infer network properties wrt prediction postconditions that require that the output of a network classifier is a certain class.
we used decision tree learning to extract layer patterns we list them all total in table iii in the appendix in .
the learning took seconds on average per layer .
minutes in total .
we discuss here the verification of one specific layer pattern.
this pattern was for label coc clear of conflict at layer and was subsequently used to decompose proofs of acasxu properties as discussed below.
the pattern has a support of inputs.
we were able to prove a property computed based on this pattern after two refinement steps section iv within minutes.
we also extracted candidate input properties corresponding to the decision pattern of the layer property following proposition .
from the inputs that satisfied the decision pattern at layer we authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
angbracketleftx1 x2 angbracketright angbracketleftn1 n1 angbracketright p f x angbracketleft0 angbracketright angbracketlefton off angbracketright true angbracketleft1 angbracketright angbracketlefton on angbracketright true angbracketleft0 angbracketright angbracketleftoff on angbracketright false angbracketleft4 angbracketright angbracketlefton on angbracketright false angbracketleft1 angbracketright angbracketlefton off angbracketright true a training dataset for decision tree.
b resultant decision tree.
the pattern harvested for true is n1 on n1 off .
figure illustration of decision tree learning for mining properties for the network in figure 1a.
the output property is that the top predicted class is .
extracted distinct decision prefixes corresponding to inputs.
we were able to prove all of them properties within an average time of minute per property.
these experiments show that it is feasible to extract input and layer properties in terms of the on off patterns of the relu nodes of real networks.
the experiments also show that the patterns constraining lesser number of neurons have higher support and layer properties have higher support than input properties as expected since they cover a union of regions in the input space.
explaining network predictions the input output properties derived for acasxu can explain the network behavior.
we further used lp solving to calculate underapproximation boxes corresponding to input properties.
we calculated such a box for each of the input properties that we had proved.
we also generated under approximation boxes for input decision patterns that could not be proved within a time limit of hours but had high support.
this helped elicit novel properties of the network which were validated by the domain experts.
we give some examples below.
all the inputs within range .
.
.
.
vown .
vint should have the turning advisory as coc.
all the inputs within range .
.
.
vown vint should have the turning advisory as strong left.
please refer the appendix in for more results.
we further experimented with computing minimal assignments that satisfy the inferred properies.
for instance we analyzed a layer 2property for the label coc with a support of inputs.
by computing the minimal assignment over an input that satisfied this property we determined that the last two input attributes namely vown speed of ownship andvint speed of intruder were not relevant when the other attributes are constrained as follows range .
and .
.
this represents an input output property of the network elicited by our technique.
the domain experts confirmed that this was indeed a valid and novel propertyof the acasxu network.
layer patterns as interpolants to evaluate the use of layer patterns in simplifying difficult proofs we selected properties from the acasxu application.
these properties have previously been considered for verification directly using reluplex .
we list here the three properties.
property all the inputs within the following region .
range .
.
.
.
vown vint should have the turning advisory as clear of conflict coc .
this property takes approx.
minutes to check with reluplex.
property all the inputs within the following region range .
.
or .
.
.
.
.
vown vint should have the turning advisory as coc.
this property has a huge input region and direct verification with reluplex times out after hours.
property all inputs within the following region range .
.
.
.
.
vown vint should have the turning advisory as coc.
this corresponds takes approx.
hours to check with reluplex.
all three properties have the form a b wherea specifies constraints on the input attributes and bspecifies that the output turning advisory is coc.
for each property we used decision tree learning to extract multiple layer patterns for label coc at every layer and selected the one that covers maximum number of inputs within the input regiona.
incidentally for all three properties the same pattern at layer denoted by 5 was selected.
property we found inputs in the training set that fall withinaand classify as coc.
all of these inputs are also covered by 5. we therefore proceeded to prove a 5 and 5 busing reluplex.
for proving 5 b we had to strengthen the pattern by constraining nodes at layer .
this made the proof go through and finish in authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
minutes.
we then attempted to prove a 5for the strengthened version.
this process finished in minutes.
thus we were able to prove this property in minutes.
in contrast direct verification of the property using reluplex takes minutes.
properties and we could not identify a single layer pattern that covered the inputs within acompletely.
the pattern 5had maximum coverage with respect to the training inputs within a inputs for property for property .
we split the proof into two parts.
first we extracted the activation signature prefixes up to layer 5for each of the training inputs that satisfy 5. letcov be the set of these prefixes.
we then checked a logicalortext i cov i x b8checks of the form a i x bwere spawned in parallel for every i. this completed in an hour for property and within mins for property .
the remaining obligation in completing the proof for the property was a logicalortext i cov i x b. to check this efficiently we determined the underapproximation boxes for each i and spawned parallel checks on the partitions within anot covered by the boxes.
the longest time taken by any job was hours minutes for property and hour minutes for property .
this is a promising result as a direct proof of property using reluplex times out after hours.
for property a direct proof takes hours.
b. analysis of mnist we also analyzed mnist an image classification network based on a large collection of handwritten digits .
it has training input images each characterized by attributes and belonging to one of labels.
we first analyzed a simple network from the reluplex distribution containing layers with relu nodes per layer .
the simplicity of the network makes it amenable to proofs using reluplex.
for the distillation experiments described in the following subsection we use a more complex mnist network that is close to state of the art.
property inference we extracted input properties using iterative relaxation and layer properties using decision tree learning showing the feasibility of our approach in the context of image classification which involves a much larger input space compared to acasxu.
details about the computed properties total are given in tables i and ii in the appendix in .
the reluplex checks for some of the network properties generated counter examples which show potential vulnerabilities of the network since they are close in the euclidean space to other inputs that are classified differently figure .
8since 5implies the property bonly after strengthening showing that a logicalortext i cov i x 5is not enough to ensure that a logicalortext i cov i x b. figure original images from the data set left .
counterexamples to failed proofs for patterns containing the original images right .
figure visualization of mnist input properties using under approximation boxes.
explaining network predictions we further computed and visualized under approximation boxes for the inferred properties.
as an example in figure we show a visualization of input properties corresponding to three different images from the training set.
the first column shows original images.
columns and show images with all pixels set to their minimum and maximum values in the computed underapproximating box respectively.
columns and have each pixel set to the mean value of its range in the box a randomly chosen value below the mean and a randomly chosen value above the mean respectively.
in figure we visualize layer properties via underapproximation boxes corresponding to input properties based on randomly chosen images from the support of the property.
each box is represented by images setting all the pixels to their respective minimum and maximum values in the box.
note that the images drawn from the under approximation boxes represent new inputs not in the training set that satisfy the same property and hence are labelled the same.
while input properties capture visually or syntactically similar images layer properties cluster images of the same digit written in different ways indicating that layer properties can potentially capture common features across inputs.
the developer can examine the generated images to get a sense of the image characteristics that contributed to the network decisions.
misclassifications under approximation boxes can also be used to reason about misclassifications .
misclassified inputs are typically rare and spread across the input space and it is very difficult for developers to understand their cause and fix the underlying problem.
figure shows an image of digit misclassified to digit figure first column .
we used this input to extract an input decision pattern and compute an under approximation box for it authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
figure visualization of mnist layer properties using under approximation boxes.
figure digit misclassified to and images with min and max values from underapproximation box of original image.
figure 2nd and 3rd columns .
we can thus draw many more inputs from the box that are similarly misclassified.
these inputs can help developers understand the cause of misclassification and re train the network on them.
c. distillation our final experiment is to evaluate the use of layer properties in distilling a network.
as discussed in section iii c the key idea is to use prediction properties at an intermediate layer as distillation rules.
for inputs satisfying the property we save the inference cost of evaluating the network from the intermediate layer onwards.
we present a preliminary evaluation of this idea using a more complex mnist network with hidden layers two convolutional one max pooling two convolutional one max pooling and two fully connected layers.
the network has a superior accuracy of .
but it is computationally expensive during inference.
we use the decision tree algorithm to obtain layer patterns.
we then empirically validate them using a validation set of5000 images and select ones with accuracy above a threshold see section iii .
the selected properties are used as distillation rules for inputs satisfying them.
using a held out test dataset we measure the overall accuracy and inference time of this hybrid setup for different values of .
figure shows the results of distillation from the first max pooling layer9 which consists of neurons.
the x axis shows the empirical validation threshold used for selecting properties.
the extreme right point threshold corresponds to one where no properties are selected and therefore distillation is not triggered.
the reported inference times are based on an average of runs of the test dataset on a single core intel r xeon r cpu .30ghz.
the figure shows the trend of overall accuracy and inference time as the threshold is varied from .9to1.
.
observe that at a threshold of .
one can achieve a saving in 9while max pooling neurons are different from relu neurons we could still consider activation patterns on them based on whether the neuron output is greater than 0or equal to .
a decision tree can then be learned over these patterns to fit the prediction labels.
figure distillation of an eight layer mnist network from using properties at the first max pooling layer.
figure distillation of an eight layer mnist network from using layer patterns at the second max pooling layers.
inference time while only degrading accuracy from .
to .
.
this is quite promising.
as expected lowering the threshold further considers more properties and therefore reduces both inference time and accuracy.
the results from the second max pooling layer shown in figure are similar except that both the degradation in accuracy and the saving in inference time are smaller.
this is expected as the second max pooling layer is closer to the output and therefore the properties that we infer approximate a smaller part of the network.
vi.
r elated work we survey the works that are the most closely related to ours.
in it has been shown that neural networks are highly vulnerable to small adversarial perturbations.
since then many works have focused on methods for finding adversarial examples.
they range from heuristic and optimization based methods to analysis techniques which can also provide formal guarantees.
in the latter category tools based on constraint solving interval analysis or abstract interpretation such as dlv reluplex ai2 reluval neurify and others are gaining prominence.
our work is complementary as it focuses on inferring input output properties of neural networks.
in principle we can leverage the previous analysis techniques to verify the inferred properties.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
there are several papers on explaining predictions made by neural networks see for a survey.
one line of work is on explaining individual predictions by attributing them to input features .
they are either based on computing gradients of the prediction with respect to input features back propagating the prediction score to input features using a set of rules using attribution techniques from cooperative game theory or computing local linear approximations of the behavior of the network .
the closest to ours is the work on anchors which aims to explain the network behaviour by means of rules called anchors which represent sufficient conditions for network predictions.
these anchors are computed solely based on the black box behaviour of the neural network.
input properties from our work can be viewed as anchors for various output properties.
the key difference is that our input properties are obtained via a white box analysis of the neurons in the network and are backed with a formal guarantee.
also relevant there is work on computing the influence of individual neurons on predictions made by the network .
in a sense our layer properties can be seen as a means for identifying influential neurons for a prediction the key difference being that layer properties also guarantee that decisions of the influential neurons indeed imply the prediction.
these previous approaches evaluate neuron influence by measuring how accurately the top k most influential neurons alone can predict the class.
interestingly we believe these works also lend themselves to distillation.
we leave a thorough comparison of different distillation mechanisms to future work.
there is a large body of work on property inference including to name just a few although none of the previous works have addressed neural networks.
the programs considered in this literature tend to be small but have complex constructs such as loops arrays pointers.
in contrast neural networks have simpler structure but can be massive in scale.
a recent paper uses properties over neuron activation distributions to determine whether a given input is benign i.e.
non adversarial .
the invariants in are meant to capture properties of a given set of inputs benign inputs while our input and layer properties are meant to capture properties of the network.
furthermore our properties partition the input space into prediction based regions and are justified with a formal proof.
we do note that our properties can be seen as invariance properties of the network that have the special form precondition implies postcondition .
our distillation approach is related to teacher student learning in neural networks .
note that we do not perform transfer learning from a teacher to a student but instead use the inferred properties to simplify the network.
thus unlike teacher student learning our distillation ap proach is adaptive allowing to process some inputs that satisfy the layer properties using the simplified computation the other inputs that may need more complex processing go through the original network.
furthermore we provide formal guarantees as by construction our distilled network satisfies the properties used in the distillation.
vii.
c onclusion we presented techniques to extract neural network inputoutput properties and we discussed their application to explaining neural networks providing robustness guarantees simplifying proofs and distilling the networks.
as more decision procedures for neural networks become available we plan to incorporate them in our tool thus extending its applicability and scalability.
we also plan to leverage the decision patterns to obtain parallel verification techniques for neural networks and to investigate other applications of the inferred properties such as confidence modeling adversarial detection and guarding monitors for safety and security critical systems.