too long didn t watch!
extracting relevant fragments from software development video tutorials luca ponzanelli1 gabriele bavota2 andrea mocci1 massimiliano di penta3 rocco oliveto4 mir hasan5 barbara russo2 sonia haiduc5 michele lanza1 1universit a della svizzera italiana usi switzerland 2free university of bozen bolzano italy 3university of sannio italy 4university of molise italy 5florida state university usa abstract when knowledgeable colleagues are not available developers resort to o ine and online resources e.g.
tutorials mailing lists and q a websites.
these however need to be found read and understood which takes its toll in terms of time and mental energy.
a more immediate and accessible resource are video tutorials found on the web which in recent years have seen a steep increase in popularity.
nonetheless videos are an intrinsically noisy data source and nding the right piece of information might be even more cumbersome than using the previously mentioned resources.
we present codetube an approach which mines video tutorials found on the web and enables developers to query their contents.
the video tutorials are split into coherent fragments to return only fragments related to the query.
these are complemented with information from additional sources such as stack over ow discussions.
the results of two studies to assess codetube indicate that video tutorials if appropriately processed represent a useful yet still under utilized source of information for software development.
ccs concepts software and its engineering !software maintenance tools documentation keywords recommender systems mining unstructured data .
introduction developers need to continuously acquire new knowledge to keep up with their daily tasks.
for example to use a new library learn a new programming language or to develop mobile applications they can use several resources to get the information they need.
especially online resources are on the rise e.g.
forums blogs question answer q a websites slide presentations due to the amount and diversity of available information.
permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
copyrights for components of this work owned by others than acm must be honored.
abstracting with credit is permitted.
to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
request permissions from permissions acm.org.
icse may austin tx usa c acm.
isbn .
.
.
.
using search engines to nd information for their tasks developers often get a mix of results from these sources.
among them a recent and rapidly emerging source of information are video tutorials .
video tutorials can be e ective in providing a general and thorough introduction to a new technology as they often include a step by step learn byexample introduction to how a technology should be applied in practice.
a recent study by macleod et al.
investigated how and why software development video tutorials are created and found that they share details such as software customization knowledge personal development experiences implementation approaches application of design patterns or data structures.
the study also highlighted key advantages of video tutorials compared to other resources such as user manuals.
these advantages include the ability to visually follow the changes made to the source code to see the environment where the program is executed to view the execution results and how they relate to the source code and to understand a development activity in depth by looking at di erent levels of details.
in essence video tutorials can provide a learning perspective di erent and complementary to that o ered by traditional text based sources of information.
despite these bene ts there is still limited support for helping developers to nd the relevant information they require within video tutorials .
in many cases video tutorials are lengthy and lack an index to allow nding speci c fragments of interest.
thus to nd information about a concept in a video tutorial a developer can either watch the entire video leading to e ort and time wasted watching the irrelevant parts or skim it risking to miss important information.
moreover a developer may need information from diverse sources to thoroughly understand a new concept.
for example when learning to use a new library a developer could bene t from an introductory video tutorial complemented by discussions about known issues of that library from forums such as stack over ow.
to the best of our knowledge there is no support for integrating this kind of complementary cross platform information about a programming topic.
while approaches have been proposed to support developers by mining api documentation and q a websites such as stack over ow or by automatically synthesizing code examples from existing code bases there is currently no approach aimed at leveraging relevant information found within fragments of video tutorials and linking these fragments to other relevant sources of information.
we propose codetube a novel approach that e ectively leverages the information found in video tutorials and other online resources providing it to developers for a task at hand.
ieee acm 38th ieee international conference on software engineering codetube recommends video tutorial fragments relevant to a given textual query and complements them with stack over ow discussions related to the extracted video fragments.
codetube starts from a set of videos relevant to a broad topic of interest e.g.
android development j2ee .
then codetube analyzes the videos and identi es when source code is being shown e.g.
through the ide on the screen by using a series of algorithms and heuristics aimed at identifying shapes and fragments of java source code in the frame.
then it isolates cohesive video fragments i.e.
sequences of frames in which source code is being written scrolled or alternated with other informative material.
the text contained in each video fragment is extracted and complemented with the text of the audio transcript occurring at the same time.
finally all this information is indexed using information retrieval techniques.
in addition codetube searches and indexes stack over ow discussions relevant to each video fragment.
a developer can then query codetube through a web interface and obtain a ranked list of relevant video fragments with related stack over ow discussions.
codetube is currently available with a set of indexed videos related to android development extracted from youtube.
the videos currently considered resulted in a total of fragments.
the mean length of videos is 908s 1stquartile 433s median 684s 3rdquartile 073s the fragments are one order of magnitude shorter with a mean length of 66s 1stquartile 52s median 55s 3rdquartile 66s .
we evaluated codetube in two di erent studies.
in the rst study developers with android experience performed an intrinsic evaluation of the results produced by codetube through an online survey.
the participants evaluated i the coherence and conciseness of the video fragments produced by codetube as well as their relevance to a query as compared to the results returned by youtube and ii the relevance and complementarity of stack over ow discussions returned by codetube for speci c video fragments.
in the second study we performed an extrinsic evaluation of the approach by introducing codetube to three leading developers involved in the development of android apps.
after that we asked them questions about the usefulness of codetube focusing on the value of extracting fragments from video tutorials and of providing recommendations by combining di erent sources of information.
paper structure.
section details codetube while section and section describe and report the results of the intrinsic and the extrinsic evaluations.
threats to validity are discussed in section .
after a discussion of the related literature section section concludes the paper.
.
codetube overview codetube is a multi source documentation miner to locate useful pieces of information for a given task at hand.
the results are fragments of video tutorials relevant for a given textual query augmented with additional information mined from other classical text based online resources.
figure depicts the codetube pipeline.
it is composed of i an o ine analysis phase aimed at collecting and indexing video tutorials and other resources and ii an online service where developers can search these processed resources.
the analysis of video tutorials is currently limited to english videos dealing with the java programming language.
in the following we detail each step of the codetube pipeline.
video tutorials crawler video tutorials analyzerlucene index builder lucene ir engine video fragements identifiervideo tutorials youtube vimeo ... video tutorial fragments island parser lucene ir engine tesseract ocr online resource index stackoverflow discussions etc.
video slices index videosvideoste x tsource code audio t ranscriptvideosvideosvideo tutorials audio t ranscriptonline resources stackoverflow mailing lists documentation ... figure codetube analysis process.
.
crawling and analyzing video tutorials the rst step of the process is de ning the topics of interest.
the user provides i a set of queries qdescribing the video tutorials she is interested in e.g.
android development and ii a set of related tags tto identify and index relevant stack over ow discussions e.g.
android .
each query in qis run by the video tutorials crawler using the youtube data api1to get the list of youtube channels relevant to the given query qi2q.
for each channel thevideo tutorials crawler retrieves the metadata e.g.
video url title description and the audio transcripts which are either automatically generated or written by the author.
using google2srt2we extract the transcriptions for the videos.
the crawling of video meta information is performed on youtube but it can be extended to any video streaming service or video collection where the same type of metainformation and transcripts are available or can be extracted e.g.
using a speech recognition api.
once the videos have been crawled their metadata is provided as input to the video tutorial analyzer .
it analyzes each video and extracts pieces of information to isolate video fragments related to a speci c topic.
the video tutorial analyzer aims at characterizing each video frame with the text and the source code it contains.
it uses multi threading to concurrently analyze multiple batches of videos.
frame extraction.
the analysis starts by downloading the video at the maximum available resolution.
codetube uses the multimedia framework ffmpeg3to extract one frame per second saving each frame in a pngimage.
given the set of frames in the video we compare subsequent pairs of frames f i fi to measure their dissimilarity in terms of their pixel matrices.
if they di er by less than we only keep the rst frame in the data analysis since the two frames show almost the same information.
this scenario is quite common in video tutorials where the image on the screen is xed for some seconds while the tutor speaks.
this optimization considerably reduces the computational cost of our process without losing important information.
after obtaining the reduced set of frames to analyze codetube performs the following information extraction steps .
mpeg.org example frames from which codetube is able to extract code fragments.
english terms extraction.
we use the tool tesseractocr4 optical character recognition to extract the text from the frame.
we only consider correct english words by matching them with a vocabulary.
ocr tools are usually designed to deal with text on white background i.e.
paper documents .
in order to cope with this many ocr tools convert colored images to black and white before processing them.
when using an ocr tool on video frames the high variability of the background and the potential low quality of a frame can result in a high amount of noise.
thus after splitting composite words based on camel case or other separators we use a dictionary based ltering to ignore strings that are invalid english words5.
java code identi cation.
in principle the output of the ocr could be processed to extract the depicted java constructs.
however such output often contains noise.
figure shows three frames containing java code.
in frame the code occupies the whole screen and there is a clear background the noise of the ocr output is limited.
the noise increases in the frames and due to the buttons menu labels the graphics on the t shirt etc.to limit the noise produced by the ocr we identify the sub frame containing code using two heuristics shape detection and frame segmentation.
shape detection.
we use boofcv6to apply shape detection on a frame identifying all quadrilaterals by using the di erence in contrast in the corners.
this is typically successful to detect code editors in the ide as in frame .
frame segmentation.
the shape detection phase could fail in identifying sub frames with code.
in frame of figure boofcv fails because of missing quadrilaterals.
in this case we apply a segmentation heuristic by sampling small subimages having height and width equal to of the original frame size and we run the ocr on each sub image.
we mark all sub images smcontaining at least one valid english word and or java keyword and we identify the part of the frame containing the source code as the quadrilateral delimited by the top left sub image i.e.
the one having the minimum x andycoordinates and the bottom right sub image i.e.
the one having the maximum xandycoordinates in sm.
5we use the os x english dictionary.
java code.
after identifying a candidate subframe we run the ocr to obtain the raw text that likely represents code.
then we use an island parser on the extracted text to cope with the noise the imperfections of the ocr and the incomplete code fragments.
the island parser separates invalid code or natural language water from matching constructs islands and produces a heterogenous abstract syntax tree h ast .
by traversing the h ast we can exclude water nodes and keep complete constructs e.g.
declarations blocks other statements and incomplete fragments e.g.
partial declarations like methods without a body .
if we are not able to match complete or incomplete java constructs with any of the described heuristics we assume that the frame does not contain source code.
.
identifying video fragments the video fragments identi er detects cohesive fragments in a video tutorial using the previously collected information.
we refer to figure to illustrate the performed steps.
codetube starts by identifying video fragments characterized by the presence of a speci c piece of code.
the conjecture is that a frame containing a code snippet is coupled to the surrounding video frames showing parts of the same code.
identifying the video frames containing a speci c code snippet presents non trivial challenges.
first a piece of code could be written incrementally during a video tutorial if writing a java class in a video tutorial lasts minutes all frames in the minute interval will contain snippets of code related to that class and thus should be considered as part of the same video fragment.
however such code snippets are di erent i.e.
they contain di erent programming constructs due to the incremental writing.
second the tutor could to provide a line by line explanation scroll the code snippet shown on video.
again this causes frames showing the same code snippet to show di erent portions of it.
last the tutor could interleave two frames showing the same snippet of code with slides or other material e.g.
the android emulator .
codetube overcomes these challenges and identi es video fragments characterized by the presence of a speci c piece of code by comparing subsequent pairs of frames containing code to verify if they refer to the same code snippet.
the frames depicted in red in figure represent code frames that is frames containing code fragments.
given two code frames codetube veri es if they contain at least one common complete or incomplete java construct.
if so the two frames are marked as containing the same code component.
if not we cannot exclude that the two frames do not refer to the same code we have to take into account i possible imprecisions of the ocr when extracting the source code from the two frames i.e.
it could happen that a java construct is correctly extracted only in one of the two frames and ii the possibility that a scrolling from one frame to another has hidden some constructs in one of the two frames.
if the island parser fails in matching a common construct in the two frames we compute the longest common substring lcs between the pixel matrices representing the code frames.
speci cally we represent matrices as strings where each pixel is converted to a bit grayscale representation.
if the lcs between the two frames includes more than of the pixels in the frames codetube considers the two frames as showing the same code snippet.
the process adopted to tune the threshold is reported in section .
.
263no code frame code framecode interval transcript intervalvideo fragment12 fragment fragment fragment 3figure identi cation of video fragments.
note that the lcs is not a ected by possible ocr imprecisions and it does not su er of problems related to the ide scrolling as shown in figure in cyan the portion of the two frames identi ed as lcs .
as a drawback lcs is sensitive to zooming.
since the alignment of the proportions between two subsequent frames changes lcs would fail in identifying a common part.
overall given the advantages of the lcs over the java constructs matching between the two frames via island parser one may think that applying the lcs for each pair of code frames is the way to go.
unfortunately the lcs is very expensive to compute due to the huge number of pixels composing a frame a 1080p hd video has 2m pixels per frame and estimating the lcs on each pair of code frames would require an unreasonable computation time.
for this reason we adopt the lcs as a contingency strategy when the island parser is unable to identify common java constructs in the two frames under analysis.
to speed up the lcs computation we scale the frames to of their size.
in the example depicted in figure codetube compares the code frame pairs and identifying the rst two pairs as containing the same code snippet.
as highlighted by the grey line below the frames it identi es the rst two cohesive code intervals i.e.
the rst going from frame to frame and the second containing frame only.
the non code frames and blue in figure are included in the rst code interval since they are surrounded by two code frames and containing the same snippet.
in a subsequent step codetube analyzes the audio transcripts black lines at the bottom of figure to re ne the already identi ed code intervals grey lines .
codetube identi es the audio transcripts starting and or ending inside each code interval.
the audio transcripts are provided in the subrip7format when extracted from youtube s videos.
in the example reported in figure three audio transcripts are considered relevant when re ning the code interval going from frame to .
codetube uses the beginning of the rst and the end of the last relevant audio transcript for a code interval to extend its duration and avoid that the code interval starts or ends with a broken sentence.
the extended code interval represents an identi ed video fragment fragment light cyan in figure .
there might still be non code frames in the video that have not been assigned to any video fragment e.g.
frames and in figure .
these frames are grouped together on the basis of the audio transcript part they fall in.
for example the rst two frames in figure are grouped in the same video fragment fragment since they both fall in the same audio transcript part.
as a nal step each subsequent pair of fragments is compared to remove very short video fragments and to merge semantically related fragments.
public string read file file fis new fileinputstream file byte data new byte fis.read data fis.close return new string data utf byte data new byte fis.read data fis.close return new string data utf public boolean isnull object obj figure lcs between two frames showing the same code.
the right frame is scrolled down by the tutor.
codetube merges together two subsequent fragments if one of two conditions applies .
their textual similarity computed using the vector space model vsm is greater than a threshold .
each video fragment is represented by the text contained in its audio transcripts and in its frames as extracted by the ocr .
the text is pre processed by removing english stop words splitting by underscore and camel case and stemming with the snowball stemmer8.
.
one of the two fragments is shorter than seconds.
this is done to remove short video fragments that unlikely represent a complete and meaningful fragment of a video tutorial.
.
tuning of codetube parameters the performance of codetube depends on three parameters that need to be properly tuned minimum percentage of lcs overlap between two frames to consider them as containing the same code fragment minimum textual similarity between two fragments to merge them in a single fragment minimum video fragment length.
to identify the most suitable con guration one of the authors who did not participate in the approach de nition built a video fragment oracle by manually partitioning a set of video tutorials into cohesive video fragments.
then we looked for the codetube parameters con guration best approximating the manually de ned oracle.
a challenge in this context is how to de ne the closeness of the automaticallyand manually generated video fragments.
estimating video fragments similarity.
a video can be seen as a set of partitions video fragments of frames where each frame belongs to only one partition i.e.
the generated video fragments are clusters of frames.
to compare the closeness of the video fragments generated by codetube and those manually de ned in the oracle we used the mojo e ectiveness measure mojofm a normalized variant of the mojo distance computed as mojofm a b mno a b max mno 8e a b wheremno a b is the minimum number of move orjoin operations needed to transform a partition ainto a partitionb andmax mno ea b is the maximum possible distance of any partition afrom the partition b. thus mojofm returns if ais the farthest partition away from b and returns if ais exactly equal to b.
264table parameter tuning intervals.
parameter min max 000s 000s 000s while mojofm is suitable to compare di erent partitions video fragments of the same elements frames we must take into account that video fragments are characterized by a constraint of sequentiality i.e.
they can only contain subsequent frames .
this could lead the mojofm to return high values similarity even when applied to two totally di erent video partitions.
for example consider the video frames f f1 6gand two sets of video fragments where the rst set a f1 6g contains a unique partition video fragment with all the elements frames and the second set b ff1 3g f4 6gg contains partitions of size .
since the mojofm is not a symmetric function it would returnmojofm a b andmojofm b a i.e.
two di erent values despite the fact that the two partitions are the same.
keeping a one way comparison between the oracle and the obtained video fragments undermines the tuning phase.
to avoid this yet keeping a margin of approximation both sides of the mojofm should be taken into account.
two sets of fragments will tend to have the same value if they are close in their partitioning.
for this reason we calculate the similarity in both directions and compute their mean value closeness a b mojofm a b mojofm b a in so spikes of high values for the mojofm between two sets of video fragments for one direction are lowered or preserved depending on the opposite.
estimating the most suitable parameter con guration.
for each parameter we identi ed a set of possible values.
table shows the intervals we adopted and the step used whenever a new combination is generated.
in total we experimented di erent parameter combinations adopting the one with the top ranked mojofm 50s for the fulledged analysis phase.
.
integrating other sources of information codetube can be enriched by mining other online resources as our long term goal is to o er a holistic point of view on the information at disposal also because we argue that no single type of resource can o er exhaustive assistance.
to illustrate this we added as an additional online information source the stack over ow data dump.
we mined and extracted discussions related to the topics of the extracted video tutorials pre processed them to reduce the noise and made them available to codetube .
the last step in the data pre processing of codetube consists in indexing both the extracted video fragments and the stack over ow discussions using lucene9 where each video fragment is considered as a document.
for stack overow we separately index each question and answer for each discussion.
the text pre processing phase is identical to the one explained in section .
.
the text indexed for a video fragment is represented by the terms contained in its 345figure codetube user interface.
frames and audio transcripts.
the text indexed for the stack over ow post is represented by the terms they contain.
.
the codetube user interface codetube provides a service that allows user to search watch and navigate the di erent fragments of a video.
a detailed description of the codetube s service is reported in a companion tool demonstration paper .
figure shows the user interface of codetube .
when a video fragment is selected for watching from the search results codetube uses the youtube player provided by the youtube api10.
the video starts at the time devised by the selected fragment.
codetube provides an additional controller to visualize the timestamps of the fragments identi ed by our approach select a speci c fragment or move to the next previous fragment.
during the video playback the selector underneath the video player keeps the pace of the video timing and shows the current fragment.
when a new fragment is reached or the user jumps to it codetube automatically extracts a query from the text contained in the fragment i.e.
transcripts and ocr output of the frames it contains queries both the index of stack over ow and of the video fragments and updates the related discussions and the suggested youtube video fragments .
a search bar is always available to the user to run new queries.
.
study i intrinsic ev aluation the goalof this study is to evaluate codetube with the purpose of determining the quality of the extracted video fragments and related stack over ow discussions perceived by developers.
the quality focus concerns i the perceived bene ts and obstacles in using video tutorials during development and ii the quality of video fragments cohesiveness self containment relevance to a query and stack over ow discussions relevance and complementarity to the video fragment mined by codetube .
the four research questions rq the study aims to answer are rq what are the perceived bene ts and obstacles of using video tutorials?
apireference 265rq to what extent are the extracted video tutorial fragments cohesive and self contained?
rq to what extent are the stack over ow discussions identi ed by codetube relevant and complementary to the linked video fragments?
rq to what extent is codetube able to return results relevant to a textual query?
the context of the study consists of participants andobjects .
the participants have been identi ed using convenience sampling among personal contacts of the authors and by sending invitations over mailing lists for open source developers.
in total participants completed the survey.
the objects of the study are the set of video tutorials about android development indexed in codetube .
from these video tutorials codetube extracted a total of fragments.
.
study design and procedure the study has been conducted using an online survey questionnaire through which we asked questions to the potential respondents to assess the results of codetube .
the survey questionnaire is composed of three sections preceded by preliminary assessment of the primarily activity industrial open source developer student academic programming experience and speci c experience about android development of respondents.
the rst section addressing rq contains questions having an exploratory nature and aimed at understanding i how often and in which circumstances respondents use video tutorials and q a websites ii whether they found useful information there and iii how they react to video tutorials being too long e.g.
scroll it watch it anyway or give up .
we also asked participants what the main points of strength and weakness of video tutorials are compared to standard documentation and q a websites.
the second section shows to respondents three video fragments extracted by codetube as well as the original video tutorial from youtube.
then it asks rq whether the fragment is cohesive and self contained.
for each video fragment we also show the top three relevant stack over ow posts and ask rq to what extent they are relevant and complementary to the video tutorial fragments.
while approaches to recommend stack over ow discussions exist our aim is to determine whether the textual content of the video tutorial fragment can be used to retrieve relevant discussions.
for each respondent the second section is repeated for two video tutorials randomly chosen from a sample of video tutorials randomly selected from the .
the third section aims to assess the relevance of the topthree returned video fragments to a given query rq .
as a baseline for comparison we evaluate the relevance of the top three videos returned by youtube using the same query.
the query shown to each respondent is sampled from a set of queries formulated by graduate students at florida state university having a long experience in android development.
the queries are related to typical android problems e.g.
sending logs to servers initiate activities in background animate transitions access accelerometer data stopping background services or modifying the ui layout.
the queries are generic and youtube is likely able to return as relevant results as codetube .
only speci c queries referring to code elements not contained in youtube metadata would show the advanced of the indexing capabilities of codetube .
instead we are interested inshowing that for the typical queries a developer formulates codetube returns at least as relevant as youtube but consisting in shorter cohesive and self contained fragments.
finally after the third section we asked the respondents to evaluate through an open comment the main points of strength and weakness of codetube .
all assessmentrelated questions follow a level likert scale e.g.
very cohesive somewhat cohesive and not cohesive .
we limit the number of video fragments q a discussions and queries for each respondent to avoid the questionnaire being too long.
before sending the questionnaire to perspective respondents we ran a pilot study to assess its estimated duration which resulted to be between and minutes.
the questionnaire was then uploaded on the qualtrics11 online survey platform and a link to the questionnaire was sent via email to the invitees.
we made it clear that anonymity of participants was presented and data were only published in aggregate form.
the qualtrics survey platform allowed us to achieve randomization and balancing by automatically selecting video tutorials with related stack over ow discussion and queries to be evaluated by each respondent.
after sending out the invitation invitees had two weeks to respond.
.
study results out of the study participants declared to have no experience in android development.
since the video tutorials considered in the study were not introductory but related to speci c android topics we excluded their answers.
excluding these we collected a total of video tutorial fragment evaluations with respect to their cohesiveness and self containment so discussion evaluations and video tutorial fragment evaluations with respect to a query.
ideally we could have collected more evaluations but we have to consider that each of them requires respondents to watch a video tutorial fragment and in the case of the queries also the whole video tutorial itself hence we had to be realistic in the workload required by the targeted respondents.
with such numbers and given our design each fragment and so discussion received a number of evaluations varying between and except for videos and queries that due to the exclusion of some participants motivated above received less than evaluations.
these videos and queries were excluded from the analysis.
with a set of videos smaller than our we could have obtained more responses per fragment and so discussions.
we decided to favor the evaluation of a relatively larger set and variety hence more generalizability of videos rather than having more responses and therefore more reliable evaluation for each video.
the population who completed our survey is composed of .
of professional and open source developers .
of master students and .
of phd students.
the majority of developers in the population guarantees on average a higher level of experience .
of the population has more than year experience .
has between and years .
between and years .
between and years.
no one declared less than year of programming experience.
when asked about android programming experience the majority .
declared less than year of experience followed up by .
of respondents with more than years experience .
between and years and .
between and years of experience.
.
.
median score of video fragments a cohesion .
.
median score of video fragments b self containment figure distribution of median cohesion and selfcontainment scores for the assessed video fragments.
.
.
rq what are the perceived benefits and obstacles of using video tutorials?
the usage of video tutorials either happens on a weekly .
or monthly .
basis.
declared to use video tutorials on a daily basis nobody declared to never use them.
video tutorials are unlikely to help bug error xing but are the primary means to learn new concepts .
when asked to provide open comments on the weaknesses and strengths of video tutorials respondents pointed out di erent key aspects.
the primary point of strength is the step by step nature of a video.
one respondent wrote as opposed to q a websites video tutorials describe a complete process step by step.
the visualized ow of actions is particularly useful in setting up working environments another emphasized the possibility to see the complete interaction of the developer with the ide and how a speci c library is imported before it is used in the code.
this does not hold when you simply copy and paste code from websites .
another point of strength identi ed by respondents concerns the guidance given by a tutor.
one respondent reported that there is a real person talking with you so it is easy to learn new concepts while another respondent emphasized the fact that you can see what the tutor does .
the primary weakness identi ed by respondents concerns time.
when a video tutorial is too long respondents said they would either try to scroll it to seek the relevant information or give up to nd alternative sources .
nobody opted for the third option i.e.
watching the whole video anyway.
respondents generally consider videos too long and slow and not suited if you need to quickly solve a problem or if you need just a small piece of information .
one of the respondents reported how due to time constraints during software development i cannot always watch the entire tutorial .
the lack of searching and indexing functionalities of the contents of a video is also considered a weakness.
one of the respondents claimed that browsing is not easy unless the video has an index to navigate through the concepts sections in the video while another highlighted how searching for a particular piece of information in the whole video is much harder than the same in a text document .
.
.
rq to what extent are the extracted video tutorial fragments cohesive and self contained?
figure a shows the distribution of median perceived cohesiveness scores for the fragments of the videos that received at least three evaluations.
the rst quartile median and third quartile of the distribution are and respectively.
a large majority of the evaluated .
.
median score of so discussions a relevance .
.
median score of video b complementariness figure relevance of stack over ow discussions to video fragments and complementariness to videos.
fragments achieved a score of cohesive and only one fragment was considered as not cohesive.
figure b shows the distribution of the median selfcontainment score of the video fragments as provided by the evaluators.
in this case the rst quartile median and third quartile are .
and respectively.
as one can notice from the gure the proportion of video fragments that received a median score of is lower than for cohesiveness .
this is not surprising because obtaining self contained fragments and hence understandable without watching the rest of the video is more challenging than achieving a high cohesiveness.
nevertheless the achieved cohesiveness is overall more than reasonable as of the fragments achieve a score greater than and only of them were considered as not selfcontained score less than .
examples.
let us consider a video having high cohesion12 the tutor introduces the problem of implementing animations and sets up the code for the next steps fragment implements the actual core of the animation fragment and runs the code to verify the animation fragment .
in almost all the cases the fragments identi ed by codetube resulted to be very coherent.
a counter example lies in the last fragment of another tutorial13 that is considered not cohesive by the majority of the participants.
let us now consider one positive case of self containment14.
in the rst two fragments of the video the tutor initializes the views and adds the contents to a textview .
participants perceived a positive self containment of these fragments because they strongly depend on each other.
absolute positive consensus is reached on the last fragment where the tutor runs and tests the sample application he implemented.
the last video15is a case of negative self containment across all the identi ed fragments.
this video is a particular corner case where the tutor gives for granted few basic notions and thus the video itself exhibits a lack of self containment thus making codetube not e ective.
.
.
rq to what extent are the stack overflow discussions identified by codetube relevant complementary to the linked video fragments?
figure a shows the distribution of the median perceived relevance of the stack over ow discussions associated to the video fragments of each video tutorial considered in the study.
267the distribution rst quartile is the median and the third quartile .
on the one hand the perceived relevance is relatively low with only of the stack over ow discussions achieving a median relevance of .
on the other hand if we look at figure b we notice that the distribution is polarized towards the maximum value rst quartile median and third quartile equal to with of the total of the videos where the stack overow discussions were considered as complementary.
results indicate that while respondents only considered the retrieved discussions fairly relevant to the fragments from where the queries were generated they almost totally agreed about the complementarity of the provided information.
we believe that video tutorials have a di erent purpose than stack over ow discussions.
the former have an introductory stepby step guide to a given problem the latter discuss a speci c problem answering a speci c questions.
for instance given the fragments of a video16showing how to code a layout in xml for android codetube retrieved and suggested stack over ow discussions concerning typical problems a developer could encounter like a button not showing up17 or not well formed xml18.
.
.
rq to what extent is codetube able to return results relevant to a textual query?
in the last part of the survey we asked participants to evaluate the top three results that codetube and youtube retrieved for a set of queries.
each participant evaluated the relevance of a result with respect to the query by following a three level likert scale i.e.
very related somewhat related and not related .
we use the normalized cumulative discounted gain ndcg to aggregate the results.
similarly to what done for the other research questions queries with less than replies are ignored.
the ndcg is thus calculated on a set of queries out of the initial .
we obtainedndcg ct q andndcg y t q forcodetube and youtube respectively.
even if codetube seems to perform slightly better than youtube a statistical analysis of the ndcg y tandndcg ctdistributions performed using the wilcoxon paired test did not show the presence of a statistically signi cant di erence pvalue .
.
even though the data collected is not enough to draft any statistically signi cant conclusion there are some considerations to make.
first when extracting the top three results from youtube we removed all the retrieved videos that are not included in the codetube dataset.
this makes the comparison unfair for our approach.
second youtube recommends entire videos while codetube recommends speci c fragments.
thus our approach is potentially more focused even if both the fragment and the whole video recommended by youtube are equally relevant.
.
.
codetube strengths and weaknesses in the last part of the questionnaire we asked participants to freely comment about codetube .
the participants have in general a positive impression of codetube .
the ui has been appreciated by some of the participants.
for example one of the respondents reported codetube looks very useful added to the bookmarks!
while another wrote excellent ow.com questions ow.com questions 11829271work the idea behind codetube is brilliant .
the extraction of fragments from video tutorials has been appreciated and considered very useful for developers who are already knowledgeable about the topic they can save a lot of time .
the possibility of having complementary sources of information e.g.
stack over ow has been appreciated by some participants.
one of them reported that the concept is amazing and has a lot of possibility of improvement given the huge amount of di erent sources of data available while other participants asked for additional features to improve this functionality.
one participant asked for the possibility to search for so discussions directly below the video while another wondered that it would be nice if the tool can provide a summary description that describes the context .
.
study ii extrinsic ev aluation a successful technological transfer is the main target objective for each prototype tool.
thus the goal of this second study is to extrinsically investigate codetube s industrial applicability.
speci cally the research question we aim to answer with this second evaluation is rq would codetube be useful for practitioners?
the context of the study is represented by three leading developers all with more than ve years of experience in app development of three italian software companies namely next ideasoftware and genialapps.
.
study design and procedure we conducted semi structured interviews to get quantitative and qualitative feedback on codetube .
each interview lasted two hours.
during the interview we let developers explore codetube for about minutes searching for video tutorials on speci c technology or to x problems.
each interview was based on the think aloud strategy.
we also explicitly asked the following questions do you use video tutorials during development tasks?
would the extraction of shorter fragments make you more productive?
is the multi source nature of codetube useful?
are you willing to use codetube in your company?
participants answered each question using a point likert scale absolutely no no yes absolutely yes.
the interviews were conducted by one of the authors who annotated the answers as well as additional insights about the strengths and weaknesses of codetube that emerged during the interviews.
.
study results nicola noviello project manager next .
nicola positively answered to our rst three questions i.e.
absolutely yes .
nicola declared to use video tutorials daily they are particularly useful for senior and junior developers for both learning a new technology or nding the solution to a given problem.
i see very often my developers on specialized youtube channels searching for and watching video tutorials.
nicola also appreciated the multi source nature of codetube the video tutorial provides the general idea on the technology while stack over ow discussions are particularly useful to manage alternative usage scenarios and speci c issues.
.
regarding the extraction of fragments nicola commented that i usually discard video tutorials that are too long because when i try to scroll fast forward it to manually locate segments of interest i am generally not able to nd 268what i need.
i strongly believe that the relevant segment is there but randomly scrolling a video tutorial is not worthwhile!
i prefer to look for more focused video tutorials.
.
nicola then con rmed that the availability of shorter fragments would make him much more productive.
nicola answered yes to the question related to the usefulness of codetube i did not answer absolutely yes because of the limited number of indexed tutorials.
however i strongly believe that the tool has an enormous potential.
.
nicola declared that he will present the tool to a newcomer trainee to quantify to what extent the tool is useful for developers that have a little knowledge on the android world i usually suggest to trainees to look for and watch video tutorials but very often they are not able to nd the right information.
i would like to see whether codetube is able to mitigate such a problem.
.
luciano cutone project manager ideasoftware .
luciano positively answered to our rst three questions i love video tutorials but several times they are too long and i do not have enough time to watch whole videos.
thus i have to scroll the video hoping to identify relevant segments.
this takes time and makes video tutorials less e ective.
with codetube life will be easier!
when exploiting di erent sources of information luciano works di erently from nicola i like the idea of having video tutorials together with stack over ow discussions.
however the main source of information for me is stack over ow while video tutorials should be used to x problems if i need to apply a new technology i would like to start from stack over ow since there i can nd snippets of code that i can copy and paste into my application.
then if something goes wrong i try to nd a video tutorial to x the problem.
.
luciano also suggested a nice improvement besides the integration of video tutorials with discussions on forums i suggest to add another source of information namely sample projects.
speci cally on github there are several sample projects that explain how to apply speci c technologies.
having them together with video tutorials and stack over ow discussions would be fantastic.
another suggestion was the addition of a voting mechanism to provide information on the usefulness and the e ectiveness of a speci c fragment of a video tutorial.
luciano answered absolutely yes to our last question i.e.
the one related to the usefulness of codetube i just added codetube to my bookmarks.
this is the tool i wanted.
i spent several hours of the day and of the night on youtube and stack over ow to x problems or learn new things.
this is part of my job unfortunately.
with codetube i am sure that i will nd relevant information quickly.
i can nally go back to sleep during the night!
.
the day after the interview we got a text message from luciano i have just used codetube this morning.
i was looking for something related to android websocket.
i found all i needed.
awesome!
.
giuseppe socci project manager genialapps .
giuseppe answered absolutely yes to our rst question stating that in his opinion video tutorials are a crucial source of information for learning a new technology .
instead he answered no to our second research question related to the extraction of fragments i am not sure that extracting shorter fragments makes you more productive.
it depends on the scenario where the video tutorial is used.
tome video tutorials should be used to learn a new technology.
in this case i should watch the whole video.
however there could be cases where you just need to x a problem or have some clari cations on a speci c part of the technology.
in this case watching fragments instead of whole videos could be worthwhile .
giuseppe suggested a way to make the tool more usable based on his way of interpreting video tutorials the search of a video tutorial should be scenario sensitive.
before searching the user should specify why she is searching for a video tutorial.
the rst option could be i have a problem .
in this case the search is based on fragments.
the second option could be i want to learn .
here whole videos should be retrieved .
as well as the other two developers giuseppe liked the integration of video tutorials with forum discussion he answered absolutely yes to our third research question .
consistently with ndings of study i section .
.
he highlighted the need for manually re ning queries when retrieving stack over ow discussions all the visualized stack over ow discussions are related to a speci c video tutorial.
however stack over ow discussions should be useful to resolve a problem i encountered when applying the technology explained in the video tutorial.
thus it might be useful to lter the retrieved discussion by a speci c query e.g.
the type of error i got .
.
finally giuseppe answered yes to our nal question i think that the tool is nice.
you are trying to solve an important and challenging problem that is merging accurately di erent sources of information in order to make them more productive.
.
giuseppe also gave a suggestion on how to improve the visualization of the relevant fragments after submitting a query codetube provides the list of relevant video fragments.
however it is quite di cult from the title of the video and the cover image to identify the most relevant one.
i strongly suggest to show for each video the relevant textual part of the video content similar to the part of the text in a web page content visualized by web search engines.
the same approach could be used also to make the navigation of the fragments of a speci c video easier.
.
.
reflection approach vs. tool the reception of codetube was positive.
all leading developers saw great value and even greater potential in this line of work.
several improvement suggestions obtained also in study i regard the tool that embodies our approach which we are currently considering.
clearly tools can always be improved given su cient time and human resources.
however we would like to emphasize that stepping beyond mere implementation and ui concerns the main contribution of the paper lies in the underlying approach.
.
threats to v alidity threats to construct validity are mainly related to the measurements performed in our studies and study i in particular.
instead of using proxy measures we preferred to let developers evaluate video fragments and their related stack over ow discussions.
subjectiveness of such an evaluation was mitigated by involving multiple evaluators for each video although as explained in section .
we favored the number of videos over the number of responses per fragment.
threats to internal validity concern factors internal to our studies that could have in uenced our results.
one possible problem is that the evaluation could have been in uenced by the knowledge of respondents about the topic.
we mit269igated this threat by discarding responses of participants not having any knowledge about android.
in addition the evaluation is mainly related to cohesiveness self containment and relevance of video fragments and relevance and complementariness of stack over ow discussions rather than to how they would be helpful for the respondents.
in such cases the bias represented by respondents is fairly limited.
the videos used in the survey have been randomly sampled by considering minutes as maximum video duration and three as maximum number of fragments for each video and query results.
these limitations have been introduced to restrict the survey duration to a reasonable time.
threats to external validity concern the generalizability of our ndings.
our evaluation is intendedly limited to video tutorials related to android development though further evaluation with a wide variety of tutorials is desirable.
nevertheless such tutorials are not much di erent in their structure and content than other java development tutorials.
both codetube and its evaluation need to be extended in the future to support multiple languages and possibly to evaluate it when processing tutorials involving multiple languages and pieces of technology.
finally the validity of the second study is limited to the three very speci c mobile app development contexts considered.
.
related work to our knowledge the only work investigating the use of video tutorials by developers is the study by macleod et al.
which as discussed in the introduction represents the underlying motivation behind codetube .
we discuss related work about i recommender systems for software documentation and code examples i multimedia retrieval and processing and iii use of multimedia in learning.
recommender systems for software documentation and code examples .
numerous approaches have been proposed to provide developers with o cial or informal documentation for their task at hand as well as code samples they can reuse.
among the various informal documentation sources stack over ow has been used by many recommender systems .
other recommenders have focused on recovering links between code and documentation with some focusing on recommending or enhancing api documentation .
among these the work of petrosyan et al.
is the most related as it analyzed tutorials to extract fragments explaining api types.
with respect to such approaches codetube is speci c for analyzing video tutorials and recommending their cohesive and self contained fragments.
other approaches aimed to retrieve code elements or code examples relevant to a task at hand from the current project or its code base or from online resources .
other work suggested relevant web discussions to help solve coding problems .
the infrastructure of codetube is designed such that any source of documentation can potentially be used to complement the information extracted from video tutorials.
multimedia processing and retrieval .
multimedia information retrieval focuses on extracting and retrieving relevant information from multimedia resources e.g.
images audio or video .
one problem in the eld is splitting a video into semantically coherent fragments.
existing approaches usually employ supervised machine learning techniques applied to various textual acoustic and visual features to resolve such an issue.
galu s c akov a and pecina ex plored the use of passage retrieval segmentation techniques to retrieve relevant segments by a textual query in a set of audio visual recordings.
mettes et al.
proposed an approach using hierarchical clustering and syntactic and semantic similarity metrics to identify the segments.
while codetube also identi es fragments within a video it is signi cantly di erent than those proposed in multimedia retrieval it is not supervised and bases its segmentation algorithm on information speci c to the software development domain i.e.
the occurrence of code in the tutorials.
use of multimedia in learning .
multimedia resources especially those using videos have been shown to be a very e ective medium for learning which is also often preferred by students over written text.
mayer established twelve principles based on numerous studies that de ne the use and e ciency of multimedia in learning environments.
some of these principles clearly motivate codetube i the multimedia principle states that people learn better from words and graphics than from words alone ii the temporal contiguity principle indicates that people learn better when corresponding words and pictures are presented simultaneously rather than successively.
previous work has also shown that youtube can be an e cient way to teach new concepts.
du y has shown that students like to use youtube as it provides a user guided experience.
for mullamphy et al.
videos allow students to learn at their own pace.
these observations were also con rmed within our rst study.
.
conclusion we presented codetube a novel approach to extract relevant fragments from software development video tutorials.
codetube mixes several existing approaches and technologies like ocr and island parsing to analyze the complex unstructured contents of the video tutorials.
our approach extracts video fragments by merging the code information located and extracted within video frames together with the speech information provided by audio transcripts.
codetube also automatically complements the video fragments with relevant stack over ow discussions.
we conducted two studies to evaluate codetube .
our survey highlighted the limitations of current video providers when it comes to dealing with software development.
we received positive feedback about our approach and its potential.
also we investigated the perception of our approach in industry environments by interviewing three leading developers receiving useful insights on the strengths and potential extensions of our current work.
to our knowledge codetube is the rst and freely available19approach to perform video fragment analysis for software development.
the current approach can be ameliorated and the fragments identi cation can be strengthened as well.
we also plan to improve the user experience.
lastly we plan to integrate additional sources of information other than stack over ow towards the concept of a holistic recommender .