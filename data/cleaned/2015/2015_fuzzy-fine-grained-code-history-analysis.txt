fuzzy fine grained code history analysis francisco servant virginia tech fservant vt.edujames a. jones university of california irvine jajones uci.edu abstract existing software history techniques represent source code evolution as an absolute and unambiguous mapping of lines of code in prior revisions to lines of code in subsequent revisions.
however the true evolutionary lineage of a line of code is often complex subjective and ambiguous.
as such existing techniques are predisposed to both overestimate and underestimate true evolution lineage.
in this paper we seek to address these issues by providing a more expressive model of code evolution the fuzzy history graph by representing code lineage as a continuous i.e.
fuzzy metric rather than a discrete i.e.
absolute one.
using this more descriptive model we additionally provide a novel multi revision code history analysis fuzzy history slicing .
in our experiments over three real world software systems we found that the fuzzy history graph provides a tunable balance of precision and recall and an overall improved accuracy over existing code evolution models.
furthermore we found that the use of such a fuzzy model of history provided improved accuracy for code history analysis tasks.
index t erms software engineering computer aided software engineering software maintenance reasoning about programs i. i ntroduction the analysis of source code evolution provides automatic support for a variety of software engineering tasks e.g.
identifying bug introducing changes recommending developers to fix bugs e.g.
identifying changes in third party apis and discovering code clones .
furthermore developers often need to examine and understand code evolution for a wide variety of purposes requiring high effort .
while code history analysis techniques support developers for numerous tasks their accuracy is still limited by the accuracy of their underlying code history models.
multiple techniques have been proposed to model and analyze the evolution of source code at the line of code level of granularity e.g.
.
yet existing techniques present potential limitations in terms of modeling too many false positives low precision or too many false negatives low recall respectively when compared with true code history.
in this paper we follow the intuition that such limitations in code history models originate in the fact that existing models map lines of code in prior revisions to lines of code in subsequent revisions in an absolute and unambiguous manner.
consider the following output of the diff command 7c5 if a a in range valid if a a in valid rangegiven this textual differencing result existing techniques follow one of two approaches.
some existing history analyses e.g.
conservatively represent the lin eage of lines of code mapping each and every candidate line of code in the older revision to each and every candidate line of code in the newer revision.
in the example diff output these analyses would assess that every line i.e.
lines and in the prior revision absolutely evolved into every line i.e.
lines and in the subsequent revision.
other techniques e.g.
further analyze such results to disambiguate each line in the prior revision to each line in the subsequent revision.
in the example diff output these analyses may assess that line in the prior revision evolved to line in the subsequent revision and line in the prior revision evolved to line in the subsequent revision however the backward history of line in the subsequent revision and the forward history of line in the prior revision are lost.
as a result existing approaches emphasize either precision or recall but present limitations in the opposite metric.
moreover such errors typically are compounded for analyses performed over multiple revisions which can lead to substantially inaccurate results.
in this paper we propose the idea that in truth lines of code evolve into other lines to varying degrees instead of in an absolute manner.
therefore we present a novel approach for modeling and analyzing code history in a fuzzy manner.
we present the fuzzy history graph as a model of fine grained code history that represents the varying degrees to which individual lines of code evolve into others.
additionally we present fuzzy history slicing as an automatic code history analysis technique that takes advantage of the fuzzy history graph to improve the accuracy of a fundamental task in code history analysis identifying all the revisions of a set of lines of code.
through our experiments in this paper we found that the fuzzy history graph provided higher accuracy than existing models of fine grained code history.
in addition to the improved overall accuracy the fuzzy history graph also provided a tunable balance of both precision and recall as opposed to existing models that emphasize only one of the two.
we also found that such accuracy improvement led to higher accuracy in code history analysis tasks.
in our experiments a common code history analysis task identifying bugintroducing changes with the szz approach provided higher accuracy with an underlying fuzzy history graph than with existing absolute code history models.
in all the fuzzy history graph and fuzzy history slicing allowed for multirevision fine grained analyses of code history that provided a flexible balance between precision and recall and higher accuracy in multi revision code history analysis tasks.
ieee acm 39th international conference on software engineering ieee acm 39th international conference on software engineering .
ieee authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
revision by alice revision by chris revision by chris revision by bob revision by bob g1 g2 g1 g3 g1 g4 g1 g5 g1 g6 g1 g7 g1 g8 g1 g9 g1 g10 g2 g1 g2 g2 g2 g3 g2 g4 g2 g5 g1 g2 g1 g3 g1 g4 g1 g5 g1 g6 g1 g7 g1 g8 g1 g9 g1 g10 g2 g1 g2 g2 g2 g3 g1 g2 g1 g3 g1 g4 g1 g5 g1 g6 g1 g7 g1 g8 g1 g9 g1 g10 g1 g2 g1 g3 g1 g4 g1 g5 g1 g6 g1 g7 g1 g8 g1 g9 g1 g2 g1 g3 g1 g4 g1 g5 g1 g6what are the corresponding lines in other revisions that changed this line of code?
answer with the all to all model answer with the one to one model actual corresponding lines in bold array firstarray getfirstarray array secondarray getsecondarray get union with maximum size array u getsetunion firstarray secondarray print u array firstarray getfirstarray array secondarray getsecondarray get union with maximum size float maxsize get the union of arrays array u getunion firstarray secondarray maxsize print u array a getfirstarray array b getsecondarray a sortarray a b sortarray b float m max size get the array union array u getunion a b m print u array a for int i i i a.add i array b for int i i i b.add i a sortarray a b sortarray b float m max size get the array union array u getunion a b m print u array a array b for int i i i b.add i a sortarray a b sortarray b float m max size get the array union array u getunion a b m print u fig.
code evolution example this paper provides the following research contributions a novel model fuzzy history graph and analysis fuzzy history slicing of fine grained code history that preserve and account for the degree to which lines of code evolve.
novel algorithms to perform fuzzy fine grained modeling and analysis of code history that improve the accuracy of current fine grained code history models and analyses.
an evaluation composed of two experiments that show that the fuzzy history graph improved the accuracy of existing fine grained code history models and that such accuracy improvement led to higher accuracy in performing code history analysis tasks.
ii.
m otiv ation and background many software engineering tasks benefit from fine grained code evolution analyses.
multiple studies found industry developers to often require the study of the history of finegrained code selections for a wide variety of purposes such as identifying the rationale of code .
in addition multiple automatic code evolution analyses have been proposed to support developers in diverse tasks such as automatic identification of changes in third party apis automatic discovery of code clones automatic identification of bug introducing changes szz automatic recommendations of developers to fix bugs e.g.
and automatic prediction of future bugs in code locations .
as such the accuracy of code evolution models and analyses impacts both researchers and practitioners in a variety of tasks.
running example.
to illustrate such a fine grained multirevision code evolution analysis and the uses to which it could be applied consider the source code history included in figure .
this example program evolved through five revisions.
lines that changed between consecutive revisions are marked with connected rectangles.
the example task that we pose is answering the set of lines throughout the code history that contributed to the current revision of line in revision .
to perform such an analysis each revision can be compared and the corresponding lines in the previous revision may be identified through manual inspection.
those lines that match can be documented and the pairwise analysis can continue revision pair by revisionpair until the beginning of the history is reached or until all trajectories reach their earliest origin.ground truth human assessed rev5 rev4 rev3 rev2 rev1 rev5 rev4 rev3 rev2 rev1 slicing criterion a ground truth history graph b ground truth history slice fig.
human assessed history graph a and slice b .
on the slice b solid edges and solid nodes denote changes contributing to the slicing criterion dashed edges and hollow nodes denote corresponding but unchanged lines.
history models and history analyses.
in order to demonstrate and motivate the need for more descriptive models of source code history and analyses thereof we refer to our earlier work in which we defined an explicit model of sourcecode history i.e.
ahistory graph and a dependence analysis that operates on it i.e.
history slicing .
in past work we defined the concept of history slicing to automate analysis of the correspondence of lines and changes across multiple revisions of code.
the result a history slice of the history slicing process is defined as the complete and minimal history across all revisions of the queried set of lines of code.
in keeping with the slicing tradition the queried lines of code for a particular revision is called the slicing criterion .
for history slicing a fine grained model of the evolution of the code is needed.
we call such a fine grained multi revision model of the code history a history graph .
the history graph maps the corresponding lines between each two consecutive revisions across any epoch of the code history.
once the history graph is constructed either a priori or on demand the history slice can be computed for any slicing criterion by traversing the graph in either time direction .
example.
figure a depicts a history graph for the program history shown in figure .
this history graph was created without any automation and was assessed by a person from one of our empirical studies described later in section iv .
each column represents a revision and in each column the nodes represent lines of code.
between each adjacent pair of revisions edges are drawn to represent evolution of lines of the incident nodes.
solid edges are drawn to represent changed and corresponding lines and dotted edges represent authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
rev5 rev4 rev3 rev2 rev1 rev5 rev4 rev3 rev2 rev1 slicing criterionall to all existing automatic technique a all to all histor y graph b all to all histor y slice fig.
existing all to all history graph and slice.
slice has high recall but low precision.
unchanged and corresponding lines.
on this graph the slicing criterion is defined as line in revision .
the computation of the history slice is depicted in figure b .
in this figure the analysis is performed as a backward in time analysis and the edges are now depicted as directional to convey the traversal of the reachability analysis.
nodes that represent changed lines are depicted as a solid red dot these constitute the resulting history slice.
nodes that did not change but are on the trajectory of the slice are depicted as open red nodes.
as our example demonstrates people can manually construct a history graph and perform the history slicing analysis.
note that the code history may be assessed differently by another individual such manual assessments are subject to both human fallibility and differences of opinion.
in truth often such histories can be subject to debate and no authoritative truth is possible.
more importantly the manual task of computing the history of lines of code can be time consuming.
existing automated all to all history analyses.
to help automate such history analyses tools and techniques have been developed and used.
a commonly used tool diff can be used to determine which lines changed from one revision to another for any pair of files.
such continuous blocks of changed code are called change hunks .
for example diff computes this difference between revision and revision 8c1 array a getfirstarray array b getsecondarray a sortarray a b sortarray b int m max size get the array union array u getunion a b m array firstarray getfirstarray array secondarray getsecondarray get union with maximum size int maxsize get the union of arrays array u getunion firstarray secondarray maxsize using such diff results researchers created models of history and analyses on them by encoding the potential for all lines in the prior revision to have changed into all lines in the subsequent revision for each change hunk.
for example zimmermann et al.
proposed a model called annotation graphs .
we generalize all such models that map all lines of the prior revision to all lines of the later revision of a change hunk we refer to them as all to all history graphs .
the all to all history graph reduces the number of false negatives i.e.
not mapping lines of code that actually did evolve one into the other by performing conservative mapping.
as a consequence such all to all models can be expected to provide high recall although they may also provide low precision .
moreover such conservative mapping can cause compoundingrev5 rev4 rev3 rev2 rev1 rev5 rev4 rev3 rev2 rev1 slicing criterionone to one existing automatic technique a one to one history graph b one to one history slice fig.
existing one to one history graph and slice.
slice has high precision but low recall.
imprecision when performing reachability analyses on the graph for history slicing.
example.
for our running example figure a depicts the history graph constructed using an all to all strategy to map lines in the older revision to lines in the newer revision for each change hunk.
compared to the manually assessed but time consuming model in figure b we observe that the all to all analysis produced a result that wholly subsumes the correct lines in each revision.
however as expected it includes many more lines in each revision particularly for the oldest revision that contains all lines except one.
additionally the number of revisions that would be recommended for examination is also an over approximation.
as a result automatic analyses to assess risk for bugginess based on code history e.g.
would overapproximate the risk of this code selection since it would be reported as being changed five times even though it was changed only three times.
similarly automatic analyses to recommend expert developers for code based on its history e.g.
would also overapproximate including chris as an expert as much as bob even if chris never changed the code selection.
existing automated one to one history analyses.
to address the problems introduced by the over approximate nature of all to all history models researchers developed advanced line mapping techniques that allow for the disambiguation of lines in change hunks e.g.
.
the methods by which each such technique resolves which lines in the older revision correspond to which lines in the newer revision may differ however a common technique is to use an optimization algorithm to find the most optimal one toone mapping.
in this work we generalize history models that are based on such one to one line mapping for change hunks we refer to these as one to one history graphs .
the one to one history graph reduces the number of false positives i.e.
not mapping lines of code that are not truly associated .
as a consequence such one to one models can be expected to provide high precision although they may also provide low recall .
moreover the errors of under approximation introduced by the one to one models can cause compounding false negative errors when performing reachability analyses on the graph for slicing.
example.
for our running example figure a depicts the history graph constructed using a one to one strategy to map lines in the older revision to lines in the newer revision authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
for each change hunk.
compared to the manually assessed model in figure b we observe that the one to one analysis produced a result that contains no spurious lines for any revision.
however as expected it excludes many lines in each revision that should have been included.
additionally the set of revisions that would be recommended for examination is also an under approximation.
thus automatic analyses to assess risk for bugginess based on code history e.g.
would underapproximate the risk of this code selection since it would be reported as being changed only once even though it was changed three times.
likewise automatic analyses to recommend expert developers for code based on its history e.g.
would also underapproximate including only bob as an expert and therefore missing alice who also contributed to the selected code s history.
for each type of automatically generated history graph all to all and one to one errors are felt and moreover those errors tend to compound when used for multi revision analyses such as history slicing.
given this background our goal is to enable accurate multi revision analyses.
iii.
f uzzy history analysis in this paper we follow the intuition that code evolution has a fundamental fuzzy nature.
that is there are varying degrees to which lines of code evolve in subsequent revisions as opposed to the mapping of lines between revisions being binary mapped or not .
this intuition was further strengthened by the human assessed manual line mappings that we encountered.
moreover there were sometimes uncertainty by individuals performing manual mapping or dispute between multiple individuals as to the correct mapping.
as such we created fuzzy history slicing as an automated analysis that is based on a fuzzy model of code evolution which we naturally call the fuzzy history graph .
these techniques have the goal of addressing the over approximation errors found with all to all analyses and the under approximation errors found with one to one analyses.
we create a fuzzy approach to history slicing that can account for the indeterminate nature and degree of evolution of lines from one revision to the next.
while past work showed the productivity improvements provided by history slicing this paper studies the accuracy of fine grained code history analysis contributing a novel approach to model finegrained code history that recognizes the fuzzy nature of code evolution a novel algorithm to compute such fuzzy code history a novel approach to analyze fine grained code history that leverages the different extents to which lines of code evolve an algorithm to perform the fundamental code history operation of obtaining the fuzzy evolution of a set of lines of code and evaluations of the accuracy improvement provided by the novel fuzzy code history analysis for single code evolutions and complete code histories.
example.
before defining fuzzy history analysis we return to our running example.
figure a depicts the fuzzy history graph that was constructed by assessing the degree to whichrev5 rev4 rev3 rev2 rev1 rev5 rev4 rev3 rev2 rev1 slicing criterionfuzzy new automatic technique a fuzzy history graph b fuzzy history slice fig.
novel fuzzy history graph and slice.
slice allows for tuning precision and recall in a way that is more accurate than absolute techniques.
each line in the older revision is similar to each line in the newer revision.
darker lines represent a strong correspondence and lighter lines represent weaker correspondence.
figure b demonstrates a fuzzy history slice computed on the fuzzy history graph.
the lines in each revision that are included in the fuzzy history slice are colored solid red and their membership values are represented by the saturation of those nodes.we observe that among the lines in each revision with the highest membership these more strongly agree with the human assessed slice shown in figure .
moreover the revisions that would be recommended for examination also more strongly match the human assessed revisions.
fuzzy history slicing approach.
the approach for performing fuzzy history slicing involves three processes.
select fuzzy history slicing criterion.
in this process a user or an automated analysis selects the fuzzy history slicing criterion that represents the lines of code and revisions of interest.
the fuzzy history slicing criterion is specified as a fuzzy set that is composed of angbracketleftline starting revision ending revision angbracketrighttuples.
each tuple represents a line of code of interest that is characterized by the two revisions of the program between which the history analysis is requested for that line.
a fuzzy history slicing criterion can include any set of lines of code contiguous or not from any set of files and revisions.
build fuzzy history graph.
this process creates our novel fine grained model of code evolution the fuzzy history graph by analyzing the revision control system.
following our intuition that lines of code evolve into other lines to varying degrees the fuzzy history graph includes a measure of the degree to which each older line became a new one.
as we described in figure and similarly to previous fine grained code evolution models the fuzzy history graph has the shape of a multipartite graph.
each part represents a revision each node represents a line of code each edge represents a mapping between incident line nodes and each edge has a weight assigned or membership function that estimates the the degree to which an older line became a new one.
edge weights can be computed in multiple ways and different approaches to computing them can inform different analyses of fuzzy code evolution.
the fuzzy history graph can be constructed once and then updated for every new revision of the code and it can also be reused for different fuzzyhistory slice analyses.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
algorithm build fuzzy history graph procedure fuzzy maprevs revisionl revisionr m mapunchangedlines revisionl revisionr for linesl linesr chhunks revisionl revisionr do m m fuzzymaplines linesl linesr end for return m end procedure procedure fuzzy maplines linesleft linesright forlleft linesleft do ml ml fuzzymapline lleft linesright end for forlright linesright do mr mr fuzzymapline lright linesleft for lr rr wr mr do ifml contains rr lr then ll rl wl ml.get ll rl ml.update ll rl m a x wr wl end if end for end for return ml end procedure procedure fuzzy mapline l linesright cs fori ma x cs do newcs for c w cs do forr linesright do ifcnot contains r then wr levenshtein l r newc concatenate c r wnewc levenshtein l newc if wnewc wc wnewc wr then newcs newcs newc wnewc end if end if end for end for cs cs newcs end for m forr linesright do m m l r maxw concatscontaining r end for return m end procedure we created a technique to build the fuzzy history graph that uses a branch and bound optimization algorithm to minimize the textual difference between lines by using the levenshtein distance .
our intention with this technique is to estimate the degree to which lines of code evolved into others and to be able to capture situations where any number of lines evolve into any other number of lines.
this technique is described in algorithm and can be divided into multiple steps.
we include in parentheses the line number that implements each step.
first we map the lines that did not change at all between revisions with a weight of .
second we process the change hunks that remain .
for each change hunk we iterate through every line of code in the older revision and try to map it to the most similar concatenation of lines from the newer revision .
whenever a candidate concatenation branch is less similar to the candidate line than any of its components we stop adding lines to that concatenation we bound our search .
for our experiments we also bounded our search to a maximum of three lines of code although this setting is configurable.
third we iterate through every newer line and assign it the maximum weight identified for a concatenation that contains it .
fourth we perform the same operation in the opposite order iterating every line of code in the newer revision to compare it to concatenations of lines in the older revision .
fifth we iterate through every line pair between older and newer line and assign it the maximum weight found for it by comparing the mappings obtained in both orders .
slice fuzzy history graph.
this process involves the analysis of the fuzzy history graph to obtain the complete history of thealgorithm slice fuzzy history graph procedure fuzzy history slice criterion fhs for angbracketleftstartline startrev endrev angbracketright criterion do startnode getnode startline startrev fhs startnode futurenodes startnode currentrev startnode.rev while currentrev endrev do nf uturenodes forfuturenode futurenodes do forpastnode futurenode.getp astnodes do pastnode.w edge pastnode futurenode .w futurenode.w ifnf uturenodes contains pastnode then ifnf uturenodes.get pastnode .w pastnode.w then nf uturenodes.update pastnode w else pastnode nf uturenodes.get pastnode end if else nf uturenodes nf uturenodes pastnode end if fhs fhs pastnode currentrev pastnode.rev end for end for futurenodes nf uturenodes end while end for return fhs end procedure lines of code that were specified in the fuzzy history slicing criterion between the revisions that were specified in it.
in the process of slicing the fuzzy history graph we also estimate the degree to which each analyzed line on each analyzed revision belongs to the history of the lines specified in the slicing criterion.
essentially every time a new revision is visited this operation answers in a fuzzy manner the question included in our example in figure what are the corresponding lines in other revisions to a given line of code?
the traversal of the fuzzy history graph can be configured to compute a minimal fuzzy history slice including only nodes with changes to the previously visited node e.g.
only the solid nodes in figure or an extended fuzzy history slice including both changed and unchanged nodes e.g.
solid and open nodes in figure .
the final output of the fuzzy history slicing process is a fuzzy history slice i.e.
a fuzzy set of lines and revisions that are related to the lines in the fuzzy slicing criterion.
the fuzzy history slice of a set of lines of code contains the revisions of the program that modified those lines the lines that correspond to them in such revisions a weight for each included line indicating the degree to which it belongs to the fuzzy history slice and the weighted edges that connect included lines in consecutive revisions indicating the degree to which they evolved into each other.
as an example of a code history analysis technique that benefits from the fuzzy information stored in the fuzzy history graph we created a novel fuzzy history slicing technique.
we also used this technique for our experiments in section iv.
we implemented this technique as a breadth first search algorithm over the fuzzy history graph.
we describe this technique in algorithm .
we include in parentheses the line number that implements each step.
first it creates a working set of lines to visit that includes every line in the fuzzy history slicing criterion and assigns them a weight of .
.
second it iterates through the working set of lines and obtains every line of code that belongs to a previous revision of it .
third for each previous revision it assigns each line s weight by multiplying the weight assigned to the line from which it was visited by the weight of the authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
edge that connects them .
fourth once it has performed this process for every line in the working set it overwrites the working set of lines with the set of past revisions visited .
fifth it filters the working set of lines by when there are duplicate lines keeping the line with the highest weight .
sixth it also adds every line in the working set of lines to the fuzzy history slice .
seventh it checks if the visited revision is the last one specified to visit .
if it is not it starts the process again for the working set of lines.
if it is it stops and it returns the fuzzy history slice.
iv .
e v aluation in order to evaluate how fuzzy history analysis mitigates the limitations of current models of fine grained code history we perform two separate experiments that complement each other.
first we study the accuracy improvement that the fuzzy history graph may provide over current models for representing code history.
then we study the impact of such accuracy improvement over code history analysis tasks.
experiment fuzzy history graph accuracy.
in our first experiment we evaluate the accuracy with which the fuzzy history graph represents code evolution for individual changes.
the goal of this experiment is to evaluate whether and to what extent fuzzy history graphs improve the accuracy in terms of precision and recall of current code evolution models.
thus we built fuzzy one to one and all to all history graphs for a set of real world changes and measured their accuracy.
subjects and sampling.
we used three real world software projects to sample changes for our evaluation.
we picked a diverse set of projects in terms of domain size and history apache commons io which is a library to perform input and output functionality m ozilla rhino is a javascript parser written in java and a spect j is an aspect oriented programming framework for java.
a pache commons io has a size of thousand lines of code kloc and a history of years m ozilla rhino is composed of kloc and has a history of years and a spect j s size is around kloc and its history spans years.
we randomly sampled change hunks samples from each software project.
we extracted the change hunks produced by all the changes in a software project by using diff .
we sampled change hunks that had between and lines in the older or newer revision so that they had a manageable size to ask developers to assess their evolution.
human assessment.
four participants independently and manually assessed the code change histories and defined their judgment of the correct and ideal mapping.
the participants had years of experience programming in java to ensure that they were capable of assessing the ideal mapping.
confirming our description in section ii we observed the subjective nature of actual code evolution of the sampled change hunks obtained different assessments from different developers each change hunk was assessed by developers see sample for an example of varied assessment .
to reflect this fuzzy nature of code evolutions foreach older line that was assessed to evolve into a newer line we assigned a weight to this evolution equal to the number of developers that assessed it to exist divided by the total number of developers that assessed the change hunk.
for example if three developers assessed the change hunk from revision r4to revision r5of our example in figure and only one developer assessed line from r4as evolving into line in r5 that mapping would have a weight of .
in the human assessment for that change hunk .
independent v ariable change hunk type.
as observed in section ii the accuracy of current models is especially impacted when lines of code evolve into or from multiple other lines.
in order to study both cases where current models are expected to have limitations and cases in which they are not we classify the studied change hunks into four categories.
the classification divided our sample into one to one change hunks one to many change hunks many toone change hunks and many to many change hunks.
one to one.
every line of code in the older revision evolved into at most one line of code in the newer revision.
one to many.
at least one line in the older revision evolved into multiple lines in the newer revision.
many to one.
multiple lines of code in the older revision evolved into the same line of code in the newer revision.
many to many.
at least one line in the older revision evolved into multiple lines in the newer revision and more than one line in the older revision evolved into the same line in the newer revision.
independent v ariable evolution model.
we compare the accuracy of the fuzzy history graph to that of the other two existing evolution models one to one and all to all history graphs.
we build the existing models for each change hunk by replicating a corresponding state of the art technique.
while other techniques could have been chosen for building each evolution model they would similarly suffer the intrinsic limitations of modeling code evolution in a one to one or allto all fashion.
one to one history graph.
each line in the older revision is modeled as evolving into at most one line in the newer revision.
we build this evolution model using the technique proposed by servant and jones .
all to all history graph.
every line of code in the older revision is modeled as evolving into every line of code in the newer revision.
we build this evolution model using the technique proposed by zimmermann et al.
.
fuzzy history graph.
every line of code in the older revision is mapped as evolving into every line of code in the newer revision to a different extent which is indicated by a weight.
we build this evolution model using the technique described in section iii.
independent v ariable similarity threshold.
most of the techniques that build a one to one model use a similarity threshold to avoid modeling evolutions of lines that are very dissimilar.
in order to apply the same treatment to all the evaluated models we discard mapped lines with similarity authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
below the similarity threshold calculated as one minus the levenshtein distance after the one to one model and the fuzzy history graph are built.
because the all toall model does not account for the similarity of the modeled evolutions it is not affected by the similarity threshold.
we use ten different values for the similarity threshold .
.
.
.
.
.
.
.
.
and .
.
dependent v ariables.
we measure the accuracy with which a model represents each change hunk by measuring three dependent variables precision formula recall formula and f measure formula .
we used the fuzzy variation of the precision and recall metrics since we assessed the evolution of a change hunk as a fuzzy set of line mappings.
however we will refer to these metrics as simply precision and recall in the rest of the paper.
the fuzzy set definitions of precision and recall depend on fuzzy cardinality and intersection.
the cardinality of a fuzzy set is defined as the sum of its membership degrees as in formula .
the intersection of two fuzzy sets is defined as the set of all the elements that are in common each of which is assigned a membership degree equal to its minimum membership degree from both sets as in formula .
a summationdisplay a x x x a b x m i n a x b x x x precision modeled mappings human assessed mappings modeled mappings recall modeled mappings human assessed mappings human assessed mappings f measure precision recall precision recall results.
in the results of this experiment we expected to observe the limitations in terms of precision and recall of existing code evolution models that we described in section ii as well as the fuzzy history graph mitigating such limitations.
we depict in figure the mean precision recall and fmeasure provided for each type of change hunk by each model in a matrix of graphs.
from top to bottom each row of graphs shows mean precision mean recall and mean fmeasure scores respectively.
from left to right each column of graphs shows the results provided by each model for one to one one to many many to one and many to many change hunks as well as the mean results for all kinds of change hunks.
the vertical axis of each graph represents mean precision mean recall and mean f measure scores in the first second and third row respectively.
the horizontal axis of all graphs represents the similarity threshold used.
within each graph we use red squares to represent the scores obtained by the one to one model blue circles for all to all and green triangles for the fuzzy history graph.
the one to one model provided the highest mean precision and the lowest mean recall of all models for all types of change hunks and similarity thresholds.
we expected the oneto one model to provide high precision because it includes at most one mapping per older line of code and is therefore less likely to include false positives than other models.
for the same reason we also expected the one to one model toprovide low recall.
as the similarity threshold decreased the recall provided by the one to one model increased because it included more mappings.
however the recall stabilized below the similarity threshold of .
value since the one toone model did not include more than one mapping per line regardless of the similarity threshold used.
this characteristic also caused the one to one model to provide higher recall for the one to one change hunks than for the other types of change hunks.
these results demonstrate the limitations of one to one models described in section ii.
the all to all model provided the lowest mean precision and the highest mean recall of all models for all types of change hunks and similarity thresholds.
because the all toall model mapped every older line of code to every newer line of code in a change hunk it always reached a recall of .
.
however it modeled many false positives which caused it to provide low precision for all change hunk types particularly for one to one change hunks.
these results show the limitations of all to all models described in section ii.
the fuzzy history graph provided mean precision and mean recall values between those provided by existing models.
as we anticipated the fuzzy history graph always provided higher precision than the all to all model and higher recall than the one to one model.
moreover precision was positively correlated with the similarity threshold and recall was negatively related with the threshold.
as such the fuzzy history graphs allow a more flexible increase of the recall provided by the one to one model without sacrificing as much precision as the all to all model.
we also observed that the potential for increasing recall is much higher for one to many many toone and many to many change hunks because the one toone model already provides a quite high recall for one toone change hunks.
we also observed benefits of the fuzzy history graph in terms of the f measure which provides a balanced metric between precision and recall.
in terms of fmeasure the fuzzy history graph reached a higher value than the existing models for most change hunk types and most similarity thresholds specifically for similarity threshold .
which is the recommended value by most techniques that build one to one models e.g.
.
experiment impact of accuracy improvement in code history analysis tasks.
in our second experiment we evaluate how the accuracy improvement provided by the fuzzy history graph impacts code history analysis tasks.
we chose to study the popular code history analysis task of identifying bugintroducing changes as proposed by the szz approach since szz is an application area that represents very well the kinds of applications that would benefit from fuzzy history slicing.
szz is based on fine grained code history analysis and is therefore potentially limited by the compounding accuracy limitations of existing code history models.
since szz was introduced it has been adopted both by researchers and practitioners.
in the research literature szz has been extensively applied to study the characteristics of bug introducing changes e.g.
as well authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
as to provide automatic recommendations about the quality of code changes .
in addition practitioners use szz to detect the origin of bugs in industrial systems .
we analyzed the fuzzy one to one and all to all history graphs for three software projects by applying fuzzy history slicing defined in section iii to obtain the history slice for a set of sampled lines and measured the accuracy with which we could obtain the originating line s for each sample.
subjects sampling and human assessment.
in this experiment we used the same subjects as our previous experiment apache commons io m ozilla rhino and a spect j. for every subject we randomly sampled slicing criteria of a line of code that experienced at least five changes in their prior history.
for each slicing criterion we manually traversed the history of the program and determined the version in which the selected line was originated by iteratively using git blame over the history of the program.
we also manually assessed which lines of code corresponded to each sampled line in their originating revision by iteratively comparing each subsequent revision.
given the arduous nature of producing correct manual assessments we conducted this experiment with a total of slicing criteria randomly chosen with five criteria per subject program.
from slicing criterion to its first authorship the length of the history slices spanned a median of five years of development with a maximum length spanning nine years of development.
these changed files from criterion to first authorship spanned on average over revisions per criterion which had to be manually inspected and traversed.
independent v ariable evolution model.
we used the same evolution models as in experiment .
since the one to one and all to all history graphs produce discrete mappings we assigned their edges a .
weight.
dependent v ariable szz accuracy.
we measured the accuracy of szz by evaluating the weighted lines contained0.
.
.
.
.00precisionone to one change hunks .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
similarity thresholdf measure0.
.
.
.
.00recallone to many change hunks .
.
.
.
.
.
.
.
.
.
similarity thresholdmany to one change hunks .
.
.
.
.
.
.
.
.
.
similarity thresholdmany to many change hunks .
.
.
.
.
.
.
.
.
.
similarity thresholdall change hunk types .
.
.
.
.
.
.
.
.
.
similarity threshold one to one all to all fuzzy fig.
mean precision recall and f measure for the different code evolution models and change hunk types higher is better .in the originating revision with the normalized discounted cumulative gain ndcg metric .
ndcg is commonly used in information retrieval to assess the quality of weighted results.
the ndcg metric was chosen because it provides a convenient and standard way to evaluate potentially weighted results in a way that accounts for positions of multiple correct and incorrect results and accounts for the size of the result set.
ndcg evaluates a weighted set as a recommendation that is sorted in terms of the elements weights.
ndcg results range from for the worst recommendation possible to for the best recommendation possible.
we used the ndcg formula proposed by burges et al.
as in equation .
ndcg p dcg p recomm.
dcg p ideal recomm.
dcg p p summationdisplay i 12reli log2 i ndcg is calculated as the discounted cumulative gain dcg score for a recommendation divided by the dcg score of an ideal recommendation in which the correct lines are contained in its top positions.
in the dcg formula equation irepresents the top ithposition inside a recommendation and rel irepresents the actual relevance of the item recommended in position i. we attributed a relevance of to every line of code that we assessed as corresponding to the criterion.
we used ndcg 50scores to accommodate even the largest produced recommendations in our study lines .
in some cases multiple lines were recommended with the same weight as was the case with the absolute discrete models.
in such cases we computed the average case for the order of the recommendation i.e.
as if the recommendation results were randomly ordered over an infinite number of orderings .
results.
in this experiment the fuzzy history graph performed better than existing models.
we observed the limitations of the one to one model and the all to all model propagating through multiple revisions of the code and thus decreasing the accuracy of the szz code evolution analysis task.
figure shows for each subject box plots that represent the distribution of ndcg 50scores provided by each history model.
the one to one model provided a median ndcg 50score of .
for all subjects which is displayed as a flat bar at the .
score in figure .
for most of the studied lines of code the one to one model did not capture their changes in enough revisions to track their history back to their originating revision we illustrated this limitation in figure .
since the oneto one model applies a similarity threshold to decide which lines evolved into others it prematurely ended code history.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
.
.
.
.
.
commons io rhino aspectj subject programndcg score one to one all to all fuzzy fig.
accuracy of szz for different code history models.
higher scores are better.
as a result szz returned no lines for the studied lines in their actual originating revisions.
the all to all model obtained a median ndcg 50score of .
in m ozilla rhino and a median ndcg 50score of .
i na pache commons io and a spect j. because the allto all model often contains multiple mappings for each line of code the history of a single line of code included increasing numbers of lines as the traversal length increased over history.
however in the end we were surprised to find that szz using the all to all history graph sometimes included the correct human assessed lines in the originating revision within a reasonably sized set of lines.
we speculate that at least for our randomly chosen slicing criteria the compounding imprecision in the example program in section ii was found to a limited extent.
in contrast the fuzzy history graph obtained a median ndcg 50score of .
in all subjects which is displayed as a flat bar at the .
score in figure .
for all the studied lines of code except for one in a spect j szz recommended all their actual originating lines of code in the top position of its recommendation.
the weights assigned to mappings in the fuzzy history graph allowed szz to select the paths with highest overall similarity in the history of the studied lines and thus recommend their actual corresponding lines in the top positions of its recommendation.
differently than the one toone model the fuzzy history graph contains all potential mappings so the history of lines of code did not end prematurely.
differently than the all to all model the fuzzy history graph assigned weights to mappings to represent their strength so szz could provide more informed recommendations by using the strength of the changes experienced by the line of code.
discussion.
reflecting upon these results we discuss the implications and other aspects of our evaluation.
benefits of accuracy improvement for code history tasks.
we observed the limitations of existing code history models compounding as more past code revisions were included in the code history analysis as also illustrated in figure .
a representative case is one of our studied samples for r hino line revision .
of interpreter.java .
with the one to one model szz identified only past revisions containing only line of code each.
since szz estimated that changes before those past revisions modified the code too much it stopped identifying revisions early far from reaching the originating revision.
with the all toall model szz identified past revisions reaching the originating revision but identifying lines of code in it.
sinceszz accounted for every potential line of code evolution it identified too many revisions and lines within them.
with the fuzzy history graph szz identified the same revisions and lines as the all to all model but it assigned the highest relevance i.e.
membership value to the actual originating line of code that corresponded to the selected line.
as a consequence users of szz would not find the originating revision for the selected code if using a one toone model or over approximate it to a large amount of information if using an all to all model.
for practitioners this would imply incorrectly learning lessons from changes that were not actually bug introducing or incorrectly learning that a bug was introduced by a large superset of changes.
for researchers such under and over approximations would introduce inaccuracies in szz based research techniques e.g.
estimating the quality of code changes .
in contrast when using the fuzzy history graph practitioners and researchers would correctly identify the bug introducing changes at the top of the ranked lines returned by szz and therefore would be able to learn from the correct changes.
computational efficiency.
for all three approaches for all subject programs and for all history tasks the results for each graph analysis were computed in less than a second in a consumer laptop .
ghz intel core duo p8700 8gb ram since the graph is pre computed in a database and it does not need to be kept in memory in full.
fuzzy history graphs are built offline being a time cost with negligible cost incremental updates for new code changes.
the graph is then reused for all analyses.
as such none of these approaches i.e.
one to one all to all nor fuzzy exhibited any challenges in terms of computational scalability despite that all of our software subjects are real world systems with over years of active development.
all such approaches were virtually equivalent in terms of computational time overhead.
results summary.
in summary our experiments revealed that the fuzzy history graph improved the accuracy of existing code history models and the accuracy of an automatic technique to perform a code history analysis task szz .
v. r elated work researchers proposed techniques to analyze the multirevision evolution of code for specific purposes and at different granularities e.g.
kim et al.
and duala ekoko and robillard track the history of code fragments that contain code clones to study their evolution.
herzig and zeller analyze multiple revisions of methods to predict defects.
hassan and holt analyze the evolution of methods to infer change rationale.
in contrast history slicing facilitates multi purpose multi revision analyses of code evolution at the granularity of a line of code.
moreover in this paper we seek to improve the effectiveness of such multi revision code analyses by representing evolution more descriptively.
a number of researchers proposed line mapping techniques.
one example of line mapping technique that produces an allto all model is the annotation graph proposed by zimmermann et al.
.
many approaches have been proposed to authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
model code evolution in a one to one fashion.
canfora et al.
chen et al.
williams and spacco use a linemapping technique that first performs an inexact difference of revisions and then refines it by using an optimization algorithm.
reiss proposed a group of line mapping techniques some of which considered adjacent lines.
asaduzzaman et al.
proposed a language independent line mapping technique that also detects lines that evolve into multiple others although only when they change little and are contiguous.
in prior work the authors of this paper also proposed a one to one history graph using levenshtein distance and the kuhnmunkres algorithm.
in this current work we describe the first explicit weighted model of code evolution.
other models represent code evolution at different granularities.
hassan and holt model code evolution at the methodlevel .
hata et al.
proposed a model for tracking the history of methods and fields that accounts for renames.
godfrey and zou and wu et al.
also track the history of methods and fields and detect their splits and merges.
zimmermann et al.
fluri et al.
and spacco and williams capture differences at the statement level.
girba and ducasse proposed a code evolution meta model at multiple levels of granularity.
other researchers proposed algorithms that perform the mapping over models of the program e.g.
allowing the detection of moved code e.g.
or providing techniques for specific domains e.g.
.
some techniques capture code changes by monitoring the ide e.g.
to model evolution with high accuracy when all developers always use the required ide.
our model is applicable to such models.
davies et al.
proposed software bertillonage to track the evolution of releases of code outside the revision control system.
finally kim and notkin presented a survey of techniques that track program elements between revisions.
to the extent of our knowledge the model proposed in this paper is the first fine grained code evolution model to quantify the evolution of code and preserve it as a fuzzy measure to augment the model itself thus enabling multi revision analyses of code evolution at the line of code granularity to leverage such fuzzy measure.
vi.
t hreats to validity an external threat to validity is whether our proposed technique may capture some complex changes such as movements of code between files since it is based on textual differencing.
we intend to study in future work the accuracy improvements that may be provided by modeling fine grained code history with semantic approaches e.g.
in a fuzzy manner.
in this paper however our goal is to study the accuracy improvements provided by a fuzzy approach to modeling and analyzing code history.
the limitation for capturing moved code between files affects both our proposed textual differencing technique and all the other techniques studied in our experiments.
in that respect we believe that this limitation did not affect the results of our experiments.
additionally the fuzzy history graph may address this limitation since it allows its construction with other line mapping techniques e.g.
.another possible external threat to validity is whether our technique would scale to other code bases.
we studied software systems of up to kloc in size and up to years of development and all over years of development.
in all cases for all techniques the computational cost was well under second which demonstrates that the computational cost of such querying is negligible.
vii.
c onclusions and future work in this paper we presented a novel model of source code history at the line of code granularity fuzzy history graph and novel multi revision analysis based upon it fuzzy history slicing that can improve the accuracy of the modeling and analysis of code history.
the fuzzy history graph allows for a more expressive representation of code history by including a measure of the degree to which lines of code evolve.
we provided techniques to build fuzzy history graphs and analyze them fuzzy history slicing .
we demonstrated their accuracy over three real world software projects each having over a decade of history.
we evaluated the benefits provided by fuzzy history graphs for representing and analyzing code history.
the fuzzy history graph provided a tunable balance between precision and recall and moreover provided a higher f measure score than afforded by existing code history models.
also we found that the fuzzy history graph improved the accuracy of an automatic technique for a code history analysis task identifying bug introducing changes with szz over existing code history models.
in practice these results mean that software engineers could more accurately identify past bug introducing changes to learn from them and automatic szz based techniques would more accurately predict the quality of code changes e.g.
.
moreover and more importantly this paper provides a novel theoretical fuzzy framework for modeling and analyzing code history which also opens the door for other future fuzzy code history analyses to emerge as well potentially even by adapting other existing discrete approaches to a fuzzy model e.g.
automatic recommendations of developers to fix bugs or detection of code clones .
in the future we plan to experiment with additional algorithms to build the fuzzy history graph that may provide yet other benefits to the model and client analyses.
we also plan to design additional code history analysis techniques that can benefit from processing the weights of the fuzzy history graph such as an analysis technique to identify the most relevant changes in the history of a method.
viii.
r eplication we provide our experimental dataset as a resource for future research and for experimental replication .
acknowledgment this work is supported by the national science foundation under award career ccf .
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.