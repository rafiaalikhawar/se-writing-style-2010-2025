deep api learning xiaodong gu1 hongyu zhang2 dongmei zhang3 and sunghun kim1 1the hong kong university of science and technology hong kong china guxiaodong1987 .com hunkim cse.ust.hk 2the university of newcastle callaghan australia hongyu.zhang newcastle.edu.au 3microsoft research beijing china dongmeiz microsoft.com abstract developers often wonder how to implement a certain functionality e.g.
how to parse xml les using apis.
obtaining an api usage sequence based on an api related natural language query is very helpful in this regard.
given a query existing approaches utilize information retrieval models to search for matching api sequences.
these approaches treat queries and apis as bags of words and lack a deep understanding of the semantics of the query.
we propose deepapi a deep learning based approach to generate api usage sequences for a given natural language query.
instead of a bag of words assumption it learns the sequence of words in a query and the sequence of associated apis.
deepapi adapts a neural language model named rnn encoder decoder.
it encodes a word sequence user query into a xed length context vector and generates an api sequence based on the context vector.
we also augment the rnn encoder decoder by considering the importance of individual apis.
we empirically evaluate our approach with more than million annotated code snippets collected from github.
the results show that our approach generates largely accurate api sequences and outperforms the related approaches.
ccs concepts software and its engineering !reusability keywords api deep learning rnn api usage code search .
introduction to implement a certain functionality for example how to parse xml les developers often reuse existing class libraries or frameworks by invoking the corresponding apis.
obtaining which apis to use and their usage sequence the method invocation sequence among the apis is very helpful in this regard .
for example to parse xml permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
copyrights for components of this work owned by others than acm must be honored.
abstracting with credit is permitted.
to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
request permissions from permissions acm.org.
fse nov seattle wa usa c acm.
isbn .
les using jdk library the desired api usage sequence is as follows documentbuilderfactory newinstance documentbuilderfactory newdocumentbuilder documentbuilder parse yet learning the apis of an unfamiliar library or software framework can be a signi cant obstacle for developers .
a large scale software library such as .net framework and jdk could contain hundreds or even thousands of apis.
in practice usage patterns of api methods are often not well documented .
in a survey conducted by microsoft in .
respondents mentioned that there are obstacles caused by inadequate or absent resources for learning apis .
another eld study found that a major challenge for api users is to discover the subset of the apis that can help complete a task .
a common place to discover apis and their usage sequence is from a search engine.
many developers search apis from general web search engines such as google and bing.
developers can also perform a code search over an open source repository such as github and then utilize an api usage pattern miner to obtain the appropriate api sequences.
however search engines are often ine cient and inaccurate for programming tasks .
general web search engines are not designed to speci cally support programming tasks.
developers need to manually examine many web pages to learn about the apis and their usage sequence.
besides most of search engines are based on keyword matching without considering the semantics of natural language queries .
it is often di cult to discover relevant code snippets and associated apis.
recently raghothaman et al.
proposed swim which translates a natural language query to a list of possible apis using a statistical word alignment model .
swim then uses the api list to retrieve relevant api sequences.
however the statistical word alignment model it utilizes is based on a bag of words assumption without considering the sequence of words and apis.
therefore it cannot recognize the deep semantics of a natural language query.
for example as described in their paper it is di cult to distinguish the query convert int to string from convert string to int.
to address these issues we propose deepapi a novel deep learning based method that generates relevant api usage sequences given a natural language query.
we formulate the api learning problem as a machine translation problem given a natural language query x x1 xnwherexiarxiv .08535v3 jul 2017is a keyword we aim to translate it into an api sequence y y1 ytwhereyjis an api.
deepapi shows a deep understanding of natural language queries in two aspects first instead of matching keywords deepapi learns the semantics of words by embedding them into a vector representation of context so that semantically related words can be recognized.
second instead of word to word alignment deepapi learns the sequence of words in a natural language query and the sequence of associated apis.
it can distinguish the semantic di erences between queries with di erent word sequences.
deepapi adapts a neural language model named rnn encoder decoder .
given a corpus of annotated api sequences i.e.
hapi sequence annotation ipairs deepapi trains the language model that encodes each sequence of words annotation into a xed length context vector and decodes an api sequence based on the context vector.
then in response to an api related user query it generates api sequences by consulting the neural language model.
to evaluate the e ectiveness of deepapi we collect a corpus of million annotated code snippets from github.
we select thousand instances for testing and the rest for training the model.
after hours of training million iterations we measure the accuracy of deepapi using bleu score a widely used accuracy measure for machine translation.
our results show that deepapi achieves an average bleu score of .
outperforming two related approaches that is code search with pattern mining .
and swim .
.
we also ask deepapi apirelated queries collected from real query logs and related work.
on average the rank of the rst relevant result is .
.
of the top returned results and of the top returned results are deemed relevant.
our evaluation results con rm the e ectiveness of deepapi .
the main contributions of our work are as follows to our knowledge we are the rst to adapt a deep learning technique to api learning.
our approach leads to more accurate api usage sequences as compared to the state of the art techniques.
we develop deepapi1 a tool that generates api usage sequences based on natural language queries.
we empirically evaluate deepapi s accuracy using a corpus of million annotated java code snippets.
the rest of this paper is organized as follows.
section describes the background of the deep learning based neural language model.
section describes the application of the rnn encoder decoder a deep learning based neural language model to api learning.
section describes the detailed design of our approach.
section presents the evaluation results.
section discusses our work followed by section that presents the related work.
we conclude the paper in section .
.
deep learning for sequence generation our work adopts and augments recent advanced techniques from deep learning and neural machine translation 1available at input t output t context t context t a rnn structure eos text file read start hidden layer contexts output layer h1 h2 h3 h4y1 y2 y3 y4 y1 y2 y3 read text fileinput layer b rnnlm for sentence estimation figure illustration of the rnn language model .
these techniques are on the basis of sequence tosequence learning namely generating a sequence usually a natural language sentence conditioned on another sequence.
in this section we discuss the background of these techniques.
.
language model it has been observed that software has naturalness .
statistical language models have been adapted to many software engineering tasks such as learning natural code conventions code suggestion and code completion .
these techniques regard source code as a special language and analyze it using statistical nlp techniques.
the language model is a probabilistic model of how to generate sentences in a language.
it tells how likely a sentence would occur in a language.
for a sentence y wherey y1 yt is a sequence of words the language model aims to estimate the joint probability of its words pr y1 yt .
since pr y1 yt ty t 1pr ytjy1 yt it is equivalent to estimate the probability of each word in ygiven its previous words namely what a word might be given its predecessing words.
aspr ytjy1 yt is di cult to estimate most applications use n gram models to approximate it that is pr ytjy1 yt wpr ytjyt n yt where an n gram is de ned as nconsecutive words.
this approximation means that the next word ytis conditioned only on the previous n words.
.
neural language model the neural language model is a language model based on neural networks.
unlike the n gram model which predicts a word based on a xed number of predecessing words a neural language model can predict a word by predecessing words with longer distances.
it is also powerful to learn distributed representations of words i.e word vectors .
we adopt rnnlm a language model based on a deep neural network that is recurrent neural network rnn .
figure 1a shows the basic structure of an rnn.
the neural network includes three layers that is an input layer which maps each word to a vector a recurrent hidden layer which recurrently computes and updates a hidden state after reading each word and an output layer which estimates the probabilities of the following word given the current hidden state.
figure 1b shows an example of how rnnlm estimates the probability of a sentence that is the probability of each word given predecessing words equation .
to facilitate understanding we expand the recurrent hidden layer foreach individual time step.
the rnnlm reads the words in the sentence one by one and predicts the possible following word at each time step.
at step t it estimates the probability of the following word p yt 1jy1 yt by three steps first the current word ytis mapped to a vector yt by the input layer yt input yt then it generates the hidden state values in the hidden layer htat timetaccording to the previous hidden state ht 1and the current input yt ht f ht yt finally the pr yt 1jy1 yt is predicted according to the current hidden state ht pr yt 1jy1 yt g ht during training the network parameters are learned from data to minimize the error rate of the estimated y details are in .
.
rnn encoder decoder model the rnn encoder decoder is an extension of the basic neural language model rnnlm .
it assumes that there are two languages a source language and a target language.
it generates a sentence yof the target language given a sentencexof the source language.
to do so it rst summarizes the sequence of source words x1 xtxinto a xed length context vector ht f ht xt and c htx wherefis a non linear function that maps a word of source language xtinto a hidden state htat timetby considering the previous hidden state ht .
the last hidden state htx is selected as a context vector c. then it generates the target sentence yby sequentially predicting a word ytconditioned on the source context cas well as previous words y1 yt pr y ty t 1p ytjy1 yt c the above procedures i.e.
fandpcan be represented using two recurrent neural networks respectively an encoder rnn which learns to transform a variable length source sequence into a xed length context vector and a decoder rnn which learns a target language model and generates a sequence conditioned on the context vector.
the encoder rnn reads the source words one by one.
at each time stampt it reads one word then updates and records a hidden state.
when reading a word it computes the current hidden state htusing the current word xtand the previous hidden state ht .
when it nishes reading the end ofsequence word eos it selects the last hidden state htx as a context vector c. the decoder rnn then sequentially generates the target words by consulting the context vector equation .
it rst sets the context vector as an initial hidden state of the decoder rnn.
at each time stamp t it generates one word based on the current hidden state and the context vector.
then it updates the hidden state using the generated word equation .
it stops when generating the end of sentence word eos .the rnn encoder decoder model can then be trained to maximize the conditional log likelihood namely minimize the following objective function l nnx i 1tx t 1costit wherenis the total number of training instances while tis the length of each target sequence.
costitis the cost function for thet th target word in instance i. it is de ned as the negative log likelihood costit logp yitjxi where denotes model parameters such as weights in the neural network while p yitjxi derived from equation to denotes the likelihood of generating the t th target word given the source sequence xiin instance iaccording to the model parameters .
through optimizing the objective function using optimization algorithms such as gradient descendant the optimum value can be estimated.
.
rnn encoder decoder model for api learning .
application of rnn encoder decoder to api learning now we present the idea of applying the rnn encoderdecoder model to api learning.
we regard user queries as the source language and api sequences as the target language.
figure shows an example of the rnn encoderdecoder model for translating a sequence of english words read text le to a sequence of apis.
the encoder rnn reads the source words one by one.
when it reads the rst word read it embeds the word into vector x1and computes the current hidden state h1using x1.
then it reads the second word text embeds it into x2 and updates the hidden state h1toh2using x2.
the procedure continues until the encoder reads the last word leand gets the nal state h3.
the nal state h3is selected as a context vector c. the decoder rnn tries to generate apis sequentially using the context vector c. it rst generates start as the rst word y0.
then it computes a hidden state h1based on the context vector candy0 and predicts the rst api filereader.new according to h1.
it then computes the next hidden state h2according to the previous word vector y1 the context vector c and predicts the second api bu eredreader.new according to h2.
this procedure continues until it predicts the end of sequence word eos .
di erent parts of a query could have di erent importance to an api in the target sequence.
for example considering the query save le in default encoding and the target api sequence file.new fileoutputstream.new fileoutputstream.write fileoutputstream.close the word leis more important than default to the target api file.new .
in our work we adopt the attention based rnn encoder decoder model which is a recent model that selects the important parts from the input sequence for each target word.
instead of generating target words using the same context vector c c htx an attention model de nes individual cj s for each target word yjas a weighted sum of all historical hidden states h1 htx.
that is cj txx t jtht start h1 h2 h3 h4y1 y2 y3 y4 y1 y2 y3h1 h2 h3 x1 x2 x3 read text filecencoder rnn decoder rnn bufferereader .newfilereader .newbufferereader .readbufferereader .close eos bufferereader .newfilereader .newbufferereader .readbufferereader .closeh5y5 y4 inputoutput hiddenfigure an illustration of the rnn encoder decoder model for api learning where each jtis a weight between the hidden state htand the target word yj while can be modeled using another neural network and learned during training see details in .
.
enhancing rnn encoder decoder model with api importance the basic rnn encoder decoder model does not consider the importance of individual words in the target sequence either.
in the context of api learning di erent apis have di erent importance for a programming task .
for example the api logger.log is widely used in many code snippets.
however it cannot help understand the key procedures of a programming task.
such ubiquitous apis would be weakened during sequence generation.
we augment the rnn encoder decoder model to predict api sequences by considering the individual importance of apis.
we de ne idf based weighting to measure api importance as follows widf yt log n nyt wherenis the total number of api sequences in the training set and nytdenotes the number of sequences where the apiytappears in the training set.
using idf the apis that occur ubiquitously have the lower weights while the less common apis have the higher weights.
we use api weight as a penalty term to the cost function equation .
the new cost function of the rnn encoderdecoder model is costit logp yitjxi widf yt where denotes the penalty of idf weight and is set empirically.
.
deepapi deep learning for api sequence generation in this section we describe deepapi a deep learning based method that generates relevant api usage sequences given an api related natural language query.
deepapi adapts the rnn encoder decoder model for the task of api learning.
figure shows the overall architecture of deepapi.
it includes an o ine training stage and an online translation stage.
in the training stage we prepare a large scale corpus of annotated api sequences api sequences with corresponding natural language annotations .
the annotated api sequences are used to train a deep learning model i.e.
the rnn encoder decoder language model as described in code corpus deep learning rnn encoder decoderapi related user query suggested api sequencesnatural language annotations training instances api sequencestraining offline trainingfigure the overall work ow of deepapi section .
given an api related user query a ranked list of api sequences can be generated by the language model.
in theory our approach could generate apis written in any programming languages.
in this paper we limit our scope to the jdk library.
the details of our method are explained in the following sections.
.
gathering a large scale api sequence to annotation corpus we rst construct a large scale database that contains pairs of api sequences and natural language annotations for training the rnn encoder decoder model.
we download java projects from github created from to .
to remove toy or experimental programs we only select the projects with at least one star.
in total we collected java projects from github.
we use the last snapshot of each project.
having collected the code corpus we extracthapi sequence annotation ipairs as follows .
.
extracting api usage sequences to extract api usage sequences from the code corpus we parse source code les into asts abstract syntax trees using eclipse s jdt compiler .
the extraction algorithm starts from the dependency analysis of a whole project repository.
we analyze all classes recording eld declarations together with their type bindings.
we replace all object types with their real class types.
then we extract api sequence from individual methods by traversing the ast of the method body for each constructor invocation new c we append the api c.new to the api sequence.
for each method call o m whereois an instance of a jdk class c we append the api c.m to the api sequence.
for a method call passed as a parameter we append the method before the calling method.
for example copies bytes from a large over 2gb inputstream to an outputstream .
this method uses the provided buffer so there is no need to use a bufferedinputstream .
paraminput the inputstream to read from .
.
.
since .
publicstaticlongcopylarge finalinputstream input finaloutputstream output finalbyte buffer throwsioexception longcount intn while eof!
n input.read buffer output.write buffer n count n returncount api sequence inputstream.read outputstream.write annotation copiesbytes from a large inputstream to an outputstream .figure an example of extracting api sequence and its annotation from a java method ioutils copylarge7 o1.m1 o2.m2 o3.m3 we produce a sequence c2.m2c3.m3 c1.m1 whereciis the jdk class of instance oi.
for a sequence of statements stmt stmt ... stmtt we extract the api sequence sifrom each statement stmti concatenate them and produce the api sequences1 s2 ... st. for conditional statements such as if stmt fstmt gelsefstmt g we create a sequence from all possible branches that is s1 s2 s3 wheresiis the api sequence extracted from the statement stmti.
for loop statements such as while stmt fstmt g we produce a sequence s1 s2 wheres1ands2are api sequences extracted from the statement stmt 1andstmt respectively.
.
.
extracting annotations to annotate the obtained api sequences with natural language descriptions we extract method level code summaries speci cally the rst sentence of a documentation comment2for a method.
according to the javadoc guidance3 the rst sentence is used as a short summary of a method.
figure shows an example of documentation comment for a java method ioutils copylarge4in the apache commons io library.
we use the eclipse jdt compiler for the extraction.
for each method we traverse its ast and extract the javadoc comment part.
we ignore methods without javadoc comments.
then we select the rst sentence of the comment as the annotation.
we exclude irregular annotations such as those starting with todo auto generated method stub note and test .
we also lter out non words and words within brackets in the annotations.
finally we obtain a database consisting of hapi sequence annotation ipairs.
.
training encoder decoder language model 2a documentation comment in java starts with slashasterisk asterisk and ends with asterisk slash index .html main java org apache commons io ioutils.java start file.new fileinputstream.new stringbuilder.newfilereader.new file.exists file.mkdir 12datainputstream.new fileinputstream.read fileinputstream.close6 14bufferedreader.read 79bufferedreader.new stringbuilder.new filereader.close3 string.equals ...... ...figure an illustration of beam search beam width as described in section we adapt the attention based rnn encoder decoder model for api learning.
the rnn has various implementations we use gru which is a state of the art rnn and performs well in many tasks .
we construct the model as follows we use two rnns for the encoder a forward rnn that directly encodes the source sentence and a backward rnn that encodes the reversed source sentence.
their output context vectors are concatenated to the decoder which is also an rnn.
all rnns have hidden units.
we set the dimension of word embedding to .
we discuss the details of parameter tuning in section .
.
all models are trained using the minibatch adadelta which automatically adjusts the learning rate.
we set the batch size i.e.
number of instances per batch as .
for training the neural networks we limit the source and target vocabulary to the top words that are most frequently used in api sequences and annotations.
for implementation we use groundhog an opensource deep learning framework.
we train our models in a server with one nvidia k20 gpu.
the training lasts hours with million iterations.
.
translation so far we have discussed the training of a neural language model which outputs the most likely api sequence given a natural language query.
however an api could have multiple usages.
to obtain a ranked list of possible api sequences for user selection we need to generate more api sequences according to their probability at each step.
deepapi uses beam search a heuristic search strategy to nd api sequences that have the least cost value computed using equation given by the language model.
beam search searches apis produced at each step one by one.
at each time step it selects napis from all branches with the least cost values where nis the beam width.
it then prunes o the remaining branches and continues selecting the possible apis that follow on until it meets the end ofsequence symbol.
figure shows an example of a beam search beam width for generating an api sequence for the query read text le .
first start is selected as the rst api in the generated sequence.
then it estimates the probabilities of all possible apis that follow on according to the language model.
it computes their cost values according to equation and selects file.new and fileinputstream.new which have the least cost values of and respectively.
then it ignores branches of other apis and continue estimating possible apis after file.new andfilein putstream.new .
once it selects an end of sequence symbol as the next api it stops that branch and the branch is selected as a generated sequence.
finally deepapi producesnapi sequences for each query where nis the beam width.
we rank the generated api sequences according to their average cost values during the beam search procedure.
.
evaluation we evaluate the e ectiveness of deepapi by measuring its accuracy on api sequence generation.
speci cally our evaluation addresses the following research questions rq1 how accurate is deepapi for generating api usage sequences?
rq2 how accurate is deepapi under di erent parameter settings?
rq3 do the enhanced rnn encoder decoder models improve the accuracy of deepapi?
.
accuracy measure .
.
intrinsic measure bleu we use the bleu score to measure the accuracy of generated api sequences.
the bleu score measures how close a candidate sequence is to a reference sequence usually a human written sequence .
it is a widely used accuracy measure for machine translation in the machine learning and natural language processing literature .
in our api learning context we regard a generated api sequence given a query as a candidate and a human written api sequence extracted from code for the same query as a reference.
we use bleu to measure how close the generated api sequence is to a human written api sequence.
generally bleu measures the hits of n grams of a candidate sequence to the reference.
it is computed as bleu bp exp nx n 1wnlogpn where each pnis the precision of n grams that is the ratio of lengthnsubsequences in the candidate that are also in the reference pn n grams appear in the reference n grams of candidate 1forn n wherenis the maximum number of grams we consider.
we setnto which is a common practice in the machine learning literature .
each wnis the weight of each pn.
a common practice is to set wn n.bpis a brevity penalty which penalties overly short candidates that may have a higher n gram precision .
bp if c r e r c ifc r whereris the length of the reference sequence and cis the length of the candidate sequence.
we now give an example of bleu calculation.
for a candidate api sequence fa c d bgand a reference api sequence fa b c d eg their grams are fa b c dgandfa b c d eg.
all four grams of the candidate are hit in the reference.
then p1 .
their grams are fac cd dbgandfab bc cd deg respectively.
then p2 2as onlycdis matched.p3 3andp4 2as no gram nor 4gram is matched.
as their lengths are and respectively bp e .
the nal bleu is exp log1 log1 log1 log1 bleu is usually expressed as a percentage value between and .
the higher the bleu the closer the candidate sequence is to the reference.
if the candidate sequence is completely equal to the reference the bleu becomes .
.
.
extrinsic measures frank and relevancy ratio we also use two measures for human evaluation.
they are frank and relevancy ratio .
frank is the rank of the rst relevant result in the result list .
it is important as most users scan the results from top to bottom.
the relevancy ratio is de ned as the precision of relevant results in a number of results .
relevancy ratio relevant results all selected results the value of both measures ranges from to .
the higher the better.
.
comparison methods we compare the accuracy of our approach with that of two state of the art api learning approaches namely code search with pattern mining and swim .
.
.
code search with pattern mining to obtain relevant api sequences for a given a query one can perform code search over the code corpus using information retrieval techniques and then utilize an api usage pattern miner to identify an appropriate api sequences in the returned code snippets.
we compare deepapi with this approach.
we use lucene to perform a code search for a given natural language query and up miner to perform api usage pattern mining.
lucene is an open source information retrieval engine which has been integrated into many code search engines .
much the same as these code search engines do we treat source code as plain text documents and use lucene to build source code index and perform text retrieval.
up miner is a pattern mining tool which produces api sequence patterns from code snippets.
it rst clusters api sequences extracted from code snippets and then identi es frequent patterns from the clustered sequences.
finally it clusters the frequent patterns to reduce redundancy.
we use upminer to mine api usage sequences from the code snippets returned by the lucene based code search.
in this experiment we use the same code corpus as used for evaluating deepapi and compare the bleu scores with those of deepapi .
.
.
swim swim is a recently proposed code synthesis tool which also supports api sequence search based on a natural language query.
given a query it expands the query keywords to a list of relevant apis using a statistical word alignment model .
with the list of possible apis swim searches related api sequences using lucene .
finally it synthesizes code snippets based on the api sequences.
as code synthesis is beyond our scope we only compare deepapi with the api learning component of swim that is from a natural language query to an api sequence.
in theirtable bleu scores of deepapi and related techniques tool top1 top5 top10 lucene up miner .
.
.
swim .
.
.
deepapi .
.
.
experiments swim uses bing clickthrough data to build the model.
in our experiment for fair comparison we evaluate swim using the same dataset as we did for evaluating deepapi .
that is we train the word alignment model and build api index on the training set and evaluate the search results on the test set.
.
accuracy rq1 .
.
intrinsic evaluation evaluation setup we rst evaluate the accuracy of generated api sequences using the bleu score.
as described in section .
we collect a database comprising 907hapi sequence annotation ipairs.
we split them into a test set and a training set.
the test set comprises pairs while the training set consists of the remaining instances.
we train all models using the training set and compute the bleu scores in the test set.
we calculate the highest bleu score for each test instance in the top n results.
results table shows the bleu scores of deepapi swim and code search lucene up miner .
each column shows the average bleu score for a method.
as the results indicate deepapi produces api sequences with higher accuracy.
when only the top result is examined the bleu score achieved by deepapi is .
which is greater than that of swim bleu .
and code search bleu .
.
the improvement over swim is and the improvement over code search is .
similar results are obtained when the top and results are examined.
the evaluation results con rm the e ectiveness of the deep learning method used by deepapi .
.
.
extrinsic evaluation to further evaluate the relevancy of the results returned bydeepapi we selected queries used in .
these queries have corresponding java apis and are commonly occurring queries in the bing search log .
to demonstrate the advantages of deepapi we also designed longer queries and queries with semantically similar words.
in total queries are used.
these queries do not appear in the training set.
table lists the queries.
for each query the top returned results by deepapi and swim are manually examined.
to reduce labeling bias two developers separately label the relevancy of each resulting sequence and combine their labels.
for inconsistent labels they discuss and relabel them until a settlement is reached.
the frank and the relevancy ratios for the top and top returned results are then computed.
to test the statistical signi cance we apply the wilcoxon signed rank test p .
for all results of both approaches.
a resulting p value less than .
indicates that the di erences between deepapi and swim are statistically signi cant.
table shows the accuracy of both deepapi and swim.
the symbol means no relevant result has been returned within the top results.
the results show that deepapiis able to produce mostly relevant results.
it achieves an average frank of .
an average top accuracy of and an average top accuracy of .
furthermore deepapi produces more relevant api sequences than swim whose average top and top accuracy is and respectively.
for some queries swim failed to obtain relevant results in the top returned results.
we conservatively treat the frank as for these unsuccessful queries.
then the frank achieved by swim is greater than .
which is much higher than what deepapi achieved .
.
the p values for the three comparisons are .
.
and .
respectively indicating statistical signi cance of the improvement ofdeepapi over swim.
in summary the evaluation results con rm the e ectiveness of deepapi .
table also shows examples of generated sequences by deepapi .
we can see that deepapi is able to distinguish word sequences.
for example deepapi successfully distinguishes the query convert int to string from convert string to int .
another successful example is the query expansion.
for example the query save an image to a le andwrite an image to a le return similar results.
deepapi also performs well in longer queries such as copy a le and save it to your destination path andplay the audio clip at the speci ed absolute url .
such queries comprise many keywords and deepapi can successfully recognize the semantics.
we also manually check the results returned by swim.
we nd swim may return partially matched sequences.
for example for the query generate md5 hash code swim returns many results containing only object.hashcode which simply returns a hash code.
swim also returns project speci c results without fully understanding the query.
for example for the query test le exists swim returns file.new file.exists file.getname file.new file.delete fileinputstream.new fileinputstream.read ... which is not only related to le existence test but also to other project speci c tasks.
such project speci c results can also be seen for the query create le .
compared with deepapi swim performs worse in long queries.
for example swim performs worse in the query copy a le and save it to your destination path than in the query copy le .
this is because long queries often have multiple objectives which cannot be understood by swim.
still deepapi could return inaccurate or partial results.
for example for the query parse xml it returns related apis inputsource.new documentbuilder.parse .
but it misses the apis about how documentbuilder is created documentbuilderfactory.newdocumentbuilder .
the reason could be that an api sequence may be called in an inter procedural manner.
when preparing the training set we only consider api sequences within one method.
the api documentbuilderfactory.newdocumentbuilder could be called in another method and is passed as a parameter.
this causes incomplete sequences in the training set.
in the future we will perform more accurate program analysis and create a better training set.
.
accuracy under different parameter settings rq2 we also qualitatively compare the accuracy of deepapi in di erent parameter settings.
we analyze two parameters that is the dimension of word embedding and the number of hidden units.
we vary the values of these two parameters and evaluate their impact on the bleu scores.table queries for human evaluation fr frank rr5 top relevancy ratio rr10 top relevancy ratio query how to... swim deepapigenerated api sequence by deepapifr rr5 rr10 fr rr5 rr10 convert int to string integer.tostring convert string to int integer.parseint string.tochararray character.digit append strings stringbuilder.append stringbuilder.tostring get current time system.currenttimemillis timestamp.new parse datetime from string simpledateformat.new simpledateformat.parse test le exists file.new file.exists open a url url.new url.openconnection open le dialog jfilechooser.new jfilechooser.showopendialog jfilechooser.getselectedfile get les in folder file.new file.list file.new file.isdirectory match regular expressions pattern.compile pattern.matcher matcher.group generate md5 hash code messagedigest.getinstance messagedigest.update messagedigest.digest generate random number random.new random.nextint round a decimal value math.
oor math.pow math.round execute sql statement connection.preparestatement preparedstatement.execute preparedstatement.close connect to database properties.getproperty class.forname drivermanager.getconnection create le file.exists file.createnewfile copy le fileinputstream.new fileoutputstream.new fileinputstream.read fileoutputstrem.write fileinputstream.close fileoutputstream.close copy a le and save it to your destination path1 fileinputstream.new fileoutputstream.new fileinputstream.getchannel fileoutputstream.getchannel filechannel.size filechannel.transferto fileinputstream.close fileoutputstream.close filechannel.close filechannel.close delete les and folders in a directory1100 file.isdirectory file.list file.new file.delete reverse a string stringbu er.new stringbu er.reverse create socket serversocket.new serversocket.bind rename a le file.renameto file.delete download le from url url.new url.openconnection urlconnection.getinputstream bu eredinputstream.new serialize an object objectoutputstream.new objectoutputstream.writeobject objectoutputstream.close read binary le datainputstream.new datainputstream.readint datainputstream.close save an image to a le file.new imageio.write write an image to a le file.new imageio.write parse xml inputsource.new documentbuilder.parse play audio sourcedataline.open sourcedataline.start play the audio clip at the speci ed absolute url1 applet.getaudioclip audioclip.play average .
.
a performance of di erent dimensions of word embedding b performance of di erent numbers of hidden units figure bleu scores of di erent parameter settings figure shows the in uence of di erent parameter settings on the test set.
the dimension of word embedding makes little di erence to the accuracy.
the accuracy of deepapi greately depends on the number of hidden units in the hidden layer.
the optimum number of hidden units is around .
.
performance of the enhanced rnn encoderdecoder models rq3 in section we describe two enhancements to the original rnn encoder decoder model for the task of api learning an attention based rnn encoder decoder proposed by section .
and an enhanced rnn encoder decoder with a new cost function section .
proposed by us.
we now evaluate if the enhanced models improve the accuracy of deepapi when constructed using the original rnn encoderdecoder model.
table shows the bleu scores of the three models.
the attention based rnn encoder decoder outperforms the basic rnn encoder decoder model on api learning.
the relative improvement in the top and results in terms of bleu score is and respectively.
this result con rms the e ectiveness of the attention based rnn encoder decoder used in our approach.
table also shows that the enhanced model with the new cost function leads to better results as compared to the attention based rnn encoder decoder model.
the improvement in the top and results in terms of bleu score is and respectively.
figure shows that the performance of the enhanced model are slightly di erent under di erent parameter settings with an optimum of around .
.
the results con rm the usefulness of the proposed cost function for enhancing the rnn encoderdecoder model.
.
discussion .
why does deepapi work?table bleu scores of di erent rnn encoderdecoder models encoder decoder model top1 top5 top10 rnn .
.
.
rnn attention .
.
.
rnn attention new cost function .
.
.
figure performance of the enhanced rnn encoderdecoder model under di erent settings of a major challenge for api learning is the semantic gap between code and natural language descriptions.
existing information retrieval based approaches usually have a bagof words assumption and lack a deep understanding of the high level semantics of natural language and code.
we have identi ed three advantages of deepapi that address this problem.
word embedding and query expansion a signi cant di erence between deepapi and bag of words methods is deepapi embeds words into a continuous semantic space where the semantically similar words are placed close to each other.
when reading words in a query the model maps them to semantic vectors.
words with similar semantics have similar vector representations and have a similar impact on the hidden states of the rnn encoder.
therefore queries with semantically similar words can lead to similar results.
figure shows a d projection of the encoded vectors of queries.
these queries are selected from the annotations in the test set.
for ease of demonstration we select queries with a keyword le and exclude those longer than eight words.
as shown in the graph deepapi can successfully embed similar queries into a nearby place.
there are three clear clusters of queries corresponding to read load les write save les and remove delete les .
queries with semantically related words are close to each other.
for example queries starting with save write and output are in the same cluster though they contain di erent words.
learning sequence instead of bag of words the hidden layer of the encoder has the memory capacity.
it considers not only the individual words but also their relative positions.
even for the same word set di erent sequences will be encoded to di erent vectors resulting in di erent api sequences.
in that sense deepapi learns not only the words but also phrases.
while traditional models simply consider individual words or word level alignments.
a typical example is that queries with di erent word sequences such as convert int to string andconvert string to int can be distinguished well by deepapi .
generating common patterns instead of searching speci c samples another advantage of our approach is that it can learn common patterns of api sequences.
the decoder itself is a language model and remembers the likeli hoods of di erent sequences.
those common sequences will have high probabilities according to the model.
therefore it tends to generate common api sequences rather than project speci c ones.
on the other hand the information retrieval based approaches simply consider searching individual instances and could return project speci c api sequences.
though several techniques such as query expansion and frequent pattern mining can partially solve some of the above problems their e ectiveness remains to be improved.
for example it has been observed that expanding a code search query with inappropriate english synonyms can return even worse results as compared to the original query .
furthermore few techniques can exhibit all the above advantages.
.
threats to validity we have identi ed the following threats to validity all apis studied are java apis all apis and related projects investigated in this paper are jdk apis.
hence they might not be representative of apis for other libraries and programming languages.
in the future we will extend the model to other libraries and programming languages.
quality of annotations we collected annotations of api sequences from the rst sentence of documentation comments.
other sentences in the comments may also be informative.
in addition the rst sentences may have noise.
in the future we will investigate a better nlp technique to extract annotations for code.
training dataset in the original swim paper the clickthrough data from bing.com is used for evaluation.
such data is not easy accessible for most researchers.
for fair and easy comparison we evaluate swim on the dataset collected from github and java documentations the same for evaluating deepapi .
we train the models using annotations of api sequences collected from the documentation comments.
in the future we will evaluate both swim and deepapi on a variety of datasets including the bing clickthrough data.
in the future we will perform more accurate program analysis and create a better training set.
.
related work .
code search there is a large amount of work on code search .
for example mcmillan et al.
proposed a code search tool called portfolio that retrieves and visualizes relevant functions and their usages.
chan and cheng designed an approach to help users nd usages of apis given only simple text phrases.
lv et al.
proposed codehow a code search tool that incorporates an extended boolean model and api matching.
they rst nd relevant apis to a query by matching the query to api documentation.
then they improve code search performance by considering the apis which are relevant to the query in code retrieval.
as described in section deepapi di ers from code search techniques in that it does not rely on information retrieval techniques and can understand word sequences and query semantics.
.
mining api usage patterns instead of generating api sequences from natural language queries there is a number of techniques focusing ondelete removesave write load read 40454035302520figure a 2d projection of embeddings of queries using t sne mining api usage patterns .
api usage patterns are frequent api method call sequences.
xie et al.
proposed mapo which is one of the rst works on mining api patterns from code corpus.
mapo represents source code as call sequences and clusters them according to similarity heuristics such as method names.
it nally generates patterns by mining and ranking frequent sequences in each cluster.
up miner is an improvement of mapo which removes the redundancy among patterns by two rounds of clustering of the method call sequences.
by applying api usage pattern mining on large scale code search results these techniques can also return api usage sequences in response to user s natural language queries.
while the above techniques are useful for understanding the usage of an api they are insu cient for answering the question of which apis to use which is the aim of deepapi.
furthermore di erent from a frequent pattern mining approach deepapi constructs a neural language model to learn usage patterns.
.
from natural language to code a number of related techniques have been proposed to generate code snippets from natural language queries.
for example raghothaman et al.
proposed swim a code synthesis technique that translates user queries into the apis of interest using bing search logs and then synthesizes idiomatic code describing the use of these apis.
swim has a component that produces api sequences given user s natural language query.
our approach and swim di er in many aspects.
first swim generates bags of apis using statistical word alignment .
the word alignment model does not consider word embeddings and word sequences of natural language queries and has limitations in query understanding.
second to produce api sequences swim searches api sequences from the code repository using a bag of apis.
it does not consider the relative position of di erent apis.
fowkes and sutton build probabilistic models that jointly model short natural language utterances and source code snippets.
the main di erences between our approach and theirs are two fold.
first they use a bag of words model to represent natural language sentences which will not recognize word sequences.
second they use a traditional probabilistic model which is unable to recognize semantically related words.
.
deep learning for source code recently some researchers have explored the possibility of applying deep learning techniques to source code .
a typical application that leverages deep learning is to extract source code features .
for example mou et al.
proposed to learn vector representations of source code for deep learning tasks.
mou et al.
also proposed convolutional neural networks over tree structures for programming language processing.
deep learning has also been applied to code generation .
for example mou et al.
proposed to generate code from natural language user intentions using an rnn encoder decoder model.
their results show the feasibility of applying deep learning techniques to code generation from a highly homogeneous dataset simple programming assignments .
deep learning has also been applied to code completion .
for example white et al.
applied the rnn language model to source code les and showed its e ectiveness in predicting software tokens.
raychev et al.
proposed to apply the rnn language model to complete partial programs with holes.
in our work we explore the application of deep learning techniques to api learning.
.
conclusion in this paper we apply a deep learning approach rnn encoder decoder for generating api usage sequences for a given api related natural language query.
our empirical study has shown that the proposed approach is e ective in api sequence generation.
although deep learning has shown promise in other areas we are the rst to observe its e ectiveness in api learning.
the rnn encoder decoder based neural language model described in this paper may bene t other software engineering problems such as code search and bug localization.
in the future we will explore the applications of this model to these problems.
we will also investigate the synthesis of sample code from the generated api sequences.
an online demo of deepapi can be found on our website at .