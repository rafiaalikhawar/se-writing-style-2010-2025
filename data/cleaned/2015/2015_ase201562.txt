have we seen enough traces?
hila cohen and shahar maoz school of computer science tel aviv university israel abstract dynamic specification mining extracts candidate specifications from logs of execution traces.
existing algorithms differ in the kinds of traces they take as input and in thekinds of candidate specification they present as output.
onechallenge common to all approaches relates to the faithfulnessof the mining results how can we be confident that the extractedspecifications faithfully characterize the program we investigate?since producing and analyzing traces is costly how would weknow we have seen enough traces?
and how would we know wehave not wasted resources and seen too many of them?
in this paper we address these important questions by presenting a novel black box probabilistic framework based ona notion of log completeness and by applying it to three differentwell known specification mining algorithms from the literature k tails synoptic and mining of scenario based triggers andeffects.
extensive evaluation over models taken from differentsources shows the soundness generalizability and usefulness ofthe framework and its contribution to the state of the art indynamic specification mining.
i. i ntroduction much literature has been published on dynamic specification mining which extracts candidate specifications from logs of program execution traces.
different approaches suggestdifferent algorithms which differ in the kinds of traces theytake as input and in the kinds of candidate specification theypresent as output in terms of content expressive power andformat .
example approaches include .
one challenge common to all approaches relates to the faithfulness of the mining results how can we be confidentthat the extracted specifications faithfully characterize theprogram we investigate?
as the mined specifications may beused for comprehension test generation and verification theirfaithfulness to the program we investigate is important.
y et producing and analyzing traces is costly so how would weknow we have seen enough of them?
and how would weknow we have not wasted resources and seen too many ofthem?
in this paper we address these important questions by presenting a novel black box probabilistic framework basedon a notion of log completeness.
we consider logs of executiontraces extracted from a running system under investigation.intuitively a log is complete with regard to a specific systemand a mining algorithm if adding any new system trace to thelog will not change the output of the algorithm.
in dynamicspecification mining the system and its full set of systemtraces is unknown.
therefore given a log of system traces we estimate the probability that the log is complete.
we saythat this estimation is the log s confidence.a log s confidence may be practically used as follows.
if not many traces are available one can compute the confidenceof the available log in order to estimate the expected faith fulness of the mining results.
a low confidence of say .
hints that the mining results may be far off from characterizingthe behavior of the system under investigation.
a very highconfidence of say .
hints that the mining results areprobably very close to correctly characterize the behavior ofthe system under investigation.
if producing and analyzingmore traces is possible but costly one can set a high confidencethreshold of say .
and stop adding new traces when thethreshold is reached.
we apply the new framework to three different well known dynamic specification mining algorithms from the literature k tails synoptic and mining of scenario based triggersand effects .
inspired by invarimint we represent eachalgorithm using a set of log properties.
for k tails we usea property describing the existence of possible sequences oflength k in the log.
for synoptic we use four different prop erties corresponding to the k tails property with k and to the three temporal invariant properties used by the synopticalgorithm.
for triggers and effects we use a single three valuedproperty representing the possible relation between the triggerand all of the possible effects or vice versa .
the frameworkassumes that mining randomly and independently samplestraces from the log.
for all three algorithms we compute theconfidence of a set of traces by estimating the probability thatit manifests the complete properties that any log of the systemunder investigation can manifest.
each log property requires adifferent probabilistic estimation.
an interesting feature of our notion of completeness is that it is relative to a system under investigation and a specificmining algorithm a log may be complete with regard to onealgorithm and incomplete with regard to another.
y et comput ing a log s confidence with regard to a specific algorithm doesnot require running the specification mining algorithm itself.
an important feature of our notion of confidence is its nonmonotonicity adding traces to a log does not guarantee anincrease in confidence and may even decrease it still a log sconfidence doesn t depend on the order of traces in it .
wediscuss this apparently counter intuitive feature in sect.
vii.
finally we present an extensive evaluation of our work including the results of experiments with models of real world systems taken from publicly available previously pub lished works.
the results show that for all three algorithms theprobability that a log is complete can be estimated efficientlyand be effectively applied with high reliability to improvethe use of the dynamic specification mining algorithm and theconfidence one may have in its results.
30th ieee acm international conference on automated software engineering .
ieee in recent preliminary work ase new ideas track we have presented a notion of confidence computation for ktails termed k confidence with preliminary evaluation of itseffectiveness.
our present paper extends this previous worksignificantly and makes the following contributions the presentation of a general framework for log con fidence and its application beyond k tails to two ad ditional well known specification mining algorithms an extensive evaluation over real world models which provides strong evidence for the correctness andeffectiveness of the confidence computations an implementation available for reproduction and ex tension for additional specification mining algorithms.
sect.
ii presents examples for the use of log confidence for synoptic and for mining triggers and effects.
sect.
iii presentsthe formal foundations of the log completeness frameworkand sect.
iv presents its application to the three dynamicspecification mining algorithms.
sect.
v presents an exampleconfidence computation.
sect.
vi presents the evaluation sect.
vii discusses design decisions and limitations sect.
viiidiscusses related work and sect.
ix concludes.
ii.
e xamples we use small examples to demonstrate the usage of log confidence.
all traces and models discussed in the examplesbelow are available in .
the presentation of the examplesis semi formal for illustrative purposes.
a. example i in the authors use an example of a shopping cart to demonstrate how synoptic is able to reveal a bug where the user can use an invalid coupon to reduce the price.
to revealthis bug the problematic behavior must appear in the traces.
consider an engineer having a log of traces of the shopping cart system adapted from the example traces of .fig.
shows the model suggested by synoptic for this log thedashed transition invalid coupon toreduce price is not part of the model suggested by synoptic for this traces log .
the model does not include the bug so at this stage theuser may wrongly conclude that the shopping cart system hasno bugs.
how would she know if more traces are needed?
indeed adding more traces and feeding the resulting log of traces to synoptic results in a revised model as shownin fig.
including the dashed transition which reveals theinvalid coupon bug.
our tool computes a confidence of .
to the first log and of .
to the second log.
this confidence is essentiallyan estimation for the probability that the log is complete computed solely based on the traces themselves.
if the userhas set a minimum confidence threshold of .
which is avery safe threshold according to our evaluation she would nothave stopped analyzing traces too soon i.e.
before finding thebug.
should she continue to analyze more traces?
given the computed confidence of .
the probability that additionaltraces will reveal new behaviors is very small.
indeed in ourexample an extension of the log with additional traces all fig.
shopping cart model as mined by synoptic from thelog of traces without the dashed transition and from thelog of traces including the dashed transition new traces not duplicates of any of the traces seen before resulted in a slightly higher confidence of .
but in the same model as was suggested by synoptic for the traces.
thus by stopping the analysis when confidence reached .
theengineer saved the resources required in order to produce andanalyze the additional traces yet did not lose any information.
b. example ii in mining scenario based triggers and effects the engineer provides a trigger scenario a sequence of events as input and receives a set of candidate effects sequences ofevents as output with the following semantics whenever thetrigger scenario occurs in the traces in the specified eventsorder but possibly with other events interleaved eventuallyeach of the candidate effects occurs too again in the specifiedevents order but possibly with other events interleaved .
in the authors use an example set of execution traces from crossftp an open source ftp server .
the full data set available from contains traces with an averagetrace length of over an alphabet of events.
consider an engineer investigating the behavior of the crossftp server looking for scenario based effects to thetrigger consisting of a call to open a new connection and acall to transfer data used in crossftp both in the context ofupload and in the context of download connectionmanagerimpl.newconnection ... requesthandler.transfer ... .
when the engineer executed the mining with this trigger on a sub log of randomly selected traces from the fulllog more than unique candidate effects were reported.
for 94example one of these candidate effects was the scenario connectionmanagerimpl.closeconnection ... connectionmanagerimpl.dispose ... .
however none of these candidate effects truly characterizes the behavior of the crossftp .
when executing mining oftriggers and effects with the same trigger on the full log of 54traces no effect is reported since a few traces include multiplecalls to the transfer ... method with no occurrence of an effect between them.
indeed in crossftp no scenarioexists which always occurs in this log after the given trigger.
our tool computes a confidence of .
to the traces log and a confidence of .
to the traces log.
again this confidence is essentially an estimation for the probabilitythat the log is complete computed solely based on the tracesthemselves.
indeed mining scenario based triggers and effectsfrom the log with the low confidence produced results thatdo not characterize the true behavior of the system underinvestigation.
in other words the results of mining from a logthat has a low confidence should not be trusted.
c. running example we take the java.util.zip.zipoutputstream model from as a small running example for this paper.
the model consists of states over an alphabet of events.
weconsider a randomly generated log for this model consistingof traces.
see fig.
.
iii.
l og completeness framework a. basic definitions a trace over an alphabet is a finite word angbracketlefte1 e2 ... e m angbracketrightwheree1 ... e m .f o rj 1we use j to denote the jth element in .
letmbe a model over an alphabet .w eu s et m to denote all traces accepted by the model m. a log of m l t m is a finite set of traces from t m .
we denote the set of all possible logs of mbyl m .
the basic definition underlying log completeness is the log property lp consisting of a pair of functions.
the first function lptr maps every trace and a sequence of events esto a value in some domain dtr.
intuitively lptrassigns a value to the relation between the property lp and the trace.
the second function lplog maps subsets of dtrtodlog i t aggregates the trace level results to the log level.
example .
ifdtr dlog lptrmay be used to represent whether a property holds in the trace and lplog may represent whether it holds in an entire log.
an example property is an invariant of the form a always precedes b .
definition log property .
a log property lp angbracketleftlptr lp log angbracketrightis a pair of functions lptr i dtrandlplog p dtr dlog.
we say that a log l l m is complete with regard to a log property lp if the information one may extract about the property from the log lis equal to the information one may extract about it from any log that includes l and thus specifically from all the traces in t m .
formally definition lp log completeness .
al o gl l m is complete with regard to a log property lp angbracketleftlptr lp log angbracketright iff l prime l m s.t.l l prime es i lplog lp tr es l lplog lp tr es l prime .
we now lift the completeness definition from properties to algorithms.
a specification mining algorithm aaccepts a log l l m as input and outputs a candidate model a l m prime.
we represent an algorithm aby a set of log properties lp a lp1 lp2 ... lpk .
we say that a log lis complete with regard to an algorithm aifflis complete with regard to each of the log properties of a. formally definition a log completeness .
a logl l m is complete with regard to an algorithm aiff lp lp a l is complete with regard to lp.
note that to make the framework useful one should define the set of log properties lp a such that if l l m is complete with regard to a adding any trace t m tol will not affect the candidate model acomputes for l indeed this is part of our evaluation see sect.
vi b .
also note that logcompleteness is defined relative to an algorithm specificallya set of log properties .
the same log may be complete withregard to one algorithm and incomplete with regard to anotheralgorithm.
b. estimating log completeness given an algorithm aand a log l l m our goal is to estimate the probability that lis complete with regard to a i.e.
to compute l s confidence.
to do this we compute l s confidence with regard to the lpsi nlp a and take the minimum intuitively choosing the minimum is a conservative choice .
for each lp lp a we define a random variable y lp over t m which maps a trace to its property results.
formally ylp ylp lptr es .
example .
we denote the invariant property a always precedes b mentioned above by lp .
for the trace tr2 of our running example in fig.
and the sequences angbracketleftinit closeentry angbracketrightand angbracketleftputnextentry closeentry angbracketright w e havey lp tr2 and ylp tr2 angbracketleftputnextentry closeentry angbracketright because the first holds in the trace while the second does not.
fory d i tr we denote the probability that ylp equals yby lp y lp y p .
example .
to continue our example above where dtr dlog for the invariant property a always precedes b we have i and soycan be viewed as a dimensional array a matrix over .
in our running example the alphabet size is and so for this property we will use a 5matrix see later in table i .
95tr1 init closeentry close close tr2 init closeentry putnextentry closeentry putnextentry closeentry close close tr3 init putnextentry write putnextentry putnextentry closeentry close tr4 init putnextentry write close tr5 init close tr6 init putnextentry write close close tr7 init closeentry putnextentry write closeentry closeentry putnextentry close fig.
the running example model of java.util.zip.zipoutputstream from and randomly generated traces used to demonstrate confidence computation.
lp y is the probability that in a random trace from t m we get the values of lp as they are encoded in y. it is determined by mbutmis considered unknown.
we consider all traces from a log lto be samples from ylp.
we assume that traces are randomly and independently chosen from t m .i f l nwe denote them byylp1 ylp2 ... y lp n .
these are independent identically distributed random variables versions of ylp.
another random variable we define is yn lp which aggregates all these samples to the property values for the entire log yn lp yn lp lplog ylp i i n we now define the true but unknown log property values flp in order to later compute the probability that yn lp is equal to it flp flp lplog y y .
example .
for the running example model in fig.
the log property always precedes lp and the sequence angbracketleftputnextentry closeentry angbracketright since there are traces in t m where the invariant is not violated e.g.
tr3 and others where it is violated e.g.
tr2 the property does not hold in the log and soflp angbracketleftputnextentry closeentry angbracketright .
note that mdetermines flp .
we can now write def.
using the above notation as follows a log lis complete with regard to an algorithm aiff lp lp a .yn lp flp .
recall that our goal is to estimate the probability that lis complete with regard to a. using the notation defined above what we are looking to estimate is p yn lp flp .
the above represents l s confidence with regard to a single log property lp.
we define the confidence of a log lwith regard to an algorithm a to be the minimum of l s confidence with regard to all lpsi nlp a .
formally definition a log confidence .
the confidence of a log l l m with regard to an algorithm ais min p yn lp flp lp lp a .
iv .
l og completeness applied we now present the application of the framework to three different previously published dynamic specification mining algorithms k tails synoptic and mining of scenario based triggers and effects .
for each algorithm we definethe relevant log properties lp a and show the estimation of p y n lp flp for eachlp lp a .a.
k tails k tails is a dynamic specification mining algorithm based on merging states whose future kstates are identical.
it has been used in several variants in many recent works e.g.
.
below we reformulate thecomputations of using the framework defined above.
log properties to apply the log completeness framework to k tails we define a single log property lp k for the existential property k directly follows .
roughly theproperty k directly follows for a sequence of events es angbracketlefte e2 ... e k angbracketrightholds in a trace iff the sequence appears somewhere in the trace.
the intuition behind the use of this property is as follows.
consider a model produced by k tails for a log and a newtrace whose all subtraces of length k appear in the produced model.
applying k tails to a new log that consists of theoriginal log and the new trace produces the same model.
theproof for this claim albeit using a different formulation canbe found in .
the definitions of lp k tr andlp k logbelow follow the semantics of k directly follows as an existential property.formally we use d tr dlog and define lp ak tails lp k where lp k tr angbracketlefte1 e2 ... e k angbracketright braceleftbigg1 j logicalandtext m k j m em 0otherwise lp k log s braceleftbigg s 0otherwise computing log confidence the probability that an existential property does not hold in t m but appears in one of the traces is zero.
thus we only need to consider the othercase where the sequence of length kdoes not appear in the traces y n but is possible in the model f .
formally p p f esp f p f braceleftbigg p f f braceleftbigg producttext i np f f we useqesto denote the probability that the existential property for esholds on a random trace from t m i.e.
that 1since they are fixed we omit the specific lp and from the formulas in this section 96the sequence angbracketlefte1 e2 ... e k angbracketrightappears somewhere in the trace.
whenf we have qes 0and producttext i np qes n. sinceqesis unknown we estimate it using the average of thenrandom variables yi qes n summationdisplay i 1yi n and so overall we have p summationdisplay es qes qes n. b. synoptic synoptic is a dynamic specification mining algorithm based on three temporal invariants of length and a process of refinement coarsening using counter example guided abs traction refinement cegar and a variant of k tails.
log properties to apply the framework to synoptic we define four log properties for three invariant propertiesand for one existential property.
the three invariant propertiesare always followed by denoted always precedes denoted and never followed by denoted notarrowright .
the existential property is directly follows denoted .
formally lp asynoptic lp lp lp notarrowright lp and all four synoptic s log properties use dtr dlog .
the intuition behind the use of these properties is as follows.
first the three invariants are mined by synopticand then used during the refinement process the final modelproduced by synoptic is guaranteed to satisfy all three in variants.
second the existential directly follows propertycorresponds to the initial step in the synoptic algorithm whichbuilds a permissive model that accepts all traces.
formalcorrectness proof for the selection of these properties appearin .
the definition of lp angbracketleftlp tr lp log angbracketrightis based on its semantics.
lp trtakes two events as input and outputs iff every occurrence of the first is followed by an occurrenceof the second.
lp log s takes the result of applying lp tr to all traces and outputs iff all traces satisfy the invariant.formally lp tr angbracketlefte1 e2 angbracketright braceleftbigg k k e1 m k m e2 0otherwise lp log s braceleftbigg s 0otherwise the definition of the two other invariants is similar lp tr takes two events as input and outputs iff every occurrenceof the second is preceded by an occurrence of the first lp notarrowright tr takes two events as input and outputs iff no occurrence ofthe first is followed by an occurrence of the second.
formally lp tr angbracketlefte1 e2 angbracketright braceleftbigg k k e2 m k m e1 0otherwise lp notarrowright tr angbracketlefte1 e2 angbracketright braceleftbigg k k e1 m k m e2 0otherwise all three log properties are invariants so they have the samelplogfunction that is lp log lp log lp notarrowright log.finally the log property lp relating to the existential property directly follows is a special case of the k directlyfollows property defined above for k tails see sect.
iv a1 fork .
computing log confidence we estimate the probability of log completeness with regard to synoptic by taking theminimum of the probabilities of log completeness for eachproperty alone.
the three invariant properties .w eu s ees to denote the sequence angbracketlefte e2 angbracketright.
for the three invariant properties the computation is the same.
the probability that the invariant holds in t m but is violated in one of the traces is zero.
thus we only need to consider the other case where the invariant holds in all tracesthat we have seen y n but not in t m f .
formally p p f esp f p f braceleftbigg p f f braceleftbigg producttext i np f f we useqesto denote the probability that the invariant holds foreson a random trace from t m .
whenf we haveqes 1and producttext i np qn es.
sinceqesis unknown we estimate it using the average of thenrandom variables yi qes n summationdisplay i 1yi n and overall for each of the three invariant properties we have p summationdisplay es qes qes n. the existential property.
computing confidence for the exis tential property directly follows is again a special case ofthe computation of k directly follows we have shown abovein sect.
iv a2 so we do not repeat it here.
finally we consider the log s confidence with regard to the synoptic algorithm as a whole to be the minimum of the fourprobabilities of the log completeness properties.
c. mining scenario based triggers effects mining scenario based triggers and effects mining t e was presented in .
roughly given a trigger scenario a sequence of events the miner looks for all effect scenarios sequencesof events such that for each whenever the trigger occurs ina trace in the specified events order but possibly with otherevents interleaved eventually the effect occurs in this trace in the specified events order but possibly with other events interleaved .
below we use the notation from .
given a trigger scenario tgand an effect scenario es pos tg es is the set of all positive witnesses of the combined scenario tg es i.e.
all cases where an occurrence of tgis eventually followed by an occurrence of es andneg tg es is the set of all negative witnesses of the combined scenariotg es i.e.
all cases where an occurrence of tgis not followed by an occurrence of es.
formal definitions appear in .
we consider the case where the input consists of a trigger and the miner looks for effects.
the other case is symmetric.
log properties we define a single log property corresponding to the following given a trigger and a candidateeffect is it true that whenever the trigger occurs eventuallythe effect occurs too?
we denote this trigger effect property byt e lp a trigger effect lpt e .
the intuition behind the use of this property is that it is equivalent to the property which the algorithm looks for log completeness with regard to this property entails that themining algorithm results are indeed correct and complete withregard to the true model.
the definition of lp t e angbracketleftlpt e tr lpt e log angbracketrightis based on its semantics.
lpt e tr takes a trace and a candidate effect as input and outputs true iff the trace has at least one positivewitness and no negative witnesses for the combined triggereffect false iff the trace has at least one negative witnessfor the combined trigger effect and unknown if the triggernever occurs in the trace.
the domains for the log property lp t e are three valued dtr dlog .
lpt e log s takes the result of applying lpt e tr to all traces and outputs iff it returned for at least one trace and returned for no trace.
formally lpt e tr es braceleftbigg1 pos tg es neg tg es neg tg es 1otherwise lpt e log s braceleftbigg11 s s s 1otherwise s computing log confidence we useesto denote the sequence angbracketlefte1 e2 ... angbracketright the length of the effect we are looking for is unbounded.
the computation considers the possible cases where the log and the model do not agree.
first the case where the triggerdoes not occur in the log y n although it is possible int m f negationslash .
second the case where the trigger occurs in the log with no negative witnesses yn although the combined trigger effect is not true t m f .
other cases are impossible e.g.
the case where we seea negative witness in the log although the combined triggereffect is true in t m .
formally p y n f p negationslash f parenleftbig esp f negationslash esp f parenrightbig we compute each of the two probabilities above as follows.
we useqtg esandqtgto denote the probability that a randomtrace from t m has only positive witnesses of tg esandtg respectively.
for the first probability we have p f negationslash braceleftbigg p f negationslash otherwise braceleftbigg p qtg otherwise whenf negationslash 1we haveqtg 0becausetgis possible in the model.
in this case by definition of lpt e log s w eh a v e the probability that the trigger will not occur in any of the n traces p qtg n. for the second probability we have p f braceleftbigg p f otherwise whenf we haveqtg negationslash qtg esbecausetg esdoes not hold in the model.
in this case by definition of lpt e log s we have to consider the case where in the ntraces we have seen the trigger at least once and we have not seen any negativewitnesses p y n qtg n qtg qtg es n finally since qtgandqtg esare unknown we estimate them using the nrandom variables yi qtg summationdisplay yi n qtg es summationdisplay yi n and so overall we have p parenleftbig qtg qtg n qtg negationslash qtg es qtg n qtg qtg es n parenrightbig .
d. implementation we have implemented the computation of log confidence for the three dynamic specification algorithms.
for each ofthe three algorithms the implementation gets as input a log a set of traces and algorithm specific parameters none forsynoptic kfor k tails and the trigger or effect sequence for scenario based trigger and effect .
note that the confidencecomputation does not need to run the mining algorithm.
given a log land an algorithm a computing the log s confidence starts with separately computing its confidence foreach of the log properties in lp a .
for each log property lp for each trace l and for each sequence es w e compute lp tr es .
the computed values are used as input for the computation of the log s confidence with regard tolp.
the reported log s confidence of lwith regard to a i s the minimum of all the confidences for the log properties.
98event close closeentry init putnextentry write close .
.
.
.
.
.
.
.
closeentry .
.
.
.
.
.
.
.
init .
.
.
.
.
.
.
.
putnextentry .
.
.
.
.
.
.
.
write .
.
.
.
.
.
.
.
table i example log confidence computation with regard to the invariant property always precedes lp for the log of traces shown in fig.
.
the computed confidence for this property is .
.
see sect.
v. v. e xample computa tion we demonstrate log confidence computation on our running example model and randomly generated traces from this model shown in fig.
.
for these traces table i shows thecomputation of log confidence with regard to the invariantproperty always precedes lp as used in the confidence computation for synoptic see sect.
iv b .
the table cell i j corresponds to the invariant i always precedes j e.g.
the table cell in the row of closeentry and column of close corresponds to the property closeentry always precedes close .
the value in table cell i j is q angbracketlefti j angbracketrightfrom equ.
.
for example the value qcloseentry close .57is the probability to have an instance ofcloseentry close with always precedes in a random trace given the log that we have the invariant holds in of the7 traces tr tr2 tr3 andtr7 so4 .57is the probability thatcloseentry always precedes close .
since the log has traces the negative contribution to the accumulatingconfidence for this property is .
.
see equ.
that s the probability that in a random log of size thisinvariant will hold .
the overall confidence for the always precedes property is computed by assigning all the numbers from the table to the q ess in equ.
we omit the zeros from the formula .
.
.
.
.
.
.
.
.
vi.
e v alua tion the research questions guiding our evaluation are rq1 is the representation of the three specification mining algorithms using lps sound?
rq2 can log confidence be efficiently computed and serve as an effective proxy for true log completeness?
a. models used in evaluation in the evaluation we used finite state automaton models taken from publicly available previously published works andreports and .
themodels varied in size and complexity the alphabet size rangedfrom to mean .
the number of states ranged from5 to mean .
and the number of transitions rangedfrom to mean .
.
all logs models and implementation code described in this paper are available for inspection and reproduction togetherwith documentation from .b.
rq1 soundness of representation methodology to evaluate the soundness of the representation of the three specification mining algorithms us inglps we use two definitions lp equivalence and aequivalence.
first roughly given a log property lp two logs are lpequivalent if their results agree on all sequences.
formally definition lp equivalence .
for a log property lp t w o logsl l2arelp equivalent iff es i lplog lp tr es l1 lplog lp tr es l2 .
we trivially lift the above definition to a set of lps that is from each lp alone to the set lp a .
second roughly given a specification mining algorithm a two logs are a equivalent if they agree on the result of the algorithm.
formally definition a equivalence .
for a specification mining algorithma two logs l l2area equivalent iff a l1 a l2 .
finally we say that the lp representation of an algorithma lp a is sound iff lp a equivalence implies aequivalence.
experiment design for each model we used the following experiment protocol.
first we generated traces from the model using a trace generator.
second for each algorithm wefound the minimal sub log in some arbitrary order of traces which islp a equivalent to the entire log.
third we ran the specification mining algorithm aon the two logs and checked whether the output is the same.
for each of the models and for each specification mining algorithm k tails synoptic and mining t e we ranthe experiment three times.
in all experiments we used thetrace generator from with path coverage but high statecoverage for some of the models because the generator ran outof memory when computing path coverage for these models .
results in all executions i.e.
for all models and for all algorithms the model generated from the sub log was identical to the one generated from the entire log.
to answer we have strong evidence for the sound ness of the lps representation for all three algorithms.
c. rq2 effectiveness of log confidence methodology to evaluate the effectiveness of log confidence we use two key measures reliability and redundancy.
99for a fixed algorithm a we define the reliability of a log to be if the log is complete with regard to aand otherwise.
for a set of logs l a mean reliability close to hints that most of the logs are complete.
for a fixed algorithm a w e define the redundancy of a log to measure how close is it to its minimal prefix log which is complete assuming an arbitraryfixed order of traces .
for a set of logs l a mean redundancy close to and a low standard deviation hint that the logs donot include much redundant traces.
formally definition reliability .
for an algorithm a the reliability of a loglisrel l braceleftbigg 1lis complete with regard to a 0otherwise.
definition redundancy .
for an algorithm a g i v e nal o gl in a fixed arbitrary order let i min l be the minimal index of traces in lsuch that the set of traces 1 2 ... imin l is complete with regard to a. the redundancy of a log lis red l imin l l .
example .
recall the log and model of our running example shown in fig.
and the results of computing its confidence with regard to the always precedes property as shown intable i. this log s reliability with regard to this property isrel l .
since it reaches completeness for this property already after the 4th trace and we have traces its redundancywith regard to this property is red l .
.
note that to calculate reliability and redundancy as in the above example one must know the system from which thetraces were extracted so that she can calculate a true valuefor each property.
this is typically unknown in a real worldsetting but it is known in our controlled evaluation setting.
in order to answer we are interested in the performance of the confidence computation in the values of thereliability and their correlation with the confidence values andin the redundancy values across the models for each ofthe three algorithms.
experiment design for each model we used the following experiment protocol.
first we generated traces from themodel using a trace generator.
second we created an initial logby randomly selecting a minimal number of traces.
third forseveral fixed thresholds we iteratively computed the currentlog s confidence and added a trace to it adding traces to thecurrent log until we reached the fixed confidence threshold or we ran out of traces to add .
finally we computed thereliability and redundancy of the final log.
for each model and for each algorithm we repeated the above protocol times and computed the mean of reliabilityand redundancy for the sets of logs.
in all experiments we used the trace generator of with path coverage high state coverage for some of the modelsbecause the generator ran out of memory when computingpath coverage for them a minimal number of traces and aseries of fixed confidence thresholds from .
to .
i.e.
foreach threshold th we started with an initial log by randomly selecting traces and continued the addition of traces to thelog until the probability that it is complete was at least th or we ran out of traces to add .
we checked true completenessusing a model checker i.e.
by expressing the relevant log properties in temporal logic and verifying them against themodel.
we usedk for k tails and manually selected a trigger of length or for the triggers and effects algorithm.
results performance.
all experiments were executed on an ordinary laptop computer intel i7 cpu .0ghz 8gbram with windows bit os java .
.
bit.
for all models in all our experiments confidence computation neverexceeded milliseconds.
this shows that the log confidencecomputation for the three specification mining algorithms wedeal with is fast.
it is not surprising as the computation is bydefinition linear in the number of traces in the log.
reliability.
fig.
shows the reliability results across the models for increasing confidence thresholds for each of the three algorithms.
the boxplots show the median reliability the25th and 75th percentile with range for whiskers.
for all three algorithms the boxplots show that in general the reliability increases as the confidence threshold increases and the variance in reliability across the different modelsdecreases as the confidence threshold increases.
specifically when the confidence threshold is .
the reliability is veryhigh and its variance across the different models is very low.
the boxplots also show that the reliability is always greater or equal to the confidence threshold.
this is a result of theconservative nature of our confidence computation it is muchmore likely to underestimate completeness than to overestimateit.
it is also a result of our experiment design we stop addingtraces to the log once its confidence pass the given threshold i.e the actual confidence is higher than the threshold used andshown in the figure the lower the threshold the higher thepossible difference .
the spearman s rank correlation between confidence and reliability was .
p .
.
p .
and .
p .
for k tails synoptic and triggers and effects respectively.
these values are considered to expressstrong correlation .
a power analysis for thecorrelation tests shows that our sample size of n is much above the minimal size required with significance level .
power .
and our resulting correlation coefficients.
redundancy.
fig.
shows the redundancy results across the models for increasing confidence thresholds for each of thethree mining algorithms.
for all algorithms the boxplots showthat in general as expected the redundancy increases as theconfidence threshold increases.
when confidence threshold is.
the maximal redundancy is of about .
and the maximalmedian redundancy is about .
.
the worst case for the threealgorithms was reaching the .
threshold with a log that isabout times longer than its minimal complete sublog.
log sizes differed much between the different models and across the different confidence thresholds roughly rangingfrom to traces per log.
some models required manymore traces than others to reach high confidence across allthree algorithms .
the results for the individual models areavailable from .
we observe that the variance between the different models for both reliability and redundancy seems higher for miningt e than for the other two algorithms.
this may be viewed as g19 g17 g21 g19 g19 g17 g22 g24 g19 g17 g24 g19 g19 g17 g25 g24 g19 g17 g27 g19 g19 g17 g28 g24 g19 g17 g23 g19 g17 g25 g19 g17 g27 g20 g17 g19 g38 g82 g81 g73 g76 g71 g72 g81 g70 g72 g53 g72 g79 g76 g68 g69 g76 g79 g76 g87 g92 g78 g237 g55 g68 g76 g79 g86 g19 g17 g21 g19 g19 g17 g22 g24 g19 g17 g24 g19 g19 g17 g25 g24 g19 g17 g27 g19 g19 g17 g28 g24 g19 g17 g23 g19 g17 g24 g19 g17 g25 g19 g17 g26 g19 g17 g27 g19 g17 g28 g20 g17 g19 g38 g82 g81 g73 g76 g71 g72 g81 g70 g72 g53 g72 g79 g76 g68 g69 g76 g79 g76 g87 g92 g54 g92 g81 g82 g83 g87 g76 g70 g19 g17 g21 g19 g19 g17 g22 g24 g19 g17 g24 g19 g19 g17 g25 g24 g19 g17 g27 g19 g19 g17 g28 g24 g19 g17 g21 g19 g17 g23 g19 g17 g25 g19 g17 g27 g20 g17 g19 g38 g82 g81 g73 g76 g71 g72 g81 g70 g72 g53 g72 g79 g76 g68 g69 g76 g79 g76 g87 g92 g48 g76 g81 g76 g81 g74 g3 g87 g18 g72 fig.
reliability results for the three specification mining algorithms.
see sect.
vi c. g19 g17 g21 g19 g19 g17 g22 g24 g19 g17 g24 g19 g19 g17 g25 g24 g19 g17 g27 g19 g19 g17 g28 g24 g19 g17 g22 g24 g19 g17 g23 g19 g19 g17 g23 g24 g19 g17 g24 g19 g19 g17 g24 g24 g19 g17 g25 g19 g19 g17 g25 g24 g38 g82 g81 g73 g76 g71 g72 g81 g70 g72 g53 g72 g71 g88 g81 g71 g68 g81 g70 g92 g78 g237 g55 g68 g76 g79 g86 g19 g17 g21 g19 g19 g17 g22 g24 g19 g17 g24 g19 g19 g17 g25 g24 g19 g17 g27 g19 g19 g17 g28 g24 g19 g17 g22 g19 g17 g23 g19 g17 g24 g19 g17 g25 g19 g17 g26 g38 g82 g81 g73 g76 g71 g72 g81 g70 g72 g53 g72 g71 g88 g81 g71 g68 g81 g70 g92 g54 g92 g81 g82 g83 g87 g76 g70 g19 g17 g21 g19 g19 g17 g22 g24 g19 g17 g24 g19 g19 g17 g25 g24 g19 g17 g27 g19 g19 g17 g28 g24 g19 g17 g19 g19 g17 g20 g19 g17 g21 g19 g17 g22 g19 g17 g23 g19 g17 g24 g19 g17 g25 g19 g17 g26 g38 g82 g81 g73 g76 g71 g72 g81 g70 g72 g53 g72 g71 g88 g81 g71 g68 g81 g70 g92 g48 g76 g81 g76 g81 g74 g3 g87 g18 g72 fig.
redundancy results for the three specification mining algorithms.
see sect.
vi c. a weakness.
however the median values for mining t e are higher for reliability and lower for redundancy compared tothe other two algorithms which may be viewed as a strength.note though that the kind of candidate specification mined bymining t e is very different from the kind mined by the othertwo algorithms hence they are not comparable.
to answer we have strong evidence that logconfidence can be efficiently computed and is an effectiveproxy for true completeness for the three specificationmining algorithms.
d. threats to v alidity we discuss threats to the validity of our results.
first the selection of models in our evaluation may not represent typicalsystems.
to mitigate this we used publicly available modelstaken from previous works see sect.
vi a .
y et we do notknow if these are representative of real world systems.
second in our evaluation we used a publicly available trace generator with path coverage when the model wastoo complex for the trace generator to handle we used statecoverage .
it is possible that one may get different results ifa different trace generator or a different coverage criterion areused.
in a real world setting when the model is unknown codecoverage methods may be used.
third the selection and order of traces in the log affect thepoint where the analysis may reach the confidence thresholdand thus affect the point used to compute redundancy.
wemitigated this by using randomization in the selection of tracesand in the order in which they were analyzed and by repeatingall evaluation experiments times.
fourth we have evaluated the soundness of the lps empirically against specific implementations of the three algo rithms.
all have variants which may produce slightly differentoutputs e.g.
synoptic chooses the order in which invariantsare used in the cegar process arbitrarily.
thus when wewritea l in sect.
vi b we refer to a specific implementation only.
finally our work presents a general framework for log completeness and confidence but the evaluation is limited tothree algorithms.
one may get different results when the frame work is applied to other algorithms.
still the results providesome evidence for the generalizability of the framework.
vii.
d iscussion we now discuss some important features design decisions and several limitations of our present work.
an importantfeature of our log confidence computation is that it is notmonotonic but converges to when the size of the logapproaches infinity for all three algorithms .
on the one hand as traces are added to a log its confidence may increase ordecrease in the absence of additional information e.g.
aboutthe order in which traces are produced a new trace may 101introduce new information e.g.
invalidate an invariant reveal an e wk length sequence which leads us to revise our previous estimations.
thus confidence is not necessarily monotonic.still in contrast it is important to note that our notion of logcompleteness is monotonic i.e.
by definition any extension ofa complete log is complete.
on the other hand despite the nonmonotonicity the expected confidence converges to when thesize of the log approaches infinity for the three algorithms .for example for k tails we have lim n e summationdisplay es qes qes n .
thus as the size of the log grows the expected change in confidence that an additional trace may cause approaches zero.the proof for this claim can be found in .
in the presence of multiple lpsi nlp a we have chosen to define confidence as the minimum of confidences overalllps.
we consider this to be a preliminary conservative choice which in the tradeoff between high reliability and lowredundancy favors the former over the latter.
alternatively one may choose other less conservative yet perhaps morerobust aggregate functions e.g.
the harmonic mean or someweighted average in case some lps are considered more important than others.
we leave the investigation of thesealternatives per algorithm to future work.
an important assumption underlying our framework is that the traces are randomly and independently chosen from t m .
this assumption may not always hold e.g.
if traces depend onrunning tests that were generated according to some strategy.we note however that our work is meant to be used to evaluatethe confidence one may have in the results of applying miningalgorithms to logs of execution traces.
this should not beconfused with evaluating the quality of a test suite.
finally an apparent limitation relates to the size of the log.
for logs with only a few traces confidence results are verysensitive and fluctuate much so they are practically useless.in practice however this is typically not a problem becausereal world logs consist of many traces.
moreover as statedabove as the size of the log grows the expected fluctuationsapproach zero.
viii.
r ela ted work dynamic specification mining.
much literature deals with looking for candidate specifications in execution traces e.g.
.
the works differ in the kinds of tracesthey take as input and in the kinds of candidate specificationthey present as output.
in recent work beschastnikh et al.
have presented invarimint a framework for declarative specification of fsm inference dynamic log analysis algorithms.
our work maybe viewed as building on invarimint s presentation of modelinference algorithms using declarative properties as a key toits ability to define log completeness for k tails and synoptic.formally however we define properties in a different way.while invarimint uses parameterized fsm and evaluationfunctions to describe property types and applies compositionfunctions to combine them our framework describes propertiesusing the functions lp trandlplog which enable the computation of probabilities.
it may be possible to define our notionof log completeness on top of the invarimint framework.
weleave this for future work.
addressing completeness.
dallmeier et al.
consider dynamic specification mining and ask what makes us believe that we have seen sufficiently many executions?
while it seemsthat we ask a similar question our work is fundamentallydifferent.
in a partial set of traces is heuristically enrichedin order to explore previously unobserved aspects of theexecution space.
in contrast we consider a black box settingand provide a formal probabilistic measure to the notion of sufficiently many traces .
this allows engineers to assess thecompleteness of the traces they have relative to the dynamicspecification mining algorithm of their choice.
hee et al.
presented a probabilistic approach to log completeness of the algorithm which mines petri nets and is used in the field of process mining.
our work extendsthe work of hee et al.
significantly we present an algorithm independent framework for log completeness and demonstrateits application to three algorithms from the dynamic specifica tion mining literature k tails synoptic and mining t e. apart from our own recent preliminary work where we have presented a notion of confidence computation for k tails with preliminary evaluation to the best of our knowledge no other work has considered the question of estimating logcompleteness with regard to these three algorithms specificallyand with regard to dynamic specification mining in general.
ix.
c onclusion in this paper we addressed the question of analyzing too few or too many traces in the context of dynamic specificationmining by presenting a novel black box probabilistic frame work based on a notion of log completeness.
we applied theframework to three dynamic specification mining algorithmsfrom the literature.
our evaluation over models from theliterature provided evidence for the effectiveness and useful ness of our work.
given large logs as input whose analysis may require too much time and memory to the extent that make it impractical our work can be used to analyze only a fraction of the logyet to construct a candidate specification which is with highconfidence identical to the specification one could build fromthe complete log.
the work is part of our larger project oninvestigating ways to scale up specification mining and otherlog analysis algorithms in face of long and complex logs see .