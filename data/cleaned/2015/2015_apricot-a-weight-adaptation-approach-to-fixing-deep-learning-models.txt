apricot a weight adaptation approach to fixing deep learning models hao zhang department of computer science city university of hong kong hong kong hzhang339 c my.cityu.edu.hk w.k.
chan department of computer science city university of hong kong hong kong wkchan cityu.edu.hk abstract a deep learning dl model is inherently imprecise.
to address this problem existing techniques retrain a dl model over a larger training dataset or with the help of fault injected models or using the insight of failing test cases in a dl model.
in this paper we present apricot a novel weight adaptation approach to fixing dl models iteratively.
our key observation is that if the deep learning architecture of a dl model is trained over many different subsets of the original training dataset the weights in the resultant reduced dl model rdlm can provide insights on the adjustment direction and magnitude of the weights in the original dl model to handle the test cases that the original dl model misclassifies.
apricot generates a set of such reduced dl models from the original dl model.
in each iteration for each failing test case experienced by the input dl model idlm apricot adjusts each weight of this idlm toward the average weight of these rdlms correctly classifying the test case and or away from that of these rdlms misclassifying the same test case followed by training the weight adjusted idlm over the original training dataset to generate a new idlm for the next iteration.
the experiment using five state of the art dl models shows that apricot can increase the test accuracy of these models by .
.
with an average of .
.
the experiment also reveals the complementary nature of these rdlms in apricot.
keywords deep neural networks optimization model evolution debugging model fixing model repair i. introduction deep learning dl systems have found successful applications in many areas such as natural language processing computer vision data processing and computer games to make non trivial decisions.
their deep learning model s referred to as dlm s often deliver higher accuracy than the prior state of thearts that were invented and significantly improved after years of research investigation.
however these models are also inherently imprecise.
using them in for example controlling driverless cars or making decisions in surgeries may incur significant threats.
making them more accurate is essential.
a dlm is a deep learning network dnn initialized with a set of weights for the connection between its neurons where such weights are obtained from a training process.
thus by pairing the same dnn with different sets of weights called weight matrices the corresponding dlms may exhibit different classification behaviors.
to train a dlm one needs a training dataset which is a set of inputs referred to as test cases .
each test case is labeled with an expected classification result or expected result for short such as the output class of the target dlm that should receive the highest likelihood value.
running a dlm to classify a test case produces a classification result which is referred to as the actual result .
if a dlm classifies an input inconsistent to its expected result a misclassification is identified.
the input is said to be a failing test case and we also say that the dlm fails on this test case incorrectly classifies the test case or experiences a failure .
if there is no misclassification detected the test case is a passing test case and the dml correctly classifies it.
the accuracy of a dlm over a dataset is the percentage of test cases that the dlm correctly classifies them.
for a training dataset it is called training accuracy and for a testing dataset it is called test accuracy .
if a dlm is not accurate enough it should be fixed .
one category of strategies is to expand training datasets with additional test cases.
collecting these test cases such as via automated generations of adversarial examples or from other sources need additional costs and time.
besides these test cases should be labeled with expected results.
take the huge imagenet dataset for example.
many state of the art dlms such as vgg16 and resnet can achieve or higher in accuracy.
further expanding the dataset with the aim of observable increase in accuracy of such dlms is challenging.
another category of strategies is to further optimize a dlm with the original training dataset by for example changing parameters progressively exploring different weight assignments producing variants of the dnn underlying the dlm or a mix of them to generate evolved dlms before training them.
a common characteristic of these strategies is to generate a set of dlm variants often through evolutionary algorithms in each iteration and these dlm variants are trained with the original training dataset.
these strategies also do not use the expected results of the training inputs in generating these dlms.
the third category of strategies is to optimize a dlm with the original training dataset but unlike the category stated in the paragraph above without using multiple dlm variants at each iteration in their optimization processes.
for instance mode identifies a hidden layer where features contained in its neurons are most representative for exposing erroneous behaviors of dlm.
layers from the input layer to this identified layer are reconstructed to form a feature model and such a feature model can provide guidance on selecting inputs for retraining the dlm.
regularization techniques this research is supported in part by the grf of hksar research grants council project nos.
and the hksar itf project no.
its the cityu mf ext project no.
the cityu srg project nos.
and and the cityu sgs conference grant.
correspondence author.
34th ieee acm international conference on automated software engineering ase .
ieee authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
make a dlm s weight matrices sparser to reduce the impacts of unimportant weights on the classification results.
these techniques typically make a coarse adjustment by adding a regularization term e.g.
lp norm to the loss function in the training process of the dlm.
intuitively many ill trained weights are small in value but not all weights with small values are ill trained ones.
fixing a dlm at a coarse level is challenging to fix the problem in selected few and unknown ill trained weights in the dlm.
in this work we present apricot a novel weight adjustment approach to fixing deep learning models.
apricot is built on top of two intuitions as the number of inputs in a training dataset t0 increases in general training a dl model tends to become more difficult for the resultant dl model to retain a large proportion of its weights well trained to capture all essential features in t0.
let us consider a scenario.
suppose that there is a pair of dlms denoted as d0 and dsub respectively where their dnns and the training processes are identical except that d0 and dsub are trained with t0 and a subset s0 of t0 respectively.
further suppose that a test case x in s0 is classified correctly and incorrectly by dsub and d0 respectively.
an intuition for to classify x correctly is that is trained on a smaller dataset s which makes to probabilistically retain some features essential in classifying x correctly which has unfortunately lost them by a large extent in its training process and thus x represents a failing test case .
the weight assignments for dsub likely capture insights on the direction and magnitude to adjust the weight matrices of d0 to make d0 more likely to correctly classify inputs similar to x. for ease of our reference we refer to such a dsub as a reduced deep learning model rdlm .
one rdlm may not capture the essential features to classify a particular test case correctly.
if there is a set of rdlms such that on average each rdlm is more likely to classify a test case correctly than the otherwise then intuitively the central tendency of this set of rdlms is also more likely to classify the test case correctly.
given a pair of dlm d0 and a training dataset t0 apricot first generates a set of rdlms each training with a random subset of t0.
it then goes into an iterative process with d0 as the input model denoted as idlm d1 of the first iteration.
at the k th iteration for each failing test case x of the idlm dk apricot divides the set of rdlms into two partitions denoted as incorrectsubmodels k x and correctsubmodels k x where each rdlm in these two partitions classifies x incorrectly and correctly respectively.
then for each weight assignment w of dk apricot takes the mean of the corresponding weight assignments of the dlms in incorrectsubmodels k x and correctsubmodels k x and combines these two mean values into a single value.
it then adjusts w of dk accordingly.
apricot can be configured to use either both average values or only one of them.
next it trains the adjusted dk with t0 to produce the idlm dk for the k th iteration.
the output of the above procedure is a dlm with repaired weights.
a clear merit of apricot is that it only changes the weights of a dlm and needs fewer epochs to train dlm compared to original training process applied on dlm.
we have evaluated apricot with five dl models over the cifar dataset.
the empirical results show that for the strategy using the mean value of correctly classified rdlms called strategy apricot increases the test accuracy on three cnn models by .
.
with an average of .
and on two resnet models by .
.
with an average of .
.
by using both correctly and incorrectly classified rdlms called strategy apricot achieves the highest increase in test accuracy on four out of five models by .
.
with an average of .
.
by combining the results of all three strategies initialized with apricot an average improvement of .
across all models is obtained and the average maximum gain is .
.
apricot is fully automated.
it can be initialized with different weight adjustment strategies and is applicable to other kinds of dl models.
in view the present result we believe that apricot delivers a promising result and represents a feasible direction to produce dlms with repaired weights.
the main contribution of this paper is threefold.
this paper presents apricot.
apricot does not need any additional inputs.
it connects the original dlm and a set of rdlms via failing test cases which provides a guidance to repair ill trained weights of the original dlm which sets it apart from regularization and other debugging work.
it does not generate any fault based dlms which makes it different from fault based testing debugging or repair techniques.
this paper presents an evaluation of apricot which shows that apricot is viable to improve model accuracy.
this work demonstrates that using multiple rdlms with failing test cases of the original dlm can provide interesting insights for fixing the original dlm by exploring the connections among all these dlms.
the organization of the remaining sections is as follows.
section ii revisits the background.
section iii presents apricot in detail followed by its evaluation in section iv.
section v discusses related works.
we conclude this work in section vi.
ii.
background a. deep neural networks dnns a typical deep neural network dnn contains a set of layers e.g.
an input layer an output layer and multiple hidden layers and each layer contains a set of neurons.
neurons of adjacent layers are connected.
a neuron is a function that receives one or more inputs from its incoming connections.
each such connection carries a value called weight.
the neuron sums these weighted inputs possibly with some bias constant or regularization term to compute a weighted sum and passes this sum to an activation function usually has a non linear shape to produce an output representing whether there is an input to its output connections which serve as incoming connection to other neurons for example .
formally a deep neural network is a triple tuple d l t 2 where l li i ... k is a set of k layers where l1 is called the input layer and lk is called the output layer.
other layers are called hidden layers.
each layer li contains ni neurons.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
t l l is the set of connections between two layers representing the edges between neurons of these two layers.
each connection is labeled with a specific value called weight and the weights of all the connections between a pair of layers in t forms a weight matrix .
i i ... m is a set of activation functions .
in many configurations neurons belonging to the same layer have the same activation function.
if a deep neural network is initialized with a set of weight matrices it is called a deep learning model dlm .
assigning a weight with a particular value is called a weight assignment .
to obtain the set of weight matrices for a dlm we may train the dlm over a training dataset.
the involved training process may directly train the dlm over the training dataset or firstly divide the training dataset into multiple subsets where each such subset is called a batch followed by training the dlm over a sequence of these batches.
on training a dlm over a dataset or a batch it often requires iterating many times and each such iteration is called an epoch .
however the presences of ill trained weights in a dlm may lead the dlm to behave erroneously.
apart from the limitation of the data quality of a given training dataset and whether the dlm is over or under fitted through its training process a popular belief of incurring ill trained weights in a dlm is that some inputs in the training dataset may conflict with each other i.e.
the updating directions of parameters i.e.
weights between two inputs or two batches of them may be opposite.
the output of the hidden layers of a dlm can be regarded as an abstract representation of what the dlm has learnt.
b. ill trained weights in dlm and repair in the literature dlm bugs can be classified into two kinds structural bugs and training bugs.
structural bug refers to the structure including the type of layers the connections between layers the types and allocations of activation function of the dlm being not well designed.
fixing this type of bugs automatically is slow because apart from making a candidate dlm sufficiently trained and tested the number of candidates is very large making the search space much larger than fixing training bugs.
training bug refers to some weights in the weight matrices of a dlm being not well trained due to insufficient training process or bias in the training dataset.
we refer to these weights as ill trained weights in this paper.
it is challenging to isolate the impact of a weight or a set of them on the performance e.g.
accuracy of a dlm.
precisely identifying ill trained weights is still unreachable yet.
a related approach to addressing the problem of ill trained weights is to modify the weights in some weight matrices through retraining directly.
retraining a dlm with a different dataset such as adding more inputs to the original training dataset or using a different set of weight matrices for the initialization of the dlm before retraining will produce a new set of weight matrices.
adding more inputs to a training dataset is widely considered as an effective and most popular approach to repairing ill trained weights.
nonetheless using more inputs for retraining is laborious in data collection and labeling and finding sufficiently more inputs may be impractical in many cases.
it is interesting to develop effective techniques to utilize the existing datasets to adjust the weight matrices to alleviate the problem of ill trained weights.
as we have summarized in section i there are two categories of work in this area.
apricot is also in this direction but different from them.
iii.
apricot in this section we present apricot.
a. overview apricot is a novel weight adaptation approach to fixing deep learning models.
we first recall from section i that given a dlm d0 with its training dataset t a reduced deep learning model rdlm for short is obtained from training the deep neural network of d0 but with a subset of t as its training dataset using the same training procedure that has trained d0.
apricot explores the relationship between d0 and a set of its rdlms on the failing test cases experienced by d0 over t0.
it does not need any mutated or faulty versions of d0.
in general once a state of the art or good dlm is welltrained with a large dataset such as the cifar dataset or the fig.
overall process of repairing deep neural networks by apricot authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
imagenet dataset it is difficult to further improve its accuracy significantly.
our work shows a possibility to make such an improvement without needing extra information which we will present evidence in section iv evaluation .
the overall process of apricot is depicted in fig.
.
there are two phases the training phase and the adaptation phase.
in the training phase the training dataset t0 is divided into multiple subsets where t0.
to ensure rdlms to be trained sufficiently the size of each subset shall be large enough.
note that there may or may not be some overlapping between subsets.
next apricot trains d0 on t0 followed by training all rdlms di on t i for i to n respectively.
in the adaptation phase apricot divides t0 into a sequence of batches.
it processes these batches in turn.
on processing each batch it invokes a sequence of two activities weight adjustment followed by retraining.
in the weight adjustment activity each batch b accepts a dlm as an input called input dlm or idlm for short .
apricot identifies all the test cases in b that the idlm fails on each of them.
for each such failing test case x it divides the set of rdlms into two partitions one partition denoted as correctsubmodels x contains these rdlms each classifying x correctly and the other partition denoted as incorrectsubmodels x contains all the remaining rdlms i.e.
these each classifies x incorrectly .
then it adjusts the weights of the idlm toward the average weight of these rdlms in correctsubmodels x and or away from that of these rdlms in incorrectsubmodels x .
in the retraining activity apricot trains the idlm which is produced by the weight adjustment activity for the same batch using the entire training dataset t0 to produce a dlm serving as the input for the iteration on handling the next batch.
our experiment see section iv shows that using rdlms that correctly classify these failing test cases experienced by d0 can outperform using only incorrectly classified rdlms or both of these two kinds of rdlms on average but using both types of rdlms can achieve the highest increase in test accuracy.
in fact all three strategies show improvements in accuracy and an average of .
improvement in accuracy is obtained.
this result indicates the complementary nature of these two kinds of rdlms used in apricot.
b. adjusting weights of dlm by rdlms the algorithms for the training and adaptation phases of apricot are shown in algorithms and respectively.
in algorithm the training dataset and the dnn of the original dlm e.g.
type of layers and parameters for each layer are given as inputs to the algorithm.
in line the algorithm creates n subsets of the original training dataset where the original training dataset is specified as inputs train x and the corresponding expected results train y .
then it feeds each such subset to a corresponding rdlm that has the same structure as the given dlm by firstly copying the dnn from dnn followed by training the rdlm using the subset lines .
it finally collects the trained rdlms as the outputs lines and .
we note that in the training process of the dlm and these rdlms only models with highest test accuracy are kept which is a typical setting chosen in training a dlm in practice .
algorithm adjusting weights of dlm by rdlms input train x train y inputs and labels of training dataset test x test y inputs and labels of test dataset submodellist the list of trained rdlms dnnmodel the trained idlm strategy strategy of adjusting weights output dnn model with repaired weights bestweights getweights dnnmodel bestacc evaluatemodel dnnmodel test x test y for each xbatch ybatch in getbatch train x train y do baseweights getweights dnnmodel for each x y in xbatch xbatch do ysublist modelprediction x submodellist yorigin modelprediction x dnnmodel if yorigin equals ythen continue else correctsubmodels correctlypredict ysublist y if correctsubmodels is empty then no correct predictions continue end if incorrectsubmodels incorrectlypredict ysublist y correctweights avgweights correctsubmodels incorrweights avgweights incorrectsubmodels corrdiff baseweights correctweights incorrdiff baseweights incorrectweights baseweights adjustweights baseweights corrdiff incorrdiff strategy dnnmodel .setweights baseweights end if end for evaluate adjustments curracc evaluatemodel dnnmodel test x test y if bestacc curracc then bestweights baseweights dnnmodel .setweights baseweights dnnmodel trainingmodel submodel train x train y bestacc curracc else baseweights bestweights dnnmodel trainingmodel submodel train x train y end if dnnmodel .setweights bestweights end for return dnnmodel algorithm generating rdlms input train x train y inputs and labels of training dataset n the number of generated rdlms dnn the dnn of original dlm output set of generated rdlms subtrainingdataset splitdataset train x train y n submodellist for each subset in subtrainingdataset do submodel copymodelstructure dnn submodel trainingmodel submodel subset submodellist .append submodel end for return submodellist authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
algorithm presents the procedure of adjusting the weights of a dlm using a set of trained rdlms.
in lines the weights of the given idlm and test accuracy achieved by this idlm are collected via functions getweights and evaluatemodel respectively.
then the whole training dataset is divided into a set of batches via the function getbatch where each batch contains a specific number of inputs xbatch and corresponding expected results ybatch of these inputs line .
for each test case and its corresponding expected result in each batch the classification results of all rdlms as well as idlm on x are collected lines through the function modelprediction .
if idlm classifies x correctly the weights of idlm are not adjusted lines .
on the other hand if idlm classifies x incorrectly then the set of rdlms is divided into two partitions correctsubmodels and incorrectsubmodels at line and line respectively.
if no models classify x correctly no adjustment will be applied lines .
it is because our adjustment strategies will be presented in the next paragraph require correctly classified rdlms to provide directions of weights adjustment.
note that the adjustment procedure continues if no rdlms classify x incorrectly.
if correctsubmodels is non empty then the average weights of both correctsubmodels and incorrectsubmodels are calculated via the function avgweights at lines .
apricot calculates average weights as follows where n is the total number of rdlms is the weight matrices for each rdlm.
all matrices of rdlms are added by adding corresponding elements together and then means of weights are calculated.
in lines the difference in weights between idlm and correctsubmodels as well as that between the weights of idlm and in correctsubmodels are calculated which are kept by the variables corrdiff and incorrdiff respectively.
in line it adjusts the weights of idlm by updating the value of each weight of idlm via the function setweights .
the function adjustweights requires strategy as its input.
apricot includes three strategies of weight adjustments denoted as strategies and respectively as follows where is the adjusted weight for the corresponding edge in the idlm after th iteration of the for loop spanning over lines is a constant representing the learning rate and pcorr and pincorr are proportions of correctly and incorrectly classified rdlms respectively.
that is let a and b be the numbers of rdlms in the sets correctsubmodels and incorrectsubmodels respectively.
we have pcorr a a b and pincorr b a b .
in both weight components from correct and incorrect rdlms are utilized.
in it ignores the component for incorrectsubmodels and in it ignores the components for correctsubmodels .
the intuition behind these equations is that apricot aims to minimize the distance between current weights and weights of correctsubmodels and or maximize the distance to weights of incorrectsubmodels .
after the above weight adjustment activity for the current batch the algorithm evaluates the adjusted idlm on the test dataset line .
it trains the adjusted idlm on whole training dataset for several epochs the detailed settings will be described in the next section .
it also applies a greedy algorithm to retain the dlm with highest test accuracy.
more specifically in lines if the test accuracy of an adjusted idlm is higher than that of the best case obtained so far then the weights of this particularly adjusted idlm are saved.
if not the weights of the idlm are rolled back to the best case obtained so far lines .
in line the weights of idlm are set to the best case founded so far.
iv.
experiment and data analysis in this section we evaluate apricot on the cifar dataset with five state of the art deep learning models.
a. experimental setup we have implemented apricot on the top of keras .
.
and tensorflow .
.
which are popular machine learning libraries in python.
all experiments were performed on windows running on an intel i7 8700k cpu 32gb ram a table i structure of cnn s model block conv conv maxpooling conv batchnormalization conv batchnormalization maxpooling conv conv conv maxpooling block conv conv maxpooling conv batchnormalization maxpooling conv conv conv maxpooling block conv batchnormalization conv batchnormalization maxpooling conv globalavgpooling output dense dense dense softmax flatten dense softmax dense softmax table ii descriptive summary of dnn models model num.
of parameters avg.
training accuracy avg.
test accuracy cnn .43m .
.
cnn 272k .
.
cnn .00m .
.
resnet 274k .
.
resnet 470k .
.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
256gb ssd and a single nvidia geforce ti gpu with the vram size of 11gb.
dataset .
the experiments were conducted using the entire cifar dataset that is widely used for image classification training and testing research.
deep learning models.
five state of the art dlms were implemented three cnn models and two resnet models .
we applied apis provided by keras for training models.
settings of the training process are as follows for cnn we set epochs to and batch size to .
in cnn training process we set epochs to and batch size to .
besides an image data generator provided by keras is used to enrich the training dataset.
for cnn we set epochs and batch size to and respectively.
for resnet and resnet epochs and batch size are set to and .
besides an image data generator is applied in the training process of resnet models.
we set activation functions to relu for all cnns.
we applied the same settings except for epochs for training rdlms.
we set epochs to for training rdlms of cnn and for training other rdlms.
for each dlm we trained rdlms.
the value of was arbitrarily chosen without any preexperimental trial.
the total numbers of test cases in the cifar10 training dataset tcifar and test dataset were and respectively.
the size of the subset for training rdlms was set to .
each image in training dataset was indexed.
the separation of training dataset into batches in algorithm is as follows.
the first second and third subsets are the images with index from to from to and from to respectively.
other subsets are similarly defined.
note that the epoch and dataset for training an rdlm are smaller than that for training original dlm thus training an rdlm is much faster than training a dlm.
we used three representative structures for the three cnn models which are summarized in table i. these models had different numbers of convolutional layers and hyperparameters.
cnn contained two blocks the first block consisted of two convolutional layers with kernels followed by a max pooling layer.
the second block was similar to the first block but the number of kernels was set to .
the output part consisted of three fully connected layers with neurons respectively.
cnn and cnn had similar structures compared to cnn .
in cnn batchnormalization layers were applied.
in cnn a global average pooling layer was applied.
for resnet and resnet we used the existing implementations which represented the resnet with and residual layers respectively.
the summary of these dlms is shown in table ii.
column shows the dlms we implemented in our experiment.
column is the number of parameters for each dlm.
column and column are the average training accuracy and average test accuracy of each dlm on cifar dataset in five runs.
during the training process only models with the highest test accuracy were saved.
for algorithm the batch size that each time the function getbatch line retrieves was set to .
these batches were mutually disjointed.
again this value of was chosen arbitrarily.
since the dataset contains images and so there were batches in total.
besides for the function adjustweights we set the learning rate to .
for every dlm.
the reason for choosing this value was that the weights in these dlms may be small and it would be difficult to find an optimum if the learning step is too large.
for training step in algorithm lines and we set epochs to and batch size to and for the three cnns and the two renets respectively.
we ran the above procedure five times to evaluate to what extent apricot can improve the accuracy of the original dlms.
in each iteration the time for training models and the accuracies of dlms and rdlms are collected for further analysis.
b. results the time consumed for training the original dlm and the corresponding rdlms are summarized in table iii.
columns to present the training time of dlm the total training time table iii summary of training time of dlm and r dlm s model training time to of dlm total training time ttotal of rdlms num.
of rdlms avg.
training time tr cnn 1min46s 15min24s 46s .
cnn 31min39s 26min44s 1min20s .
cnn 5min47s 43min48s 2min11s .
resnet 28min30s 2h56min3s 8min48s .
resnet 31min21s 2h58min35s 8min55s .
table iv summary of r dlm s rdlm avg.
training accuracy training accuracy std.
avg.
test accuracy test accuracy std.
percentage of correct classification while dlm classifies incorrectly cnn .
.
.
.
.
cnn .
.
.
.
.
cnn .
.
.
.
.
resnet .
.
.
.
.
resnet .
.
.
.
.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
of corresponding rdlms number of rdlms and average training time of rdlms respectively.
the time of training a dlm is much longer than that of training an rdlm.
training dlms need 1min46s 31min39s 5min47s 28min30s and 31min21s for cnn cnn cnn resnet and resnet respectively.
in our experiments we trained rdlms sequentially and it is worth noticing that these rdlms can be trained and collected in a distributed and paralleled way.
column shows percentages of time reduction for training rdlms compared to training dlm.
on average training an rdlm reduces .
in time compared to training a corresponding dlm.
the results of the training process of rdlms are shown in table iv.
columns to represent the average training accuracy test accuracy and their corresponding standard deviations respectively.
the training accuracies of rdlms are close to each other as evident by their relatively small standard deviations so are test accuracies.
in column we show the percentage of test cases that at least one rdlm classify each of them correctly but the original dlm classifies them incorrectly.
the result is consistent with the intuition that rdlms have learnt some features that the original dlm cannot easily get correctly which give apricot some insights for weight adaptation.
in general the results show that exploring features and behaviors of rdlms has a potential good effect in improving the accuracy of a dlm.
the distribution on the accuracy of rdlms is shown in fig.
.
recall that we ran the experiment five times and for each dlm we trained rdlms in total.
each subplot summarizes accuracies of the rdlms obtained in five runs.
the x axis represents the training test accuracy of the rdlms produced in the experiment and the y axis represents the number of rdlms with the corresponding accuracy.
bars in green represent the training accuracy and bars in blue represent test accuracy.
in general the test accuracy of rdlms is significantly lower than the original dlm by or more.
it appears that rdlm has been trained on a much smaller subset of training dataset and thus less information and features have been obtained and learnt.
the experimental results of the adaptation phase are shown in table v and fig.
.
columns to are average training accuracy average test accuracy and maximum gain in test accuracy i.e.
the highest increase in test accuracy that apricot has ever achieved in conducting the experiment after the adaptation phases using strategies and respectively have been completed.
numbers in bold refer to the highest average test accuracy or highest increase in test accuracy in the experiment.
columns are the overall average gain and maximum gain across three strategies respectively.
fig.
presents the detailed training and test accuracies achieved in five runs.
for each dlm there are two subplots reporting the training and test accuracies respectively.
these four bars are respectively arranged from left to right in each plot.
boxes in blue represent training and test accuracies achieved by original dlms and boxes in orange green and red represent training and test accuracies achieved by dlms after applying strategies and respectively.
in general the training accuracy and test accuracy of dlms after fixing are much higher than the original ones.
besides all three strategies can improve the accuracy of dlms.
the experimental results showed that for strategy apricot consistently increases the accuracy on the three cnn models by .
.
with an average of .
and on the two resnet fig.
the training accuracy and test accuracy achieved by the reduced dlms in the experiment.
for each model there is a pair of plots.
the plot on the left green bars is the result on training accuracy and the plot on the right blue bars is the result on test accuracy.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
models by .
.
with an average of .
.
apricot achieves the highest increase in test accuracy on all dlms by .
.
by applying strategy .
we note that apricot does not require additional inputs to train the given model and the accuracies achieved by the two resnet before applying apricot are .
and .
and apricot has achieved a significant improvement.
by combining the results of the three strategies an average improvement across all models is .
and an average maximum gain in accuracy is .
.
it appears to us that apricot delivers a promising result and represents a feasible direction to produce dlms with repaired weights in the experiment.
c. further analysis apparently apricot achieved more significant improvements on the three cnn models than on resnet and resnet .
apart from the reason that these two models have achieved high accuracy on the test dataset we believe that another reason is the more complex structure of resnet.
recall that apricot s improvement on resnet is .
on average using strategy .
on resnet and resnet they are .
and .
respectively.
as to be discussed below by comparing with the results in the literature we consider that apricot is effective in improving resnet.
in resnet resnet resnet resnet resnet achieved the test accuracy of .
.
.
.
and .
respectively.
the differences in test accuracy between consecutive pairs of resnet were .
.
.
and .
respectively.
it showed that the increase in test accuracy of resnet strongly relied on adding more residual layers and yet the margin of the increase was still very limited.
for instance by increasing the number of residual layers from to represented by resnet and resnet110 respectively the difference in test accuracy was less than .
.
similar evidence was presented on the official website of cifar10 resnet on which resnet and resnet achieved the test accuracy of .
and .
respectively.
table v experimental results of adaptation process model strategy strategy strategy overall average gain overall max.
gain avg.
training accuracy avg.
test accuracy max.
gain avg.
training accuracy avg.
test accuracy max.
gain avg.
training accuracy avg.
test accuracy max.
gain cnn .
.
.
.
.
.
.
.
.
.
.
cnn .
.
.
.
.
.
.
.
.
.
.
cnn .
.
.
.
.
.
.
.
.
.
.
resnet20 .
.
.
.
.
.
.
.
.
.
.
resnet32 .
.
.
.
.
.
.
.
.
.
.
average improvement .
.
fig.
the training accuracy and test accuracy achieved by dlms in the experiment.
for each dlm there is a pair of plots.
the plot on the left is the result on training accuracies of original dlm blue boxes and dlms fixed by applying strategy orange boxes green boxes and red boxes respectively.
the plot on the right is the result of test accuracy.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
the difference was .
between the two models on this dataset and that between resnet and resnet is .
.
from table v the improvements of apricot from resnet to resnet is in fact large.
compared to strategy and strategy strategy achieved higher improvements except on cnn but the results on cnn achieved by strategy was .
which was relatively high.
the results show that rdlms were useful for adjusting weights and optimizing the original dlm in the experiment.
strategy achieved a higher increase in test accuracy except on cnn by .
.
.
the results show that although strategy did not produce a higher average performance compared to strategy it is likely to fix more ill trained weights and provide insightful information for finding a global optimum.
in general if rdlms classify the same input correctly there is something in common such as capturing similar features realized as weights and the weights of these rdlms can provide insightful information for adjusting weights of the original dlm.
besides those incorrectly classified rdlms can help search for a global optimum.
as the experiment shows apricot achieved the highest average test accuracy by applying strategy in four dlms and the highest gains in test accuracy by applying strategy in four dlms.
the overall results seem to indicate that both correct and incorrect rdlms can provide an effective search direction.
these correct rdlms can achieve a relatively stable increase in accuracy and incorrect rdlms can help perturb weights and avoid local optimums.
however further studies should be made to confirm this conjecture.
from our experience in the experiment we also found it difficult to extract useful information precisely from rdlms.
that is it is challenging to adjust weights in more detailed with a clear trend.
besides recognizing which weights need to be modified and how to modify them are still unclear to us.
through apricot we have presented a novel and effective approach to utilize different kinds of dlms.
there is still a large room of improvement in formulating effective synthesis strategies and extracting features from rdlms more precisely.
some optimization methods like regularization are also helpful for improving the accuracy of dlm.
the difference between our work and neural network regularization is that our objective is to utilize rdlms to further optimize the original dlm by adjusting its weights guided by rdlms but regularization methods aim to increase the accuracy or enhance the robustness by making weight matrices sparser by adding l0 norm or making weights smaller by adding l2 norm causing a significant change in weights.
besides it is worth exploring if our approach can further increase the accuracy of a dlm that has been regularized.
d. threats to validity we only evaluated apricot on the cfiar dataset on two kinds of dlms.
apricot is general which its weight adaptation approach can be applied to different kinds of dnn architectures like rnn and gan.
evaluating apricot on more datasets and models can strengthen the generalization of this study and our future work will evaluate apricot on different state of the art dlms and large datasets.
during the experiment we found that if the original dlm got overfitted i.e.
the training accuracy was close to it was difficult for apricot to repair the dlm.
it is because that during the adaptation process apricot only focuses on inputs where the original dlm predicts incorrectly.
if the training accuracy is close to it is likely that no or very few adaptation processes could be triggered.
for example for mnist dataset the test accuracy of state of the art dlms are nearly and the training accuracy is .
we have experimented it on a smaller scale but found that apricot cannot be effectively triggered.
this is the reason why we omit the evaluation on minst dataset.
this also shows that such scenarios are not the current use cases of apricot.
apricot starts with failing test cases with respect to the original dlm.
in our future work we will study whether it is effective to trigger apricot with non failing test cases with respect to the original dlm.
we also note that for most state ofthe art dlms and real world large datasets it is unlikely to reach accuracy for both training and test processes.
thus we believe that apricot is applicable in a majority of scenarios.
algorithm presents a basic algorithm to update the weights of a dlm lines .
owing to this issue we believe that the performance of apricot can be further improved if this basic algorithm is replaced by a more advanced one such as a searchbased algorithm.
a study on using different weight adjustment schemes both linear and non linear ones is worthy of study in the future.
a possible issue is that in apricot our weight adjustments rely on the original weights of the generated rdlms i.e.
the overall adjustment result relies on the performance of rdlms.
if these rdlms are not sufficiently trained it will be more difficult to find a good solution.
to overcome this problem more rdlms which currently the experiment used such rdlms can be used in apricot reducing the effect of potential bias and likely further improving the accuracy performance achieved by apricot but training more models can be time consuming in some cases.
deep learning is gup heavy by nature.
with the success in obtaining impressive classification results it seems to us that the time and cost budgets for fixing a model can be higher.
another possible issue is that rdlms may retain different features compared to the original dlm or rdlms and dlm may learn similar features but these features are kept in a different permutation with respect to the node order in the architecture.
this issue can be alleviated by adding an initialization step at the beginning i.e.
dlm is firstly trained after several epochs and then both architecture and coarsely trained weights are copied to rdlms.
in practice it is common to start building a learning model with a pre trained one provided by companies e.g.
.
this initialization step has similar concepts.
it ensures that some features can be kept in weights and in a later training process ensuring that neurons and weights of dlm and rdlms in the same position perform the same tasks.
the effectiveness of such initialization steps needs further study and we leave it as our future work.
the experimental results show that both correctly and incorrectly classified rdlms are complementary to original authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
dlm and the effects of these two kinds of rdlms are different both rdlms can help improve the accuracy of dlms.
those correct rdlms are able to provide an insightful search direction and incorrect rdlms can help perturb weights to find global optimums and avoid local optimums.
to fix ill trained weights in dlms apricot provides different strategies for different considerations and preferences.
we ran the experiment five times to show the effectiveness of apricot in improving the accuracy of dlms.
as shown in fig.
apricot have presented consistent improvement in accuracy across all five models but the differences between these three strategies are relatively marginal.
it may worth exploring a time efficient strategy to reduce the cost incurred by apricot.
to alleviate this problem strengthening the experiment with more times can help present a clearer trend on the effectiveness of these three strategies.
in apricot the differences between dlm and rdlms are utilized for adjusting weights.
unlike the use of differential analysis in mode to identify ill trained weights or buggy neurons apricot does not aim to identify ill trained weights or problematic neurons and such weight differences are applied to guide searching weights in a coarse level which is the main difference between apricot and other differential analysis like mode.
v. related work a. deep neural network testing in recent years there are several proposals for testing deep neural networks.
the first category is about test adequacy criteria and test case generation.
pei et al.
firstly proposed the neuron coverage to evaluate the test sufficiency of a dlm.
in neuron coverage each neuron in each hidden layer is measured on whether it has been activated during the testing phase and if this is the case the neuron is said to be covered.
they propose the notion of neuron coverage based on this idea and measures the adequacy of testing efforts.
their work also proposed deepxplore to explore corner cases of the input space searching potential adversarial examples that may lead to serious problems.
nonetheless previous experimental results showed that even a small set of test data can achieve high neuron coverage rate.
ma et al.
proposed a set of multi granularity testing criteria for dlms.
the main idea of k multisection coverage is that the ranges of value of outputs for each neuron are collected during the training phase and then are divided into k sections.
a neuron is said being covered if all these sections of the neuron are covered at least once.
the neuron boundary coverage is to count how many cases that the outputs of neurons exceed or below a given bound.
sun et al.
further proposed four testing criteria sign sign ss coverage value sign vs coverage sign value sv coverage and value value vv coverage inspired by the mc dc coverage criterion.
these criteria give us some insights into neuron behaviors of dnn models and the experimental results showed that these criteria are helpful for debugging neural networks and measuring test sufficiency.
some studies explored different methods to test deep learning models.
tian et al.
proposed a method called deeptest to generate new inputs for self driving cars and maximize neuron coverage at the same time.
experimental results showed that only a small image transformation can lead to misclassifications and erroneous behaviors.
inspired by mutation testing ma et al.
proposed deepmutation to test deep learning models.
like mutation testing in traditional software a set of mutation operators at both code level and model level are predefined like weight shuffling layer deactivation layer addition etc.
mutation score used in their work is a metric to evaluate the quality of a test dataset.
ma et al.
proposed mode for debugging and fixing deep learning models.
two types of common problems are analyzed under fitting problem and overfitting problem.
given a buggy model mb that contains an under fitting or overfitting problem a hidden layer is selected where its outputs that are viewed as features are most representative.
then a feature model is constructed and trained by extracting layers of mb from the input layer to the selected hidden layer followed by an extra full connected layer.
weights between the selected hidden layer and the constructed output layer are viewed as the degree of importance of the corresponding features.
given a test case x a heat map is constructed for recognizing the degree of importance of features.
for each category mode recognizes features responsible for correct incorrect classification by implementing a differential analysis on heat maps that are generated by correctly incorrectly classified inputs.
then training samples to which these features are most sensitive to them are selected for training mb.
mode provides a detailed and specific method for recognizing buggy features or neurons in a specified layer but other layers are not analyzed.
in apricot we compare the differences between the original dlm and correct incorrect rdlms.
unlike mode apricot uses these differences to adjust weights rather than recognize ill trained weights or neurons.
b. exposing vulnerabilities of deep neural networks deep neural networks are vulnerable to adversarial examples .
as we have discussed approaches of neural network testing and adversarial attack algorithms can give us some insights about erroneous behaviors of dnn models and expose potential vulnerabilities providing useful information for repairing neural networks.
there is also a large body of work on adversarial attacks.
szegedy et al.
proposed box constrained l bfgs to find adversarial examples with high success rates.
norm is used to measure the distance between original inputs and generated inputs.
they also found that training original dnn model using generated adversarial examples can regularize the model but it can be time consuming and impractical for actual usage.
goodfellow et al.
proposed fast gradient sign method fgsm to generate adversarial examples.
fgsm uses to measure distances and calculates gradients of the loss function to guide its search direction.
the experimental results showed that fgsm is effective in generating adversarial examples and its idea inspired many other adversarial attack algorithms.
deepfool is another algorithm for generating adversarial examples.
this work proposed to find hyperplanes authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
separating different classes.
in this regard developers can find some misleading examples near these hyperplanes.
using this assumption simplifies the dnn model for generating adversarial examples.
xiao et al.
proposed to use generative adversarial networks gans to generate adversarial examples.
the basic idea is that using a generator to generate adversarial inputs and using a discriminator to distinguish between the original inputs and the generated inputs.
the prediction result of the discriminator is used as a part of the loss function of the generator to improve its performance.
su et al.
proposed a new attack algorithm that only changes one pixel to generate adversarial examples so called one pixel attack .
for the image classification task many adversarial attack algorithms mutate all pixels and use and as constraints ensuring the perturbation is acceptable.
their paper uses to restrict that only one pixel can be modified without limiting its value.
it is acceptable for humans that the meaning of an image won t change if only one pixel changed especially for those high resolution images.
although it could be difficult to find adversarial examples by changing only one pixel and the success rate may not as high as other adversarial attack algorithms like lsa and fgsm the proposed method gives us insights into how one pixel affects final classification results.
c. neural network regularization neural network regularization is a useful method to enhance the robustness of deep neural networks without losing accuracy.
a common way of regularizing neural networks is to add a term called norm to a loss function.
han et al.
proposed a new training process that contains regularization steps.
the overall process is that given a converged dnn for each layer it finds a threshold and removes all connections where their weights are below the threshold.
after obtaining the sparse dnn it freezes the remaining weights and retrains the model.
then it retrains the whole model.
the reason on why it works is that after the densesparse dense training process the weight distribution becomes sharper which means that most weights are close to reducing the possibility of erroneous behaviors caused by those weights.
chang et al.
proposed a regularization approach to improve the robustness of deep neural networks and discussed the impacts of different norms on regularizing deep neural networks.
the original norm is .
a possible issue using norm is that when is small the gradient of can be extremely large.
to overcome this problem the penalty is modified from norm to norm when is smaller than a constant which ensures that the gradients are not too large.
from their experimental results chang et al.
concluded that the modified norm can significantly reduce the complexity of deep neural networks and the accuracy can be preserved.
vi.
conclusion in this paper we have presented apricot a novel weightadaptation approach to evolve dlms iteratively.
our insight is that dlms trained on smaller datasets can provide useful information on the weight adjustment and adaptation thus optimizing a larger dlm further.
apricot generates a set of rdlms adjusts the weights of the original dlm toward average weights of these rdlms that each classifies an input correctly and or away from these rdlms that each classifies the same input incorrectly where the input in question is a failing test case experienced by the original dlm.
if a higher test accuracy is achieved after weight adjustment a training process is triggered for further improvement.
the experimental results on the cifar dataset and five dlms have shown that apricot can consistently increase the accuracy of these dlms by .
.
with an average of .
and the highest increases in test accuracy that apricot has ever achieved in the experiments were .
.
with an average of .
.
one line of future work is to debug and repair deep learning models.
there are some challenging problems like evaluating the impacts of a small set of weights on the overall dlm and repairing dlms.
we observe that there is still a huge gap between understanding the behaviors of deep neural networks and the need underlying the repair work of these networks.
besides evaluating the performance of deep neural models only by test accuracy or robustness may still not be enough in some cases.
we would like to study these issues in the future.