automaticallyanalyzing groupsofcrashes forfinding correlations marcocastelluccio mozilla london uk universityfederico ii of naples naples italy marco.castelluccio unina.itcarlosansone universityfederico ii of naples naples italy carlo.sansone unina.it luisaverdoliva universityfederico ii of naples naples italy verdoliv unina.itgiovanni poggi universityfederico ii of naples naples italy poggi unina.it abstract we devised an algorithm inspired by contrast set mining algorithmssuchasstucco toautomaticallyfindstatisticallysignificant properties correlations in crash groups.
many earlier works focusedonimprovingtheclusteringofcrashesbut tothebestof our knowledge the problem of automatically describing properties of a cluster of crashes is so far unexplored.
this means developers currentlyspendafairamountoftimeanalyzingthegroupsthemselves which in turn means that a they are not spending their time actually developing a fix for the crash and b they might miss something in their exploration of the crash data there is a large numberofattributesincrashreportsanditishardanderror prone tomanuallyanalyzeeverything .ouralgorithmhelpsdevelopers and release managers understand crash reports more easily and in an automated way helping in pinpointing the root cause of the crash.
the tool implementingthe algorithm has been deployed on mozilla scrash reportingservice.
ccs concepts software andits engineering software reliability keywords crashes crash reports crash analysis.
acmreference format marco castelluccio carlo sansone luisa verdoliva and giovanni poggi.
.
automatically analyzing groups of crashes for finding correlations.
inproceedingsof201711thjointmeetingoftheeuropeansoftwareengineering conference and the acm sigsoft symposium on the foundations of softwareengineering paderborn germany september4 8 esec fse 10pages.
permissionto make digitalor hard copies of allorpart ofthis work for personalor classroom use is granted without fee provided that copies are not made or distributed forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation on the first page.
copyrights for components of this work owned by others than acm mustbehonored.abstractingwithcreditispermitted.tocopyotherwise orrepublish topostonserversortoredistributetolists requirespriorspecificpermissionand ora fee.
request permissions from permissions acm.org.
esec fse september 4 8 paderborn germany associationfor computing machinery.
acm isbn ... .
introduction fixingcrashesisoneofthetopprioritiesforsoftwareorganizations as they are one of the main pain points for users and might lead them to leave.
even a single crash can dramatically worsen how usersperceiveasoftware especiallyifitcausesthelossofimportant data.actingquicklyisthusreallyimportanttoavoidlosingusers andkeepahigh qualitysoftware.
severalsoftware organizationshavedeployedautomatedcrash reportingsystems suchasmozilla ssocorro andwindowserror reporting whichare used to collect reports from users at the time of crash.
a report received by socorro comprises typically more than a hundred attribute value fields.
these reports are then analyzed by dedicated personnel to find out fixes and improve software quality.
it should be realized however that these systems collectahugenumberofcrashreportsdaily aboutthreehundred thousandreports dayforsocorro whichcannotbeprocessedon anindividualbasis.therefore thetypicalworkflowconsistsoftwo key phases crash report clustering clusterfeaturingandanalysis.
the goalof clustering istogrouptogether similar reports asthey are likely originated by multiple instances of the same software problem.
once the problem is fixed all these reports can be discardedatoncefromfurtheranalysis.moreover clusteringallows one to compute precious statistics on the cluster itself enabling the second phase of the workflow.
in fact the typical features of interestinaclusterconcernthefrequencyofoccurrenceofattributevalue pairs which may provide useful hints for the solution of the problem.asanexample assumethataperfectclusteringprocess succeeds in grouping together all crash reports originated by a given software bug and assume also that all such reports are characterizedbyadistinctivefeaturewhichisneverobservedinreports ofotherclusters.whilenotconclusive thisobservationwouldprovideastrongcluefortheanalyst andwouldprobablyallowaquick fixoftheproblem.thisidealizedprocessissummarizedgraphically infigure .
717esec fse september4 paderborn germany m. castelluccio c.sansone l. verdoliva andg.poggi clustering featuring... group group g1 features g2 features overall features dataset figure idealized process with perfect clustering propertiesthat define thegroupsare easily found.
needlesstosay real worldoperationsareveryfarfromthissimplisticcase.on offfeaturesrarelyoccur andtheanalystmustfocus onminorvariationsinthefrequenciesofoccurrenceofattributevaluepairsacrossgroups.moreover themostdistinctivefeatures concern usually jointoccurrences.
if the number of elementary featuresisalreadylarge thenumberoffeaturesconcerningmore complex behaviors possibly involving tuples of attribute value pairs makes brute force analysis simply infeasible.
it requires very skilledanalyststonavigateeffectivelythroughthesedataandextract useful clues.
to further complicate things the preliminary clustering of crashes is itself far from perfect which may strongly affecttheresultsofsubsequentanalyses.whenaclusterincludes reports that have no relation with one another the resulting features are averaged together and hardly distinctive anymore.
on the contrary when there are too small groups since reports for the same crash are divided in multiple clusters features become unstable leadingto erroneous conclusions.
theabovediscussionunderlinestheneedofeffectiveautomated toolsthatsupporttheanalyst sworkinbothphasesontheprocess toi perform a reliable clustering of crash reports and ii single out the most meaningful features.
many previous studies in the literaturehavefocusedonthefirstproblem namely proposinga number of competing solutions to best cluster crashes in groups.
section contains a more detailed explanation of some of them.
in thispaper instead wefocusonthesecondproblem andpropose anautomatedtooltosupportgroupunderstandingaftertheclustering has already taken place.
the proposed tool finds statistically significant properties in crash groups sorts them by decreasing importance and submits them to the analyst.
developers are therefore freed from this tedious preliminary analysis and can focus on fixing the crash.
it should be also underlined that the manual analysis giventhelargenumberofattributesincrashreports isnot onlytediousbutalsoerror prone alsoduetotheeffectsoffatigue .
theproposedtoolmayhappentofindinterestingpropertiesthat figure dialog window presented to the users when they experienceacrash.
theanalystcouldmiss.automaticallyfindingpropertiesofcrash groups also allows release managers to quickly act with temporary workarounds for example by blocking updates to a crashy version for aparticularsetofusers.
specifically ourapproachisbasedonadataminingtechnique contrast setlearning appliedsuccessfullytoanumberofother problems in software engineering and beyond e.g.
.
the approachwepresentinourstudycanalsohelpwiththetriageof crashgroups infactreleasemanagerscandecideontheirimportance afterunderstandingthepossiblecausesandpropertiesofa crash.
we evaluatethe systemusing crash datacollected from the mozilla crash reporting system and bug tracking system.
although asystematic analysisofperformanceinnot feasibleforpractical reasons we collected significant evidencethat the systemmay actuallyhelpunderstandingagroupofcrashesandreducethetime neededto solve the problem.
the remainder of this paper is organized as follows.
section provides background information about socorro the mozilla crash reportingsystemusedinourstudy.section3describestheproposed algorithm.
section presents the validation of the results of our algorithm appliedtorealworldcasesformozillafirefoxcrashes.
section discusses threats to the validity of this study.
section summarizes relatedworks andsection 7concludes the paper.
socorro and crash reports mozilla sapplicationsareshippedwithabuilt inautomaticcrash reporting tool .
when end users encounter a crash they are presented with a dialog window that asks them to submit a report see figure .
crash reports include stack traces of the threads that were runningatthetimeofthecrashandotherinformationabouttheuser s environment e.g.
operating system memory relatedinformation modulesloadedintheprocess etc.
.asubsetofthefieldscontained in a crash report is depicted in table .
the reader may refer to for an up to date json schema of a crash report.
some of the information containedina crash report mightbe sensitive which 718automatically analyzing groupsofcrashes for findingcorrelations esec fse september4 paderborn germany table asubset oftheattributes present inacrashreport.
name description platform thename ofthe operating system.
platformversion thedetailedversionoftheoperatingsystem e.g.uname a on linux .
addons a list of the addons with their version installed in the firefox profile.
modules alistofthemodules dllfilesonwindows so files on linux dylib files on mac with theirversion loadedintheapplication sprocess.
usercomment a usuallybrief commentleftbytheuserat the time ofcrashing.
cpu info detailed information vendor family model stepping numberofcores aboutthecpuof the user.
adapter vendorid thevendorofthegraphicscardontheuser s machine.thereareotherrelatedattributes suchasadapterdeviceid adapterdriver version etc.
safemode a boolean variable that indicates whether firefox was runningin safe mode.
useragentlocale thelanguage ofthe user.
... ... is why the submission of crash reports is not silent but requires the userto acceptaprompt.
as can be seen from figure the user has a chance to enter a short comment at the time of crash.
this allows users to specify detailsabouttheircrashreport.forexample whattheywere rightbeforetheyexperiencedthecrash.crashreportsarethensent to the socorroserver which assignsaunique id to eachreport performs somepost processing onthe reports groups the reports together using an extremely fast but not very reliable algorithm describedbelow.
see figure 3for an overviewofthe socorroarchitecture.
the reports are clustered based on the top method signature ofthestacktraceofthecrashingthread oranotherthread ifthe crashisduetotheapplicationwillinglyterminatingitselfaftera hang .table2showsanexampleofastacktrace withthegroup name itwasassignedbythe socorroalgorithm.
there areseveral rules that allowto skip somemethods if they aredeemedtobeuselessforgroupingpurposes e.g.averygeneric function a function from an external driver etc.
.
some of the rules are general purpose e.g.
c standard library functions some are really specific to the mozilla applications e.g.
xpcom functions .
this large set of rules has been built over time manually bydevelopers.
this algorithm is sometimes ineffective as two crashes that happen in the same function might be completely different fromtable example stack trace.the group name is inbold.
frame module signature xul.dll mozilla storage service getsingleton xul.dll mozilla storage serviceconstructor xul.dll nscomponentmanagerimpl createinstancebycontractid char const nsisupports nsid const void xul.dll nscomponentmanagerimpl getservicebycontractid char const nsid const void xul.dll nscomptr base assign from gs contractid nsgetservicebycontractid nsid const xul.dll nscomptr mozistorageservice nscomptr mozistorageservice nsgetservicebycontractid xul.dll nspermissionmanager opendatabase nsifile xul.dll nspermissionmanager initdb bool xul.dll nspermissionmanager init xul.dll nspermissionmanager getxpcomsingleton xul.dll nsipermissionmanagerconstructor xul.dll nscomponentmanagerimpl createinstancebycontractid char const nsisupports nsid const void xul.dll nscomponentmanagerimpl getservicebycontractid char const nsid const void xul.dll nscomptr base assign from gs contractid nsgetservicebycontractid nsid const xul.dll nscomptr nsipermissionmanager nscomptr nsipermissionmanager nsgetservicebycontractid xul.dll mozilla services getpermissionmanager xul.dll mozilla dom notificationtelemetryservice recordpermissions xul.dll notificationtelemetryserviceconstructor xul.dll nscomponentmanagerimpl createinstancebycontractid char const nsisupports nsid const void xul.dll nscomponentmanagerimpl getservicebycontractid char const nsid const void xul.dll nscomptr base assign from gs contractid nsgetservicebycontractid nsid const xul.dll nscomptr nsisupports nscomptr nsisupports nsgetservicebycontractid xul.dll ns createservicesfromcategory char const nsisupports char const char16 tconst xul.dll nsxredirprovider dostartup xul.dll xremain xre mainrun xul.dll xremain xre main int char const nsxreappdataconst xul.dll xre main firefox.exe do main firefox.exe wmain firefox.exe scrt common main seh kernel32.dll basethreadinitthunk ntdll.dll rtluserthreadstart ntdll.dll rtluserthreadstart figure overview ofthe crashreporting system eachother.thisisparticularlynoticeablewithcrashesrelatedto the javascript jit compiler.
however processing speed isdeemed moreimportantthanaccuracyinthiscontextandnewclustering methodsshould be alsovery fast to qualifyas aviable alternative.
automaticanalysisofcrash groups the analysis method adopted here is a slightly modified version of the contrast set mining algorithm stucco searching and testing forunderstandableconsistentcontrasts proposedoriginallyby bayandpazzani .toillustratethemethodwewillrefertoa toyexample withthedatasetpartitionedintwoclusters orgroups with cardinalities g1 and g2 and reports including onlyn 2attributes platform p andgraphicscard whichcan 719esec fse september4 paderborn germany m. castelluccio c.sansone l. verdoliva andg.poggi root p w p l p m g n g a p w g n p w g a p l g n p l g a p m g n p m g a figure root andallpossible specializations takethreeandtwovaluesrespectively p w l m forwindows linux andmac and n a fornvidia andamd .
.
the contrast set miningproblem in the contrast set mining framework the dataset is a set of ndimensionalvectors whosecomponentsarediscretevalues.the vectors are partitioned beforehand in mutually exclusive groups g1 g2 ... according to external criteria.
a contrast set is defined as a set of attribute value pairs.
for example cset1 p w is a contrast set concerning a single attribute value pair while cset2 p w n concerns a coupleofattribute valuepairs andisactuallya specialization ofthe former.thesupportofacontrast setinagroup s cset g isthe percentageofvectorsinthegroupforwhichthecontrast setistrue.
contrast set supports are the features used to characterize groups.
so for example having s cset1 g1 .
ands cset1 g2 .
means that in group of crashes occurred on a windows platform whileingroup2thepercentagewas30 .suchalarge difference seems to indicate that the platform is not irrelevant for these crashes.
accordingly the goal of contrast set mining is tofindcontrast sets alsocalled deviations whosesupportdiffers meaningfullyacrossgroups.
more formally for a contrast set to be declared a deviation it must be both largeandsignificant .
the first condition is expressed as max ij barex barexs cset gi s cset gj barex barex where is a constant minimum support difference defined by the user.
significance instead is declared based on the outcome of a statisticaltest ofhypotheses braceleftbiggh0 p cset true gi p cset true gj h1 p cset true gi nequalp cset true gj carried out for all couples of groups gi gj with a user defined false alarm level .
.
stucco in stucco contrast set mining is cast as a tree search problem.
the root node is an empty contrast set.
then for each step of the algorithm existing nodes are specialized by appending new attribute valuepairsto existingones.a canonical orderingofthe attributes is used to avoid visiting the same node twice.
with referencetoourtoyexample figure4showsthesearchtreeaftertwo levels of specialization.
note that the nodes nand ahave nochildren as comes after pinour orderedattribute list.
stuccoperformsabreadth firstlevel wisesearchinthetree.
we provide here a very high level description of the algorithm going into more details in the following subsection.
for each node atagivenlevel thenumberofoccurrencesforeachgroupinthe dataset is counted.
based on such data some heuristics are appliedalgorithm1 stuccoalgorithm setofcandidates c setofdeviations d setofprunedcandidates p letprune c returntrueifcshould be pruned whilecis not empty do scan data andcount support c c foreachc cdo ifsi nificant c lar e c then d d c end ifprune c truethen p p c else cnew cnew genchildren c p end end c cnew end dsurprisin findsurprisin d todecideonwhetherthenodeshouldbepruned becomeaterminal node orgeneratenewchildren.thetreegrowsuntilnomorechild node can be generated or a suitable stopping condition applied to limit processing time is met.
after the whole tree is grown each surviving node corresponds to a valid candidate contrastset.
contrast sets that are found to be both large and significant deviations andalsosurprising areeventuallykept andsubmitted totheanalystasanorderedlist fromlargesttosmallest.algorithm1 providesapseudo codedescriptionoftheprocess.figure5 instead showsthefirstfewstepsofthealgorithmappliedtoourtoyexample.
in particular allpossibleattribute valuepairs candidates are generatedfor eachattribute inacrash report figure 5a thenumberofoccurrencesforeachcandidateineachgroup iscounted figure 5b somenodesareprunedbasedonsuitableheuristics figure 5c newcandidatesaregeneratedbymergingpreviousones which survived pruning for example p w and n give riseto p w n figure 5d .
steps are repeated until there are no more candidates or a suitable stopping condition is met for example the maximum number ofiterations.eventually allnodes contrast setsaretested andonly thosethatarelarge significant andsurprisingaresubmittedtothe analyst.
thefollowingsubsectionsprovidethenecessarydetailsforafull comprehension ofthe algorithm describing thetests on largeness significance and surprise as well as the heuristic rules for tree pruning.
.
.
selecting large contrast sets.
this is a straightforward test for a contrast set to be large its support must be larger than the threshold definedbythe user.
720automatically analyzing groupsofcrashes for findingcorrelations esec fse september4 paderborn germany root g1 g2 p w p l p m g n g a a generationof allpossible attribute valuepairs root g1 g2 p w g1 g2 p l g1 g2 p m g1 g2 g n g1 g2 g a g1 g2 b countof the occurrences for allcandidates root g1 g2 p w g1 g2 x x g n g1 g2 g a g1 g2 c pruning of candidates using a set of heuristics root g1 g2 p w g1 g2 x x g n g1 g2 g a g1 g2 p w g n p w g a d generationof a new level of candidates figure5 samplerunofthealgorithminthecontextofcrash reports .
.
selecting significant contrast sets.
to evaluate whether a contrast setissignificant werelyonthetestofhypothesesofeq.
.
the null hypothesis is that the support of the contrast set is equal across all groups or differently said it is independent of group membership.
to this end we build a contingency table like that shown in table reporting the occurrences of a contrast set across groups and the corresponding supports our features of interest that is the frequencies ofoccurrence inthe group.table example contingency table p wp nequalwgroup size group group overall in ourexampleweanalyze cset1 namely platform windows.
ifgroupandthe platformwereindependentvariables theproportionofcrashreportswiththewindowsplatformshouldbeabout the same across all groups.
this is not the case in our example.
however thesupportsmaydifferjustbecauseofrandomfluctuations and the difference may not be statistically significant.
hence weneedtodeterminewhethersuchdifferencesaretheeffectofa true dependency between the variables or if it can be attributed torandomness whichiswhyweneedastatisticaltest.thestandard test for independence of variables in contingency tables is the chi square test 2 r summationdisplay.
i 1c summationdisplay.
j oij eij eij whereoijistheobservedfrequencyincell ijandeijisthefrequency expectedunderthehypothesisofindependencebetweenrowand column variables.
we then compare the resulting value against the 2distribution under the null hypothesis selecting level of significance which represents the probability of rejecting the null hypothesiswhen itholds false alarm .
for a single test a level .
implying a false alarm probability of could be considered acceptable for our application.
however since a large number of contrast sets are typically tested for significance the overall number of false alarms may be disturbinglylarge.forexample ifweran100testsat .
andthe nullhypothesiswerealwaystrue wewoulddetectontheaverage5 significant differences that are not actually there.
to keep the false alarm rate within acceptable limits stucco reduces according tothebonferronicorrection given h1 h2 ... hkhypotheses and their corresponding p valuesp1 p2 ... pk the hypothesis hiis rejectedif pi k.thebonferronicorrectioncontrolsthefamilywise error rate fwer which is the probability of incorrectly rejecting at leastone true hypothesis hi at .
fwer p ktrue uniondisplay.
i parenleftbig pi k parenrightbig ktrue summationdisplay.
i braceleftbig p parenleftbig pi k parenrightbig bracerightbig ktrue k thisholdsnomatterhowmanyofthenullhypothesesaretrueand even withdependent tests .
there are two problems in the application of the bonferroni correctioninthecontextofstucco firstofall ifwereportresults in a level wise fashion shorter first then longer we cannot know howmanytestswewillperformintotal whichmakesitimpossible to know the exact value of k. moreover as gets smaller the statisticalpowerofthetestsdecreases increasingtheprobabilityof producing falsenegatives.
this cannot be avoided sincewewant 721esec fse september4 paderborn germany m. castelluccio c.sansone l. verdoliva andg.poggi to reduce the probability of false positives.
however we can use differentvaluesof fortestsconcerningdifferentlevelsofthetree ensuring a high power for tests at higher levels which are more general and easier to understand and accepting a lower power for tests more down the tree.
since the bonferroni method holds as longas summationtext.
i i stuccoadopts level dependent values l min parenleftbigg 2l cl l parenrightbigg where listhecutoffforlevel l and cl isthenumberofcandidates atlevell.thiswayweassign1 2ofthetotal risktotestsatlevel 4totestsatlevel2 etc.theminruleensuresthat aswemove to deeper levels the cutoff can onlydecrease makingthe tests more likely not to rejectthe null hypothesis.
.
.
selectingsurprisingcontrast sets.
asalreadysaid contrastsetsareshowninalevel wisefashiongivenhigherprioritytohigher levels e.g.
level with a single attribute value pair as they are easiertointerpret.furtherspecializationsarethenincludedonly if they are surprising namely when the observed frequencies depart significantly from the expected frequencies.
for example if for allgi s s p w n gi s p w gi n gi that is the support of the specialization can be derived based on an independence conjecture than the specialization itself does not add information is not surprising and thus can be discarded even when itisadeviation according to the definition.
.
.
pruning the search space.
when building the contrast set tree anumberofheuristicscanbeappliedtolimititssizeandhence reduce the computationalburden.
minimumdeviationsize.
whenacontrast sethassupportless than for every node it can be pruned.
in fact if the support is smallerthan foranygivengroup thedifferencebetweenanytwo supports cannotbe larger than .
expected cellfrequencies.
the validity of a test depends on the size of the available sample becoming scarcely reliable when only a small number of items are available.
a typical lower bound for the 2testis5 .therefore whenwereachacontrast setwitha numberofoccurrencessmallerthan5 wecansafelypruneit since anyfurtherspecializationcanonlyfurtherreducethenumberof occurrences.
2bounds.
bayandpazzanishowedthatitispossibletodefinean upperboundonthe 2statistic.thiscanbeusedtoprunenodes when we know that the corresponding statistic will not exceed the cutoff.
identical support.
specializations with the same support as the parent might be not interesting and can be discarded.
theytarget the same set of dataset entries as the parent and often represent findings that are common knowledge e.g.
the support of platform detail debianwheezy willobviouslybethesameasthe supportof platform linux platform detail debianwheezy the additionof platform linux providesnoinformation .
fixed relations.
often a group has larger support for a given contrast set than any other group and specializing the contrast set with additional attribute value pairs does not change the situation.
in thosecases the node can be pruned.
platform platform version cpu brand adapter vendor id list of modules cpu microcode version adapter device id adapter subsys id adapter driver version figure detail ofthe dependencygraph .
domain specific variations theimplementationofthealgorithmmusttakeintoaccountthe largenumberofitemstodealwithinourreal worldapplication.at the time of writing around crash reports per week are generatedforasinglefirefoxversion1.moreover eachreportcontains a large number of attributes more than spanning different possible values.
this means that the number of possible candidates explodes very rapidly as soon as contrast sets are specialized beyond level .
testing candidates for each couple of groups is clearlyinfeasible.therefore inourimplementation wetesteach groupagainsttherestofthedataset thatis welookforfeatures thatpresentanomaliesw.r.t.theaveragebehavioroverthe whole dataset.inaddition forperformancereasons wehaveimplemented the toolusing apache spark .
another specific feature of our application is the existence of strong dependencies among groups of attributes.
for example the presence of a given dll might be directly linked to a particular version of windows the cpu microcode version is directly linked tothecpuvendor etc.wemodifiedstuccototakeintoaccount suchinformationbymeansofagraphofdependencies seefigure6 foradetailofthedependencygraph .whenadependencyisfound thepercentageofoccurrenceisrecalculatedrestrictingthegroup to the reports where the dependency holds true.for example in a groupwestudied themodule bcryptprimitives.dll waspresent in83.
ofcrashreportsvs.
.
overall qualifyingforalikely deviation.however ifwetakeintoaccounttheoperatingsystem windows10 thepercentageschangeto100 vs98.
andhence this rulecould be ignored.
oneofthefieldsofthecrashreportsisasmalltextareawhere the user who experiences the crash can write a short comment.
mostusersdonotprovideusefulinformationbutexpressonlytheir frustration which makes the comments field widely different from usualbugreports.nonetheless inourmanualinspections wehave foundcomments to be sometimes useful even if just as hints.
with the aim to extract some useful information from the comments field we employed a well known information retrieval technique termfrequencyandinversedocumentfrequency tf idf which highlights the words most frequently used in the comments for a given crash group vs. other groups.
this allows developers to quicklyglanceifthereissomethingwrongwithaparticularsetting.
for example in one particular instance many users were mentioning playing and the crash turned out to be due to a resource exhaustion dueto videogamesrunning inthe background.
3d2017 date crash reports 722automatically analyzing groupsofcrashes for findingcorrelations esec fse september4 paderborn germany table summary oftheresults ofthevalidation.
type numberofbugs very useful results that directly helpedfixing the bug.
compatible results that were compatiblewiththeresolutionofthebug but were not useful for fixing the bug.
misleading results not compatible withthe resolutionofthe bug.
validation ofresults inordertovalidatetheresults wehaveselectedasetofbugreports where we knew developers used our tool and we have verified whether the tool helpedinthe resolutionofthe bug gave compatible clues but didnot helpsolving the bug gave somemisleadingclues.
the tool has been integrated in socorro but we do not know whenthedevelopersuseitfortheirinvestigations.somedevelopers whenusingthetool copiedtheresultsofthetoolinthebugreport they are working on.
this allows us to select a set of real world casesthatwecananalyze giventhatdevelopershavefixedthem already sowecanevaluateiftheresultsofthetoolhavebeenuseful for fixing the bug.
we considered about800 crash bug reports approximately400 closed generatedfromseptember2016 whenourtoolhasbeenput inproduction tofebruary2017 mostlyfrommozilladevelopers.
for of these reports closed we have definitive evidence that our tool was used.
we have manually analyzed this set of bug reports and the code changes that are attached to them finding caseswherethetoolhasbeenreallyuseful 19caseswherethetool generated compatible results but did not help solving the bug caseswherethetoolhasproducedmisleadingresults.theseresults are summarizedintable4.
in some of the caseswhere thetool hasbeen useful we believe thebugwouldnothavebeensolvedifnotwithverylargeinvestigativeeffort.outofthethreecaseswherethetoolhasbeenmisleading we believe that by improving the initial clustering algorithm two misleadingresults wouldhave beenavoided.
these are analyzedin moredetailinsection4.
.4and4.
.
.asalreadysaidintheintroduction thequalityofclusteringcanstronglyaffecttheresultsof the algorithm polluting group statistics with unrelated reports or generating groups too small to provide meaningful statistics at all.
whentheclusteringalgorithmfailsbygeneratinggroupsthat aretoolarge clusteringtogethercrashesthathavenorelationwith eachother itisharderforthecorrelationtooltofindinteresting properties.indeed asmanycrasheswhichareactuallyreallydifferent from each other get clustered together it gets more difficult to analyze them both manually andautomatically .
whentheclusteringalgorithmfailsbygeneratinggroupsthat are too small allocating reports for the same crash to differentgroups thecorrelationtool andmanualanalysis ismoreproneto find spuriouscorrelations.
the clusters dimensions can vary wildly between thousands of reports themostcrowdedclustercontainsaround20000crashes and a very small number of reports even a single one .
we only apply the tool to the largest clusters as they are the most important ones after the 200th cluster we only have clusters with lessthan100reports .thesetopclustersaccountforaround55 of all reports but there is a very long tail of clusters with very few reports.
.
deploymenton socorro we tested the tool on crash groups which we already analyzed in the past to assess its validity and we put it in production for new crash groups.
in this section we summarize a few interesting results that we obtainedduringour analysis.
.
.
amdcpubug.
agroupofcrasheswasfoundtobecorrelated with a particular family of amd cpus.
we later found that the particular family of amd cpus that was involved in the crash groupwasaffectedbyahardwarebug anddeveloperswereableto find aworkaround for it.
.
.
antivirus related crash.
a group of crashes was found to be correlated with a version of an addon of an antivirus suite.
in cases like this the tool allows us to act quickly and simply block theaddons ormodules thatcauseproblems whilewetalkwith the vendorsto solve the problem inthe longterm.
.
.
crashwithoutadblock.
interestingly thetoolalsogenerates results that are quite open to intepretation.
for example therewasacrashgroupthatwasmorecommontouserswithout ad blocking addons.
it was a crash happening often with a very famousflashgame.webelievethecrashwascausedbysomead network serving particular advertisement that would cause the browser to crash.
the crash disappeared quickly on its own which supports that hypothesis.
.
.
misleadingresultcausedbyclusteringfailure toofew clusters .
crashesrelatedtothejitcompilerforjavascriptarea clearexample of howcrashclusteringcan affecttheresultsof the tool.
the clustering algorithm employed by socorro does not work well for those kind of crashes often lumping unrelated crashes together.the correlationtool isonly abletotell thatthegroupof crashesisrelatedto the jit but cannotsay muchmore.
.
.
misleading result caused by clustering failure too many clusters .
there wasa crash whichwaslaterdiagnosed to be due to concurrency issues which was happening in different functions accordingtocpubrandorgraphicscard.thiscausedtheclustering algorithm used by socorro to generate a new cluster for each cpu brand graphics card making each cluster obviously correlated to those.clearly the correlations were spurious.
.
.
analyzing crash reports before after a change.
the algorithmisreallyusefulwhenanalyzingacrashgroupgenerated bysocorro butcanbeusedforgenericgroupsaswell.forexample to analyze the differences in the properties of crash reports 723esec fse september4 paderborn germany m. castelluccio c.sansone l. verdoliva andg.poggi before after a change e.g.
to assess the effectiveness of the change andas anothermeans to ensure that itdidnot cause regressions.
we employed the tool to analyze the differences between the crashesbefore afterachangethatrelaxedtheblocklistforgraphics acceleration on nvidia graphics cards.
we found that the change improved the stability with a particular version of the nvidia drivers onewherehardwareaccelerationwaspreviouslyblockedand unblockedbythechange probablybecausehardwareacceleration isamore common andthoroughlytestedcode path.
.
feedbackfrom developers developers and people triaging crash bugs generally expressed favourable opinions about thetool.
we collected suggestionsfrom them since the deployment to socorro.
most of the suggestions were requests of addition of new possible fields to the analysis sometimes meta information dynamically generated from already existingfields .someofthesuggestionswereinsteadrelatedtothe way results are shown which is actually a pretty important aspect.
indeed we empiricaly noticed that if the information presented to the user is too crowded e.g.
too many useless attributes too much information the user is more likely to complain or overlook something.intheremainderofthissection wepresentsomeofthe more specific suggestionsthat we receivedfrom developers.
.
.
employing thecorrelation resultsthemselves to improve clustering.
the correlation analysis itself might be useful to improve the clustering algorithm.
for example two groups which present similar correlations might be clustered together.
groups which do not have any interesting correlation might be candidates to be split.
we observed that this operation was done manually by developers in the results validation.
concerning two bugs where the correlations were very similar the developers noticed that the two groupswere actually a single one and closed a bugas a duplicate ofthe other .
.
.
extractinformationfromunstructuredcrashreportfields.
the algorithm we presented only works with discrete fields but crash reports often contain unstructured information too.
the user comment is a clear example.
the tf idf solution works for simple casesanditcouldbegreatlyimproved.forexample ifseveralusers mention the same thing in different ways tf idf will not notice it.
usingamorepowerfultextminingalgorithmmightimprovethe results although it is still not clear to us how much information is actually contained in the users comments.
we noticed some cases where it turnedout to be useful butdevolvingtime and resources for this mightnot be toovaluable.
.
.
driving automated tests configuration.
at mozilla we developed a tool which automatically tries to reproduce crashes with different settings and under different configurations called bughunter .thecorrelationresultscouldhelpindrivingthe tool to directly test under a configuration that is more likely to reproduce the crash both saving running time e.g.
if a crash is only happening with a specific graphics card vendor and a specific driver there isnopoint intryingto reproduce it with a graphics cardfrom adifferentvendor andmakingreproducibility easier.
.
.
predicting volume of a crash in a release channel from pre releasechannels.
bylinkingthedatageneratedbythecorrelation tool with data about the user population distribution we can estimate how a crash that is affecting a pre release version will affect the release version.
the reader can refer to the work by khomh et al.
for an explanation of the firefox pipelined releasemodel.thishasbeenattemptedinthepastusingmachine learning techniques in kim et al.
it was used to predict which crashstackismoreprobabletobecomea topcrash andshouldbe fixed first.
for example firefox beta users are predominantly from theunitedstates.thepercentageofthoseusersisfairlylowerin firefoxrelease.thismeansthatcrashesthatareeasilyreproducible ona website that isnot in the english language are very likely to go unnoticed during the beta cycle and explode when firefox is released.
if we had a way to re rank the crashes considering the attributesto whomtheyare correlatedandtheincidenceofthose attributesindifferentchannels thenthosecrasheswouldlesslikely gounnoticed.
threats to validity internalvaliditythreats concernfactorsthatmayaffectadependent variableandwerenotconsideredinthestudy.weevaluatedourtool on41closedbugs whichmightnotbearepresentativedataset.we have chosen to evaluate the results on the fixed bugs as we needed to check if the fix was compatible with the findings of the tool.
external validity threats are concerned with the generalizability of our results.
in this paper we only evaluated the results of the tool applied to mozilla firefox crashes because its crash data bug reports andsourcecode are publiclyavailable.
related work bird et al.
studied the effect of extrinsic factors on software reliability.inourexperiencewefoundevidencethatcorroborates their findings there are several crashes that are due to external softwarebadlyinteractingwithfirefox.inourcasethoughweoften noticedsecurity applicationsbeing the root cause of the crashes.
.
automaticcrash reporting systems several past studies have shown how a crash reporting system such as socorro can be very valuable for discovering and fixing crashes.
for example glerum et al.
presented their experience with wer windows error reporting .
ahmed et al.
studied the mozilla crash reporting system.
one of the problems presented in istheoverwhelmingamountofdatathatismadeavailable through a crash reporting system.
our work tries to solve this problem by using data mining techniques to handle the complexity ofthe data andprovideawayto automaticallyunderstandit.
.
crash clustering thecrashclusteringproblemhasbeenstudiedextensivelyinthe literatureandiscloselyrelatedtothetechniquepresentedinourpaper.indeed agoodclusteringtechniqueisneededinordertoavoid false positives or false negatives.
lohman et al.
and modani et al.
adaptedstop wordremoval tocall stacks removingrecursive calls and using similarity measures like edit distance longest common subsequence and prefix matching.
bartz et al.
used 724automatically analyzing groupsofcrashes for findingcorrelations esec fse september4 paderborn germany editdistance proposingseventypesofeditsassignedwithdifferent weights.
dhaliwal et al.
proposed a two level grouping of crash reports using levenshtein distance to evaluate the similarity between stack traces.
dang et al.
presented rebucket an algorithm for clustering crashes based on a custom method called pdm position dependent model that uses the position of a function in the stack trace and the offset between matched functions for calculating the similarity between stack traces.
lerch et al.
proposedusingawellknowninformationretrievaltechnique term frequency and inverse document frequency to rate stack traces.
campbell et al.
presented an overview of several clustering algorithms including the one presented by lerch et al.
evaluating their results in the same setting ubuntu apport crashes .
they foundtraditionalinformationretrievaltechniquestooutperform techniquesspecificallydesignedforcrashclustering.the proposed algorithmisstronglyrelatedtocrashclustering asitoperateson clustersofcrashes.thus itsperformanceisdirectlyaffectedbythe qualityofthe clustering algorithm employed.
.
visualizationofcrash reports anotherrelatedareaofresearchisthevisualizationofcrashreports toaidintheunderstandingbydevelopers.forexample kimetal.
proposedanapproachbased onanaggregated graphview of multiplecrashes.theyalsopresentedawaytousethecrashgraphs for clustering.
chan et al.
presented three types of graphs to analyze field testing results under three different perspectives.
the above approaches could be combined with our proposed approach to improve understanding ofgroup ofcrash reports.
.
triaging ofcrash reports kimetal.
presentedamachinelearningtechniquetopredict which crash stacks are more probable to become top crashers and should be fixed first.
khomh et al.
proposed an entropy evaluationapproach takingintoaccountvolumeofcrashgroups anddistribution among users to rank thecrash clustersby importance.
the above approaches focused on prioritizing the groups of crash reports for bug fixing.
our approach instead identifies generic properties of the groups which can be later used by developers and managers not only for prioritization but also to directly understandpossible causes.
conclusion crashes are one of the main pain points for users of a software.
fixing them promptly can improve the users perception of the quality of a software.
we found that analyzing crash reports in an automated manner can help developers in fixing crashes by removingmanualanalysisburdenfromdevelopers orbyfinding propertiesthatwouldhavebeenreallydifficulttofindwithmanual analysis orcangivecluesinthecharacterizationofcrashes.software organizations can use these data mining techniques to speed upandsimplifytheresolutionofcrashesandtoreducetheamount ofmanual tediouswork for developers.
.
futurework weidentifiedtwointerestingdirectionsforfuturework.first as discussed in the validation section section with examples insection4.
.4and4.
.
theresultsofthecrashclusteringcangreatly affect the results of our tool.
thus improvements to the clustering algorithm used by socorro other than being useful by themselves wouldbenefit ourresults as well.second itcould beuseful to have adashboardtosimplifyfindingreproduciblecrashes.atmozilla we are often helped by volunteers in reproducing crashes that are specific to some configuration that we do not have readily available.thecorrelationresultsmightbeusefultocreateaway for volunteers to automatically find the crashes that they might be abletoreproduce byshowingthemthecrashgroupsthatarerelated to their hardware or software e.g.
installed addons antivirus etc.
configuration.