fastlane test minimization for rapidly deployed large scale online services adithya abraham philip ranjita bhagwan rahul kumar chandra sekhar maddila and nachiappan nagappan microsoft research abstract today we depend on numerous large scale services for basic operations such as email.
these services built on the basis of continuous integration continuous deployment ci cd processes are extremely dynamic developers continuously commit code and introduce new features functionality and fixes.
hundreds of commits may enter the code base in a single day.
therefore one of the most time critical yet resource intensive tasks towards ensuring code quality is effectively testing such large code bases.
this paper presents fastlane a system that performs datadriven test minimization .
fastlane uses light weight machinelearning models built upon a rich history of test and commit logs to predict test outcomes.
tests for which we predict outcomes need not be explicitly run thereby saving us precious testtime and resources.
our evaluation on a large scale email and collaboration platform service shows that our techniques can save .
i.e.
almost a fifth of test time while obtaining a test outcome accuracy of .
.
index t erms test prioritization commit risk machine learning i. i ntroduction o365 is a large enterprise collaboration service that supports several millions of users runs across hundreds of thousands of machines and serves millions of requests per second.
thousands of developers contribute code to it at the rate of hundreds of commits per day.
dozens of new builds are deployed every week.
testing such a large and dynamic continuous integration continuous deployment ci cd system at scale poses several challenges.
first and foremost a massive fully dedicated set of compute resources are required to run these tests continuously.
in spite of having such dedicated resources o365 s pipelines are often unable to keep up with testing all commits thoroughly.
several enterprise testing platforms suffer from this problem .
this is mainly because of a growing code submission rate and a constantly increasing testpool size.
as a result a large fraction of commits that could potentially contain bugs go untested.
a key approach to addressing this problem is to minimize the tests to run.
one can use several approaches towards this.
however with large ci cd systems such as o365 we identify a new opportunity big data storage and analytics systems are now ubiquitous.
modern day services use these systems to store and process detailed logs over extended time periods thereby deriving rich insights about every aspect of the system development life cycle most relevant to our problem are largescale commit logs and test run logs.
o365 s logs for instance reside on big data stores and we routinely analyze more than one year of test and commit data in the fastlane pipeline.
we therefore ask the following question can we make highconfidence data driven decisions towards test minimization?
in other words can we learn models and rules from past data that can guide more intelligent decisions on what subset of tests we need to run?
there has been a large body of prior work in the test prioritization selection and minimization areas .
more closely related to our work is the work by elbaum et al.
which prioritizes tests based on the probability of fault existence.
our work draws inspiration from prior published work but differs in several key ways as detailed below.
we analyzed o365 s commit and test logs in detail and made the following observations some commits are more likely to fail tests than others.
not all commits are created equal.
some commits make major changes such as changing the functionality of a network protocol.
other commits make tweaks to configuration files which may not impact core functionality at all.
some commits introduce completely new features to ui components while others may just make cosmetic changes to the ui.
this by itself is not a new finding prior work has found this to hold for large open source software repositories .
nevertheless our study helped us determine that it is indeed feasible to learn the complexity and therefore predict the risk associated with every commit.
several tests exercise the same or similar functionality.
several developers add test cases over time for the same codebase.
in many cases these tests may be redundant or at the very least related.
that is their code coverage is largely the same.
consequently we observe inter test correlations i.e.
the outcomes of various test pairs are heavily correlated.
several tests are combinations of smaller test cases whose outcomes are related.
such tests usually contain different code paths that evaluate similar or same functions leading to intra test correlations .
this emerges as a correlation between the test s outcome and its run time.
for instance a specific test used the same api call multiple times with slightly different parameters.
when the test fails it tends to fail at the first api call and therefore has a very short run time.
this emerges as a correlation between test failure and very short run times of the test.
based on the above observations we designed three different approaches towards predicting test outcomes and therefore saving test resources.
this paper makes the following contributions ieee acm 41st international conference on software engineering icse .
ieee authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
commit risk prediction since commits vary in complexity observation we learn classification models that predict the complexity of a commit and therefore the need to test it.
our model should predict that a commit that makes major changes is risky while a commit that makes a minor tweak is safe .
we can then use this label to test only risky commits while fast tracking safe commits to deployment.
we describe this in section iii b. test outcome based correlation since several tests have well correlated outcomes observation we learn association rules that find test pairs that pass together and fail together.
for each test pair we then need to run only one test since we can predict the outcome of the second with high confidence.
we describe this in section iii c. runtime based outcome prediction since some tests are amalgamations of related tests observation we use techniques derived from logistic regression to estimate a runtime threshold for these tests.
this threshold nicely separates passed runs from failed runs for each test.
we can then use this to stop these tests after they have run for the threshold time and predict their outcome as pass or fail .
we describe this in section iii d. integrated algorithm system design we describe an integrated algorithm that incorporates the above mentioned approaches into one control flow figure .
we have built a system called fastlane which incorporates this algorithm section iv .
while providing lightweight techniques fastlane also provides threshold tuning knobs which can be used to trade off test time saved with test prediction accuracy.
fastlane is implemented and integrated into o365 s pipelines section v .
evaluation we provide a quantitative evaluation of the above strategies on o365 s logs collected over a period of months.
we find that using such techniques we can save .
of test time while maintaining an accuracy of test outcomes at .
.
finally we provide findings from userstudies to understand the reasons why our techniques work in practice section vi .
to the best of our knowledge this is the first attempt to leverage code risk and test interrelationships using a black box machine learning based approach for test minimization on such large scale services.
our techniques are simple lightweight and generic.
they use well known machine learning and modeling techniques and so can be extended to other services as well.
ii.
o verview in this section we provide an overview of o365 s development processes.
we then describe our problem statement and provide an overview of our approach.
a. o365 o365 uses git as its version control system.
it sees about to code commits per day of which around to commits are tested .
a commit varies in complexity from a single line change in one file to major changes in hundreds table i example of the components modified by a commit and the test suites run .the three components modified are functionally different .h ence three test suites are run .
component modified test suite run src abc testcreatemessageapi src xyz testparseforminput src klm v alidatelogentry writelogfile even thousands of files.
the developer who creates the commit chooses one or more reviewers who review the commit.
after potentially multiple iterations with the reviewers the developer runs unit tests on their commit.
once these tests pass the developer runs functional tests on the commit.
our work concentrates on minimizing runs of functional tests since they are most time and resource intensive.
henceforth we use the term test and functional test interchangeably.
over time test engineers and developers have built a set of rules based on code coverage and their knowledge of which code files could affect a test.
these determine what set of functional tests to run on a given commit.
each rule maps a modified component to a set of test suites where a component is a subtree in the file hierarchy of the code base and a test suite is a group of related tests.
thus depending on the components that the commit modifies the system determines the tests suites to run.
table ii shows some example rules.
note that by design functional tests are independent of each other and therefore can be run in parallel.
the code base has around test suites.
each test suite consists of between to tests with an average of tests per test suite.
each test takes between less than second to more than seconds to run with an average run time of seconds.
.
of all tests pass.
on average every commit runs tests.
given this set up some commits can take almost hours to finish testing and be ready for deployment.
this extremely fast rate of development and large scale testing causes delays to commits from being deployed worldwide.
test resources i.e.
machines on which we run tests are limited.
the number of tests to run for a commit can be large and therefore it may take a long time for all tests running on a given commit to complete.
this motivates our problem and approach.
b. problem statement and approach given the problem explained at the end of ii a we ask the question can we decrease the amount of testing required while maintaining code quality?
there are various approaches to address this question.
a large amount of previous work targets the problem of test selection i.e.
how we can use code coverage metrics and static analysis techniques to prune the set of tests to run for a given commit .
such techniques can help us with the problem of test selection.
however the complexity and scale of o365 require us to use additional light weight techniques on top of traditional test authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
selection techniques to deal with the problem of minimizing test resource usage.
fortunately o365 uses big data systems to maintain logs that contain months of test run time data.
these logs hold detailed information on the set of tests run on every commit the time that each test took and the outcome of the test.
we therefore use a black box data driven approach to answer the above question.
we use machine learning on test and commit logs to learn models that predict the outcome of certain tests so that we do not have to explicitly run them thereby saving test resources and decreasing time to deployment.
to determine if such an approach is feasible we first analyzed a fraction of the test logs to find predictable patterns.
we make three observations based on this commit risk prediction commrisk not all commits are equal.
for instance a commit that changes or adds a feature to code is more likely to fail tests than a commit that makes simple changes to a configuration file.
we therefore use machine learning to determine what characteristics make a commit less risky or rather safe so that we can deploy it without any testing.
test outcome based correlation te s t co rr several developers work on the same code base and over time may create tests that are redundant or test very similar functionality.
consequently several test pairs either pass together or fail together.
such correlations exist mostly within a test suite but can also exist across test suites.
therefore for a test pair whose outcomes have been almost perfectly correlated in the past we run only one of the two tests and predict the outcome of the second with high confidence.
runtime based outcome prediction runp red developers often combine testing slight variations of the same functionality into a single test.
we found that for several such composite tests the amount of time they took to run was very well correlated with actual outcome.
these tests either fail instantly with the first variation of the functionality it tests failing or pass after a longer duration after testing all variations.
the difference in duration between passes and fails is even more pronounced when the functionality being tested is variations of the same api call as api calls tend to inherently take longer.
some tests display the converse behavior with tests passing early or failing after a long time.
we observed that such tests typically involve network calls and timeouts in the services they make the calls to result in their failing after a prolonged duration as opposed to a quicker run if all the calls go smoothly and they pass.
hence for such tests we predict outcomes after the test has run for a certain period of time that we call a runtime threshold .
iii.
a lgorithm in this section we first describe the log record history that we use in our analysis and predictions.
we then provide detailson how we learn rules for each of the three strategies outlined in section ii b. a. data our analysis uses two data sources test logs the o365 system stores test logs for months and we use the logs from this entire duration for our analysis.
each log entry contains information about a commit test pair it contains the start time of the test the end time of the test the host machine and the commit the test ran on and the test outcome.
the outcome can be either passed or failed .
commit logs o365 stores years of commit logs.
commit logs store information about each commit namely what time each commit was made the developer who made the commit the reviewers who reviewed the commit and the files modified.
b. commit risk prediction the objective of commit risk prediction is to determine at commit creation time whether it is risky or safe.
if it is safe we do not test the commit thereby saving test time and resources.
our approach is to use the test logs and commit logs to learn a classifier that labels a commit as risky orsafe .
to train the classifier we label commits in the following way a commit is risky if it causes at least one test to fail.
a commit is safe if all tests run on it pass.
we used a total of features to characterize commits.
table ii provides a brief outline.
we chose our features based on inferences derived in previous work and our own findings with o365 outlined below the type of change determines how risky it is.
we capture several features related to the files that a commit modifies or adds.
for instance we capture the number of files changed and file types changed.
we choose such features based on previous findings that certain types of file changes are more likely to cause bugs than others .
some components are riskier than others.
we use historybased attribution to determine code hotspots.
from past test runs for each component we measure a risk associated with a component i.e.
the fraction of times that a change within a component lead to a test failing.
the more often a file changes the more risky it is .
for every file we capture frequency of change in the last and months and since the creation of the file.
number of contributors to a file affects risk .
for each file we also leverage previous work on ownership to record the developers who are major and minor owners of the file and their percentage of ownership.
the features are calculated over the last and months and since the creation of the file.
developer and reviewer history we use features to capture developer experience and reviewer experience.
a developer who has recently joined the group may be more likely to introduce a bug.
similarly experienced reviewers will tend to find more bugs and weed them out at review time.
some developers or their teams may work authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
table ii as ampling of the fea tures used in commrisk and their definition feature sample definition features file type counts boolean variables per file type capture the set of file types that a commit changes.
change frequency maximum value over all files changed of the number of times a file is changed in the last months.
ownership maximum value over number of owners for each file changed.
developer reviewer history the number of commits made by the commit s developer so far.
component risk the fraction of times this component has been tested and has failed at least one test.
on inherently risky parts of code and have a greater chance of producing regressions while some reviewers review primarily risky code changes.
these features are calculated over the last and months and since the creation of the file.
most of the characteristics we capture such as change frequency are at the level of a file.
therefore to create commit level features we aggregate the file specific values using operators such as max average and median .
to train our model we used a total of features and a total of commits spanning year .
we test our model using months of data namely commits across the months of january and february .
we used several classifiers to evaluate our model.
table v shows the precision values for each classifier that we built.
we focus on precision in the case of commit risk because it is important to not allow any high risk change to slip into the deployment phase.
the fasttree algorithm a fast implementation of gradientboosted decision trees achieved good precision f1 score and auc values while remaining easily interpretable.
we therefore use it in our implementation.
we found that the most important features provided were the file types.
changes to .cs files and .xml files were much more likely to cause a test to fail than changes to a .csproj or a .ini file.
our findings from the user study described in section vi f explain this behavior.
apart from file types code hotspots and code ownership based metrics also added significantly to the accuracy of our model.
c. test outcome based correlation the second step in reducing test load is to correlate the outcome of various test runs over time.
we first describe some example reasons for the correlation and then outline our algorithm.
our investigation revealed that there are numerous pairs of tests that always pass or fail together.
we discovered the following reasons for these correlations the functionality covered by one test can be a finergrained version of another broader test.
one such actual pair we discovered is testlistsize100 and testlistsize .testlistsize100 tests the same functionality as testlistsize except the former test runs for list sizes greater than .
the test run logs show that all instances of these two tests either passed together or failed together.
in other words if the functionality works for sizesgreater than it also work with a smaller size.
thus testlistsize100 passing implies testlistsize must also pass.
two tests depend on the same underlying functionality.
one such example is testforwardmessage and testsaveaftersend both of which require the basic send email functionality.
if that common functionality is currently failing both tests fail together.
two tests may be redundant versions of each other .
since multiple developers work on the same large code base over time they may also create tests that are redundant or test tiny variations of the same functionality.
testentityupdate andtestentityrepair both tests performed the same actions but written as part of two different components by two different sets of developers.
algorithm describes the te s t co rr algorithm.
broadly te s t co rr has three steps.
first we filter the list of test pairs that we consider to contain only pairs that have run together at least times failed together at least times and passed together at least times line .
second for every test pair a and b we count the number of times they both passed or failed on the same commit.
if the ratio of this count to the count of all the times tests a and b ran together on a commit and test a passed or failed is greater than a confidence threshold ctoc we learn the rule test a passes fails test b passes fails lines .
fastlane sets ctocto the relatively high value of .
.
our approach towards finding correlated tests is therefore deliberately conservative.
within the o365 dataset in total we found testpairs.
this number seems surprisingly large at first glance but given the scale of the system it seems quite natural to find tests that validate a subset of another test s functionality or depend on some common service.
an alternative approach would be to use rule mining algorithms such as apriori to discover not just test pairs but larger clusters of tests that pass and fail together.
however these algorithms are slow and in fact any cluster of ntests will be represented by parenleftbign parenrightbig rules of size .
hence we use the lightweight pairwise approach outlined above.
d. runtime based outcome prediction in this section we outline the runp red algorithm described in algorithm .
first for each test t we use techniques derived from logistic regression to identify the duration where the log likelihood of separation between failures and passes authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
algorithm te s t co rr rule generation algorithm.
input t tests run in training period ctoc confidence threshold output rules initialization rules for every pair of tests ti tjintwhere i negationslash jdo letri jbe commits where both tiandtjwere run letpi jbe commits where both tiandtjpassed letfi jbe commits where tiandtjwere both run andtipassed if ri j 50orpi j 20orfi j then continue end if letpass fraction i j pi j fi j if pass fraction i j ctoc then add ti tj t orules end if end for return rules is maximized line .
we call this duration the runtime threshold for the test t o r t r. second we check if this threshold achieves a good separation between failed and passed test runs for the test t. our definition of a good separation is that the precision on the training data should be greater than or equal to a precision threshold crop lines .
if so we learn a runtime threshold for that test lines and .
if the precision is lower than the threshold we do not learn any rules for this test.
algorithm runp red rule generation algorithm input t tests run in training period crop precision threshold output rules pass rules fail initialisation rules pass rules fail for every test tintdo let t r duration where log likelihood is maximized letpt runs where t s run time ct randt passed letft runs where t s run time ct randtf a i l e d letpp t pt pt ft letfp t ft pt ft if pp t crop then add t t r t orules pass end if if fp t crop then add t t r t orules fail end if end for return rules pass rules fail iv .
s ystem design in this section we describe how fastlane integrates all three approaches into a single system design.figure shows a flow graph that captures the way we integrate our models.
the process can broadly be divided into two stages.
first fastlane continuously learns and updates models using the three approaches described in section iii box shown in blue .
second as and when developers make commits fastlane applies these models on the commits so that we can reduce the amount of testing required boxes shown in green .
when a developer makes a commit the system uses the model that commrisk learned to determine if this commit is safe step .
if not the system determines the tests to be run on the commit using the component to test case mapping described in section ii a. next the system uses the rules that te s t co rr learn to determine test pairs for which only one test needs to be run step .
for each applicable rule fastlane picks the test that has the lower average run time and runs it.
based on its outcome fastlane infers the outcome of the second test.
finally the system applies runp red i.e.
the system monitors the run time of each test and if this is above the pre determined threshold it stops the test and predicts its outcome step .
we now describe step in figure .
sometimes our models may make incorrect predictions.
moreover code functionality and tests can change over time.
hence we need to continuously retrain and update our models.
therefore the system runs a fraction of all tests for which fastlane made predictions in the background.
the administrator determines the value of this fraction.
by running these tests in the background and off the critical path we make more judicial use of our test resources.
by comparing the actual results of the runs with the outcomes predicted by the models fastlane continuously validates and updates the models and their rules to be consistent with the current state.
while commrisk te s t co rr and runp red are generically applicable to other systems as well we recognize that some are easier to apply than others.
not running tests on a safe commit is easy to incorporate into any test process.
incorporating runp red on the other hand may not be easy because this requires constant monitoring of test runtime and also the ability to kill a test after the run time threshold is reached.
we therefore evaluate all three strategies independently as well and leave it to the service administrators to determine which combination of the strategies can be practically deployed in their environment.
v. i mplementa tion we have implemented fastlane with a combination of c using .net framework v4.
sql and a custom query language.
we use the ml.net library to build our machine learning models and evaluate them.
currently the implementation is approximately lines of code.
since fastlane requires information about various different entities commits developers reviewers and tests a significant part of our implementation are data loaders for these different types of data.
we implemented loaders for various source control systems such as git and others internal to our authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
fig.
.
the integrated algorithm and fastlane test prediction flow.
this includes all three types of predictions fastlane performs green boxes .
commit risk prediction .
test outcome based correlation and .
runtime based outcome prediction.
the blue box captures the learning functionality used to continuouslytrain fastlane.
organization.
these loaders ingest source code code versions and commit histories and store this data in a normalizedfashion in an sql database.
test logs on the other hand are stored in our organization s proprietary big data storagesystem.
fastlane s source data loaders and test log analyses run once a day.
during the learning phase the commit risk prediction model runs on commits which including file and code review information is approximately mb ofdata.
this takes around minutes.
test logs on the otherhand are .
tb in size.
fastlane takes hours to learnrules for test outcome based correlation and hour to learnrules for runtime based outcome prediction.
vi.
e v alua tion in this section we first explain the data being used in the evaluation of fastlane.
next we describe our evaluationof how effective each of the three techniques are.
finally we show the effectiveness of putting all three techniquestogether.
to measure how effective fastlane is we answerthe following questions how well does each technique perform as compared to a random model?
how much test time does each technique save while maintaining accuracy?
how much test time does fastlane save when we put all three techniques together?
a. data setup table iii summarizes our data logs.
our data broadly consists of two types of logs commit specific and test specific.our commit specific data consists of commits madefrom jan to feb to the o365 code base.
we use test logs from test runs made between jan and feb .
our test log dataset contains around 1000test suites.
each test suite contains around to tests onaverage and the total number of individual tests is .the total number of test runs over the entire time period is63 .
of these test runs failed and 979passed.
these fail and pass counts exclude test runs whosetable iii summarizing our test and train data training data log type duration size rows commit jan to dec .
mb test jan todec .
tb test data log type duration size rows commit jan tofeb .
mb test jan tofeb gb outcomes are neither passes nor fails such as not run and missing which occur due to errors or resource constraints inthe internal testing infrastructure.
for each test run we recordthe start time end time and test outcome.
we use data between jan and dec to train our models and data from jan and feb to evaluatethem.
we believe this approach is more suitable than standard cross validation because system properties change with time.
as shown in section iv we continuously learn and up date our models.
therefore the suitable approach to evaluationis to train our models using past data and test on more recentdata.
b. commit risk prediction to evaluate commrisk we calculate the metrics defined in table iv.
the safe precision p safe tells us what fraction of commits thatcommrisk classified as safe are actually safe while the risky precision p risky tells us what fraction of commits commrisk classified as risky are actually risky.
we trained our model using various classifiers.
table v summarizes their performance.
note that the f1 score and auc for all models are comparable.
fastlane uses fasttree as theinterpretability of the decision trees allows us to reason about authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
table iv metrics used in our ev alua tion of commrisk .text in parentheses rpass and rfail apply to te s t co rr and runp red metric definition tp true positivessafe commits passed tests classified as safe passed tn true negativesrisky commits failed tests classifiedas risky failed fp false positivesrisky commits failed tests classifiedas safe passed fn false negativessafe commits passed tests classifiedas risky failed psafe ppass safe pass precisiontp tp fp prisky pfail risky fail precisiontn tn fn rpass pass recalltp tp fn rfail fail recalltn tn fp fts time saved fractionrun time of predicted tests total time to run all tests fig.
.
auc for the commrisk model.
the model s predictions.
we set the number of trees learned to .
we now probe a little deeper into the performance of fasttree.
the area under the roc curve auc seen in figure 2is .
which is significantly higher than the baseline thata random classifier would obtain which is .
.
also a modelwith an auc greater than .
for a given classification problemis considered suitable to use for that problem .
this showsthat our classifier is very effective at predicting whether acommit will cause tests to fail risky or not safe .
ultimately though we are interested in the amount of test run time our model saves.
this is a function of the number ofcommits we label as safe the more commits our model labelssafe the more time we save since we do not run tests onthese commits.
however labeling a larger number of commitsas safe may also mean that we potentially miss testing riskycommits.
to investigate this trade off we now translate theoutput of the model to fraction of time saved or f ts.
for this we determine the time to run all tests on all commits in ourtest set that we predicted are safe.
we then calculate this as afraction of total time required to run all our tests in the test set.we then plot this as a function of safe precision.
figure shows how f tsvaries with safe precision.
this fig.
.
safe precision time saved graph for the commrisk model.
curve shows that we can save .
of test time while achiev ing .
pass precision.
note that this is at the commit level as opposed to the test case level.
the pass precision of commrisk at the test case level is .
and its overall accuracy on the system is .
as seen in table viii.this overall accuracy takes into account not only the testscommrisk predicts will pass and should not be run but also the tests commrisk chooses to run for commits it deems risky thereby obtaining the correct outcomes for those tests.
c. test outcome based correlation we now evaluate how te s t co rr performs.
the metrics used in this evaluation are the same as those used in table iv except instead of commits being classified as safe orrisky it is now test outcomes that are classified as pass orfail respectively.
so safe and risky precision are now referred toas pass and fail precision.
we also introduce two new metrics pass recall r pass and fail recall r fail .
as part of our sensitivity analysis we varied the value of ctoc confidence threshold defined in section iii c between and .
to evaluate different points in the design space.
aswe reduce the value of c toc we expect to find more correlated test pairs using algorithm .
this implies we have more rulesto apply and will therefore save more test time.
however thismay also decrease our precision values since rules learnedat lower c tocvalues are inherently less confident than rules learned at higher ctocvalues.
table vi shows this effect quantitatively.
we also evaluated a random straw man for the same value of time saved i.e.
f ts and present its precision and recall numbers.
as we decreased ctocfrom to .
we noticed that pass precision ppass decreases while ftsincreases.
this is as expected.
however the fail precision p fail initially increases asctoc is reduced and reaches its peak when ctocis at .
.
this is counter intuitive as we expect less confident rules to be lessprecise.
however the number of test failures predicted are ofthe order while the number of test passes predicted are of the order so fail precision is more prone to random effects than pass precision.
this imbalance in number of predictionsis a reflection of the low percentage of test runs which fail asdiscussed in the overview of our data in section v. after discussions with product groups we settled on .
as thec tocvalue for our model which provides the desired trade414 authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
table v performance of different classifiers for commit risk prediction model psafe prisky f1 score auc logistic regression .
.
.
.
linear svm .
.
.
.
binary neural network .
.
.
.
local deep svm .
.
.
.
xgboost .
.
.
.
fasttree boosted trees .
.
.
.
table vi te s t co rr results show how the fraction of time sav e d fts v aries with pass precision ppass for different values of confidence threshold ctoc ctoc fts rules ppass fastlane ppass random pfail fastlane pfail random rpass rfail .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
off between time saved .
and precision .
.
note this value can be tuned for any service as desired by the administrators.
overall accuracy on the system as defined at the end of section vi b and seen in table viii is .
.
d. runtime based outcome prediction finally we evaluate the runp red technique.
we use the same metrics used in section vi c in this evaluation.
in this case we perform our sensitivity analysis by varying the value of the precision threshold crop as defined in section iii d to determine how the precision and recall values are affected as we make more aggressive predictions.
table vii shows that we can save .
of time while maintaining .
pass precision when crop is which is the threshold we chose based on discussions with product groups.
again depending on system requirements fastlane can tune the crop value to either save more time or improve pass precision.
overall accuracy on the system when cropis as defined at the end of section vi b and seen in table viii is .
.
e. overall gains finally we show how the models perform when we apply them to our data in different combinations.
as seen in table viii fastlane saves .
of test time when it combines commrisk te s t co rr andrunp red as described in section iv while maintaining an overall accuracy of .
.
the table also shows how much time fastlane saves when it uses other combinations of the three techniques.
for instance suppose an administrator decides to use only commrisk .
she will still save .
of test time.the other point to note here is that the savings of commrisk and te s t co rr are fairly independent of each other.
individually they save .
and .
test time respectively.
if the set of tests they predicted outcomes for were completely disjoint they would have saved .
test time.
in reality they save .
together which is only .
lower.
similarly savings from commrisk and runp red are independent too.
the sum of their savings is .
while combined they save .
very close to the sum.
on the other hand te s t co rr andrunp red have a larger common set of tests that they predict outcomes for.
combined they save .
only .
more than te s t co rr alone.
this may suggest that for o365 te s t co rr largely subsumes runp red .
however this need not be true since te s t co rr and runp red are very different techniques.
first in a different environment or as the system evolves with time runp red may save on a disjoint set of tests.
second testers in different environments may find that runp red is a more acceptable technique than te s t co rr since te s t co rr does not run the test at all and is therefore more aggressive whereas runp red makes predictions after starting the test.
f .
user study we performed a user study to help confirm the validity of our models and understand why each of our approaches works.
we reached out to developers roughly for each technique and asked them whether the predictions by fastlane was correct or not if yes why and if no why not?
of the developers responded to the study.
in this section we summarize their comments.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
table vii runp red results show how the fraction of time sav e d fts v aries with pass precision ppass for different values of precision threshold crop crop fts tests predicted ppass fastlane ppass random pfail fastlane pfail random rpass rfail .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
table viii overall gains of using different combina tions of commrisk te s t co rr and runp red when combined as described in section iv model fts tests predicted accuracy predicted accuracy overall commrisk .
.
.
.
t estcorr .
.
.
.
runp red .
.
.
.
commrisk t estcorr .
.
.
.
commrisk runp red .
.
.
.
t estcorr runp red .
.
.
.
commrisk testcorr runpred .
.
.
.
commit risk prediction modifications to .csproj files were often simple dependency updates and errors in these changes would be detected at build time without the need for testing.
also changes to .ini files tended to enable an older existing feature for different user groups.
since the feature was introduced earlier it had already been tested and changes to the .ini files could be checked in without testing.
these reasons were mostly captured by our file specific features described in section iii b and table ii.
test outcome based correlation many tests test the same functionality in very similar ways.
some tests fail together due to outages in a service that both tests depend on for instance if both tests used a specific database setup.
also tests fail together if they have similar setup processes if the setup for one test fails the other one will fail too.
these findings are in addition to the reasons for correlation that we stated in section iii c. runtime based outcome prediction the difference in durations of pass and fail runs were seen primarily in tests that make network calls.
several such test cases validate rest apis and start by fetching initial metadata about the rest service or connect and make requests to a database.
these requests tend to fail if the service is down or go on to pass the test after making several time consuming calls.
the test environment being polluted by other tests is another reason for early failure.
vii.
t hrea ts tovalidity a. external v alidity generality of our approach while fastlane has shown the applicability of our techniques on o365 s logs we believe these techniques are univer sally applicable to any large service that uses a ci cd pipeline as long as we have rich logs of test and commit history.
the properties we observe and build upon commit risk prediction inter test correlation and intra test correlation are inherent to several large scale software development processes .
moreover all our approaches use generic machine learning and statistics techniques that do not make use of any specific properties or characteristics of o365.
b. internal v alidity prior work has investigated the problem of flaky tests and these could affect the validity of our models and rules.
o365 has several flaky test detection mechanisms that use similar techniques as explored in previous work.
we therefore apply these detection mechanisms prior to running our prediction model to avoid losing accuracy.
we also recognize that a trade off exists between maintaining high precision and time saved.
to that end we provide test administrators with various knobs for each of our techniques which can be tuned to obtain the time saved versus precision trade off that suits their needs best.
for instance fastlane uses te s t co rr with a correlation requirement of .
an administrator can dial this up to if they want to minimize missing failures.
in the case of o365 this decreases our timesaved from .
to .
table vi .
on the other hand they can turn this down too if they can accept a lower level of pass precision.
viii.
r ela ted work prior work has addressed problems related to defect prediction test selection minimization and test log analysis.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
in this section we discuss these three aspects in the context of fastlane.
a. defect prediction the features that we use in our commit risk prediction module have been derived from a vast body of previous work in the field of software defect prediction.
zimmermann et al.
have shown that defects can be attributed at component or file level .
our commit risk predictor therefore uses file level and directory level risk as features.
past research has also shown that process level features are more effective at predicting software defects than code level features .
we therefore use such process level features in commrisk .
basili et al.
investigated the ability of the classic ck objectoriented design metrics to predict fault proneness .
additionally nagappan et al.
have shown how code churn correlates with field failures.
jaafar et al.
investigating the effect of time found that classes having a specific lifetime model are significantly less fault prone than other classes and faults fixed by maintaining co evolved classes are significantly more frequent than others.
we use similar approaches in our analysis as well investigating changes based on when they happened and also learning from churn based features.
bird et al.
have shown that code ownership or the lack thereof has a direct correlation with software defects.
our learner therefore also uses ownership based features.
our work takes inspiration from this vast body of work to develop suitable input features and builds upon it with our specific application in mind test minimization and resource savings.
therefore we use commit risk prediction as a tool towards test minimization.
moreover fastlane does not derive its definition of risk from field level bugs and reports but rather from test failures.
b. test minimization a large body of work concentrates on the problem of test selection and minimization .
in their seminal work rothermel et al.
use several techniques for using test execution information to prioritize test cases for regression testing by ordering test cases based on their total coverage of code components ordering based on the coverage of components not previously covered and ordering based on their estimated ability to reveal faults.
the techniques studied improved the rate of fault detection of test suites.
elbaum et al.
advance this further and show that fine granularity techniques outperformed coarse granularity techniques by a small margin.
using fault proneness techniques produced relatively small improvements over other techniques in terms of rate of fault detection and in general the effectiveness of various techniques can vary significantly across target programs.
v ahabzadeh et al.
have recently proposed a technique that uses code instrumentation to analyze and remove fine grained redundancy within tests.
these techniques mostly rely on code coverage as the main criterion.
while effective applying them continuously as code and tests change can be a heavyweight process andnot easily applicable to large dynamic software code bases such as o365.
fastlane on the other hand uses lightweight machine learning based techniques to perform test minimization.
moreover fastlane unlike previous work gives us the ability to tune thresholds at runtime depending on our accuracy requirements we can turn fastlane s thresholds to achieve different time accuracy trade offs.
finally previously proposed techniques based on code coverage can generate the list of tests that are input to fastlane.
thus the two techniques can be used in tandem to obtain better test minimization.
it is also important to note that fastlane differs from work on code execution classification which tries to classify the outcome of a program execution as a pass or fail after it has completed while fastlane predicts the outcome of a test before it has completed.
from an industrial stand point in recent work at google the authors empirically leverage the relationship between google s code test cases developers programming languages and code change frequencies to improve google s ci and development processes.
they find that very few tests fail and those failures are generally closer to the code they test and frequently modified code breaks more often.
we use similar churn and test execution metrics in our analysis.
work at microsoft describes echelon a test prioritization system that works on binary code to scale to large binaries and to enable the testing of large systems like windows.
echelon utilizes a binary matching system that can compute the differences at a basic block granularity between two versions of the program in binary form to prioritize tests.
all such techniques can be used in tandem with fastlane.
c. test log analysis andrews first investigated the use of log files for testing presenting a framework for automatically analyzing log files and defining a language for specifying analyzer programs.
the language permitted compositional compact specifications of software for unit and system testing.
recent work has analyzed test logs and described the correlation between test failures and the closeness of code changed and frequency of code change .
however our concentration is on analyzing tests logs and using such insights to effectively save test time.
ix.
c onclusion fastlane is a system that saves test time in large scale service development pipelines.
it uses machine learning on large volumes of logs to develop accurate models that predict test outcomes.
with a combination of commit risk prediction test outcome correlation and runtime based outcome prediction we show that for a large scale email and collaboration service fastlane saves .
of test time while ensuring a test outcome accuracy of .
.
x. a cknowledgements we would like to thank rob land daniel guo b. ashok sumit asthana chetan bansal and sonu mehta for their valuable suggestions and help building and evaluating fastlane.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.