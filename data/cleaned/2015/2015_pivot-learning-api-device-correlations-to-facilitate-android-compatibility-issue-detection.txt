pivot learning api device correlations to facilitate android compatibility issue detection lili wei yepang liu shing chi cheung dept.
of computer science and engineering the hong kong university of science and technology hong kong china shenzhen key laboratory of computational intelligence southern university of science and technology shenzhen china email lweiae cse.ust.hk liuyp1 sustc.edu.cn scc cse.ust.hk abstract the heavily fragmented android ecosystem has induced various compatibility issues in android apps.
the search space for such fragmentation induced compatibility issues ficissues is huge comprising three dimensions device models android os versions and android apis.
fic issues especiallythose arising from device models evolve quickly with the frequentrelease of new device models to the market.
as a result anautomated technique is desired to maintain timely knowledge ofsuch fic issues which are mostly undocumented.
in this paper we propose such a technique p ivot that automatically learns api device correlations of fic issues from existing android apps.
pivot extracts and prioritizes api device correlations from a given corpus of android apps.
we evaluated p ivot with popular android apps on google play.
evaluation results show that p ivot can effectively prioritize valid api device correlations for appcorpora collected at different time.
leveraging the knowledge inthe learned api device correlations we further conducted a casestudy and successfully uncovered ten previously undetected ficissues in open source android apps.
index t erms android fragmentation compatibility static analysis learning i. i ntroduction the android market is highly dynamic.
to maintain market competitiveness android device vendors keep releasing new models running customized os with unique features.
as aresult a lot of device models with different customized osversions are available at the same time in the market makingthe android ecosystem heavily fragmented.
compatibility is sues induced by android fragmentation have been recognizedas a critical challenge in android app development .
these f ragmentation induced compatibility issues fic issues for short can cause android apps to exhibit inconsistent behavior across different devices.
fic issues canbe categorized into two types non device specific ones anddevice specific ones .
fic issues are non device specific if they can be triggered on any device model running a particularandroid version which is denoted by an integer e.g.
forandroid .
known as an api level.
fic issues are devicespecific if they can only be triggered on certain device models running particular api levels.
compared with non device specific ones the search space for device specific fic issues ismuch enlarged with an additional dimension of device models.hence device specific fic issues are more difficult to detect.
yepang liu is the corresponding author of this paper.we make two observations on device specific fic issues.
first their search space is large consisting of three dimen sions device models api levels and android apis.
there are distinct device models running differentapi levels in the market .
each api level supportsthousands of apis.
detecting such fic issues by checking ifeach combination of device model api level and invoked apican induce inconsistent app behaviors is practically infeasible.second the search space is dynamic.
it continually evolveswith the release of new device models and api levels.
forexample the number of distinct device models in wassix times as many as in .
in addition there havebeen two or more api level upgrades each year which arecommonly customized by android device manufacturers andshipped with new device models.
detecting device specificfic issues in such a huge and evolving search space ischallenging.
therefore developers often realize the existenceof fic issues only after receiving users complaints.
the observations motivate us to study how to automatically extract the knowledge of fic issues which can then beleveraged to effectively reduce the search space for ficissue detection.
in this paper we focus on device specific fic issues.
these issues are common but challenging toresolve .
while resources provided by google e.g.
api guide and emulators can help developers locateand patch non device specific fic issues no similar resourcesare provided for device specific fic issues.
the root causesof device specific fic issues often reside in the proprietarysystems customized by the device vendors.
these systems aretypically closed source with little public documentation.
several solutions have been proposed to address fic issues but few of them tackled the problem of extracting theknowledge of fic issues to reduce fic issue search space.khalid et al.
lu et al.
and vilkomir et al.
proposed techniques to prioritize the device models for testingandroid apps.
however these prioritization techniques mainlyconsider the properties of device models but do not correlatethe device models with fic issues.
fazzini et al.
proposed d iffdroid to identify gui inconsistencies of android apps when running on different platforms.
d iffdroid focuses on the oracle problem i.e.
how to determine the existence of ficissues.
it does not address the search problem of fic issues.
in our previous work we found that fic issues are commonly caused by invoking specific apis on ieee acm 41st international conference on software engineering icse .
ieee authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
specific devices.
in other words fic issues mostly correlate issue inducing apis with affected device models .
leveraging this finding a static analysis technique f icfinder w a s proposed to locate callsites of apis that can induce fic issues on affected device models.
f icfinder takes predefined api device correlations as input for issue detection.
in the previous work the api device correlations were manually extracted from an empirical study.
however this manual approach is impractical because the fic issue search space evolves quickly.
it requires tremendous efforts to manually keep track of api device correlations of fic issues that continually arise from new device models.
on the other hand li et al.
proposed a technique to analyze android framework revision histories to learn patterns of fic issues caused by android framework evolution.
their technique relies on the open source android framework code.
however device specific fic issues the target of this paper mostly arise from closed source systems customized by device vendors.
without source code li et al.
s technique is inapplicable.
in this paper we propose a technique called p ivot apidevice c orrela tor to automatically learn the knowledge of device specific fic issues in terms of api device correlations from existing android apps.
in the remaining part of this paper we will refer to device specific fic issues asfic issues for ease of presentation unless specified otherwise.
our insight is that fic issues are commonly handled by exercising an alternative execution path if the running device matches an issuetriggering model.
in other words the handling of a fic issue usually involves a condition that checks device information at runtime.
an example of such conditions is given in line of figure where nexus is the issue triggering model and lines provide an alternative execution path.
based on this insight p ivot extracts api device correlations such as angbracketleftparameters .setrecordinghint boolean nexus angbracketrightby identifying the device checking conditions and the api invocations guarded by them.
such learned knowledge can then be leveraged to facilitate fic issue testing or infer rules patterns to pinpoint fic issues in android apps via static analysis.
pivot extracts api device correlations of fic issues from a given android app corpus and prioritizes the extracted correlations based on their likelihood to capture real fic issues.
an outstanding challenge is to find valid api device correlations from massive noises.
in our evaluation the noises account for of our sampled api device correlations extracted from popular android app corpora.
existing techniques in api precondition mining remove noises based on the assumption that most api usages in code corpora are correct i.e.
mistakes are rare .
however this assumption does not hold for apis that can induce fic issues due to two phenomena.
first since fic issues continuously evolve lots of fic issues especially the new ones are likely left undetected in android apps.
second common code clones and library usages across android apps can confuse the mining of fic issues based on frequency.
these cloned code snippets can be duplicated in many apps .
these two phenomena can introduce noises that greatly affect the learning accuracyof fic issues.
to address this challenge we devise a novel ranking strategy to prioritize extracted api device correlations based on the likelihood that the analyzed apps have handled the corresponding fic issues and the diversity of the originating occurrences of api device correlations.
we implemented p ivot on soot and ran it to learn api device correlations from two app corpora each of which comprises over top ranked apps on google play collected at different time.
p ivot achieved a precision of among the top five ranked api device correlations and over precision among the top ten for both of the corpora.
it also successfully identified distinct and valid apidevice correlations capturing different fic issues among the top ranked api device correlations.
we built an archive accordingly.
it comprises the api device correlations learned by p ivot and the corresponding discussions collected from online resources.
the issue archive is publicly available to android developers and is expected to grow in future.
to show the usefulness of our learned api device correlations and the issue archive we conducted a case study and encoded the knowledge of the fic issues learned by p ivot in a state of the art fic issue detection tool to locate undetected issues in open source android apps.
we successfully found ten apps that suffer from these fic issues.
we further reproduced and reported our detected issues to the app developers.
so far seven reported issues have been acknowledged among which four issues have been quickly fixed.
this demonstrates that the api device correlations learned by p ivot can be used to facilitate fic issue detection for android apps.
to summarize we make three major contributions in this paper we proposed and implemented the first technique to learn api device correlations from existing android apps and showed that such api device correlations can be used to facilitate fic issue detection for android apps.
we devised a new ranking strategy that can effectively identify valid api device correlations capturing real fic issues.
our evaluation results show that this strategy can significantly outperform traditional ones.
we archived the fic issues identified by p ivot .
with the archive we conducted a case study and successfully revealed previously unknown fic issues in ten android apps many of which were confirmed or fixed by the app developers.
ii.
p roblem formula tion m otiv a tion a. fic issue pattern api device correlations the f icfinder work found that fic issues demonstrate patterns they often arise when certain apis are invoked on certain device models.
we observed that although ficfinder successfully detected previously unknown fic issues its major limitation is that the patterns used for fic issue detection were manually extracted from an empirical study.
as the android ecosystem evolves the applicability of these once effective issue patterns gradually diminishes.
for example among the issue patterns used by f icfinder are authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
now outdated because the device models that can trigger the issues have faded out from the market.
this inspires us to develop a sustainable mechanism to keep the knowledge of fic issues updated with respect to the evolution of android ecosystem.
we note that companies of popular commercial apps are likely to notice and patch fic issues in their apps early once new issues emerge because of their large user base and rich maintenance resources.
we therefore propose to learn api device correlations from these high quality commercial android apps to maintain a knowledge base of fic issues.
the learning leverages an observation that fic issues are mostly patched by applying workarounds on specific device models .
these workarounds often comprise a conditional statement that checks the runtime device information e.g.
the device model identifier against predefined values mostly constants .
the runtime device information can be obtained by querying the android.os.build class provided by the android sdk.
such conditional statements characterize the existence of code snippets that handle fic issues.
for illustration we show a code snippet that handles a low frame rate issue in camera preview on nexus in figure .
when invoking the camera api on nexus to take photos the default frame rate for photo preview is low frames per second making the preview choppy.
the patch applies a workaround specifically for nexus by setting the recording mode hint to true.
at line the code checks the app s runtime environment.
if the device model is nexus the workaround is applied lines .
from this example we observe that the conditional statement line encapsulates the information of the device model nexus that can trigger the fic issue.
the api call line that is dependent on the conditional statement demonstrates a strong correlation with the fic issue.
by identifying such conditional statements and api calls that are dependent on the conditions we can recover api device correlations to characterize fic issues .
to learn api device correlations p ivot formulates each correlation as a pair of an api and an identifier for a device model device identifier for short .
in this paper we focus on learning api device correlations for android sdk apis rather than apis of third party libraries.
the device identifier of a correlation describes an issue triggering device model such as the name of the model or the manufacturer.
in figure the api setrecordinghint depends on a conditional statement that checks the device identifier against nexus .
in such a case p ivot will derive an api device correlation angbracketleftparameters .setrecordinghint boolean nexus angbracketright.
note that p ivot does not assume that the apis in api device correlations are issue inducing.
they can also be issue fixing ones such as the setrecordinghint in our example.
currently p ivot does not include api levels in the extracted api device correlations.
this is because we found that it is uncommon .
to check both device models and api levels in the code snippets that handle fic issues according to a previously published fic issue dataset .
the underlying reason may be that many devices operating system rarely gets major updates after the devices are shipped.
as a result .
.
.
.
.
.
.
.
.camera mcamera camera.
open camera.parameters params mcamera.getparameters ... if build.
model.equals nexus params.setrecordinghint true ... mcamera.setparameters params mcamera.startpreview fig.
.
patch for camera preview frame rate issue on nexus most fic issues can be patched without checking api levels.
therefore we include only the information of apis and device models in our api device correlations.
b. application scenarios of api device correlations api device correlations can help reduce the search space of fic issues and save testing efforts.
for example the api device correlation extracted from figure suggests the existence of a fic issue when using the camera of a nexus .
with such information developers can focus on testing the app components that use cameras on nexus .
this can help trigger the fic issue quickly.
otherwise triggering the issue would require developers to extensively test their apps on a huge number of different devices.
let us analyze the reduction of testing efforts.
assume that developers carefully test their apps using amazon device farm a widely used online testing platform providing over device models including nexus .
according to an existing study a popular android app contains entry methods on average.
then app developers may need to test combinations of entry methods and device models to trigger the issue.
such testing efforts are unaffordable for most development teams.
as a result fic issues would likely be left undetected in the released apps.
comparatively knowing the correlation between android camera apis and nexus developers can focus on testing a few entry methods that involve camera apis on nexus to expose potential fic issues before releasing their apps.
api device correlations can also be analyzed to derive rules to automate fic issue detection and patching.
let us consider the example in figure again.
from the api device correlation angbracketleftparameters .setrecordinghint boolean nexus angbracketright we can infer that android camera apis may induce fic issues on nexus .
we can also infer that a possible patch is to invoke setrecordinghint and set the flag to true .
we can further validate the observations by checking relevant resources online.
for example by a search on google we can find concrete evidence e.g.
showing that camera apis indeed can cause fic issues on nexus .
via such analyses we can build a knowledge base of fic issues containing their patterns and high quality patches.
the issue patterns can be used as inputs to compatibility analysis tools such as f icfinder .
the issue patches can serve as templates to help fix fic issues and support future research on automatically repairing fic issues.
to show the feasibility of this application scenario in our evaluation section iv b we derived five fic issue patterns based on learned api device authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
public boolean onkeyup intkeycode keyevent event if keycode keyevent.
keycode menu islge log.
i tag applying lg workaround openoptionsmenu return true app specific code cloned from vlc view v getcurrentfocus ... return super .onkeyup keycode event public boolean islge return build.
manufacturer .compareto lge protected void oncreate bundle savedinstancestate log.
i tag activity created ... .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
fig.
.
patch for a crashing fic issue on some lg devices correlations.
with these issue patterns f icfinder detected ten previously unknown fic issues in popular open source android apps.
for instance with the nexus camera issue pattern f icfinder detected three new issues.
the developers also quickly fixed these three issues according to our suggested patch i.e.
invoking setrecordinghint .
c. motivating example overview options menu crash issue on lg devices.
figure shows a code snippet handling an infamous crashing fic issue triggered by pressing the physical menu button on some lg devices if the corresponding options menu is customized.
the lg s solution lines helps avoid app crashes by explicitly opening the options menu line rather than calling the onkeyup method of the super class.
with the example we now illustrate the major steps and challenges in learning valid api device correlations from an android app corpus.
step extracting api device correlations.
api device correlations can be extracted by identifying the conditional statements that check device information and the apis guarded by these statements.
we call these statements device checking statements .
a device checking statement and its guarded api calls may reside in different methods.
as shown in figure the device checking statement resides in the method islge line while its guarded api call openoptionsmenu resides in the method onkeyup line .
therefore extracting api device correlations requires inter procedural analysis.
to capture these correlations p ivot first builds an inter procedural control flow graph for an android app and then traverses the graph to identify the device checking statements as well as the api calls depending on them.
step filtering noises.
api device correlations extracted in the first step contain massive noises because apis that are irrelevant to fic issues may also be guarded by device checking statements as part of app specific logic.
for example the api log.i is invoked when the condition manuf acturer equals lge is satisfied.
the api is called for profiling purpose but the inter procedural analysis in the first step would generate a noisy api device correlation angbracketleftlog.i lge angbracketright which is unrelated to any fic issues.
according to ourexperiments section iv of our sampled api device correlations generated by the first step are noises.
filtering such massive noises is a major challenge in learning valid api device correlations from android apps.
existing api usage mining techniques cannot effectively help filter such noises due to two reasons.
we explain the reasons and present the intuitions of p ivot s solution below.
huge and evolving fic issue search space.
the existing api usage mining techniques assume that the majority of api usages are correct and adopt conventional statistical metrics i.e.
confidence or support .
however this assumption may not hold for api device correlation learning.
since the search space of fic issues is huge and evolving in practice fic issues are commonly left unhandled in released apps.
as such many valid api device correlations especially those related to new fic issues are not subject to high confidence or support.
we observe that the confidence of an api device correlation within an app helps distinguish valid and noisy correlations.
the intuition is that within the same app the apis irrelevant to fic issues can be invoked at various places without device checking statements.
callsites of apis related to the same fic issues are often guarded by device checking statements.
figure contains an example the irrelevant api log.i invoked at line which is guarded by a devicechecking statement is also invoked in another method of the app without any device checking statements line .
this observation helps distinguish apis that are relevant to fic issues from irrelevant ones.
therefore we propose a metric inapp confidence that computes how often an api s invocation is guarded by a specific device checking statement in an app.
as illustrated this metric helps identify irrelevant apis that are also often invoked without checking device information.
code clones in android apps.
simply ranking apidevice correlations by in app confidence and the frequency of an correlation s occurrences is insufficient because of code clones which are common in android apps .
due to code clones noisy api device correlations in cloned code snippets can recur in different apps.
this increases the noises and makes the valid api device correlations indistinguishable.
for example lines in figure are app specific code which are unrelated to fic issues.
line invokes the apiactivity.getcurrentfocus to get the currently focused view.
this line and the code denoted by ... in line are cloned from a popular open source video player vlc .
in our evaluation we observed that instances of noisy api device correlations extracted from this cloned code snippet recurred in many apps in our collected app corpora.
to mitigate this problem our ranking strategy also considers the diversity of the occurrences of the extracted api device correlations.
more details of our approach will be presented in the next section.
iii.
p ivot approach as shown in figure p ivot takes a corpus of android apps as input and outputs a ranked list of api device correlations.
the process consists of two steps.
first the correlation authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
apkcorrelation extractorcorrelation prioritizerranked api device correlations fig.
.
overview of p ivot keycode keycode menu call islge islge return manufacturer .compareto lge b1 islge b1 true log.
i tag applying lg ... openoptionsmenu return true view v getcurrentfocus ... return super.onkeyup keycode event manufacturer equals lge manufacturer equals lge fig.
.
inter procedural control flow graph of the code in figure extractor performs static analysis to extract raw api device correlations from the input apps.
then the correlation prioritizer ranks the extracted api device correlations.
a. extracting api device correlations the correlation extractor performs inter procedural static analysis on an input app in three steps building inter procedural control flow graphs.
for each input app the correlation extractor builds an inter procedural control flow graph by combining the app s call graph and each method s control flow graph.
figure shows the interprocedural control flow graph for the code snippet in figure .
for ease of presentation we label each block in the graph with a unique number.
note that android apps are event driven.
when building inter procedural control flow graphs p ivot does not consider the implicit control flow between different event handlers.
as reported in a prior study it is unlikely that fic issue patches would cross event handlers .
this means that the pieces of code by which an api device correlation is learned likely reside in the same event handler or its callees.
as a result eliminating control flows between event handlers may not significantly affect api device correlation extraction.
identifying device checking statements.
the correlation extractor then traverses the inter procedural control flow graph to identify device checking statements and evaluates the conditions imposed on each branch.
since device information is encapsulated by the class android.os.build a conditional statement is considered device checking if it uses this class.
in figure block contains such a conditional statement the block is in the method islge .
computing device constraints for program blocks and deriving api device correlations.
the correlation extractor then computes the device related constraints induced by theconditions that should be satisfied to reach each program block.
for ease of presentation we refer to these constraints as device constraints.
the device constraint for each block is the disjunction of the device constraints of all paths by which the block can be reached from the application entry points.
as discussed the pieces of code by which an api device correlation is learned likely reside in the same event handler or its callees.
therefore p ivot considers each event handler to be an entry point.
finally all apis called in a block are paired with the device identifiers in the device constraint of this block to produce api device correlations.
in figure the method onkeyup is an event handler defined in the activity class and is therefore treated as an entry point for our static analysis.
since there is only one path reaching block from the entry point the device constraint is computed as the conjunction of the device constraints associated with the edges on this path i.e.
manuf acturer equals lge .
by pairing up the apis called in block and the identifier in the device constraint two api device correlations are produced angbracketleftlog.i lge angbracketright angbracketleftactivity.openoptionsmenu lge angbracketright.
b. prioritizing api device correlations in this step the api device correlations extracted in the first step are prioritized based on their likelihood of capturing real fic issues.
as discussed in section ii c existing techniques cannot effectively filter invalid api device correlations.
to prioritize api device correlations we propose a new approach that leverages two metrics in app confidence and occurrence diversity .
the two metrics are inspired by our observations discussed in section ii c. in app confidence new fic issues continually arise with the release of new device models and the evolution of android platforms.
these issues may not be commonly and quickly fixed in real world android apps.
therefore the conventional metric confidence which is based on an apidevice correlation s popularity over the whole app corpus cannot effectively prioritize api device correlations.
on the other hand although fic issues may not be commonly fixed we observed that once developers of an app identify a real fic issue they tend to modify all callsites of the issue inducing api within the app to fix the issue.
the callsites of apis irrelevant to fic issues are mostly not guarded by any device constraints.
as such we propose to use in app confidence iac to prioritize api device correlations.
the iac of an api device correlation cin an app ais defined as iac a c occurrences of c in a callsites of c.api in a wherec.api is the api of c. intuitively iac computes how often the invocation of c.api is guarded by a device checking statement that checks the app s runtime device model against the device model captured in c. the total in app confidence metric wiac c for an apidevice correlation cis the sum of iacs of all apps in the corpus that contain the api device correlation wiac c summationdisplay iac a c authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
occurrence diversity intuitively if an api device correlation recurs in more apps it is more likely to be valid.
however prioritization of api device correlations based on their number of occurrences alone can be insufficient.
since code clones are common in android apps the api device correlations extracted from cloned code can appear in many apps and get a high rank even if they have nothing to do with fic issues see section ii c for an example .
to mitigate this problem we propose a new metric occurrence diversity to measure the diversity of the apps and methods within which the instances of an api device correlation care found.
we denote it as d c .
we leverage shannon index to measure occurrence diversity.
shannon index was proposed to measure the diversity of the characters in a string and was later widely applied in ecology to measure the species diversity .
shannon index is computed based on the distribution of different groups of entities in a population and is defined as follows h summationdisplay n i 1pilogpi wherepiis the proportional abundance of the i th group in a population.
intuitively shannon index is higher if there is a larger number of different groups in the population and the groups of entities are more evenly distributed.
using shannon index we measure an api device correlation c s occurrence diversity at two levels app level and method level .
app level diversity measures the diversity of the apps that contain the instances of c. we use app names and app company names which can be extracted from app markets as identifiers to distinguish different groups of apps.
method level diversity measures the diversity of methods that contain the api callsites in c s instances.
we use package names of the methods enclosing classes and method control flow structures to distinguish different methods.
package names can be extracted by static analysis but are subject to code obfuscation.
to cope with obfuscation we also measure the diversity of control flow structures using an existing technique that detects code clones in android apps by projecting the control flow structure of each method to a three dimensional centroid and calculating distances between these centroids.
this technique has been shown to be accurate and scalable.
since it is based on the control flow structures of methods the technique is robust to code obfuscation.
to calculate the control flow structure diversity we first calculate centroids for all methods that contain the api callsites inc s instances.
then the methods are clustered based on the centroids according to the single linkage clustering algorithm .
specifically a method is added to an existing cluster if the distance between its centroid and the centroid of any method in this cluster is smaller than a threshold which is set to .
in our experiment.
the output clusters are considered as different control flow structure groups.
after grouping api device correlation occurrences we apply shannon index to calculate the diversity of app name happ app company name hcompany method package name hpackage and method centroid hcentroid .
the overalloccurrence diversity of an api device correlation cis then calculated as follows d c l o g happ c hcompany c hpackage c hcentroid c ranking score the ranking score of an api device correlationcis then calculated by combining the above metrics s c wiac c d c the extracted api device correlations are ranked based on their ranking scores.
if the ranking score of an api device correlation is higher it is more likely to capture fic issues.
iv .
e v alua tion we implemented p ivot on top of soot .
to evaluate the effectiveness of p ivot and the usefulness of its learned apidevice correlations we study the following research questions rq1 effectiveness of p ivot can pivot effectively identify valid api device correlations of real fic issues from popular android apps?
can our proposed ranking score outperform the metrics adopted by existing api precondition mining techniques?
rq2 usefulness of api device correlations can the apidevice correlations learned from popular apps facilitate fic issue detection in other apps?
to investigate the rqs we conducted two experiments experiment i to answer rq1 we ran p ivot on popular apps collected from google play and evaluated the precision of its learned api device correlations.
we compared the results with a baseline approach that adopts the ranking metric of a representative api precondition mining technique proposed by nguyen et al.
.
since fic issues evolve quickly we ran p ivot on two different app corpora collected in and and compared the results to evaluate whether p ivot can effectively identify valid apidevice correlations from popular apps at different time.
experiment ii to answer rq2 we conducted a case study.
we leveraged the api device correlations learned by p ivot in the first experiment to detect fic issues in open source android apps and reproduced the detected issues.
the experiments were conducted on a linux server running centos .
with two intel xeon e5 octa core cpu .1ghz and gb ram.
a. rq1 effectiveness of pivot experiment i setup in this experiment we evaluate the effectiveness of p ivot to prioritize valid api device correlations.
in the following we discuss the data collection process baseline approach ground truth and evaluation metrics.
data collection.
to evaluate whether p ivot can identify fic issues that are active at different time we applied it to two app corpora collected in and respectively.
to prepare the two corpora we crawled the apk files of the top free apps for each category on google play in november and june .
the first collection contains apps authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
table i sta tistics of ourappcorpora corpus corpus apps total classes total methods average rating .
.
average downloads and we were able to run p ivot on of them.
the second collection contains apps and we were able to run p ivot on of them.
soot crashed when analyzing the remaining apps.
the number of apps collected is not in hundreds because some apk files cannot be downloaded due to server errors.
the analyzable apps formed our two app corpora.
we will call them corpus and corpus hereinafter.
the two app corpora slightly overlap apps are in both corpora but the app versions are different.
we analyzed the apk files of the apps in the two corpora and collected the apps meta data from google play .
table i shows the statistics.
as shown in the table the two app corpora both have tens of millions of classes and over one hundred million methods.
the apps are also of high quality and popular.
the average rating is .
out of .
on average each app received over and million downloads in corpus and corpus respectively.
baseline approach.
we compared p ivot with a baseline approach adapted from a state of the art api precondition mining technique by nguyen et al.
.
the technique learns api preconditions that involve api receivers and parameters.
it originally does not support extracting device related preconditions.
to adapt the technique to learn valid apidevice correlations we integrated our correlation extractor section iii a with the technique s filtering and ranking components.
specifically the api device correlations were first filtered by their support.
those api device correlations that only occurred once in a corpus were filtered out.
the api device correlations were then ranked by the multiplication of method level confidence and project level i.e.
app level confidence.
app level confidence of an api device correlation cis computed as the ratio of the apps that contain c s instances to the apps that contain callsites of c s api.
similarly methodlevel confidence of an api device correlation cis the ratio of the methods containing callsites of c s api that are guarded by statements checking the device identifier modeled in cto the methods that contain the callsites of c s api.
ground truth valid api device correlations.
we consider an api device correlation cvalid if calling the api in ccan trigger or fix fic issues on the corresponding device model.
to establish the ground truth we manually inspected top api device correlations of each ranked list produced by p ivot and the baseline approach.
we also randomly sampled apidevice correlations from the unranked api device correlations extracted by correlation extractor to show the massiveness of noises.
we only manually validated top api device corre 50precision n top n api device correlations pivot pivot baseline baseline fig.
.
precision n of p ivot and baselines lations because without an automated approach it is unlikely for users to check a large number of api device correlations produced by p ivot or the baseline approach.
when validating each api device correlation we first inspected the originating location of its instances and determined whether the api callsites are dependent on some statements checking the device identifier in the correlation.
if yes we proceeded to use the api signature the name of api s enclosing class and the device identifier as keywords to search on google github and stack overflow .
an api device correlation cis then considered valid only if we can find multiple sources e.g.
forum discussions or issue reports confirming that the api ofccan induce inconsistent app behavior on the device model specified in c or the api can be used to address the fic issues that can be triggered on the device model.
recall the example in figure the patch suggested by lg developers was to explicitly invoke an api to open the options menu line .
as a result the api device correlation angbracketleftactivity.openoptionsmenu lge angbracketrightis considered valid.
we published the valid api device correlations and the corresponding online discussions at our project website .
evaluation metric.
to measure the effectiveness of p ivot and the baseline approach in prioritizing api device correlations we adopt the metric precision n which reports the percentage of valid api device correlations among the top n api device correlations in a ranked list.
higher precision n indicates that the ranking strategy is more effective.
results of experiment i pivot extracted and api device correlations from corpus and corpus respectively.
to evaluate the effectiveness of p ivot w e randomly sampled api device correlations extracted from each app corpus to show the massiveness of noises evaluated precision n n ... for top apidevice correlations in each ranked list compared the results of p ivot for the two different app corpora and compared the results of p ivot and that of the baseline approach.
massiveness of noises.
from the randomly sampled api device correlations for each app corpus we only identified three valid ones that capture real fic issues.
none of these three valid api device correlations was ranked to top by p ivot because they either only occurred once in one app or occurred only in cloned code snippets.
this shows that noises are massive in the api device correlations extracted from the app corpora approximately .
identifying valid api device correlations is an outstanding challenge.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
precision n of p ivot .figure plots the results of experiment i. the two solid lines show the results of p ivot for the two app corpora.
in both corpora p ivot achieves precision among the top five api device correlations and over precision among the top ten.
the precision gradually drops as n grows.
this shows that p ivot can effectively prioritize valid api device correlations.
p ivot identified valid api device correlations among the top precision for corpus and valid ones among the top for corpus precision .
among these and valid correlations eight are overlapped.this means that p ivot identified a total of distinct valid api device correlations.
we further studied why p ivot ranked some invalid apidevice correlations among top .
we identified two major reasons.
first some apis are commonly used in different apps for specific purposes irrelevant to fic issues.
one typical example is the logging apis that are widely used for runtime information collection.
api device correlations involving such apis may receive a high ranking score because the occurrence diversity of such api device correlations could be high.
second most other invalid api device correlations were ranked high due to the limitations of existing constraint solvers and simplifiers.
when deriving device constraints for program blocks we leveraged a popular constraint solver choco and a rule based constraint simplifier jbool expressions to simplify the device constraints.
as boolean expression minimization is an np hard problem our simplified device constraints may not be minimal.
thus api calls that are not made under any device constraints could be mistakenly included and paired with device constraints.
comparison between the results of the two corpora.
as shown in figure p ivot achieved similar precision n for the two app corpora collected at different time.
the valid apidevice correlations among top for corpus and corpus only slightly overlap as discussed above.
this shows that pivot can learn valid api device correlations from corpora of popular apps at different time.
comparison with baseline.
the two dashed lines in figure show the results of the baseline approach.
p ivot significantly outperforms the baseline approach.
the baseline approach failed to rank any valid api device correlations to top for corpus and only identified one valid correlation at the 14th position for corpus .
we further studied why the baseline approach performed poorly.
we found that most of its top ranked api device correlations involve rarely used apis.
for example the top api device correlations produced by the baseline approach for corpus received .
confidence yet none of them are valid.
this shows that learning apidevice correlations differs from mining api preconditions.
general api precondition mining techniques cannot effectively identify valid api device correlations.
b. rq2 usefulness of api device correlations experiment ii setup we built an archive of distinct fic issues based on the valid api device correlations learned by p ivot .
there are fewer distinct fic issues thanapi device correlations because multiple api device correlations could refer to the same fic issue.
for example an api that triggers an fic issue and another api that addresses this fic issue can result in two valid api device correlations according to our approach.
for each issue our archive provides the api device correlations of the issue learned by pivot the package ids of the apps from which p ivot learned these correlations and the related issue discussions we collected from online resources to validate the api device correlations.
this archive is also publicly available .
to investigate the usefulness of the learned api device correlations we conducted a case study on open source android apps.
in the study we leveraged f icfinder a static analyzer that detects fic issues in android apps to detect and reproduce undiscovered instances of our archived fic issues.
issue selection .
from our archive we selected five fic issues to carry out the case study.
we provide videos to demonstrate the inconsistent app behaviors caused by these issues on our project website .
we selected these five issues because the device models that can trigger the issues are available on amazon device farm or wetest and the inconsistent app behaviors caused by the issues are observable on the online testing platforms.
the first criterion enables us to reproduce the later detected fic issues on online testing platforms.
the second criterion allows us to have a clear oracle to determine the occurrence of fic issues.
app selection.
to find undiscovered instances of the five fic issues in real world android apps we collected the latest version of apps on f droid .
all these apps have at least stars on github have over commits have at least one push during a five month period before the case study and contain at least one callsite of any api related to the five fic issues.
these criteria ensure that our selected apps are popular and well maintained and could be liable to the selected fic issues.
note that although the apps are open source some of them are also popular on google play.
for example barcode scanner has received over million downloads on google play table ii .
issue detection and reproduction.
for each of the selected issues we encoded it as a rule in f icfinder s api context pair format.
we then ran f icfinder using these rules as input to analyze the app subjects.
f icfinder reported warnings for of these subjects.
we manually inspected these apps and excluded those that require special hardware software environments to run e.g.
specific server setups from this study.
as a result we focused on reproducing detected issues in apps using amazon device farm and wetest .
usefulness of api device correlations among the detected issues we successfully reproduced ten in ten different apps.
we failed to reproduce the remaining nine due to three major reasons.
first some apps did not exhibit inconsistent behavior as they only use the minor functionalities of the issue inducing apis.
for example some apps use the camera api to turn on the flash light to use the phone as a torch.
in such cases the camera preview was not displayed and the issues cannot be observed.
second f icfinder generated authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
table ii case study subjects and reported issues id app name categorylatest revision no.kloc stars rating downloads issue id s barcode scanner shopping c8da0c1 .
.
100m 959b newsblur news magazines 0f0f1f1 .
.
50k xabber communication 925e996 .
.
1m octodroid productivity e491d76 .
.
100k 821a simple task productivity 0572a62 .
.
10k 862a face slim c62bb57 .
319a simple camera tools 8aebf00 .
.
100k 120b walleth finance 929216c .
.
5k 201b calendula health fitness 39e6e96 .
.
1k k 92b open manga ac3cd27 .
means not applicable.
superscript a means the issues were acknowledged and developers agreed to fix in future.
b means the issues have already been fixed.
false positives because it failed to recover issue workarounds that already exist in the apps.
third we failed to reach the api callsites of several apps because they crashed prematurely.
table ii gives the information of the ten apps whose fic issues were successfully reproduced.
these apps contain thousands of lines of code large scale cover different app categories diversified receive over stars on github and thousands of downloads on google play popular and are rated at least .
on google play decent quality .
we reported the ten reproducible issues to the original app developers to seek their feedback.
the issue ids of our reports are provided in the last column of table ii.
among the ten reported issues seven have been acknowledged and four were immediately fixed.
for example the issue of calendula would crash the app when invoking the built in datepicker api on some popular samsung devices running android .
e.g.
galaxy note .
upon receiving our report the app developer quickly fixed the issue with a workaround documented in our issue archive .
these results show that api device correlations can help detect fic issues in android apps and reproduce the issues on the corresponding issue triggering device models.
the information provided by our fic issue archive section iv b1 is actionable and can facilitate the detection and diagnosis of fic issues.
specifically the device identifiers and apis specified in api device correlations can help reduce the search space of fic issues.
with the information developers can design tests to cover the app components that call fic issueinducing apis and execute these tests on the device models that can trigger the fic issues to expose potential issues.
v. d iscussions a. threats to v alidity quality of input app corpora.
pivot can only identify valid api device correlations from apps that contain code snippets handling fic issues.
it is unlikely that such code snippets would exist in apps that are not well maintained.
as such the quality of app corpora can affect the performance of p ivot .
it is suggested to build an app corpus with popularapps on app stores as we did in our experiments.
p ivot can then extract valid and useful api device correlations.
other code patterns to handle fic issues.
pivot learns api device correlations from code snippets handing fic issues which feature device checking statements with the use of class android.os.build .
note that there can be other code patterns to handle fic issues.
p ivot may not discover api device correlations for all fic issues.
nevertheless the practice of checking device information was shown to be common in practice when handling fic issues .
imprecise static analysis.
pivot performs static analysis on inter procedural control flow graphs to extract api device correlations.
it is possible that the graphs generated by static analysis are imprecise or unsound .
because of such imperfectness p ivot may miss some api device correlations or generate invalid api device correlations.
however as p ivot learns api device correlations from large app corpora such problems can be mitigated in p ivot s final output.
b. comparison with ficfinder in our previous studies we conducted an empirical study and published the empirical study dataset.
we also proposed f icfinder to detect fic issues in android apps.
the goals of f icfinder and p ivot are different.
while ficfinder aims to detect fic issues with a given set of predefined patterns p ivot aims to learn the knowledge of fic issues from popular apps.
as shown in section iv b the knowledge learned by p ivot can serve as input to f icfinder and help detect previously unknown fic issues.
we did not apply p ivot to the apps used by the empirical study in f icfinder because the empirical study involved only five apps making it difficult for p ivot to distinguish valid api device correlations from noises.
alternatively we compared the fic issues in f icfinder s dataset with those learned by p ivot .
ten of the valid apidevice correlations learned by p ivot are related to fic issues in f icfinder s dataset.
among the other valid apidevice correlations that were not included in f icfinder s dataset of them concern fic issues that emerged in ficfinder s dataset was published in .
this confirms that p ivot can identify new valid api device correlations.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
c. automated api device correlation v alidation in our experiments we manually validated api device correlations.
the manual process is subject to errors.
to reduce human efforts and provide more reliable validation results we plan to study automated validation of api device correlations in future.
particularly we plan to combine static and dynamic analysis to synthesize test apps from the apps that contain topranked api device correlations.
with such test apps we will be able to exercise the apis on the device models specified by api device correlations to validate the correlations.
vi.
r ela ted work a. android fragmentation issues several studies have been conducted to understand the problems induced by android fragmentation.
han et al.
mined android issue tracking system and provided evidence of android fragmentation.
other studies pointed out that android fragmentation could induce various consequences.
liu et al.
and hu et al.
found that a notable proportion of performance issues and webview bugs are specific to device models.
li et al.
found that app usage patterns are sensitive to device models.
fan et al.
found that the compatibility issues induced by fragmentation commonly cause framework crashes.
these studies pointed out the issues induced by android fragmentation but did not propose techniques to address them.
other studies proposed techniques to mitigate the problems induced by android fragmentation.
for example several techniques were proposed to prioritize device models for android app testing.
vilkomir et al.
selected android devices based on combinatorial methods to cover different device characteristics.
khalid et al.
proposed to prioritize testing devices based on the user ratings of other apps from the same category.
lu et al.
designed p rada which prioritizes device models based on the usage data of similar apps.
these techniques prioritize device models but are not specifically designed to catch fic issues.
as a result they cannot provide actionable information to guide fic issue detection.
fazzini et al.
designed d iffdroid to identify gui inconsistencies of android apps when they run on different android platforms.
diffdroid compares gui models of an app when running on different device models but such comparisons do not help reduce the search space of fic issues.
huang et al.
studied compatibility issues induced by the evolution of callback apis whose scope is different from ours.
our previous studies conducted an empirical study of fic issues in open source apps and designed a static analyzer f icfinder to detect fic issues.
f icfinder requires a given list of fic issue patterns which were manually derived.
however manually deriving issue patterns requires intensive human efforts and may not be practical as fic issues are constantly evolving.
li et al.
proposed techniques to automatically learn patterns of compatibility issues caused by android framework api evolution whose scope is different from our study we study device specific fic issues .
in comparison p ivot automatically learns api device correlations of device specific ficissues from a given android app corpus.
our case study shows that the learned api device correlations are useful and can help detect previously unknown fic issues in real world android apps.
b. mining api usage patterns v arious techniques have been proposed to mine api usage patterns from code repositories.
the majority of them aim to mine api co occurrence relationships.
pr miner and dynamine were proposed to mine sets of apis that frequently co occur in code repositories.
mapo was among the first techniques to mine frequently used api sequences.
follow up studies further improved the pioneering techniques .
most of them rely on mining techniques and adopt light weight static analysis without analyzing code control dependencies.
several techniques were proposed to infer api calling preconditions via static analysis and mining code repositories.
ramanathan et al.
inferred preconditions that must hold before api invocations from code revision histories.
nguyen et al.
mined api preconditions with regard to the api arguments and receivers.
these techniques target at mining general api preconditions that may not be relevant to fic issues.
in addition these techniques leverage traditional filtering metrics such as confidence to identify valid api preconditions.
as shown in our evaluation such metrics cannot effectively prioritize valid api device correlations.
in contrast p ivot focuses on learning api device correlations and features a new and effective ranking strategy to prioritize the correlations.
vii.
c onclusion in this paper we proposed the first automated api device correlation learning approach p ivot to facilitate fic issue detection.
to effectively identify valid api device correlations pivot performs inter procedural static analysis to extract apidevice correlations and leverages a novel ranking strategy to prioritize them.
the evaluation results show that our ranking strategy can effectively identify valid api device correlations and significantly outperform an existing technique.
based on the learned api device correlations we built an archive of fic issues and further conducted a case study to show the usefulness of api device correlations.
our experiment results and other data are published at our project website .
currently p ivot requires human efforts to validate the learned api device correlations.
in future we plan to study how to automate the validation process by combining program analysis and test synthesis techniques.