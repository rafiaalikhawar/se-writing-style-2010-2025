measuring software redundancy antonio carzaniga andrea mattavelli and mauro pezz universit della svizzera italiana usi switzerland university of milano bicocca italy email antonio.carzaniga usi.ch andrea.mattavelli usi.ch mauro.pezze usi.ch abstract redundancy is the presence of different elements with the same functionality.
in software redundancy is useful and used in many ways for example for fault tolerance and reliability engineering and in self adaptive and self checking programs.
however despite the many uses we still do not know how to measure software redundancy to support a proper and effective design.
if for instance the goal is to improve reliability one might want to measure the redundancy of a solution to then estimate the reliability gained with that solution.
or one might compare alternative solutions to choose the one that expresses more redundancy and therefore presumably more reliability.
we first formalize a notion of redundancy whereby two code fragments are considered redundant when they achieve the same functionality with different executions.
on the basis of this abstract and general notion we then develop a concrete method to obtain a meaningful quantitative measure of software redundancy.
the results we obtain are very positive we show through an extensive experimental analysis that it is possible to distinguish code that is only minimally different from truly redundant code and that it is even possible to distinguish lowlevel code redundancy from high level algorithmic redundancy.
we also show that the measurement is significant and useful for the designer as it can help predict the effectiveness of techniques that exploit redundancy.
i. i ntroduction a software system may implement the same functionality in different ways.
for example a container library may provide two functionally equivalent sorting algorithms a simple inplace algorithm like insertion sort which is preferable for small sequences and a more complex but asymptotically faster algorithm like merge sort to be used on larger sequences.
even algorithmically identical operations could be performed in different ways.
for example a program may create a table of formulas in a spreadsheet by adding the first row and then copying that row vertically or by adding the first column and then copying horizontally.
a system might even contain replicas of exactly the same single operation semantic clones and sometimes that might be a good design choice.
for example a drawing function from a graphics library may have been refactored with only syntactic changes but the library may also retain the old version for backward compatibility.
in all these cases whenever a system is capable of performing the same function with different code or even with the same code but executed in different ways we say that the software system is redundant.
redundant elements can be present in different forms and at different granularity levels from code snippets to entire systems.
sometimes this redundancy is introduced systematically by design as in the case of n versionprogramming while other times it arises as a side effect of other design goals as in the examples above.
software redundancy has many useful applications.
in n version programming where the design is deliberately redundant redundancy is intended to provide fault tolerance.
other techniques exploit the intrinsic redundancy exemplified above for example to avoid failures through automatic workarounds to generate and deploy test oracles and to overcome failures and fix faults automatically .
however a common limitation of all these techniques is that while they seek to exploit redundancy they provide no mechanism to assess how much redundancy is in fact there to be exploited.
so for example three teams of developers may work on three independent versions of a system but the resulting versions may turn out to be based on the same algorithm and therefore might be susceptible to correlated failures and the developers would not be able to assess the level of independence of the three versions and therefore the level of reliability of the system.
similarly a self healing system may try to deploy an automatic workaround for a failing method by replacing that method with a supposedly equivalent but hopefully non failing alternative.
but the fundamental question remains how much redundancy is there in the chosen alternative?
and therefore how likely is it that the chosen alternative would avoid the failure?
more specifically is the alternative executing different code or is it merely a thin wrapper for the same code?
even if the code is different is the alternative radically different or is it using essentially the same algorithm?
more fundamentally how do we even quantify redundancy?
with this paper we intend to provide answers to these questions.
we begin by formulating a very general and abstract notion of redundancy which in essence we define as functional equivalence with execution diversity.
then again abstractly we define a measure of redundancy in terms of the dissimilarity between the execution traces of equivalent code fragments computed over a certain type of execution traces and aggregated over a space of executions.
these abstract notions of redundancy and its measure are conceptually important but they are also ultimately undecidable and therefore not directly usable in practice.
notice in fact that equivalence alone is undecidable and that the dissimilarity measure should be computed over an infinite space of executions.
we therefore develop a method to measure redundancy that is based on the abstract model but is also practical and in fact quite efficient.
the method considers a finite set of executiontraces obtained from generated input values generated tests uses a specific projection of the execution trace in which we log changes in the application state memory accesses and measures a specific form of edit distance between traces.
we first validate our method through micro benchmarks to show that the measurement is internally consistent and stable with respect to some forms of program transformations.
we then use the method to take measurements in a number of case studies to assess the significance of the measure.
the results show that the measurement is a very good indicator of redundancy.
in particular the measurement clearly distinguishes shallow differences where two apparently different code fragments reduce to the same code underneath from deep code differences from algorithmic differences where not only the code is different but the algorithmic nature of the two executions differs significantly.
we also demonstrate that our measures of redundancy can be good predictors of the effectiveness of techniques that exploit redundancy such as automatic workarounds.
in summary this paper contributes a complete and consistent definition of redundancy for software systems and develops and evaluates a practical method to measure redundancy quantitatively.
we see this as a first foundational step in a broader study of software redundancy.
we see redundancy as a precious resource that can and should be exploited to improve software quality.
in particular we believe that many software engineering techniques can produce an added value only to the extent that they can find and exploit information within the software itself.
in other words those techniques feed on the redundancy of software.
it is therefore important to study redundancy at a minimum to characterize it qualitatively and quantitatively in specific cases but then also to generalize its characterization perhaps to identify properties of a design or development process that lead to more or less redundancy.
ii.
b ackground and motivation redundancy has many applications in software engineering including fault tolerance self healing systems self adaptive services self checking programs self optimizing code automatic fault fixing and the automatic generation of test cases and oracles .
it is exploited at different abstraction levels from a service or subsystem to a method call .
some techniques and applications deliberately introduce redundancy within a system as in the case of nversion programming and recovery blocks while other techniques exploit redundancy available outside the system for example in a marketplace of web services and yet other techniques seek to exploit the redundancy that is intrinsic in software systems .
we now briefly review a few relevant applications of redundancy in the domains of software reliability self healing systems and automated fault fixing.
we do that to motivate the idea of measuring redundancy.
then we review the research work most related to that idea.n version programming is a well known technique to meet the reliability requirements of safety critical applications .
an n version system consists of multiple independently developed implementations of the same system that execute in parallel on the same input.
the system then outputs the result of the majority of the versions so the gain in reliability rests on the assumption that coincidental faults in independently developed components are very unlikely.
the validity of this assumption has been disputed most notably by knight and leveson who argue that independently developed components may not be as independent or as redundant as one would expect.
this suggests that a consistent measure of redundancy would support the engineering of n version systems by at least identifying weak components.
automatic workarounds exploit redundancy in methods and code fragments to achieve a form of self healing .
the idea is to identify redundant code fragments that can replace failing fragments at runtime to automatically circumvent a fault and avoid the failure.
the technique relies on the amount of redundancy of alternative code fragments.
a measurement of that amount could indicate the likelihood that a particular alternative fragment would succeed in avoiding the failure thus leading to a more efficient self healing mechanism.
a recent approach to fixing faults automatically is to use genetic programming to evolve a faulty code towards a correct one .
thus redundancy plays a crucial role also in this case because some of the mutations through which the system evolves replace a fragment of code with another fragment taken from the system itself.
therefore a measure of redundancy could indicate the likelihood of success for the entire evolutionary process and it could also be used as a fitness function for the selection of an individual mutation.
measuring software redundancy seems like a useful proposition but it also remains an open problem.
some researchers have proposed ideas and concrete techniques to assess the semantic similarity of code fragments within a system which is an essential ingredient of redundancy.
in particular the most relevant work is that of jiang and su who consider the problem of identifying semantic clones .
their definition of clones is based on a notion of equivalent code fragments similar to the one we also develop in this paper.
however it is in the definition of equivalence relation that our model differs significantly.
in essence jiang and su consider fragments with identical effects whereas we consider two fragments to be equivalent when their observable effects are identical.
we re examine this difference in more detail in section iii a. another related work is described in a recent paper by higo and kusumoto on the functional sameness of methods .
here too the authors are interested in the semantic similarities between methods within a system.
however their approach differs almost completely from ours and also from jiang and su since they use an exclusively static analysis of the code and furthermore they do that by combining three measures of similarity that in and of themselves have little to do with the actual semantics of the code.
specifically they use the similarity of the vocabulary of variables symbols the nameof the methods and the structural distance of methods within the package hierarchy.
the most interesting aspects of the work of higo and kusumoto is that perhaps thanks to the simplicity of their analysis they were able to analyze a massive amount of code.
iii.
c haracterizing software redundancy we now formalize our notion of redundancy.
we first give an abstract and general definition that we then specialize to develop a practical measurement method.
we are interested in the redundancy of code.
more specifically we define redundancy as a relation between two code fragments within a larger system.
a code fragment is any portion of code together with the necessary linkage between that code and the rest of the system.
a fragment can be seen as the in line expansion of a function with parameters passed by reference where the parameters are the linkage between the fragment and its context.
figure illustrates the notion of redundant fragments with two examples.
for each pair of fragments we specify the linkage between the fragments and the rest of the system by listing the variables in the fragments that refer to variables in the rest of the system.
all other variables are local to the fragments.
linkage int x int y int tmp x x y y tmp x y y x x y linkage abstractmultimap map string key object value map.put key value list list new arraylist list.add value map.putall key list fig.
.
examples of redundant code fragments.
the first example first row shows a code fragment that swaps two integer variables using a temporary variable left side and another fragment that swaps the same variables without the temporary by using the bitwise xor operator right side .
the second example refers to a multi value map in which one can add an individual mapping for a given key put or multiple mappings for the same key putall .
in both cases the fragment on the left is different from but equivalent to the fragment on the right.
this is our intuitive definition of redundancy two fragments are redundant when they are functionally equivalent and at the same time their executions are different.
we now formalize these two constituent notions.
a. an abstract notion of redundancy we want to express the notion that one should be able to replace a fragment awith a redundant fragment b within a larger system without changing the functionality of the system.
this means that the execution of bwould produce the same results as aand would not cause any noticeable difference in the future behavior of the system.
in other words we want bto have the same result and equivalent side effects or state changes as a. other studies on semantically equivalent code adopt a purely functional notion of equivalence and therefore assume no visible state changes .
yet others consider state changes to be part of the input output transformation of code fragments but then accept only identical state changes .
instead we would still consider two fragments to be equivalent even if they produce different state changes as long as the observable effects of those changes are identical.
this notion is close to the testing equivalence proposed by de nicola and hennessy and the weak bi similarity by hennessy and milner .
we now formulate an initial definition of equivalence between code fragments similar to testing equivalence.
basic definitions we model a system as a state machine and we denote with sthe set of states and with athe set of all possible actions of the system.
the execution of a code fragment cstarting from an initial state s0amounts to a sequence of actions a1 a2 ak2athat induces a sequence of state transitions s0a1 !s1a2 !
ak !sk.
in this model we only consider code fragments with sequential and terminating and therefore finite but unbounded executions and without loss of generality we consider the input as being part of the initial state.
we then use oto denote the set of all possible outputs that is the set of all externally observable effects of an execution.
we use out s a 2oto denote the output corresponding to the execution of action astarting from state s and generalizing we denote with out s0 c 2o the output of the sequence of actions a1 a2 akcorresponding to the execution of c from state s0.
observational equivalence we say that two code fragments caand cbareobservationally equivalent from an initial state s0if and only if for every code fragment cp probing code the output out s0 ca cp is the same as out s0 cb cp where ca cpandcb cpare code fragments obtained by concatenating caandcbwith the probing code cp respectively.
this definition requires that the two code fragments and the follow up probing code produce exactly the same output which does not take into account the intended semantics of the system whereby different output sequences may be equally valid and therefore should be considered equivalent.
for example consider a container that implements an unordered set of numbers that in state s0represents the set f10g.
consider now a fragment cathat adds element 20to the set and a supposedly equivalent fragment cbthat also adds 20to the set but with a different internal state transformation caleaves the set in a state such that an iteration would first go through 10and then while cbcauses the same iteration to first go through 20and then .caandcbwould not be considered observationally equivalent according to the definition above since a probing code that iterates through the elements of the set would expose a difference.
to account for the semantics of the system we consider a more general definition that requires the output of the twofragments and the follow up probing code to be equivalent according to an oracle relation that embodies the semantics of the system.
let ts0 ca be a family of equivalence relations hereafter oracles that depending on s0and ca and for every valid probing code cpdefines an equivalence oracle ts0 ca cp o o that essentially says whether two output sequences are both correct and therefore equivalent for the execution of ca cpfrom s0.
thus we say that caandcbare observationally equivalent in a semantically meaningful sense from an initial state s0 when for every probing code fragment cp the output sequences out s0 ca cp andout s0 cb cp are equivalent according to the oracle.
more specifically we say that cbcan replace cawhen the outputs are equivalent according to ts0 ca cp and vice versa cacan replace cbwhen the outputs are equivalent according to ts0 cb cp.
finally we say that caandcbare equivalent when they can replace each other.
notice that the former and more strict definition is a special case in which the oracles reduce to the identity relation.
redundancy putting the pieces together we say that two code fragments caandcbare redundant in state s0when they are observationally equivalent from state s0in a semantically meaningful sense and their executions from s0differ meaning that the sequence of actions aa aa induced by ca from s0 differs from the sequence ab ab induced by cb from s0 .
we then say that caandcbare always redundant if they are redundant in every state s0in which their application is valid every syntactically valid application of the fragments with every valid input .
b. discussion and practical considerations this model of redundancy is built upon our practical experience in developing various concrete techniques to capture and exploit software redundancy and generalizes to other uses of software redundancy such as nversion programming and recovery blocks .
however our main objective now is to abstract from each technique and to capture the essence of software redundancy and this is why we formulated an abstract and general model.
we see this as a first necessary step towards understanding the nature of redundancy in software systems and to use it systematically to improve the reliability of software systems.
from this abstract model we then want to derive a concrete method to characterize the redundancy of a system.
in particular we would like to obtain a measurement that would somehow correlate with the attainable benefits of the redundancy present within a system.
to do that we need to overcome two obstacles.
first our abstract notion of redundancy is not decidable since it subsumes a basic form of equivalence between programs that amounts to a well known undecidable problem by rice s theorem .
we therefore need to either limit the expressiveness of the model or somehow accept an incomplete or imprecise decision procedure.
second our model expresses a binary decision but we would like a more informative measure for example to rank different designs by the amount of redundancy they possess.
we must therefore enrich the model with a formof distance and we must define a corresponding operational measurement method.
the first problem deciding equivalence has been studied extensively from a theoretical perspective independent of its relation to the notion of redundancy.
we also explored the same problem from a practical perspective and specifically in relation to redundancy.
in particular we initially proposed a completely manual method to simply express equivalence in the form of rewriting rules that we then used to annotate potential sources of redundancy in code bases of significant size and complexity .
we then developed a method to automatically test the equivalence of code fragments in the specific context of test oracles using a bounded search.
in this paper we enhance this bounded search method to decide equivalence and therefore redundancy.
the second problem obtaining a non binary measurement of redundancy is our main focus here.
we discuss it next.
c. a practical and meaningful measure of redundancy recall once again that redundancy is present whenever two code fragments induce different executions with the same functional effect on a system.
we now want to extend this abstract binary condition which is defined for each starting state s0 to obtain a more general and meaningful measurement of the redundancy of two code fragments.
by meaningful we mean a measurement that can serve as a good indicator or predictor for software designers.
in particular we consider a measure of redundancy to be meaningful when it is indicative of some useful property or some design objective related to redundancy.
for example if we use redundant fragments in an n version programming scheme to increase the reliability of a system then a meaningful measurement of their redundancy should correlate with the gain in reliability attainable with that scheme.
here we formulate a general method that can be specialized with several different metrics and later in section iv we experimentally evaluate the predictive ability of each specialization.
we define a meaningful measure of redundancy by first turning the binary condition into a richer non binary metric and then by aggregating this metric over several starting states.
informally given two code fragments we combine a measure of the degree of functional equivalence of the fragments with a measure of the distance between their executions and then aggregate the results over a set of representative initial states.
a bit more formally let es ca cb denote the degree of equivalence between two code fragments caandcbin state s. intuitively es ca cb can be seen as the probability that a probing code cpwould not expose any difference between ca andcbwhen starting from state s. also let ds ca cb denote the distance normalized between the executions of caandcbstarting from s. thus ds ca cb 0indicates two identical executions while ds ca cb 1indicates completely different executions.
with these equivalence and distance measures we define the generic measure of the redundancy of caandcb in state s asrs es ca cb ds ca cb .
then ideally we would like tocompute the expected value of rsover the space of all possible initial states s. in practice we aggregate over a limited sample of the state space.
input code fragments ca cb repeat ntimes s choose from s sample the state space e es ca cb measure equivalence d ds ca cb measure difference rs e d return aggregate all r s rsin expectation fig.
.
general algorithm to measure redundancy.
in summary we measure the redundancy of two fragments using the algorithm of figure .
we now present the techniques that implement steps and of the algorithm.
sampling of the state space we must choose and set up a number of initial system states from which to execute the two code fragments caandcb.
this amounts to generating tests for the system in which at some point we can insert the two fragments either one .
to do that we employ two common testing methods namely random testing and input category partitioning.
the main method we use is random test input generation.
in principle once we have a test we could insert one of the two fragments in almost any position in the test.
however this would require some care in linking the fragments with the system.
so to automate this process completely we let the test generator itself insert the fragments directly into the test.
in practice we generate many tests and select those that already contain ca and for those with multiple instances of cawe consider as an initial state the state right before each instance of ca.
in addition to random testing in some special cases we also manually categorized the input to the system so as to represent classes of equivalent inputs.
we then compile a list of tests that cover each category.
we then use these tests as operational definitions of the initial state.
observational equivalence measure we compute the degree of observational equivalence es ca cb by directly applying its definition we generate a large number of probing code fragments cp which we execute right after caandcb respectively from state s and we compare the output for each pair of executions.
we then return the percentage of cases in which the outputs are the same.
in essence probing code fragments amount once again to random tests specifically for the variables corresponding to the linkage of the two fragments.
we therefore implement a specialized random test generator that starts from a pool of variable descriptors each indicating name and type.
at each step the generator selects a variable from the pool together with a public method to call on that variable and adds that call to the test.
then if the method returns a primitive value or if the variable is itself of a primitive type then the generator adds a statement to output the value.
otherwise if the method returns another object the generator assigns the result of thecall to a newly declared variable and also adds a descriptor for the new variable name and type to its pool of variables.
the generator also adds the necessary code to catch and output any exception that might be raised at each step of the test.
the generator terminates and outputs the generated test after a preset number of steps.
figure shows an example of a generated probing code fragment for a code fragment similar to the second example of figure .
... testing code to set up initial state... code fragment a linkage boolean result arraylistmultimap map boolean result map.put var1 var2 generated probing code system.out.println result boolean x0 map.isempty system.out.println x0 map.clear java.util.map x1 map.asmap x1 added to the pool int x2 map.size system.out.println x2 int x3 x1.size system.out.println x3 java.util.set x4 x1.entryset x4 added to the pool java.util.iterator x5 x4.iterator x5 added to the pool boolean x6 x4.isempty system.out.println x6 try x5.remove catch java.lang.illegalstateexception e system.out.println e fig.
.
example of a generated probing code executed immediately after one of the code fragments a under measurement.
the code is simplified and abbreviated for presentation purposes.
notice that we compare the output of the generated probing code fragments using a simple equality test that in general leads to a conservative form of observational equivalence as described in section iii a .
still this method is both practical and efficient and it is also exact no false negatives for all the subjects considered in our evaluation section iv .
difference between executions we define a distance measure ds ca cb by applying a dissimilarity measure to a projection of the executions of the two code fragments caand cbstarting from state s. we define and experiment with many such distance measures by combining various dissimilarity measures with various projections.
a projection of an execution a1 a2 akis a particular trace in which we log a subset of the information associated with each action ai.
in particular we use two categories of projections.
incode projections for each action we log the code executed in that action.
we experimented with a number of code projections in which we log a simple identifier of the line of source code the line of code plus its depth in the call stack or to the full call stack.
indata projections for each action we log the read write operations performed in that action.
we only log read or write operations on object fields or static fields.
both read and write entries logged individually consist of an address part that identifies the field from which we read or into which we write and a data part that identifies the value being read or written.
we then specialize this projection by encoding different piecesof information in the address and data parts.
for the address we use the field name the class name or the type of the field being read or written and a number of their combinations.
for the value we use its string representation for basic types or arrays of basic types or no value at all.
we experimented with various combinations of code and data projections and also with slightly more elaborate variants of each.
for example for write operations we log the old value as well as the new value.
table i summarizes the most significant projections we propose to use.
the examples refer to the simple code fragment boolean x map.put k v .
we evaluate the effectiveness of these projections in section iv.
table i projections used to derive an action log from an execution type projection example from an actual log a code statement arraylistmultimap.put lobject lobject z abstractlistmultimap.put lobject lobject z abstractmultimap.put lobject lobject z depth statement arraylistmultimap.put lobject lobject z abstractlistmultimap.put lobject lobject z abstractmultimap.put lobject lobject z data type value ljava util map !
ljava util set !
ljava util hashmap !
i!
i field value map!
map!
entryset!
this !
modcount!
expectedmodcount class field value abstractmultimap.map !
hashmap.entryset !
hashmap entryset.this !
hashmap hashiterator.modcount !
hashmap hashiterator.expectedmodcount field old value map!
entryset!
this !
modcount!
expectedmodcount no value abstractmultimap.map !
hashmap.entryset !
hashmap entryset.this !
hashmap hashiterator.modcount !
hashmap hashiterator.expectedmodcount a code fragment boolean x map.put k v abbreviations arraylistmultimap iscom.google.common.collect.arraylistmultimap abstractmultimap iscom.google.common.collect.abstractmultimap hashmap isjava.util.hashmap object isjava.lang.object to obtain a clean execution log we also discard log entries corresponding to platform related actions that we consider irrelevant and potentially confusing for our purposes.
for example in our implementation which is in java we log the actions of the java library but we discard those of the class loader.
with such logs we then proceed to compute the difference measure for code fragments.
letls aandls bbe the logs of the execution of fragments caandcbfrom state s. we generally compute the distance measure ds ca cb similarity ls a ls b where similarity isa normalized similarity measure defined over sequences or sets interpreting the logs as sets .
intuitively the normalization of the similarity measures takes into account the length of the logs but in general each measure has its own specific normalization procedure.
notice that in the application of the similarity measure we consider each entry as an atomic value that we simply compare equals with other entries.
table ii lists the most effective similarity measures we experimented with.
the abbreviations on the right side identify the measures in their experimental evaluation in section iv.
table ii similarity measures applied to action logssequence basedlevenshtein lev damerau levenshtein damlev needleman wunsch need cosine similarity cos jaro jaro jaro winkler jarow q grams qgrams smith waterman smithw smith waterman gotoh smithg overlap coefficient ovlp set basedjaccard jaccard dice dice anti dice adice euclidean euclid manhattan man matching coefficient mc aggregating the measure of redundancy ideally we would like to obtain the expected redundancy of two fragments caandcb.
however we also want to use a general aggregation method independent of the particular distribution of the input for the system at hand.
we therefore simply compute the average of the redundancy measures over the sample of initial states.
we also experimented with other obvious aggregation functions such as minimum maximum and other quantiles but those proved less effective than the simple average.
iv.
e xperimental validation we conduct an experimental analysis to validate the measurement method we propose.
we consider two validation questions.
the first question q1 is about consistency we want to check that our measurements are internally consistent.
in particular we want to verify that the method yields measurements that remain stable when using common semantic preserving code transformations such as refactoring and also when we sample the state space from a domain of semantically similar inputs.
the second question q2 is about significance we want to make sure that the measurements we obtain are meaningful and useful.
in general we want to show that those measurements can help developers make design decisions related to the redundancy of their system.
thus we judge their significance and their utility by correlating the measurements with specific uses of redundancy.
a. experimental setup we conduct a series of experiments with a prototype implementation of the measurement method described insection iii c .
we consider a number of subject systems described below for which we consider a number of pairs of code fragments also detailed below .
for each system we generate a set of test cases either manually using the category partition method or automatically with either randoop or evosuite depending on the experiment.
we use the tests generated for each system with all the pairs of code fragments defined for that system to sample the input space as described in section iii c .
then for each pair of fragments and for each initial state test we measure the degree of observational equivalence as explained in section iii c .
for each pair of fragments and initial state we also trace the executions of the two fragments using the disl instrumentation framework .
with these traces we then apply a number of projections as explained in section iii c and with the resulting logs we compute a number of similarity measures using a modified version of the simmetrics library.1finally we compute the redundancy measure for each initial state and aggregate with its overall average and standard deviation.
we experiment with two sets of programs benchmark is a set of different implementations of two search algorithms and four sorting algorithms.
table iii lists each algorithm and the number of corresponding implementations.
in the case of benchmark we consider each whole system as a code fragment and we compare code fragments of the same category.
for example we may compare one implementation of bubble sort with one of quicksort or two implementations of binary search.
benchmark is a set of classes of the google guava library.
the set of guava classes contains methods that can be substituted with other equivalent code fragments equivalent according to the documentation .
we therefore consider all pairs of fragments consisting of a method ca and an equivalent fragment cb .
table iv lists all the subject class with the number of methods for which we have equivalent fragments and the total number of equivalent fragments.
table iii benchmark d ifferent implementations of search and sorting algorithms algorithm implementations binary search linear search bubble sort insertion sort merge sort quicksort b. internal consistency q1 we check the internal consistency of the measurement method with three experiments.
the first experiment checks the modifications are to reduce the space complexity of several measures.
for example the levenshtein distance in simmetrics uses o n2 space which is necessary to output the edit actions that define the edit distance.
however since we only need to compute the numeric distance we use a simpler algorithm.table iv benchmark g uava classes some of their methods and their equivalent implementations library class methods equivalences guavaarraylistmultimap concurrenthashmultiset hashbimap hashmultimap hashmultiset immutablebimap immutablelistmultimap immutablemultiset iterators linkedhashmultimap linkedhashmultiset linkedlistmultimap lists maps treemultimap treemultiset the obvious condition that a fragment is not redundant with itself since the two executions should be identical .
we conduct this experiment using the code fragments programs of benchmark for which we indeed obtain a redundancy measure of .
with the second experiment we check that the measurement is stable with respect to semantic preserving program transformations in code fragments as well as with semantically irrelevant changes in the input states.
we use once again the fragments of benchmark .
in a first set of experiments we first apply all the automatic refactoring operations available within the eclipse ide extract to local variable extract method inline expression and change name as many times as they are applicable but only once on each expression.
we then measure the redundancy between each original fragment and its refactored variants.
figure shows a minimal but indicative subset of the results of the refactoring experiments all other results are consistent .
we plot the redundancy measure for the binary search case study with data and code projections in histograms corresponding to all the refactoring operations identified by the color of the bar.
the x axis indicates the similarity measure used to compute the redundancy see table ii for the abbreviations of the similarity measures .
we notice immediately that code projections are inconsistent and are negatively affected by essentially all refactoring operations under every similarity measure.
by contrast data projections have an excellent consistency and stability and correctly report zero or near zero redundancy under all refactorings and with all similarity measures.
an analysis of the results reveals that data projections based on type rather than field name are particularly robust for some refactoring activities such as extract method and change name and less robust with respect to others that may change the execution actions.
for example if we apply the extract local variable operator to the variable in a for loop condition that checks the length of an array field then that changes the number of field accesses and thus the data projections.data projection .
.
.
.
adice man cos damlev dice euclid jaccard jaro jarow lev mc need ovlp qgrams smithw smithgredundancyextract to local variable change name inline expression extract method equivalent input code projection .
.
.
.
adice man cos damlev dice euclid jaccard jaro jarow lev mc need ovlp qgrams smithw smithgredundancyextract to local variable change name inline expression extract method equivalent input fig.
.
consistency of the redundancy measure using various projections on binary search.
notice that the scale of the first chart is from to .
.
this is to better highlight the fact that the results for the data projection are very low either exactly zero or very close to zero.
in a second consistency check we consider the redundancy measured between executions of the same fragment but starting from a different but semantically equivalent state test case .
this experiment does not conform to our definition of redundancy.
still it can be useful to test the stability of the measurement with respect to small insignificant variations in the initial state.
for these experiments we use the test cases that select the initial states within the same input category input category partitioning .
we report the results of these experiments also in figure in the rightmost bar in each group darkest color labeled equivalent input .
the results are in line with those of the other consistency checks that is data projections have excellent consistency and stability while code projections are inconsistent.
table v observational equivalence for the methods of the guava class array listmultimap method equivalence average clear .
containsentry object object .
containskey object .
containsvalue object .
create .
create int int .
isempty .
keys .
median .
a put object object .
putall multimap .
putall object iterable .
remove object object .
removeall object .
replacevalues object iterable .
size .
a see detailed measurements in table vi with the third consistency experiment we focus specifically on the measure of the degree of equivalence which corresponds to the probability that a probing code would not reveal a difference see section iii c .
for this experiment we can not use the fragments from benchmark since we know that thoseare all equivalent.
we therefore focus on the particular case of thearraylistmultimap class taken from benchmark .
table v lists all the methods that define our first code fragment ca for arraylistmultimap .
for each one of them we then measure and report in the table the degree of observational equivalence with all the corresponding fragments from benchmark average over several other fragments cband over all initial states .
the degree of equivalence is exactly 1for all methods which is what we expected except for method keys which is paired with a fragment that uses keyset .
table vi equivalence measurement of methods keys and keyset initial state generated cp failed cp equivalence s1 .
s2 .
s3 .
s4 .
s5 .
s6 .
s7 .
average .
.
.
a closer examination indicates that keys and keyset are similar but not completely equivalent since they differ when the multimap contains multiple values for the same key.
to better analyze the case we repeated the experiment with probing codes cpstarting from different initial states s1 s7.
the results show that the measurement correctly quantifies the differences in the sequences of actions and that the results are consistent across initial states and probing codes.
in summary the results of the three experiments described so far demonstrate the internal consistency and robustness of the measurement.
these experiments were also essential to identify the best projections and similarity measures.
in the following experiments we use only data projections with a few of the most effective similarity measures.
when not indicated the similarity measure is the levenshtein distance.c.
significance q2 we evaluate the significance of the redundancy measurements obtained through our method in two ways.
we first assess the ability of the measurement to identify differences redundancy at various levels of abstractions and more specifically low level code redundancy versus high level algorithmic redundancy.
we conduct this series of experiments on the cases of benchmark .
then in a second series of experiments based on some cases taken from benchmark we assess the ability of the redundancy measure to predict the effectiveness of a particular technique designed to take advantage of redundancy.
binary search .
.
.
.
damlev lev need smithw smithgredundancy liner search .
.
.
.
damlev lev need smithw smithgredundancy bubble sort .
.
.
.
damlev lev need smithw smithgredundancy insertion sort .
.
.
.
damlev lev need smithw smithgredundancy fig.
.
redundancy between implementations of the same algorithm.
figure shows the measurements of the redundancy between fragments that implement exactly the same algorithm.
each plot shows groups of values representing the average and standard deviation over the measurements between each implementation and every other implementation.
however notice that in some cases the results are always zero and therefore do not appear in the histogram.
so for example the first histogram shows the case of the four implementations of binary search see table iii one of which has zero redundancy and therefore the histogram shows three bars for each similarity measure.
in general the redundancy measures are low which makes sense since all the fragment pairs implement the same algorithm and can only have low level code differences.
binary search .
.
.
.
damlev lev need smithw smithgredundancy linear search .
.
.
.
damlev lev need smithw smithgredundancy bubble sort .
.
.
.
damlev lev need smithw smithgredundancy insertion sort .
.
.
.
damlev lev need smithw smithgredundancy fig.
.
redundancy between different algorithms.
figure shows the redundancy between fragments that implement different algorithms.
here each histogram represents one particular algorithm and shows the comparisons between each implementation of that algorithm and every other implementation of another algorithm in the same category sorting and searching .
here the measures are relatively high indicating a high degree of redundancy which makes sense since all the fragment pairs implement different algorithms and therefore should have significant differences.
the last series of results we present are intended to assess the significance of the measurement in terms of its predictive ability.
for this we analyze the redundancy of some equivalent fragments that we used as automatic workarounds with a technique intended to increase the reliability of systems .
in particular we consider a number of pairs of equivalent code fragments used with varying degrees of success as workarounds.
we then measure the redundancy for each pair and see how that correlates with the success ratio.
table vii shows the results of these experiments.
for each subject system we sort the equivalent pairs by their success ratio to highlight the correlation with the measure of redundancy.table vii correlation between redundancy measure and the effectiveness of automatic workarounds system method ca workaround cb success ratio redundancy caliperiterators.forarray a arrays.aslist a .iterator .
.
linkedhashmultiset.retainall collection c foreach o in map if o not in c map.remove o .
.
arraylistmultimap.putall object k collection c foreach o in c put k o .
.
linkedhashmultimap.putall object k collection c foreach o in c put k o .
.
linkedhashmultimap.create create .
.
linkedhashmultimap.create int int create .
.
linkedhashmultimap.isempty size ?
true false .
.
carrotimmutablemultiset.of object..c foreach o in c builder .setcount o count o in c .
.
immutablemultiset.of object..c builder .add ..c .build .
.
arraylistmultimap.putall object k collection c foreach o in c put k o .
.
immutablemultiset.of object o builder .add o .build .
.
lists.newarraylist new arraylist .
.
lists.newarraylist new arraylist .
.
lists.newarraylistwithcapacity int c new arraylist .
.
lists.newarraylistwithcapacity int c new arraylist c .
.
maps.newhashmap maps.newhashmapwithexpectedsize .
.
maps.newhashmap new hashmap .
.
maps.newhashmap new hashmap .
.
the most obvious cases are when the two code fragments caand cb are either not redundant at all or completely redundant.
when there is no redundancy the equivalence is also completely ineffective to obtain workarounds and conversely when we obtain a measure of complete redundancy in the case ofiterators.forarray a in caliper the equivalence is always effective as a workaround.
the redundancy measure is also a good indicator of the success of a workaround in the other non extreme cases.
consider for example the case of immutablemultiset.of object..c in carrot where the first equivalent alternative has a higher redundancy measure and a higher success ratio than the second one 07and0 59vs.
12and0 .
this case shows that the redundancy measure can be an effective predictor to select or rank alternative fragments for use as workarounds.
overall we obtain a positive correlation coefficient .
from which we conclude that our redundancy measure is indeed a good indicator and predictor of useful design properties.
d. threats to validity we acknowledge potential problems that might limit the validity of our experimental results.
here we briefly discuss the countermeasures we adopted to mitigate such threats.
the internal validity depends on the correctness of our prototype implementations and may be threatened by the evaluation setting and the execution of the experiments.
the prototype tools we used are relatively simple implementations of well defined metrics computed over execution logs and action sequences.
we collected and filtered the actions of interests with robust monitoring tools and we carefully tested our implementation with respect to the formal definitions.
threats to external validity may derive from the selection of case studies.
an extensive evaluation of the proposed measurements is out of the scope of this paper whose goal is to discuss and formally define the concept of software redundancy.
we present results obtained on what we would refer to as ground truth that is on cases with clear andobvious expectations that would therefore allow us to check the significance and robustness of the proposed metrics.
v. c onclusion in the past we developed techniques to exploit the redundancy of software to make software more reliable and adaptive.
several other techniques more or less mature exploit the redundancy of software in a similar way.
on the basis of this past experience we now want to gain a deeper and at the same time broader understanding of software redundancy.
and the first step is to model andmeasure redundancy.
this is what we did in this paper.
we formulated a model that we consider expressive and meaningful and we derived from it a concrete measurement method that we evaluated for its consistency does the measurement make sense at a very basic level?
and predictive ability is it a good indicator of useful properties?
.
our experiments show that the measurements are indeed consistent and significant which means that they can be useful in support of a more principled use of redundancy in software design.
we see a number of ways to build upon this work.
one would be to enhance the model.
the main limitation of the model is that it considers only single threaded code fragments.
notice in fact that the model as well as the measure of dissimilarity is based on the notion of an execution consisting of one sequence of actions.
one way to model multi threaded code would be to linearize parallel executions although that might be an unrealistic oversimplification.
other straightforward extensions include a more extensive experimentation and an improved measurement in particular in sampling the state space.
however our primary interest is now in using the model and the measurement to study redundancy further.
our ultimate goal is to comprehend redundancy as a phenomenon to harness its power by design.
acknowledgment this work was supported by the swiss national science foundation with project shade grant n. .