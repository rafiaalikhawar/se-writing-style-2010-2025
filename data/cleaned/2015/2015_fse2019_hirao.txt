thereview linkage graph forcodereview analytics arecovery approachand empiricalstudy toshikihirao nara institute of scienceand technology nara japan hirao.toshiki.ho7 ais.naist.jpshane mcintosh mcgilluniversity montr al canada shane.mcintosh mcgill.ca akinoriihara wakayamauniversity wakayama japan ihara sys.wakayama u.ac.jpkenichi matsumoto nara institute of scienceand technology nara japan matumoto is.naist.jp abstract modern code review mcr is a pillar of contemporary quality assurance approaches where developers discuss and improve code changespriortointegration.sincereviewinteractions e.g.
comments revisions arearchived analyticsapproacheslikereviewer recommendation and review outcome prediction have been proposed to support the mcr process.these approachesassume that reviews evolve and are adjudicated independently yet in practice reviewscan be interdependent.
inthispaper wesetouttobetterunderstandtheimpactofreview linkage on code review analytics.
to do so we extract review linkage graphs where nodes represent reviews while edges represent recovered links between reviews.
through a quantitative analysis of six software communities we observe that a linked reviewsoccurregularly withlinkedreviewratesof25 in openstack inchromium and3 8 in android qt eclipse and libreoffice and b linkage has become more prevalent over time.
throughqualitative analysis we discover that linksspan types that belong to five categories.
to automate link category recovery we train classifiers to label links according to the surrounding document content.thoseclassifiersachievef1 scoresof0.71 0. at leastdoublingthef1 scoresofazerorbaseline.finally weshow thatthef1 scoresofreviewerrecommenderscanbeimprovedby 88 5 14 percentage points by incorporating information from linked reviews that is available at prediction time.
indeed review linkage should be exploited by future code review analytics.
ccs concepts software andits engineering softwareevolution .
keywords code review software analytics miningsoftware repositories permissionto make digitalor hard copies of allorpart ofthis work for personalor classroom use is granted without fee provided that copies are not made or distributed forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation on the first page.
copyrights for components of this work owned by others than acm mustbehonored.abstractingwithcreditispermitted.tocopyotherwise orrepublish topostonserversortoredistributetolists requirespriorspecificpermissionand ora fee.
request permissions from permissions acm.org.
esec fse august 26 30 tallinn estonia associationfor computing machinery.
acm isbn ... .
format toshikihirao shanemcintosh akinoriihara andkenichimatsumoto.
.
the review linkage graph for code review analytics a recovery approach and empirical study.
in proceedings of the 27th acm joint european software engineering conference and symposium on the foundations of software engineering esec fse august 26 30 tallinn estonia.
acm newyork ny usa 12pages.
introduction moderncodereview mcr alightweightvariantoftraditional code inspections allows developers to discuss the premise content andstructureofcodechanges.manycommunitiesadopta review then commit rtc philosophy where each code change must satisfy review based criteria before integration into official repositoriesispermitted.sincemcrtoolsarchivereviewingactivities e.g.
patch revisions review participants discussion threads active developmentcommunities generateplenty of mcrdata.
researchershaveproposedanalyticsapproachesthatleverage mcr data to support practitioners.
for example reviewer recommenders help developers to select appropriate reviewers and review outcome predictors estimate the likelihoodofacode changeeventually being integrated.
when performing code reviewanalytics each review has traditionally been treated as an independent observation yet in practice reviewsmaybeinterdependent.byignoringconnectionsbetween reviews review analytics approaches may underperform.
for example the discussion for review openstack.org c of theopenstack neutron project occurred on its linked review .
without considering the comments on the linked review a review outcome predictor would mistakenlypresumethatreview 314319hadnodiscussion and wouldthus be unlikely to be integrated.
moreover review of theopenstack nova project is abandoned because a competing solution in the linked review 134853wasintegrated.toensureafairreviewprocess reviewerlistsofcompetingsolutionsmayneedtobesynchronized yetlinksare not analyzedbytoday sreviewer recommenders.
in this paper we set out to better understand the impact of reviewlinkageoncodereviewanalytics.todoso weextractthe review linkage graph from six active mcr communities a directed graph where nodes represent reviews and edges represent links between reviews.
we analyze and leverage those graphs to address the following fourresearch questions esec fse august tallinn estonia toshikihirao shanemcintosh akinoriihara andkenichi matsumoto rq1 towhat degree are reviewslinked?
motivation to gain an initial intuition about the connectedness of reviews we first set out to quantitatively analyze the extractedreviewlinkage graphs.
results linkageratesrangefrom3 to25 .linkagetendsto be more common in the two largest communities in openstackand17 in chromium likelybecausetheyhaveinvested moreheavilyincodereviewing.indeed thesecommunitieshave significantlymorecommentsandreviewersperreview pairwise mann whitney u tests with bonferroni correction .
andnon negligible cliff sdelta effectsizes .
rq2 whyare reviewsbeing linked?
motivation the potentialreasons for review linkageare manifold.toexplorethesereasons wesetouttoqualitativelyanalyze recoveredlinksbetween reviews.
results using open coding and card sorting we discover types of review links that belong to five categories i.e.
patchdependency broadercontext alternativesolution versioncontrolissues andfeedbackrelated.thesedifferent link types have different implications for review analytics techniques.forexample whilebroadercontextlinksindicatethata discussionmayspanacrosslinkedreviews alternativesolution linkspointoutcompeting solutions.
rq3 to what degree can link categories be automatically recovered?
motivation the qualitative approach that we used to address rq2isnotscalableenoughforlarge scaleanalysesoflinkcategories.
hence we want to explore the feasibility of training automaticclassifiers to identifylinkcategories.
results wetrainlinkcategoryclassifiersusingfive classificationtechniques.theseclassifiersatleastdoubletheperformance ofazerorbaseline achievingaprecisionof0.71 0. arecall of0.72 0. andan f1 score of0.71 0. .
rq4 towhatdegreedolinkedreviewsimpactcodereview analytics?
motivation whilerq1 rq3suggestthatlinkagemayimpact revieweranalytics theextentofthatimpactisunknown.weset outtoquantifythatimpactbycomparingpriorreviewanalytics techniques to extendedversionsthat are linkaware.
results code review analytics tend to underperformon linked reviews.
in 84 of linked reviews reviewer recommenders omit at least one shared reviewer.
moreover review outcome predictorsmisclassify35 39 oflinkedreviews.link aware approaches improve the f1 score of reviewer recommenders by 88 5 14percentagepoints .
our empirical study indicates that linkage is a rich activity that shouldbetakenintoconsiderationinfuturemcrstudiesandtools.
in addition this paper contributes a replication package 1which includes a reviewlinkagegraphsthatfeature1 702reviewsand 341linksfromthesixstudiedcommunities b 752manually coded links spanning types and five categories and c scripts that reproduce our statisticalanalyses .
paper organization.
the remainder of this paper is organized as follows.
section 2situates this paper with respect to the related 3describesthestudiedcommunities andtheirmcr processes.sections 4 7presenttheexperimentsthatweconducted to address rq1 rq4 respectively.
section 8discusses the broader implicationsofourresults.section 9disclosesthreatstothevalidity ofour study.finally section 10draws conclusions.
related work linkageofrelatedsoftwareartifactshaslongbeenconsideredan importantphenomenon.canfora etal.
foundthatlinksbetween issue reports of different software projects are not uncommon.
boisselleandadams reportedthat44 ofbugreportsinubuntu arelinkedtoindicateduplicatedwork.ma etal.
showedthat linkedissuesdelaythereleasecycleandincreasemaintenancecosts.
moreover theyfoundthatrecoveringalinkisadifficulttask often taking developers more thanone dayto do byhand.
toeasetherecoveryoflinks researchershaveproposedautomaticapproaches.antoniol etal.
appliednaturallanguageprocessing nlp techniquestodetectlinksbetweensourcecodeand relateddocuments.alqahtani etal.
proposedanautomaticapproach to recover links between api vulnerabilities.
guo et al.
useddeeplearningtechniquesthatexploitdomainknowledgeto detect semantic links.
rath et al.
detect missing links between commits andissuesusing processandtext relatedfeatures.
linkagealsoappearsinpeercodereviewsettings.zampetti et al.
found that developers reference other resources in reviews toenhancedocumentation of pullrequests.
perhaps themost similar prior work is that of li et al.
who reported that of github pull requests from python projects on github have links whichspansix types.thispaperexpandsupontheworkof liet al.by studying linkage in six large and successful software communities rather than a broad sample of github projects and the impact oflinkage onreviewanalytics approaches.
.
reviewerrecommendation selecting appropriate reviewers plays an important role in the value that is generated by a code review.
bosu et al.
found thatthereviewerexpertiseisanimportantfactorindetermining whethermicrosoftdevelopersconsidercodereviewfeedbackuseful.
kononenko et al.
also found that reviewer expertise is a key factor indeveloper perceptionsof code reviewquality at mozilla.
tosupportauthorsinselectingappropriatereviewers researchers have proposed reviewer recommenders.
for example balachandran proposed reviewbot which recommends reviewers based on pastcontributionsto thelines thatwere modified bythepatch.
thongtanunam et al.
proposed revfinder which recommends reviewers based on their prior contributions to files in similar locations within the codebase.
more recent work has improved reviewer recommendations by leveraging past review contributions technological experience and experience with other related projects and the content of the patch itself .
kovalenkoetal.
questionthevalueofrecommendingreviewers incaseswhere the bestreviewers are already known.
review links may also provide useful information for the reviewer recommenders.
since links may indicate a strong relationship between connected reviews reviewers who are recommended for one of the linked reviews may also need to be recommendedthereviewlinkagegraphforcode reviewanalytics esec fse august tallinn estonia table anoverview ofour subjectcommunities.
product language studiedperiod reviews revs projects openstack python 2011 01 chromium javascript 2011 01 android java 2008 01 qt c 2011 01 eclipse java 2012 01 libreoffice python 2012 01 total .8years for theothers.
for example review is another attemptat tackling the underlyingtaskof theabandoned review .
topreservecontinuityofthereviewdiscussion thereviewersof review 105238should alsobe recommended for review .
.
codereviewoutcome not all changes that are submitted for code review end up being integrated.indeed wei gerber etal.
foundthat39 and42 of openafs and flac code changes were eventually integrated.
jianget al.
found that of linux code reviews were eventuallyintegrated.baysal etal.
foundthat36 39 ofcodechanges inmozillafirefox were rejectedandresubmittedat leastonce.
to better understand the chances of submissions being integrated researchershavestudiedthecharacteristicsofcodechanges andtheirreviews thatwereeventuallyintegrated.forexample wei gerber etal.
foundthatsmallcodechangesareintegrated more frequently than large ones.
jiang et al.
showed that prior experience patch maturity and code churn significantly impact the likelihood of integration.
baysal et al.
found that nontechnical issues are a common reason for abandonment in webkit and blink projects.
moreover tao et al.
found that patch designissueslikesuboptimalsolutionsandincompletefixesareoften raised during the reviews of the abandoned code changes of the eclipseandmozillaprojects.
review links may affect orimply review outcomes.
for example sincereviewsthatsupersedepriorreviewshavehadtheopportunity to improve the design of the code change they may have a higher likelihoodofbeingintegratedthaninitialsubmissions.moreover large tasks that have been divided into a series of reviews e.g.
reviews 1025323and 1025434ofopenstack willhavereview outcomes that are inherently linked.
priorworksuggeststhatreviewlinkageisimportant however the extentoflinkageinlargecommunitiesanditsimpactonreview analyticsisunclear.inthispaper wesetouttobridgethesegaps.
studied communities the goal of our study is to extract and analyze review graphs of largesoftwarecommunitiesthathaveinvestedintheirmcrprocesses.
to do so we focus on the six popular communities that appearintherecentrelatedwork .openstack isacloud computing platform.
chromium is an open source web browser.
android is a mobile software platform.
qtis a cross platform eclipseisanintegrateddevelopmentenvironment ide andassociatedtools.
libreoffice isafreeandopen implementationofthe office software suite.
the studied communities use gerrit for code review.
to conductourstudy wecollectmcrdatausingthegerritapi.table providesanoverviewofthecollecteddata.below weprovidean overviewofthe gerritprocesses of the studiedcommunities.
gerritcodereviewprocess.
gerritisapopular web basedcode reviewmanagementtoolthattightlyintegrateswiththegitversion control system.
rather than pushing code changes directly to an upstream git repository developers push changes to gerrit where only after satisfying project specific review criteria e.g.
a member of the core team approves the changes may the author push their changes into the upstream git repository.
similar to other code reviewingprocesses e.g.
githubpullrequests eachgerritreview goes throughthe following phases uploading a proposed set of changes.
an author uploads a proposed set of changes to the gerrit system and invites reviewers tocritique it byleaving comments for the author to clarify discuss oraddress.
solicitingpeerfeedback.
reviewerscritiquethepremise content and structure of theproposed set of changes and provide feedbackintheformof generalorinlinecomments thatcorrespondto the entire changeandlineswithin it respectively.
revising the proposed patch.
authors may revise their set of changes to address reviewer feedback.
after revising the reviewreturns to phase2.
automatedtesting.
automatedtestsareexecutedoneachset of changes to mitigate the risk of introducing regression issues.
ifthesetestsfail thesetofchangesisblockedfromintegration until the author uploads a revision that addresses the issues.
whenrevisions are uploaded the reviewreturns to phase2.
final integration.
oncethesetofchanges satisfiesreviewer and automated testing criteria the author can integrate it into upstream git repositories.
review graph extraction rq1 in this section we set out to study the extent to which reviews are linked to one another in our studied communities.
to do so we extractreviewgraphsfromthestudiedcommunities.thereview graphrg r l isadirectedgraphwiththefollowingproperties graph nodes rrepresent reviewentries.
eachreview entry r ris comprised of a set of properties such as idr a uniquereviewidentifier dr thechangedescription prr the set of patch revisions revr the set of reviewers .
gcr andicr generalandinline comments respectively .
graph edges lrepresent links between review entries.
each edgel lhas a type tlthat describes why the link was recorded whichwe study insections 5 7. the set of reviews ris what has typically been extracted and analyzed by prior work on code review.
in this section we first propose a lightweight approach to recover graph edges lfrom the dr gcr andicrfields of each r r .
.
then we apply that approach to the studied communities and analyze the extracted graphs to addressrq1 .
.esec fse august tallinn estonia toshikihirao shanemcintosh akinoriihara andkenichi matsumoto .
linkrecoveryapproach weperformapreliminaryanalysisof410randomlyselectedreviews togaininsightintothelinkagehabitswithinthestudiedcommunities.
we observe that links appear in review description fields dr as well as within general and inline comment threads gcr andicr .
moreover we observe twowaysthat linksare recorded bychangeid e.g.
ic8aaa0728a43936cd4c6e1ed590e01b a8f0fbf5b i.e.
a40 digithexadecimalidentifierassigned to each review at creation time prefixed with an ito avoid confusionwithgit commit ids .
byurl e.g.
.
thus torecoverlinksfromareview r r wescanitsdescription draswellasallofthegeneralandinlinecomments gcr icr using regular expressions.
to detect changeids our regular expression scansfortermsoftheform i .todetecturls ourregularexpressionisoftheform https?
proj c whereprojis replaced with the base url of the project e.g.
review.openstack.org .forthechromium community ourregularexpressionsneededtobeadaptedto https?
chromium revi ew.googlesource.com c repo whererepocorresponds to any of the repositories within the chromium community.the linkrecovery processisrepeated r r. .
results by applying our link recovery approach to the six studied communities we set out to better understand i the prevalence of review linkage and ii linkage trends over time.
to do so we measure a linkage rate for each studied system i.e.
the proportion of reviews that are connectedbyat leastone link.
prevalenceoflinkage.
table2showsthat17 and25 of chromiumandopenstack reviews are connected by at least one link respectively.
although the linkage rate in qt eclipse andandroidreviews are lower 8 linkage is not uncommon.
however the libreoffice linkage rate is only .
we suspect that this result is reflective of the differences in the importance that the studied communities have placed on code review.
indeed reviewsinthe openstack andchromium communitiesreceive17 and comments on average whereas reviews in other subject communities receive 4 8 comments on average.
two tailed unpairedmann whitneyutestsbetween openstack andtheother studied communities after bonferroni correction to control for family wise errors .
.
indicate that openstack receivessignificantlymorecommentsthantheotherstudiedcommunities p .
with cliff s delta effect sizes of negligible when compared to chromium .
.
small when comparedto android andqt .
.
.
.
medium when compared to eclipse .
.
.
and large when compared to libreoffice .
.
.
furthermore openstack reviews tend to involve more reviewersthantheotherstudiedcommunities averagingtworeviewers per review more than the next highest community chromium .
two tailed unpaired mann whitney u tests indicate that openstackreviews have significantly more reviewers than the other studied communities p .
with cliff s delta effect sizes of mediumwhencomparedto chromium .
.
.
.
.
.
.
.
.
studied periodlinked review ratesubject system openstack chromiumaosp qteclipse libreoffice figure monthly linkagerate inthe studied communities.
and large when compared to android qt eclipse andlibreoffice .
.
.
.
.
.
we also find that there is no tendency where the larger systems are likely to receivemorecommentsintermsofanindividualcontribution i.e.
2 4 comments per reviewer on average across our studied systems .
indeed despite of the significant differences of unpaired mann whitney u tests across our six studied systems cliff s delta effectsizesarenegligiblewhencomparedto qtandlibreoffice .
.
.
smallwhencomparedto android and eclipse .
.
.
.
and medium when comparedto chromium .
.
.
.
table2also shows that the largest proportion of links are recoveredfromdiscussionthreads gc ic .indeed 97 oflinksare recoveredfrom gcandicthreads.thisindicatesthatlinkstend to emergeduringthe reviewratherthanwhen itiscreated.
furthermore table 2shows that 40 of links connect reviews across project boundaries.
for example review linksfromthe novaprojecttothe cinderprojectof openstack .
furthermore openstack showsagreaterrateofcross projectlinks than the other studied communities likely because the openstack community develops more projects than the other studied communities.indeed table 1showsthat openstack containsatleastfour times as manyprojectsas the otherstudiedcommunities.
linkagetrends.
figure1showsthatlinkageratesinthefourcommunitiesthathavemadethelargestinvestmentsincodereview i.e.
personnel and activity per review have stabilized or peaked in the more recent studied periods.
indeed the linkagerate in the openstackcommunityhasarapidlyincreasingtrenduntillate2014and more gradual increases in recent months.
the chromium community began with moderate linkage rates until mid when rates droppedtobelow .
however therates have climbedabove reviewanalytics esec fse august tallinn estonia table review graphcharacteristics inthesubjectcommunities.
productlinked reviews perreview mean perreviewer description generalcomment inline comment cross project reviews reviews comments reviewers comments links links links links links links links links openstack chromium android qt eclipse libreoffice inmid .thisgrowthmaybeduetoseveralfactors e.g.
communityinitiative growthintaskcomplexity .the qtandandroid communitieshadlinkageratesbelow7 untilmid whenrates roughlystabilizedat and9 respectively.
on the other hand linkage rates remainstable or are decreasing inthetwostudiedcommunitiesthathavemadetheleastinvestment in code review.
indeed the libreoffice community shows a stable trend whilethe eclipsecommunity s trend isdecreasing.
rq1 linkedreviewsoccurregularlyincommunitiesthathave madelargeinvestmentsincodereview.thus codereviewanalytics shouldlooktolinkageasapotentialsourceofusefulinformation.
qualitative analysisofreview links rq2 reviews may be linked to other reviews for several reasons.
for example alinkmayexpressadependencybetweenreviews e.g.
6isdependenton ortheevolutionofanearlierideaintoitscurrentform e.g.
isafollowuppatch to .
inthissection wesetouttobetterunderstandtheunderlying reasonsforreviewlinkagethroughaqualitativeanalysis.tounderstandwhyalinkhasbeenrecorded weuseamanually intensive researchmethod whichcreatespracticallimitationsonthebreadth of communities that we can analyze.
thus we elect to analyze the openstack community the largest and most dynamic graph in oursetofstudiedcommunities seetables 1 2andfigure .the openstack community is composed of several projects of which weselectthetwolargest foranalysis i.e.
nova theprovisioning managementmodule and neutron thenetworkingabstraction interface .
below we describe our approach to classify links in the studiedprojects .
andpresent the results .
.
.
approach we applyanopencoding approach to classifyrandomly sampled links between reviews.
open coding is a qualitative data analysis methodby which artifacts under inspection review links in our case are classified according to emergent concepts i.e.
codes .
aftercoding weapplyopencardsorting toliftlow levelcodes to higher level concepts.
below we describe our sampling coding andcardsortingprocedures inmore detail.
sampling.
section4showsthatthereare133 650linkedreviewsin theopenstack community 144ofwhichappearinthe novaand change i7b18b767 fix wrong exception return in fixed ips v2 extention review.openstack code review 3powered by gerrit code review .
.
g1707fec get help press ?
to view keyboard shortcuts body reserve none self.assertraises exceptions.notfound self.client.reserve fixed ip my.invalid.ip body any suggestions?
eli.
ken ichi ohmichi patch set eli we faced this kind of problems and we can change tempest code before this like self.assertraises exceptions.notfound self.assertraises exceptions.notfound exceptions.badrequest self.client.reserve fixed ip my.invalid.ip body oct eli qiao patch set hi ken ichi thanks i v post a patch to tempest at let s wait for it merged first.oct christopher y eoh patch set code review pending tempest change merge oct alex xu patch set code review oct ken ichi ohmichi patch set recheck oct elastic recheck patch set i noticed jenkins failed i think you hit bug s check tempest dsvm ironic pxe ssh nv if you b ... oct ken ichi ohmichi patch set code review workflow oct elastic recheck patch set i noticed jenkins failed i think you hit bug s gate grenade dsvm if you believe we ve correctl ... oct ken ichi ohmichi patch set recheck oct eli qiao patch set recheck oct jenkins change has been successfully merged into the git repository.
oct jordan pittier patch set reverted this patchset was reverted in change i191 b626a471626f334e4835fab602acea505f f78 feb 2016reviewer author author reviewer figure2 anexampleofareviewlinkfromreview innova.
neutron projects.
since coding of all of these links is impractical we randomly sample novaandneutron reviewlinksfor coding.
to discover as complete of a set of link types as possible we strivefor saturation .similartopriorwork wesetoursaturation criterion to i.e.
we continue to code randomly selected links until nonewcodes have been discoveredfor consecutive links.
to ensure that we analyze links that appear in descriptions and comments we aim to achieve saturation twice once when coding description based links and again when coding comment based links.wereachsaturationaftercoding340comment basedlinks and146description basedlinksin nova and161comment based linksand105description basedlinksin neutron .
coding.
coding was performed by the first and second authors during collocated coding sessions.
both coders have experience with code reviews both in research and commercial software development settings acting as both patch authors and reviewers .
in total thesecoding sessions took hours or112person hours .
when codinglinks the codersfocused on the key reasons why the link was recorded.
for example figure 2shows that comments fromreviewer1on novareview 126831haveinspiredtheauthor tocreatereview .bothcodersindependentlycodeandthen discusseachlinkuntilaconsensusisreached.wealsorecordthe direction of the link e.g.
review links to review .
in theory multiple codes may apply to each link yet in practice we find that multi coded links are rare.
indeed while a link may havedifferentcodesifinterpretedindifferentdirections wedonot find any multi codeddirectionallinks.
since open coding is an exploratory data analysis technique it may be prone to errors.
to mitigate errors we code in three passes.
first since codes that emerge late in the process may apply toearlierreviews aftercompletinganinitialroundofcoding we perform a second pass over all of the links to correct miscodedesec fse august tallinn estonia toshikihirao shanemcintosh akinoriihara andkenichi matsumoto table the frequency of the discovered types of review linkagein openstacknova andneutron .
categoryfrequency nova neutron c1 patchdependency patch ordering root cause shallowfix follow up merge relatedreviews multi part c2 broadercontext relatedfeedback demonstration additionalevidence c3 alternativesolution superseding duplicated c4 versioncontrol issues integrationconcern gerritmisuse revert c5 feedbackrelated fixrelatedissues feedbackinspiredreviews entries.duringthefirstcodingpass wecodeonlyusingthelink source description comment .
in several cases more contextual informationwasneeded.wecodedsuchcasesas needsadditional context duringthefirstcodingpass.duringathirdcodingpass we check additional sources of information e.g.
the content of the patch thelinkedreview commentsindiscussion threads tocode thesecasesmorespecifically.afterthethreecodingpasses allof the sampledlinkshave been assignedto aspecific code.
cardsorting.
similartopriorstudies weapplyopen cardsortingtoconstructataxonomyofcodes.thistaxonomyhelps us to extrapolate general themes from our detailed coded data.
the card sorting process is comprised of two steps.
first the coded linksaremergedintocohesivegroupsthatcanberepresentedby a similar subgraph.
second the related subgraphs are merged to form categoriesthat can be summarizedbyashort title.
.
results table3provides an overview of the categories that summarize related labels the complete table is available online1 .
we observe that the frequenciesat which thelink labels appear are consistent between the two studied projects.
moreover we only coded two of links from novaand two of links from neutron as falsepositives i.e.
spuriouslydetectedlinksthatdonotindicate a relationship between reviews suggesting that our link extraction approach does not produce much noise precision .
in both cases .furthermore we requiredadditionalcontextinformation beyond the link source to code links all of which were more specifically coded during the third pass when we analyzeadditionalinformationsources.
below wedescribe thediscovered codes according to the categoriesto whichthey belong.
patch dependency c1 .
we find that and of the analyzedlinksin novaandneutron connectreviewstoothersthat they depend upon.
patch dependency links may influence integration decisions and the reviewers who should be recommended.
indeed theintegrationdecisioninonereviewmaybeinherently linkedtothat ofanotherif theyshare adependency.
for example review 1027045of thenovaproject was only abandoned because ofitsdependencyonreview whichwasabandonedearlier.
moreover reviewers of a dependent review may need to review its dependencyaswell.forexample areviewerofreview was added only because they reviewed its dependency review .
we further explore the usefulness of these linkage based reviewer invitationsinsection rq4 .
ab ba a patch ordering root cause shallow fix follow up merge related reviews multi partb c c1 patch dependency ccode baselinkage direction patch integration figure the patch dependencysubgraphs.
figure3showsthreeshapesthatpatchdependencylinkstake.
first patch ordering root cause shallow fix and follow up take theshapeoftwoeventuallyintegrated orabandoned reviewsthat sharealink.whiletheyshareashape thesemanticsofthepatterns differ i.e.
patch ordering links indicate a timing dependency that mustberespectedatintegrationtime whilefollow up rootcause andshallowfixlinksproviderationaleforreviewbbypointingto enabling enhancements or limitations in review a. second merge related reviews links merge two or more reviews into a more cohesivewhole.finally multi partlinksindicatethatalargereview has been split intoaseries of smallerreviews.
wei gerber et al.
observed that smaller patches tend to be accepted in two large open source projects.
rigby et al.
argue that one of the statutes of an efficient and effective code review process is the early frequent review of small independent completesolutions .thefrequencyofthemulti partpattern i.e.
thesplittingoflargepatchesintosmallerones maybeanindication that theseprior observations stillhold.
reviewanalytics esec fse august tallinn estonia broader context c2 .
we find that and of the analyzed linkspointtootherreviewswithrelevantresources.theindividual analysis of reviews that are connected with broader context links may not be valid.
indeed analyses of review outcome prediction oftencomputethelengthofdiscussionthreads .however a discussion may span across several reviews when broader context links are present.
for instance a reviewer of review 1552239asks the authorto refer to asimilar discussiononreview .
related feedback demonstration additional evidenceabcomment code c2 broader context or or code base figure the broader contextsubgraph.
figure4shows that our three codes within the broader context category share the same shape however the codes differ in the artifact to which they refer.
related feedback links connect discussions on one review to discussions in other reviews while demonstration links point to example code from other reviews.
additional evidence links point to other reviews as proof code discussions specifications of the existence removal or relevance oftheproblemsthatareaddressedbythereviewunderinspection.
alternative solution c3 .
wefindthat14 and15 oftheanalyzed links connectreviews to others thatimplement similar functionality.
similarto patch dependency links alternative solution links may also impact integration decisions and reviewer recommendations.forexample review 6743110wasabandonedbecause another submitted solution forthe same underlying issue review waspreferred.especiallyinsuchexampleswherean either or decision needs to be made the same reviewers should likely be invited to all of the competing reviews for the sake of fairness .furthermore priorworkhasdemonstratedthatalack of awareness of concurrently developed solutions may result in redundantwork andisakeysourceofsoftwaredevelopment waste .theseconflatedintegrationdecisionsarenotcongruent with review outcome or reviewer recommendation models that assumeeachsubmissionisindependently adjudicated .
c3 alternative solution superseding duplicationa b acode base figure the alternative solutionsubgraph.
category share the same shape yet differ in their semantics.
supersedinglinksshowthatthesolutioninanearlierreviewhas beenreplacedwithanupdatedsolutioninthecurrentreview while duplication links highlight the existence of another competing solution to the same underlying problem.
in a large scale crosscompany software organization like openstack it is difficult to coordinatedevelopmenteffort.however thefrequencyatwhich work isduplicatedsuggeststhat tooling mayhelp.
version control issues c4 .
we find that of analyzed links point to reviews that introduced version control issues.
rigby and storey alsofoundsuchissuesareoftendiscussedduringthe broadcast based reviews in several open source systems.
shimagakietal.
foundthat5 ofcommitsinalargeindustrialsystem wererevertedafterbeingintegrated.sincerevertisoneofthecodes within our category our review graphs can complement version controldatatobetterunderstandthepracticeofrevertingcommits.
ab integration concerns gerrit misuse revert c4 version control issues conflict code base figure the versioncontrolissues subgraph.
figure6shows thatour three codes withintheversioncontrol issues category share the same shape.
integration conflict and gerrit misuse links expose technical integration or gerrit issues whilerevertlinksindicatethat apartialorcomplete rollback.
feedbackrelated c5 .
wefindthat5 and4 ofanalyzedlinks innovaandneutron connect reviews to others that resolve or wereinspiredbyreviewercomments.reviewsthatwereinspired by feedback in another review might be more likely to be accepted since one reviewer is already in favour of the idea.
for example in review 11areviewer sfeedbackinspiredthecreationof the new review .
then one of reviewers of joined review and eventually approves it for integration.
there are twopossiblewaystoactuponc5 linkedreviews.the reviewer who inspired the change may be well suited to review the inspired change.
thus reviewer recommenders may need to recommend them.
on the other hand since the reviewer who inspired the changemaynotbeimpartialwhenreviewingtheinspiredreview reviewer recommenders may need to recommend other reviewers.
figure7shows thatour two codes within the feedback related categorysharethesameshape.fixedrelatedissueslinksshowthat part of a raised concern has been addressed by another review.
feedback inspiredlinksshowanewcontributionwherefeedback onreviewa inspires the creation of anewpatch.
rq2 a broad variety of reasons for linkage exist.
these different types of links may introduce noise in or opportunities for improvement ofcode review analytics.
august tallinn estonia toshikihirao shanemcintosh akinoriihara andkenichi matsumoto c5 feedback related feedback inspired fix related issues ab c code base figure the feedbackrelated subgraph.
automated link classification rq3 insection wefindthatseveraltypesoflinksmayimpactreviewer recommendation and outcome prediction.
since different review analyticstechniquesmayneedtotraverseorignorelinksdepending on the type a more scalable approach to link type recovery is needed.indeed ittooktheauthors112person hourstocode752 reviewlinks seecodinginsection .
.ifwecontinuetocodeat thisrate itwouldtakeanadditional19 793person hourstocode the remaining reviewsinthe openstack data set.
inthissection westudythefeasibilityofusingmachinelearning techniquestoautomaticallyclassifylinksbycategories.todoso we use the manually coded data from section 5as a sample on whichtotrainandevaluateclassifiersthatidentifythelinkcategory c1 c5 based on the document that it appears within i.e.
the review description field or the comment in the general or inline discussion thread .
below we describe our approach to automated linkcategory classification .
followedbythe results .
.
.
classification approach feature extraction.
weapplystandardtextpreprocessingtechniques to lessen the impact of noise on our classifiers.
we first tokenizethedocumentandremovestopwordsusingthepython nltk stop word list.
next we apply lemmatization to handle term conjugationusingthepythonnltk lemmatize function.finally weconverteachsampleddescriptionorcommenttoavectorofthe term frequency inverse document frequency tf idf weights of its terms.
broadly speaking terms that appear rarely across documents and or often within one document are of higher weight.
we use the python scikit learn tfidfvectorizer function to compute tf idf scores for alldocuments inatraining sample.
classifier validation technique.
to estimate classifier performanceonunseendata weapplytheout of samplebootstrapvalidation technique which tends to yield more robust results than other validation techniques e.g.
k fold cross validation .
first a bootstrap sample of size n is randomly drawn with replacementfromtheoriginalsampleofthesamesizen.thisbootstrap sampleisusedtotrainourclassifiers whilethedocumentsfrom the original sample that do not appear in the bootstrap sample are set aside for testing.
since the bootstrap sample is selected with replacement onaverage .
ofthedocumentswillnotappear inthebootstrapsampleandcanbeusedtoevaluateclassifierperformance.we perform iterations of the bootstrapprocedure reporting the mean performance scores across these iterations to ensure that our performance measurements are robust.classification techniques.
to train our classifiers we experiment with a broad selection of popular classification techniques.
support vector machines svm use a hyperplane to classify documents by first transforming feature values into a multidimensional feature space.
random forest is an ensemble learning technique that builds a large number of decision trees each using a subset of the features and then aggregates the results from each tree to classifydocuments.multinomialna vebayes mnb isaconditional probabilitymodelthatusesamultinomialdistributionforeachof thefeatures.multi layerperceptron mlp isasupervisedlearning techniquewhereweightedinputsaredeliveredthroughneuronsin sequentiallayers.multinomiallogisticregression mlr generalizesthelogisticregressiontechniquetothemulti classclassificationsetting.
we use the python scikit learn implementations of theclassificationtechniques svm.svc randomforestclassifier multinomialnb mlpclassifier andlogisticregression .
hyperparameter optimization.
the classification techniques that we use have configurable parameters that impact their performance.similartopriorwork weuseagridsearchtotune theparametersettings.gridsearchisanexhaustivesearchingtechnique that examines all of the combinations of a specified set of candidate settings to find the best combination.
we explore the same set of candidate settings as tantithamthavorn et al.
.
wesearchfortheoptimalparametersettingsforeachclassification technique ineach bootstrap sample i.e.
without using the testing data using the scikit learn gridsearchcv function.
performanceevaluation.
toevaluateourclassifiers weusecommon performance measures.
precision is the proportion of links that are classified as a given category that are correct.
recall is the proportionoflinksofagivencategorythataclassifiercandetect.
the f1 score is the harmonic mean of precision and recall.
the area underthe curve auc computes the area under the curve that plots the true positive rate against the false positive rate as the threshold that is used for classifying documents varies.
auc rangesfrom0to1 whererandomguessingachievesanaucof0.
.
sinceourlinkshavemorethantwocategories weneedtouse multi classgeneralizationsoftheseperformancemeasures.each measure is computed for each category before being aggregated into an overall score.
since the link categories are imbalanced see table3 we weighthe category scoresby their overall proportion.
wealsocompareourclassifierstoazerorclassifier whichalways reports the most frequently occurring class.
in our setting a zeror classifier achieves a recall of one and a precision equal to the frequency of the most frequently occurring category c1 forthatclass andaprecisionandrecallofzerofortheothercategories.notethat aucdoes not apply to zerorclassifiers because likelihood estimates are not produced.
we use the scikit learn metricslibrary to compute our performance measurements.
.
results table4showsthatwhilenoclassificationtechniqueconsistently outperforms the others the classifiers achieve a precision of .71 .
a recallof0.72 0. and f1 scoresof0.71 0.
.since these performance scores are on par with those of prior classification studies we believe that our classifiers show promise.
moreover table 4showsthatourclassifiersoutperformbaselinethereviewlinkagegraphforcode reviewanalytics esec fse august tallinn estonia table the performance of our five link category classifiers allofwhichoutperformthezerorandrandomguessingbaselines inallcases.
modelnova neutron prec.
rec.
f1.
auc prec.
rec.
f1.
auc svm .
.
.
.
.
.
.
.
rf .
.
.
.
.
.
.
.
mnb .
.
.
.
.
.
.
.
mlp .
.
.
.
.
.
.
.
mlr .
.
.
.
.
.
.
.
zeror .
.
.
.
.
.
approaches achievingprecision recall andf1 scoresthatare22 51 percentage points better than the zeror baseline and auc values above the .
random guessingbenchmark.
rq3 despite the complexity of the five class classification problem our classifiers achieve precision recall and f1 scores that exceed thezerorbaselineby22 51percentagepoints.
linkageimpactanalysis rq4 our analysis in rq2 suggests that linkage can impact code review analytics.
in this section we measure that impact on reviewer recommendation .
andreviewoutcome prediction .
.
.
reviewerrecommendation approach.
in section we observe that patch dependency links c1 alternative solution links c3 and feedback related links c5 may impact reviewer recommendation because reviewers of a linking reviewmayneedto reviewits linkedreview.
to measure the degree to which reviewers contribute to both linkingandlinkedreviews wecomputethe overlappingreviewer rate orr i.e.
theproportionofreviewersfromthelinkingreview whoalsoreviewthelinkedreview.wecomputetheorrrateson our sampledlinksfrom section .
to study the extent to which state of the art reviewer recommenders identify overlapping reviewers we apply chrev which makes recommendations based on prior contribution and workinghabits.weapproximatedatasetswherec1 c3 andc5linkedreviewsareknownbyapplyingourtop performingclassifier svm from section 6to the linked novaandneutron reviews.
we exclude c5 linked reviews from further analysis because we detect too few instances i.e.
five to draw meaningful conclusions.
we then compare the performance of chrev to an extended versionthatranksreviewersoflinkingreviewsatthetopofthelistfor linkedreviews.sincelinksappearasreviewsevolve weselectonly those links that are available at prediction times zero one three and sixhoursafter the reviewhas been created.moreover we only identify candidate overlapping reviewers who have commented on linking reviewsat orbefore thoseprediction time settings.
results.
theorrratesofc1andc3are50 51 and65 77 respectively.bywayofcomparison wefindthattheorrrateis lessthan1 forrandomlyselectedpairsofnon linkedreviews.the resultsindicatethatreviewersaremorelikelytoparticipateinboth reviewswhen linksare present.a closer inspection reveals that chrev misses at least one overlapping reviewer in 100 of linked reviews across top 1 5 recommendation lists.
since medians of and reviewers participate in novaandneutron reviews respectively missing at least one overlapping reviewer is a concern.
moreover none of the overlapping reviewers are recommended in 81 of novaand 84 of neutron reviews.
when overlapping reviewers are omitted they appear in 13th 15th place on average.
increasing the weightofoverlappingreviewers mayimprove recommendations.
table5shows that the precision recall and f1 scores of chrev improve by 88 3 17 percentage points if reviewers of a linked review are recommended at the top of the list.
moreover the degree ofthe improvement remainsconsistent acrossthe four studiedpredictiontimesettings indicatingthatnopredictiondelay isnecessarytogainthebulkofthevalue.longerdelaysmayachieve better results but would be less useful in practice since waiting morethansixhoursforreviewerrecommendationsisimpractical.
.
reviewoutcome approach.
insection we reportthatc1 c2 broadercontext andc3linksmayimpactreviewoutcomepredictionbecausethe integrationdecisioninonereviewmaybeinherentlylinkedtothat of theother.similarto thereviewerrecommendation experiment above we apply our svm classifier to identify c1 c2 and c3 links inthe full novaandneutron data sets.
forc1 c2 andc3reviews wecomputethe identicaloutcome rate ior i.e.
therate atwhich linking andlinked reviews result inthe same outcome i.e.
integration or abandonment .
moreover to study the extent to which state of the art outcome predictors misclassifyidenticaloutcomes weapplytheoutcomeprediction approachofgousios etal.
.morespecifically wetrainprediction modelsthatclassifyreviewsasintegratedorabandonedbasedon review properties e.g.
comments participants .
in our setting wetrainthepredictorsonunlabeledlinkedreviewsandevaluate themonour labeledsamples.
results.
the ior rates of integrated c1 and c2 linked reviews are 87 in novaand 71 in neutron while the ior rates for abandonment are 86 and 75 respectively.
thissuggeststhatreviewsthatareconnectedwithc1andc2links tend to have the same outcome.
since c3 links connect competing solutions itisunlikelythattheywillhavethesameoutcome.thisis reflectedinloweriorratesof18 26 forintegration respectively.
ontheotherhand theiorratesforabandonmentare46 in nova and in neutron indicating that it is not uncommon for both competing solutions to be abandoned.
outcomepredictorsmaymisclassifyreviewoutcomesforlinked reviewswhenthefeaturevaluesspanmultiplereviews e.g.
discussioncontexts participants .indeed wefindthatpriorapproach misclassifies35 and39 ofc1 c2 andc3 linkedreviewsin nova andneutron respectively.
rq4 reviewerrecommenderstendtoomitorpoorlyrankreviewers who participate in both linking and linked reviews.
moreover reviewoutcomepredictorstendtomisclassifylinkedreviewoutcomes.
leveraging links that are available at prediction time can yieldconsiderable performance improvements.esec fse august tallinn estonia toshikihirao shanemcintosh akinoriihara andkenichi matsumoto table the mean performance scores of chrev and our proposed link aware reviewer recommenders at different prediction delays.the bulk oftheperformanceimprovementisachieved intheno delay 0hour setting.
nova neutron top1 top3 top5 top1 top3 top5 model pre.
rec.
f1.
pre.
rec.
f1.
pre.
rec.
f1.
pre.
rec.
f1.
pre.
rec.
f1.
pre.
rec.
f1.
baseline .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
hour .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
hour .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
hours .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
hours .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
practicalimplications linkage should be taken into consideration in code review analytics.
our quantitative study section shows that up to of reviews in our subject communities link to at least one other review.
moreover in the four studied communities that have madethelargestinvestmentinreviewing openstack chromium android andqt we observe increasing or stable trends in the monthlylinkagerate.priorworkhasshownthatlinkedartifactscan impactrepositorymininganalytics .indeed ourimpactanalysis section showsthatreviewerrecommendersandoutcome predictorscan be improvedbytaking linkage intoaccount.
duplicatedetectionwouldenhancereviewefficiency.
ourqualitativestudyshows that14 15 ofcongruent linksin novaand neutron fallinthealternativesolutioncategory i.e.
superseding and duplication .
duplicate contributions are a form of waste in software development .
boisselle and adams argued that automatic classification of bug reports that are linked due to duplicationwouldbehelpful.however inlargeprojectslike openstack andchromium it is difficult to keep track of duplicated work .
systematicdetectionofduplicateswouldbeimportantfromareviewfairness perspectiveaswell sincethecompetingsolutions should be subjectto the same level ofscrutiny.
linkcategoryrecoverymaynotbenecessary.
themajorityof linksareoftypesthatpotentiallyimpactreviewerrecommendation c1 c3 and c5 and outcome prediction c1 c2 and c3 .
since we find that all studied link categories are useful future work may assumethat alllinksare useful andomit linktype classification.
threats to validity construct validity.
constructvalidityisconcernedwiththedegreetowhichourmeasurementscapturewhatweaimtostudy.we recoverlinksbetweenreviewsusingregularexpressionsthatdetect change ids and urls of other reviews.
however these regular expressions may extract change ids or urls that are not intended tobelinks falsepositives .ontheotherhand section 5showsthat thefalsepositiverateinourmanuallyanalyzedsampleisquitelow .
.thus we false positives donot appear to be ofconcern.
in our qualitative analysis links may be miscoded due to the subjective nature of our open coding approach.
we take several precautions to mitigate the miscoding threat.
first the code for each link is agreed upon by two coders who have experience with codereviewinacademicandcommercialsettings.furthermore we employ a three pass approach where each code is revisited at least onceto ensure that the correctcode wasselected.internal validity.
internalvalidityisconcernedwithourability to draw conclusions from the relationship between study variables.
links may not be detected in all of the cases when they should be whichmayintroducenoisein ourlinkagerateobservationsin section4.hence ourobservationsinsection 4shouldbeinterpreted as lower bounds ratherthanas exact linkage ratevalues.
ifwe stopcoding too earlyduringour qualitative analysis section5 itmaythreatenthecompletenessofthediscoveredsetof link types.
to mitigate the threat we continue to code until our samples saturate a concept that we operationalized by continuing until we coded a span of coded links without discovering any newcodes.
othershave usedsimilar saturationcriteria .
other classification techniques or hyperparameter settings may yieldbetterresultsthantheonesthatwestudiedinsection .to combat this we select a broad set of popular classification techniquesanduseanautomaticparameteroptimizationapproachto selectthebestconfigurationofhyperparametersettingsforeach bootstrap iteration.
nonetheless exploration of other classification techniques andhyperparameter settings mayyieldbetterresults.
external validity.
external validity is concerned with our ability to generalize based on our results.
we extract review graphs section4 fromsixcommunitiesthatusethegerritcodereview tool.
due to the manually intensive nature of our coding approach wefocusonanin depthanalysisofthetwolargestprojectsfrom theopenstack community.
as such our linkage types classifiers and impact analyses may not generalize to code reviewing environments inall software communities.
replication studies may be neededtoarriveatmoregeneralconclusions.tosimplifyreplication we have madeour scripts anddata publiclyavailable.
conclusion researchershaverecentlyproposedseveralanalytics basedtechniquestosupportstakeholdersinthemcrprocess.however those techniqueshave tacitlyorexplicitly treated eachreview as anindependentobservation whichoverlooksrelationshipsamongreviews.
our empirical study suggests that linkage is not uncommon in six studied software communities.
moreover adding linkage awareness to review analytics approaches yields considerable performanceimprovements.thus reviewlinkageshouldbetakeninto considerationinfuture mcrstudiesandtools.