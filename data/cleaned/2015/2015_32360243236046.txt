model transformation languages under a magnifying glass a controlled experiment with xtend atl and qvt regina hebig chalmers university of gothenburg swedenchristoph seidl technische universit t braunschweig germanythorsten berger chalmers university of gothenburg sweden john kook pedersen it university of copenhagen denmarkandrzej w sowski it university of copenhagen denmark abstract in model driven software development models are automatically processed to support the creation build and execution of systems.
a large variety of dedicated model transformation languages exists promising to efficiently realize the automated processing of models.
to investigate the actual benefit of using such specialized languages we performed a large scale controlled experiment in which over subjects solve individual tasks using three languages.
the experiment sheds light on commonalities and differences between model transformation languages atl qvt o and on benefits of using them in common development tasks comprehension change and creation against a modern general purpose language xtend .
our results show no statistically significant benefit of using a dedicated transformation language over a modern general purpose language.
however we were able to identify several aspects of transformation programming where domain specific transformation languages do appear to help including copying objects context identification and conditioning the computation on types.
ccs concepts software and its engineering context specific languages general programming languages keywords model transformation languages experiment xtend atl qvt acm reference format regina hebig christoph seidl thorsten berger john kook pedersen and andrzej w sowski.
.
model transformation languages under a magnifying glass a controlled experiment with xtend atl and qvt.
in proceedings of the 26th acm joint european software engineering conference and symposium on the foundations of software engineering esec fse november lake buena vista fl usa.
acm new york ny usa pages.
permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
copyrights for components of this work owned by others than the author s must be honored.
abstracting with credit is permitted.
to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
request permissions from permissions acm.org.
esec fse november lake buena vista fl usa copyright held by the owner author s .
publication rights licensed to acm.
acm isbn .
.
.
.
attribute class method modifier public static final private namedelement name estring package project structuralelement modifiers modifier elements classes subpackages packagesfigure syntax model for source code introduction inmodel driven software development mdsd models are automatically processed to support creation build and execution of systems.
transformations are among others used to compute views on models to validate models to refactor models to interpret or otherwise execute models to implement model debuggers to transform models to lower level models and to implement model management operations such as versioning .
to support the multitude of processing tasks many specialized model transformation languages have been developed as a result of a substantial research effort .
outside mdsd the transformation languages are also gaining importance in the programming language and the data processing community see for example transformation languages come with an implicit promise to be easier to use and more efficient for specifying transformations than general purpose programming languages gpls .
however does this promise hold?
we heard this question multiple times in interactions with industrial software teams.
unfortunately little systematic knowledge exists to respond besides experience reports from case studies .
this hampers choosing between a gpl which can solve many tasks and a specialized language that promises efficiency gains but requires highly specialized programmers.
as the automation of software engineering tasks is a growing trend and as software projects mix increasingly many languages and formats we can only expect that the time spent by developers on creating transformation programs will be growing and so will the amount and importance of transformations.
the transformation languages promise to positively contribute to this effort.
it is thus key that we develop understanding on how programmers use transformation languages what problems they face and what aspects of these languages emerge as particularly useful or problematic.
esec fse november lake buena vista fl usa r. hebig c.seidl t. berger j. kook pedersen a. w sowski we settled to answer some of these questions in a controlled experiment with three established model transformation languages employed in program comprehension program modification and program creation tasks.
we recruited graduate students from chalmers university of gothenburg and technische universit t braunschweig and observed how they cope with the languages atl qvt o and xtend the first two dedicated and established model transformation languages the third a high level gpl.
analyzing solutions of tasks we found that handling multi valued features collections recursion and designing logical branching conditions are among the most difficult skills to master for the developers.
even well qualified subjects struggle to evolve transformations optimally producing changes of widely diverse sizes.
implicit object creation implicit structure copying and support for type driven computation and explicit computation context do appear to reduce the amount of errors.
there is no sufficient statistically significant evidence of a general advantage of specialized model transformation languages atl qvt o over a modern gpl xtend .
this work aims at the interest of researchers and practitioners working with transformation languages and building new tools in the modeling dsl and programming languages communities.
it can also be of interest to software architects considering using gpls or dedicated languages for a transformation task.
background we are concerned with model to model m2m transformations so programs transforming instances of a source model to instances of atarget model structured data to structured data in contrast to model to text m2t transformations which are typically implemented in template languages and used for code generation.
to represent the abstract syntax of model instances we use instance specifications object diagrams where objects represent model elements and the links between them represent the relationships between model elements.
all three languages considered in this experiment are integrated with the eclipse modeling framework emf which offers a variety of tools and technologies for mdsd based on a simple class diagram language notation called ecore .
figure shows an example ecore model1of program code used to implement a refactoring transformation commonly seen in ides.
figure shows an example instance specification for this model.
the model of fig.
contains classes called types in the remainder such asproject orclass together with class attributes and class relationships.
the latter are either generalizations e.g.
structuralelement is a generalization of method containment e.g.
project .
packages or association relationships.
containments and associations carry cardinalities determining how many objects of the type can be in a relationship with the object of the other type e.g.
an object of type project can have or more objects of type package .
the instance specification of fig.
contains objects whose structure adheres to the model links are correct instantiations of the relationships between the objects types and each object attribute has a value adhering to the respective class attribute s signature.
1in the mdsd community such an ecore model is typically called a meta model.
attribute name age modifiers public static attribute name date modifiers public class name order class name customer package name p2 package name p1 project name customermanagement method name confirm modifiers public attribute name name modifiers public attribute name membershipno modifiers public final method name getage modifiers public packages classes classes elementselementselementselements elementselementssubpackagesfigure an instance of the model shown in fig.
we focus on three languages used for m2m the atlas transformation language atl is a mostly declarative domain specific m2m language.2listing 3a shows an example of atl the keyword rule defines a named transformation for model elements of the source type from to those of the specified target type to .
the first specified rule implicitly designates the entry point for the transformation specification.
the invocation order of rules is implicit the transformation engine processes source instances according to the containment hierarchy specified in the respective model and automatically involves a matching rule for the encountered element of the source instance.
the rules marked lazy may be invoked manually in which case the call has to be qualified with the implicit thismodule variable.
the result of a rule is created by an implicit instantiation of the target type.
then the values are assigned to the fields object attributes and links of the instantiated element.
in atl serves as the assignment operator.
atl provides various operations on collections for instance exists checks if at least one collection member satisfies a predicate select creates a derived set with only those members that satisfy a given condition and collect called mapin many other languages applies a mapping function to every element of a collection creating a new collection.
query view transformation operational qvt o is an imperative domain specific m2m language.3listing 3b shows an example in qvt o the keyword main marks the entry point for the transformation.
the keyword mapping defines a named transformation from elements of a source type specified before the mapping name to those of a target type specified after the mapping name .
by default the target type is instantiated automatically when invoking the mapping and the respective element is available via the implicitly initialized variable result .
alternatively it is possible to use the keyword object to explicitly instantiate a return type and then assign it to result manually.
as qvt o is imperative the mappings are invoked according to the user specified control flow.
in particular the mapoperation on collections invokes a specified mapping for each of the source collection s values and stores each transformation result at a similar position in the target collection.
in the mapping s body values are assigned to the fields object attributes and links of result which is the implicit context for the 2note that we are aware of atl s hybrid character due to the imperative nature of its doblock in called rules but focus on the commonly used declarative matched rules.
3qvt r is declarative but we focus on the imperative portion of qvt here.
446model transformation languages under a magnifying glass esec fse november lake buena vista fl usa left hand side of each assignment.
in qvt o is the assignment operator for fields and allows to add to collections.
qvt o also has collection operations with similar syntax and semantics as atl.
xtend is a gpl with a syntax largely inspired by java.
unlike atl and qvt o xtend has no specific language constructs for writing model transformations additional boilerplate code is used for loading and saving instances.
however thanks to the rich variety of gpl constructs the language lends itself well to creating model transformations.
listing 3c shows an example of xtend the method main of an xtend program constitutes the entry point of a transformation.
further transformation rules can be specified as usually static methods.
the source type that the transformation operates on is specified as the first parameter so that the method may be called as an extension as if it was defined in the source type .
the target is the return type of the method and has to be instantiated manually by calling the respective factory method generated by emf ecore.
the with operator binds the left operand to the implicit context for the sequence of assignments within the lambda expression given in the right operand.
similar to qvt o xtend defines the mapoperation to call a method on all members of a source collection and store the results in a target collection which is used for explicitly calling transformation methods.
preparatory study we performed a pre study in collaboration with a danish industrial partner a company that consolidates multiple commercial and government data sources to provide support services for trade and taxation in denmark.
the project investigated suitability of model transformation technology in the context of data aggregation.
the task involved reading many real time sources and correlating transactions in these sources in order to join related records clean and normalize the data.
the structure of the input and output data has been described in ecore models.
the source model comprised nine classes attributes and relationships.
the target model consisted of two classes attributes and one relationship.
creating the output instance required flattening and correlating pieces of information with a complex structure.
the study was performed by a single programmer the author of the original c transformation used in the production system and fourth author of this paper who is a very experienced developer but new to the transformation languages.
at the time he held nine years of full time professional programming experience with c learned transformation languages in an open university course about mdsd at it university of copenhagen and obtained operational command of them for the purpose of this pre study.
two tasks were considered create to study writing a transformation from scratch and change to study evolution of the transformation .
for the create task the c transformation has been re implemented in four languages etl the declarative fragment of atl xtend and java.
as far as possible the idiomatic style of each language was followed not the style of the original c code except for java .
in the change task the transformations have been modified to accept another version of the input model.
to ensure that the evolution step was realistic we used an actual legacy version of the model slightly older than the one used for thecreate task.
this ensured that the evolution step was realistic.although the step was executed backwards from the chronological perspective the created difference should likely be the same as if it was executed forwards.
the difference between the models affected about half of the classes including dropping classes.
the extent of necessary transformation changes was not obvious on the outset.
we performed a qualitative analysis of the created transformations.
this list has contributed to the selection of language use dimensions in the design of the actual experiment sec.
.
observation .
the pre study programs exhibit aspects such as creating objects populating attributes and other properties with input data checking logical conditions filtering and other collection operations involving predicates ranking and sorting data elements using standard functions .
the change task involved both restructuring the algorithm of the transformation and performing local modifications such as renaming of elements adjusting navigation expressions etc.
we counted the sizes of the transformations see table after formatting them using rules inspired by the work of nguyen et al.
.
besides the actual transformation all four languages required implementing startup code so that they can be executed automatically.
the size is included in the table after the plus sign in xtend for the xtend transformation and in java for the other languages.
observation .
the pre study transformations implemented in dedicated rule based languages etl atl were up to smaller than the java4variants.
for a single nontrivial transformation the need for startup code reduces the conciseness benefit noticeably.
we also measured the size of the required change in each of the change task implementations see the bottom of table .
the startup code was not modified so it does not affect the numbers.
interestingly the sizes of edits in all languages were extremely close.
the size benefit when creating transformations is primarily due to reduction in boilerplate.
this boilerplate is relatively robust with respect to changes and the size benefit disappears in the change task.
this is interesting given that code evolution is commonly accepted as similarly costly or even more expensive than code creation.
for example sommerville reports that of effort in software engineering is spend on maintenance and evolution.
observation .
we observed that the size of changes in the prestudy transformations in all involved languages were similar and the changes almost did not affect boilerplate code.
obviously observations from a single person single case experiment are not generalizable due to idiosyncrasy of the case of the 4java was released only after we had conducted the pre experiment.
its stream api might reduce the sloc count of the java transformation code.
table sizes of the pre study transformations and changes etl atl xtend java create trafo startup gain vs java incl.
startup change diff size gain vs java 447esec fse november lake buena vista fl usa r. hebig c.seidl t. berger j. kook pedersen a. w sowski 1module refactoringtrafoatl 2create out mm from in mm 6rule project2project 7from s mm!project 8tot mm!project name s.name packages s.packages collect p thismodule .package2package p ... 16lazy rule method2method from sm mm!method totm mm!method name sm.name modifiers sm.modifiers 23lazy rule attribute2attribute from sa mm!attribute tota mm!attribute name sa.name modifiers sa.modifiers a atl1modeltype cmuses classmodel1mm 2transformation refactoringtrafo inm1 cm out m2 cm 5main 6m1.rootobjects map copyproject 10mapping cm project copyproject cm project name self .name packages self .packages map copypackage ... 17mapping cm structuralelement copyelement cm structuralelement init if self .oclistypeof cm method result object cm method else result object cm attribute name self .name modifiers self .modifiers b qvt o1class refactoringtrafo1 2val private static factory 3classmodel1mmfactory.einstance 6def static void main string args code to load m1 and save m2 omitted 8val m2 copyproject m1 11def static project copyproject project p factory.createproject name p.name packages p.packages.map ... 17def static structuralelement copyelement method m factory.createmethod name m.name modifiers m.modifiers 23def static structuralelement copyelement attribute a factory.createattribute name a.name modifiers a.modifiers c xtend figure excerpts of transformation specifications realizing a refactoring transformation on the source code model in fig.
programmer and due to learning effects.
yet they were sufficiently interesting to motivate further exploration.
we proceeded to design a controlled experiment to investigate the matter in detail.
we used the pre study to select the dimensions of interest and to generate some hypotheses.
we describe the resulting experiment below.
method we address the following research question how effectively programmers use model transformation languages what problems they face and what aspects of these languages emerge as particularly useful or problematic in contrast to gpls?
.
experiment design the treatment in our experiment is the transformation language.
due to their extensive use in education research and some industrial applications we selected atl as a declarative domain specific transformation language qvt o as an imperative domain specific transformation language and xtend as an imperative gpl.
they are all supported by official eclipse foundation projects.
finally we could secure a substantial number of trained subjects for them.
we have decided to not include any pure gpls.
while it would be highly desirable to evaluate functional programming languages in the transformation context say haskell it would also make the experiment considerably more complex as it is hard to guarantee that students would reach a comparable level of training.
haskell is not well integrated with major modeling tool chains which would require significant modification of the considered development scenarios introducing new uncontrolled factors.
it would also require substantial extension of the participant base which is difficult to attain especially that it is hard to identify a homogeneous population of subjects that know both haskell and the model transformation languages functional languages are typically taught in cs degrees transformation languages in software engineering degrees .the dependent variables are solution completeness andmistakes done by the participants.
we further split these into detailed dimensions of analysis arranged by transformation programming skills required for the tasks create object initialize single valued fields initialize collection valued fields use interpret value conditions use interpret type conditions navigate the model place computations in correct context table cf.
obs.
.
the experiment follows a between subjects design where each participant learns and works with one of the three languages.
we consider three development tasks transformation comprehension transformation creation and transformation changing .
these are selected as key activities in code development and evolution.
as comprehension is a prerequisite for change we introduce an explicit dependency ordering between the two.
the subjects first solve a comprehension task then they approach a change task for the same code.
to avoid learning bias they solve the creation task for another problem.
we use two domain scenarios to allow this cross over.
subjects starting with the first scenario feature modeling cross to the second scenario refactoring and vice versa as fig.
shows scenario fm scenario re comprehend fm comprehend rechange fm change recreate fm create re figure task execution paths in the cross over design scenarios .
the feature model fm scenario is a transformation between two different representation formats of feature models .
fms are tree like structures that capture features of a software product line a portfolio of software variants .
as many different variations of the fm notation exist and even the same notation can be represented differently creating a transformation to convert between two representations is a realistic scenario .
the transformation reorganizes instance objects among the containment 448model transformation languages under a magnifying glass esec fse november lake buena vista fl usa hierarchy differently.
note that we taught feature models in the course to give our subjects sufficient exposition.
the refactoring re scenario is the implementation of an attribute refactoring for simple object oriented syntax model a task common in ides with support for properties.
the source and target models are the same.
the task is to create getters and setters for each non public attribute depending on the absence of static andfinal modifiers.
a fragment of this transformation is shown in fig.
for all considered languages.
tasks .
in the comprehension task the subject attempts to understand what a transformation does e.g.
whether parts of a model are copied modified or new parts created.
the subjects get the source and target models and an implementation of a transformation for one scenario in one language we prepared the implementation of both scenarios in all three languages in total six programs .
we then provide a source instance diagram and ask to draw the output instance.
we assess the correctness of the produced output with respect to the dimensions of analysis listed above also see table .
for instance if the wrong model elements are modified we assume that the subject does not command the skill of use interpret value conditions or the skill of use interpret type conditions depending on whether the type or logical condition was missed .
the change task investigates whether a subject can identify where in the code a change is needed what information needs to be accessed and whether she can actually implement the change.
we provide the same transformation as for the comprehension task.
for the fm scenario we ask the participants to adapt the transformation to use cardinalities instead of the class hierarchy to represent feature groups a new target model is provided .
for the re scenario we ask to amend the transformation to set the visibility modifier of an attribute to private if a getter or setter exists still the same target model .
we assess the correctness of the change with respect to the same dimensions.
for instance if the changed expressions do not follow the types of the target model we assess that the skill navigating the model has not been demonstrated.
finally in the create task each subject attempts to construct a new transformation from scratch in her language.
we provide the relevant source and target models a description of the requirements in english as well as stubs for the transformation headers and boilerplate code in the appropriate language this helps to disambiguate the task .
we then ask the subject to produce the transformation.
again we assess the result using the same dimensions of analysis.
for instance if the produced code places the main computation in a context of a type from which some relevant information is not accessible we assess the subject does not demonstrate the skill of placing computations in a correct context .
the scenarios models transformations stubs expected solutions and task definitions are available in our online appendix .
subject selection .
the subjects are graduate students at the european universities chalmers university of gothenburg gu and tu braunschweig who just completed a course on mdsd during which they had learned the transformation languages used in this experiment.
all had several years of prior experience with programming but had not worked with transformation languages before the course.
each of the transformation languages was introduced in a separate lecture addressing all participants.
then each participanttable distribution of subjects across runs and languages chalmers gu spring tu braunschw.
fall chalmers gu spring total atl qvt o xtend total implemented three transformations in the transformation language randomly assigned to them in the beginning and later used in the experiment .
this included solving and formative assessment of transformations supported by learning material examples and supervision.
at the point of the experiment they have been acquainted with the languages for at least one month.
table shows the distribution of participants across project partners.
these subjects are a reasonable representation for programmers who are considering using transformation languages in a professional setting are evaluating or starting to use the technology .
this is an important target group as the mdsd technology is in the adoption phase.
results might not transfer to experienced developers using these languages for an extended period.
controlled variables .
all languages assigned randomly are represented in similar proportions in all three runs of the experiment .
among others this avoided an impact of country teachers and university on the results.
tasks were assigned randomly subject have followed the top path in fig.
and subjects have followed the bottom one.
each subject has been asked to attempt all three tasks.
only three participants did not attempt the 3rd task as they left the experiment early.
this resulted in answers for the first path and for the second path.
.
execution and data collection the participation in the experiment was voluntary and had no impact on the students grades.
we incentivized the participation by emphasizing that the experiment conditions are similar to exam conditions so it can be used as training.
students were aware of the experiment situation.
we briefed the subjects after the experiment to discuss their challenges with the goal of reducing negative selfperception due to failure in the more challenging tasks.
the tasks were solved on paper which eliminates the factor of familiarity with the programming environment.
it also allows us to investigate the very languages not the quality of the error reporting from say a type checker.
the models and transformations were distributed as printouts.
the models were small enough to each fit one page.
for the change tasks we printed the transformations with increased interline space.
for the create tasks we printed stubs with white gaps.
to compensate for the fact that subjects work on paper we provided cheat sheets that summarized main language features and concepts that participants might want to look up.
the experiment was performed in three runs at two technical universities in two european countries as summarized in table .
each run of the experiment was performed in a lecture room where participants had enough space to work.
we distributed the tasks in such a way that participants sitting next to each other would solve different tasks.
the time limit for the experiment was set to hour and minutes.
the subjects were allowed to leave early.
we 449esec fse november lake buena vista fl usa r. hebig c.seidl t. berger j. kook pedersen a. w sowski suggested to use the first minutes for the comprehension task the next minutes for the change task and the last minutes for the create task.
we announced the current time at the and minute marks.
not all subjects succeeded in completing all the tasks in the allotted time and some have left early.
we eliminated two entries one of a student following the course a year earlier and one of a student with a writing handicap.
.
data analysis scoring .
after we collected the data we graded the points against the dimensions of analysis.
not each dimension is applicable to every task scenario combination as not all language elements are always used.
table summarizes the dimensions and their compatibility with tasks.
the dimensions correspond to operational skills to facilitate assessment.
yet assessing the score of a student s solution does differ somewhat from an exam grading process.
for example for the comprehension task severe syntax problems would in an exam lead to no points.
we were forgiving to syntax problems if the intention was clear.
we prepared a criterion description for each dimension of analysis in the context of each task.
for example for the skill navigate the model for the comprehension task the description said correct overall structure links and objects with correct attributes .
in total such descriptions were created ranging from to words see online appendix .
these descriptions were used to perform the scoring possibly uniformly.
we score each dimension on a three step scale no demonstration of the skill clear demonstration .
the step .
was used when some demonstration of the skill was observed but we could not agree on assigning or .
the scoring happened in three phases pair scoring to enable alignment of the scoring styles three authors have scored a hand in each tasks in a think aloud mode in pair with another author.
each of the three sessions lasted minutes.
the observing author acted as a consultant asking and answering questions.
scoring by language the three authors performed the first scoring of all the tasks in one language each.
this cost about .
days per person.
besides recording the scores we annotated the records with qualitative justifications of assigned points observed mistakes and other points of interest.
scoring by task another author not involved in phase revised all the scores in the by task direction to ensure consistency of scoring across languages.
this resulted in several corrections in scoring.
this allowed to control for different reactions of graders to unexpected mistakes.
none of the authors is involved with the development or otherwise heavy use of the languages that were subject to this experiment.
in the grading we attempted to be objective as much as possible.
hypothesis testing .
declarative languages have a lower spread than imperative languages.
therefore most programmers are rather familiar with the imperative way of thinking.
therefore we formulate the following hypotheses including null hypotheses h1 subjects comprehending a qvt o or xtend transformation perform better than those who comprehend a transformation in atl.
h1 subjects comprehending a qvt o or xtend transformation perform worse or equal to those comprehending an atl transformation.h2 subjects who change a transformation written in qvt o or xtend perform better than those who change a transformation in atl.
h2 subjects changeing a transformation written in qvt o or xtend perform worse or equal to those who change an atl transformation.
h3 subjects who create a model transformation in qvt o or xtend perform better than those who create a transformation in atl.
h3 subjects who create a model transformation in qvt o or xtend perform worse or equal to those who create a transformation in atl.
as the main purpose of domain specific languages it is to make task solving in a domain easier or more efficient.
thus we formulate the following hypotheses including null hypotheses h4 subjects who comprehend a transformation in qvt o perform better than those comprehending a transformation in xtend.
h4 subjects who comprehend a transformation written in qvt o perform worse or equal to those comprehending it in xtend.
h5 subjects changing a transformation written in qvt o perform better than the subjects who change an xtend transformation.
h5 subjects changing a transformation in qvt o perform worse or equal than the subjects who change an xtend transformation.
h6 subjects who create a model transformation in qvt o perform better than those who create a transformation in xtend.
h6 subjects who create a model transformation in qvt o perform worse or equal to those who create a transformation in xtend.
analysis .
for the quantitative analysis we compared the average scores and standard deviation for the three languages per task and scenario using the comprehension tasks for hypotheses and the change tasks for hypotheses and and the creation tasks for hypotheses and .
we used a shapiro normality test on each data set i.e.
each set of student s scores for one task and language which showed that we cannot assume normal distribution for some of the data sets.
therefore we decided to use the non parametric wilcoxon signed rank sum test.
we tested each task to compare the scores reach with the three different languages using the standard confidence level .
.
due to the setup we test every combination of languages times two scenarios for each task comprehend change and create .
therefore we apply a bonferroni correction to the threshold for the confidence levels by dividing .
by leading to a threshold of .
.
to ensure also relevance we assessed effect size using vargha and delaney s a vda following their interpretation a .
small a .
medium and a .
large.
all test were executed with r. furthermore we analyzed the statistics for the individual dimensions of analysis and analyzed comparing solutions and language constructs the cases were strong interesting effects were visible.
experiment results table summarizes the average scores awarded to subjects by task and language.
in the following we elaborate on some of these.
.
analysis of typing errors in the comprehension task many subjects created instances that are invalid violate model types .
this could be an indicator of insufficient competence of the subjects.
in order to ensure that we assess success in applying model transformation skills as opposed to modeling skills we wanted to eliminate the subjects who do 450model transformation languages under a magnifying glass esec fse november lake buena vista fl usa table applicability of dimensions of analysis among tasks dimension description comprehend change create fm re fm re fm re basic constructs initialize single valued fields correctly interprets or creates value assignments to single valued object attributes or links atl qvt o xtend n a initialize collection valued fields correctly interprets or creates value assignments to single valued object attributes or links atl qvt o or xtend or n a use interpret value conditions correctly interprets or uses value conditions n a use interpret type conditions correctly interprets or uses conditions on types n a navigate the model correctly interprets or uses object traversal follow links access object attributes n a compound constructs create object correctly interprets or uses object creation n a copy complex elements correctly interprets or creates rules that copy multiple objects with all their attributes and linksn a transformation decomposition place computations in correct context places computation into the correct context n a n a used as grading criteria n a not applicable not demonstrate understanding of the class diagram language.
we used navigate the model score of the comprehension task to identify qualified subjects interpreting it as a proxy for the skill of modeling.
we assume that only subjects with a positive or .
score for this dimension in their comprehension task solution are qualified.
so for this particular analysis in this subsection we projected the other subjects out of the data set to consider typing errors specific to transformations.
this left us with data for subjects of the original sample .
as expected the subjects are still well distributed across all the buckets at least and at most subjects taking each path in fig.
for each language.
we begin by summarizing the typical type related mistakes seen objects are created on the wrong abstraction level e.g.
we found instances of instances.
source and target models are merged e.g.
the output instance contained instances of classes from both models.
elements from the transformation e.g.
variable names from the transformation program occur as data in the output associations in the instance do not conform to the model objects are contained by multiple containers violating the no sharing constraint of class diagrams instances of non existing types are created.
abstract classes are instantiated these problems could be observed throughout the three languages with similar intensity times for atl for qvt o for xtend .
as educators we find this list useful as a specification of what training material for teaching transformations shall be created.
.
creating and copying objects creating objects and understanding what objects are created is a basic but crucial skill.
interestingly of the qualified subjects using qvt o demonstrate the create object skill score while only ca.
do this for atl and xtend.
a reason might be that object creation happens implicitly in qvt o with special language support.
in xtend complex factory methods need to be called explicitly.
in atl not all blocks can create objects rules can but not helpers .
this lack of orthogonality may cause some errors.
observation .
qualified subjects programming qvt o correctly use and reason about object creation more often of cases than subjects using atl and xtend of cases across all three tasks.most subjects correctly identify that a transformation copies structures of multiple connected objects.
similarly most subjects are able to create such copying when writing transformations.
yet the average score of qualified subjects using our two domain specific languages is higher .
than for our gpl xtend .
.
observation .
subjects copy complex structures and reason about copying more effectively with the domain specific transformation languages atl and qvt o than with the gpl xtend.
copying complex structures does play an important role in model transformations.
the experiment confirms that dedicated support for this in the domain specific languages is paying well.
in contrast xtend requires using recursion for the task which is notoriously difficult.
we remark that in situations that were not handled with automatic copying so when explicit recursion was required we observed the same difficulties across all three languages.
this indicates that further support for hiding recursion might be useful for example the rascal language has first class rich visitors to build sophisticated traversals without recursion .
we also investigated how collection valued fields are handled.
in models and transformations the boundary between simple values and collections is blurred.
simple values are often seen as singleton collections.
the gpls distinguish these firmly.
approximately of qualified subjects master the skill of initializing collection valued fields.
this proportion is lower for atl and xtend .
it does appear that this performance is low for all three languages and there is space for improving collection support in them.
.
identifying the correct context in transformations it is key to identify the location in the model the type where the computations are being placed.
the context determines which information and operations are reachable via navigation how far and also which information is accessible implicitly via the this reference .
we record an advantage of subjects working with our domain specific languages qvt o and atl average score over those with the gpl xtend average score .
observation .
context selection is easier for the subjects working with the domain specific transformation languages atl and qvt o than with the gpl xtend.
451esec fse november lake buena vista fl usa r. hebig c.seidl t. berger j. kook pedersen a. w sowski table average scores of subjects per task language normalized to includes both qualified and not qualified subjects comprehend fm comprehend re change fm change re create fm create re atl qvt o xtend atl qvt o xtend atl qvt o xtend atl qvt o xtend atl qvt o xtend atl qvt o xtend average .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
std.
dev.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
given that only of task solutions score maximum in this dimension better support for context selection might be a focus for future research and innovation e.g.
opportunities of detecting bad context as smell and providing automatic refactoring support .
we speculate that an advantage of our domain specific languages qvt o and atl is their encouragement of a better decomposition of the transformation into rules enhancing comprehension.
specifically they require to explicitly declare the input and output types instead of resorting to not even immutable parameters of a method call in xtend.
programmers in xtend might approach the decomposition less consciously.
investigating this aspect in a separate study constitutes valuable future work.
.
branching on values and types most subjects had difficulty with interpretation or writing branching selection or filtering conditions.
remarkably this skill scored the lowest amongst all the average score of qualified subjects was .
with all the other dimensions scoring on average above .
.
observation .
creating correct conditions for branching and object selection as well as understanding them correctly is by far the most difficult skill among those we analyzed.
this observation is both interesting and expected.
expected as creating the right branching structure for any program is the very essence of the computer programming art but also one of its key difficulties.
interesting because this is an aspect to which the transformation language designer community traditionally attaches little attention.
the expression sublanguages used within transformation languages tend to be imported from elsewhere ocl java javascript and little transformation specific innovation happens.
perhaps this low score is a pointer for the designers to try again.
there is a notable exception to stagnation in expression languages for transformations type dependent branching.
transformation languages have specialized facilities for scheduling computations based on types usually a form of pattern matching .
this is true for all three considered languages.
for this reason we have tracked the use of type conditions separately from predicates on values in the analysis.
the average score for using type conditions across all languages and tasks is .
for qualified subjects substantially more than using value conditions .
.
this is a good indication that the investment in the language design may pay off.
observation .
subjects are much more likely to create correct branching conditions based on types than based on values in the transformation specifications.
.
size of change edits evolution let us get back to obs.
from the pre study where we found that the change sizes were similar across the languages.
to expand on this observation we investigated differences in the size of edits that the subjects perform for the change tasks.
working on paper thesubjects did not follow common line breaking conventions so we measured size differences unambiguously in tokens not lines.
first we created specimen solutions to the change tasks.
we observed that they had similar diff sizes in all three languages corroborating obs.
.
the edit required removal addition modification of tokens in atl tokens in xtend and tokens in qvt o cf.
task descriptions and example solutions in the online appendix .
these numbers are likely close to the optimal minimal change.
for the subject solutions we manually counted the size of diffs in tokens for all correct solutions.
we only considered this problem for thechange fm task as the results of change re did not contain sufficiently many correct answers.
we assumed that a solution is correct if scored at least of the maximum score summed over all dimensions subjects have met this condition.
we removed two outliers one with qvt and one with tokens xtend .
table summarizes the results.
it appears that even though the specimen solutions do seem to confirm obs.
the average performance of our subjects does not.
also even if the specimen solution for qvt o was the smallest the average subject solution for qvto is the largest and the qvt o sample is characterized by the largest standard deviation.
this might be yet another confirmation of the fact that even if the language expert can present a perfect use of the language constructs the users may struggle to exploit the opportunities in the language to the same extent.
only for atl the optimal solution is well approximated but this has to be interpreted with care as we are down to only data points in this case .
observation .
sizes of the change edits performed by subjects differ widely across the population and are most often far from the optimal solutions not exploiting fully the potential of the languages.
a possible explanation for the phenomenon is that the specimen and the pre study solutions were implemented by more experienced programmers than our subjects are.
this topic requires a deeper investigation.
it would be interesting to study productivity differences between programmers using gpls and specialized transformation languages and between senior and junior developers in the context of transformation.
otherwise it is difficult to convince larger parts of the industry to adopt these technologies.
.
hypothesis testing we now return to our hypotheses investigating whether the overall differences in scoring between languages are statistically significant.
table summarizes the test results.
we split the tests by task and scenario to reflect the differences in the scenarios.
table size of the change edit for create fm task atl qvt o xtend average diff size .
.
.
.
.
.
452model transformation languages under a magnifying glass esec fse november lake buena vista fl usa after the bonferroni correction no statistically significant difference can be found after the bonferroni correction.
most differences seem to be of small to negligible effect size.
consequently we cannot reject the null hypotheses that atl is leading to a similar or better performance than qvto and xtend h1 h2 and h3 for each task respectively .
more interestingly we cannot reject the null hypothesis that the domain specific language qvto perform equal or worse than the general purpose language xtend h4 h5 and h6 for each task respectively .
which leads us to the following controversial observation observation .
there is no sufficient statistically significant evidence of general advantage of the specialized model transformation language qvto over the modern gpl xtend for the tasks scenarios and analysis dimensions considered in this paper.
this is clearly concerning given the amount of work that has been invested in model transformation technology.
we do emphasize that this conclusion is made under narrow conditions and encourage others to corroborate or reject our observation via further studies.
threats to validity construct validity .
we conceived the tasks carefully and ensured that they are solvable with similar effort in all languages.
the atl tasks were limited to the declarative part of atl imperative concepts were neither used nor taught.
we scored measurable skills instead of the pure completeness of solutions clearly defining scoring criteria measuring the most general aspects of the languages.
while we could conceive the comprehension and creation tasks to cover all general aspects this was difficult for the change tasks.
so we designed the latter differently for the two scenarios so that they together cover all aspects.
we admit the limitations of a pen and paper experiment.
whether to study pure concepts or concepts embedded in tooling is a standard problem in designing experiments.
the former allows to control the conditions better the latter provides a more realistic setting but also many confounding factors familiarity with tools and ide stability ad hoc influences such as screen size etc.
ideally both kinds of experiments are needed to obtain a complete picture.
in this paper we decided to study the ability to comprehend and express transformations as a function of the concepts of transformation languages.
this has the advantage of producing more fundamental durable findings languages and language groups change much slower than tools .
however this means that our conclusions should not be generalized to tools.
we did mitigate this limitation somewhat by ignoring simple errors such as typos and minor syntactic problems which would be detected by tools.
internal validity .
the perception of a teacher being dis passionate about a language may influence subject s performance.
to mitigate this we used two locations with different teachers.
differences caused by the university local culture and the teacher were controlled by enforcing an equal distribution of the treatments in both sites.
the imbalance in the number of data points between the universities could be problematic if the results were differed.
fortunately no big difference were observed.
we mitigated selection bias by randomizing the student treatment assignment early in the courses.
yet some students left before the experiment late in the course but the mortality rate was low andtable wilcoxon rank sum test significance level .
corrected threshold for p values .
x y h0 p value result vd.a comprehend fm qvto atl x y .
h0not rejected .
medium qvto xtend x y .
h0not rejected .
small xtend atl x y .
h0not rejected .
neg.
comprehend re qvto atl x y .
h0not rejected .
small qvto xtend x y .
h0not rejected .
small xtend atl x y .
h0not rejected .
neg.
change fm qvto atl x y .
h0not rejected .
medium qvto xtend x y .
h0not rejected .
medium xtend atl x y .
h0not rejected .
neg.
change re qvto atl x y .
h0not rejected .
small qvto xtend x y .
h0not rejected .
small xtend atl x y .
h0not rejected .
medium create fm qvto atl x y .
h0not rejected .
small qvto xtend x y .
h0not rejected .
small xtend atl x y .
h0not rejected .
neg.
create re qvto atl x y .
h0not rejected .
medium qvto xtend x y .
h0not rejected .
medium xtend atl x y .
h0not rejected .
small affected all languages similarly.
we did not count these cases as failed attempts.
we prohibited communication and assigned tasks with different scenarios to adjacent participants.
the tasks were ordered in increasing cognitive difficulty for all subjects and treatments comprehend change create .
thus results of the create task are affected by learning effects and fatigue.
this is acceptable as all data points are affected similarly and because we did not compare performance between tasks.
this order also reflects the working situation of developers in practice.
for the comprehension tasks we traced our observations from the target instance back to the participant s understanding of language concepts.
for instance if no new objects are created we attributed this to a misunderstanding of the language s concepts for creating objects e.g.
in qvt o via mapping rules or the object keyword .
it could be that the participant understood the concept but assumed it is not used due to misunderstanding control flow.
we mitigated this threat by making sure that multiple observations in the target model map to a language concept.
atl and qvt o use ocl as an expression language that is known to be complex.
we did treat this complexity as an inherent part of both languages.
yet understanding the impact of this language design choice and comparing ocl to another expression language would be a valuable future experiment.
external validity .
naturally experienced developers working in industry differ from students even if both have to learn a language completely anew.
more experienced developers might reach proficiency faster than students.
yet they would likely have less time available to learn a language.
so we think that the mistakes and 453esec fse november lake buena vista fl usa r. hebig c.seidl t. berger j. kook pedersen a. w sowski successes of our students are representative for challenges to be expected from developers who learn a transformation language.
students might differ due to their demography.
all students had at least .
years of university experience including object oriented programming in java and programming projects.
while the body is relatively uniform deviations are possible.
our results do not indicate corresponding biases.
however future studies will have to show whether the distribution in experience impacts the results.
the challenges posed in the two devised scenarios may influence the results.
to mitigate this we selected two scenarios representative of common transformations.
still there is substantial risk that some of the observations characterize the scenarios just as much as the languages especially observations .
overcoming this risk requires creating even larger studies with more scenarios.
finally our observations are stated solely for atl qvt o and xtend.
we hesitate to generalize them to other languages.
cognition of large non trivial languages and complex problems is subtle.
more studies are needed to establish whether our results pertain to other languages including gpls functional programming languages and other transformation languages including grammar and graph grammar based languages .
our insights about individual language concepts are likely transferable across languages.
conclusion validity .
a larger sample would strengthen the power of tests and the ability to draw statistically significant conclusions.
yet it is unlikely to considerably change the effect size.
the observed effects are mostly small with no constancy of medium and large sizes across the tasks and scenarios.
for example there is a large effect for the change task between qvt o and xtend in the fm scenario but only a small one for the re scenario.
related work hutchinson et al.
present results of a twelve month long empirical study on the application of mdsd in industry.
they find that using transformations might increase development time significantly while decreasing maintenance time due to the possibility of applying transformations multiple times.
this acknowledges the relevance of studying transformations languages.
prior surveys propose taxonomies of model transformations.
we selected the subject languages with these taxonomies in mind sampling over the key dimensions language paradigm declarative vs. imperative and application domain dsl vs. gpl .
van amstel and van den brand introduce and evaluate three analysis techniques for transformation specifications.
they suggest that a common understanding of the quality of transformations is missing which challenges the design of m2m languages.
we address this challenge and contribute details about difficult language concepts and challenging transformation skills.
kosar et al.
compare program comprehension between nontransformation gpls and dsls in three controlled experiments.
they find that subjects are more accurate and more efficient in program comprehension when using dsls.
interestingly we do not observe the general advantage of transformation dsls in our experiment not even just for the comprehension task.
kramer et al.
describe the design of a planned experiment on the comprehension only of m2m languages versus gpls.
unfortunately no actual experiment is conducted.
the scope of ourexperiment is broader we also investigate how developers change and create transformations and also compare dedicated m2m languages with each other not just with a gpl .
gr nmo and oldevik propose desired properties of m2m languages and use them to compare the uml model transformation tool umt with other languages including atl .
they solely transform uml whereas we inspect different model transformation languages irrespective of the transformed language.
rose et al.
report on the model transformation contest5 where participants perform transformation tasks with various tools.
they compare nine different transformation but focus on model migration so their observations do not easily generalize.
paige et al.
describe state of the art of model evolution.
they acknowledge the suitability of m2m languages for this task and name it as a future research direction.
our experiment may help in guiding the search for an ultimate m2m language.
iosif lazar et al.
report on implementing and debugging a non trivial software modernization transformation.
they discuss different errors than us since we observe early stage errors and they observe errors surviving after a thorough testing process.
conclusion how effectively do programmers use model transformation languages what problems do they face and what aspects of these languages emerge as particularly useful or problematic in contrast to gpls?
all studied languages declarative imperative domain specific or general purpose appear to help users in complex tasks such as the copying of model parts.
the domain specific languages support subjects better in identifying the starting point and context for changes compared to xtend gpl .
still we did identify a potential for improvement for all studied languages.
most subjects struggled to correctly create and change value conditions to initialize multivalued properties and to use recursion.
the future language and tool design research can address some of these problems.
importantly we were unable to statistically confirm an anticipated advantage of transformation dsls over xtend or of atl over the imperative languages.
this is a concerning finding it means that migrating from a gpl to a dedicated transformation language might not bring substantial benefits especially if size and number of transformations is small the benefits seen in the experiment are not significant with small effect sizes .
at the same time expert users of gpls are much easier to hire than transformation language experts so productivity with a modern gpl may well be higher.
model transformation researchers should consider these results as an indication that further improvements are needed in this technology to warrant strong benefits.
acknowledgment we thank our experiment participants eu h2020 and the swedish research council .