using bio metrics to predict code quality online sebastian c. m ller thomas fritz department of informatics university of zurich switzerland smueller fritz ifi.uzh.ch abstract finding and xing code quality concerns such as defects or poor understandability of code decreases software development and evolution costs.
a common industrial practice to identify code quality concerns early on are code reviews.
while code reviews help to identify problems early on they also impose costs on development and only take place after a code change is already completed.
the goal of our research is to automatically identify code quality concerns while a developer is making a change to the code.
by using biometrics such as heart rate variability we aim to determine the di culty a developer experiences working on a part of the code as well as identify and help to x code quality concerns before they are even committed to the repository.
in a eld study with ten professional developers over a two week period we investigated the use of biometrics to determine code quality concerns.
our results show that biometrics are indeed able to predict quality concerns of parts of the code while a developer is working on improving upon a naive classi er by more than and outperforming classi ers based on more traditional metrics.
in a second study with ve professional developers from a di erent country and company we found evidence that some of our ndings from our initial study can be replicated.
overall the results from the presented studies suggest that biometrics have the potential to predict code quality concerns online and thus lower development and evolution costs.
.
introduction a commonly accepted principle in software evolution is that delaying software quality concerns such as defects or poor understandability of the code increases the cost of xing them .
ward cunningham even went as far as stating that every minute spent on not quite right code counts as interest on that debt .
code reviews are one practice that is widely used today to detect code quality problems early on.
code reviews are generally performed by peers after a developer completes the changes for a task and they help to improve code permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
copyrights for components of this work owned by others than the author s must be honored.
abstracting with credit is permitted.
to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
request permissions from permissions acm.org.
icse may austin tx usa c copyright held by the owner author s .
publication rights licensed to acm.
isbn .
.
.
.
readability and to nd defects .
at the same time code reviews impose costs in terms of time and e ort by peers to perform the review.
several automatic approaches to detect code quality concerns have been proposed for instance to detect defects or code smells .
these approaches generally have two disadvantages in common rst they are predominantly based on metrics such as code churn or module size that can only be collected after a code change is completed and often require access to further information such as the history of the code second they do not take the individual di erences between developers comprehending code into account such as the ones that exist between novices and experts .
the goal of our work is to use biometric sensing to overcome these disadvantages and lower the development cost by identifying code quality concerns online while a developer is still working on the code.
previous research including one of our earlier studies has already shown that certain biometric measures such as heart rate variability hrv or electrodermal activity eda can be linked to task di culty or difculty in comprehending small code snippets .
the general concepts behind these studies are that biometric measures can be used to determine cognitive load the amount of mental e ort required to perform a task and that the more di cult a task the higher the cognitive load and the higher the error rate .
in our work we build on top of these concepts and aim to examine the use of biometrics to determine the places in the code that professional developers perceive to be di cult and are therefore more likely to contain quality concerns errors .
this would allow us to automatically perform preemptive code reviews helping developers to commit code with less quality concerns.
to investigate the use of biometrics to predict code quality concerns online we performed a eld study with ten professional developers in a canadian company over a period of two weeks.
we collected a variety of metrics including biometrics such as heart rate variability as well as more traditional metrics such as code complexity and churn.
after each committed change and periodically throughout the study we asked developers to assess the perceived di culty of the code elements methods and classes they were just working with.
additionally we collected quality concerns identi ed in peer code reviews of the committed changes.
amongst other results our study shows that biometrics outperform more traditional metrics and a naive classi er in predicting a developer s perceived di culty of code elements while working on these elements.
our analysis also shows that code elements that are perceived more di cult by de2016 ieee acm 38th ieee international conference on software engineering velopers also end up having more quality concerns found in peer code reviews which supports our initial assumption.
in addition the results show that biometrics helped to automatically detect of the bugs found in code reviews and outperformed traditional metrics in predicting all quality concerns found in code reviews.
to assess our approach s generalizability we conducted a second study with ve developers in a swiss company over a period of a week.
the results of this study provide evidence that some but not all of our ndings can be replicated.
in summary this paper makes the following contributions it presents results of a two week study with ten developers investigating the use of biometrics in the eld to determine code quality concerns and developers perceived di culty.
it provides a comparison between various metrics showing that biometrics can outperform more traditional metrics in predicting code quality concerns online.
it presents results of a one week replication study with ve developers from a di erent company and country.
overall the results of our studies suggest that developers biometrics have potential to identify di cult places in the code and in turn quality concerns and thus might be used to lower the overall software maintenance cost.
.
related work work related to our research can roughly be categorized into three major areas the manual detection of quality concerns in form of inspections and code reviews automatic detection based on code change and interaction metrics and more broadly the use of biometrics in software development.
manual detection.
the substantial bene ts and cost savings of manual software inspection have long been known based on evidence from multiple places .
while these results were mostly based on formal inspections companies today often employ more lightweight and tool supported code review processes that require less time and effort .
several studies have looked into these lighter weight code reviews in particular their practices characteristics and outcomes and shown amongst other results that these lightweight code reviews still lead to substantial code improvements and the detection of defects .
overall the results from these studies show that manual code inspection can help to detect many quality concerns soon after code changes were performed and lead to signi cant cost savings in software evolution.
at the same time manual inspections still require time and e ort of peer developers and can only be done after the code was committed or shared for review.
automatic detection.
there is a myriad of research investigating the automatic detection of code quality concerns.
most of these approaches focus on various software metrics such as complexity size or change metrics and their correlation to software defects .
instead of code and change metrics researchers have also looked into organizational information to predict defects for instance the number of developers who touched a le .
others have focused on the automatic detection of code smells predominantly by using code metrics in combination with absolute or relative thresholds or rule sets but also by mining the change history .
furthermore there are tools such as findbugs or pmd that can help to identify potential quality concerns in the code .
most of these ap proaches only allow for a post hoc classi cation and do not take into account the individual di erences between developers working on the code.
a rst step into this direction was taken by lee et al.
who focused on developers individual interaction patterns and proposed micro interaction metrics for defect prediction.
in a case study the authors compared defect prediction learners based on change metrics and source code metrics with models based on micro interaction metrics and found that developers interaction patterns such as the ratio between edits and selects can signi cantly improve the defect prediction.
rather than identifying quality concerns code metrics have also been used to assess the di culty of various coderelated activities such as program comprehension.
for instance curtis et al.
or feigenspan et al.
investigated how di erent kinds of code metrics correlate with developers performance on maintenance tasks respectively program comprehension.
closer to our research carter et al.
used interaction logs within the ide to predict when a developer is stuck experiencing a lot of di culties and cannot make any progress.
in contrast to these studies we are investigating the use of biometric measurements to identify quality concerns.
using biometrics would allow for an online detection that takes into account the individual di erences between developers.
biometrics.
in psychology a broad range of biometric measurements has been investigated and correlated with a person s cognitive states and processes.
these biometrics can be roughly categorized into skin heart and breathing related measurements.
commonly used measurements are electrodermal activity eda and skin temperature for the skin heart rate hr and heart rate variability hrv for the heart and the respiratory rate rr for breathing related measurements.
for all these measurements researchers have found correlations to mental and cognitive load e ort as well as to task di culty as presented in table .
in the context of software engineering these biometric measurements were used to assess developers mental load and perceived di culty while working on small code snippets.
parnin investigated the potential of electromyography emg to measure sub vocal utterances and found that this might be used to determine programming task difculty.
in a similar direction nakagawa et al.
used near infrared spectroscopy nirs to measure developers cerebral blood ow cbf while working on code comprehension tasks with two di culty levels.
radevski et al.
proposed an approach that uses electro encephalography eeg to assess developers productivity in real time.
finally in a previous study we used a combination of biometric sensors and found that they can be used to predict the di culty of small code comprehension tasks .
besides these studies most research in software engineering using biometric measurements focused on eye tracking technology e.g.
or developers brain activities e.g.
to gain a better understanding of program comprehension.
in contrast to all these studies we focus on the online prediction of code quality concerns and are one of the rst ones to perform a longitudinal two week eld study with biometrics sensors.
.
psychological background our work on the use of biometrics builds on top of established psychological research and concepts including the 453task developer task format complexity time pressure ... age personality traits ... input psychological concept outcome measures qcs errors difficulty eda rr hrv ...biometric measurementscognitive load self reports peer reports influences measurement conceptmeasureslegendfigure concepts and relationships between input cognitive load biometric measurements and outcome.
cognitive load theory.
figure illustrates some of these relations relevant to our work.
cognitive load cl refers to the required mental e ort to perform a task and is composed of intrinsic e.g.inherent task di culty extrinsic e.g.the way the code is written and germane load e ort for processing information .
in general the more di cult it is to perform a task for an individual the higher the cognitive load and in turn the lower the individual s performance and the higher the error rate .
previous studies have shown that mental e ort and cognitive load can be measured using biometrics e.g.
.
based on the links between cognitive load errors and biometrics we might be able to use biometric measurements to determine a developer s perceived di culty when working with a code element and the likelihood of an error being created.
also since biometrics are linked directly to a developer s cognitive load and thus capture individual di erences even for the same task this approach should be more accurate than proxies that try to capture cognitive load from artifacts.
.
study method to investigate the use of biometrics to detect quality concerns online we analyzed four main research questions rq1 can we use biometrics to identify places in the code that are perceived to be more di cult by developers?
rq2 can we use biometrics to identify code quality concerns found through peer code reviews?
rq3 how do biometrics compare to more traditional metrics for detecting quality concerns?
rq4 how sensitive are these biometrics to the individual?
to address our research questions we conducted a longterm empirical eld study with ten professional software developers working for a medium sized software development company in canada.
over the course of two weeks participants worked on their usual tasks in their usual work environment while wearing biometric sensors.
we periodically asked participants to rate the di culty of the code elements methods and classes they were working with on a point likert scale and collected quality concerns identi ed in peer code reviews.
in addition we gathered more traditional metrics for comparison purposes1.
1a replication package of this study is available online .
.
participants sensors we were able to recruit ten professional software developers from a medium sized software development company in canada for our study.
the ten participants nine male one female ranged in age from to years and had an average professional software engineering experience of .
years ranging from to years.
all study participants worked on the same project but were split over three di erent teams that were in charge of di erent components of the project.
all teams followed a similar agile software development process and worked on tasks with similar sizes2.
each participant had access to her biometric data and was allowed to quit any time without providing a reason.
we used two biometric sensors for this study an empatica e4 wristband to capture skin and heart related measurements and a sensecore chest strap3to capture skin except for eda heart and breathing related measurements.
participants were asked to wear the chest strap and optionally also the wristband.
we ended up with all ten participants wearing the sensecore sensor for the two week study period and six of them p01 p04 p05 p06 p07 and p08 also wearing the empatica wristband in addition.
.
study procedure at the beginning of the study we asked each participant to install a small self written interaction monitor plugin into their eclipse ide that logged each time a developer selected or edited a method or a class within the ide in combination with the current timestamp.
at the same time the plugin collected a set of code metrics for each code element that was selected or edited.
after that we introduced participants to the biometric sensors gave them the option of either wearing both or just the sensecore chest strap and helped them to put the sensor s on for the rst time.
then we told participants to continue performing their work as usual for the next two weeks while wearing the biometric sensors.
an overview of the procedure and data collection for the twoweek period is presented in figure .
at the end of each workday we collected the biometric data from each participant and charged the batteries of the sensor s .
once per day of the study participants were also asked to watch a two minutes video of sh swimming in a sh tank while wearing the biometric sensor s .
the movie was intended to help participants relax and allow us to record a baseline during the second minute of the two minutes session that we used later on to normalize the captured biometric data.
in previous studies we saw that a person s biometric features drop back to a baseline after about a minute of watching the video.
in addition to the code metrics and interaction logs that we recorded with our eclipse plugin we also collected three di erent types of outcome measures.
first every minutes the eclipse plugin prompted participants to answer a small questionnaire within eclipse that asked them to rate the perceived di culty of randomly selected code elements that they were working with within the last minutes.
second every time a participant committed a set of code changes to the repository we asked the participant 2for privacy reasons we are not able to disclose more speci cs on the company and also substituted code element names throughout the paper.
3sensecore sensors are no longer available due to the company s closure.
454figure overview of study procedure and collected data.
table overview of collected biometrics and their previously found correlations to psychological aspects.
measurement previously found correlations heart related heart rate variabilitymental e ort task di culty mental load task demand heart rate mental e ort mental load task di culty breathing related respiratory mental e ort task di culty rate task demand skin related skin temperature task di culty electro dermal activitymental load task di culty stress and cognitive load to rate the di culty s he perceived while working on and changing each of the classes and methods in the committed changes.
as part of the company s development process each committed code change was also reviewed by one to three peers.
finally we collected the outcome of the code reviews for the code changes committed by our participants.
at the end of the study each participant completed a short demographic background questionnaire.
.
metrics and outcome measures we collected four kinds of metrics biometrics code metrics interaction metrics and change metrics and three different types of outcome measures.
.
.
biometrics we used the chest strap and the wristband to collect various biometric measurements that have previously been linked to task di culty as well as cognitive and mental effort.
table provides an overview of the biometrics we captured for this study and the previously found correlations.
a complete list of all extracted features can be found in the replication package .
to use biometric data for predicting quality concerns of code elements we had to apply several data segmentation data cleaning and feature extraction steps.
the biometric sensor data is captured as a sequence of data entries with a timestamp and the person s biometric values for that point in time.
to map biometric data to code elements we used the assumption that a developer is thinking about and affected by the code element s he just selected or edited see section and therefore segmented the biometric data based on the user interaction log that we captured with our eclipse plugin.
speci cally we used the time interval from the pointin time a developer interacted with a code element cin the ide up to the point in time s he interacted with a di erent element or left the ide to segment the biometric data and associated the biometric data segment corresponding to this time interval with the code element c. since a person s heart rate and the phasic part of the eda signal typically take about one to two seconds to adapt to changes we only considered segments that span at least three seconds in our analysis i.e.when the developer spent at least three seconds on a code element before moving on and ltered the biometric data for the rst two seconds of the segment to allow for the change in the biometrics to take place.
heart related biometrics.
for the heart rate we extracted the mean and the variance of the signal while for the heart rate variability we used features that represent the di erence in time between two heart beats such as rmssd root mean square of successive di erences or nn50 the number of pairs of successive beat to beat intervals that di er more than 50ms .
all these features have been linked to mental e ort and load as well as task di culty .
breathing related biometrics.
previous research linked a person s respiratory rate to task di culty .
we therefore extracted commonly used features such as the mean respiration rate or the log 10variance of the respiration signal and added them to our feature set.
skin related biometrics.
for the skin temperature we extracted features such as the mean temperature that research has linked to task di culty .
to extract features from the eda signal we used butterworth lters to split it into two parts the high frequency fast changing phasic part and the low frequency slowly changing tonic part .
in a next step we extracted features related to the peaks in the phasic signal and features from the tonic part that research has linked to mental load and task di culty .
all biometric measurements were normalized using the baseline measurements that we collected during the second minute of the two minutes sh tank movie.
.
.
code change and interaction metrics we collected several metrics for code elements methods and classes that have previously been associated with difcult code or defects.
most of these metrics were captured with our eclipse plugin.
code metrics.
for each code element the plugin calculated code metrics that research has linked to di culty in program 455comprehension and code quality.
the collected metrics were mccabe s complexity e.g.
halstead s complexity measures e.g.
various size metrics e.g.
and fanout e.g.
.
since code metrics might alter when a developer makes changes to a code element we captured the metrics every time a developer interacted with a code element.
change metrics.
every time a developer committed a change set to the repository in the study period we extracted the number of lines added and removed for each code element.
previous research has shown that these metrics can be reliable predictors for defects e.g.
.
due to limited access to the source code repositories in the company we were only able to collect these metrics on class and not on method level.
interaction metrics.
previous research has shown that metrics on interaction data in particular the ratio between edit and select events might be used to improve defect prediction and to determine when a developer experiences difculties e.g.
.
we therefore collected the number and ratio of edit and select events for each code element.
.
.
outcome measures over the course of the study we collected three di erent types of outcome measures.
perceived di culty during a change task.
every minutes participants were prompted with a questionnaire that asked them to rate the di culty they perceived while working on randomly selected code elements from the previous minutes on a point likert scale from very easy to very di cult .
for the elements in each questionnaire we equally balanced the number of methods and classes and the number of edited and selected code elements unless the participant did not interact with a su cient number of elements in the previous minutes.
perceived di culty at the end of a change task.
we manually monitored code repositories.
as soon as we noticed that a developer committed a change set to the repository we asked her him to rate the di culty s he perceived while performing the necessary changes for each class and method that was changed.
for this rating we used the same point likert scale as for the rst outcome measure.
code quality concerns detected through peer reviews.
each committed change set was typically reviewed by one to three peers shortly after the commit time.
the reviewers looked for actual bugs inadequate documentation or test cases and violations of coding styles.
we collected the results of these code reviews for each change set that was committed by one of the study participants.
we marked a code element as containing a quality concern when at least one was identi ed in a code review.
.
data collection across all study participants and the two weeks of the study we were able to collect biometric measurements for a total of developer work days ?
.
.
.
this resulted in .
gb worth of biometric data consisting of .
million data points.
for all ten study participants we collected skin temperature hr hrv and rr data.
for six study participants who volunteered to also wear the empatica wristband sensor we were able to collect the eda as well as a second skin temperature and hr v measurement.
we decided to take the signal from the sensecoretable number of collected data points for each study participant during and at the end of a change task.
subjectmethods classestotalduring after during after p01 p02 p03 p04 p05 p06 p07 p08 p09 p10 total table number of quality concerns found in code reviews.
category method class total coding style violation bug missing test insu c. exception handling inadequate comments other total sensor whenever possible and only rely on the empatica signal in case the sensecore signal could not be recorded since our previous experiences with the two sensors indicate that the sensecore signal is more accurate.
in addition to the biometric data we collected perceived di culty ratings for methods and classes.
from the di culty ratings for methods were collected while developers were working on a change task while the rest were collected at commit time.
similarly classes were rated while working on a change task and at commit time.
on average study participants spent .
minutes on a particular class and .
minutes on a particular method between two consecutive di culty ratings that occurred every minutes.
table provides an overview of the di culty ratings we collected for each participant in the study.
for all code elements that were changed and committed by one of our participants we were also able to collect the results of the peer code reviews of these elements.
in total we collected quality concerns on method level and on class level.
we ended up with .
classes in which a quality concern was found and .
without any quality concern.
similarly our dataset consists of .
methods with a quality concern and .
methods without any quality concern.
table provides an overview of the categories of quality concerns found during code reviews.
finally we also collected answers to the demographic questionnaires at the end of the study.
.
data mapping figure illustrates some of the ratings and biometric data that we collected for participant p02 on class classx.java over the course of his her work on a change task.
during the depicted time period p02 was interacting with classx seven times.
at three points in time during the depicted period the developer was prompted by our plugin to rate the perceived di culty while working with this class.
for the three ratings the perceived di culty changed from three to one to ve.
while the developer was working on this 456figure exemplary perceived di culty rating and biometric data heart rate skin temperature and respiration rate over seven time periods during which participant p02 worked on the class classx.java .
class we also captured the biometric measurements as described earlier on.
a subset of these metrics is also depicted in figure .
for each rating by the developer on perceived di culty during work we associated the biometric measurements collected between the current and the previous rating.
for the example shown in figure we only considered the biometrics captured in interval for rating the intervals for rating and intervals for rating .
in this example there is a visible di erence with the mean heart rate being rather low between rating and rating for which interval the class was perceived easy and the mean heart rate between rating and rating when the class was perceived more di cult .
for a developer s rating of perceived di culty at the time of a commit we associated all biometric measurements collected between the current and the previous commit.
for each code metric we captured for a code element and a given time frame either between two ratings or between two commits we calculated and collected the metric every time a developer interacted with the element and then calculated the mean over all interaction instances within the considered time frame.
.
analysis and results in the following we address our research questions by presenting the analysis and results of the gathered data.
.
perceived difficulty and quality of code figure depicts the distribution of collected di culty ratings.
overall only very few code elements .
that developers worked with were perceived as di cult or very di cult while most .
were perceived as very easy or easy.
to investigate whether and how the perceived di culty of a code element changes over time we analyzed a developer s figure distribution of developers di culty ratings of code elements.
di culty ratings that we collected for the same code element during or at the end of a change task.
while we did not collect multiple ratings for each code element during a change task due to the random selection process we had cases per developer in which we did.
in .
of these cases the perceived di culty changed between two consecutive ratings with of these cases in which the perceived di culty increased.
in most of these cases in which the perceived di culty changed over the time a developer worked on a change task code metrics did not change.
for instance the number of lines metric only changed in less than half and mccabe s cyclomatic complexity only in less than a third of the cases.
these results indicate that the perceived di culty of a code element changes frequently over the course of a change task and that these changes might often not be re ected in code metrics.
table provides an overview of the number of code elements that participants rated at commit time and the number of quality concerns that were found in these elements 457table quality concerns qc found in code elements during code reviews grouped by perceived di culty.
perceived di culty methods reviewed with qc classes reviewed with qc in the code reviews.
as an example from the methods that were rated as being very easy .
were found to contain a quality concern during code review.
the results show that the more di cult a code element is perceived the higher the likelihood of it containing a quality concern con rming our initial hypothesis.
so while for example only .
of the methods perceived as easy had quality concerns .
out of methods of the di cult elements that were rated as had quality concerns.
.
prediction of code difficulty and quality to answer our research questions we performed a machine learning experiment.
we chose machine learning since it has been shown to be a good approach for nding links between low level biometric data and high level phenomena such as perceived di culty and quality concerns .
.
.
machine learning approach we conducted three kinds of predictions on two granularity levels method and class level each.
in particular we examined whether we can use machine learning to rst predict a developer s perceived di culty of a code element while working on a change task rq1 second predict a developer s perceived di culty of a code element after completing i.e.committing the work on a change task rq1 and nally predict whether a code element contains a quality concern found in a code review rq2 .
since we collected less than four data points for participant p01 p02 and p04 for perceived di culties of methods after a commit and machine learners need a bigger sample size for reasonable results we excluded these three participants from this speci c prediction analysis.
for the machine learning classi cations we used weka a java based machine learning framework.
for the classi er we opted for a random forest learner under the assumption that the non parametric characteristics of decision trees would t our collected data which often exhibited a non parametric distribution and because random forest learners can deal well with small sample sizes .
studies have shown that for bug prediction based on code and change metrics the learner should not have a big in uence on the performance .
we performed a leave one out evaluation for each participant separately.
this means for each participant and prediction we trained our classi ers in turn with all data points we captured except one and then used the remaining one as test set.
we made sure that no identical code elements were in both the training and the test set.
for comparing biometrics with more traditional metrics we performed each of the six x predictions for ve di erent classi ers a classi er based on biometric data one based on code metrics one on change metrics one on interaction metrics and one that combines all metrics.
.
.
machine learning results we split our results based on the outcome measure.
perceived di culty rq1 rq3 rq4 .
figure summarizes the results of our machine learning experiments for predicting perceived di culty.
in particular it presents cohen s kappa values for predicting a developer s perceived di culty of code elements during figure 5a and after nishing figure 5b a change task.
cohen s kappa measures the agreement between the prediction and the ground truth taking into account the agreements that might occur by chance.
according to landis and koch kappa values from to .
can be considered as slight from .
to .
as fair from .
to .
as moderate from .
to .
as substantial and from .
to as almost perfect agreement.
for comparison reasons we also added the value for a naive predictor that always predicts the most dominant class but never any other one.
to be of practical value our biometric classi er should be able to outperform this naive predictor.
for three out of the four cases see figure the biometric classi er outperforms the classi ers that are based on interaction metrics and on code metrics as well as it outperforms the naive classi er on average by more than .
only a classi er that combines all metrics including biometrics achieves better results in these cases and only for the case of predicting the di culty of classes after a change task is the biometric classi er worse than a naive one predicting only a dominant class.
these results demonstrate the potential that biometrics have in particular for predicting the perceived di culty of a code element online while the developer is still working on the change task.
for a more detailed analysis of the results we chose one case and depicted the confusion matrix for the perceived difculty prediction on method level in table .
the matrix shows that in most cases the predicted di culty value to is only slightly o of the real value.
finally table presents the percentage of correct predictions of the biometric classi er for each participant.
these results illustrate the individual di erences in the accuracy of predictions.
for instance some participants such as p10 have a high accuracy for all predictions while others such as p07 have a high accuracy for some but not all predictions.
quality concerns rq2 rq3 .
when predicting whether a code element contains a quality concern qc or not no qc a biometric classi er performs best over all and even outperforms a classi er that combines all metrics.
the top part of table presents the results in terms of precision and recall.
we chose precision and recall instead of f score to highlight the tradeo between the two.
the biometric classi er is able to correctly identify out of .
code elements with a quality concerns on method level and out of on class level.
at the same time the precision is not very high with .
respectively .
and further research is needed to examine this in more detail.
table provides more details on the percentage of correct classi cations for each quality concern category.
the data reveals that with the exception of the other category the level of correctness is in a similar range for each category.
particularly interesting is the bug category that shows that our biometric classi er is able to identify half of all bugs found in code reviews.
within vs. across participant rq4 .
to investigate how sensitive the biometrics are to an individual we per458 a during change task b after change task at commit figure cohen s kappa for predicting perceived di culty for class and method level.
table confusion matrix for perceived di culty prediction on method level during the work on a change task.
each cell contains values from each predictor in the order of all biometrics code metrics interaction metrics change metrics.
actualprediction table percentage of correct predictions per participant using biometrics.
sub.di culty during di culty after quality concerns method class method class method class p01 .
.
.
.
p02 .
.
.
.
p03 .
.
.
.
.
.
p04 .
.
.
.
p05 .
.
.
.
.
.
p06 .
.
.
.
.
.
p07 .
.
.
.
.
.
p08 .
.
.
.
.
.
p09 .
.
.
.
.
.
p10 .
.
.
.
.
.
all .
.
.
.
.
.
formed a second machine learning experiment in which we trained the classi ers not on each participant individually but on data from all participants.
we again used a leaveone out approach to train the machine learning classi ers in turn for each participant except one and then used the remaining one as test set.
we made sure that no code element was in both the test and training set.
the results for predicting perceived di culty either during or after a change task are very low.
cohen s kappa values were very close to or well below showing that the predictive power of the classi ers is not any better than chance.
for predicting quality concerns with a biometric classi er across participants the results however are better and in some cases even outperform the prediction based on individual classi ers as presented in the bottom half of table .
the recall values on quality concern predictions on method level are signi cantly higher than the ones achieved by a within participant classi cation.
however this comes with a cost and the precision is generally lower and the recall for the code elements that do not contain a quality concern also decreased signi cantly.
we hypothesize that the classi ers trained with data across individuals tend to predict more often that a code element contains a quality concern since thistable results for quality concern qc prediction within across participants in p precision r recall ud.
unde ned .
bold values accent the best result in each category.
metricmethod class qc no qc qc no qc p r p r p r p rw ithinall .
.
.
.
.
.
.
.
biometric .
.
.
.
.
.
.
.
code .
.
.
.
.
.
.
.
interaction .
.
.
.
.
.
.
.
change .
.
.
.3ac rossal l .
.
.
.
.
.
.
.
biometric .
.
.
.
.
.
.
.
code .
.
.
.
.
.
.
.
interaction .
.
.
.
.
.
.
.
change ud.
.
.
.
table percentage of correct quality concern predictions by category using a biometric classi er.
quality concern category correct method class coding style .
.
bug .
.
missing tests .
.
insu cient exception handling .
.
inadequate comments .
.
other .
.
case is represented in the training set more often compared to the training set for each participant individually.
.
replication study since there are many factors that might in uence the study ndings such as the development process or the source code to name just a few we performed a second smaller and shorter study.
for this study we collected similar but less data from ve professional developers of a medium sized software development company in switzerland4.
4for privacy reasons we are not able to disclose more speci c information about the company.
459table number of collected data points per participant of the second study during and at the end of a change task.
subjectmethods classestotalduring after during after p11 p12 p13 p14 p15 total study method participants.
for this second study we were able to recruit ve professional software developers working at a medium sized software development company in switzerland.
the ve study participants worked in four di erent teams and each team worked on a di erent product.
the study participants were all male ranged in age from to years ?
.
.
and had an average professional software development experience of .
years .
.
we followed the study method from our rst study to collect metrics and outcome measures.
all ve participants used the sensecore chest strap sensor for approximately one week.
over all participants we collected data for a total of work days ?
.
.
including .
gb of biometric data that consists of .
million data points.
table provides an overview of all data points collected during the second study.
on average a study participant spend .
minutes per method and .
minutes per class between two consecutive di culty ratings that occurred every minutes.
di erences limitations.
the teams in our main study and in the replication study followed a similar development process and developers worked on tasks with similar size.
in contrast to the rst study the replication study only lasted one week due to time constraints of the participants.
we also only had limited access to the code repositories and thus we were not able to collect perceived di culty ratings on method level at the end of a change task and we were not able to collect any change metrics.
due to the lack of a code review process in the company we were also not able to collect any data on quality concerns found in peer reviews.
while these di erences do not allow us to perform the same analysis it still allows us to replicate some of the analysis in a vastly di erent setting.
especially in light of the e ort and di culty to nd professional software developers that provide us access to their repositories and that are willing to wear biometric sensors for an extended period of time we believe this is a reasonable step for an initial replication.
machine learning predictions results.
for the data collected during the second study we extracted the same features from the data and performed the same leave one out within participant predictions as we did for the rst study.
table summaries the results of the predictions.
in the second study the biometric classi er outperforms classi ers based on interaction or code metrics in the after commit case i.e.after the code changes for a task were nished with an improvement of more than .
in the other two cases for predicting di culty during a change task the classi er based on code metrics performs better but the biometrics classi er is still signi cantly better than the naive classi er.
similar to the results of the rst study the classi er that incorporates all the di erent metrics is the best classi er.table cohen s kappa for perceived di culty prediction for the second study.
metricmethod class during during after interaction .
.
.
code .
.
.
biometrics .
.
.
all .
.
.
naive .
.
.
in summary the results of the second study provide initial evidence that we can replicate some of our ndings from our main study but not all.
there are many potential reasons for the di erences in ndings one of which is that we only collected about half the time of biometric data per code element and rating.
further studies are needed to investigate these aspects in more detail.
.
discussion in this section we discuss the results of our study as well as their implications on practice and further research.
predicting code quality online.
our study is the rst longer term study in a real world software development context with biometric sensors that provides evidence on the feasibility of using these sensors in the eld.
the results show that it is possible to predict quality concerns and perceived di culty of code elements with higher accuracy than traditional metrics in most cases even despite the noise in professional work environments.
biometrics di erent to traditional metrics allow for online while the developer is still working on the code measures and thus for example to prevent bugs from ever being committed by focusing developers attention on these parts without requiring access to repositories.
biometrics also factor in developers individual di erences that are not captured by traditional metrics and thus should provide more accurate results in particular when they can be trained on each individual.
our results also show that code elements that are perceived more di cult are also more likely to contain quality concerns.
this adds to existing evidence that the di culty a developer experiences when working on a code element can have a strong in uence on the quality concerns the developer creates or adds when changing the code element for the task at hand.
consistently our results suggest that it is possible to use biometrics not only for predicting perceived di culty but also quality concerns identi ed in peer code reviews.
while the precision for identifying quality concerns in our study could be higher the fast technology advances leading to more accurate and less noise sensitive sensors should soon lead to an increase in precision and the value of biometrics in this context.
also we performed the data analysis for this study retrospectively but the sensors we used already support real time data transmission.
since the predictions only require short time windows of a few biometric features almost instantaneous feedback should soon be possible.
while our smaller scale replication study provides evidence that some of our initial ndings can be replicated in other settings it did not con rm all of our ndings.
even though the biometric classi er still always outperformed the naive classi er in two out of the three predictions the biometric classi er was outperformed by a classi er based on code metrics.
there are many potential reasons for this e.g.
the development phase the source code structure the devel460opers personalities or even just the fact that the two studies were performed on di erent continents.
especially given the sensitivity of biometric sensors further longer term studies are planned to investigate these aspects in more detail.
tool support.
our results open up new opportunities for providing tool support.
since we are able to predict early on while developers are still writing code whether a code element contains a quality concern we might be able to help developers and prevent them from ever submitting code with quality concerns to the repository.
this could be done by highlighting the a ected code element s to the developer before s he commits them and suggesting to spend additional time reviewing.
similarly one can use this information to suggest which parts of the code might bene t most from a peer code review and prioritize them.
biometric data could also be used to detect when a developer is experiencing di culties within the code and to provide interactive and immediate feedback ranging from a recommendation to talk to a co worker to taking a break and continuing later on.
while the study results show that it is possible to detect when a developer experiences di culties and determine the corresponding code elements to be able to provide the discussed tool support more research is needed to assess how to best present this information to developers especially without creating frustration.
also to provide this kind of tool support the biometric data needs to be collected continuously and transferred in real time which poses challenges due to sensor invasiveness and more as discussed below.
challenges.
biometric sensors that have the capability to collect the ne grained data needed for the kind of study presented here are still under development and pose several challenges due to their usability invasiveness and the data sensitivity.
for our study we always made sure to have one researcher on site to support participants and we chose sensors that could be worn for several weeks without being too invasive.
with the recent advances in sensor technology the physical invasiveness will decrease even further in the near future.
at the same time more privacy and ethical concerns have to be addressed and investigated especially since these sensors can be used to collect huge amounts of very sensitive health related data.
for all these reasons recruiting study participants who are willing to wear such sensors for weeks and agree to collect a lot of personal data was also very tedious and time consuming but in the near future people might almost automatically collect similar data when wearing watches such as the apple watch .
.
threats to v alidity there are several threats to the validity of our study.
external validity.
the generalizability of our ndings is limited in many ways such as the limited number of participants and companies in our study the focus on java code and the use of the eclipse ide or the limited number of code elements developers work with and perceive as di cult or very di cult.
we tried to mitigate this risk by replicating our initial study and also by collecting data from professional developers in the eld working in di erent teams and even companies over a longer period of time and on industrial project code.
however due the broad spectrum of software development di ering in aspects such as the development process the change task size the programming languages the team size and the development phase the team is in to name just a few further studies are needed to investigate their implications on the use of biometrics.
internal validity.
in one part of this study we used biometrics to predict the quality and di culty of code elements.
a threat to the study is that the data captured with biometric sensors might be a ected by other aspects than the perceived di culty such as the study participants personality traits or their general stress level.
to mitigate this risk we used the sh tank videos to capture a baseline each day and normalize the data with it.
construct validity.
using the interaction log as an approximation of the code elements a developer might currently be thinking about and using this to segment the biometric data also poses a threat to the validity of our study.
however given the current technologies this was the best approximation that was also feasible.
eye tracking devices might provide even more accurate and richer data on which code elements a developer is looking at and thinking about as another study has shown but eye tracking devices are currently too expensive or invasive to be used in a long term eld study of this size.
another threat to validity is the use of developers self reports since they might not always accurately represent their experienced di culty.
finally our comparison to traditional metrics is limited due to the lack of access to the necessary data and repositories and future studies are needed to also examine other metrics linked to code quality such as code churn between multiple versions.
.
conclusion there is a broad range of tools and research that focuses on the identi cation of code quality concerns.
yet most of these approaches only allow for a post hoc assessment and do not take individual di erences of developers into account such as di erent expertise or experience.
in this paper we presented a rst two week eld study on the use of biometric sensors to identify code quality concerns while a developer is working on the code.
the results of our study are promising suggesting that developers biometrics can indeed be used to determine the perceived di culty of code elements and furthermore to identify places in the code that end up with code quality concerns such as bugs.
a second smaller replication study we conducted also con rmed some of our ndings on the automatic determination of di cult parts in the code.
these results open up new opportunities to support developers when they are experiencing di culties in the code and to x quality concerns as early as possible even right when they are being created.
with the recent advances in biometric sensing technologies and their decrease in invasiveness we might soon be able to collect biometric data on each developer just like we are now already able to collect interaction data.
however this also opens up a discussion on privacy concerns and more research is needed to investigate a feasible solution.