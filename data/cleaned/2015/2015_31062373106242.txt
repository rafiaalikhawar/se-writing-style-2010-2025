atexrace across thread and execution sampling for in house race detection yu guo department of computer science western michigan university kalamazoo mi usa yu.guo wmich.edu yan cai state key laboratory of computer science institute of softwar e chinese academy of sciences beijing china ycai.mail gmail.com zijiang yang department of computer science western michigan university kalamazoo mi usa zijiang.yang wmich.edu abstract data race is a major source of concurrency bugs.
dynamic data race detection tools e.g.
fasttrack monitor the executions of a program to report data races occur ring in run time.
however such tools incur significant overhead tha t slow s down and perturbs execution s. to address the issue the state of the art dynamic data race detection tools e.g.
literace apply sampling technique s to selectively monitor memory accesses .
although they reduce overhead they also miss many data ra ces as confirmed by existing studies .
thus practitioners face a dilemma on whether to use fasttrack which detects more data races but is much slower or literace which is faster but detects less data races.
in this paper we propose a new sampling appro ach to address the major limitation s of current sampling techniques which ignore the facts that a data race involves two threads and a program under testing is repeated ly executed.
we develop a tool called atexrace to sample memory accesses across both threads and executions.
by selectively monitoring the pairs of memory accesses that have not been frequently observed in current and previous executions atexrace detects as many data races as fasttrack at a cost as low as literace .
we have compared atexrace against fasttrack and literace on both parsec benchmark suite and a large scale real world mysql server with test cases.
the experiments confirm that atexrace can be a replacement of fasttrack and literace .
ccs concepts software and its engineering software testing and debugging theory of computation program verification .
keywords data race sampling concurrency bugs acm reference format yu guo yan cai and zijiang yang.
.
atexrace across thread and execution sampling for in house rac e detection.
in proceedings of 11th joint meeting of the european software engineering conference and the a cm sigsoft symposium on the foundations of software engineering paderborn germany september esec fse pages.
.
.
.
introduction a data race or race for short occurs when two or more threads access the same memory location at the same time and at least one of them is a write .
race is a major source of concurrency bugs and may result in real world disasters .
static race detection techniques are scalable but may report many false pos itives .
various filters have been developed to address this issue.
however false positives remain and false negatives emer ge with these filters in the static race detection tools .
dynamic techniques report much fewer false positives.
they are mainly based on either the lockset discipline or the happens before relation .
the former requires that all accesses to a shared memory location should be protected by a common set of locks.
the latter is usually implemente d via vector clocks to track the status of thread s locks and memory location s. happens before based race detectors hb detectors for short report less false positives but incur higher overhead than the lockset based ones .
fasttrack by avoiding a large number of o n operations on memory accesses reduce s the overhead to the level as that of the lockset based race detectors .
even so by continuously monitoring all memory accesses of a multithreaded program fasttrack still incurs from to overhead .
sampling is a promising technique to reduce the overhead of dynamic detect ors by selectively monitor ing memory accesses .
there are two types of sampling.
with the assumptions that concurrency bugs cannot be eliminated during testing and dail y use s of released software provide a large test bed t he first type attempts to detect races at user sites including pacer crsampler and a possible adaption of datacollider .
this type of sampling must be extremely light weight i.e.
overhead .
and they usually detect a small number of data races depending on the sampling rate and the overhead limit.
the second type aims at reducing in house testing overhead.
before releasing a software the developers usually test the program again st a large number of test cases and for each test case the program may be executed multiple times.
lower overhead co first author.
corresponding author s. permission to m ake digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the fi rst page.
copyrights for components of this work owned by others than the author s must be honored.
abstracting with credit is permitted.
to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission a nd or a fee.
request permissions from permissions acm.org.
esec fse september paderborn germany copyright is held by the owner author s .
publication rights licensed to acm.
acm isbn ... .
g .
.
esec fse september paderborn germany y. guo y. cai and z. yang enables more testing and thus less races in the tested software.
literace is a representative tool in this category.
it is based on the hypothesi s that undetected races often exist in cold functions that have not been frequently called .
therefore literace reduces overhead by avoiding the sampling of memory accesses in hot functions that have been frequently executed.
figure shows a code sketch with two threads t1 and t2.
functions f1 and f2 are repeatedly executed in t1 and f3 and f4 are repeatedly executed in t2.
races occur when f1 and f4 execute simultaneously and when f2 and f3 execute simultaneously.
assume that t1 is executed more freq uently than t2 and the thenbranches are executed more frequently than the else branches .
initially all functions are cold but quickly f1 becomes hot while other three functions are still cold.
at this moment literace stops monitoring f1 and becomes faste r than fasttrack because the latter still continuously monitors f1.
after a while f2 and f3 get a chance to be executed.
since both functions are cold literace still monitor their execution s and thus can report the race between f2 and f3 at a cost lower t han that of fasttrac k. next f4 is executed at the same time with f1.
in this case literace fails to detect the race between f1 and f4 because it already stopped tracking f1.
on the other hand fasttrack can catch the race because it still monitors f1.
this example illustrates the dilemma in choosing between full scale tools and sampling based tools.
a programmer has to either sacrifices efficiency for accuracy or sacri fices accuracy for efficiency.
we argue that programmers do not have to choose between efficiency and accuracy.
this is achievable because there are two major limitation s in c urrent sampling techniques.
from the definition a race occurrence requires two memory accesses of different threads .
therefore sampling memory accesses in isolation is ineffective.
the aforementioned ex ample shows that a function f may become hot before any other functions that race with f. in this case sampling those functions that race with f is useless.
we call this inefficiency thread local sampling because it does not consider other threads when it decides whether to sample the current thread.
the second major limitation is that sampling algorithms remain the same for all the executions of a program.
this is ineffective because in in house testing a program is usually executed repeatedly against a large set of test cases.
for a multithreaded program a develop may even run it multiple times under a single test case.
the net effect of current sampling strategy is that those functions that are cold in individual execution but hot in accumulative executions are repeatedly sampled.
we call this inefficiency execution local sampling as it does not consider previous executions when decides whether to sample the current execution.
in this paper we propose atexrace a new d ynamic race detection tool based on across thread and across execution sampling .
it is designed to sample memory access pairs from different threads and is also aware of executions.
however several challenges must be resolved to make it practical .
firstly tracking memory accesses across threads incurs much larger overhead than tracking thread local data only e.g.
higher cache miss rate .
secondly even if a pair of memory accesses is observed to be race free before it does not mean that the pair will not race later.
this is because while instruction s are static the memory addresses they access are dynamic.
lastly atexrace avoids sampling previously observed memory pairs which requires additional recording.
with increa sing number of executions the re corded data set may grow rapidly which further slow s down the samp ling processes e.g.
the need of more time to search memory access pairs .
we have implemented atexrace fasttrack and literace on top of pin and evalua ted them on five programs on parsec benchmark suite and a real world program mysql.
in the experiment s we run each parsec program for times and run mysql under different test cases.
the experimental results surprisingly show that atexrace detects more races in parsec benchmarks than fasttrack does!
as for mysql atexrace detects almost the same number of dynamic races as that by fasttrack .
literace as predicted detects significantly fewer races than both fasttrack and atexrace .
if we do not consider the same races that are detected again atexrace detects more unique races than fasttrack and literace .
in terms of efficiency literace and atexrace reduce almost the same percentage of overhead on top of fasttrack .
this makes atexrace a replacement of fasttrack and literace .
the main contribution s of this paper are we present a novel sampling technique called atexrace toward race detection.
unlike existing sampling techniques that are thread local and execution local atexrace is across thread and across execution .
to make atexrace practical we have designed optimization heuristics that include utilizing thread local storage to avoid competing accesses to shared sampling data set exploiting burst sampling strategy to enhance race coverage and adopting n frequent function pairs to improve map lookup efficiency .
we have implemented atexrace and conducted a set of experiments on benchmarks includ ing a real world large scale program mysq l. our experiments confirm that atexrace detects as many races as fasttrack at a cost as low as literace.
the tool is at .
.
background .
multithreaded programs a multithreaded program consists of a set of threads a set o f locks or lock synchronization objects and a set of memory locations or locations for short .
each thread t has a unique thread identifier tid denoted as t.tid.
during an execution of a multithreaded program p each thread t performs a seque nce of events e1 e2 ... ek .
an event ca n be one of the following types acq m or rel m synchronization events to acquire or release a lock m. other synchronization events can be similarly defined .
read x or write x memory access events to read from or write to a memory location x and call f or return f control events to execute events in function f or return to execute the events from the previous function f. .
.
.
.thread t for ... if ... f1 else f2 .
.
.
.thread t for ... if ... f3 else f4 figure .
a code sketch with two threads and four function calls .
316atexrace across thread and execution samp ling for in house race detection esec fse september paderborn germany .
data races data races can be defined according to either the lockset discipline or the happens before relation .
in this paper we adopt the later one as it is relatively precise .
however our sampling strategy is independent from concrete definition s. the happens before relation denoted as hbr for short is defined by the three rules if two events and are performed by the same thread and appear s before then if is a lock release event and is a lock acquire event on the same lock and appear s before then and if and then .
given two memory access e1 and e2 that access the same memory location and one of them is a write events a race occurs if neither e1 e2 nor e2 e1.
.
motivations .
motivating example figure shows a multithreaded program p that extends the code sketch given in figu re .
the program consists of two threads t1 and t2 operating on two shared variables x and y. there are two locks m and n protecting accesses to shared variables x and or y. given two parameters a b thread t1 consecutively call s function f1 for a times and then calls function f2 for a times within a loop lines and thread t2 performs similar calls to functions f3 and f4 each for b times lines .
the four functions increase the values of x and y based on the passed parameters .
due to the pa rallel execution of the two threads in figure any pair of functions between threads t1 and t2 can potentially be executed simultaneously.
the four pairs of functions that can be executed at the sam e time are f1 f3 f1 f4 f2 f3 and f2 f4 .
for the pairs f1 f4 and f2 f3 as the variable y is protected by different locks i.e.
lock m in function f1 and f3 but lock n in function f2 and f4 races may occur.
for example if line s and or lines and are executed at the same time the program may produce incorrect results due to the race on variable y. .
heavy overhead of dynamic data race detection dynamic race detectors usually incur large overhead due to heavy instrumentation and race checking per memory access.
this is unavoidable because they have to track whether the pair of a current access and a previous access violates any hbr.
we use the memory access x i in figure line to illustrate the overhead.
for each access to the location x one function call like onread x or onwrite x is inserted see figure .
within these call s there are two types of operations that cost time .
the first type is from fetching shadow data or meta data for each thread and each memory location.
for each memory location d ynamic ones track all accesses to it and store the information at shadow memory e.g.
shadowmemory x in figure .
similarly shadow threads e.g.
shadowthread t in figure are used for each thread .
therefore a memory access in the original program is accompanied by several additional memory acc esses to get the shadow data for a memory location and a thread e.g.
sx and st for memory location x and thread t respectively .
for the shadow threads many instrumentation framework s provide fast access interface e.g.
thread local storage in pin and thread execution blocks in windows .
however to the best of our knowledge no fast access to shadow memory is supported.
the latter is much difficult in practice.
for jav a program the shadow memory could be allocated together with the memory allocation in the original program .
however for c c programs this becomes difficult.
the second type is from race checking .
after fetching shadow data the values from two shadow data i.e.
from the memory location and from the current thread are checked to detect any hbr violation.
this process also involves additional memory accesses especially the write operations to maintain the access infor mation i.e.
to update sx in figure .
note that fasttrack optimizes the process on race detection but it still requires maintenance read and write on shadow data.
.
limitations of existing sampling approaches although dynamic approaches incur heavy overhead they are usually precise for data race detection.
therefore sampling approaches have been proposed to reduce the runtime overhead by track ing a subset of events and to detect races among them.
existing s ampling approaches include deployed sampling and in house sampling .
the former approaches are deployed at the users sites a fter a software is released.
such approaches are based on the crowd source testing if there are many users races escaped during in house testing may be detected by sampling a tiny portion of an execution by each user .
hence deployed sampling require s extremely low run time instrumentation x i tmp x onread x tmp i x tmp onwrite x a dynamic data race detection onread x or onwrite x sx shadowmem ory x st shadowthread t t is the current thread.
if any previous and the current access to x violates any hbr from sx and st then report the violation as a data race.
end if update sx from st .
b figure .
an illustration on the instrumentation and race detection for each memory access.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.thread t for i 1to a if i a f1 i else f2 i function f1 i acq m x i y i rel m function f2 i acq n y i rel n .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.thread t for j 1to b if j b f3 j else f4 j function f3 j acq m x j y j rel m function f4 j acq n y j rel n shared variables intx y lock m n input a b figure .
a program with races on variable y between line and line and between line and line .
317esec fse september paderborn germany y. guo y. cai and z. yang overhead e.g.
.
the lat ter attempts to reduce runtime overhead during in house testing phase .
the representative tool is literace .
as our approach falls into this category we discuss literace in detail in the rest of this subsection.
litera ce is based on the cold region hypothesis races are likely to occur whe n a thread is executing a cold region i.e.
the program portion not frequently executed .
literace tries to avoid tracking those frequently executed functions i.e.
hot functions .
initially it sets up a thread local sampling rate of for each function.
t his sampling rate is then gradually reduced whenever a function is called by the corresponding thr ead until the rate reaches a low bound e.g.
.
.
for example in figure literace initially checks all events from function f1.
after the function is executed once the thread local sampling rate of function f1 by thread t1 is reduced.
if thread t2 calls function f3 the sampling rate of function f3 by thread t2 is also reduced in the same way.
literace reduce s runtime overhead at the expense of its race detection capability .
for example in an evaluation it only detected about of freque nt data races and about of rare data races of continuously monitoring tools such as fasttrack .
this is also verified by other works .
we explain this limitation of literace via our running example in figure .
figure gives four execution cases that illustrate how the functions in the two threads interleave.
in each case a column shows the execution of a thread in term of function calls .
the difference between the four cases is at how the last call to function f1 and the first call to function f2 by thread t1 interleaves with the last call to function f3 and the first ca ll to function f4 by thread t2.
recall that locks m and n protect the accesses to y in functions f1 and f3 and in functions f2 and f4 respectively .
because two different locks are used a race on variable y occurs when either functions f1 and f4 execute in parallel or functions f2 and f3 execute in parallel.
no data race occurs i n either case a or case b because neither pair of functions may execute in parallel.
that is we can infer that accesses in function f1 happen before accesses in function f4 by following lock acquisition order i.e.
the solid arrow s and the program order within each thread i.e.
the dashed arrow s .
the same reasoning also applies on the functions f3 and f2.
however for case c there is no strict order between the accesse s in functions f1 and f4 hence a hb detector may detect the race on y from the two functions.
due to same reason for case d the race on y from functions f3 and f4 may also be detected.
when literace is applied to the four cases in figure a function is not tracked after it has been called by the same thread for certain number of times.
therefore function f1 executed by thread t1 and f3 executed by thread t2 are no longer tracked if they become hot function s. in case c even when function f1 and function f4 execute in parallel literace may miss the race.
this is because literace only tracks the cold function f4 without tracking function f1.
similarly i n case d literace may also miss the race.
we bel ieve t he main reason that literace frequently fails to detect races as observ ed previously is that its sampling across threads is not coordinated.
since a data race requires two conflict memory access es from two threads sampling one memory access from one threa d but not the other is useless.
this is illustrated by cases c and d above.
consider an extreme case where all races involve a function .
if this particular function is considered hot after being visited several times all future samplings are in vein.
besides the issue of thread local sampl ing literace also suffers from execution local sampling.
when testing a multithreaded program by running it repeatedly against a large number of test cases the same thread interleaving with minor variations tend to be exercised since thread schedulers generally switch among threads at the same program locations.
in addition although the whole program execution may witness variants from one run to another partial execution may exhibit similar behaviour.
for example even all the four cases in figure are executed in different runs the initial interleaving of two threads are similar.
that is functions f1 and f3 interleave until fu nction s f2 or f4 is called.
we highlight these function calls in grey background for illustration purpose.
as literace is unware of execution similarities it adopts the same sampling strategy across different executions.
the net effect of strategy is that those functions that are cold in individual execution but hot in accumulative executions are repeatedly sampled.
this defeats the principle of sampling that the real cold cases should be tracked.
the two main limitations of current sampling techniques motivate our work in this paper.
.
our approach .
goal and challenges in this section we present our approach to fix the two limitations of current sampling techniques .
in order to address thread local sampling our insight is that whether to sample a memory access event should also depend on the execution of other threads and those already observed executions .
that is even if a memory address has been accessed by a thread many times we may still need to sample it if a second thread access the memory func fy thread ty func fz thread tzfunc fx thread tx func pairs fx fy fy fz samplerace detectorsaved sample info figure .
the overview of atexrace framework .
case a case b case c case d t t t t t t t t f1 ... f1 f2 ... f2 f3 ... f3 f4 ... f4 f1 ... f1 f2 ... f2 f3 ... f3 f4 ... f4 f1 ... f1 f2 ... f2 f3 ... f3 f4 ... f4 f1 ... f1 f2 ... f2 f3 ... f3 f4 ... f4 no race.
no race.
race f1 f4 may be missed byliterace .race f2 f3 may be missed byliterace .similar executions lock order program order legend figure .
three executions scenarios of the program in figure and the similarity of different executions .
318atexrace across thread and execution samp ling for in house race detection esec fse september paderborn germany addres s for the first time.
as for execution local sampling our idea is to keep and store sampling information from previous runs.
except the first execution that starts with a cold run the subsequent executions load sampling infor mation of accumulated prior e xecutions.
although such ap proach incurs overhead we blieve less sampling with optimization heuristics can lead to net benefit.
the new sampling approach atexrace also works at function levels like literace .
but u nlike literace atexrace mainly samples accesses inside a pair of functions whose simultaneous executions are not observed before including previous executions .
unfortunately a basic implementation of the idea is not very scalable.
firstly tracking executions across threads usually incur larger overhead than thread local tracking.
secondly even two functions are observed to have executed in parallel before data races may still occur within them.
thirdly as atexrace perform s sampling across different execution s instead of within a single execution it must effectively record function interleaving information to be used in the subsequent executions.
.
basic atexrace algorithm the overview of atexrace is shown in figure .
during execution.
when functio n fy in thread ty is being executed atexrace collects all the f unctions e.g.
fx and fz that are being executed by other threads.
by so atexrace forms pairs of functions that are being executed simultaneously e.g.
fx fy .
it then makes a samp ling dec ision according to whether a pair of functions have been executed in parallel before.
if so neither function is sample otherwise both are sampled.
if a function is sampled all its events are passed to a race detector.
at the end of an execution all function pairs are saved and will be used in the next execution.
note in order not to report false positives all synchronizations are fully sampled.
this is the same as literace .
algorithm gives the basic atexrace algorithm that takes a program p and a set of function pairs fpair that have been observed in the previous executions.
the first three lines initialize two necessary runtime data structures a map f that maintains the functions being executed by each thread and a map s that indicates w hether memory accesses from a thread should be sampled.
both f and s are empty initially.
the function oncallfunc lines is the core of our sampling .
whenever a function f is to be executed i.e.
at the entrance of function f by a thread t for every other thread t in program p atexrace check s whether the pair f f t already exists in fpairs .
if not s is updated to map both threads t and t to true otherwise s maps t to false .
a true value of s t mandate s sampling of the current memory ac cess in thread t and a false value does the opposite.
next atexrace executes events in function f line and samples its memory accesses i.e.
function onmemoryaccesses if s t is true.
at the end of the call to function f atexrace merges fpairs and the observed function pair s f f t which indicate s that the function f and another function f t in thread t have been executed simultaneously .
in practice two functions from different threads are usually called at different time.
therefore it i s the case that a function f is initially not sampled but later it should be sampled as a different thread t calls a function f f t and the pair f f t is never observed before.
this is considered by atexrace .
we can see from lines and th at at the call entrance to function f thread t also performs an iteration over other threads at line .
at the iteration on thread t it cannot find the pair in fpair s. then it maps both threads t and t to be true value in structure s. so the function f executed by thread t has to be sampled.
.
limitations of basic atexrace the basic sampling algorithm of atexrace suffers from the two limitation s given two function f1 and f2 even if their parallel execution has been observed and tracked thus beco me hot races betw een them may still not detected and significant overhead resulted from across thread and execution sampling.
the first limitation is the issue of race coverage .
a function usually contains multiple basic blocks bbls .
an execution of a function does not mean all its bbls are executed.
for example figure shows two functions f5 and f6 that contain two races on variables x lines and and y lines and .
there are four bbls b11 b12 b21 and b22 we omit other bbls in the if statement for simplicity .
since the two threads in the example execute f5 and f6 respectively only b11 and b22 are executed.
hence the race on variable x lines and is detected while the race on variable y lines and is not .
if the pair f5 f6 is considered hot after this execution the race on y can never be detected by the basic atexrace .
one approach to address this issue is to degrade the sampling level from functions to bbls and then apply either literace or the part of our atexrace .
however this bring heavy runtime overhead and may even incur more overhead than a full detector such as fasttrack .
this is because compared to a function a bbl usually contains much fewer instruc tions.
as a result the sampling overhead in time per bbl may already larger than the race detection overhead without sampling .
because sampling algorithm is not extremely light weight it is not worthy to perform sampling at bbl level .
algorithm basic atexrace .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
input p a multithreaded program.
input fpairs a set containing functions.
let f be an empty map from a thread to a function let s be a map from a thread to a boolean value.
for each thread t p f t s t true end for function oncallfunc thread t func f let f t f and st false st is a temp orary variable that keeps s t for each thread t p t t do pair f f t if pair fpairs then st true s t true end if end for s t st execute f for each thread t p t t do fpairs fpairs f f t end for end function function onmemoryaccess thread t event e if s t true then call data race detector end if end function save fpairs 319esec fse september paderborn germany y. guo y. cai and z. yang on the other han d for c c programs even an instruction contains one or more memory accesses it is possible that each execution of the instruction may accesses different memory location.
for example considering the following two lines of code .
object obj getobj ... .
obj val we can observe that within the same and repeated executions of the two lines if the point er obj points to different objects it accesses different memory locations at line .
therefore for sampled memory accesses it is still necessa ry to track them.
the second limitation is the sampling overhead of atexrace itself.
a sampling tool should sample as fewer memory accesses as possible to reduce the overhead.
at the same time it should also try to incur less overhead from its sampling s trategy.
literace adopts thread local sampling and requires two thread local counters per function .
this can be efficiently implemented .
for atexrace there are expansive map queries i.e.
fpairs on each function call lines .
these operations bring heavy slowdown for two reasons.
firstly with the increasing number of function calls by multiple threads the size of fpair s also increases resulting in a large data set .
for example in our experiment after execu tions on mysql there are nearly function pairs .
a query over such a large map is time consuming .
secondly the map fpairs is accessed by multiple threads.
this requires synchronizations among different threads when they operate on the map.
such syn chronization incurs further slowdown.
besides when different threads access the map fpairs the cache miss rate will be higher because once a thread updates the map all other threads that query the map must wait until their local cache s are updated.
this again leads to additional time consumption.
all these reasons bring challenges to reduce the overhead of our sampling algorithm atexrace itself.
.
optimizations algorithm is an enhancement to the basic atexrace algorithm that addresses the two kinds of limitations .
to address the issue of race coverage atexrace further samples those sampled function pairs in order to increase their coverage on data race detection.
this corresponds to lines in algorithm .
for this part atexrace accept s a sampli ng rate i.e.
the input r to algorithm and samples the function pair according the rate.
note that atexrace does not perform a simple sampling that generate s a random number and compare s the random number with the given sampling rate .
instead atexra ce adopts burst sampling strategy .
it samples the first n consecutive calls out of all m calls to a function such that the rate n m equals to the given sampling rate r. for example if the sampling rate is it samples the first calls and discards the next calls to the same function resulting the sampling rate of .
of course to implement this functionality a counter mapped from each function pair is required.
hence the original set of function pai rs is changed into a map see the fourth input and the lines and in algorithm .
to overcome the second kind of limitations we firstly propose to use thread local maps.
in algorithm we use the symbol fp to denote the thread local maps of fu nction pairs.
that is we allocate one map structure for each thread and w hen atexrace .
.
.
.
.
.
.
.
.
.
.
.
.thread t f5 function f5 i if i acq m x rel m else acq n x y rel n .
.
.
.
.
.
.
.
.
.
.
.
.thread t f6 function f6 j if j acq m y rel m else acq n y x rel n bbl b11 bbl b12bbl b21 bbl b22 figure .
a program consisting of two threads with two data races on variables x lines and and y lines and .
algorithm complete atexrace .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
input p a multithreaded program.
input r a sampling rate .
input n a number determine n frequent value input fpairs a map from functions pai rs to counters of the last n executions .
initialization let f be an empty map from a thread to a function let s be a map from a thread to a boolean value.
let fp be a map from a thread to a copy of fpair s. thread local map s for each thread t p do f t s t true fp t fpair s deep clone end for runtime sampling function onenterfunc thread t func f let f t f and st false st is a temp variable that keeps s t for each thread t p t t do pair f f t if pair fp t then st true s t true else fp t fp t pair counter fp pair if counter pair fp t satisfies r then st true s t true else st false end if end if end for s t st execute f for each thread t p t t do fp t fp t pair end for end function function onmemoryaccess thread t event e if s t true then call data race detector end if end function the end of an execution let fpairs be an empty map.
for each thread t p do fpairs fpairs f t end for save fpairs 320atexrace across thread and execution samp ling for in house race detection esec fse september paderborn germany starts an execution it duplicates the given map data line .
during an execution atexrace only checks whether the pair exists in the map fp of the current thread lines and .
if a pair already exists in a thread local map its counter is incremented by at line .
at the end of an execution atexrace merges all thread local maps and saves the merged map lines .
secondly we do not record all function pairs observed in previously executions.
instead we only keep the recently frequently observed function pairs .
given an execution e and a number n n we define a function pair fx fy to be n frequen t with respect to execution e if fx fy is obse rved in current and all the n previous executions.
specially when the value of n is the 1frequent function pairs are those observed in the current execution.
by keep ing only the n frequent function pairs the recorded function pairs are those frequ ently executed .
this is reasonable not to sample these frequent function pairs to reduce sampling overhead.
hence for each execution the number of function pairs taken as input is small and does not increase with increasing number of executions.
the thir d and the fourth inputs to algorithm reflects this design where n determines the function pairs in fpairs .
by adopt ing thread local maps and recording only n frequent function pairs the only side effect is that atexrace may sample function pairs that have been sampled in the same execution due to the content difference of different threads within the same execution.
this may incur unnecessary overhead.
however it produces no bad result on the data race coverage as sampling the same functions more than one time also increases the probability to detect those missed data races see the first kind of limitations in section .
.
.
atexrace on example program in this section we use the running example in figure to illustrate how atexrace sampling its execution s in figure .
initially both functions f1 and f3 are sampled as the input fpairs are empty.
such sampling continues until in each thread the recorded functions pairs contain f1 f3 .
probably1 after a certain number of calls to both functions atexrace stops continuous sampling of f1 and f3 because f1 f3 is hot.
of course in our algorithm functions in a hot pair still have chances to be sampled due to our burst sampling str ategy.
next suppose thread t1 calls f2 for the first time while t2 is executing f3.
because pair f2 f3 is cold atexrace restarts to sample function f2.
of course f3 is sampled as well.
similarly atexrace restarts to sample function f1 if functions f1 and f4 are executed at the same time.
on the other hand if it is f2 and f4 that are executed at the same time neither f1 nor f3 is sampled.
hence for c ases c and d atexrace has a larger probability to detect the two races that are probably miss ed by literace .
however for c ases a and b although there is no race in this section we frequently used the word probably because the execution of multiple threads is undetermined.
e.g.
we say that if functions f1 and f3 are called mul tiple times as shown in figure most of their executions are simultaneous .
but in theory it is possible that all executions of function f1 are executed before any execution of function f3.
or given two threads that can be executed in parallel there are executions where they can be sequentially executed.
atexrace still samples the first calls to function f3 and f4.
in the subsequent execution after functions f3 and f4 are called for several times atexrace stops the continuous samp ling of the two functions.
after one execution of the example program atexrace records the observed function pairs probably the four pairs f1 f3 f1 f4 f2 f3 and f2 f4 .
if the program is executed again atexrace may not continuously sample the function pairs already collected.
hence the total overhead to detect data race can be reduced not only within the same execution but also across different executions of the same program.
.
discussion on atexrace we aim to reduce race detection overhe ad without sacrificing race detection capability when there are many test cases .
atexrace does not target a single execution as one of our innovations is to record the recently observed function pairs and skips their sampling in subsequent executions .
henc e on a small number of execution s it may initially incur larger overhead than that by fasttrack and literace see figure a and figure in our experiment .
atexrace is more suitable for programs e.g.
industrial programs that are tested against a large number of test cases.
of course as a dynamic sampling approach it also reports false negatives.
figure shows the ideal scenario of atexrace.
initially atexrace may incur higher overhead than literace or even fasttrack .
however with increasing number of executions atexrace gradually inc urs lower overhead .
.
experiments this section presents the evaluation on atexrace.
we compared it with literace and fasttrack .
because fasttrack is one of the fastest and most widely used tools in this category.
it fully detects data races and can be considered as a sampling tool with a rate of .
and literace is the state of the art in house sampling to ol.
both are representative and well known .
.
implementation and benchmarks implementation .
we have implemented atexrace fasttrack and literace on top of pintool a widely used binary instr umentation framework .
our implementation targets multithreaded programs with pthread library on linux system.
note that pintool runs like a virtual machine and incurs large overhead.
a better implementation can be done as the original literace implementation i.e.
to integrate sampling tools into the program under testing at compilation time .
function encoding .
on linux platform pintool modes each program as image that contains sec tions and each section concumulative number of executed test casesoverhead fasttrack literace figure .
ideal overhead changes with increasing executions .
321esec fse september paderborn germany y. guo y. cai and z. yang sists of multiple routines or functions .
we use a bit integer to encode a routine.
the first bits are used as the image identifier and the remaining bits are used as routines identifier per image.
this encoding allows at most images and routines per image which is enough in practice .
benchmarks .
we choose the parsec benchmark suite .
to evaluate the race detectors .
the suite consists of benchmarks.
after eliminating the b enchmarks that are not multithreaded or cannot be compiled under the pin environment we obtain five benchmarks blackscholes bodytrack canneal freqmine and streamcluster .
in our experiments we run each benchmark from parsec for times to collect t heir results.
table gives the source code size sloc of the five benchmarks.
it can be observed that the lines of code range from .3k to 16k.
to further evaluate the performance of atexrace we select the mysq l database server v6.
.
a widely used real world program.
the version we use mysql .
.
alpha has lines of code.
among the test cases that comes with its distribution of them can be successfully executed in the pin environment .
we run all the test cases in our experiment.
.
experimental setup our experiment s were performed on a workstation thinkpad w540 with an i7 4710mq cpu four cores 16g memory and 250g ssd.
the workstation was installe d with ubuntu .
x86 system.
for atexrace we set its sampling rate and the value n determining n frequent function pairs to be and respectively.
for literace we adopt the fixed thread local sampling configuration as defined in previous work .
.
result analysis on parsec benchmark suite .
.
overall results .
for all techniques table gives the time of the executions spent by pin and the three tools of the benchmarks the overhead of the race detectors compared to the time consumed by pin framework and the number of unique races i.e.
the number of variables in the source code detected by each tool.
as expected both literace and atexrace are much faster than fasttrack by reducing about overhead based on pin .
it can also be observed that liter ace and atexrace incurred almost the same average overhead.
on race detection capability both literace and atexrace outperform fasttrack .
at first glance the results are surprising.
however it is known that sampling perturb s thread scheduling so a race detector with sampling runs different executions with the one without sampling even under the same test case.
such phenomenon is previously observed .
table shows that literace detects more unique races than fasttrack all of the additional races are from the single benchmark freqmine .
atexrace detects more unique races than literace .
the above result s indicate that atexrace detect the most number of races at a cost almos t the same as literace .
however among the five benchmarks literace is better in only two of them.
on the other hand the three benchmarks seem to have very few races or even no races so none of the race detectors can discover more races.
when there are more races the benefit of atexrace seems obvious.
since these relatively small benchmarks do not give a doubtless evaluation of atexrace we further evaluate our approach on a large real world database server mysql.
but before we present our empirical stu dy on mysql table .
the statistics of parsec benchmark and its overall result s. benchmarks size sloc time seconds overhead of unique races pin ft lr ar ft lr ar ft lr ar blackscholes .
.
.
.
.
.
.
bodytrack .
.
.
.
.
.
.
canneal .
.
.
.
.
.
.
freqmine .
.
.
.
.
.
.
streamcluster .
.
.
.
.
.
.
avg.
.
.
.
sum figure .
the trend of overhead with increasing number of executions .
96fasttrack literace atexrace 96fasttrack literace atexrace 96fasttrack literace atexrace40 96fasttrack literace atexrace 96fasttrack literace atexrace a blackscholes b bodytrack c canneal d freqmine e streamcluster 322atexrace across thread and execution samp ling for in house race detection esec fse september paderborn germany we use parsec to illustrate the advantage of cross execution sampling of atexrace .
.
.
overhead trend across executions .
one of key features of atexrace is its cross execution sampling which may result in lower overhead with increasing num ber of executions.
in figure we show how the overhead changes with increasing number of executions for three techniques on the five benchmarks.
in each subfigure the x axis shows the number of executions and the y axis shows the overhead incurred by three techniques on each execution.
the cumulative overhead on the i th execution is calculated by the following formula overhead i ttool i tprog i tprog i eq.
where ttool i represents the execution time under a tool on the i th execution and tprog i represents the native program ex ecution time under pin .
from figure we see that overall fasttrack and literace incur almost the same overhead across executions i.e.
nearly a horizontal line .
except the first benchmark literace s overhead is much lower than that by fasttrack which is expected due to the sampling of literace .
however on blackscholes literace incurs larger overhead than that by fasttrack .
we have performed several additional experiment s and confirmed the results .
for atexrace overall its overhead decreases with i ncreasing number of executions although the trend is less obvious in steamcluster .
this is consistent with our theoretical analysis in section .
.
it can also be observed that with increasing n umber of executions atexrace s performance becomes the best on three benchmarks i.e.
the subfigure a b and d .
however the overhead reduction reaches a plateau after a certain number of executions .
this is not surprising because according to se ction .
.
the number of recorded function pairs barely increases .
.
.
number of function pairs .
as a parsec benchmark is repeatedly executed under the same input there is no obvious increase in the number of function pairs with more executions.
after executions the number of functions pairs of the five benchmarks are and .
if we store frequent pairs only the number of function pairs after executions are and .
.
result analysis on mysql mysql has one mil lion lines of code .
we run it against test cases in the default order of the test script mysql test run .
.
.
number of detected races .
figure a gives the number of unique races that are detected by fasttrack literace and atexrace after executions of mysql .
not surprisingly compared with literace atexrace detect s more unique races.
what we have not expected is that atexrace detects even more unique races than fasttrack .
of course as explained in section .
.
this is possible because sampling perturbs thread scheduling.
however we would like to have a clearer picture of race detecting capability.
thus we collect data on all the races not just unique races that are detected by the three tools.
although in theory unique races are more interesting in practice the number of total races is helpful to de bugging because they can illustrate different scenarios how a race occurs.
detecting the same traces multiple times is also a good indicator of a race detector s capability.
the results of total races are illustrated in figure b .
the number of total races is significantly more than the number of unique races.
it can be observe d that fasttrack detects the most races but atexrace is a very close second .
literace on the other hand detects significantly fewer number of races than the other two.
.
.
overhead.
figure depicts how the overhead y axis change s across execution s x axis .
unlike benchmarks from parsec where all repeated executions are conducted again st the same test cases each of the mysql executions is conducted against a different test case .
therefore on mysql fasttrack as well and literace and atexrace may incur different overhead on different executions.
the formula to calculate the cumul ative overhead of the first i executions is the same as that on parsec i.e.
eq.
.
the results shown in figure are as expected where fasttrack incurs the largest overhead over native execution on pin and literace incurs the smallest .
although atexrace s overhead is larger than literace s the gap is gradually shrinking .
at the end of all executions atexrace incurs almost the same overhead as that by literace .
given more test cases atexrace may have a c hance to incur less overhead than literace .
considering both figure and figure our experiments confirm that atexrace achieves a sweet spot between literace and fastt rack by detecting almost the same number of races as fasttrack at a cost almost the same as literace .
.
.
number of function pairs .
atexrace does not record all observed function pairs but only keeps recently observed ones to avoid potentially unlimite d increase on the number of function pairs.
figure shows a comparison on the cumulative number of function pairs y axis with the increasing number of executions up to .
the two lines represent the data by recording all observed ones all pairs and recording recently observed a unique races.
b dynamic races figure .
the number of races detected by three .
fasttrack literace atexrace 221fasttrack literace atexrace figure .
the cumulative overhead of three techniques with increasing executions .
221fasttrack literace atexrace 323esec fse september paderborn germany y. guo y. cai and z. yang ones frequent pairs respectively .
we observe that with increasing number of executions the number of all function pairs also increases .
after executions the number of observed function pairs is nearly .
if we keep all these function pairs a large overhead on querying is inevitable which may eventually offset the benefit of sampling.
this is the reason we only rely on the recently observed function pairs.
from figure we see that this strategy is effective as over all the executions the numbers of the frequent function pairs are almost always below with only six exceptions .
and on out of executions there are less than function pairs.
on average there are function pairs on each execution.
our experiments are all performed with frequent function pairs and the data confirm its effectiveness.
.
related work data races are extremely difficult to be found and reproduced.
both static techniques and dynamic techniques aim to detect data races .
static ones can analyse the source code of a whole program however due to lack of runtime information static approaches can easily report many false positives .
dynamic ones analyse concrete executions to detect data races according to some rules e.g.
the lockset discipline and the happens before relation .
although dynamic techniques are relatively precise they incur heavy overhead.
we have heavily discussed sampling appro aches on data race detection .
crsampler also targets on sampling but its main purpose is at user site.
it is based on hardware breakpoints and clock races to detect data races .
datacollider purely relies on hardware breakpoints to detect those occurred data race by suspending threads.
atexrace aims at in house sampling .
to explore all possible execution s is one direction to find concurrency bugs e.g.
m odel checking .
however it is usually impossible to explore all the interleaving although they may achieve certain coverage .
practically enumerating each schedule is not practical for large scale real world programs even with reduction techniques .
therefore to explore a small portion of interleaving space that are error prone is also one direction.
chess sets a heuristic bound on the number of pre emption s to explore the schedules.
also although systematic approaches avoid executing previously explored schedules they usually incur large overhead s and fail to scale up to handle long running programs.
for example maple is a coverage driven tool to mine thread interleaving so as to expose unknown concurrency bugs.
pct randomly schedules a program to expose concur rency bugs which also requires large number of executions.
however it is diffi cult to apply these techniques to large scale program s such as mysql .
other works aim to firstly predict a set of potential data races and then to verify them.
rvpredict achieve s a strictly higher coverage than hbr based detectors .
it firstly predicts a set of potential races and then relies on a number of production executions to check against each predicted race.
racageddon aims to solve races that could be predicted in one execution but require different inputs.
it still needs a larger number of execution s to check against each predicted race .
both rvpredict and racageddon have to solve scheduling constraints for each predicted race which may fail.
racemob statically detects data race warnings and distribut es them to a large number of users to validate real races.
in such a run the schedules are guided by the set of data race warnings to trigger real data races.
this kind of approach is able to confirm real ra ces but cannot eliminate false positives.
besides it may miss real races if such races are not predicted in the static prediction phase.
drfinder tries to predict the happens before relation to further expose races hid den by the happens before relation.
it dynamically predicts and tries to reverse happens before relations from observed executions.
however it s active scheduling is also heavy e.g.
about for java programs .
cci proposes cross thread sampling strategies to find causes of concurrency bugs based on ran domized sampling .
unlike race sampling techniques e.g.
crsampler datacollider pacer and literace cci focuses on failure diagnosi s. however cci may cause heavy over head e.g.
up to although it targets on lightweight sampling .
carisma improves pacer by further sampling memory locations allocated at the same program locati on for java.
valor infers data races by detecting region confilt which has good performance compared with fasttrack .
bedides multithreaded programs data race may also exist in other kinds of pgorams such ev en driven programs such as android application s concurrent librar y invocations and modified program codes .
atexrace could also be adapted to detect these races.
we leave it as future work.
.
conclusion we have proposed a new cross thread and cross execution sampling approach to achieve both high race detection rate and high efficiency.
by ad opting several novel designs our prototype atexrace shows its potential to replace fasttrack and literace .
this is confirmed by the experiment s with benchmarks obtained from both parsec benchmark suite and a real world large scale mysql database.
acknowl edgement we thank anonymous reviewers for their invaluable comments and suggestions on improving this work.
this work is supported in part by national natural science foundation of china nsfc and national program of china 2014cb340702 the youth innovation promotion association of the chinese academy of science s yicas and the national science foundation nsf dge .
figure .
the cumulative number of function pairs .
221all pairs frequent pairs 324atexrace across thread and execution samp ling for in house race detection esec fse september paderborn germany reference b. alpern c.r.
attanasio a. cocchi d. lieber s. smith t. ngo j.j. b arton s.f.
hummel j.c. sheperd and m. mergen.
implementing jalape o in java.
in proc.
oopsla .
c. bienia.
ph.d. thesis benchmarking modern multiprocessors.
princeton university january .
s. biswas m. cao m. zhang m.d.
bond and b .p.
wook.
lightweight data race detection for production runs.
in proc.
cc .
s. biswas m. zhang m. d. bond and b. lucia.
valor efficient software only region conflict exceptions.
in proc.
oopsla .
s.m.
blackburn r. garne r c. hoffmann a.m. khang k.s.
mckinley r. bentzur a. diwan d. feinberg d. frampton s .z.
guyer m. hirzel a. hosking m. jump h. lee j. eliot b. moss a. phansalkar d. stefanovi t. vandrunen d. von dincklage and b. wiedermann.
the dacapo benchmarks java benchmarking development and analysis.
in proc.
oopsla .
e. bodd en and k. havelund.
racer effective race detection using aspectj.
in proc.
issta .
m.d.
bond k. e. coons and k. s. mckinley.
pacer proportional detection of data races.
in proc.
pldi .
a. bron e. farchi y. magid y. nir an d s. ur.
applications of synchronization coverage.
in proc.
ppopp .
s. burckhardt p. kothari m. musuvathi and s. nagarakatte.
a randomized scheduler with probabilistic guarantees of finding bugs.
in proc.
asplos .
y. cai and l. cao.
effective and precise dynamic detection of hidden races for java programs.
in proc.
esec fse .
y. cai and w.k.
chan.
loft redundant synchronization event removal for data race detection.
in proc.
issre .
y. cai j. zhan g l. cao and j. liu.
a deployable sampling strategy for data race detection.
in proc.
fse .
d. dimitro v. raychev m. vechev and e. koskinen.
commutativity race detection.
in proc.
pldi .
j. erickson m. musuvathi s. burc khardt and k. olynyk.
effective data race detection for the kernel.
in proc.
osdi .
m. eslamimehr and j. palsberg.
race directed scheduling of concurrent programs.
in proc.
ppopp .
c. flanagan and s. n. freund.
fasttrack efficient and precise dynamic race detection.
in proc.
pldi .
c. flanagan and s. n. freund.
the roadrunner dynamic analysis framework for concurrent programs.
in proc.
paste .
c. flanagan and p. godefroid.
dynamic partial order reduction for model checking software.
in proc.
popl .
s. hong j. ahn s. park m. kim and m.j. harrold.
testing concurrent programs to achieve high synchronization coverage.
in proc.
issta .
s. hong y. park and m. kim.
detecting concurre ncy errors in client side java script web applications.
in proc.
icst .
c. hsiao y. yu s. narayanasamy z. kong c.l.
pereira g.a.
pokam p.m. chen and j. flinn.
race detection for event driven mobile applications.
in proc.
pldi .
j. huang p.o.
meredith and g. rosu.
maximal sound predictive race detection with control flow abstraction.
in proc.
pldi .
j. jackson.
nasdaq s facebook glitch came from race conditions may .
icle financial it nasdaq sfacebook glitch came from race conditions .html last visited on march .
g. jin a. thakur b. liblit and s. lu.
instrumentation and sampling strategies for cooperative concurrency bug isolation.
in proc.
oopsla .
v. kahlon y. yang s. sankaranarayanan and a. gupta.
fast and accurate static data race detection for concurrent programs.
in proc.
cav .
b. kasikci c. zamfir and g. candea.
racemob crowdsourced data race detection.
in proc.
sosp .
l. lamport.
time clocks and the ordering of events.
communications of the acm .
z. letko t. vojnar and b. k rena.
coverage metrics for saturation based and search based testing of concurrent software.
in proc.
rv .
n.g.
leveson and c. s. turner.
an investigation of the therac accidents.
computer .
s. lu s. park e. seo and y.y.
zhou learning from mistakes a comprehensive study on real world concurrency bug characteristics.
in proc.
asplos .
b. lucia and l. ceze.
cooperative empirical failure avoidance for multithreaded programs.
i n proc.
asplos .
.
c. k. luk r. cohn r. muth h. patil a. klauser g. lowney s. wallace v. j. reddi and k. hazelwood.
pin building customized program analysis tools with dynamic instrumentation.
in proc.
pldi .
p. maiya a. k anade and r. majumdar.
race detection for android applications.
in proc.
pldi .
d. marino m. musuvathi and s. narayanasamy.
literace effective sampling for lightweight data race detection.
in proc.
pldi .
m. musuvathi s. qa deer t. ball g. basler p. a. nainar and i. neamtiu.
finding and reproducing heisenbugs in concurrent programs.
in proc.
osdi .
s. nagarakatte s. burckhardt m. m.k.
martin and m. musuvathi.
multicore acceleration of priority based schedu lers for concurrency bug detection.
in proc.
pldi .
m. naik a. aiken and j. whaley.
effective static race detection for java.
in proc.
pldi .
s. narayanasamy z. wang j. tigani a. edwards and b. calder.
automatically classifying benign and harmful data races using replay analysis.
in proc.
pldi .
c.s.
park k. sen p. hargrove and c. iancu.
efficient data race detection for distributed memory parallel programs.
in proc.
sc .
k. poulsen.
software bug c ontributed to blackout.
feb. .
e. pozniansky and a. schuster.
efficient on the fly data race detection in multithreaded c programs.
in proc.
ppopp .
p. pratikakis j.s.
foster and m. hicks.
locks mith context sensitive correlation analysis for race detection.
in proc.
pldi .
a.k.
rajagopalan and j. huang.
rdit race detection from incomplete traces.
in proc.
esec fse .
s. savage m. burrows g. nelson p. sobalvarro and t. anderson.
eraser a dynamic data race detector for multithreaded programs.
acm tocs .
k. sen. race directed random testing of concurrent programs.
in proc.
pldi .
k. serebryany and t. iskhodzhanov.
threadsanitizer d ata race detection in practice.
in proc.
wbia .
y. smaragdakis j. evans c. sadowski j. yi and c. flanagan.
sound predictive race detection in polynomial time.
in proc.
popl .
f. sorrentino a. farzan and p. madhusudan.
pene lope weaving threads to expose atomicity violations.
in proc.
fse .
microsoft.
thread execution blocks.
k. vineet and c. wang.
universal causality graphs a precise happens before model for detecting bugs in concurrent programs.
in proc.
cav .
j.w.
voung r. jhala and s. lerner.
relay static race detection on millions of lines of code.
in proc.
fse .
c. wang k. hoang.
precisely deciding control state reachabilit y in concurrent traces with limited observability.
in proc.
vmcai .
c. wang m. said and a. gupta.
coverage guided systematic concurrency testing.
in proc.
icse .
x.w.
xie and j.l.
xue.
acculock accurate and efficient detectio n of data races.
in proc.
cgo .
j. yu s. narayanasamy c. pereira and g. pokam.
maple a coverage driven testing tool for multithreaded programs.
in proc.
oopsla .
y. yu t. rodeheffer and w. chen.
racetrack efficient detect ion of data race conditions via adaptive tracking.
in proc.
sosp .
t. yu w. srisa an and g. rothermel.
simrt an automated framework to support regression testing for data races.
in proc.
icse .
k. zhai b.n.
xu w.k.
chan and t.h.
tse.
carisma a context sensitive approach to race condition sample instance selection for multithreaded applications.
in proc.
issta .
w. zhang m. d. kruijf a. li s. lu and k. sankaralingam.
conair featherweight concurrency bug reco very via single threaded idempotent execution.
in proc.
asplos .
.