privacy preserving via interval covering based subclass division and manifold learning based bi directional obfuscation for effort estimation fumin qi1 xiao yuan jing1 xiaoke zhu1 fei wu1 li cheng1 1state key laboratory of software engineering school of compute r wuhan university china 2school of automation nanjing university of posts and telecommu nications china 3school of computer and information engineering henan universit y china corresponding author jingxy 2000 .com abstract when a company lacks local data in hand engineers can build an effort model for the effort estimation of a new project by util izing the training data shared by other companies.
however one of th e most important obstacles for dat a sharing is the privacy concer ns of software development organizat ions.
in software engineering most of existing privacy preserving works mainly focus on the defect prediction or debugging and testing yet the privacypreserving data sharing problem has not been well studied in effort estimation.
in this paper we aim to provide data owners with an effective approach of privatizing their data before rel ease.
we firstly design an interval covering based subclass division icsd strategy.
icsd can divide the target data into several subclasses by digging a new attribute i.e.
class label from the effort data.
and the obtained class label is beneficial to maintaining the distribution of t he target data after obfuscati on.
then we propose a manifold learning based bi directional data obfuscation mlbdo algorithm which uses two nearest neighbors which are selected respectively from the previous an d next subclasses by utilizing the manifold learning based neares t neighbor selector as the distur bances to obfuscate the target sample.
we call the entire approach as icsd mlbdo.
experimental results on seven p ublic effort datasets show that icsd mlbdo can guarantee the privacy and maintain the utility of obfuscated data.
i csd mlbdo can achieve better privacy and utility than the comp ared privacy preserving method s. ccs concepts software and its engineering e m p i r i c a l s o f t w a r e validation.
security and privacy privacy preserving protocols.
keywords effort estimation privacy pre serving locality preserving projection subclass division.
.
introduction engineers usually try to build a model for estimating predictin g a new project by seeking training samples from other companies when their own company lacks enough local data.
however except the limited publicly avail able datasets e.g.
promise it is very hard to obtain useful data from other companies.
the main reason for this phenomenon can be summarized as follows there usually exist some sensitive attributes in the data to be share d which may bring privacy disclosure for the data owners e.g.
t he leakage of commercial secret leading to that the data owners are unwilling to share their data.
therefore privacy preserving ha s been one of the most important research topics in software engineering and has attracted much attention from both academi c and industrial communities .
to avoid privacy disclosure data owners usually remove the sensitive attributes and use privacy preserving methods to obfuscate the data before publishing their dataset.
the commonl y used general privacy preserving methods include generalization and suppression based methods clustering based methods and swapping based methods .
recently a few ppds methods have been presented for software engineering .
most of these methods mainly focus on the applications suc h as defect prediction or debugging and testing.
specifically pe ters et al.
studied on the ppds for defect prediction.
claus e taneja et al.
and lo d investigated the privacy preserving problem in debugging and testing.
privacy preserving is also needed in effort estimation.
in prac tice since many indicators i.e.
att ributes contained in the effor t data are related to the properties of the product or the image of a team e.g.
function points count fp line of code loc and number of function point size data holders don t hope these attribu tes to be made public.
in addition peter s et al.
mentioned that in a personal communication barry boehm stated that he was able to publish less than cost estimation records even after years of cocomo effort .
all of these mean that the privacy threats have hindered people to share their effort data.
theref ore it s urgent to investigate how t o preserve the data privacy in effort data sharing.
.
background in order to facilitate understand ing privacy preserving in effo rt estimation and the protected attributes researched in this pape r we offer the following definitions.
us repo effort permission to make digital or hard copies of all or part of thi s work for personal or classroom use is gran ted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page .
to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
request permis sions from permission acm.org.
ase september singapore singapore copyright acm ... .
permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
copyrights for components of this work owned by others than acm must be honored.
abstracting with credit is permitted.
to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
request permissions from permissions acm.org.
ase september singapore singapore c acm.
... .
let ii nn ss y s y s y denote a data set with n samples where iisyis the thi sample of s isrepresents independent attributes and iyrepresents dependent attributes.
all the attributes in s can be classified into the following one or more categories sensitive attributes sa attributes we do not want adversaries to associate with a target.
explicit identifiers attributes that clearly identify individuals.
quasi identifiers qids attributes whose values when taken together can potentially identify an individual.
privacy threat refers to the unwanted disclosures of sa explicit identifiers and qids.
privacy threats can be categorized into t hree types sensitive attribute values disclosure identi ty disclosure or re identification and membership disclosure.
sensitive attribute occurs when a target is associated with information about their sensitive attributes.
re identification which occurs when an attacker with external information can re identify an individual from data that has been removed of personally identifiable informa tion.
membership disclosure is another privacy threat that focuses on protecting a person s mi cro data.
adversaries can identify the relationship between sample and target classes according to public data.
like in we mainly evaluate icsd mlbdo against the first privacy threat i.e.
sensitive attribute disclo sure in this paper.
the evalua tion of icsd mlbdo against the other two types of privacy threats will be our future work.
.
motivation sensitive attribute disclosure problem is one of the main obsta cles to effort data sharing.
the qid s values are principal component s for building an effort model which are usually contained in th e published data.
if the data is published without any anonymization processing the a dversaries can deduce the values of related sensitive attributes by using the qids values in the se data and obtain relative advant ages in bidding.
for example l oc is linked closely with qids in effort data and can be obtained according to the qids values with specific background knowledge and then the adversaries can get ranges of hourly productivity by dividing the loc by effort.
to the best of our knowledge the problem of sensitive attributes values disclosure in effort dat a sharing has not been well studied.
although there exist a number of general privacy preserving methods these methods cannot be directly employed to solve the privacy preserving problem in effort data sharing effectively.
specifically gene ralization and suppression based anonymization methods use generalization or suppression with some rules to replace qids values.
however the utility of the data obfuscated by these m ethods will decline when most of the values tend to be consistent .
clustering based methods use the mean center values of some attributes in a cluster to replace the value of the corresponding attribute in the target sample from the same cluster.
thus these methods will be severely influenced by the clustering parameter k. swappingbased methods replace the value of an attribute by using the other values in the value list of this attribute acco rding to certain percentage and rules.
these methods will be influenc ed by the swapping percentages and thus their performances are unstable.
in recent years a few privacy preserving works have been presented in software engineering .
however these methods cannot be utilized to t ackle the privacy preserving problem in effort data sharing.
specifically methods utilize the nearest unlike neighbors to obfuscate the target da ta and remain the utility and privacy of obfuscated data.
methods are designed to solve the sensitive attributes values disclosure problem for defect da ta and it cannot directly be u sed for effort data since the effort data is different with defect d a t a the defect data has the class labels while the effort data doe sn t have this attribute .
methods are designed for software debugging and testing.
these met hods cannot be directly used fo r effort data due to the follo wing reason there exists an assumption in debugging and testi ng data that is the data own s detailed connection knowledge betw een parts of a system yet th is assumption doesn t exist in effort data.
researches in show that the performance of the estimato r and classifier are influenced by data distribution.
if the distribution of original data can be maintained in obfuscated d ata the capability of estimator or classifier will be kept.
researc hes in indicate that the class labels of data are helpful to maintain the boundaries of subclasses after obfuscation.
this boundary information is beneficial to preserve the distribution of data after obfuscation.
however there are no class labels in t he effort data.
intuitively there may exist some relationships between samples having similar effort.
following this intuition we conducted an experiment we fir st categorize the samples wit h similar effort into the same subclass and then investigate the data distribution of each subclass.
we divide the observed samples i nto three equal subclasses according to the effort values perform principal component analysis pca on these samples to obtain the principle components and then use two major pca features of samples to illustrate the distributions.
figure illustrates the distribution of each subclass in the kitchenham and coc81 dataset .
we can see that the samples from the sam e subclass have a roughly similar di stribution.
this inspires us to design an efficient method to dig class labels from effort valu es i.e.
divide effort data into several subclasses according to the effort values .
furthermore the effort value ranges of differe nt subclasses are ordered and di fferent subclasses have clear boundary information which motivates us to use the subclass order for protecting the boundary of obfuscated data and maintaining the distribution of the data inherited from origina l data.
in this paper we aim to answer the following research question s rq in privacy preserving of effort data how to maintain the utility of the privatized data?
rq how to effectively preser ve the privacy contained in the original effort data?
second principal componentfirst principle componentkitchenham subclass effort range subclass effort range subclass effort range second principle componentfirst principle componentcoc81 subclass effort range subclass effort range subclass effort range figure .
an example of sub cl ass division for effort data .
contribution the contributions of our study are summarized as following thre e points .
we are among the first to investigate the problem of privacy preserving in software effort e stimation data sharing and prov ide an effective solution for this problem.
.
we design an interval covering based subclass division icsd strategy for effort data.
icsd digs a new attribute i.e.
clas s label for effort data which is helpful to maintain the distribution of original data after obfuscation.
in addition for other tasks i n which the data has no the class label icsd can also be applied to dig class labels for their data such that the quantitative pro blem can be transformed into qualitative problem.
.
we propose a manifold learning based bi directional obfuscation algorithm mlbdo for effort data obfuscation.
mlbdo uses two nearest neighbors which are selected from the previous subclass and the next s ubclass of target sample by usi ng manifold learning based selector as the disturbance to obfusca te the target sample.
we conduct experiments on the public datasets from promise repositories including nasa93 maxwell kitchenham kemerer coc81 china and albrecht .
the experimental results demonstrate that our approach i.e.
icsd mlbdo is an effective pr ivacy preserving approach for effort data and it can protect the privacy of original data an d maintain the utility of obfus cated data simultaneously.
.
related work .
general privacy preserving methods to solve the privacy preserving problem a number of general privacy preserving methods have been presented including generalization and suppression ba sed methods clusteringbased methods and swapping based methods etc.
generalization and suppression ba sed methods use a less specifi c and more general value which is faithful to the original value to replace the target value.
in the process of generalization pro per suppression strategies are usual ly incorporated to avoid all of the values are generalized into the maximal element e.g.
and are generalized to the same value .
for example kanonymity requires that each sample is indistinguishable wi th at least 1k other samples with respect to the qids.
however kanonymity cannot ensure the privacy if the attacker has background knowledge of the domain .
l diversity aims to solve the disadvantages in k anonymity which requires that the distribution of a sensitive attr ibute in each equivalence class has at least l well represented values.
however researches in demonstrate that l diversity is insufficient to prevent the attribute disclosure.
t closeness aims to keep the distance between the distributions of a sensitive attribute in a qids group and that of the whole table no more than a threshold t apart.
yet t closeness has the following shortcoming i t limits the relationship betwe en quasi identifiers and sensitive attributes and lacks computati onal procedures which allow to reach its goal with minimum data utility loss .
clustering based methods firstly divide the original data into several clusters where the samples within the same cluster are related and those from different clusters are unrelated and th en replace the qids value of a target sample by using the mean center qids value of its c orresponding cluster.
for instan ce aggarwal et al.
partitioned the records into several clust ers with each cluster containing at least k data points i.e.
records and then published the final cluster centers along with some cluster size and radius information.
method in uses the clustering idea to implement the k anonymity and wants to find a set of clusters i.e.
equivalence classes each of which cont ains at least k records.
the clustering based methods are sensitive to the setting of parameters k and improper selection of parameter k will influence the privacy and utility of obfuscated data.
swapping based anonymization me thods select a part of qids values to replace the other partial qids values which belong t o permutation approach that dissoci ate the relationship between a n insensitive qids and a numerical s ensitive attribute .
esti villcastro and brankovic propo sed a method which randomly swaps the class labels for priva tizing data.
in the census bure au s version records are swapped between census blocks for individuals or households that have been matched on a predetermined set of k variables.
these methods are affected by the percentage of swapping and their performances are instable .
.
privacy preserving methods in software engineering in recent years a few privacy preserving methods have been presented in software engineering .
these works mainly focus on defect predicti on testing and debugging.
representative privacy preserving methods for defect prediction include lace1 and lace2 with leaf .
lace1 is a collective name including tw o methods moprh and cliff morph .
moprh uses the nearest unlike neighbors to obfuscate the target sample and achieves promising results.
considering that the uninformative samples may affect the performance of the privacy result and the speed of processing cliff morph was presented w hich employs an instance pruner to delete uninformative sa mples.
recently lace2 is presented to tackle the privac y preserving data sharing problem where data owners can incrementally share their owned data into the same data pool.
due to the limited resource co mpanies usually outsource part o f software to other companies.
whe n the outsourced software enter s the phase of testing the subcontractors need the relevant data to test the software.
however the data to be provided to subcontractors may contain sensitive attribute values which makes the data owners do not wan t to provide real samples for t he testing.
in order to solve this issue taneja et al.
propo sed privacy equalizer for softwar e testing priest which combines a new data privacy framework with program analysis enabling business analysts to determine the output testing data .
budi et al.
proposed a ekb anonymity method which creates the testing coverage data based on the concept of subpath equivalence .
clause and orso designed the camouflage method which introduces the path condition relaxation and breakable input conditions to genera te several anonymized versi on sample of original failu re inducing input sample.
.
manifold learning manifold learning is an efficien t dimension reduction technique which can reduce the dimension and preserve the non linear structure of the data .
manifold learning has been applied in many practical problems such as human action recognition voice recognition and face recognition .
locality preserving projections lpp is a representative manifold learning method.
lpp fir stly uses the information of 77data points to establish a connection adjacency graph and then computes a transformation matrix which maps the data points int o a subspace and gets the represe ntation of the data in a lower dimensional space.
in the low di mensional space the intrinsic dimensionality of the data can b e obtained and the distribution of the original data can be maintained.
.
our approach .
overview of our approach the privacy and utility are two important aspects that need to be considered when designing a privacy preserving algorithm.
the basic idea of our approach is as follows we firstly divide the effort data into several subclasses with the designed icsd stra tegy.
then target samples in each subclass are obfuscated by utilizi ng the proposed mlbdo algorithm.
figure illustrates an overview of our approach for privacy preserving problem in effort data sharing.
more technical details will be introduced in subsectio n .
and .
.
jj j l jk ii i i i i obfuscated x x x h x h 1l ih 1k ih ix thi ix thi figure .
illustration of th e framework of our privacypreserving approach .
interval covering based subclass division algorithm researches in indicate tha t the class labels of data ar e helpful to maintain the boundaries of subclasses after obfuscat ion.
c o n s i d e r i n g t h a t t h e r e a r e n o c l a s s l a b e l s i n e f f o r t d a t a i t i s necessary to dig a new attribute i.e.
class label for effort d a t a .
figure indicates that the samples with similar effort have roughly similar distributions wh ich motivates us to design a subclass division strategy according to the effort values.
in practice since the final effort of a new project may be aff ected by some uncertainty factors e.g.
changes in funds and requirement the estimation error is inevitable in effort estim ation.
denoted by the estimation error if the actual value is the estimated value should fall i n the interval of .
therefore it is reasonable to consider the estimation error in the process of designi ng the subclass di vision strateg y. based on the above analysis we design the following basic dividing criterion given two samples whose efforts are 1y and 2y respectively if yy y these two samples can be classified into the same subclass.
obviously th e problem of subclass division based on this dividing criterion i s actually an interval covering problem .
therefore we formulate our subclass division problem as the following interv al covering problem given an effort dataset ii nn x xy xy x y with n samples iixy denotes the thisample ix represents the independent attributes qids of the thi sample iy represents effort of the thi samples then the effort labels of xcan be denoted by n yy y y .
we use jj is f j m to denote mintervals at the anytime jjsf and then we aim to get the following output a numberiy in y which is not covered by any interval in i or a minimum cardi nality subset c of intervals i which collectively covers all points in y. the division process of icsd is as follows step calculate the tolerance error range of eachiy i.e.
upper boundary and lower boundary ofiy according to formula .
the obtained ranges of all sa mples are represented by lu lu lu ii nn y r yy yy yy l ii i u ii iyy y yy y whereu iy is the upper bound and l iy is the lower bound.
step calculate the coverage number of each iy i.e.
how many ranges iy is covered by according to formula .
denote by in cc c c the coverage numbers of all samples where icis the coverage number of iy.
1n ii j jcc where lu ij j ijif y y yc otherwise .
step label samples according to the ascending order of the c. for thethisample that has not been categorized into any subclass we classify all the samples covered by the tolerance error rang e of iy into a new subclass if these samples have not been labeled.
the reason of using the ascending order is that if a sample has higher covering number then mo re samples may be covered by the range of the sample with higher possibility.
therefore labeling samples according to the descending order of c will generate subclasses suffering fr om the class imbalance problem .
step for the sample whose tolerance error range only covers itself we offer two ways to process it discarding it in our opinion this kind of sample can be regarded as noise sample th at may impair the effort estimation of a new project classify ing it into the nearest subclasses.
researches in show that the error between the estimated effort and the actual effort is acceptable within .
in this paper we set the error tolerance .
in reality the researchers can modify the tolerance according to their own needs .
to help understand our icsd we provide an example as follows we randomly select a part of samples from dataset nasa93 .
the effort values of the selecte d samples are shown in figure a .
the tolerance error used in this paper is .
.
first we calculate the tolerance error ranges of each effort value accor ding 78to formula and store the results in figure b .
then w e calculate the range num bers that each effort value is covered b y according to formula .
for example the effort .
is cove red by the tolerance error ranges of and itself i.e.
.
and352.
the coverage number of .
is set as i.e.
c .
the effort is covered by tolerance error ranges of and itself the coverage numbe r of i s s e t a s i .
e .
c .
repeat this process for each effort value and the results is reported in figure c .
finally we label each sample according to the ascending order of the coverage numbers.
for example from figure c we can see that the samples with lowest coverage number i.e.
1ic are and from figure b we can see that th e tolerance error ranges of only cover themselves so we discard these samples the tolerance error range of covers the effort .
and itself i.e.
.
we put the efforts .
and into a new subclass whose cl ass label is set as .
in a similar way the efforts and can be classified into another subclass wit h the class label .
next we label the samples with 2ic .we firstly check whether these samples have been classified into a subclass and find that .
and have been classified into subclasses and respectiv ely and then efforts .
an d are skipped.
repeating this process until all samples have been labeled or discarded.
the division results of icsd on example data are reported in figure d .
d the results of icsd on a effor t352.
upper bound effort .
8211low er bound .
.
effort .
sub classes effort .
750c a effort labels of partial samples in nasa93 dataset b tolerance error sub ranges of effort labels in a c coverage number of each effort label for b figure .
an example of effort d ata subclass division via icsd .
manifold learning based bidirectional data obfuscation algorithm b y u s i n g t h e d i v i s i o n s t r a t e g y i csd the dataset is divided int o several sub classes with each sample in the dataset being classified into one subclass or discarded.
in this subsection we describe how we protect the pr ivacy of the samples in each subclass and keep their data utility simultaneously.
nearest unlike neighbor nun bas ed obfuscation algorithms have achieved interesting results in software engineering applications .
however w hen these algorithms are used for obfuscating the effort sampl es in each subclass they selec t nun samples as disturbance from the whole dataset except the subclass to which the target sa mple belongs and thus the selec ted disturbance sample may be a noise sample sample that is close to t h e t a r g e t s a m p l e b u t h a s a s i g n i f i c a n t l y d i f f e r e n t e f f o r t v a l ue .
this will result in that the target sample is close to the nois e s a m p l e a f t e r o b f u s c a t i o n w h i c h i s h a r m f u l t o t h e u t i l i t y o f privatized data.
to solve this p roblem we design a bidirection al obfuscation algorithm.
specifically it utilizes the order of l abels of subclasses and selects nun sam ples disturbance samples from the previous and next subclasses such that the influence of noise samples can be avoid.
the definition of nun can be found in definition .
assume that after icsd the original dataset is divided into m sub classes 1m .the obfuscation strategy is shown in formula 1jjj l iii i jjj k iii i jjj l j k i i ii iixxx h i f i xxx h i f i m x xx h x h i fi m wherej ixis the thjsample of the thi subclass in original data j ixdenotes the privatized sample ofj ix 1l ih and 1k ih are two disturbance samples which are t he nearest neighbor samples fro m the thi and thi subclasses of original data respectively for obfuscatingj ix.
and are random values to control the obfuscation degree for target sample.
the values of and range from .
to .
.
definition nearest unlike neighbor nun .
g iven a da tas e t im ss s s with m sub classes is denotes the thi subclass of s j iiss denotes the thjsample in is.
we call the sample l jjssi j as the nearest unlike neighbor nun sample of j is if the l js is the nearest neighbor sample of j is in js.
in the designed obfuscation strategy nun samples are used as disturbances therefore we should select a proper nun selector for our obfuscation algorithm.
euclidean distance based nearest neighbor selector is one of the most popular nearest neigh bor selectors in both academic and industrial communities.
however o n e w e a k n e s s o f t h e b a s i c e u c l i d e an distance selector is that i f one of the input attributes has a relatively large range then it can overpower the other attributes leading to that the true nun sample may be missed .
he nce we should filter those attributes that may overpower the other ones when selecting the nun samples.
as described in subsection .
l pp is a representative manifol d learning method which is similar with some spectral graph theo ry technologies e.g.
spectra l clustering used for software engineering.
lpp can obtain th e intrinsic dimensionality and preserves the structure of data.
this property is beneficial fo r selecting a more precise sample.
therefore we design a manifol d learning based nearest unlike neighbor selector .
specifically we use lpp as the basic method to m ap the original data into an intrinsic dimensionality space and then select the nun sampl e in the projection space.
given a dataset in x xxx experiencing the icsd process lpp aims to find out a transform matrix a and an equal class in z zzz wheret iiza x .
the procedure of lpp is formally stated as follows constructing the adjacency graph let g denote a graph with m nodes.
nodes i and j are connected by an edge if ix and jx are close .
close is measured by following two methods neighborhoods r if ijxx then ix and jx are close .
k nearest neighbor.
kn ix and jx is close if ijxnearest x k or jixnearest x k nearest x k denotes the k nearest neighbors of x. choosing the weights the weight ijwbetween ix and jx has two forms heat kernel ijxx t ijwe tr simple minded 1ijw if and only if vertices i a n d j a r e connected by an edge.
the justification for the choice of weights can be traced back to .
eigenmaps compute the eigenvectors and eigenvalues for the generalized eig envector problem ttxlx a xdx a where d is a diagonal matrix whose entries are column or row since d is symmetric sums of w ii ji jdw .
ld w is the laplacian matrix.
thethi column of matrix xis ix.
let the column vectors l aa be the solutions of equation ordered according to their eigenvalues l .
thus the embedding is as follows t ii i lx za x aa a whereizis a l dimensional vector and a is a nl matrix.
after obtaining t he equal class z then we can obfuscate each sample j ix of the thisub class ix with it.
we firstly get two nun samples indexes of j ix from thi and thi subclasses of z respectively and then we select the two nun samples 1l ih and 1l ih from s according to this two indexes.
finally we can obfuscate the j ixaccording to equation .
we call the bidirectional obfuscatio n algorithm with the manifold learning based nearest unlike neighbor selector as manifold learning based bidirectional data obfuscation mlbdo algorithm.
.
an example of icsd mlbdo in this subsection we provide a complete example to explain ou r icsd mlbdo approach.
we randomly select a part of samples from nasa93 and set the tolerance error as .
.
the selected samples are shown in figure a .
we firstly use icsd to divide the data into se veral subclasses the detail process of subclasses division is shown in figure .
the original data is divided into sub classes and the division result is shown in figure c .
next we use the mlbd o to obfuscate the samples in figure c and the result of obfuscation is reporte d in figure d .
next we test whether the privacy of the effort data has been protected successfully.
we suppose that the kloc attribute has been removed after obfuscation and the adversary has the relat ed background knowledge about nasa da taset.
the test strategy is as follows the adversary sends a query to original dataset and privatized dataset respectively then both datasets will return a group of answers for this query if the result returned from th e original dataset is equal to that returned from the privatized dataset the protection for this sample for this attack is rega rded as a failure and vice versa.
in the testing process for the orig inal and privatized data we first divide the range of possible values o f each attribute into n bins sub ranges by employing the equal frequency binning efb method .
here n is set as .
figure b shows the equal frequency binned version of figure a .
figure e shows an equal frequency binned version of figure d .
assume that the adversary sends the same query cplx to figure b and figure e respectively where cplx means please return the sensitive attribute va lues of the samples with the cplx attribute value of .
th e figure b will return the sensitive values of and samples i.e.
.
and .
.
the figure e will return the sensitive values o f samples i.e.
.
from the results we can see that the returned results of figure b and e are different which means that the icsd mlbdo successfully protects the privacy of the data under the requirement that que ry cplx and query size .
e efb version of d d the obfuscated data after icsd mlbdo a the remained samples of a after icsd b efb version of a a randomly selected partial samples from nasa93 cplx acap pcap kloc effort .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
cplx acap pcap kloc effort .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
cplx acap pcap kloc effort subclasses .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
cplx acap pcap kloc effort .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
cplx acap pcap kloc effort .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
figure .
an example of icsd mlbdo .
answers for two research questions a n s w e r s f o r r q in privacy preserving of effort data how to maintain the utility of the obfuscated data?
in order to achieve this purpose we design the icsd to classif y the samples with similar effort into the same class and the obtained ordered class labels p rovide a guideline for obfuscati ng the target sample.
in the process of obfuscation instead of selecting nun samples from all of other subclasses we select t he nun samples from the previous and the next subclasses 80according to the class labels and use the obtained nun samples as disturbances to obfuscate the target sample.
in this way th e obfuscated target sample will not invade the boundaries of the other subclasses that have significantly different effort value s which means that the data distribution can be maintained after obfuscation.
answering for rq2 how to effectively preserve the privacy contained in the ori ginal effort data?
in order to achieve this purpose we design the mlbdo algorithm to obfuscate the target sample.
mlbdo uses two nun samples which are selected by using manifold learning based nearest unlike neighbor selector as the disturbance samples to obfusca te the target sample bi directionally.
the bi directional strategy can not only avoid the influence of noise sample but also increase the privacy of obfuscation.
.
comparison with related works in this subsection we provide a discussion about the differenc es between our privacy preserving method and related privacy preserving methods .
comparison with general pr ivacy preserving methods t h e main differences between our approach and general privacy preserving methods are two folds these methods are not designed for tasks in software engineering while our metho d is designed for the ppds of effort data.
these methods don t consider the influence of outli er samples while our approach c an cut these samples automatically such that the remaining sample s are more suitable for building a precise estimation prediction model.
comparison with privacy pres erving methods in software engineering the main differences between our approach and these methods are two folds different with these methods which use one nun samp le as the disturbance to obfuscate the target sample our method uses two nun samples as the disturbance to obfuscate the target sample bi directionally .
by using the bi directional strategy our method can avoid using t he noise sample as the disturbance whose effort values are significantly different from thos e of target sample.
the utiliz ation of noise samples will affect the maintaining of data distributi on.
when maintaining the utility of obfuscated data we not only consider the influence of obfuscation ranges but also consider maintaining the data distr ibution after obfuscation.
table .
brief properties of used data sets with different quer y size dataset number of samples number of attributes minimum effort value maximum effort value nasa93 .
maxwell kitchenham kemerer .
.
coc81 .
china albrecht .
.
.
experiments .
data sets to evaluate the performance of our icsd mlbdo approach we conduct extensive experiments on seven effort datasets includi ng nasa93 kitchenham kemerer coc81 china albrecht and maxwell .
the metrics of these datasets are based on cocomo or function points .
the brief properties of these datase ts used in this paper are shown in table .
the metrics of these datasets are show in figure .
rely required software reliability durationtotal elapsed time for the project nlannumber of different developmentlanguages used datadata base size rawfp raw function points count t01 customer participation turn turnaround tim e adjfp adjusted function points t02development environm entadequacy time time constraint for cpu fpadj transformation of rawfp t03 staff availability stormain m em ory constraint enquiryfunction points ufp of ex ternalenquiryt04 standards use virt machine volatility fileufp of internal logical files orentity referencest05 methods use tooluse of software tools pdr ufpnormalized level productivitydelivery ratet06 tools use dcedschedule constraint npdr afpnormalized productivitydelivery ratet07 software s logical complexity aexp application ex perience outputfunction points ufp of ex ternaloutputt08 requirements volatility pcap program mers capability t09 quality requirements vexpvirtual machine ex perience npdu ufp productivity delivery rate t10 efficiency requirements lexplanguage ex perience input function points ufp of input t11 installation requirements modp modern programing practices afp adjusted function points t12 staff analysis skills cplxprocess com pl ex ity ksloc thousands of lines of code t13 staff application knowledge acapanalysts capability app application type t14 staff tool skills locline of code har hardware platform t15 staff team skills dba databas eduratio nduration interfacefunction points ufp ofex ternal interface addedifc user interface time time changedfunction points ufp ofchanged functionssource where developed sizeapplication size num ber offunction points deletedfunction points cfp ofdeleted functionstelonuse telon use effort resource team typecocomo function pointsmaxwell function points maxwell figure .
the metrics of the dat a sets used in this work.
the red rectangle box outlines the sensitive attributes used in thi s paper.
.
evaluation measures the privacy preserving methods s hould ensure that the privatize d data has both favorable privacy and utility.
to evaluate the privacy and utility of the privatized data we employ the follo wing measures.
.
.
measure of privacy we use the increased privacy ratio ipr to evaluate the privacy ability of a method.
given n qq q q denotes n queries.
informally the ipr can be defined as follows 1q i ipi p r t kq where t represents the dataset to be evaluated and max max .iitt iif s r s rk otherwise .
here max ti sr is the highest frequency value of tir.
tiris the results of thiquery which is a group of value from any dataset matches the thi query.
for example tir denotes the results of thi query returned from privatized data and then max ti sr .
the higher ipr the better a privacypreserving method.
the query generator used in this paper detailed in subsection .
.
.
.
measure of utility median magnitude of relative e rror mdmre and pred are two commonly used measures for evaluating the effort 81estimation accuracy of estimators.
in the experiments we emplo y both measures to evaluate the utility of the privatized data.
t he definitions of mdmre and pred are as follows given a sample ix with the actual effort being iy if the predicted effort is iy the magnitude of relative error mre of ix can be calculated by ii i iyymrey .
then mdmre of n samples can be computed as in mdmre median mre mre mre .
pred is defined as the percentage of estimated values falling within percent of the actual values .
n i iif mrepredotherwise n .
for these two measures the lower of mdmre represents the better performance of estimator and the higher pred represents the estimator s being more precise.
.
query generator in this subsection we introduce t he query generator used in th is paper.
assume the query size is the process of the generator to create a query is as follows randomly select an attribute from qids attributes except sensitive attributes .
for example randomly select an attribut e from figure b here assume that the cplx attribute has bee n selected by the generator.
then the generator will find out th e distinct ranges from cplx i.e.
.
.
.
rangescplx .
randomly select a range from rangescplx as a query.
for example the generator randomly selects the then the n ew created query is cplx which means please return the sensitive attribute values of the samples with the cplx attribu te value of .
table shows the examples of ge nerated queries with different query sizes on the data of figure b .
table .
examples of generated queries query size qids return cplx .
cplx acap .
.
experimental settings assume that a dataset has im qids attributes with the thj attribute has jn distinct sub ranges.
if the query size is p we can get ip p mjcn quires.
it is unrealistic and unnecessary to enumerate all possible quires of all possible query sizes especially when the number of qid s attributes is very large.
fo r example the dataset nasa93 ha s qids attributes if each qids attribute has distinct sub ranges and query size is respectively and the n the generator will create ccc queries.
thus in our experiments the selected query sizes include and and up to queries are generated for each query size.
the numbe r of sensitive attributes and the si ze of efb used in this paper are listed in table .
the sensitive attributes used in this paper include loc kloc afp and size because these attributes are very important influence factors for bidding and the data owne rs may not want these data to be obt ained by adversaries.
in addit ion kloc afp and size can be converted to each other .
we choose the k nearest neighbor as the close measure and the heat kernel as the weight measure in lpp respectively.
in the experiment of utility w e randomly select modules in each of effort dataset for training and the remained modules ar e used for testing.
the random selection process for training and testing data may be biased and may affect the evaluation performance.
therefore we repe at random selection times and report the average estimation results.
table .
experimental settings used in this work dataset number of qids sensitive attributes efb size nasa93 kloc maxwell size kitchenham afp kemerer ksloc coc81 loc china afp albrecht afp .
evaluation of privacy and utility for icsd mlbdo for this part we perform experiments to evaluate the privacy a nd utility for our approach and the applicability of our privacypreserving approach for different effort estimators respective ly.
compared methods .
to benchmark our method we compare our approach with four methods including k anonymity swapping clustering combined with mlbdo clustering mlbdo and icsd combined with morph icsd mlbdo .
we implement th e k anonymity by following the datafly algorithm and create two versions of kanonymity namely anonymity and anonymity.
in swapping for each qids attributes a certain percent of values nee d to be replaced by any other distinguishable values in that qids.
i n the experiments the used percen tages include and .
the clustering mlbdo method is used to evaluate the performance of the designed icsd strategy.
in experiments kmeans is employed as the clustering algorithm with the statistical significance level .
.
the icsd morph is used to evaluate the performance of the proposed bi directional obfuscation algorithm.
results of privacy and utility testing .
in the experiments the classic classification and re gression trees cart is employed as the baseline estim ator.
we conduct our approach and the compared methods on datase ts and then compute the ipr pred and mdmre of each method.
due to the limited space figure only provides the experi mental results with query size .
f r o m f i g u r e w e c a n s e e t h a t t h e p r i v a c y a n d u t i l i t y o f icsd mlbdo are better than those of the competing methods.
compared with k anonymity our approach achieves significantly better utility performance.
the r eason is that k anonymity uses the generalization strategy to protect the sensitive values lead ing to that the information used for m odeling becomes less.
compared with swapping our approach can achieve more stable performance.
the main reason is that swapping method replaces the values of sensitive attributes with the random strategy.
compared with icsd morph icsd mlbdo achieves higher privacy performance.
the main reasons in our opinion a re two folds morph uses the global nun sample selected from all other subclasses as the disturbance to obfuscate the target sample while mlbdo selects the nun samples from previous and next subclasses and thus the disturbance ability of the nu n 82samples selected by morph ma y be lower than that of nun samples selected by mlbdo.
the designed bi directional obfuscation algorithm of mlbdo can provide more powerful obfuscating ability.
compared with clustering mlbdo icsd mlbdo achieves higher utility.
the reason is that icsd considers the estimation error in the process of subclass divis ion and removes the outlier sample automatically.
icsd mlbdo combines the advantages of icsd and mlbdo and therefore better performances in privacy and utility can be achieved.
the boxplot figures in figure s how the variability of utility measures of different privatized data obtained by using differe nt privacy methods we can see that the variability of icsd mlbdo is better than that of compared methods.
figure illustrates the experiment results under different query sizes and on different datasets.
we can see that our approach obta ins higher privacy performances than the compared methods under all three query sizes.
results of applicability testing .
to investigate whether the privatized data with our approach can be applied to multiple estimators we design another expe riment.
we select another two estimators including automatically transformed linear model atlm and radial basis function networks rbfn .
tables and report the average effort estimation results of icsd mlbdo and the competing methods with these two estimators on seven datasets for the mdmre and pred measures respectively.
in tables and we also report the estimation results using original data and the results are cal led as normal .
from both tables we can see that the performances of our approach are still better tha n those of the competing metho ds which indicates that the privatized data by using our approach can well apply to different estimators.
to statistically analyze th e results given in tables and we conduct a sta tistical test i.e.
wilcoxon test with per cent confidence to get the so called win tie loss w t l results.
win means the results of our approach is significantly diffe rent with compared methods and tie means equal otherwise lose .
we can see that the proposed approach makes a signifi cant difference in comparison with other compared methods.
nasa93 maxwell kitchenham kemerer coc81 china albrecht0 datasetsipr query size nasa93 maxwell kitchenham kemerer coc81 china albrecht2030405060 datasetsipr query size nasa93 maxwell kitchenham kemerer coc81 china albrecht50556065 datasetsipr query size icsd mldbo anonymity anonymity swapping swapping swapping icsd morph clustering mlbdo figure .
privacy comparision o f a l l m e t h o d s o n d a t a s e t s versus different query sizes.
.
threats and validity followings are several potential threats to the validity with r espect to experiments bias of estimators.
a bias i n this study is the estimators we u s e d f o r e f f o r t e s t i m a t i o n .
i n experiments we select three commonly used estimators to eva luate our approach.
as to more other estimators experiments mi ght need to be done to evaluate our approach.
bias of evaluation measures.
another bias is the mdmre and pred measures used to repor t the imputation or estimation performances.
other measures such as mean balanced relative error mbre the mean inve rted balanced relative error mibre cluster and standardized accuracy are not used.
in this work we employ the widely used mdmre and pred measures to show the empirical evaluation for the application of softwar e effort estimation.
.
.
.
.259mdmre ipr nasa93 .
.
.
.8mdmre ipr maxwell .
.
.
.6mdmre ipr kitc henham .
.
.
.6mdmre ipr kemerer .
.
.5mdmre ipr coc81 .
.
.
.6mdmre ipr china .
.
.
.8mdmre ipr albrecht pred n o r m a l o u r s 1s 2s 4k 2k 4i m c mpred of nasa93pred normalour s1 s2 s4 k2 k4 im cmmdmre of nasa93mdmre pred normalour s1 s2 s4 k2 k4 im cmpred of maxwellpred n o r m a l o u r s 1s 2s 4k 2k 4i m c mmdmre of maxwellmdmre pred normalour s1 s2 s4 k2 k4 im cmpred of kitchenhampred normalour s1 s2 s4 k2 k4 im cmmdmre of kitchenhammdmre pred n o r m a l o u r s 1s 2s 4k 2k 4i mc mpred of kemererpred normalour s1 s2 s4 k2 k4 im cmmdmre of kemerermdmre pred n o r m a l o u r s 1s 2s 4k 2k 4i mc mpred of coc81pred normalour s1 s2 s4 k2 k4 im cmmdmre of coc81mdmre pred n o r m a l o u r s 1s 2s 4k 2k 4i mc mpred of chinapred normalour s1 s2 s4 k2 k4 im cmmdmre of chinamdmre pred pred of swapping s1 mdmre of swapping s1 pred of swapping s2 mdmre of swapping s2 pred of swapping s4 mdmre of swapping s4 pred of original data normal mdmre of original data normal pred of icsd mlbdo our mdmre of icsd mlbdo our pred of anonymity k2 mdmre of anonymity k2 pred of anonymity k4 mdmre of anonymity k4 pred of clustering mlb do cm mdmre of clustering mlbdo cm pred of icsd morph im mdmre of icsd morph im privacy baseline with ipr pred line of original data mdmre line of original data n o r m a l o u r s 1s 2s 4k 2k 4i mc mpred of albrechtpred normalour s1 s2 s4 k2 k4 im cmmdmre of albrechtmdmre figure .
comparison of privacy preserving methods using the ca rt estimator on mdmre and pred measures with query size the horizontal dashed thin line represents the pred measure s the dashed thick line represen ts the mdmre measures and the vertical line denotes the privacy baseline with ipr .
83table .
comparison of utility r esults using two estimators wit h seven data sets on mdmre estimator methods params nasa93 maxwell kitchenham kemerer coc8 china albrecht atlm k anonymity k .
.
.
.
.
.
.
.
.
.
.
.
.
k .
.
.
.
.
.
.
.
.
.
.
.
.
.
swapping n n .
.
.
.
.
.
.
.
.
.
.
.
.
.
n .
.
.
.
.
.
.
.
.
.
.
.
.
.
n .
.
.
.
.
.
.
.
.
.
.
.
icsd morph .
.
.
.
.
.
.
.
.
.
.
.
clustering mlbdo .
.
.
.
.
.
.
.
.
.
.
icsd mlbdo .
.
.
.
.
.
.
.
.
.
.
.
.
.
normal .
.
.
.
.
.
.
.
.
.
.
.
statistical test w t l rbfn k anonymity k .
.
.
.
.
.
.
.
.
.
.
.
.
.
k .
.
.
.
.
.
.
.
.
.
.
.
.
.
swapping n n .
.
.
.
.
.
.
.
.
.
.
.
.
.
n .
.
.
.
.
.
.
.
.
.
.
.
.
n .
.
.
.
.
.
.
.
.
.
.
.
.
icsd morph .
.
.
.
.
.
.
.
.
.
.
.
.
.
clustering mlbdo .
.
.
.
.
.
.
.
.
.
.
.
.
.
icsd mlbdo .
.
.
.
.
.
.
.
.
.
.
.
.
.
normal .
.
.
.
.
.
.
.
.
.
.
.
.
statistical test w t l table .
comparison of utility r esults using two estimators wit h seven data sets on pred estimator methods params nasa93 maxwell kitchenham kemerer coc81 china albrecht atlm k anonymity k .
.
.
.
.
.
.
.
.
.
.
.
.
k .
.
.
.
.
.
.
.
.
.
.
.
.
swapping n n .
.
.
.
.
.
.
.
.
.
.
.
n .
.
.
.
.
.
.
.
.
.
.
.
.
n .
.
.
.
.
.
.
.
.
.
icsd morph .
.
.
.
.
.
.
.
.
.
.
.
.
clustering mlbdo .
.
.
.
.
.
.
.
.
.
icsd mlbdo .
.
.
.
.
.
.
.
.
.
.
.
normal .
.
.
.
.
.
.
.
.
.
.
.
.
statistical test w t l rbfn k anonymity k .
.
.
.
.
.
.
.
.
.
.
.
.
k .
.
.
.
.
.
.
.
.
.
.
.
.
swapping n n .
.
.
.
.
.
.
.
.
.
.
.
.
n .
.
.
.
.
.
.
.
.
.
.
.
.
n .
.
.
.
.
.
.
.
.
.
.
.
.
icsd morph .
.
.
.
.
.
.
.
.
.
.
.
.
.
clustering mlbdo .
.
.
.
.
.
.
.
.
.
.
.
.
icsd mlbdo .
.
.
.
.
.
.
.
.
.
.
.
.
normal .
.
.
.
.
.
.
.
.
.
.
.
statistical test w t l bias of compared methods.
in the family of anonymization there exist many anonymization methods and it is hard to compare our icsd mlbdo with all of other anonymization methods.
in this paper we compare our method with four different privacy methods from both software engineering domain and general field.
as to more ot her privacy methods experiment s might need to be done to compare our approach.
.
conclusion and future work in this paper we study the privacy preserving problem on effor t data.
when a company lacks history data to build a model for estimating the effort of a new project the engineers may try t o request relevant data from other companies.
however considerin g the risk of sensitive attribute values disclosure most compani es would refuse these requests.
in order to solve this problem we propose the icsd mlbdo approach.
icsd mlbdo uses the designed icsd strategy to divide the original data into several subclasses whose labels are orde red and then it utilizes the designed mlbdo algorit hm to obfuscate the target sample.
experimental results on seve n benchmark effort datasets demonstrate that our approach can make the effort data obtain favorable privacy and keep its utility simultaneously.
for the future work we would like to utilize more effort datasets to validate the effectiveness of our approach.
.