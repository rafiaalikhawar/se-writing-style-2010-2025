database backed program analysis for scalable error propagation cathrin weiss cathrin.weiss gmail.comcindy rubio gonz lez university of california davis crubio ucdavis.eduben liblit university of wisconsin madison liblit cs.wisc.edu abstract software is rapidly increasing in size and complexity.
static analyses must be designed to scale well if they are to be usable with realistic applications but prior e orts have often been limited by available memory.
we propose a database backed strategy for large program analysis based on graph algorithms using a semantic web database to manage representations of the program under analysis.
our approach is applicable to a variety of interprocedural finite distributive subset ifds dataflow problems we focus on error propagation as a motivating example.
our implementation analyzes multi million line programs quickly and in just a fraction of the memory required by prior approaches.
when memory alone is insu cient our approach falls back on disk using several hybrid configurations tuned to put all available resources to good use.
i. introduction as computers become more powerful software applications continue to grow in size.
for example linux is almost seven times larger now than it was twelve years ago.
as a consequence particular attention is placed on scalability when designing techniques to analyze software.
unfortunately computer resources are often a limitation when analyzing large code bases.
the key scalability limitation is memory.
memory usage is often correlated with the size of the code base under analysis.
recent papers describe scalable program analyses that are applied to large code bases.
the largest programs analyzed in these papers range in size from kloc to8.
mloc .
despite the fact that these analyses either have di erent purposes or follow di erent approaches to solving similar problems it is noteworthy that their memory usage ranges from mb to20 gb with a few instances running out of memory in their particular configuration settings.
one rarely sees analyses of larger code bases or analyses of combinations of programs e.g.
analyzing a kernel and user applications in conjunction .
presumably the main reason is poor scalability.
doop and semmlecode developed as codequest use database engines to query and analyze program behavior.
databases routinely work with more data than fits in memory so a database backed program analysis could potentially break through the memory scalability barrier.
however prior work has not systematically explored the practical consequences of moving analysis from memory only to memory plus disk.
for example smaragdakis et al.
explicitly focus on doop configurations that do not bring the disk heavily into play.
in this paper we present a database backed program analysis technique that makes good use of available memory whileallowing very large analyses to fall back on disk.
we significantly reduce the amount of memory required thereby allowing memory only analyses of larger code bases than was possible in prior work.
for problems that are too large for memory we identify useful memory plus disk configurations to optimize use of available resources.
we demonstrate the e ectiveness of our technique by implementing a static program analysis that tracks how error codes propagate in c c applications and finds instances in which unhandled error codes are dropped .
figure 1a shows an example of a dropped error in the firefox web browser.
function dasharraytojsval may return one of two error codes ns error out of memory or ns error failure .
the error code is dropped on line while failing to be stored in the reference parameter error .
ignoring this failure could cause mozdash to remain uninitialized leading to a confirmed potential security vulnerability.
1note that although the bug fix seems trivial finding the bug and agreeing on a fix was definitely not an easy task.
as shown in figure 1a error propagation analysis is particularly important because defective error propagation has the potential to cause not only security vulnerabilities but also silent unrecoverable data corruption.
furthermore the systems potentially a ected can be massive.
applying error propagation analysis to such large code bases is an important goal but one that faces major scalability challenges.
we apply our database backed analysis to the linux kernel and the firefox web browser.
experiments show that we can perform analyses with modest resources while other analysis tools require dedicated large memory servers.
our approach is highly configurable allowing it to work e ciently and scalably across a wide range of data characteristics.
our contributions are as follows we show how to encode error propagation analysis section ii as a graph saturation problem section iii tuned for e cient database backed inference.
we provide an e cient and scalable implementation of our target analysis using a database backed graph indexing scheme section iv .
we explore several database configurations representing trade o s between available memory and time to completion section v .
1https bugzilla.mozilla.org show bug.cgi?id 11value canvasrendering getmozdash context cx errorresult error 2value mozdash 4dasharraytojsval currentstate .dash cx mozdash unsaved error return mozdash a original code with an unsaved error on line 41value canvasrendering getmozdash context cx errorresult error 2value mozdash inttemp 4temp dasharraytojsval currentstate .dash cx mozdash 5temp ok overwritten error return mozdash b transformed code with an overwritten error on line fig.
.
an unsaved error found in the firefox web browser.
figure 1a is the original code in which function dasharraytojsval may return one of two error codes ns error out of memory orns error failure .
function getmozdash fails to propagate the error leading to a confirmed and now fixed potential security vulnerability.
figure 1b is the code after program transformations that convert the unsaved error into an overwritten error.
we apply our analysis to two large real world code bases the linux kernel and the firefox web browser.
our technique dramatically reduces required time and or memory compared to a prior memory only approach section v .
section vi discusses related work and section vii concludes.
ii.
b ackground incorrect error handling is a longstanding problem in a wide variety of domains.
ideally whenever a run time error occurs software systems should respond accordingly.
unfortunately that is often not the case.
error handling code tends to be poorly understood poorly documented and poorly tested .
unsurprisingly then error handling code is often buggy.
one of the reasons is that handling errors is in general a di cult task.
exceptional conditions must be considered during all phases of software development introducing interprocedural control flow that can be di cult to reason about .
as a result error handling code is usually scattered across di erent functions and files making software more complex and less reliable.
modern programming languages such as java c and c provide exception handling mechanisms.
unfortunately c does not have exceptions so c programmers emulate exceptions in a variety of ways.
the return code idiom is among the most popular idioms used in large c programs including operating systems.
errors are represented as simple integer codes where each integer value represents a di erent kind of error.
2these error codes propagate through conventional mechanisms such as variable assignments and function return values.
even c programmers sometimes prefer the return code idiom over language level exceptions .
unfortunately the errorcode idiom is highly error prone.
several approaches have been proposed to detect or monitor error propagation patterns at run time typically during controlled in house testing with fault injection to elicit failures .
other approaches use dataflow analysis to detect bugs in the propagation of errors in system software and user applications .
our case study is particularly inspired by the error propagation analysis of rubio gonz lez et al.
which tracks errors as they propagate through c c programs.
2for example the linux kernel defines eio eagain and enomem as integers and respectively.
these error codes correspond to i o error try again and out of memory .
error codes are not in general standardized across applications each program or library may define its own idiosyncratic codes.the error propagation analysis is an interprocedural flowand context sensitive static program analysis that finds the set of error codes that each variable may contain at each given program point.
this information is used to detect a variety of errorhandling related bugs in linux file systems that can potentially cause silent unrecoverable data corruption .
in particular the analysis detects unhandled errors that are overwritten with a new value overwritten error go out of scope out of scope error or are returned by a function but not saved by the caller unsaved error .
figure 1a shows an example of an unsaved error.
for simplicity the analysis transforms both out of scope and unsaved errors into overwritten errors.
figure 1b shows how to transform the unsaved error of figure 1a into an overwritten error.
the transformation consists of two steps first the unsaved error is transformed into an out of scope error.
this is achieved by introducing a new temporary variable temp on line .
the variable is assigned the value returned by function dasharraytojsval .
because function dasharraytojsval may return an error code the transformed function now contains an out of scope error variable temp goes out of scope while storing an error code.
second the out of scope error is transformed into an overwritten error.
for this an assignment is inserted at the end of the function for each integer local variable.
in our example only one assignment to variable temp is inserted on line .
note that okis a special value introduced by the analysis to represent a non error value.
after this the transformed function now contains an overwritten error instead of an out of scope error variable temp contains an error that is overwritten with the value okon line .
at the high level assignment statements or overwritten errors constitute the program points of interest for the analysis.
internally the analysis can still distinguish between the three kinds of dropped errors which helps provide more precise diagnostic information.
the following paragraphs describe other analysis characteristics.
exchange variables the analysis introduces global variables referred to as exchange variables.
exchange variables are used for the purpose of value passing between callers and callees.
there is an exchange variable for each function parameter and function return value.
callers export arguments into the corresponding exchange variables and callees import these exchange variables into its formal parameters.
similarly 2before assignment x y z after assignment x y zintraintraintra fig.
.
example graph fragment corresponding to y x callees export their return value into the corresponding exchange variable and callers import this variable into the receiver.
this process makes value passing explicit.
pointer variables each pointer variable pis treated as two locations pand p and no pointer is assumed to alias any other.
this is neither sound nor complete but it has been shown to yield useful results in bug finding.
under these conditions pointer parameters are equivalent to call by copy return parameters.
pointed to values are copied from the caller to the callee just as for function parameters.
callee values are copied back into the caller.
this extra copy back on return is what distinguishes pointer arguments from non pointer arguments because it allows changes made by the callee to become visible to the caller.
function pointers indirect calls are treated as a nondeterministic choice among a conservative over approximation of all possible callees.
specifically calls across functions pointers are rewritten as switch statements that choose among possible implementations nondeterministically.
iii.
a nalysis codification this section describes how the error propagation analysis of section ii can be codified as a graph edge saturation problem.
section iv will describe how this graph problem is mapped into a form suitable for e cient implementation.
a. variable expanded control flow graph error propagation analysis requires determining the set of error codes that a given variable may contain at a given program point.
this constitutes an interprocedural dataflow analysis problem.
we begin with the interprocedural control flow graph cfg .
replace each statement node in this cfg with a vector of nodes one for each global variable local variable or formal function parameter in the program.
if x y and zare program variables we might have three nodes representing x y and z at some statement s1 three more representing these variables at a di erent statement s2 and so on for each variable at each program location.
this makes the graph significantly larger than the original but allows us to distinguish each variable s value at each program point thereby supporting flow sensitive analysis.
we call this new enlarged graph the variable expanded cfg .
it can be seen as a specific instance of an exploded supergraph as used in the interprocedural finite distributive subset ifds framework of reps et al.
.
suppose statements s1ands2were statement nodes connected by an intraprocedural control flow edge in the original cfg.
in the variable expanded cfg connect variable nodes at s1to selected variable nodes at s2to reflect possible flows of values as a result of executing s1.
figure shows an example graphfragment corresponding to the assignment y x .
observe that while yis overwritten with the previous value of x this assignment has no e ect on the values of xorz.
edges reflecting value flow within a single function are labeled intra for intraprocedural flow.
at each function call in the original cfg split the call into a vector of nodes for each variable before the call and a distinct vector of nodes for each variable after the call.
do not directly connect before call nodes to after call nodes.
rather assign each call site a unique identifier.
at call site i create interprocedural call edges labeled i connecting actual arguments in the caller to the corresponding formal arguments at the entry point of the callee.
conversely create interprocedural return edges labeled i connecting variables at exit points from the callee to variables that may receive returned values in the caller.
lastly create a node for each error code.
error codes are immutable so these nodes need not be replicated at each program location.
connect error code nodes to variable nodes where appropriate to reflect flow of error codes into variables.
for example y enomem adds an edge from the enomem node to the node representing yafter the assignment.
edges from error code nodes can be interprocedural as well as in foo eagain or return eio .
we handle additional program features such as parameter passing in the manner of prior work on error propagation .
refer to section ii for a brief summary.
b. interprocedurally valid paths the variable expanded cfg reflects single step flows of values from one statement to the next.
determining which error codes flow into a given variable at a given program point requires extending these local flows across multiple statements.
we are looking for interprocedurally valid paths obeying two criteria within a function a valid path must cross a sequence of intraprocedural flow edges intra .
across a function call a valid path must enter and exit the callee at the same call site.
that is each call edge i must match a corresponding return edge i .
mismatched calls and returns such as are disallowed as they cannot correspond to any properly nested function invocation.
paths corresponding to a complete normally terminating execution would begin with some main edge representing the call to the program s main routine and would end with a corresponding main edge.
however we are interested in partial executions during which error codes are propagating from one part of the program to another.
therefore our valid paths may begin with a prefix of unmatched return edges representing returns from calls that were already in progress when the error arose.
this is called a positive flow the caller is receiving information returned to it by the callee.
likewise our valid paths may end with a su x of unmatched call edges representing calls into functions that are still in progress upon reaching the statement of interest.
this is called a negative flow the caller is giving information to the callee.
if all calls and returns match then a path is a matched flow .
thus an interprocedurally valid path for a partial execution consists of a positive flow prefix 3followed by a negative flow su x with arbitrary matched flows intermixed at any point along the path.
c. path discovery via edge saturation discovering interprocedurally valid paths proceeds bottom up.
we begin with flows already present in the variable expanded cfg.
based on these we infer progressively longer paths culminating in interprocedurally valid paths.
we codify the inference process as a suite of subgraph patterns given in figure .
we saturate the graph using these patterns whenever any pattern matches any part of the graph add the corresponding green dashed edge.
repeat this until no new opportunities to add edges can be found.
once that fixed point is reached the analysis results can be read directly out of the edges labeled valid .
edge saturation for interprocedurally valid paths can be formulated in many ways.
all would ultimately lead to the same results but di erent formulations can vary dramatically in how many intermediate edges they add and therefore in how well they scale up.
we have carefully formulated the patterns in figure to focus edge creation on known points of interest avoiding inferring edges that are correct but not useful.
these patterns also leverage our database engine s e cient transitive closures section iv d and fast matching against partial source edge destination patterns section iv a .
any ifds problem would use similar patterns though the specific edge labels and relationships would vary.
we now clarify the meaning and role of each pattern.
figure 3a matched seed we do not need to know about every variable at every program location only some of these are actually of interest.
before analysis begins we mark these nodes of interest with self edges labeled seed .
trivially a seed self edge is a matched flow of length zero.
this zero length matched flow can then serve as a basis for inferring longer flows using other patterns that follow.
thus seed edges are the seeds from which longer paths grow.
figure 3b intra inferred suppose we have already discovered any inferred flow from xtob.
additionally there is a single step of intraprocedural flow from atox.
put these two together and we have a slightly longer inferred flow of the same kind from atob.
this figure actually represents three patterns with inferred varying over fmatched pos neg g. in conjunction with figure 3a these patterns e ectively create a predominantly backward analysis that begins at seeds and extends paths backward to error codes.
figure 3c callee matched suppose we have already discovered any inferred flow from xtoy and that xis a return point from call i. in order to know what reaches y we need to know what could have happened in that call.
so mark the corresponding point just inside the call as a zero length matched flow to itself.
that is not very interesting in its own right but it serves as a new starting point for further analysis of the body of the called function.
note that the matched flow inferred at a is actually independent of the iedge and the xnode to which that edge returns.
this is an important property it means that whatever we learn while analyzing the callee will be reusable if some other flow eventually reaches aas well.
we never needto search for matched flows to amore than once.
this figure actually represents three patterns with inferred varying over fmatched pos neg g. figure 3d promote return if we have found a negative flow that leads up to a return edge that return edge might eventually match up with a call.
this possibility will be explored due to the earlier rule that adds a matched self edge.
however it is also possible that this return edge will never match up with a call i.e.
that this return edge is the final step in a positive flow.
discovering that positive flow is important because it can eventually become a valid reaching path in conjunction with the negative flow we started out with.
so we promote this return edge into a single step positive flow and possibly continue working backward from there.
figure 3e return nonneg unmatched returns extend positive flows or turn matched flows into positive flows.
this figure actually represents two patterns with nonneg varying over fmatched pos g. figure 3f call nonpos unmatched calls extend negative flows or turn matched flows into negative flows.
however this should only be done when the negative flow could potentially be part of a valid flow to a seed.
this figure actually represents two patterns with nonpos varying over fmatched neg g. figure 3g hoist justified hoist matched flow from callee to caller but only when we already have some inferred flow after the call to justify our interest.
this figure actually represents three patterns with inferred varying over fmatched pos neg g. figure 3h valid a valid reaching path is positive flow followed by negative flow per section iii b. figure 3i promote valid alternatively a valid reaching path can be negative flow only with no preceding positive flow still ending at a seed of interest.
also inferring a valid reaching path from positive flow only with no preceding negative flow is unnecessary the bend of such a path will always carry a seed edge from which a zero length negative flow can be inferred using other rules.
iv .
a pproach in theory section iii reveals the critical elements needed in order to perform error propagation analysis.
in practice memory and other resource limits present significant scalability challenges.
here we discuss practical considerations that must be addressed to apply the ideas of section iii to large realworld code bases.
sections iv a andiv b describe our diskbased graph indexing scheme.
section iv c describes how our selected representation is used in the main analysis algorithm.
we describe additional supporting analyses and optimizations in sections iv d andiv e while section iv f considers e ective use of limited memory and disk for further performance gains.
a. hexastore e cient management of large graphs using the graph saturation strategy of section iii requires a suitable data structure to represent the variable expanded cfg.
unfortunately this graph including inferred edges can easily grow too large to fit in memory limiting the size of programs that can be analyzed.
databases however routinely work with data 4aseed matched a matched seeda x b intra inferredinferred b intra inferredx y ainferred matched i c callee matchedb x aneg ipos d promote returnx b anonneg i pos e return nonneg a x b ineg nonposseed f call nonposa z b x yinferred iinferred matched i g hoist justifiedx a bneg pos validseed h valida b neg validseed i promote valid fig.
.
inference patterns for valid paths analysis.
in each pattern italics represent wildcard values to be filled in after matching the pattern while regular upright text represents specific values that must appear as given.
solid black arrows represent edges already present or inferred while green dashed arrows represent new edges to be added when the pattern matches.
too big to fit in memory.
semantic web research in particular o erstriple stores optimized for storing and accessing large graph data to and from disk.
with a disk based representation of the variable expanded cfg available memory acts merely as a working cache or bu er not as a limiting upper bound.
good performance on large graphs depends critically on the indexing scheme used we must be able to quickly find needed information either on disk or in memory bu ers while minimizing i o and staying within reasonable memory limits.
the approach we use hexastore indexes graphs six fold according to each of the permutations of source destination and edge label.
for example hexastore s source edge destination index maintains a sorted disk based map indexed by source node.
each source node maps to a sorted index of outgoing edge labels and each of these edge labels maps to a sorted set of destination nodes for the given source node and edge label.
thus with one look up we can quickly find all edges for a given source node.
with a second look up we can quickly find all destination nodes for a given source node and edge label.
hexastore s other indices allow similar look ups based on other permuted criteria.
in general given any one or two fixed elements of a source edge destination tuple hexastore can quickly access the related remaining information.
hexastore allows storing indices on disk .
reads from this persistent structure are relatively cheap while updates require rebuilding the entire persistent structure.
reindexing is relatively quick even for large numbers of edges about minutes for million edges on a standard desktop machine with an average hard drive.
this for every new edge is impractical but batch updates can work well for long running analyses.
new edges can be held in memory until enough have accumulated to make it worthwhile to pause rebuild indices and then continue.
a disk based representation has other advantages besides reducing memory requirements.
the entire analysis is naturally persistent it can easily be interrupted mid analysis and resumed later even on a di erent machine.
distributed analysis is alsostraightforward multiple machines can trivially share the same disk based representation of the initial variable exploded cfg with each machine exploring di erent paths in parallel.
pooling discovered edges would require cross machine coordination.
however the idempotent and monotonic nature of edge saturation makes this easier to manage.
for example we always have the option to redundantly discover edges that have already been discovered elsewhere.
this lets us reduce or eliminate cross machine communication in exchange for extra local work.
b. index optimizations it is convenient to refer to graph nodes by unique names.
we use names of the form function location variable to refer to the value of a given variable at a particular numbered location of a given function .
location numbers are derived from a simple intraprocedural numbering of cfg nodes.
local variables names are systematically renamed to be globally unique.
in practice these names are interned and mapped into unique id numbers suitable for use as index o sets.
unfortunately the sheer number of such unique names would require an unacceptably large string intern table.
to our knowledge this problem has not previously arisen in popular semantic web data sets.
relative to those graphs our data set contains a much larger number of nodes that are much less densely connected most of our nodes have only one incoming and one outgoing edge.
we optimize the string intern pool and data indices by treating function names as namespaces.
location numbers and variables are tuples in those namespaces.
thus rather than interning a complete function location variable string we instead intern and assign id numbers to just the function and variable names.
we then combine these with the location already numerical to form a unique triple of numbers.
this triple can then be used as the key to look up the value of a given variable at a given location in a given function in various hexastore indices.
5c.
graph saturation the main analysis iterates over the set of all assignments after applying the program transformations described in section ii.
for each of these assignments we perform two graph saturations as described in section iii one determines the new value of the variable after the assignment while the other determines the previous value of the same variable before the assignment.
we refer to this pair of saturations as one analysis instance .
during each analysis instance we maintain a work list with recently discovered edges so that we only look for new pattern matches where new discoveries were made.
after each instance completes we print its results for diagnostic purposes then continue to the next assignment.
in practice variables are often overwritten by constants.
in this case saturation to determine the variable s new value completes within one step.
saturation to find the old value commonly takes much longer.
the main analysis operates on a graph representation with implicit identity edges.
implicit flows are materialized as needed to match inference patterns from figure but are never persistently stored in memory or on disk.
3new edges inferred during saturation are always fully explicit and ultimately comprise the bulk of the saturated graph as shown in table i. d. global variable bypass assignments to global variables are rare most global variables flow unchanged through nearly all functions except for the few places where one or another is explicitly overwritten.
if saturation leads through many function calls with many edges to traverse we may add a vast number of edges without receiving any new information.
however if we know in advance that certain graph regions do not modify certain global variables we can bypass those areas entirely during saturation.
by avoiding this unnecessary work we can reduce both time and memory requirements while preserving correctness.
to achieve this we use several pre analyses to determine which functions modify which global variables.
one intraprocedural analysis determines which global variables may or must be modified directly by each function.
a second intraprocedural analysis determines which functions may or must be called directly from within each function.
during graph saturation our analysis monitors which specific variable corresponds to a given inferred edge.
when saturation could traverse into a called function figures 3c to 3e we consider whether the resulting edge corresponds to a global variable that must never be changed during that call.
this requires computing an interprocedural transitive closure across the intraprocedural may must facts recorded earlier.
hexastore s indices are ideally suited to computing transitive closures such as these using a number of queries linear in the size of the result set .
hexastore also has the advantage of being able to compute this information on demand when needed by the saturation analysis.
intermediate inferences are memoized for possible reuse during later graph saturation iterations.
3this approach is analogous to a video player that decompresses and displays video frames on the fly without ever storing the entire decompressed stream.if we determine that the global variable in question would not be modified during the call then we bypass the call entirely.
we do not descend into the callee as suggested by figures 3c to 3e.
instead we bridge the global variable s value across the call as an inferred identity flow.
the e ect is similar to that of the hoist justified pattern in figure 3g but without spending time and memory to find a matched x yflow across the callee.
e. unreachable code after infinite loops linux intentionally contains numerous infinite loops immediately after code that detects fatal errors.
without treating these carefully our predominantly backward analysis might discover extra flows of values originating in code that could never actually run.
to exclude these we impose an extra reachability check whenever saturation discovers an assignment from a constant to a variable.
the reachability check determines whether the assignment itself can be reached from the entry of the containing function.
this check is performed on demand within our analysis.
we check intraprocedurally only we do not attempt to filter out unreachable code that follows a call to a non returning function.
however this simple intraprocedural check proves su cient in practice.
f .
memory and disk management our analysis tool is very flexible in how it uses memory and disk storage.
we can leave the initial graph in memory while keeping inferred edges in memory only up to a certain number.
after that we can discard inferred edges possibly rediscovering them later or instead add them to persistent disk storage.
as described in section iv a writing each discovered edge to disk one by one is prohibitively slow.
batched updates however are quite practical.
another option is to leave the initial graph persistently on disk and to keep some or all discovered edges in memory.
intuitively while the analysis can cater to almost arbitrary memory constraints the more data that can be managed in memory the faster the analysis runs.
v .
e xperimental evaluation we have conducted several experiments to evaluate the usefulness of our database backed approach.
we introduce the benchmarks and hardware configuration used for our experiments in section v a. section v b discusses correctness with respect to a reference implementation.
the remainder of this section presents our experiments with di erent analysis configurations and varying memory usage constraints.
our first experimental setup section v c compares the performance of the all in memory configuration of our tool to the in memory error propagation analysis of rubio gonz lez et al.
.
our second experiment section v d demonstrates an optimized configuration strategy for programs whose initial edges fit easily in memory but whose many inferred edges must periodically be flushed to disk.
lastly section v e we introduce a complementary configuration for programs with very large initial graphs but relatively few inferred edges.
6table i sizes of programs analyzed edges programlines of code assignments initial inferred ext3 reiserfs linux linux firefox a. benchmarks and hardware configuration we evaluated our implementation on a suite of benchmarks of varying size and complexity.
our ext3 and reiserfs benchmarks are parts of the linux .
.
.
operating system kernel that implement specific file systems.
we include these relatively small examples because analysis of error management in file system code was the main focus of prior work in this area.
our linux and linux benchmarks represent a much larger portion of the linux .
.
.
kernel.
these two di er only in that the linux benchmark excludes a single assignment that consistently required an unusually long time to analyze.
this assignment appears deep within a widely used memory management module its pre assignment value can come from myriad other locations throughout the kernel.
as it happens analysis ultimately showed that this specific assignment does not constitute an error propagation bug.
the incrementallyreduced linux benchmark is a practical analysis target if one is willing to skip a single di cult but ultimately nonbuggy assignment.
4the full linux benchmark shows expected performance if everything must be checked without even a single exception.
these four linux derived benchmarks are written in c. of course error propagation analysis is also important beyond linux and c. our firefox benchmark is the complete source code to the open source web browser.
firefox is written in c but uses the return code idiom instead of exceptions.
table i summarizes the size and complexity of our data sets measured in various ways.
the nature of this complexity is very di erent for the linux and firefox benchmarks.
firefox has roughly equal numbers of initial and inferred edges meaning that the initial graph accounts for a significant fraction of firefox s total memory needs.
by contrast linux s initial graph is one third the size but has twice as many assignments and analysis of these infers one hundred times as many edges.
thus analyzing linux puts a much greater burden on e cient management of inferred edges.
this also suggests that flows in linux are significantly longer and more complex than those in firefox.
experiments were run on one .
ghz cpu of a way intel xeon desktop workstation with gb of ram gb of swap space and a commodity rpm sata hard drive running red hat enterprise linux .
.
in tables ii iv and v 4outliers such as this problematic assignment stand out easily in our analysis logs.
furthermore analyses are disk backed and saved per assignment.
thus one can easily stop recognize and exclude an outlier then resume without it.
ram gb columns refer to the peak memory used at any moment during the entire analysis of a given benchmark.
b. implementation and correctness we o er two front ends for converting source code into graph form for analysis.
first we have adapted a cil based front end used in prior work by adding the intraprocedural may must analyses described in section iv d .
cil handles c but not c including non standard c extensions used in the linux kernel.
second we have developed an entirely new front end derived from clang and llvm .
custom llvm passes implement the may must analyses and graph generation.
clang handles both c and c but not some c extensions used by linux .
we use the cil based front end for all linux derived benchmarks and the llvm based front end for firefox.
our goal is to perfectly replicate the analysis results of prior error propagation work while dramatically reducing memory requirements and thereby improving scalability.
to provide a basis for comparison we reran all experiments from scratch using a reference implementation provided by rubio gonz lez et al.
.
this implementation treats error propagation as a path problem over weighted pushdown systems.
it uses the wali weighted pushdown system library version .
to compute meet over all paths solutions before and after each assignment.
wali is a general framework that must be instantiated using data structures selected specifically for the problem at hand.
the wali implementation of error propagation analysis represents transfer functions also referred to as weights using binary decision diagrams bdds as implemented by the buddy bdd library version .
carefully hand tuned for performance on this problem.
in the remainder of this section we refer to this reference implementation as the wali based analysis or simply wali .
we refer to our database backed approach as the hexastore based analysis or simply hexastore .
the remainder of this section focuses on evaluating performance and scalability.
however we have also carefully checked the correctness of the analysis results in all reported experiments taking the wali based analysis as a reference.
our hexastorebased analysis results exactly agree with those of the walibased analysis at each of the assignments across all five of our benchmarks.
the only di erence observed between the two implementations consists of firefox assignments that hexastore reports but wali does not.
we have manually inspected out of these assignments.
we found that all involve synthetic assignments introduced at the end of functions to clear local variables that are about to go out of scope.
most of these local variables in turn are temporary variables introduced by our front end.
the additional assignments missed by wali then predominantly arise as side e ects of internal representations and are not a significant practical concern.
we believe these are actually unreachable code such as functions never called from the main entry point.
our hexastore based analysis works backward stopping once it reaches a constant such as eio.
unlike wali it does not try to prove that the originating constant assignment is itself reachable.
this can cause hexastore to report results for 7table ii performance of in memory analyses .
marks wal i analyses that require more than gb ofram plus gb of swap space .
ram gb time minutes program wali hexastore wali hexastore ext3 .
.
.
.
reiserfs .
.
.
.
linux .
.
linux .
.
firefox .
.
unreachable assignments that wali s forward analysis would not report.
c. in memory only a database backed approach can potentially fall back on disk if data grows too large for memory.
to establish a baseline for comparison we first experimented with a hexastore configuration that is strictly memory based.
we held all indices representing the initial graphs in memory.
we also held inferred edges in memory but checked how many we had accumulated by the end of each analysis instance i.e.
after analyzing each assignment .
if we had more than two million then we purged all inferred edges from memory and started fresh for the next assignment.
keeping inferred edges around lets us avoid some redundant work but managing large data structures adds overhead.
empirically we found that discarding after two million edges was a good balance.
unlike wali hexastore was designed with disk in mind and is not necessarily optimized for memory only performance.
we therefore expected that the wali based analysis would be significantly faster than a memory only configuration of the hexastore based analysis.
table ii shows our results comparing both time and memory required to complete each analysis.
contrary to our expectations hexastore outperformed wali on all counts.
for the smaller ext3 and reiserfs benchmarks hexastore is nearly as fast as wali and uses far less memory.
we attribute hexastore s superior performance to several factors.
as mentioned in section iv d hexastore s indices allow it to compute transitive closures very e ciently.
these indices are also very compact with the last level of each stored as a denselypacked cache friendly sorted vector.
less memory also means less time spent allocating filling and managing that memory.
hexastore succeeded on all three large benchmarks where wali failed outright due to memory exhaustion.
for the sake of completeness we also ran the wali analyses on a large dedicated server not available to most developers.
wali required gb of ram to analyze firefox.
in theory wali would require gb to analyze linux or linux .
in practice memory pressure from the operating system and other processes doomed the attempt on our developer grade workstation the wali analysis ran for several hours swapped heavily and was eventually killed by the operating system when both ram and swap were depleted.
even if ample swap space were available common wisdom holds that database managed i o outperformstable iii comparison of in memory analysis times for large benchmarks .
relative times are the ratio of hexastore to wal i. absolute minutes program wali hexastore relative linux .
.
.
linux .
.
.
firefox .
.
.
generic os swapping .
thus swapping alone is unlikely to solve the memory scalability barrier.
the large server needed for wali has faster cpus .
ghz than the humble desktop described in section v a and used for table ii.
yet hexastore completes the large analyses dramatically faster as shown in table iii.
hexastore uses just to as much time as wali requires for the large benchmarks.
d. optimized index management for many inferred edges per table ii analyzing linux entirely in memory required gb of ram.
this significantly improves upon wali for which gb of ram plus gb of swap was insu cient.
however we wished to reduce memory consumption even further to make analysis on common desktop computers feasible.
as we described in section v a the majority of memory needed to analyze linux comes from the inferred edges.
for this experimental setup we therefore maintained the relatively compact initial index in memory as well as some but not all inferred edges.
we discarded inferred edges between analysis instances once more than two million had accumulated using the threshold described in section v c. since we needed to allow this threshold to be exceeded during an analysis instance we introduced a second threshold the flush to disk threshold .
if the flush to disk threshold was exceeded at any point during saturation all inferred edges indices were immediately flushed to disk all on disk hexastore indices were rebuilt and the inmemory index representation reset.
once an index was flushed to disk newly inferred edges were maintained in memory again until the flush to disk threshold was exceeded and so on.
therefore inferred edges have to be retrieved from both the in memory indices as well as from disk.
disk is slower than memory of course.
it is therefore crucial to choose the flush todisk threshold carefully we must not exceed memory constraints but also should not waste time rebuilding the persistent indices too often.
this setup is particularly beneficial for data sets where individual analysis instances discover too many inferred edges to fit comfortably into memory.
for this setup we expected to see an upper memory consumption bound not to be exceeded but more analysis time required compared to in memory only analyses.
for firefox it did not make sense to raise the flush to disk threshold above since no firefox analysis instance ever infers more 5all times in table iii were measured using the same large dedicated server with .
ghz cpus all other experimental results in this paper used the slower .
ghz cpus of our desktop workstation.
thus the hexastore analysis times in table iii are consistently slightly smaller than corresponding times in table ii.
8table iv linux analysis performance when flushing excessive inferred edges to disk .
means never flush to disk .
programflush to disk threshold ram gb time minutes linux .
.
linux .
.
linux .
.
linux .
.
linux .
.
than edges.
however linux contains edges for one particular analysis instance.
in this case an appropriate flush to disk threshold might significantly reduce memory consumption.
table iv presents the results for this experiment.
analyzing linux with a flush to disk threshold of million edges cuts memory requirements by in exchange for tripling analysis time.
decreasing the flush to disk threshold to million does not further reduce peak memory in fact memory requirements grow slightly.
this lower threshold also increases analysis time by demonstrating that excessive flushing can be counterproductive.
some memory overhead is required to merge data accessed from disk as well as for recording interprocedural may must facts computed on demand.
this collection of facts may grow fairly large for large numbers of functions and global variables.
this is why flushing at million edges does not halve memory consumption relative to flushing at million edges.
we ran linux only with a threshold of million edges no single analysis instance infers more than million edges so a threshold of million edges would be equivalent to no threshold at all.
we found flushing at million edges increased analysis time without reducing memory consumption.
in fact .
gb of memory seems to be a lower bound for both linux and linux .
we attribute this to the accumulation of may must facts that are never discarded from memory.
e. optimized index management for many initial edges the initial graph is used frequently during analysis so keeping its indices in memory improves performance significantly.
unfortunately this may simply be impossible if the initial graph is too large.
however while hexastore maintains six indices per section iv a not all are used equally often.
our analysis works predominantly backwards so the most heavily used index is that which maps from destination nodes to edge labels to source nodes we call this the des index .
it may make sense to maintain only the initial graph s des index in memory and access all other initial graph indices from disk.
this leaves more memory available for storing indices over inferred edges.
this can aid in analyzing data sets that have a large initial graph but that infer only a moderate number of edges during each analysis instance.
our firefox benchmark is one such example.
table v shows that maintaining only the initial des index and inferred edges in memory reduces memory consumption by when analyzing firefox.
this is understandable giventable v firefox analysis performance for different initial index management strategies strategy ram gb time minutes only initial des in ram .
.
all initial indices in ram .
.
that the initial edges constitute of firefox s entire graph data.
maintaining the frequently accessed des index in memory allows the analysis to complete within a reasonable time frame of slightly less than two hours.
if all indices were accessed from disk analysis would take nearly hours.
these results are particularly striking considering that the wali based approach required over gb of ram to perform the same analysis.
with this configuration we can analyze firefox on a contemporary laptop computer within reasonable time.
for example at the time of this writing the best selling laptop on amazon.com costs and comes with gb of ram .
f .
hexastore configuration guidelines hexastore is very flexible.
it is to be expected that proper tuning is necessary to achieve optimal performance for data sets of this size.
even commercial databases require a fair amount of tuning in order to perform well.
to achieve best performance results using our hexastore based analysis we recommend adhering to the following configuration guidelines.
a purely in memory configuration is a reasonable starting point.
we recommend trying this first especially since this configuration is fastest.
hexastore s more e cient representation means that many problems that did not fit in memory before may now fit with no need for secondary storage.
if memory must be conserved though the first priority is to keep the most heavily used indices in memory.
for our predominantly backward analysis the top priority is the des index that maps destinations to edges to sources.
any remaining memory should be devoted first to other indices representing the initial graph and then to inferred edges with periodic discarding or flushing to disk as needed to keep within allotted memory bounds.
we recommend applying the configurations in the described order to find a data set optimal setup.
vi.
r elated work a scalable program analysis modular static program analysis has been proposed to reduce analysis running time and memory cost.
the idea is to analyze parts e.g.
functions of very large programs separately and then compose the analyses of these program parts to obtain information on the whole program.
one advantage of this approach is that the process may be parallelizable depending on the interactions between the di erent parts of the program.
another approach is to use sparse analysis techniques to improve scalability .
the key idea is that for a given program analysis many parts of the program may not be relevant.
excluding irrelevant parts of the program e ectively shrinks the analysis problem.
9our technique is complementary to these approaches and could be combined with them to improve scalability even further.
b datalog for program analysis the ifds style of inferring new facts from old is closely related to bottom up evaluation of datalog programs.
the inference patterns in figure could be recast as datalog inference rules as can a wide variety of other program analysis problems .
doopencodes java points to analyses in a dialect of datalog for evaluation on the commercial logicblox database engine .
direct comparison between our approach and doop is not meaningful as the two perform di erent analyses on di erent source languages.
instead one might reimplement our approach using logicblox s datalog dialect and engine or conversely implement a disk backed logicblox compatible datalog engine atop hexastore.
semmlecode uses another datalog dialect to encode a variety of program queries.
these are translated into sql and executed on any relational database .
however prior semantic web research suggests that triple stores outperform relational databases for certain graph traversal tasks such as transitive closure.
this is due to the use of highly optimized indices that significantly reduce the number of expensive joins .
reps described how to use the magic sets transformation for logic programs to convert exhaustive dataflow analyses into demand driven analogues.
this method alone is not su cient to produce our inference patterns from a na ve exhaustive formulation.
however this and other optimizations from the logic programming and deductive database communities could certainly simplify parts of that process making it easier to formulate new analyses for extreme scalability.
c large graph data and the semantic web the semantic web community actively encourages exploring new ways to manage and reason over large graph data.
one example is the billion triple challenge held annually in conjunction with the international semantic web conference iswc .
participants are provided with a data set containing a semantic web graph with one billion edges and try to come up with new applications working with this data.
another semantic web trend is to put semantic web technologies into application context thereby providing new problem solving methods to other areas.
for example the workshop on semantic web enabled software engineering swese was created to improve software development activities by applying semantic web technologies.
semantic web inference naturally requires computing transitive closures of relations.
keivanloo and rilling exploited inference engines to improve source code clone detection but did not focus on single instance scalability.
motivated by the need for web scale data management we have seen some progress on graph optimized index structures and database systems .
however in recent years research activity has shifted from improving singleinstance semantic web data management to leveraging cloud services and o oading scalability concerns to distributed storage and compute systems .
these developments bode well for long term future scalability of database backed program analyses while we have already reduced single machine resourceneeds distributing program analysis into the cloud will allow even greater leaps of scalability.
vii.
c onclusion as software grows in size and complexity main memory imposes restrictions in the scalability of program analyses.
fortunately the database community smashed through the memory barrier long ago a modern semantic web database can represent billions of relations edges among entities nodes using a tunable mix of main memory and secondary disk storage.
this suggests a way for static program analyses to break through the memory barrier as well.
we have presented a reformulation of error propagation analysis as a graph saturation problem in the style of reps et al.
s ifds framework.
our inference patterns are carefully designed to create a demand driven predominantlybackward analysis that avoids wasted e ort wherever possible.
to manage the large graphs needed for this analysis we have adapted hexastore a semantic web database.
hexastore is especially well suited to e ciently storing querying and transitively closing millions or even billions of related entities.
hexastore can be configured to use a flexible mixture of memory and disk allowing us to solve error propagation analyses in a fraction of the time and or memory required by prior work.
even when using no disk at all our hexastore based analyses of large programs finish to60 faster and use to88 less memory.
incorporating disk storage allows further memory savings in exchange for longer analysis times.
our databasebacked strategy configured to use both memory and disk can analyze over one million lines of linux in seven hours and under gb of ram a very reasonable allocation for overnight processing on any decently equipped developer workstation.
using prior approaches firefox s three million lines of code required twelve minutes gb of ram and a dedicated server to handle the workload.
our database backed approach requires something closer to a laptop it completes in eight minutes and less than gb of ram or can even be restricted to just .
gb of ram if one has two hours to spare.
using the configuration guidelines in section v f developers equipped with our hexastore based database backed analysis engine can continue to scale important program analyses up to meet the demands of large software today and into the future.
acknowledgment we thank the anonymous reviewers for their invaluable feedback.
this research was supported in part by nsf grants ccf and doe grant de sc0008699 darpa subcontract r18682 and gifts from oracle and mozilla.
opinions findings conclusions or recommendations expressed herein are those of the authors and do not necessarily reflect the views of the sponsors.
the first and third authors are deeply grateful to the organizers of dagstuhl seminar without whose kind invitations we likely would have never met married or written this paper.
10references b. hardekopf and c. lin the ant and the grasshopper fast and accurate pointer analysis for millions of lines of code in pldi j. ferrante and k. s. mckinley eds.
acm pp.
.
i. dillig t. dillig and a. aiken sound complete and scalable pathsensitive analysis in pldi r. gupta and s. p. amarasinghe eds.
acm pp.
.
k. chen and d. wagner large scale analysis of format string vulnerabilities in debian linux in plas m. w. hicks ed.
acm pp.
.
h. oh k. heo w. lee w. lee and k. yi design and implementation of sparse global analyses for c like languages in pldi j. vitek h. lin and f. tip eds.
acm pp.
.
l. li c. cifuentes and n. keynes boosting the performance of flow sensitive points to analysis using value flow in sigsoft fse t. gyim thy and a. zeller eds.
acm pp.
.
c. cifuentes n. keynes l. li n. hawes m. valdiviezo a. browne j. zimmermann a. craik d. teoh and c. hoermann static deep error checking in large system applications using parfait in sigsoft fse t. gyim thy and a. zeller eds.
acm pp.
.
b. hardekopf and c. lin semi sparse flow sensitive pointer analysis in popl z. shao and b. c. pierce eds.
acm pp.
.
o. lhot k and k. c. a. chung points to analysis with e cient strong updates in popl t. ball and m. sagiv eds.
acm pp.
.
h. yu j. xue w. huo x. feng and z. zhang level by level making flow and context sensitive pointer analysis scalable for millions of lines of code in cgo a. moshovos j. g. ste an k. m. hazelwood and d. r. kaeli eds.
acm pp.
.
b. hardekopf and c. lin flow sensitive pointer analysis for millions of lines of code in cgo .
ieee pp.
.
m. bravenboer and y .
smaragdakis strictly declarative specification of sophisticated points to analyses in oopsla s. arora and g. t. leavens eds.
acm pp.
.
e. hajiyev m. verbaere o. de moor and k. d. v older codequest querying source code with datalog in oopsla companion r. e. johnson and r. p. gabriel eds.
acm pp.
.
e. hajiyev m. verbaere and o. de moor codequest scalable source code queries with datalog in ecoop ser.
lecture notes in computer science d. thomas ed.
vol.
.
springer pp.
.
y .
smaragdakis m. bravenboer and o. lhot k pick your contexts well understanding object sensitivity in popl t. ball and m. sagiv eds.
acm pp.
.
h. s. gunawi c. rubio gonz lez a. c. arpaci dusseau r. h. arpacidusseau and b. liblit eio error handling is occasionally correct in fast m. baker and e. riedel eds.
usenix pp.
.
c. rubio gonz lez h. s. gunawi b. liblit r. h. arpaci dusseau and a. c. arpaci dusseau error propagation analysis for file systems in pldi m. hind and a. diwan eds.
acm pp.
.
f. cristian exception handling in dependability of resilient computers pp.
.
m. lippert and c. v .
lopes a study on exception detection and handling using aspect oriented programming in icse pp.
.
r. p. l. buse and w. weimer automatic documentation inference for exceptions in issta b. g. ryder and a. zeller eds.
acm pp.
.
r. miller and a. tripathi issues with exception handling in objectoriented systems in in object oriented programming 11th european conference ecoop .
springer verlag pp.
.
m. p. robillard and g. c. murphy regaining control of exception handling university of british columbia vancouver bc canada tech.
rep. .
gcc team gcc coding conventions sep. .
.
available codingconventions.html llvm project llvm coding standards oct. .
.
available docs codingstandards.html p. terdiman exceptions just say no mar.
.
.
available blog ?p b. weinberger c. silverstein g. eitzmann m. mentovai and t. landray google c style guide sep. revision .
.
.
available svn trunk cppguide.xml g. candea m. delgado m. chen and a. fox automatic failure path inference a generic introspection technique for internet applications inproceedings of the the third ieee workshop on internet applications wiapp .
san jose california ieee jun.
pp.
.
c. a. flanagan and m. burrows system and method for dynamically detecting unchecked error condition values in computer programs united states patent b1 apr.
.
t. goradia dynamic impact analysis a cost e ective technique to enforce error propagation in issta pp.
.
m. hiller a. jhumka and n. suri an approach for analysing the propagation of data errors in software in dsn.
ieee computer society pp.
.
propane an environment for examining the propagation of errors in software in issta pp.
.
epic profiling the propagation and e ect of data errors in software ieee trans.
computers vol.
no.
pp.
.
a. jhumka m. hiller and n. suri assessing inter modular error propagation in distributed software in srds .
ieee computer society pp.
.
a. johansson and n. suri error propagation profiling of operating systems in dsn .
ieee computer society pp.
.
k. g. shin and t. h. lin modeling and measurement of error propagation in a multimodule computing system ieee trans.
computers vol.
no.
pp.
.
m. w. bigrigg and j. j. v os the set check use methodology for detecting error propagation failures in i o routines in workshop on dependability benchmarking washington dc jun.
.
c. rubio gonz lez and b. liblit expect the unexpected error code mismatches between documentation and the real world in paste s. lerner and a. rountev eds.
acm pp.
.
defective error pointer interactions in the linux kernel in issta m. b. dwyer and f. tip eds.
acm pp.
.
t. w. reps s. horwitz and s. sagiv precise interprocedural dataflow analysis via graph reachability in popl r. k. cytron and p. lee eds.
acm press pp.
.
c. weiss p. karras and a. bernstein hexastore sextuple indexing for semantic web data management pvldb vol.
no.
pp.
.
c. weiss and a. bernstein on disk storage techniques for semantic web data are b trees always the optimal solution?
in the 5th international workshop on scalable semantic web knowledge base systems ssws2009 oct. pp.
.
g. c. necula s. mcpeak s. p. rahul and w. weimer cil intermediate language and tools for analysis and transformation of c programs in cc ser.
lecture notes in computer science r. n. horspool ed.
vol.
.
springer pp.
.
clang a c language family frontend for llvm nov. .
.
available http clang.llvm.org c. lattner and v .
s. adve llvm a compilation framework for lifelong program analysis transformation in cgo .
ieee computer society pp.
.
c. rubio gonz lez finding error propagation bugs in large software systems using static analysis ph.d. dissertation university of wisconsin madison aug. .
j. s. m ller b. webster and m. charlebois llvmlinux feb. .
.
available http llvm.linuxfoundation.org n. kidd t. reps and a. lal wali a c library for weighted pushdown systems aug. .
.
available http wpis wpds download.php r. e. bryant binary decision diagrams and beyond enabling technologies for formal verification in iccad r. l. rudell ed.
ieee computer society pp.
.
j. lind nielsen and h. cohen buddy a bdd package apr.
.
.
available http sourceforge.net projects buddy m. stonebraker and a. kumar operating system support for data management ieee database eng.
bull.
vol.
no.
pp.
.
amazon best sellers best sellers in laptop computers jan. .
.
available http best sellers electronicslaptop computers zgbs electronics w. r. bush j. d. pincus and d. j. siela a static analyzer for finding dynamic programming errors softw.
pract.
exper.
vol.
no.
pp.
.
p. cousot and r. cousot modular static program analysis in cc ser.
lecture notes in computer science r. n. horspool ed.
vol.
.
springer pp.
.
a. aiken s. bugrara i. dillig t. dillig b. hackett and p. hawkins an overview of the saturn project in paste m. das and d. grossman eds.
acm pp.
.
i. dillig t. dillig a. aiken and m. sagiv precise and compact modular procedure summaries for heap manipulating programs in pldi m. w. hall and d. a. padua eds.
acm pp.
.
j. d. choi r. cytron and j. ferrante automatic construction of sparse data flow evaluation graphs in popl d. s. wise ed.
acm press pp.
.
g. ramalingam on sparse evaluation representations in sas ser.
lecture notes in computer science p. v .
hentenryck ed.
vol.
.
springer pp.
.
h. chen d. dean and d. wagner model checking one million lines of c code in ndss .
the internet society .
j. whaley and m. s. lam cloning based context sensitive pointer alias analysis using binary decision diagrams in pldi w. pugh and c. chambers eds.
acm pp.
.
m. s. lam j. whaley v .
b. livshits m. c. martin d. avots m. carbin and c. unkel context sensitive program analysis as database queries inpods c. li ed.
acm pp.
.
y .
smaragdakis and m. bravenboer using datalog for fast and easy program analysis in datalog ser.
lecture notes in computer science o. de moor g. gottlob t. furche and a. j. sellers eds.
vol.
.
springer pp.
.
g. kastrinis and y .
smaragdakis hybrid context sensitivity for points to analysis in pldi h. j. boehm and c. flanagan eds.
acm pp.
.
t. w. reps demand interprocedural program analysis using logic databases in workshop on programming with logic databases book ilps ser.
the kluwer international series in engineering and computer science r. ramakrishnan ed.
kluwer pp.
.
j. whaley d. avots m. carbin and m. s. lam using datalog with binary decision diagrams for program analysis in aplas ser.
lecture notes in computer science k. yi ed.
vol.
.
springer pp.
.
m. eichberg s. kloppenburg k. klose and m. mezini defining and continuous checking of structural program dependencies in icse w. sch fer m. b. dwyer and v .
gruhn eds.
acm pp.
.
t. neumann and g. weikum rdf 3x a risc style engine for rdf pvldb vol.
no.
pp.
.
t. w. reps solving demand versions of interprocedural analysis problems in cc ser.
lecture notes in computer science p. fritzson ed.
vol.
.
springer pp.
.
j. rohmer r. lescoeur and j. m. kerisit the alexander method a technique for the processing of recursive axioms in deductive databases new generation comput.
vol.
no.
pp.
.
c. beeri and r. ramakrishnan on the power of magic j. log.
program.
vol.
no.
pp.
.
f. bancilhon d. maier y .
sagiv and j. d. ullman magic sets and other strange ways to implement logic programs in pods a. silberschatz ed.
acm pp.
.
h. alani l. kagal a. fokoue p. t. groth c. biemann j. x. parreira l. aroyo n. f. noy c. welty and k. janowicz eds.
the semantic web iswc 12th international semantic web conference sydney nsw australia october proceedings ser.
lecture notes in computer science vol.
.
springer .
i. keivanloo and j. rilling clone detection meets semantic web based transitive closure computation in proc.
raise .
ieee pp.
.
o. erling virtuoso a hybrid rdbms graph column store ieee data eng.
bull.
vol.
no.
pp.
.
d. j. abadi a. marcus s. madden and k. j. hollenbach scalable semantic web data management using vertical partitioning in vldb c. koch j. gehrke m. n. garofalakis d. srivastava k. aberer a. deshpande d. florescu c. y .
chan v .
ganti c. c. kanne w. klas and e. j. neuhold eds.
acm pp.
.
j. urbani j. maassen and h. e. bal massive semantic web data compression with mapreduce in hpdc s. hariri and k. keahey eds.
acm pp.
.
j. urbani s. kotoulas j. maassen f. van harmelen and h. e. bal owl reasoning with webpie calculating the closure of billion triples in eswc ser.
lecture notes in computer science l. aroyo g. antoniou e. hyv nen a. ten teije h. stuckenschmidt l. cabral and t. tudorache eds.
vol.
.
springer pp.
.