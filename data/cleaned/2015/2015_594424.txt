teesrep teesside university s research repository this full version available on teesrep is the authors post print version.
for full details see tlv abstraction through testing learning and validation j un sun1 hao xiao2 y ang liu2 shang wei lin1 and shengchao qin3 1istd pillar singapore university of technology and design singapore 2school of computer engineering nanyang technological university singapore 3school of computing teesside university united kingdom abstract a java class provides a service to its clients i.e.
programs which use the class .
the service must satisfy certain specifications.
different specifications might be expected at different levels of abstraction depending on the client s objective.
in order to effectively contrast the class against its specifications whether manually or automatically one essential step is to automatically construct an abstraction of the given class at a proper level of abstraction.
the abstraction should be correct i.e.
over approximating and accurate i.e.
with few spurious traces .
we present an automatic approach which combines testing learning and validation to constructing an abstraction.
our approach is designed such that a large part of the abstraction is generated based on testing and learning so as to minimize the use of heavy weight techniques like symbolic execution.
the abstraction is generated through a process of abstraction refinement with no user input and converges to a specific level of abstraction depending on the usage context.
the generated abstraction is guaranteed to be correct and accurate.
we have implemented the proposed approach in a toolkit named tlv and evaluated tlv with a number of benchmark programs as well as three real world ones.
the results show that tlv generates abstraction for program analysis and verification more efficiently.
.
introduction abstraction is perhaps the single most powerful weapon for combating the complexity in program analysis and verification.
a good abstraction of a program should be at a proper level of abstraction which is decided by the usage context.
it should have a much smaller state space so that it is subject to efficient search based analysis like model checking .
it should be an over approximation of all behaviors of the program so that we could conclude that the given program satisfies a safety property if the abstraction does.
it should be sufficiently accurate so that analysis based on the abstraction would result in few false alarms.
the challenge is how do we automatically construct such an abstraction?
in this work we propose an automatic approach called tlv which combines testing learning and validation to generating an permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
to copy otherwise to republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
copyright 20xx acm x xxxxx xx x xx xx ... .
.abstraction of a given java class.
the abstraction characterizes behaviors of any object of the class.
in a way tlv is designed to mimic programmers so as to combat the complexity of program analysis and verification.
when experienced programmers are asked to analyze a given program they often execute the program with various inputs from which among other artifacts like documentations program comments and domain knowledge they would form some initial idea on what the program does and how and then validate their guess with more test cases or through code review.
they may guess a number of times until they build a correct abstraction in the mind on what the program does.
depending on their objective they would stop the process once the abstraction allows them to accomplish their analysis goal.
the workflow of tlv is inspired by the above process as shown in figure .
the inputs are the source code of a program and optionally an artifact which tlv could use to determine the proper level of abstraction.
tlv has three phases learning validation and refinement.
in the learning phase we apply automatic testing techniques to generate inexpensively sample behavior of the class which consists of sequences of method calls.
the hope is that the test cases would cover a large portion of the complete behavior.
furthermore we adopt techniques from the machine learning community and design a learning algorithm based on the l algorithm to not only guide the test case generation but also generate candidate abstractions systematically based on the testing results.
in the validation phase we apply more heavy weight techniques like symbolic execution to validate the abstraction so that the abstraction is guaranteed to be correct and accurate.
after validation the abstraction is checked to see whether it is at a proper level of abstraction.
if it is too abstract we refine the abstraction and restart from the testing phase.
the iterative process ends when the correct and accurate abstraction is constructed.
however a correct abstraction could be completely trivial and thus useless.
in order to make sure the abstraction is useful we need to answer two questions.
the first question is what is the right model for the abstraction?
the answer decides what kind of behaviors the abstraction is capable of capturing which in turn defines what purposes the abstraction could serve.
one form of program abstraction is predicate abstraction which is particularly useful for analyzing programs with non trivial data states .
given a program and a set of predicates predicate abstraction constructs an abstraction of the program by focusing only on the truth values of a set of predicates.
in our setting predicate abstraction means to construct an abstraction of the class in the form of a labeled kripke structure i.e.
a finite state automaton whose transitions are labeled with method names and whose states are labeled with predicates.
an example is shown in figure b .
compared with other models like finite state automata this model is more expressive for 1instance using a predicate on the number of elements in a stack it c an express languages like the number of popoperations must be less than or equal to the number of push operations and more catered for classes with rich data states.
furthermore such models can be readily fed into a model checker for verification.
the second question is what level of abstraction is sufficient for the analysis.
equivalently in the context of predicate abstraction what is the set of predicates?
this question can be answered only based on the usage context.
tlv provides three different ways.
first if the abstraction is used to verify whether the class satisfies certain temporal logic formula it must be at a level which would allow us to either prove or disprove the property.
tlv extracts from the formula an initial set of predicates and then generates an abstraction as accurate as possible with respect to the predicates.
afterwards the abstraction can be verified against the given property.
in the event that a spurious counterexample is found tlv provides a way of automatically identifying a candidate predicate for abstraction refinement based on the testing results and machine learning techniques.
with the new predicate a new abstraction is constructed and this process repeats until tlv generates an abstraction which either proves or disproves the property.
however if the abstraction is used by humans the users should be able to customize the level of abstraction and tlv provides two ways to set the abstraction level manually.
that is users can either provide a set of predicates or users can choose to provide no predicate initially but then ask tlv to resolve non determinism in the abstraction through automatically generating new predicates.
the underlying idea of tlv is simple.
the task of abstracting a class is to discover all of its behavior whereas testing could be effective in uncovering behavior.
therefore we first apply testing techniques with the hope to discover a large part of the behavior inexpensively.
however simply relying on random testing is limited e.g.
for predicate coverage and thus active learning techniques are adopted to not only guide the testing process but also to construct concise candidate abstractions automatically.
only when a likely abstraction has been obtained theorem proving techniques are used to validate the abstraction.
furthermore through learning we are able to automatically discover predicates which can be used to refine the abstraction.
the idea of learning from traces of a program is not new .
neither is the idea of verifying the learned model against programs .
rather tlv combines a number of techniques for effective abstraction.
in short we make the following technical contributions.
first we develop an approach on combining testing active learning and validation to construct predicate abstractions at the proper level of abstraction.
second we propose a way of generating new predicates to refine a predicate abstraction.
third we integrate our approach in a toolkit called tlv.
we evaluate our approach using a number of programs including benchmark programs as well as three real world classes and show that tlv generates abstraction efficiently for program analysis and verification.
.
an illustrative example in this section we illustrate how tlv works using a simple example.
the only input to tlv is the bounded stack class shown in figure .
for simplicity we focus on two methods push and pop.
recall that we need a usage context in order to determine the right level of abstraction.
for now assume that the abstraction is to be used for human comprehension and the user chooses not to provide any predicate initially.
based on the assumption above the initial set of predicates is where is a special default predicate which denotes whether a failure i.e.
assertion violation or un handled exception has occurred and denotes no failure.testing learning validationjava c odetraces queriesfinal a bstractioncandidate a bstractiontraces refinementpredicates abstraction figure the high level workflow of the tlv p u b l i c c l a s s boundedstack p r i v a t e s t a t i c f i n a l i n t max size p r i v a t e i n t s i z e p r i v a t e i n t e l e m e n t s p u b l i c boundedstack s i z e e l e m e n t s new i n t p u b l i c void push i n t e l e m e n t i f s i z e max size throw new i l l e g a l s t a t e e x c e p t i o n f u l l s t a c k e l e m e n t s e l e m e n t s i z e p u b l i c i n t pop i f s i z e throw new i l l e g a l s t a t e e x c e p t i o n empty s t a c k s i z e return e l e m e n t s figure a bounded stack in java the learning phase in the learning phase tlv applies a learning algorithm similar to the l algorithm to learn a candidate abstraction relying on automatic testing techniques .
tlv drives the learning process by generating two kinds of queries both of which are slightly different from those in the l algorithm .
one is membership queries i.e.
whether a sequence of method calls would result in a particular abstract state.
the other is candidate queries i.e.
whether a candidate abstraction is correct and accurate formally defined in section .
the queries and testing results are summarized in an observation table as shown in figure a where a bracketle t a bracketri htis an empty sequence of method calls a bracketle tpop push a bracketri ht denotes the sequence of calling push afterpop.
the result column shows the abstract state after the corresponding method calls.
for instance after an empty sequence of method calls is true and calling pop right after initialization results in exception i.e.
.
notice that because methods may take parameters the same sequence of method calls may result in different abstract states as we shall see later.
based on the observation table tlv generates the first candidate abstraction as presented in figure b .
next tlv asks a candidate query is the abstraction in figure b correct?
to answer the query tlv performs random walking i.e.
randomly generates a set of tests which correspond to traces of the abstraction.
through the random walking one inconsistency between the abstraction and the class under analysis is identified.
that is the abstraction predicts that calling pop from state always results in whereas it is not the case.
for instance calling method push first and then pop results in no failure.
the inconsistency suggests that the abstraction must be modified.
in this case the observation table is updated as shown in figure c which includes the sequence a bracketle tpush pop a bracketri htand its testing result.
after more membership queries tlv constructs the candi2trace result angbracketleft angbracketright angbracketleftp op angbracketright angbracketleftp ush angbracketright angbracketleftp op push angbracketright angbracketleftp op pop angbracketright a push poppush pop b trace result angbracketleft angbracketright angbracketleftp op angbracketright angbracketleftp ush angbracketright angbracketleftp ush pop angbracketright angbracketleftp op push angbracketright angbracketleftp op pop angbracketright c push pop poppush pop d push pop push poppush pop e f igure artifacts in the 1st learning and validation iteration date abstraction shown in figure d .
the answer to the candidate query is positive and thus the learning phase terminates.
the validation phase the candidate abstraction may not be correct due to limitations of random testing.
for instance the abstraction in figure d is not correct as invoking method push at state may result in when the size of the stack equals max size.
this behavior is missing because there is no test case which invokespush more than times.
in general cases like this are hard to generate through random testing.
thus the learned abstraction must be validated and refined if necessary.
for the candidate abstraction shown in figure d two proof obligations are generated.
one is push a hoare triple which denotes that invokingpush when there is no failure always results in no failure.
the other is pop i.e.
invoking popat may or may not result in failure.
we adopt the assertion checking feature in symbolic pathfinder spf to discharge proof obligations.
first tlv modifies the push method by enclosing its method body with a try block it adds assert false to the catch block i.e.
to assert that there is no failure and adds assert true to the finallyblock i.e.
to assert the post condition it adds the pre condition to an if conditional.
the modified push method is shown in figure .
then tlv symbolically executes the modified push with both parameters element andsize as symbolic inputs.
an assertion violation is found with concrete values for the symbolic inputs element andsize .
using the concrete values as parameters for push tlv constructs a test case and executes push which results in an exception i.e.
.
thus a transition from state to is added to the abstraction.
after the proof obligation pop is also discharged the abstraction shown in figure e is guaranteed to be correct and accurate see the proof in section .
learning a candidate abstraction helps to reduce the proving effort.
if a na ve approach was used to abstract the class we would need to check satisfiability of every combination m i.e.
whether invoking mwith results in a state satisfying where and are constraints which can be formed using conjunction of the given predicates or their negations and mis a method.
the number of such combinations is exponential to the number of predicates.
the refinement phase a nondeterministic abstraction like figure e might be confusing if it is intended for humans.
for in p u b l i c void push i n t element i n t s i z e i f t r u e t r u e encodes t h e pre c o n d i t i o n t r y i f s i z e max size throw new e x c e p t i o n f u l l s t a c k e l e m e n t s e l e m e n t s i z e catch e x c e p t i o n e a s s e r t f a l s e f i n a l l y a s s e r t t r u e post c o n d i t i o n figure modified push method sz push pop push poppush pop a sz sz push pop pop push push pop push pop b figure refined abstraction where szstands for the field size stance what does it mean to say that calling popmay or may not lead to failure?
to resolve non determinism like this tlv can be instructed to identify predicates which would explain for instance when exactly calling popleads to failure.
the standard approach e.g.
as in is to partition the state based onwp pop i.e.
the weakest precondition of pop resulting in exception.
computing weakest precondition is often expensive.
instead tlv applies machine learning techniques e.g.
supporting vector machines svms to identify a new predicate.
in particular tlv gathers two groups of object states based on the test cases at state .
one group contains stack objects which would result in state after invokingpop.
the other group contains those which would result in .
tlv uses svm to generate a predicate which partitions the two groups.
the generated predicate is size which is turned intosize 0after some bookkeeping based on the fact that size is an integer .
with the new predicate we repeat the learning and validation phase and obtain the abstraction in figure b .
the level of abstraction can be determined for different usage contexts.
for instance if a temporal logic property is present i.e.
to be verified tlv would generate and refine the abstraction based on interactions with the model checker.
for instance assume the property is g push xpop x size written in state event linear temporal logic i.e.
after push andpop size 0should be always true.
the initial set of predicates is set to be size i.e.
all predicates in the property plus the default one .
through the learning and validation phase we obtain the abstraction shown in figure a .
through model checking taking the abstraction as a labeled kripke structure we found a spurious counterexample a bracketle tsize push size pop a bracketri ht which is a run of the abstraction.
to remove this spurious counterexample again the standard approach is to partition the state p based onwp pop .
tlv rather applies svm to identify a new predicate for differentiating states from which invoking popresults in state from states resulting in size .
with the generated predicatesize tlv generates a new abstraction shown in figure b .
we remark that the spurious counterexample above is ruled out by the new abstraction.
model checking the abstraction against g push xpop x size is successful and thus this abstraction serves as a proof of the property at an abstraction level which is more abstract than the code.
.
the tlv approach i n this section we present the details on how tlv generates an abstraction.
we start with defining the problem.
.
problem definition we assume a java class ccontains a finite set of instance variablesvand a finite set of methods m each of which may update variables in v. the semantics of cis a labeled transition system sc sc m t c wherescis a set of states each of which is a valuation of all variables in v sc scis the initial state tc sc m scis the transition relation such that s m s tc iff given the variable valuation s executing method mmay result in variable valuation s .
a run of the labeled transition system a.k.a.
a test of c is a finite sequence of alternating states and transitions a bracketle ts0 m0 s1 m1 mk sk a bracketri htsuch thats0 scand si mi si tcfor alli .
the sequence of method calls in the run a bracketle tm0 m1 mk a bracketri htis called a trace.
the problem is to construct an abstraction of cautomatically.
letprop be a set of propositions constituted by variables in v. we write 2propto denote the set of predicates each of which is the conjunction of a subset of propositions in prop and the negation of the rest.
for instance if prop p q 2propis p q p q p q p q .
we write the powerset of 2propas 2prop i.e.
the set of all subsets of 2prop.
a member of 2prop can be represented succinctly.
for instance the set p q p q can be represented as p i.e.
their disjunction.
we write s to denote that evaluates to true given the variable valuation s. given a set of concrete states x we writeabsprop x to denote the disjunction of all members of2propsuch thats for somes x. for instance if prop size size absprop size mapsto size mapsto issize .
an abstraction of cw.r.t.prop denoted as a is a labeled transition system sa sa m t a wheresa 2prop is a set of abstract states each of which is a subset of 2propor a special state denoting exception sa sasatisfiessc sa ta sa m sais an abstract transition relation.
the abstraction is correct if there exists s m s tcsuch thats and s imply m ta.
the abstraction is accurate if for all m taimplies there exists s m s tcsuch that s ands .
however a correct and accurate abstraction may still contain spurious runs due to broken traces i.e.
an abstract transition might be feasible locally but not globally .
we use abstract states and predicates interchangeably hereafter.
a na ve approach to obtaining ais to check whether every possible transition m where saandm mis contained in a. this is infeasible as in the worst case there are prop m prop checks where prop is the number of propositions and m is the number of methods.
thus we propose the process shown in figure to learn a. .
testing and learning tlv starts with a testing and learning phase to obtain a candidate abstraction inexpensively.
in this phase tlv can be viewed as a game between two players.
one is a learner who in order to learn asks a series of membership queries and candidate queries.
a member query asks which abstract states can be reached after a trace.
for instance in the stack example a membership query would be a bracketle tpush pop a bracketri ht.
after multiple membership queries the learner makes a guess on what the abstraction is by generalizing what it has learned so far and asks a candidate query.
a candidate query asks whether a candidate abstraction is correct and accurate.
the other player is a teacher.
the teacher s job is to answer both kinds of queries.
ideally a teacher would answer a membershipalgorithm t he learning algorithm input a program and a set of propositions prop output an abstraction 1letobsbe an empty observation table visited be while truedo whileo bsis not closed and the time is not up do le t trace trs.t.t tr e atio slash t tr prefixtr oftr for m mdo g enerate a membership query tr a bracketle tm a bracketri ht letx randoop tr a bracketle tm a bracketri ht obs obs tr a bracketle tm a bracketri ht mapsto absprop x g enerate a candidate query afromobs apply random walking to check a if no inconsistency found then if a lgorithm a obs visited returns true then return a else le t tr s be a counterexample to the candidate a 16obs obs tr mapsto absprop s query with all abstract states that can be reached with the given tr ace.
the teacher answers positively to a candidate query iff the candidate abstraction is correct and accurate if the answer to a candidate query is negative the teacher should provide a counterexample in the form of a concrete test case which shows the candidate abstraction is problematic.
in practice having a perfect teacher is expensive.
for instance answering a membership query would require checking whether it is feasible to satisfy any proposition in prop after a sequence of method calls which is a non trivial reachability analysis problem.
even worse answering a candidate query would require solving the abstraction problem itself.
thus instead of using a perfect teacher tlv employs a tester i.e.
an imperfect teacher to answer the queries.
tlv s algorithm is presented as algorithm .
the inputs are a program and a set of propositions prop and the output is an abstraction.
tlv maintains two data structures.
one is an observation tableobsfor storing abstract testing results and the other is a set visited for storing validation results.
the observation table obsis a tuple p e t wherep m is a set of traces e sais a set of abstract states t p eis a mapping function such that t tr means that after the trace tr the abstract state can be reached.
initially p e t andvisited are all empty line .
we writeobs obs tr mapsto to denote the operation of adding the mappingtr mapsto into the table i.e.
replacing pwithp tr replacingewithe tis updated with t tr iftrwas not in the domain of t otherwise t tr t tr .
intuitively the latter states that if we knew that after tr we can reach an abstract statet tr with the new mapping tr mapsto we now know that aftertr we can reach either t tr or .
within a certain time limit tlv tries to make the observation tableclosed by asking multiple membership queries and adding mappings intoobs line .
note that the concept of consistency in thel algorithm is irrelevant in our setting.
an observation table is closed if the setpis prefix closed and for all tr psuch thattr is not a prefix of some other trace in p i.e.
tris maximum there always exists a prefix of trsaytr psuch thatt tr t tr .
intuitively the latter means that trcan be represented by its prefix and therefore tlv does not need to test further.
since there are only finitely many abstract states trwould eventually visit a state which 4is visited by its prefix.
we remark that this definition is justified bec ause our goal is to discover as many abstract states and transitions as possible.
if the observation table is not closed there must be a tracetrsuch thatt tr is not equivalent to t tr for every prefixtr oftr.
in such a case a membership query i.e.
tr a bracketle tm a bracketri ht is generated for each method line .
in order to answer the query inexpensively tlv generates multiple test cases using random testing line .
function randoop tr is similar to the randoop algorithm .
given a membership query tr tlv generates multiple test cases calling the methods in the query one by one from the initial concrete state .
in general the methods would have multiple parameters and tlv generates arguments for every method call.
given a typed parameter tlv randomly generates a value from a pool of type compatible values.
this pool composes of a set of predefined values e.g.
a random integer for an integer type null or an object with the default object state for a user defined class and type compatible objects that have been generated during the testing process.
in order to re create the same object we store the test case which produces the object.
after generating and executing multiple test cases according to tr a bracketle tm a bracketri ht tlv collects the concrete data states reached by the test cases sayx and updates the observation table with the mapping t tr a bracketle tm a bracketri ht absprop x line .
ideally after multiple membership queries once the observation table p e t is closed tlv constructs a candidate abstraction a sa sa m t a such that sa e sais the state corresponding to the empty trace t a bracketle t a bracketri ht m taif there exists tr pandm msuch that t tr andt tr a bracketle tm a bracketri ht .
in practice with many methods in the class it might take a long time before the observation table is closed.
nonetheless with the validation phase we can construct the candidate abstraction even if the observation table is not closed.
in fact the goal is to discover every abstract behavior of the class and it is guaranteed that every behavior is discovered either during testing or validation.
thus if closing the observation table takes a long time tlv times out and constructs abased onobs.
once the observation table is closed or learning timeouts tlv raises a candidate query on whether ais correct and accurate w.r.t.
prop line .
tlv then employs a slightly different testing technique to answer candidate queries.
we associate each abstract state inawith a set of concrete states which have been generated through testing so far and satisfy .
based on these concrete states tlv uses random walking to construct test cases from each abstract state inato further explore behaviors of c line .
the testing result is then compared with ato see whether they are consistent.
ais consistent with the testing result iff for any sequence of method calls tr from a concrete state associated with an abstract state the resultant concrete states xare consistent with the corresponding abstract state reached by the same sequence of methods in a i.e.
absprop x logically implies .
there is an inconsistency iff there exists a concrete state s xsuch thats e atio slash line .
in such a case tlv constructs a pair tr s wheretr tr1 tr andtr1is the shortest trace reaching ina as a counterexample to the candidate query line which is then used to update the observation table line .
for instance assume prop size and the abstract state after trin the observation table is size i.e.
t tr size .
if after calling the methods in trin sequence the concrete states are size mapsto size mapsto size mapsto then it is consistent.
however a testing result size mapsto would be an inconsistency and the observation table would be updated so that t tr size size .
once the observation table is updated tlv again checks whether it is closed and raises membership queries if it is not until the nextalgorithm t he validation algorithm input abstraction a sa sa m t a table obs p e t setvisited output true iff ais validated for sa andm mdo if th e pair m is not invisited then c heck the proof obligation m using spf where is the disjunction of all such that m ta if a counterexample is found by spf then c onstruct a concrete state s with the counterexample and invoke monsand obtain a concrete state s ifabsprop s is not inethen le ttrbe the shortest trace in psuch that t tr updateobswith the new mappingtr a bracketle tm a bracketri ht mapsto absprop s return false else a dd a transition from toabsprop s labeled with m else a dd pair m intovisited return tr ue candidate query is generated.
once the tester answers positively to a candidate abstraction at line tlv obtains an abstraction which is correct modulo the limitation of random testing.
then algorithm is invoked to validate a line .
if it returns true a is returned line otherwise the process repeats.
the details of algorithm is presented in the subsequent subsection.
given that the number of states in a and the size of ein the observation table is bounded by prop the learning algorithm is always terminating.
furthermore we argue that amay be much smaller than this bound in practice.
firstly variables in a class are often co related which is equivalent to say that there are hidden class invariants.
due to those class invariants often not every abstract state is reachable.
for instance if a hidden class invariant isv1 v2andprop v1 v2 the abstract state v1 v2 0is infeasible.
because ais constructed based on concrete testing results those hidden class invariants are embedded inanaturally and hence awould not contain those infeasible abstract states.
secondly as mentioned given a set of concrete statesx reached by the same trace the abstract state constructed isabsprop x which would effectively collapse many abstract transitions into one.
furthermore unlike the l algorithm tlv may learn a non deterministic abstraction which could be exponentially smaller than its deterministic equivalent.
nonetheless we admit that the effectiveness of the testing technique may affect the size of the abstraction.
we skip the discussion on the complexity of the algorithm as it depends on the effectiveness of the testing techniques.
rather we show empirically in section that the learning phase is usually efficient and the generated candidate abstraction usually covers a large portion of the behavior of c. .
validation due to the limitation of random testing the abstraction learned through testing might not be correct as some behaviors of cmay never be tested.
for instance in the stack example it is unlikely 5that we could generate a test case which pushes more than tim es and thus the transition push would be missing.
however the abstraction is guaranteed to be accurate but may not be correct .
lemma .
.
algorithm returns an accurate abstraction a. proof sketch to prove that ais accurate we need to prove that for every transition m ina there exists a concrete state s such thats and invoking matswould result in a concrete states such thats .
this is guaranteed by line and in algorithm which adds a mapping into the observation table such that ift tr andt tr a bracketle tm a bracketri ht then there must be a concrete transition from a state satisfying to a state satisfying through invoking m in both cases.
afterwards we can prove the lemma based on the construction of a. square the lemma above states that every transition in acorresponds to at least one concrete transition.
next tlv checks if there are missing transitions and if there is none ais guaranteed to be an over approximation at the same time.
in the following we illustrate how the validation algorithm algorithm works.
the inputs are the observation table obsand the corresponding abstraction aas well as the set visited which contains pairs of the form m where is an abstract state and mis a method name.
the setvisited stores the successfully discharged proof obligations so far.
every time the algorithm is invoked for every pair m of abstract states exclusive of and methods tlv checks whether it is invisited line .
intuitively it is in visited iff tlv has obtained all abstract states which are reachable from by invokingm.
if it is not in visited tlv generates a proof obligation m where is the disjunction of all abstract states which are reachable from throughmina line .
the proof obligation is discharged using symbolic execution i.e.
with the help of symbolic pathfinder spf as explained in the following.
in a nutshell given a java program spf executes the code symbolically so as to see whether there is an assertion violation.
if an assertion violation is possible spf generates a counterexample which consists of the valuation of input variables and a path condition that lead to the assertion violation.
we refer interested readers to work for details on spf.
we instead present how the proof obligation is encoded as an assertion violation checking problem.
the first step of the encoding is to syntactically transform the methodmsuch that all relevant instance variables become parameters of the method.
next tlv instruments the modified method with the required pre condition and post condition .
the following illustrates how the instrumentation is done systematically.
i f t r y body of method m catch e x c e p t i o n e a s s e r t f a l s e i f e x c e p t i o n i s n o t i n f i n a l l y a s s e r t tlv first encloses the original method body with a try catchfinally block to catch all exceptions.
the try block contains the method body of m. if logically implies i.e.
asuggests that exception might be the result when we invoke method mwith precondition the try block contains no assertion otherwise it contains the assertion assert false .
thus if an exception is not supposed to occur then the occurrence of an exception would lead to an assertion failure.
the finally block contains the assertion assert which asserts the post condition.
next tlv encloses the try catch finally block with an if conditional block.
the condition is set to be the pre condition so that spf checks only symbolic inputs which satisfy the pre condition.
the modified program is then fed to spf for assertion violation checking.if no assertion violation is found the pair m is added into visited line .
otherwise using the information returned by spf tlv constructs a test case which starts from a concrete state satisfying and results in a concrete state violating line .
note that in the actual implementation spf is configured to generate multiple counterexamples at once to reduce the number of spf invocations.
for the stack example when spf is used to prove size push size a counterexample is generated which allows tlv to construct a concrete state with element and size .
invoking method push at this concrete state results in state which violates size .
ifabsprop s is insa not a newly discovered abstract state at line tlv adds a new transition from toabsprop s .
if the abstract state absprop s was unreachable previously at line tlv updates the observation table with a new mapping tr a bracketle tm a bracketri ht mapsto absprop s wheretr i.e.
the shortest trace which reaches is a representative of all traces reaching .
with the new abstract state the observation table is no longer closed and therefore algorithm returns false line and tlv will execute the learning algorithm again to obtain another candidate.
the idea is that we always first rely on testing to discover some of the states and transitions inexpensively.
note that executing the learning algorithm again does not invalidate lemma .
as we show in the following that aremains accurate during the validation algorithm.
the validation algorithm returns true when every pair m is invisited line .
the following theorem establishes the correctness of tlv .
theorem .
.
when the validation algorithm algorithm terminates ais a correct and accurate abstraction of c. proof sketch according to lemma .
ais accurate before the validation algorithm starts i.e.
for every abstract transition m ina there is a concrete transition s m s such that s ands .
we need to prove that during the validation algorithm an abstract transition m is added to aif there is a concrete transition s m s such thats ands if there is a concrete transition s m s such thats and s the abstract transition m is ina.
is true because new transitions are only introduced at line and indirectly at line in algorithm .
in both cases is true as sis obtained from line with a concrete transition.
can be proved by contradiction.
assume s m s is a concrete transition such that s ands and m is not a transition in a. then there is a proof obligation m such that does not imply generated at line .
assume that spf works correctly then the proof must fail which contradicts the fact all proof obligations must be discharged before the validation algorithm terminates.
thus we conclude the above theorem is correct.
square in the following we discuss the complexity of the algorithm.
assume that proving with spf is terminating because the number of states inais bounded the validation algorithm always terminates.
the number of proof obligations is determined by the number of abstract states in a. in the worst case it is exponential in the number of propositions in prop .
in practice it is often much less as we show empirically in section .
the transitions in aare discovered through either testing or symbolic execution.
the more testing discovers the less symbolic execution is needed.
because testing is more scalable than symbolic execution thus by design tlv minimizes symbolic execution as much as possible.
although ais correct and accurate it does not mean that all runs in aare feasible.
for instance the run a bracketle t push push a bracketri htof the abstraction shown in figure e is infeasible.
this is essentially due to the phenomenon known as broken traces .
we use abstraction refinement to remove such infeasible runs.
.
abstraction refinement t here are two cases where an abstraction refinement is necessary.
one is that the user requires to resolve some non determinism in the abstraction.
the other is to refine the abstraction so as to prune a particular spurious counterexample identified by a model checker.
in the following we explain the latter first and show that the two cases can be solved in the same way.
the abstraction generated after the validation phase is subject to verification techniques like model checking.
assume that the property to be verified is a safety property e.g.
a bounded ltl formula constituted by propositions on instance variables in c .
because the abstraction is guaranteed to be correct if model checking based on aconcludes there is no counterexample then the same property is satisfied by c. if a counterexample is identified we need to check whether it is spurious.
if it is spurious amust be refined to exclude the spurious counterexample.
in the following we show that a new predicate can be generated based on the information tlv gathered during the learning and validation process.
we remark that finding the optimal refinement is known to be hard and is not our goal.
recall that by assumption in the setting of verifying a temporal logic formula prop contains all propositions in the formula.
let a bracketle t 0 m0 1 m1 k mk k a bracketri htbe the spurious counterexample which is a finite run of a as this property is a safety property .
because this run is spurious it must be broken at some abstract state iwherei k i.e.
invoking miat a reachable from the concrete initial state state satisfying inever results in a state satisfying certain required constraint i .
the idea is that if we are able to find a new predicate which could separate those concrete states abstracted as i which after invoking mi would result in a state satisfying i 1from those would result in a state violating i then we can construct a new abstraction with the new predicate to rule out this spurious counterexample.
for instance in the stack example shown in section the spurious counterexample is a bracketle tsize push size pop a bracketri ht.
it is sufficient to rule out the run if we could find a predicate separating those concrete states associated with abstract state size 0into two groups one resulting in afterpopand the other resulting in size 0afterpop.
thus the problem is to find a classifier for two sets of states which can be solved using a machine learning based approach .
in the case of resolving a non determinism as requested by the user by definition we have one abstract state at which calling the same method would result in two different abstract states.
thus the task of resolving the non determinism is similarly to find a classifier for two sets of states at the abstract state.
in the following we briefly explain how support vector machines svms is used to find the classifier.
during the process of generating the abstraction tlv associates a set of concrete states for each abstract state which can be partitioned into two groups accordingly.
for instance in the stack example above one group contains stack objects with size for which there is no exception after pop and the other contains a stack object with size for which an exception occurs after pop .
with these two groups say xandy tlv tries to identify a classifier.
formally a classifier for xandyis a proposition such that for all x x xsatisfies and for ally y andy does not satisfy .
tlv finds the classifier automatically based on techniques developed by machine learning community e.g.
svm.
as long asxandyare linearly separable svm is guaranteed to find a classifier i.e.
a hyperplane separating xandy.
furthermore there are usually more than one classifiers.
in this work tlv favors the optimal margin classifier if possible.
this separating hyperplane could be seen as the strongest witness why the two groups are different.in order to use svm to generate classifiers each element in x orymust be casted into a vector of numerical types.
in general there are both numerical type e.g.
int and categorical type e.g.
string variables in java programs.
thus we need a systematic way of mapping arbitrary object states to numerical values so as to apply svm techniques.
furthermore the inverse mapping is also important to feedback the svm results to the original program.
we leverage our earlier approach to generate a numerical value graph from each object type and apply svm techniques to values associated with nodes in the graph level by level.
we illustrate our approach using an example in the following.
recall that one group contains stack objects with size and the other contains a stack object with size .
tlv first extracts two sets of feature vectors from the two groups using the first level features i.e.
features which can be accessed using the stack object and no other