a comparative study to benchmark cross project defect prediction approaches steffen herbold alexander trautsch jens grabowski university of goettingen insititute of computer science g ttingen germany herbold alexander.trautsch grabowski cs.uni goettingen.de extended abstract cross projectdefectprediction cpdp asameanstofocusqualityassuranceofsoftwareprojectswasunderheavyinvestigation inrecentyears.however withinthecurrentstate of the artitis unclearwhichofthemanyproposalsperformsbestduetoalack ofreplicationofresults anddiverseexperimentsetupsthatutilize different performance metrics and are based on different underlyingdata.withinthisarticle weprovideabenchmarkfor cpdp.
our benchmark replicates cpdpapproaches proposed by researchers between and .
through our benchmark we answer the following research questions rq1 whichcpdpapproaches perform best in terms of f measure g measure auc and mcc?
rq2 doesany cpdpapproachconsistentlyfulfilltheperformance criteria for successful predictions postulated byzimmermann et al.
i.e.
have at least .
recall .
precision and .
accuracy?
rq3 what is the impact of using only larger products 100instances withacertainbalance atleast5 defective instances and at least non defective instances on the benchmark results?
rq4 whatistheimpactofusingarelativelysmallsubset of a larger data set on the benchmark results?
weidentified5publicdatasets whichcontaindefectdataabout 86softwareproductsthatweusedtoanswertheseresearchquestion.theadvantageofusingmultipledatasetswasthatwecould increasethenumberofsoftwareproductsand thereby increasethe external validity of our results.
moreover we wanted to use multipleperformancecriteriafortheevaluationofthe cpdpapproaches.
therefore rq1ranksapproachesnotjustusingasinglecriterion butusingthefourperformancemetrics auc f measure g measure andmcc.existingapproachesfortherankingofstatisticallydifferentapproachesneitheraccountforsoftwareproductsfromdifferent data sets nor multiple performance metrics.
therefore we defined anewapproachforthecombinationofseparaterankingsforthe performance criteria and data sets into one common ranking.
figure1depictstheresultsforrq1.theresultsshowthatanapproachproposedbycamargocruzandochimizu performsbest and even outperforms cross validation.
moreover our results show permission to make digital or hard copies of part or all of this work for personal or classroom use is granted without fee provided that copies are not made or distributed forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation onthefirstpage.copyrightsforthird partycomponentsofthisworkmustbehonored.
for all other uses contact the owner author s .
icse may june gothenburg sweden copyright held by the owner author s .
acm isbn .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
trivial fixcanfora13 modeprandom randomryu14 vcbsvmnam13 nbuchigaki12 leliu10 gpmenzies11 nbryu15 nbzimmermann09 nbpeters13 nbnam15 lrpeters12 nbpanichella14 codep bnzhe13 rfwatanabe08 nbkawata15 nbkoshgoftaar08 nbphe15 nball nbturhan09 nbherbold13 netyzhang15 maxvotema12 nbpeters15 nbamasaki15 nbcv rfcamargocruz09 nb .
.
.
.
.
mean rankscoreapproachranking of approaches using auc f measure g measure and mcc figure mean rank score over all data sets for the metrics auc f measure g measure and mcc.incasemultipleclassifiers were used we list only the result achieved with thebest classifier.
thatonly6ofthe24approachesoutperformoneofourbaselines i.e.
using all data for training without any transfer learning.
regardingrq2 wedeterminedthatpredictionsonlyseldomlyachieve a high performance of .
recall precision and accuracy.
the best cpdpapproaches only fulfill the criterion for of the products i.e.
.
ofthetime.thus cpdpstillhasnotreachedapointwhere the performance of the results is sufficient for the application in practice.
rq3andrq4wereusedtoseeifresultsareaffectedbysubsetting data asisoftendonefordefectpredictionexperiments.forrq3 i.e.
usingalargesubset wedeterminednodifferencebetweenusingall dataandusingthesubset.forrq4 i.e.
usingasmallsubsetofof data we found that there are statistically signifcant differences inreported performances of up to .
thus the use of small subsets should be avoided.