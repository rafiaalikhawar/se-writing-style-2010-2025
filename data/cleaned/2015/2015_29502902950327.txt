crash consistency validation made easy y anyan jiang haicheng cheny feng qiny chang xu xiaoxing ma jian lu state key lab.
for novel software technology nanjing university china dept.
of computer science and technology nanjing university china ydept.
of computer science and engineering the ohio state university united states jiangyy outlook.com chen.
qin.
osu.edu changxu xxm lj nju.edu.cn abstract software should behave correctly even in adverse conditions.
particularly we study the problem of automated validation of crash consistency i.e.
le system data safety when systems crash.
existing work requires non trivial manual efforts of specifying checking scripts and workloads which is an obstacle for software developers.
therefore we propose c3 a novel approach that makes crash consistency validation as easy as pressing a single button.
with a program and an input c3automatically reports inconsistent crash sites.
c3 not only exempts developers from the need of writing crash site checking scripts by an algorithm that computes editing distance between le system snapshots but also reduces the reliance on dedicated workloads by test ampli cation .
we implemented c3as an open source tool.
with c3 we found bugs in open source software that have severe consequences at crash and of them were previously unknown to the developers including in highly mature software e.g.
gnu zip and gnu coreutils sort and popular ones being actively developed e.g.
adobe brackets and t exstudio .
ccs concepts software and its engineering !software reliability keywords file system crash consistency software reliability .
introduction .
crash consistency validation quality and reliable software is expected to behave correctly even in adverse conditions.
unfortunately adverse conditions are relatively infrequent in practice and some may 1this work was done when yanyan jiang was a visiting student at the ohio state university.
chang xu and xiaoxing ma are the corresponding authors.
appl i c a t i o n fi l e s ys t e m dr i v e r lo g g e r i nput wo r kl o a d ge ne r i c o r a c l e te s t a mpl i fic a t i o nche c k e r spe c i fie d b y de v e l o pe r ge ne r a t o r bug r e po r t figure the work ow of crash consistency validation.
white background cells denote the work ow of existing work .
in comparison c3introduces generic oracle blue test ampli cation red and avoids user speci ed checker dashed grey .
even be tricky that developers are not aware of their existence leaving hidden time bombs in the software.
once such adverse conditions are triggered the consequences can be entirely out of control maybe as minor as a mobile app crash caused by an uncaught exception or as severe as causing billions dollars of economic cost caused by a race condition in the blackout in .
in this paper we focus on the particular issue of crash consistency which is an important property for any software that persists data.
crash consistency requires the application data e.g.
documents data and con gurations to be recoverable even if the system crashes .
crash consistency is of signi cant importance because as the software becomes widespread any issue will eventually be exposed simply because of the law of large numbers and crash inconsistency may lead to severe consequences.
it would be shocking if your favorite document editor destroys your paper draft when your pet accidentally hits the hardware reset button at le saving.
however developers oftentimes fail to provide crash consistency as they often lack of knowledge on the crash behavior of the le operations and their underlying le system.
even experienced developers leave crash consistency bugs in their mature software systems .
crash consistency can be validated using semi automatic tools that simulate the crash behavior of a le system .
these approaches share a common work ow figure the program under test e.g.
a database implementation is fed with test inputs or workloads the program execution s le system or i o operations are logged simulated permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
copyrights for components of this work owned by others than acm must be honored.
abstracting with credit is permitted.
to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
request permissions from permissions acm.org.
fse november seattle wa usa c acm.
... .
table possible recovered crash sites of ted text editor.
a le is opened and saved once.
crash sites would be more complicated if multiple les are saved for multiple times and specifying of what are correct is a di cult task for its developer.
category original file status backup file status consistent?
explanation c1unmodi edn axsave operation failed with the undamaged original le c2 corrupted c3 unmodi edup to date xrecoverable failure with the up to date backup le c4 deleted c5 deleted corrupted data loss c6 up to date n a x the up to date original le crash le system images crash sites are generated using the log and each crash site is checked against a manually speci ed checking script e.g.
the database s acid checker for crash consistency.
while being e ective in disclosing crash consistency bugs in data storage systems with well de ned crash semantics existing approaches heavily rely on developers manual efforts making them cumbersome to use in practice.
to make crash consistency validation easy the rst challenge test oracle is that existing techniques require developers to specify checking scripts to determine consistency of a crash site.
however they have no idea of crash consistency and are not trained for specifying such property.
the second challenge test input is that the existing test inputs usually test cases for functional validation may not be su cient to reveal crash consistency bugs.
.
how to make it easy?
in this paper we propose the crash consistency checker c3for short to automatically validate crash consistency of application software.
c3makes crash consistency validation as easy as clicking one button.
given a program with an input usually a simple use case c3either certi es the execution to be crash consistent or reports an inconsistent crash site for further inspection.
we present the motivation the challenges and the overview of c3in section .
toremove the manual e orts of writing checking script s we devise a generic test oracle at le system level instead of application level for validating whether a crash site is consistent.
we observed that developers usually expect the le system snapshot after a meta data operation e.g.
directory operations le close and fsync to be consistent.
accordingly we de ne crash sites that can be aligned with such a consistent snapshot via simple recovery operations to be consistent.
the oracle fully automates the crash consistency validation procedure exempting developers from writing the checking scripts that relates to the program semantics.
automating the validation is not su cient to reveal many crash consistency bugs.
we observed that a le system implementation may enforce crash consistency by chance e.g.
truncate and overwrite a small le causing both manualspeci ed checking script and our generic oracle to miss a crash consistency bug.
such bugs can only be manifested by dedicated workloads e.g.
a su ciently large input le which are di cult for developers to provide in practice.
toreduce the reliance on dedicated workloads we further propose test ampli cation that injects benign le system synchronization operations in the middle of a program execution to break such accidental atomicity so that our generic test oracle can disclose more crash consistency bugs.
tech nical details are discussed in section .
we implemented c3prototype tool made it publicly available and open source and hope it will help developers discover more crash consistency bugs early.
our c3implementation adopts non intrusive system call instrumentation and virtual device that are transparent to the program and the le system.
almost any program written in any language running on any le system can be validated by our tool.
the implementation decisions are discussed in section .
we conducted experiments on popular open source programs to evaluate the e ectiveness and e ciency of c3.
we discovered crash consistency bugs in subjects where were previously unknown cannot be manifested without our test ampli cation .
all the bugs lead to severe consequences data loss or corruption .
some bugs are from highly mature software e.g.
gnu zip gnu coreutils sort or from popular ones under active development e.g.
github atom adobe brackets and jedit .
evaluation results also show that c3is easy to use and consumes a ordable resources.
the evaluation is presented in section .
finally we summarize the lessons learned in our experiments and communications with the open source community in section followed by related work and conclusion in sections and respectively.
.c3in a nutshell .
two motivating examples we demonstrate the challenges of crash consistency validation by two real world crash consistency bugs discovered byc3 both were previously unknown and have severe consequences.
inconsistent crash sites can be manifested on a typical linux distribution with ext4 le system with default settings which represents a typical user s environment.
.
.
ted text editor productivity software manages user data such as documents photos and settings.
such contents should be handled with extreme care as corrupting them can lead to catastrophic consequences.
the following simpli ed le saving code is from the ted text editor on android which has more than 100k installations 1backuppath path .tmp 2textfileutils.writetextfile backuppath content 3deleteitem path 4renameitem backuppath path 134at a rst glance this code seems to be crash safe le contents are rst saved to a temporary le the original le is then deleted followed by a renaming of the temporary le.
the developer expected that whenever the system crashes at least one from the original le and the backup le will remain in the le system.
such expectation lays on the assumption that each le system operation is processed in order and immediately takes e ect.
unfortunately this assumption is not valid as both le system and device driver reorder requests for performance.
there is no ordering guarantee between the system calls write intextfileutils.writetextfile and unlink indeleteitem causing the original le being deleted before the backup le contents are persisted.
the le system after crash recovery may contain a single corrupted le byte indicating a catastrophic data loss.
to ensure the ordering between such le system operations in the example one can either insert a le system ush call fsync after the le contents being written or remove the deleteitem line ext4 le system on android provides strong consistency guarantee for renaming .
our patch is already merged by the developers1.
this example demonstrates the challenge of automatically deciding consistency of a crash site.
in the example even the simplest use case has six categories of crash sites and only one of them is inconsistent.
validating crash consistency is a non trivial task for software developers because developers often do not master the knowledge of crash consistency there can be many accesses to multiple les and consistency should be de ned for every potential intermediate state and le system accesses can be in libraries that are not well understood.
we address the challenge by proposing a generic oracle for automated crash site validation.
.
.
gnu coreutils sort sort is a command line tool that prints input lines in sorted order which appeared in the rst version of unix and is now provided by gnu s core utilities.
sort is mostly used by pipeline and redirection.
however it still provides an option to write the results to a destination le for backward compatibility of the old time sort that sorts a le in place .
the developer community also considers sorting les in place using sort data o data a valid option and this solution received the highest votes by the viewers on stackover ow2.
unfortunately the practice or option of overwriting the source le for in place sorting leads to potential data loss when the system crashes.
the destination le is rst opened and truncated to empty.
if at this time system crashes or the disk runs out of space contents in data are permanently lost.
we reported this issue to the developers.
they indicated that a completely safe and portable solution is di cult to work out due to permission owner and hard link issues and the bug is currently xed by explicitly documenting this dangerous behavior3.
surprisingly if the input le is of small size this bug cannot be triggered on the ext4 le system with the default setting.
in all possible crash sites of a pro ling run the data le ow.com questions .
c3 pr o g r a m a nd t e s t i nput cr a s h c o ns i s t e nc y v a l i da t i o n cs cs a l i g ns wi t h no escs cscs.
.
.
es es es cr a s h s i t e g e ne r a t i o n co ns i s t e nt fil e s y s t e m s na ps ho t g e ne r a t i o n te s t a mpl i fic a t i o n re po r t e d c r a s h c o ns i s t e nc y bug pr o fil e r una mpl i fie d r uns i o e v e nt l o g g e r bo unde d s e a r c h fi l e s ys t e m s na ps ho t .
.
.
figure architectural overview of our c3approach.
blue red and green components are discussed in sections .
.
.
and .
respectively.
is either unmodi ed or up to date because the le system implementation ensures the atomicity of a small le overwrite.
neither manually speci ed checkers nor our generic oracle can detect the crash consistency bug unless dedicated workloads e.g.
large les are provided.
this example demonstrates the challenge of reducing the reliance on the dedicated workloads.
among all existing approaches only alice has a chance to detect the bug without dedicated workloads.
however it relies on the correct abstract model of le systems.
alternatively we address this challenge by test ampli cation that injects benign events in the middle of program execution.
.
workflow of c3 c3adopts a methodology in crash consistency validation similar to that of storage stacks decomposing the problem into three sub problems .
test input find suitable inputs workloads that can reveal potential crash inconsistent vulnerabilities.
.
crash site generation derive possible crash sites for each test run.
.
test oracle validate each crash site s consistency.
we explain the work ow of c3in the following.
the architectural overview of c3is shown in figure .
the technical details are expanded in section .
.
.
test input the validation procedure of c3is driven by the software s functional tests use cases which are easy to obtain.
recall that existing work use dedicated workloads to nd bugs 135in storage stacks .
such workloads are usually overkill for validating application software because applications have much simpler le system access patterns than a storage system e.g.
a database or a version control system .
c3also adopts test ampli cation to further reduce the reliance on dedicated workloads because le system implementation may keep atomicity of operations by chance section .
.
.
.
.
crash site generation c3takes the standard approach to generate simulated crash sites by intercepting i o requests at runtime using a virtual ram disk.
we formally de ne the semantics of i o requests and use this de nition to derive all possible crash sites based on the speci cation of linux block layer.
based on the observation that inconsistency can mostly be manifested by dropping a small number of metadata blocks c3uses a bounded search algorithm to generate crash sites.
the algorithm enumerates the crash points and systematically drops a subset of the blocks yielding crash sites to be validated.
each crash site is mounted in the local le system and validated by our generic oracle.
.
.
test oracle the key idea of c3generic oracle is to make the expectation of software developers explicit de ning a set of consistent le system snapshots.
our observation is that programs are usually crash consistent if le system operations has atomicity and persistence otherwise the bug can be manifested without system crash which is out of our scope .
accordingly c3collects le system snapshots after metadata operations directory operations le close and fsync and consider them to be consistent.
c3certi es a crash site to be consistent if it has a small editing distance to a consistent snapshot i.e.
it can be transformed to a consistent snapshot via a series of simple recovery operations that do not involve out of thin air content creation.
in other words starting from such a crash site software users can easily fall back to a consistent state.
realizing that exact computation of editing distance is intractable we adopt an alternative relaxed necessary condition that can be e ciently computed in c3.
.
v alidating crash consistency in this section we provide in depth discussion of c3in a slightly di erent order than its work ow.
we rst discuss the de nition of expected le system snapshots ess and why they are consistent in section .
followed by how to obtain crash le system snapshots css in section .
.
then we show how to validate the consistency of a cs in section .
.
finally we discuss the design of test ampli cation in section .
.
.
defining consistent file system snapshots when developers are manipulating user generated contents they usually do have considerations of data safety e.g.
ted intentionally writes to the backup le .
therefore the gap between developer s expectation and actual implementation of le system consistency can lead to crash consistency bugs.
file systems only provide simple interface for data management and do not have transactional semantics.
as a result the highest level of le system consistency is atomicity andpersistence of system calls as if each is issuedin order and immediately persisted to disk.
file system implementations do provide such consistency semantics to its users assuming the system never crashes.
however such consistency breaks at system crash because both le system and device driver are allowed to bu er and reorder i o requests for maximized performance .
unfortunately this phenomenon is not well understood by the developers and becomes the root cause of unrealistic expectations.
for example ted developers expected bu ered data to be always persisted to disk before le deletion takes e ect but this is unfortunately the case in the target platform s le system implementation ext4 .
following this intuition we assume that the program correctly handles crashes on a strongly consistent le system.
in other words we assume that developers do not make obvious data safety mistakes that can be triggered without any system crash e.g.
deleting original le before backup is written4.
particularly it is reasonable to believe that developers have knowledge of the intermediate state after every metadata operation directory operations le close and fsync because these operations cause signi cant changes to the le system state.
therefore we consider le system snapshots of such intermediate states to be expected reference snapshots expected snapshots or ess .
ess serve as the basis of de ning consistency of a crash site.
ess are collected by a pro ling run in which system calls are intercepted.
after each le metadata operation we pause the program and traverse the le system to obtain its snapshot.
back to the ted example each of categories and corresponds to a consistent le system snapshot after meta data operation program start c1 close of backup le c3 deletion of original le c4 and renaming c6 .
an es consists of les in directories.
we de ne an es to be a set of tuples fhf1 c1i hfn cnig wherefidenotes i th le s full path e.g.
mnt crashdisk file.txt andci denotes its contents.
we atten the tree structure because crash consistency focuses on safety of le contents.
a le fi with contents ci denotes that its size is m bytes andj th byte value is bj.
the pro ling run returns e the set of all ess.
.
generating crash sites to generate crash sites for validation we do not actually power o the machine.
rather we take the standard approach of existing work by keeping a log of i o requests performed by the program and synthesizing crash sites at simulated crash points.
physical disks are notrequired to process i o requests in their arrival order for performance which is a major source of crash inconsistency .
when le system requires ordering between operations it invokes a disk barrier indicated by a req flush orreq fua ag in a linux block i o request to ush pending requests to disk.
to capture the e ect of all possible request ordering disk semantics is formalized as follows.
a disk dis a mapping from sector identi er to its actual stored data.
for each sectors2f1 g we used s to reference its data.
at runtime there is an internal queue qof requests pending to be ushed as well as auxiliary mappings uandv.u i andv i denotesi th request s sector identi er and data 4there can be data loss if the program is killed in the middle.
136algorithm crash snapshot generation algorithm input a sequence of i o requests fe1 e2 e ngand a search bound k output a setccontaining crash snapshots 1c ?
2forj2f1 ng ejis not a barrier do let d q fei ei e jg u v be the state after performingfe1 e2 e jg fe1 e i 1gare persisted indand events in qare pending to be ushed for 2f0 minfk j i 1ggdo forp f0 j i 1g jpj j i do dc d fors2p fj igdo dc dc ifdc 2cthen s mount dc c c fsg respectively and both are initially empty.
a sequence of write and barrier requests5fe1 e2 e ngare allowed to be performed on a disk with the following semantics.
.
a write request w s d tos th sector with data d. rather than being immediately persisted the request is queued in q. the notation a denotes map replacing i.e.
a an x a x x y ei w s d d q u v d q v .
a barrier request bensures all write operations before it to be persisted ei b q fep ep e qg dp d dk dk k2fp p qg d q u v dq ?
u v finally at any system state d q u v we allow the system to crash yielding a set of valid crash disks dcrash q fei ei e jg di fdg dk dk jd2dkg d q u v d crash dj this crash model describes the exact contract between a disk driver and the linux block i o layer.
it de nes all possible outcomes of reordering from a disk s perspective any e ect of reordering is equivalent to dropping a subset of requests .
furthermore our crash model assumes the physical disk to be reliable i.e.
persisted data never corrupts.
otherwise unreliable physical disk e.g.
severe faults studied in may lead to crash sites that cannot be recovered.
algorithm displays the crash site generation algorithm.
exhaustively enumerating all crash sites is too timeconsuming.
instead we use a bounded search algorithm based on the observation that dropping only a few of 5reads do not a ect contents in the disk and we do not consider them in de ning crash semantics.critical i o requests can manifest crash consistency bugs.
we accordingly enumerate the point of system crash line and those crash sites who drop at most krequests in the pending queue q lines .
the search bound kis adjustable if the time budget is limited we can bound kto be a small constant.
a su ciently large kis equivalent to an exhaustive enumeration.
generated disk images are mounted to the native le system and further checked for crash consistency.
a crash le system snapshot crash snapshot or cs is similar to an es described in section .
the crash snapshot s fhfi ciig denotes that le fihas a contents of ci.
.
validating crash sites the key insight of our general oracle is based on the following case analysis of a crash site s .sis identical to a consistent es s02e.
our basic assumption of es implies that sis consistent.
.
we can transform stos02eby performing simple recovery steps that do not involve out of thin air content creation.
an example is c2 of table where a corrupted le may contain partial data and deleting corrupted backup le yields a consistent state.
if we can obtain a consistent state from sregardless of program semantics sshould be consistent.
.
neither nor applies.
in this case non trivial recovery scheme is required to fall back to a consistent state.
if such scheme does not exist for general application software sis highly likely to be inconsistent.
this trichotomy yields a de nition of crash consistency based on the editing distance that avoids both false positives reporting a recoverable non es crash site as inconsistent and false negatives failing to report inconsistent css .
formally for a crash site s fhfi ciigto be consistent there must exists an s0 fhf0 i c0 iig2e such thatscan be transformed to s0using a bounded number of following editing operations assume that hf ci2s c andf0can be arbitrary le name other than f .
creation of an empty le s s hf0 ?i.
.
deletion of a le s snhf ci.
.
renaming of a le s snhf ci hf0 ci.
.
moving a consecutive segment of le contents s sn hf cinhf0 c0i hf b1 b m b0 p b0 q i hf0 b0 b0 p b0 q b0 m0 i where b0 p b0 q is a substring in the contents of le f0.
this de nition echoes the trichotomy a cs is consistent only if it can be aligned with an es with a small editing distance.
otherwise a large or in nite6editing distance indicates an impossible or highly non trivial recovery and we have su cient evidence to report it as inconsistent.
unfortunately this particular version of editing distance is intractable.
interested readers can refer to our npcompleteness proof in the auxiliary material.
we discovered that a relaxed de nition of alignment is already su cient for crash consistency validation and can be e ciently computed.
particularly we de ne a cs sto be consistent if scan be transformed to an es s0with a nite number of editing operations.
this relaxed de nition is equivalent to the existence of an injective mapping from every byte in the les of sto a byte in that of s0 simply because an unbounded number of 6if it is impossible to transform a cs to an es the editing distance is in nite.
137editing operations allows bytes in sto be arbitrarily permuted redistributed and deleted.
this relaxed property is also much easier to check.
formally sis consistent only if there exists s02esuch that for every byte value x hf ci2s0 fjjcj g x hf ci2s fjjcj g this alternative de nition of alignment naturally gives a linear time validation algorithm by comparing the number of each byte value s occurrences.
finally we argue that the relaxation is also e ective in crash consistency validation.
first whenever a cs cannot be aligned with an es in the relaxed de nition the editing distance must be in nite.
therefore as long as the editing distance reports no false positive of crash inconsistency so does the relaxed de nition.
in theory the relaxed de nition may misclassify an actually inconsistent cs as consistent leading to potential false negatives.
however this is expected to be rare in practice as reporting crash inconsistency only requires onewitness and the relaxed condition fails to detect the issue only if it reports false negative on all css.
there likely exists at least one inconsistent cs that is largely corrupted e.g.
le contests are mostly corrupted so our relaxed condition tends to capture it and report the crash consistency bug.
.
amplifying test inputs in the gnu coreutils sort example section .
.
the crash consistency bug cannot be manifested without dedicated workloads because the le system implementation ensures small le overwrite s atomicity by chance.
however such atomicity is not a guaranteed o er.
if the le is sufciently large we can observe inconsistent crash sites that only contain partial data and cannot be aligned to any es.
to exempt the need of dedicated workloads e.g.
huge input les we designed a test ampli cation approach.
recall the root cause of the hidden bug is not guaranteed atomicity of consecutive operations we break such atomicity by injecting system wide synchronization operation sync in the middle of a program execution.
such operations are totally benign i.e.
do not a ect the application view of the le system but can manifest the inconsistent intermediate crash sites.
test ampli cation is conducted in a single separated program execution called ampli cation run .
in the ampli cation run we intercept system calls that may silently lead to data loss ftruncate andopen which are usually contained in library code of which developers are not aware and inject async after each of them.
the i o request log collected for the ampli cation run is used for further crash site generation section .
and consistency validation section .
.
in the gnu coreutils sort example test ampli cation injects a sync after the data le is truncated yielding a cs that contains only an empty data le which cannot be aligned to any es and is correctly reported as a crash consistency bug.
.
implementation we implemented our c3approach as a prototype tool and made it public and open source7.
both the instrumentation and the i o requests logger in c3are transparent to the 7available at 2def init setup prepare init file run program 5def start program os.system brackets execute program delay .
8def do edit edit document keypress ctrl s save document keypress alt f4 exit program figure simpli ed test script for the brackets text editor in which we found crash consistency bug.
le system.
therefore c3can validate software written in any language using any libraries and running on any le system.
the idea of c3can be also implemented on other systems e.g.
by using a simulated iscsi device .
the rest of this section expands discussion of techniques used in ourc3implementation.
.
test input c3runs the program multiple times using the same test inputs.
test inputs are speci ed by test scripts which are based on a series of decorated functions in python figure .
a test script provides means to specify an initial le system snapshot how to load the program and actions to be performed at program runtime.
to further ease the testing procedure we also developed a simple record tool that captures system level ui events and automatically synthesizes a test script for gui software.
for each ampli cation run c3instruments the program using ptrace intercepting the program s control ow whenever a system call is about to execute.
c3injects a synchronous sync call if a designated point is reached and then resumes the program execution.
in this paper we do not focus on how such inputs are obtained.
even though the program may be large and complicated there usually are only a few places that interact with the le system.
we believe that simple use cases are su cient to reveal many crash consistency bugs and developers will have no obstacle providing test inputs that cover all le system operations.
.
crash site generation c3collects a i o request log for crash site generation by a virtual ram disk driver which is similar to explode .
before executing the test script the virtual disk issues an ioctl call to the driver for capturing the initial snapshot of the virtual disk.
during the test script execution the virtual disk handles i o requests like a normal ram disk and at the same time keeps an internal copy of all write and barrier requests.
after the termination of the test script these logged data are dumped back to user space via another ioctl call and css are generated using algorithm .
c3can only validate consistency of le system snapshots on the virtual ram disk.
therefore test scripts should place les to be manipulated on the virtual disk.
however the program may also modify les whose paths are hardcoded to the local le system e.g.
install path .config .
138if developers also intend to validate crash consistency of such les they can create its shadow copy on the virtual disk and replace the le in the local le system by a symbolic link.
.
test oracle c3collects a le system snapshot after each le system metadata operation and considers such ess to be consistent.
ess are collected at a separate pro ling run in which system calls are instrumented by ptrace .
es cannot be obtained by the virtual disk le system calls do not take e ect immediately .
rather the le system itself always has its consistent current view and c3peeks the le system by a simple readonly traversal of the le system.
furthermore c3does not consider a le system snapshot that contains no data to be consistent such that we can detect bugs caused by developer s accidental deletion of a le.
finally the atomicity of an es collection is guaranteed via serializing le system calls by ptrace and restricting the program to be the only process that can access the virtual disk.
each generated cs is mounted for crash consistency validation.
a cs is scanned to obtain each byte value s statistics and these values are compared against those of ess to decide whether the cs is consistent.
though the time complexity of consistency checking is linear we still adopt ngerprinting to further improve the e ciency of c3.
we associate each disk image both css and ess with the hash ngerprint8of its contents.
ess are de duplicated according to their ngerprints and the css that have been validated are immediately skipped to reduce time cost.
.
putting them together c3combines all techniques discussed in this section to realize the work ow in figure and creates crash consistency bug reports.
c3runs the program three times a pro ling run to collect ess and two test runs a normal run and an ampli cation run to collect css for crash consistency validation.
for each inconsistent cs we calculate dto be the minimum editing distance to an es in our relaxed de nition ddenotes the number of bytes that cannot be aligned .
c3reports the crash site that has a maximumdas the inconsistent crash site for the program.
the reported crash site has the most bytes that cannot be aligned and thus is most likely to be inconsistent.
if it is indeed inconsistent i.e.
a true positive developer can x the problem and run c3again for further validation.
otherwise the cs cannot be transformed to an es using simple recovery operations suggesting that a checking script is needed.
furthermore we only report an inconsistent cs when d to reduce false positives caused by a small degree of non determinism.
an example is a program that writes the timestamp into le s contents.
in this case any cs in the test run would not align with an es in the pro ling run i.e.
d because timestamp in the cs and the es are distinct.
if a cs is inconsistent it has at least one sector of data to be corrupted which likely to yield more than bytes of data .
of a sector with the size of bytes that cannot be aligned.
therefore this treatment both reduces false positives and has negligible probability of missing a truly inconsistent cs.
8we keep bit sha ngerprints such that the probability of hash collision is negligible.
.
ev aluation .
methodology we evaluated the e ectiveness ease of use and performance of c3using real world software and typical use cases.
for e ectiveness section .
.
we study whether c3 can discover crash consistency bugs in real world software which is demonstrated by an empirical study of bugs found whether test ampli cation is e ective in detecting crash consistency bugs which is denoted by the percentage of bugs that require test ampli cation to manifest and whether c3reports false positives which is presented by a qualitative study.
we also evaluated more subjects studied by alice to compare the e ectiveness of the c3oracle with the manual checking scripts.
for ease of use section .
.
we study whether the manual e orts to use c3are minor.
c3only asks the developer to specify a use case and the subsequent test ampli cation and crash consistency validation is fully automated.
for performance section .
.
we study whether the cost of c3is practically a ordable.
we measure the following quantities for each run of c3 number of es collected number of cs checked and time consumed in each phase.
we evaluate c3using applications from two categories utilities for command line use e.g.
make gzip and indent in total and productivity applications for editing user generated contents e.g.
t exstudio atom and libreo ce in total .
we select these applications because they manipulate le system data and are of signi cant popularity based on authors experiences and internet search results.
for each subject we specify onetypical use case either from the documents or from authors daily use in the test script format section .
.
the use case represents the most common usage of the software in which we believe the crash consistency bug will have the most severe consequences.
as c3is publicly available developers can easily validate crash consistency for any corner case test input.
for each use case we validate its crash consistency by c3.
if c3reports an inconsistent cs c3always outputs the crash site with the most bytes that cannot be aligned it is manually analyzed by studying the source code and the system call trace.
true positives i.e.
crash consistency bugs are reported to the developers.
all evaluations were conducted on a commodity environment for software users a virtual machine with two virtualized intel i5 cpus and 2gb of ram running ubuntu linux .
kernel .
.
the virtual disk is formatted with ext4 of default options which denotes the most prevalent le system setting.
developers can also validate crash consistency under other le system settings by modifying only one line in the c3con guration.
.
evaluation results .
.
effectiveness bugs found .
we summarize bugs found by c3in table .
among evaluated subjects even if each subject is evaluated by one simple use case c3reported inconsistent crash sites all have a su ciently large editing distance d exceeding the threshold .
all crash sites are manually analyzed with the system call traces in which we con rmed the existence of data loss or corruption.
therefore we submitted the bug reports for all subjects and the developers 139table crash consisntecy bugs discovered by c3.
bug denotes the bug issue id in the issue tracking system.
a bold bug indicates a previously unknown bug.
the amp.
column indicates the bug can only be manifested with test ampli cation.
type application loc language version bug tracker amp.
consequence d bytes utilitygnu make .0k c .
savannah incorrect build .33k gnu zip .3k c .
debbugs data loss .04k bzip2 .12k c .
.
n a email data loss .56k gnu coreutils sort .65k c .
debbugs x data loss .9k perl 801k c .
perlbug data loss .4k shelve .23k python .
.
bug tracker corruption 907productivitygimp 522k c .
.
bugzilla x data loss 188k cutemarked .8k c .
.
github x data loss .61k texmaker .7k c .
launchpad x data loss .61k texstudio .6k c .
.
sourceforge x data loss .61k ted .7k java .
github data loss .10k jedit 188k java .
.
sourceforge data loss .61k github atom .8k node.js .
.
github x data loss .61k adobe brackets 117k node.js .
.
github x data loss .61k con rmed as previously unknown bugs and as previously known bugs e.g.
the bug is xed in the current development branch but our validation is based on the latest stable release .
the remaining bug reports have yet received any responses but we believe they were also previously unknown based on the search results in the bug issue tracking system.
all bugs found by c3have severe consequences like data loss or corruption which are analyzed as follows.
in out of bugs gzip bzip2 sort perl and all productivity subjects the user s le or data can be completely lost after crash.
furthermore such bugs were triggered in practice.
for example github atom users manifested the same bug in another adverse condition when the disk runs out of space at the halfway of le saving.
gzip developers also believe data loss had happened before however the bug is not reported maybe due to its irreproducibility.
for the python standard library shelve the bug leads to corrupted database that cannot be analyzed.
the library provides three backends for data storage but c3found that none of them is crash safe.
one of such backends is gdbm whose crash consistency bug is also discussed in .
some developers believe that a sqlite backend should be provided for data safety.
for gnu make we validated the use case of incremental build of foo.c .
the inconsistent crash site contains a corrupted foo.o whose timestamp is up to date.
if we proceed with incremental build after system crash foo.c will be ignored.
such behavior leads to failed e.g.
fail to link a corrupted build target or erroneous build e.g.
corrupted le packed into the package .
implications of these real world bugs are further studied in section .
finally bugs reported by c3also received positive feedbacks from the open source community.
after we reported the bug of gzip in the mailing list the developers of lzip a functional equivalent of gzip con rmed that lzip has the same crash consistency bug.
these results evidently support that c3is e ective and promising in crash consistency validation.
test ampli cation .
column of table shows that half of the bugs cannot be manifested without test ampli cation using simple test inputs.
an interesting case is t exstudio which writes the le contents to a temporary le opens the original lewith o trunc unlinks the temporary le and writes the le contents to the original le.
surprisingly the le system implementation postpones the e ect of unlink and this seemingly obvious data loss bug cannot be observed in any possible crash site unless the le is huge.
with c3 s test ampli cation we can discover the inconsistent crash site that only contains a truncated le.
these results indicate that the test ampli cation is e ective in exempting the need of dedicated workloads.
false positive s. we did not observe any false positive in the evaluated subjects.
however c3may report false positives if the crash recovery requires non trivial e orts e.g.
in validating databases .
nevertheless false positive may not be a big issue for software developers because c3reports inconsistent cs with an explanation the cs cannot be easily transformed to an es .
by examining the cs and es the developer can quickly pinpoint the root cause of false positives and provide additional rules to lter out actually consistent crash sites that is reported by the generic oracle of c3.
comparisons with manual checking scripts .
we evaluated more subjects studied in alice .
these crash consistency bugs are discovered by manual checking scripts.
we ran them with c3using simple workloads.
for gdbm c3 correctly reported a corrupted database le.
for leveldb and lmdb c3reported false positives inconsistent snapshots that have a relatively small d .
for the reported crash sites running the default database recovery will obtain a consistent database.
for sqlite c3considers it as consistent and missed the durability bug because it relates to the database s semantics.
for git and mercurial c3did not found crash inconsistency.
the system call trace study suggests that crash may lead to corrupted data cannot be opened but data is not actually lost and may be recovered by an experienced user.
these results are expected because c3trades to some degree the e ectiveness of the tool detecting more bugs by learning the semantics of each application for the easy of use of the tool automating the crash consistency checking procedure .
.
.
ease of use we demonstrate that the e orts of using c3are minor and trivial for developers.
to validate crash consistency a devel1400 lines of code of test input scripts of subjects figure histogram of loc of test input scripts.
average loc .
oper only needs to provide c3a test script section .
that consists of an initial software setup arguments to run the program and actions to be performed at runtime for interactive programs only .
all such e orts are contained in the test script.
we show the statistics of test script loc in figure .
even if we are end users of the evaluated subjects writing such a short test script with the mean of .
lines of code takes only a few minutes of work which usually consumes less time than setting up the software from scratch.
the longest test scripts are gnu make simulating an incremental build and gnu patch generating patch les from two sets of synthesized les which are and lines of code respectively.
developers can also reuse their existing test cases by executing them in the test script.
.
.
performance we show the performance evaluation results in table which is conducted on a machine with limited computational power.
for all evaluated subjects c3 nishes the entire process in minutes which is certainly a ordable in a testing environment.
there are two major factors that impact the performance ofc3 taking le system snapshots to obtain an es and generation and validation of css.
the cs generation and validation consumes the most of time but we still consider such cost is a ordable because applications often interact with le system via limited patterns and a few test cases are su cient to reveal potential crash consistency bugs.
due to the limitation of ptrace c3cannot precisely decide which le system call is related to the virtual disk so es are collected on all possible system calls.
the results show that pro ling slightly slows the program but this is only a minor issue because the slowdown is transparent to the program as if the system call takes longer time to return .
pro ling runs of gui subjects take longer time than command line subjects because we insert one second delay between all consecutive gui operations to ensure their completion.
.
lessons learned handling le data demands caution.
file system implementations usually do not provide a strong atomicity and persistence guarantee.
therefore when user s contents are being erased even if backup had been performed the developer should be careful.
even experienced developers of mature software made mistakes e.g.
sort and gzip and many correct solutions in our subjects e.g.
vim and sed table performance evaluation results.
values in a row indicate es collected cs validated pro ling run time denoted as p. cs validation time denoted as v. and total time including initial setup three runs and cs validation respectively.
the last row displays averaged number of all evaluated subjects.
applicationamount time minutes es cs p. v. tot.
gnu make .
.
.
gnu zip .
.
.
bzip2 .
.
.
gnu coreutils sort .
.
.
perl .
.
.
shelve .
.
.
gimp .
.
.
cutemarked .
.
.
texmaker .
.
.
texstudio .
.
.
ted .
.
.
jedit .
.
.
github atom .
.
.
adobe brackets .
.
.
average all subjects .
.
.
are counter intuitive or overkill.
even worse protecting data safety is much trickier than it appears because such data erasure may implicitly happen in the underlying libraries of which the developer may not be aware.
for example python pillow provides image.save for writing an image which opens the le with o trunc .
using this function to change an image in place is a crash consistency bug9and such a pattern is quite likely to occur in an image editing software10.
furthermore developers tend to trust the crash consistency of a mature standard library which also may not be valid.
an example is python standard library shelve that uses gdbm as its backend by default which does not provide any crash guarantee.
therefore the rule of thumb is to handle le data with care e.g.
adding extra flush and fsync to ensure the persistence if performance is a secondary concern or crash consistency should be validated with tools like c3.
library support matters.
relying on developers to handle all corner cases is impractical.
it also seems impractical for libraries and le systems to provide strong consistency guarantee le operations still are the bottleneck of many applications.
rather libraries should provide means to protect data safety or explicitly document their behaviors or guarantee.
only well designed libraries can relieve the developers burden of considering le system crash behaviors.
through the communications with the open source community we learned that many frameworks provide good solutions to safely manipulate les.
for example qt provides qsavefile and gtk provides g file replace to handle le operations in the safest way possible .
we also validated these two libraries by c3and we could not nd an incon9we did not report this as a bug because pillow o ers no crash safety guarantee.
10the most famous open source image editing software gimp has a similar crash consistency bug in all versions before .
.
141sistent crash site.
therefore we strongly recommend developers to use libraries that explicitly document their safety and such safety can be easily validated by c3 in handling le data.
on the more emerging platforms however there lack crashsafe library support.
in addition to the two aforementioned python examples node.js as a server side language only provides a simple library for le system operations.
this design is valid because server programs usually persist data in a database.
however when the application domain of node.js expands such library becomes a weak link in crash consistency.
github atom developers found the crash consistency bug di cult to x because node.js lacks a portable library for safely saving a document.
therefore we recommend library developers to validate crash consistency of api use cases with tools like c3and explicitly document whether a library function provides crash consistency guarantee.
crash consistency deserves more attention.
a developer does not get rid of the crash consistency issue even if the software has nothing to do with the le system.
recall the gnu make example section .
.
in which crash may lead to a corrupted objective le that has a up to date timestamp.
it is not gnu make developer s responsibility to x the problem rather it is gcc that does not meet crash safety requirement of gnu make timestamp should not be updated until output le is persisted .
yet gcc as a compiler is not required to provide such guarantee.
the cascading e ect of a minor crash inconsistency nally leads to potentially severe consequences.
even if gcc was crash safe gnu make allows arbitrary scripts to be executed in objective le generation and nobody can guarantee crash consistency for all of them.
therefore the only solution is to alert users of such issues and start a build from scratch e.g.
by executing make clean after a system crash.
finally this example suggests that developers should receive more education on crash consistency.
we believe that the results and analyses presented in this paper will be a wake up call for general software developers to pay more attention to crash consistency.
.
related work software reliability in various adverse conditions have been extensively studied.
examples are external system events that access con icting resources combination of multiple exceptional conditions and reordered shared memory accesses in a relaxed memory model system .
this paper focuses on crash consistency the particular adverse condition of system crash.
as cpu and memory state vanish after crash crash consistency bugs are scoped in the storage stack.
the storage stack consists of layers of abstractions hardware interface device driver le system library and database and is nally used by the software.
at hardware level the robustness of physical drives is studied .
at le system level data consistency and crash recovery are extensively studied .
a le system implementation can be validated by testing or model checking .
however even if the le system survives the crash it does not guarantee atomicity and persistence of each individual le system call leading to crash consistency bugs.
our previous work devised special workloads to exposure such bugs in databases .
seminal work alice and explode introduced general frameworks to validate crash consistency for both system software and applications which largely inspired our work.
alice focuses on modeling crash behaviors across le system implementations and explode focuses on systematic exploration of execution paths that contain exceptional controlow.
however such techniques are not su cient to e ciently validate crash consistency of a wide varieties of applications.
the generic oracle and test ampli cation in c3facilitate fully automated checking of crash consistency and they are orthogonal to the technical contributions of alice and explode .
one can integrate both the generic oracle and the test ampli cation of c3into alice and or explode .
furthermore alice depends on the abstract le system behavior model extracted from a pro ling tool that may not be sound leading to false positives while any crash site reported by c3guarantees to be valid and can be manifested in practice.
recent work studied crash consistency models which resembles memory consistency models to characterize and validate crash behavior of le systems.
checking an application s crash consistency against abstract le system models is a promising future direction.
an alternative approach to crash consistency is providing transaction among system calls which can be achieved either by operating system support or by hardware assistance .
finally the ultimate solution to crash consistency is a le system implementation that has provable strong consistency guarantee atomicity and persistence for each individual le system call.
such possibility has recently been explored .
however such work is still in its early stage to be realized in performance critical production environments.
.
conclusion in this paper we present c3 a novel approach for validating the crash consistency of application software.
the generic oracle and test ampli cation facilitate the automated validation of crash consistency for application software.
evaluation on real world applications demonstrates the e ectiveness and e ciency of c3in detecting crash consistency bugs.
we not only made c3public and open source but also presented valuable lessons learned from the bugs discovered by c3and the communications with the open source community.
we hope the results in this paper will be a cornerstone for further enhancement of software reliability in terms of system crash.
.