online app review analysis for identifying emerging issues cuiyun gao jichuan zeng michael r. lyu and irwin king shenzhen research institute of the chinese university of hong kong china the chinese university of hong kong china cygao jczeng lyu king cse.cuhk.edu.hk abstract detectingemergingissues e.g.
newbugs timelyandpreciselyis crucialfordeveloperstoupdatetheirapps.appreviewsprovidean opportunity to proactively collect user complaints and promptly improveapps userexperience intermsofbugfixingandfeature refinement.
however the tremendous quantities of reviews and noisewords e.g.
misspelledwords increasethedifficultiesinaccurately identifying newly appearing app issues.
in this paper we propose a novel and automated framework idea which aims to identify emerging app issues effectively based on online review analysis.weevaluate ideaonsixpopularappsfrom google play and apple s app store employing the official app changelogs as our ground truth.
experiment results demonstrate the effective ness of ideain identifying emerging app issues.
feedback from engineersandproductmanagersshowsthat88.
ofthemthink that the identified issues can facilitate app development in practice.
moreover wehavesuccessfullyapplied ideatoseveralproducts of tencent which serve hundreds of millions of users.
ccs concepts softwareanditsengineering dynamicanalysis information systems web and social media search keywords app reviews online analysis emerging issues acm reference format cuiyungao jichuanzeng michaelr.lyu andirwinking.
.online app review analysis for identifying emerging issues.
in proceedings of icse 40thinternationalconferenceonsoftwareengineering gothenburg sweden may june icse pages.
introduction appdevelopersareeagertoknowwhatisgoingonwiththeirapps afterpublished .timelyandpreciselyidentifyingtheemerging issues of apps is of great help for app developers to update their apps such as fixing bugs refining existing features and adding new functions.
permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation on the first page.
copyrights for components of this work owned by others than acmmustbehonored.abstractingwithcreditispermitted.tocopyotherwise orrepublish topostonserversortoredistributetolists requirespriorspecificpermissionand ora fee.
request permissions from permissions acm.org.
icse may june gothenburg sweden association for computing machinery.
acm isbn ... .
reviews are direct feedback from the users who have experiencedtheapps andreflecttheinstantuserexperience .the emergingissuesdetectedfromuserreviews suchastheexisting bugs e.g.
crashes and unfavorable app features e.g.
too many ads canprovideinformativeevidenceforappdevelopersin maintaining their apps and scheduling the app updates.
for example facebook messenger received massive one star ratings the lowest rating in august accounting for nearly of all its reviewsonapple sappstore1 andsufferedalargelossofusers since the version contained severe privacy issues e.g.
accessing the photosand contact numbersin users phones .however such issues had already been flushed out with complaints from over user reviews on app store one month ago.
the situation couldbeeffectivelyalleviatediftheemergingissuesweretimelydetected from user reviews.
therefore user reviews provide an effective and efficient way to identify the emerging issues of apps which would be a significant help to the developers.
thecharacteristicsofuserreviewsmakeaccurateissuedetection verychallenging.first appreviewsaregeneratedeverydayinlarge volume.
manual analysis is prohibitively time consuming for apps withlargenumbersofreviews e.g.
facebookreceivesmorethan reviews in google play every day .
second app reviews containnumerousnoisewords suchasmisspelledwords repetitive words andnon englishwords.also theyareoftenshorterinlength sincemostofthemarewrittenbyusersviamobileterminals.third only of the reviews provide informative user opinions for app updates .
furthermore detailed and newly appearing app issues arehardtobepredefined becausetheyarediversefordifferentapps and versions.
previous research mainly focuses on reducing the manualpowerinextractingsoftwareaspectsoruserpreferences such as establishing dictionaries for preprocessing reviews filtering out non informative reviews or classifying reviews to predefined topics .
however effectively detecting emerging issues from user reviews has rarely been studied.
weproposeanovelandautomatedframework ideafordetecting emergingissues topics2basedononlinereviewanalysis.
ideatakes reviews of different versions as input.
to track the topic variations overversions anovelmethodaolda adaptivelyonlinelatent dirichletallocation is employedforgeneratingversion sensitive topicdistributions.theemergingtopicsarethenidentifiedbasedon the typical anomaly detection method.
to make the topics comprehensible idealabelseachtopicwiththemostrelevantphrasesand sentencesbasedonaneffectiverankingschemeconsideringboth semantic relevance and user sentiment.
the prioritized topic labels are the app issues identified.
finally ideavisualizes the variations ofappissuesalongwithversions andhighlightstheemergingones for better understanding.
1the app store in this paper refers to apple s app store.
2the topics and issues are semantically equal in this paper.
acm ieee 40th international conference on software engineering authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
to verify the effectiveness of idea we consider the official app changelogs as ground truth since they encompass the primary changesofthereleasesandrepresenttheissuesconcernedbydevelopers.ourexperimentsareconductedonsixpopularapps with twoof themfrom appstore andtheothers fromgoogle play.we compare ideawith the method based on olda online latent dirichletallocation oneclassicalmethodforemergingissue detection.
results indicate that the average precision recall and f score of ideaon the subject apps are .
.
and .
respectively which increases the f score of the olda based method by72.
.wealsoconductausersurveyintencent indicatingthat .
of respondents think that the identified issues of ideacan facilitate app development in practice.
moreover we apply ideato four tencent3products which serve hundreds of millions of users worldwide and confirm the effectiveness and efficiency of ideain industrial practice.
the contributions of our paper are elaborated as below.
we propose a framework called ideato automatically identifyemergingissuesfromappreviewseffectively.also idea isanonlineanalysistoolandcanprocessnewappreviews in a timely fashion.
weproposeanovelmethodcalledaoldaforonlinereview analysis whichadaptivelycombinesthetopicsofprevious versions to generate topic distributions of current versions.
wevisualizethevariationsofthecaptured emerging app issues along with versions with the emerging ones highlighted.
we publish the code and review data on website4.
weverifytheeffectivenessof ideabasedontheappreviews of six popular apps which are from different categories and platforms.thesurveyandapplicationintencentalsovalidate the performance of our framework in practice.
the remainder of the paper is organized as follows.
section describes the motivation and the background of our work.
section outlines the overall picture and details each step involved in theframework.section4illustratesexperimentresults.section5 presents the practical usage of our framework.
section discusses possible limitations with related work introduced in section .
section concludes the paper.
background and motivation .
emerging app issues for an app issue to be considered an emerging issue it must be heavily discussedinthistimeslicebutnotpreviously .figure1 a presents the issue distributions of facebook messenger in three periods march april may june and july august based on the manually labelled review samples from each period.
generally theissuedistributionsarenearlyconsistentalongwithperiods e.g.
from march april to may june in figure a .
however emerging issuescaninfluencetheissuedistributionofoneperiod creating significantdifferenceswiththoseofpreviousperiodsintermsof proportion.forexample theproportionofthecrashissuepresentsa hugeincreaseduringthejuly augustperiod.wefurtherinvestigate the number of reviews containing the keyword crash along with 3the company has many popular products such as wechat qq and honor of kings and serves billions of users worldwide.
timing and present the results in figure b .
the volume of thecrashissueshowsasuddenincreasearoundjuly august which signifiesthattheissuetendstobeanemergingissueduringthat period.
definition .
emerging issues in user reviews .
an issue in a timesliceiscalledanemergingissueifitrarelyappearsinprevious slicebutismentionedbyasignificantproportionofuserreviews in current slice.
in definition .
the time slice the degree of rarely and the significantproportion canbedefinedaccordingtodifferent situations.forexample the timeslice inthispapercorrespondsto the app version.
based on the detected emergingissues developers canlocatethebuggyfeaturesoftheirappsefficiently updatethe apps accordingly and ultimately improve the user experience.
a issue distribution in facebook messenger.
b the number of reviews containing the keyword crash .
figure illustration of emerging issues.
.
online review analysis online review analysis ora is an automated way to acquire and processuserreviewsinrealtimeasreviewsarearrivedcontinuously.
asshowninfigure2 oratakesthereviewsofslice t currentreview slice asinput andoutputsanalysisresults suchastrackinguser preferenceanddetectingemergingissues.inthisway theurgent user concernsincarnated byapp reviewscan becaptured byora inatimelymannerandfedbacktodevelopersforinstantbugfixing orfeatureimprovement.thus oraisacrucialcomponentinthe closed cycle of app development.
user reviewsonline review analysis app updatecurrent review sliceslice t slice t slice t slice t review stream... emerging issues rating changes bug tracking ... figure closed cycle for app development.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
currently mostoftheappissuesminedfromuserreviewsare manuallysettledordefined suchasprivacyandgui which are usually general categories.
although such definition facilitates the process of task assignment to individuals it is unfavorablefordetectingnewly presentedandmoredetailedissues e.g.
notification center .
thus for detecting emerging issues ora isa practicalwaydueto itstimelinessandno needforpredefined issues which has rarely been studied previously.
.
app changelogs app changelogs describe the noticeable modifications of the latest versions for attracting users to install and experience new releases.
similar to user reviews.
changelogs also correspond to specific versions.generally developerswriteintothechangelogswithinformationrelatedtowhethertheappsareaddingorremovingfeatures and whether the apps have made improvements with certain devices or to specific bugs.
figure illustrates a sample changelog of noaa radar pro a weather alerts forecast app in app store.
what s new in version .
introducing weather reporting.
the app now allows anyone to be a weather reporter.
confirm the w eather or report your weather conditions and take part in impr oving our data and forecasts.
performance improvements you won t necessarily notice but definitely enhancing your experience with the app.
figure changelog of noaa radar pro.
the rectangles highlighttwokeytermswhichrepresentthemajorchanges of version .
.
as figure indicates the new version introduces new functionality i.e.
weatherreporting andrefinesperformanceissues.the delivered changes exhibit the issues that are concerned by developers.althoughthechangelogsmaynotcoverallthemodifications to the releases they represent a lower bound and the prominent part of the changes.
hence changelog is a reasonable ground truth for verifying whether the extracted emerging issues are helpful for developers.
methodology figure framework of idea.
in this section we first outline the overall framework of idea in figure and then elaborate on the four components involved in the framework.
each time in the first stage part a in figure ideapreprocessesaversionofrawreviewsfromthereviewstream for reducing noisy words and non informative words and extracts phrasesforsubsequentanalysis section3.
.inthesecondstage partbinfigure4 theproposedalgorithmaoldacapturesthe topic distributions of each version by considering the topics in previousversions basedonwhichemergingtopicsareidentified usinganomalydiscovery section3.
.then tointerpretthetopics part c in figure ideaemploys the meaningful phrases and sentences as candidates to label each topic according to their semantic relevance and user sentiment section .
.
the topic labels are the identifiedappissues.finally partdinfigure4 ideavisualizes the appissues along with thedifferent versions andhighlight theemerging ones for better understanding section .
.
.
preprocessing since app reviews are generally submitted via mobile terminals andwrittenusinglimitedkeyboards theycontainmassivenoisy words such as casual words repetitive words misspelled words andnon informativewords e.g.
thewordssimplydescribingusers feelings .inthefollowing weintroduceourrule basedmethodsfor formatting words the phrase extraction process and our filtering method for reducing non informative words.
.
.
word formatting.
we first convert all the words in the review collection into lowercase and then stem each word intoits original form.
we employ the preprocessing method in for lemmatization.
we then replace all digits with digit .
since newtermsandcasualwordswouldcontinuouslyincreaseinuser reviews we do not employ the dictionaries provided by for avoidingover correction.we adopttherule based methodsbased on torectify repetitivewords misspelled words andnonenglish words.
.
.
phrase extraction.
since phrases mainly referring to two consecutivewordsinourpaper areemployedinpartcof ideafor interpretingtopics theyshouldbeextractedinthepreprocessing step and trained along with all the other words in part b. in this way we can capture the semantics of each phrase based on which wecanlabelthetopicswiththemostrelevantphrases.sincethe topiclabelsinphrasesshouldbemeaningfulandcomprehensible we use a typical phrase extraction method based on pmi pointwise mutual information which is effective in identifying meaningful phrases based on co occurrence frequencies pmi wi wj logp wiwj p wi p wj wherep wiwj indicatestheco occurrenceprobabilityofthephrase wiwjandp wi o rp wj represents the probability of the word wi orwj in the whole review collection.
higher pmi values exhibitthatthecombinationofthetwowordsismorelikelytobea meaningful phrase.
we extract the meaningful phrases by experimentally set a threshold for pmi.
the phrases with pmis larger than the threshold are extracted.
.
.
filtering.
thefilteringstepaimstoreducethenon informative words suchasemotionalwords e.g.
bad and nice abbreviations e.g.
asap anduselesswords e.g.
someone .non informative words are summarized by two researchers from reviews which are also referred to as predefined stop words .
the box below lists of the total non informative words due to space limitations.
the predefined stop words are filtered out together with authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
the stop words provided by nltk .
we do not employ the supervisedmethodin forfiltering sinceinthisworklabeling massivenon informativereviewsrequiresagreatdealofmanual effort.finally alltheremainingwordsandextractedphrases where thewordsineachphraseareconnectedwith arefedintothe next step for emerging topic detection.
predefined stop words cool fine hello alright poor plz pls thank old new asap someone love like bit annoying beautiful dear.
.
emerging topic detection in this section we aim to detect the emerging topics of current versions by considering the topics in previous versions.
we first introducetheproposedmethodaoldaforadaptivelyonlinetopic modeling from which we capture the topic evolutionsalong with versions.
we then present how we discover the emerging topics e.g.
anomaly topics .
.
.
aolda adaptively online latent dirichlet allocation.
online latent dirichlet allocation olda is a classic method for tracking the topic variations of text streams which models the topics of texts in one time slice based on the topics of the last slice.
however appreviewsaretypicallyshortandcontainmassivenoise words.suchreviewfeaturescaninfluencethetopicdistributionsin consecutive versions with olda and thereby decrease the performanceofemergingtopicdetection.toreducetheinfluenceofnoise words and more accurately capture the topic evolution along with versions we propose an adaptively online topic modeling method aolda.theproposedaoldaimprovesoldabyadaptivelycombining the topic distributions in previous versions.
the details are described below.
the preprocessed reviews are divided by version denoted as r r1 r2 ... rt ... wheretindicates the t th version and inputintoaoldaonebyone.inaolda eachreviewistreated as one document.
the prior distributions over document topic and topic word distributions are defined initially represented as and respectively.
determines the topic distributions of the terms in theinput.thenumberofthetopicsisspecifiedas k.forthek th topic t kis the probability distribution vector over all the input terms.
we introduce the parameter window size w which defines the number of previous versions to be considered for analyzing the topic distributions of the current version.
the overview of the model aolda is depicted in figure .
different from olda as figure shown we adaptively integrate the topic distributions of the previous wversions denoted as t ... t i ... t w for generating the prior tof thet th version.the adaptiveintegrationreferstosummingupthetopic distributions of different versions with different weights t i t k w summationdisplay i 1 t i k t i k whereidenotesthe i thpreviousversion i w .theweight t i kisdeterminedbythesimilarityofthe k thtopicbetweenthe t i th version and the t th version which is calculated by the softmax function figure5 overviewofaolda.theredrectanglewithdasheddots highlights the adaptive integration of the topics of the wpreviousversionsforgeneratingtheprior inthet thversion.r tis the review corpus in the t th version.
the dotted linesindicatethatwesimplifytheoriginallda stepsforclearness.
t i k exp t i k t k summationtextw j 1exp t j k t k wherethedotproduct t i k t k computesthesimilaritybetween thetopicdistribution t i kandthepriorofthe t thversion t k. such adaptive integration can endow the topics of the previous versionswithdifferentcontributionstothetopicdistributionsof the current version.
.
.
anomalydiscovery.
basedonthecapturedtopicevolution by aolda we identify the anomaly topics which present obvious differenceswiththoseofthepreviousversions.theidentifiedanomalytopics are regarded asemergingtopics.
to obtainthedifference ofthek thtopicsbetweentwoconsecutiveversions e.g.
t kand t k weemploytheclassicjensen shannon js divergence .
js divergence measures the similarity between the two probability distributions djs t k t k 2dkl t k m 2dkl t k m wherem t k t k .
the kullback leibler kl divergence dklis utilized to measure the discrimination from one probability distribution pto another q computed by dkl p q summationdisplay ip i log p i q i wherep i is thei th item in p. higher js divergence indicates that the two topic distributions have a larger difference.
basedonthecomputeddivergences djsbetweenthetopicsof consecutiveversions wecaptureanomalytopicsbyleveraginga typical outlier detection method .
the method assumes that thedivergences followa gaussiandistribution withthemean and variance at and 2respectively.
the anomaly topics are then detectedbysettingathreshold .forthet thversion thethreshold tis dynamically defined according to the following steps.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
.wecompute djsoftheprevious wversionsforeach topic which generatesa w kmatrix where kis thenumber of topics .
.we compute the mean and variance 2of all the values in the computed djsmatrix.
.wesetthethreshold tas t .25 wherethecoefficient .255is experimentally set for accepting of topics as anomaly topics as shown in figure .
figure gaussian distribution for anomaly discovery.
the shadedareameanstheintegralofthegaussiandistribution whichequals90 .thetopicswithdivergencelargerthan t are considered as emerging topics.
forthet thversion thetopicswithdivergenceshigherthanthe defined threshold tare regarded as emerging topics.
.
topic interpretation the topics based on aolda are represented as the probability distributions over all the input terms.
one snapshot of the top five terms to each topic is illustrated in table .
by only observing afew words it would be non trivial for developers to capture the meaningofthetopics.inthissection weaimtointerpretthetopics automatically.tointerpreteachtopic wecanutilizewords phrases sentences or entire reviews.
however single words may be ambiguous in semantics and cannot display the complete meaningsof the topic.
for example we list the top five relevant words for eachofthefourtopicsofyoutube asshownintable1 although boththewords video and work aremostrelevanttotopics2 and these two topics may deliver different meanings e.g.
topic 2isrelatedtothevideodescriptionsandtopic4isaboutloading videos.moreover onereviewmaycomplainaboutseveralissues.
forexample oneinstagramusercomplainsaboutthevideosand stories in one review videos don t post.
videos don t load.
stories disappearallthetime .therefore topiclabelsinwordsorreviews may not be helpful in accurately capturing the semantics of the topics.torenderthetopicscomprehensible weemploythemost relevant phrases and sentences to label each topic in this section.
.
.
candidateextraction.
weobtaincandidatephrasesand sentences for labeling topics.
phrasecandidate thecandidatesofthephraselabelsaregeneratedbasedontheextractedphrasesinsection3.
.
three rules are employed to identify more meaningful phrases length limit thelengthofeachwordinthephraseshouldbenolessthanthree stopwordlimit thephraseshouldnotcontainwordsthatarein thestopwordlistofnltk and3 part of s peechlimit the 5thecoefficientcanbeadjustedaccordingtothepercentageofanomalytopicstobe discovered.
we use .25here for accepting of the total topics as anomalies.table top five terms for each topic of youtube.
topic topic topic topic topic termcomment link back load say video also video reply open button even try work change work error description go back take phrase should include at least one noun or verb and no adverbs e.g.
here or determiners e.g.
the .
sentencecandidate we employthe reviews before thefilteringstepinsection3.
startingbychunkingthemintosentences based on nltk s punkt tokenizer .
then we retrieve sentences withmorethanfourwords duringwhichthenoisysentences such assofarsobad andgreatone arefilteredout.theremainingsentences are regarded as our sentence candidates.
.
.
topic labeling.
the topic labeling method is a ranking method whichconsiderstwoaspects thesemanticsimilaritybetweenthecandidatesandthetopics andalsotheusersentimentof the candidates.
semanticscore goodtopiclabelsshouldcoverthelatentmeaning of the topic .
the semantic score measures the semanticsimilarity between the candidate and the topic.
moreover the labels of different topics should be discriminative and cover different aspects of input reviews instead of delivering overlapping infor mation.
hence the semantic score of one candidate involves the semanticsimilaritytothetargettopicandalsothesemanticsimilarities to all the other topics.
a good topic label should be similar to thetargettopicandalsodifferentfromtheothertopicsinsemantics.
weemploythemethodin tomeasurethesemanticsimilarity betweenonephrasecandidate aandthetargettopic t k definedas sim a t k dkl a t k summationdisplay wp w t k logp a w c p a c p w c wherep w t k is the probability of term win the topic distribution t k.p w c andp a c denotethepercentagesoftheterms wandain the whole review collection c respectively.
the p a w c indicates the co occurrence probability of the two terms aandwin the collection c. for the sentence candidates s we utilize equation to calculate the similarity.
sim s t k dkl s t k summationdisplay wp w t k logp w s len s p w t k wherep w s canbecalculatedbythetermfrequencyof winthesentences.thesemanticscoreisthendefinedbycombining sim l t k with the similarity scores to other topics summationtext j negationslash ksim l t j which means the label lshould be semantic close to the topic distribution t kand discriminate from other topic distributions.
scoresem l t k sim l t k k summationdisplay j negationslash ksim l t j authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
wherelcan be a phrase candidate aor sentence candidate s and kis the number of topics.
the parameter is utilized to adjust the penalty for the semantic similarities to other topics.
larger signifies that the candidates that are more different from other topics.
sentiment score the topic labels should reflect users concerns.
generally the reviews with low ratings tend to express poor user experience and app issues and the reviews with longerlengths are more likely to provide valuable information to developers.
therefore we compute the sentiment score scoresenof one candidate lby combining the user ratings and review lengths scoresen l e x p rl log hl wherelcanbeaphrasecandidateorsentencecandidate.
randh denote the average user rating and the average word length of the reviews containing l respectively.
overallscore weprioritizethecandidatesforeachtopicbased on their semantic scores and sentiment scores.
the overall score score l t k is defined as score l t k scoresem l t k scoresen l wheretheweight istobalancethetwoaspects.inthismanner all the topics including the detected emerging topics are labeled with the prioritized candidates.
the topic labels are the identified app issues.foreachtopic thereisatradeoffbetweenthenumberof prioritizedlabelsandthecostofusercomprehension e.g.
toomany labelsusuallyspendusersmoretimeinunderstandingthemeaning of the topic .
according to the survey three labels are the moderate choice for users to comprehend the topics.
therefore for onetopic wechoosethe threemostrelevantphrasesandsentences respectively as labels for each topic.
.
visualization inthis part we visualizethe theevolutionof appissues i.e.
topic labels alongwithversionsforbetterunderstanding.weemployan issueriver todisplayissuevariations.figure7presentsoneexample ofyoutubeforios.alltheappissuesconstituteoneriverandeach branch of the river indicates one topic.
by moving the mouse over onetopic onecantrackdetailedissuechangesalongwithversions where the emerging issues are highlighted as shown in figure .
theappissueswithwiderbranchesareofgreaterconcerntousers wherethe widthofthek thbranchinthe t thversionisdefinedas widtht k summationdisplay alogcount a scoresen a wherecount a is the count of the phrase label ain the review collectionofthe t thversion and scoresen a denotesthesentiment score of the label a. experimentation we evaluate the performance of ideain identifying emerging app issues based on case studies.
in this section we explain how we selectthesubjectappsforexperiments theperformancemetrics andfinallythecomparisonresultsofdifferentmethods.wefocus on answering the following three research questions.
figure7 issueriverofyoutubeforios.thenumberoftopicskis set as corresponding to branches of the river.
the horizontal axis represents the app versions and the brancheswithlargerwidthsindicatethatthecorrespondingissues are more cared about by users at those versions.
rq1 what is the performance of ideain identifying emerging app issues?
rq2 can ideaachievebetter performance comparedwithother methods?
rq3 howdodifferentparametersettingsimpacttheperformance ofidea?
.
dataset weselectthesubjectappsbasedonthefollowingfourcriteria the apps are i popular apps in the app markets indicating that the developers would update their apps regularly and the user reviews can be collected from several consecutive versions ii apps from different categories and platforms to ensure the generalizationof the proposed framework iii apps with enough user reviews whichnecessitatesanautomatedanalysis andiv appswithdetailed changelogs for most versions to facilitate our validation process.
to obtain apps that satisfy the first three criteria we randomly inspect the apps ranked in the top on either app store or googleplayaccordingtoappannie anappanalyticsplatform.
onlytheappswithmorethan2 000usreviews areinspected further sincesignificanteffortisrequiredformanualanalysis.to filterouttheappsthatdonotmeetthefourthcriterion wecheck the historical changelogs of these apps.
we eliminate apps with more thanfive successive sketchychangelogs i.e.
thechangelogs provide no details related to what functionality had been changed or how the user experience was being affected.
one example of sketchychangelogsis multiplebugfixesandimprovementsacross the entire app where the bugs and improvement are not concrete enough for verifying prioritized app issues.
finally we select six subject apps with the details illustrated in table .
in table we list the subject apps with the app name category platform thenumberofreviewscrawled andthenumberofversionsinthereviewcollection.overall weobtain164 026reviews from august to april for the six apps from versions intotal.theappsaredistributedindifferentcategories withtwo authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
table subject apps.
app name category platform reviews versions noaa radar weather app store youtube multimedia app store viber communication google play clean master tools google play ebay shopping google play swiftkey productivity google play of them from app store and the others from google play.
with multiplecategoriesandplatforms thegeneralizationof ideacan be ensured.
.
performance metrics the app changelogs i.e.
our ground truth are collected from app annie.
since the prioritized issues of ideaare in phrases and sentences wemanuallyextractkeytermsfromthesechangelogsfor verification.
one example is illustrated in table with the key terms highlighted.
for each key term in changelogs we validate whether the term is covered by the prioritized issues.
since the word2vec model canaccuratelycapturethesemanticmeanings of input terms based on their vector representations we obtain the cosine similarities between each key term and the phrase level issuesbasedonthemodel.thekeytermisconsideredcoveredifits similarity to one of the issues is larger than .
.
for sentencelevel issues we split the sentences into terms including phrases and words andverify whether the key term inchangelogs can be coveredinasimilarway.weemploysuchsemi automaticevaluationmethodtofacilitateparameteradjustmentandcomparison with other methods.
weemploythreeperformancemetrics6forverifyingtheeffectiveness of idea.
the first metric is for measuring the accuracy in detecting emerging issues defined as precision e. the second is to evaluate whether our prioritized app issues including both emerging and non emerging issues reflect the changes mentioned inthechangelogs definedas recalll.weintroducethethirdmetric fhybridto measure the balance between precision eandrecalll.
higher values of fhybridindicate that changelogs are more preciselycoveredbydetectedemergingissuesandmorechangelogs are reflected in the prioritized issues.
precision e i e g i e recalll i l g i g fhybrid precision e recalll precision e recall.
wheree g andlare three sets containing the detected emerging issues thekeytermsinthechangelogs andallappissues including both emerging and non emerging issues respectively.
i denotes thenumberoftheissuesin .duringevaluation weexperimentally set the parameters as w k .
pmi and .
.
we also initialize and with .
and .
respectively.
6we do not involve recall efor validation since changelogs possibly include partial emergingissues.also precision lcannotbeconsideredbecausechangelogsmay cover items other than user concerned issues.
here precision eandrecall lmeasuretheprecisionoftheemergingissuesandcoveragerateofchangelogsbyallthe extracted issues respectively which are consistent with the standards and convincing for this task.table topic word distributions based on aolda.
v11.
v11.
v11.
topic 1link open video open video watch video work fine go work go want description click change topic 2make digit back want thing make button get would back interfacebutton use want people .
result of rq1 case study in this part we evaluate the performance of ideaby employing a case study on youtube.
we first present the results of the versionsensitive topic distributions based on aolda then exhibit the prioritized labels to interpret the topics and finally illustrate the performance of the proposed framework on youtube.
.
.
resultofaolda.
table3depictstheexampletopic word distributions based on aolda where the top five words are listed for each topic.
according to the table the general meanings of the topicsareconsistentalongwithversions.forexample topic1isrelatedtothevideoforallthethreeversions andtopic2isconstantly related to the user interface.
howev er for one topic the specific meanings may be distinguished in the three versions.
take topic asanexample.thetopicmaydiscussthevideodescription linkfor version11.
whileittalksabout click relatedthingsinversion .
.
it would be very laborious for developers to comprehend topics based on the top words.
therefore we conduct automatic topic interpretation in the next step.
.
.
resultoftopicinterpretation.
table4illustratestheprioritizedphrasesforlabelingtopics whereonlyoneofthethreelabels arelistedforsavingspace.thehighlightedlabelsintable4arethe emerging app issues detected by the anomaly discovery method in section .
.
.
topic of version .
is interpreted as description box which is consistent with the meaning of that topic in table intuitively.
table illustrates the ranked sentence for labeling each topic.
although phrase labels can be quickly understood we discover that sentence labels can detail the information conveyed by phrases and interpret the topics more comprehensively.
for example thesentencelabeloftopic1forversion11.
i.e.
...clickalink in the description... provides more details than the corresponding phrase label description box in table .
with both issues in phrasesandsentences developerscanefficientlyspotandlocate specificapp issues.tohelpdevelopers gainbetter understanding wevisualizetheidentifiedissuesalongwithversionsinfigure7.
by moving the mouse over topic of version .
we can ob serve both phrase level and sentence level issues among whichthe emerging ones are highlighted.
developers can readily trackthe changes of each topic and discover urgent issues in a timely manner.
.
.
performanceevaluation.
wecollectthegroundtruthof youtube based on the method in section .
.
table displays part of the changelogs.
we manually inspect whether the identified app issues of one version can be reflected in the changelogs of the next version.
accordingto table version .10improves theuser authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
table topic labels in phrases for youtube.
the highlighted ones indicate detected emerging issues.
the valueafter each label is the overall score of the label.
v11.
v11.
v11.
topic descriptionbox .
comment section .
notification center .
topic user interface .
splitscreen .
split screen .
topic playback error .
batterydrain .99performanceimprovement .
topic certain spot .
cpu usage .
camera roll .
topic profile picture .
main page .
home screen .
topic say playback error .
long period .
forcequit .
topic copyright issue .
bring back .
nothing happen .
topic take forever .
ten minute .
pure torture .
topic sound quality .
major issue .
buffer forever .
topic home button .
full screen .
home page .
table topic labels in sentences for youtube.
the highlighted ones are the detected emerging issues.
v11.
v11.
topic 1imeanitworkbutwhydoyoutakeoff whereyouwouldclickalinkinthe descriptionanditdoesn tevenletme gothroughthevideo .05it say error every time i try to reply back to a comment .
topic 2but right now the lack of multitasking have actually make it a betterexperience to use youtube in safari .79addsplitviewandslideoverbutno pictureinpicture .
topic 3please fix this app fix this bug and that playback error .80dearyoutube pleasereleaseafixfor overheatissueonolderiphoneandthe batterydrainjusttooridiculous .
table changelog of youtube version date changelog .
mar added slideover and splitview support moved hometabsinto navigationbarforipadin landscapemode fixed bug that prevented urls invideodescriptions from opening .
mar fixedbugwhereaccessibility voiceover loopedoverthe same elements fixed issue where the video couldn t be exitedafter completing bug fixes and stability improvements views 012345678posts viewsposts figure count of posts and views related to the battery issue in youtube ios forum.
interfacebyaddingthefunctionalityofmultitasking i.e.
sliding overandsplittingview andfixesthebuginvideodescriptions.
referringtotable4andtable5 wediscoverthatthetwoissuesaredetectedby ideaintopic1andtopic2ofthepreviousversion11.
.
thentostatisticallymeasuretheperformanceofourframework we employ the proposed three metrics in section .
.
based on the collected versions for youtube ideaachieves precision e recalll andfhybridat0.
.
.636insentence levelissues and .
.
and .
in phrase level issues respectively.
discussionoftheperformance sincethechangelogsmaynot cover all the changes in releases the metric precision erepresentstable comparison result of different methods on six subject apps.
the value under each app name indicates the av erage number of reviews across the versions.
g51 g85 g72 g70 g76 g86 g76 g82 g81 g40 g53 g72 g70 g68 g79 g79 g47 g41 g75 g92 g69 g85 g76 g71 g51 g85 g72 g70 g76 g86 g76 g82 g81 g40 g53 g72 g70 g68 g79 g79 g47 g41 g75 g92 g69 g85 g76 g71 g50 g47 g39 g36 g19 g17 g23 g25 g27 g19 g17 g24 g21 g27 g19 g17 g23 g26 g22 g19 g17 g23 g27 g21 g19 g17 g25 g21 g21 g19 g17 g24 g22 g23 g44 g39 g40 g36 g16 g53 g19 g17 g25 g19 g25 g19 g17 g23 g25 g20 g19 g17 g24 g21 g19 g19 g17 g23 g26 g27 g19 g17 g24 g26 g19 g19 g17 g24 g19 g22 g44 g39 g40 g36 g16 g54 g19 g17 g21 g24 g19 g19 g17 g24 g22 g19 g19 g17 g22 g23 g19 g19 g17 g23 g20 g26 g19 g17 g24 g23 g26 g19 g17 g23 g26 g22 g44 g39 g40 g36 g14 g19 g17 g24 g26 g20 g19 g17 g23 g28 g26 g19 g17 g24 g22 g20 g19 g17 g23 g26 g25 g19 g17 g25 g22 g28 g19 g17 g24 g23 g25 g50 g47 g39 g36 g19 g17 g23 g23 g20 g19 g17 g23 g25 g21 g19 g17 g23 g24 g20 g19 g17 g24 g26 g27 g19 g17 g25 g25 g23 g19 g17 g24 g28 g26 g44 g39 g40 g36 g16 g53 g19 g17 g24 g19 g25 g19 g17 g23 g21 g28 g19 g17 g23 g24 g25 g19 g17 g24 g24 g19 g19 g17 g25 g24 g28 g19 g17 g24 g27 g25 g44 g39 g40 g36 g16 g54 g19 g17 g24 g23 g27 g19 g17 g23 g25 g25 g19 g17 g24 g19 g21 g19 g17 g23 g24 g25 g19 g17 g25 g24 g25 g19 g17 g24 g21 g21 g44 g39 g40 g36 g14 g19 g17 g24 g28 g21 g19 g17 g23 g26 g21 g19 g17 g24 g21 g22 g19 g17 g25 g21 g27 g19 g17 g25 g25 g25 g19 g17 g25 g22 g25 g50 g47 g39 g36 g19 g17 g20 g24 g26 g19 g17 g22 g19 g24 g19 g17 g20 g25 g25 g19 g17 g22 g20 g22 g19 g17 g24 g24 g19 g19 g17 g22 g26 g24 g44 g39 g40 g36 g16 g53 g19 g17 g24 g23 g21 g19 g17 g22 g21 g25 g19 g17 g23 g19 g26 g19 g17 g25 g21 g24 g19 g17 g24 g26 g20 g19 g17 g24 g28 g26 g44 g39 g40 g36 g16 g54 g19 g17 g24 g19 g19 g19 g17 g22 g23 g21 g19 g17 g23 g19 g25 g19 g17 g24 g19 g19 g19 g17 g24 g20 g27 g19 g17 g24 g19 g28 g44 g39 g40 g36 g14 g19 g17 g25 g21 g24 g19 g17 g22 g23 g19 g19 g17 g23 g23 g19 g19 g17 g25 g21 g24 g19 g17 g25 g24 g20 g19 g17 g25 g22 g27 g50 g47 g39 g36 g19 g17 g22 g19 g19 g19 g17 g21 g25 g28 g19 g17 g20 g25 g19 g19 g17 g21 g19 g19 g19 g17 g23 g21 g20 g19 g17 g20 g21 g28 g44 g39 g40 g36 g16 g53 g19 g17 g24 g19 g19 g19 g17 g21 g20 g25 g19 g17 g22 g19 g20 g19 g17 g26 g24 g19 g19 g17 g22 g26 g26 g19 g17 g24 g19 g21 g44 g39 g40 g36 g16 g54 g19 g17 g19 g25 g26 g19 g17 g21 g27 g28 g19 g17 g22 g25 g25 g19 g17 g24 g19 g19 g19 g17 g22 g28 g27 g19 g17 g23 g23 g22 g44 g39 g40 g36 g14 g19 g17 g25 g25 g26 g19 g17 g22 g20 g27 g19 g17 g23 g22 g20 g19 g17 g25 g25 g26 g19 g17 g23 g22 g23 g19 g17 g24 g21 g25 g50 g47 g39 g36 g19 g17 g20 g25 g26 g19 g17 g21 g22 g27 g19 g17 g20 g28 g25 g19 g17 g24 g19 g19 g19 g17 g23 g27 g27 g19 g17 g23 g28 g23 g44 g39 g40 g36 g16 g53 g19 g17 g21 g21 g28 g19 g17 g21 g23 g22 g19 g17 g21 g21 g19 g19 g17 g25 g23 g25 g19 g17 g23 g28 g25 g19 g17 g24 g25 g20 g44 g39 g40 g36 g16 g54 g19 g17 g20 g21 g24 g19 g17 g21 g27 g24 g19 g17 g20 g22 g21 g19 g17 g22 g24 g23 g19 g17 g23 g26 g25 g19 g17 g23 g19 g25 g44 g39 g40 g36 g14 g19 g17 g21 g21 g28 g19 g17 g21 g24 g20 g19 g17 g21 g21 g26 g19 g17 g25 g23 g25 g19 g17 g24 g21 g26 g19 g17 g24 g27 g19 g50 g47 g39 g36 g19 g17 g20 g19 g19 g19 g17 g24 g25 g26 g19 g17 g20 g23 g27 g19 g17 g22 g25 g26 g19 g17 g25 g20 g26 g19 g17 g23 g24 g27 g44 g39 g40 g36 g16 g53 g19 g17 g22 g22 g22 g19 g17 g25 g20 g20 g19 g17 g22 g26 g25 g19 g17 g23 g20 g26 g19 g17 g26 g22 g22 g19 g17 g24 g20 g24 g44 g39 g40 g36 g16 g54 g19 g17 g22 g22 g22 g19 g17 g25 g21 g21 g19 g17 g22 g26 g21 g19 g17 g24 g19 g19 g19 g17 g26 g20 g20 g19 g17 g24 g27 g26 g44 g39 g40 g36 g14 g19 g17 g24 g20 g26 g19 g17 g25 g24 g22 g19 g17 g24 g21 g22 g19 g17 g24 g27 g22 g19 g17 g26 g19 g19 g19 g17 g24 g27 g26 g57 g76 g69 g72 g85 g11 g21 g15 g20 g23 g20 g12 g38 g79 g72 g68 g81 g3 g48 g68 g86 g87 g72 g85 g11 g25 g15 g22 g22 g21 g12 g40 g69 g68 g92 g11 g22 g15 g28 g23 g22 g12 g54 g90 g76 g73 g87 g46 g72 g92 g11 g20 g15 g22 g20 g22 g12 g36 g83 g83 g3 g49 g68 g80 g72 g11 g6 g68 g89 g74 g17 g3 g85 g72 g89 g76 g72 g90 g86 g12 g48 g72 g87 g75 g82 g71 g51 g75 g85 g68 g86 g72 g54 g72 g81 g87 g72 g81 g70 g72 g49 g50 g36 g36 g3 g53 g68 g71 g68 g85 g11 g24 g21 g22 g12 g60 g82 g88 g87 g88 g69 g72 g11 g20 g15 g20 g23 g22 g12 a lower bound of the performance.
for example the highlighted emerging issues such as split screen and battery drain for version .
in table are not clearly embodied by the changelog of version .
shown intable .wethen inspectthe reasonwhy thedetectedissues fail tobenoticed bydevelopers.wediscover that split screen is one new added feature of version .
and it is reasonable for a hot discussion about the drawbacks of thisfeature in the user reviews which explains why split view is identifiedas oneemergingissue.then fortheissue batterydrain we dig into the official user forum of youtube for ios and observethenumberofpostsandviewsoftheissuebysearchingthe phrase illustratedinfigure8 .wefindthatthereexistsasudden increase in the counts of posts and views around may which also demonstrates that the battery issue was an emerging issue for the version.
therefore we summarize that changelogs may not completely cover all emerging issues and our performance metric computesa lower boundof theperformance of idea.the comparisonwithothermethodscanvalidateourproposedframeworkmore sufficiently.
.
result of rq2 comparison results with different methods for validatingthe performanceof aoldain idea wechoose the typical method for online topic modeling olda .
for evaluating theproposed topic labelingmethod in section .
.
we also compare with the method only considering the sentiment score for labeling denoted as idea r and the method only considering the semantic score for labeling denoted as idea s .
for clarity our proposedframeworkisrepresentedas idea .table7illustratesthe comparison resultson thesix subjectapps.
we discussthe performance of ideafrom three aspects in the following subsections.
.
.
issues in phrases v.s.
issues in sentences.
according to the results of idea in table issues in sentences can attain better performance than those in phrases by .
.
and .
in precision e recalll andfhybridonaveragerespectively.thismay beattributedtothefactthatsentencescandelivermoredetailedand completeinformationthanphrases explainedinsection4.
.
and authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
therebycovermorekeytermsinchangelogs.focusingonthemetric fhybrid employing sentence level issues improves the properties of using phrase level issues by .
.
times.
for precision e the issues in sentences increase those in phrases by .
.
times.thenegativeincreaseonlyoccurstotheappnoaaradar whichmaybebecausethesmalldatasetsoftheapp 512reviews perversion introduceinstabilityforourframework .forthe metricrecalll idea showsanincreaserangeof7.
.1times.
overall sentence levelissuescanbetterrepresent appissues and we employ such issue representations for comparing with different methods in the following.
.
.
aolda v.s.
olda.
on average idea achieves .
.
and0.585for precision e recalll andfhybridrespectively while the olda based method only obtains .
.
and .
for the three metrics.
considering the metric fhybrid aolda enhancestheperformanceofoldaby2.
.08times whereolda presentsthepoorestperformance .
ontheappwiththelargest quantity of reviews e.g.
clean master with reviews per version .forthemetrics precision eandrecalll ourframeworkcan improvetheperformanceby .
.33timesand0.
.
respectively.
although idea exhibits a slightly lower precision e thantheolda basedmethodfortheappnoaaradar itshows better performance in both fhybridandrecalll which indicates that our framework can well balance the precision and recall in issue detection.
.
.
ideav.s.differenttopiclabelingmethods.
wediscover thatidea canachievebetterperformancethan idea randpresent theincreaseratesat7.
.
and7.
onaverageforthethree metricsrespectively.for fhybrid ourframeworkimproves idea r by3.
.
.whencomparedwith idea s ourframeworkincreasesby34.
.
and20.
onaveragein precision e recalll andfhybrid respectively.therefore both theuser sentimentand semantic similarity should be considered for topic labeling.
.
rq3 effect of different parameter settings in this part we demonstrate the impact of different parameter settingsontheperformanceofourframework.wefocusonanalyzing two important parameters including the window size wand the numberoftopics k.wealsoexplainhowwechoosetheparameters in our experiments.
.
.
windowsize.
figure9illustratestheresultsofdifferent windowsizeson twoapps includingyoutubeandebay.for both apps the values of fhybridpresent an inverted u shape for both phrase level and sentence level issues.
we attribute this to the reasonthatthetopicdistributionsofthecurrentversionarestrongly dependent on those of the previous versions.
when the window sizeissetrelativelysmall thedetectedissuesofcurrentversions maybemoredivergentandunstable .however largerwindowsizes mayweakenthedistinctionofappissuesamongversions which isunfavorablefordetectingtheemergingissues.since w 3can achievethebestperformanceonourdatasets indicatedinfigure9 we set the window size as three in our experiments.
.
.
thenumberoftopics.
generally thetopicnumbershould be defined according to the size of the review collection .
in idea a largertopicnumber canbringmoreprioritized appissues .
.
.
.
.
.
12345phrase sentence0.
.
.
.
.
.
12345phrase sentence window size window size a youtube b ebay figure impact of window size.
whichcancovermorechangelogs i.e.
increasing recalll .however more app issues may be a double edged sword since the metricprecision ecan be decreased.
figure shows the results of differenttopicnumbersontwoapps includingnoaaradarandebay.forebay onaverage3 943reviewsperversion thevalues offhybriddisplay an ascending tendency in both phrase level and sentence levelissues.butfornoaaradar onaverage523reviews per version a larger topic number will reduce the performance whenusingphrase levelissues.tobetterbalancetheprecisionand recall we set the topic number as during experiments.
.
.
.
.
.
.
.
12phrase sentence topic number a noaa radar00.
.
.
.
.
.
.
12phrase sentence topic number b ebay figure impact of topic number.
idea in practice in this section we explore the performance of ideain practice.
first weintroduceausersurveyconductedintencent.thenwe describe the successful application of ideain tencent s products.
.
user survey to further demonstrate the significance and effectiveness of our work we conduct a user study among staff in tencent with developers .
five data analysts .
four product managers .
three maintenance engineers .
one test engineer .
and three from other positions .
.
the user study is conductedthroughanonlinequestionnaire whichconsistsofsix questions onequestiononparticipants background fourquestions for experimental assessment and one question for understanding their attitude towards such automatic analysis.
.
.
changelogs as ground truth.
we interview the participants about their opinions of using changelogs as ground truth since changelogs may only include partial changes of the releases.
thesurveyresultsindicatethat31 .
oftheintervieweesagree thatchangelogscanreflectmodifiedissuesofthenewreleases and .
ofthemindicateastrongapproval.moreover .
of participants think that changelogs embody the user concerns of the previous releases with .
echoing strong agreement.
since our framework aims to prioritize app issues based on user reviews using changelogs as ground truth is reasonable.
.
.
effectiveness of our framework.
during the survey we validate our framework in terms of three aspects the presentation authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
styleof idea sresults theperformanceachievedbyourframework and the significance of such automatic analysis.
the survey results indicatethat75.
ofparticipantsthinkthevisualizationwithan issueriver iscomprehensibleforthem whilethephrase levelissues only with the approval rate at .
are considered more difficult to understand than sentence level issues with an approval rate of .
.
for inquiring about their opinions of the performanceof idea we present the example results of wiznote with precision eandfhybridat50 .accordingtothesurvey .
of the interviewees think that the performance is acceptable in practicalusage and31.
stronglyapproveofsuchperformance.
in addition all the participants think such automatic analysis of detecting emerging issues is significant for app development with .
of them strongly agreeing with this sentiment.
these results provide strong evidence of the effectiveness of our framework.
.
successful story in industrial practice teamxoftencentaimstoprovidedeveloperswithabnormalevents reportand operationstatisticsof20 appsoftencent.traditional reviewanalysisinxrequireslotsofmanpower.withtheincreasingquantitiesofappreviewsandtheonslaughtofspaminuserreviews x has been seeking a means of automatic analysis.
we have successfully applied ideainto x to maintain four apps with review quantitiesat500 000perday.thefourappsservehundredsof millionsofusersworldwide andtheirqualityisveryimportantfor thecompany.
ideaobtainsuserreviewsbythehourordaybased on the review collection api provided by x. the collected reviews aregroupedbyversionsandprocessedinrealtime.thedetected emerging issues are fed back to developers for further analysis.
in july of app y encountered a serious problem when the contentsearchservicewasnotavailableforaperiodoftime and receivedasuddenincreaseintheamountofuserfeedback.with idea the team x quickly identified the issue and reported it to the development team.
the team also confirmed this issue.
moreover ideacanefficientlyanalyzelargenumbersofreviews.
wedeploy ideaonapcwithintel r xeone5 2620v2cpu .
ghz 6cores and16gbram.for36 000productreviewsperversion ideaachieves a high throughput nearly reviews per second andonlyconsumes1.02gbofmemoryonaverage.overall ideaisprovedtobeeffectiveandefficientinquicklypinpointing urgent app issues for developers in the industrial practice.
threats to validity first we only select six subject apps for validating our framework and the apps represent a tiny portion of all apps on app markets.since we utilize user reviews for detecting emerging issues our methods can be easily applied to other apps even those with other languages.
also we alleviate this threat by choosing the apps from different categoriesand platforms.
second the number ofuser reviewscanimpacttheperformanceof idea.however sincesmall datasetscanbe easilyanalyzedmanually our frameworkaimsfor automaticanalysisoflargereviewdatasets.wealsomitigatethis threatbyselectingappswithdifferentquantitiesofuserreviews on average523 332reviewsperversion .third thetopicnumber should bemanually defined which caninfluence the performanceofourframework.suchathreatstemsfromtheoriginaltopicmodelingmethod whichisstillagreatchallengeinacademia .
inthispaper wealleviatethisthreatbytestingondifferenttopic numbers introducedinsection4.
.
.inpractice wecanemploy heuristic approaches to determine the optimal topic number.
related work .
app review mining some previous work focuses on identifying users major concerns or preferences from app reviews .
different from these work where the reviews are manually analyzed there exists someresearchwhichextractsappissuesautomatically.forexample designframeworksforautomaticretrievalofmobile app feature requests from reviews.
mcilroy et al.
contribute to automaticallyassigningmultiplelabelstoeachreview.although thework classifyappreviewsintodifferentcategories for recommending software updates they mainly analyze static reviews and pay little attention to tracking issue changes.
in theauthorsanalyzevariationsinappratings prices or reviewsizesalongwithtime buttheissuesareneitheridentified automatically nor studied online.
similarly online review analysis isnotthefocusofgao etal.
swork .therealsoexistssome work focusing on analyzing the parts of apps that are loved byusers.differentfrompreviousefforts ourworkaimstodetect the emerging issues automatically and dynamically.
we employ changelogsforverifyingeffectivenessofourframework.moreover wepresentappissuesinaninteractiveandcomprehensiblemanner.
.
emerging topic detection there are research efforts focused on detecting emerging topics in socialmedia suchastwitter andmicroblog .onlinetopic models are the typical methods for discovering burst topics.
wearethefirsttoapplyonlinetopicmodelingmethodsintoapp reviews andweimproveonpreviousworkbyproposinganovel aolda.
aolda can adaptively combine the topics in previous app versions and greatly enhances the performance of olda .
conclusion timely and effectively detecting app issues is crucial for app developers.wepropose idea anovelframeworkforautomatically identifying emerging issues from user reviews.
our frameworkcan be easily applied to text based online detection tasks and reportemergingissuestimely.industrialpracticealsovalidatesthe effectiveness of idea.
in the future we will refine ideato be capable of definingthe topic number automatically andmake ideaa distributed algorithm for supporting ultra large scale datasets.