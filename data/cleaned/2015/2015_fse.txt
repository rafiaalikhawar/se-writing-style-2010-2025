justfuzz it solvingfloating pointconstraints usingcoverage guided fuzzing daniel liew dan su root.co.uk imperialcollegelondon unitedkingdomcristian cadar c.cadar imperial.ac.uk imperialcollegelondon unitedkingdomalastair f.donaldson afd imperial.ac.uk imperialcollegelondon unitedkingdomj.ryanstinnett jryans gmail.com mozilla unitedstates abstract we investigate the use of coverage guided fuzzing as a means of proving satisfiability of smt formulas over finite variable domains withspecificapplicationtofloating pointconstraints.weshowhow ansmtformulacanbeencodedasaprogramcontainingalocation that is reachable if and only if the program s input corresponds to asatisfyingassignmenttotheformula.acoverage guidedfuzzer canthenbeusedtosearchforaninputthatreachesthelocation yieldingasatisfyingassignment.wehaveimplementedthisidea in a tool justfuzz itsolver jfs and we present a large experimentalevaluationshowingthatjfsisbothcompetitivewithand complementary to state of the art smt solvers with respect to solving floating point constraints and that the coverage guided approachofjfsprovidessignificantbenefitovernaivefuzzingin thefloating pointdomain.appliedinaportfoliomanner thejfs approach thus has the potential to complement traditional smt solvers for program analysis tasks that involve reasoning about floating pointconstraints.
ccs concepts theory of computation constraint and logic programming softwareanditsengineering softwaretestingand debugging .
keywords constraintsolving feedback directedfuzzing acmreference format danielliew cristiancadar alastairf.donaldson andj.ryanstinnett.
.
just fuzz it solving floating point constraints using coverage guided fuzzing.in proceedingsofthe27thacmjointeuropeansoftwareengineeringconferenceandsymposiumonthefoundationsofsoftwareengineering esec fse august 26 30 tallinn estonia.
acm new york ny usa 12pages.
introduction satisfiability modulo theories smt solvershave made tremendous progress over the last decade and now underpin many important software engineering tools includingsymbolic execution permissionto make digitalor hard copies of allorpart ofthis work for personalor classroom use is granted without fee provided that copies are not made or distributed forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation onthefirstpage.copyrights forcomponentsofthisworkownedbyothersthanthe author s mustbehonored.abstractingwithcreditispermitted.tocopyotherwise or republish topostonserversortoredistributetolists requirespriorspecificpermission and or a fee.
request permissions from permissions acm.org.
esec fse august 26 30 tallinn estonia copyright heldby the owner author s .
publicationrightslicensed to acm.
acm isbn ... .
e.g.
program verifiers e.g.
andprogram synthesis frameworks e.g.
.
despitetheseadvances smtsolversoftenexhibitlimitedscalabilityonlargeproblems andsolvingcanbechallengingfor certain underlying theories.
scalable smt solving in the theory of floating pointarithmeticisaparticularchallenge andthesubject ofalot ofrecent andongoing work .
anunrelatedtechnology coverage guidedmutation basedfuzzing iswidelyusedtoautomaticallyfindinputstoasystemundertest sut that expose crashes and potentially exploitable undefined behaviours .
for an sut that has been instrumented to record coverage information a coverage guided mutation based fuzzer takes an initial corpus of inputs and uses genetic algorithms to synthesise further inputs by mutating and combining elements of the corpus.
inputs that cover new parts of the sut are added tothecorpus underthehypothesisthatviafurthermanipulation theymayyieldinputsthatprovideevenmorecoverage andthat aimingfor high coverageisagoodstrategy for triggeringbugs.
inthispaper wepresentanin depthinvestigationintothepotentialforcoverage guidedmutation basedfuzzingtobeusedto solve smt formulas.
our idea is to transform an smt formula intoaprogramwhoseinputcorrespondstoanassignmenttothe free variables of the formula containing a statement target that is reachableifandonlyiftheinputcorrespondstoasatisfyingassignment.
a coverage guided fuzzer aims to find inputs that maximise coverage sowhenappliedtothisprogramitwillsearchrelentlessly foraninputthatreaches target i.e.forasatisfyingassignmentto theformula.
our hypothesis is that thistechnique maysometimes be able to rapidly find satisfying assignments for formulas that are challengingforgeneral purposesolvers.themethodwepropose doesnotintend to helpinproving unsatisfiability of formulas.
wepresentjfs justfuzzitsolver aprototypeconstraintsolver based on coverage guided mutation based fuzzing.
jfs is sound a sat result can be trusted.
however it is incomplete jfs could time out and as discussed above unsatisfiability cannot be proven.
we envision jfs would be run in parallel with a complete solver to formaportfolio solver.jfs wasinspiredbythe limited scalability wehaveobservedforstate of the artsmtsolverswithrespectto floating point constraints and currently supports the combination of boolean bitvector and floating point theories but our idea of smtsolvingviacoverage guidedfuzzingshouldbestraightforward to adapt to any smttheory over finite domainvariables.
we present a large experimental evaluation comparing jfs with sevenfloating point capable smt solvers over a set of 1344benchmarks from three different smt comp suites.
our evaluation aims to answer the following research questions 521esec fse august 26 30 tallinn estonia d. liew c.cadar a.f.
donaldson andj.
r. stinnett rq1towhatextentiscoverage guidedmutation basedfuzzing superiortonaiverandominputgenerationforsmtsolving?
rq2towhatextent canjfsbeacceleratedvia smartseeds derived from the formula under analysis and or the associated smttheory?
rq3howdoestheexecutiontimeofjfscomparewithstate ofthe art smt solvers when applied to satisfiable formulas over boolean bitvector andfloating pointvariables?
our main finding is that jfs is competitive with state of the art solvers such as mathsat5 and z3 on floating point constraints complementing these solvers both in terms of number of solved benchmarksand execution time.by contrast it isuncompetitive onbitvector onlyconstraints.intermsofdesignfeatures wefound coverage guided mutation based fuzzing superior to naive random inputgeneration andthe use ofsmart seedsto be beneficial.
we qualify the relative success of jfs with respect to floatingpointconstraintsbyacknowledgingthatsolversupportforfloating point as well as available evaluation benchmarks are relatively recent while traditional solvers are very mature for bitvector only constraints andthebenchmarksavailableforthistheoryareknown to be challenging.
in summary our main contributionsare theideaofleveragingcoverage guidedmutation basedfuzzing to find satisfying assignments to smt formulas illustrated concretely viaaworkedexample in jfs asound incompletesolverforfloating pointandbitvector constraintsbasedonthis idea anevaluationcomparingjfswithsevenfloating point capable smt solvers over 1344smt comp benchmarks addressing the above researchquestions .
aftercoveringrelevantbackground wegiveanoverview of jfs discuss the design and implementation of the approach andtool andpresentadetailedexperimentalevaluation .
we then discuss related work and ideas for future research directions .
throughout the paper we discuss the limitations of jfsandthreatsto the validity ofour approach.
background we provide relevant background on coverage guided fuzzing .
andsomebriefnotesonfloating pointarithmetic .
.
.
coverage guidedmutation based fuzzing mutation based fuzzing starts with a set of existing seedinputs knowntoalreadyexercisethesutinsomedepth andgenerates further inputs by mutating and combining seeds.
intuitively the resulting inputs are much more likely to exercise the sut in interestingwayscomparedwithinputsgeneratedinapurelyrandom fashion.ifcodecoveragedataforthesutcanbeobtained through compile time or binary instrumentation a fuzzer can operate in a coverage guided manner.
code covered by an input can be used as a proxy for measuring how interesting that input is with an input that covers newcode being deemedinteresting.
coverage guidedmutation basedfuzzing combinestheseideas starting from an initial corpus sut inputs are generated via mutation.
an input that covers new code is added to the corpus to be consideredasaseedforfuturemutation.typicalmutationsincludemaking small changes to an input in isolation and performing crossover where multiple inputs are combined into one.
this approach is essentially an evolutionary algorithm where an input isconsidered fitifitcoversnewcode.anevolutionaryalgorithm used in this context is part of a broader research area known as search based test case generation .
two popular coverage guided mutation based fuzzers afl andlibfuzzer onwhichjfsisbased havefoundnumerous bugsinreal world software .
.
floating pointarithmetic amotivatingusecaseforourworkissmtformulasthatcontain constraintsoverfloating pointvariables.werecaphereafewterms andconceptsthat willbe usedlateron.
single anddouble precisionfloating pointnumbersarerepresentedinsmt lib bythefloat32 float64 types whichcorrespondtotheieee 754binary32 binary64types .thesemantics of most floating point operations match the process of performing the operation with real number semantics then rounding the result to a nearby floating point number.
several rounding modes can be used includingroundingtothenearestfloating pointnumberwith ties favouring an even binary representation rne and rounding towards positive infinity rtp .
the set of floating point bit patternsincludesspecialpatternstorepresentinfinities aswellas not a number nan which handles the results of computations for whichnonumerical representation makes sense such as .
overview ofjfs inbrief jfsusesthefollowingmethodtofindasatisfyingassignmentto aformula qpresentedas aconjunction of constraints a program pisconstructedsuch that ptakes a sequence of variables as input with each variable corresponding to afree variable in q. pcontains a sequence of constraint branches one per constraint in q each of which is an ifstatement whose conditioncorrespondsexactly to the associatedconstraint.
pcontains a targetstatement that returns if and only if all thetruebranches of the constraintbranches are traversed.
jfsthenpassestheprogram ptoacoverage guidedmutationbasedfuzzer whichrepeatedlyruns pwithdifferentinputsuntilan inputthatreachesthetargetisfound correspondingtoasatisfying assignment to q or the fuzzer reaches a given time limit.
the intuitionbehindapplyingacoverage guidedfuzzeristhatitwill relentlesslytrytogenerateinputsthatcover newcode.inparticular the program location that returns 1isatarget for the fuzzer.
as an illustration of this idea consider the example constraints in listing shown in smt libv2.
format .
free variables a andb of type float64 see .
are declared on lines 1and2 respectively.
on lines 3and4 variables div rne anddiv rtp are definedtobethedivisionof abybusingtheroundingtonearest ties to even rne and rounding toward positive infinity rtp roundingmodes respectively.
thesatisfiabilityproblemcapturedbytheexampleistheconjunction of the constraints specified in the five assertstatements.
the 1anyformulacanbetransformedtoanequisatisfiableformulainconjunctiveform e.g by using the linear timetseytintransformation .
522jfs solvingfp constraints usingcoverage guidedfuzzing esec fse august 26 30 tallinn estonia listing an example conjunction of floating point constraintsinthesmt libv2.
format.
declare fun a float64 declare fun b float64 define fun div rne float64 fp.div rne a b define fun div rtp float64 fp.div rtp a b assert not fp.isnan a assert not fp.isnan b assert not fp.isnan div rne assert not fp.isnan div rtp assert not fp.eq div rne div rtp check sat listing a translation of the constraints in listing 1to a c program.
1intfuzzoneinput constuint8 t data size t size 2double a makefloatfrom data size 3double b makefloatfrom data size 4if !isnan a else return 5if !isnan b else return 6double a b rne div rne a b 7double a b rtp div rtp a b 8if !isnan a b rne else return 9if !isnan a b rtp else return if a b rne !
a b rtp else return return target reached first four constraints state that none of a b div rne anddiv rtp arenan the last states that div rne isnot equal to div rtp.
theseconstraints are satisfiable.using c hexfloatnotation onesatisfyingassignmenthas asetto0x0.410815d750e65p .
andbto0x1.021c1b000e7cp .
.
dividing abybrounding to nearest ties to even yields 0x0.0000000408001p .
and rounding towardpositiveinfinityresultsin 0x0.0000000408002p .
.
apossibletranslationoftheseconstraintsintoac program is shown in listing where the guard of each ifstatement correspondstoaconstraint.thefuzzerwillrepeatedlycall fuzzoneinput line1 eachtimepassinganinputof sizebytesviathe databuffer.
if1isreturned theinputcorrespondstoasatisfyingassignment otherwisethe fuzzerproceedsto try anotherinput.
the program first constructs the free variables from the input bufferdata.
variables aandbcorrespond directly to the free variablesaandbinlisting 1and areconstructedonlines 2and3from thedatabuffer using bits 0to a andbits to b .
anifstatement checks whether ais nan line encoding the constraintonline 5oflisting .whether bisnanishandledanalogously line .variable a b rnecorrespondstothe div rnemacro on line3of listing and is set to the result of calling div rne a b line6 .thisperformsfloating pointdivisionroundingtheresult to the nearest value ties to even .
the assignment to a b rtpis analogous withroundingtowardspositive infinity.
the checks for whether a b rne anda b rtp andnanare handledsimilarlytothechecksforwhether aandbarenan lines8and .
the comparison of a b rne anda b rtp line10 corresponds to the constraintonline 9oflisting .
finally on line 11the function returns which tells the fuzzer thatasatisfyingassignmenthasbeenfound.notethatthislineis only reachableif allpreviously evaluatedconstraintswere true.therearemultiplewaysofencodingconstraintsasaprogram.
listing2uses thefail fastencoding discussedfurther in .
.
design and implementation ofjfs jfs is written in c and builds on several existing projects theconstraintlanguageandapiofz3 isusedforin memory constraint representation allowing reuse of z3 s parser and constraint simplification tactics clang and llvm are used to compile generated c code and the coverage guided mutation based fuzzerlibfuzzer isusedto fuzz the resultingbinary.
jfsacceptsansmt libv2 formulaconsistingofaconjunction oftop levelconstraints.programanalysistools suchasthosebased ondynamicsymbolicexecution butnotonly generate such conjunctions directly and as mentioned in any formula can be transformed to an equisatisfiable formula in conjunctive form e.g byusing the linear time tseytin transformation .
the design of jfs in principle supports finding satisfying assignments to any theory using finite data types.
our current implementation supports combinations of the core i.e.
boolean fixedsizebitvectors andfloatingpoint smt libv2theories overfloat32andfloat64floating pointvariables andbitvector variables ofarbitrary widthsupto bits.
we now discuss practical issues related to the design of jfs covering simplification of formulas pre fuzzing .
the mapping of formula variables to the program input buffer .
choices for howtoencodetheformulaasaprogram .
andtheinjection of smartseeds toguidethefuzzer .
.wealsobrieflydiscuss jfs s runtimelibrary .
.
.
formulasimplification tomakethec programthatjfswillultimatelygeneratemore friendly to libfuzzer jfs first applies the simplification passes detailedintable inorder totheinputformula.thetableindicates which passeswere alreadyavailable via callsinto the z3 library vs. whichweimplementedusingthez3api.thesepassesrepresent various cheap ways to simplify formulas that we observed to be usefulusefulduringearlyprototypingofjfs.weremarkbrieflyon theandhoistingpass jfsusesz3toparseconstraints andparsing always returns a single conjunct the and hosting pass simply splits this intoindependent conjuncts.
ifaftersimplificationtheformulaissyntacticallyequivalentto false jfs immediately reports unsat without invoking libfuzzer.
.
input bufferpreparation havingsimplifiedtheformula jfsmustdecidehowtorepresent free variables ofthe formula inthe program s inputbuffer.
first an equality extraction pass is used to partition the free variables and constants appearing in the formula into equivalence classesbasedonsyntacticequalities suchthatmembersofthesame equivalenceclassareguaranteedtobeconstrainedtobeequal.each resultingclasscontainsat mostone constant ifmultiple distinct constantswereconstrainedtobeequal jfswouldhavereported the formula as trivially unsat after formula simplification .
.
each equivalence class is then considered.
if a class contains a constant cthen there is no need to reserve space for variable of the class in the input buffer each variable is declared in the 523esec fse august 26 30 tallinn estonia d. liew c.cadar a.f.
donaldson andj.
r. stinnett table the ordered set ofsimplifyingpassesrun by jfson aformulabefore program generation simplification description alreadyinz3?
andhoisting separatesthe constraint and a b intotwoseparate constraints no constant propagation apply z3 s propagate values tactic to propagateconstants yes duplicateconstraintelimination removes duplicateconstraintsfrom the constraintset no expressionsimplification invokesz3 s expressionsimplifier whichperforms e.g.constant folding yes simplify contradictions replaces and a not a withfalse no trueelimination removes constraintsofthe form truefrom the constraintset no listing3 exampleconstraintsusedtoillustrateequalityextraction.
declare fun a floatingpoint declare fun b floatingpoint declare fun c floatingpoint declare fun d floatingpoint assert a b assert b c assert d zero assert not fp.isnan fp.add rne c d check sat programandinitializedto c.otherwise kbitsoftheinputbuffer are allocated to represent the common value of all free variables in the class where kis the width of the associated data type e.g.
k 32forfloat32 variables .thevariablesarealldeclaredlocally intheprogramandinitializedviathesame kbitsoftheinputbuffer.
this process is illustrated by the formula of listing where zero denotesthe64 bitpositivezeroconstant andthe associatedprograminlisting .theequivalenceclassesare a b c and d .
.asaresult theinputbuffer datarequires8bytesin ordertostorethedouble precisionvaluecommonto a bandc.the makefloatfromdata functioninitializes aviathisbuffer andthe valueofaisthencopiedinto bandc.variable ddoesnotrequire associatedspaceinthebuffer itisinitializedwiththeconstantvalue .
.
because this process fully accounts for equality constraints betweenvariablesandconstants suchconstraintsdonotneedto be modelledinthe controlflowofthe generatedprogram.
equalityextractionbothreducesthesizeoftheinputbuffer and alleviates libfuzzer from the onerous task of guessing equality between certainsetsofvariables.
the input buffer is tightly packed so that the chunks of data associated with variables need not be aligned to word or even byte boundaries.
chunks are ordered by the order they appear while traversingtheinputformula.thismakestheorderdeterministic usefulforreproducibility butarbitrary.non alignedaccessesmake readingfromthebuffersub optimal butavoidspaddingbitsthat have no impact on program behaviour.
such bits would be detrimentaltolibfuzzerasitwouldwastetimeattemptingtomutate those bits to increase coverage.
with additional engineering effort we could adapt jfs to make libfuzzer aware of padding bits and instructitnottomutatethem allowingtheperformancebenefits associatedwithbetteralignment.
.
programencodings we have experimented withtwowaystoencodeansmtformula as aprogram fail fastandtry all.listing a translation of the constraints in listing 3to a c program based on the equalityextractionpass.
1intfuzzertestoneinput constuint8 t data size t size 2double a makefloatfrom data size 3double b a 4double c a 5double d .
6double c plus d add rne c d 7if !isnan c plus d else return 8return target reached listing a translation of the constraints in listing 1to a c program usingthe try allencoding.
1intfuzzertestoneinput constuint8 t data size t size 2double a makefloatfrom data size 3double b makefloatfrom data size 4size t counter 5if !isnan a counter 6if !isnan b counter 7double a b rne div rne a b 8double a b rtp div rtp a b 9if a b rne !
a b rtp counter if !isnan a b rne counter if !isnan a b rtp counter if counter !
return return target reached with the fail fastencoding listings 2and4 the program exits as soon as an unsatisfied conjunct is found without evaluating the remaining conjuncts.asatisfying assignment isfound if and only if the end of the program is reached.
with the try allencoding listings1and5 allnconjunctsoftheinputformulaareevaluated and azero initialised counter is incrementedeach time a conjunct is found to hold.
a satisfying assignment is found if and only if the counter equals nat the end of the program.
thepotentialadvantageof try allisthatevaluating everyconstraint provides rich coverage information if an input satisfies somepreviously unsatisfiedconjunct coveragewillincreaseand thecoverage guidedfuzzerwillstoretheinputtobeconsideredfor furthermutation.thepotentialadvantageof fail fastisthatitdoes not waste time furtherevaluatingan inputonce it isknown that it does not satisfy some constraint.
experimentally we have found thatfail fastenables jfs to solve significantly more benchmarks thantry all thus we only consider the fail fastencoding in our evaluation .
524jfs solvingfp constraints usingcoverage guidedfuzzing esec fse august 26 30 tallinn estonia .
smartseeds asdiscussedin .
acoverage guidedmutation basedfuzzerrelies onacorpusofinitialseedinputs whichinthecaseofjfsareinitial valuations of the input buffer.
we have experimented with two modes for selecting seeds.
innaiveseeds mode jfsgeneratestwoseeds abufferofallzeros andabufferofallones whichatleastprovidelibfuzzer scrossover mutatorwithapair ofdiverseinputsto work with.
insmart seeds mode seeds are generated as follows.
for each distinctdatatypeassociatedwithafreevariable e.g.
float64 bv32 etc.
weconstructasetconsistingof specialvaluesforthattype such as positive negative zero infinities and nan bit patterns for floating pointtypes see .
andbitpatternsencoding0 1and for bitvector types and values of constants of the given type that appear in the input formula.
we then construct a seed by randomly sampling from the space of possible input permutations thatcanbegeneratedfromthesesets.thenumberofseedsselected isconfigurable andsetto 100bydefault.
ourhypothesesforwhysmartseedsmaybevaluablearethat special values are often important for particular data types e.g.
afloating point formula that looks unsatisfiable on first sight often turns out to be satisfiable due to the subtle semantics of nanvalues and thesatisfiabilityofconstraintsismorelikely to depend on values equal or similar to values appearing in the formula than on arbitrary values with mutations of seeds being likelytoyieldsaidsimilarvalues .weevaluatethebenefitsofsmart seedsexperimentally in .
.
runtime library theprogramthatjfsgeneratescallsintoaruntimelibrarythatimplementsthesemanticsofrelevant floatingpoint andbitvector typesfromthesmt libv2standard handlingroundingmodesthat arenativelysupportedbythe x86 64architecture allmodesexcept round to nearest ties to awayfrom zero .
evaluation wenowturntotheevaluationofjfs comparingitagainstseven state of the art smt solvers that support solving floating point constraints.
we discuss the benchmark selection process .
the solversandhowweconfiguredthem .
and ourexperimental setup .
.wethenpresenttheresultsoftheexperiments .
in thecontextoftheresearchquestionsidentifiedin .wehavemade the sourcecode ofjfsandallour data setspubliclyavailable.
.
benchmark selection table2summarisesthe qf fp qf bvfp andqf bvsmt libsuites from which we have drawn benchmarks for our experiments.
a subsetofthesesuitesareusedinsmt comp theannualsmtsolver competition.allbenchmarksarequantifier free qf beyondwhich thesuitesarebuiltoverfloating point qf fp bitvector qf bv and a combination of bitvector and floating point qf bvfp types.
for eachsuite the suitecolumn provides a reference to thegit repository and sha hash associated with the version of the suite that we used.
the satandunsatcolumns under unpruned total numberof benchmarks in each suite either already labelledsatorunsat or thatwereunlabelled butcouldbe classified empirically as sat or unsat by either mathsat5 or z3 within900secondssecondsonourtestplatform.the unknown andtotalcolumnsshowthenumberofbenchmarksthatremained unlabelled andthe totalnumber of benchmarks respectively.
since jfs is not designed to prove unsatisfiability we pruned all benchmarkslabelledunsat.wealsoprunedallbenchmarksfor whichthepre processingstepsperformedbyjfs .
reducedthe benchmark to contain only constants.
we believe it was important to removesuch trivial benchmarksto focusour evaluationonthe effectivenessoffuzzingforconstraintsolving ratherthantheeffectiveness of these well known pre processing steps.
the pruned benchmarks are summarized under non trivial no unsat in table2.noticethatmanysatbenchmarkswerefoundtobetrivial includingthe vastmajority of the qf fpsuite.
thelargenumbersofremaining qf bvfpandqf bvbenchmarks would require prohibitive computation resources for our experiments.
therefore in a final step we sampled a subset of these benchmarks.
to make sure we include benchmarks of varying difficulty weperformed stratifiedrandomsampling basedonthe performanceofbothmathsat5andz3.thatis foreachbenchmark suite wecomputedtwohistograms oneformathsat5andonefor z3 ofsolver executiontime withfive second wide bins.
toselect abenchmark firstahistogramisselected round robin thenahistogram bin is selected random and then a benchmark is selected fromthatbin random .thisprocesswasrepeateduntilthedesired numberofbenchmarkswereselected.weselected5 ofthebenchmarksfromeachofthepruned qf bvfpandqf bvsuites usingthe prunedqf fpsuiteinitsentirety.detailsofthefinalbenchmark subsets are summarised under final subsets in table2 which we refertoas qf bvfpfs qf fpfsandqf bvfs respectively where fs stands for finalsubset .
.
solverconfigurations we compare jfs against seven state of the art constraint solvers forfloating point constraints.
for eachsolver table 3summarizes the version v or revision r used and the main technique on which the solver is based.
we also include a synthetic portfolio solver jfs mathsat5 toaiddiscussionsofusingjfsinaportfolio setting.jfs mathsat5modelsacompleteportfoliosolverthatruns bothjfs lf ssandmathsat5inparallelandreturnstheanswer fromwhicheversolveranswersfirst.itissyntheticbecausesolving timeis computedas theminimum ofthesolving timesof existing runs of jfs lf ss and mathsat5.
jfs lf ss and mathsat5 are combined because they are the best performing jfs configuration .
.
andsolver for qf fpfs .
.
respectively.
we acknowledge that some of these solvers are capable of provingunsataswellassat whilejfsisonlycapableofprovingsat.
this mightappear to give jfs an advantage but we are not aware of any way to configure those solvers to only focus on sat hence we believe there isnofairer wayof performingthe comparison.
atthe timeexperimentswere run xsathadnotbeenofficially released weuse aversionofthesolveruploadedtostar exec4 for the smt compcompetition.
525esec fse august 26 30 tallinn estonia d. liew c.cadar a.f.
donaldson andj.
r. stinnett table summary ofthesmt libbenchmarksuites we use as abasisforour experiments.
unpruned non trivial no unsat final subset fs suite sat unsat unknown total sat unknown total sat unknown total qf fp qf bvfp qf bv table the solvers compared inour experiments.
solver version technique colibri r1572 intervalsolving coral v0.
meta heuristicsearch cvc4 v1.
bit blasting gosat rb5a423c mathematical optimisation jfs thispaper r5ceecd1 coverage guidedfuzzing mathsat5 v5.
.
bit blasting xsat see text mathematical optimisation z3 v4.
.
bit blasting thecoral gosatandxsatsolversdonotsupportbitvector reasoning thus we can only apply them to the qf fpfsbenchmark suite.
instead of the smt libv2.
format coral uses its own constraint language that only supports a subset of the semantics of theqf fptheory.toallowabest effortcomparisonwithcoral we have implemented a tool to convert smt libv2.
constraints intothis language.
we run each solver using its default configuration edited if necessarytoenablefloating pointreasoningandtoenforcesmt lib compliance.exceptionsarecoral whichwerunusingoptions suggested by the developersas we were unsure how to bestinvoke the solver and mathsat5 which comes with a file describing preferredoptionsforeachbenchmarksuite smtcomp2015 main.txt .
weruncoralintwodistinctmodes alternatingvariablemethod coral avm andparticleswarmoptimisation coral pso .we run jfsinthree modes using libfuzzer withnaive seeds jfs lfns usinglibfuzzerwithsmartseeds jfs lf ss andusingpurely naive random input generation i.e.
without libfuzzer jfs nr .
in allcasesthe fail fastencoding isused see .
.
where solvers support setting a random seed we use a fixed per solver seedto try to ensure reproducibleresults.
.
experimentalsetup we ran the configurations eight solvers with coral in two and jfs in three configurations respectively on a machine with two intel xeon e5 v2 cpus physical cores each with 256gib of ram running ubuntu .04lts .
each solver was run five times per benchmark with a timeout of seconds per run andwithafixedrandomseed ifsupported .therepeatrunsofa solverareusedtocomputeaverageexecutiontimeandobservenondeterministic behaviour.
to allow experiments to complete within a reasonable time frame each solver was executed in parallel over the set of benchmarks with at most benchmarks running in parallel.
each time a solver is run on a benchmark we record a result label.
if solver reports unknown crashes or hits the memory ortimelimit theresultislabelledasunknown.ifthesolverreports sat unsat and that matches the expected satisfiability of the benchmark or the expected satisfiability is unknown then the resultislabelledassat unsat .ifthesolverreportssat unsat andtheexpectedsatisfiabilityofthebenchmarkisunsat sat then the result islabelledas wrong.
wecombinedresultslabelsforrepeatrunsofasolveronabenchmark as follows if at least one label is sat unsat and all labels are either sat unsat or unknown the combined label is sat unsat .
if at least one label is wrong or the labels include a mixtureofsatandunsat thecombinedlabeliswrong.otherwise in the case where alllabels are unknown the combined label isunknown.
tocombinetheexecutiontimes wallclocktime thearithmetic mean andconfidence intervals .
are computed.
mean executiontimesareonlyconsidereddistinguishablebetweensolversif theirconfidence intervals do not overlap.
.
results we now present and discuss our experimental results relating themtotheresearchquestionsidentifiedin .in .
.1weaddress rq1andrq2bycomparingdifferentjfsconfigurations.thenin .
.2wecomparetheoverallbestjfsconfigurationfoundin .
.
against othersolvers inorder to address rq3.
tovisualisesolverperformanceweusequantileplots e.g.figure1 .eachcurveonaplotcorrespondstoasolverconfiguration.a curveisplottedbycomputingascoreforeachrunonabenchmark forcorrect forwrong and for unknown sorting correct results by solver execution time and then plotting accumulating scoreagainstsolverexecutiontime.anextraleftmostpointisthen addedtothecurveandallotherpointsareoffsetalongthex axisby this value.the xvalueof this pointisthe sum of negative scores.
the resulting quantile plot has the following properties the x value of the leftmost point on a curve indicates the number of incorrect solver answers e.g.a valueof onthe x axisindicates thesolverincorrectlyreportedsatisfiabilityonfivebenchmarks therefore the x valueoftheleftmostpointscanbecomparedbetweencurves rankedbyleastnumberofwronganswers the x valueoftheright mostpointonacurveisthedifferencebetween thenumberofcorrectvs.incorrectsolveranswers therefore the x valueoftherightmostpointscanbecomparedbetweencurves ranked by total solver score the total execution time of a solveroncorrectlysolvedbenchmarksisequaltotheareaunder the curve.
we cannot compare the points with the same y value betweencurvesbecausethepointsdonotnecessarilyrefertothe same benchmark.
however we can compare the general shapes of curves.
the quantileplots that followare bestviewedincolour.
526jfs solvingfp constraints usingcoverage guidedfuzzing esec fse august 26 30 tallinn estonia accumulated score runtime s jfs nr jfs lf ns jfs lf ss figure comparingjfsconfigurationsover qf fpfs.
accumulated score runtime s jfs nr jfs lf ns jfs lf ss figure comparingjfsconfigurationsover qf bvfpfs.
.
.
jfs configuration comparison.
we compare jfs in three different configurations jfs lf ns jfs lf ss jfs nr .
on the three benchmarksuites.
on theqf bvfssuite all jfs configurations performed poorly .
ofthebenchmarkscouldnotbesolvedbyanyconfiguration withverylittledifferenceinperformancebetweentheconfigurations.wediscussthepoorperformanceofjfsonthissuitein .
.
restrictingourattentionto qf fpfsandqf bvfpfsfortheremainder ofthis subsection.
the quantile plots of figures 1and2summarise the performance of the jfs configurations over the qf fpfsandqf bvfpfs benchmarks respectively.
the zero leftmost x values of all curves indicatesthatnoincorrectresultswereproduced thisalsoholds forqf bvfs .
forqf fpfs figure1 the right most x value of each curve showsthatjfs lf sssolvedthemostbenchmarks followed byjfs lf ns andfinallybyjfs nr providingpositive support for rq1 and rq2.
the shape of the curves shows that jfslf ss is generally faster than both jfs lf ns and jfs nr smaller areaundercurveifcurvewidthsarenormalised furthersupporting rq2.however uponinvestigationwenoticedthatjfs lf sswastable jfs lf ssvs.other jfsconfigurationsover qf fpfs.
solver both onlylf ss onlyother neither jfs lf ns .
.
.
.
jfs nr .
.
.
.
allabove .
.
.
.
thefastestconfigurationfor22benchmarks jfs lf nsfor6 and jfs nrfor24.fortheremainingbenchmarks itwasnotpossible todeterminewhichconfigurationwasfastest eitherbecausethe solverexecutiontimeconfidenceintervalsoverlappedorbecause none of the solvers reported sat.
it is expected that jfs nr might sometimesbefasterbecauseithasloweroverheadthantheother configurations e.g.
no coverage instrumentation no seeds to read .
forqf bvfpfs figure2shows thatjfs lf ns solvedthe most benchmarks followedby jfs lf ss andfinally jfs nr .
we can see that the shape of the curves for the libfuzzer configurationsaresimilar suggestinglittledifferenceinoverallperformancebetweenthem.however thenaiverandomconfiguration is clearly worse.
these results provide positive support for rq1 andare inconclusive withrespectto rq2.
quantile plots do not tell the complete story.
tables 4and5 show jfs lf ss similarity complementarity and limitations for theqf fpfsandqf bvfpfsbenchmarks compared to the other jfs configurations.ineachtable the bothcolumnstatesthenumber ofbenchmarksshowntobesatisfiablebybothjfs lf ssandthe other jfs configuration.
the only lf ss only other column showsthenumberofbenchmarksthatwereshowntobesatisfiable by jfs lf ss other configuration and not by the other configuration jfs lf ss .
the neithercolumn shows the number of benchmarks that were shown to be satisfiable by neither jfs lf ss northeotherconfiguration.eachrowofthe tablecorrespondsto theothersolver specifiedbythe solvercolumn .the allabove row has a special meaning and is a combination of all the above results.
for the all above row the bothtable cell is the union of all benchmarks thatbothjfs lf ss andanother jfsconfiguration managed to solve i.e.
it is a union of intersections not an intersection of intersections the only lf ss table cell is the number of benchmarksfoundsatisfiablebyjfs lf ssandnoneoftheother configurations the only other table cell is the union of all benchmarks found to be satisfiable by another configuration and not jfs lf ss and the neithertable cell is the number of benchmarks not foundsatisfiablebyany jfs configuration.
forqf fpfs table4shows that jfs lf ss and jfs lf ns are quitesimilar .
ofthebenchmarkssolvedbybothand .
by neither perhaps unsurprising given that they only differ in the seeds fed to libfuzzer.
by contrast jfs nr is less similar with .
ofbenchmarks solvedonly byjfs lf ss.
in terms of complementarity jfs lf ss always solved benchmarksthattheotherconfigurationsdidnot.althoughtheconverse is true other configurations solving benchmarks that jfs lf ss did not it is less frequent.
looking at limitations .
of the benchmarks were not solvedbyany jfs configuration.
forqf bvfpfs whilethequantileplotoffigure 2suggeststhat jfs lf ns performs slightly better than jfs lf ss due to the numberofbenchmarksolved table 5showsthattherearetwobenchmarks that only jfs lf ss solved and three that only jfs lf ns 527esec fse august 26 30 tallinn estonia d. liew c.cadar a.f.
donaldson andj.
r. stinnett table5 jfs lf ssvs.otherjfsconfigurationsover qf bvfpfs.
solver both onlylf ss onlyother neither jfs lf ns .
.
.
.
jfs nr .
.
.
.
allabove .
.
.
.
solved showing that neither configuration is strictly superior to theotheronthisbenchmarksuite.regardinglimitations thejfs configurations performed collectively well on this suite withonly .
not solvedbyany jfsconfiguration.
overall for formulas involving floating point constraints the results of this subsection show that using coverage guided fuzzing overnaiverandominputgenerationoffersbenefit supportingrq1.
theresultsalsopartiallysupportrq2inthisdomain showingthat smartseedsimprovetheperformanceofjfsover qf fpfs.whilethe performanceresultsforjfs lf ssandjfs lf nsover qf bvfpfsdo notrevealaclearwinner weusejfs lf ssasthejfsconfiguration for comparison against other solvers in .
.2due to its superior performance onthe qf fpfssuite.
.
.
jfscomparedwithothersolvers.
wenowaddressrq3by comparingthejfs lf ssconfigurationofjfsagainstsevensolvers ontheqf fpfsbenchmarksandfouronthe qf bvfpfsandqf bvfs benchmarks.
comparison over qf fpfs.the quantile plot of figure 3summarisesperformanceresultsfortheeightnon portfoliosolversplus jfs mathsat5over qf fpfsbenchmarks.theleftmostpointsfor xsatandcolibriindicatethattheygave 34and5wronganswers respectively.
in all cases this was due to unsat being reported for asat labelledbenchmark.
in terms of the number of benchmarks found to be satisfiable jfs mathsat5 was the most successful followed by mathsat5 jfs cvc4 colibri z3 gosat xsat coral pso and finally coral avm .
even though jfs does not rank the highest by number of benchmarks solved we can see from the shape of the curves that jfs s totalsolving time is significantlysmaller than mathsat5 swhich solved the most benchmarks out of the non portfolio solvers.
the jfs mathsat5syntheticportfoliosolverillustratesthataportfoliocombinationofjfs lf ssandmathsat5wouldperformwell because it would solve the most benchmarks and in less time on average.
table6shows jfs s capability complementarity and limitations for theqf fpfsbenchmarks.
the columns and special all above rowhavethesamemeaningasdiscussedfortable 4in .
.
.table6 showsgreatdealofsimilarity bothcolumn betweenmathsat5 andjfs followedbycolibriandcvc4 andthenz3.thesimilarity withtheothersearch basedsolvers coral avm coral pso gosat andxsat issomewhat lower.
jfscomplementseveryothernon portfoliosolver i.e.thereisat leastonebenchmarkthatjfscansolveandtheothersolvercannot.
however every benchmark solved by jfs can be solved by at least one other solver.
for the search based solvers coral gosat jfs andxsat jfsfindsmanybenchmarkstobesatisfiablethattheother solver does not.
this shows that out of the all the search based solvers jfsisthemostcompetitiveonthe qf fpfsbenchmarksuite.
accumulated score runtime s colibri coral avm coral pso cvc4gosat jfs mathsat5xsat z3 jfs mathsat5figure quantile plot comparing the performance of solvers on the qf fpfsbenchmarks table jfscompared to other solvers over qf fpfs.
solver both onlyjfs onlyother neither colibri .
.
.
.
coral avm .
.
.
.
coral pso .
.
.
.
cvc4 .
.
.
.
gosat .
.
.
.
mathsat5 .
.
.
.
xsat .
.
.
.
z3 .
.
.
.
allabove .
.
.
.
intermsoflimitations everysolverexceptcoral avmfindssome benchmarks to be satisfiable that jfs does not i.e.
most solvers are able to complement jfs .
there are also some benchmarks that neither jfs noranothersolver manage to showas satisfiable.
jfs is also complementary in terms of execution time.
figures and5showscatterplotscomparingtheexecutiontimeofjfsagainst mathsat5 and cvc4 respectively.
we show mathsat5 and cvc4 herebecausethesearethesolversthatfoundthehighestnumber of benchmarks to be satisfiable that jfs did not.
on these plots each point represents a benchmark.
a diagonal line y x is drawn uponwhichabenchmarkwouldlieifbothsolverssolved thebenchmarkinanidenticalamountof time.pointsthatappear belowthediagonalarecaseswherejfswasfaster andpointsabove the line are cases where the other solver was faster.
the number of points where this is the case and where confidence intervals do not overlap are shown on the figures along with annotation indicating howmanypointsare caseswherebothsolversreached atimeout.theseplotsonlyshowcaseswherebothsolverseither reported sat or reached a timeout because it does not make sense to compare execution times if one of the solvers crashed.
the plots show that the solvers are highly complementary with jfs being faster for benchmarks in each case while mathsat5 was faster for benchmarks andcvc4for .
inrelationtorq3 theseresultsshowthatjfsisverycompetitive with other solvers on the qf fpfsbenchmarks and is able to complementevery solver considered.
528jfs solvingfp constraints usingcoverage guidedfuzzing esec fse august 26 30 tallinn estonia mathsat5 execution time s 900jfs execution time s dual timeouts160 benchmarks jointly sat or timeout figure4 scatterplotcomparingtheexecutiontimeofmathsat5 andjfson the qf fpfsbenchmark.
cvc4 execution time s 900jfs execution time s dual timeouts160 benchmarks jointly sat or timeout figure5 scatterplotcomparingtheexecutiontimeofcvc4 andjfson the qf fpfsbenchmark.
comparisonover qf bvfpfs.figure6showsaquantileplotcomparingjfsagainstjfs mathsat5andtheotherthreenon portfolio solversthatsupportthe qf bvfpfssuite.theplotshowsthatthe none of the solvers report incorrect answers and that they all reportasimilar numberofbenchmarksas satisfiable.
jfs mathsat5 cvc4 mathsat5 and z3 report 699benchmarks as satisfiable followedbyjfswith andcolibriwith .thefigurealsoshows that for every solver over benchmarks were solved in under a second.
this suggeststhatthe benchmark suite despite ourbest efforts during stratifiedsampling is not well balanced interms of difficulty and may not accurately reflect the kind of constraints that might be encountered inpractice.
table 7shows the similarity complementarity and limitations of jfs on this benchmark comparedtoothernon portfoliosolvers.thetableshowsahighdegree ofsimilaritybetweenthesolversandthatjfsisonlyabletocomplement colibri.
every solver is able to solve benchmarks that jfsisunabletosolve.however ifwemakescatterplotscomparing the execution time of jfs with that of other solvers we find in eachcaseasignificantnumberofbenchmarkswherejfssolvesthe constraints faster faster than cvc4 faster than colibri faster than mathsat5 and faster than z3 .
we omit these plots for brevity but they look very similar to figures 4and5.
accumulated score runtime s colibri cvc4jfs mathsat5 z3 jfs mathsat5figure quantile plot comparing the performance of solvers on the qf bvfpfsbenchmarks.
table jfscompared to other solvers over qf bvfpfs.
solver both onlyjfs onlyother neither colibri .
.
.
.
cvc4 .
.
.
.
mathsat5 .
.
.
.
z3 .
.
.
.
allabove .
.
.
.
with reference to rq3 these results show that jfs is competitive over qf bvfpfs complementing colibri in the number of benchmarkssolved andallothersolversintermsofexecutiontime.
however as discussed the results across all solvers suggest that qf bvfpfsmaynot be an especiallychallenging suite.
comparisonover qf bvfs.jfsisnotcompetitiveonthe qf bvfs suite finding only 22benchmarks satisfiable comparedtoe.g.
forz3and 344formathsat5.
weomittheassociatedquantileplot forspacereasons.
however foreachsolverexceptcvc4 thereare alwayscaseswhere jfsisableto solve somebenchmarks faster.
wesuspecttwomainreasonsforthepoorperformanceofjfs onthebitvector onlytheory comparedtothetheoriesinvolving floating point.
first floating point constraints result in much more complex circuits which often blow up the underlying sat solvers usedbystate of the artsmtsolvers.asaresult amorelightweight approach like the one used by jfs is competitive on these theories.
second bitvectorsolvershavebeenavailableforoveradecade which has allowed a set of difficult and challenging benchmarks to be developed over a long period of time.
these benchmarks likely evolvedindifficultyasbitvectorsolversgraduallyincreasedtheir capability.
on the other hand solvers for floating point constraints are comparatively new and have had much less time to develop.
as a consequence the available floating point benchmarks are a reflection of the relatively immature floating point constraint solvers currently available.
itisalsoworthdrawingananalogywithcoverage guidedfuzzers applied to bug finding their usual domain .
these fuzzers are typically good at finding shallow bugs and can only excel at finding deep bugs with a large amount of compute time good seeds or 529esec fse august 26 30 tallinn estonia d. liew c.cadar a.f.
donaldson andj.
r. stinnett domain specificknowledge.itcouldbethecasethatthefloatingpointbenchmarkscurrentlyavailableinsmt libaretheequivalent ofshallowprograms where bugsare easyfor afuzzerto find.
in summary with respect to rq3 the results across all three benchmarksuitesshowthatjfsishighlycompetitiveontwosuites both involving floating point and uncompetitive on the bitvector benchmarksuite.
related work thereisalargebodyofexistingworkthatseekstoimprovesolving floating point constraints.
the coral and flopsy solvers apply meta heuristic search techniques to try to find satisfying assignments to floating point constraints.
like jfs these methodsare incompletebecausetheycanonlyshowsatisfiability.
all solvers construct a fitness function which they attempt to maximise.jfs sfitnessfunctioniscoarse thenumberofnewbranches covered in contrast to coral s and flopsy s fitness functions which gradually change as candidate solutions get closer to a satisfyingassignment.despitethecoarsenessofjfs sfitnessfunction ourresultsshowthatjfsperformsbetteroverallthancoral both in terms of the number of benchmarks it can show to be satisfiable and in execution time.
we could not easily compare with flopsy duetoitstightintegrationwithpex thesymbolicexecution toolitisdesignedto work with.
coral supports using an interval solver to improve the quality of its initial candidate inputs.
it s likely we could apply a similar approach injfsto generatehigher qualityseedsfor the fuzzer.
the gosat and xsat solvers both reformulate finding a satisfying assignment as a mathematical optimisation problem and applyexistingmathematicaloptimisationalgorithmstotrytofinda globalminimum.thisissimilarinspirittojfs flopsyandcoral in that the functions that gosat and xsat seek to minimise are essentiallyfitnessfunctions.thedifferenceisinthealgorithmsused to performthe search.
likejfs this strategy isincomplete.
again despite jfs s coarser fitness functions the experimental evaluation foundjfsto perform betteronthosebenchmarks.
cvc4 mathsat5 sonolar and z3 solve floating point constraints by transforming floating point operationsintobitvectorcircuitsandthenbit blastingtheseintoasat problem.
this problem is then solved using a sat solver.
unlike jfs thesesolversarecomplete buttheycanendupgeneratingvery large sat problems which are difficult to solve.
like jfs these solverssupportacombinationofthebitvectorandfloating point smt libv2.
theories.
our comparison with cvc4 mathsat5 and z3indicatesthattheapproachesarecomplementary particularly for the floating point benchmarks suggesting these solvers would likely benefitfrom incorporatinga jfs style search based strategy with their existing strategies to form a portfolio solver.
we did not compare jfs with sonolar but given that its design is similar to that of sat based solvers we do not expect such experiments to change our main conclusions.
a prior study comparing satbasedsolvingwithrandomand heuristic solversalsofound thata portfolioapproach performs best .
colibri andfpcs useintervalsolvingasacomplete methodforsolvingfloating pointconstraints.asforthecomparison with sat based solvers our comparison with colibri showedcomplementarity suggestingthatthesesolverscouldalsobenefit from incorporating a search based strategy.
we did not compare against fpcsbecause itisnot publiclyavailable.
realizer tries to solve floating point constraints by transforming inanequisatisfiablemanner floating pointconstraints into constraints over reals using z3 as a back end to solve these constraints.
realizer s strategy is particularly suitable for workingwithconstraintsthatchecktheaccuracyoffloating pointexpressionscomparedtotheirrealcounterparts.jfscannotdothis because it cannot handle constraints over reals.
we have not yet hadtime to compare jfswithrealizer.
more generally floating point constraint solving has gathered a lot of attention from the research community with several tools based on symbolic execution model checking abstract interpretation etc.
using it to perform test case generation precision tuning verification equivalence checking peephole optimizations branch instabilityassessment etc.involvingfloating pointcode 10 19 23 52 56 .
conclusion wehaveinvestigatedusingcoverage guidedmutation basedfuzzing toprovesatisfiabilityofsmtformulasoverfinitevariabledomains andfloating pointconstraintsinparticular viaaprototypesolver jfs.
our main experimental findings are that in the domain of floating point constraints solving via coverage guided fuzzing outperformssolvingvianaivefuzzing andperformancecanbefurther improvedbygeneratinginitialseedsinasmartmanner jfsishighly competitivewithandcomplementarytoallsolverswecompared with in the floating point domain and jfs is much less effective whenappliedtothedomainofbitvectors.oursyntheticportfolio solving results indicate that jfs s complementary nature would make itauseful componentinaportfoliosolver.
infuturework wewouldliketobetterunderstandtheproperties of benchmarks that dictate whether jfs performs well with a view to developing heuristics to help decide when it would be beneficial to apply jfs.
a first step in this direction would be to use model countingsolversto understandwhether suitabilityfor solvingvia fuzzing relates to number of solutions.
a practical problem here is that modelcountingsuffers from limitedscalability.
regarding our smart seeds smarterseeds could be generated basedondomain specificknowledgeaboutthecontextinwhichjfs isbeingused.for example if jfs wereintegratedwithasymbolic executionengine seedsencodingknowledgeaboutfeasiblepaths andthusfeasibleinputs couldbecommunicatedfromthesymbolic execution engine to jfs.
we also envisage severalimprovements to the fuzzing component of jfs designing mutators tailored to thecontextofsmt formulas would likelybe beneficial thefuzzer couldbemadeawareofdataflow usinginformationaboutthebytes that caused a constraint to become satisfied to guide mutations andcandidatesformutationcouldbeprioritisedaccordingtothe numberofconstraintstheysatisfy whichwehypothesisewould leadto fastersynthesis of satisfyingassignments.