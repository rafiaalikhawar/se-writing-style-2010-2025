an empirical evaluation of two user interfaces of an interactive program verifier martin hentschel tu darmstadt dept.
of computer science darmstadt germany hentschel cs.tudarmstadt.dereiner h hnle tu darmstadt dept.
of computer science darmstadt germany haehnle cs.tudarmstadt.derichard bubel tu darmstadt dept.
of computer science darmstadt germany bubel cs.tudarmstadt.de abstract theorem provers have highly complex interfaces but there are not many systematic studies of their usability and effectiveness.
specifically for interactive theorem provers the ability to quickly comprehend intermediate proof situations is of pivotal importance.
in this paper we present the as far as we know first empirical study that systematically compares the effectiveness of different user interfaces of an interactive theorem prover.
we juxtapose two different user interfaces of the interactive verifier key the traditional one which focuses on proof objects and a more recent one that provides a view akin to an interactive debugger.
we carefullydesignedacontrolledexperimentwhereusersweregiven variousproofunderstandingtasksthathadtobesolvedwith alternating interfaces.
we provide statistical evidence that the conjectured higher effectivity of the debugger like interface is not just a hunch.
ccs concepts software and its engineering software verification formal software verification software testing and debugging keywords verification proof understanding empirical evaluation .
introduction one of the most time consuming and challenging steps in deductive semi automatic program verification is to understand why a proof attempt fails.
reasons for failure include of course buggy programs or specifications.
it is also possiblethattheautomateddeductioncomponentisnotpowerful enough to find a proof.
in either case the user needs to develop sufficient understanding of the current proof situationto be able to fix the program specification or to perform adequate interactive proof steps.
this involves navigating in large proof trees and inspection of open proof obligations which may consist of dozens of large formulas.
to improve the efficiency of understanding intermediate proof situations therefore promises considerable gains in the overall human user time that needs to be invested into formalverification.
toachievethisgoalwedecidedtodesign acompletelynewguiforthestate of artverificationsystem key based on a software productivity tool all programmers are familiar with and which according to anecdotal evidence they spend most of their time with a debugger.
specifically we extended the symbolic execution debugger sed by adding support for performing verification proofs .
the sed1is an eclipse extension for interactive symbolic execution into which any symbolic execution engine can be integrated.
the enhanced sed is able to process the information contained in any key proof to summarize it and to present that summary in a succinct manner to the user in a number of different views.
more precisely the sed visualizes the partial program behavior explored in a proof attempt in form of a symbolic execution tree.
each tree node represents an execution step made by the program and allows the user to inspect the corresponding symbolic state thus helping to comprehend program behavior.
in addition nodes are marked as not verified if a proof obligation could not be shown.
an important feature of the sed is that for each subformula of a proof obligation it can be traced whether it has already been shown to hold.
this permits to easily identify those parts of a proof obligation and of a related specification that have notbeen shown to hold.
all that sounds good plus there was anecdotal evidence from the user community that key s new user interface indeed tends to improve the efficiency of verification.
but before investing more effort in the new gui we wanted to confirm whether this perceived efficiency increase is more than a hunch.
to do so we decided to use an empirical approach that is standard in experimental software engineering but as far as we know constitutes the first study to empirically compare the effectiveness and efficiency of different user interfaces ui of an interactive theorem prover .
we compare the new ui based on the sed with the key s standard ui.
both interfaces let the user inspect a proof attempt to verify that a java program complies with its specifica1available at permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
copyrights for components of this work owned by others than acm must be honored.
abstracting with credit is permitted.
to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
request permissions from permissions acm.org.
copyright is held by the owner author s .
publication rights licensed to acm.
ase september singapore singapore acm.
... .
tion.
the specification style follows the design by contract paradigm and the java modeling language jml is used as the specification language.
the goal of our work is to gain experimental evidence of whether there is a significant difference in effectiveness and efficiency between both uis.
participants of the experiment were shown several proof attempts and were asked questions to measure how well they understand them.
each proof attemptwasabouttheverificationofasmallexample inspired by an interesting problem or a real world case study.
the experiment was announced publicly on the key website and keymailinglisttargetingallkeyusersandkeydevelopers.
we summarize the scope of the experiment analyze proof inspection in key and sed for the purpose of evaluating effectiveness and efficiency from the point of view of the researcher in the context of all key users .
thepaperisorganizedasfollows section2discussesrelated work.
then we briefly summarize the main characteristics of the prover uis section followed by a description of the experiment s planning and setup.
the measured variables are determined in section the hypotheses to test in section .
section lays out the design of the experiment section presents the instrumentation.
we conclude experiment planning by discussing threats to validity in section .
the execution of the experiment is presented in section .
collected data are analyzed in section before discussing the results in section .
we conclude the paper with section .
.
related work the authors of evaluate the usability of key and isabelle using focus groups.
their goal is to improve the usability of these tools but they do not perform a direct comparisonbetweenthem.
theauthorsof presenta cooperative evaluation of a specific feature called interactive proof critics .
similar to our experiment participants had to inspect and correct failed proof attempts however user interfaces were not evaluated.
in a questionnaire to identify desired features of user interfaces of proof systems is presented.
most of the identified points are realized by the sed.
in the use of hol is analyzed and a three layer model for interaction with a theorem prover is presented.
the sed covers all levels with its different views.
in a survey toexplorepossiblenewfeaturesofthenuprltheorem prover is presented.
in summary usability investigations were made for several interactive theorem provers.
but to the best of our knowledge no experiment was performed to actually evaluate whether proposed features really improve productivity or to compare different user interfaces.
.
ui characteristics the key verification system is based on a deductive formulation of symbolic execution in a program logic where programs are annotated with loop invariants and method contracts.
key s standard ui focuses on proof objects while the one based on sed provides a view akin to an interactive debugger.
to get an impression of these fundamentally different approaches consider figures .
in figure the sed is used to inspect the proof attempt of class myinteger in editor view on top left .
the symbolic execution treeview top right shows that only one execution path is feasible.
this is because the precondition non null of the jml method contract excludes that a nullpointerexception is thrown.
in addition the red crossed out icon of the selected symbolic execution tree node end indicates that the method contract does not hold here.
to identify the reason consider the properties view bottom left .
the only open goal node shows on the right side of the sequent arrow the formula to be proven in the current state in curly braces .
that formula is a translation of the jml specification into logic and with a little experience easy to read.
the view colors subformulas to indicate whether they were evaluated to true false or that their status is still unknown.
it was evaluated to false and operators are colored in red indicating that something is wrong.
we know that the class invariant is preserved and that no exception is thrown that would violate jml s normal behavior because the related formulas hold are colored in green .
only the postcondition and the assignable clause remain open colored in orange .
the left side of the sequent arrow says under which assumption the right side is evaluated.
the method parameter summand and the thisreference called self point to the same object which is suspicious.
this state is also visualized in the symbolic object diagram shown in the callout top right .
alternatively view variables shows the symbolic state as a tree structure.
it is obvious that the precondition does not hold in this state and the defect is found.
in figure the same proof attempt as in figure is inspected using key s standard ui.
the proof tree is shown in the bottom left tab proof.
the proof obligation of the selected proof tree node is shown in the view on the right current goal .
during proof attempt inspection it is recommended to focus on one goal.
the tab goalsallows the user to navigate between the open goals.
the first step is usually to identify the currently taken symbolic execution path.
this is achieved by hiding all non branching proof steps seethe calloutinfigure2 .
here objects m summand and m 1are not null.
in addition summand self and self.value !
hold.
reading this path condition is challenging because it contains objects and expressions not part of the verified source code and its specification.
the next step is to inspect the proof obligation of the current goal.
if this does not reveal the defect the only way to increase understanding is to look at each proof step.
alternatively the proof could be continued interactively which here is hopeless because of the present defect.
to summarize the full proof including all performed steps can be inspected using key whereas the sed hides many proof steps by offering various summary views.
.
variable selection first we need to determine and classify the variables of the experiment.
we distinguish two kinds of variables independent variables anddependent variables .
the independent variables are those which can be varied or at least controlled by us and whose influence and effect on the outcome of the experiment we intend to study.
dependent variables are the ones measured during the course of the experiment and which we want to study.
a value of an independent variable that was changed during the experiment is called treatment .
table lists the variables of our experiment.
the independent variables which can be varied by us are m with treatments key and sed and p with the four proof at404figure screenshot of the sed in which the proof attempt of class myinteger is inspected temptstoinspect .
thesubsetofindependentvariablesthat are merely controlled are calledejava jml key sed.
their values reflect the participants experience level.
the separation between less and more than two years is made to separate beginners from experienced users assuming that this is roughly the time needed to master java jml and key well enough for this evaluation.
as the sed is rather new it is assumed that participants do not have a lot of experience with it.
for this reason the separation between beginners and experienced users is set to one year.
the dependent variables are used to quantify efficiency andeffectiveness of the different tools.
efficiency is measured by the time ttmspend to answer the questions using tooltm m. effectiveness is measured in the number of correctly answered questions and the confidence in the given answers.
questions are single or multiple choice questions to enable an automatic analysis.
each question lists a number of correct and wrong answers from which the participant has to choose.
for a given tool tm a multiple choice question is answered correctly measured by qtm if all and only the correct answers are selected.
a correctness score is used to give credit for partially correct answers.
the correctness score qstm summationtext q tmqs q is the sum of the scores over all questions of treatment tm.
for a single question qthe scoreqs q is defined as qs q braceleftbigg corselansw q wrgselansw q corselanswif corselansw q wrgselansw q corselansw q wrgselansw q wrgselanswif corselansw q wrgselansw q the question score qs q is the difference between the numberofselectedcorrectanswers corselansw q andthenumberofselectedwronganswers corselansw q ofquestion q normalized by the total number of correct wrong answers.after each question we asked the participants about their confidence in the answer.
confidence levels are sure my answer is correct!
educated guess as far as i understood the content my answer should be correct.
andunsure i tried my best but i don t believe that my answer is correct.
.
for each question q each question score qs q a confidence rating c q cs q is computed according to table .
a participant who is sure the answer is correct when it is actually correct the confidence score is positive obtains maximal points.
if the answer is wrong but the participant was sure that it is correct the confidence score is positive he or she gets the lowest possible rating.
if the answer is based on an educated guess which is weaker than certainty the participant gets less or loses less points.
if the participant is unsure and thinks the answer is wrong and it is actually wrong the confidence score is not positive then still one score point is assigned because the intuition was correct.
if the participant thinks the answer is wrong but it is right the confidence score is positive he or she loses one scorepointforthesamereason.
finally theconfidencescore ctm summationtext q tmc q is the sum of the confidence ratings over all questions answered for treatment tm.
the confidence score based on question scores cstm summationtext q tmcs q qs q takes partially correct answers into account.
.
hypothesis formulation from our experiment we want to gain statistical evidence that using the sed is more efficient and effective than using key s standard user interface.
to this extent we formulate for each dependent variable see table an alternative hypothesish1q h1t see table .
as usual the claims 405figure screenshot of key in which the proof attempt of class myinteger is inspected table variables name values description independent variablem key sed compared tools p calendar account arrayutil myinteger inspected proof attempts and related questions each proof attempt verifies a method contract of one of the listed classes controlled variableejava none 2y.
2y.
experience with java ejml none 2y.
2y.
experience with jml ekey none 2y.
2y.
experience with key esed none 1y.
1y.
experience with sed dependent variableqtminteger number of correctly answered questions per treatment tmofm qstmreal correctness score per treatment tmofm ctminteger confidencescorepertreatment tmofmbasedonq cstmreal confidencescorepertreatment tmofmbasedon qs ttminteger time needed to answer questions of a treatment tmofmin seconds table confidence ratings c q cs q of question q correct answer wrong answer ofqorqs q 0ofqorqs q sure educated guess unsure of these hypotheses are confirmed by ruling out each corresponding null hypothesis h0q h0t.
.
choice of design type an important design decision of the experiment is to ensure that participants benefit from their participation.
to achieve this each participant uses both tools resulting in a paired comparison design see table .
in case participants are unfamiliar with key or the sed this allows them to try out both tools and to decide which one is of greater benefit for their work.we applied the general design principles randomization blocking andbalancing to avoid biases to block out effects in which we are not interested in and to simplify and strengthen hypothesis testing.
we randomized the order of proof scenarios presented to the participants to avoid that forinstance differencesinthelevelofdifficultycaninfluence the result of the experiment.
the first two proof attempts are always to be understood with help of the same tool and the next two proof attempts with the other tool recall that we have four proof understanding tasks .
the decision which tool is used for the first two proof attempts is random.
this avoids multiple switches between tools which could confuse the participant.
additionally a participant who is not familiar with a tool has more experience in the second task.
the server used to collect evaluation results guarantees that all possible permutations of proof orders will be evaluated equally often as well as all other constraints.
the performance of the participants may depend on their experience with key and sed.
as the sed is relatively new and likely unknown to most participants prior experi406table hypotheses name of null hypothesis definition of vtmfor dependent variable v treatment tmname of alt.
hypothesis h0q qsed qkeywith qtm qtm questionsoftmnt x q x h1q qsed qkey h0qs qssed qskeywith qstm qstm questionsoftmnt x q x h1qs qssed qskey h0c csed ckey with ctm ctm questionsoftmnt x q x h1c csed ckey h0cs cssed cskeywith cstm cstm questionsoftmnt x q x h1cs cssed cskey h0t tsed tkey with ttm ttm timeofalltmnts x q x h1t tsed tkey table paired comparison design proof proof proof proof attempt attempt attempt attempt sed subjnsubjnsubjn 1subjn key subjn 1subjn 1subjnsubjn ence with key is used for blocking.
grouping the participants according to their experience level with key allows us to interpret the results for the different groups separately.
balancing is automatically achieved by the chosen design because each participant uses both tools and inspects all four proof attempts.
thus the number of participants is the same for each treatment.
.
instrumentation we did not want to limit the group of participants to people familiar with formal methods jml or the tools key and sed.
the only hard requirement the participants needed to fulfill was basic knowledge of java or a similar language .
to accommodate this decision the evaluation had to be selfexplanatory.
we achieved this by showing three instructional videos an introduction to the evaluation itself and one to each tool.
a brief textual introduction was given on how to read and write jml specifications we do not use advanced concepts .
during the evaluation a participant inspects proof attempts with key and the sed.
as both tools are available within eclipse the evaluation itself is implemented as an eclipse wizard which is opened in an additional window so that eclipse itself remains fully functional.
the evaluation setup consists of two phases during which information is collected and sent to the server.
the first phase collects background knowledge on the participant and determines the order of proof attempts and the tool assignment.
the actual evaluation is performed in the second phase.
a participant who cancels the evaluation during the second phase is asked to send partial results to the server.
when that participant opens the evaluation wizard the next time heorsheisofferedtorecoverthepreviousstatetocontinue the already started evaluation.
the evaluation workflow is in detail .
initialization phase a terms of use terms of use need to be accepted.
b background knowledge experience with java jml key sed.
c sending data data is sent and order of proof attempts is received.
.
evaluation phase a evaluation instructions a video explaining how to answer questions.
b jml a textual documentation introducing the features of jml necessary for the evaluation.
c sed key instruction avideoexplainingneeded features and best practices to review a proof attempt with sed key depending on order .
d proof attempts and the first and second proof attempt and the questions that test the understanding.
e the complementary sed key instruction the remaining video.
f proof attempts and as above g feedback about tools and evaluation the participant is asked to rate the usefulness of sed and key features mentioned in the videos .
h sending data and acknowledgment data is sent and the successful completion is acknowledged.
for each proof attempt the jml annotated java source code2is shown to the user inside the eclipse ide.
the inspectedproofattemptitselfisshowninsidethetoolassigned to the current task.
we summarize the four proof attempts to be inspected and the defects the participants were supposed to identify account is a simplified problem used in a graduate course on software verification with key.
to find out why the proofisstillopen onehastodiscoverthatthecontract of an invoked method is too weak except the type no information about the returned value was specified .
calendar is a simplified version of a program taken from .3the participant must realize that the specified class invariant renders one branch of an if statement unreachable.
inaddition theclassinvariantisnotpreservedandan arraystoreexception mightbethrown.
arrayutil is a simplified problem from an undergraduate course taught at tu darmstadt.
the proof remains openfortworeasons thespecifiedloopinvariantisnot preserved and on one execution path the value stored atanarrayindexisreturnedinsteadoftheindexitself.
understandingproofattemptsevaluation proofs 3available at 407myinteger is from a talk jml editing in eclipse and keyide given by one of the authors at the workshop jml advancing specification language methodologies .4the challenge is to realize that the postcondition does not hold in the case when two inputs are aliased objects.
wedesignedquestionsandanswersforeachproofattempt following the same schema the participant is first asked whether the proof is closed and which statements have been symbolically executed.
in case a participant answers that the proof is still open all applicable reasons why the proof could not be closed from a predefined list of potential causes had to be chosen.
the list is composed of i options generated for each present jml construct as a potential cause ii the possibility that automated reasoning power was insufficient and interactive proof steps are required and iii a free text form.
when a jml construct is selected as cause the participant is asked in which execution paths that construct is invalid preserved etc.
execution paths are identified by comments in the source code.
in case a normal behavior contract is violated due to a thrown exception the participant has to specify the kind of the uncaught exception instead of selecting an execution path.
all questions offer also the opportunity to give up after ten minutes.
.
validity evaluation we discuss threats to the validity of our experiments and the drawn conclusions.
for each threat we provide a mitigation strategy.
conclusion validity concerns the statistical analysis of results and the composition of subjects.
the hypotheses of this experiment are tested with well known statistical techniques.
threats to conclusion validity are the low number of samples and the validity of the quality of answers.
subjects may fake answers to compromise the experiment.
however several participants are people we know colleagues project partners students etc.
in addition some were monitored during the evaluation.
we consider the motivation of subjects to compromise the experiment to be very low.
internal validity concerns matters that may affect the independent variable with respect to causality without the researcher s knowledge.
inspecting a proof is time intensiveandtheestimatedparticipationtimeis60minutes hence participants may get tired or bored.
there is also a risk that participants lack motivation and thus answer questions not seriously.
however participation is voluntary and can be done at any time convenient for the subject.
maturation is a threat to internal validity as each tool is applied to two proof attempts and participants may learn how to use it which is desired.
we consider this non critical as randomization is applied to the order of proof attempts and assigned tools.
some participants may have experience with key but most likely not with sed as it is relatively new.
this is not critical as the instrumentation introduces all relevant features of both tools.
there might be a threat that some participants are not willing to learn how to use the sed.
however sed is designed to support the verification with key and not as a competitor.
a potential bias info.php3?wsid 677about the experience with these tools would only contribute against our claim that sed improves upon efficiency and effectiveness and not in its favor.
other threats are considered to be uncritical.
construct validity concerns generalisation of the experiment result to concept or theory behind the experiment.
a threat to construct validity is that the chosen proofattemptsmightnotberepresentative.
tomitigatethis issue the proof attempts were taken from different case studies and teaching materials that reflect typical usage scenarios of key.
in addition we took care that the proof attempts cover all major jml features like method contracts as well as class and loop invariants.
other threats to construct validity are considered uncritical.
even though a participant might guess the expected outcome from the general motivation of the experiment a comparison between key and the sed and that sed is the newer tool we consider it uncritical as the exact hypotheses and related measurements are unknown to them.
in addition the participants do not have any advantage or disadvantage from the outcome of the experiment.
external validity concerns generalisation of the experiment result to other environments than the one in which the study is conducted.
a threat to external validity is that the source code related to proof attempts is kepttoaminimum inmanycasesonlyonemethod.
thisis required to reduce the time participants need to understand the verified source code and its specification.
real java code is much more complex.
on the other hand contract based verification is modular only a small part of the source code one method at a time is considered per proof.
the participantsareselectedrandomlyandtheirexperiencevariesfrom none to expert.
consequently the selection of participants is not a threat to external validity.
we state that there are threats to the validity of the experiment and hence the drawn conclusions are valid within the limitations of the threats.
.
execution the experiment started in june with the staff of the software engineering group at tu darmstadt.
it included students phd students and postdocs.
each participant was monitored during the evaluation to improve the instructions and answers.
questions and answers remained stable after the first participant.
for this reason the results of the first participant were excluded but the others were kept.
initially all instructions were given as textual descriptions.
it turned out that the participants have little motivation to read them and would prefer videos instead.
this was realized after the first few iterations.
the content of the videos is identical to the initial textual descriptions so the results of the previous participants are still valid.
the evaluation went public in july .
it was announced on the key website key mailing list and during the 14th key symposium.
the evaluation is available as a preconfigured eclipse product.
installation instructions and download links are available on the key website.5main steps are to download and run the eclipse product and to perform the evaluation.
an installation is not required the participants system is unaffected.
until mid novem5 understandingproofattempts.html 408none xyears xyears024681012141618 knowledge participantsjava x jml x key x sed x figure knowledge of participants table key vs sed experience sed none year year none key years years ber participants started the evaluation but only completed it.
twelve of the participants were monitored during the evaluation with their approval .
figure shows the distribution of background knowledge of the participants.
all participants had experience with java only four were unfamiliar with jml.
knowledge about key is evenly distributed between the experience levels.
six participants had surprisingly experience with the sed.
the relation between the key and the sed experience is shown in table .
it shows that for each level of key experience none year and year at least some participants have also experience with the sed.
.
analysis we visualize the collected data to get a first impression about their distribution and to identify possible outliers before we test our hypotheses.
interpretation and discussion of the results is done in the following section.
to visualize data we use boxplots figures .
the middle vertical bar in the rectangle of a boxplot indicates the median of the data.
the left border represents the lower quartile lqand the right border represents the upper quartile uq.
the left and right whisker indicate the theoretical bounds of the data assuming a normal distribution.
data points outside the whiskers are outliers.
the left whisker is defined as lq .
uq lq and the right whisker asuq .
uq lq .
additionally whiskers are truncated to the nearest existing value within the bounds to avoid meaningless values.
the constant .5is chosen following .
the boxplots in figure show the distribution of the correctly answered questions with the lower bound 0meaning that no question was answered correct and the upper bound 1attained when all answers were correct.
the boxplots in figure 4a show the distribution for all participants for the treatments key and sed whereas figures 4b 4d show the distribution of correct answers broken down to different levels of key experience.
except for participants with years of key experience the results are better when using sed.
only the group with 2years of key experience0 .
.
.
.
1sedkey a all participants .
.
.
.
1sedkey b no key experience only .
.
.
.
1sedkey c years of key experience .
.
.
.
1sedkey d 2years of key experience figure correct answers achieved better results using key.
however this class has an outlier who answered everything correct using the sed.
thedistributionofthemeasuredcorrectnessscores which take also partially correct answers into account see section are shown in figure .
in each case the correctness score is equal to or higher than the correct answers figure .
except for the class of key users with 2years of experience the achieved correctness scores are better when using the sed as compared to key.
.
.
.
.
1sedkey a all participants .
.
.
.
1sedkey b no key experience only .
.
.
.
1sedkey c years of key experience .
.
.
.
1sedkey d 2years of key experience figure correctness score 409the distributions of the confidence scores are similar to thecorrectnessscoredistributions.
asfigure6andfigure7 show the confidence is higher with sed except for the class of key users with 2years of experience.
in each case the confidence score increases the boxplot moves right when taking partially correct answers into account.
2sedkey a all participants 2sedkey b no key experience only 2sedkey c years of key experience 2sedkey d 2years of key experience figure confidence score 2sedkey a all participants 2sedkey b no key experience only 2sedkey c years of key experience 2sedkey d 2years of key experience figure confidence score of partially correct answersthe measured time6is shown in figure .
a value of means that a participant spent of the time using one tool.
the participants with key experience spent less time when using key than when using the sed.
for participants without key experience it is the other way round.
.
.
.
.
1sedkey a all participants .
.
.
.
1sedkey b no key experience only .
.
.
.
1sedkey c years of key experience .
.
.
.
1sedkey d 2years of key experience figure time the null hypotheses of table can be rejected without assuming a normal distribution using a one sided wilcoxon signed rank test or a one sided sign test see .
as basis for the tests we used the results of allparticipants and did not test each experience level separately because there are too few participants in each to apply any test method.
the significance level is set to .05meaning that there is a chance at which a hypotheses is wrongly rejected.
the results of the tests are shown in table .
all tests reject the correctness related hypotheses h0q andh0qsat the given significance level but not hypothesesh0cs for the confidence taking partially correct answers into account .
as we can reject the latter hypothesis with a significance level of .
we expect to be able to reject hypotheses h0csandh0conce more people participate in the experiment.
however the tendency of the data figure hints at only a low chance to reject hypothesis h0t.
.
interpretation in section .
we analyze the proof situations in which the participants performed better using the sed before we summarize the feedback of the participants about specific sed features in section .
.
.
correctness of answers analysis of our experiment permits to conclude that participants performed significantly better in finding the actual 6thetimesmeasuredforfouroftheparticipantswereinvalid and therefore excluded.
410table one sided test results with .05hypothesiswilcoxon signed rank test sign testw value p value rejected p value rejected h0q163 true true h0qs true true h0c false false h0cs false false h0t false false reason for a failed proof attempt when they used the sed.
concerning the confidence participants put into the correctness of their answers we could not reject the corresponding null hypothesis but there is clear tendency pointing towards a higher confidence of the participants in their answers to those proof attempts for which they used the sed.
to answer the question whether the sed performs universally better or only in a specific proof situation we look at how often an expected correct answer was given using each of the tools.
table shows only the expected correct answers.
a selected answer does not mean that the question is correctly answered only that the participant selected it in addition to possibly wrong answers.
for each class of key experience and both tools the percentage how often an answer is selected is given.
if a correct answer was more often selected using one of the tools the value is colored in blue.
almost all participants gave a correct answer to the question whether a proof was closed.
some participants with 2years of key experience overlooked nodes marked as not verified in the symbolic execution tree for arrayutil .
consequently they did not answer the questions about why the proof is open.
this indicates that usability of the sed can be improved by better highlighting of nodes that are not verified.
the correct reason why a proof remains open could often be better identified using sed.
the only case where this observation does not hold is where a proof could not be closed because a given loop invariant is not preserved.
in this case the results were better with key.
a possible explanation is that participants overlooked the not verified marker attached to the loop body termination node in the symbolic execution tree.
again better highlighting of unverified nodes might help.
another explanation is that experienced key users understand loop invariants better in general and hence they did better when using key.
the question about which execution paths do not comply with the given specification is answered more often correctly using the sed.
this is probably due to the visualization of the symbolic execution tree which only distills the program behavior which is hard to figure out from the standard proof tree view of key.
the sed clearly labels execution paths that end with an uncaught exception which explains that participants using the sed perform better when answering questions about thrown exceptions.
when asked which contracts were applied during proof search an applied contract was more often correctly identified when using the sed.
this is surprising because key has a feature for listing all applied contracts which was also shown in the introductory video.thequestionwhichstatementswereexecutedisoftenbetter answered when using the sed which highlights reached code members directly in the source code.
however the monitored participants often overlooked this feature and answered this question by looking at the symbolic execution tree.
interestingly key users with 2years of experience often failed to identify dead code in the calendar proof attempt when using key but succeeded with sed.
the time spent using sed is always higher compared to key.
a possible reason is that most participants never used the sed before.
in the monitored evaluations the participants needed some time to learn how to use the sed.
some participants spent non productive time to discover features of the sed before actually answering the questions.
this behavior could not be observed when key was used perhaps because the participants already used key before.
we conclude that the sed helps in all proof attempts to understand why the proof is still open.
participants without or 2years of key experience achieved significantly better results using the sed.
participants with 2years of key experience performed slightly better when using key.
.
perceived usefulness of features in the following we summarize how the participants classified the helpfulness of selected features.
for key almost all participants considered the proof tree and the possibility to filter out intermediate proof steps as mostly helpful.
the goals tab that allows to navigate directly to open proof goals is considered helpful by of the participants the others mostly never used it.
the possibility to list applied contracts was used by less than half of the participants.
the feedback on the proof sequent view showing the proof obligation of the selected node in the proof tree is interesting it is the only way in key to inspectanopengoalandtounderstandwhichpartoftheproof obligation is not yet proven.
most participants without key experience consider it as not helpful or only somewhat helpful participants with some key experience considered it as somewhat helpful and key user with 2years of experience considered it as very helpful.
this suggests that years of key experience are required to understand the cause for a failed proof attempt when inspecting a failed proof attempt with key.
for the sed most participants considered the symbolic execution tree the highlighting of source code reached during symbolic execution and tracking the verification status of subformulas as very helpful.
the variable view used to show the symbolic state of a selected symbolic execution tree node are mostly considered as somewhat helpful and sometimes as not helpful.
this view becomes important for programs with complex heap modifications.
this was not the case in any of the four problems which explains the low rating.
aliasing could occur only in one problem hence sed s capability to visualize all non isomorphic memory layouts was used infrequently.
some participants provided constructive suggestions for improvements first key and sed both translate jml expressions into logic terms and formulas.
mapping formulas in proofs back to corresponding jml constructs was requested.
second we highlight formulas with red green 7detailed results are presented at understandingproofattemptsevaluation results 411table comparison of the given expected answersproof attemptkey experience all none y. y. question answer key sed key sed key sed key sedcalendaris verified no why not verifiedinvariant is not preserved exception is thrown when not preserved after else what is thrown arraystoreexception what is executedline line 100accountis verified no why not verified postcondition does not hold when does not hold termination what is executedline line line line what is appliedmethod contract of withdraw method contract of canwithdraw 100arrayutilis verified no why not verifiedpostcondition does not hold loop invariant is not preserved when does not hold termination when not preserved loop body termination what is executedline line line line line line line 75my integeris verified no why not verified postcondition does not hold what is executed line winning tool count and yellow to track their verification status.
participants with red green blindness couldn t distinguish these colors.
finally it was suggested to extend the sed in such a manner that interactive proof steps can be performed without leaving the tool.
this was recently implemented.
it is now possible to use the sed as a full fledged replacement for the standard key ui .
participants were also asked which tool they prefer to inspect proof attempts.
both tools have different strengths so it is not surprising that many let their preference depend on the proof situation or task.
overall participants without or years of key experience tended to prefer the sed and experienced key users lean towards the standard key user interface.
this confirms our conjecture that the sed lowers the barrier to use the key system.
to satisfy the needs of key experts features such as inspection of sequents and interaction with the theorem prover are yet missing from the sed.
.
conclusion we described an experiment comparing the effectiveness andefficiencyofunderstandingproofattemptsusingtwodif ferent uis of an interactive theorem prover one with a focus on proof objects and the other providing a view akin to an interactive debugger.
the result provides statistically significant evidence for increased effectiveness when presenting proofs in a debugger like fashion.
especially inexperienced users performed better with it.
we can hence state that the sed approach to user interface design lowers the barrier to formal verification.
this is crucial when using theorem provers in teaching and industrial contexts.
despite the considerable effort required to perform user case studies like the one reported here we strongly encourage system builders to do them the investment is relatively modest compared to the implementation effort for major user interface extensions however the result provides solid support for the decision which development directions and which features will give the largest return.
acknowledgment .
we thank all participants of the evaluation for their valuable time and feedback.
part of this paper was written during a research sabbatical of the second author at university of torino whose support is gratefully ackowledged.
412references w. ahrendt b. beckert d. bruns r. bubel c. gladisch s. grebing r. h hnle m. hentschel m. herda v. klebanov w. mostowski c. scheben p. schmitt and m. ulbrich.
the key platform for verification and analysis of java programs.
in d. giannakopoulou and d.kroening editors verified software theories tools and experiments volume of lncs pages .
springer .
w. ahrendt b. beckert r. h hnle p. r mmer and p. h. schmitt.
verifying object oriented programs with key a tutorial.
in f. de boer m. m. bonsangue s.graf andw.deroever editors postconf.
proc.5th international symposium on formal methods for components and objects fmco volume of lncs pages .
springer verlag .
j. aitken p. gray t. melham and m. thomas.
interactive theorem proving an empirical study of user activity.
journal of symbolic computation .
b. beckert s. grebing and f. b hl.
a usability evaluation of interactive theorem provers using focus groups.
in software engineering and formal methods sefm collocated workshops hofm safome opencert mokmasd ws fmds grenoble france september revised selected papers pages .
j. cheney.
project report theorem prover usability.
technical report report of project comm .
m. frigge d. c. hoaglin and b. iglewicz.
some implementations of the boxplot.
the american statistician .
m. hentschel.
integrating symbolic execution debugging and verification .
phd thesis technische universit t darmstadt jan. .
tu darmstadt.de .
m. hentschel r. bubel and r. h hnle.
symbolic execution debugger sed .
in b. bonakdarpour and s. a. smolka editors runtime verification 14th international conference rv toronto canada volume oflncs pages .
springer .
m.hentschel r.h hnle andr.bubel.
theinteractive verification debugger effective understanding of interactive proof attempts.
in s. apel and s. khurshid editors proc.
31st ieee acm international conference on automated software engineering ase singapore.
acm press sept. .
a. ireland m. jackson and g. reid.
interactive proof critics.formal aspects of computing .
g. kadoda r. stone and d. diaper.
desirable features of educational theorem provers a cognitive dimensions viewpoint.
in proc.
11th annual workshop of the psychology of programming interest group .
g. t. leavens e. poll c. clifton y. cheon c. ruby d. cok p. m ller j. kiniry p. chalin d. m. zimmerman and w. dietl.
jml reference manual may .
draft revision .
t. nipkow l. c. paulson and m. wenzel.
isabelle hol a proof assistant for higher order logic .
springer verlag berlin heidelberg .
c. wohlin p. runeson m. h st m. c. ohlsson and b. regnell.
experimentation in software engineering .
springer .