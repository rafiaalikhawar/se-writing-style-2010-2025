an automated approach to estimating code coverage measures via execution logs boyuan chen york university toronto canada chenfsd cse.yorku.cajian song baidu inc. beijing china songjian02 baidu.compeng xu baidu inc. beijing china xupeng baidu.com xing hu baidu inc. beijing china huxing baidu.comzhen ming jack jiang york university toronto canada zmjiang cse.yorku.ca abstract software testing is a widely used technique to ensure the quality of software systems.
code coverage measures are commonly used to evaluate and improve the existing test suites.
based on our industrial and open source studies existing state of the art codecoverage tools are only used during unit and integration testing duetoissueslikeengineeringchallenges performanceoverhead and incomplete results.
to resolve these issues in this paper we have proposed an automated approach called logcoco to estimatingcodecoveragemeasuresusingthereadilyavailableexecution logs.
using program analysis techniques logcoco matches the execution logs with their corresponding code paths and estimates three different code coverage criteria method coverage statement coverage andbranchcoverage.casestudiesononeopensource system hbase andfivecommercialsystemsfrombaiduandsystems show that the results of logcoco are highly accurate in seven out of nine experiments under a variety of testing activities unittesting integrationtesting andbenchmarking and the results of logcoco can be used to evaluate and improve the existing test suites.
our collaborators at baidu are currently considering adopting logcoco and use it on a daily basis.
ccs concepts software and its engineering software testing and debugging keywords software testing logging code test coverage empirical studies software maintenance acm reference format boyuanchen jiansong pengxu xinghu andzhenming jack jiang.
.
an automated approach to estimating code coverage measures permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation on the first page.
copyrights for components of this work owned by others than acm mustbehonored.abstractingwithcreditispermitted.tocopyotherwise orrepublish topostonserversortoredistributetolists requirespriorspecificpermissionand ora fee.
request permissions from permissions acm.org.
ase september montpellier france association for computing machinery.
acm isbn ... .
execution logs.
in proceedings of the 33rd acm ieee international conference on automated software engineering ase september montpellier france.
acm newyork ny usa 12pages.
org .
.
introduction a recent report by tricentis shows that software failure caused .
trillion in financial losses in .
therefore software testing which verifies a system s behavior under a set of inputs is arequiredprocesstoensurethesystemquality.unfortunately as softwaretestingcanonlyshowthepresenceofbugsbutnottheir absence completetesting a.k.a.
revealingallthefaults isoften not feasible .
thus it is important to develop high quality test suites which systematically examine a system s behavior.
code coverage measures the amount of executed source code whenthesystemisrunningundervariousscenarios .thereare various code coverage criteria e.g.
statement coverage condition coverage and decision coverage proposed to measure how well the testsuite exercises thesystem s source code.for example the statementcoveragemeasurestheamountofexecutedstatements whereas the condition coverage measures the amount of true false decisionstakenfromeachconditionalstatement.althoughthere are mixed results between the relationship of code coverage and testsuiteeffectiveness codecoverageisstillwidelyused in research and industry to evaluate and improve the quality of existing test suites.
therearequiteafewcommercial e.g.
andopensource e.g.
tools already available to automatically measure thecodecoverage.
allthesetoolsrelyon instrumentationatvariouscode locations e.g.
methodentry exit pointsandconditional branches eitheratsourcecode oratbinary bytecodelevels .
there are three main issues associated with these tools when usedinpractice engineeringchallenges forreal worldlargescale distributed systems it is not straight forward to configure and deploy such tools and collect the resulting data .
performanceoverhead theheavyinstrumentationprocesscan introduce performance overhead and slow down the system exe cution .
incomplete results due to various issues associated with code instrumentation the coverage results from these tools do not agree with each other and are sometimes incomplete .hence theapplicationcontextofthesetoolsaregenerally very limited e.g.
during unit and integration testing .
it is very authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
ase september montpellier france boyuan chen jian song peng xu xing hu and zhen ming jack jiang challengingtomeasurethecoverageforthesystemundertest sut in a field like environment to answer questions like evaluating the representativeness of in house test suites .
such problem is going to be increasingly important as more and more systems are adopting the rapid deployment process like devops .
execution logs are generated by the output statements e.g.
log.info user user checked out that developersinsertintothesourcecode.studieshaveshownthatexecution logshavebeenactivelymaintainedformanyopensource andcommercialsoftwaresystems andhavebeenusedextensivelyinpracticeforavarietyoftasks e.g.
systemmonitoring problem debugging and business decision making .
in this paper we have proposed an approach called logcoco logbasedcodecoverage which automatically estimates the code coverage criteria by analyzing the readily available execution logs.
we first leverage program analysis techniques to extract a set of possible code paths from the sut.
then we traverse through these code paths to derive the list of corresponding log sequences representedusingregularexpressions.wematchthereadilyavailable executionlogs eitherfromtestingorinthefield withtheseregular expressions.
based on the matched results we label the code regionsas must definitelycovered may maybecovered maybenot andmust not definitely not covered and use these labels to infer threetypesofcodecoveragecriteria methodcoverage statement coverage andbranchcoverage.thecontributionsofthispaperare this work systematically assesses the use of the code coveragetoolsinapracticalsetting.itisthefirstwork tothe authors knowledge toautomaticallyestimatecodecoverage measures from execution logs.
casestudiesononeopensourceandfivecommercialsystems frombaidu showthatthecodecoveragemeasuresinferred bylogcocoishighlyaccurate achievinghigherthan96 accuracy in seven out of nine experiments.
using logcoco we can evaluate and improve the quality of various test suites unittesting integrationtesting andbenchmarking by comparing and studying their code coverage measures.
thisprojectisdoneincollaborationwithbaidu alargescale software company whose services are used by hundreds of millions of users.
our industrial collaborators are currently considering adopting and using logcoco on a daily basis.
this clearlydemonstrates the usefulness and thepractical impact of our approach.
paperorganization the restof this paper isstructured as follows.
section 2explains issues when applying code coverage tools inpractice.section 3explainslogcocobyusingarunningexample.
section4describesourexperimentsetup.section 5and6studytwo research questions respectively.
section 7introduces the related work.section 8discussesthethreatstovalidity.section 9concludes the paper.
applying code coverage tools in practice we interviewed a few qa engineers at baidu regarding their experienceontheuseofthecodecoveragetools.theyregularlyused code coverage tools like jacoco and cobertura .
however they apply these tools only during the unit and integrationtesting.
it turned out that there are some general issues associated with these state of the art code coverage tools which limit their application contexts e.g.
during performance testing and in the field .wesummarizedthemintothefollowingthreemainissues whicharealsoproblematicforothercompanies engineeringchallenges dependingontheinstrumentationtechniques configuringanddeployingthesetoolsalongwiththesutcanbe tedious e.g.
involving recompilation of source code and errorprone e.g.
changingruntimeoptions .
performanceoverhead althoughthese toolscanprovide variouscodecoverage measures e.g.
statement branch andmethodcoverage theyintroduceadditional performance overhead.
such overhead can be very apparent when the sut is processing hundreds or thousands of concurrent requests.therefore theyarenotsuitabletoberunningduringnonfunctional testing e.g.
performance or user acceptance testing or in the field e.g.
to evaluate and improve the representativeness of thein housetestsuites .
incompleteresults thecodecoverage results from these tools are sometimes incomplete.
in this section we will illustrate the three issues mentioned above through our experience in applying the state of the art code coverage tools on hbase in a field like environment.
.
the hbase experiment hbase whichisanopensourcedistributednosqldatabase has been used by many companies e.g.
facebook twitter and yahoo!
serving millions of users everyday.
it is important toassessitsbehaviorunderload a.k.a.
collectingcodecoverage measures andensuretherepresentativenessofthein housetest suites a.k.a.
covering the behavior in the field .
ycsb isapopularbenchmarksuite originallydevelopedby yahoo!
toevaluatetheperformanceofvariouscloud basedsystems e.g.
cassandra hadoop hbase and mongodb .
ycsb contains six core benchmark workloads a b c d e and f which are derived by examining a wide range of workload characteristics fromreal worldapplications .hence weusethisbenchmark suite to simulate the field behavior of hbase.
ourhbaseexperimentwasconductedonathree machine cluster with one master node and two region server nodes.
these three machineshavethesamehardwarespecifications inteli7 4790cpu 16gbmemory and2tbhard drive.wepickedhbaseversion1 .
.
for this experiment since it was the most current stable release by thetimeofourstudy.weconfiguredthenumberofoperationsto be million foreach benchmark workload.each benchmark test exercised all the benchmark workloads under one of the following threeycsbthreadnumberconfigurations and15.different number of ycsb threads indicates different load levels the higher the number of threads the higher the benchmark load.
.
engineering challenges since hbase is implemented in java we experimented with two java based state of the art code coverage tools jacoco and clover .
both tools have been used widely in research e.g.
and practice e.g.
.
these two tools use different instrumentationapproachestocollectingthecodecoveragemeasures.clover instrumentsthesutandinjectsitsmonitoring authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
an automated approach to estimating code coverage measures via execution logs ase september montpellier france abcdef workloadoverhead figure the jacoco overhead for the hbase experiment.
probesatthesourcecodelevel whilejacoco usesthebytecode instrumentation technique and injects its probes during runtime.
overall we found the configuration and the deployment processes for both tools to be quite tedious and error prone.
for example to enable the code coverage measurement by jacoco we hadtoexaminevarioushbasescriptstofigureoutthecommand lineoptionstostartuphbaseanditsrequiredjarfiles.thisprocess wasnon trivialandrequiredmanualeffort asthecommandline options could differ from systems to systems and even different versions of the same systems.
the process for clover was even morecomplicated aswehadtoreconfigurethemavenbuildsystem to produce a new set of instrumented jar files.
in addition we could not simply copy and replace the newly instrumented jar filesintothetestenvironmentduetodependencychanges.itrequireda thoroughcleanupofthetestenvironmentbeforere deployingsut andrunninganytests.weconsideredsucheffortstobenon trivial as we had to repeat this process on all three target machines.
this effortcouldbemuchhigheriftheexperimentsweredoneontensorhundredsofmachines whichisconsideredasanormaldeployment size for hbase .
we decided to proceed with jacoco.
its instrumentation and deploymentprocesswerelessintrusive asthebehaviorofhbase needed to be assessed in a field like environment.
.
performance overhead we ran each benchmark test twice once with jacoco enabled and once without.
we gathered the response time statistics for each benchmark run and estimated the performance overhead introducedbyjacoco.figure 1showstheperformanceoverheadforthe sixdifferentworkloads workload a ... f .withineachworkload the figure shows the average performance overhead in percentages as well as the confidence intervals across different ycsb threadnumbers.forexample theaverageperformanceoverhead for workload ais but can vary from to depending on the number of threads.
depending on the workload the performance impact of jacoco varies.
workload bhas the highest impact to with jacoco enabled whereas workload ehas the smallest impact to13 .overall jacocodoeshaveanegativeimpactonthesut with a noticeable performance overhead on average across all benchmark tests.
hence it is not feasible to deploy jacoco in a field likeenvironmentwiththesut asitcansignificantlydegrade the user experience.
.
incomplete results wesampledsomeofthecodecoveragedataproducedbyjacoco for manual verification.
we found that jacoco did not reportthe code coverage measures for some modules.
jacoco only in strumented the hbase modules a.k.a.
the hbase server module in which the ycsb benchmark suite directly invoked.
if the hbase server moduleinvokesanothermodule e.g.
client not specified during the hbase startup the clientmodule will not be instrumentedbyjacocoandwillnothaveanycoveragedatareported.
for example during our experiment the logging statement from the method settablestate inzktablestatemanager.java was outputted.
hence settablestate should be covered.
since settablestate calls settablestateinzk whichcalls joinznode inzkutil.java the method joinznode should also be covered.
however the joinznode method was marked as not covered by jacoco.
a similar problem was also reported in .
to resolve the three issues mentioned above we have proposed a new approach to automatically estimating the code coverage measuresbyleveragingthereadilyavailableexecutionlogs.our approachestimatesthecodecoveragebycorrelatinginformation in the source code and the log files once the tests are completed.
it imposeslittleperformanceoverheadtothesut andrequiresno additional setup or configuration actions from the qa engineers.
logcoco source code log filescode path logre pairs log sequenceslabeled source codecoverage resultsprogram analysis log analysispath analysiscode coverage estimation figure an overview of logcoco.
inthissection wewilldescribelogcoco whichisanautomated approach to estimating code coverage measures using execution logs.
as illustrated in figure our approach consists of the following four phases during the program analysis phase we analyze the sut s source code and derive a list of possible code pathsandtheir corresponding logsequencesexpressedinregular expressions logre .
during the log analysis phase we analyze theexecutionlogfilesandrecoverthelogsequencesbasedontheir execution context.
during the path analysis phase we match eachlogsequencewithoneofthederivedlogreandhighlightthe correspondingcodepathswiththreekindsoflabels may must and must not .
based on the labels we estimate the values for the followingthreecodecoveragecriteria methodcoverage statement coverage andbranchcoverage.intherestofthissection wewill explaintheaforementionedfourphasesindetailswitharunning example shown in figure .
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
ase september montpellier france boyuan chen jian song peng xu xing hu and zhen ming jack jiang log sequences seq seq final code coverage branch selection set logre log log log log log code snippets intermediate code coverage void computation int a int b must must must int a randomint must must must log.info random no a must must must if a must must must a process a must must not must else must not must must a a must not must must if a must must must a may may may for b b must must must a must must must log.info loop a must must must if a must must must log.info check a must not must not must not int process int num must must must log.info process num must must must return num must must must figure the code snippet of our running example.
.
ph a s e1 p r ogram analysis differentsequencesofloglineswillbegeneratedifthesutexecutes different scenarios.
hence the goal of this phase is to derive thematchingpairsbetweenthelistofpossiblecodepathsandtheir corresponding log sequences.
this phase is further divided into three steps step deriving ast for each method.
wederivethepermethod abstract syntax tree ast using a static analysis tool called java development tools jdt from the eclipse foundation.
jdt is a very robust and accurate program analysis tool which has been usedin manysoftware engineeringresearch papers e.g.
bugprediction loggingcodeanalysis andsoftwareevolution .
considerourrunningexampleshownontheleftpartoffigure .
thisstepwillgeneratetwoastsforthetwomethods computation andprocess.eachnodeintheresultingastismarkedwiththe correspondinglinenumberandthestatementtype.forexample at line there is a logging statement and at line there is an if statement.
there are alsoedges connecting two nodes if one node is the parent of the other node.
step deriving call graphs.
the resulting asts from the previoussteponlycontainthecontrolflowinformationatthemethod level.
in order to derive a list of possible code paths we need toform call graphs by chaining the asts of different methods.
wehave developed a script which automatically detects method invocationsintheasts andlinksthemwiththecorrespondingmethod body.intherunningexample ourscriptwillconnectthemethod invocationofthe process methodatline5withthecorresponding method body starting at line .
step deriving code paths and logre pairs.
based on the resulting call graphs we will derive a list of possible code paths.
the number of resulting code paths depends on the number and the type of control flow nodes e.g.
if else for and while which may contain multiple branching choices.
consider the if statement at line4inourrunningexample dependingonthetrue falsevalues fortheconditionalvariable a therecanbetwocallpathsgenerated and .
weleveragethebreadth first search bfs algorithmtotraverse throughthecallgraphsinorderto derivethelistofpossiblecode paths and their corresponding logres.
when visiting each control flow node we pick one of the decision outcomes for that node and gotothecorrespondingbranches.duringthisprocess wealsokeep track of the resulting logres.
each time when a logging statement is visited we add itto our resulting logre.
if a logging statement isinsidealoop a signwillbeappendedtoitindicatingthatthis loggingstatementcouldbeprintedmorethanonce.forthelogging statement which is inside a conditional branch within a loop it willbeappendedwitha ?
followedbya .intheend wewill authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
an automated approach to estimating code coverage measures via execution logs ase september montpellier france info random no info random no info process info loop info loop info loop figure log file snippets for our running example.
generate a branch selection set for this particular code path and its corresponding logre.
there can be some control flow nodes underwhichthereisnologgingstatementnode.inthiscase we cannotbecertainifanycodeunderthesecontrolflownodeswill be executed.for scalabilityconcerns we donot visit thesubtrees under these control flow nodes.
inourrunningexample therearefourcontrolflownodes line4 if if for and16 if .iftheconditionsaretrueforline4 and and false for line the branch selection set is represented as .
the value for theifconditionnode atline 9isirrelevant asthere isno logging statement under it.
we will not visit its subtree as no changes will be made to the resulting logre.
the resulting code path for this branch selection is .
thecorrespondinglogreis log log log .line10 in the resulting code path is shown in brackets because there is no logging statement under the ifcondition node at line .
thus we cannot tell if line is executed based on the generated log lines.
.
phase log analysis execution logs are generated when logging statements are executed.
however since there can be multiple scenarios executed concurrently logs related to the different scenario executions may be inter mixed.
hence in this phase we will recover the relatedlogs into sequences by analyzing the log files.
suppose after executingsometestcasesforourrunningexample asetofloglines shown in figure is generated.
this phase is further divided into the following three steps step abstracting log lines.
each log line contains static texts which describe the particular logging context and dynamic contents which reveal the sut s runtime states.
logs generated by modernloggingframeworkslikelog4j canbeconfiguredto contain information such as file name and line number.
hence we caneasilymapthegeneratedloglinestothecorrespondinglogging statements.
in our example each log line contains the file name test.java and the line number.
in other cases if the file name and the line number is not printed we can leverage existing log abstractiontechniques e.g.
whichautomaticallyrecognizethedynamicallygeneratedcontentsandmaploglinesintothe corresponding logging statements.
step grouping related log lines.
each log line contains some execution contexts e.g.
thread or session or user ids .
in this step wegrouptherelatedloglinesintosequencesbyleveraging these execution contexts.
in our running example we group therelated log lines by their thread ids.
there are in total two log sequences in our running example which correspond to thread andthread .step forming log sequences.
in this step we replace the groupedloglinesequencesintosequencesofloggingstatements.
for example the log line sequence of line grouped under thread becomes log log log log .
.
phase path analysis based on the obtained log line sequences from the previous phase we intend to estimate the covered code paths in this phase using a four step process.
step matching log sequences with logres.
wematch thesequencesofloggingstatementsobtainedinphase2withthelogres obtained in phase .
the two recovered log sequences are matched with the two logres which are shown on the third row in figure3.
thesequenceof loggingstatementin ourrunningexample log log log log a.k.a.
seq1 willbematched with logre log log log .
step labeling statements.
inthesecondstep basedoneachof thematchedlogre weapplythreetypesoflabelstothecorresponding source code based on their estimated coverage must may and must not .thelowerpartoffigure 3showstheresultsforourworkingexample.for seq1 welabellines asmust astheselinesaredefinitelycoverediftheabove logsequenceisgenerated.line10ismarkedas may becauseweare uncertainiftheconditionofthe ifstatementatline9issatisfied.
lines 17are marked as must not because the branch choice istrueatline4andfalseatline17.duetothepagelimit wedonot explain the source code labeling process for seq .
step reconciling statement level labels.
as one line of source code may be assigned with multiple different labels from different log sequences in the third step we reconcile the labels obtainedfrom different log sequences and assign one final resulting label to each line of source code.
we use the following criteria for our assignment at least one mustlabel since a particular line of source codeisconsideredas covered whenithasbeenexecutedat least once.
hence if there is at least one mustlabel assigned to that line of source code regardless of other scenarios it is considered as covered a.k.a.
assigning mustlabels as the final resulting label .
in our running example line is markedas mustinseq1andmust not inseq2.therefore it will be marked as mustin the final label.
nomustlabels andatleastone maylabel inthisparticularcase wemayhavea specificlineof source codeassigned withall maylabels oramixtureof mayandmust not labels.
as there is a possibility that this particular line of source code can be covered by some test cases we assigned it to be mayin the final resulting label.
in our running example line is marked may.
allmust not labels in this particular case since there are noexistingtestcasescoveringthislineofsourcecode we assignedittobe must not inthefinalresultinglabel.inour running example line17 is marked must not in bothseq andseq .
it will be marked as must not in the final label.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
ase september montpellier france boyuan chen jian song peng xu xing hu and zhen ming jack jiang step inferring labels at the method levels.
basedonthelinelevel labels we assign one final label to each method using the following criteria for a particular method if there is at least one line of source code labeled as must this method will be assigned with a mustlabel.inourrunningexamples bothmethodswillbe labeled as must.
for methods without mustlabeled statements we apply the following process initiallabeling alloftheloggingstatementsundersuch methods should already be labeled as must not since none of these logging statements are executed.
if there isatleastoneloggingstatementwhichisnotunderany controlflowstatementnodesinthecallgraph thismethod will be labeled as must not.
calleelabeling startingfromtheinitialsetofthe must not labeled methods we search for methods that will only be called by these methods and assign them with the must not labels.weiterativelyrepeatthisprocessuntil no more methods can be added to the set.
remaining labeling we assign the maylabels to the remaining set of unlabeled methods.
similarly eachbranchwillbeassignedwithonefinalresulting label based on the statement level labels.
due to space constraints we will not explain the process here.
ph a s e4 c od ec o v erage estimation in this phase we estimate the method branch statement level code coverage measures using the labels obtained from the previous phase.
as logging statements are not instrumented everywhere there are code regions labeled as may which indicates uncertainty of coverage.
hence when estimating thecode coverage measures weprovidetwovalues aminimumandamaximumvalueforthe above three coverage criteria.
the minimum value of statement coverage is calculated as ofmust labels total of labels and the maximum value iscalculatedas ofmust labels ofmaylabels total of labels.inourrunningexample the numbers of must may and must not statements are and respectively.
therefore the range of the statement coverage is from to .
similarly sincethenumberof must may and must not branches is and in our running example the range of branch coverage is from .
to .
.
thenumberof must may and must not methodsare2 and .
hence the method level coverage is .
case setup toevaluatetheeffectivenessofourapproach wehaveselectedfive commercialprojectsfrombaiduandonelarge scaleopen source project in our case study.
table 1shows the general information about these projects in terms of their project name project descriptions and their sizes.
all six projects are implemented in java andtheirdomainsspanwidelyfromwebservices toapplication platformsandnosqldatabases.themainreasonwhywepicked commercialprojectstostudyisthatwecaneasilygetholdofqa engineersforquestionsandfeedback.thefivecommercialprojects c1 c2 c3 c4 and c5 werecarefullyselectedbasedonconsultations with baidu s qa engineers.
we also picked one large scalepopular open source project hbase because we can freely discussaboutthedetails.wefocusonhbaseversion1 .
.6inthis study since itisthemostrecentstable releasebythetime ofthestudy.
all six studied projects are actively maintained and being usedbymillionsorhundredsofmillionsofusersworldwide.we proposedthefollowingtworesearchquestions rqs whichwill be discussed in the next two sections table information about the six studied projects.
projet descriptions loc c1internal api library 24k c2platform 80k c3cloud service 12k c4video streaming service 35k c5distributed file system 228k hbase distributed nosql database 453k rq1 accuracy how accurate is logcoco compared to the state of the art code coverage tools?
the goal of this rq is to evaluate the quality of the code coverage measures derived from logcoco against the state of the art code coverage tools.
we intend to conduct this study using data from various testing activities.
rq2 usefulness canweevaluateandimprovetheexisting test suites by comparing the logcoco results derived from various execution contexts?
the goal of this rq is to check if the existing test suites can be improved by comparing the estimatedcoverage measuresusinglogcoco fromvarious system execution contexts.
rq1 accuracy on one hand existing state of the art code coverage tools e.g.
jacoco cobertura collect the code coverage measures by excessively instrumenting the sut either at the source code o r atthebinary bytecodelevels .theexcessiveinstrumentation e.g.
for every method entry exit and for every conditional and loop branch ensures accurate measurements of code coverage butimposesproblemslikedeploymentchallengesandperformance overhead section which limit their application context.
on the other hand logcoco is easy to setup and imposes little performanceoverheadbyanalyzingthereadilyavailableexecutionlogs.
however theestimatedcodecoveragemeasuresmaybeinaccurate or incomplete as developers only selectively instrument certain partsofthesourcecodebyaddingloggingstatements.hence inthis rq wewanttoassessthequalityoftheestimatedcodecoverage measures produced by logcoco.
.
experiment we ran nine test suites for the six studied projects as shown in table2.
the nine test suites contained unit and integration tests.
sincetheunittestsuiteswerenotconfiguredtogeneratelogsfor c1 c4 andc5 wedidnotincludetheminourstudy.
c5andhbase authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
an automated approach to estimating code coverage measures via execution logs ase september montpellier france are distributedsystems so weconducted their integrationtests in a field like deployment setting.
each test suite was run twice once with the jacoco configured and once without.
we used the code coverage data from jacoco as our oracle and compared it against the estimated results from logcoco.
for all the experiments we collected data like generated log files and code coverage measures from jacoco.
jacoco is a widely used state of the art code coverage tool which is used in both research and practice .
we picked jacoco to ensure that the experiments could be done in a field like environment.
code coverage tools which leverage source code level instrumentationtechniques requirerecompilationandredeployment of the sut.
such requirements would make the sut s testing behaviornolongercloselyresemblethefieldbehavior.jacoco a bytecodeinstrumentationbasedcodecoveragetool islessinvasiveandinstrumentsthesutduringruntime.foreachtest wegathered the jacoco results and the log files.
depending on the tests the sizes of the log files range from mb to .
gb.
.
data analysis wecomparedthethreetypesofcodecoveragemeasures method statement and branch coverage derived from logcoco and jacoco.
since logcoco marks the source code for each type of coverage using the following three labels must may and must not we calculated the percentage of correctly labeled entities for three types of labels.
forthe mustlabeledmethods wecalculatedtheportionofmethodswhicharemarkedas coveredinthejacocoresults.forexample if logcoco marked five methods as mustamong which four were reportedas coveredinjacoco theaccuracyofthelogcocomethodlevelcoveragemeasurewouldbe4 .similarly forthe must not labeledentities wecalculatedthepercentageofmethods which were marked as not covered by jacoco.
for the maylabeled methods we calculated the portion of methods which are reported as coveredby jacoco.
note that this calculationis nottoassesstheaccuracyofthe maycoveredmethods but toassesstheactualamountofmethodswhichareindeedcovered during testing.
whencalculatingtheaccuracyofthestatementandbranchlevel coveragemeasuresfromlogcoco weonlyfocusedoncodeblocks fromthe mustcoveredmethods.thisisbecauseallthestatement and branch level coverage measures will be mayormust not for themayormust not labeledmethods respectively.itwouldnotbe meaningfultoevaluatethesetwocasesagainatthestatementor branch level.
theevaluationresultsforthethreecoveragemeasuresareshown intable2.ifacellismarkedas itmeansthereisnosourcecode assigned with the label.
we will discuss the results in details below.
.
discussion on method level coverage as shown in table all methods labeled with mustare accurate.
it means that logcoco can achieve accuracy when detectingcoveredmethods.ratherthaninstrumentingallthemethods like the existing code coverage tools do logcoco uses pro gram analysis techniques to infer the system execution contexts.
for example only of the methods in c1have logs printed.
the remaining of the mustcovered methods are inferred indirectly.the methods labeled with must not are not always accurate.
threecommercialprojects c3 c4 andc5 andhbasehavesome methods which are actually covered in the tests but are falsely flaggedas must not coveredmethods.exceptforthreecases the accuracyofthe must not labeledmethodsareallabove90 .we manuallyexaminedthemisclassifiedinstancesandfoundthefollowingtwomainreasons wehavelimitedthesizeofourcall graphsto20levelsdeeporamaximumof100 000pathsperast tree due to memory constraints of our machine.
therefore we missedsomemethods whichhaddeepercallchains.
ourcurrent technique cannot handle recursive functions properly.
theamountof maycoveredmethodsthatareactuallycovered is highly dependent on the type of projects and can range from to .
in addition this number seems to be irrelevant of the types oftestingconducted.inordertoobtainamoreaccurateestimate of the code coverage measures using logcoco additional logging statements need to be added into the sut to reduce the amount ofmaylabeled methods.
however the logging locations should be decided strategically e.g.
leveraging techniques like in order to minimize performance overhead.
.
discussion on the statement and branch coverage for statement and branch coverage the accuracy of the must not labelsis100 foralltheexperiments.however theaccuracyofthe mustcoveredlabelsrangesfrom83 to100 forstatementcoverage and to for branch coverage.
in seven out of the nine total experiments theaccuracyofthe mustcoveredstatementsis97 or higher.
we manually examined the cases where the logcoco results are different from jacoco.
we summarized them as follows limitations on static analysis logcoco issue java supports polymorphism.
the actual type of certain objects are unknownuntiltheyarebeingexecuted.logcocoinfersthecall graphsstaticallyandmistakenlyflagssomeofthemethod invocations.
newprogrammingconstructs jacocoissue thelambdaexpressionisoneofthenewprogramminglanguageconstructs introduced in java .
jacoco mistakenly tags some statements containing lambda expressions as not covered.
theaccuracyofthe mustcoveredbranchesisgenerallyabove except one case during the integration testing of c3 logcoco detectedtwo mustcovered branchesbeing executed oneof which was falsely labeled.
the rationales for the differences of the branch coverage measures are the same as the statement coverage measures.
theamountof mayactuallycoveredstatementsandbranchesare generally higher than the amount of actually covered maymethods.
however similartothemethod levelcoverage wecannoteasily guess the actual coverage information for a maylabeled statement or branch.
.
feedback from the qa engineers we demonstrated logcoco to the qa engineers at baidu.
they agreedthatlogcococanbeusedfortheirdailytestingactivities due to its ease of setup wider application context and accurate results.
in particular instead of treating all the source code equally authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
ase september montpellier france boyuan chen jian song peng xu xing hu and zhen ming jack jiang table comparing the performance of logcoco against jacoco under various testing activities.
the numbers above shows the amount of overlap between logcoco and jacoco.
projecttype of size of method coverage statement coverage branch coverage testing the logs must must not may must must not may must must not may c1integration mb c2unit mb integration mb c3unit mb integration mb c4integration mb c5integration .
gb hbaseunit mb integration mb theywouldpayparticularattentiontothecoverageofthemethods which have logging statements instrumented.
this was because manyoftheloggingstatementswereinsertedintoriskymethods or methods which suffered from past field failures.
having test casescoverthesemethodsisconsideredahigherpriority.logcoco addressedthistasknicely.inaddition theyagreedthatlogcoco can also be used to speed up problem diagnosis in the field by automaticallypin pointingtheproblematiccoderegions.finally theywerealsoveryinterestedintheamountof maylabeledentities a.k.a.
methods statements andbranches astheyknewlittleabout theruntimebehavioroftheseentities.theyconsideredreducingthe amount of maylabeled entities as one approach to improving their existingloggingpracticesandwereveryinterestedtocollaborate further with us on this topic.
findings the accuracy of mustandmust not labeled entities from logcoco is very high for all three types of code coverage measures.however onecannoteasilyinferwhethera maylabeled entity is actually covered in a test.
implications to further improve the accuracy one must reduce the amount of maylabeled entities through additional instrumentation.
researchers and practitioners can look into existing works e.g.
which improve the sut s logging behavior with minimal performance overhead.
rq2 usefulness existingcodecoveragetoolsareusuallyappliedonlyduringunitorintegrationtestingduetovariouschallengesexplainedinsection .
logcoco which analyzes the readily available execution logs can workonamuchwiderapplicationcontext.inthisrq weintend to check if we can leverage the logcoco results from various executioncontextstoimprovetheexistingtestsuites.totacklethis problem we further split this rq into the following two sub rqs rq2.
can we improve the in house functional test suites by the comparison among each other?
inthissub rq wewillfocusonunitandintegrationtesting asthey have different testing purposes.
unit testing examines the sut s behavior with respect to the implementation of individual classes whereas integration testing examines whether individual units canworkcorrectlywhentheyareconnectedtoeachother.weintend tocheckifonecanleveragethecoveragedifferencestoimprovethe existing unit or integration test suites using data from logcoco.
experiment.
to study this sub rq we reused the data obtained fromrq1 sexperiments.inparticular weselectedthedatafrom twocommercialprojects c2andc3 astheycontaindatafromboth unit and integration test suites.
the main reason we focused on the commercial projects in this sub rq was because we can easily get hold of the qa engineers of baidu for feedback or surveys e.g.
whethertheycanevaluateandimprovetheunitorintegrationtests by comparing the coverage data .
data analysis and discussion.
itwouldbeimpracticaltostudy all the coverage differences from the two types of tests due to their large size.
we randomly sampled a subset of methods where both typesoftestingcoveredbuttheirstatementandbranchlevelcoveragemeasuresdiffered.wepresentedthisdatasettoqaengineers fromthetwocommercialprojectsforfeedback.aftermanualexaminations the qa engineers agreed to add additional unit testing cases for all the cases where unit testing did not cover.
however addingadditional integrationtestsisharderthan addingadditional unit tests.
the qa engineers rejected about of the cases where unit testing covered but integration testing missed as they wereconsidered as hard or lower priority.
we summarized their rationales as follows defensive programming defensive programming is a programming style to guard against unexpected conditions.
althoughitgenerallyimprovestherobustnessofthesut there can be unnecessary code introduced to guard against errors thatwouldbeimpossibletohappen.developersinsertmuch errorcheckingcodeintothesystems.someoftheseissues are rare or impossible to happen.
it is very hard to come up withanintegrationtestcasewhoseinputvaluescanexercise certain branches.
lowriskcode someofthemodulesareconsideredaslow riskbasedontheexperienceoftheqaengineers.sincetheyarealreadycoveredbytheunittestsuites addingadditional integration test cases is considered as low priority.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
an automated approach to estimating code coverage measures via execution logs ase september montpellier france rq2.
can we evaluate the representativeness of in house test suites by comparing them against field behavior?
one of the common concerns associated with qa engineers is whether the existing in house test suites can properly represent fieldbehavior.weintendtocheckifonecanevaluatethequality oftheexistingin housetestsuitesbycomparingthemagainstfield coverage using data from logcoco.
experiment.
duetoconfidentialityreasons wecannotdisclose the details about the field behavior for the commercial projects.
therefore we studied the open source system hbase for rq2.
.
the integration test suite from hbase is considered as a comprehensive test suite and is intended for elaborate proofing of a release candidate beyond what unit tests can do .
hence we consideritashbase sin housetestsuite.therearetwosetupapproachestorunningthehbase sintegrationtests amini cluster or a distributed cluster.
the mini cluster setup is usually run on onemachineandcanbeintegratedwiththemavenbuildprocess.
the distributed cluster setup needs a real hbase cluster setup and is invoked using a separated command.
in this experiment we ran under both setups and collected their logs.
theworkloadsdefinedinycsbarederivedbyexaminingawide rangeof workloadcharacteristicsfrom realwebapplications .
we thus used the ycsb benchmark test suite to mimic the field behavior of hbase.
however as we discovered under default settings hbasedidnotoutputanylogsduringthebenchmarkingprocess.
we followed the instructions from to change the log levels forhbasefrominfotodebugonthefly a.k.a.
withoutserver reboot .
the resulting log file size is around mb when running the ycsb benchmark tests for one hour.
data analysis and discussion.
based on the logcoco results there are methods which were covered by the ycsb test and not by the integration test under the mini cluster setup.
most of thesemethodswererelatedtothefunctionalitiesassociatedwith cluster setup and communications.
under the distributed cluster setup which is more realistic all the covered methods in the yscb test were covered by the integration test.
thelogverbositylevelfortheunitandtheintegrationtestsof hbaseinrq1waskeptasthedefaultinfolevel.bothtestsgenerated hundreds of megabytes of logs.
however under the default verbosity level the ycsb benchmarking test generated no logs except a few lines at the beginning of the test.
this is mainly because hbasedoesnotperformloggingfortheirnormalread write and scan operations for performance concerns.
the integration tests output more info level logs is because many of the testing methodsareinstrumentedwithinfoorhigherlevellogs.suchlogsarenotprintedinpractice and inadditiontothefunctionalities covered in the ycsb benchmark integration tests also verify other usecases whichcangeneratemanylogs.forexample oneintegration test case is about region replications.
in this test one of the hbase component zookeeper which is responsible for distributed configurationandnamingservice generatedmanyinfolevellogs.
wefurtherassessedtheperformanceimpactofturningonthe debuglevellogsforhbase.wecomparedtheresponsetimeunder the debug and the info level logging with ycsb threadsconfiguredat5 and15 respectively.theperformanceimpact wasverysmall underallthreeycsbsettings a.k.a.
three different ycsb benchmark runs .
thus for hbase the impact of debuglevelloggingismuchsmallerthanjacoco.furthermore comparedtojacoco whichrequiresserverrestarttoenable disable its process the debug level logging can easily be turned on off during runtime.
findings logcocoresultscanbeusedtoevaluateandimprove the existing test suites.
multiple rationales are considered when adding a test case besides coverage.implications therearematuretechniques e.g.
evosuite andpex toautomaticallygenerateunittestcaseswithhigh coverage.however therearenosuchtechniquesforothertypesoftests whichstillrequirehighmanualefforttounderstandthe context and to decide on a case by case basis.
further research is needed in this area.
the coverage information from logcoco highly depends on amountofgeneratedlogs.researchersorpractitionersshould lookintosystemmonitoringtechniques e.g.
sampling or adaptive instrumentation which maximize the obtained information with minimal logging overhead.
related work in this section we will discuss two areas of related research code coverage and software logging.
.
code coverage codecoveragemeasurestheamountofsourcecodeexecutedwhile runningsutsundervariousscenarios .theyhavebeenused widely in both academia and industry to assess and improve the effectivenessofexistingtestsuites .thereare quiteafewopensource e.g.
andcommercial e.g.
code coverage tools available.
all these tools leverage additional codeinstrumentation eitheratthesourcecodelevel e.g.
oratthebinary bytecode e.g.
level toautomatically collecttheruntimesystembehaviorinordertomeasurethecodecoveragemeasures.in h ubletal.derivedcodecoverageinformationfromtheprofilingdatarecordedbyanthejust in time jit compiler.
they also compared their coverage information against jacoco.
they showed their results are more accurate than jacocoandyieldsmalleroverhead.h ubletal.
sapproachisdifferentfromours astheyreliedondatafromtheunderlyingvirtual machines whereas we focus on the logging statements from the sut ssourcecode.recently horv thetal.
comparedtheresultsfromvariousjavacodecoveragetoolsandassessedtheimpact of their differences to test prioritization and test suite reduction.in this paper we have evaluated the state of the art java based codecoveragetoolsinafieldlikesettingandproposedanewapproach which leverages the readily available execution logs to automatically estimating the code coverage measures.
inadditiontothetraditionalcodecoveragemetrics e.g.
method branch decision and mc dc coverage new metrics have been proposed to better assess the oracle quality to detect untested code regions and to compose test cases with better abilities to detect faults .
there are various empirical studies conducted to examinetherelationshipbetweenthetesteffectivenessandvarious code coverage metrics.
for example inozemtseva and holmes authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
ase september montpellier france boyuan chen jian song peng xu xing hu and zhen ming jack jiang leveraged mutation testing to evaluate the fault detection effectivenessofvariouscodecoveragemeasuresandfoundthatthereisa lowtomoderatecorrelationbetweenthetwo.kochharetal.
performedasimilarstudy excepttheyusedrealbugsinstead.their studyreportedastatisticallysignificantcorrelation moderateto strong between fault detection and code coverage measures.
gligoric et al.
compared the effectiveness of various code coverage metrics in the context of test adequacy.
the work by wang et al.
whichistheclosesttoourwork comparedthecoverage betweenin housetestsuitesandfieldexecutionsusinginvariantbasedmodels.ourworkdiffersfrom inthefollowingtwomain areas they used a record replay tool which instruments the suttocollectcoveragemeasures.ourworkestimatesthecoveragemeasures based on the existing logs without extra instrumentation.
while they mainly focused on the client and desktop based systems ourfocusisontheserver baseddistributedsystemsdeployed in a field like environment processing large volumes of concurrent requests.
in our context extra instrumentation would not be ideal as it will have a negative impact on the user experience.
.
software logging software logging is a cross cutting concern that scatters across theentiresystemandinter mixeswiththefeaturecode .unfortunately recentempiricalstudiesshowthattherearenowellestablished logging practices for commercial and open sourcesystems .recentlyresearchershavefocusedonproviding automated logging suggestions based on learning from past loggingpractices orprogramanalysis .execution logs are widely available inside large scale software systems for anomaly detection system monitoring problem debugging testanalysis andbusinessdecisionmaking .ourworkwasinspiredby whichleveraged logs to infer executed code paths for problem diagnosis.
however thisisthefirstwork totheauthors knowledge whichuseslogsto automatically estimate code coverage measures.
the limitation is that we rely on that the study systems contain sufficientlogging.itisgenerallythecaseamongserver sideprojects.forclient sideorotherprojectswithlimitedlogging ourapproach should be complementary by other code coverage tools.
threats to validity in this section we will discuss the threats to validity.
.
internal validity inthispaper weproposedanautomatedapproach toestimating code coverage by analyzing the readily available execution logs.
theperformanceofourapproachhighlydependsontheamountof theloggingandtheverbositylevels.theamountofloggingisnota majorissueasexistingempiricalstudiesshowthatsoftwarelogging is pervasive in both open source and commercial systems.theloggingoverheadduetolowerverbositylevelsissmall forthehbasestudy.forothersystems onecanchoosetoenable lower verbosity level for a short period of time or use advanced logging techniques like sampling and adaptive instrumentation.
.
external validity inthispaper wefocusedontheserver sidesystemsmainlybecause these systems use logs extensively for a variety of tasks.
all these systems are under active development and used by millions ofusers worldwide.
to ensure our approach is generic we studied both commercial and open source systems.
although our approach was evaluated on java systems to support other programming languages we just need to replace the parser for another language e.g.
saturn for c and ast for python in logcoco.
the remaining process stays the same.
our findings in the case studies may not be generalizable to systems and tools which have no or veryfewloggingstatements sometimesseeninmobileapplications and client desktop based systems .
.
construct validity when comparing the results between logcoco and the state ofthe art code coverage tools we focused on jacoco which collects codecoverageinformationviabytecodeinstrumentation.thisis because jacocoiswidelyusedinbaidu sowecaneasilycollect the code coverage for the systems and gather feedback from the qaengineers and weintendtoassessthecoveragemeasures in a field like environment in which the system is deployed in a distributedenvironmentandusedbymillionsofusers.source codeinstrumentation based code coverage tools e.g.
are not ideal as they require recompilation and redeployment of the sut.
conclusions and future work existingcodecoveragetoolssufferfromvariousproblems which limittheirapplicationcontext.toovercomewiththeseproblems this paper presents a novel approach logcoco which automat ically estimates the code coverage measures by using the readily available execution logs.
we have evaluated logcoco on a variety of testing activities conducted on open source and commercial systems.ourresultsshowthatlogcocoyieldshighaccuracyandcan be used to evaluate and improve existing test suites.
inthefuture weplantoextendlogcocoforotherprogramming languages.
in particular we are interested in applying logcoco to systemsimplementedinmultipleprogramminglanguages.further more wealsointendtoextendlogcocotosupportothercoverage criteria e.g.
data flowcoverageandconcurrencycoverage .finally since the quality of the logcoco results highly depends on the qualityoflogging wewillresearchintocost effectivetechniques to improve the existing logging code.
acknowledgement this work is done during the first author s internship at baidu.
the findings and opinions expressed in this paper are those of the authors anddo not necessarily represent orreflect those ofbaidu and oritssubsidiariesandaffiliates.moreover ourresultsdonot in any way reflect the quality of baidu s products.