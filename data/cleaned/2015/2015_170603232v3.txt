darwinian data structure selection michail basios lingbo li fan wu leslie kanthan earl t. barr university college london uk michail.basios lingbo.li fan.wu l.kanthan e.barr cs.ucl.ac.uk abstract data structure selection and tuning is laborious but can vastly improve an application s performance and memory footprint.
some data structures share a common interface and enjoy multiple implementations.
we call them darwinian data structures dds since we can subject their implementations to survival of the fittest.
we introduce artemis a multi objective cloud based search based optimisation framework that automatically finds optimal tuned dds modulo a test suite then changes an application to use that dds.
artemis achieves substantial performance improvements for every project in 5java projects from dacapo benchmark 8popular projects and 30uniformly sampled projects from github.
for execution time cpu usage and memory consumption artemis finds at least one solution that improves allmeasures for of the projects.
the median improvement across the best solutions is .
.
.
for runtime memory and cpu usage.
these aggregate results understate artemis s potential impact.
some of the benchmarks it improves are libraries or utility functions.
two examples are gson a ubiquitous java serialization framework andxalan apache s xml transformation tool.
artemis improves gson by16.
and2.
for memory runtime and cpu artemis improves xalan s memory consumption by .
.every client of these projects will benefit from these performance improvements.
ccs concepts software and its engineering software evolution keywords search based software engineering genetic improvement software analysis and optimisation data structure optimisation acm reference format michail basios lingbo li fan wu leslie kanthan earl t. barr.
.
darwinian data structure selection.
in proceedings of the 26th acm joint european software engineering conference and symposium on the foundations of software engineering esec fse november lake buena vista fl usa.
acm new york ny usa pages.
.
permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
copyrights for components of this work owned by others than the author s must be honored.
abstracting with credit is permitted.
to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
request permissions from permissions acm.org.
esec fse november lake buena vista fl usa copyright held by the owner author s .
publication rights licensed to acm.
acm isbn .
.
.
.
waste enormous amounts of time thinking about or worrying about the speed of noncritical parts of their programs and these attempts at efficiency actually have a strong negative impact when debugging and maintenance are considered.
we should forget about small efficiencies say about of the time premature optimization is the root of all evil.
yet we should not pass up our opportunities in that critical .
donald e. knuth introduction under the immense time pressures of industrial software development developers are heeding one part of knuth s advice they are avoiding premature optimisation.
indeed developers appear to be avoiding optimisation altogether and neglecting the critical .
when selecting data structures from libraries in particular they tend to rely on defaults and neglect potential optimisations that alternative implementations or tuning parameters can offer.
this despite the impact that data structure selection and tuning can have on application performance and defects.
consider three examples.
selecting an implementation that creates unnecessary temporary objects for the program s workload .
selecting a combination of scala data structures that scaled better reducing execution time from 45to1.5minutes .
avoiding the use of poor implementation such as those in the oracle bug database that leak memory .
optimisation is time consuming especially on large code bases.
it is also brittle.
an optimisation for one version of a program can break or become a de optimisation in the next release.
another reason developers may avoid optimisation are development fads that focus on fast solutions like premature optimisation is the horror of all evil and hack until it works .
in short optimisation is expensive and its benefits unclear for many projects.
developers need automated help.
data structures are a particularly attractive optimisation target because they have a well defined interface many are tunable and different implementations of a data structure usually represent a particular trade off between time and storage making some operations faster but more space consuming or slower but more space efficient.
for instance an ordered list makes retrieving the entire dataset in sorted order fast but inserting new elements slow whilst a hash table allows for quick insertions and retrievals of specific items but listing the entire set in order is slow.
we introduce darwinian data structures distinct data structures that are interchangeable because they share an abstract data type and can be tuned.
the darwinian data structure optimisation problem is the problem of finding an optimal implementation and tuning for a darwinian data structure used in an input program.
we aim to help developers perform optimisation cheaply focusing solving the data structure optimisation problem.
we present artemis a cloud based optimisation framework that identifies darwinian data structures and given a test suite automatically searchesarxiv .03232v3 aug 2018esec fse november lake buena vista fl usa michail basios lingbo li fan wu leslie kanthan earl t. barr for optimal combinations of implementations and parameters for them.
artemis is language agnostic we have instantiated it for java and c and present optimisation results for both languages section .
artemis search is multi objective seeking to simultaneously improve a program s execution time memory usage and cpu usage while passing all the test suites.
artemis scales to large code bases because is uses a genetic algorithm on those regions of its search space with the most solutions section .
.
artemis is the first technique to apply multi objective optimisation to the darwinian data structure selection and tuning problem.
artemis promises to change the economics of data structure optimisation.
given a set of darwinian data structures artemis can search for optimal solutions in the background on the cloud freeing developers to focus on new features.
artemis makes economical small optimizations such as a few percent that would not pay for the developer time spent realizing them.
and sometimes of course artemis by virtue of being used will find unexpectedly big performance gains.
artemis is a source to source transformer.
when artemis finds a solution the program variants it produces differ from the original program only at constructor calls and relevant type annotations.
thus artemis variants are amenable by design to programmer inspection and do not increase technical debt .
to ease inspection artemis generates a diff for each changes it makes.
developers can inspect these diffs and decide which to keep and which to reject.
we report results on 8popular diverse github projects on dacapo benchmark which was constructed to be representative and a corpus of 30github projects filtered to meet artemis s constraints and sampled uniformly at random.
in this study artemis achieves substantial performance improvements for all 43projects in its corpus.
in terms of execution time cpu usage and memory consumption artemis finds at least one solution for 37out of 43projects that improves allmeasures.
across all produced optimal solutions the median improvement for execution time is .
memory consumption .
and cpu usage .
.
this result is for various corpora but it is highly likely to generalise to arbitrary programs because of the care we took to build a representative corpus section .
.
these aggregate results understate artemis s potential impact.
some of our benchmarks are libraries or utilities.
all of their clients will enjoy any improvements artemis finds for them.
three examples are the apache project s powerful xslt processor xalan google http java client the unbiquitious java library for accessing web resources and google s in memory file system jimfs .
section shows that artemis improved xalan s memory consumption by .
while leaving its execution time unchanged artemis improved google http java client s execution time by and its cpu usage by .
finally artemis improved jimfs s execution time by .
and its cpu usage by .
while leaving its memory consumption unchanged.
our principal contributions follow we formalise the darwinian data structure selection and optimisation problem ds2 section .
we implement artemis a multi language optimisation framework that automatically discovers and optimises sub optimal data structures and their parameters.
t list t getaslist t value if value null return null list t result new arraylist t result.add value return result listing a function from http java client.
we show the generalizability and effectiveness of artemis by conducting a large empirical study on a corpus comprising8popular github project 5projects from the dacapo benchmark and 30github projects filtered then sampled uniformly.
for all 43subjects artemis find variants that outperforms the original for all three objectives.
we provide artemis as a service along with its code and evaluation artifacts at motivating example listing contains a code snippet from google http java client1 a popular java library for accessing efficiently resources on the web.
in the listing getaslist packages http headers and is invoked frequently from other methods because they use it every time they construct an http request.
thus its functionality is important for the performance of google http java client .
listing uses arraylist to instantiate the result variable.
however other list implementations share the same functionality but different non functional properties.
thus replacing arraylist with other list implementations may affect the performance of the program.
considering the variant created when replacing arraylist listing line with linkedlist when we compare it with the original program against the same test set for 30runs section we see that the google http java client achieves a median with confidence interval improvement in execution time section .
artemis our optimization framework automatically discovers underperforming data structures and replaces them with better choices using search based techniques section .
.
first it automatically creates a store of data structures from the language s collection apilibrary section .
.
then artemis traverses the program s astto identify which of those data structures are used and exposes them as parameters to the artemis soptimizer section .
by transforming line into list t result new d t where dis the tag that refers to the exposed parameter associated with the defined data structure type section .
listing does not specify the initial capacity size of the arraylist so the default size 10was used.
if the instantiated list object contains less than 10items the default capacity can result in memory bloat.
if the list object contains more than 10items the default capacity can slow the execution time more memory realllocation operations will happen.
therefore an appropriate value must be chosen to find a good tradeoff between memory and execution time.
data structure selection esec fse november lake buena vista fl usa artemis automatically exposes such arguments as tunable parameters then adjusts them to improve the runtime performance of the program.
for instance artemis changes line to the code below list t l new arraylist s where srefers to the exposed parameter associated with the amount of pre allocated memory.
darwinian data structure selection and tuning this section defines the darwinian data structure and parameter optimisation problem we solve in this paper.
definition abstract data type .
anabstract data type adt is class of objects whose logical behavior is defined by a set of values and a set of operations .
adata structure concretely implements an adt.
for the corpus of programs cand the adt a the data structure extraction function dse a c returns all data structures that implement ainc.
this function is integral to the definition that follows.
definition darwinian data structure .
when d0 d1 dse a c d0 d1 d0andd1are observationally equivalent modulo a d0andd1aredarwinian data structures .
in words darwinian data structures are darwinian in the sense that they can be replaced to produce program mutants whose fitness we can evaluate.
the adt ahas darwinian data structures when it has more than one data structure that are equivalent over the operations the adt defines.
in java list is an adt and arraylist which implements it is a data structure.
linkedlist also implements list so both arraylist andlinkedlist are darwinian.
for the adt aand the corpus c darwinian data structures are interchangeable.
thus we can search the variants of p cformed by substituting one darwinian data structure for another to improve p s nonfunctional properties like execution time memory consumption or cpu usage.
just as we needed a function to extract an adt s data structures from a corpus for definition we need a function that returns the adt that a data structure implements when d dse a c let adte d c a. let dbind fully scope qualified declarations of names to darwinian data structures in c. we use dwhen creating variants of a program via substitution.
we are interested not just searching the space of darwinian data structures but also tuning them via their constructor parameters.
to this end we assume without loss of generality that adefines a single constructor c and we let n.c x denote calling identifier n s constructor cwith parameters x .
to create a variant of p cthat differs from ponly in its k bindings of names to darwinian data structures or their constructor initialization parameter we define p n di k dk j xj p if di djs.t.adte di adte dj p otherwise definition darwinian data structure selection and tuning .
for the real valued fitness function fover the corpus c the darwinian data structure and tuning problem is arg max ni di k k d dk j adte di c k xj f p ni di dj xj this vector based definition simultaneously considers all possible rebinding of names to darwinian data structures in p it is also cumbersome compared to its point substitution analogue.
we could not however simply present a scalar definition and then quantify over all potential ddss substitutions as so would not surface synergies and antagonisms among the substitutions.
artemis theartemis s optimisation framework solves the darwinian data structure selection problem.
figure illustrates the architecture with its three main components the darwinian data structures store generator ddssg the extractor and the optimiser .
artemis takes the language s collection apilibrary the user s application source code and a test suite as input to generate an optimised version of the code with a new combination of data structures.
the ddssg builds a store that contains data structure transformation rules.
the extractor uses this store to discover potential data structure transformations and exposes them as tunable parameters to the optimiser see section .
.
the optimiser uses a multi objective genetic search algorithm nsga ii to tune the parameters and to provide optimised solutions see section .
.
a regression test suite is used to maintain the correctness of the transformations and to evaluate the non functional properties of interest.
artemis uses a built in profiler that measures execution time memory and cpu usage.
artemis relies on testing to define a performance search space and to preserve semantics.
artemis therefore can only be applied to programs with a test suite.
ideally this test suite would comprise both a regression test suite with high code coverage for maintaining the correctness of the program and a performance test suite to simulate the real life behaviour of the program and ensure that all of the common features are covered .
even though performance test suites are a more appropriate and logical choice for evaluating the non functional properties of the program most real world programs in github do not provide such performance test suite.
for this reason we use the regression test suites to evaluate the non functional properties of the github projects of this study whenever a performance test suite is not available.
.
darwinian data structure store artemis needs a darwinian data structure store ddss from which to choose when creating variants.
let abe a set of adts known to be darwinian.
a developer can augment this set figure shows those that artemis knows by default.
for our corpus cof java benchmarks augmented with jdk libraries over a ddss a adse a c .
to build the default ddss for java artemis extracts and traverses each project s class hierarchy similar to the one illustrated in figure .
this hierarchy shows potential darwinian data structures of a specific interface.
when this traversal finishes artemis extracts all the implementations of a particular darwinian dataesec fse november lake buena vista fl usa michail basios lingbo li fan wu leslie kanthan earl t. barr figure system architecture of artemis .
collection list set linkedlist arraylist treeset hashset figure dds in the java collections api.
abstract data type implementation list arraylist linkedlist map hashmap linkedhashmap set hashset linkedhashset concurrent list vector copyonwritearraylist concurrent deque concurrentlinkeddeque linkedblockingdeque thread safe queue arrayblockingqueue synchronousqueue linkedblockingqueue delayqueue concurrentlinkedqueue linkedtransferqueue table data structure groups.
structure e.g.
list arraylist linkedlist .artemis considers these implementations mutually replaceable.
for java a default ddss is provided by artemis which the developer can edit.
for other languages the ddss can be provided manually by the user and this step can be skipped.
the optimiser described next uses the store during its search.
the developer can also extend the store with custom user supplied implementations or with implementations from other third party libraries such as google guava collections2 fastutil3and apache commons collections4.
.
discovering darwinian data structures theextractor takes as input the program p s source code identifies darwinian data structures in pmodulo its store section .
outputs a scope qualified list of names of darwinian data structures and their constructor parameters extracted data structures and parameters in figure .
for all a ddss extractor s output realises dse a p section .
to mark potential substitions to the transformer the extractor outputs a templated version of the code which replaces the data structure with data structure type identifiers templated source code in figure .
to find darwinian data structures the extractor builds an abstract syntax tree ast from its input source code.
it then traverses theastto discover potential data structure transformations based on a store of data structures as shown in table .
for example when an expression node of the astcontains a linkedlist expression theextractor marks this expression as a potential darwinian data structure that can take values from the available list implementations linkedlist orarraylist .
the extractor maintains a copy of the ast referred to as the rewriter where it applies transformations without changing the initial ast.
when the ast transformation finishes the rewriter produces the final source code which is saved as a new file.
.
code transformations when implementing artemis we encountered coding practices that vastly increase the search space.
many turn out to be known bad practices .
consider listing .
in lines and we see two linkedlist variables that the extractor marks darwinian and candidates for replacement by their equivalent arraylist implementation.
in these lines user is violating the precept to program to the interface here list but is instead declaring the variable to have the concrete data structure not adt type linkedlist .
this bad practice adds dependencies to the code limiting code reuse.
they are especially problematic for artemis because they force artemis to apply multiple transformations to replace and optimise the data structure.
further func3 takes a linkedlist as a parameter not list despite the fact that it only calls the get method defined by list on this parameter.
this instance of violating the program to the interface precept triggers a compilation error if artemis na vely changes func1 s type.
artemis transforms the code to reduce the optimiser s search space and handle thesedarwinian data structure selection esec fse november lake buena vista fl usa 1void func1 2linkedlist t v 3v new linkedlist 4v.add new t 5int value func3 v 7void func2 linkedlist t v 8linkedlist t v1 new linkedlist 9int value func3 v1 int func3 linkedlist t v t t v.get return t.value listing code to illustrate bad practices.
bad practices.
artemis supports thee transformations parserless supertype and profiler.
the parserless mode changes greadily each appearance of a darwinian implementation.
when optimising list it exhaustively tries every implementation of list for every list variable.
it is parserless since it needs only a regular expression to identify rewritings.
this makes it simple easily portable to other languages and fast so it is artemis default.
however it generates invalid programs and a large search space.
artemis sypertype transformation converts the type of a darwinian implementation to that of their darwinian adt for example linkedlist t list t on lines 8and11.
for listing this tranformation exposes only two dds to the optimiser and produces only syntactically valid code.
to implement this transformation artemis invokes eclipse s re factoring functionality via its api then validates the result.
artemis aims to be languageagnostic without any additional dependencies on language specific tools.
for this case artemis auto performs this transformation by adding the supertype as an equivalent parameter in the store of data structures.
whenever the astvisitor traverses a variable or parameter declaration expression it may replace the darwinian data structure with its supertype.
all data structures are equal but some data structures are more equal than others some dds affect a program s performance more than others as when one stores only a few rarely accessed items.
to rank dds artemis profiles its input program to identify costly methods.
the extractor uses this info to identify the subset of a program s dds worth considering for optimisation.
artemis instrumentation is particularly important for large programs.
.
search based parameter tuning theoptimiser searches a combination of data structures that improves the performance of the initial program while keeps the original functionality.
practically we can represent all those data structures as parameters that can be tuned using search based software engineering approaches .
because of the nature of the various conflicting performance objectives the problem we faced 5adapted from animal farm by george orwellhere requires a multi objective optimisation approach to search the near optimal solutions.
an array of integers is used to represent the tuning parameters.
each parameter refers either to a darwinian data structure or to the initial size of that data structure.
if the parameter refers to a data structure its value represents the index in the list of darwinian data structures.
the optimiser keeps additional mapping information to distinguish the types of the parameters.
for each generation the nsga ii applies tournament selection followed by a uniform crossover and a uniform mutation operation.
in our experiments we designed fitness functions to capture execution time memory consumption and cpu usage.
after fitness evaluation artemis applies standard non dominated selection to form the next generation.
artemis repeats this process until the solutions in a generation converge.
at this point artemis returns all non dominated solutions in the final population.
search space size we used ga because the search space is huge.
letdbe the definitions of darwinian data structures in program p. letibe the number of implementations for a particular d d. the size of the search space is d di d dom d.c where d.cisd s constructor.
.
deployability artemis provides optimisation as a cloud service.
to use the service developers only need to provide the source code of their project in a maven build format and a performance test suite invoked by mvn test .artemis returns the optimised source code and a performance report.
artemis exposes a restful api that developers can use to edit the default store of darwinian data structures.
the api also allows developers to select other search based algorithms theoptimiser uses nsga ii by default.
to use our tool from the command line a simple command is used .
artemis input program src where this command defaults to artemis s built in ddssg .artemis writes the source of an optimized variant of its input for each measure.
artemis also supports optional parameters to customise its processing.
evaluation to demonstrate the performance improvements that artemis automatically achieves and its broad applicability we applied it to three corpora 8popular github projects 5projects from the dacapo benchmark and 30projects filtered to meet artemis s requirements then sampled uniformly at random from github.
to show also that artemis is language agnostic we applied it to optimise guetzli6 section .
a jpeg encoder written in c .
.
corpus artemis requires projects with capable build systems and an extensive test suites.
these two requirements entail that artemis be able to build and run the project against its test suite.
artemis is november lake buena vista fl usa michail basios lingbo li fan wu leslie kanthan earl t. barr language agnostic but is currently only instantiated for java and c so it requires java or c programs.
our first corpus comprises eight popular github projects.
we selected these eight to have good test suites and be diverse.
we defined popular to be projects that received at least 200stars on github.
we deemed a test suite to be good if its line coverage met or exceeded .
this corpus contains projects usually well written optimised and peer code reviewed by experienced developers.
we applied artemis on those projects to investigate whether it can provide a better combination of data structures than those selected by experienced human developers.
this first corpus might not be representative precisely because of the popularity of its benchmarks.
to address this threat to validity we turned to the dacapo benchmarks .
the authors of dacapo built it from the ground up to be representative.
the goal was to provide the research community with realistic large scale java benchmarks that contain a good methodology for java evaluation.
dacapo contains 14open source client side java benchmarks version .
and they come with built in extensive evaluation.
each benchmark provides accurate measurements for execution time and memory consumption.
dacapo first appeared in to work with java v. .
and has not been further updated to work with newer versions of java.
for this reason we faced difficulties in compiling all the benchmarks and the total number of benchmarks were reduced to 5out of .
in this corpus we use the following five fop avrora xalan pmdandsunflow figure .
because of its age and the fact that we are only using subset of it our dacapo benchmark may not be representative.
to counter this threat we uniformly sampled projects from github.
we discarded those that did not meet artemis s constraints like being equipped with a build system until we collected 30projects.
those projects are diverse both in domain and size.
the selected projects include static analysers testing frameworks web clients and graph processing applications.
their sizes vary from 576to94klines of code with a median of .
their popularity varies from 0to5642 stars with a median of 52stars per project.
the median number of tests is170and median line coverage ratio is .
collectively we systematically built these corpora to be representative in order to demontrate the general applicably of the artemis optimization framework.
the full list of the programs used in this experimental study are available online7in the project s website.
.
experimental setup experiments were conducted using microsoft azuretmd4 v2 machines with one intel e5 2673v3 cpu featuring cores and 14gb of dram and built with oracle jdk .
.
and ubuntu .
.
lts.
performance measurements may lead to incorrect results if not handled carefully .
thus a statistical rigorous performance evaluation is required .
to mitigate instability and incorrect results we differentiate vm start up and steady state.
we ran our experiments in a fresh azure vm that contained only the jvm and the subject.
we use junit which runs an entire test suite in a single jvm.
we manually identified and dropped startup runs then we spot checked the results to confirm that the rest of the runs achieved a steady state and were exhibiting low variance.
all the means and medians we reported fall within the computed interval with confidence.
to assure the accuracy and reduce the bias in the measurement program profiling period was set as .1seconds and each generated solution was run for more than simulations.
also we use mann whitney u test to examine if the improvement is statistically significant.
to measure the memory consumption and cpu usage of a subject program we use the popular jconsole profiler8because it directly handles jdkstatistics and provides elegant api.
we extended jconsole to monitor only those system processes belonging to the test suite.
we use maven surefire plugin9to measure the test suite s execution time because it reports only the execution time of each individual test excluding the measurement overhead that other maven plugins may introduce.
for the optimiser we chose an initial population size of 30and a maximum number of 900function evaluations.
we used the tournament selection based on ranking and crowding distance simulated binary crossover with crossover probability .
and polynomial mutation with the mutation probability .
.
we determined these settings from calibration trials to ensure the maturity of the results.
since nsga ii is stochastic we ran each experiment 30times to obtain statistical significant results.
.
research questions and results analysis artemis aims to improve all objectives at the same time.
therefore the first research question we would like to answer is rq1 what proportion of programs does artemis improve?
to answer rq1 we applied artemis to our corpus.
we inspected the generated optimal solutions from 30runs of each subject by examining the dominate relation between the optimal and inital solutions regarding the optimisation objectives.
we introduce the terms strictly dominate relation andnon dominated relation to describe the relation.
defined by zitzler et al.
a solution strictly dominates another solution if it outperforms the latter in all measures.
a solution is non dominated with another solution if both outperform the other in at least one of the measures.
for dacapo artemis found at least one strictly dominant solution for 4out of 5projects it found no such solution for sunflow .
it found solutions from which are strictly dominant median is5.5solutions per project and are non dominated median is 18solutions per project .
for the popular github projects artemis found at least one strictly dominant solution for all 8projects.
the total number of solutions found is and16 of them are strictly dominant median is 50solutions per project and are non dominated median is .5solutions per project .
for the sampled github projects artemis found a strictly dominant solution for 25out of 30projects but found no solution for projects rubix verifier epubcheck d worker telegrambots andfqueue .
it found of which of them are strictly dominant median is 24solutions per project and are non dominant data structure selection esec fse november lake buena vista fl usa median is 125solutions per project .
with these results we answer rq1affirmatively finding1 artemis finds optimised variants that outperform the original program in at least one measure for allprograms in our representative corpus.
this finding understates artemis s impact.
not only did it improve at least one measure for all programs artemis found solutions that improve all measures for88 of the programs.
having found that artemis finds performance improvements we ask how good are these improvements with rq2 what is the average improvement that artemis provides for each program?
though artemis aims to improve all candidate s measures it cannot achieve that if improvements are antagonistic.
in some domains it is more important to significantly improve one of the measures than to improve slightly all measures e.g.
a high frequency trading application may want to pay the cost of additional memory overhead in order to improve the execution time.
our intuition is that theoptimiser will find many solutions on the pareto front and at least one of them will improve each measure significantly.
we answer rq2quantitatively.
we report the maximum improvement median value with confidence interval for execution time memory and cpu usage for each subject of the three corpora.
we use bar charts with error bars to plot the three measures for each program.
in y axis we represent the percentage of improvement for each measure.
a value less than represents an improvement and a value greater than means degradation e.g.
memory consumption implies that the solution consumes of the memory used in the input program.
selected popular github programs.
figure 3a presents the three measures of the solutions when the execution time is minimised for each program from the popular github programs.
we observe that artemis improves the execution time of every program.
google http java client s execution time was improved the most its execution time was reduced by m ci .
.
.
we also notice that this execution time improvement did not affect negatively the other measures but instead the cpu usage was reduced by m .
ci and memory consumption remained almost the same.
the other interesting program to notice from this graph is solo a blogging system written in java its execution time improved slightly by but its memory consumption increased by .
.
finally for this set of solutions the median execution time improvement is .
whilst memory consumption slightly increased by .
and cpu usage decreased by3.
.
for those programs artemis extracted a median of data structures and the optimal solutions had a median of 4data structures changes from the original versions of the program.
figure 3b shows the solutions optimised for memory consumption.
we notice that artemis improves the memory consumption for all programs with a median value of .
the execution time was improved by a median value of .
for these solutions while the median value of cpu usage is slightly increased by .
.
we notice that solo has the best improvement by m .
ci http java clientjimfs jool cglib gsongraphjetsolojoda time406080100120140relative difference execution time memory cpu a best execution time of popular github programs.
the median value is93.
mean is .
.
median number of dds is12and mean is .
.
median number of ddschanges is 4and mean is .
solo http java clientgson cglib jool jimfsjoda time graphjet406080100120140relative difference execution time memory cpu b best memory consumption of popular github programs.
the median value is and mean is .
median number of ddsis12and mean is .
.
median number of ddschanges is 4and mean is .
.
http java clientjool jimfs gson cglib solographjet joda time406080100120140relative difference execution time memory cpu c best cpu usage of popular github programs.
the median value is .
and mean is .
.
median number of ddsis12and mean is .
.
median number of ddschanges is 5and mean is .
.
figure answers rq2.
description.
but with an increase of m .
ci in execution time and m .
ci in cpu usage.
graphjet a real time graph processing library has the minimum improvement of m .
ci .
the optimal solutions had a median of 4data structures changes per solution.
figure 3c presents solutions optimised for cpu usage.
the median cpu usage improvement is .
.
the median value of execution time improved by .
and the median value of memory consumption improved by .
.
the program with the most significant improvement in cpu is http java client with m .
ci but with a decrease in memory of m .
ci .
the optimal solutions make a median of data structures changes to the original versions of the program.
dacapo.
figure presents all solutions optimised for execution time and memory consumption for the dacapo benchmark.
we used only two measures for the dacapo benchmark as those were the ones built in the benchmark suite.
we chose not to extend or edit the profiling method of dacapo to avoid the risk of affecting the validity of its existing well tested profiling process.
artemis found solutions that improve the execution time for every program without affecting significantly the memory consumption except project xalan which had improvement m .
ci in execution time but with an increase .
ci in memory consumption.
all solutions for optimised memory consumption did not affect execution time except for a slight increase for program fop.
finally for this set of solutions the median percentage of execution time improvement is .
and .
for memory consumption.
for this set of programs esec fse november lake buena vista fl usa michail basios lingbo li fan wu leslie kanthan earl t. barr fop avrora xalan pmd sunflow6080100120relative difference execution time memory a best execution time of the dacapo benchmark.
the median value is .
and mean is .
.
median number of ddsis18and mean is .
.
median number of ddschanges is 5and mean is .
.
xalan fop sunflow avrora pmd6080100120relative difference execution time memory b best memory consumption of the dacapo benchmark.
the median value is .
and mean is .
.
median number of ddsis18and mean is14.
.
median number of ddschanges is 3and mean is .
.
figure answers rq2.
description.
artemis extracted a median of 18data structures per program and the optimal solutions had a median of 5data structures changes for the execution time optimised solutions and 4for the memory optimised solutions.
sampled github programs.
figure presents all solutions optimised for execution time memory consumption and cpu usage for the sampled github programs.
as with the previous corpora artemis found solutions that improved each measure significantly.
artemis improves the median value of execution time across all projects by .
memory consumption by .
and cpu usage by4.
.
artemis found solutions with antagonistic improvement for projects jafka anddocuments4j .artemis found a solution that improves the execution time of jafka a distributed publish subscribe messaging system by m ci but also increases its memory consumption by m .
ci .
it also found a solution that improves the memory consumption ofdocuments4j m ci but introduced extra cpu usage m .
ci .
a median of .5data structures were extracted and the optimal solutions had a median of 5data structures changes from the original versions of the program.
observing again the numbers across the three corpora we can say that they are quite consistent showing that artemis finds optimal solutions that improve significantly the different optimisation measures.
we also see that the number of darwinian data structures extracted between .5and18 and the optimal solutions dds changes between 4and5 are quite similar for the three corpora.
analysing all results from the 3corpora we conclude the discussion of rq2 with finding2 artemis improves the median across all programs in our corpus by .
execution time .
memory consumption and .
cpu usage.
rq3 which darwinian data structures does artemis find and tune?
we ask this question to understand which changes artemis makes to a program.
table contains the transformations artemistranformation time memory cpu hashmap linkedhashmap linkedlist arraylist hashset linkedhashset linkedblockingqueue linkedtransferqueue arraylist linkedlist linkedhashset hashset vector copyonwritearraylist linkedhashmap hashmap table dds changes for optimal solutions across all measures.
applied across all optimal solutions.
we see that the most common transformation for all measures is replacing arraylist with linkedlist it appears 86and87times respectevely across all measures.
this transformation indicates that most developers prefer to use arraylist in their code which in general is considered to be faster neglecting use cases in which linkedlist performs better e.g.
when the program has many list insertion or removal operations.
except hashmap tolinkedhashmap the other transformations happen relatively rare in the optimal solutions.
last the median number of lines artemis changes is .
finding3 artemis extracted a median of 12darwinian data structures from each program and the optimal solutions had a median of 5data structure changes from the original versions of the program.
rq4 what is the cost of using artemis ?
in order for artemis to be practical and useful in real world situations it is important to understand the cost of using it.
the aforementioned experimental studies reveal that even for the popular programs the existing selection of the data structure and the setting of its parameters may be sub optimal.
therefore optimising the data structures and their parameters can still provide significant improvement on non functional properties.
to answer this research question the cost of artemis for optimising a program is measured by the cost of computational resources it uses.
in this study we used a microsoft azuretmd4 v2 machine which costs .41per hour at a standard pay as you go rate10 to conduct all experiments.
the experiments show that an optimisation process takes .
hours on average for all studied subjects.
the program graphjet andjimfs are the most and the least time consuming programs respectively with .16hours and .12minutes optimisation time.
accordingly the average cost of applying artemis for the subjects studied is .
with a range from .02to .
.
the experimental results show that overall cost of using artemis is negligible compared to a human software engineer with the assumption that a competent software engineer can find those optimisation in a reasonable time.
artemis transforms the selection of data structure and sets parameters by rewriting source code thereby allowing human developers to easily investigate its changes and gain insight about the usage of data structures and the characteristics of the program.
data structure selection esec fse november lake buena vista fl usa jafka zxing light 4j truth mapper jsoniter querqy shuzai bootiquerest assured documents4jopenlrs jobproxy tablesaw plungerrubix verifierevent store cmnglowstonemilo cmn validatortap pluginguice poilight hospital systemjavapoet epubcheck d workertelegrambotscmn codecfqueue406080100120140relative difference execution time memory cpu a best execution time of uniformly selected github programs.
the median value is .
and mean is .
.
median number of ddsis9.5and mean is .
.
median number of ddschanges is 5and mean is .
.
zxing jafka documents4jlight 4jcmn codec tablesaw querqy truth mapper fqueue jsoniterrest assuredplunger bootique event store cmnopenlrs glowstoneshuzai milopoilight javapoet jobproxy epubcheck tap pluginguice telegrambotsd workerhospital system cmn validator rubix verifier406080100120140relative difference execution time memory cpu b best memory consumption of the uniformly selected github programs.
the median value is .
and mean is .
.
median number of ddsis9.5and mean is .
.
median number of ddschanges is 5and mean is .
.
light 4jdocuments4jmapperjafka truth plunger jsoniter zxingcmn codec bootique glowstone tablesaw openlrs shuzai querqyrest assuredmilojobproxy event store cmnjavapoet tap plugintelegrambotsepubcheckguice cmn validator hospital systempoilight d worker fqueuerubix verifier406080100120140relative difference execution time memory cpu c best cpu usage of the uniformly selected github programs.
the median value is .
and mean is .
median number of dds is9.5and mean is .
.
median number of ddschanges is 5and mean is .
.
figure answers rq2.
description.
finding4 the cost of using artemis is negligible with an average of .25per project providing engineers with insights about the optimal variants of the project under optimisation.
to show the versatility of the artemis framework we ask rq2 rq3 and rq4 over google guetzli a very popular jpeg encoder written in c .
we used the stl containers and their operations as darwinian data structures.
more specifically we considered the push back andemplace back as equivalent implementations of the same functionality and exposed those as tunable parameters toartemis s optimiser.
we collected a random sample of images available online11 and used it to construct a performance suite that evaluates the execution time of guetzli .
we answer rq2 by showing that artemis found an optimal solution that improves execution time by .
we answer rq3 by showing that artemis extracted and tuned 25parameters and found an optimal solution with 11parameter changes.
artemis spent .
hours costs .
to find optimal solutions which is between the limits reported in rq4.
last we spent approximately 4days to extend artemis to support c using the parserless mode.
threats to validity section .
discusses the steps we took to address the threats to the external validity of the results we present here.
in short we built three subcorpora each more representative than the last for a total of 43programs diverse in size and domain.
the biggest threat to the internal validity of our work is the difficulty of taking accurate performance measurements of applications running on vm like the jvm.
section .
details the steps drawn from best practice we took to address this threat.
in essence we conducted calibration experiments to adjust the parameters such that the converges quickly and stops after the results become stable.
for measuring the non functional properties we carefully chose jconsole profiler that directly gathers runtime information from jdk such that the measurement error is minimised.
moreover we carefully tuned jconsole to further improve the precision of the measurements by maximising its sampling frequency such that it does not miss any measurements while minimising the cpu overhead.
to cater for the stochastic nature of artemis and to provide the statistic power for the results we ran each experiment 30times and manually checked that experiments had a steady state and exhibited low variance.
related work multi objective darwinian data structure selection and optimisation stands between two areas search based software engineering and data structure performance optimisation.
.
search based software engineering previous work applies genetic programming to either improve the functionality bug fixing or nonfunctional properties of a program .
their approaches use existing code as the code base and replace some of the source code in the program under optimisation with the code from the code base.
however many of these approaches rely on the plastic surgery hypothesis which assumes that the solutions exist in the code base.
artemis on the other hand does not rely on this hypothesis.
artemis can harvest darwinian data structures both from the program but also from external code repositiories further artemis relies on a set of transformation rules that it can automatically exhaustively extract from library code or documentation.
wu et al.
introduced a mutation based method to expose deep parameters similar to those we optimise in this paper fromesec fse november lake buena vista fl usa michail basios lingbo li fan wu leslie kanthan earl t. barr the program under optimisation and tuned these parameters along with shallow parameters to improve the time and memory performance of the program.
though the idea of exposing additional tunable parameter is similar to artemis their approach did not optimise data structure selection which can sometimes be more rewarding than just tuning the parameters.
moreover they applied their approach to a memory management library to benefit that library s clients.
the extent of improvement usually depends on how much a program relies on that library.
in contrast artemis directly applies to the source code of the program making no assumptions about which libraries the program uses affording artemis much wider applicability.
.
data structure optimisation and bloat a body of work has attempted to identify bloat arising from data structures.
in shacham et al.
introduced a semantic profiler that provides online collection usage semantics for java programs.
they instrumented java virtual machine jvm to gather the usage statistics of collection data structures.
using heuristics they suggest a potentially better choice for a data structure for a program.
though developers can add heuristics if they lack sufficient knowledge about the data structures they may bias the heuristics and jeopardise the effectiveness of the approach.
artemis directly uses the performance of a data structure profiled against a set of performance tests to determine the optimal choices of data structures.
therefore artemis does not depend on expert human knowledge about the internal implementation and performance differences of data structures to formulate heuristics.
instead.
artemis relies on carefully chosen performance tests to minimse bias.
furthermore artemis directly modifies the program instead of providing hints thus users can use the fine tuned program artemis generates without any additional manual adjustment.
other frameworks provide users with manually or automatically generated selection heuristics to improve the data structure selection process.
jitds exploits declarative specifications embedded by experts in data structures to adapt them.
collectionswitch uses data and user defined performance rules to select other data structure variants.
brainy provides users with machine learning cost models that guide the selection of data structures.
artemis does not require expert annotations user defined rules or any machine learning knowledge.
storage strategies changes vms to optimize their performance on collections that contain a single primitive type artemis rewrites source code and handles user defined types and does not make vm modifications.
in manotas et al.
introduced a collection data structure replacement and optimisation framework named seeds .
their framework replaces the collection data structures in java applications with other data structures exhaustively and automatically select the most energy efficient one to improve the overall energy performance of the application.
conceptually artemis extends this approach to optimise both the data structures and their initialization parameters.
artemis also extends the optimisation objectives from single objective to triple objectives and used pareto non dominated solutions to show the trade offs between these objectives.
due toa much larger search space in our problem the exhaustive exploration search that used by seeds is not practical therefore we adopted meta heuristic search.
furthermore artemis directly transforms the source code of the programs whilst seeds transforms the bytecode so artemis provides developers more intuitive information about what was changed and teaches them to use more efficient data structures.
moreover artemis can be more easily applied to other languages as it does not depend on language specific static analysers and refactoring tools such as wala and eclipse ide s refactoring tools.
in order to support another language we just need the grammar of that language and to implement a visitor that extracts a program s darwinian data structures.
we note that antlr which artemis uses currently provides many available grammar languages12.
apart from the novelties mentioned above this is the largest empirical study to our knowledge compared to similar work.
in the studies mentioned above only 4to7subjects were included in the experiments.
our study included the dacapo benchmark 30sampled github subjects and 8well written popular subjects to show the effectiveness of artemis therefore our results are statistically more meaningful.
conclusion developers frequently use underperformed data structures and forget to optimise them with respect to some critical non functional properties once the functionalities are fulfilled.
in this paper we introduced artemis a novel multi objective multi language searchbased framework that automatically selects and optimises darwinian data structures and their arguments in a given program.
artemis is language agnostic meaning it can be easily adapted to any programming language extending artemis to support c took approximately 4days.
given as input a data structure store with darwinian implementations it can automatically detect and optimise them along with any additional parameters to improve the non functional properties of the given program.
in a large empirical study on 5dacapo benchmarks 30randomly sampled projects and8well written popular github projects artemis found strong improvement for all of them.
on extreme cases artemis found improvement on execution time .
improvement on memory consumption and .
improvement on cpu usage.
artemis found such improvements making small changes in the source code the median number of lines artemis changes is .
thus artemis is practical and can be easily used on other projects.
at last we estimated the cost of optimising a program in machine hours.
with a price of .41per machine hour the cost of optsimising any subject in this study is less than with an average of .
.
therefore we conclude that artemis is a practical tool for optimising the data structures in large real world programs.