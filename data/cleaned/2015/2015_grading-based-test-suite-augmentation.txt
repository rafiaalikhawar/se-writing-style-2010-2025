grading based test suite augmentation jonathan osei owusu angello astorga liia butler tao xie and geoffrey challen department of computer science university of illinois at urbana champaign jo28 aastorg2 liiamb2 challen illinois.edu key laboratory of high confidence software technologies peking university ministry of education taoxie pku.edu.cn abstract enrollment in introductory programming cs1 courses continues to surge and hundreds of cs1 students can produce thousands of submissions for a single problem all requiring timely and accurate grading.
one way that instructors can efficiently grade is to construct a custom instructor test suite that compares a student submission to a reference solution over randomly generated or hand crafted inputs.
however such test suite is often insufficient causing incorrect submissions to be marked as correct.
to address this issue we propose the grasa grading based test suite augmentation approach consisting of two techniques.
grasa first detects and clusters incorrect submissions by approximating their behavioral equivalence to each other .
to augment the existing instructor test suite grasa generates a minimal set of additional tests that help detect the incorrect submissions.
we evaluate our grasa approach on a dataset of cs1 student submissions for three programming problems.
our preliminary results show that grasa can effectively identify incorrect student submissions and minimally augment the instructor test suite.
index t erms programming education testing clustering i. i ntroduction enrollment in introductory programming cs1 courses continues to surge at remarkable rates .
as current instructional resources cannot keep pace with the rapidly growing demand instructors must adapt or face a decline in cs1course quality .
one key area in need of critical attention is grading.
for a programming problem hundreds of students can produce thousands of submissions over the period of a semester.
each of these submissions must be graded to provide feedback critical to student learning .
however grading approaches reasonable for a small class e.g.
inspecting and grading each submission by hand are no longer viable as the class size increases.
automated testing while not exclusive to a large class remains the most common approach to evaluate a large number of cs1 student submissions related to programming.
one way for instructors to grade efficiently is to construct a custom test suite that compares a submission to a reference solution over randomly generated or hand crafted inputs.
such test suite is often insufficient failing to include corner case inputs for exposing faults in some incorrect submissions.
as a result incorrect submissions may be mistakenly marked as correct1.
a test suite of insufficient quality not only may cause unfairness to students e.g.
students who do not meet the 1correct ones may also be marked as incorrect however in our experience such cases are usually reported by students.intended expectations of a problem receive the same grade as students who do but also may cause instructors to miss valuable opportunities to gain insight about issues in students learning.
this shortcoming is exacerbated as the class size increases and subsequently the number of different ways that submissions are incorrect increases.
to address test suite insufficiency in cs education we propose a new approach of conducting test suite augmentation namely the grasa gra ding based test suite augmentation approach in the space of multiple correct or incorrect implementations of the same specification.
the main objective of grasa is to augment the given instructor test suite with a minimal set of generated tests that aim to detect a maximum number of incorrect submissions.
the reasons for emphasizing minimal tests in grasa s main objective are minimizing the generated tests can alleviate the burden of instructors who wish to maintain control of assigning different point values per test e.g.
some tests are more important than others while manually inspecting the generated tests minimizing the generated tests can reduce the runtime cost for executing these tests especially when they are run against a large number of submissions.
to accomplish the main objective grasa first runs the given instructor test suite tion each submission against a reference solution rto identify and focus on only those submissions cdetermined by tito be correct.
then we conduct grasa s two techniques behavioral equivalence approximation and equivalence guided test generation.
in the technique of behavioral equivalence approximation two programs e.g.
submissions and r are approximately behaviorally equivalent if they produce the same outputs on the sample inputs in the input space produced by a structural test generator such as pex .
we group programs into a cluster when these programs are approximately behaviorally equivalent.
the cluster including ris the cluster of correct submissions and each of the remaining clusters is a cluster of incorrect submissions.
then in the technique of equivalence guided test generation we again leverage pex to generate a minimal set of tests ttg that help detect the incorrect submissions detected by the technique of behavioral equivalence approximation.
finally we use the generated tests to augment the given instructor test suite.
in summary this paper makes the following main contributions 34th ieee acm international conference on automated software engineering ase .
ieee authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
fig.
.
overview of the proposed grasa approach.
grading based test suite augmentation grasa for conducting test suite augmentation based on multiple correct or incorrect implementations of the same specification with the target application domain as cs education.
techniques for identifying and clustering incorrect submissions and for augmenting the given instructor test suite with a minimal set of generated tests that help detect the incorrect submissions.
preliminary results on submissions for three programming problems from a cs1 course spanning two semesters.
ii.
a pproach our grasa approach consists of two techniques behavioralequivalence approximation and equivalence guided test generation as shown in figure .
a. behavioral equivalence approximation our technique of behavioral equivalence approximation first checks the behavioral equivalence in later parts of this section we explain how to accomplish this checking in an approximate way between each submission in the initial set of submissions c determined by the instructor test suite tito be correct with the reference solution r. any submission nonequivalent to ris detected as an incorrect submission .
then all the submissions equivalent to rare put into the cluster of correct submissions.
for the remaining incorrect submissions our technique further checks the behavioral equivalence between every two incorrect submissions.
two equivalent incorrect submissions are put into the same cluster of incorrect submissions i.e.
they are incorrect in the same way .
to check behavioral equivalence in an approximate way we extend paired symbolic execution pse .
pse intends to generate test inputs for exposing different behaviors of two given programs sharing the same interface e.g.
the same method signature .
its key idea is to first construct a wrapper method to compare the outputs of the two programs given the same inputs and then apply a structural test generator such as pex on this wrapper method to generate its argument values aiming to achieve high branch coverage of the wrapper method along with the methods directly or indirectly invoked by the wrapper method.
some generated argument values for1 public static void wrapperforpairedsymbolicexecution args assert isequal prog1 args prog2 args fig.
.
simplified wrapper constructed for paired symbolic execution.
the wrapper method may be able to cause different outputs of the two programs under comparison.
figure shows a simplified version of a wrapper method.
in this simplified version we assume that both programs are static methods and their method arguments denoted as args are either primitive type arguments or immutable objects.
assert with the boolean argument is a typical assertion method e.g.
one commonly used in a unit testing framework .
isequal is a method for checking the equivalence of two values specified in its two arguments.
when the two values are of non primitive type isequal can be implemented as checking the object state equivalence based on its custom equals method.
when the method arguments args include mutable objects the simplified wrapper method shown in figure is extended to declare two arguments denoted as argprog1 andargprog2 for each mutable argument of the programs.
then the beginning of the wrapper method body invokes an assumption method assume isequal argprog1 argprog2 .
if any generated argument values for the wrapper method cause the boolean argument of assume to be false the generated argument values are automatically discarded i.e.
classified as invalid .
when the programs under comparison are non static methods thus having receiver objects being mutable similarly the simplified wrapper method shown in figure declares two arguments denoted as receiverprog1 and receiverprog2 and the beginning of the wrapper method body invokes assume isequal receiverprog1 receiverprog2 .
note that additionally the end of the wrapper method body invokes the assertion method for asserting the equivalence of two updated receiver objects for non static methods under comparison or two updated mutable argument objects for methods under comparison including a mutable argument .
after applying a structural test generator such as pex on the wrapper method to generate tests i.e.
argument values for the wrapper method we say that two programs are approximately behaviorally equivalent in short as equivalent for simplicity when all of the following three conditions are satisfied there is no generated test for causing violation of authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
any assertion synthesized by us in the wrapper method body if the program inputs e.g.
receiver object and method argument values derived from a generated test cause one program to throw an exception then the equivalent program inputs derived from the same test also cause the other program to throw an exception of the same type and if the program inputs derived from a generated test cause one program to execute infinitely then the equivalent program inputs derived from the same test also cause the other program to execute infinitely.
to support conditions and which are heuristic by nature for behavioral equivalence checking we further extend the wrapper method with additional checking code.
b. equivalence guided test generation the technique of equivalence guided test generation augments the given instructor test suite with a minimal set of tests that can detect the incorrect submissions detected by the technique of behavioral equivalence approximation i.e.
can detect behavioral inequivalence between the reference solution rand the incorrect submissions.
note that a test that can detect behavioral inequivalence between rand a submission in a cluster can also detect behavioral inequivalence between rand all other submissions of the same cluster.
thus to guide generation of minimal tests our technique selects only one representative from each cluster of incorrect submissions i.e.
nrepresentatives where nis the total number of clusters of incorrect submissions resulted from the technique of behavioral equivalence approximation .
our technique works on iterations each of which includes two steps.
in step we conduct greedy test generation generate a single test tthat can detect behavioral inequivalence between rand the maximum number of representatives under consideration denoted as sr which initially include allnrepresentatives .
our greedy test generation iteratively constructs a wrapper with a simplified one shown in figure and then applies a structural test generator such as pex on this wrapper method till the test generator generates an assertion violating test.
in figure representative1 ... representativen are all the representatives from sr. the constant gin line is initially set as sr and decremented by iteratively till an assertion violating test is generated by the test generator.
in step from srwe remove the representatives detected byt generated in step to be incorrect i.e.
causing to cover the true branch of their corresponding ifstatements in the wrapper method body and conduct greedy test generation again until sris empty.
finally all the tests tgenerated from all iterations are the minimal set of tests produced by our technique.
iii.
p reliminary ev aluation a. evaluation setup our evaluation subjects include student submissions for three programming problems given in quizzes and exams in a cs1 course public static void wrapperforequivguidedtestgen args int count if !isequal representative1 args r args count if !isequal representative2 args r args count ... if !isequal representativen args r args count assert count g fig.
.
simplified wrapper constructed for equivalence guided test generation.
table i preliminary results problem clusters incorrect testsmin.
tests addtoend partitioner sort addtoend .
a method that takes as input an integer and appends it to the end of a singly linked list.
this method is defined in a singly linked list class with member variables defined by the instructor where students need only to fill in the addtoend method body.
partitioner .
a method that takes as input an array of integers.
the method returns an index such that the element to this index s left right is strictly less greater than or equal to the element stored at the indexed location.
sort.
a method that takes as input an array of integers and returns the array sorted in the ascending order.
all of the student submissions are originally written in java.
we take the submissions classified as correct by the instructor test suite and translate them to c via the sharpen tool .
this translation is done to make the student submissions compatible with pex the used test generator2.
in addition we write factory methods to help pex create complex objects as inputs e.g.
addtoend s singly linked lists and isequal methods that help determine whether complex data structures are equivalent.
for addtoend there are totally submissions from which are marked correct and are used in our evaluation we omit submissions that cause translation failures.
for partitioner there are totally submissions from which are marked correct and analyzed.
for sort there are totally submissions from which are marked correct and analyzed.
b. preliminary results table i shows the results of applying our grasa approach on the evaluation subjects.
in two out of the three programming problems grasa detects incorrect submissions that are mistakenly classified by the existing instructor test suite as correct.
in particular for addtoend and partitioner grasa detects and incorrect submissions respectively.
grasa forms and 2we use pex because of its effectiveness in previous related work .
however alternative structural test generators could also be used.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
clusters for these incorrect submissions of addtoend and partitioner respectively.
in table i tests denotes the total number of incorrectness exposing ie tests produced across all clusters one ie test per cluster when the same test is generated for multiple clusters we count it only once .
min.
tests denotes the number of minimal ie tests produced by grasa.
the results show that for both addtoend and partitioner tests as is reduced to min.
tests as .
we conduct additional experimentation to confirm that ie tests are indeed the minimal tests for exposing the incorrect submissions.
an example ie test produced by grasa to augment addtoend s instructor test suite appends an integer to the end of a list with an initial size of .
in the instructor test suite before augmentation instructor constructed lists used for testing are randomly generated with constrained size limits between and .
however randomly generating a list of size is not guaranteed.
of the grasa identified incorrect submissions exhibit undesirable behavior in this corner case.
note that because the instructor test suites including random test generation constructed by the instructor for the three programming problems are of quite high quality already we expect the extent of benefits brought by grasa to be much higher for general cases.
iv .
r elated work existing work on test suite augmentation focuses on generating additional tests that cover the typically small changes from one version of a program to its next version.
however the existing work does not address the case focused by our approach where a test suite can be used to assess the correctness of multiple implementations with respect to the same specification e.g.
student submissions and reference solution.
in particular the existing work often cannot handle changes across these multiple implementations given that these changes are typically much more substantial than those changes across nearby versions of a program.
due to rapid growth in enrollment of cs courses various approaches help instructors understand a large number of student submissions and help enable other analyses such as automated repair and feedback generation.
for example gulwani et al.
cluster correct programs based on their runtime control flow and variable value equivalence throughout program execution in order to generate repairs for incorrect programs.
head et al.
cluster programs based on learned code transformations for representing a fix.
in order to learn a transformation their approach requires the existence of a pair of incorrect and correct programs being sufficiently similar whereas our approach does not have this requirement.
singh et al.
formulate feedback generation as a synthesis problem our future work plans to use synthesis based approaches to learn preconditions as feedback for summarizing incorrect behaviors of incorrect student submissions.
v. c onclusion to address the insufficiency of an instructor test suite for grading student submissions in this paper we have presentedthe grasa gra ding based test suite augmentation approach that first detects and clusters incorrect submissions and then generates a minimal set of additional incorrectness exposing tests to augment the existing test suite.
our preliminary evaluation results on three programming problems demonstrate the effectiveness of grasa.
in our approach checking behavioral equivalence is approximated with a structural test generator whose checking is incomplete by nature.
our preliminary results show that our test generation can still find additional incorrect submissions not detected by the existing instructor test suite which is already of quite high quality with random test generation.
in addition the provided reference solution can be incomplete specification of the problem s desired behaviors.
if the reference solution captures only one of multiple possible desired behaviors then our approach would misclassify correct submissions as incorrect but such misclassification cases can often be caught by either students or instructors.
in addition our approach can be easily extended to support multiple reference solutions with different desired behaviors a submission is determined as correct when its behavior is equivalent to one of the multiple reference solutions.
acknowledgment we thank jacob laurel wing lam august shi and nicholas strole for their feedback and vijayendra japtap for his help on our earlier work.
this work was supported in part by nsf under grant no.
cns ccf the nsf of china under grant no.
a grant from futurewei and the gem fellowship.