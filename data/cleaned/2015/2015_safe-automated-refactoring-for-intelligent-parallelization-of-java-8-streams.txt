safe automated refactoring for intelligent parallelization of java streams raffi khatchadourian yiming tang mehdi bagherzadeh syed ahmed cuny hunter college cuny graduate center oakland university email raffi.khatchadourian ytang3 hunter gradcenter .cuny.edu mbagherzadeh sfahmed oakland.edu abstract streaming apis are becoming more pervasive in mainstream object oriented programming languages.
for example the stream api introduced in java allows forfunctional like mapreduce style operations in processing bothfinite and infinite data structures.
however using this apiefficiently involves subtle considerations like determining whenit is best for stream operations to run in parallel when runningoperations in parallel can be less efficient and when it is safe torun in parallel due to possible lambda expression side effects.
inthis paper we present an automated refactoring approach thatassists developers in writing efficient stream code in a semantics preserving fashion.
the approach based on a novel data orderingand typestate analysis consists of preconditions for automaticallydetermining when it is safe and possibly advantageous to convertsequential streams to parallel and unorder or de parallelizealready parallel streams.
the approach was implemented as aplug in to the eclipse ide uses the w ala and safe analysisframeworks and was evaluated on java projects consisting of 642k lines of code.
we found that of candidate streams .
were refactorable and an average speedup of .
on performance tests was observed.
the results indicate that the ap proach is useful in optimizing stream code to their full potential.
index t erms refactoring static analysis automatic parallelization typestate analysis java streams i. i ntroduction streaming apis are widely available in today s mainstream object oriented programming languages and platforms including scala javascript c java and android .
these apis incorporate mapreduce like operations on native data structures such as collections.
below is a sum of even squares example in java where map accepts a expression unit of computation and results in the list element s square.
the expression argument to filter evaluates to true iff the element is even list.stream .filter x x .map x x x .sum mapreduce which helps reduce the complexity of writing parallel programs by facilitating big data processing onmultiple nodes using succinct functional like programmingconstructs is a popular programming paradigm for writing a specific class of parallel programs.
it makes writing parallel code easier as writing such code can be difficult due to possible data races thread interference and contention .
for instance the code above can execute in parallel simply by replacing stream with parallelstream .
mapreduce though traditionally operates in a highlydistributed environment with no concept of shared memory while java stream processing operates in a single node under multiple threads or cores in a shared memory space.
in the lattercase because the data structures for which the mapreduce like operations execute are on the local machine problems may arise from the close intimacy between shared memory and the operations being performed.
developers thus must manually determine whether running stream code in parallel results in an efficient yet interference free program and ensure that no operations on different threads interleave .
despite the benefits using streams efficiently requires many subtle considerations.
for example it is often not straight forward if running a particular operation in parallel is more optimal than running it sequentially due to potential side effects of expressions buffering etc.
other times using stateful expressions i.e.
those whose results depend on any state that may change during execution can undermine performance due to possible thread contention.
in fact 4k stream questions have been posted on stack overflow of which remain unanswered suggesting that there is developer confusion surrounding this topic.
in general these kinds of errors can lead to programs that undermine concurrency underperform and are inefficient.moreover these problems may not be immediately evidentto developers and may require complex interproceduralanalysis a thorough understanding of the intricacies of a particular stream implementation and knowledge of situational api replacements.
manual analysis and or refactoring semantics preserving source to source transformation to achieve optimal results can be overwhelming and error andomission prone.
this problem is exacerbated by the factthat total candidate streams 1across projects with a project maximum2were found during our experiments iv a number that can increase over time as streams rise in popularity.
in fact mazinanian et al.
found an increasing trend in the adoption of expressions an essential part of using the java stream api with the number of expressions being introduced increasing by two fold between and2016.
and a recent github search by the authors yielded 350k classes importing the java.util.stream package.
the operations issued per stream may be many we found an average of .
operations per stream.
permutating through operation combinations and subsequently assessing performance if such dedicated tests even exist can be burdensome.
manual 1the number of candidate streams is affected by several analysis parameters which involve performance trade offs as described in iv b and iv c. 2a stream instance approximation is defined as an invocation to a stream api returning a stream object e.g.
stream parallelstream .
ieee acm 41st international conference on software engineering icse .
ieee authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
interprocedural and type hierarchy analysis may be needed to discover ways to use streams in a particular context optimally.
recently attention has been given to retrofitting concurrency on to existing sequential imperative programs translating imperative code to mapreduce verifying and validating correctness of mapreduce style programs and improving performance of the underlying mapreduce framework implementation .
little attention though has been paid to mainstream languages utilizing functional style apis that facilitate mapreduce style operations over native data structures like collections.
furthermore improving imperativestyle mapreduce code that has either been handwritten or produced by one the approaches above has to the best of our knowledge not been thoroughly considered.
tang et al.
only briefly present preliminary progress towards this end while khatchadourian et al.
discuss engineering aspects.
the problem may also be handled by compilers or run times however refactoring has several benefits including giving developers more control over where the optimizations take place and making parallel processing explicit.
refactorings can also be issued multiple times e.g.
prior to major releases and unlike static checkers refactorings transform source code a task that can be otherwise error prone and involve nuances.
we propose a fully automated semantics preserving refactoring approach that transforms java stream code for improved performance.
the approach is based on a novel data ordering and typestate analysis.
the ordering analysis involves inferring when maintaining the order of a data sequence in a particular expression is necessary for semantics preservation.
typestate analysis is a program analysis that augments the type system with state and has been traditionally used for preventing resource errors .
here it is used to identify stream usages that can benefit from intelligent parallelization resulting in more efficient semantically equivalent code.
typestate was chosen to track state changes of streams that may be aliased and to determine the final state following a terminal reduction operation.
non terminal intermediate operations may return the receiver stream in which case traditional typestate applies.
however we augmented typestate to apply when a new stream is returned in such situations cf.
iii b and iii d .
our approach interprocedurally analyzes relationships between types.
it also discovers possible side effects in arbitrarily complex expressions to safely transform streams to either execute sequentially or in parallel depending on which refactoring preconditions which we define pass.
furthermore to the best of our knowledge it is the first automated refactoring technique to integrate typestate.
the refactoring approach was implemented as an open source eclipse plug in that integrates analyses from wala and safe .
the evaluation involved studying the effects of our plug in on java projects of varying size and domain with a total of 642k lines of code.
our study indicates that i given its interprocedural nature the fully automated analysis cost is reasonable with an average running time of .
minutes per candidate stream and .
seconds per thousand lines of code ii despite their ease of use parallel streams are not commonly manually used in modern java software motivating an automated approach and iii the proposed approach is useful in refactoring stream code for greater efficiency despite its conservative nature.
this work makes the following contributions precondition formulation.
we present a novel refactoring approach for maximizing the efficiency of their java stream code by automatically determining when it is safe and possibly advantageous to execute streams in parallel when running streams in parallel can be counterproductive and when ordering is unnecessarily depriving streams of optimal performance.
our approach refactors streams for greater parallelism while maintaining original semantics.
generalized typestate analysis.
streams necessitate several generalizations of typestate analysis including determining object state at arbitrary points and support for immutable object call chains.
reflection is also combined with hybrid typestate analysis to identify initial states.
implementation and experimental evaluation.
to ensure real world applicability the approach was implemented as an eclipse plug in built on wala and safe and was used to study java programs that use streams.
our technique successfully refactored .
of candidate streams and we observed an average speedup of .
during performance testing.
the experimentation also gives insights into how streams are used in real world applications which can motivate future language and or api design.
these results advance the state of the art in automated tool support for stream code to perform to their full potential.
ii.
m otiv ation background and problem insight we present a running example that highlights some of the challenges associated with analyzing and refactoring streams for greater parallelism and increased efficiency.
lst.
portrays code that uses the java stream api to process collections ofwidget s with weight s class not shown .
lst.
1a is the original version while lst.
1b is the improved but semantically equivalent version after our refactoring.
in lst.
1a acollection ofwidget s is declared line that does not maintain element ordering as hashset does not support it .
note that ordering is dependent on the run time type.
astream a view representing element sequences supporting mapreduce style operations of unorderedwidgets is created on line .
it is sequential meaning its operations will execute serially.
streams may also have an encounter order which can be dependent on the stream s source.
in this case it will be unordered since hashset s are unordered.
on line the stream is sorted by the corresponding intermediate operation the result of which is a possibly new stream with the encounter order rearranged accordingly.
widget getweight is a method reference denoting the method that should be used for the comparison.
intermediate operations are deferred until a terminal operation is executed likecollect line .
collect is a special kind of mutable reduction that aggregates results of prior intermediate operations into a given collector .
in this case it is one that yields a list .
the result is a widget list sorted by weight .
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
listing snippet of widget collection processing using java streams based on java.util.stream java se jdk .
a stream code snippet prior to refactoring.
1collection widget unorderedwidgets new hash set 2collection widget orderedwidgets new arraylist 4list widget sortedwidgets unorderedwidgets .stream .sorted comparator .comparing widget getweight .collect collectors .tolist collect weights over .
into a set in parallel.
set double heavywidgetweightset orderedwidgets .parallelstream .map widget getweight .filter w w .
.collect collectors .toset sequentially collect into a list skipping first .
list widget skippedwidgetlist ordered widgets .stream .skip .collect collectors.tolist collect the first green widgets into a list.
list widget firstgreenlist ordered widgets .stream .filter w w.getcolor color .green .unordered .limit .collect collectors .tolist collect distinct widget weights into a treeset.
set double distinctweightset orderedwidgets .stream .parallel .map widget getweight .distinct .collect collectors.tocollection treeset new collect distinct widget colors into a hashset.
set color distinctcolorset orderedwidgets .parallelstream .map widget getcolor .distinct .collect hash set new set add set addall b improved stream client code via refactoring.
1collection widget unorderedwidgets new hashset 2collection widget orderedwidgets new arraylist 4list widget sortedwidgets unorderedwidgets .stream parallelstream .sorted comparator .comparing widget getweight .collect collectors .tolist collect weights over .
into a set in parallel.
set double heavywidgetweightset orderedwidgets .parallelstream .map widget getweight .filter w w .
.collect collectors .toset sequentially collect into a list skipping first .
list widget skippedwidgetlist orderedwidgets .stream .skip .collect collectors .tolist collect the first green widgets into a list.
list widget firstgreenlist orderedwidgets .stream parallelstream .filter w w.getcolor color .green .unordered .limit .collect collectors .tolist collect distinct widget weights into a treeset.
set double distinctweightset orderedwidgets .stream .parallel .map widget getweight .distinct .collect collectors .tocollection treeset new collect distinct widget colors into a hashset.
set color distinctcolorset orderedwidgets .parallelstream .map widget getcolor .unordered .distinct .collect hashset new set add set addall it may be possible to increase performance by running this stream s pipeline i.e.
its sequence of operations in parallel.
lst.
1b line displays the corresponding refactoring with the stream pipeline execution in parallel removed code is struck through while the added code is underlined .
note however that had the stream been ordered running the pipeline in parallel may result in worse performance due to the multiple passes and or data buffering required by stateful intermediate operations sios like sorted .
because the stream is unordered the reduction can be done more efficiently as the framework can employ a divide and conquer strategy .
in contrast line instantiates an arraylist which maintains element ordering.
furthermore a parallel stream is derived from this collection line with each widget mapped to its weight each weighted filtered line and the results collect ed into a set.
unlike the previous example however no optimizations are available here as an sio is not included in the pipeline and as such the parallel computation does not incur the aforementioned possible performance degradation.
lines create a list of widget s gathered by sequentially skipping the first thousand from orderedwidgets .
like sorted skip is also an sio.
unlike the previous example though executing this pipeline in parallel could be counterproductive because as it is derived from an ordered collection the stream is ordered.
it may be possible to unorder the stream via unordered so that its pipeline would be more amenable to parallelization.
in this situation however unordering could alter semantics as the data is assembled into a structure maintaining ordering.
as such the stream remainssequential as element ordering must be preserved.
on lines the first five green widget so f orderedwidgets are sequentially collect ed into a list aslimit is an sio performing this computation in parallel could have adverse effects as the stream is ordered with the source being orderedwidgets .
yet on line the stream is unordered3before thelimit operation.
because the sio is applied to an unordered stream to improve performance the pipeline is refactored to parallel on line in lst.
1b.
although similar to the refactoring on line it demonstrates that stream ordering does not solely depend on its source.
a distinct widget weight set is created on lines .
unlike the previous example this collection already takes place inparallel .
note though that there is a possible performance degradation here as the sio distinct may require multiple passes the computation takes place in parallel andthe stream isordered .
keeping the parallel computation but unordering the stream may improve performance but we would need to determine whether so is safe which can be error prone if done manually especially on large and complex projects.
our insight is that by analyzing the type of the resulting reduction we may be able to determine if unordering a stream is safe.
in this case it is a mutable reduction i.e.
collect on line to a set of which subclasses that do not preserve ordering exist.
if we could determine that the resulting set is unordered unordering the stream would be safe since the collection operation would not preserve ordering.
the type of the resulting set returned here is determined 3the use of unordered is deliberate despite nondeterminism.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
table i convert sequential stream to parallel preconditions .
exe ord se sio rom transformation p1 seq unord f n a n a convert to para.
p2 seq ord ff n a convert to para.
p3 seq ord ft f unorder and convert to para.
by the passed collector in this case collectors.
tocollection treeset new the argument to which is a reference to the default constructor.
unfortunately since treeset s preserve ordering we must keep the stream ordered.
here to improve performance it may be advantageous to run this pipeline perhaps surprisingly sequentially line lst.
1b .
lines map in parallel each widget to its color filter those that are distinct and collect ing them into a set.
to demonstrate the variety of ways mutable reductions can occur a more direct form of collect is used rather than a collector and the collection is to a hashset which does notmaintain element ordering.
as such though the stream is originally ordered since the mutable reduction is to an unordered destination we can infer that the stream can be safely unordered to improve performance.
thus line in lst.
1b shows the inserted call to unordered immediately prior to distinct .
this allows distinct to work more efficiently under parallel computation .
manual analysis of stream client code can be complicated even as seen in this simplified example.
it necessitates a thorough understanding of the intricacies of the underlying computational model a problem which can be compounded in more extensive programs.
as streaming apis become more pervasive it would be extremely valuable to developers particularly those not previously familiar with functional programming if automation can assist them in writing efficient stream code.
iii.
o ptimization approach a. intelligent parallelization refactorings we propose two new refactorings i.e.
c onvert sequen tial stream to parallel and o ptimize parallel stream .
the first deals with determining if it is possibly advantageous performance wise based on type analysis and safe e.g.
no race conditions semantics alterations to transform a sequential stream to parallel.
the second deals with a stream that is already parallel and ascertains the steps transformations necessary to possibly improve its performance including unordering and converting the stream to sequential.
converting sequential streams to parallel table i portrays the preconditions for our proposed c onvert sequential stream to parallel refactoring.
it lists the conditions that must hold for the transformation to be both semantics preserving as well as possibly advantageous i.e.
resulting in a possible performance gain.
column exedenotes the stream s execution mode i.e.
whether upon the execution of a terminal operation its associated pipeline will execute sequentially or in parallel seq is sequential and para is parallel .
column orddenotes whether the stream is associated with an encounter order i.e.
whether elements of the stream must be visited in a particular order ord is ordered andtable ii optimize parallel stream preconditions .
exe ord sio rom transformation p4 para ord tf unorder.
p5 para ord tt convert to seq.
unord is unordered .
column serepresents whether any behavioral parameters expressions that will execute during the stream s pipeline have possible side effects.
column sio constitutes whether the pipeline has any stateful intermediate operations.
column rom represents whether the encounter order must be preserved by the result of the terminal reduction operation.
a tdenotes that the reduction result depends on the encounter order of a previous intermediate operation.
conversely an fsignifies that any ordering of the input operation to the reduction need not be preserved.
column transformation characterizes the transformation actions to take when the corresponding precondition passes note the conditions are mutually exclusive .
n a is either torf.
a stream passing p1 is one that is sequential unordered and has no side effects.
because this stream is already unordered whether or not its pipeline contains an sio is inconsequential.
since the stream is unordered any sios can run efficiently in parallel.
moreover preserving the ordering of the reduction is also inconsequential as no original ordering exists.
here it is both safe and possibly advantageous to run the stream pipeline in parallel.
the stream derived from unorderedwidgets on line lst.
is an example of a stream passing p1.
a stream passing p2 is also sequential and free of expressions containing side effects.
however such streams are ordered meaning that the refactoring only takes place if no sios exist.
p3 on the other hand will allow such a refactoring to occur i.e.
if an sio exists only if the ordering of the reduction s result is inconsequential i.e.
the reduction ordering need not be maintained.
as such the stream can be unordered immediately before the first sio as performed on line lst.
1b .
the stream created on line lst.
is an example of a stream failing this precondition.
optimizing parallel streams table ii depicts the preconditions for the o ptimize parallel stream refactoring.
here the stream in question is already parallel.
a stream passing either precondition is one that is ordered and whose pipeline contains an sio.
streams passing p4 are ones where the reduction does not need to preserve the stream s encounter order i.e.
rom isf.
an example is depicted on line lst.
.
under these circumstances the stream can be explicitly unordered immediately before the first sio as done on line of lst.
1b.
streams passing p5 on the other hand are ones that the reduction ordering does matter e.g.
the stream created on line .
to possibly improve performance such streams are transformed to sequential line lst.
1b .
b. identifying stream creation identifying where in the code streams are created is imperative for several reasons.
first streams are typically derived from a source e.g.
a collection and take on its characteristics e.g.
ordering .
this is used in tracking stream attributes across their authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
pipeline iii c .
second for streams passing preconditions the creation site serves a significant role in the transformation.
there are several ways to create streams including being derived from collection s being created from arrays e.g.
arrays.stream and via static factory methods e.g.
intstream.range .
streams may also be directly created via constructors but it is not typical of clients which are our focus.
we consider stream creation point approximations as any expression evaluating to a type implementing the java.util.stream.basestream interface which is the toplevel stream interface.
we exclude however streams emanating from intermediate operations i.e.
instance methods whose receiver and return types implement the stream interface as such methods are not likely to produce new streams but rather ones derived from the receiver but with different attributes.
c. tracking streams and their attributes we discuss our approach to tracking streams and their attributes i.e.
state using a series of labeled transition systems ltss .
the ltss are used in in the typestate analysis iii d .
execution mode definition .
the lts eis a tuple e es e e where es seq para is the set of states e is a set of labels ande is a set of labeled transitions.
the labels e corresponds to method calls that either create or transform the execution mode of streams.
we denote the initial stream phantom state as .
different stream creation methods may transition the newly created stream to one that is either sequential or parallel.
transitions stemming from the state represent stream creation methods iii b .
as an example the stream on line lst.
1a would transition from toseq while the stream at line would transition from seqtopara as a result of the corresponding call.
ordering whether a stream has an encounter order depends on the stream source run time type and the intermediate operations.
certain sources e.g.
list are intrinsically ordered whereas others e.g.
hashset are not.
some intermediate operations e.g.
sorted may impose an encounter order on an otherwise unordered stream and others may render an ordered stream unordered e.g.
unordered .
further some terminal operations may ignore encounter order e.g.
foreach while others e.g.
foreachorderer abide by it .
definition .
the lts ofor tracking stream ordering is the tuple o os o o whereos ord unord and other components are in line with definition .
for instance the stream on line lst.
1a would transition from tounord due to hashset.stream .
although the compile time type of unorderedwidgets iscollection line we use an interprocedural type inference algorithm explained next to approximate hashset .
the stream at line would transition from toord state as a result of orderedwidgets having the type arraylist line .
a approximating stream source types and characteristics the fact that stream ordering can depend on the run time type of its source necessitates that its type be approximated.
forthis we use an interprocedural type inference algorithm via points to analysis that computes the possible run time types of the receiver from which the stream is created.
once the type is obtained whether source types produce ordered or unordered streams is determined via reflection.
while details are in i v a briefly the type is reflectively instantiated and itsspliterator extracted.
then stream characteristics e.g.
ordering are queried .
this is enabled by the fact that collections and other types supporting streams do not typically change their ordering characteristics dynamically.
using reflection in this way amounts to a kind of hybrid typestate analysis where initial states are determined via dynamic analysis.
if reflection fails e.g.
an abstract type is inferred the default is to ordered and sequential.
this choice is safe considering that there is no net effect caused by our proposed transformations thus preserving semantics.
furthermore to prevent ambiguity in state transitions it is required that each inferred type have the same attributes.
d. tracking stream pipelines tracking stream pipelines is essential in determining satisfied preconditions.
pipelines can arbitrarily involve multiple methods and classes as well as be data dependent i.e.
spanning multiple branches .
in fact during our evaluation iv we found many real world examples that use streams interprocedurally.
our automated refactoring approach involves developing a variant of typestate analysis to track stream pipelines and determine stream state when a terminal operation is issued.
typestate analysis is a program analysis that augments the type system with state information and has been traditionally used for prevention of program errors such as those related to resource usage.
it works by assigning each variable an initial state.
then mutating method calls transition the object s state.
states are represented by a lattice and possible transitions are represented by ltss.
if each method call sequence on the receiver does not eventually transition the object back to the state the object may be left in a nonsensical state indicating the potential presence of a bug.
our typestate analysis makes use of a call graph which is created via a k cfa call graph construction algorithm making our analysis both object and context sensitive the context being the k length call string .
in other words it adds context so that method calls to an object creation site new operator can be distinguished from one another .
it is used here to consider client side invocations of api calls as object creations.
setting k would not suffice as the analysis would not consider the client contexts as stream creations.
as such at least for streams kmust be .
although kis flexible in our approach we use k 2as the default for streams and k elsewhere.
i v b discusses howkwas set during our experiments as well as a heuristic to help guide developers in choosing a sufficient k. we formulate a variant of typestate since operations like sorted return possibly new streams derived from the receiver stream with their attributes altered.
definition portrays the formalism capturing the concept of typestate analysis authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
used in the remainder of this section.
several generalizations are made to extract typestate at a particular program point.
definition typestate analysis .
define tstate lts is exp swhere lts is a labeled transition system isa stream instance expan expression and to be the possible states sofisatexpaccording to lts.
in definition exp an expression in the abstract syntax tree ast is used to expose the internal details of the analysis.
typically typestate is used to validate complete statement sequences.
regarding definition this would be analogous to exp corresponding to a node associated with the last statement of the program.
in our case we are interested in typestates at particular program points otherwise we may not be able to depict typestate at the execution of the terminal operation accurately.
as an example let isbe the stream on line lst.
1a and exp the expression collect at line .
then tstate o is collect .. ord .
traditional typestate analysis is used with mutating methods that alter object state.
the stream api though is written in an immutable style where each operation returns a stream reference that may refer to a new object.
a na ve approach may involve tracking the typestates of the returned