assessing the generalizability of code2vec token embeddings hong jin kang singapore management university hjkang.
phdis.smu.edu.sgtegawend e f. bissyand e university of luxembourg luxembourg tegawende.bissyande uni.ludavid lo singapore management university davidlo smu.edu.sg abstract many natural language processing nlp tasks such as sentiment analysis or syntactic parsing have benefited from the development of word embedding models.
in particular regardless of the training algorithms the learned embeddings have often been shown to be generalizable to different nlp tasks.
in contrast despite recent momentum on word embeddings for source code the literature lacks evidence of their generalizability beyond the example task they have been trained for.
in this experience paper we identify potential downstream tasks namely code comments generation code authorship identification and code clones detection that source code token embedding models can be applied to.
we empirically assess a recently proposed code token embedding model namely code2vec s token embeddings.
code2vec was trained on the task of predicting method names and while there is potential for using the vectors it learns on other tasks it has not been explored in literature.
therefore we fill this gap by focusing on its generalizability for the tasks we have identified.
eventually we show that source code token embeddings cannot be readily leveraged for the downstream tasks.
our experiments even show that our attempts to use them do not result in any improvements over less sophisticated methods.
we call for more research into effective and general use of code embeddings.
index t erms code embeddings distributed representations big code i. i ntroduction in recent years there have been many works proposing new techniques to construct representations of text.
the representation of a word by embedding it onto a vector space is known as word embeddings .
embedding techniques such as word2vec output vectors of real numbers which are successfully leveraged in a variety of natural language processing nlp tasks.
indeed embedding models attempt to represent words that are semantically similar as vectors which are close in the vector space.
while the nlp literature provides several methods to train word embeddings a number of applications have successfully demonstrated that most word embedding models generalize to various nlp tasks beyond the ones the embeddings have been initially trained on.
for example word embeddings which are often trained over predicting the next word in a sentence given its previous words have been used for many downstream tasks such as sentiment analysis word sense disambiguation named entity recognition and part of speech tagging .
besides embeddings for natural language words various embedding models have been proposed for object representations in other domains including graphs knowledge bases or even source code.
for example in recent years inspired by the advances in word embeddings many researchers have used embedding models for software engineering tasks.
on the one hand the naturalness hypothesis which suggests that like natural language software is also likely to be statistically repetitive and predictable has encouraged the use of natural language processing techniques on source code.
the increase of publicly available source code such as open source projects data on github facilitates research on big code analysis.
in this context several code embeddings approaches have been proposed where source code tokens are treated similarly to text.
apart from the direct application of word embedding techniques to source code other researchers have proposed specialized methods for source code.
for example there have been attempts to include more structural information of the program.
among recent advances code2vec which stands as a state of the art traverses paths in the abstract syntax tree ast to train embeddings for predicting method names.
the authors study shows that accounting for such structural information improves the performance in method name predictions.
many research directions in the software engineering domain have proposed new methods of training code embeddings.
however they are often only evaluated on the single task that they were trained for .
in contrast to the plentiful evidence that word embeddings are useful in downstream tasks there is little evidence to suggest that the code embeddings can be useful in a variety of software engineering tasks.
given the promise of code embeddings our work is motivated by this need to fill the gap in confirming the generalizability of code embedding models.
treating code2vec as representative of code embeddings our study investigates whether it can be successfully used in a variety of software engineering tasks beyond predicting method names.
in this paper we assess the token embeddings proposed by code2vec in terms of providing appropriate representations of source code in several different software engineering downstream tasks i.e.
tasks in which the learned code embeddings may be helpful on.
these tasks are not directly related to its original training task of predicting method names.
concretely we propose to use source code token embeddings to enhance existing models for tasks of code comment generation code authorship identification and code clones detection.
then we 34th ieee acm international conference on automated software engineering ase .
ieee authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
evaluate the performance of these models against baseline models originally designed for the considered tasks.
we make a replication package of our work available.1this paper makes the following contributions we investigate the generalizability of tokens embeddings learned by code2vec for downstream software engineering tasks.
to the best of our knowledge this is the first effort in this direction in the literature.
we experimentally demonstrate that code2vec s token embeddings may not be generalizable they do not always contribute to a significant increase in the performance of models for each of the software engineering tasks.
we provide a comprehensive discussion on the generalizability of code embeddings and motivate the need for further research on novel embedding models for source code that can generalize to various downstream tasks.
the remainder of this paper is organized as follows.
in section ii we provide details for the context of this study.
in section iii we introduce the three software engineering downstream tasks that we have identified for evaluating code embeddings evaluate code2vec on the tasks and discuss the results.
in section iv we discuss the threats to validity of our work.
in section v we present related work.
finally in section vi we conclude the paper with a call for further research.
ii.
p reliminaries our study aims to answer a single research question are embeddings of source code tokens generalizable for use in tasks that they are not trained for?
the main components of our study are as follows code embedding model.
structural information from asts has been widely leveraged for building models in the literature .
in particular it has been used to train representations of source code for predicting method names a common task in software engineering literature .
as code2vec is located in the intersection of these two trends in code representation research we select it as a representative state of the art among embedding models.
code2vec embeds entire code snippets into a single vector during training.
however our work focuses on the token embeddings that result from its training due to its similar granularity to word tokens used in word embeddings and its broader vocabulary which we believe allows it to be more generalizable.
word embedding model.
aside from code2vec being specialized for source code tokens we also consider generic nlp word embeddings to build a comparison baseline.
to that end we consider glov e as a representative word embedding technique which we train on a similar dataset as code2vec by considering source code as natural language text.
tasks.
we identify three downstream tasks of code comment generation code authorship identification and code clones detection.
for each task we select an existing approach that uses source code tokens as part of its input.
we select models from recent work or use well known models.
for code comment generation and code authorship identification we use recent work by hu et al.
and abuhamad et al.
respectively.
for code clone detection we use the well documented baseline model sourcerercc .
we try to augment these models using embeddings of source code tokens.
finally we compare the performance of the models using embeddings against simpler models as a baseline.
in the same vein as the suggestions provided by fu and menzies in their comparative study of machines learning approaches in software engineering the first baseline we use is the simpler basic model without the use of code embeddings.
secondly we compare our code2vecaugmented model against a model that is augmented in the same way but this time using the glov e vectors that are trained over source code tokens.
a. code2v ec the code2vec deep representation learning technique was initially proven effective through a demonstration of training code embeddings for the following prediction task a code snippet was given as input and a tag was predicted as output.
code2vec was mainly used for method name prediction where each input is a method body and the method name is used as the associated output tag.
structural information from the ast notably paths between ast terminals is extracted and leveraged during training each code snippet is represented by a bag of path contexts.
an attention mechanism is used to learn the importance of each path context to the output tag.
a single path context comprises a tuple of the terminal nodes and the path between them.
from the path contexts a neural network model is trained to predict the code snippet s method name.
the following example of a path context for the expression x is given by alon et al.
angbracketleftx nameexpr assignexpr integerliteralexpr angbracketright code2vec produces sets of vectors.
from its output layer a set of vectors for method names can be exported.
from its input layer a set of vectors for token identifiers can be exported.
our work focuses on the token vectors due to its more precise granularity which we believe will make it more generalizable and applicable to other tasks.
for our study we use code2vec token vectors exported from the trainable model downloaded from the code2vec repository.
these vectors are dimensions wide with a vocabulary size of words.
b. glov e to evaluate code2vec we need a baseline set of vectors that is simpler and easier to train.
to this end we treat source authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
code as text and we use the glov e algorithm that is used to learn word embeddings to train code embeddings.
due to the naturalness hypothesis embedding models designed for natural language may be effective when directly applied to source code.
unlike many word embedding algorithms glov e is an unsupervised algorithm using token token co occurrence statistics.
we trained glov e vectors that are dimensions to have the same dimensionality as the code2vec token embeddings.
we adjusted the parameters of glov e to have a similar number of tokens in its vocabulary as code2vec.
thus we set the minimum number of occurrences to be .
other parameters of glov e are set to the default values for example we trained glov e for iterations with a window size of .
the dataset used to trained glov e is the java large dataset provided by the authors of code2vec.2it includes the most starred github java projects consisting of about million methods and amounts to 37gb of data.
eventually the glov e vectors are dimensions wide with a vocabulary size of words.
the original dataset used to trained code2vec is only available in a processed form and is not appropriate for training glov e embeddings.
however the javalarge dataset is comparable to the original dataset in terms of size and its source.
as such we do not expect this difference to be a threat to validity.
iii.
e v alua tion on downstream tasks we consider in this study three downstream software engineering tasks targeting different properties of source code that may be encoded in embeddings code comment generation code authorship identification and code clones detection.
we now briefly describe the objective of each task the dataset that we use as well as the evaluation procedure.
to evaluate code embeddings we try to augment existing models with the code embeddings and observe if the resulting model leads to an improved performance.
for each task we select a model from recent papers.
whenever it is not obvious how to augment an existing model with embeddings we propose a new approach to incorporate embeddings into it.
we focus on using techniques that are token based to make it simple to augment the model with code embeddings.
the techniques we use in these tasks also vary.
two out of three tasks use a neural network based approach while the last task utilizes vector space calculations to compare the similarity of two vectors.
in this study we do not focus on the overall effectiveness of the techniques.
instead we evaluate if the use of code embeddings can improve the performance of these techniques.
for each task we select datasets and use experiment settings similar to what was reported in literature.
a. code comment generation our first task is code comment generation.
as we focus our work at the granularity of methods this task involves the generation of method level comment from the body of a method .
the generated method comment should summarize the functionality provided by the method in the form of a descriptive high level natural language sentence.
the task has implications for software maintenance and program comprehension.
techniques developed for this task can produce a wide range of benefits for developers including helping in software reuse re documentation and concept location .
several recent works have used neural networks to synthesize natural language from source code .
approach for this task there have been several techniques using a deep learning approach.
we use the latest approach proposed by hu et al.
.
in their approach they treated the problem as a machine translation task.
their approach incorporates and retains structural information from the ast when preprocessing the data from code snippets representing method bodies into sequences of tokens representing the ast nodes.
a recurrent neural network based seq2seq language model is used to translate these sequences to natural language code comments.
we selected this approach since it uses a neural network approach and uses an embedding layer where our code embeddings can be used.
in addition their model gave state of the art results.
thus we follow the approach described by hu et al.
similar to the preprocessing done by hu et al.
we took only the first sentence of the javadoc method comment as this first sentence is usually the description of the functionality provided by a method based on javadoc convention.
like hu et al.
we filtered out simple cases from the dataset.
we omitted a pair of code snippet and comment if the comment is empty or just contain a single word additionally getters setters constructors and test methods are omitted.
we show a sample input for this task taken from table in the work by hu et al.
in listing .
for this example the ground truth output will be the first in this case the only sentence of the javadoc comment summarizing the method.
listing .
example of a code snippet convert bitmap to byte array.
public static byte bitmaptobyte bitmap b bytearrayoutputstrea mo n e w bytearrayoutputstream b.compress bitmap.compressformat.png o return o.tobytearray the metric bleu is used to measure the quality of generated comments.
this is commonly used to evaluate the performance of machine translation of natural language and measures how closely the translation is to a human translation.
bleu takes the generated translation and reference translations as input and outputs a percentage value between and with scores closer to indicating higher quality.
it is as computed as follows.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
bleu bp exp parenleftbig summationtextn n nlog pn parenrightbig bp braceleftbigg1 ifc r e r c ifc r pnis the ratio of length n subsequences that are both in the candidate and reference translation.
nis the maximum number of n grams.
bp is the brevity penalty.
cis the length of the candidate translation generated while ris the length of the reference translation.
the bleu metric has been shown to correlate well with human perception of the quality of translations .
in software engineering literature this has been used for the evaluation of several tasks including comment generation.
there are a few variants of bleu depending on the value of n. in this task we use bleu i.e.
n since it was used by hu et al.
to evaluate the quality of the generated comment.
bleu is a measure of precision of grams.
to accurately summarize a method using high level natural language a technique will need to infer semantic properties of the source code.
thus this task may be sensitive to the ability of code embeddings to encode semantic information.
preprocessing we used the dataset that was collected by hu et al.
which involves java projects from github.
then we followed the same procedure as hu et al.
to convert the ast of each method body into a sequence of tokens.
a highlevel overview of the procedure to preprocess the dataset is given in figure .
the eclipse jdt parser was used to construct the ast and we traversed the tree following the structure based traversal sbt algorithm described by hu et al.
this preserves information about the tree structure of the ast in the sequence and allows the reconstruction of the ast tree from the sequence of tokens.
tokens in the sequence consist of the ast node type and the value of the node either a literal or identifier name .
for example for a local variable x its representation in the sequence will be simplename x .
for a method invocation of a method tolowercase this will be represented as follows methodinvocation simplename tolowercase simplename tolowercase methodinvocation in machine translation for natural language the vocabulary is often restricted to the most common words.
words out of the vocabulary are marked as unk .
similarly we limited the vocabulary of both code tokens and comments to the most common tokens.
for code tokens outside of the vocabulary we convert them to to the ast node type.
concretely this means that rare identifier names will not be represented in the dataset.
for example a variable veryrareandlongname will be converted into the token simplename while a common variable name such as xwill be converted as simplename x .
the rationale for this was given by hu et al.
this representation of out ofvocabulary tokens mitigate the problem caused by the factsource code ast code sequencemethod comment seq2seq model fig.
.
preprocessing data for comment generation that the vocabulary of source code tokens is much greater than natural language.
rather than losing all information when we remove rare words from the dataset some structural information is retained.
we preprocessed the vocabulary in the embeddings similarly by prefixing ast node types to each word.
next for any word found in the training data that is not contained in the code embeddings we expanded the vocabulary of the embeddings to include it and initialize it with a random vector.
we found that there are less than such tokens in the dataset.
this indicates that the step of normalizing rare identifiers into their ast node types is effective in minimizing the number of out of vocabulary tokens seen during training of the machine translator.
for the example about bitmaptobyte in listing the following sequence will be generated for the statement return o.tobytearray .
we do not show the sequence for the entire method due to space constraints.
returnstatement methodinvocation simplename o simplename o simplename tobytearray simplename tobytearray methodinvocation returnstatement training next we trained a recurrent neural network based seq2seq language model using opennmt .
the model consists of an encoder decoder network.
on both encoder and decoder we use a long short term memory lstm layers with hidden units in each layer.
we set the learning rate to .
the dropout to .
and we train it for epochs.
in total there are over methods in the training data and we limit the validation and test data to methods.
the model consists of an embedding layer.
when the code2vec and glov e embeddings are not used randomly initialized vectors are used instead similar to the work in hu et al.
there are settings that we use for the experiments on this task.
as the tokens from code2vec are all lower cased we lower cased the identifiers from the ast trees we extracted and also created a version of the glov e vectors with its tokens lowercased.
for a more comprehensive evaluation we trained a new set of code2vec embeddings on the java large dataset described above.
in this set of embeddings the words are not lowercased.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
table i quality of comments genera ted with sbt preprocessing preprocessing embedding model bleu lowercased glov e .
lowercased code2vec .
lowercased no pretrained embeddings .
non lowercased glov e .
non lowercased code2vec .
non lowercased no pretrained embeddings .
table ii quality of comments genera ted without sbt preprocessing preprocessing embedding model bleu lowercased glov e .
lowercased code2vec .
lowercased no pretrained embeddings .
non lowercased glov e .
non lowercased code2vec .
non lowercased no pretrained embeddings .
results we report results in table i. as the sbt traversal adds structural information to the model we wish to investigate if not so will affect the performance of the model.
thus we present the results of running a seq2seq model without performing proprocessing with the sbt traversal.
in this case without the handling of rare tokens in the source code there are over tokens that are unrepresented in the code2vec vectors.
the results of not using the ast node information in comment generation are given in table ii findings based on the results it appears that the use of pretrained embeddings do not improve the sequence to sequence model.
the best performing configuration does not use either code2vec or glov e. however code2vec token vectors outperforms glov e vectors in each setting indicating that structural information may be valuable during the training of code embeddings.
these results suggest that this approach of generating code comment cannot utilize any semantic information encoded in either the glov e or code2vec vectors to boost performance.
b. code authorship identification our second task is to identify the authors of short programs.
while identifying authors of natural language documents have been studied extensively there are fewer works for so on source code.
this task has many implications for privacy and security concerns.
for example techniques on this task may be used to violate the privacy of programmers.
they may be used to de anonymize programmers who wish to hide their identities such as the creator of bitcoin.
other uses of such techniques include copyright infringement or plagiarism detection.
the process of identifying the author of a code fragment may also be useful for identifying the authors of malware and other malicious programs.to identify authors successfully approaches must be able to distinguish between the coding styles of programmers in their code.
techniques used in this task leverage features that express the programming style of programmers such as layout and lexical features .
previous works have found that the use of machine learning using tf idf features covering unigrams bigrams and trigrams can be used to identify programmers at high accuracy .
dataset as we did not manage to find any of the datasets used in prior work we follow the same procedure described by abuhamad et al.
to build a similar dataset.
this dataset is collected from program submissions to the google code jam.3the google code jam is a programming competition organized by google over several years.
participants may choose from several programming languages and have to solve a small number of problems within a short time period.
for any problem a participant may make multiple submissions.
naturally in this setting a single program only has one author.
we obtain programs written in java from authors participating in google code jam and train a model over the dataset.
in total there are programs in our dataset.
on average there are lines in each java program although the number of lines varies from to over lines.
existing works on code authorship evaluate their approaches using accuracy.
the dataset is constructed such that each author has the same number of programs in it.
thus as a classification task the classes are balanced and accuracy is a sufficient evaluation metric.
while the previous task of code comment generation evaluates techniques for capturing semantic properties of code we select this task for evaluation as it requires techniques to encode features related to syntactic style.
the ability of code embeddings to improve basic models on this task may indicate that it is able to distinguish between syntactic styles of different authors.
approach inspired by the work of abuhamad et al.
we propose a similar neural network.
as baseline we compare our approach against a model using tf idf features which was shown to be effective by abuhamad et al.
.
this network is comprised of hidden fully connected layers with nodes.
we use dropout for regularization and set it to .
.
we use the top tf idf features determined by feature selection using the anov a f value between each feature and the authors.
while the work of abuhamad et al.
used a random forest classifier based on the intermediate outputs of their neural network we were not able to replicate good results without our own modifications on a neural network based on the architecture they described.
as such we experimented with a neural network with some modifications that allowed it to produce comparably accurate predictions.
as our goal was to evaluate the code embeddings and not to have a state of the art system we did not use the second step authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
h1 t h2 h3 ... hn lstm 1x1 x2 x3 ... xnh1 h2 h3 ... hn lstm 2h1 t h2 t h3 t ... hn t fully connectedy1 y2 ... yn fig.
.
neural network for code authorship identification of passing the neural network results through a random forest classifier once we achieved good performance on our model.
while our objective is to evaluate code embeddings we were not able to successfully replace the tf idf features with them.
we attempted to use the average of the code vectors in the program and replace each tf idf feature with one dimension of the averaged code vectors.
this will result in features each corresponding to one dimension of the code vectors .
however we find that this results in poor performance.
further tuning of the model s hyperparameters did not help to improve its performance.
as there are tf idf features and only dimensions in our code vectors the number of input features decreased from to features.
hence it may be possible that the poor performance can be attributed to the decrease in the number of features.
we tried to train a new set of code2vec vectors of dimensions.
however this did not improve the performance of the model.
thus to further evaluate the potential of code embeddings on this task we used another neural network using lstm layers.
an lstm neural network provides the advantage of allowing variable length input hence we can input the entire code snippet into our model.
this neural network comprises of hidden lstm layers followed by a fully connected layer.
we illustrate the neural network in figure .
we limited our study to programs written in java the same language that code2vec and our glov e vectors were trained on.
for the lstm neural network we use both pretrained embeddings as well as randomly initialized embeddings.
we present the accuracy as a number between to with indicating a perfect accuracy.
for each model we train to epochs.
results from table iii we see that initializing the lstm neural network using both code2vec and glov e embeddings underperforms a randomly initialized embedding layer.
fur table iii accuracy for identifica tion of code authorship setting accuracy lstm code2vec lstm glov e lstm randomly initialized fully connected layers tf idf thermore the use of the lstm neural network using code embeddings underperformed a fully connected neural network that used tf idf features.
when using the code embeddings with the neural network with only fully connected layers we get accuracies of near .
findings comparing code2vec vectors and glov e vectors the glov e vectors obtained a higher accuracy than the code2vec vectors.
this implies that glov e embeddings may encode syntactic relationships better than the code2vec token embeddings.
however both glov e and code2vec token embeddings were outperformed by a randomly initialized set of embeddings.
this suggests that code2vec token embeddings do not generalize to the task of code authorship identification.
finally the model with the tf idf features is the best performing model in our experiments.
the poor performance of using code2vec token embeddings suggests that they are unable to distinguish between the syntactic differences of code authors as well as tf idf features.
c. detecting code clones finally our last task is to detect code clones.
code clones detection is the task of determining if a pair of code fragments are similar to each other.
this task has received much attention in the literature.
detecting code clones has numerous implications for software development and maintenance.
for example code clones can potentially increase the cost of maintenance complicating the design of software and make it difficult to introduce minor changes in the long run .
code clones are also likely to cause bugs to be propagated through copy paste behaviour in a software system .
dataset we use datasets for this task.
firstly we use the standard bigclonebench which is a benchmark of known clones in the ijadataset .
the ijadataset is a large repository of over open source java projects with over million source files.
in bigclonebench a code fragment is a single method and there are over million validated code clones in the dataset.
as only a subset of code fragment pairs in the entire ijadataset is validated the bigclonebench benchmark reports only the estimated recall of a model but not its precision.
as such we use a second dataset ojclone .
ojclone is a dataset of programming problems with the student submissions to each problem.
each programming problem has submissions.
for detecting code clones two submissions to the same problem are considered as code clones.
in total there are code fragments in this dataset.
between each pair of code fragments we can determine authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
table iv recall on bigclone bench setting type type strong type moderately type weak type type code2vec .
.
.
.
.
glov e .
.
.
.
.
sourcerercc .
.
.
.
.
whether a pair is code clones based on whether or not they are submitted to the same programming problem.
as such we can compute both recall and precision on this dataset.
researchers have classified code clones into types based on the level of syntactic similarity.
pairs of type clones are syntactically the same while pairs of type clones have no syntactic similarity but implements the same functionality.
while bigclonebench classifies each code clone from type1 to type there is no classification of the code clones into their types in the ojclone dataset although previous work have considered them to be type and above .
for type and type clones approaches that only use syntactic information is sufficient for achieving high precision and recall but for type and type clones which are syntactically different approaches need to consider the semantics of the program fragment.
there has been documented difficulties in detecting type and type clones at high precision and recall .
success at detecting code clones of type and type2 indicates that syntactic information is encoded within an approach while successfully detecting type and type code clones may indicate that semantic information can be encoded.
thus this task measures both the ability of code embeddings to capture syntactic and semantic information at the same time.
approach technique wise we used sourcerercc a token based model that gives near state of the art performance for type to type clones as basis for our work.
sourcerercc compares the tokens contained in pairs of code fragments.
to do so efficiently sourcerercc implements a sophisticated algorithm using several properties and heuristics they identified to reduce the number of comparisons to perform.
however the main criterion to determine if two code fragments are code clones is based on the number of tokens that are present in both code fragments.
given code fragments bxandby to determine if they are code clones it counts the number of tokens that overlap in both code fragments computing its overlap similarity and compare it against a configurable threshold to identify if the fragments are code clones.
the measure of overlap o bx by is computed as follows o bx by bx by to adapt sourcerercc to use vectors of source code tokens we changed the criteria to determine if a pair of code fragments are code clones.
instead of a count based measure of theoverlap between tokens our criteria is based on the cosine similarity of the average of the token vectors of the code fragments.
prior work has shown that averaging vectors for both natural language and source code can be used to represent larger fragments of tokens .
thus in our adaptation of sourcerercc for two code fragments bxandby to be considered as code clones they must share at least one token and the cosine similarity between them should exceed a threshold in this work we use a default value of .
.
this requirement of sharing at least one token is made for scalability reasons.
without this additional criteria all pairs of code fragments need to be compared which will be prohibitively large for our experiments.
for tokens in the code fragments that not in the embeddings vocabulary we use the zero vector.
the cosine similarity of two code fragments is computed based on averaging all the vectors of tokens contained in bxand by.
after averaging the token vectors we have xandy the average of token vectors in the two code snippets that are vectors in an n dimensional space.
let xirefer to the ithdimensional value of the vector x. then the cosine similarity is computed as follows summationtextn i 1xi yi summationtextn i 1x2 i summationtextn i 1y2 i results as described earlier we evaluated our adaptations to sourcerercc on two datasets bigclonebench and ojclone.
in our experiments on bigclonebench we only consider clones that are greater than lines and tokens.
this is the standard configuration for measuring recall .
as described earlier bigclonebench does not provide a process for evaluating precision.
table iv shows the recall of our approach on each clone type.
for ease of interpretation we provide the definition of the classification of the clone types that are widely used in literature type identical code fragments differing by whitespace comments type identical code fragments differing by identifier names or literal values type code fragments that have statements added modified or removed type code fragments that semantically perform the same computation with little syntactic similarity.
type clones can be split up further based on the level of syntactic similarity.
strong type clones refer to type clones that are syntactically similar while weak type clones authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
table v recall and precision on the ojc lone da taset setting precision recall f1 code2vec .
.
.
glov e .
.
.
sourcerercc .
.
.
random .
.
.
table vi counts of tokens in the code fragments tha t are out of the embeddings vocabulary vectors tokens found oov tokens code2vec glov e are syntactically dissimilar.
the results of evaluating sourcerercc on bigclonebench suggests that the use of code embeddings improve the recall of the sourcerercc on the less syntactically similar clone types type and type but may cause the recall on type and type clones to drop.
however it is unclear what its effects on precision are.
in order to evaluate our approach s precision we used a second dataset ojclone.
we used all programming contest questions in the dataset and our results are shown in table v. as about of pairs of code snippet in this dataset are clone pairs we introduce another baseline where we randomly accept a pair of code fragments as code clones of the time.
the clones in the ojclone dataset has been previously considered to be of type and above .
the increase in recall that we see is consistent with what we observe in the bigclonebench benchmark on type and type clones.
on the other hand the results suggest that our approach causes the precision of sourcerercc to decline.
due to the poor recall of sourcerercc the overall f1 of the approach using code embeddings are slightly higher than the f1 when using sourcerercc alone.
one hypothesis is that the poor precision of code embeddings is caused by a large number of tokens encountered in the task s dataset that are out of vocabulary oov in the embeddings.
we count the number of times our approach tried to retrieve a code vector and the number of times it failed to retrieve a token.
the counts are presented in table vi.
we see that over of the time our approach can successfully retrieve the vectors of the tokens in the program fragments.
therefore out of vocabulary tokens are not the cause of poor performance of our model.
findings while it appears that the approaches using embeddings improves the overall f1 score the improvement is small.
it is unconvincing that the approaches using code embeddings have encoded semantic qualities of code fragments necessary to detect code clones.
overall the recall of all approachesare low and the embeddings enhanced approaches suffer a drastic loss of precision .
to less than .
.
therefore we do not conclude that embeddings have successfully improved sourcerercc s ability to detect clones.
from a practical standpoint our augmentation to sourcerercc also resulted in a large decline in speed as we cannot use the heuristics employed by sourcerercc to reduce the number of clone pairs to compare.
scalability of detecting code clones is a key concern for real world usage and we note that our technique is only proposed to evaluate the code embeddings and our technique may not be appropriate for real world usage due to its lack of scalability.
d. lessons learned from the tasks above we see that code embeddings cannot be used readily to improve simpler models .i n fact in out of tasks the use of embeddings lowers the performance of the models they are added to.
in the case of the code authorship task simpler approaches such as tf idf outperforms models augmented with embeddings of source code tokens.
the only task where the code vectors do not cause performance to deteriorate is the task of detecting code clones.
even in this task it appears that the use of embeddings exchanges sourcerercc s high precision for a higher recall while maintaining a similar f1 score.
our findings support the observations by fu and menzies that simpler baselines run faster and may outperform complex techniques and they should be used as baselines .
we see that on the task of code authorship identification the use of code embeddings under perform a simpler approach that uses simple tf idf features.
likewise the use of code embeddings did not improve performance of sourcerercc.
in short having a continuous representation of code tokens may not necessarily perform better than simple baselines that treat code tokens simply as symbols.
code embeddings may not be a silver bullet to boost the performance of deep learning models other considerations may have more impact.
for example we found that the pre processing on the data has large consequences on the model s performance.
one hurdle to the effective use of neural networks in the software engineering domain is the problem of out of vocabulary tokens.
hellendoorn and devanbu have raised this issue before and in their work suggested that deep learning techniques struggle with the large vocabulary of source code.
they demonstrated their point with a nondeep learning model that can update and expand its vocabulary outperforming a deep learning model with a fixed vocabulary.
our experiments validate the importance of pre processing on the code comment generation task in which the technique of converting rare tokens into the ast node type proposed by hu et al.
result in improved performance.
on the other hand on both the code clone detection and code authorship tasks we achieve poor performance although out of vocabulary tokens did not appear to be an issue on those tasks.
in the code authorship identification task the baseline features of just tf idf features were sufficient for good performance.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
the composition of source code token embeddings requires further investigation.
in the domain of natural language it has been suggested that the composition of tokens by summation averaging or concatenation may be useful for representing larger fragments of tokens .
however in the code clones detection task the composition of source code tokens by these operators does not appear to represent a body of tokens meaningfully enough to effectively detect code clones.
we believe that this result should motivate research into other operators or methods of composing code embeddings.
we find the lack of interpretability of code embeddings to be a source of difficulty in this work .
sourcerercc s criteria of measuring the overlap of code tokens is simple and easy to interpret on the other hand our approach averaging code vectors result in a representation that is hard to debug.
in additional there are practical ramifications of our approach.
the original sourcerercc with its heuristics based on its count based criteria runs in a significantly shorter time and achieves a comparable f measure.
finally due to the lack of success we face trying to improve models with code embeddings it may indicate that token embeddings learned over source code may not encode a significant amount of either semantic or syntactic information usable in different downstream tasks .
we are unable to use either the code2vec or glov e embeddings effectively in the downstream tasks we identified which may suggest a lack of generalizability of token embeddings.
we believe our findings should motivate more work in the area of finding good representations of code tokens and that future work on code representation should aim to address the difficulties of using code embeddings on downstream tasks.
iv .
t hrea ts to validity a. threats to internal v alidity threats to internal validity concern factors that may influence our results.
our evaluation of code embeddings relies on enhancing other techniques with the embeddings.
one limitation is that the techniques we have picked may not be suitable for using a vector representation of source code.
another limitation is that our integration of code2vec into these techniques may be too naive.
we have tried to mitigate these limitations by selecting techniques that already use code tokens in its input and by using a variety of different techniques in our evaluation.
both neural network based approaches and techniques to use vector space calculations are used which will explore both the potential of code embeddings to be used to initialize a neural network model and also its ability to encode semantic and syntactic qualities through vector space calculations.
our experiments do not provide any insight about the code embeddings lack of generalizability that we observed.
they suggest that code embeddings may not generalize beyond the task it was trained on but we were unable to find conclusive reasons explaining why the code embeddings did not helpexisting techniques.
we leave further experiments and detailed analysis that may provide these reasons for future work.
b. threats to external v alidity threats to external validity concern the generalizability of our findings.
while we have experimented on downstream tasks there are other tasks that may benefit from the use of pretrained token embeddings.
it may also be possible that the downstream tasks we have selected are not the best tasks for applying code embeddings.
for example we only considered downstream tasks where the input data is homogeneous.
we did not explore the effectiveness of code embeddings in downstream tasks involving heterogenous inputs such as duplicate bug report detection or duplicate stackoverflow post detection .
the inputs to models may contain multiple types of data e.g.
code snippets stack traces and text .
to use code embeddings they will have to be used together with other types of embeddings e.g.
word embeddings for natural language text and it will be interesting to observe if code embeddings is helpful in these tasks.
however existing literature does not suggest what common software engineering tasks can benefit from token embeddings.
to the best of our knowledge this is the first work that applies any model of code embeddings to multiple downstream tasks.
indeed the lack of obvious software engineering tasks to apply code embeddings on is motivation of our work.
moreover in our work we try to cover a diversity of tasks that are different from one another.
for example only code comment generation is closely related to natural language processing.
each task is likely to measure different qualities that the code embeddings can encode.
for example the code authorship tasks will require techniques to distinguish between syntax preferences of different authors while detecting type and type code clones will require techniques that detect the same semantic functionality.
in addition the tasks in this work involve both generative and classification tasks.
our experiments also may not imply anything about embeddings of other granularity of source code.
embeddings have been trained over execution traces or sequences of api method invocations .
these embeddings may be generalizable to other downstream tasks that do not use tokenbased approaches.
we note that evaluating these embeddings are out of the scope of our work and we do not say anything about their generalizability.
in this work we focus only on embeddings of source code tokens and code2vec is selected to be representative of these embedding techniques.
comparison with other code embedding techniques is beyond the scope of this paper and it is worth investigating them in future to confirm or refute the findings of this work.
v. r ela ted work in this section we discuss prior work on evaluation of word embeddings done in the nlp domain and embeddings of source code.
due to page limitations the survey here is by no means complete.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
a. evaluation of word embeddings in natural language processing there has been identical work on evaluating word embeddings.
evaluation of word embeddings can be categorized into intrinsic and extrinsic evaluation .
intrinsic evaluation involves the use of word analogy or similarity tasks while extrinsic evaluation refers to the evaluation of embeddings when used on downstream tasks.
research has also found that intrinsic evaluations of word embeddings do not correlate with extrinsic performance .
we believe that these insights and conclusions are applicable to code embeddings as well thus our work performs an extrinsic evaluation of code embeddings.
b. embeddings for source code granularity of embeddings other than code2vec there have been many proposed embeddings for code.
a survey of existing code embeddings are presented by chen and monperrus where works on embeddings are into categories depending on the granularity of source code that is embedded source code tokens functions sequences or sets of method calls and binary code are the granularities of source code that have been considered.
for examples of models that embed granularities of program elements other than source code tokens consider the work by xu et al.
and theetan et al.
xu et al.
trained embeddings of binary instructions and theetan et al.
trained embeddings of library imports.
while in this work we investigated only token based code embeddings future work should investigate and evaluate other granularities of code embeddings on downstream tasks.
token based embeddings in our work we focused on embedding source code tokens which we consider to be the most specific granularity.
researchers have trained and used embeddings in a diverse set of tasks.
there are several examples of models that trained embeddings from source code tokens into a vector space .
azcona et al.
proposed user2code2vec which are embeddings trained for profiling students.
these embeddings are used to predict if a student s submissions are correct.
white et al.
trained embeddings for automatic program repair.
they used embeddings to compute the similarity between identifiers for use in their repair technique.
they used a recurrent neural network language model to learn embeddings and used them to transform program repair ingredients by replacing identifiers based on identifier similarity.
for code search gu et al.
trained a joint embedding space representing both code snippets and method documentation.
they represented code snippets by their method names api sequences in the method bodies and the tokens in the method bodies.
they are jointly trained such that the method and its documentation are embedded near to each other in the vector space.
hellendoorn et al.
used a deep neural network for type inference for dynamically typed languages.
their model first embeds tokens into a vector space then learn type vectors in order to annotate the types of variables.evaluation of embeddings while there are many embeddings proposed on a large variety of tasks many research works including the works discussed above did not evaluate their embeddings on downstream tasks or did so only on tasks that are closely related to the training task .
we found only few examples of works that evaluate their work on downstream tasks.
similar to code2vec alon et al.
trained embeddings of ast paths.
they evaluated it on predicting names of variable and methods and predicting types of local variables.
they compared it against a baseline trained using word2vec .
defreez et al.
proposed func2vec which maps synonymous functions to vectors grouped together and a downstream task of mining error handling specifications in the linux kernel.
their miner successfully detected violations of the specifications they mined.
henkel et al.
proposed to embed traces of symbolic execution into a vector space.
they evaluated their code embeddings on a downstream task of predicting error codes.
their results indicate that their embeddings may be useful for finding bugs or suggesting repairs.
in their work they proposed a benchmark for the code analogy task.
the code analogy task is an intrinsic evaluation on code embeddings where the embeddings are evaluated on their ability to express relationships between analogous words in the vector space such as the analogy that mutex lock is to mutex unlock as spin lock is to spin unlock .
however work on nlp has suggested that performance on the word analogy task does not imply good performance on downstream tasks.
in these works while the code embeddings are shown to be useful they are often not compared against simpler baselines and the use of code embeddings is evaluated only in at most one other task.
one exception is the work by ben nun et al.
where the trained embeddings are evaluated on downstream tasks.
they trained statement embeddings over a graph constructed from both the data and control flow graph.
they evaluated their embeddings on downstream tasks of classifying algorithms a prediction task to predict if a program will run faster on a cpu or gpu and another prediction task of the amount of work done on each gpu thread while running a given program.
however unlike our evaluation of code2vec the downstream tasks they use include uncommon software engineering tasks and are similar to one another.
vi.
c onclusion and future work to conclude our experiments on source code embeddings suggest that they do not generalize readily to other tasks.
we performed experiments using code embeddings on three downstream tasks code comment generation code authorship identification and code clones detection.
in each task the code embeddings do not result in models with improved overall performance.
furthermore in two of the tasks they are outperformed by simpler models.
as a consequence of our work we call for the community to evaluate embedding models more carefully.
similar to the work already done for nlp we propose that the usefulness of authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
embeddings are more appropriately evaluated using a variety of downstream tasks.
while it may be interesting to have distributed representations of program elements it is far more important that embeddings can help in downstream tasks.
users of code embeddings should be careful in their choice of code embeddings keeping in mind that not all code embeddings will necessarily be helpful for their targeted downstream task.
for future work a more comprehensive evaluation of existing source code token embeddings can be done on the three tasks we identified in this work.
deeper analysis of the differences between embeddings may lead to deeper insights into how to train and use token embeddings.
beyond token embeddings an evaluation of distributed representations of other granularities e.g.
function embeddings in downstream tasks is a natural next step for future work.
we end with a call for further research beyond the introduction of new models of training code embeddings but to describe how the embeddings can be used for a variety of downstream tasks and to demonstrate that they can be useful beyond the single task they were trained on.
we believe that the software engineering community should not view the training of embeddings as an end to itself but instead as a means to achieve better performance in other tasks.