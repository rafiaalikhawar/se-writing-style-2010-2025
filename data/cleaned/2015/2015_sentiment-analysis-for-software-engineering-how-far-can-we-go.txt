sentiment analysis for software engineering how far can we go?
bin lin software institute universit della svizzera italiana usi switzerlandfiorella zampetti department of engineering university of sannio italygabriele bavota software institute universit della svizzera italiana usi switzerland massimiliano di penta department of engineering university of sannio italymichele lanza software institute universit della svizzera italiana usi switzerlandrocco oliveto stake lab university of molise italy abstract sentiment analysis has been applied to various software engineering se tasks suchasevaluatingappreviewsoranalyzingdevelopers emotions in commit messages.
studies indicate that sentiment analysis tools provide unreliable results when used out of the box sincetheyarenotdesignedtoprocesssedatasets.the silverbulletfor a successful application of sentiment analysis tools to se datasets might be their customization to the specific usage context.
wedescribeourexperienceinbuildingasoftwarelibraryrecommenderexploitingdevelopers opinionsminedfromstackoverflow.
toreachourgoal weretrained onasetof40kmanuallylabeled sentences words extracted from stack overflow a state of the art sentimentanalysistoolexploitingdeeplearning.despitesuchan effort andtime consumingtrainingprocess theresultswerenegative.wechangedourfocusandperformedathoroughinvestigationoftheaccuracyofcommonlyusedtoolstoidentifythesentimentofserelatedtexts.meanwhile wealsostudiedtheimpactofdifferentdatasetsontoolperformance.ourresultsshouldwarntheresearch community about the strong limitations of current sentiment analysis tools.
ccs concepts information systems sentiment analysis keywords sentiment analysis software engineering nlp acm reference format binlin fiorellazampetti gabrielebavota massimilianodipenta michele lanza and rocco oliveto.
.
sentiment analysis for software engineering howfarcanwego?.in icse icse 40thinternationalconference onsoftwareengineering may27 june3 gothenburg sweden.
acm new york ny usa pages.
permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation onthe firstpage.copyrights forcomponentsof thisworkowned byothersthan the author s mustbehonored.abstractingwithcreditispermitted.tocopyotherwise or republish topostonserversortoredistributetolists requirespriorspecificpermission and or a fee.
request permissions from permissions acm.org.
icse may june gothenburg sweden copyright held by the owner author s .
publication rights licensed to the association for computing machinery.
acm isbn ... .
introduction recentyearshaveseentheriseoftechniquesandtoolstoautomaticallymineopinionsfromonlinesources .themainapplication ofthesetechniquesistheidentificationofthemoodandfeelings expressedintextualreviewsbycustomers e.g.
tosummarizethe viewers judgment of a movie .
sentiment analysis i sa frequently used opinion mining technique.
its goal is to identify affective states and subjective opinions reported in sentences.
in its basic usage scenario sentiment analysis is used to classifycustomers written opinions as negative neutral or positive.
the software engineering se community has adopted sentiment analysis tools for various purposes.
it has been used to assess thepolarityofapps reviews e.g.
gouletal.
andpanichella etal.
and to identify sentences expressing negative opinions about apis .
tourani et al.
used sentiment analysis to identify distress or happiness in a development team while garcia et al.
found that developers expressing strong positive or negative emotionsinissuetrackersaremorelikelytobecomeinactiveinthe open source projects they contribute.
ortu et al.
studied the impactofsentimentexpressedinissues commentsandtheissue resolution time while sinha etal.
investigated thesentiment of developers commits.
mostpriorworksleveragesentimentanalysistoolsnotdesigned toworkonsoftware relatedtextualdocuments.this out of thebox usage has been criticized due to the poor accuracy these tools achievedwhenappliedinacontextdifferentfromtheoneforwhich theyhavebeendesignedand ortrained .forexample the stanford corenlp opinion miner has been trained on movie reviews.
in essence the silver bullet to make sentiment analysis successful when applied on software engineering datasets might be their customization to the specific context.
thus therecenttrendistocustomizeexistingsentimentanalysis tools to properly work on software engineering datasets .
themostwidelyusedtoolinthesecommunityis sentistrength .sentistrength assesses the sentiment of a sentence by lookingatthesinglewordsthesentenceiscomposedof thatis itassignspositive negativescorestothewordsandthensumsupthesescorestoobtainanoverallsentimentforthesentence.
sentistrength can be customizedto providethe sentimentfor domain specificterms.
forinstance islamandzibran developed sentistrength se which improved identification performance for se related texts.
acm ieee 40th international conference on software engineering authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
icse may june gothenburg sweden b. lin f. zampetti g. bavota m. di penta m. lanza and r. oliveto inspired by these works we started a research project to design and implement an approach to recommend software libraries to developers.
the idea was to assess the quality of software libraries exploitingcrowdsourcedknowledgebyminingdevelopers opinionsonstackoverflow.onekeycomponentneededtosucceedwas a reliable sentiment analysis tool e.g.
to capture positive negative developers opinions about the usability of a library .
given the warning raised by previous work in our field there wastheneed fortrainingandcustomizing thesentimentanalysis tool to the stack overflow context.
also looking at the opinion mining literature we decided to adopt a state of the art approach basedona recursiveneuralnetwork rnn ableto compute the sentimentofasentencenotbyjustsummingupthesentimentof positive negativeterms butbygrammaticallyanalyzingtheway words compose the meaning of a sentence .
we built a training set by manually assigning a sentiment score to a total of 40k sentences words extracted from stack overflow.
despitetheconsiderablemanualeffort theempiricalevaluationwe performed led to negative results with unacceptable accuracylevels in classifying positive negative opinions.
given this we started a thorough empirical investigation aimed at assessing the actual performance of sentiment analysis tools when applied on software engineering datasets with the goal of identifying atechnique able toprovideacceptableresults.weexperimentedwithallmajortechniquesusedinourcommunity byusingthemout of the boxaswell aswithcustomizationdesignedtoworkinthesoftwareengineering context e.g.
sentistrength se .
also we considered threedifferentsoftwareengineeringdatasets i ourmanuallybuilt dataset of stack overflow sentences ii comments left on issue trackers and iii reviews of mobile apps .
our results show that none of the state of the art tools provides a precise and reliable assessment of the sentiments expressed in themanuallylabeledstackoverflowdatasetwebuilt e.g.
allthe approachesachieverecallandprecisionlowerthan40 onnegative sentences .
results are marginally better in the app reviews and in the issue tracker datasets which however represent simpler usage scenarios for sentiment analysis tools.
thegoalofourpaperistosharewiththeseresearchcommunity our negative findings showing the current difficulties in applying sentimentanalysistoolstosoftware relateddatasets despitemajoreffortsintailoringthemtothecontextofinterest.ourresultsshould also warnresearchers to not simplyuse a customized sentiment analysis tool assuming that it provides a reliable assessment of the sentiments expressed in sentences but to carefully evaluate its performance.
finally we share our large training dataset as well as all the tools used in our experiments and the achieved results to foster replications and advances in this novel field.
structure of the paper.
section2presentstheavailablesentiment analysis tools and discusses sentiment analysis applications and studies in se.
section presents our original research plan.section reports and discusses the negative results we obtained whenevaluatingthesentimentanalysiscomponentofourapproach.
section reports the design and results of the study we performed toassesstheperformanceofsentimentanalysistoolsonsoftware engineering datasets while section discusses the threats that could affect the validity of our results.
finally after a discussion of lessons learned section section concludes the paper.
related work westartbyprovidinganoverviewofexistingsentimentanalysis tools and discuss the applications of these tools in the software engineeringdomain.then wepresentrecentstudiesquestioning the effectiveness of sentiment analysis when applied on se related datasets.table1reportsasummaryofthemainsentimentanalysis tools used in software engineering application to date.
table sentiment analysis tools used for se applications.
tool technique trained on used by sentistrength rule based myspace nltk vader rule based micro blog stanford corenlp recurs.
neural net movie reviews our work emotext lexical features stack overflow jira sentistrength se sentistrength jira uddin and khomh sentim.
orientation api reviews .
sentiment analysis tools there are several sentiment analysis tools available.
some of them are commercial tools such as meaningcloud1 getsentiment2 o r watsonnaturallanguageunderstanding3.
there are also sentiment analysis libraries available in popular machine learning tools suchas rapidminer4orweka aswellas sentiwordnet an extension of a popular lexicon database wordnet for sentiment analysis.
the sentiment analysis tools applied to software engineering applications are sentistrength is the most adopted one originally trained on myspace5comments.
the core of sentistrength is based on thesentiment word strength list a collection of positive and negative terms with an associated positive negative strength value.
it also leverages a spelling correction algorithmaswellasotherwordlistssuchasa boosterwordlist andanegatingwordlist forabettersentimentassessment.
sentistrength assigns a sentimentscore to each word composing a sentence under analysis and derives the sentence sentiment by sum ming up the individual scores.
the simple approach behind sentistrength makesiteasytocustomizeforaspecificcontext by defining a list of domain specific terms with associated sentiment scores.
despite this only islam and zibran adopted a customized version in software engineering.
nltk is a lexicon and rule based sentiment analysis tool havingvader valenceawaredictionaryandsentimentreasoner atitscore.
vaderisspecificallytunedtosocialmediatextsbyincorporatinga gold standard sentimentlexiconextractedfrom microblog like contexts and manually validated by multiple independent human judges.
stanford corenlp is built on top of a recursive neural network whichdiffersfrom sentistrength andnltkthanksto its ability to compute the sentiment of a sentence based on howwordscomposethemeaningofthesentence andnotby summing up the sentiment of individual words.
it has been trained on movie reviews.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
sentiment analysis for software engineering how far can we go?
icse may june gothenburg sweden emotxt .thisisatoolkitforemotionrecognitionfromtextthat combines a n gram approach proposed by ortu et al.
with lexical featuresconveying emotions inthe inputtext emotion lexicon politeness positiveandnegativesentimentscores computedbyusing sentistrength anduncertainty.thenovelty ofemotxtreliesontherecognitionofspecificemotions such asjoy love andanger.thetoolhasbeenpreliminaryevaluated on two datasets mined from stack overflow and jira .
.
sentimentanalysis softwareengineering sentiment analysis has been applied on different software engineeringartifacts suchastechnicalartifacts e.g.
issuesandcommit messages and crowd generated content e.g.
forum messages and users reviews and to support different tasks.
sentimentiscommonlyexpressedinthedeveloper writtencommit messages and issues .
guzman et al.
analyzed the sentimentofcommitcommentsingithubandprovidedevidencethat projects having more distributed teams tend to have a higher positivepolarityintheiremotionalcontent.additionally theauthors found that those comments written on mondays tend to express more negative emotions.
a similar study was conducted by sinha etal.
on28 466projectswithinasevenyeartimeframe.the results indicated that a majority of the sentiment was neutral and that tuesdays seem to have the most negative sentiment overall.
also theauthorsfoundastrongpositivecorrelationbetweenthe numberoffileschangedandthesentimentexpressedbythecommits the files were part of.
ortu et al.
analyzed the correlation between the sentiment in 560k jira comments and the time to fix a jira issue finding that positive sentiment expressed in theissuedescriptionmighthelpissuefixingtime.finally souzaand silva analyzedtherelationbetweendevelopers sentimentand builds performed by continuous integration servers.
they found that negative sentiment both affects and is affected by the result of the build process.
analyzing the polarity of apps reviews is particularly useful to supporttheevolutionofmobileapplications .gouletal.
applied a sentiment analysis tool suite to over reviews observing that sentiment analysis can address current bottlenecks torequirementsengineering butthatcertaintypesofreviewstend to elude algorithmic analysis.
carre o et al.
presented a techniquebasedonaspectandsentimentunificationmodel asum to extract common topics from apps reviews and present users opinionsaboutthosetopics.guzman etal.
proposedtheuseof sentistrength tosupportasimilartask.panichella etal.
used anaivebayesclassifiertoassigneachsentenceinusers reviews toa sentimentclass amongnegative neutral andpositive.
this is one of the features they use to classify reviews on the basis of theinformationtheybring e.g.
featurerequest problemdiscovery etc.
.
sentiment analysis has also been applied to classify tweets relatedtosoftwareprojects .theresultsoftheirempiricalstudy indicated that searching for relevant information is challengingeven if this relevant information can provide valuable input for softwarecompaniesandsupportthecontinuousevolutionofthe applications discussed in these tweets.
asemotionscanimpactthedeveloperproductivity taskcompletion quality and job satisfaction sentiment analysis has also beenusedtodetectthepsychologicalstateofdevelopers .guzman and bruegge used sentiment analysis to investigate the role of emotionalawarenessindevelopmentteams whilegachechiladze et al.
usedsentiment analysis to builda fine grained modelfor angerdetection.inaddition thestudybypletea etal.
provided evidencethatdeveloperstendtobemorenegativewhendiscussing security relatedtopics.finally garcia etal.
analyzedtherelationbetweentheemotionsandtheactivityofcontributorsinthe opensourcesoftwareprojectgentoo.theyfoundthatcontributorsaremorelikelytobecomeinactivewhentheyexpressstrong positive or negative emotions in the issue tracker or when they deviate from the expected value of emotions in the mailing list.
sentiment expressed on q a sites such as stack overflow is also leveraged by researchers to recommend comments on quality deficienciesorscopesfor furtherimprov ementforsourcecode or to identify problematic api design features .
.
assessment of sentiment analysis tools in software engineering contexts while the authors of the above works presented an extensive evaluation of the relationship between sentiment and other factors no analysisisreportedforwhatconcernstheaccuracyofthesentiment classification.
indeed unsatisfactory results have been reported by researcherswhenusingthesesentimentanalysistoolstoanalyze texts under software engineering contexts.
touraniet al.
used sentistrength to extract sentiment information from user and developer mailing lists of two major successfulandmatureprojectsfromapachesoftwarefoundation tomcat and ant.
however they found sentistrength achieved a very low precision i.e.
.
for positive sentences and .
for negative sentences.
the low precision is caused by the ambiguous technicaltermsandthedifficultyofdistinguishingextremepositive negativetextsfromneutralones.novielli etal.
highlighted anddiscussedthechallengesofemployingsentimentanalysistechniques to assess the affective load of text containing technical lexicon as typical in the social programmer ecosystem.
jongeling etal.
conductedacomparisonoffourwidelyused sentimentanalysistools sentistrength nltk stanford corenlp andalchemyapi .
they evaluated their performance on a human labeledgoldensetfromadeveloperemotionsstudybymurgia etal.
andfoundnoneofthemcanprovideaccuratepredictionsof expressedsentimentinthesoftwareengineeringdomain.theyalsoobservedthatdisagreementexistsnotonlybetweensentimentanalysis tools and the developers but also between different sentiment analysis tools themselves.
their further experiment also confirmed thatdisagreementbetweenthesetoolscanresultincontradictory results when using them to conduct software engineering studies.
theresultsachievedinthesestudiescallforasentimentanalysis techniquecuratedwithsoftwareengineeringrelateddatatoaddress the problem of low accuracy when dealing with technical terms.
following this suggestion sentiment analysis tools specificfor software datasets have beenproposed.
islam and zibran developed sentistrength sebasedon sentistrength toaddressthe majordifficultiesbycreatingdomaindictionaryandintroducing otherheuristicrules.thepresentedevaluationshowedthattheir tool significantly outperformed sentistrength.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
icse may june gothenburg sweden b. lin f. zampetti g. bavota m. di penta m. lanza and r. oliveto uddin and khomh detected the polarity positive negative neutral ofsentencesrelatedtoapiusagebyusingacustomized versionofthesentimentorientationalgorithm .thealgorithm wasoriginallydevelopedtomineandsummarizecustomeropinions about computer products.
however uddin and khomh customized the tool with words specific to api reviews.
to the best of our knowledge these are the only cases where the authors tried to customize state of the art sentiment analysis tools to fit the software engineering domain.
methodology we briefly describe our initial plan to build a tool to recommend software libraries to developers given i a short description of a task at hand i.e.
functional requirements and ii a list of nonfunctional requirements considered more less important by the developerforthespecificimplementationtask e.g.
securityisof paramountimportance whilehighperformanceisnicetohavebut not really needed .
the basic idea was to leverage crowdsourced knowledge by mining opinions posted by developers while discussing on q a websites such as stack overflow.
our plan failed due to very poor results obtained whenmining opinionsfrom sedatasets.for this reason while we present a detailed description of the opinion mining process we adopted we only provide a brief overview of the overall idea and its different components.
stackoverflow developer8 front endmaven libraries miner database2fine grained linker3 45opinion miner figure our vision of the library recommender system.
theoverallideaisdepictedinfig.
.thedashedarrowsrepresent dependencies e.g.
1and3 while the full arrows indicate flows ofinformationpushedfromonecomponenttoanother.the libraries minermines from the maven central repository6all available java libraries 1in fig.
.
we extract for each library its i name ii description iii linktothe jarofthelatestversion iv license and v number and list of clients using it.
all the information is stored inourdatabase .thefine grainedlinker minesstackoverflow discussions to establish fine grained links between the libraries storedinthedatabase 4andrelevantsentencesinstackoverflow discussions .
opinion minercomponent can retrieve them identify the expressed sentiments i.e.
positive neutral o r negative classify opinions on the basis of the non functional requirements it refers to e.g.
usability performance security communitysupport etc.
andstore them in the database .
finally the developer interested in receiving recommendations about software libraries submits a textual query describing the task in a web based front end and important non functional requirements .this information is provided to a web service 9to identifythemostrelevantandsuitablelibrariesconsideringboth functional and non functional requirements.
in the following we detail our work to create the opinion miner component where sentiment analysis plays a vital role.
we report thenegative results we achieved in section .
.
mining opinions in software engineering datasets previous work that attempted to mine opinions in se datasets offersaclearwarning usingsentimentanalysis opinionminingtechniquesout of the boxonsedatasetsisarecipefornegative results.
indeed these tools have been designed to work on user sreviews of products movies and do not take into considerationdomain specific terms.
for example the word robusthas a clear positivepolaritywhenreferredtoasoftwareproduct whileitdoes not express a specific sentiment in a movie review.
this pushedresearchers to create customized versions of these tools enriching them with information about the sentiment of domain specific terms e.g.
sentistrength seby islam and zibran .
despite the effort done by some authors in developing customizedtools thereisasecondmajorlimitationofthesentiment analysistoolsmostlyusedinse e.g.
sentistrength .such tools assess the sentiment of a sentence by looking at the single words in isolation assigning positive negative scores to the words and then summingthese scores to obtainan overall sentiment for the sentence.
thus the sentence composition is ignored.
for example a sentence such as i would not recommend this library even though it is robust and fast would be assessed by these techniques aspositiveinpolarity giventhepresenceofwordshavingapositivescore i.e.
robust fast .suchalimitationhasbeenovercome by the stanford corenlp approach used for the analysis of sentimentinmovies reviews.theapproachisbasedonarecursiveneuralnetwork rnn computingthesentimentofasentence based on how words compose the meaning of the sentence .
clearly a more advanced approach comes at a cost the effort required to build its training set.
indeed it is not sufficient to simply provide the polarity for a vocabulary of words but to learnhow positive negative sentences are grammatically built on topof positive negative words it needs to know the polarity of all intermediate nodes composing a sentence used in the training set.
we discuss the example reported in fig.
.
gray nodes represent sequencesof wordshavinga neutralpolarity redonesindicate negativesentiment green ones positivesentiment.
overall the sentence has a negative sentiment see the root of the tree in fig.
despite the presence of several positive terms the tree s leafs and intermediate nodes.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
sentiment analysis for software engineering how far can we go?
icse may june gothenburg sweden i would not recommend this libraryeven though it is robust andfast figure example of the labeling needed to build the stanford corenlp training set.
to use this sentence composed of words in the training set of thernn wemustprovidethesentimentofall27nodesdepictedinfig.
.thisallowsthernntolearnthatwhile itisrobustandfast hasa positivepolarityiftakenin isolation theoverallsentence is expressing anegative feeling about thelibrary due tothe i would not recommend this library sub sentence.
giventhehighcontext specificityofourworktosedatasets i.e.
stack overflow posts we decided to adopt the stanford corenlp tool and to invest a substantial effort in creating a customized training set for it.
indeed as highlighted in previous work itmakesnosensetoapplyanapproachtrainedonmovie reviews on se datasets.
.
.
buildingatrainingsetfortheopinionminer.
weextracted fromthelatestavailablestackoverflowdump datedjuly2017 the listofalldiscussions i taggedwithjava and ii containingone of the following words library libraries api s .
given our original goal i.e.
recommendingjavalibrariesonthebasisofcrowdsourced opinions we wantedtobuild atrainingset asdomain specificas possibleforthernn.byapplyingthesefilters wecollected276 discussions from which we extracted sentences by using thestanford corenlp toolkit .
we randomly selected sentences and manually labeled them by assigning a sentiment score to the whole sentence and to every node composing it.
thelabelingprocesswasperformedbyfiveoftheauthors from nowon evaluators andsupportedbyawebapplicationwebuilt.
the web app showed to each evaluator a node extracted from a sentence to label with a sentiment going from to with 2indicating strong negative weak negative neutral weak positive and strong positive score.
the choice of the five levels sentimentclassificationwas notrandom butdriven bytheobservation of the movie reviews training set made publicly available by the authors of the stanford corenlp sentiment analysis tool7.notethatanodetoevaluatecouldbeawholesentence an intermediatenode thus asub sentence oraleafnode i.e.
asingle word .toavoidanybias thewebappdidnotshowtotheevaluator the complete sentence from which the node was extracted.
indeed knowing the context in which a word sentence is used could introduce a bias in the assessment of its sentiment polarity.
finally the thusreducingthesubjectivitybias.thisprocess whichtook working hours of manual labeling resulted in the total labeling of the sentiment polarity for nodes i.e.
nodes extracted from the sentences evaluators per node .
once the labeling was completed two of the authors worked on conflicts resolution i.e.
cases in which two evaluator assigned a differentsentimenttothesamenode .allthe279conflictsinvolving complete sentences .
of the labeled sentences were fixed.indeed it is of paramount importance to assign a consistent and double checked sentiment tothe complete sentences considering the fact that they will be used as a ground truth to evaluate our approach.
concerning the intermediate leaf nodes we had a total of 199conflicts .
ofthe labeled intermediate leaf nodes .
we decided to only manually solve strong conflicts meaning those forwhichtherewasascoredifference e.g.
oneoftheevaluators gave the other one while we automatically process the having a conflict of only one point.
indeed slight variations of the assigned sentiment e.g.
one evaluator gave and the other are expected due to the subjectivity of the task.
the final sentiment scorewas s incasetherewasagreementbetweentheevaluators while it was round in case of unsolved conflict where roundistheroundingfunctiontotheclosestintegervalueand si is the sentiment assigned by the ithevaluator.
negative results before incorporating the opinion miner component we decided to assess it individually and not in the context of the whole library recommendationtask.weperformedthisassessmentonthedataset ofmanuallylabeled1 500sentences.amongthosesentences are positive are neutral and are negative.
we performed a ten fold cross validation we divided the sentences into ten different sets each one composed of sentences.
then we used asetasa testset weonlyusethe150completesentencesinthetest set and not all their intermediate leaf nodes while the remaining 350sentences withalltheirlabeledintermediate leafnodes were usedfortraining8.sincewearemostlyinterestedindiscriminating betweennegative neutral and positiveopinions we discretized the sentimentin thetest setinto thesethreelevels.sentenceslabeled with and are considerednegative those labeledwith neutral andthoselabeledwith and aspositive .
we discretized the output of the rnn into the same three levels.
weassessedtheaccuracyoftheopinionminerbycomputingrecall andprecisionforeachcategory.computingtheoverallaccuracy would not be effective given the vast majority of neutralopinions in ourdataset i.e.
a constant neutralclassifier would obtain ahigh accuracy ignoring negativeandpositiveopinions .
table2reportstheresultsachievedbyapplying stanford core nlp so9on sentences extracted from stack overflow discussions.
8thestanfordcorenlp toolrequires duringthe trainingoftheneuralnetwork a socalled development settotunesomeinternalparametersofthenetwork.among the sentences with intermediate leaf nodes in training set we randomly selected sentences for composing the development set at each run.
9stanford corenlp so isthenameofthetoolwithournewmodeltrainedwithstack overflow discussions while stanfordcorenlp is the sentiment analysis component ofstanfordcorenlp with the default model trained using movie reviews.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
icse may june gothenburg sweden b. lin f. zampetti g. bavota m. di penta m. lanza and r. oliveto table testing results of stanford corenlp sentiment analyzer with new model trained with stack overflow discussions.
batch correct prediction positivesentencespositiveprecisionpositiverecall neutralsentencesneutralprecisionneutralrecall negativesentencesnegativeprecisionnegativerecall .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
overall .
.
.
.
.
.
thetableshowsthenumberofcorrectpredictions thenumberof positive neutral negative sentences in the batch of testing sets and thecorrespondingprecision recallvalues whilethelastrowreports the overall performance on the whole dataset.
table shows some concreteexamplesofsentimentanalysiswith stanford corenlp so.
table examples of sentiment analysis results of stanford corenlp so.
sentence oracle prediction it even works on android.
positive positive hope that helps some of you with the same problem.
positive negative there is a central interface to access this api.
neutral neutral how is blocking performed?
neutral negative i am not able to deploy my app engine project locally.
negative negative anyway their current behavior does not allow what you want.negative neutral the results shown in table highlight that despite the specific training stanford corenlp so doesnotachievegoodperformance in analyzing sentiment of stack overflow discussions.
indeed its precision and recall in detecting positive and negative sentiments is below thus discouraging its usage as a fundamental part of a recommendation system.
although stanford corenlp so can correctly identify more negative than positive sentences only asmall fraction of sentences with positive negative sentiment is identified.also therearemoremistakenlythancorrectlyidentified sentences in both sets.
based on the results we achieved it is impracticable to build on the top of stanford corenlp so an effective recommender system forlibraries thehighpercentageofwrongsentimentclassification willlikelyresultintherecommendationofthewronglibrary.thus besides the huge effort we spent to train stanford corenlp so withaspecificandlargesoftwaredataset wefailedinachievingan effective sentiment analysis estimator.
for this reason we decided tochangeouroriginalplanandperformadeeperanalysisoftheaccuracy of sentiment analysis tools when used on software related datasets.
specifically we aim to understand whether i domainspecific training data really helps in increasing the accuracy ofsentiment analysis tool and whether ii other state of the art sentiment analysis tools are able to obtain good results on software engineeringdatasets includingourmanuallylabeledstackoverflow dataset.
understanding how these tools perform can also help us in gaining deeper insights into the current state of sentiment analysis for software engineering.
evaluating sentiment analysis for software engineering thegoalofthestudyistoanalyzetheaccuracyofsentimentanalysistoolswhenappliedtosoftwareengineeringdatasets withthe purposeof investigating how different contexts can impact their effectiveness.the contextofthestudyconsistsoftextextractedfrom threesoftware relateddatasets namelystackoverflowdiscussions mobile app reviews and jira issue comments.
.
research questions and context the study aims to answer the following research questions rq1 how does our stanford corenlp so perform compared to othersentimentanalysistools?
wewanttoverifywhetherother state of the art tools are able to achieve better accuracy on the stack overflow dataset we manually built thus highlighting limitationsof stanford corenlp so .indeed itcouldbethatour choice of the stanford corenlp and therefore of developing stanford corenlp so wasnotthemostsuitableone andother existing tools already provide better performance.
rq2 do different software related datasets impact the performance ofsentimentanalysistools?
wewanttoinvestigatetheextentto which analyzing other kinds of software engineering datasets e.g.
issue comments and app reviews sentiment analysis tools wouldachievedifferentperformancethanforstackoverflow posts.
for example such sources might contain less neutral sentencesand theappreviewsinparticular bemoresimilarto the typical training sets of sentiment analysis tools.
the context of the study consists of textual documents from threedifferentserepositories i.e.
i question answerforums i.e.
stackoverflowdiscussions ii appstores i.e.
users reviews on mobile apps and iii issue trackers i.e.
jira issue comments.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
sentiment analysis for software engineering how far can we go?
icse may june gothenburg sweden we chose these types of textual documents as they have been studiedbyseresearchers alsointhecontextofsentimentanalysis .asourgoalistoevaluatetheaccuracyofdifferent sentiment analysis tools on these three datasets we need to define the ground truth sentiment for each of the sentences texts they contain.
the following process was adopted to collect the three datasets and define their ground truth stack overflow discussions.
wereusethegroundtruthfor the sentences used to evaluate stanford corenlp so.
mobile app reviews.
we randomly selected reviews from thedatasetof3kreviewsprovidedbyvillarroel etal.
which containsmanually labeledreviewsclassifiedonthebasisofthe main information they contain.
four categories are considered bugreporting suggestionfornewfeature requestforimproving non functional requirements e.g.
performance of the app and other meaning reviewsnotbelongingtoanyoftheprevious categories .
when performing the random selection we made sure to respect the proportion of reviews belonging to the four categories in the original population in our sample e.g.
if ofthe3kreviewsbelongedtothe other category werandomly selected50 ofoursamplefromthatcategory .the341selected reviews represent a statistically significant sample with confidence level confidence interval.
onceselected wemanuallylabeledthesentimentofeachreview.thelabelingprocesswasperformedbytwooftheauthors from now on evaluators .
the evaluators had to decide where the text is positive neutral or negative.
a third evaluator was involved to solve conflict cases.
jira issuecomments.
weusethedatasetcollectedbyortu et al.
containing 4k sentences labeled by three raters with respect to four emotions love joy anger and sadness.
this dataset has been used in several studies as the golden set for evaluatingsentimentanalysistools .duringtheoriginal labeling process each sentence was labeled with one of six emotions love joy surprise anger sadness fear.among these six emotions love joy anger and sadnessare mostly expressed.
as also done by jongeling et al.
we map the sentences withthelabel loveorjoyintopositivesentences andthosewith labelangerorsadnessinto negative sentences.
table4reportsforeachdataset i thenumberofsentencesextracted and ii the number of positive neutral negative sentences.
table4 datasetusedforevaluatingsentimentanalysistools in software engineering dataset sentences positive neutral negative stack overflow app reviews jira issue .
data collection and analysis onthethreedatasetsdescribedaboveweexperimentedwiththe following tools which are popular in the se research community sentistrength .sentistrength does not give the sentiment ofthetextdirectly instead itreportstwosentimentstrength scoresofthetextanalyzed onescoreforthenegativesentiment expressed in the text from not negative to extremely negative theother forthepositivesentimentexpressedfrom not positive to extremely positive .
we sum these two scores and map the sum of over and below into positive neutral and negative respectively.
nltk.based on vader sentiment analysis nltkreports foursentimentstrengthscoresforthetextanalyzed negative neutral positive and compound .thescoresfor negative neutral and positive rangefrom0to1 whilethe compound scoreisnormalizedtobebetween mostextremenegative and most extreme positive .
as suggested by the author ofthevadercomponent10 weusethefollowingthresholds to identify the sentiment of the text analyzed score .
positive .
score .
neutral score .
negative.
stanford corenlp .bydefault stanford corenlp reportsthe sentiment ofthetext ona five valuescale verynegative negative neutral positive and very positive.
since we are only interestedindiscriminatingbetweennegative neutral andpos itiveopinions wemergedverynegativeintonegative andvery positive into positive.
sentistrength se .as it is a tool based on sentistrength andusesthesameformatofreportedresults weinterpretits sentiment score by adopting the same approach we used for sentistrength.
stanford corenlp so .similarly weusethesameapproach adoptedfor stanford corenlp toconvertfive scalevaluesinto three scalevalues.toexaminetheperformanceonappreviews and jira issue comments we used the stack overflow labeled sentences including internal nodes as training set11.
we assess the accuracy of the tools by computing recall and precisionforeachofthethreeconsideredsentimentcategories i.e.
positive neutral negative in each dataset.
.
results table5reportstheresultsweachievedbyapplyingthefivesentimentanalysisapproachesonthethreedifferentsedatasets.the tablereportsthenumberofcorrectpredictionsmadebythetool andprecision recallforpredictingsentimentofpositive neutral negative sentences.
for each dataset metric the best achieved results are highlightedin bold.inthefollowingwediscusstheachievedresults aiming at answering our research questions.
.
.
rq howdoesour stanford corenlp so performascomparedtoothersentimentanalysistools?
toanswerrq weanalyze theresultsachievedbythefivetoolsonthestackoverflowdataset we built.
asforthecomparisonof stanford corenlp so withtheoriginal model of stanford corenlp the results show that on neutral sentences stanford corenlp so achievesabetterrecallwhilekeeping almostthesamelevelofprecision.also onpositiveandnegative sentences stanford corenlp so is still able to provide a good increment of the precision.
11in this case of the training set was used as development set.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
icse may june gothenburg sweden b. lin f. zampetti g. bavota m. di penta m. lanza and r. oliveto table evaluation results for sentiment analysis tools applied in software engineering domain.
in bold the best results.
dataset tool correct predictionpositiveprecisionpositiverecall neutralprecisionneutralrecall negativeprecisionnegativerecall stack overflowsentistrength .
.
.
.
.
.
nltk .
.
.
.
.
.
stanford corenlp .
.
.
.
.
.
sentistrength se .
.
.
.
.
.
stanford corenlp so .
.
.
.
.
.
app reviewssentistrength .
.
.
.
.
.
nltk .
.
.
.
.
.
stanford corenlp .
.
.
.
.
.
sentistrength se .
.
.
.
.
.
stanford corenlp so .
.
.
.
.
.
jira issuessentistrength .
.
.
.
nltk .
.
.
.
stanford corenlp .
.
.
.
sentistrength se .
.
.
.
stanford corenlp so .
.
.
.
however in this case the increment of precision has a price topay stanford corenlp so provideslevelsofrecalllowerthan stanford corenlp .
the comparison between stanford corenlp andstanford corenlp so should be read taking into account that theoriginal stanford corenlp modelistrainedonover10klabeled sentences i.e.
215k nodes .
stanford corenlp so is trained on a smaller training set.
thus it is possible that a larger training set couldimprovetheperformanceof stanford corenlp so .however as of now this is a mere conjecture.
when looking at other tools the analysis of the results reveal that all the experimented tools achieve comparable results and more important none of the experimented tools is able to reliably assessthesentimentexpressedinastackoverflowsentence.indeed whileallthetoolsareabletoobtaingoodresultswhenpredicting neutralsentences theiraccuracyfallswhenworkingonpositiveand negative sentences.
for example even considering the toolhaving the highest recall for identifying positive sentences i.e.
sentistrength i there is only .
chance that it can correctly spot a positive sentence and ii one out of five sentences that it willlabelaspositivewillbeactuallyfalsepositives precision .
therecallisalmostthesameasrandomlyguessingwhichhas33.
chance of success.
these results reveal that there is still a long way togobeforeresearchersandpractitioners canusestate of the art sentiment analysis tools to identify the sentiment expressed in stack overflow discussions.
rq1main findings i the training of stanford corenlp on so discussions does not provide a significant improvement as comparedtotheoriginalmodeltrainedonmoviereviews ii thepredictionaccuracyofalltoolsarebiasedtowardsthemajorityclass neutral forwhichaverygoodprecisionandrecallisalmostalways achieved and iii all tools achieve similar performance and it is impossibletoidentifyamongthemaclearwinneror inanycase atoolensuringsufficientsentimentassessmentofsentencesfrom stack overflow discussions.
.
.
rq do different software related datasets impact the performance of sentiment analysis tools?
to answer rq we compare the accuracy of all tools on the three datasets considered in ourstudy.
when we look at results for app reviews we can see that differentlyfromwhatobservedinthestackoverflowdataset most tools can predict positive texts with reasonable precision recall values.
even for negative reviews the results are in general much better.itisworthnotingthat stanford corenlp iscompetitivefor identifyingpositive andnegativesentimentas comparedtoother tools.
indeed compared to other texts in software engineering datasets suchas stackoverflow discussions andjira issues app reviews can beless technical and relatively more similarto movie reviews with which the original model of stanford corenlp is trained.however whenidentifyingneutralappreviews alltools exhibit poor accuracy.
this is likely due to the fact that while positive and negative app reviews could be easily identified by the presence absence of some marker terms e.g.
the presence of the bugtermislikelyrelatedtonegativereviews thisisnotthecase for the neutral set of reviews in which a wider and more variegate vocabulary might be used.
when inspectingresults for jira issuecomments we find that sentistrength andsentistrength sehavebetteraccuracythan othertools with sentistrength seprovidingabetterprecisionrecallbalanceacrossthetwocategoriesofsentiment i.e.
positive and negative .
despite the mostly good results achieved by the experimented toolson thejira dataset there are someimportantissues in the evaluations performed on this dataset.
first theabsenceofneutralsentencesdoesnotprovideaclear and complete assessment of the accuracy of the tools.
indeed as shown in the app reviews neutral texts might be in some datasets themostdifficulttoidentify likelyduetothefactthattheyrepresent that grey zone close to both positive and negative sentiment.
second thejiradatasetisbuiltbymappingemotionsexpressed inthecomments e.g.
joyorlove intosentiments e.g.
positive .
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
sentiment analysis for software engineering how far can we go?
icse may june gothenburg sweden table confusion matrices on the stack overflow dataset.
sentistrength positive neutral negative positive neutral 99negative nltk positive neutral negative positive 3neutral 6negative stanford corenlp positive neutral negative positive 56neutral negative sentistrength se positive neutral negative positive neutral 24negative stanford corenlp so positive neutral negative positive 16neutral 97negative however such a mapping does not always hold.
for instance positive comments in issue tracker does not always express joy or love e.g.
thanksfortheupdatedpatch thusallowingtoobtainavery partial view of the accuracy of sentiment analysis tools.
tohighlighttheimportanceof neutralitemsintheevaluation of a sentiment analysis tool table shows the confusion matrices obtained by the five different sentiment analysis tools on the stack overflow dataset see table .
all tools are effective in discriminating between positive and negativeitems.forexample our stanford corenlp so onlymisclassifiedtwonegativesentencesaspositive and16positivesentences as negative.
nltkonly misclassifies five negative sentences as positive and three positive sentences as negative.
the errors aremostlyduetonegative positivesentencesclassifiedasneutral andviceversa.thisconfirmstheissuesfoundbytourani etal.
whenusing sentistrength onsedata andthisiswhyevaluating sentiment analysis tools on datasets not containing neutral sentencesintroducesaconsiderablebias.similarobservationsholdfor theappreviewsdataset inwhichtheperformanceinclassifying neutral reviews is as shown in table extremely poor.rq2main findings theaccuracyofsentimentanalysistools is ingeneral pooronsoftwareengineeringdatasets.weclaimthis becausewefoundnotoolabletoreliablydiscriminatingbetween positive negative and neutral items.
indeed while the accuracy ontheappreviewsandjiradatasetsareacceptable i intheapp reviews dataset the accuracy in identifying neutral items is verylow and ii the data obtained with the jira dataset can not be considered as reliable due to the discussed issues.
threats to validity threats to construct validity concern therelation betweentheory and observation.
the first concern is related to our manual sentimentlabeling.sentimentexpressedinthetextmightbemisinterpretedbypeople.also thelabelingmightbeimpactedbysubjective opinions of evaluators.
although we adopted an additional conflict resolving process it is not guaranteed that the manually assigned sentiment is always correct.
another threat is the sentiment score mapping i.e.
mapping five scale sentiment to three scale sentiment.
indeed sentimentexpressed in the text have different degrees.
predicting slightlynegative sentence as neutral should be considered a smaller mis take then predicting a very negative sentence as neutral since thethresholdtodrawalinebetweentheneutralandthenegative sentiment can be more subjective.
threats to internal validity concern internal factors we did not consider that could affect the variables and the relations being investigated.inourstudy theyaremainlyduetotheconfiguration of sentiment analysis tools approaches we used.
in most cases we usethedefaultorsuggestedparameters forexample thethreshold fornltk.
however some parameters might be further tuned to increase the sentiment prediction performance.
threats to conclusion validity concerntherelationbetween thetreatmentandtheoutcome.werandomlyselectedsentences from stack overflow discussions and app reviews from an existing dataset .
while we considered statistically significant samples we cannot guarantee that our samples are representative of the whole population.
threats to external validity concern the generalizability of our findings.
while the evaluation has considered the most commonlyusedsentimentanalysistoolsinsoftwareengineering some lesspopulartoolsmighthavebeenignored.constantlythereare lots of new ideas and approaches popping up in the natural lan guage processing domain but few of them have been examined and verified in the software engineering context.
since our goal is to seek a good sentiment analysis tool for software related texts in this paper we only select the tools already used in previous software engineering studies.
our datasets are limited to three frequently mined software engineering repositories while texts in othercontexts suchmailinglistandircchats arenotconsidered.
lessons learned no tool is ready for real usage of identifying sentiment ex pressed in se related discussions yet.
no tool including the onesspecificallycustomizedforcertainsoftwareengineeringtasks is able to provide precision and recall levels sufficient to entail the tooladoptionforatasksuchasrecommendingsoftwarelibraries.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
icse may june gothenburg sweden b. lin f. zampetti g. bavota m. di penta m. lanza and r. oliveto byrelyingonsuchtools wewouldcertainlygeneratewrongrecommendations and miss good ones.
our results are a warning to the research community sentiment analysis tools should always be carefully evaluated in the specific context of usage before building something on top of them.
for example while uddin and khomh presented a very interesting approach to mine apis opinionsfrom stackoverflow they donotreportthe accuracyof the sentiment analysis component they exploit to identify positive negative opinions about apis.
specific re training is required but does not represent a silver bullet for improving the accuracy.
previous literature haspointedourthatsentimentanalysistoolscannotbeusedoutof the boxforsoftwareengineeringtasks .insome cases toolshaveintroducedadatapreprocessingorare trainingto copewiththespecificsoftwareengineeringlexicon inwhichthere arepositiveornegativewords sub sentencesthatarenotpositiveornegativeinothercontexts or viceversa e.g.
theword buggenerally carriesanegativesentimentwhenreferredtoalibrary whileitcan be consideredneutral in moviereviews .
however as results have shown thismightstillbeinsufficienttoguaranteegoodaccuracy in terms of both precision and recall on all polarity levels.
also customizationisverydatasetspecific andthereforeapplyingthe tool on different datasets would require a new training.
in other words customizingasentimentanalysistoolforjiradoesnotmake itreadyforstackoverflowand viceversa.finally somealgorithms suchasrecursiveneuralnetworks requirecostlyre training.inour case the training performed with sentences which turnedinto labeling almost 40k nodes revealed to be insufficient for a clear improvement of the stanford corenlp accuracy.
somesoftwareengineeringapplicationsmakesentiment analysis easier than others.
sentiment analysis tools perform betteronappreviews.appreviewscontainsentencesthat inmost cases clearlyexpresstheopinionofauser whowantstoreward an app or penalize it by pointing out a nice feature or a serious problem.hence thecontextisverysimilartowhatthosesentiment toolsarefamiliarwith.still asobserved thetools performanceon theneutralcategory is very poor.
looking at the issue tracker data besides the lack of neutral sentences in the jira dataset which per semakesthelifeofthesentimentanalysistoolsmucheasier again thepredominanceofproblem reportingsentencesmay slightly playinfavourofsuchtools.stackoverflowisadifferentbeast.posts mostly contain discussions on how to use a piece of technology and between the lines somebody points out whether an api or a codepatternisgoodorlessoptimal.inmanycases withouteven expressing strong opinions.
this definitely makes the applicability of sentiment analysis much more difficult.
shouldweexpect100 accuracyfromsentimentanalysis tools?no we should not.
in our manual evaluation out of the stack overflow sentences we manually labeled there were 279casesofdisagreement .
.thismeansthatevenhumansarenotabletoagreeaboutthesentimentexpressedinagivensentence.
thisisalsoinlinewithfindingsofmurgia etal.
onemotion mining exceptwhenasentenceexpressesclearemotionsoflove joy and sadness even for humans it is hard to agree.
hence it ishard to expect that an automated tool can do any better.
having saidthat advancesarestillneededtomakesentimentanalysistools usable in the software engineering domain.textreportingpositiveandnegativesentimentisnotsufficient to evaluate sentiment analysis tools.
asdiscussed the mostdifficulttaskforsentimentanalysistoolsistodiscriminatebetween positive negative vsneutral sentiment while they are quite effectiveindiscriminatingbetweenpositiveandnegativesentiment.
thisiswhydatasetssuchasthejiraonethatwe andothers used in previous work is not sufficient to evaluate sentiment analysis tools.
we hope that releasing our dataset will help in more robust evaluations of sentiment analysis tools.
conclusion somesaythattheroadtohellispavedwithgoodintentions.our work started out with what we consider a promising idea we wanted to develop an approach to automatically recommend apis andlibrariesgivenasetoffunctionalandnon functionalrequirements.todoso wewantedtoleveragethelargebodyofknowledge thatisstoredinq awebsiteslikestackoverflow.theapproach was going toexploit opinion miningusing deep learning through recurrentneuralnetwork.however aswefinalizedourworkwe noticed that it simply did not work because the opinion mining component had unacceptable performance.
the reason for the failure is manifold.
firstly it highlights how machine learning even in its most advanced forms is and remains a black box and it is not completely clear what happens in thatblack box.
to this one can add the design principle garbage in garbageout nomatterhow advancedatechnique iftheinputis notappropriate itis improbablethatanacceptableoutputcanbe produced.
in the specific case one might argue that stack overflow is not really the place where emotions run high it is a place where developersdiscusstechnicalities.thereforeitisratherobviousthat opinion mining will have a hard time.
while this might be true ourstudyrevealedthatalsoindatasetswhereemotionsaremore evident like app reviews and issue trackers there is an intrinsicproblem with the accuracy of current state of the art sentiment analysis tools.
intheendwedecidedto writea negativeresults paper .a s walter tichy writes negative results if trustworthy are extremely important for narrowing down the search space.
they eliminate uselesshypothesesandthusreorientands peedupthesear chforbetter approaches .wehopethatthesoftwareengineeringcommunitycan appreciateandleveragetheinsightsthatweobtainedduringour work.wearealsoreleasingthecompletedatasetasareplication package.
as a final word we would like to stress that we are not dismissing opinion mining in software engineering as impractical but rather as not mature enough yet .
we believe there is promise in thefield butthatacommunityeffortisrequiredtobringopinion mining to a level where it actually becomes useful and usable in practice.