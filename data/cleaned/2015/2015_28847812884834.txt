revisit of automatic debugging via human focus tracking analysis xiaoyuan xie state key lab of software engineering computer school wuhan university xxie whu.edu.cnzicong liu state key lab of novel software technology nanjing university zicong.liu.nju gmail.comshuo song state key lab of novel software technology nanjing university songshuosz gmail.com zhenyu chen state key lab of novel software technology nanjing university zychen nju.edu.cnjifeng xuan state key lab of software engineering computer school wuhan university jxuan whu.edu.cnbaowen xu state key lab of novel software technology nanjing university bwxu nju.edu.cn abstract in many fields of software engineering studies on human behavior have attracted a lot of attention however few such studies exist in automated debugging.
parnin and orso conducted a pioneering study comparing the performance of programmers in debugging with and without a ranking based fault localization technique namely spectrum based fault localization sbfl .
in this paper we revisit the actual helpfulness of sbfl by addressing some major problems that were not resolved in parnin and orso s study.
our investigation involved participants and debugging tasks.
a user friendly sbfl tool was adopted.
it was found that sbfl tended not to be helpful in improving the efficiency of debugging.
by tracking and analyzing programmers focus of attention we characterized their source code navigation patterns and provided in depth explanations to the observations.
results indicated that a short first scan on the source code tended to result in inefficient debugging and inspections on the pinpointed statements during the follow up browsing were normally just quick skimming.
moreover we found that the sbfl assistance may even slightly weaken programmers abilities in fault detection.
our observations imply interference between the mechanism of automated fault localization and the actual assistance needed by programmers in debugging.
to resolve this interference we provide several insights and suggestions.
ccs concepts software and its engineering !software testing and debugging corresponding author.
permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
copyrights for components of this work owned by others than acm must be honored.
abstracting with credit is permitted.
to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
request permissions from permissions acm.org.
icse may austin tx usa c 2016 acm.
isbn .
.
.
.
automated debugging spectrum based fault localization user studies attention tracking navigation pattern fault comprehension .
introduction it is widely known that software engineering is a human centric discipline .
studies on human behavior during the software life cycle have attracted extensive attention in the community .
such studies usually aimed to reveal how people actually behave and perform in various software engineering activities in order better facilitate these activities.
software fault detection is one of the most human intelligenceintensive tasks in which analysis of human behavior is essential.
uwano et al.
took the first step performing eye tracking analysis in static code review where a particular pattern namely scan was identified.
scan characterizes how a reviewer navigates the entire source code before carefully inspecting each code line.
on the other hand bednarik shifted the focus from static code review to manual debugging1 specifically how programmers dealt with various information sources was investigated.
apart from static code review and manual debugging there is another large family of fault detection techniques namely automated debugging which has been widely investigated over the past two decades.
in this field researchers have been mainly focused on proposing new techniques and investigating their performance without paying much attention to human factors.
however the results provided by current automated debugging techniques are only approximate and their correctness is generally not guaranteed.
as a consequence these results still require being understood and verified by the person who performs the repair.
therefore human behavior is critical and worth investigating in these techniques.
parnin and orso realized this problem and conducted a study which compared the actual performance of developers in debugging with and without a lightweight ranking based fault localization technique where they explicitly indicated the importance of human factors in determining the helpfulness of this technique.
as a preliminary study this work reveals several potential aspects 1w e refer to debugging in this paper as the dynamic fault elimination process using test execution information in contrast to the static code review.
ieee acm 38th ieee international conference on software engineering that should be further investigated.
first a more comprehensive experiment is required to obtain a statistically conclusive result.
secondly the helpfulness of a better automated debugging tool is worth studying.
thirdly the impact from the accuracy of fault localization needs to be re examined by considering the suggested measure of absolute ranking .
fourthly although it has been generally accepted that there is no perfect bug2detection we are interested to know whether automated debugging has any impact on human ability in comprehending the source code and identifying the bugs.
finally we still do not know what particular patterns programmers may follow in navigating the source code during automated debugging and how these patterns affect debugging efficiency.
therefore in this study we revisit the helpfulness of automated debugging by addressing the above points.
we are most interested in identifying the reasons behind the observed results via a quantitative focus tracking analysis which refers to tracking and analyzing the focus of attention of programmers.
in this paper we answer three research questions rq from an experiment with participants and debugging tasks which were categorized according to their fault localization accuracies.
our experiment used the same ranking based fault localization technique that parnin and orso used in i.e.
spectrum based fault localization sbfl .
each participant was required to debug two programs with and without sbfl respectively.
a platform namely mooctest with user friendly sbfl assistance was implemented which can colorize the suspicious code lines and record all of the operations performed by the participants during debugging such as file opening cursor movement and file changing.
these recorded operations were used to analyze the focus of attention of the participants and to reveal their code navigation patterns.
we found that an accurate localization result was helpful in completing the debugging tasks.
however surprisingly we also observed that sbfl was not helpful in improving the efficiency of debugging and sometimes even made it worse.
by analyzing the operation logs recorded by mooctest we found some navigation patterns.
in debugging with sbfl programmers typically started with a first scan i.e.
a skim of the entire or part of the code before inspecting the most suspicious code highlighted by the platform and then switched between the most suspicious code and others.
a quantitative analysis showed that a short first scan tended to result in inefficient debugging and inspections on the pinpointed statements during the follow up browsing on the source code after the first scan were normally just quick skimming.
moreover we found that the sbfl assistance in mooctest especially for cases with inaccurate results may even slightly weaken programmers abilities in comprehending the code and identifying the faults.
our analysis confirms the importance of code comprehension.
also it implies that presenting code together with fault ranking information which intends to help programmers focus on the suspicious code as quickly as possible without wasting time on other parts of the program may actually interfere with the real assistance needed by programmers in debugging.
this interference is most likely the reason for the decrease in efficiency.
we conjecture that the interference is due to an inappropriate application of the technique.
we further give some insights and suggestions on how to properly perform automated debugging in order to really benefit from it.
the contributions of this paper are summarized as follows.
we conducted a comparison of programmers performance 2in this paper we will use bug and fault interchangeably.between debugging with and without sbfl where participants and debugging tasks were involved and a userfriendly debugging platform was adopted.
we also analyzed the impact from different levels of sbfl accuracy by considering absolute ranking .
we performed analysis to track the focus of attention of our participants where two important code navigation patterns namely first scan and follow up browsing were observed.
and their relations with the efficiency of sbfl assisted debugging were revealed.
we reconfirmed the importance of code comprehension with supportive evidence.
our analysis also revealed that automated fault localization may interfere with programmers code comprehension and fault identification.
to help programmers really benefit from automated debugging we provided some insights and suggestions.
.
related work .
analyses of human behavior in software engineering human behavior has been considered to have a major impact on the entire software life cycle .
understanding how people behave and perform in various software engineering activities can help to answer why a particular technique is or is not effective.
crosby and stelovsky first investigated the influence of programming experience on viewing a short but complex algorithm via an eye tracking technique.
sharif and his colleagues conducted eye tracking studies on uml diagram comprehension .
they also performed similar investigation about the impact of identifier style on code comprehension .
rodeghero et al.
tracked developers focus of attention to provide evidence on how humans chose the keywords of a program for source code summarization.
and lewis et al.
evaluated how well a notable bug predication algorithm fixcache helped developers.
in static code review uwano et al.
took the first step in adopting eye tracking techniques to explain the performance of various reviewing strategies.
uwano et al.
identified a scan pattern in static code review i.e.
people usually have a preliminary reading of the entire code at the beginning of their review.
they found that the longer a reviewer scanned the code the more efficiently he could find the fault in code review.
this finding was later confirmed by sharif et al.
via more comprehensive empirical studies.
concerning debugging stein and brennan conducted an interesting analysis which demonstrated that novice programmers can debug more efficiently after viewing the eye gaze traces from other professional programmers.
ko et al.
tracked developers actions such as searching navigating and editing to answer how do developers seek relate and collect relevant information in debugging tasks.
there were also studies that aimed at predicating programmers code navigation behavior .
however all of these works were about manual debugging for automated debugging to the best of our knowledge there are still very few similar studies.
.
analyses on automated debugging with human factors it is widely accepted that debugging is extremely time consuming.
in order to speed up this process many automated debugging techniques have been proposed over the past two decades.
one type of techniques utilizes human intelligence to facilitate debugging for example one is called whyline implemented by ko et al.
.
ko et al.
invented a new debugging paradigm namely interrog ative debugging which allowed programmers communicate with the software by asking why did questions.
answers given by whyline can guide programmers to find the cause of the failure and fix the bug.
another family of automated debugging techniques aims to reduce human involvement by providing possible fault locations.
one classic idea is to use program dynamic slicing which can effectively isolate statements involved in the calculation of the observed failure.
this method was first proposed by korel and laski followed by a series improved versions .
another idea is to model a fault localization problem into an information retrieval task where bug reports are treated as queries and potential faults are the most matchable code areas .
besides there is a widely studied method namely spectrum based fault localization sbfl which utilizes various program spectra and testing results to evaluate the suspiciousness for each program entity.
all entities are then ranked in descending order and are provided to programmers as the suggested fault locations .
however the fault locations suggested by this family of techniques still require programmers comprehension and verification to repair the software.
in other words although they reduce manual efforts these techniques cannot completely eliminate human involvement.
hence whether they are really helpful to programmers is well worth investigating.
however most of these studies focused on how to improve the accuracy of fault localization and very few have taken human factors into account.
weiser and lyle did the first comparison of developers performance between debugging with and without program slicing where no significant improvement was found by using slicing.
francel and spencer also investigated the helpfulness of program slicing to programmers in their code comprehension and debugging abilities.
in contrast their experiments indicated that slicing improved programmers performance.
tao et al.
studied the effectiveness of human debugging via machine generated patches.
a recent study by wang et al.
investigated how well information retrieval techniques help developers to locate bugs .
in the field of sbfl that has been regarded as a light weight and practical fault localization technique even fewer related works have been reported.
parnin and orso did a pioneering study to answer the question can automated debugging help programmers where the actual performance of participants in debugging with and without sbfl was compared.
they showed that sbfl can be helpful in some cases especially for experienced programmers.
they also reported some surprising observations such as changes in the ranking do not produce any significant impact on programmers performance programmers may not follow the provided ranking list and pointed out that the perfect bug detection is generally unrealistic.
besides some suggestions were given based on their observations to better improve the sbfl tools.
.
motivation and research questions the study by parnin and orso provides a new perspective from which to re examine sbfl.
many aspects were revealed to be in need of further investigation such as large scale experiments in terms of the number of participants and debugging tasks should be conducted.
the experiment in only involved programmers and two faulty programs.
therefore it is necessary to have larger scale experiments for a more statistically conclusive result.
as suggested in programmers performance with a userfriendly tool is worth studying.
parnin and orso provideda plug in for sbfl which presented the localization results simply in a ranking list.
for example two for loop predicates are ranked first and second in the list.
then a result presented to a programmer looks like for int i i n i for int i i m i other statements clearly such reordered statements are incomprehensible.
parnin and orso alleviated this problem by providing navigation from each statement in the list to its original location.
they have done this on purpose because their goal was to investigate the impact purely from the ranking list.
however it is also interesting to know whether a more easy to follow result can lead to similar or better performance.
actually gouveia et al.
have considered programmers performance with their proposed dynamic graphical localization reports .
however since the human factor was not the focus of that study experiments were still very preliminary.
in addition facilities of test execution can be improved.
in for each program only one failed test case was provided in a descriptive way rather than in an executable format3.
more importantly the failure information in one of their subject programs clearly indicated the lines throwing the exceptions upon which programmers were more likely to rely.
impact on debugging performance from sbfl accuracy with respect to the absolute ranking needs to be re examined.
as conjectured by parnin and orso programmers may not follow the ranking after inspecting a few irrelevant statements which could be one possible explanation for their no impact observation since neither of their changes on the list has ever had the fault ranked top.
whether sbfl could affect fault detection i.e.
comprehend and identify the fault is still unknown.
it has been generally accepted that there is no perfect bug detection .
simply inspecting a fault is not sufficient for immediately detecting it.
however using the sbfl assistance and detecting the fault may not be completely independent of one another.
therefore it is interesting to know whether the sbfl assistance has any impact on fault detection.
last but most importantly an in depth analysis that tracks programmers focus of attention to reveal their code navigation pattern is needed.
parnin and orso provided some preliminary discussion on how developers navigate the program when debugging.
however it will be more convincing and informative if some visualized and quantitative analysis can be provided.
in summary there are still many questions to be answered which can help to reveal why sbfl is or is not helpful and how to improve it.
therefore in our study we revisit the performance of sbfl by considering human factors to address the above points.
we recruited participants to perform debugging on faulty programs.
a platform namely mooctest with better sbfl assistance than the plug in in was implemented.
it adopted jones et al.
s idea to colorize the code according to their suspiciousness without changing their positions such that the risk can be pinpointed but the integrity and readability of the program can still be preserved.
each debugging task was associated with a set of junit test cases that were executable and the execution results of these test cases were linked to the sbfl colorization.
our investigation was no longer solely on the helpfulness of the suggested 3the plug in hard codes the sbfl ranking in a static xml file which is not related to the given failed test case.
810ranking list but of the entire debugging tool.
to learn the impact from sbfl accuracy we compared debugging with good if the faulty statement is ranked top and bad otherwise sbfl results.
more importantly instead of simply reporting the performance of debugging we set our major focus as to identify the reasons and give explanations to the observed phenomena .
mooctest recorded all of the operations of participants during their debugging process which were used for tracking and analyzing their focus of attention.
from the analysis navigation patterns in debugging with sbfl and the impact from sbfl on fault detection were investigated.
we formulated the following three research questions rq1 can mooctest benefit debugging?
specifically does the accuracy of fault localization affect debugging efficiency?
rq2 is there any particular navigation pattern on source code during debugging with sbfl?
if yes how does it affect the efficiency and does it have any relation with the accuracy of fault localization ?
by addressing this question we want to find reasons for the observations in rq1.
rq3 does the assistance from sbfl have any impact on programmers fault detection abilities?
.
experiment .
mooctest an on line examination platform with sbfl we have developed mooctest an on line examination platform for a coursera course on software testing to provide all supportive features.
the subcomponent in mooctest specifically for sbfl is called mdebug which consists of three major modules fault localizer provides static source code analysis for control flow graph generation dynamic coverage analysis for execution profile construction and risk analysis for suspiciousness calculation.
we borrowed jones et al.
s idea to colorize the code according to their suspiciousness without changing their positions such that the risk can be pinpointed while the integrity and readability of the program can still be preserved.
different from we only colorized high risk statements as red but distinguished their suspiciousness with different levels of saturation the higher the level the greater the suspiciousness.
as suggested by that programmers are normally interested in only several top ranked statements fault localizer highlights the statements ranked as the top four or tied for the top four.
the formula used to calculate the suspiciousness can be configured.
in our experiment ochiai was adopted.
operation tracker records each operation during debugging e.g.
file opening cursor movement mouse clicking file modification and junit test execution with a time stamp such that we can track a programmer s operations to obtain more details about his task completion.
log analyzer receives the log file and performs various analyses to provide in depth knowledge about the sbfl assisted debugging process.
the server of mooctest assigned debugging tasks with an associated junit test suite to the participants.
it also specified whether the sbfl feature was switched on.
participants were required to login with their mooctest accounts and run the mdebug client on their local machines to perform the assigned tasks.
during debugging operation tracker recorded all the necessary information in the logs and sent them back to the server for marking and analyzing.
figure illustrates the mooctest gui for a debugging task with the sbfl feature switched on which is associated with the testing results of the provided test suite.
figure the sbfl feature on mooctest .
participants and program subjects there were participants from two classes involved in our experiment where class i and ii had and participants respectively.
they were 3rd year college students in computer science from our university who were enrolled in our coursera course on software testing a compulsory on line subject.
these students participated in our experiment during an examination which required them to concentrate and deliver more reliable results than volunteers.
besides they all had about two years of java programming experience.
their programming skills were diverse which can help to reduce the bias in our analysis.
in the experiment we selected seven programs from classic computer science algorithms whose brief introduction is given in table .
as compared with the two programs used by parnin and orso ours were smaller in size but should have a more suitable level of difficulty for our student participants comprehending these programs that have nested loops as well as complex data structure and logic is non trivial but is still accomplishable.
besides these algorithms involved no domain expertise which allowed our analysis to focus on the impact from mdebug and code comprehension.
table program subjects program description loc t ype quicksort quick sorting algorithm s heapsort heap sorting algorithm s findt riplefind all triples with sum 0in an integer array38 s subsequenceget the number of all subsequences of a string17 s t ictactoe noughts crosses game m ele vator an elevator scheduler m boatbomba game of guessing the boat in an n n grid164 m ysmeans single file program and mrepresents multiple file program.
as shown in table there are four single file and three multiplefile programs which partially indicate two levels of complexity in debugging.
for each program we artificially seeded exactly one fault on one code line to get a faulty version.
we obtained faulty versions for all these program subjects.
as compared with the two faulty programs in where each one was associated with only 811one failed test case in descriptive way each of our faulty programs was associated with a set of executable junit test cases.
testing results were different on these versions and hence the sbfl results varied as well.
in contrast the plug in in hard coded the sbfl ranking results in a static xml file.
in order to provide a comprehensive analysis on the impact from sbfl accuracy we categorized these versions according to their sbfl results.
first we used hit to indicate whether the faulty statement sfis red with the highest saturation hit if yes and otherwise.
for those cases where hit precision was then used to further distinguish the results with many false positives from those with few.
in our context precision n c where ncis the number of correct statements in red with the same highest saturation as sf.
the higher the precision the better result provided by sbfl.
for the cases where hit i.e.sfdoes not have red with the highest saturation we considered the distance in terms of the number of code lines and data dependency between sfand its nearest line in red with the highest saturation.
finally we categorized the faulty versions into six groups as shown in table .
and the category of each faulty version is shown in table which also gives the number of all test cases 2ndcolumn and the number of the failed test cases 3rdcolumn .
table categorization strategy hit hit p p dist dep 1dist dep 0dist dep 1dist dep a b c d e f ypmeans precision dist represents code line distance and depindicates whether there is data dependency means yes and means no .
in our experiment and loc .
table all faulty versions f aulty version t est cases f ailures cate gory quicksort a e quicksort b e heapsort b c heapsort c e findt riple a e findt riple b a findt riple c a subsequence a a subsequence b a t ictactoe a f t ictactoe b d t ictactoe c d ele vator a d ele vator b e boatbomb a c boatbomb b b boatbomb c b .
experimental procedure a tutorial on sbfl theory and the mdebug tool were first given to all participants to make sure that they fully understood the information provided by the tool.
then these two classes attended an examination.
participants from each class were required to perform two debugging tasks within minutes where one was on a singlefile program and the other one was on a multiple file program.
as a reminder participants were told that they would be scored according to whether they fixed the bugs and passed all given test cases rather than their time consumption.
the timeframe of minutes was imposed to avoid endless debugging.
class i was required to debug the single file program by hand but to debug the multiple fileprogram with sbfl.
class ii had the reversed set up.
the tasks were randomly assigned to each participant.
table summarizes the experiment design.
table experiment design class i class ii single file program without sbfl with sbfl multiple file program with sbfl without sbfl .
results and analysis in this section we will present our empirical results to address the three research questions4.
.
rq1 can mooctest benefit debugging?
to address this question we analyzed the task completion rate and completion time to measure the effectiveness and the efficiency of debugging respectively.
for each debugging task i.e.
to repair one program with or without the sbfl assistance completion rate rcis defined as sc sall where scis the number of participants who have successfully fixed the bug within the required timeframe andsallis the number of all participants involved in this task.
for each individual participant who has correctly fixed the bug within the required timeframe completion time tcrepresents the time cost for successfully repairing the program.
completion rate rc.
intuitively we were expecting that with the sbfl assistance groups a and b where the faulty statement has been successfully pinpointed in red with the highest saturation should have increased rc.
since group a has even better accuracy than group b the improvement of group a should be greater than that of group b. for groups c d e and f the improvement of rc if there is any should be smaller than those of groups a and b. figure demonstrates this comparison for each group where the results for groups a and b comply with our expectation that both of them have obvious improvement on rcwhen sbfl is switched on.
rcin groups a and b increase by .
and .
respectively which is also consistent with the intuition.
on the other hand for groups c d e and f which do not correctly pinpoint the fault the assistance from sbfl hardly shows any advantage groups e and f demonstrate similarrcof debugging with and without sbfl and groups c and d even have the rcdecrease with sbfl.
although we cannot foresee this result before the experiment the decreased rcis still understandable it is very likely that the bad sbfl results have side tracked programmers and hence brought in noise during the process.
concerning the comparison among groups c d e and f there is no obvious relationship observed.
groups c and d do not show any advantage over groups e and f which indicates that a small distance between the fault and its nearest highlighted statement seems not helpful to mitigate the difficulties in debugging with inaccurate fault localization results.
by viewing the comparison results of group c v.s.
group d and group e v.s.
group f data dependency between the faulty and the highlighted statements tends to be not useful either.
in summary it is reasonable to conclude that under certain conditions the sbfl assistance in mooctest does help to improve the completion rate.
one dominant factor is the hit value of 4all the raw data and analysis are available on 812comple g415on rate without sbfl with sbfl figure completion rate for each group of faulty programs the sbfl result only when the faulty statement is correctly pinpointed i.e.
ranked or tied at the top of the list does rc tend to increase with the sbfl assistance.
the low precision i.e.
many statements are tied at the top may slightly weaken this advantage while the small line distance and data dependency may not be able to compensate for the impact from the inaccurate localization results.
these observations verify the explanation for no impact from the accuracy and the feasibility of the suggested absolute ranking in .
therefore in the following discussion the six groups of faulty versions will be merged into two namely accurate group gaccwhere hit including groups a and b and inaccurate group ginwhere hit including groups c d e and f .
completion time tc.
in terms of the completion time we want to investigate whether mooctest can be helpful in decreasing the time cost to successfully fix a bug.
figure a demonstrates the comparison of average tcvalues.
the first and second bars are for gaccwithout and with sbfl respectively where the average tcwith sbfl .
sec is slightly longer than that without sbfl .
sec .
the third and fourth bars are for ginwithout and with the sbfl feature respectively where the average tcincreases by .
from the cases without sbfl .
sec to the cases with it .
sec .
if we compare the helpfulness of the sbfl feature between gaccandgin shown in the second and the fourth bars respectively it can be found that the average tcofgin is about .
higher than that of gacc.
however the average time cost of these two groups is actually very similar shown in the first and the third bars when debugging by hand.
these results imply that sbfl prolongs the debugging process especially in inaccurate cases.
single file programs accurate nosbflaccurate withsbflinaccurate nosbflinaccurate withsbfltime s a single file mul g415ple file programs accurate nosbflaccurate withsbflinaccurate nosbflinaccurate withsbfltime s b multiple file figure average completion time tc similar results can be concluded from the comparison among multiple file programs in figure b .
for gacc the sbfl fea ture helps to slightly reduce the average tc the first and the second bars .
regarding gin similar to the above results for the single file programs the average tcsignificantly increases by .
with the sbfl feature the third and the fourth bars .
our sample t tests both tailed and tailed shown in tables and further verify the above comparison5.
table t test on tcfor single file programs x y h0 h1 p v alue accept gacc nosbflgacc sbflx yx y .
h0 gin nosbflgin sbflx yx y .
h1 gacc sbflgin sbflx yx y .
h1 t able t test on tcfor multiple file programs x y h0 h1 p v alue accept gacc nosbflgacc sbflx yx y .
h0 gin nosbflgin sbflx yx y .
h1 gacc sbflgin sbflx yx y .
h0 in summary we can conclude that generally speaking sbfl may not be helpful in reducing the time cost of debugging even for those with accurate localization results.
concerning the cases which give inaccurate results sbfl may even lead to significant time increase.
these observations are surprisingly interesting and somehow counter to our intuition.
at first we conjectured that the longer average tcmay be caused by the increased rcwhich implies that some uncompleted debugging tasks become resolved with sbfl and these tasks normally require higher time cost.
however by viewing the detailed data we reckoned that the involved high time cost from these difficult tasks should not be the major contribution to the increase of average tcbecause actually there were only two groups of programs having increased rc while for the other four groups whose rcdecreased we still observed even more clearly increased tc in all groups including a and b not just the top high tcwith sbfl were higher than those without it the cases of low tchad a similar tendency.
therefore in order to find out the explanations we further investigated the following research questions.
.
rq2 is there any navigation pattern in sbfl assisted debugging?
in order to gain insight into what was happening during the sbflassisted debugging process and find the reason for the above observations we tracked and analyzed participants focus of attention from which two navigation patterns were observed as follows.
first scan pattern.
as introduced in section .
uwano et al.
identified a scan pattern in static code review where they found that the duration of scan presented a positive correlation with the efficiency of review.
this observation is reasonable since a careful scan shall give the reviewer a better understanding about the code and hence will be helpful in identifying the fault more quickly.
motivated by we are curious as to whether there also exists a similar scan pattern in debugging activities with sbfl.
5all hypothesis tests in this paper is set to be under the significant level of .
.
813dif ferent from in which eye movement was used to track reviewers focus of attention we used participants operations on the screen such as cursor movement mouse clicking file opening and code modification to achieve this goal.
in fact neither eye movements nor these operations can be precise to reflect a programmer s focus of attention.
however as shown in both psychology and computer human interaction studies operations such as cursor and mouse movements can be eligible surrogates with good practicality.
figures and give two sample navigation patterns on the source code without and with sbfl respectively where the horizontal axis records the elapsed time and the vertical axis indicates the code line.
the red dot line in figure only and the blue dashed lines in both figures and that run through the whole debugging process represent the statements colored as red with the highest saturation presented to programmers with the sbfl feature and the actual faulty locations hidden to programmers during the process respectively.
the black line segments record the duration of the programmer s focus on the corresponding code lines.
and the orange points on some black line segments indicate modifications on these lines by the programmer.
time s 1000line numbers0 figure code navigation without sbfl time s 1400line numbers0 figure code navigation with sbfl figure illustrates that debugging without sbfl has a similar pattern as static code review in which programmers normally have a first scan followed by several rounds of navigation along through all the code lines sequentially and finally reach a particular area and fix the bug.
for debugging with sbfl shown in figure the code navigation presents a different pat tern i.e.
programmers no longer iteratively follow the natural sequential order of the code lines.
instead they frequently switch their focus of attention between the red lines with the highest saturation and the others.
interestingly we have found that the first scan pattern seems to be preserved in debugging with sbfl although it becomes less obvious.
in the theory of sbfl programmers are expected to inspect the code lines along the given ranking list.
however we found that regardless of the accuracy of the sbfl results there was almost nobody who directly jumped into the red line with the highest saturation at their first visit on the code.
instead a first scan was performed which may not be on the entire code then was followed by the inspection of the red line with the highest saturation.
however the duration of this first scan varied across different participants some were longer while others could be very short such that only a few lines were skimmed within a short period of time as the one in figure circled in blue.
this observation is not surprising.
however we are more interested in whether the duration of this first scan denoted as t1 affects final debugging efficiency in the similar way that scan affects static code review .
different from we did not investigate the relationship between the absolute t1andtc the completion time .
instead we defined r1 t1 tcto evaluate the portion of the effort that a programmer put in his first scan out of his total effort in fixing the bug.
we wanted to investigate the impact of r1ontc for debugging with sbfl.
we defined for sbfl assisted debugging cases where r1 as short scan while cases where r1 as long scan .
as a consequence all participants debugging with sbfl can be split into two parts namely cases with short scan and with long scan .
for single file programs belonging to the inaccurate group gin t tests comparing tcamong debugging with long scan short scan and no sbfl assistance are presented in table .
table t test on tcfor different r1 gin x y h0 h1 p v alue accept sbfl longsbfl shortx yx y .
h1 nosbflsbfl shortx yx y .
h1 sbfl longnosbfl x yx y .
h0 t able shows that tcwith short scan tends to be significantly larger than those with long scan as well as those without sbfl while long scan and debugging without sbfl produce no significant difference on their tc.
this implies that among all the tcof sbfl assisted cases smaller ones i.e.
cases with higher debugging efficiency tend to appear with long scan while higher ones i.e.
cases with lower efficiency usually belong to debugging with short scan .
the increase on tcwith sbfl in ginis very likely due to the existence of many short scan cases.
on the other hand long scan could be helpful in reducing the gap between debugging with and without sbfl.
figure a depicts the consistent results on the average tcin a more vivid manner where the leftmost bar is for debugging without sbfl and the second third and fourth bars are for the sbfl assisted debugging in all cases short scan and long scan respectively.
the average tcfor debugging with short scan is about .
and .
higher than those for debugging with long scan and without sbfl respectively.
0inaccurate group nosbfl alltime s withsbfl all withsbfl short withsbfl long a gin 0accurate group nosbfl alltime s withsbfl all withsbfl short withsbfl long b gacc figure average tcwith different r1 and for gacc tailed t tests did not indicate any significant difference.
the p values for the same comparisons as rows in table become .
.
and .
respectively.
however the average tccomparison shown in figure b reveals some slight difference which is similar to gin but less obvious.
it can be found that for gacc the average tcfor short scan the third bar is about .
and .
higher than those for the long scan the fourth bar and debugging without sbfl the leftmost bar respectively.
similar results can also be found in multiple file programs.
in summary quickly focusing on the highlighted lines without sufficient first code scan could be harmful to the efficiency of debugging.
and the situation could be even worse when the sbfl results are inaccurate.
this observation is consistent with the one in .
this is most likely because regardless of sbfl assisted debugging or manual static code review the success of fault detection shall always eventually rely on human intelligence.
reading and comprehending the source code are inevitable to finally detect and correct the faults.
a more careful scan on the code will generally lead to a better understanding of the program and hence a more efficient debugging.
this observation makes us re examine the original motivation of sbfl one of whose goals is to help programmers quickly enter the most suspicious code area when given a program to debug.
however as discussed above the debugging process may not be accelerated in this way.
this will be further discussed in section .
follow up browsing pattern.
as shown in figure from the first visit on the red lines with the highest saturation to the completion of debugging participants tend to switch their focus of attention between the highlighted lines and the others.
however we also found that they actually spent most of the time outside rather than on the red lines with the highest saturation.
here we use single file programs as illustrations.
lett2denote the total time that a programmer spends on statements outside the red lines with the highest saturation after his first scan and r2denote t2 tc t1 .
figure gives the boxplot diagrams for the distribution of r2ingaccandgin.
in gin the right box about .
of the participants have an r2over and .
of the participants even have an r2 higher than .
the average r2is as high as .
.
for gaccin the left box the r2values are relatively lower.
however of the participants still have an r2over .
the average r2for the accurate group is .
.
in other words no matter whether or not the sbfl result is accurate programmers normally tend to spend most of their rest debugging time after the first scan outside the red lines with the highest saturation.
inaccurate sbfl results normally lead to more time cost outside the highlighted lines.
this phe0.
.
.
.
accurateinaccurate groupratefigure r2in the follow up browsing nomenon implies that no matter how precisely we pinpoint the buggy lines wasting time on a wider range of the source code is generally indispensable and even fundamental since it is helpful in comprehending the context.
obviously simply relying on the disjoint colored code lines cannot be helpful to collect such information.
this raises doubts about another goal of sbfl that is to pinpoint the most suspicious statements and make programmers concentrate on these risky lines without wasting time on other safe lines.
based on our observation even if we assumed that the lines outside the pinpointed ones were really safe there was still a large portion of time spent on these safe areas.
then does it mean that highlighting the risky code to save inspection efforts on those safe statements is infeasible during practical debugging activities?
again we will discuss this in section .
so far it seems that we have found some possible explanations to the decrease in debugging efficiency with sbfl.
in summary no matter whether programmers claim that they are reluctant to follow the sbfl results the colorization will affect their debugging behaviors more or less.
some may trust the sbfl result very much and would like to quickly start to check the pinpointed lines while others may not feel comfortable to check these lines until they have a longer scan and better understanding on the code.
generally speaking the former cases have shown an obvious harmfulness to the efficiency of debugging especially when provided with inaccurate sbfl results.
after the first visit on the pinpointed code lines programmers will switch their focus of attention between these lines and others.
most of their time has actually been spent outside these lines in order to comprehend the context and hence to detect and correct the fault.
as a consequence the critical factor that reduces the helpfulness of sbfl may not be the ones that we normally suspected such as the accuracy and reliability of sbfl results or people s being reluctant to follow the localization results.
the critical factor is most likely residing in the interference between the mechanism of automated fault localization and the actual assistance needed by programmers in debugging.
based on these observations we now delve further to investigate the impact from sbfl on fault comprehension and identification.
.
rq3 will sbfl affect fault detection?
it has been widely accepted by the sbfl research community that there is no perfect bug detection.
simple inspection of a fault is not sufficient for immediately detecting it i.e.
understand and identify the fault .
however there is a lack of evidence about whether sbfl has any impact on fault detection.
thus in this study we analyzed participants operation logs to address this question.
for both debugging with and without sbfl we counted the frequency of each participant s visits on the real faulty line without 815detecting it denoted as vf and the average duration of all his visits on the faulty line denoted as df .
figure a demonstrates the average vffor debugging on programs of gaccandgin without and with sbfl which confirms that regardless of the debugging method there is generally no perfect bug detection .
for the same debugging task debugging with sbfl tends to have a higher frequency for programs in gaccthe average vfwith sbfl the second bar is .
higher than that of debugging by hand the first bar .
when the sbfl is inaccurate gin this difference is as high as .
the third and the fourth bars for debugging without and with sbfl respectively .
these imply that when using sbfl programmers tend to revisit the bug more times in order to detect it.
average visi g415ng frequency accurate nosbflaccurate withsbflinaccurate nosbflinaccurate withsbflfrequency15 .
.
.
a average vf average visi g415ng dura g415on accurate nosbflaccurate withsbflinaccurate nosbflinaccurate withsbfltime s .
.
b average df figure fault revisit a similar tendency can be found on df shown in figure b .
forgacc the average dftends to be slightly longer when using sbfl .
sec in the second bar than by hand .
sec in the first bar .
similarly for gin the average dfwith sbfl the fourth bar is about sec longer than that without it .
sec in the third bar .
the above comparison results are consistent with the one in rq1 that debugging with sbfl is slower than debugging by hand.
with these results we now have more understanding about the average ability that people detect a fault and have learnt that the fault revisit frequency and the average duration on these visits may increase when the sbfl feature is switched on.
these phenomena appear to be more obvious when the sbfl result is inaccurate.
it is very likely because sbfl may confuse programmers in their code comprehension and slightly weaken their bug detection abilities.
.
threats to validity first we have used programmers operations such as cursor movement mouse clicking file opening and changing to represent their focus of attention on the code.
however this information may not always be precisely reflecting the real situation.
another way to achieve this goal is to use eye movement.
however as shown in previous studies both eye movement and operations contain noise and the latter one can be eligible surrogates with good practicality.
actually the operations may contain less noise than eye movement in our context.
based on our observation participants may randomly shift their eye attention to any place within or even outside the screen but not really for the purpose of inspecting the code.
for example they may frequently check the time especially when the minutes were about to run out.
on the other hand we observed that our participants always moved their cursor along each code line that they were inspecting.
therefore we feel that in our experiment tracking the operations may provide the data more closely approximate to the fact.
secondly although we recruited many more participants in our experiment than compared to prior work these participants were all students with very similar education background.
there were no professional programmers with industrial experience involved.however our debugging tasks were neither from industry projects nor involved any domain knowledge.
as a consequence these students should be eligible representatives in our experiment .
actually students may even provide more reliable results than volunteers from the industry because students participated in our experiment in the form of an examination which required them to concentrate.
besides these students from two classes have presented diverse java programming skills which can help to reduce the bias in our analysis.
the final threat to validity is in regards to the representativeness of the program subjects which were small size programs with seeded faults.
actually as discussed in section .
these programs should be suitable for our participants.
besides we have confirmed that the seeded faults did not include those too obvious or stupid such as a a bbeing mutated to a a. more importantly these programs did not involve any domain knowledge or advanced programming skills thus could be proper to investigate the impact from an sbfl tool and code comprehension.
as a reminder though we adopted both single file and multiple file programs to represent two levels of difficulty in debugging we actually did not observe much difference between these two types of programs.
thus in our future studies we will explore programs with more levels of debugging difficulty to investigate how different levels of difficulty affect the results.
.
insights and suggestions .
actual debugging process in section rq1 first reveals a decrease in the efficiency of debugging with sbfl.
by investigating rq2 and rq3 we have found some possible explanations.
on one hand by quickly entering the area of the suggested suspicious code a programmer may miss a good global understanding about the software.
he may have to waste more time to compensate for being unfamiliar with the source code.
concerning the cases where the suggestion is actually misleading even more extra efforts may be required.
in contrast a good first scan which has been regarded as an efficient pattern for programmers in static code review turns to be also essential in sbfl assisted debugging.
on the other hand continuously and exclusively focusing on the pinpointed code lines is generally unrealistic.
browsing the context is more necessary in detecting the fault.
moreover suggestions from sbfl may interfere with programmers fault detection.
these observations conflict with the motivation of automated fault localization which helps localize the most suspicious code and save the time that programmers waste on the irrelevant code.
it is generally believed that debugging involves fault localization denoted as ja as well as code comprehension and fault correction denoted as jb .
the total cost of debugging is decided by the costs of these two tasks.
automated fault localization aims to reduce the time cost and human involvement in jaby providing programmers with some suggested fault locations and expects that such saving can lead to the final improvement on the total debugging efficiency.
however this expectation has an assumption that jaandjbare independent and performed sequentially in debugging such that saving on jaby sbfl can lead to saving on the total cost.
but in practice these two tasks are tightly coupled and there is no clear boundary between them.
thus it could be very likely that saving on jahas some impact on jb such that final debugging efficiency is not changed as expected.
in the following two subsections we will discuss some possible solutions to the conflict between the motivation of automated debugging and the real life situation.
.2different fault localization techniques for different levels of debugging although there are some opinions that statistical fault localization such as sbfl may be helpful in small scale programs but not suitable for large scale systems where the small percentage of the to be inspected code will result in a large number of statements we are holding a different view.
based on the above analysis in section we conjecture that such automated debugging techniques are not actually helpful to smallscale programs where the fault localization is always performed on statement level.
in contrast these techniques may be useful in large scale systems however not for the purpose of locating the faulty statement but the faulty module .
these suggestions are not only because a coarser granularity can significantly reduce the absolute number of the to be inspected entities for large scale systems but are also supported by the following evidences.
fault may not be localizable in statement level.
thung et al.
observed that many real life faults span across multiple code lines some even involve multiple methods.
this fact makes locating a real life fault very difficult.
on the other hand we observed that it is unlikely that one fault could span across multiple modules.
in other words it is more feasible to locate a faulty module than to locate a faulty statement.
in locating the faulty statement for a unit program due to the nature of the control dependency it is impossible to always rank the faulty statement at top.
distributions of ep the number of passed test cases that cover the statement and ef the number of failed test cases that cover the statement could be very different in the entry statement a loop predicate a branch predicate an assignment statement and the exit statement and such difference is not controllable by test cases but due to the nature of their roles in the control flow graph.
any of these statements could be faulty thus a general method cannot guarantee to pinpoint the fault all the time.
in contrast the topological graph in high level of a large system could be different especially those following the principles of high cohesion and low coupling.
there are fewer tight control dependencies.
the distribution of epandefon these modules are relatively easier to control.
hence there is much higher chance to make an accurate diagnose .
due to the high cohesion a module is usually self descriptive.
for example it is very easy to understand the major functions of class postman in a postoffice system without learning too much about other classes especially when there are wellwritten javadoc.
but given a statement like for int i i n i nobody can comprehend it immediately.
as a consequence programmers can quickly focus on the pinpointed module to start identifying the fault.
the time saved by the fault localization technique has much higher chance to result in a total saving on the efficiency.
therefore we propose to first adopt statistical fault localization on large scale systems to isolate the suspicious module.
then for each suspicious module a more sophisticated method like program slicing is suggested which is not only more accurate but also informative for code comprehension.
.
improving the practicality based on the above discussion we now summarize our suggestions in improving the practicality of automated fault localization.
first apply the right technique on the right scenario.
as suggested above to achieve a better debugging performance a smart combination of various fault localization techniques is necessary.secondly accuracy still matters.
it is always important not to mislead programmers.
this can be done by designing better algorithms performing program refactoring or adjusting test suites .
some researchers also proposed to predicate the accuracy before really utilizing the localization results .
thirdly incorporate effective code comprehension assistance.
integration of automated debugging and code comprehension assistance shall be helpful to provide better practicality.
finally build a platform that can provide the features and information really needed by programmers in different scenarios.
.
conclusions and future works although not many studies in automated debugging have taken human factors into account it is undeniable that human involvement plays a critical role in this activity.
in this study we revisited the helpfulness of spectrum based fault localization by examining programmers actual performance in debugging with its assistance.
our experiment involving participants and debugging tasks indicated that an accurate localization result was helpful in terms of completing the debugging task.
however regardless of the accuracy sbfl was not helpful in terms of improving the efficiency of debugging.
and an inaccurate sbfl result may lead to an even longer debugging process.
to identify the reason we tracked and analyzed programmers focus of attention from which source code navigation patterns namely first scan and followup browsing and sbfl s impact on bug detection were identified.
we found that a slow and careful first scan that provides a better understanding about the code is favorable for a quicker debugging process browsing on the context of the pinpointed code is essential and a natural sequential code scan tends to be more efficient than an sbfl guided one in detecting a fault.
these observations reconfirmed the importance of code comprehension in automated debugging.
more importantly they indicated that the decrease in debugging efficiency was most likely due to the interference between the mechanism of automated fault localization and the actual assistance needed by programmers in debugging.
to resolve the interference we proposed a conjecture that it is not the problem of the technique itself.
instead it should be due to an inappropriate application of the technique.
and we further gave some suggestions on how to properly perform automated debugging in order to have an actual improvement on the efficiency.
in our future studies we will focus on improving the practicality of automated debugging from the suggested directions such as the applicability of a technique an integration of automated debugging and code comprehension assistance a better debugging platform etc.
and their actual helpfulness to programmers will be examined.
acknowledgment this work is partially supported by the national key basic research and development program of china program 2014cb340702 and the national natural science foundation of china grant no.
.
.