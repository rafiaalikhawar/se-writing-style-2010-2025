model based whitebox fuzzing for program binaries van thuan pham marcel b hme abhik roychoudhury school of computing national university of singapore singapore thuanpv marcel abhik comp.nus.edu.sg abstract many real world programs take highly structured and complex files as inputs.
the automated testing of such programs is non trivial.
if the test does not adhere to a specific file format the program returns a parser error.
for symbolic execution based whitebox fuzzing the corresponding error handling code becomes a significant time sink.
too much time is spent in the parser exploring too many paths leading to trivial parser errors.
naturally the time is better spent exploring the functional part of the program where failure with valid input exposes deep and real bugs in the program.
in this paper we suggest to leverage information about the file format and data chunks of existing valid files to swiftly carry the exploration beyond the parser code.
we call our approach modelbased whitebox fuzzing mowf because the file format input model of blackbox fuzzers can be exploited as a constraint on the vast input space to rule out most invalid inputs during path exploration in symbolic execution.
we evaluate on vulnerabilities in large program binaries with separate file formats and found that mowf exposes all vulnerabilities while both traditional whitebox fuzzing and model based blackbox fuzzing expose only less than half respectively.
our experiments also demonstrate that mowf exposes vulnerabilities without any seed inputs.
ccs concepts software and its engineering !software testing and debugging security and privacy !vulnerability scanners keywords symbolic execution program binaries .
introduction testing file processing programs can be challenging.
even though a structured file is stored as a vector of input bytes it is often parsed as a tree where data chunks contain fields and other data chunks.
our key insight is that certain branches in a file processing program are exercised only depending on i the presence of a specific data chunk ii a specific value of a data field in a data chunk or iii the integrity of the data chunks.
hence an efficient test generation technique not only sets specific values of the fields but also adds removes complete chunks and establishes their integrity e.g.
checksum or size .fuzzers help to test such file processing programs.
model based blackbox fuzzers mobf utilize input models to generate valid random files.
the input model specifies the format of the data chunks and integrity constraints.
however while valid the modification is still inherently random.
whitebox fuzzers wf employ symbolic execution to explore program paths more systematically.
given a valid file they can generate the specific values for the data fields quite comfortably.
however when it comes to adding or deleting data chunks or enforcing integrity constraints they are bogged down by the large search space of invalid inputs .
grammar based whitebox fuzzers gwf can generate files that are valid w.r.t.
a context free grammar .
like wf gwf computes path constraints logical formulas that are satisfied only by new files exercising alternative paths.
unlike wf these constraints are converted into regular expressions such that a context free constraint solver can generate an input that is accepted by both the grammar and the expression.
however the expression is much weaker than the path constraint.
suppose symbolic execution yields the path constraint x y .
after conversion the regular expression cannot capture that arithmetic constraint.
moreover gwf cannot encode integrity constraints such as size of offset of length of and checksums.
these integrity checks are very common in several highly structured file formats like png pdf and wa v .
in this work we present model based whitebox fuzzing mowf an automated testing technique for industrial size program binaries that process structured inputs.
mowf is a marriage of modelbased blackbox fuzzing and whitebox fuzzing that generates valid files efficiently that exercise critical target locations effectively.
it is adirected path exploration technique that prunes from the search space those paths that are exercised by invalid malformed inputs i mowf uses information about the file format to explore those branches that are exercised depending on the presence of specific chunks.
to this end mowf removes the referenced chunk or adds a new valid chunk by instantiation from the input model or a process we call data chunk transplantation mowf identifies the set of input bytes corresponding to the required chunk in a donor file and transplants them into the appropriate location of the receiving file.
ii mowf employs selective symbolic execution to explore those branches that are exercised depending on specific values of the data fields.
iii lastly mowf establishes the integrity of the generated files repairing checksums and offsets.
unlike mobf mowf is directed and enumerates the specific values of data fields more systematically.
unlike wf mowf does not get bogged down by the large search space of invalid inputs or require any seed inputs cf.
.
unlike gwf mowf maintains fullpath constraints so it has no impact on the soundness and completeness of wf.
moreover mowf leverages a more expressive yet simple input model to handle integrity constraints.
permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
copyrights for components of this work owned by others than acm must be honored.
abstracting with credit is permitted.
to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
request permissions from permissions acm.org.
ase september singapore singapore c acm.
... .
89504e470d0a1a0a 0000000d 7fffffff ba1bd884 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx width ihdr height others plte trns idat iend png data signature ... others figure the structure and the hex code of a png file.
a data chunk is a section in the hex code embedding one piece of information about the image.
the hex code above the light grey boxes identifies the data chunk type while the hex code above the dark grey boxes protects the correctness of the data chunk via checksum .
the input model is used to generate valid files efficiently enforce integrity constraints and facilitate the transplantation of data chunks.
since it only prunes search space the input model does not need to be complete.
on one hand whitebox fuzzing eventually constructs all relevant semi valid files by exploring paths that are not pruned by the input model.
on the other hand transplantating data chunks from donors maintains underspecified integrity constraints such as the concrete compression algorithm with which the image data in a png file must be encoded.
an input model is constructed once and can be used across all future testing sessions.
it has been shown that input models can also be derived in an automated fashion .
each of our input models was constructed manually in less than a day.
the two main challenges of traditional whitebox fuzzing twf that we address are path explosion .
parser code is often a large and very complex part of a program.
in practice twf gets bogged down by an exponential number of paths in the parser that are exercised by invalid inputs .
seed dependendence .
most twf approaches assume the existence of a seed file that features all necessary data chunks it is only a matter of setting the correct values for the data fields to expose an error.
in practice however this may not be the case.
data chunks may be missing or in the wrong order.
in other cases no seed files may be available at all.
the main contributions of mowf are as follows.
pruning invalid paths .
the input model allows to prune most paths that are exercised by invalid inputs.
as opposed to twf mowf is capable of negating those crucial branches that are exercised only in the presence of certain data chunks without having to iteratively construct the data chunk by exploring the parser code.
all generated test inputs are valid in that they adhere to the input model.
integrity constraints are enforced.
given a 24h time budget our mowf tool exposed all of thirteen vulnerabilities in our experimental subjects while the twf tool exposed only six.
reduced seed dependence .
the instantiation from the input model allows to construct seed inputs from scratch.
moreover given a seed input that is missing a data chunk to reach a target location mowf allows to utilize other seed files as donors transplant the missing data chunk and construct a new seed input that is closer to the target location.
in the absence of a donor the missing data chunk can be directly instantiated from the input model.
out of the thirteen vulnerabilities in our experimental subjects our mowf tool exposed nine without any seed inputs .
fuzzing tool .
we implement our mowf tool as an extension of the twf tool h ercules .
we compare our mowf tool not only to the h ercules twf but also to the p each model based blackbox fuzzer .
given a 24h time budget our mowf tool exposed all of vulnerabilities in our experimental subjects while the both h ercules and p each tool exposed only six.insights .
through our experiments we also gain insights about the relative strengths of our technique mowf symbolic execution based traditional whitebox fuzzing twf and model based blackbox fuzzing mobf as in fuzzers like peach spike .
twf performs well only if there exists a seed input that features all necessary data chunks and only certain values for data fields need to be set.
mobf performs well if the vulnerability is exposed by putting boundary values for certain data fields or by removing adding empty data chunks.
deep vulnerabilities that require specific values are best exposed by a symbolic execution based approach.
mowf performs well even in the absence of seed inputs and swiftly generates the specific values needed to expose even deep vulnerabilities while also gaining the capability to add and remove complete data chunks as in mobf.
.
overview .
motivating example we motivate mowf based on a real serious vulnerability in a library that is shipped with several browsers and media players.
libpng is the official png reference library it supports almost all png features and has been extensively tested for over years.
the library is integrated into popular programs such as vlc media player google chrome web brower and apple tv .
pngs consist of four mandatory and fourteen optional types of data chunks.
for easy parsing and error detection the file format requires to specify the size type and checksum of each data chunk besides the actual data.
the particular png file in figure happens to expose a memory access violation vulnerability osvdb95632 in vlc .
.
which uses libpng .
.
.
to trigger the bug the image width defined in the ihdr chunk must take a specific value from 0x7ffffff2 to0x7fffffff and the optional trns chunk must exist.
the trns chunk specifies alpha values to control the transparency of pixels in the image.
figure partially shows structure of a file that exposes the bug.
the first eight bytes identify the file as png.
the next four bytes specify the sizeof the next data chunk 0xd hex bytes followed by four bytes identifying the type of the chunk as ihdr light grey box .
the next bytes are data fields specifying image width and height.
this is followed by four bytes of checksum protecting the correctness of the ihdr chunk dark grey box .
the remaining chunks are structured similarly.
the image data in the idat chunk is compressed using the deflate compression algorithm and the end of the png file is indicated by iend chunk.
listing shows the pertinent code in libpng.
in each iteration png read info lines parses information about the current chunk like its size and type.
depending on the type it calls the corresponding function to handle the current chunk and validate the checksum.
these handler functions parse a chunk s data fields and store their values for further image transformation and processing steps.
the chunks are parsed until the first idat chunk is reached lines .
the file shown in figure passes all checks in the parser and chunk handling code and is therefore valid .
544fragment program v ah int 1ah mov ax dx mov dx cx mov cl shl dx cl mov bx ax mov cl file stitcher seed files initial file poolpotentially invalid files file repair fragment condition tainted by enum.
type?
program v ah int 1ah mov ax dx mov dx cx mov cl shl dx cl mov bx ax mov cl hercules smt solver ?
file stitcher file cracker existing initial symbolic input file poolpotentially invalid file valid symbolic input file input files file repair file cracker identify stitched files selective executed crucial ifssymb.
exec.
valid files .
add remove chunks .
explore data fields .
use as next seeds crash files figure model based whitebox fuzzing.
elements marked in grey are informed by the data model.
read chunks info before first idat chunk 2void png read info png structp ptr read and check the png file signature 5read sig f 6for get current chunk s information uint 32 length read chunk header ptr uint 32 chunk name ptr chunk name mandatory chunks if chunk name png ihdr handle ihdr ptr length else if chunk name png iend handle iend ptr length else if chunk name png plte handle plte ptr length else if chunk name png idat ptr idat size length break optional chunks else if ... else if chunk name png trns handle trns ptr length else if ... initialize row buffer for reading data from file 31void png read start row png structp ptr size t buf size ... buf size calculatebufsize ptr ptr row buf png malloc ptr buf size png memset ptr row buf ptr rowbytes listing simplified parser code for data chunks.
the code is shown to ease the explanation mowf works directly with program binaries.
when all other chunks have been parsed libpng starts reading pixel data from idat chunks.
for each image row libpng allocates and initializes a buffer lines in png read start row .
this is the faulty function.
specifically the existence of trns chunk and the improper validation of large image width leads to an integer overflow while libpng is calculating buffer size for each row as simplified in calculatebufsize at line .
because of that the allocated buffer is much smaller than required line .
as a consequence a buffer overflow occurs in png memset causing the program to crash.
notice that the third argument for the function call memset ptr!rowbytes is much larger than the size of the buffer.
.
exposing vulnerabilities .
.
traditional whitebox fuzzing given a benign png file having the required data chunks in figure and the dangerous location in png memset a whitebox fuzzing twf tool can automatically generate an input that exposes the vulnerability.
however suppose the benign file is missing the trns chunk it will be an obstacle for twf because it is very unlikely that twf can correctly synthesize the missing chunk and keep the file valid.
in fact if there is no trns chunk the true branch of the if statement in line of listing is not taken.
although twf can negate the branch and get a chunk with the name trns its size and content still adheres to specification of another chunk.
where libpng expects the size data and checksum of the new trns chunk it only finds random noise .
so twf overrides perfectly encoded image data only to spend substantial time constructing a valid trns chunk in its place.
since idat chunk is compulsory twf spends even more time navigating the space of invalid inputs to construct another idat chunk until it finally constructed a valid file that contains a valid trns chunk and all compulsory chunks where all integrity constraints are satisfied.
.
.
model based whitebox fuzzing we propose model based whitebox fuzzing mowf as a marriage of model based backbox fuzzing and whitebox fuzzing.
the model based approach allows mowf to cover the search space of valid test inputs efficiently while the whitebox approach in detail covers each subdomain more effectively.
both approaches are integrated in a feedback loop that is described in figure .
setup .
in this example the user provides the buggy vlc binary a crash report a set of existing benign png files if available and a png model as shown in listing .
to implement mowf we leverage a model based blackbox fuzzer.
the peach framework allows to specify a file format as peach pit .
it describes the types of and relationships size count offsets between data chunks and fields.
it also supports fixups and transformers.
fixups allow to repair related data fields such as checksums.
transformers are used for encoding decoding and compression.
the png peach pit in listing first specifies the generic data chunk lines .
png chunks all contain at least three data fields specifying the length type and checksum of the data chunk.
the other data chunks inherit these attributes lines fix the chunk type as enumerable ihdr plte trns .. and add further data fields.
the whole png file is specified last lines .
it starts with a specific magic number signature for png files followed by a header chunk ihdr and upto chunks in flexible order before ending up with an iend chunk.
datamodel name chunk number name length size relation type size of data number block name typedata blob name type length blob name data block number name crc size fixup class crc32fixup param name ref value typedata fixup number datamodel datamodel name chunk ihdr ref chunk block name typedata string name type value ihdr block name data number name width size number name height size ... block block datamodel ... datamodel name chunk trns ref chunk block name typedata string name type value trns blob name data block datamodel datamodel name png number name sig value 89504e... block name ihdr ref chunk ihdr choice name chunks maxoccurs block name plte ref chunk plte ... block name trns ref chunk trns block name idat ref chunk idat choice block name iend ref chunk iend datamodel listing png input model as peach pit given the setup to generate the crashing input in the motivating example mowf manages to i insert a trns chunk into proper position in a benign png file ii explore the paths affected by the existence of trns towards crash location and iii generate specific value for the image width data field in ihdr chunk.
this is achieved in four steps.
step .
seed selection and file cracking .
as shown in figure mowf first selects as initial input that file which is closest to a potential crash location.
all other png files are considered donors disassembled by the file cracker and added to the fragment pool .
file fragments can be transplanted into input files as needed.
if no initial files are provided mowf instantiates the initial input from the input model.
then mowf marks as symbolic all data fields which the user specified as modifiable .
only modifieable data fields are considered for the fuzzing.
in this example all data fields e.g.
image width are marked as modifiable except for the chunk s checksum and size.
the resulting hybrid symbolic png file i.e.
some parts are symbolic where others are concrete is then executed concolically by a traditional whitebox fuzzer.
step .
adding and removing data chunks .
certain branches in a file processing program are exercised only if a certain data chunk is absent or present.
to exercise these branches during path exploration mowf removes the specific chunk or adds a new one.
first in the execution of a given file f mowf identifies those crucial if statements ifs by their dependence on a data field in fof enumerable type.
in listing the ifs in lines can be considered crucial while none of the those inside the handle func tions are.
in our experiments we observe that such enumerables do often uniquely identify a data chunk s type.
first mowf identifies the input bytes in fthat influence the outcome of executed branch predicates using classical taint analysis .
in our example mowf determines the relationship between the input bytes above the grey boxes in figure and the ifs in listing .
then mowf learns the type of the referenced data field using the input model.
finally if the data field is of enumerable type and the ifis not already executed in both directions then the ifis considered crucial and mowf removes the corresponding data chunk or adds a new one through transplantation or instantiation from the input model.
once mowf identifies the type corresponding to the data chunk being removed or added the file stitcher coordinates the data chunk transplantation.
first the stitcher searches the fragment pool for candidate data chunks that are allowed according to the input model to be put at the same level as the chosen chunk in the current seed filef.
finally the file sticher uses the input model to identify the set of input bytes corresponding to each candidate data chunk in the pool and transplants them into the appropriate location of the receiving file fto generate a number of new seed files one for each chunk.
for our example in what follows we assume that the candidate containing the trns chunk is chosen next.
step .
changing data fields in inserted data chunk .
other branches in a file processing program are exercised only if specific values are set in the chunks data fields .
in our example the vulnerability is exposed only when the image width is in a range of certain values.
to exercise these branches by finding the specific values is the strength of whitebox fuzzing.
selective symbolic execution explores the local search space of semi valid inputs starting from the negated crucial branch.
this local search is very efficient when compared to classical twf.
during exploration any integrity check is identified and ignored.
the potentially invalid files are later fixed during the file repair .
once the target location is reached the whitebox fuzzer checks the satisfiability of the conjunction of path constraint and crash condition inferred from the given crash report or provided as output of static analysis tool .
if the conjunction is satisfiable the whitebox fuzzer generates a crashing input.
otherwise it uses the unsatisfiable core to guide the path exploration towards the crash location and does the check again.
step .
repeat.
data chunks can be nested in certain file formats such as wa v .
thus mowf uses the generated files as new seeds to continue the next iteration starting from step .
from the augmented seeds initial seeds new seeds mowf selects a file which is closest to the crash location and moves to next steps.
mowf executes selected file identifies crucial if statements transplants data chunks and continues path explorations.
summary.
in this motivating example mowf follows these four steps.
during concolic execution it identifies line listing as crucial if statement.
from the input model the file stitcher infers that a trns chunk is a candidate for transplantation and it is allowed after plte and before the idat chunk.
so file stitcher transplants a trns chunk from the fragment pool or directly instantiates a minimal trns chunk from the input model and places it right before idat chunk.
as a result the true branch of the ifstatement in line is taken and the trns chunk is parsed before further processing.
once the crash location is reached the image width dependent crash condition is checked and a png file is produced.
the resulting file is still invalid because the new value of image width invalidates the checksum of ihdr chunk.
so the file repair tool fixes the checksum and the vulnerability is exposed.
.
model based whitebox fuzzing algorithm gives an overview of the procedure of directed modelbased whitebox fuzzing.
it takes a program p an input modelm a set of target locations linp and seed inputs t. the objective of algorithm is to generate valid crashing files that exercise l. if no target is provided mowf uses static analysis to identify dangerous locations in the program such as locations for potential null pointer dereferences or divisions by zero line .
the algorithm uses the provided test cases tas seed inputs for the test generation.
however if no seed file is provided mowf leverages the input modelmto instantiate a seed file lines .
algorithm model based whitebox fuzzing input programp input modelm input initial test suite t targetsl output augmented test suite t0 ifl then l identify critical locations p end if ift then t instantiate asvalid input m t ftg end if while timeout not exceeded do target location l choose target l input file t choose best t l fragment pool filecracker t m crucial ifs detect crucial ifs t l p m for all do valid files t filestitcher t m for allt 2t that negate do hybrid file t mark symbolic vars t m files f path exploration t l l p for allf2fdo valid file f0 filerepair f m t t f0 end for end for end for end while t0 t the main loop of algorithm is shown in lines .
first mowf chooses the next target location l. if mowf works in crash reproduction mode lis the known crash location extracted from the given crash report.
otherwise lis picked if its average distance to all seed inputs in tis smallest.
the distance between an input tand a program location lis specified in definition .
second mowf chooses the next seed file taccording to a search strategy that seeks to generate the next input with a reduced distance to l line .
the remaining seed files are sent to the file cracker to construct the fragment pool in line .
the fragement pool takes a central role during data chunk transplantation.
definition input distance to location given an input t a programpand a program location linp.
let t be the set of nodes in the control flow graph cfg of pthat are exercised by t. the distance t l fromttolis the number of nodes on the shortest path from any b2 t tol.
next algorithm executes tonpto determine crucial ifs line .
as specified in definition a crucial ifis evaluated in different directions only depending on the type of the data chunkspresent int.
our implementation leverages mto identify crucial ifs by their dependence on a data field in tof enumerable type.
we observed that such enumerables do often uniquely identify a data chunk s type.
note that we ignore executed ifs negating which does not reduce the distance to the target location l. definition crucial if statement given input tfor programpand a target location linp an ifstatementbinpiscrucial if the statement bis executed by tinp only one direction of bhas been taken the negation of the branch condition at breduces the distance tol and let b be the branch condition at b the outcome of b depends on a field in tthat specifies the chunk s type.
for each crucial if thus identified algorithm employs the file stitcher to negate s branch condition lines .
for each stitched filet that successfully negates the algorithm executes selective symbolic execution followed by file repair to fine tune the specific values of the data chunks and reduce the distance to l lines .
more specifically it marks all modifiable data fields in t as symbolic and starts the directed path exploration lines .
during path exploration mowf does not collect integrity checks as branch constraints.
for instance a checksum check might not allow to change a data field which would otherwise lead to reducing the distance to l cf.
taintscope .
such integrity constraints are repaired in line .
whenever a potential dangerous location in lis reached mowf checks if the crash condition is satisfied and generates a crashing test case accordingly.
a detailed discussion of the procedures in algorithm is found in the following sections procedure discussion 2identify critical locations .
5instantiate asvalid input .
choose best .
filecracker .
detect crucial ifs .
filestitcher .
mark symbolic vars .
path exploration .
.
filerepair .
.
directed model based search in order to generate inputs that expose vulnerabilities mowf uses the initial seed inputs tto reduce the distance to the provided or identified critical location luntil it is reached and the crash condition is satisfied.
critical locations .
if no targets lare provided to the algorithm mowf identifies critical locations in the program p. acritical location is a program location that may expose a vulnerability if exercised by an appropriate input.
there are several methods to identify such critical locations .
in our implementation we use idapro to dissamble the program binary pand perform some lightweight analysis to identify instructions that conform to the patterns shown in listing .
these patterns partially cover program instructions that may trigger divide by zero and null pointer dereference vulnerabilities.
specifically we focus on division and memory move instructions taking registers or stack arguments as operands.
for those instructions the crash condition is obvious.
once a critical location is reached during concolic exploration we just check whether the value of register stack argument is zero in case it is concrete or can be zero in case it is symbolic .
div register div mov operand mov operand mov operand mov operand listing crash instruction templates model based search .
to generate input that reduces the distance tol mowf first chooses the seed input twith the least distance toland then identifies the executed crucial ifs lines in alg.
.
the task of the subsequent data chunk transplantation and instantiation will be to generate valid inputs that negate the branch conditions of .
while other implementations are possible we decided to implement a hill climbing algorithm.
our implementation of choose bestselects the input file t2tsuch that for selected location l2lwe have that the distance from ttol is minimal.
to detect crucial branches mowf first determines using taint analysis those input bytes in tthat may impact the outcome of some b2 t .
we recall that t is the set of nodes in the cfg of program pwhich are exercised by t. in our implementation of detect crucial ifs we leverage those capabilities in a symbolic execution tool hercules.
next mowf uses the cfg to compute the number of nodes on the shortest path between band locationl2l.
the negation of b may reduce the distance to l only ifbis in static backward slice of land the branch b0immediately following bdoes not have a smaller number of nodes on the shortest path between b0andl.
lastly mowf uses mto determine the data field corresponding to the identified input bytes and whether the data field specifies the chunk s type.
if all conditions specified in definition are met then bis marked as a crucial if and added to .
.
transplantation instantiation and repair file cracker .
file cracking refers to the process of interpreting valid files according to a provided input model i.e.
the peach pit file .
given the input model mand a valid file t2t the filecracker identifies all data chunks and their data fields in t. in model based blackbox fuzzers like peach fuzzer the valid input files are cracked and fuzzed independently.
however in mowf we crack all files and place their data components inside a fragment pool .
as a result we can consider all files and even the input model as donors for data transplantation.
by that mowf can generate more semi valid files and improve coverage.
file stitcher .
given a valid file tand the crucial if the objective of filestitcher is to negate and reduce the distance tolby adding or removing chunks from t. first the stitcher has to determine the chunk cintthat should be removed or before which a different chunk should be added in order to negate .
chunk cwas memorized previously when determining that the outcome of depends on the data field specifying c s type.
second the stitcher generates a new file by removing cfromtif allowed according to m. third for each chunk type cthat is allowed before cint i transplantation.
if there exists a chunk c0of typecin the pool copy the input bytes corresponding to c0from the donor file to the position before cin the receiving file t. ii instantiation .
otherwise use the specification of cinmas a template to generate the bytes for c0beforecint.
all files thus generated that actually negate will be used for the subsequent selective symbolic execution stage.
file repair .
given a file fand the input model m the file repair tool re establishes the integrity of the file.
our implementation utilizes the fixup and transformers that can be specified in min the peach framework.
.
selective and targeted symbolic execution we reuse the targeted search strategy for symbolic exploration implemented in hercules .
basically to mitigate the path explosion problem it enables fully symbolic reasoning only in some selected modules of interest i.e.
executable binaries like .exe and .dll files .
the list of selected modules can be inferred from the target module tm which contains the selected target location and a so called module dependency graph mdg .
the mdg is constructed by running the program under test with benign inputs and collecting the control transfer between program modules.
using the constructed mdg tm and all modules on paths from entry module main program to tm are selected to explore in fully symbolic execution mode.
the search strategy of hercules is targeted in the sense that it explores program paths towards a target location critical locations like crashing one by pruning irrelevant paths.
moreover hercules leverages the unsatisfiable core produced by a theory prover like z3 to guide the exploration.
.
handling incomplete memory modeling the memory models of symbolic execution engines like hercules klee or s2e do not support memory allocation with symbolic size.
if a symbolic size is given it is concretized before allocating heap memory.
the concretization mechanism could prevent us from exposing heap buffer overflow vulnerabilities.
suppose in the motivating example the image width of the benign png file is very small say and it is marked as symbolic.
in the processing code libpng needs to allocate a heap buffer having symbolic size that depends on width and other symbolic variables .
when the buffer is allocated width is bound inpc by the constraint on concretized value for allocated buffer size.
once the crash location e.g.
the instruction accessing the allocated heap buffer is reached hercules checks the satisfiablity of the conjunction between the current path constraint pc and the crash condition cc.
suppose that to satisfy the crash condition the image width must be large enough.
for the current file with the small image width the crash condition cc could contradict the path constraint pc pc cc is unsatisfiable.
usually based on the unsatisfiable core1ofpc cc hercules find a set of branches that can be negated to explore neighboring paths along which the crash condition ccmay be satisfiable.
however since width is already bound there exists no alternative path along which the crash conditioncccan be satisfied.
in our extension of hercules we leverage recent advances in maximal satisfication with z3 maxsmt .
using a whitelist our tool automatically marks certain clauses as soft clauses .
the satisfiability modulo theory smt solver z3 allows to generate an assignment to the symbolic variables as solution that satisfies the conjunction of all clauses but not necessarily the soft clauses.
specifically in our case we set all constraints in cc as hard clauses while specifying e.g.
constraints due to memory allocation inpcas soft clauses.
to identify which constraints in pccan be soft first we check whether the conjunction pc cc is unsatisfiable.
if so we extract all symbolic variables in cc.
thereafter we iterate through all constraints in pc and consider them as soft constraints accordingly if they contain any symbolic variable from cc.
after all these steps we get pc0 the updated pc and we send another query to maxsmt solver to check the maximum satisfiability of pc0 cc.
ifpc0 cc is satisfiable by possibly 1given an unsatisfiable boolean propositional formula in conjunctive normal form a minimal subset of clauses whose conjunction is still unsatisfiable is called an unsatisfiable core of the original formula.
548making one or more soft clauses in pc0as false we generate a input file as the solution to the constraint.
as an additional confirmation we validate the generated file by feeding it to the program binary and checking whether it crashes the program.
.
implementation file cracker file stitcher file repair hercules crucial ifs detector maxsmt interface pin tools profiling static analysis finding critical locations input model manipulation enhanced whitebox fuzzing figure components of our mowf tool our mowf tool is based on several third party tools and libraries.
we implemented our technique into the hercules directed symbolic execution engine which itself leverages s2e and the z3 satisfiability modulo theory constraint solver.
we also improved the accuracy of the taint analysis that is implemented inhercules .idapro and the intel dynamic binary instrumentation tool or pin tool were used for static analysis to find dangerous locations in the program code executing which might crash the program cf.
.
.
the pin tools were also used i for instruction profiling to generate the execution trace and compute the distance of the current seed input to the dangerous locations and ii for branch profiling to determine which crucial branches are explored.
the framework around the peach model based blackbox fuzzer allowed us to implement the input model based components such as file cracker file stitcher and file repair .
in fact the first was modified for our purposes and the latter two were implemented from scratch for instance to support data chunk transplantation.
.
experimental ev aluation we evaluated our mowf technique experimentally to answer the following research questions.
rq.
how many vulnerabilities are exposed by mowf compared to traditional whitebox fuzzing twf ?
rq.
how many vulnerabilities are exposed by mowf compared to model based blackbox fuzzing mobf ?
rq.
how many vulnerabilities are exposed by mowf if no initial seed inputs are available?
each technique was evaluated with a hour time budget.
.
experimental setup .
.
subjects we selected our subjects from a pool of well known program binaries of video players document readers music players and image editors which take a variety of complex file formats.
since hercules serves as a base line technique we also added all five subjects on which hercules was evaluated originally shown with grey background .
we also took the categories of vulnerabilities into consideration.
as shown in table we chose eight distinct real world applications some with different versions adobetable subject programs program version buggy module size errors video lan client .
.
libpng.dll kb video lan client .
.
libpng.dll kb libpng test program .
.
libpng.dll kb xnview .
xnview.exe .
mb adobe reader .
cooltype.dll .
mb windows media player .
quartz.dll .
mb real player sp .
realplay.exe kb midi player .
mamplayer.exe kb orbital viewer .
ov.exe kb total reader ar video lan client vlc windows media player wmp real player rp 4and music animation machine midi player mp xnview xnv libpng ltp 7and orbital viewer ov .
table shows not only the subjects and their versions but also the target buggy modules and their respective sizes.
in addition it features the number of known vulnerabilities that we sought to reproduce.
in one case xnview we started without any known vulnerabilities and looked for unknown ones.
in other cases although we targeted the known vulnerabilities we managed to discover new ones.
indeed our mowf tool reproduced successfully all known errors and discovered unknown errors in xnview and in windows media player see section .
.
.
.
input modeling todefine input models of five file formats pdf png midi flv and orb from scratch we utilized the modeling language of the peach model based blackbox fuzzer.
we augmented the input model for wa v files which is provided freely by peach fuzzer.
in particular we modeled one common image file png three audio and video files midi wa v and flv one portable document file pdf and one geometry file orb .
in table we report the size of the input models which are relatively small ranging from kb to kb.
it took us less than a day to write each model for a file format.
table information on the input models format size time spent files average size pdf .
kb hours kb png .
kb hours kb midi .
kb hours kb flv .
kb hours kb orb .
kb hours kb wa v .
kb hours kb .
.
initial seed files selection toselect the initial seed files we randomly downloaded files of the corresponding format from the internet except orb and png initial seed files.
the orb files were downloaded from software vendor s website9while png files were downloaded from the schaik online test suite.10the average size of seed files in each test suite is shown in the fifth column of table .
.
.
infrastructure we evaluated three tools our mowf tool the hercules traditional whitebox fuzzer twf and the peach model based blackbox fuzzer mobf .
for the experiments we used the community version of peach fuzzer which is provided with its source code.
both model based techniques used the same input models.
all subject programs were run on windows xp bit sp .
for each program each tool was configured for a timeout after hours of execution.
we conducted all experiments on a computer with a .
ghz intel core i7 cpu and gb of ram.
.
results and analysis table the vulnerabilities exposed by our mowf tool the hercules twf and the peach mobf.
vulnerabilities from thehercules benchmark are marked as grey.
program advisory id model files mowf mobf twf vlc .
.
osvdb png vlc .
.
cve png ltp .
.
cve png xnv .
unknown png xnv .
unknown png xnv .
unknown png wmp .
unknown wa v wmp .
cve wa v wmp .
cve midi ar .
cve pdf rp .
cve flv mp .
cve midi ov .
cve orb table shows the results in reproducing known vulnerabilities and finding unknown ones of the three compared techniques.
overall in the experiments our mowf tool outperforms both hercules andpeach .
while our mowf tool successfully generated crashinducing inputs neither hercules norpeach can produce half of them .
furthermore our mowf tool also found potential unknown vulnerabilities in windows media player and xnview.
indeed these vulnerabilities have previously not been reported at mitre12 osvdb13or exploit db.
.
in addition the power of our mowf tool is also demonstrated by its ability to expose different types of vulnerabilities including integer and buffer overflows null pointer dereference and divide by zero.
in the following sections we have an in depth analysis to answer the three research questions about the effectiveness and sensitivity of our approach.
rq.
versus traditional whitebox fuzzing our experiments confirm the observations that twf is unlikely to synthesize missing composite data chunks.
as in osvdb cve cve and unknown hercules cannot produce crash inputs to expose the vulnerabilities because they require the existence of optional composite data chunks.
in our experiments hercules gets stuck in synthesizing such required data chunks.
in particular the following requirments must be met to expose the vulnerabilities that are not in the hercules benchmark osvdb buffer overflow it requires a png file with a trns optional data chunk specifing either alpha values that are associated with palette entries for indexed colour images or a single to download.
colour for greyscale and truecolour images .
moreover the value of a data field image width in ihdr chunk the header chunk of png must be able to trigger an integer overflow in the libpng plugin in vlc .
.
.
cve buffer overflow it requires a png file with a text optional data chunk which stores text strings associated with the image such as an image description or copyright notice.
furthermore the length of the data chunk must be big enough to exceed the size of a heap buffer allocated for the image.
however it cannot be so huge that it prevents libpng from successfully allocating a heap buffer that is supposed to store the data in text chunk.
cve divide by zero they require a png file with a chrm optional data chunk.
the chrm specifies chromaticities of the red green and blue display primaries used in the image and the referenced white point.
second some data fields in chrm chunk must have specific values to trigger a divide by zero bug in the libpng library.
unknown memory read access violation they require png files having optional data chunks itxt ztxt or iccp accordingly which have no content.
that is the chunks that specify a size of zero followed by chunk name and checksum.
unknown divide by zero it requires a wa v file in which the format chunk contains an optional extra composite data field and one specific byte in the field is zero.
unlike hercules our mowf tool leverages the input models to transplant required data chunks from other files in the initial test suite or generate the chunks automatically from the input model.
hence our mowf tool can successfully produce crash inputs as witnesses for the seven vulnerabilites mentioned above.
since our mowf tool is an extension of hercules it can successfully reproduce all six vulnerabilites in the hercules benchmark.
as we will see for rq.
our mowf tool does not require seed inputs to reproduce three out of the six vulnerabilites in the hercules benchmark cve cve and cve because of its capability to generate semi valid files directly from input models.
rq2.
versus model based blackbox fuzzing thepeach model based blackbox fuzzer cannot expose half of the vulnerabilities that our mowf tool can expose see table .
we note that we conservatively assume that data chunk transplanation and instantiation is available in peach even though it is not.
it is worth mentioning that supporting transplanation and instantiation inpeach could be challenging.
in fact finding the correct chunk to transplant and transplanting it to the correct location in the seed input is subject to combinatorial explosion in an undirected fuzzing technique like peach .
in constrast mowf uses information about crucial ifs to direct the transplantation.
in the experiments we simulated peach s capability to do data chunk transplanation and instantiation by augmenting the set of all seed inputs where none contains the missing data chunk with at least one seed input where we manually transplanted the missing data chunk.
in table we indicate that peach with the simulated capability can expose three vulnerabilities unknown since these only require the existence of empty data optional chunks.
however for the remaining vulnerabilities the mobf tool peach cannot successfully expose of vulnerabilities even though we provide inputs with the required optional data chunks.
it is because of its limitation on generating specific values .
the reason lies with the inability of blackbox fuzzing to generate the specific values for data fields that would expose deep vulnerabili550ties.
for example given a byte integer data field the chance for a blackbox fuzzer to randomly mutate and get a specific value x is extremely small just only .
in contrast symbolic executionbased whitebox fuzzing is very good at finding such values.
meanwhile our mowf tool is an enhancement of twf by leveraging input models and can tackle both the missing data chunk problem and the limitation on generating specific input values.
as a result it can successfully produce test cases to expose all of the vulnerabilities.
rq3.
sensitivity to the initial test suite table vulnerabilities exposed by our mowf tool if no initial seed files are provided.
program advisory id model files mowf vlc .
.
osvdb png vlc .
.
cve png ltp .
.
cve png xnv .
unknown png xnv .
unknown png xnv .
unknown png wmp .
unknown wa v wmp .
cve wa v wmp .
cve midi ar .
cve pdf rp .
cve flv mp .
cve midi ov .
cve orb for this experiment we run our mowf tool with no initial seed inputs as shown in table .
by leveraging input models of png midi and orb for each file format our mowf automatically generates one minimal seed file.
in particular a minimal png file is an 1x1 image having four mandatory chunks ihdr plte idat and iend.
in case of midi it is a single track audio file with one header chunk mthd and one audio track chunk mtrk .
the minimal orb file contains all required properties for rendering an orbital object.
once the files are generated we run our mowf tool on all subjects listed in table .
the experiments show that with the minimal files our mowf tool can expose of vulnerabilities which can be revealed by png midi and orb files as reported in table .
it means that our mowf tool exposes vulnerabilites without any provided seed inputs providing evidence that mowf technique reduces the dependence of twf on selected seed inputs.
mowf does not succeed in exposing the vulnerabilities in of vulnerabilities because they require wa v flv and pdf files as inputs.
however our models for these file formats are still coarse.
although they are enough to allow mowf to work with given test suites they need to be more complete to support directly generating semi valid files.
since these file formats are complex on one hand we can spend more time to read and fully understand their specifications in order to augment the input models.
on the other hand we can reuse exhaustive models written by software vendors or the owners of file formats.
for instance according to a post at the official adobe blog 15developers at adobe system wrote their model for pdf file which was a proprietary format controlled by adobe until and used peach fuzzer to fuzz their most popular software adobe reader.
given such partially complete input models our mowf approach would complement mobf tool like peach fuzzer to maximize the utility of these models and hence expose more vulnerabilities.
threats to v alidity the main threat to external validity is the generality of our results.
mowf has been developed for real world program binaries that take complex program inputs.
we choose a variety of wellknown programs from different domains where specifications of the input models are available.
while for proprietary applications such format specifications might not be available we believe that grammar inference techniques can be a powerful tool to automatically derive the input model.
half of the vulnerabilities have already been picked in earlier work .
to showcase the effectiveness of mowf the other half has been chosen such that an optional data chunk is required to expose the vulnerability.
the main threat to internal validity is selection bias during the seed selection see table .
we chose the seed inputs either randomly from a benchmark or from the internet.
moreover our experiments confirm the reduced dependence on the available seed inputs.
the main threat to construct validity is the correctness of our implementation.
however our tool is an extension of both hercules and peach the two baselines for our evaluation.
so our tool inherits the incorrectness of the baseline.
.
related work the first automated testing technique for file processing programs fuzz was implemented in by miller et al.
to understand the reliability of unix tools.
since then fuzzing has evolved substantially become widely adopted into practice and exposed serious vulnerabilities in many important software programs.
a fuzzer quickly generates an excessive amount of program inputs in an attempt to make it crash.
today most compilers support to inject so called sanitizers during the compilation of the program under test.
a sanitizer is an automated oracle that can expose more intricate but serious software bugs such as buffer overflows data races and memory errors.
together fuzzers and the sanitizers allow the automated testing and exposing of deep and intricate software bugs in programs of any scale.
security sensitive programs are hardened in a feedback loop where a program is first sanitized then fuzzed the exposed errors fixed the patched version is fuzzed again and so on.
we can distinguish the more efficient blackbox techniques that generate test inputs without the analysis of the program source code and the more effective whitebox techniques that leverage program analysis to expose bugs hiding deeper in the source code of the program.
blackbox fuzzing .
programs processing simply structured plain text input can be fuzzed by random input generators like f uzz .
in fact random test generation can be a very efficient test generation technique .
however for programs processing highly structured input files like a pdf reader most random files are rejected as invalid.
hence model based blackbox fuzzing mobf tools utilize a user given input model to generate valid random files .
however due to the random choice of values for data fields mobf may still be ineffective in exposing more deeper errors in the program s functionality.
systematic path exploration to enumerate the specific values of a data field is significantly more effective.
traditional whitebox fuzzing seeks to explore alternative paths in the program by substituting input bytes in a given file with other values.
taint based whitebox fuzzing identifies those hot bytes in the input file that impact the value of a dangerous location like a divisor or system call.
fuzzing the 16see rq.
.
in section .
.
551hot bytes can reveal errors more quickly.
more effective symbolic execution based whitebox fuzzers substitute input bytes that impact the outcome of a branch with symbolic variables and employ symbolic execution to negate those branches.
checksum aware whitebox fuzzing attempts to identify checksum checks and circumvent them during whitebox fuzzing.
the check is identified as the first if statementsthat depends on many input bytes and is circumvented by removing sfrom the program.
to repair the generated malformed files the branch condition of sis computed in terms of the identified input bytes made symbolic.
however checksum aware whitebox fuzzing cannot solve any other integrity constraints like chunk size or offset.
throughout the paper we have shown the limitations of traditional whitebox fuzzing such as being bogged down by the large search space of invalid inputs and the dependence in seed files.
grammar based whitebox fuzzing gwf generates inputs that are valid w.r.t.
a context free grammar g. we use the example in listing for illustration.
1int i 2char input 3char getnexttoken return input 6bool issorted int prev digit if getnexttoken do char token getnexttoken if token continue if token return true int digit asint token if prev digit digit return false prev digit digit while true return false listing issorted returns true if the input is a sorted list of single digit numbers the context free grammar gmay be written as g !
numbers numbers !numbers numbers numbers !digit digit !0j1j2j3j4j5j6j7j8j9 which encodes that valid inputs start with an open curly bracket followed by a comma separated list of at least one digits and a closing curly bracket.
gwf encodes a path condition as regular expression.
for input gwf yields the following constraint rto explore the alternative branch where the input does not end in a curly bracket token token digit token token digit token where digit is a symbolic variable.
using a context free constraint solver it is possible to derive an array with three digits that is accepted by both gandr e.g.
.
however since the regular expression cannot express the arithmetic relationship between token 2and token i.e.
a completely different path might be exercised.
this renders gwf both unsound as well as incomplete.
in contrast mowf maintains path conditions as smt formulas and merely prunes paths that are exercised by inputs that are invalid w.r.t.
the input model.
moreover the context free languagewhich encodes the file format cannot express integrity constraints such as the checksum or the size of a data chunk.
functions computed over the data in a data field such as a compression algorithm cannot be expressed either.
our input models allow to specify integrity constraints and compression algorithms through the concept of fixups and transformers.
hybrid fuzzing .
driller combines the effectiveness of whitebox and the efficiency of blackbox fuzzing.
after running the blackbox fuzzer for some time the whitebox fuzzer is run on the most promising seed files produced by the blackbox fuzzer.
in contrast to mowf driller does not leverage information from an input model to generate more valid files.
driller does not primarily target such programs that process highly structured inputs.
in this respect our approache is orthogonal to driller.
driller can benefit from mowf when testing programs processing highly structured inputs.
.
discussion we introduced model based whitebox fuzzing mowf as an automated testing technique for program binaries that process highly structured inputs.
we have observed that certain branches in a fileprocessing program are exercised only depending on i the presence of a specific data chunk ii a specific value of a data field in a data chunk or iii the integrity of the data chunks.
hence we extend hercules an existing traditional whitebox fuzzing technique not only to set specific values of the fields but also to add remove complete chunks and re establish their integrity during fuzzing.
pruning invalid paths .
we discussed several approaches to prune the vast search space of invalid inputs including integrity enforcement and data chunk transplantation and instantiation.
as opposed to traditional whitebox fuzzing twf mowf is capable of negating those branches that are exercised only in the presence of certain data chunks without having to iteratively construct the data chunk by exploring the parser code.
all generated test inputs are valid in that they adhere to the input model.
integrity constraints are enforced.
given a 24hour time budget our mowf tool exposed all of thirteen vulnerabilities in our subject programs while the twf tool exposed only six.
reduced seed dependence .
we also investigated the dependence of mowf on the provided initial seed files.
mowf can instantiate the initial seed files directly from the provided input model.
moreover given a seed input that is missing a data chunk to reach a target location mowf allows to utilize other seed files as donors transplant the missing data chunk and construct a new seed input that is closer to the target location.
in the absence of a donor the missing data chunk can be directly instantiated from the input model.
out of the thirteen vulnerabilities in our experimental subjects our mowf tool exposed nine without any seed inputs .
in summary mowf is a promising fuzzing technique for program binaries that process highly structured input.
it is particularly helpful when no initial seed files are available that contain the required optional data chunks.
given the same time budget mowf can generate more valid test inputs which aids in exposing vulnerabilities that could not be exposed otherwise.
.