on the limits of mutation reduction strategies rahul gopinath oregon state university gopinath eecs.orst.edumohammad amin alipour oregon state university alipour eecs.orst.eduiftekhar ahmed oregon state university ahmedi onid.orst.edu carlos jensen oregon state university cjensen eecs.orst.edualex groce oregon state university agroce gmail.com abstract although mutation analysis is considered the best way to evaluate the effectiveness of a test suite hefty computational cost often limits its use.
to address this problem various mutation reduction strategies have been proposed allseeking to reduce the number of mutants while maintainingthe representativeness of an exhaustive mutation analysis.
while research has focused on the reduction achieved the effectiveness of these strategies in selecting representativemutants and the limits in so have not been investi gated either theoretically or empirically.
we investigate the practical limits to the effectiveness of mutation reduction strategies and provide a simple theoret ical framework for thinking about the absolute limits.
ourresults show that the limit in improvement of effectivenessover random sampling for real world open source programs i sam e a no fo n l y1 .
.
interestingly there is no limit to the improvement that can be made by addition of new mutation operators.
given that this is the maximum that can be achieved with perfect advance knowledge of mutation kills what can bepractically achieved may be much worse.
we conclude thatmore effort should be focused on enhancing mutations than removing operators in the name of selective mutation for questionable benefit.
categories and subject descriptors d. .
testinganddebuggingtesting tools keywords softwaretesting statisticalanalysis theoreticalanalysis mu tation analysis .
introduction the quality of software is a pressing concern for the software industry and is usually determined by comprehensivetesting.
however tests are themselves programs usually permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributedfor profit or commercial advantage and that copies bear this notice and the full cita tion on the first page.
copyrights for components of this work owned by others thanacm must be honored.
abstracting with credit is permitted.
to copy otherwise or re publish to post on servers or to redistribute to lists requires prior specific permissionand or a fee.
request permissions from permissions acm.org.
icse may austin tx usa acm.
isbn .
.
.
.
by human beings and their quality needs to be monitored to ensure that they in fact are useful in ensuring soft ware quality e.g.
it is important to determine if the tests are also a quality software system .
mutation analysis is currently the recommended method for evaluating the efficacy of a test suite.
it involvessystematictransformationofaprogramthroughthe introduction of small syntactical changes each of which is evaluated against the given test suite.
a mutant that can be distinguished from the original program by the test suiteis deemed to have been killedby the test suite and the ratio of all such mutants to the set of mutants identified by a test suite is its mutation kill score taken as an effectiveness measure of the test suite.
mutation analysis has been validated many times in the past.
andrews et al.
and more recently just et al.
found that faults generated through mutation analysis resemble real bugs their ease of detection is similar to that of real faults and most importantly for us a test suite seffectiveness against mutants is similar to its effectiveness against real faults.
however mutation analysis has failed to gain widespread adoption in software engineering practice due to its substantial computational requirements the number of mutantsgenerated needs to be many times the number of programtokens in order to achieve exhaustive coverage of even first order mutants involving one syntactic change at a time and each mutant needs to be evaluated by a potentially fulltest suite run.
a number of strategies have been proposedto deal with the computational cost of mutation analysis.
theseha v ebeenclassified orthogonallyinto do faster do smarter a n d do fewer approaches correspondingtowhether they improve the speed of execution of a single mutant parallelize the evaluation of mutants or reduce the number ofmutants evaluated.
a large number of do fewer strategies mutation reduction methods that seek to intelligently choose a smaller representative set of mutants to evaluate have been in vestigated in the past.
they are broadly divided into operator selection strategies which seek to identify the smallest subset of mutation operators that generate the most usefulmutants and strata sampling techniques which seek to identify groups of mutants that have high similar ity between them to reduce the number of mutants while maintaining representativeness and diversity .
even more complex methods using clustering static analysis and other intelligent techniques are under active research .
ieee acm 38th ieee international conference on software engineering these efforts raise an important question what is the actual effectiveness of a perfect mutation reduction strategy over the baseline random sampling given any arbitraryprogram?
we define the efficiency of a selection technique as the amount of reduction achieved and the effectiveness as the selection technique s ability to choose a representativereduced set of mutants that require as many test cases to kill as the original set of mutants.
the ratio of effectiveness of a technique to that of random sampling is taken as theutilityof the technique.
we approach these questions from two directions.
first we consider a simple theoretical framework in which to evaluate the improvement in effectiveness for the best mutation reduction possible using a few simplifying assumptions and given oracular knowledge of mutation kills.
thishelps set the base line.
second we empirically evaluatethe best mutation reduction possible for a large number ofprojects given post hoc that is oracular detection knowl edge.
this gives us practical and optimistic limits given common project characteristics.
our contributions are as follows we find a theoretical upper limit for the effectiveness of mutation reduction strategies of .
for a uni form distribution of mutants the distribution most favorable for random sampling.
we later show that for real world programs the impact of distribution is verysmall .
suggesting that uniform distribution isa reasonable approximation.
wefindanempiricalupperlimitforeffectivenessthroughtheevaluationofalargenumberofopensourceprojects which suggests a maximum practical utility of .
on average and for of projects a maximum util ity between .
and .
one sample u testp .
.
we show that even if we consider a set of mutants that are distinguished by at least by one test thus discounting the impact of skew in redundant mutants wecan expect a maximum utility of .
on average and for of projects a maximum utility between .
and .
one sample u test p .
.
what do our results mean for the future of mutation reduction strategies?
any advantage we gain over randomsampling is indeed an advantage however small.
however our understanding of mutant semiotics 2is as yet imperfect and insufficient to infer whether the kind of selection em ployed is advantageous.
in fact our current research shows that current operator selection strategies seldom provide any advantage over random sampling and even strata sampling based on program elements never achieves morethan a advantage over pure random sampling.
our re sults suggest that the effort spent towards improving mutant selection mechanisms should be carefully weighed against 1we use the non parametric mann whitney u testas it is more robust to normality assumption and to outliers.
we note that a t testalso gives similar results.
2here semiotics is the relation between a syntactic change and its semantic impact.the potential maximum utility and the risks associated with actually making things worse through biased sampling.
ourresearchisalsoanendorsementof theneed forfurther research into new mutators.
it suggests that addition of newmutators and then randomly sampling the same number ofmutantsasthatoftheoriginalset isonlysubjecttoasimilarmaximumdisadvantage .
.
.
upperlimitfor projects while having essentially no upper bound on advantage due to increase in effectiveness.
the asymmetry between improvement obtained by operator removal and operator addition is caused by the difference in population from which the random comparison sample is drawn.
for operator selection the perfect set remainingafter removal of operators is a subset of the original population.
since the random sample is drawn from the originalpopulation it can potentially contain a mutant from each strata in the perfect set.
for operator addition the newperfect set is a superset of the original population with asmany new strata as there are new mutants no bounds onthe number of new strata .
since the random sample is constructed from the original population it does not containthe newly added strata.
our results suggest a higher payoff in finding newer categoriesof mutations than in trying to reduce the mutation operators already available.
in the interests of easy replication our research is organized and reproducible using knitr.
the raw knitrsource of our paper along with the rdata set required to build the paper and the instructions to do so are available .
.
related work according to mathur the idea of mutation analysis was first proposed by richard lipton and formalized by demillo et al.
a practical implementation of mutation analysis was done by budd et al.
in .
mutationanalysissubsumesdifferentcoveragemeasures the faults produced are similar to real faults in terms of the errors produced and ease of detection .
just et al.
investigated the relation between mutation score and test case effectiveness using real bugs and foundthat the mutation score increased with effectiveness for of cases which was better than the reported for structural coverage.
performingamutationanalysisisusuallycostlyduetothe large number of test runs required for a full analysis .
there are several approaches to reducing the cost of mu tation analysis categorized by offutt and untch a s dofewer d osmarter and do faster.t h edo fewer approaches include selective mutation and mutant sampling while weak mutation parallelization of mutation analysis and space time trade offs are grouped under the umbrella ofdo smarter .f i n a l l y t h e do faster approaches include mutant schema generation code patching and other meth ods.
the idea of using only a subset of mutants was conceived along with mutation analysis itself.
budd and acree showed that even sampling approximates the full muta tionscorewith99 accuracy.
thisideawasfurtherexploredby mathur wong et al.
and offutt et al.
using mothra for fortran.
512a number of studies have looked at the relative merits of operator selection and random sampling criteria.
wong et al.
compared x selection of each mutant type with op erator selection using just two mutation operators and foundthat both achieved similar accuracy and reduction .mresa et al.
used the cost of detection as a means of operator selection.
they found that if a very high mutation score close to is required x selective mutation is better than operator selection and conversely for lowerscores operator selection would be better if the cost of de tecting mutants is considered.
zhang et al.
compared operator based mutant selection techniques to random sampling.
they found that noneof the selection techniques were superior to random sam pling.
they also found that uniform sampling is more effective for larger programs compared to strata sampling on operators and the reverse is true for smaller programs.
recently zhang et al.
confirmed that sampling as few as of mutants is sufficient for a very high correlation withthefullmutationscore withevenfewermutantshavinga good potential for retaining high accuracy.
they inves tigated eight sampling strategies on top of operator basedmutant selection and found that sampling strategies basedon program components methods in particular performedbest.
some studies have tried to find a set of sufficient mutation operators that reduce the cost of mutation but maintain correlation with the full mutation score.
offutt et al.
suggested an n selective approach with step by step removal of operators that produce the most numerous mutations.barbosa et al.
provided a set of guidelines for selecting such mutation operators.
namin et al.
f o r m u l a t e d the problem as a variable reduction problem and found thatjust out of operators in proteum were sufficient for accurate results.
using only the statement deletion operator was first suggested by untch who found that it had the highest correlation r .
with the full mutation score compared to other operator selection methods while generating the smallest number of mutants.
this was further reinforced bydeng et al.
who defined deletion for different languageelements and found that an accuracy of is achievedwhile reducing the number of mutants by .
a similar mutation reduction strategy is to cluster similar mutations together which has been attempted based on domain analysis and machine learning techniques based on graphs .
in operator and mutant subsumption operators or mutants that do not significantly differ from others are elimi nated.
kurtz et al.
found that a reduction of up to times can be achieved using subsumption alone even thoughthe result is based on an investigation of a single program cal.
research into subsumption of mutants also includes higher order mutants hom whereby multiple mutationsare introduced into the same set of mutants reducing thenumber of individual mutants by subsuming component mutants.
homs were investigated by jia et al.
who found that they can reduce the number of mutants by .
ammannetal.
observethatthesetofminimalmutants corresponding to a minimal test suite has the same cardi3the authors choose a random operator and then a mutant of that operator.
this is in effect strata sampling on operators given equal operator priority.nality as the test suite and provides a simple algorithm for finding both a minimal test suite and a correspondingminimal mutant set.
their work also suggests this minimalm u t a n ts e ta saw a yt oe v a l u a t et h eq u a l i t yo fam u t a t i o nreduction strategy.
finally ammann et al.
also found thatthe particular strategies examined are rather poor when itcomes to selecting representative mutants.
our work is anextension of ammann et al.
in that we provide a theoretical and empirical bound to the amount of improvementthat can be expected by anymutation reduction strategy.
in comparison with previous work our analysis is backed by theory and compares random sampling to thelimit of selection .
that is the results from our study are applicable to techniques such as clustering using static analy sis and even improved strata sampling techniques.
further we are the first to evaluate the effectiveness of non adequate test suites zhang et al.
evaluates only the predictive power of non adequate test suites not effectiveness .
finally previous research does not compare the effectiveness of the same number of mutants for sampling and operator selection but rather different operator selections with samples of increasing size such as etc.
we believe that practitioners will be more interested in comparingthe effectiveness achieved by the same numbers of mutants.
.
theoretical analysis the ideal outcome for a mutation reduction strategy is to findtheminimumsetofmutantsthatcanrepresentthecom plete set of mutants.
a mutation reduction strategy accomplishes this by identifying redundant mutants and grouping them together so that a single mutant is sufficient to rep resent the entire group.
the advantage of such a strategyover random sampling depends on two characteristics of the mutant population.
first it depends on the number of re dundant mutants in each group of such mutants.
random sampling works best when these groups have equal numbersof mutants in them uniform distribution while any otherdistribution of mutants skew results in lower effectiveness ofrandomsampling.
however thisdistributionisdependent on the program being evaluated.
since our goal is to findthe mean advantage for a perfect strategy for an arbitrary program we use the conservative distribution uniform ofmutants for our theoretical analysis we show later that the actual impact of this skew is less than for real world mutants .
the next consideration regards the minimum number of mutants required to represent the entire population of mutants.
if a mutant can be distinguished from another in terms of tests that detect it then we consider both to bedistinguishable from each other in terms of faults they represent and we pick a representative from each set of indis tinguishable mutants.
note that in the real world the population of distinguishable mutants is often larger than the minimum number of mutants required to select a minimum test suite 4able to kill the entire mutant population.
this is 4aminimum testsuitewithrespecttoasetofmutantsisthe smallest test suite that can kill all mutants in the set and aminimal test suite is a test suite from which no further tests can be removed without decreaseing mutation score.our approach tries to approximate the actual minimum test suite using the greedyalgorithm that has an approximation bound of k ln n where kis the true minimum and nis the number of elements.
since we have a strong bound on the 513because while some mutants are distinguishable from others in terms of tests that detect them there may not be anytest that uniquely kills them .
since this is external to the mutant population and also because such a minimum setof mutants does not represent the original population fully we can get away with a lower number only because the testsuiteisinadequate weassumethatdistinguishablemutants are uniquely identified by test cases.
we note however that having inadequate test suites favors random sampling and hence lowers the advantage for a perfect mutation reduc tion strategy because random sampling can now miss themutant without penalty.
we derive the limits of mutation reduction for this system using the best strategy possible g i v e no r a c u l a rk n o w l e d g eo fm u t a n tk i l l s .impact of deviations of parameters skew the presence of skew reduces the effectiveness of random sampling and hence increases the utility of the perfectstrategy.distinguishability any distinguishable mutant that is not chosen by the strategy due to not having a unique detectingtest case decreases the effectiveness of the selection strat egy decreasing its utility.
before establishing a theoretical framework for utility of mutation reduction strategies we must establish some ter minology for the original and reduced mutant sets and theirrelated test suites.
terminology l e t mand m strategydenote the original set of mutants and the reduced set of mutants respectively.
the mutants from mkilled by a test suite tare given by kill t m we use mkilledas an alias for kill t m .
similarly the tests in tthat kill mutants in mare given by cover t m .
kill t m m cover t m t the test suite tstrategycan kill all mutants in mstrategy.
that is kill tstrategy m strategy m strategy.i fi ti sm i n i mized with respect to the mutants of the strategy we denote it by tmin strategy.
two mutants mand m primeare distinguished if the tests that kill them are different cover t m negationslash cover t m prime .
we use muniq killedto denote the set of distinguished mutants from the original set such that m m prime mcover t m negationslash cover t m prime .
theutility ustrategy of a strategy is improvement in effectiveness due to using that strategy compared to the baseline the baseline is random sampling of the same number6 of mutants .
that is ustrategy vextendsingle vextendsingle vextendsingle vextendsingle vextendsinglekill tmin strategy m kill tmin random m vextendsingle vextendsingle vextendsingle vextendsingle vextendsingle approximation and since the algorithm is robust in practice we use the minimal computed by the greedyalgorithm as a proxy for the minimum test suite .
5consider the mutant test matrix implies the test kills the mutant .
while all the mutants are distinguishable just two test cases are sufficient tokill them all.
6for the rest of the paper we require that efficiency of random sampling is the same as that of the strategy it is com pared to i.e.
m strategy mrandom .note that tmin strategyis minimized over the mutants selected by the strategy and it is then applied against the full set of mutants m i nkill tmin strategy m .
this follows the traditional evaluation of effectiveness which goes as follows start with the original set of mutants and choose a subset of mutants according to the strategy.then select a minimized set of test cases that can kill allthe selected mutants.
this minimized test suite is evaluated against the full set of mutants.
if the mutation score obtained is greater than then the reduction is deemed tobe effective.
note that we compare this score against thescore of a random set of mutants of the same size in order to handle the case where the full suite itself is not mutation adequate or even close to adequate .
our utility answersthe question does this set of mutants better represent thetest adequacy criteria represented by the full set of mutantsthan a random sample of the same size and if so by how much?
the strategy that can select the perfect set of representative mutants the smallest set of mutants such that they have the same minimum test suite as the full set is called theperfect strategy with its utility denoted by u perfect7.
we now show how to derive an expression for the maximum uperfectfor the idealized system with the following restrictions.
.
weassumethatwehaveanequalnumberofredundant mutants for each distinguished mutant.
from here on we refer to a set of non distinguished mut a n t sa sastratum and the entire population is referred to as thestrata.
given any population of detected mutants the mutation reduction strategy should produce a set of mutants such that if a test suite can kill all of the reduced set the same test suite can kill all of the original mutantset remember that t strategyk i l l sa l lm u t a n t si n mstrategy .
hence kill tperfect m kill t m the quality of the test suite thus selected is dependent onthe number of unique mutants that we are able to sample.
since we have supposed a uniform distribution say we have xelements per stratum and total nmutants.
our sample size swould be p kwhere kis the number of strata p is the number of samples from each stratum and is a nat ural number i.e.
the sample would contain elements fromeach stratum and those would have equal representation.
note that there will be at least one sample and one strata i.e.
s .
since our strata are perfectly homogeneous by construction in practice p is sufficient for perfect representation and as we shall see below ensures maximal ad vantage over random sampling.
next we evaluate the number of different unique strata expected in a random sample of the same size s. letx ibe a random variable defined by xi braceleftbigg 1i f s t r a t a iappears in the sample 0o t h e r w i s e .
letxbe the number of unique strata in the sample which isgivenby x summationtextk i 1xi andtheexpectedvalueofx con7where unambiguous we shorten the subscript such as p forperfect a n drforrandom.
514sidering that all mutants have equal chance to be sampled is given by e x e k summationdisplay i 1xi k summationdisplay i 1e xi k e x1 next consider the probability that the mutant has beenselected where the sample size was s p k p x i parenleftbiggk k parenrightbiggpk the expectation of xi e x1 p xi hence the expected number of unique strata appearing ina random sample is k e x k k parenleftbiggk k parenrightbiggpk we already know that the number of uniquestrata appearing in each strata based sample is k because it is perfect so each strata is unique .
hence we compute the utility asthe difference divided by the baseline.
u max k parenleftbig k k parenleftbigk k parenrightbigpk parenrightbig k k parenleftbigk k parenrightbigpk k k pk this converges to8 lim k k k pk ep and has a maximum value when p .
umax e .
note that this is the meanimprovement expected over randomsamplingfor uniform distribution ofredundantmutants in strata and with oracular knowledge .
that is individ ual samples could still be arbitrarily advantageous after all the perfect strata sample itself is one potential random sample but on average this is the expected gain over random samples.
how do we interpret this result?
if you have a robust set of test cases that is able to uniquely identify distinguishable mutants then given an arbitrary program you can expect a perfect strategy to have at least a mean .
advantage over random sample of the same efficiency in terms of effectiveness.
however if the program produces redundant mutants that are skewed then the advantage of perfect strategy with oracular knowledge will increase depending on theamount of skew .
similarly if the tests are not sufficient to identify distinguishable mutants uniquely we can expect the advantage of the perfect strategy to decrease.
finally strategies can rarely be expected to come close to perfectionin terms of classifying mutants in terms of their behavior without post hoc knowledge of the kills.
hence the advan tage held by such a strategy would be much much lower or it may not even have an advantage .
8w h i l ew ec a ne x p e c tk to be finite for mutation testing we are looking at the maximum possible value for this expression.table pit mutation operators.
the operators were added or extended by us.
in remove negative sign from numbers rv mutate return values m mutate arithmetic operators vmc remove void method calls nc negate conditional statementscb modify boundaries in logical conditions i modify increment and decrement statements nmc remove non void method calls returning default value cc replace constructor calls returning null ic replace inline constants with default value ri remove increment and decrement statements emv replace member variable assignments with default value es modify switch statements rs replace switch labels with default thus removing them rc replace boolean conditions with true dc replace boolean conditions with false mutantsmutation scorelog10 tests .
.
.5projects figure distribution of number of mutants and test suites.
it shows that we have a reasonable non biased sample with both large programs with high mutation scores and also small low scoring projects.
.
empirical analysis the above analysis provides a theoretical framework for evaluating the advantage a sampling method can have over random sampling with a set of mutants and test suite constructed with simplifying assumptions.
it also gives us anexpected limit for how good these techniques could get for a uniform distribution of mutants.
however in practice itis unlikely that real test suites and mutant sets meet our assumptions.
what advantage can we expect to gain with real software systems even if we allow our hypothetical methodto make use of prior knowledge of the results of mutationanalysis?
to find out we examine a large set of real worldprograms and their test suites.
our selection of sample programs for this empirical study of the limits of mutation reduction was driven by a few over riding concerns.
our primary requirement was that our re sults should be as representative as possible of real worldprograms.
second we strove for a statistically significant result therefore reducing the number of variables present in the experiments for reduction of variability due to theirpresence.
we chose a large random sample of java projects from github 9and the apache software foundation that use the popular maven build system.
from an initial 800projects weeliminatedaggregateprojects andprojects without test suites which left us with projects.
out of 9github allows us access only a subset of projects using their search api.
we believe this should not confound our results.
515nmc rv ic dc nc rc vmc cc emv m cb i ri rs es in nmc rv ic dc nc rc vmc cc emv m cb i ri rs es in1 .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
figure subsumption rate between operators.
note that subsumption is not a symmetrical relation.
no operators come close to full subsumption.
this suggests that none of the operators studied are redundant .
these projects compiled common reasons for failure included unavailable dependencies compilation errors due tosyntax and bad configurations .
next projects that did notpass their own test suites were eliminated since the analysis requires a passing test suite.
tests that timed out forparticular mutants were assumed to have not detected the mutant.
the tests that completely failed to detect any ofthe mutants were eliminated as well as these were redun dant to our analysis.
we also removed all projects with trivial test suites leaving only those that had at least test cases.
this left us with projects.
the projects are g i v e ni nt a b l e .
we used pit for our analysis.
pit was extended to provideoperatorsthatitwaslacking acceptedintomainline .
wealsoensuredthatthefinaloperators w ere not redundant.
the redundancy matrix for the full operator set is given in figure .am u t a n t m1is deemed to subsume another say m2if any tests that kills m1is guaranteed to killm2.
this is extended to mutation operators whereby the fraction of mutants in o1killed by test cases that kills all mutants in o2istakenasthe degreeofsubsumptionof o1by o2.
the matrix shows that the maximum subsumption was just that is none of the operators were redundant.for a detailed description of each mutation operator pleaserefer to the pit documentation .
to remove the effects of random noise results for each criteria were averaged overten runs.
the mutation scores along with the sizes of test suites are given in figure .
it is of course possible that our results may be biased by the mutants that pit produces and it may be argued that the tool we use produces too many redundant mutants and hence the results may not be applicable to a better tool that reduces the redundancy of mutants.
to account for thisargument we run our experiment in two parts with similarprocedures but with different mutants.
for the first part we use the detected mutants from pit as is which provides uswith an upper bound that a practicing tester can expect totable the projects mutants and test suites pro je c t m mkilled muniq killed t tmin events .
annotation cli .
mercurial plugin .77fongo .
config magic .
clazz .
ognl .
java api wrapper .
webbit .
mgwt .
csv .
joda money .
mirror .
jdbi .
dbutils .
cli .
commons math1 l10n .02mp3agic .
asterisk java .
pipes .
hank .
java classmate .
betwixt .
cli2 .
jopt simple .
faunus .
beanutils2 .
primitives .
sandbox primitives .56validator .
xstream .
commons codec .
beanutils .
configuration .
collections .
jfreechart .
commons lang3 .
commons math1 .
jodatime .
experience now using an industry accepted tool.
for thesecond part we choose only distinguishable mutants from the original set of detected mutants.
what this does is toreduce the number of samples from each stratum to and hence eliminate the skew in mutant population.
note that this requires post hoc knowledge of mutant kills not justthat the mutants produce different failures but also thatavailable tests in the suite can distinguish between both and is the best one can do for the given projects to enhance the utility of any strategy against random sampling.
we provide results for both the practical and more theoreticallyinteresting distinguishable sets of mutants.
additionally incase adequacy has an impact we chose the projects that had plausible mutation adequate test suites and computed the possible advantage separately.
.
experiment o u rt a s ki st ofi n dt h e uperfectfor each project.
the requirements for a perfect strategy are simple .
the mutants should be representative of the full set.
that is kill tp m kill t m .
the mutants thus selected should be non redundant.
that is m mpkill tp m p m kill tp m p 516the minimal mutant set suggested by ammann et al.
s a t isfies our requirements for a perfect strategy since it is representative a test suite that can kill the minimal mutantscan kill the entire set of mutants and it is non redundantwith respect to the corresponding minimal test suite.
ammann et al.
observed that the cardinality of a minimal mutant set is the same as the cardinality of the corresponding minimal test suite.
that is m min perfect mint est t m tmin all finding the true minimal test suite for a set of mutants is np complete10.
the best possible approximation algorithm is chvatal s using a greedy algorithm where each iteration tries to choose a set that covers the largest number of mutants.
this is given in algorithm .
in the worst case i ft h en u m b e ro fm u t a n t si sn and the smallest test suite that can cover it is k this algorithm will achieve a k ln n approximation.
we note that this algorithm is robust inpractice and usually gets results close to the actual minimum k see figure .
further feige showed that this is the closest approximation ratio that an algorithm can reachf o rs e tc o v e rs ol o n ga snp negationslash p .
since it is an approximation we average the greedily estimated minimal test suite size over runs.
the variabilityi sg i v e ni nf i g u r e3 ordered by the size of minimal test suite.note that there is very little variability and the variabilitydecreases as the size of test suite increases.
all we need now is to find the effectiveness of random sampling for the same number of mutants as produced by the perfectstrategy.
algorithm finding the minimal test suite function mintest t ests mutants t t ests m kill t mutants tmin while t negationslash m negationslash do t random max t kill t m t t t m kill t mutants tmin tmin t end whilereturn t min end function next we randomly sample mmin perfect mutants from the original set mrandom obtain the minimal test suite of this sample tmin random and find the mutants from the original set that are killed by this test suite kill tmin random m which is used to compute the utility of perfect strategy with respectto that particular random sample.
the experiments were re10this is the set covering problem which is npcomplete .
11weavoidedthe reverse greedy algorithm givenbyammann et al.
for two reasons.
first while the approximation ratioofthe greedyalgorithmisatmost k ln n where kisthe actual minimum that of reverse greedy is much larger if any .
secondly the number of steps involved in reverse greedyismuchlargerthanin greedywhenthesizeofminimal set is very small compared to the full set.
we also verifiedthat the minimum frequency o fk i l l so ft h es e to fm u t a n t sb y the minimal test suite was .
a larger minimum frequency indicates that at least that many tests are redundant whichis a rare but well known problem with the greedyalgorithm.
projectsmintcmintc distribution figure variation of minimal test cases for each sample as a percentage difference from the mean ordered by mean minimal test suite size.
there is very little variation and the variation decreases with test suite size.
.
.
.
minimal test suite sizeutilitydetected mutants log10 .
.
.
.
figure the figure plots utility y axis against the average minimal test suite size log10 .
bubble size represents the magnitude of detected mutants log10 .
the figure suggests that there is no correlation between utility and average minimal test suite size.
peated times for each project and averaged to compute uperfectfor the project under consideration.
.
results .
all mutants our results are given in table .
we found that the largest utility achieved by the perfect strategy was .
for project faunus while the lowest utility was .
for projectjoda money.
the mean utility of the perfect strat .
.
.
number of detected mutantsutility minimal test suite log10 .
.
.
figure the figure plots utility y axis against the number of detected mutants.
bubble size represents the magnitude of average minimal test suite size log10 .
the figure suggests that there is no correlation between utility a n dn u m b e ro fd e t e c t e dm u t a n t s .
517table the maximum utility achievable by a perfect strategy for each project pro je c t kill t m kill tr m uperf events .
.
annotation cli .
.
mercurial plugin .
.
fongo .
.
config magic .
.
clazz .
.
ognl .
.
java api wrapper .
.
webbit .
.
mgwt .
.
csv .
.
joda money .
.
mirror .
.
jdbi .
.
dbutils .
.
cli .
.
commons math1 l10n .
.
mp3agic .
.
asterisk java .
.
pipes .
.
hank .
.
java classmate .
.
betwixt .
.
cli2 .
.
jopt simple .
.
faunus .
.
beanutils2 .
.
primitives .
.
sandbox primitives .
.
validator .
.
xstream .
.
commons codec .
.
beanutils .
.
configuration .
.
collections .
.
jfreechart .
.
commons lang3 .
.
commons math1 .
.
jodatime .
.16table the maximum utility achievable by a perfect strategy for each project using distinguishable mutants pro je c t kill t m kill tr m uperf events .
.
annotation cli .
.
mercurial plugin .
.
fongo .
.
config magic .
.
clazz .
.
ognl .
.
java api wrapper .
.
webbit .
.
mgwt .
.
csv .
.
joda money .
.
mirror .
.
jdbi .
.
dbutils .
.
cli .
.
commons math1 l10n .
.23mp3agic .
.
asterisk java .
.
pipes .
.
hank .
.
java classmate .
.
betwixt .
.
cli2 .
.
jopt simple .
.
faunus .
.
beanutils2 .
.
primitives .
.
sandbox primitives .
.
validator .
.
xstream .
.
commons codec .
.
beanutils .
.
configuration .
.
collections .
.
jfreechart .
.
commons lang3 .
.
commons math1 .
.
jodatime .
.
table the correlation of utility for all mutants killed mutants mutation score and minimal test suite size based on both full set of mutants and also considering only distinguished mutants r2 all r2 distinguished m .
.
mkill .
.
mkill m .
.
tmin .
.
egy was .
.
a one sample u testsuggests that of projectshavemaximumutilitybetween12.
and14.
p .
.
the distribution of utility for each project is captured in figure .
projects are sorted by average minimal test suite size.
one may wonder if the situation improves with either test suite size or project size.
we note that the utility u phas low correlation with total mutants detected mutants shown in figure5 mutationscore andminimaltestsuitesize shown in figure .
the correlation factors are given in table .
an analysis of variance anova to determine significant variables affecting uperfectsuggests that the variability due to project is a significant factor p .
and interactswith kill trandom m strongly.
up project kill tr m project kill tr m the variable projecthas a correlation of .
with the uperfect andthecombinedtermshaveacorrelationof0 .
with uperfect.
.
distinguishable mutants our results are given in table .
we found that the largest utility achieved by the perfect strategy was .
for project mercurial plugin while the lowest utility was .
for project joda money.
the mean utility of the perfect strategy was .
.
a one sample u testshowed that of projects have a maximum utility between .
and .
p .
.
the utility distribution for each project is captured in figure7.
the projects are sorted by the average minimal test suite size.
this situation does not change with either test suite or project size.
the utility u phas low correlation with total mutants detected mutants mutation score and minimal test suite size.
the correlation factors are given in table .
an analysis of variance anova to determine significant .
.
.
.
projectsmaximum utility red redutility distribution of all mutants figure using all mutants.
.
.
.
.
.
projectsmaximum utility red redutility distribution of distinguished mutants figure using distinguished mutants.
distribution of mean utility using distinguished mutants across projects.
the projects are ordered by the cardinality of mean minimal test suite.
the red line indicates the mean of all observations.
variables affecting uperfectfound that the variability due to project is a significant factor p .
and strongly interacts with kill trandom m .
up project kill tr m project kill tr m the variable projecthas a correlation of .
with the uperfect andthecombinedtermshaveacorrelationof0.
with uperfect.
.
adequate mutants finally one may ask if adequacy has an impact on the effectiveness of selection strategies.
following the industry practice of deeming well tested projects adequate after discounting equivalent mutants we chose large well tested projects that had at least mutants and a mutation score of at least in the range of similar studies above which were deemed adequate.
we evaluated theutility for configuration commons lang3 commons math1 jodatime and found that they have a mean maximum utility of .
.
these same projects have a distinguished meanmaximum utility of .
.
this suggests that adequacydoes not have a noticeable impact on the effectiveness of selection strategies.
.
discussion mutation analysis is an invaluable tool that is often difficult to use in practice due to hefty computational requirements.
there is ongoing and active research to remedy this situation using different mutation reduction strategies.
hence it is important to understand the amount by whichone can hope to improve upon the simplest baseline strategyfor reduction pure random sampling.
our theoretical analysis of a simple idealized system finds a mean improvement of .
over random sampling for amutation reduction strategy with oracular knowledge of mu tation kills given a uniform distribution of mutants.
this serves as an upper bound of what any known mutation re duction strategy could be expected to achieve under the assumption that the mutant distribution is reasonably closeto uniform .
ourempiricalanalysisusingalargenumberofopensource projects reveals that the practical limit is much lower however on average only .
for mutants produced by pit.even if we discount the effects of skew by using only distinguished mutants the potential improvement is restricted to17.
on average.
it is important to distinguish the different questions that the theory and empirical analysis tackle.
the theoreticallimit shows the best that can be done by a perfect mutationstrategy given the worst distribution of mutants one mayencounter.
on the other hand the empirical analysis findsthe average utility of a perfect strategy without regard to the distribution of mutants in different programs.
however given that the effects of skew were found to be rather weak only .
the theoretical bound is reasonable for the empirical question too.
the empirical upper bounds on gain in utility are surprisingly low and call into question the effort invested into improving mutation reduction strategies.
of course one canstill point out that random sampling is subject to the vagaries of chance as one can get arbitrarily good or bad samples.
however our results suggest that the variance of individual samples is rather low and the situation im proves quite a bit with larger projects e.g.
the varianceofcommons math1 is just .
.
hence the chances for really bad samples are very low in the case of projects largeenough to really need mutant reduction and drop quicklyas the number of test cases increases.
one may wonder if the adequacy of test suites has an impact but our analysis of projects with adequate test suites suggests that there isvery little difference due to adequacy u perfect .
.
in general using accepted standard practices for statisticalsampling to produce reasonably sized random mutant sam ples should be practically effective for avoiding unusually bad results due to random chance.
the added advantage is that random sampling is easy to implement and incursnegligible overhead.
we note that our framework is applicable not only to selective mutation but also to mutation implementors looking to add new mutators.
say a mutation implementor has a perfect set of mutation operators such that their current set of mutants does not have any redundant mutants practically infeasible given our shallow understanding of mutant semiotics .
even if we consider the addition of a new set of random mutants that do notimprove the mutation set at all in that they are redundant with respect to the original 519set rare in practice given that we are introducing new mutants the maximum disadvantage thus caused is boundedbyourlimit .
upperlimitfor95 ofprojects .
how ever at least a few of the new mutants can be expected toimprove the representativeness of a mutation set comparedto the possible faults.
since we can t bound the number ofdistinguishable mutants that may be introduced there is no upper bound for the maximum advantage gained by adding new mutation operators.
adding new operators is especiallyattractive in light of recent results showing classes of real faults that are not coupled to any of the operators currentlyin common use .
our previous research suggests that a constant number of mutants a theoretical maximum of and inpracticefor1 accuracy issufficientforcomputingmutation score with high accuracy irrespective of the total number of mutants.
this suggests that sampling will lead to neither loss of effectiveness nor loss of accuracy and henceaddition of new mutation operators and sampling the re quired number of mutants is potentially a very fruitful endeavour.
.
threats to v alidity while we have taken care to ensure that our results are unbiased and have tried to eliminate the effects of randomnoise.
random noise can result from non representative choise of project tool or language and can lead to skewedstrata and bias in empirical result.
our results are subjectto the following threats.
threats due to approximation we use the greedy algorithm due to chvatal for approximating the minimum test suite size.
while this is guaranteed to be h m a p proximate there is still some scope for error.
we guard against this error by taking the average of runs for each observation.
secondly we used random samples to evaluate the effectiveness of random sampling.
while we have used100 trials each for each observation the possibility of biasdoes exist.
threats due to sampling bias to ensure representativeness of our samples we opted to use search results from the github repository of java projects that use the maven build system.
we picked allprojects that we could retrieve given the github api and selected from these only based on constraints of building and testing.
however our sample of programs could be biased by skew in the projects returned by github.
bias due to tool used for our study we relied on pit.
we have done our best to extend pit to provide a reason ably sufficient set of mutation operators ensuring also thatthemutationoperatorsarenon redundant.
further wehavetried to minimize the impact of redundancy by consideringthe effect of distinguished mutants.
there is still a possibility that the kind of mutants produced may be skewed which may impact our analysis.
hence this study needs tobe repeated with mutants from diverse tools and projects infuture.
.
conclusion our research suggests that blind random sampling of mutants is highly effective compared to the best achievableboundformutationreductionstrategies usingperfectknowledge of mutation analysis results and there is surprisinglylittle room for improvement.
previous researchers showed that there is very little advantage to currentoperator selection strategies compared to random sampling .
however the experiment lacked direct comparison with random sampling of the samenumber of mutants.
secondly it was also shown that currentstrategies fare poorly when compared to the actual minimum mutant set but lacked comparison to random sampling.
our contribution is to show that there is a theoretical limit to the improvement that any reduction strategy can have irrespective of the intelligence of the strategy and also a directempirical comparison of effectiveness of the best strategy possible with random sam pling.
our theoretical investigation suggests a mean advantage of58 .
foraperfectmutationreductionstrategywithoracular knowledge of kills over random sampling given an arbi trary program under the assumption of no skew in redundant mutants.
empirically we find a much lower advan tage .
for a perfect reduction strategy with oracular knowledge.
even if we eliminate the effects of skew in redun dant mutant population by considering only distinguished mutants we find that the advantage of a perfect mutation reduction strategy is only .
in comparison to randomsampling.
the low impact of skew .
suggests that our simplifying assumptions for theoretical analysis were not very far off the mark.
the disparity between the theoreticalprediction and empirical results is due to the inadequaciesof real world test suites resulting in a much smaller minimum mutant set than the distinguishable mutant set.
we note that mutation reduction strategies routinely claim highreduction factors and one might expect a similar magnitude of utility over random sampling which fails to materialize either in theory or practice.
thesecondtakeawayfromourresearchisthataresearcher or an implementor of mutation testing tools should consider the value of implementing a mutation reduction strategy carefully given the limited utility we observe.
in fact ourresearch suggests that popular operator selection strategies we examined have reduced utility compared to randomsampling andevenstratasamplingtechniquesbasedonprogram elements seldom exceed a improvement.
given that the variability due to projects is significant a testingpractitioner would also do well to consider whether the mutation reduction strategy being used is suited for the particular system under test perhaps based on historical data for that project or projects that are in some established sense similar .
random sampling of mutants is not extremely farfrom an empirical upper bound on an ideal mutation reduction strategy and has the advantage of having little room for an unanticipated bias due to a clever selection method that might not work well for a given project.
the limit re ported here is based on using full knowledge of the mutation kill matrix which is to say the least difficult to attain in practice.
perhaps the most important takeaway from our research is that it is possible to improve the effectiveness of mutationanalysis not by removing mutation operators but ratherby further research into newer mutation operators or new categories of mutation operators such as domain specific operators for concurrency or resource allocation .
our researchsuggests that the maximum reduction in utility due to ad dition of newer operators is just .
while there is no limit to the achievable improvement.
.