ocelot a search based test data generation tool for c simone scalabrino university of molise pesche italygiovanni grano university of zurich zurich switzerlanddario di nucci vrije universiteit brussel brussels belgium michele guerra university of molise pesche italyandrea de lucia university of salerno salerno italyharald c. gall university of zurich zurich switzerland rocco oliveto university of molise pesche italy abstract automaticallygeneratingtestcasesplaysanimportantroletoreduce the time spent by developers during the testing phase.
in last years severalapproacheshavebeenproposedtotacklesuchaproblem amongst others search based techniques have been shown to be particularly promising.
in this paper we describe ocelot a search based tool for the automatic generation of test cases in c.ocelotallowspractitioners towriteskeletonsof testcasesfor theirprogramsandresearcherstoeasilyimplementandexperiment new approaches for automatic test data generation.
we show that ocelotachievesahighercoveragecomparedtoacompetitivetool in of the cases.
ocelot is publicly available to support both researchers and practitioners.
ccs concepts software and its engineering maintaining software search based software engineering keywords automated testing test case generation search based software engineering acm reference format simonescalabrino giovannigrano dariodinucci micheleguerra andrea de lucia harald c. gall and rocco oliveto.
.
ocelot a searchbased test data generation tool for c. in proceedings of the 33rd acm ieeeinternationalconferenceonautomatedsoftwareengineering ase september montpellier france.
acm new york ny usa 4pages.
introduction software testing and in particular test case writing is one ofthemosthuman intensiveandtime consumingactivitiesinsoftware development life cycle .
therefore noticeable effort has permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation on the first page.
copyrights for components of this work owned by others than acmmustbehonored.abstractingwithcreditispermitted.tocopyotherwise orrepublish topostonserversortoredistributetolists requirespriorspecificpermissionand ora fee.
request permissions from permissions acm.org.
ase september montpellier france association for computing machinery.
acm isbn ... .
possibly combining approaches like random testing symbolic and concolic execution .
search based approaches have also been proved to be particularly well suited .
while many search based tools are nowadays available for java some of which very mature and used in practice e.g.
evosuite the same is not true for c. indeed the tools developed in the past like testgen quest and gadget are quite dated and not available neither as executable binaries .
to thebestofourknowledge themostrecentsearch basedtoolsfor test data generation in c are i iguana proposed by mcminn developed in java and relying on jni to interface with c ii austin introduced by lakhotia et al.
developed in ocaml andbasedonthecilframework1 iii cavm recentlyproposedby kimetal.
developedinc c andpythonandbasedonclang and gcc for source code instrumentation.
considering that both iguanaandcavmarenotpubliclyreleased theonlyavailable toolfortest datagenerationincisaustin.however despitebeing open source2 this project is not active anymore.
in summary c remainsawidelyusedlanguage ranked2ndinthetiobeindexfor may20183 and forthisreason webelievethatthesearch based researchcommunityshouldputsomeeffortintoactivelydeveloping test data generation tool for this programming language.
in thispaper we takea step insuch adirection and wepresent ocelot asearch basedtest datagenerationtoolforcthatprovides anextensibleframeworktoquicklyimplementdifferenttypesof search basedapproaches.ocelotisalsoabletoautomaticallywrite test suites relying on the libcheck framework4.
we empirically evaluate ocelot with respect to austin on functions from 3open source c programs and we show that ocelot achieves ahigher branch coverage in of the cases.
ocelot is publicly available5along with its documentation6.
background in the context of white box coverage driven testing the automatic test datagenerationconsistsofthegenerationofa possiblyminimal set of inputs td for a given target program pto reach a desiredamountofcodecoverage e.g.
branchcoverage .toachieve thisgoal asearch basedtest datagenerator tdg usesasearch authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
ase september montpellier france scalabrino grano di nucci guerra de lucia gall and oliveto minimize writeinstrument wrap make le compilegenerate input execute simulate evaluate source test suite jni library con guration figure the workflow of ocelot algorithm calling pwith many combinations of inputs test data with the aim of maximizing thetotal achieved coverage.
this process continues until the specified search budget e.g.
number of iterations isover.therefore generatingtestdatarequiresacontinuousinteractionbetweenthetargetprogramandthetest data generator.
when tdgcallspwith a given input phas to provide feedback about the branches covered with that input to tdg.
since cis aprocedural programminglanguage it ispossible to considerfunctions asthe unitsto test p .
thismakestest generation conceptually different compared to object oriented languages e.g.
java where the units to test are classes with a state .
furthermore automatically generating test data for c presents unique technical challenges.
the main technical challenge c1 is theinstrumentation ofp necessaryto registerwhathappensin pwhen tdgtests a specific input.
indeed the object language of c dependsonthetargetarchitectureanditisnecessarytofindaway to instrument p without tying to a specific architecture operating system to grant a certain level of portability.
a second technical challenge c2 regardsthe integration betweentdgandp i.e.
the instrumented p .
it is necessary todevise a mechanism to i make the input generated by tdgsuitable for p and ii to make p able to communicate with tdg.
a final major research and technical challenge c3 regards one of the main peculiarities of c i.e.
pointers.
consider a function that takes as input int a int b .
at somepointinthefunction thereisacondition if a b .a test datageneratorshouldbeabletogeneratetestdatathatevaluate such a condition as true.
while java has a more rigid and implicit typingrule i.e.
objectsarestoredasreferences primitivetypesare storesbyvalues incitispossibletohavemixedsituations that makes handling data types in tdgmore difficult.
ocelot the architecture of ocelot is inspired by iguana it is developedinjavaandusesjniasinterfacewiththetargetprogram to try different combinations of test data.
running ocelot consistsoftwodistinctmacro phases buildandrun.figure 1shows the phases of test data generation in ocelot.
in the buildphase thetargetprogramisinstrumented wrappedinajnilibraryand thencompiled.theoutputofsuchaphaseisastatic library.this library is linked by ocelot and used in the runphase where a search based algorithm is exploited to identify a set of inputs that maximizethecodecoverage.theoutputofthisphaseisasetoftest datathatcanbeusedtotestthetargetprogram.ocelotalsoprovidestwoadditionaloptionalphases minimize andwrite.during theminimize phase test data that do not contribute to improve thecodecoverageareremoved whileduringthe writephase skeletons of actual test cases are written.
such skeletons lack the assertions thatshouldbemanuallyadded andtheyarebasedonthelibcheck framework.
.
build phase thebuildphaseconsistsof i instrumenting thetargetprogram i.e.
transforming ptop ii wrapping it in the jni library iii generatingthemakefile andiv compiling thestaticlibrary.ocelotdirectly instruments the c source code making it able to potentially work regardless of the target architecture.
specifically it adds probes nearthecontrolstructurestotracktheexactstepsexecutedin p. existent tools e.g.
gcovorlcov are not used since they do not report the runtime values of the variables needed to compute part of thefitness functionfor someapproaches.
duringthe wrapping sub phase ocelot adds to the target function a set of pre defined c functions to integrate p in ocelot through jni.
moreover it adapts some of those files to handle the specific inputs requiredby p. indeed while the static java interface to call premains the same eachtargetfunctionhasitsowninputtypes.the wrapping sub phasehandlestheinformationthatwillbepassedbyocelot during the runphase and translate it into actual c variables that will be passed to p for the execution.
finally ocelot generates themakefile dependingontheoperatingsystemandonthespecial requirements of the target program and it compilesthe jni library.
.
run phase therunphase consists of i generating inputs for p ii calling the jni interface to executethe code iii grabbing the execution events andsimulating themonthecontrolflowgraphof p andiv evaluatingthe inputs and giving feedback to generate other inputs.
the input generation and the feedback mechanism strongly depend onthespecifictest datagenerationstrategyused.forexample a strategy based on random search would randomly generate inputs and ignore the evaluation adding all the generated test data to the resultingtestsuite.ontheotherhand the execution andsimulation sub phases are common to all the strategies.
after the execution ofp alist ofevents i.e.
the actual evaluationsof conditionsand fitness function is generated.
such a list is used to simulatethe eventsonthecontrolflowgraphof ptoeasilycomputethefitness function necessary to give feedback to the strategy.
.
features ocelotprovidessomeadditionalfeaturescomparedtothestateof the art tools.
first of all it implements different search based authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
ocelot a search based test data generation tool for c ase september montpellier france figure the clion plugin configuration for ocelot approaches and it is easily extensible.
indeed ocelot is not tied to anyspecificapproach.itimplementslips mosa avm and the random approach while for instance cavm is only based on avm while austin implements avm and avm .furthermore itsupportsdifferentbudget handlingand minimization strategies that can be combined together with the aforementioned algorithms.
thus ocelot is not designed to work only with a specific type of algorithm and therefore it is easily extensiblewithnewtest datagenerationstrategies.withrespectto othertools e.g.
austin ocelotisbasedoneclipsecdt7.hence itisabletoautomaticallydetectthedatatypesoftheparameters and to fully instrument code.
ocelotstronglyreliesonaconfigurationfile inwhichallthe parametersforallthephaseshavetobespecified.forexample thisfilecontainsthemaximumnumberofevaluations thedesiredtarget coverage the name of the target function the path to the file with the target function and so on.
since there are many parametersthat can be set we also developed a user interface for ocelot implemented in a clion8plugin.
this plugin allows developers to easily use ocelot for their projects.
while as previously stated thecommandlineallowstomakeexperiments theclionplugin is focused on practitioners and therefore it supports by defaultthewritemode able to generate skeletons of test cases.
it adds a configuration page for ocelot in the general configuration ofclion.
moreover it introduces an item in the code menu i.e.
generate tc .
when clicking on this item the plugin shows a window with all the functions of the current files for which the developercouldgeneratetest data.finally thepluginautomatically recognizes the signature of each function allowing the users to specify for each parameter the ranges of possible values.
figure shows the ocelot configuration window in clion.
evaluation inthissectionwereportacomparisonbetweenocelotandaustin theonlyavailablesearch basedtoolforautomaticallygenerating test datainc tothebestofourknowledge.wewerenotableto compareocelottocavmoriguana sincethesetoolsarenot publicly available.
note that our goal was to compare ocelot with search based tools so we did not consider test datagenerationtoolsforcbasedonotherapproaches suchascute and dart .
this comparison will be part of future work.
as previously shown in section ocelot provides a broader number of features compared to other state of the art tools .
moreover itis more flexibleand easilyextensible.
amongstthe others ocelotallowstogeneratetestsrelyingondifferentmeta heuristics.beingthe goaloftheevaluationtocheckwhetherocelotisagood alternative to austin we set ocelot to run with avm i.e.
the search algorithm employed by austin.
with our study we aim to compare out of the box the performance of these tools.
it is worth noting that austin requires an explicitpointerconstraintsinthesourcecodeofthetargetfunctiontoinstantiateanypointer.thus apointerwillnotbeinstantiatedif the code does not compare it to null.
we argue that this an important limitation for the usability of the tool.
therefore as done in previous work we decide to not manually modify the subjects to evaluate the tools in a real world scenario.
to compare the tools we run both of them on a subset of functions coming from different c open source projects gimp gls and sglib.gimpis the open source gnu image manipulation software glsstands for gnu scientific library sglibis a library offering generic utilities.
it is worth noting that this set of func tions has been used both in our previous work and in the paper thatintroducedaustin .table1liststhesetoffunctions representingthe contextofthecomparison.intotal wetakeinto account branches for functions.
asdoneinpreviouswork weset1000evaluationsforeach branchofthefunctionundertestassearchbudget.moreover for the same reason we do not impose any time limit constraints.
werunthetools20timesforeachfunction wethencomparethe achieved branch coverage relying on the non parametric wilcoxon rank sum test with significance level .
.
significant p valuesallows us to reject the null hypothesis i.e.
that the two tools achieve the same coverage.
moreover we rely on the varghadelaney a12 statistic to estimate the effect size i.e.
the magnitude of the difference between the measured metrics.
a12 .
means that ocelot reaches a higher coverage than austin while a12 .5hastheoppositemeaning.vargha delaneystatisticsalso classifies such effect size into four different levels negligible small medium large .
for the experiments we execute both the tools on a virtual machine with cores and 32gb ram running ubuntu .
lts.
we make available two docker images on dockerhub one for each tool to foster the replicability of the results9 .
.
results table1summarizes thebranchcoverage resultswith thecomparison between austin and ocelot.
the table shows the average coverageachievedover20runsalongwiththe p valuesobtained with the wilcoxon test and the vargha delaney statistic.
we typeset the statistically significantly results i.e.
p value .
in bold highlighting the tool reaching the highest coverage.
from table 1we notice that ocelot performs better than austin in out 26cases whiletheoppositehappensinonlyonecase.in detail thecoverageimprovementrangesfromaminimumof43 authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
ase september montpellier france scalabrino grano di nucci guerra de lucia gall and oliveto table comparison between austin and ocelot program function branches austin ocelot p value sglib sglib int array quick sort .
.
.
.
l sglib sglib int array heap sort .
.
.
.
l sglib sglib int array binary search .
.
.
.
l gls gsl poly eval derivs .
.
.
.
l gls gsl poly solve cubic .
.
.
.
n gls gsl poly solve quadratic .
.
.
.
s gls gsl poly complex solve quadratic .
.
.
.
n gls gsl poly complex solve cubic .
.
.
.
l gimp gimp cmyk to rgb .
.
.
.
l gimp gimp cmyk to rgb int .
.
.
.
l gimp gimp hsl to rgb .
.
.
.
l gimp gimp hsl to rgb int .
.
.
.
l gimp gimp hsv to rgb .
.
.
.
l gimp gimp rgb to cmyk .
.
nan .
n gimp gimp rgb to hsl .
.
.
.
l gimp gimp rgb to hsl int .
.
.
.
l gimp gimp rgb to hsv4 .
.
.
.
l gimp gimp rgb to hsv int .
.
.
.
l gimp gimp rgb to hwb .
.
.
.
l gimp gradient calc square factor .
.
.
.
l gimp gradient calc radial factor .
.
.
.
l gimp gradient calc linear factor .
.
.
.
l gimp gradient calc bilinear factor .
.
.
.
l gimp gradient calc spiral factor .
.
.
.
l gimp gradient calc conical sym factor .
.
.
.
l gimp gradient calc conical asym factor .
.
.
.
l total average .
.
toamaximumof100 forthefunction e.g.
gimp cmyk to rgb .
indeed in each of the aforementioned cases the effect size is large.
qualitatively looking at the results we can see that austin stops at of coverage for the subjects having only pointers as arguments e.g.
gimp hsl to rgb .furthermore evenincaseof functions with only primitive values as parameters ocelot is able to reach a higher coverage than austin.
for example on gradient calc radial factor austin constantly achieves of coverage while ocelot hits on average with a .
standard deviation.
even if we do not impose any time limit constraints as search budget it is still worth to discuss this dimension when it comes to compare the two tools.
in particular during our experiment we noticed that given the same maximum amount of iterations ocelot is way faster than austin.
just to give an idea the evolutionarysearchforthefunction sglib int array quick sort takes seconds for ocelot while it takes minutes for austin.
conclusion and future work in this paper we presented ocelot a search based tool for automaticallygeneratingtest dataforcprograms.wereleasedthe executableof ocelot describingtheconfigurationparametersthat can be set to allow both researchers and practitioners to use the tool.ourpreliminarystudyshows thatocelotisabletoachieve higher coverage than austin.
moreover ocelot presents some additional advantages over austin i it is easier to use on the one hand austin requires manual code changes to instantiate pointers or to specify input preconditions on the other hand ocelot automatically handles those cases ii it is written in java a more common programming language compared to ocaml and it is actively maintained iii it offers a clion plugin to help the practitioners toconfigure the tool iv it supports different search algorithms generationandminimizationstrategiesthatcanbecombinedtogether v it is more effective and efficient.
future work will be aimed at improving ocelot in several aspects.
we plan to implement a different representation for the test input tosupportrecursivedatastructures.wealsoplantoimplementanewinstrumentationprocesswithofaimofreducingthe timeneededfortheinstrumentationofmultipletargetfunctions this step should improve the scalability of the tool.
finally we plan to release the code of tool as open source in the near future.