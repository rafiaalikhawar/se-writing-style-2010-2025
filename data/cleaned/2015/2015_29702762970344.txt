recommending relevant classes for bug reports using multi objective search rafi almhana wiem mkaouer marouane kessentini ali ouni computer and information science department university of michigan dearborn mi usa graduate school of information science and t echnology osaka university osaka japan firstname umich.edu ali ist.osaka u.ac.jp abstract developers may follow a tedious process to find the cause of a bug based on code reviews and reproducing the ab normal behavior.
in this paper we propose an automated approach to finding and ranking potential classes with the respect to the probability of containing a bug based on a bugreport description.
our approach finds a good balance be tween minimizing the number of recommended classes and maximizing the relevance of the proposed solution using a multi objectiveoptimizationalgorithm.
therelevanceoftherecommended classes solution is estimated based on theuse of the history of changes and bug fixing and the lexicalsimilarity between the bug report description and the api documentation.
we evaluated our system on open source java projects using the version of the project before fix ing the bug of many bug reports.
the experimental resultsshow that the search based approach significantly outperforms three state of the art methods in recommending relevant files for bug reports.
in particular our multi objectiveapproach is able to successfully locate the true buggy meth ods within the top recommendations for over of thebug reports.
ccs concepts software and its engineering search based software engineering keywords search basedsoftwareengineering bugreports multi objective optimization software maintenance.
.
introduction a software bug is a coding error that may cause abnormal behaviors and incorrect results when executing the system .
after identifying an unexpected behavior of the soft ware project a user or developer will report it in a docu ment called a bug report .
thus a bug report should permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributedfor profit or commercial advantage and that copies bear this notice and the full cita tion on the first page.
copyrights for components of this work owned by others thanacm must be honored.
abstracting with credit is permitted.
to copy otherwise or re publish to post on servers or to redistribute to lists requires prior specific permissionand or a fee.
request permissions from permissions acm.org.
ase singapore singapore c circlecopyrt acm.
isbn .
.
.
.
4provide useful information to identify and fix the bug.
the number of these bug reports can be large.
for example mozilla had received more than bug reports .
these reports are important for managers and developers during their daily development and maintenance activities .
a developer always uses a bug report to reproduce the abnormal behavior to find the origin of the bug.
however the poor quality of bug reports can make this process tedious and time consuming due to missing information.
tofind the cause of a bug developers are not only using theirdomain knowledge to investigate the bug report but interact with peer developers to collect additional information.
an efficient automated approach for locating and rankingimportant code fragments for a specific bug report may leadto improving the productivity of developers by reducing thetime to find the cause of a bug .
most of the existing studies are mainly based on lexical matching scores between the statements of bug reports and the name of code elementsin software systems .
however there is a significant dif ference between the natural language used in bug reports and the programming language which limits the efficiency of existing approaches.
in this work we start from the following observations.
first api documentation of the classes and methods canbe more useful than the name of code elements or comments to estimate the similarity between code fragments and bug reports.
second classes associated to previously fixed bugreports may be relevant also to the current report if thesepreviously bug reports are similar to a current bug report.
third a code fragment that was fixed recently is more likely to still contain bugs than another class that was last fixedlongtimeago.
fourth aclassthathasbeenfrequentlyfixed tend to be fault prone and may cause more than one abnor mal behavior in the future.
finally the recommendation of a large number of classes to inspect may make the process of finding the cause of a bug time consuming.
to consider the above observations we propose a comprehensive approach for bugs localization based on bug reports description.
to this end we propose for the first time to use a multi objective optimization algorithm to find abalance between maximizing lexical and history based simi larity and minimizing the number of recommended classes.the problem is formulated as a search for the best combinationand sequenceofclassesfromalltheclassesofthesystem that optimize as much as possible the above two conflictingobjectives.
we have executed an extensive empirical evaluation of permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
copyrights for components of this work owned by others than acm must be honored.
abstracting with credit is permitted.
to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
request permissions from permissions acm.org.
ase september singapore singapore c acm.
... .
large open source software projects with more than bug reports in total based on an existing benchmark .
the results on the before fix versions show that our system outperforms on average three state of the art approachesnot based on search techniques .
in particular our search based approach is able to successfully locate thetrue buggy methods within the top recommendations for over of the bug reports.
the primary contributions of this paper can be summarized as follows to the best of our knowledge and based on recent surveys the paper proposes the first search basedsoftware engineering approach to address the problem of finding relevant code fragments for bug reports.
theapproach combines the use of lexical and history basedsimilarity measures to locate and rank relevant code fragments for bug reports while minimizing the numb e ro fr e c o m m e n d e dc l a s s e s .
the paper reports the results of an empirical study withanimplementationofourmulti objectiveapproach.the obtained results provide evidence to support theclaim that our proposal is more efficient on average than existing techniques based on a benchmark of open source systems.
we also compared theresults of our multi objective approach with a mono objective formulation to make sure that our objectivesare conflicting.
the remainder of this paper is as follows section is dedicated for the related work.
section describes the proposed approach and the search algorithm.
an evaluation ofthe approach and its results are explained in section whilesection further discusses the obtained results.
section 6describes the threats to validity related to our experiments.
finally concluding remarks and future work are provided in section .
.
related work in this section we survey different studies related to the areas of bug localization and search based software engineering.
.
bug localization theproblemofbuglocalizationcanbeconsideredassearching the source of a bug given its description.
to address thisproblem the majority of existing studies is based on the use information retrieval ir techniques through the detection of textual and semantic similarities between a newly givenreport and source code entities .
several ir techniqueshave been investigated namely the latent semantic index ing lsi latent dirichlet allocation lda and the vector space model vsm .
in addition hybrid models extracted from these irs techniques to tackle the problemof bug localization were proposed .
we summarize in the following the different tools and approaches proposed in the literature based on the above ir techniques.
bugscout is a topic based approach us ing lda to analyze the bug related information descrip tion comments external links etc.
to detect the source ofa bug and duplicated bug reports.
the main limitation of bugscout is the dependency of the results on the keywordsentered by the user.
debugadvisor s is a bug investigation system that takes as input a bug report in terms of textqueries then uses them to mine existing fixed bug repository and generate a graph of possible reports.
however debugadvisor accuracy depends on the accuracy of the re port s description and its accuracy when describing the bugand its related code entities.
buglocator combines several similarity scores from previous bug reports for bug localization.
it generates a vsm model to extract suspect source files for a given bugreport.
then buglocator mines previously fixed bug re ports along with related files involved to rank suspect code fragments.
the main issue raised in this work is the proneness of the weight density to the noise in the large files.
toovercomethislimitation addedsegmentationandstack traceanalysistoimprovetheperformanceofthebuglocatorapproach.
the limitation of this extension is that execution traces are not necessarily available in bug repositories.
bluir has been proposed also to compare a bug report to the structure of source files.
it decomposes re ports into summaries and then uses the structural retrieval to calculate similarities between these tokenized elements and source code ones to rank source code files.
saha etal.
extended bluir to consider similar reports infor mation similarly to buglocator as an additional similarityscore.
dhbpd incorporated code change information for bug localization.
the main idea is to consider recently changed source code elements as potential candidates forhosting a bug.
ye et al.
has modeled the similarity between bug reports and source code through several characteristics that are captured through the use of similarity features thatdescribe the projects domain knowledge.
the combinationofthesemeasuresisfedtoarankingheuristiccalledlearning to rank.
therankingmodelreturnsthetopcandidatesource files to investigate for a given bug report.
the main originality of their work is the use of projects api description andauto generated documentation as one of the features to uti lize to reduce the lexical gap between the human description and the source code.
in ye et al.
extended their previous work by extending their ranking features utilized by learning to rankfrom to .
besides the existing surface lexical similarity api based lexical similarity collaborative filtering code elements naming similarity fixed bugs frequency they included other source code characteristics that can be extracted fromthe projects such as summaries naming conventions inter class dependencies etc.
although taking these features into account has given better results in terms of better files ranking suchinformationmaynotbeavailableinallprojectsandsometimes it may be outdated and that may deteriorate thelocalizations accuracy.
we propose in this paper a more comprehensive approach to address the problem of bugs localization from different perspectives as detailed in the next sections.
.
search based software engineering search based software engineering sbse uses a computational search approach to solve optimization problems in software engineering .
once a software engineering task is framed as a search problem by defining it in terms of so lution representation fitness function and solution changeoperators there is a multitude of search algorithms that can 287finding relevant classes for bug reports using nsga ii objective maximize the relevance of recommended classes objective minimize the number of recommended classes.source code and api specifications of the program to be inspected a list of previous bug reportsbest sequence of classes to inspectthe history of the applied changes in previous releasesthe description of the bug report s figure approach overview.
be applied to solve that problem.
many search based software testing techniques have been proposedfortestcasesgeneration mutationtesting regression testing and testability transformation.
how ever the problem of bugs localization was not addressed before using sbse.
the closest problem addressed using sbse techniques is the bugs prioritization problem .
a mono objective genetic algorithm was proposed to find the best se quence of bugs resolution that maximizes the relevance and importance of the bugs to fix while minimizing the cost.
the main limitation of this work is the use of a mono objectivetechnique that aggregates two conflicting objectives.
in thenext section we describe our formulation of bug localizationas a multi objective problem.
.
multi objective formulation we first present an overview of our multi objective approach to identify and prioritize relevant code fragments e.g.
classes for bug reports and then we describe the de tails of our multi objective formulation.
.
approach overview our approach aims at exploring a large search space to find relevant classes to inspect by developers given a de scription of a bug report.
the search space is determinednotonlybythenumberofpossibleclasscombinationstorec ommend but also by the order in which they are proposed to the programmer.
in fact bug reports may require the inspection of more than one class to identify and fix bugs.
a heuristic based optimization method is proposed based on two main conflicting objectives.
the first objective is the correctness function that includes two sub functions .a maximizingthelexicalsimilaritybetweenrecommendedclassesand the description of the bug report including the api andname of code elements similarity and .b maximizing thehistory based function score that includes the number of a recommended classes that have been fixed in the past recent changes introduced by the developers to these classesand similarities with previous bug reports.
the second ob jective is to minimize the number of classes to recommend.
it is clear that these two objectives are conflicting since maximizing the relevance of recommended classes may leadsto a lower precision and thus increases the number of recom mended classes.
thus we consider in this paper the taskof localizing bugs as a multi objective optimization problem using the non dominated sorting genetic algorithm nsgaii .
the proposed algorithm will explore a large searchspace of a combinatorial number of combinations of classesto recommend.
the general structure of our approach is sketched in figure .
it takes as input the source code of the program to beinspected theapispecificationsoftheclassesofthesystem the description of the bug report and a list of previous bugreports and the history of the applied changes in previous releases.
our approach generates as output a near optimalsequence of ranked classes that maximizes the relevance to the bug report and minimizes the number of recommendedclasses.
in the following we describe an overview of nsgaii the solution representation a formal formulation of the two objectives to optimize and the change operators.
.
nsga ii in this paper we adapted one of the widely used multiobjective algorithms called nsga ii .
nsga ii is a powerful search method stimulated by natural selection that isinspired by the theory of darwin.
hence the basic ideaof nsga ii is to make a population of candidate solutionsevolve toward the near optimal solution in order to solve a multi objective optimization problem.
nsga ii is designed to find a set of optimal solutions called non dominated so lutions also pareto set.
a non dominated solution is theone which provides a suitable compromise between all objectives without degrading any of them.
as described in algorithm the first step in nsga ii is to create randomly apopulation p 0of individuals encoded using a specific representation line .
then a child population q0is generated from the population of parents p0using genetic operators such as crossover and mutation line .
both populations are merged into an initial population r0of size n line .
as a consequence nsga ii starts by generating an initialpopulation based on a specific representation that will be discussed later using the exhaustive list of classes from the system to inspect given as input as mentioned in the pre vious section.
thus this population stands of a set solu tions represented as sequences of classes to inspect whichare randomly selected and ordered for a specific bug report description taken as input.
algorithm high level pseudo code for nsga ii create an initial population p0 create an offspring population q0 t whilestopping criteria not reached do rt pt qt f fast non dominated sort rt pt and i while pt fi lessorequalslantndo apply crowding distance assignment fi pt pt fi i i end while sort fi n pt pt fi qt create new pop pt t t end while the whole population that contains n individuals solutions is sorted using the dominance principle into several fronts line .
the dominance level becomes the basis of a selection of individual solutions for the next generation.fronts are added successively until the parent populationpt is filled with n solutions line .
when nsga iihas to cut off a front fi and select a subset of individual solutions with the same dominance level it relies on the crowding distance to make the selection line .
this frontfi to be split is sorted in descending order line and thefirst n pt elements of fi are chosen line .
then a new population qt is created using selection crossover and mutation line .
this process will be repeated until 288reaching the last iteration according to stop criteria line .
the following three subsections describe more precisely our adaption of nsga ii to the model change detection problem.
.
solution approach .
.
solution representation to represent a candidate solution individual we used a vector representation.
each dimension of the vector repre sents a class to recommend for a specific bug report.
thus a solution is defined as a sequence of classes to recommendfor inspection by the developer to locate the bug.
when created the order of recommended classes correspondstotheirpositionsinthevector.
theclassestorecom mend are dependent since a bug can be located in differentclasses.
in addition the goal is to recommend a minimum set of classes while maximizing the correctness objective.
stackrenderer compositerenderer trimutil figure simplified example of a solution representation.
bug id summary close all and close others menu options available when right clicking on tab in partstack when no part is closeable .
description if i create a partstack that contains multiple parts but none of the parts arecloseable when i right click on any of the tabs i get menu options for close all and close others .
selection of either of the menu options doesn t cause any tabs to be closed since none of the tabs can be closed .
reported figure an eclipse bug report example1 id figure describes a simplified solution generated to find possible relevant classes for the bug report of figure that shows an example of a bug report from the eclipse project id .
this bug report describes a defect about incorrect menu options for parts that are not closeable.
thesolution consists of a sequence of three classes to inspect extracted from the eclipse project.
.
.
fitness functions correctness objective this objective is defined as the average of two functions lexical based similarity ls and history based similarity hs .
thus we formally define this function as f1 ls hs the lexical based similarity ls consists of an average of two functions.
the first function is based on a cosinesimilarity between the description of a bug report andthe source code.
we used the whole content of a source code file the code and comments .
the vocabulary was extracted bug.cgi?id figure a code fragment from the class stackrenderer.
from the names of variables classes methods parameters types etc.
we used the camel case splitter to perform thetokenization for preprocessing the identifiers .
during the tokenization process we used a standard information retrieval stop words to eliminate irrelevant information such as punctuation numbers etc.
in addition the words are reduced to their stem based on a porter stem mer.
this operation reduces the deviation between relatedwords such as designing and designer to the same stem design.
then the cosine similarity measure is used to compare between the description of a bug report and the source code.
equation calculates the cosine similarity between two actors.
each actor is represented as an n dimensional vec tor whereeachdimensioncorrespondstoavocabularyterm.
the cosine of the angle between two vectors is considered as an indicator of similarity.
using cosine similarity the con ceptual similarity between two actors c 1andc2is determined as follows sim c1 c2 cos c1 c2 c1.
c2 bardbl c1 bardbl bardbl c2 bardbl n summationtext i wi wi radicalbigg n summationtext i wi n summationtext i wi where c1 w1 ... w n is the term vector corresponding to actor c1and c2 w1 ... w n is the term vector corresponding to c2.
the weights wi jis computed using information retrieval based techniques such as the term frequency inverse term frequency tf idf method.
thefirst lexical simialrity function is then defined as the sum ofthe of the cosine similarity scores between a description of a bug report and the source code of each the suggested classes divided by the total number of recommended classes.
as described in figures and the description of the bug report example includes several similar words with oneof the recommended classes to inspect the class stackrenderer.
thus the cosine similarity function applied between the source code of that class and the description of the bugreport will detect such similarities.
however the only useof this similarity function may not be enough.
in fact the text of a bug report is in general expressed in a natural language however the large part of the content 289api specification of muielement description a representation of the model object ui label .
t his is a mix in that will be used for ui elements that are capable of showing label information i n the gui e.g.
parts menus toolbars perspectives ... .
the following features are suppor ted label icon uri tooltip ...api specifications figure api specification of the interface muielement.
of a source code is described in a programming language.
thus the similarity score between a bug report description and a source code will be higher in case of an extensive use of comments in the code or if the bug report clearly usesthe names of code elements.
to address this challenge wepropose to use an additional lexical similarity function.
the second lexical function is based on the use of cosine similarity between the bug report description and the api specification of each method of a recommended buggy class.thus it is defined as the sum of the maximum of the cosinesimilarity scores between a description of a bug report and each of the methods composing the suggested class divided by the total number of recommended classes.
as described in figure the class stackrenderer includes a variable uielement having as a type muielement.
figure5 shows the api specification of the muielement interface that includes different terms such as parts and menus that also exists in the bug report description of figure .
thus the lexical similarity between the api specification and thedescription of a bug report may also help to better identify relevant buggy classes.
the second component of the correctness objective is the history based similarity.
this measure is an average of threefunctions.
thefirstfunctioncountsthenumberoftimesthata class was fixed to eliminate bugs based on the history of bug reports.
in fact a class that was fixed several times has a high probability of being a buggy class and includes newbugs.
formally this function normalized between isdefined as h summationtextsize s i 1nbfixedbugs report c i size s max nbfixedbugs report c the second function checks if a recommended class was recently changed or fixed.
in fact a class that was modi fied recently has a higher probability of containing a bug.thus the function compares between the date of the bug report and the last date where the recommended class was modified.
if a suggested class was modified on the same dayof the bug report then the value of this function is .
wedefine this normalized function normalized in the range of as following h summationtextsize s i report.date last report c i size s the third function evaluates the consistency between the recommended classes based on previous bug reports.
theclasses that are recommended together for similar previousbug reports have a high probability to include a bug evolving most of them.
to this end this function calculates first the cardinality cbr of the largest intersection set of classesbetween the solution s and the sets of classes recommendedfor each of previous bug reports.
then this measure is nor malized as follows h cbr size s .
.
change operators in a search algorithm the variation operators play the key role of moving within the search space with the aim ofdriving the search towards better solutions.
we used theprinciple of the roulette wheel to select individuals for mutation and crossover.
the probability to select an individual for crossover and mutation is directly proportional toits relative fitness in the population.
in each iteration weselect half of the population in iteration i. these selected in dividuals will give birth to another half of the population of new individuals in iteration i using a crossover operator.therefore two parent individuals are selected and a few dimensions recommended classes picked on each one.
theone point crossover operator allows creating two offspring p prime 1andp prime 2from the two selected parents p1andp2.i ti sd e finedasfollows arandomposition k isselected.
thefirstk classes of p1become the first kelements of p prime .
similarly the firstkoperations of p2become the first koperations of p prime .
our crossover operator could create a child that contains redundant recommended classes.
in order to resolve this problem for each obtained child we verify whether thereare redundant classes or not.
in case of redundancy we re place the redundant classes by randomly chosen ones from the system without causing another redundancy.
the mutation operator can be applied to pairs of dimensions of the vector selected randomly.
given a selected so lution the mutation operator first randomly selects one ormany pairs of dimensions of the vector.
then for each selected pair the dimensions which correspond to classes are deleted or replaced by new classes.
we used the same repairoperator described previously to eliminate redundancy.
.
ev aluation in order to evaluate our approach for recommending relevant classes to inspect for bug reports we conducted a set of experiments based on different versions of open source systems.
each experiment is repeated times and the ob tained results are subsequently statistically analyzed withthe aim to compare our nsga ii proposal with a variety of existing approaches not based on heuristic search and a mono objective formulation.
in this section wepresent our research questions and then .
research questions in our study we assess the performance of our approach by finding out whether it could identify the most relevant classes to inspect for bug reports.
our study aims at addressing the following research questions outlined below.
wealso explain how our experiments are designed to addressthese questions.
the main question to answer is to what ex tent the proposed approach can propose meaningful bug localization solutions based on the description of a bug report.
to this end we defined the following research questions rq1.
efficiency to what extent can the proposed approachidentifyrelevantclassestolocalizebugsbasedon bug reports description?
rq2.
comparison to search techniques how does theproposedmulti objectiveapproachbasedonnsga ii perform compared to random search and a monoobjective approach?
rq3.
comparison to state of the art how does our approach perform compared to existing bugs localization techniques not based on heuristic search?
to answer rq1 we validate the proposed multi objective technique on six medium to large size open source systems as detailed in the next section to evaluate the correctness of the recommended classes to inspect for a bug report.
to this end we used the following evaluation metrics precision k denotes the number of correct recommended files in the top k of recommended files by the solution divided by the minimum number of files to in spect in the ranked recommendations list to localizethe bug.
recall k denotesthenumberofcorrectrecommended files in the top k of recommended files by the solutiondivided by the total number of expected files to be recommended that contain the bug.
accuracy k measures the percentage of bug reports forwhichatleastonecorrectrecommendationwasprovided in the top k ranked classes.
to answer rq2 we compared using the above metrics theperformanceofnsga iiwithrandomsearchandamonoobjective genetic algorithm aggregating all the objectivesinto one objective with equal weight.
if random searchoutperforms a guided search method thus we can concludethat our problem formulation is not adequate.
it is important also to determine if our objectives are conflicting and outperforms a mono objective technique.
the comparisonbetween a multi objective technique with a mono objectiveone is not straightforward.
the first one returns a set of non dominated solutions while the second one returns a single optimal solution.
to this end for we choose the nearestsolution to the knee point i.e.
the vector composed ofthe best objective values among the population members asa candidate solution to be compared with the single solution returned by the mono objective algorithm.
toanswerrq3 wecomparedourmulti objectiveapproach todifferentexistingtechniquesnotbasedonheuristicsearch .
bugscout identifies relevant classes based on the use of latent dirichlet allocation measure .
buglocator ranks classes using both textual and structural simi larity.
.
learning to rank lr technique ranks classesusing a machine learning technique to learn from the his tory of previous bug reports.
in addition we compared our work with two additional baselines.
the first one is based on the only use of the lexical measure ls to rank classesand the second one is based on the only use of the historymeasure hs .
these two baselines may justify or not the need of considering complementary information from both the lexical and history similarities in our multi objective for mulation.
in the next section we describe the different projects and the fold cross validation used in our experiments.
.
software projects and experimental setting as described in table we used a benchmark datasets for six open source systems .
eclipse ui is the user interface of the eclipse development framework.
tomcat implements several java ee specifications.
aspectj is an aspect oriented programming aop extension created for the java programming language.
birtprovides reporting and business intelligence capabilities.
swtis a graphical widget toolkit.
jdtprovides a set of tool plug ins for eclipse.
table shows the different statistics of the analyzed systemsincludingthetimerangeofthebugreports thenumber ofbugreports thesize thenumberofapis andthenumber of fixed classes per bug report.
the total number of collected bug reports and associated classes is more than bug reports for the six opensource systems.
all these projects are using bugzilla tracking system and git as a version control system.
to avoid using a fixed code revision we associated a before fixed ver sion of the system to each bug report.
therefore for eachbug report the version of the software package just before the fix was committed was used in our validation.
based on the collected data we created two sets one for the training data and the other for the test data.
the bugreports for each system were sorted chronologically based onthe time dimension.
the sorted bug reports are then split into folds with equal sizes where fold 1contains the most recentbugreportsandthelastfoldfold 10containstheoldest ones.
in addition the oldest fold is split into training history of bug reports and validation.
the approach is trained on fold i 1a n dt e s t e do nf o l d i for all i from to .
the best recommended solution is then compared withexpected solution of classes that contain the bug.
.
parameters tuning and statistical tests since metaheuristic algorithms are stochastic optimizers they can provide different results for the same problem instance from one run to another.
for this reason our experi mental study is performed based on independent simula tion runs for each problem instance and the obtained results are statistically analyzed by using the friedman test with a confidence level .
the friedman test is a non parametric statistical test useful for multiple pair wise comparisons.
the latter verifies the null hypothesish 0that the obtained results of the different algorithms are samples from continuous distributions with equal medians as against the alternative that they are not h .
the p value of the friedman test corresponds to the probability of reject ing the null hypothesis h 0while it is true type i error .
a p value that is less than or equal to .
means that we accept h 1and we reject h .
however a p value that is strictly greater than .
means the opposite.
in this way we could decide whether the superior performanceof nsga ii to one of each of the other algorithms or the opposite is statistically significant or just a random result.
the friedman test allows verifying whether the results are statistically different or not.
however it does not giveany idea about the difference in magnitude.
to this end we used the vargha and delaneys a statistics which is a non parametric effect size measure.
in our context giventhe different performance metrics such as precision and re call the a statistics measures the probability that runningan algorithm b1 nsga ii yields better performance than 291table studied projects project bug reports time a p i files in the project average per version fixed files classes per bug report median eclipse ui birt jdt aspectj tomcat swt running another algorithm b2 such as ga .
if the two algorithms are equivalent then a .
.
an often omitted aspect in metaheuristic search is the tuning of algorithm parameters.
in fact parameter setting influences significantly the performance of a search algorithm on a particular problem.
for this reason for eachsearch algorithm and each system we performed a set ofexperiments using several population sizes 40and .
the stopping criterion was set to fitness evaluations for all search algorithms in order to ensure fair ness of comparison.
we used a high number of evaluations as a stopping criterion since our approach requires involvesmultiple objectives.
each algorithm was executed times with each configuration and then the comparison between the configurations was performed based on different metricsdescribed previously using the friedman test.
the otherparameters values were fixed by trial and error and are asfollows crossover probability .
mutation probability .
where the probability of gene modification is .
.
.
results .
.
results for rq1 the results of table and figures to confirm the efficiency of our multi objective approach to identify the most relevantclassesforbugreportsthatincludethebugsonthe6 open source systems.
table shows the average precision kresults of our multi objective technique on the different sixsystems with k ranging from to .
for example most of the recommended classes to inspect in the top k are relevant with a precision of .
the lowest precisionis around for k which is still could be consideredacceptable since most of the bug reports do not have manyclasses to inspect.
in terms of recall table confirms that the majority of the expected classes to recommend are located in the top k with an average recall score of94 .
an average of more than of classes recommendedin the top5 cover the expected buggy classes.
the average accuracy k results on the different six systems are described in table showing that an average of68 and are achieved for k 15and respectively.
these results confirm that if we recom mend only classes to programmers we can make correct recommendations for of the thousands of collected bug reports for every system.
figures to summarize the results of the precision recall and accuracy for every of the studied systems.
the obtained results clearly show that most of the buggy classes were recommended correctly by our multi objectiveapproach in the top with a minimum precision of foraspectj a minimum recall of for eclipse and a mini mum accuracy of for eclipse as well.
thus we noticed that our technique does not have a bias towards the eval table median precision k recall k and accuracy k on independent runs.
the results were statistically signifi cant on independent runs using the friedman test with a95 confidence level .
k precision k nsga iibug scoutbug locatorlr ls hs rs ga k recall k nsga iibug scoutbug locatorlr ls hs rs ga k accuracy k nsga iibug scoutbug locatorlr ls hs rs ga uated system.
as described in figures in all systems we had almost similar average scores of precision recall and accuracy.
all these results based on the different measureswere statistically significant on independent runs usingthe friedman test with a confidence level .
to answer rq1 the obtained results on the six open source systems using the different evaluation metrics of pre cision recall and accuracy clearly validate the hypothesesthat our multi objective approach can recommend efficientlyrelevant buggy classes to inspect for each bug report.
.
.
results for rq2 concerning rq2 table and figures to confirm that nsga ii is better than random search and the three monoobjective formulations ls hs and ga based on the threemetrics of precision recall and accuracy on all the systems.three mono objective formulations were implemented .
with an equal aggregation of both objectives ga .
a mono objective algorithm with the only objective of lexical similarity ls and .
a mono objective algorithm with the only objective of history similarity hs .
the average accuracy precision and recall values of random search rs on the six systems are lower than as 292figure average precision k of nsga ii bugscout buglocator lr ls hs rs and ga on the different systemsfor independent runs.
.
figure average recall k of nsga ii bugscout buglo cator lr ls hs rs and ga on the different systems for30 independent runs.
figure average accuracy k of nsga ii bugscout buglocator lr ls hs rs and ga on the different systems for independent runs.described in table .
this can be explained by the huge search space to explore to identify the best order of classes to inspect for bugs localization.
the performance of the three mono objective algorithms was much better than ran dom search but lower than our multi objective formulation.the aggregation of both objectives into one objective gener ates better results on all the six systems than the two other algorithms considering each objective separately.
thus an interesting observation is the clear complementary betweenthe history based similarity function and the lexical basedmeasure.
in fact we found that the buggy classes that are not detected by one of the two algorithms were identified by the other algorithm.
the average precision recall andaccuracy of each of the two algorithms lh and hs wasbetween and but the aggregation of both objec tives into one in our multi objective formulation improve a lot the obtained results.
in addition since nsga ii outperforms the mono objective ga then it is clear that thetwo objectives of correctness relevance and the number ofrecommended classes are conflicting.
all these results were statistically significant on independent runs using the friedman test with a confidencelevel .
we have also found the following results of the vargha delaney a statistic a on large and medium scale systems birt jdt eclipse ui and aspectj nsga ii is better than all the other algorithms based on allthe performance metrics with an a effect size higher than0.
b on small scale systems tomcat swt nsga iiis better than all the other algorithms with a an a effect size higher than .
.
we conclude that there is empirical evidence that our multi objectiveformulationsurpassestheperformanceofran dom search and mono objective approaches thus our formulation is adequate this answers rq2 .
.
.
results for rq3 sinceitisnotsufficienttocompareourapproachwithonly search based algorithms we compared the performance ofnsga ii with three different bugs localization techniques not based on heuristic search .
table and figures to present the precision k recall k and accu racy k results for the implemented methods with k rang ing from to .
nsga ii achieves better results on av erage than the other three methods on all six projects.
for example our approach achieved on average precision k of and are achieved for k 15and respectively as described in table .
in compari son buglocator achieved an average precision k of .
bugscout and lr achieved an average precision k of and respectively.
similar observations are also validfor the recall k and accuracy k. based on the results of figures to birt and tomcat are two projects where lr performs close to the nsga ii approach.
for many bug reports in birt most of the buggy classes are those that have been frequently fixed in previousbug reports which explain the relatively high performanceobtained by lr and nsga ii.
since the bug fixing information is exploited by both the nsga ii approach and lr it is expected that they obtain the best performance results.
to answer rq3 the obtained results on the six open source system using the different evaluation metrics of pre cision recall and accuracy clearly validate the hypotheses that our multi objective approach outperforms several bugs 293figure impact of the data training size folds on the three metrics based on the jdt project.
figure average execution time in minutes of nsga ii on the different systems for independent runs on thedifferent systems.
localization techniques not based on heuristic search.
.
discussions impact of data size.
to evaluate the impact of increasing the size of the data used history of previous bug reports and changes we executed a scenario on the jdtproject in which we increased the size of the dataset in crementally fold by fold until we include all the folds in the dataset.
it is clear from figure that for all the three metrics of precision k recall k and accuracy k that in creasing the size of the previous bug reports do not improveall the three metrics.
this can be explained by the fact thatrecent bug reports and history of changes are the most important part of the data.
the obtained results confirm also that our multi objective approach did not require a large setof data to generate good results in terms of finding possiblebuggy classes for bug reports.
execution time.
we executed our multi objective algorithm on a desktop computer with cpu intel r core tm i7 .
ghz and 20g ram.
figure presents the executiontime performance of our approach.
the average executiontime on the different systems was around minutes.
the highest execution time was observed on the jdt system with minutes and the lowest one was around minutesfor swt.
we believe that the execution is reasonable sincebugs localization is not a real time problem.
we also found that the execution time is related to the number of files to parse and the history of bug reports.
.
threats to v alidity we explore in this section the factors that can bias our empirical study.
these factors can be classified in three cat egories construct internal and external validity.
constructvalidityconcernstherelationbetweenthetheoryandtheob servation.
internal validity concerns possible bias with the results obtained by our proposal.
finally external validity is related to the generalization of observed results outsidethe sample instances used in the experiment.
in our experiments construct validity threats are related to the absence of similar work that uses search based tech niques for bug s localization.
for that reason we compared our proposal with different mono objective formulations tocheck the need for a multi objective approach.
a constructthreat can also be related to the corpus of manually localized bugs for every bug report.
a limitation related to our experiments is the difficulty to set the thresholds for some ofthe parameters of bug locator.
in fact we used the defaultthresholds used by the authors that can have an impact on the quality of the generated results.
we take into consideration the internal threats to validity in the use of stochastic algorithms since our experimentalstudy is performed based on independent simulation runsfor each problem instance and the obtained results are statistically analyzed by using the statistical test with a confidence level .
the parameter tuning of the different optimization algorithms used in our experimentscreates another internal threat that we need to evaluate in our future work by additional experiments to evaluate the impact of the parameters on the quality of the results.
external validity refers to the generalization of our findings.
in this study we performed our experiments on sixdifferent widely used open source systems belonging to different domains and with different sizes.
however we cannot assert that our results can be generalized to other applica tions other programming languages and to other practi tioners.
.
conclusion and future work we propose in this paper an automated approach to localize and rank potential relevant classes for bug reports.our approach finds a trade off between minimizing the num ber of recommended classes and maximizing the correctness of the proposed solution using a multi objective optimization algorithm.
the correctness of the recommended classesis estimated based on the use of the history of changes andbug fixing and the lexical similarity between the bug report description and the api documentation.
we have executed extensive empirical evaluations on large open source soft ware projects with more than bug reports in totalbased on an existing benchmark.
the results on the before fix versions show that our system outperforms on average three state of the art approaches not based on search techniques .
in particular our search based approachis able to successfully locate the true buggy methods withinthe top recommendations for over of the bug reports.
as part of our future work we plan to evaluate our multiobjective approach on further projects in other different pro gramming languages.
in addition we will extend our workto address the problem of the software bugs managementand prioritization using multi objective search techniques.
.