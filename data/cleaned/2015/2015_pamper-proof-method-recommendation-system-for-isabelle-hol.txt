pamper proof method recommendation system for isabelle hol yutaka nagashima ciirc czech technical university in prague prague czech republic department of computer science university of innsbruck innsbruck tyrol austria yutaka.nagashima uibk.ac.atyilun he school of information technologies university of sydney sydney new south wales australia yihe8397 uni.sydney.edu.au abstract deciding which sub tool to use for a given proof state requires expertisespecifictoeachinteractivethe oremprover itp .tomitigate this problem we present pamper aproofmethodrecommendation system for isabelle hol.
given a proof state pamperrecommends proof methods to discharge the proof goal and provides qualitative explanationsastowhyitsuggeststhesemethods.
pampergenerates these recommendations based on existing hand written proof corpora thustransferringexperiencedusers expertisetonewusers.
ourevaluationshowsthat pampercorrectlypredictsexperienced users proofmethodsinvocationespeciallywhenitcomestospecial purpose proof methods.
ccs concepts informationsystems recommendersystems information extraction security and privacy logic and verification human centeredcomputing userinterfacetoolkits theory of computation higher order logic keywords isabelle hol recommendationsystem datamining proofmethod interactive theorem prover acm reference format yutaka nagashima and yilun he.
.
pamper proof method recommendationsystemforisabelle hol.in proceedingsofthe201833rdacm ieee international conference on automated software engineering ase september3 montpellier france.
acm newyork ny usa 11pages.
introduction doyouknowwhentousetheproofmethod1calledintro classes inisabelle?whatabout uint arith ?canyoutellwhen fastforce tends to be more powerful than auto?
if you are an isabelle expert 1proofmethodsaretoolsusedtodischargeproofgoalsinisabelle.theyaresimilarto tactics in other lcf style provers.
permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation onthe firstpage.copyrights forcomponentsof thisworkowned byothersthan the author s mustbehonored.abstractingwithcreditispermitted.tocopyotherwise or republish topostonserversortoredistributetolists requirespriorspecificpermission and or a fee.
request permissions from permissions acm.org.
ase september montpellier france copyright held by the owner author s .
publication rights licensed to acm.
acm isbn ... .
might be no.
do i have to know these isabelle specific details?
interactivetheoremprovers itps areformingthebasisofreliable software engineering.
klein et al.proved the correctness of the sel4 micro kernel in isabelle hol .
leroy developed a certifying c compiler compcert using coq .
kumar et al.
built a verified compiler for a functional programming language cakeml inhol4 .inmathematics mathematiciansarereplacing their pen and paper proofs with mechanised proofs to avoid human errors in their proofs hales et al.mechanically proved the kepler conjecture using hol light and isabelle hol whereas gonthier etal.finishedtheformalproofsofthefourcolourtheorem incoq .intheoreticalcomputerscience paulsonprovedg del s incompleteness theorems using nominal isabelle .
to facilitate efficient proof developments in such large scale verification projects modern itps are equipped with many sub tools suchasproofmethodsandtactics.forexample isabelle holcomes with160proofmethodsdefinedinitsstandardlibrary.thesesubtoolsprovideusefulautomationforinteractivetheoremproving however it still requires itp specific expertise to pick up the right proof method to discharge a given proof goal.
this paper presents our novel approach to proof method recommendation and its implementation pamper.
the implementation is available at github .
our research hypothesis is that itispossibletoadvisewhichproofmethodsareuseful to a given proof state based only on the metainformation about the state and information in the standard library.
furthermore we can extract advice by applying machine learning algorithms to existing large proof corpora.
the paper is organized as follows section 2explains the basics of isabelle hol and provides the overview of pamper.
section expounds how pampertransforms the complex data structures representing proof states to simple data structures that are easier to handle for machinelearning algorithms.
section 4shows how our machine learning algorithm constructs regression trees from these simple data structures.
section 5demonstrates how users can elicit recommendationsfrom pamper.section6presentsourextensive evaluation of pamperto assess the accuracy of pamper s recommendations.section 7discussesthestrengthsandlimitationsofthe currentimplementationandthefutureworkthatmightimprove pamper sperformancefurtherorprovideevenmoredetailedevaluation of the current implementation.
section 8compares our work with other attempts of applying machine learning and data mining to interactive theorem proving.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
ase september montpellier france yutaka nagashima and yilun he background and overview of pamper .
background isabelle hol is an interactive theorem prover mostly written in standardml.theconsistencyofisabelle holiscarefullyprotected by isolating its logical kernel using the module system of standard ml.isabelle isar isarfor short is a proof language used in isabelle hol.isarprovidesahuman friendlyinterfacetospecify anddischargeproofgoals.isabelleusersdischargeproofgoalsby applying proofmethods whicharetheisarsyntacticlayeroflcfstyle tactics.
each proof goal in isabelle hol is stored within a proof state which also contains locally bound theorems for proof methods chained facts andthe background proof context of theproof goal whichincludeslocalassumptions auxiliarydefinitions andlemmas proved prior to the the current step.
proof methods are in general sensitive not only to proof goals but also to their chained facts andbackgroundproofcontexts theybehavedifferentlybasedon information stored in proof state.
therefore when users decide which proof method to apply to a proof goal they often have to take other information in the proof state into consideration.
isabellecomeswithmanyisarkeywordstodefinenewtypesand constants such as datatype codatatype primrec primcorec inductive anddefinition .
for example the funcommand is used for general recursive definitions.
thesekeywordsnotonlyletusersdefinenewtypesorconstants but they also automaticallyderive auxiliary lemmasrelevantto the defined objects behind the user interfaceand register them in the backgroundproofcontextwhereeachkeywordisused.forexample nipkowet al.defined a function sep using the funkeyword in an old isabelle tutorial as follows fun sep a a list a list where s e pa sep a sep a x y zs x a s e pa y zs intuitively this function inserts the first argument between any two elements in the second argument.
following this definition isabelle automatically derives the following auxiliary lemma sep.induct and registers it in the background proof context as well as other four automatically derived lemmas sep.induct !
!a.
?p a !
!a x.
?p a !
!a x y zs.
?p a y zs ?
pa x y zs ?p ?a0.
?a1.
where variables prefixed with ?
such as?a0.
are schematic variables !
!isthemeta logicuniversalquantifier isthemeta logic implication2.
isabelle also attaches unique names to these automatically derived lemmas following certain naming conventions hard coded in isabelle s source code.
in this example the full name of this lemma is fun0.sep.induct which is a concatenation of the theory name fun0 the delimiter .
the name of the constant 2isabelle hol is a specialization of isabelle for higher order logic hol formalized in isabelle s meta logic.
therefore it has two versions of universal quantifier and implication one in the meta logic and the other one in holdefined sep followedbyahard codedpostfix .induct which represents the kind of this derived lemma.
when users want to prove conjectures about sep they can specify their conjectures using isar keywords such as lemmaand theorem.theisarcommands applyandby allowuserstoapply proof methods to these proof goals.
in the above example nipkow et al.proved the following lemma about mapandsepusing the automatically derived auxiliary lemma sep.induct as an argument to the proof method induct tac as following lemma map f sep x xs sep f x map f xs apply induct tac x xs rule sep.induct apply simp all done wheresimp all isaproofmethodthatexecutessimplificationto all sub goals and doneis another isar command used to conclude a proof attempt.
isabelle provides a plethora of proof methods which serve as ammunitions when used by experienced isabelle users however new isabelle users sometimes spend hours or days trying to prove goals using proof methods sub optimal to their problems without knowingisabellehasalreadyspecializedmethodsthatareoptimized for their goals.
.
overview of pamper figure1illustrates the overview of pamper.
the system consists of twophases theupperhalfofthefigureshows pamper spreparation phase and the lower half shows its recommendation phase.
inthepreparationphase pamper sfeatureextractorconvertsthe proofstatesinexistingproofcorporasuchasthearchiveofformal proofs afp into a database.
this database describes which proofmethodshavebeenappliedtowhatkindofproofstate whileabstractingproofstatesasarraysofbooleanvalues.thisabstractionisamany to onemapping itmaymapmultipledistinctproofstates into to the same array of boolean values.
therefore each array represents a group of proof states sharing certain properties.
pamperfirstpreprocessesthisdatabaseandgeneratesadatabase foreachproofmethod.then pamperappliesaregressionalgorithm toeachdatabaseandcreatesaregressiontreeforeachproofmethod.
this regression algorithm attempts to discover combinations of featuresusefultorecommendwhichproofmethodtoapply.each treecorrespondstoacertainproofmethod andeachnodeinatreecorrespondstoagroupofproofstates andthevaluetaggedtoeachleafnodeshowshowlikelyitisthatthemethodrepresentedbythe tree is applied to these proof states according to the proof corpora used as training sample.
for the recommendation phase pamperoffers three commands which method why method andrank method .thewhich method commandfirstabstractsthestateintoavectorofbooleanvaluesusing pamper s feature extractor.
then pamperlooks up the regression trees and presents its recommendations in isabelle jedit s outputpanel.ifyouwonderwhy pamperrecommendscertainmethods for example auto to your proof state type why method auto .
then pampertells you why it recommended autoto the proof stateinjedit soutputpanel.ifyouarecurioushow pamperranks a certain method let us say intro classes typerank method intro classes .thiscommandshows intro classes srankgiven authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
pamper proof method recommendation system for isabelle hol ase september montpellier france full feature extractor preprocess decision tree construction fast feature extractor ?feature vector lookupdatabase large proof corpora proof method recommendationpreparation phase recommendation phase proof state proof engineer figure proof attempt with pamper.
bypamperin comparison to other proof methods.
in the following we describe these steps in detail.
processing large proof corpora thekeycomponentof pamperisitsfeatureextractor theextractor converts proof goals chained facts and proof contexts into arrays of boolean values by applying assertions to them.
.
representing a proof state as an array of boolean values currently we employ assertions manually written in isabelle s implementation language standard ml based on our expertise in isabelle hol.table 1showsselectedassertionsweusedin pamper.
mostoftheseassertionsfallintotwocategories assertionsabout proof goals themselves and assertions about the relation between proof goals and information stored in the corresponding proof context.
notethat pamper sassertionsdonotdirectlyrelyonanyuserdefined constants because pamper s developers cannot access concretedefinitionsofuser definedconstantswhendeveloping pamper.
for example we can check if the first proof goal has a constant definedinthe set.thy fileinisabelle hol butwecannotcheckif thatsub goalhasaconstantdefinedintheproofscriptthatsome user developed after we released pamper.however byinvestigatinghowisabelle holworks weimplemented assertions that can check the meta information of proof goalevenwithoutknowingtheirconcretespecificationswhendeveloping pamper.
for example the lemma presented in section .1hasafunction sep whichwasdefinedwiththe funkeyword.
pamper sfeatureextractorchecksiftheunderlyingproofcontext contains a lemma of name sep.elims .
if the context has such a lemma pamperinfers that a user defined sepusing either the fun keyword or the function keyword rather than other keywords such asprimcorec ordefinition.
we wrote some assertions to reflect our own expertise in isabelle hol.oneexampleistheassertionthatchecksiftheproof goalorchainedfactsinvolvetheconstant filter.eventually defined in isabelle s standard library.
we developed such an assertion because we knew that the proof method called eventually elim can handlemany proof goals involvingthis constant.
butin some cases we were not sure which assertion can be useful to decide whichmethodtouse.forexample wehaveassertionstocheckifa proofgoalhasconstantsdefinedin set.thy int.thy orlist.thy as these theory files define commonly used concepts in theorem proving.buttheireffectstoproofmethodselectionwereunclear until we conducted an extensive evaluation described in section .
more importantly we did not know numerical estimates on which assertion is more useful than others when developing these assertions.
for instance we guessed that the assertion to check authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
ase september montpellier france yutaka nagashima and yilun he table selected assertions.
assertions about proof goals themselves.
constants defined in isabelle s standard library check if the first goal has the bnf def.rel fun constant or the fun.map fun constant.
check if the first goal has orderings.ord class.less eq orderings.ord class.less o rgroups.plus class.plus.
check if the first goal and its chained facts have filter.eventually constants defined in isabelle s standard library at certain locations in the first proof goal check if the outermost constant of the first goal is the meta logic universal quantifier check if the first goal has the hol existential quantifier but not as the outermost constant terms of certain types defined in isabelle s standard library check if the first goal has a term of type word.word check if the first goal has a schematic variable existence of constants defined in certain theory files check if the first goal has a constant defined in the nattheory check if the first goal has a constant defined in the realtheory check if the first goal has a constant defined in the settheory assertions about the relation between proof goals and proof contexts.
types defined with a certain isar keyword check if the goal has a term of a type defined with the datatype keyword check if the goal has a term of a type defined with the codatatype keyword check if the goal has a term of a type defined with the recordkeyword constants defined with a certain isar keyword check if the goal has a constant defined with the lift definition keyword check if the goal has a constant defined with the primcorec keyword check if the goal has a constant defined with the inductive keyword or inductive set keyword.
the use of the constant filter.eventually to be useful to recommend the use of the eventually elim method but we did not have means of comparing the accuracy of this guess with other hints prior to this project.
to obtain numerical assessments for proofmethodprediction weappliedthemulti outputregression algorithm described in section .
the evaluation in section 6corroborates that it is possible to derivemeaningfuladviceaboutproofmethods.thisimpliesthat somepartsoftheexpertisenecessarytoselectappropriateproof methodsarebasedonthemeta informationaboutproofstatesor theinformationavailablewithinisabelle sstandardlibrary andour assertion based feature extractor preserves some essenceof proof states while converting them into simpler format.
.
database extraction from large proof corpora thefirststepofthepreparationphaseistobuildadatabasefrom existing proof corpora.
we modified the proof method application commands applyandby inisabelleandimplementedalogging mechanism to build the database.
the modified applyandbytake the following steps to generate the database apply assertions to the current proof state represent the proof state as an array of boolean values record which method is used to that array apply the method as the standard applyorbycommand accordingly.this step requires a slight modification to the isabelle source code toallowustooverwritethedefinitionofthesecommand.thisway we build its database by running the target proof scripts.
the current version of pamperavailable at our website i s based on the database extracted from isabelle s standard library and the afp but the database extraction mechanism is not specific tothislibrary.incaseusersprefertooptimise pamper srecommendationfortheirownproofscripts theycantakethesameapproach following the instructions at our website even though this process tends to require significant computational resources.
this overwriting of applyandbyis the only modification we made to isabelle s source code and we did so only to build the database for our machine learning algorithm.
as long as users choose to use the off the shelf default learning results they can usepamperwithoutevermodifyingisabelle ssourcecode.inthat case theyonlyhavetoincludethetheoryfile pamper pamper.thy into their own theory file using the isar keyword importjust as a normal theory file to use pamper.
notethatloggingmechanismignoresthe applycommandsthat contain composite proof methods to avoid data pollution.
whenmultiple proof methods are combined within a single command the naive logging approach would record proof steps that are backtracked to produce the final result.
one exemplary data point in an extracted database would look as the following induct whereinductisthenameofmethodappliedtothisproofstateand thenthelementin thelistshowsthe resultofthe nthassertionof the feature extractor when applied to the proof state.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
pamper proof method recommendation system for isabelle hol ase september montpellier france the default database construction from isabelle standard library andtheafptookabout6 021hours43minutesofcputime producing a database consisting of unique data points.
we used three multi core server machines3to reduce the clock time necessary to obtain this dataset.
unfortunately this database is heavilyimbalanced someproofmethodsareusedfarmoreoften than others.
we discuss how this imbalance influenced the quality ofpamper s recommendation in section .
machine learning databases in this section we explain the multi output regression tree con struction algorithm we implemented in standard ml for pamper.
we chose a multi output algorithm because there are in general multiplevalidproofmethodsforeachproofgoal andwechosea regressionalgorithm ratherthanclassificationalgorithm because wewouldliketoprovidenumericalestimatesabouthowlikelyeach methodwouldbeusefultoagivenproofgoal.wechosearegression tree construction algorithm because this simple algorithm allows us to produce qualitative explanations as to why pamper recommendscertainmethodsanditworkswell forsmalldatasets for rarely used methods as shown in section .the comparisons of various machine learning algorithms remain as our future work.
.
preprocess the database we first preprocess the database generated in section .
.
this processproduces aseparatedatabase foreachproof methodfrom therawdatabase whichdescribestheuseofmostproofmethods appearing in the target proof corpora.
among the class of problem transformation methods for multioutputregressionproblems thisstraightforwardapproachiscalled single target method it first transforms a single multi output problemintoseveralsingle targetproblems thenappliesaregression algorithm to each of them separately then combines the results of eachregressionalgorithmtobuildasinglepredictorfortheoriginal multi output problem.
forexample ifourpreprocessorfindstheexamplelinediscussed insection .
itconsidersthatanidealuserrepresentedbytheproof corpora decided to use the inductmethod but not other methods suchasautoorcoinduction andproducesthefollowinglinein the database for induct used andthepreprocessoraddsthefollowinglineinthedatabasesfor other proof methods appearing in the proof corpora not notethattheresultingdatabasesdonotalwaysrepresentaprovablycorrectchoiceofproofmethodsbutconservativeestimates.in principle therecouldbemultipleequallyvalidproofmethodsforasingleproofstate butexistingproofcorporadescribeonlyoneway of attacking it.
for example nipkow et al.applied the induct tac method tothe lemmain section .
but wecan prove thislemma withanothermethodformathematicalinduction induction as follows 3oneofthemhas2intel r xeon r cpuse5 2698v3 .30ghzwith16coresfor eachandwithhyperthreading theothertwohave2intel r xeon r cpuse5 v4 .60ghz with cores for each with hyperthreading.lemma map f sep x xs sep f x map f xs apply induction x xs rule sep.induct apply simp all done for this reason this preprocessing may misjudge some methods tobeinappropriatetoaproofstaterepresentedbyafeaturevectorin some cases.
unfortunately exploring all the possible combinations of proof methods for each case is computationally infeasible some proof methods work well only when they are followed by otherproof methods or they are applied with certain arguments and thecombinationoftheseproofmethodsandargumentsexplodes quickly.
on the other hand we can reasonably expect that the proof method appearing in our training sample is the right choice tothe proof state represented by the feature vector since isabellemechanicallycheckstheproofscripts.furthermore webuiltthe default recommendation using isabelle s standard library which was developed by experienced isabelle developers and the afp whichacceptsnewproofsonlyafterpeerreviewsbyisabelleexperts.
this allowed us to avoid low quality proof scripts that isabelle canmerelyprocessbutareinappropriate.therefore weconsider the approximation pamper s preprocessor makes to be a realistic pointofcompromiseandshowtheeffectivenessofthisapproach in section .
.
regression tree construction after preprocessing we apply our regression tree construction algorithm to each created database separately.
we implemented our treeconstruction algorithm from scratchin standard mlfor better flexibility and tool integration.
ingeneral thegoaloftheregressiontreeconstructionistopartition the feature space described in each database into partitions of sub spacesthatleadtotheminimalresidualsumofsquares rss whileavoidingover fitting.intuitively rssdenotesthediscrepancy between the data and estimation based on a model.
the rss in our problem is defined as follows rss j summationdisplay.
j summationdisplay.
i rj usedi hatwidestusedrj where rjstands for the jth sub space to which certain data points represented as lines in database belong.
the value of usediis .
if the data point represented by the subscript isays the method was applied to the feature vector and it is .
if the data point representedbythesubscript isaysotherwise.
hatwidestusedrjistheaverage valueof usedamongthedatapointspertainingtothesub space rj.
computing the rss for every possible partition of the database under consideration is computational infeasible.
therefore pamper s tree construction takes a top down greedy approach calledrecursive binary splitting .
inrecursivebinarysplitting westartconstructingtheregression tree from the root node which corresponds to the entire dataset for a given method.
first we select a feature in such a way we can achieve the greatest reduction in rss at this particular step.
wefindsuchfeaturebycomputingthereductionoftherssbyeach 4rss is also known as the sum of squared residuals ssr .
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
ase september montpellier france yutaka nagashima and yilun he feature by one level.
for each feature we split the database into two sub spaces rused j andrnot j as follows rused j used usedj .
and rnot j used usedj .
where jstands for the number representing each feature.
then for each feature represented by j we compute the following value summationdisplay.
i xi rused j usedi hatwidestusedrused j summationdisplay.
i xi rnot j usedi hatwidestusedrnot j and choose the feature jthat minimizes this value.
second we repeat this partition procedure to each emerging sub node of the regression tree under construction until the depth of tree hits our pre defined upper limit three.
after reaching the maximum depth we compute the average valueof used j inthecorrespondingsub space rforeachleafnode.
we consider this value as the expectation that the method is useful toproofstatesabstractedtothecombinationoffeaturevaluesto that leaf node.
pamperrecords these regression trees in a text file so that users canavoidthecomputationallyintensivedataextractionandregressiontree constructionprocesses unlessthey wanttooptimize the learning results based on their own proof corpora.
notethatifweaddmoreassertionstoourfeatureextractorin future the complexity of this algorithm increases linearly with the number of assertions given a fixed depth of regression tree since the partition only takes the best step at each level instead of exploring all the combinations of partitions.
recommendation phase once finishing building regression trees for each proof methodappeared in the given proof corpora one can extract recommendations from pamper.
when imported to users theory file pamper automaticallyreadsthesetreesusingthe read regression trees command in pamper pamper.thy.
pamperprovidesthreenewcommandstoprovidetwokindsofinformation the which method commandtellswhichproofmethods are likely to be useful for a given proof state the why method commandtakesanameofproofmethodandtellswhy pamperwould recommendtheproofmethodfortheproofstate the rank method commandshowstherankofagivenmethodtotheproofstatein comparisontootherproofmethods.inthefollowing weexplain how these three commands produce recommendations from the regression trees produced in the preparation phase.
.
faster feature extractor before applying the machine learning algorithm we were not sure which assertion produces valuable features but after applying the machine learning algorithm we can judge which assertions arenot useful by checking which features are used to branch each regressiontree.the build fast feature extractor command inpamper pamper.thy constructs a fasterfeature extractor fromthe regression trees built in the preparation phase and the fullfeatureextractortoreducethewaitingtimeof pamper susers.it buildsthefasterfeatureextractorbyremovingassertionsthatdo not result in a branch in the regression trees.
.
the which method command whenusersinvokethe which method command pamperapplies the faster feature extractor to convert the ongoing proof state into afeaturevector whichconsistsofthosefeaturesthataredeemedto beimportanttomakeare commendation.thespeedof thisfaster feature vector depends on both the regression trees and what each proofstatecontains.asaruleofthumb iftheproofgoalhasless terms it tends to spend less time.
then pamperlooksupthecorrespondingnodeineachregressiontreeanddecidestheexpectationthatthemethodistheright choicefortheproofstaterepresentedbythefeaturevector.
pamper computesthisvalueforeachproofmethoditencounteredinthe trainingproofcorpora bylookingupanodeineachregressiontree.finally pampercomparestheseexpectationsandshowsthe15most promising proofmethodswith their expectations in isabelle jedit s output panel.
in the on going example from section .
a user can knowwhichmethodtousebytypingthe which method command as follows lemma map f sep x xs sep f x map f xs which method then pampershows the following message in the output panel for the top methods5 promising methods for this proof goal are simp with expectation of .
auto with expectation of .
rule with expectation of .
induction with expectation of .06137metis with expectation of .
... attentivereadersmighthavenoticedthat pamper srecommendations are not identical to the model answer provided by nipkow et al.this however doesnotimmediatelymean pamper srecommendationisnotvaluable infact pamperrecommendedthe induction methodatthefourthplaceoutof239proofmethods and induction isalsoavalidmethodforthisproofgoalasdiscussedinsection .
.
.
the why method command our rather straightforward machine learning algorithm makes pamper s recommendation explainable.
if you wonder why pamper recommendsacertainmethod forexample case tac toyourproof goal type why method case tac intheproofscript.
pamperfirst checksfeaturesusedtoevaluatetheexpectationforthemethodandtheirfeaturevalues.second pampershowsqualitativeexplanations taggedtoboththesefeaturesandtheirvaluesinjedit soutput.if you wonder why pamperrecommended induction in the above example type the following lemma map f sep x xs sep f x map f xs why method induction then you will see this message in jedit s output panel 5note that we truncated the message due to the space restriction here.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
pamper proof method recommendation system for isabelle hol ase september montpellier france because it is not true that the context has locally defined assumptions.because the underlying proof context has a recursivesimplification rule related to a constant appearing in the first subgoal.
the first reason corresponds to the first branching at the root node in the regression tree forthe induction method andthe second reason corresponds to the second branching in the tree.
in this case pamperfound thatthe proof goalinvolves the constant sep and the underlying proof context contains a simplification rule sep.simps which involves a recursive call of sepas following sep.simp sep ?a ?x ?y ?zs ?x ?a sep ?a ?y ?zs .
the rank method command sometimes users already have a guess as to which proof method would be useful to their proof state but they want to know how pamperrankstheproofmethodinmind.continuingwiththeabove example ifyouwanttoknowhow pamperranksconduction for this proof state type the following lemma map f sep x xs sep f x map f xs rank method coinduction then pamperwarns you coinduction out of indicating that pamperdoes not consider coinduction to be the right choice for this proof goal before you waste your time on emerging sub goals appearing after applying coinduction.
evaluation weconductedacross validationtoassesstheaccuracyof pamper s which method command.
for this evaluation we used isabelle s standard library and the afp as follows first we extracted a database from these proof corpora.
this database consists of data points.
second we randomly chose of data points in this databasetocreatetheevaluationdataset.third webuiltregression treesfromtheremaining90 .thereisnooverlapbetweentheevaluation dataset and training dataset.
then we applied regression trees to each data point in the evaluation dataset and counted how oftenpamper s recommendation coincides with the proof methods chosen by human proof authors.
since there are often multiple equallyvalid proof methods for eachproofstate itisonlyreasonabletoexpectthat which method should be able to recommend the proof method used in the evaluationdatasetasoneofthemostimportantmethodsforeachproof methodinvocation.therefore foreachproofmethod wemeasuredhowofteneachproofmethodusedintheevaluationdatasetappears among the top nmethods in pamper s recommendations.
table2showstheresultsforthe15proofmethodsthataremost frequently used in the training data in the descending order.
forexample thetoprowfor simpshouldbeinterpretedasfollowing the simpmethodwasused102 441timesinthetraining data.
this amounts to .
of all proof method invocations inthe training data that are recorded by pamper.
in the evaluation dataset simpwas used times which amounts to .
of proofmethodinvocationsintheevaluationdatasetthatarerecordedbypamper.
for out of simpinvocations in the evaluation dataset pamperpredicted that simpis the most promising methodforthecorrespondingproofstates.for98 outof11 simpinvocationsintheevaluationdataset pamperrecommended thatsimpis either the most promising method or the second most promising method for the corresponding proof states.
notethatthenumberspresentedinthistablearenotthesuccess ratesofpamper srecommendationbutitsconservativeestimates.
assumepamperrecommends simpas the most promising method andautoas the second most promising method to a proof goal saypg in the evaluation dataset but the human proof author of pgchose to apply autoto this proof goal.
this does not immediately mean that pamperfailed to recommend autoin the first place becauseboth simpandautomightbeequallysuitablefor pg.
therefore the58 for simpmentionedaboveshouldbeinterpreted as follows pamper s recommendation coincides with the choice of experienced isabelle user for of times where human engineers appliedsimpwhenpamperisallowedtorecommendonlyoneproof method but the real success rate of pamper s recommendation can be higher than for these cases.
to avoid the confusion with successrate weintroducetheterm coincidencerate forthismeasure.
appendix of our technical report presents three tables to provide the complete list of the evaluation results.
the overall results of this evaluation are as follows pamper learnt methods from isabelle s standard library and the afp of them are defined within isabelle s standard library and the others are user defined proof methods specified in the afp entries.
out of the proof methods pamperlearnt from the training dataset proof methods appeared in the evaluation dataset.
out ofthese171proofmethodswithintheevaluationdataset 133methods are defined in isabelle s standard library and methods were defined by the afp authors.
thedistributionofproofmethodusageisheavilyimbalanced.
the three most frequently used proof methods simp auto and rule account for .
of all data points in the training dataset and the ten most frequently used methods account for .
in the trainingdataset.similarlyintheevaluationdataset thetopthree methods account for .
and the top ten methods for .
.
fig.
illustrates this imbalance in which the horizontal axis represents the rank of method usage for a proof method and the vertical axis stands for the number of methods invocations for thatproofmethod.forinstance thesquarelocatedatthetop left cornerdenotesthat themostfrequentlyused proofmethodinthe trainingdataset simp isused102 441times.andthecirclelocated at denotes that the sixth most frequently used method in the evaluation dataset fastforce is used times in the evaluationdataset.withtheuseoflogarithmicscaleonthevertical axis this figure presents the serious imbalance of proof method invocations occurring in isabelle s standard library and the afp.
fig.
summarises the overall performance of pamper.
in this figure the horizontal axis represents the number of proof methods pamperisallowedtorecommend 15bydefault whereastheverticalaxisrepresentsthenumberofproofmethods forwhich pamper achieves certain coincidence rates.
forexample thesquareat meansthat pampercanachieve of coincidence rate for methods if pamperis allowed to recommendthreemostpromisingmethods.similarly pamperachieves authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
ase september montpellier france yutaka nagashima and yilun he table evaluation of pamperon most frequently used proof methods.
proof method training evaluation simp .
.
auto .
.
rule .
.
blast .
.
metis .
.
fastforce .
.
force .
.
clarsimp .
.
cases .
.
erule .
.
subst .
.
rule tac .
.
intro .
.
simp all .
.
induct .
.
of coincidence rate for methods when recommending methods and for methods when recommending methods.
thenumberofmethods pamperthatachievedthefourcoincident rates and90 reachedaplateau when pamperis allowed to recommend about proof methods.
overall pamper s recommendations tend to coincide with humanengineers choicewhenisabellehasonlyonemethodthatis suitablefortheproofgoalathand whereas pamper srecommendations tend to differ from human engineers choice when there are multiple equally valid proof methods for the same goal.
for example pamper s coincidence rates are low for less commonly used general purpose methods such as safe clarimp best bestsimp because multiple general purpose proof methods can often handle the same proof goal equally well.
a careful observation at the raw evaluation results provided in the appendix of the technical report reveals that pamperprovides valuable recommendations when proof states are best handledbyspecialpurposeproofmethods suchas unfold locales transfer eventually elim standard and so on.
pamper s regression tree construction does not severely suffer from the imbalance among proof method invocation even though class imbalances often cause problems in other domains such as frauddetectionandmedicaldiagnosis .thecompleteevaluation resultsinappendixofthereportshowthat pamperachieved50 of coincidence rate for proof methods that appear less than .
of times in the training dataset.
the reason the imbalance did not cause serious problems to pamperisthatsomeoftheserarelyusedmethodsarespecialised proof methods for which we can write assertions that can ab stract the essence of the problem very well.
another reason is thefactthatcommonlyusedproofmethodstendtoholdupeach other s share since they address similar problems lowering expectationsforcommonlyusedgeneralpurposemethodswhereboth specialisedmethodsandgeneralpurposemethodscandischarge proof goals.on the other hand pamperdid not produce valuable recommendations to some special purpose proof methods such as vector andnormalization forwhichwedidnotmanagetodevelopassertions that capture the properties shared by the proof goals that thesemethodscanhandlewell.writingsuitableassertionsforthese remain as our future work.
some of the proof methods appearing in our evaluation dataset areclearlyoutsidethescopeof pamper.forexample cartouche tactic ml tactic rotate tac donothavemuchsemanticmeaning tacticissimplyaninterfacebetweenisabelle ssourcecode language standardml andisabelle sprooflanguage isar whereas rotate tac simplyrotatestheorderofpremiseswhenaproofgoal hasmultiplepremises.anothergoodexampleofproofmethodsout side the scope of pamperis themy simp method.
this method was definedinthestandardlibrarytotestthedomainspecificlanguage eisbach forwritingnewproofmethods my simpissimplyasynonymofsimpandnobodyisexpectedtouse my simp.predicting such methods is not a very meaningful task for pamper.
to our surprise table v in appendix of our technical report shows that pamper s recommendation achieved of coincidenceratefor 12methodsoutof38 user defined proofmethods defined outside isabelle s standard library appearing in the evaluation dataset when pamperis allowed to provide most promising proofmethods eventhough pamper sdevelopersdidnotknowanything about these proof methods at the time of development.
this suggeststhatonedoesnotneedtoknowtheproblemspecificinformationaboutproofgoalstopredicttheuseofsomeuser defined proof methods.
for example pamperachieves of coincidence rate forseprefwhen allowed to recommend only four methods by checking if the first sub goal has a schematic variable and if the first sub goal has variables of type record.
discussion and future work priortopamper isabellehadthe print methods command which merely lists the proof methods defined in the corresponding proof contextinalphabeticalorderignoringthepropertiesoftheproof authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
pamper proof method recommendation system for isabelle hol ase september montpellier france nth most commonly used proof method.number of method invocation.in training dataset in evaluation dataset figure fig.
method usage in large proof corpora.
number of methods pamperrecommends.methods above four coincidence rates.more than more than more than more than figure fig.
coincidence rate for pamper.
goalathand.therefore newisabelle holusershavetogothrough various documentations and the archive of mailing lists to learn how to prove lemmas in isabelle hol independently.
choosing the right methods was a difficult task for new itp users especially when they should choose special purpose proof methods sincenewuserstendnottoknoweventheexistenceof those rarely used proof methods.
some proof methods are strongly related to certain definitional mechanisms in isabelle.
therefore whenisabelleexpertsusesuchdefinitionalmechanisms theycan often guess which proof methods they should use later.
but this is not an easy task for new users.
and this problem is becoming severernowadays sincelargescaletheoremprovingprojectsare slowlybecomingpopularandnewitpusersoftenhavetotakeover proofscripts developedbyothers andtheyalso havetodischargeproof goals specified by others.
pamperaddressed this problem by systematicallytransferringexperiencedusers knowledgetoless experienced users.
we plan to keep improving pamperby incorporating other isabelle users intuitions as assertions.
our manually written feature extractor may seem to be naive compared to the recent success in machine learning research in someproblemdomains suchasimagerecognitionandthegameof go deep neural networks extract features of the subject matters via expensive training.
indeed others have applied deep neural networks to theorem proving but without much success .
the two major problems of automatic feature extraction for theoremprovingisthelackofenormousdatabaseneededtotraindeep neuralnetworksandtheexpressivenatureoftheunderlyinglanguage i.e.logic.thesecondproblem theexpressivenatureoflogic contributes to the first problem self respecting proof engineers tend to replace multiple similar propositions with one proposition fromwhichonecaneasilyconcludesimilarpropositions aimingat a succinct presentation of the underlying concept.
what is worse when working with modern itps it is often notenoughtoreasonaboutaproofgoal butonealsohastotake itsproofcontextintoconsideration.aproofcontextusuallycontains numerous auxiliary lemmas and nested definitions and each of them is a syntax tree making the effective automatic feature extraction harder.
furthermore wheneveraproofauthordefinesanewconstant or prove a new lemma isabelle hol changes the underlying proof context whichaffectshowoneshouldattackproofgoalsdefined withinthisproofcontext.andproofauthorsdoaddnewdefinitions because they use itps as specification tools as well as tools for theoremproving.someofthesechangesareminormodificationstoproof states that do not severely affect how to attack proof goals in the following proof scripts but in general changing proof contexts results in sometimes unexpected problems.
forthisreason eventhoughtheitpcommunityhaslargeproof corpora we essentially deal with different problems in each line of proofcorpus.forexample eventheafphas396articlesconsistingofmorethan100 000lemmas only4articlesareusedbymorethan articles in the afp indicating that many authors work on their ownspecifications creatingnewproblems.thisresultsinanimportant difference between theorem proving in an expressive logic and other machine learning domains such as image recognition where one can collect numerous instances of similar objects.
weaddressedthisproblemwithhuman machinecooperation thephilosophythatunderpinsitps.eventhoughitishardtoextract features automatically experienced itp users know that they can discharge many proof goals with shallow reasoning.
we encodedexperiencedisabelleusers expertiseasassertionstosimulate their shallow reasoning.
since these assertions are carefully handwritten in isabelle ml they can extract features of proof states including proof goal chained facts and its context despite the above mentioned problems.
currently pamperrecommends only which methods to use and shows why it suggests that method.
this is enough for special purposemethodsthatdonottakeparameters.forothermethods such asinduct it is often indispensable to pass the correct parameters to guide methods.
if you prefer to know which arguments to pass to the proof method pamperrecommends we would invite you to authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
ase september montpellier france yutaka nagashima and yilun he usepsl theproofstrategylanguageforisabelle hol which attemptstofindtherightcombinationofargumentsviaaniterative deepening depth first search based on rough ideas about which methodto use.if youwant tohavethose roughideas use pamper.
pamperconstructs regression trees of a fixed height.
we set the heighttoasmallnumber three toavoidover fitting.itmightbe possible that advanced pruning methods can improve the accuracy ofpamper s recommendation.
furthermore since we developed assertions based on our limited expertise it is likely that we havemissedoutinformationvaluabletorecommendproofmethods when abstracting proof states using assertions.
our cross validation showed that some simple assertions such ascheckingtheexistenceofcertainconstantsinproofgoals turned out to be useful.
therefore it might be possible to find more useful assertionsbysystematicallyenumeratingmoreassertionsofthis kindtochecktheexistenceofotherconstantsappearinginproof corpora.
unfortunately the database construction based on assertions already consumed serious computational resources and databaseconstructionbasedongeneratedassertionsremainsasour futureworkduetothelimitationofresourcescurrentlyavailable topamper s developers.
whenconductingthecross evaluation wefocusedonthecoincidencerateforeachmethod.itwouldbeworthwhiletocomparethe results of pamper s overall coincidence rate for all methods with the corresponding overall coincidence rate that would be producedbyanaivesystemthatrecommendsproofmethodsinorderoftheir frequency in training data without constructing decision trees.
finally our choice of machine learning algorithm is not final.
wecurrentlyuseregressiontreeconstructionalgorithmbasedona problem transformation method because the straightforward algorithmletsusproducequalitativeexplanationsof pamper srecommendation however othermachinelearningalgorithmsmightlead to higher coincidence rates.
the comparison of various machine learning algorithms on the dataset remains as our future work.
conclusion and related work we presented the design and implementation of pamper.
in the preparation phase pamperlearns which method to use from existingproofcorporausingregressiontreeconstructionalgorithm.
in the recommendation phase pamperrecommends which proof methods to use to a given proof goal and explains why it suggests that method.
our evaluation showed that pampertends to provide valuablerecommendationsespeciallyforspecialisedproofmethods which new isabelle users tend not to be aware of.
we also identifiedproblemsthatarisewhenapplyingmachinelearningto proof method recommendation and proposed our solution to them.
related work.
ml4pg extends a proof editor proof general tocollectproofstatisticsaboutshapesofgoals sequenceofapplied tactics and proof tree structures.
it also clusters the gathered data using machine learning algorithms in matlab and weka and provides proof hints during proof developments.
based on learning ml4pglistssimilarproofgoalsprovedsofar fromwhichuserscan inferhowtoattacktheproofgoalathand while pamperdirectly works on proof methods.
compared to ml4pg pamper s featureextractor is implemented within isabelle ml which made it possibletoinvestigatenotonlyproofgoalsthemselvesbutalsotheir surrounding proof context.
gauthier et al.developed tactictoe for hol4 .
it selects proved lemmas similar to the current proof goal using premise selectionandappliestacticsusedtothesesimilargoalstodischarge the current proof goal.
compared to tactictoe the abstraction via assertions allows pamperto provide valuable recommendations even when similar goals do not exist in the problem domain.
several people applied machine learning techniques to improve the so called hammer style tools.
for isabelle hol both mepo and mash decreased the quantity of facts passed to the automaticproverswhile increasingtheirqualityto improvesledgehammer sperformance.theirapproachesattempttochoosefacts that are likely to be useful to the given proof goal while pamper suggests proof methods that are likely to be useful to the goal.
mepo judgesthe relevance offacts by checkingthe occurrence ofsymbolsappearinginproofgoalsandavailablefacts whilemash computes the relevance using sparse naive bayes and k nearest neighbours.theydetectsimilaritiesbetweenproofgoalsandavailablefactsbycheckingmostlyformalization specificinformationand only two piece of meta information while pamperdiscards mostofproblemspecificinformationandfocusonmetainformation of proof goals the choice of relevant fact is a problem specific question while the choice of proof method largely depends on which isabelle s subsystem is used to specify a proof goal.
the original version of mash was using machine learning librariesinpython andblanchette etal.portedthemfrompython to standard ml for better efficiency and reliability.
similarly anearly version of pamperwas also using a python library untilweimplementedtheregressiontreeconstructionalgorithmin standard ml forbetter toolintegration andflexibility.
bothmash andpamperrecord learning results in persistent states outside the main memory so that users can preserve the learning results even after shutting down isabelle.
blanchette etal.analysedtheafp lookingatsizesanddependencies for theory files .
matichuk et al.investigated the sel4 proofs and two articles in the afp to find the relationship between the size of statement and the size of proof .
none of them analysed the occurrence of proof methods in their target proof corpora nor developed a recommendation system based on their results.
moreover pamper sdatabaseconstructionismoreactivecompared to their work it applies hand written assertions to analyse the properties of not only each proof goal but also the relationship between each goal and its background context and chained facts.