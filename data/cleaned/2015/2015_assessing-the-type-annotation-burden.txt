assessing the type annotation burden john paul ore department of computer science and engineering university of nebraska lincoln ne usa jore cse.unl.edusebastian elbaum department of computer science and engineering university of nebraska lincoln ne usa elbaum cse.unl.edu carrick detweiler department of computer science and engineering university of nebraska lincoln ne usa carrick cse.unl.edulambros karkazis department of computer science and engineering university of nebraska lincoln ne usa lkarkazis cse.unl.edu abstract type annotations provide a link between program variables and domain specific types.
when combined with a type system these annotations can enable early fault detection.
for type annotations tobecost effectiveinpractice theyneedtobebothaccurateand affordablefordevelopers.welack however anunderstandingof how burdensome type annotation is for developers.
hence this work explores threefundamental questions howaccurately do developers make type annotations how long does a single annotationtake and ifasystemcouldautomaticallysuggestatype annotation how beneficial to accuracy are correct suggestions and howdetrimentalareincorrectsuggestions?wepresentresultsof a study of programmers using random code artifacts that containvariableswithphysicalunittypesthatmustbeannotated.
subjectschooseacorrecttypeannotationonly51 ofthetimeand takeanaverageof 136secondstomake asinglecorrectannotation.
our qualitative analysis reveals that variable names and reasoning overmathematicaloperationsaretheleadingcluesfortypeselection.wefindthatsuggestingthecorrecttypeboostsaccuracyto whilemakingapoorsuggestiondecreasesaccuracyto28 .we alsoexplorewhatstate of the artautomatedtypeannotationsystemscan andcannotdo tohelpdevelopers withtypeannotations and identify implications for tool developers.
ccs concepts applied computing annotation software and its engineering softwaredefectanalysis theoryofcomputation type theory keywords abstract type inference physical units program analysis staticanalysis unit consistency dimensional analysis type checking robotic systems permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation on the first page.
copyrights for components of this work owned by others than acmmustbehonored.abstractingwithcreditispermitted.tocopyotherwise orrepublish topostonserversortoredistributetolists requirespriorspecificpermissionand ora fee.
request permissions from permissions acm.org.
ase september montpellier france association for computing machinery.
acm isbn ... .
reference format john paulore sebastianelbaum carrickdetweiler andlambroskarkazis.
.assessingthetypeannotationburden.in proceedingsofthe201833rd acm ieeeinternationalconferenceonautomatedsoftwareengineering ase september montpellier france.
acm new york ny usa 12pages.
introduction type checking is one of the most successful and enduring approachesforensuringdesirableprogramproperties .
indeed many empirical studies confirm the benefits of type systems .forexample prechelt etal.
demonstrated that type checking introduces fewer defects and allows programmerstoremovethosedefectsfaster hannenberg etal.
claimedstatictypesimprovemaintainability andspiza etal.
showed that type names alone even without static type checking improves the usability of apis.
conceptually typecheckingconsistsofthreeelements a type systemto define the abstract theory that can ensure the desired property a typemechanism toenforcetypeconsistency and a typeassociation tolinkprogramvariablestotheircorresponding types.
type association can occur through different means.
for common types such as int float o rstringthe association is often supported by the programming language and occurs when a variable is declared or is assigned some data of a known type.
for more domain specifictypes however developersmusttypicallyincorporatetypeannotations1 intothecode tolink avariable withatype therebymakingthe typeassociation.
several efforts have explored the benefits of such type annotations.
for example in the context of javascript gaoet al.
found thattypeannotationshelpfind15 ofbugsinopen sourceprojects.
injava xianget al.
showed the fault detection potential of annotatingwith real worldtypes wherevariablesrepresentmeasurablequantitiesintherealworld.for c or eetal.
check the physical unit type consistency of files written for the robot operatingsystem ros usingtypeassociationsinabuilt in map from class attributes of ros libraries to physical unit types.for c jiang and su checked programs for dimensional unit correctness using lightweight type annotations.
justlikeotherkindsofcodeannotation creatingtypeannotations is a burden for developers in part because they must first evaluate what program variables need annotation and then choose type annotations are sometimes also called type hints .
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
ase september montpellier france j. ore s. elbaum c. detweiler l. karkazis acorrecttypeannotation hencethename annotationburden .
but...how burdensome?
although many refer to the annotation burden as a given we lack an understanding of how accurately and quickly developers create type annotations and therefore have difficulty quantifying the benefits to developers.
this work presents an empirical study of subjects to first answer these foundational questions about type annotations rq1 how accurately do developers make type annotations?
rq2 how long does a single correct annotation take?
to answer these questions we design a study where we randomly select code snippets from artifacts in the robotic cyber physical domain.wethenaskdeveloperstoannotateavariablebychoosing a physical unit type from a list of common domain types and to explainwhytheymaketheannotation.toourknowledge thisis thefirstworktoquantifytheburdeninmakingtypeannotations and in general this work contributes to the limited body of data on code annotation.
we instantiate the type annotation task within the domain of physical unit types as identified by xiang et al.
s work on realworld types .
for example a variable that represents a spring constantin the real world would be annotated with the physical unit type newtons per meter nm .
the type system then checks for example that variables of this type are only added or assigned to other variables of this type.
we choose this domain because physical unit types are ubiquitous in robotic and cyber physical software yettheyarenearlyalways implicit andthelackofexplicit typing causes many type inconsistencies .
becauseofthebenefitsofannotations researchershaveexplored automatingtheannotationprocess includingwithautomatedannotationassistants.vakilian etal.
foundthatannotationworks bestwhendevelopersandautomatedtoolsworktogether.weimagine that automatic tools to suggest annotations will continue to improve but occasionally make an incorrect suggestion.
therefore this work also explores the impact of suggesting a type annotation rq3 howbeneficialtoaccuracyarecorrectsuggestionsand how detrimental are incorrect suggestions?
to address this question we apply to the study annotation questionsoneofthreetreatments withnosuggestion withacorrect suggestion and with an incorrect suggestion.
the key findings of this work are developersassign typeannotationscorrectly only51 .
of the time.
a developer takes on average .0sto correctly annotate a single variable.
acorrectsuggestion reducestheriskof assigningawrong type by a factor of .
while an incorrect suggestion increases the risk of annotating incorrectly by a factor of .
.
most subjects cite variable names alone as the clue to explaintheirannotation whileothersubjectsreferencehow reasoning over code operations informs their decisions.
state of the art tools suggest few correct type annotations and identifying what variables need to be typed is valuable to developers.
background physical unit types this work is instantiated in the type domain of physical units of measureandbasedonthesiunitsystem .thesiunitssystem hasseven baseunits eachofwhichcanitselfbeatype.additionally thesevenbaseunitscanbecombinedthroughmultiplicationand division to make compound units like kilogram meter squared persecond squared kgm2s more commonly known as torque.
physical units types have been explored in myriad efforts .notallvariablesbelongtothetypedomain.
forexample booleantypevariablesdonothaveaphysicalunits type while floatvariables can and often do represent a measured quantitywithreal worldmeaning andthereforehaveaphysical unittypeinadditiontotheirdatatype like float .determining whether a variable belongs in the physical unit type domain is part of the annotation burden.
thetypeannotationprocessinthephysicalunitdomaininvolves extractingcluesfromvariablenames comments andmathematical constraints.
for example a developer could infer that variable rin dist meters r time seconds probablyhasthetype meters per second ms .acompetentdeveloperwouldnotethatthevariables dist meters andtime secondsprobably have physical units types because of their names althoughthename rprovideslittlehelp.thenadevelopercould solve for the physical unit type of rusing simple algebra and perhapsrename rtorate meters per second .howeve r sometimes the name does not help for example the variable xin x .
cm doesnothintatypebutitlikelyhasthetype meters m becauseof the comment.
developers must choose a physical unit type from a large set of possible types but in practice some units are more commonthan others.
table 1shows the most common unit types ordered by decreasing frequency found in a large corpus of open source robotic code .
for our empirical study we use table 1as the list of possible type annotations with two additions no units for scalars and quantitiesthatarenotpartofthetypedomain and2 other for uncommon types like kilogram meter squared per second cubedper ampere one of our answers also known as voltage and to allowsubjectstothink beyondthechoicesprovided.including no unitsis essential because deciding what should be typed is the first part of the annotation burden.
methodology in this section we first describe the type annotation task and reiterateourresearchquestions.wethenpresentourexperimental designanddiscusshowweconstructedatestinstrumentwithcodeartifacts and how we selected those artifacts.
we then describe the target population and how we recruited and pre screened subjects for the experiment.
next we explain the experimental phases and finally discuss the tools used during the experiment and analysis.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
assessing the type annotation burden ase september montpellier france table common physical unit types from in decreasing order of frequency.
covered denotes whether any question s correct answer on the study was the type listed.
physical unit type si symbol covered meters m check second s quaternion q check radians per second rads check meters per second ms radians rad check meters per second squared ms check kilogram meters squared per second squared kgm2s check meters squared m2 degrees deg radians per second squared rads check meters squared per second squared m2s check kilogram meter per second squared kgms kilogram per second squared per ampere kgs 2a check celsius c kilogram per second squared kgs check kilogram per meter per second squared kgm 1s lux lx kilogram squared per meter squared per secondto the fourthkg2m 2s .
type annotation task research questions thetypeannotationtaskrequiresdeveloperstomakeatypeassociation between a variable and a type.
we assess the type annotation taskthroughanonlinetestwhereweshowcodesnippetstosubjects andask themtochoosea physicaltypeannotationfor aspecified variable.
as shown in figure a test question consists of a code snippet a highlighted variable a text question a suggestion forsome questions and a drop down menu of physical unit types.
thedrop downboxcontains21typeannotationsfromtable 1in random order from which subjects must select one.
the code snippets used in this study vary in length from lines averaging .9locand .
comments as measured by cloc .
of the test questions 20showanentirefunctionwhilesixaretruncated sothecodesnippetsfitontoonepage.
testquestionsliketheone showninfigure 1areinstancesofthetypeannotationtaskthatwe use to answer three rqs rq1 how accurately do developers make type annotations?
to answer this question we calculate the percentage of correct responses to a battery of type annotation tasks.
rq2 how long does a single annotation take?
to answer this question we measure the time to complete the type annotation task.
rq3 howbeneficialarecorrectsuggestionstoaccuracyand howdetrimentalareincorrectsuggestions?toanswerthis question we provide a single correct or incorrect suggestion tosomequestionsandmeasurethechangeinthepercentageof correct responses between questions without suggestions and questions with suggestions.afterthesubjectsfinalizetheirtypeannotationthroughtheunit selection they are asked to provide an open ended explanation for theirchoice.welaterusetheexplanationstohelpusunderstand howsubjectsreasonabouttypeannotations bothwhenthetype annotation is correct and when incorrect.
.
experimental design figure1 sampletestquestion.theyellowboxonline55in dicatesthevariabletobeannotated.thetestquestionshowstreatment t a correct suggestion.
to address our research questions simultaneously we design an experiment involving instances of the annotation task described earlier.inourexperiment wemeasurebothresponseaccuracyand the time it takes the subject to select and submit an annotation.
each test question like the example shown in figure has one of three treatments t1 no suggestion control .
a question with the suggestion section not included.
t2 correctsuggestion.aquestionwithacorrectsuggestion immediatelyabovethedrop downbox wherethetextofthe suggestion exactly matches one option in the drop down.
thesuggestionisaccompaniedbythecaveat suggestion might not be correct .
t3 incorrectsuggestion.thistreatmentisidenticalto t2exceptthesuggestionisincorrect.theincorrectsuggestionhasthesamecaveatasin t2andmatchesoneoptioninthedropdown box.
this incorrect suggestion is chosen randomly from table excluding the correct answer and other .
the measurements of accuracy and timing in response to t1answerbothrq 1andrq2andalsoarethecontrolforrq .toaddress authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
ase september montpellier france j. ore s. elbaum c. detweiler l. karkazis rq3 we compare the accuracy and time for test questions treated with t1to questions treated with t2andt3.
in this experiment theindependentvariable isthe suggestion and the dependent variables are annotation accuracy and time.
ourstudyusesa completelyrandomizeddesign .wegroup tenquestionsintoanannotationtest themaintest andrandomly assign subjects to tests.
we randomly apply a treatment to each questionandrandomizequestionorderforeachsubject.weensure that each test includes at least three questions of each treatment type to spread the treatments across subjects.
.
test instrument details question timing explanations and code artifacts.
questions include a snippet of a code artifact as shown in figure .
eachannotationquestionisinstrumentedtocollecttiminginformation specifically the duration from when the question is loaded to when the subjects finalize their answer.
asexplainedearlier afterthesubjectsfinalizetheiranswerto atypeannotationtestquestion weaskthemtoexplainwhythey chose that type in an open ended question.
we want to record explanations to understand how subjects reason about choosing an annotation type and what differentiates correct from incorrect responses.
the time to write the explanation is not included in the time to annotate.
the code artifacts come from a corpus of open source robotic and cyber physical code repositories identified in encompassingawidevarietyofapplications.thecorpuscontains797 410c filesfrom3 484githubrepositoriesthatbuildagainsttherobot operatingsystem ros aroboticmiddlewarewithmany real world types.
from those files we ran the tool phriky to identify31 928fileswithphysicalunittypevariables.afterexcluding test filesand those thatdid not compile we randomly select afile andstartingfromthetop wemanuallyidentifythefirstfunction with unit types and make a judgement about whether the function is sufficiently complex meaning that it contains either interaction between physical units or compound physical unit types see section2 .withinsuchfunctions werandomlyselectasinglevariable with a physical unit type.
we repeat this process until we have 20artifacts andeachartifactwasreviewedbyatleasttwoofthe authors.
finally we cross check the annotations one more time before the test and one more time during the test instrument evaluationphase.table 1showstheresultingdistributionofphysical unit types within the code artifacts we study.suggestions.
fortreatment t2 the21typesinthedrop downmenu arethe19mostcommonphysicalunitsfoundinacorpusofrobotic code plus no units andother see section .
for treatment t3 theincorrectsuggestionisrandomlyselectedfromtable 1minus the correct answer and other.
suggestions are randomized per test so each question has a variety of incorrect suggestions across tests.
type annotation options.
at the bottom of figure 1is a dropdownmenu withannotationtypechoices.
everyquestion regardless of treatment had the same type annotation options in a dropdown menu with the order randomized for every question to mitigate the threat of response order bias .
tests.we have a pool of artifacts each with a unique code snippetandcorrectanswer.wecompose20testswithadifferentrandomsubsetof10questionsrandomlyselectedfromtheinitial poolof20.werandomizequestionorderpersubject andrandomly assign treatments t1 t3to questions retaining a balanced number of treatments per test.
a version of the test instrument with all test questions can be found at .
subject sample population thesamplepopulationisuserswithprogrammingexperiencerecruited using amazon s mechanical turk mturk .
mturk is an onlinemarketplaceforlaborthatisincreasinglypopularforbehav iorresearch andhasanextensiveusageinsoftwareengineering .findingsubjectsonmturkisnotwithoutrisks especiallyindemographics buthasbeenshowntobe appropriate forresearchrequiringdiversecognition .themturkmechanismallowsfor exclusioncriterion topre screensubjectsbased on a demonstrated ability to complete mturk tasks successfully.
followingrecommendedpractices wepre screensubjects by requiring them to have completed tasks with approval in their mturk history and further screen subjects by requiringthemtopassapretestoftypeannotations.wepaysubjects a fixed amount for the pretest usd and main test usd regardless of accuracy since this has been shown to have little impact on quality among mturk workers .
we tell the subjects not to rush that they would be judged based on the accuracy oftheir responses to provide good explanations and to watch forrandom attention checks because this has been shown to increase performance.
table demographics for 71subjects.
years experienceprogramming c c c javaembedded systems cyber physical robotics at the beginning of the pretest we ask three demographic questions about experience with programming languages robotics and typeannotations.wewanttodetermineifsubjectdemographics would influence responses and to get a sense of who was participating in the study.
the first question relates to programminglanguages how many years of programming experience in languages like c c c java?
the second asks about embedded system programming years of experience programming embedded systems or robotic systems or cyber physical systems things that move or sense ?
table2shows a summary of the responses for the subjects who completed the main test.
as shown in the table of subjects indicate years experience with mostly statically typed languages and have more than one year of experience with robotic or embedded programming.
the thirdquestion yes no asks haveyouusedanycodeannotation frameworks?
71subjects indicatetheprevioususageof annotationframeworksandnametoolssuchas sal msdn resharper jetbrains and jsr .
we revisit the impact of these demographic factors in section .
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
assessing the type annotation burden ase september montpellier france .
tools in conducting these experiments we use several off the shelf tools amazon s mechanical turk mturk is used to recruit and pay subjects both for the pretest and the main tests.
we ensure subjectsanonymity asrequiredby ourinstitutional reviewboard irb 20170817412ex by tracking only the mturk worker id.
qualtrics isusedtocreateanddeploythetestinstruments randomize test question order per subject instrument the questions to recordtiminginformation recordresponses andgenerateaunique completion code used to pay subjects.
we configure qualtrics to prevent the same ip address from submitting multiple responses.r statisticalprogramminglanguage isusedfordataanalysis including the multinom function from the nnetpackage to build binomial log linear response models and the binompackage to calculate binomial confidence intervals.
we perform anova on timing questions using r saovfunction.
clang format is used to standardize the code formatting of the snippets shown to subjects.
.
study phases we conducted the study in two phases phase1 testinstrumentevaluationandrefinement.
inthis phase weiterativelyevaluatethetestinstrumentson27subjects each test with ten questions without suggestions.
based on this evaluation we replaced two trivially easy questions refined thesuggestionwording mightnotbecorrect andpretestdemographicinstructions notgradedorscored asrecommended by best practices for mturk in verified our annotations addedvisualhighlightstothevariablestobeannotated random izedthequestionorderpertest and addedarequiredexplanationtextboxfieldforeveryannotation.noneofthedataacquiredinthis phase is included in our results and the evaluation subjects are not eligible to take the main test.
figure code snippet used in the pretest.
phase2 testinstrumentdeploymentofpretest maintest.
we require subjects to pass a pretest.
in the pretest all subjects read two practice questions that serve as a tutorial and then must correctlyanswertwoannotationquestions.figure 2showsascreenshotofaquestionfromthepretest.thecorrecttypeassignment meters per second can be inferred from the variable name or thename of the variable assigned to it.
in total subjects started thepretest butonly487finishedit indicatingthatmanysubjects opted out of the task.
of those that finished the pretest .
of subjects passed the pretest.
after passing the pretest .
of subjects took the maintest whichtheyhadtostartwithin4hoursofthepretestand thenhad2hourstocomplete.wepaideachmain testsubject usd .
we received total responses to the main test.
2theeagle eyedreaderwillnoticewehave 71subjectswhotooka 10questiontest yet haveonly 417responses.wehadtoexclude 293responsesbecause thetestquestion order was accidentally not randomized early in this phase.
results we first address the accuracy of responses with no suggestions t1 the control treatment and examine how subjects demographicsimpact accuracy then examine t1 s timing and compare correct responses to incorrect responses.
next we explore the impact of suggestionsonaccuracy treatments t2andt3 respectively and then examine annotation timing by question difficulty.
finally we summarize the clues subjects reported using to choose a type.
.
rq 1results accuracy fortestquestionsundertreatment t1 withnosuggestions subjects correctlyannotate71 asshowninfigure .thefigure showsthemeananda95 binomialproportionconfidenceinterval of .
agresti coull .
.
.
.
.
.
accuracy figure annotation accuracy for control treatment t1.
table3showsdetailedstatisticsforaccuracyundertreatment t1.
asshowninthetable thereisawiderangeofaccuracybasedon the question.
based on the accuracy of test questions that received treatment t1 wegroupedquestionsintothreedifficultylevels easy medium hard .
figure5showstherangeofaccuracyforeachdifficultygroup oft1 no suggestion .
we make this grouping primarily to see if question difficulty correlates to the time necessary to assign a type.
previousexperiencehaslittleimpactonaccuracy.
subject s previous experience with programming languages robotics cyberphysical systems and experience with annotations described in section3.
doesnothaveasignificantimpactonaccuracy.subjects with years of programming experience n have a slightly higher mean accuracy than other subjects for years n for years n but without significance p .
.
surprisingly subjects with the least experience with robotics cyber physical have the highest accuracy n compared other subjects for years n for years n but that is within the noise p .
.
physical unit complexity has little impact on accuracy.
physical unit types in the si system have both base unit types likemeters and compoundunits types like kilogram meters persecond squared described in section .
the increasing complexity ofcompoundtypesdidnotappeartocorrelatetoinaccuracy.for example the correctanswer to q19andq20is the simplephysical unit type radian yet subjects incorrectly annotate this question more than any other times while the slightly more com plexquaternion on q12is never incorrectly annotated likely because the variable in q12is assigned from the well named function convertplanarphi2quaternion .
similarly compound physical units like kilogram meter squared per second squared onq17is incorrect5 6times while thesimilar compoundunits kilogram persecond squared isansweredincorrectly4 10timesin q2.overall the complexity inherent in the physical unit type seems less important than the surrounding clues especially good variable names.
rq1accuracyresults manually assigning type annotations is error prone accurate .
.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
ase september montpellier france j. ore s. elbaum c. detweiler l. karkazis .
rq 2results timing the timing data includes outliers because our test mechanism has a long time bound hours .
we cap the value of timing outliers using tukey s interquartile gate range method .
tukey s method identifies outliers using a scaling factor ktimes the interquartile range plus the third quartile and suggests k .
we use an even more conservative k to identify outliers to cap for upper and lower quartiles q1 and q3 we cap values above q3 k q3 q1 with k .intotal wecapquestiontimesgreater than .6s to the sample mean s value .1s.
hardmediumeasyall secondsresponse correct incorrect figure4 timetocompleteasingleannotation separatedby question difficulty and correctness annotation.subjectstakeanaverageof .0s median .6s tomakea single correct type annotation.
the results for annotation timesare shown in figure grouped by question difficulty and correctness.
correct annotations are slightly faster than incorrect ones mean .2s but not significantly faster p .
.
as shown in the figure the average time to assign a type annotation for all is nearly the same whether correct or incorrect with slightly more variance for incorrect answers.
hard questions mean .7s tendtotakelongertoanswercorrectlythan easy questions mean .3s but without statistical significance p .
likely because few hard questions were answered correctly wewouldhaveneededseveralmorehardquestionsto have enough statistical power .
rq2timing results assigning type annotations is timeintensive mean .0s median .6sper variable .
table accuracy and time for questions by treatment.
q difficultycontrol treatments t1no suggestion t2correct suggestion t3incorrect suggestion correct time s correct time s correct time s fraction mean median fraction mean median fraction mean median easy1006 all easy medium674 all medium hard171 all hard all questions authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
assessing the type annotation burden ase september montpellier france table accuracy by treatment.
risk ratio lines show a multiplication factor indicating the likelihood of an incorrect type annotation with a confidence interval.
a risk ratio of 2means twice as likely.
treatment correct responses subjects risk ratio of incorrect type annotation p value t1no suggestion control .
12345t2correct suggestion .
t3incorrect suggestion .
.
rq 3results impact of suggestions on accuracy rq3considers the impact of a single suggestion on the accuracy and timing of type annotations.
as discussed in section .
subjects are supplied with a type annotation suggestion immediately below the question text as shown in figure either correct t2 or incorrect t3 .
to measure the significance of the impact of suggestions we fit a binomial loglinear response model the model .
we use a binomial responsemodel because the test question responses are either correct orincorrect .
the output of the model includes the risk ratio by treatment.
the risk ratio is used in log linear models to quan tify the likelihood of a binomial response.
a risk ratio in our study means an increased risk of assigning an incorrect type when compared to the control t .
as shown in table a correct suggestion t2decreases the risk ofannotatingincorrectly p .
comparedto t1.themodel predictsthat t2reducestheriskofassigningawrongtypebya0 .
.
.
confidence .anincorrectsuggestion t3increases theriskofannotatingincorrectly p .
comparedto t1.the model predicts that t3increases the risk of assigning a wrong type by .
.
.
confidence .
these p values indicate that treatments t2andt3have a significant impact on annotation accuracy.
treatments t2andt3are also significantly different from each other p .281e .
fortreatment t3 incorrectsuggestion ofthe71subjectsproviding responses responses are incorrect.
of these responses tookthebait ofusingtheprovidedincorrectsuggestion.
regarding subjects this corresponds to that used an incorrect suggestion for an annotation.the most common incorrect annotation for t2 and t3 was no units meaning users infer that the units canceled outorthatthecorrectanswerwasascalar.thenextmostcommon incorrect annotations are meters t24 t312 and other t2 t37 .
figure5shows the range of accuracy for all treatments by questiondifficulty.asshowninthefigure anincorrectsuggestion t3 reducesaccuracyforeasy andmedium questions with little impact on hard questions.
correct suggestions t2benefit all questions compared to t1 with similar improvements for hard and medium questions while only helping easy questions by .
rq3accuracyresults incorrectsuggestionsincreasetheriskof incorrectannotationsbyafactorof2 .
whilecorrectsuggestions reduce the risk of incorrect annotations by a factor of .
an approximately equal but opposite impact on annotation accuracy.
.
rq 3results impactofsuggestionsontime figure6shows the impact of a suggestion on the time required to provide a correct annotation.
the three difficulty levels are shown along with the category all.
for the group all correct annotationsarefastestin t2 correctsuggestion mean .1s compared to33 longerwith t3 incorrectsuggestions mean .5s and longer with t1 no suggestion mean .0s .
the difference between the time between t2andt3is not significant p .
.
correct suggestions have the least impact on the timing of easy questions.
this small impact makes sense intuitively since easy questionsbenefitlessfromasuggestion.correctsuggestionstendto incorrect suggestioncorrect suggestionno suggestion .
.
.
.
.
accuracy easy mediumhard figure accuracy by treatment and difficulty showing confidence interval.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
ase september montpellier france j. ore s. elbaum c. detweiler l. karkazis hardmediumeasyall secondstreatment no suggestions.
one suggestion correct.one suggestion incorrect.
figure timing by difficulty and treatment for correct responses.
reduce the time required for hard questions as shown in figure althoughwithoutstatisticalsignificancethatweattributetohaving fewcorrecthardanswers.incorrectsuggestions t3tendtoincrease thetimetoannotatebothmediumandhardquestions butwithout significance.
rq3timingresults althoughadefinitiveanswerrequiresfurther study correct suggestions appear to decrease the time for correct annotations the most for hard type annotations.
.
clues for choosing a type sections4.
.3provided a quantitative analysis of the responses revealinganaccuracyof51 whichwassurprisinglylowandwhich led us to further explore the clues that led developers to choose aparticulartype.weconductedthisexplorationbycollectingall the explanations provided by the developers on all their responses andanalyzingthemusingagroundedtheory approach.we categorizedtheanswersbasedonwhatweperceivedwerecommon patterns reorganizingtheclustersduringiterativephasesasnew and better patterns emerged.
during the first iteration we applied twelvelabels.afterthreeiterations weconvergedtosixclusters andassignedthemalabel asshownintable discriminatedby correctness and treatment.
themostcommonclueusedbydevelopersforboth correctand incorrectanswers for t1wasvariable namesonly usedfor71 of all annotations.
the caveat is that although all variables had a name not all of the code snippets included comments or mathematical operations we discuss them next .
but at least from a qualitative point of view we note that the explanations tended to convey the value of meaningful identifiers q17 at least i hope torque is referring to torque.mathreasoningandnames werefrequentlyusedwhenexplaining thecorrectanswers.forexample thisisanexplanationforacorrect answer to the question in figure q4 vx cos th vy sin th willgiveaquantityinm s. since dt is a quantity in seconds multiplying by that will yield meters.
errors due to poor math reasoning were present but less frequent than we expected.
as an example for the same question we find q4 meters per second times dt would cause the seconds to cancel out and the meters to square where cause...the meters to square is incorrect.
code comments were also used as effective clues with more correct n thanincorrectanswers n .wenotethatonly two questions q6andq8 contained clues in comments which may be representative of how common comments are in spite of their value for inferring types.
incorrect answers for treatment t1 werecommonforvariablesnotinthetypedomain no units as subjectsdidnotseemabletogatherenoughcluestodeterminethat the type system even applied.
fiverespondentsexplicitlystatedthatthesuggestionsfrom t2 helped and respondents stated that they were misguided by t3.
these values however constitute lower bounds as subjects may not have confided us with the full extent to which they usethe suggestion.
still the fact that for t330 of incorrect answers matched the incorrect suggestion we provided illustrates the large potential impact of suggestions on developers actions.
qualitativeresults themaincluesfortypeselectionarevariable names and reasoning over mathematical operations.
table summary of type annotation explanations for 417answers.
explanation categorycorrect responses incorrect responses t1 t2 t3 t1 t2 t3 names only math reasoning and names code comments not in type domain no units used suggestion type depends on input authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
assessing the type annotation burden ase september montpellier france threats to validity .
external threats subjects might not represent developers.
we mitigate this hazard by requiring respondents to complete a pretest that at least shows that respondents could understand the task read code and correctly identify the physical units that should be assigned to program variables during annotation.
since subjects were not specificallytrainedtomaketypeannotations ouraccuracymeasurements likely under approximates the performance of trained developers.
annotation task fidelity.
the annotation task defined in section3withphysicalunittypesin c mightnotgeneralizeother type annotations.
first type systems vary in complexity and physical unit types might be more or less complicated time consuming than all type systems in general.
we observe that type annotation requires developer time and involves reasoning about boththe type system and how types interact with the code.
second our study examines type annotations made by non authors likely under approximating our accuracy measurements.
observing code authors could improve fidelity in follow on work.
unrepresentative code artifacts.
thecodeartifactsmightnot represent code that needs type annotation more generally.
we mitigate this threat by selecting artifacts randomly from a largecorpus .9mloc although all our samples are for a stronglytypedlanguage c .welimitedthescopeofanalysistoafunction the accuracy and time might be different for bigger scopes.
.
internal threats subjectsrecruitedthroughmturk.
werecruitedsubjectsthrough mturk and indicates mturk subjects might falsify demographic information to participate in online tests.
we mitigate this threat by clearly stating on the pretest that demographic question are not graded or scored.
we also filtered subjects and provided incentives for them to take the task seriously.
code context bias.
bias introduced by our artifacts including the amount of context or the variety of physical unit types.
we mitigatethisthreatbyshowingtheentirefunctionwhenfeasible and testing the questions during an evaluation phase to make sure it was possible to choose the correct type annotation with the available information.
test instrument format.
the question and suggestion format as provided does not reflect the full context on how a developer operatesinrealityandmayhaveaffectedthesubjectsinwayswe did not anticipate.
the test instrumentation and refinement phase helped mitigate this threat.physicalunittypecommonnames.
commonnamesforphysical unit types like force instead of kilogram meters per secondsquared are not an option in the drop down box.
we mitigate this threat by examining every explanation.
if subjects identified an equivalent common name for the physical unit type and answered otherorsaidtheycouldnotfindtheunitsinthedrop downbox weconsidertheanswerascorrect.weconsidered7 417answers as correct because of a common name.testtimewindow.
wemeasurethetimetocompleteannotation questions but allow a large time window hours to complete the whole test during which subjects might take breaks or do other tasks or take the entire allotted time to find the correct answer ceiling effect resulting in longer times to answer annotation questions.thereforeourtimingvaluesmightover approximatethe time to assign a type annotation.
we mitigate this threat by identifying and capping timing outliers.
more importantly our timing onlycapturesannotationtime butwerecognizethatdeveloper s time may be spent in for example pursuing leads generated by incorrect annotations.
.
conclusion threats statisticalsignificance.
wedonothaveenoughsubjects n tofind statisticalsignificance forsomeof ourhypotheses thathave cleartrends becauseweexhaustedtheresourcesavailabletoget moresubjectsatthistimeandunanticipateddatadistributionacross someofthefactorsweconsidered.forexample thetimeconsumed by questions of different difficulty was not found to be statistically significant because there were few hard questions with correct responses.further thisdatadistributiondoesnothavestatistical significancewhensegmentingresponsesbydemographics.inthe future we will address such limitations by deploying more tests andbymonitoringtheresultsto reassignquestionstosubjectsto even out the desired distributions.
discussion and implications section4.3indicatedthattypeannotationsuggestionscanhavea significant impact on accuracy.
building on that insight we briefly exploretheperformanceofatypeannotationtoolforthesametypedomain physicalunits.morespecifically weselecttheopen source tool phriky version .
.
that analyzes c written for the robotoperatingsystem ros .weselectedphrikybecauseitis open source operatesonros c code isstate of the art andcan automaticallysuggestphysicalunittypesforsomeprogramvariables.forexample infigure lines18 19defineastructure msgof type geometry msgs twist .
phriky has a lookup table mapping the attributes of this message class to physical units.
this mapping enables phriky to infer in line that the attribute msg.linear.x has the physical unit type meters per second.
table6showsthetoolphriky sphysicalunittypepredictions for each variable that was used in a test question.
we obtained thesesuggestionsbyrunningphriky debug print ast oneach file containing the code snippets used in the test and recording what physical unit type is assigned to the variable.
as shown in the table phriky makes a suggestion for only of the variables correcttype suggestionsfor ofvariables and incorrectsuggestionsfor2 ofvariables.existingtoolshave an opportunity to address some of the challenges.
the implications for tools developers include asfigure 5shows correctsuggestionsaremostbeneficial for hard type annotations and therefore tool developers will have a greater impact making correct suggestions in hard cases.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
ase september montpellier france j. ore s. elbaum c. detweiler l. karkazis table6 correcttypesforeachquestioncomparedto phriky units annotations.
ordered by question difficulty.
q difficulty variable namecorrect typephriky suggestion easypose.orientation q check delta d m check robotspeed.angular.z rads x2 m2 mediumdelta x m w rads av rads path move tol m springconstant kgs ratio to consume no units x no units wrench out.wrench.force.y kgms check data gyro z ms check xi m motor .voltage other hardreturn m angular velocity covariance rads torque kgm2s check anglesmsg.z rad dyaw rad findingvariablesthatlikelyneedtypeannotationsisvaluable because developers struggle to know what variables belong to the type domain.
evidence that implies a type might also suggest a new variable name with better type clues.
suggestatypeonlywhen confident becauseincorrect suggestions hurt as much as correct suggestions help.
related work empiricalstudies oftypessystems.
severalempiricalstudies confirm the benefits of type systems.
prechelt and tichy comparedtheimpactofstatictypecheckingonstudentprogrammers using ansi c and k r where ansi c s compiler type checked procedure arguments and found fewer defects in programs written withstatictypechecking.likethiswork weareinterestedinthe empiricalmeasurementoftypes butunlikethiswork weuseexistingcodeartifactsinsteadofnewones.variousefforts claimed static typing improves reliability maintainability and understandabilityofstaticallytypedprogramsincomparisontodynamic types.
while those works weighed the costs and benefits of type systems we focus on the costs of the type annotation process.
type names even without type checking improve the usability of apis androjasandfraser emphasizedtheimportanceof semantically useful names.
we likewise find that variable names contain informative clues but unlike their work we also find that a misunderstood name can lead to incorrect type annotations.
type annotations.
gao bird andbarr examinedhowtype annotations can detect bugs in javascript and quantified the annotationburdeninterms ofa timetaxandtokentax.theauthors measured their own annotation effort and reported the time and numberoftokenstoannotatetodetect onebug.usingtheir token tax token annotation per bug and time tax time per bug we infer their time per single annotation to be .8sfor typescriptand135.8sforflow.wemeasuredanuncannilysimilar .0sfor asingletypeannotation eventhoughthetask language skilllevel andtypedomainaredifferent.liketheirwork weareinterested inthecostoftypeannotation butunliketheirwork wemeasure the time for a population of individuals and not the three authorsthemselves.
xiang etal.proposea kindofprogramanalysis with real worldtypes .thisanalysisrequiresthatananalyst examine all program tokens to decide what needs to be annotated.
type annotation tools and suggestions.
nimmer and ernst evaluated the factors that made an annotation assistant useful .
like their work we perform an empirical evaluation and unliketheir work we focus on type annotations instead of assertions.
thetypequalifiertoolcascadeshowsbetterresultsbyinvolving programmersratherthan byautomaticinferencealone .like their work we consider automatic inference mixed with developer inputtobeanaturalnextstep.parninandorso sworkonautomatic suggestions in fault isolation showed that when a tool makes multiple suggestions to a developer only the first suggestion is likely to be used.
we likewise make only one suggestion and leave for future work a study of multiple suggestions.
conclusion this work contributes a rich characterization of type annotation accuracy and cost.
our findings reveal that user annotations are wrongalmosthalfofthetimeandthatcorrectlyannotatingasinglevariabletakesonaveragemorethantwominutes.througha qualitative analysis of the annotation explanations we find that variable naming and reasoning over the space of operations on the types were the most common culprits of incorrect annotations.
giventhechallengeofcorrectlyannotatingcode thereissignificant potential for automated tools to reduce this burden however they could misguide the developer if the suggestions are incorrect.
further existingtoolsthatprovidesuchautomationonlycovera small portion of the annotation space.
inthefuture wewillbroadenthecontextofthisstudytoinclude richer kinds of annotations over larger scopes todetermine when our findings generalize.
this would help to further close the gap in our understanding of the costsand benefits of annotations.
we would also like to consider the follow up phase when the annotations are consumed by either the developer or another tool tomore precisely understand the cost of incorrect annotations and thenumberofcorrectannotationsthatareneededtoreceivetangiblebenefits.last wewouldliketobuildonexistingtechniques and tools for automating type suggestions especially to cover a greaterportionoftheannotationspaceandtoexplorehybridanno tation mechanisms all while taking into consideration the baseline accuracy and cost identified in this paper.
acknowledgment wethank oursubjects fortaking partinthe study.we wouldalso liketothanknimbuslabmembersurjaacharya carlhildebrandt ajay shankar and adam plowcha for providing feedback on early versionsofthetypeannotationtestinstrument.thisworkissupported by nsf award ccf .
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
assessing the type annotation burden ase september montpellier france