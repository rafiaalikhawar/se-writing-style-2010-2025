performance diagnosis for inefficient loops linhai song fireeye inc. linhai.song fireeye.comshan lu university of chicago shanlu uchicago.edu abstract writing efficient software is difficult.
design and implementation defects can cause severe performance degradation.
unfortunately existing performance diagnosis techniques like profilers are still preliminary.
they can locate code regions that consume resources but not the ones that waste resources.
in this paper we first design a root cause and fix strategy taxonomy for inefficient loops one of the most common performance problems in the field.
we then design a static dynamic hybrid analysis tool ldoctor to provide accurate performance diagnosis for loops.
we further use sampling techniques to lower the run time overhead without degrading the accuracy or latency of ldoctor diagnosis.
evaluation using real world performance problems shows that ldoctor can provide better coverage and accuracy than existing techniques with low overhead.
keywords performance diagnosis debugging loop inefficiency i. i ntroduction a. motivation performance bugs are software implementation mistakes that cause unnecessary performance degradation in software.
they widely exist in deployed software due to the complexity of modern software .
they annoy end users and waste energy during production runs and have already caused highly publicized failures .
tools that can help developers quickly and accurately diagnose performance problems are sorely desired.
performance diagnosis is different from performance testing or bug detection it does notaim to expose previously unknown performance anomalies.
instead it is similar with general failure diagnosis it is applied after an unexpected software behavior i.e.
symptom is observed hoping to identify the root cause of this symptom and suggest strategies to eliminate this symptom.
in the context of performance problems the symptom is execution slowness the root cause is about which code region is inefficient and why.
an effective diagnosis tool can help developers quickly and correctly understand and fix already exposed performance symptoms.
also like general failure diagnosis ideal performance diagnosis tools should satisfy three criteria.
coverage.
real world performance problems are caused by a wide variety of reasons.
a good diagnosis tool should handle a good portion of them.
accuracy.
which code regions are inefficient and why they are inefficient need to be accurately identified.
linhai finished this work while he was at university of wisconsin.
performance.
diagnosis often requires collecting run time information.
the lower the overhead is the easier for the tool to deploy especially for production run usage.
no existing tools can satisfy these three requirements.
profiling is the state of practice in performance diagnosis.
it is far from providing the desired accuracy as it is designed to tell where computation resources are spent but not where and why resources are wasted.
in many cases the root cause function may not even get ranked by the profiler .
performance bug detection tools use program analysis to identify code regions that match specific inefficiency patterns .
unfortunately these tools are not designed and hence are unsuitable to identify code regions that contribute to a specific slowness symptom.
they do not provide coverage for a wide variety of real world problems they are not guided by performance failure symptoms and hence are at disadvantage in terms of diagnosis accuracy dynamic detection tools often lead to 10x slowdowns or more not ideal in terms of performance .
recently progress has been made on statistical debugging for performance diagnosis .
this approach compares runs with and without problematic performance and identifies control flow constructs such as a branch bor a loop l that are most correlated with the execution slowness.
unfortunately this approach is not effective for loop related performance problems which contribute to two thirds of real world performance problems studied in previous work .
it cannot tell whether and how loop lis inefficient and hence is limited in its diagnosis coverage and accuracy .
figure shows a performance problem in gcc.
recursive function mult alg computes the best algorithm for multiplying t a time consuming computation.
at run time mult alg is often invoked for many times and often with the same parameter partly due to its recursive nature.
to avoid redundant computation across different instances ofmult alg developers used a hash table alg hash to remember which parameter thas been processed in the past and what is the result.
unfortunately a mistake in the type declaration of hash table entry hash entry makes the memoization useless for large t. in many cases a slow path is taken when the fast path should have been taken.
this mistake does not affect software correctness but causes a large amount of redundant computation1and hurts gcc 1this will be considered as a loop redundancy problem later in this paper as we consider recursive functions as a special case of loops.
ieee acm 39th international conference on software engineering ieee acm 39th international conference on software engineering .
ieee authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
struct hash entry unsigned int t host wide uint t void mult alg ... host wide uint t ... hash index hash t if alg hash .t t fast path reuse previous results else slow path expensive recursive computation ... mult alg ... fig.
a real world performance bug in gcc the and demonstrate the patch variable and function names are simplified for demonstration purposes performance severely causing hundreds of times slow down for gcc test cases.
debugging this performance problem is challenging.
according to the discussion forum of gcc developers identified mult alg as the most time consuming function through profilers early on.
however they did not figure out whether mult alg is inefficient which part of it is inefficient mult alg is a large function with about lines of code and how it is inefficient until several weeks later.
if a tool can tell developers not only which loop or function is responsible for execution slowness but also why and how it is inefficient diagnosis and fixing would be much easier.
b. contributions this paper presents a tool ldoctor that can help effectively diagnose inefficient loop problems the most common type of performance problems with good coverage accuracy and performance.
after users or developers observe a performance failure symptom ldoctor can automatically judge whether the symptom is caused by inefficient loops and provide detailed root cause information that helps understand and fix inefficient loops.
ldoctor tackles this challenging problem in three steps.
first figuring out a root cause taxonomy for inefficient loops.
our taxonomy categorizes all inefficient loops into two main categories resultless when a large amount of computation produces no side effects and redundancy when a large amount of computation produces already available results.
each main category is further divided to sub categories.
we strive to make the taxonomy both general enough to cover common inefficient loops and specific enough to guide the design of ldoctor and eventually help developers understand and fix performance problems section ii .
second building a tool kit ldoctor that can automatically and accurately identify whether and how a suspicious loop is inefficient following these principles section iii focused checking.
different from performance bug detectors that blindly check the whole software ldoctor focuses on loops that are most correlated with performance symptoms.
this focus is crucial for ldoctor to achieve both high accuracy and high coverage.
for sn script start offset !sn sn sn next offset sn delta if offset target return sn script is a linked list with one node for each byte code instruction in a javascript file fig.
a resultless ?
bug in mozilla taxonomy guided design.
to provide good coverage we follow the root cause taxonomy discussed above and design analysis routines for every root cause category.
given a candidate loop ldoctor applies a series of analysis to see if it matches any type of inefficiency.
static dynamic hybrid analysis.
static analysis alone cannot accurately identify inefficiency root causes as some inefficiency only happens or matters under specific workload dynamic analysis alone will cause too large run time overhead.
therefore we use a hybrid approach to achieve both performance and accuracy goals.
third using sampling to further lower the run time overhead of ldoctor without degrading diagnosis capability.
random sampling is a natural fit for performance diagnosis due to the repetitive nature of inefficient loops section iii b3 .
we evaluated ldoctor on real world performance problems coming from two representative benchmark suites .
evaluation results show that ldoctor can accurately identify detailed root cause for all benchmarks and provide correct fix strategy suggestion for most benchmarks.
all of these are achieved with low run time overhead.
ii.
r oot cause taxonomy to guide the design of automated diagnosis tools we need a taxonomy for inefficient loops that satisfies three requirements coverage covering a big portion of real world inefficient loop problems actionability each root cause category being informative enough to help developers fix a performance problem generality allowing automated diagnosis to be applied to many applications.
previous work identified a wide variety of performance rootcause categories.
however existing taxonomies do not satisfy all these requirements and hence cannot be directly used by us.
therefore we have designed our own taxonomy as presented below.
we will discuss how our taxonomy meets these three requirements qualitatively in this section and quantitatively using real world performance bugs in section iv .
a. resultless loops resultless loops spend a lot of time in computation that does not produce results useful after the loop i.e.
no side effects .
they can be further categorized to four sub types based on which part of the loop is not producing useful results.
loops never produce any results in any iteration.
they are rare in mature software systems.
how to fix?
they should be deleted from software.
?
loops only produce results in the last iteration if any.
they are often related to search check a sequence of elements authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
if warning candidate p add expr for tmp to tmp tmp tmp next if candidate equal p tmp expr add expr !tmp writer ... tmp writer add writer fig.
a resultless bug in gcc one by one until the right one is found.
whether these loops are efficient or not depends on the workload.
an example is shown in figure .
large javascript files often fill the script list with tens of thousands of nodes and cause poor performance.
how to fix?
they are often fixed by data structure changes.
for example the patch for the bug in figure simply replaced thescript list with a hash table.
loops may or may not produce results in each iteration.
for some workload the majority of iterations do not produce results and cause performance problems perceived by users.
figure shows such an example.
users complained that compilation became extremely slow when the wsequence point checking is enabled.
the slowness was caused by the for loop in the figure.
as the algorithm behind this loop has quadratic complexity in the number of operands in an expression programs with long expressions suffer severe slow downs.
after further diagnosis developers observed that this loop rarely had any side effects as the if condition was rarely satisfied.
how to fix?
the patch shown in figure reflects the typical fix strategy for this type of inefficient loops.
the developers should think about what exactly is the condition for the loop to produce results and use that condition to skip the whole loop whenever possible.
loops in this category always generate results in almost all iterations.
they are inefficient because their results are useless due to high level semantic reasons.
for example several mozilla performance problems are caused by loops that contain intensive gui operations whose graphical outcome may not be observed by humans and hence can be optimized.
how to fix?
since a deep understanding of software semantics is required to understand the inefficiency of these loops the fix strategies for these loops likely vary from case to case and are difficult to automate.
b. redundant loops redundant loops spend a lot of time in repeating computation that is already conducted.
they can be further categorized to two sub types based on which part of the loop is the unit of redundancy.
cross iteration redundancy one iteration repeats what was already done by an earlier iteration of the same loop.
here we consider a recursive function as a loop treating one function call instance as one loop iteration.
how to fix?
intuitively most redundancy problems can be fixed through memoization or batching either caching the earlier computation results and skip some following iterations char sss xph generate node t anode int count for n anode n n anode prev if n localname anode localname n namespaceuri anode namespaceuri count ... called for every node in a list fig.
a cross loop redundant bug in mozilla or combining multiple iterations work together.
for example the bug shown in figure is caused by redundant computation across different invocations of recursive function mult alg .
the patch essentially enables memoization.
cross loop redundancy one dynamic instance of a loop spends a big chunk if not all of its computation in repeating the work already done by an earlier instance of the same loop.
how to fix?
just like that in cross iteration redundancy memoization and batching are the typical fix strategies for this type of loops.
mozilla shown in figure is an example.
the buggy loop counts how many previous siblings of the input anode have the same name and uri.
there is an outer loop not shown in the figure that repeatedly updates anode to be its next sibling and calls sss xph generate with the new anode .
this bug is fixed by adding an extra field for each node to save the calculated count so that a new count value can be calculated by simply adding one to the saved count value of the nearest previous sibling with the same name and uri.
intuitively the above categories cover many common inefficient loop problems each sub category is concrete to guide the design of a diagnosis tool none of these sub categories involve application specific knowledges or heuristics.
iii.
ld octor design the design of ldoctor follows three principles.
first symptom oriented .
ldoctor will be used together with other performance diagnosis tools or profilers and focus on a small number of loops that are most correlated with a specific already observed performance symptom instead of the whole program.
therefore we will have different design trade offs in terms of coverage and accuracy comparing with bug detection tools.
second static dynamic hybrid .
static analysis alone cannot provide all the needed information to judge whether a loop is inefficient.
however dynamic analysis alone will incur too much overhead.
therefore we use a hybrid approach throughout our design.
third sampling .
loop related performance problems have the unique nature of repetitiveness which make them a natural fit for random sampling.
we will design different sampling schemes for different analysis.
we envision ldoctor to be used in the following way.
existing profilers and statistical debugging tool first identify suspicious loops that are most correlated with certain performance symptoms .
ldoctor will then apply a series of analysis to judge whether a given loop belongs to any root cause type discussed in section ii and recommend corresponding fix strategy.
this series of analysis could be authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
conducted during either in house diagnosis where failuretriggering inputs are available or production runs with the run time analysis component of ldoctor running at user sites.
a. resultless checker our resultless checker includes two parts.
first we use static analysis to figure out which are the side effect instructions in a loop and hence decide whether a loop might belong to ?
or .
second to determine whether ?
and loops are indeed inefficient under specific workload we use dynamic analysis to figure out what portion of loop iterations are resultless at run time.
static analysis ldoctor considers two types of instructions as side effect instructions writes to heap or global variables writes to stack variables defined outside the loop and may be used after the loop checked through liveness analysis .
ldoctor also analyzes all functions called by a loop directly or indirectly a function fthat updates variables defined outside fmakes the corresponding call statement in f s caller a side effect instruction.
ldoctor then categorizes loops into four types.
given a natural loop l when lcontains at least one side effect instruction along every path that starts from the loop header and ends at the loop header it is a loop if there exists at least one sideeffect instruction inside l but not on every path it is a loop if there is no side effect instructions inside l lis either a or a ?
loop which will be differentiated by checking all the loop exit blocks.
for example the loop in figure is ?
because its exit block on line contains side effects.
dynamic monitoring further checking is conducted to determine whether ?
and loops are inefficient.
for a ?
loop since it only generates results in the last iteration we only need to know the total number of loop iterations of each loop instance to figure out the loop resultful rate which we define as the ratio between the number of iterations with side effects and the total number of iterations.
the implementation is straightforward we initialize a local counter to be in the pre header of the loop we increase the counter by in the loop header to count the number of iterations we dump that counter to log when the loop exits.
for we need to count not only the total number of iterations but also the exact number of iterations that execute side effect instructions at run time.
to do that our instrumentation uses a local boolean variable hasresult to represent whether one iteration have side effect or not.
hasresult is set to false in the loop header and set to true after each side effect instruction.
it will be used to help count the number of side effect iterations.
b. redundancy checker we will compare the computation of different iterations from one loop instance and that of different loop instances from one static loop and judge whether there is redundancy.
specifically several questions need to be answered.
what to compare?
given two loop iterations or loop instances c1and c2 since they originate from the same sourcecode c a naive approach is to record and compare the value read by every memory read instruction in c1and c2.
we could do better by checking fewer instructions as some of these values are determined by values read earlier in c1and c2.
informally speaking we only need to compare input values of c1and c2to decide whether they are redundant with each other.
we will present formal definition of input and the detailed algorithms in section iii b1.
how to compare?
naively we can judge two iterations or two loop instances to be redundant with each other only when they read exactly the same data and conduct exactly the same computation.
however in practice redundant loops may be largely but not completely the same computation across iterations or loop instances.
we will discuss how we handle this issue in section iii b2.
how to lower the overhead of record and compare?
we will use both static optimization section iii b4 and dynamic sampling section iii b3 to reduce the amount of data that is recorded and compared reducing time and spatial overhead.
identifying and recording inputs informally we use static analysis to identify a set of memory read instructions that the computation of code cdepends on.
we refer to these instructions as input instructions for c. the values returned from them at run time referred to as inputs will be tracked and compared to identify redundant computation among different instances of c. specifically ldoctor first identifies side effect instructions inc similar with that in section iii a1.
it then conducts backward static slicing from these instructions considering control and data dependency.
for every memory read r read v that static slicing encounters ldoctor checks whether rsatisfies either one of the following two conditions.
if rdoes it is marked as an input instruction otherwise ldoctor continues growing the slice beyond r. the two conditions are the value of vis defined outside c vis a heap or global variable.
the rationale for the first condition is that slicing outside cis unnecessary for redundancy judgement among instances of c. the rationale for the second condition is that tracking data dependency through heap or global variables is complicated in multi threaded c c programs.
the analysis for cross iteration and cross loop redundancy analysis is similar simply replacing cin the above algorithm with one iteration or the whole loop body.
our analysis considers function calls inside c slicing is conducted for return values of callees and side effect instructions inside callees.
we omit encountered constant values through slicing as they do not affect redundancy judgement.
identifying redundant loops after identifying inputs using static analysis ldoctor instruments the program to record input values at run time.
the run time trace also includes information that differentiate values recorded from different instructions loop iterations loop instances etc.
once the trace under problematic workload is collected either during off line debugging or production runs ldoctor will process the trace and decide whether the loops under study contain cross iteration or cross loop redundancy.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
1int found 2while foun d check if string source contains target char first target int max sourcelen targetlen for int i i max i look for first character.
if source !
first while i max source !
first found first character now look at the rest if i max int j i int e n d j targetlen for int k j end source target j k if j end found whole string target.
found i break append another character try again source getchar fig.
a cross loop redundant bug in apache the for loop on line searches a string source for a target sub string target .
since the outer loop on line appends one character to source in every iteration line the for loop is always working on a similar source from its previous execution with a lot of redundancy.
a high level algorithms we need to answer two questions how to judge whether two iterations or loop instances are redundant work and how to judge whether a loop contains sufficient redundant computation to be inefficient.
our answer sticks to one principle there should be sufficient amount of redundant computation to make a loop likely culprit for a user perceived performance problem and to make itself worthwhile to get optimized by developers.
for the first question ldoctor takes a strict definition for cross iteration redundancy and a looser definition for cross loop redundancy checking.
specifically two iterations that conduct exactly the same computation are considered redundant two loop instances that conduct largely the same computation are considered redundant.
the rationale is that a whole loop instance contains a lot of computation much more than one iteration in general.
even if only part of its computation is redundant it could still be the root cause of a user perceived performance problem and worth developers attention.
in practice we rarely see different loop instances exactly the same computation.
in cross loop redundancy examples shown in figure and figure each loop instance is similar but not exactly the same work from its previous instance.
for the second question we believe there should be a threshold.
a loop will be considered inefficient if its redundancy rate goes beyond the threshold.
b detailed algorithm implementation the implementation of checking cross iteration redundancy is straightforward.
we calculate a loop s cross iteration redundancy rate basedon the number of distinct iterations in a loop rate c.i.
of distinct iterations of iterations.
this rate ranges between and the smaller it is the less redundancy the loop contains.
checking cross loop redundancy goes through several steps.
first for kdynamic instances of a static loop lthat appear at run time denoted as l1 l2 ... lk we check whether redundancy exists between l1and l2 l2and l3 and so on.
second we compute a cross loop redundancy rate for l rate c.l.
of redundant pairs of pairs in this example of pairs is k .
this rate ranges between and the smaller it is the less redundancy lcontains.
we only check redundancy between consecutive loop instances because checking that between every pairs of loop instances is time consuming.
the key of this implementation is to judge whether two dynamic loop instances l1and l2are redundant or not.
the challenge is that l1and l2may have executed different numbers of iterations in different iterations different sets of input instructions may have executed.
therefore we cannot simply chain values from different input instructions and iterations together and compare two data sequences.
instead we decide to check the redundancy for each input instruction across l1 and l2first and then use the average redundancy rate of all input instructions as the redundancy rate between l1and l2.
we calculate the redundancy for an input instruction ibased on the edit distance between the two sequences of values returned by iin the two loop instances and the lengths of the two sequences denoted by seqa and seqb .
the intuition is that the redundancy rate should be if one sequence is the sub sequence of the other and be if these two sequences are completely different.
the exact formula is the following redundancy i editdistance seqa seqb length seqa length seqb min length seqa length seqb dynamic optimization sampling recording values returned by every input instruction would lead to huge runtime overhead.
ldoctor uses random sampling to reduce this overhead which requires almost no changes to our redundancy identification algorithm discussed in section iii b2.
note that although ldoctor uses sampling its diagnosis is still conducted in just one run with almost nosacrifice to diagnosis latency or quality.
this is different from traditional sampling techniques for correctness diagnosis where many more failure runs and hence longer latency are needed once sampling is enabled.
the reason is that performance bugs have a unique repetitive nature a loop can cause a severe performance problem only when it contains many redundant iterations instances.
therefore we can still recognize redundant behavior in just one failure run as long as the sampling is not insanely sparse section v .
for cross iteration redundancy analysis we randomly decide at the beginning of every iteration whether to track the values returned by input instructions in this iteration.
the implementation is similar with previous sampling work .
specifically we create a clone of the original loop iteration code and insert value recording instructions along the cloned copy.
we then insert a code snippet that randomly authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
decides to execute the cloned copy or the original copy at the beginning of a loop iteration.
for cross loop redundancy analysis we randomly decide at the beginning of every loop instance whether to track values for this instance.
since we will need to compare two consecutive loop instances for redundancy once we decide to sample one loop instance we will make sure to sample the immediate next loop instance too.
the implementation is straightforward by cloning the whole loop and making sampling decisions in the loop pre headers.
static optimization we conduct a series of static analysis to reduce the number of instructions we need to monitor.
first we avoid tracking multiple reads that we can statically prove to return the same value.
since we implement ldoctor in llvm we leverage the ssa construction and the mem2reg pass in llvm to avoid unnecessary tracking of stack variables.
for example the read of max on line of figure is an input instruction of the while loop on the same line.
llvm identifies it as a loop invariant and lifts the read of max out of the loop.
consequently ldoctor only records its value once during each loop instead of each iteration.
llvm is conservative in lifting heap global variables out of a loop.
ldoctor conducts a best effort loop invariant analysis for heap global variables.
for example ldoctor identifies that the values of anode localname andanode namespaceuri do not change throughout one loop instance in figure and hence only traces them once outside the loop.
second we leverage the scalar evolution se analysis in llvm to remove the monitoring to some loop induction related variables.
se analysis can tell which variables are loopinduction variables e.g.
ion line of figure and what are their strides.
in cross iteration redundancy checking if a loop iteration s input set contains a loop induction variable we know different iterations inputs would be different and hence conclude that there is no redundancy without run time analysis.
in cross loop redundancy checking when the address of a read is a loop induction variable such as source on line of figure we only record the address range at run time instead of every value returned by the memory read.
this optimization could lead to false positives different loop instances may work on variables read from similar memory locations but with different values.
we did not encounter such false positives in our experiments.
c. fix strategy recommendation ldoctor suggests a fix strategy for each inefficient loop based on the inefficiency category.
making this suggestion is straightforward for most categories and requires a small amount of extra analysis occasionally.
ldoctor also provides related information for carrying out the suggested fix strategy.
once a loop is identified as resultless ldoctor will suggest the loop to be deleted in case of conditionally skipped in case of or a data structure change in case of ?.
ldoctor also reports side effect instructions and what percentage of loop iterations executes each such instruction helping developers refactor the loop or change data structures.when a loop is identified as redundant ldoctor conducts extra analysis to decide whether batching or memoization should be used.
for cross iteration redundancy ldoctor suggests batching i o operations.
when the only side effect of a loop is from i o operations and the same statement s is executed in every iteration.
otherwise ldoctor suggests memoization and reports input instructions that lead to redundant computation and redundancy rate.
for cross loop redundancy whether to use memoization or batching often depends on which strategy is cheaper.
ldoctor uses a simple heuristic.
if the side effect of each loop instance is to update a constant number of memory locations like the buggy loop in figure and figure we recommend memoization.
if the side effect is to update a sequence of memory locations with the number of locations increasing with the workload memoization is unlikely to save much and hence batching is suggested.
ldoctor will also report the memory reads that return the same values again and again which can help decide what to memoize.
iv .
a ssessment of root cause taxonomy a. methodology our previous work studied the on line bug databases of five representative open source software projects apache suite including httpd web server written in c c tomcat server written in java and ant build management tool in java chromium google chrome browser in c c gcc compiler suite in c c mozilla suite including firefox web browser and thunderbird email client in c c and javascript mysql database server in c c .
by manually inspecting a set of randomly sampled bug reports previous work identified performance problems that are perceived and reported by users .
among these problems problems are related to inefficient loops and hence are the target of the study here.
b. assessment coverage as shown in table i our taxonomy does cover all inefficient loops under study.
resultless loops are about as common as redundant loops vs. .
not surprisingly loops are rare in mature software.
all other root cause subcategories are well represented.
actionability as shown in table i the root cause categories in our taxonomy are well correlated with fix strategies.
this indicates that our taxonomy is actionable once the root cause is identified developers roughly know how to fix.
for example almost all ?
resultless loops are fixed by datastructure changes all resultless loops are fixed by conditionally skipping the loop almost all redundant loops are fixed either by memoization or batching.
the only problem is that there are no silver bullets for fixing loops.
generality the root cause categories in our taxonomy are designed to be generic.
table i also shows that these categories each appears in multiple application in our study.
the only exception is resultless which never appears.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
apache chrome gcc mozilla mysql m emoization batching cso ther total of bugs cross iteration redundancy cross loop redundancy ?
resultless resultless resultless resultless table i distribution among different applications and fix strategies for bugs with each root cause category.
c change data structure s conditionally skip loop darker background means more correlation between root causes and fixes in summary the study above informally demonstrates that our taxonomy is suitable to guide our design of ldoctor.
v. e v aluation of ld octor a. methodology implementation and platform we implement ldoctor in llvm .
.
and conduct our experiments on an i53330s machine with linux .
kernel.
benchmarks ldoctor is a diagnosis tool that helps understand and fix already manifested performance problems.
consequently our benchmarks are performance problems that have already happened in real world.
for a thorough evaluation we use benchmarks from two different sources.
first general benchmark suite.
we evaluate ldoctor on all bugs in total that we can reproduce among the bugs discussed in section iv .
these bugs cover a wide variety of inefficiency root causes as shown in the upper half of table ii.
we use the problem triggering inputs reported by real world users in ldoctor run time analysis.
among these seven are extracted from java javascript programs.
for these benchmarks we did our best to keep all bug related data structures and caller callee functions intact and re implement them in c following the original data and control flow.
we expect ldoctor to also work for most of the remaining bugs in table i. however these bugs are too difficult to reproduce as they depend on special environment e.g.
windows os and .net libraries and cannot be easily extracted or reimplemented.
for example some bugs are related to gui widgets and some require big complicated graphs to trigger.
second we evaluate ldoctor on toddler benchmark suite .
toddler project provides the bug triggering inputs and detailed explanation for inefficient loop bugs that have been confirmed and fixed by developers and we evaluate ldoctor on allof them.
due to the focus of toddler all of these bugs are caused by inefficient nested loops and only cover two types of inefficiency root causes as shown in the bottom half of table ii.
we extract these bugs and re implemented them in c c we re implement basic java data structures following a recent version of openjdk .
each extracted benchmark contains at least five loops except for two cases with four loops each.
the general benchmark suite and toddler benchmark suite both provide a large set of repeatable inefficient loop problems that we can access.
at the same time they were initially set up for different reasons and methodologies and hence well complement each other.
all the benchmarks led to severeperformance problems.
after developers fixed these problems the performance of each benchmark improves 4x 500x under the user reported workload in our experiments.
evaluation settings our evaluation uses existing statistical performance diagnosis tool to process a performance problem and identify a few suspicious loops for ldoctor to analyze.
for all but four benchmarks statistical debugging identifies the real root cause loop as the most suspicious loop.
for the remaining four which all come from table i the real root cause loops are ranked number and .
we use .
as the default resultful rate threshold for identifying ?
and resultless loops we use .
as the default redundancy rate threshold for identifying redundant loops.
we use sampling rate for cross loop redundancy analysis and sampling rate for cross iteration redundancy analysis there tend to be more loop iterations than loop instances .
all our diagnosis results require only one run under the problem triggering input.
all our performance results are obtained by taking average of ten runs with the variation among different runs always less than .
research questions to answer we mainly conduct three sets of evaluation to answer three key research questions regarding the coverage accuracy and performance of ldoctor rq1 .
can ldoctor correctly identify inefficiency categories and fix strategies for many real world loops?
sec.v b rq2 .
might ldoctor report many false positives and hence waste developers diagnosis effort?
sec.v c rq3 .
what is the run time overhead of ldoctor?
sec.v d b. coverage results to answer rq1 we apply ldoctor to real root cause loops to see if it can accurately identify inefficiency categories.
as shown by the check marks in table ii the did ldoctor identify ..?
columns ldoctor does provide good diagnosis coverage.
ldoctor identifies the correct root cause for all benchmarks and suggests fix strategies that match what developers took in practice for out of cases.
the six cases where ldoctor and developers suggest take different fix strategies fall into three categories.
first the fix strategy taken by developers is a subset of what suggested by ldoctor.
for mysql and apache the rootcause loops contain both cross loop redundancy and ?
inefficiency.
consequently ldoctor suggests two fix strategies.
in practice the developers acknowledge both types of inefficiencies but the patches only changed the data structures which eliminated both types of inefficiencies in case of authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
benchmark information did ldoctor identify ...?
number of false positives bugid kloc p .
l. rootcause fix root cause fix strategy ?
c i b c i m c l total mozilla347306 c ?
c check check mozilla416628 c ?
c check check mozilla490742 js c i b check check mozilla35294 c c l b check check mozilla477564 js c l m check check mysql27287 c ?
c l c check mysql15811 c c l m check check apache32546 java c i b check check apache37184 java c i m check check apache29742 java c l b check check apache34464 java c l m check check apache47223 java c l b check check gcc46401 c s check check gcc1687 c c i m check check gcc27733 c c i m check check gcc8805 c c l b check check gcc21430 c c l m check check gcc12322 c s check apache53622 java c l ?
c check apache53637 java c l b check check apache53803 java ?
c check check apache53821 java ?
c check check apache53822 java ?
c check check collections406 java c l ?
b c check check collections407 java ?
s check collections408 java ?
s check collections409 java c l b check check collections410 java c l b check check collections412 java c l ?
b c check check collections413 java ?
c check check collections425 java ?
s check collections426 java ?
c check check collections427 java ?
c check check collections429 java ?
c check check collections429 java ?
c check check collections429 java ?
c check check collections434 java ?
c check check groovy5739 java ?
c check check groovy5739 java ?
c check check table ii ldoctor evaluation results.
in the benchmark information columns denotes benchmarks extracted from real world applications c i denotes cross iteration redundancy and c l denotes cross loop redundancy.
m b c s represent fix strategies as discussed in table i. apache53622 collections406 and collections412 contain two inefficient loops with two root causes listed mysql27287 contains one root cause loop that conducts two types of inefficient computation.
in false positive columns denotes no false positive and xydenotes real x and benign false positives y reported by ldoctor in top suspicious loops of each benchmark.
mysql and left the cross loop redundancy unsolved in apache .
second the fix strategy taken by developers is related to what suggested by ldoctor.
the root cause loops in collections bugs and all conduct frequent linear searches in arrays.
ldoctor suggests data structure changes for these three cases.
developers patches still keep the original data structures but they did use hash sets which contain the same content as the arrays to help conditionally skip the loops.
third ldoctor cannot suggest fix strategy for loops.
for gcc ldoctor correctly tells that the loop under study does not contain any form of inefficiency and produce results in every iteration and hence fails to suggest any fix strategy.
in practice gcc developers decide to skip the loop which will cause some programs compiled by gcc to be less performance optimal than before.c.
accuracy results to answer rq2 we apply statistical performance debugging to all benchmarks and then apply ldoctor to the top ranked loops2.
table ii shows that ldoctor is accurate having five real false positives and benign false positives in total for all the top five loops of the benchmarks.
the five real false positives happen for benchmarks gcc and gcc .
these five loops are identified as redundant and resultless by ldoctor.
however they are very difficult to fix and hence are not patched.
since these five loops are ranked higher than the true positive loops by statistical debugging they could cost waste ldoctor users some effort during performance diagnosis.
future work could try to prune these false positives by estimating the fix difficulty.
ldoctor also reports benign false positives.
these are correctly identified inefficient loops.
however they are not 2some extracted benchmarks have fewer than loops.
we simply apply ldoctor to all loops in these cases.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
ldoctor w optimization w o optimization bugid resultless c l r. c i r. c l r. c i r. mozilla347306 .
.
.
.
x .
x mozilla416628 .
.
.
.
x .
x mysql27287 .
.
.
x .
x mysql15811 .
.
x .
x gcc46401 .
.
.
.
x .
x gcc1687 .
.
x gcc27733 .
.
.
x gcc8805 .
.
.
x .
x gcc21430 .
.
.
x .
x gcc12322 .
.
.
x .
x table iii run time overhead of ldoctor only nonextracted benchmarks are shown dynamic analysis is not needed not applicable .
the main contributors to the perceived performance problems and hence are not fixed in patches.
different from the five false positives discussed above these loops are ranked lower than the true positive loops by statistical debugging as well as by profillers because of their low contributions to the perceived performance problems.
consequently they will not cause extra diagnosis effort for ldoctor users.
the accuracy of ldoctor benefits from its run time analysis.
for example our run time analysis has correctly pruned out false positives in ?
inefficiency detection for our benchmarks.
each of these loops is a top suspicious loop in one of our benchmarks it only generates side effects in its last iteration and hence is identified as ?
by static analysis.
without run time information ldoctor would judge all of them as inefficient ?
resultless .
fortunately ldoctor runtime counts the number of iterations of each loop instance and correctly identifies them as false positives.
similarly ldoctor run time analysis helps prune out false positives for loop identification.
ldoctor can also help improve the accuracy of statistical debugging in identifying which loop is the root cause loop.
for example the real root cause loop of apache and gcc both rank number two by the statistical performance diagnosis tool.
fortunately ldoctor can tell that the number one loops in both cases do not contain any form of inefficiency resultless or redundancy.
d. performance to answer rq3 we evaluate the run time performance of applying ldoctor to the real root cause loop.
as shown in table iii the performance of ldoctor is good.
the overhead is consistently under or around except for one benchmark mozilla .
we believe ldoctor is promising for potential production run usage.
we can easily further lower the overhead through sparser sampling.
as we can also see from the table our performance optimization discussed in section iii b3 and iii b4 has helped.
the performance benefit of sampling is huge.
without sampling redundancy analysis lead to over 100x slowdown for six benchmarks.
the benefit of static optimization is also nontrivial.
for example for mysql and mysql static analysis alone can judge that they do not contain cross iteration redundancy i.e.
no run time overhead the computation of each iteration depends on loop induction variables which are naturally different in different iterations.
as another example the buggy loops of mysql and mysql access arrays.
after changing to tracking the initial and ending memory access addresses of the array instead of the content of the whole array accesses the overhead is reduced from .
to .
for mysql and from .
to .
for mysql respectively.
e. parameter setting and sensitivity sampling rates we have tried different sampling rates for redundancy analysis.
intuitively sparser sampling leads to lower overhead but worse diagnosis results.
due to space constraints we briefly summarize the results below.
when we lower the sampling rate from to in cross loop redundancy analysis among all the benchmarks in table iii mozilla incurs the largest overhead merely .
.
when we lower the sampling rate from to in cross iteration redundancy analysis among all the benchmarks in table iii mozilla has the largest overhead merely .
.
in both cases the diagnosis results remain the same for all but gcc where too few samples are available to judge redundancy.
resultful and redundancy rate our default setting should work in most cases.
in fact the diagnosis results are largely insensitive to the threshold setting.
for example the results would remain the same when changing the redundancy rate threshold from .
to any value between about .
and .
.
we will have more false negative and fewer true false positive when the rate is .
.
the trend is similar for resultless loop checking.
developers can adjust these thresholds.
they can even get rid of thresholds and only use the raw values of resultful redundancy rates to understand the absolute and relative in efficiency nature of suspicious loops.
based on our experiments the difference between efficient and inefficient loops is obvious based on these rates.
vi.
t hreats to validity ldoctor does not cover all loop inefficiency problems.
for example it does not handle performance problems caused by cache line false sharing in multi core machines or lock contention issues.
it also cannot provide useful fixing suggestions for inefficient loops as discussed in section v b. the static analysis in ldoctor could occasionally lead to inaccurate diagnosis.
specifically ldoctor static analysis could conservatively identify some non side effect instructions such as a write to a heap variable that is not used after the loop as having side effects section iii a1 .
the se based optimization discussed in section iii b4 could cause false positives in cross loop redundancy diagnosis.
these cases are all rare in practice and not encountered in our experiments.
our default settings of resultless and redundancy rate thresholds work well in our evaluation.
however they could potentially lead to false positives and false negatives as discussed in section v e. authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
the results presented in section iv and section v should be interpreted together with corresponding methodologies and not be overly generalized.
they reflect our best effort in evaluating our root cause taxonomy and ldoctor using a non biased set of real world inefficient loop problems that have been perceived by users and fixed by developers.
the benchmark suite covers a variety of applications workload development environments and programming languages.
however there are definitely uncovered cases like problems in distributed systems and scientific computing systems and others.
furthermore although we did not intentionally ignore any aspect of loop related performance problems some looprelated problems may never be noticed by end users or never be fixed by developers and hence may skip our evaluation.
however there are no conceivable ways to study them particularly considering that ldoctor is designed to diagnose already manifested performance problems not to predict notyet observed problems.
vii.
r elated works profilers are the most commonly used tools that help developers understand performance .
they aim to tell where computation resources are spent not where and why computation resources are wasted.
the root cause code region of a performance problem often is not inside the top ranked function in the profiling result .
even if it is developers still need to spend a lot of effort to understand whether and what kind of computation inefficiency exists.
recently proposed tools go beyond profiling.
they can identify slow call stack patterns inside event handlers help understand performance causality relationship among system components identify inputs or configuration entries that are most responsible for performance problems and estimate the performance impact of any potential optimization at any point of a multi threaded program .
they all target different problems from ldoctor.
ldoctor is most related to the recent statistical performance debugging work both trying to identify source code level root causes for user perceived performance problems.
this previous work identifies which loop is most correlated with a performance symptom through statistical analysis but cannot answer whether or what type of inefficiency this loop contains.
ldoctor complements it by accurately pointing out whether the suspicious loop is inefficient which type of inefficiency a loop contains if any and what is the best fix strategy.
many dynamic and static analysis tools have been built to detect different types of performance problems such as run time bloat low utility data structures cacheable data false sharing in multi thread programs inefficient nested loops loops with unnecessary iterations input dependent loops .
as discussed in section i these tools are all useful but are not suitable for performance diagnosis.
bug detectors are not guided by any specific performance symptoms.
consequently they take different coverage accuracy trade offs from ldoctor.
ldoctor tries to cover a wide variety of root cause categoriesand is more aggressive in identifying root cause categories because it is only applied to a few loops known to be highly correlated with a specific performance symptom.
performancebug detection tools are more conservative and try hard to lower false positive rates because they need to process the whole program instead of just a few loops.
this requirement causes bug detectors to each focus on a specific root cause category.
bug detectors also do not aim to provide fix suggestions.
for the few that do provide they only focus on very specific fix patterns such as adding a break into the loop.
in addition dynamic performance bug detectors often lead to 10x slowdowns or more and never tried sampling.
automated tools have been developed to detect inefficient loop bugs .
as discussed above these tools are good detection tools but not suitable for diagnosis.
for example toddler only targets inefficient nested loops and hence can only cover about half of the bugs in our general benchmark suite.
being a dynamic tool it also incurs 10x or more slowdowns which is much more expensive than ldoctor.
caramel statically detects inefficient loops that can be fixed by adding conditional breaks.
very few bugs in table i are like this.
clarity statically detects redundant traversal bugs which arise if a program fragment repeatedly iterates over a data structure such as an array or list that has not been modified between successive traversals of the data structure.
like toddler it targets nested loops.
we expect it to detect a sub set of the cross loop redundancy loops and a sub set of ?
resultless loops in our benchmark set.
there are many test inputs generation techniques that help performance testing .
some techniques aim to improve the test selection or prioritization during performance testing .
all these techniques combat performance bugs from different aspects from performance diagnosis.
viii.
c onclusion performance diagnosis is time consuming and also critical for complicated modern software.
ldoctor tries to automatically pin point the root cause of the most common type of realworld performance problems inefficient loops and suggest fix strategies to developers.
it achieves the coverage accuracy and performance goal by leveraging a comprehensive rootcause taxonomy a hybrid program analysis approach and customized random sampling that is a natural fit for performance diagnosis.
our evaluation shows that ldoctor can accurately identify detailed root causes of real world inefficient loops and suggest fix strategies.
future work can improve ldoctor by providing more detailed fix suggestions and more information to diagnose and fix loops.
acknowledgment we thank the anonymous reviewers darko marinov and ben liblit for their comments.
our research has been supported by nsf cns iis cns ccf ccf and generous supports from alfred p. sloan foundation and ceres center for unstoppable computing.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.