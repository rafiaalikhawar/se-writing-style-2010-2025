sourcerercc scaling code clone detection to big code hitesh sajnaniyvaibhav sainiyjeffrey svajlenkoz chanchal k. royzcristina v. lopesy yschool of information and computer science uc irvine usa hsajani vpsaini lopes uci.edu zdepartment of computer science university of saskatchewan canada jeff.svajlenko chanchal.roy usask.ca abstract despite a decade of active research there has been a marked lack in clone detection techniques that scale to large repositories for detecting near miss clones.
in this paper we present a token based clone detector sourcerercc that can detect both exact and near miss clones from large interproject repositories using a standard workstation.
it exploits an optimized inverted index to quickly query the potential clones of a given code block.
filtering heuristics based on token ordering are used to signi cantly reduce the size of the index the number of code block comparisons needed to detect the clones as well as the number of required token comparisons needed to judge a potential clone.
we evaluate the scalability execution time recall and precision of sourcerercc and compare it to four publicly available and state of the art tools.
to measure recall we use two recent benchmarks a big benchmark of real clones bigclonebench and a mutation injection based framework of thousands of ne grained arti cial clones.
we nd sourcerercc has both high recall and precision and is able to scale to a large inter project repository 25k projects 250mloc using a standard workstation.
.
introduction clone detection locates exact or similar pieces of code known as clones within or between software systems.
clones are created when developers reuse code by copy paste and modify although clones may be created by a number of other means .
developers need to detect and manage their clones in order to maintain software quality detect and prevent new bugs reduce development risks and costs and so on .
clone management and clone research studies depend on quality tools.
according to rattan et al.
at least diverse tools have been presented in the literature.
with the amount of source code increasing steadily largescale clone detection has become a necessity.
large scale clone detection can be used for mining library candidates detecting similar mobile applications license violation permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
copyrights for components of this work owned by others than the author s must be honored.
abstracting with credit is permitted.
to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
request permissions from permissions acm.org.
icse may austin tx usa c copyright held by the owner author s .
publication rights licensed to acm.
isbn .
.
.
.
reverse engineering product lines nding the provenance of a component and code search .
large scale clone detection allows researchers to study cloning in large software ecosystems e.g.
debian or study cloning in open source development communities e.g.
github .
developers often clone modules or fork projects to meet the needs of di erent clients and need the help of large scale clone detectors to merge these cloned systems towards a product line style of development.
these applications require tools that scale to hundreds of millions of lines of code.
however very few tools can scale to the demands of clone detection in very large code bases .
a number of tools have been proposed to achieve a few speci c applications of large scale clone detection .
these tools make some assumptions regarding the requirements of their target domain that help with scalability.
these domain speci c tools are not described as general large scale clone detectors and may face signi cant scalability challenges for general clone detection.
general purpose clone detection is required for clone studies in large inter project repositories and to help developers manage and merge their related software forks as well as for use in the domain speci c activities.
scalable general purpose clone detection has been achieved by using deterministic or non deterministic input partitioning and distributed execution of an existing non scalable detector using large distributed code indexes or by comparing hashes after type normalization .
these existing techniques have a number of limitations.
the novel scalable algorithms do not support type near miss clones where minor to signi cant editing activities might have taken place in the copy pasted fragments and therefore miss a large portion of the clones since there are more type clones in the repositories than other types .
type clones can be the most needed in large scale clone detection applications .
while input partitioning can scale existing non scalable type detectors this signi cantly increases the cumulative runtime and requires distribution over a large cluster of machines to achieve scalability in absolute runtime .
distributable tools can be costly and di cult to setup.
we set out to develop a clone detection technique and tool that would satisfy the following requirements accurate detection of near miss clones where minor to signi cant editing changes occur in the copy pasted fragments programming language agnostic simple non distributed operation and scalability to hundreds of millions of lines of code.
to that e ect we introduce sourcerercc a token2016 ieee acm 38th ieee international conference on software engineering based accurate near miss clone detector that exploits an optimized index to scale to hundreds of millions of lines of code mloc on a single machine.
sourcerercc compares code blocks using a simple and fast bag of tokens1strategy which is resilient to type changes.
clone candidates of a code block are queried from a partial inverted index.
a ltering heuristic is used to reduce the size of the index which drastically reduces the number of required code block comparisons to detect the clones.
it also exploits the ordering of tokens to measure a live upper and lower bound on the similarity of code blocks in order to reject or accept a clone candidate with fewer token comparisons.
we found this technique has strong recall and precision for the rst three clone types.
sourcerercc is able to accurately detect exact and near miss clones in 250mloc on a single machine in only .
days.
we make two di erent versions of the tool available i sourcerercc b a batch version of the tool that is more suitable for empirical analysis of the presence of clones in a system or a repository and ii sourcerercci an interactive version of the tool integrated with eclipse ide to help developers instantly nd clones during software development and maintenance.
we evaluate the scalability execution time and detection quality of sourcerercc.
we execute it for inputs of various domains and sizes including the large inter project software repository ijadataset .
projects 250mloc million les and observed good execution time and no scalability issues even on a standard machine with a .5ghz quad core i7 cpu and 12gb of memory.
we measure its clone recall using two proven clone benchmarks.
we use bigclonebench a big benchmark of real clones that spans the four primary clone types and the full spectrum of syntactical similarity.
we also use the mutation and injection framework a synthetic benchmark that can precisely measure recall at a ne granularity.
we measure precision by manually validating a sample of its output.
we compare these results against publicly available popular and state of the art tools including ccfinderx deckard iclones and nicad .
we nd that sourcerercc is the only near miss clone detector to scale to large repositories and has the best execution time for very large inputs.
sourcerercc also has strong precision and recall and is competitive with the other tools.
the remainder of the paper is organized as follows.
section describes important concepts and de nitions.
section presents sourcerercc s clone detection process in detail.
section describes various experiments conducted to evaluate the scalability recall and precision of sourcerercc against state of the art tools on various benchmarks with threats to validity discussed in section .
after drawing connections with the related work in section section concludes with a summary of the ndings.
.
definitions the paper uses the following well accepted de nitions of code clones and clone types code fragment a continuous segment of source code speci ed by the triple l s e including the source le l the line the fragment starts on s and the line it ends on e. clone pair a pair of code fragments that are similar 1similar to the popular bag of words model from information retrieval.speci ed by the triple f1 f2 including the similar code fragmentsf1andf2 and their clone type .
clone class a set of code fragments that are similar.
speci ed by the tuple f1 f2 f n .
each pair of distinct fragments is a clone pair fi fj i j21 n i6 j. code block a sequence of code statements within braces.
type t1 identical code fragments except for di erences in white space layout and comments.
type t2 identical code fragments except for di erences in identi er names and literal values in addition to type clone di erences.
type t3 syntactically similar code fragments that di er at the statement level.
the fragments have statements added modi ed and or removed with respect to each other in addition to type and type clone di erences.
type t4 syntactically dissimilar code fragments that implement the same functionality .
the proposed method sourcerercc .
problem formulation a software project pis represented as a set of code blocks p fb1 b ng in turn a code block bis represented as a bag of tokens multiset b ft1 t kg a token is considered as programming language keywords literals and identi ers.
a string literal is split on whitespace and operators are not included.
since a code block may have token multiplicity each token is represented as a token frequency pair.
here frequency denotes the number of times token appeared in a code block.
this further reduces a code block representation to a set of token frequency pairs.
in order to quantitatively infer if two code blocks are clones we use a similarity function which measures the degree of similarity between code blocks and returns a nonnegative value.
the higher the value the greater the similarity between the code blocks.
as a result code blocks with similarity value higher than the speci ed threshold are identi ed as clones.
formally given two projects pxandpy a similarity functionf and a threshold the aim is to nd all the code block pairs or groups px bandpy b s tf px b p y b d max jp x bj jpy bj e. note that for intra project similarity pxandpyare the same.
similarly all the clones in a project repository can be revealed by a self join on the entire repository itself.
while there are many choices of similarity function we use overlap3because it intuitively captures the notion of overlap among code blocks.
for example given two code blocks bxandby the overlap similarity os bx by is computed as the number of tokens shared by bxandby.
os bx by jbx byj in other words if is speci ed as and max jbxj jbyj ist thenbxandbyshould share at least d jtjetokens to be identi ed as a clone pair.
note that if a token aappears inbxtwice and thrice in by the match between bxandby due to token ais two.
to detect all clone pairs in a project or a repository the above approach of computing similarity between code blocks can simply be extended to iterate over all the code blocks 3the presented approach can be adapted for jaccard and cosine similarity functions as well.
methods candidates x 1k 400002000400060008000figure growth in number of candidate comparisons with the increase in the number of code blocks and compute pairwise similarity for each code block pair.
for a given code block all the other code blocks compared are called candidate code blocks or candidates in short.
while the approach is very simple and intuitive it is also subjected to a fundamental problem that prohibits scalability o n2 time complexity.
figure describes this by plotting the number of total code blocks x axis vs. the number of candidate comparisons y axis in apache projects2.
note that the granularity of a code block is taken as a method.
points denoted by the show that the number of candidate comparisons increase quadratically3with the increase in number of methods.
later in section while describing sourcerercc we will propose two ltering heuristics that signi cantly reduce the number of candidate comparisons during clone detection.
.
overview sourcerercc s general procedure is summarized in figure .
it operates in two primary stages i partial index creation and ii clone detection.
in the index creation phase it parses the code blocks from the source les and tokenizes them with a simple scanner that is aware of token and block semantics of a given language4.
from the code blocks it builds an inverted index mapping tokens to the blocks that contains them.
unlike previous approaches it does not create an index of all tokens in the code blocks instead it uses a ltering heuristic section .
.
to construct a partial index of only a subset of the tokens in each block.
in the detection phase sourcerercc iterates through all of the code blocks and retrieves their candidate clone blocks from the index.
as per the ltering heuristic only the tokens within the sub block are used to query the index which reduces the number of candidate blocks.
after candidates are retrieved sourcerercc uses another ltering heuristic section .
.
which exploits ordering of the tokens in a code block to measure a live upper bound and lower bound of similarity scores between the query and candidate blocks.
candidates whose upper bound falls below the similarity threshold are eliminated immediately without further processing.
similarly candidates are accepted as soon as their 2the list is available at projects sourcerercc .
3the curve can also be represented using y x x quadratic function where xis the number of methods in a project and yis the number of candidate comparisons carried out to detect all clone pairs.
4currently we have support for java c and c using txl but it can be easily extended to other languages.
figure sourcerercc s clone detection process lower bound exceeds the similarity threshold.
this is repeated until the clones of every code block are located.
sourcerercc exploits symmetry to avoid detecting the same clone twice.
in the following sections we provide a detailed description of the ltering heuristics and overall algorithm.
.
filtering heuristics to reduce candidate comparisons .
.
sub block overlap filtering the ltering heuristics are inspired by the work of chaudhuri et al.
and xiao et al.
on e cient set similarity joins.
it follows an intuition that when two sets have a large overlap even their smaller subsets overlap.
since we represent code blocks as bag of tokens i.e.
a multiset we can extend this idea to code blocks i.e.
when two code blocks have large overlap even their smaller sub blocks should overlap.
formally it can be stated in the form of a following property property given blocks bxandbyconsisting of ttokens each in some prede ned order if jbx byj i then the subblockssbxandsbyofbxandbyrespectively consisting of rstt i 1tokens must have at least one matching token .
to understand the implications of this property in clone detection let us consider two code blocks bx fa b c d eg andby fb c d e fgwith tokens t each.
let be speci ed as meaning that the two blocks should match at leastd0 5e tokens to be considered clones i.e i .
according to property in order to nd out if bxand byare clones we only need to check if their sub blocks consisting of rst t i tokens match at least one token.
in this case they do as token bis common in both the subblocks marked in bold .
however if they had not shared any token then even without looking at the remaining tokens of the blocks we could have most certainly gured that bxandbywill not end up as a clone pair for the given .
in other words property suggests that instead of comparing all the tokens of bxandbyagainst each other we could compare only their sub blocks consisting of rst t i tokens to deduce if b1andb2willnotbe clones.
in order to apply property the tokens in the code blocks need to follow a prede ned global order.
while there are many ways in which tokens in a block can be ordered e.g.
alphabetical order length of tokens occurrence frequency of token in a corpus etc.
a natural question is what order is most e ective in this context.
as it turns out software vocabulary exhibits very similar characteristics to natural languages corpus and also follow zipf s law .
that is there are few very popular frequent tokens and the fre1159quency of tokens decreases very rapidly with rank.
in other words while most of the code blocks are likely to contain one or more of few very popular tokens e.g.
keywords or common identi er names like i j count etc.
not many will share rare tokens e.g.
identi ers that are domain or project speci c .
so if code blocks are ordered according to the popularity of tokens in the corpus naturally their subblocks will consist of these rare tokens.
such arrangement will ensure low probability of di erent sub blocks sharing similar token.
in other words this ordering will eliminate more false positive candidates5.
to describe how e ective this ltering is points denoted by4in figure show the number of candidate comparisons after applying the ltering.
the di erence with the earlier curve show the impact of ltering in eliminating candidate comparisons.
the below section discusses when the use of property may still be ine ective and demonstrate how ordering of tokens in a code block can be further exploited to formalize yet another ltering heuristic that is extremely e ective in eliminating even more candidate comparisons.
.
.
token position filtering in order to understand when property may be ineffective consider code blocks bxandbyfrom the previous example except bxnow has one fewer token.
hence bx fa b c dgandby fb c d e fg.
assuming the same value of the blocks must still match tokens d max jb xj jbyj e d0 5e to be a clone pair.
but since the two blocks have only tokens in common they cannot be identi ed as a clone pair.
however note that their sub blocks shown in bold consisting of rst t i tokens still have a common token b. as a result property 1is satis ed and bywill be identi ed as a candidate of bxalthoughbxandbyeventually will not end up as a clone pair.
in general cases when the code blocks have fairly di erent sizes it is likely that they may result in false positives and rejected even after satisfying property .
interestingly to overcome this limitation the ordering of tokens in code blocks can be exploited.
for example if we closely examine the position of the matched token binbx andby we can obtain an estimate of the maximum possible overlap between bxandbyas the sum of current matched tokens and the minimum number of unseen tokens in bxand by i.e.
min .
since this upper bound on overlap is already smaller than the needed threshold of tokens we can safely reject byas a candidate of bx.
note that we can compute a safe upper bound without violating the correctness because the tokens follow a prede ned order.
the above heuristic can be formally stated as follows .
property let blocksbxandbybe ordered and9tokentat indexiinbx s t b xis divided in to two parts where bx first bx andbx second bx .
now ifjbx byj d max jb xj jbyj e then8t2bx by jbx first by first j min jb x second j jby second j d max jb xj jbyj e. to describe how e ective this ltering is points denoted by in figure show the number of candidate comparisons after applying this ltering.
the reduction is so signi cant that empirically on this dataset the function seems to be 5candidates that eventually will not be identi ed as clones of a code block are known as false positive candidates for that code block.near linear .
this is a massive reduction in comparison with the quadratic function shown earlier without any ltering.
although both the ltering heuristics are independent of each other they complement each other to e ectively reduce more number of candidate comparisons together than alone.
the index data structure in conjunction with the above ltering heuristics form the key components of sourcerercc to achieve scalability.
the next section describes the complete algorithm of sourcerercc.
.
clone detection algorithm the algorithm works in two stages i partial index creation and ii clone detection.
each step has ltering heuristics directly embedded in it as described below.
partial index creation.
in traditional index based approaches all the tokens are indexed.
however sourcerercc s index creation step exploits property and creates indexes for tokens only in sub blocks.
we call this partial index .
this not only saves space but also enables faster retrieval because of a smaller index.
algorithm lists the steps to create a partial index.
the rst step is to iterate over each code block b line3 and sort it according to the global token frequency map gtp line4 .
this is done as a pre requisite to the application of ltering based on property .
next the size of sub block is computed using formula shown in property i.e.
t i .
later tokens in the sub block are indexed to create the partial index lines .
algorithm sourcerercc s algorithm partial index creation input bis a list of code blocks fb1 b2 ...bngin a project repository gtp is the global token position map and is the similarity threshold speci ed by the user output partial index i ofb function createpartialindex b i foreach code block binbdo b sort b gtp tokenstobeindexed jbj d jbje fori tokenstobeindexed do t b it it t i end for end for returni end function clone detection.
after the partial index is created the goal is to detect clones.
algorithm describes the steps in detail.
the detectclones function iterates over each query blockb and sorts them using the same gtp that was created during index creation line4 .
again this is done as a prerequisite for both property to be applicable.
after that it calculates the length of query sub block by using the same formula described in property line5 .
next it iterates over only as many tokens as the length of b s sub block and retrieves candidates by querying the partial index.
note that since the partial index is created using only sub blocks the candidates retrieved in this phase implicitly satisfy property .
in other words by creating the partial index the algorithm not only reduces the index size but also ensures that we only get a ltered set of candidates that satisfy property .
after the candidates are retrieved for a given query block a trivial optimization to further eliminate candidates is done using size of the candidates.
that is if a candidate cdoes 1160not have enough tokens needed for it to be b s clone pair then there is no point in even comparing them.
this is done using a conditional check jcj d jbjeonline8.
this further lters out false positive candidates.
the remaining candidates that have satis ed the above elimination process are now subjected to the ltering based on property .
first based on a threshold is computed that identi es the minimum number of tokens needed to be matched for bandcto be identi ed as a clone pair cton line9 .
now as the tokens in bandcare compared a theoritical upper bound is dynamically computed based on the number of remaining tokens in bandc line10 .
this upper bound indicates the maximum number of tokens band ccould match assuming all of their tokens will match.
if at any point in the iteration the sum of upper bound i.e maximum number of tokens bandccould match and the current similarity score i.e number of tokens bandchave matched happens to be less than ct i.e minimum number of tokensbandcneed to match cis eliminated from b s candidate map candsimmap lines 11and .
in other algorithm sourcerercc s algorithm clone detection input bis a list of code blocks fb1 b2 ...bngin a project repository iis the partial index created from b and is the similarity threshold speci ed by the user output all clone classes clonemap function detectclones b i foreach code block binbdo candsimmap b sort b gtp querysubblock jbj d jbje fori querysubblock do t b foreach c j 2itsuch thatjcj d jbjedo ct dmax jcj jbj e ubound min jbj i jcj j ifcandsimmap ubound ctthen candsimmap candsimmap j else candsimmap .eliminatec end if end for end for verifycandidates b candsimmap ct end for returnclonemap end function function verifycandidates b candsimmap ct foreachc2candsimmap such thatcandsimmap 0do tokpos c position of last token seen in c tokpos b position of last token seen in b whiletokpos b jbj tokpos c jcjdo ifmin jbj tokpos b jcj tokpos c ctthen ifb c then candsimmap candsimmap else ifgtp gtp then tokpos b else tokpos c end if end if else break end if end while ifcandsimmap ctthen clonemap clonemap c end if end for end functionwords it is violation of property .
on the other hand if the sum is more than ct the similarity between bandcgets updated with each token that is matched line12 .
once all the tokens in b s sub block are exhausted line we have a map of candidates candsimmap along with their similarity score and the last seen token in each candidate.
the reason for storing the last seen token will become clear as we explain futher.
the next task is to verify if the candidates will eventually end up being b s clones.
this is done in a call to verifycandidates function on line18.
candidate veri cation.
the goal of verifycandidates function is to iterate over candidates cof querybthat were not rejected in detectclones compute their similarity score withb and reject them if the score does not meet the computed threshold ct or add them to the clonemap if it does.
in so an important optimization is seen on line5 .
note that tokens are not iterated from the start but from last token seen in bandcbecause earlier in detectclones few tokens ofbandcwere already iterated to check if they satisfy property lines .
hence the function avoids iterating over those tokens again.
it is for this reason in detectclones candsimmap is designed to not only store candidates but also the last token that seen in each candidate i.e.
candidate tokensseenincandidate pair.
the rest of the function while iterating over the remaining tokens ensures that property holds at every iteration line and then increments the similarity score whenever there is a token match lines .
if at any iteration property is violated candidate is eliminated immediately without iterating over the remaining tokens line17 .
thus saving much computation.
another trivial but important optimization is done while iterating over code blocks.
since bandcare already sorted using a global token frequency gtp verifycandidates e cienty iterates over bandcby incrementing only the index of a block that has a lower globally ranked token lines .
hence while iterating except in the worst case when b chappen to be clone pairs time complexity is reduced fromo jbj jcj too jbj jcj .
.
detection of near miss type clones one of the distinguishing characteristics of sourcerercc compared to other token based tools is its ability to detect near miss type clones.
the bag of tokens model plays an important role in this.
type clones are created by adding removing or modifying statements in a duplicated code fragment.
since the bag of tokens model is agnostic to relative token positions in the code block it is resilient to such changes and hence can detect near miss clones as long as the code blocks bags share enough tokens to exceed a given overlap threshold.
many type clones have modi cations such as swapping statement positions in code blocks combining multiple condition expressions into one changing operators in conditional statements and use of one language construct over another for vs while .
while these changes may exhibit semantic di erence they preserve enough syntactic similarity at a token level to be detected as similar.
detecting such clones can be di cult for other token based approaches as they use token sequences as a unit of match .
while a token sequence approach could merge nearby cloned sequences into type clones they fail to detect the clones when the type gaps are too frequent or large.
1161table clone detection tool con gurations tool scale bigclonebench mutation framework sourcerercc min length lines min similarity function granularity.min length lines min similarity function granularity.
ccfinderx min length tokens min token types .min length tokens min token types .
deckard min length tokens similarity token stride.min length tokens similarity token stride.
iclones min length tokens min block tokens.min length tokens min block tokens.
nicad min length lines blind identi er normalization identi er abstraction min similarity.min length lines blind identi er normalization identi er abstraction min similarity.
.
evaluation in this section we evaluate the execution and detection performance of sourcerercc.
we begin by evaluating its execution time and scalability using subject inputs of varying sizes in terms of lines of code loc .
we then demonstrate sourcerercc s execution for a large inter project repository one of the prime targets of scalable clone detection.
we measure its clone recall using two benchmarks the mutation and injection framework and bigclonebench .
we measure precision by manually validating a sample of its output for the bigclonebench experiment.
we compare sourcerercc s execution and detection performance against four publicly available clone detection tools including ccfinderx deckard iclones and nicad .
we include ccfinderx as it is a popular and successful tool which has been used in many clone studies.
we include deckard iclones and nicad as popular examples of modern clone detection tools that support type clone detection.
while we have benchmarked a number of tools in our previous work we focus on those with the best scalability recall and or most unique performance aspects for this study.
we focus primarily on near miss clone detectors as type and type clones are relatively easy to detect.
the con gurations of these tools for the experiments are found in table .
these are targeted con gurations for the benchmarks and are based on our extensive previous experiences with the tools as well as our previous discussions with their developers where available.
our primary goal with sourcerercc is to provide a clone detection tool that scales e ciently for large inter project repositories with near miss type clone detection capability.
most existing state of the art tools have di culty with such large inputs and fail due to scalability limits .
common limits include untenable execution time insu cient system memory limitations in internal data structures unexplained crashing or reporting an error due to their design not anticipating such a large input .
we consider sourcerercc successful if it can scale to a large inter project repository without encountering these scalability constraints while maintaining a clone recall and detection precision comparable to the state of the art.
as our target we use ijadataset .
a large inter project java repository containing open source projects million source les 250mloc mined from sourceforge and google code.
.
execution time and scalability in this section we evaluate the execution time and scalability of sourcerercc and compare it to the competing tools.execution time primarily scales with the size of the input in terms of the number of lines of code loc needed to be processed and searched by the tool.
so this is the ideal input property to vary while evaluating execution performance and scalability.
however it is di cult to nd subject systems that are large enough and conveniently dispersed in size.
additionally a tool s execution time and memory requirements may also be dependent on the clone density or other properties of the subject systems.
it is di cult to control for these factors while measuring execution performance and scalability in terms of input size.
our solution was to build inputs of varying convenient sizes by randomly selecting les from ijadataset.
this should ensure each input has similar clone density and other properties that may a ect execution time except for the varying size in loc.
each input has the properties of an interproject repository which is a target of large scale clone detection.
we created one input per order of magnitude from 1kloc to 100mloc.
we built the inputs such that each larger input contains the les of the smaller inputs.
this ensures that each larger subset is a progression in terms of execution requirements.
lines of code was measured using the unix tool cloc and includes only lines containing code not comment or blank lines.
the execution time of the tools for these inputs can be found in table .
the tools were executed for these inputs using the con gurations listed under scale in table .
the tools were executed on a machine with a .5ghz quad core i7 cpu 12gb of memory and a 250gb solid state drive.
we use a 12gb con guration to approximate the average workstation where 8gb and 16gb are standard.
while the tools may perform better on 32gb con gurations this is not typical of the average workstation.
we limit the tools to 10gb to account for os memory usage and to prevent paging.
we use the same con gurations for evaluating recall with bigclonebench such that recall execution performance and scalability can be directly compared.
scalability.
sourcerercc is able to scale even to the largest input with reasonable execution time given the input sizes.
ccfinderx is the only competing tool to scale to 100mloc however it only detects type and type clones.
the competing type tools encounter scalability limits before the 100mloc input.
deckard and iclones run out of memory at the 100mloc and 1mloc inputs respectively.
nicad is able to scale to the 10mloc input but refuses to execute clone detection on the 100mloc input.
in our previous experience nicad refuses to run on inputs that exceeds its internal data structure limits which prevent executions that will take too long to complete.
from our experiment it is clear that the state of the art type tools do not scale to large inputs whereas sourcerercc can.
execution time.
for the 1kloc to 100kloc inputs sourcerercc has comparable execution time to the competing tools.
iclones is the fastest but it hits scalability issues memory as soon as the 1mloc input.
sourcerercc has comparable execution time to ccfinderx and nicad for the 1mloc input but is much faster than deckard.
sourcerercc has comparable execution time to ccfinderx for the 10mloc input size but is much faster than nicad.
for the largest input size sourcerercc is twice as fast as ccfinderx although their execution times fall within the same order of magnitude.
before the 100mloc input sourcerercc and ccfinderx have comparable execution times.
1162table execution time or failure condition for varying input size loc sourcerercc ccfinderx deckard iclones nicad 1k 3s 3s 2s 1s 1s 10k 6s 4s 9s 1s 4s 100k 15s 21s 1m 34s 2s 21s 1m 1m 30s 2m 18s 1hr 12m 3s memory 4m 1s 10m 32m 11s 28m 51s memory 11hr 42m 47s 100m 1d 12h 54m 5s 3d 5hr 49m 11s internal limit sourcerercc is able to scale to inputs of at least 100mloc.
its execution time is comparable or better than the competing tools.
of the examined tools it is the only state ofthe art type clone detector able to scale to 100mloc.
while ccfinderx can scale to 100mloc for only detecting type and type clones sourcerercc completes in half the execution time while also detecting type clones.
.
experiment with ijadataset since sourcerercc scaled to 100mloc without issue we also executed it for the entire ijadataset 250mloc .
this represents the real use case of clone detection in a large inter project software repository.
we execute the tool on a standard workstation with a quad core i7 cpu 12gb of memory and solid state drive.
we restricted the tool to 10gb of memory and 100gb of ssd disk space.
we executed sourcerercc using the scale con guration in table with the exception of increasing the minimum clone size to ten lines.
six lines is common in recall benchmarking .
however a six line minimum may cause an excessive number of clones to be detected in ijadataset and processing these clones for a research task can become another difcult scalability challenge .
additionally larger clones may be more interesting since they capture a larger piece of logic while smaller clones may be more spurious.
sourcerercc successfully completed its execution for ijadataset in days and hours detecting a total of million clone pairs.
the majority of this time was clone detection.
extracting and tokenizing the functions required .
hours while computing the global token freqeuncy map and tokenizing the blocks required only minutes.
sourcerercc required 8gb of disk space for its pre processing index .2gb and output.
of the .
million functions in ijadataset greater than lines in length .
million appeared in at least one clone pair detected by sourcerercc.
we have demonstrated that sourcerercc scales to large inter project repositories on a single machine with good execution time.
we have also shown that building an index is an inexpensive way to scale clone detection and reduce overall execution time.
since ccfinderx scales to the 100mloc sample we also executed it for ijadataset.
we used the same settings as the scalability experiment.
we did not increase ccfinderx s minimum clone size from tokens which is roughly lines assuming tokens per line .
ccfinderx executed for days before crashing due to insu cient disk space.
its pre processed source les 25gb and temporarily disk space usage 65gb exceeded the 100gb reserved space.
based on the ndings of a previous study where ccfinder was distributed over a cluster of computers we can estimate it would require tens of days to complete detection on 250mloc given su ciently large disk space.
so we can con dently say that sourcerercc is able to complete sooner while also detecting type clones.
.
recall in this section we measure the recall of sourcerercc and the competing tools.
recall has been very di cult for tool developers to measure as it requires knowledge of the clones that exist in a software system .
manually inspecting a system for clones is non trivial.
even a small system like cook when considering only function clones has almost a million function pairs to inspect .
bellon et al.
created a benchmark by validating clones reported by the clone detectors themselves.
this has been shown to be unreliable for modern clone detectors .
updating this benchmark to evaluate a modern tool would require extensive manual clone validation with a number of modern tools.
as such many clone detection tool papers simply do not report recall.
in response we created the mutation and injection framework a synthetic benchmark that evaluates a tool s recall for thousands of ne grained arti cial clones in a mutation analysis procedure.
the framework is fully automatic and requires no validation e orts by the tool developer.
however we recognized that a modern benchmark of real clones is also required.
so we developed an e cient clone validation strategy based on code functionality and built bigclonebench a big clone benchmark containing million validated clones within and between open source projects.
it measures recall for an extensive variety of real clones produced by real developers.
the benchmark was designed to support the emerging large scale clone detection tools which previously lacked a benchmark.
this combination of real world and synthetic benchmarking provides a comprehensive view of sourcerercc s clone recall.
.
.
recall measured by the mutation framework the mutation framework evaluates recall using a standard mutation analysis procedure.
it starts with a randomly selected real code fragment a function or a code block .
it mutates this code fragment using one of fteen clone producing mutation operators.
each mutation operator performs a single code edit corresponding to one of the rst three clone types and are based on an empirically validated taxonomy of the types of edits developers make on copy pasted code.
this arti cial clone is randomly injected into a copy of a subject system.
the clone detector is executed for this system and its recall measured for only the injected clone.
the framework requires the tool to not only su ciently report the injected clone but also appropriately handle the clone type speci c change s introduced by the mutation.
as per mutation analysis this is repeated thousands of times.
further details including the list of mutation operators are available in our earlier studies .
procedure.
we executed the framework for java c and c clones using the following con guration.
for each language we set the framework to generate clones using randomly selected functions randomly selected injection locations and the mutation operators for a total 1163table mutation framework recall results tooljava c c t1 t2 t3 t1 t2 t3 t1 t2 t3 sourcerercc ccfinderx deckard iclones nicad of unique clones per language total .
for java we used jdk6 and apache commons as our source repository and ipscanner as our subject system.
for c we used the linux kernel as our repository and monit as our subject system.
for c we use mono and monodevelop as our repository and monoosc as our subject system.
we constrained the synthesized clones to the following properties lines in length tokens in length and a mutation containment of .
we have found this con guration provides accurate recall measurement .
the tools were executed and evaluated automatically by the framework using the con gurations listed in table .
to successfully detect a reference injected clone a tool must report a candidate clone that subsumes of the reference clone by line and appropriately handle the clone type speci c edit introduced by the mutation operator .
results.
recall measured by the mutation framework for sourcerercc and the competing tools is summarized in table .
due to space considerations we do not show recall per mutation operator.
instead we summarize recall per clone type.
sourcerercc has perfect recall for the rst three clone types including the most di cult type clones for java c and c .
this tells us that its clone detection algorithm is capable of handling all the types of edits developers make on copy and pasted code for these languages as outlined in the editing taxonomy for cloning .
sourcerercc exceeds the competing tools with the mutation framework.
the runner up is nicad which has perfect recall for java and near perfect recall for c and c .
iclones is also competitive with sourcerercc although iclones has some troubles with a small number of type and type clones.
sourcerercc performs much better for type and type clones than ccfinderx.
of course as a type tool ccfinderx does not support type detection.
sourcerercc performs much better then deckard across all clone types.
while deckard has decent recall for the c clones its java recall is very poor.
we believe this is due to its older java parser java .
only while the java reference clones may contain up to java .
features.
sourcerercc has perfect recall with the mutation framework which shows it can handle all the types of edits developers make on cloned code.
as per standard mutation analysis the mutation framework only uses one mutation operator per clone.
this allows it to measure recall very precisely per type of edit and clone type.
it also prevents the code from diverging too far from natural programming.
however this means that the framework makes simple clones.
it does not produce complex clones with multiple type of edits and the type clones it produces generally have a higher degree of syntactical similarity.
to overcome this issue we use the real world benchmark bigclonebench as follows.
.
.
recall measured by bigclonebench here we measure the recall of sourcerercc using big table bigclonebench clone summary clone type t1 t2 vst3 st3 mt3 wt3 t4 of clone pairs clonebench and compare it to the competing tools.
we evaluate how its capabilities shown by the mutation framework translate to recall for real clones produced by real developers in real software systems spanning the entire range of clone types and syntactical similarity.
together the benchmarks provide a complete view of sourcerercc s recall.
bigclonebench is a big clone benchmark of manually validated clone pairs in the inter project software repository ijadataset .
.
ijadataset consists of open source java systems spanning million les and 250mloc.
bigclonebench was built by mining ijadataset for functions implementing particular functionalities.
each clone pair is semantically similar by their target functionality and is one of the four primary clone types by their syntactical similarity .
the published version of the benchmark considers target functionalities .
we use an in progress snapshot of the benchmark with target functionalities and million validated clone pairs for this study.
for this experiment we consider all clones in bigclonebench that are lines and tokens in length or greater.
this is the standard minimum clone size for measuring recall .
by specifying this both in lines and tokens we are able to con gure the tools appropriately for clone size .
clone size is a primary clone detection con guration and this prevents it from biasing the comparison of the tools recall.
the number of clones in bigclonebench given this size constraint is summarized per clone type in table .
there is no agreement on when a clone is no longer syntactically similar so it is di cult to separate the type3 and type clones in bigclonebench.
instead we divide the type and type clones into four categories based on their syntactical similarity as follows.
very strongly type3 vst3 clones have a syntactical similarity between inclusive and exclusive strongly type st3 in moderately type mt3 in and weakly type type wt3 in .
syntactical similarity is measured by line and by token after type and type2 normalizations.
we use the smaller of the measurements for categorization.
the categories and the benchmark in general are explained in more detail elsewhere .
procedure.
we executed the tools for ijadataset and evaluated their recall with bigclonebench.
as we saw previously section .
most tools do not scale to the order of magnitude of ijadataset 250mloc .
our goal here is to measure recall not scalability.
we avoid the scalability issue by executing the tools for a reduction of ijadataset with only those les containing the known true and false clones in bigclonebench les 10mloc .
some of the competing tools have di culty even with the reduction in which case we partition it into small sets and execute the tool for each pair of partitions.
in either case the tool is exposed to every reference clone in bigclonebench and it is also exposed to a number of false positives as well creating a realistic input.
we measure recall using a subsume based clone matching algorithm with a threshold.
a tool successfully detects a reference clone if it reports a candidate clone that subsumes of the reference clone by line.
this is the same algorithm we use with the mutation framework and is a standard in benchmarking .
1164results.
recall measured by bigclonebench is summarized in table .
it is is summarized per clone type and per type category for all clones as well as speci cally for the intra and inter project clones.
sourcerercc has perfect detection of the type clones in bigclonebench.
it has near perfect type detection with negligible di erence between intra and inter project.
this shows that the threshold is su cient to detect the type clones without identi er normalizations.
sourcerercc has excellent type recall for the vst3 category both in the general case and for intra project clones .
the vst3 recall is still good for the inter project clones but it is a little weaker.
sourcerercc s type3 recall begins to drop o for the st3 recall .
its recall is good in this type category for the intra project clones but poor for the inter project clones .
we believe this is due to inter project type clones having a higher incidence of type di erences causing them to not exceed sourcerercc s overlap threshold.
remember that the reference clone categorization is done using syntactical similarity measured after type normalizations whereas sourcerercc does not normalize the identi er token names to maintain precision and index e ciency .
lowering sourcerercc s threshold would allow these to be detected but could harm precision.
sourcerercc has poor recall for the mt3 and wt3 t4 which is expected as these clones fall outside the range of syntactical clone detectors .
type detection is outside the scope of this study.
compared to the competing tools sourcerercc has the second best recall overall with nicad taking the lead.
both tools have perfect type recall and they have similar type2 recall with nicad taking a small lead.
sourcerercc has competitive vst3 recall but loses out in the inter project case to nicad.
sourcerercc is competitive with nicad for intra project clones in the st3 category but falls signi cantly behind for the inter project case and overall.
nicad owes its exceptional type recall to its powerful source normalization capabilities.
however as we saw previously in section .
nicad has much poorer execution time for larger inputs and hits scalability constrains at the 100mloc input.
so sourcerercc instead competes with execution performance and scalability.
comparison to ccfinderx is interesting as it is the only other tool to scale to the 100mloc input.
both tools have comparable type and type recall with sourcerercc having the advantage of also detecting type clones the most di cult type.
while bigclonebench is measuring a non negligible vst3 recall for ccfinderx it is not truly detecting the type clones.
as shown by the mutation framework in table ccfinderx has no recall for clones with type edits while sourcerercc has perfect recall.
rather ccfinderx is detecting signi cant type regions in these very strongly similar type clones that satisfy the coverage threshold.
this is a known limitation in real world benchmarking which is why both real world and synthetic benchmarking is needed.
ccfinderx s detection of these regions in the vst3 is not as useful to users as they need to manually recognize the missing type features.
ccfinderx s type recall drops o past the vst3 category where type gaps are more frequent in the clones.
while we showed previously that ccfinderx also scales to larger inputs section .
sourcerercc s faster execution type support and better recall make itan ideal choice for large scale clone detection.
deckard and iclones are the other competing type clone detectors.
both sourcerercc and iclones have perfect type1 recall but sourcerercc exceeds iclones in both type2 and type detection and iclones does not scale well.
deckard has poor overall recall for all clone types along with its scalability issues.
.
precision unlike clone detection recall where there exists high quality benchmarks measuring precision remains an open problem and there is no standard benchmark or methodology.
instead we estimate the precision of the tools by manually validating a random sample of their output which is the typical approach.
from each tool we randomly selected of the clone pairs they detected in the recall experiment.
the validation e orts were equally distributed over ve judges all software researchers with each validating clones from each tool.
the clones were shu ed and the judges were kept blind of the source of each clone.
the judges were familiar with the cloning de nitions and were asked to validate the clones as per their judgment.
we nd that sourcerercc has a precision of the second best precision of these tools.
this is a very strong precision as per the literature and demonstrates the accuracy and trustworthiness of sourcerercc s output.
we summarize the precision of all the tools in table and contrast it against their overall and type recall measured by bigclonebench.
we do not include the mt3 and wt3 t4 clones as they are outside the scope of these tools.
iclones has the top precision because it is cautious when reporting type clones although this results in a type3 recall signi cantly below sourcerercc and nicad .
sourcerercc s bag of tokens model and similarity threshold allows it to provide a good balance of recall and precision achieving the 2nd best type recall while also providing superior scalability.
nicad has a precision of possibly because of its use of normalizations and relaxed threshold.
however with these settings nicad has a very strong overall and type recall and among the top of the tools.
the authors report a precision of for nicad depending on the con gurations.
ccfinderx s precision while competitive is low considering it only targets type and type clones although it detects some type regions in type clones .
deckard has very poor precision in this experiment reporting some clones that are very dissimilar.
this may be because we relaxed its similarity threshold to detect more type clones.
the authors report a precision of for java .
code with a similarity threshold.
nonetheless ccfinderx and deckard show very poor type recall as well.
tool con guration particularly minimum clone size is a bias in this precision experiment.
this was controlled in the recall experiment by setting a minimum clone size of six lines and tokens in bigclonebench and con guring the tools appropriately.
however there is no agreement between lines of code and the tokens contained and even the tools measure lines original pretty printed and tokens original ltered in di erent ways.
this makes comparing the precision of the tools di cult because this con guration issue may cause a tool to detect many small spurious clones that another tool does not due to di erence in clone size con guration and or measurement.
to examine this we re measured precision 1165table bigclonebench recall measurements toolall clones intra project clones inter project clones t1 t2 vst3 st3 mt3 wt3 t4 t1 t2 vst3 st3 mt3 wt3 t4 t1 t2 vst3 st3 mt3 wt3 t4 sorcerercc ccfinderx deckard iclones nicad table tool recall and precision summary sourcerercc ccfinderx deckard iclones nicad precision precision 10loc recall190 recall t3 1including t1 t2 vst3 st3.2including vst3 st3.
using a minimum clone size of original lines of code in order to harmonize the minimum clone size of the tools.
we used the existing validation e orts randomly selecting validated clones per tool per judge clones per tool that are 10loc or greater.
these results are shown in table .
this precision measurement is more fair by comparing the tools under equivalent conditions as we did with the recall experiment but is less directly comparable with the recall results.
all of the tools see a boost in precision although nicad most signi cantly.
with full normalization and a generous threshold of dissimilarity nicad may be detecting small false clones that are pretty printed lines or so but contain very few tokens spurious similarity .
nicad can be con gured with a maximum clone size and can e ciently be executed with multiple con gurations so it may be best to run nicad with a more strict threshold for just the very small clones 9loc .
a full exploration of tool setting permutations versus performance is challenging and outside the scope of this paper.
.
threats to validity as observed by wang et al.
clone detection studies are a ected by the con gurations of the tools and sourcerercc is no exception.
however we carefully experimented with its con gurations to achieve an optimal result.
as for the other tools we conducted test experiments and also discussed with the corresponding developers for obtaining proper con gurations where available.
their con gurations also provided good results in our past studies .
there are some limitations in the precision measurement.
the choice of subject system in our case a subset of ijadataset tool con guration and targeted use case can all have a signi cant impact on the precision measured.
the reliability of even expert judges is also a concern .
measuring clone detection precision is very much an open problem and although many of the obstacles in measuring precision have been identi ed there does not exist a benchmark or methodology that overcomes these challenges.
it is outside the scope of this work to explore new precision methodologies or benchmarks to resolve these issues.
.
related work rattan et al.
found at least clone detectors in the literature.
however very few tools target scalability to very large repositories.
liveri et al.
introduced a method ofdistributing an existing non scalable tool to very large inputs.
they partition the input into subsets small enough to be executed on a single machine and execute the tool for each pair of partitions.
partitioning achieved scalability in execution resource requirements while scalability in time is achieved by distribution of the executions over a large number of machines.
svajlenko et al.
use a non deterministic shu ing heuristic to reduce the number of tool execution signi cantly at the cost of a reduction in recall.
distribution of these executions over a small number of machines is still recommended for scalability in time.
sourcerercc uses a novel scalable clone detection technique and is capable of scaling to large repositories on a single machine.
ishihara et al.
use md5 hashing to scale methodclone detection.
while they achieve fast execution time their methodology does not detect type clones which are the most common in large repositories .
hummel et al.
were the rst to use an index based approach to scale clone detection to large repositories although they detect only type and type clones.
their technique produces a very large index so the index and the computation must be distributed using mapreduce.
in contrast our sourcerercc produces a very small index just .2gb for 18gb 250mloc of code and detects type clones in large repositories using a single machine.
others have scaled clone detection in domain speci c ways and are not directly related to ours.
koshke used su x trees to scale license violation detection between a subject system and a large inter project repository.
keivanloo et al.
and lee et al.
use index based approaches to scale clone search to large inter project repositories.
chen et al.
implement a technique for detecting cloned android applications across large application markets.
.
conclusion in this paper we introduced sourcerercc a token based accurate near miss clone detection tool that uses an optimized partial index and ltering heuristics to achieve largescale clone detection on a standard workstation.
we demonstrated sourcerercc s scalability with ijadataset a large inter project repository containing open source java systems and 250mloc.
we measure its recall using two state of the art clone benchmarks the mutation framework and bigclonebench.
we nd that sourcerercc is competitive with even the best of the state of the art type clone detectors.
we manually inspected a statistically signi cant sample of sourcerercc s output and found it to also have strong precision.
we believe that sourcerercc can be an excellent tool for the various modern use cases that require reliable complete fast and scalable clone detection.
sourcerercc is available on our website6.
.