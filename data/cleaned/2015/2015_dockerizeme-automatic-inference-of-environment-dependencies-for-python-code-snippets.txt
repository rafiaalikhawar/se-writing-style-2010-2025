dockerizeme automatic inference of environment dependencies for python code snippets eric horton chris parnin nc state university raleigh nc usa email ewhorton cjparnin ncsu.edu abstract platforms like stack overflow and github s gist system promote the sharing of ideas and programming techniques via the distribution of code snippets designed to illustrate particular tasks.
python a popular and fast growing programming language sees heavy use on both sites with nearly one millionquestions asked on stack overflow and thousand public gistson github.
unfortunately around of the python examplecode shared through these sites cannot be directly executed.
whenrun in a clean environment over of public python gists faildue to an import error for a missing library.
we present dockerizeme a technique for inferring the dependencies needed to execute a python code snippet without importerror.
dockerizeme starts with offline knowledge acquisition ofthe resources and dependencies for popular python packagesfrom the python package index pypi .
it then builds dockerspecifications using a graph based inference procedure.
ourinference procedure resolves import errors in out of nearly3 gists from the gistable dataset for which gistable s baselineapproach could not find and install all dependencies.
index t erms docker configuration management environment inference dependencies python i. i ntroduction sharing code snippets to illustrate a specific task is frequently used practice within the software engineering industry .
due to the importance of sharing examples platforms like stack overflow and github s gist system have been created to facilitate social learning through community driven interaction.
github gists are short but complete programs often only a single file.
unfortunately many code snippets do not contain information regarding the system configuration needed for proper execution as system configuration is not an inherent property of code.
consider sentry an error reporting system.
the official client for python raven supports the flask framework .
examples1demonstrating how to use sentry with flask often have no indication that it needs to be installed with flask extras causing developers to encounter runtime errors2.
this is a wide spread problem.
research by yang et al.
found that only of code snippets from stack overflow can be run without error .
horton and parnin later found .
of python gists from github to run without error .
the main cause of failure experienced by .
of the gists evaluated was a dependency error.
seo et al.
also found that approximately of build errors are caused by dependencies .
further the effort involved in manually constructing an environmentspecification is non trivial developers can spend between minutes and hours creating a dockerfile for a single code snippet and often fail to construct a valid specification .
common challenges include mapping a code resource toits originating package and determining the correct order of installation for transitive dependencies.
this work focuses on automating the dependency resolution process of system configuration management for both languagelevel and system level dependencies.
before performing dependency resolution we build an offline knowledge base fromtwo sources.
first we process existing packages on the python package index pypi by extracting declared resources andusing dynamic analysis to determine possible dependencies.second we inspect project configuration files from github and generate association rules for pairs of packages which are frequently seen together.
environment inference for a code snippet is performed by querying the knowledge base to map code resources to installable packages.
a search algorithm then resolves all transitive dependencies in a consistent order.
we implement dockerizeme a tool for applying dependency resolution to a code snippet and generating a dockerfile forthe corresponding environment.
unlike other approaches toautomated software configuration which focus on repairing configuration errors dockerizeme focuses on inferring a complete configuration without external inputs.
being able to automatically infer code dependencies has the potential to save developers time reduce costs of learningand development and enable repair and verification of code snippets in online platforms.
it is also a first step towards fully automated software configuration management.
to evaluate dockerizeme we performed environment configuration for gists from the gistable dataset whichstill failed due to python s importerror after applying gistable s environment inference algorithm section iii cfrom .
dockerizeme successfully removed import errors for gists.
in summary this work contains the following contributions a technique for computing package dependencies using static analysis dynamic analysis and developer generated knowledge sources.
an inference algorithm for direct and transitive dependencies that respects installation order.
ieee acm 41st international conference on software engineering icse .
ieee authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
1import pcapy 2from impacket.impactdecoder import list all the network devices 5pcapy .findalldevs 7max bytes 8promiscuous false 9read timeout in milliseconds 10pc pcapy .open live eth0 max bytes promiscuous read timeout arrowhookleft 12pc.setfilter tcp callback for received packets 15def recv pkts hdr data packet ethdecoder .decode data print packet 19packet limit infinite 20pc.loop packet limit recv pkts capture packets a snippet.py python .
.
update apt package list and install required system dependency arrowhookleft arrowhookleft 4run apt get update 5run apt get install y libpcap dev arrowhookleft install python dependencies not included with snippet.py arrowhookleft arrowhookleft 8run pip install pcapy 9run pip install impacket 11copy snippet.py scripts snippet.py arrowhookleft 12cmd python scripts snippet.py b dockerfile fig.
a code snippet for capturing packets on a network interface.
b dockerfile for running the code snippet.
dockerizeme a tool for building inferred environments.
an empirical evaluation of dockerizeme s effectiveness and a categorization of additional challenges in environment configuration.
ii.
m otiv ating example many code snippets shared as examples are not directly executable often because they depend on external libraries that are not present by default on a developer s system .
discovering all required dependencies is a time consuming process that even experienced developers have trouble with .
consider the following scenario a developer is working on a networking component and needs to parse packets from a network interface.
they would like to use python and search for python libraries that can be used to perform this task.
fortunately other developers have previously asked for recommendations on libraries to solve the same problem.
they quickly come across a post on stack overflow3with a couple different recommendations.
the accepted answer recommends scapy but it is licenced under gplv2 a copyleft license which the developer cannot use for their project.
however another answer recommends pcapy and provides an example snippet for printing packets as they arrive on an interface.
the developer wants to see if the example works so they create a file named snippet.py figure 1a containing the example code modifying the network device name in the example name of network device to capture from to be eth0.
however when running python snippet.py they are met with the error importerror no module named pcapy due to the fact that pcapy is not a part of the python standard library.
the developer notes that there are two packages imported in the snippet pcapy and impacket.
both packages exist on python package index pypi so the developer attempts to install each with pip install pcapy impacket .
unfortunately pcapy fails to install due to a compiler error.
further investigation reveals that pcapy relies on the pcap system library headers that the developer does not have installed.
the developer first attempts to install the package pcap using apt get their system s package manager but no such package exists.
the actual package name is libpcap0.
.
however the pcap library does not come with the headers that pcapy requires and the developer finds they must install the development package libpcap dev.
the final configuration is encoded by the dockerfile in figure 1b.
without any aid developers face a trialand error struggle to discover dependencies for environment specifications such as this.
iii.
d ockerize me the main purpose of dockerizeme is to solve the dependency resolution problem in software configuration management.
we now define the dependency resolution problem given an runnable code snippet c correctly install all languagelevel and system level software packages required for cto execute without an import error.
language level dependencies are dependencies managed by a package manager or tooling provided with the language runtime environment.
a systemlevel orsystem dependency is installed on the system but managed externally to the language runtime environment.
in the context of dependency resolution a code snippet c is considered runnable if it can be evaluated by the execution environment.
that is it does not experience fatal errors at compile or load time.
a runnable code snippet may experience a fatal error during runtime.
we say cexperiences an import error if it experiences a fatal runtime error caused by the failure to find a requested library.
we focus on python a popular language with a robust ecosystem containing over packages on its standard package authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
platform .
a python code snippet experiences an import error if it exits due to python s exception importerror .
we begin addressing dependency resolution by building an offline knowledge base sections iv and v .
we then design an inference algorithm section vi to return dependencies in a feasible installation order.
dockerizeme4is implemented as a nodejs command line utility.
running dockerizeme on a python package will generate the contents of a proposed dockerfile containing all dependencies recovered by the inference procedure.
iv .
k nowledge acquisition dockerizeme uses an offline knowledge base to correctly infer dependencies for a target script.
this knowledge base contains packages their versions and resources and the relationships between them.
it is built by applying static and dynamic analysis to known packages from the libraries.io dataset.
static analysis enumerates packages known resources for later retrieval and dynamic analysis gathers information about transitive dependencies.
association rule mining of dependencies in public python projects takes advantage of developer generated knowledge of system level transitive dependencies.
we now discuss each technique in detail.
a. discovering package resources inferring which packages correspond to code resources used by a script can be a challenging and non trivial task.
as reported by many resources have a different name than the package that they belong to.
it is often difficult for developers to determine which packages to use.
to better inform our inference procedure we analyzed the top ten thousand python packages on pypi based on their sourcerank in the libraries.io dataset .
packages were selected by source rank to include the most commonly used libraries as popular libraries can affect large portions of a package ecosystem and the size of the ecosystem is prohibitive to full analysis .
if the install was successful we recorded the distribution s top level resources as listed in top level.txt .
for example we extracted the resources bio and biosql from the python package biopython.
installation succeeded for of the tested packages.
some packages may have failed to install due to missing dependencies or some other unknown configuration.
when this happened we attempted to download and parse the package distributions manually.
all packages were downloaded with pip using the options no cache dir and no deps .
if the package provided a wheel a distribution in python s binary format on pypi we downloaded it with only binary all .
if the package did not have a wheel on pypi but did have a source distribution we downloaded it with no binary all .
for source distributions we then attempted to build a wheel distribution using the option no deps .
if successful in either downloading or building a wheel for a package we then parsed package s top level resources by finding and reading the wheel s top level.txt file.
this was successful for one in three packages.
b. dynamic analysis some packages may not properly list their dependencies preventing pip from automatically handling resolution during install.
we address this issue by performing dynamic analysis using the packages by sourcerank from the libraries.io data.
first we attempt to install each package using pip install package .
if the installation succeeds we then parse the top level resources and attempt to import each.
any error output from the install import process is logged and on failure we parse the output for instances of the following patterns which indicate dependence on some python package that was not present.
no module named name .
pip install name .
cannot find name .
cannot import name name .
for example attempting to install the python package pyhum results in the following output importerror no module named numpy.
please install numpy first it is needed before installing pyhum.
based on the output our dynamic analysis procedure enters a dependency record into the knowledge base which indicates that pyhum requires numpy.
c. association rules static and dynamic analysis cannot provide meaningful information about a package if the installation fails and no wheel can be found or built.
dynamic analysis may also fail to find a package s dependencies due to non standard error messages or