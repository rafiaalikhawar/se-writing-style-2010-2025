recommending crowdsourced software developers in consideration of skill improvement zizhe wang hailong sun yang fu luting ye state key laboratory of software development environment school of computer science and engineering beihang university beijing china wangzz fuyang yeluting act.buaa.edu.cn sunhl buaa.edu.cn abstract finding suitable developers for a given task is critical and challenging for successful crowdsourcing software development.
in practice the development skills will be improved as developers accomplish more development tasks.
prior studies on crowdsourcing developer recommendation do not consider the changing of skills which can underestimate developers skills to fulfill a task.
in this work we first conducted an empirical study of the performance of developers on topcoder.
with a difficulty weighted algorithm we re compute the scores of each developer by eliminating the effect of task difficulty from the performance.
we find out that the skill improvement of topcoder developers can be fitted well with the negative exponential learning curve model.
second we design a skill prediction method based on the learning curve.
then we propose a skill improvement aware framework for recommending developers for software development with crowdsourcing.
index terms crowdsourcing recommender systems software development topcoder.
i. i ntroduction crowdsourcing has become a prevalent paradigm for software development.
platforms such as topcoder freelancer and kaggle usually adopt a contest mechanism to elicit contributions from individual developers.
take topcoder as an example a requestor publishes a task to topcoder with task description and a certain amount of monetary rewards.
then developers on topcoder platform check the task description and the rewards to see if it is worthwhile the task.
next the interested developers will register with the task and submit their deliverables to topcoder after they finish the development.
then a core team on topcoder is responsible for evaluating the submissions from developers.
some top ranked developers are granted rewards according to the pre set rules.
the above process is also known as the open call mode in which the software development productivity and quality depend heavily on the skills and efforts of the developers who answer the task call.
recently several efforts are made to recommend developers to a given task.
essentially existing work concerns finding developers whose skills can meet the requirements of a task.
in practice software development skills are gradually improved as developers perform more tasks.
however no efforts are seen to study the skill improvement issue in crowdsourced software development.
instead existing work corresponding authoron developer recommendation treats the skills of developers statically.
in this work we aim at studying a developer recommendation approach for crowdsourced software development by considering the skill improvement of developers.
to achieve this goal we choose topcoder as our research platform because topcoder is known as one of the earliest and largest crowdsourcing platforms.
note in topcoder a task is also referred to as a challenge.
we interchangeably use the two terms in the rest of this paper.
to be specific we are mainly concerned with answering three research questions how to measure the skill level of developers?
intuitively in topcoder this can be realized by using the scores that a developer obtains for finishing a development task.
however received scores are also affected by the difficulty of tasks.
thus the raw score data cannot be straightforwardly used to measure a developer s skills.
how do the skills of developers improve over time?
intuitively a developer will improve her skills as she accomplishes more and more challenges.
however a clear understanding to the improvement is still a pending issue.
what can we do when we know the way that skills improve?
this is the ultimate question we want to answer in this study.
actually we aim at designing an approach to recommend developers by considering the skill improvement.
to answer the three questions we selected developers who have participated over challenges in topcoder.
and for each developer the score of each submission is available.
first to measure the skills of a developer we design a difficultyweighted scoring algorithm.
in this algorithm we first define the difficulty of challenges as a synthesized score of four attributes including the time of duration prize number of registrants and reliability bonus.
the four attributes of each submission are all given in topcoder.
then the scores of each submission are weighted according to the difficulty.
second we model the skill improvement with known learning curves with the statistical analysis of the difficulty weighted scores of each developers.
and we find that the negative exponential learning curve can best model the skill improvement of topcoder developers.
third we design a skill improvement aware .
c ieeease urbana champaign il usa technical research new ideas717 authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
framework for recommending developers for crowdsourced software development tasks where the learning curves of developers are incorporated into recommendation algorithms.
the major contributions of this work are as follows we have empirically studied the skill improvement issue in topcoder and we confirm that developers do learn as they perform more development tasks.
as far as we know we are the first to study this problem in crowdsourced software development.
we propose to model the skill improvement with learning curve models and verify that the negative exponential learning curve is suitable for characterizing the skill improvement of developers in topcoder.
we present an approach to recommend developers for crowdsourced software development by incorporating skill improvement.
the remainder of this paper is organized as follows.
in section ii we propose a difficulty weighted algorithm to measure the skills of a developer.
section iii presents our study of using learning curves to describe the skill improvement.
section iv gives a prediction model with the learning curve.
in section v we design a recommendation approach considering skill improvement.
section vi discusses the related work.
finally in section vii we conclude this work.
ii.
r epresenting developers performance with difficulty weighted scores a. data preparation we crawled a dataset from topcoder involving challenges developers who made submissions from to .
for most developers the number of submissions are less than .
and we chose developers who have over submissions to study the changing of the developers skills.
a final score is given when a submission is submitted on topcoder.
when a submission s final score is it usually means the submission is unfinished which cannot reflect the skill level of the developer.
so we delete the submissions which score .
then there are finally developers left.
our dataset and source code can be found on githuby.
b. correlation analysis to characterize developers performance we first directly plot the final scores of each developer s submissions in chronological order.
as shown in figure there are no apparent trends in developers performance.
we further conducted a spearman correlation analysis between the final scores and the chronological order of those scores and the results are presented in figure .
in figure we find that the majority of spearman correlation coefficients are between and0 .
the mean value of jrj is0 and the mean value of ris0 .
therefore we can conclude that the correlation between performance and time is weak.
y 8020406080100final scoresfig.
.
scatter diagram of developers final score.
x axis represents the serial number of time y axis is the final scores.
.
.
.
.
.
.
correlation coefficient024681012141618number of developers fig.
.
the distribution of developers spearman correlation coefficients.
however this result does not comply with our intuition of the skill improvement with time.
thus we are wondering whether the final scores can reflect the true skills of developers?
a straightforward thought is that the final scores are also affected by the difficulty of challenges except the development skills.
developers usually get higher scores on less difficult challenges.and the results shown in figure can be caused by the un uniform distribution of the challenge difficulty.next we analyze the factors that may reflect the challenge difficulty.
c. the factors reflecting difficulty given a challenge we consider four parameters that can be used to infer the difficulty of challenges including the time of duration prize number of registrants and reliability bonus.
time of duration usually a difficult and complex challenge needs more time to be processed.
prize the prize given by the requester is also a significant attribute.
a high prize means the challenge is more difficult and needs developers with better skills.
number of registrants the number of registrants is the number of developers who register with the challenge.
a large number of registrants mean it is more difficult to win the prize.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
5012345weighted scores 8012345fig.
.
scatter diagram of developers weighted final scores.
x axis is serial number y axis is the difficulty weighted scores.
reliability bonus reliability bonus is the bonus that the requester sets to ask for a more reliable program.
the difficulty increases when the reliability is asked for.
d. the algorithm we first normalize the four attributes to .
for challenge i we denote its time of duration by ti and denote the maximum oftibytmax.
then the time parameter of challenge iis represented as follows ti ti tmax in a similar way we define the prize parameter pi registrant parameterriand reliability parameter biaspi pi pmax ri ri rmaxandbi bi bmaxrespectively.
since the four attributes are all positively related to difficulty the summation of them is also positively related to difficulty.
so we define the difficulty parameter dias the summation of the four parameters.
di ti pi ri bi multiplying the final scores by the difficulty parameters we get the difficulty weighted scores which eliminate the influence of challenge difficulty.
by arranging the weighted scores of each developer according to time we can observe an apparent growing trend of developers skills.
figure plots the results of developers randomly selected from the .
similarly we calculate the spearman correlation coefficient rbetween the difficulty weighted final scores and time using the same method.
the distribution of rcan be seen in figure .
.
of the developers have an rgreater than .
and the mean value ofjrjis0 the mean value of ris0 which shows a moderate correlation.
so we can conclude that the difficulty algorithm is effective and the performance and time have a positive correlation.
.
.
.
.
.
.
correlation coefficient024681012141618number of developersfig.
.
the distribution of the developers spearman correlation coefficients.
iii.
t helearning curve models of developers perfromance since the positive correlation has been observed we introduce two learning curves to fit the scatter diagram of the difficulty weighted scores and make a comparison.
a. the hyperbolic learning curve letwbe a developer with the prior knowledge pwand the learning speed rw.
and the highest score is k. then according to the hyperbolic learning curve the performance qw x of developer wcan be defined as qw x kx pw x pw rw regarding the serial numbers of each developer s submissions as xand the difficulty weighted score of these submissions as qw x we can estimate the value of pwand rw.
to learn a model for qw x we letzhw x k k qw x hw rw hw pw rw .
then we get a linear model zhw x hwx hw using linear regression method we estimate the value of hwand hw.
and then we calculate the value of pwandrw.
part of fitting results are shown in figure and the values ofpw rwandnormr of them are shown in table i normr stands for the norm of residuals.
from figure and table i we find that the hyperbolic learning curve doesn t fit the data well.
the value of pwstands for the prior knowledge of developer w and it should be positive in this model.
but in table i some of them are negative which indicates that the fitting is not appropriate.
since that we adopt another learning curve model called negative exponential learning curve model to fit the experimental data.
b. the negative exponential learning curve letwbe a developer with the prior knowledge pwand the learning speed rw.
then according to the negative exponential authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
1012345weighted score20 8012345fig.
.
the fitting results of developers using hyperbolic learning curve model.
table i thepw rw normr values and p values of the 8developers in figure serial number pw rw normr p value .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
learning curve the performance qw x of developer wcan be defined as qw x k e x pw rw similarly we transform eq.
into a linear function by equationszew x ln q w x k ew r ew pw rw lnk.
so the linear model is zew ewx ew using least square linear regression we estimate the value of ewand ew.
and then we calculate the value of pwand rw.
part of fitting results are shown in figure and the values ofpwandrwof them are shown in table ii.
c. comparison from figure and figure we can see that the negative exponential learning curve fits the data better than the hyperbolic one.
in table i and table ii the norms of the residuals of the negative exponential model are far less than the hyperbolic one.
and the p values in table ii are all less than which means the fittings are reliable at a significance level.
on the contrary some of the p values in table i are larger than .
indicating that the fittings are not reliable.
5012345weighted scores 8012345fig.
.
the fitting results of developers using negative exponential learning curve model.
table ii thepw rw normr values and p values of the 8developers in figure serial number pw rw normr p value .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
actually among all the fittings using the negative exponential model there are respectively fittings have p values less than .
.
.
.
but for the hyperbolic model there are only fittings have p values less than .
.
.
.
this shows that negative exponential model is more reliable to fit the difficulty weighted final scores.
the results also show that most developers skills improvement obeys the negative exponential learning curve.
iv.
t heskill prediction model a. the prediction model we propose to use the learning curve model to predict the performance of developers and recommend the developers who may outperform others for requester.
since the negative exponential learning curve performs well in fitting the developer s scores we use it to predict the developers performance.
we choose the developers whose p values are less than .
in section iii which means the learning curve law is significant on them.
we select the first weighted final scores of each developer and use the first nscores to estimate the value of parameter pwandrwin eq.
.
then we use the model as a prediction model and use the nextmscores to evaluate the model.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
n value0.
.
.
.
.
.
.
.
.
.
.9rn value exp last meanfig.
.
the r values of the prediction model last one method and mean method.
x axis is n value y axis is r value.
m .
b. comparison we design three prediction methods as comparisons to our prediction model.
hyperbolic this method uses the hyperbolic learning curve to fit the developers first nscores and employs the models to predict the next mscores.
mean this method calculates the mean values of each developers first nscores and regards the mean values as predicted values of the next mscores.
last one this method regards the nthscores of the developers as predicted values of the next mscores.
c. evaluation to evaluate the reliability of prediction we calculate the difference between the predicted values and the real values of the nextnscores.
the equation to calculate the difference is as follows rn m 5050x w 1vuut1 mmx i qw n i yw n i whereyw n i is the real value of the n i thscore.
the comparison under different nandmcan be seen in figure since the rn m values are far larger than the other methods figure shows the rn 5values of exponential mean and last one methods under different nvalues.
we can see that our prediction model has the minimal rvalues when n is more than .
actually our prediction model always has the minimalrvalues with an n larger than when mchanges from to .
a lowerrvalue means a more reliable prediction so we can conclude that our prediction model has a superior forecasting performance.
v. t herecommendation workflow in prior recommendation methods the improvement of developers skills are not taken into account.
thus we design fig.
.
the recommendation workflow with difficulty weighted score and the prediction model a recommendation workflow on the basis of the difficulty algorithm and the learning curve model.
the workflow is divided into three parts and it is illustrated in figure .
a. building learning curve models in section iv we have prediction models of many developers and they perform well.
but we can t use these models for recommendation directly.
since different tasks require different skills developers won t do the tasks they are not good at.
thus we should select the developers who are proficient at certain kind of tasks first and build their learning curve models on different kind of tasks.
at first we apply an algorithm such as k means to cluster the tasks in the historical data.
for each cluster we build learning curve models of each developer with their difficultyweighted scores in the cluster.
then we get the learning curve models that forecast the developers performance on different kind of tasks.
b. finding developers when a task is released we suppose to find out which developers are good at this kind of task.
we can classify the new task by calculating its distance to each cluster mentioned in section v a. the distance can be calculated by measuring their differences in platforms and techniques or other characteristics.
the cluster with the shortest distance will be the most similar cluster to the new task.
and the developers who have done the tasks in the cluster are those who are good at this kind of tasks.
c. predicting and ranking the developers knowing who are good at this kind of task we can find their learning curve models in this cluster.
then we can predict their possible performance on the new task by calculating the difficulty weighted scores next time.
since the difficulty in the difficulty weighted scores is the difficulty of the new task the difficulty weighted scores of each developer have the same difficulty weight.
therefore we can compare the performance of each developer by comparing their difficulty weighted scores.
by ranking the scores we get the developers who score higher and recommend these developers to the new task.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
vi.
r elated work our work concentrates on the change of worker performance in crowdsourcing process.
in crowdsourcing there are a large number of works concentrating on worker ability.
some design a tool to analyze the performance data of developers for improvement recommendation some identify developers of high quality from their open source contributions some weigh workers according to their inferred expertise for hiring good worker .
nevertheless they don t consider about that the performance will change over time.
there are also some works taking the change of worker ability into consideration.
some researchers use a time serial model to describe and predict the change of worker performance .
and some use a hyperbolic learning curve to model the performance change which is close to our work.
studies in industry engineering indicate that the quality of workers improve when they complete repetitive work .
and learning curve is a mature theory for describing such improvements .
there are many types of learning curve .
such as hyperbolic learning curve exponential learning curve dejong learning curve and s curve.
in this paper we use the hyperbolic model and negative exponential model to fit the performance data since they are designed to measure and predict each worker s percentage of correct completed tasks which are replaced by a difficulty weighted score in our work.
hyperbolic model is proved more efficient stable and robust than many other models .
but in our work the negative exponential model outperforms it.
vii.
c onclusion in this paper we study how crowdsourced software developers skills get improved over time.
specifically we conducted an empirical study on a dataset collected from topcoder one of the most popular web sites for software development with crowdsourcing.
we first plot the final scores of the selected developers in chronological order and cannot obtain any meaningful observation.
then we design an algorithm to cancel off the effect of task difficulty on developers scores and re plot the difficulty weighted scores.
we find that the performance of developers does improve over time which is consistent with the intuition.
furthermore we aim at fitting developers performance with existing learning curves and we show that the negative exponential learning curve model is better than the hyperbolic learning curve.
with the negative exponential learning curve model we can predict the future performance of developers.
and we finally present a framework for recommending developers based on the prediction results with the negative exponential learning curve.
future work leads to three directions.
first as different tasks may require different skills we will further study howdevelopers skills improve on certain type of tasks.
second we aim at designing practical recommendation algorithms on the basis of the obtained learning curve models and conduct experimental evaluations on real world datasets.
third we plan to extend our study to other crowdsourced software development sites e.g.
kaggle and opensourced software development communities e.g.
github .
acknowledgment this work was supported partly by the national key research and development program of china under grant no.2016yfb1000804 the national basic research program of china under grant nos.
2014cb340304 2015cb358700 and the state key laboratory of software development environment under grant no.
sklsde 2017zx14.