belief evidence in empirical software engineering prem devanbu dept of computer science uc davis davis california usa ptdevanbu ucdavis.eduthomas zimmermann christian bird microsoft research redmond washington usa tzimmer cbird microsoft.com abstract empirical software engineering has produced a steady stream of evidence based results concerning the factors that affect important outcomes such as cost quality and interval.
however programmers often also have strongly held a priori opinions about these issues.
these opinions are important since developers are highlytrained professionals whose beliefs would doubtless affect their practice.
as in evidence based medicine disseminating empirical findings to developers is a key step in ensuring that the findings impact practice.
in this paper we describe a case study on the prior beliefs of developers at microsoft and the relationship of these beliefs to actual empirical data on the projects in which these developers work.
our findings are that a programmers do indeed have very strong beliefs on certain topics b their beliefs are primarily formed based on personal experience rather than on findings in empirical research and c beliefs can vary with each project but do not necessarily correspond with actual evidence in that project.
our findings suggest that more effort should be taken to disseminate empirical findings to developers and that more in depth study the interplay of belief and evidence in software practice is needed.
.
introduction we all learn from experience however what we learn is profoundly influenced by our prior beliefs.
if a new experience roundly contradicts strongly held prior beliefs we often tend to cling these beliefs unwilling to let go until our pet theories are repeatedly and resoundingly refuted.
on the other hand if a new experience is mostly consistent with but somewhat differentiated from our prior beliefs we are more willing to accept it as long as we don t have to revise our beliefs too much.
sticking to prior beliefs is not just always just mindless stubbornness in fact it is often sensible.
prior beliefs are either themselves learned from experience or are devanbu s primary appointment is listed however his contributions to this paper were made mostly during his visit to the other authors at microsoft research.
permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
copyrights for components of this work owned by others than the author s must be honored.
abstracting with credit is permitted.
to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
request permissions from permissions acm.org.
icse may austin tx usa c copyright held by the owner author s .
publication rights licensed to acm.
isbn .
.
.
.
in our genes in either case it would be imprudent and perhaps dangerous to abandon them too quickly.
we all are therefore naturally suspicious of new phenomena that contradict our beliefs.
science and engineering practice are all about learning from experience.
not surprisingly the effects of prior beliefs in science are complex even paradoxical however these effects are vitally important to the continued vibrancy and societal impact of experimental disciplines.
on the one hand when a new experiment reports surprising or unexpected results we demand that the experiment be very convincing.
how the experimental subjects were chosen we ask.
how was the data collected?
how was it analyzed?
what was the effect size?
questions and debates thicken and intensify for more surprising results getting the community to accept these results can be a challenge!
this resistance to new ideas is a serious issue in medicine where is vital that physicians embrace and adopt new practices that are supported by evidence and findings but they won t do this if they are not convinced!
chaloner et al have argued from a bayesian perspective that rigorous demanding experimental design constraints are needed or even morally obligated when the findings might contradict strongly held prior beliefs and practices and might actually save lives.
on the other hand paradoxically students of the sociology of science have noted that surprising results are disproportionately rewarded by the scientific community.
prestigious journals such as science andnature favor surprising results which are more likely to attract mainstream media attention.
the same is arguably true in computer science surprising results tend to be received more favorably.
however a bayesian analysis on this yields the rather pessimistic view that surprising results are more often wrong section .
.
this leads to a distressing situation surprising and therefore perhaps wrong results get lots of media attention and thus are actually more likely to be noticed by politicians influence policy etc.
this paper to our knowledge is the first to empirically assess developer belief and project evidence in empirical software engineering.
the cost pervasiveness and socio economic impact of software are well known and provide a durable and formidable imperative for evidence based improvements in the practice of software engineering just as in medicine.
and so just as in medicine we argue that taking the prior beliefs of practitioners into account can strengthen the field in several ways first we could have a stronger impact on practice more carefully and systematically disseminating our work second by deploying more robust and rigorous experimental techniques when findings may contradict programmers beliefs and thus encounter resistance and finally by being influenced by prior beliefs we can more systematically ameliorate the risk of making false discoveries ourselves specially in settings where large sample sizes are difficult to obtain .
ieee acm 38th ieee international conference on software engineering we make the following contributions .
we surveyed developers in several large microsoft projects as to the strength and disposition of their beliefs regarding several consequential claims about empirical software engineering.
the survey results suggest that developers do hold strong and diverse opinions and that some results inspire more passion and dissension than others.
we also find that their beliefs don t always correspond with known results in empirical software engineering.
.
our survey results indicate that developers beliefs are primarily based on personal experience and far less so on research results this suggests that empirical software engineering researchers need to make more efforts to disseminate our findings.
.
finally we investigated the relationship between microsoft developer beliefs concerning the quality effects of distributed development and the actual phenomena as observable from project data.
while developers in two different projects expressed differing opinions we found that the project data consistently indicated very little quality effect of distribution as did previous findings at microsoft .
our work suggests that a more and more systematic effort is required to disseminate empirical findings and b further study on the sources of developer belief and how it might be changed are needed.
the rest of the paper is structured as follows we begin in section with a review of the bayesian and frequentist approaches to evidence and belief and prior related work in medicine.
we relate this work to software engineering research in section .
we then present our approach to surveying developers beliefs and the results of these surveys in section section presents actual quantitative evidence from two projects relating specifically to the quality effects of distributed software development and the apparent inconsistency of this evidence with developers beliefs as found in the surveys.
in this study we did not specifically study how developers incorporate empirical evidence with prior beliefs and whether this conforms with the bayesian model we hope to do so in future research.
.
background the project of adapting belief to evidence is as old as science itself the goal is to design a repeatable procedure to gather data relevant to a hypothesis under study and then use this data to shed light on the hypothesis.
certainly of course experimenters come with with some sort of belief concerning the hypothesis before they gather any data.
once the data is gathered however it must be analyzed to make an inference regarding the hypothesis at this point there is a systematic process by which one s prior beliefs are integrated with the data this is the realm of statistical inference.
two competing statistical inference methods are available frequentist and bayesian.
.
two conflicting views frequentist analysis of experimental data arguably has its roots in the monumental work of r. a. fisher.
the decades old views of fisher and his collaborators neyman and pearson to this day dominate the statistical analysis of experimental data.
frequentists assert that the probability of correctness of a theory should be indirectly but exclusively inferred from the frequency with which the consequents of the theory are observed in experiments whenviewed in light of assumed sampling distributions of the measurements of concern.
this view is empirical and entirely grounded on observation and data leaving no room for prior belief.
it doesn t matter what you believe before or after the experiment the data is the data and it speaks the observer via the p value as long as the experiment is powerful and well designed.
this way of ignoring prior belief and taking a neutral belief stance is epistemically symmetric all beliefs are considered equi probable viz.
as sides of a fair dice with all possible related hypotheses being considered equally likely before the experiment begins and after the experiment is done and the data is gathered you can calculate the probability p value of the observation under each a priori equiprobable hypothesis and reject the null hypothesis if it renders the data observation sufficiently improbable.
bayesians assert that probability and statistics should reflect a state of subjective belief if i were to say that the probably of an eventxis .
i m essentially stating that i would bet cents on a possible pay off of should the event occur.
in the bayesian world view the prior belief regarding the hypothesis must be considered.
in an experimental setting we probe the world gather data and interpret the data in the context of our prior belief and then combine the prior belief with experimental data to yield an updated posterior belief.
bayesians argue that is a more realistic view of people actually react to evidence we are more doubtful of outlandish claims and ask for stronger evidence thus a report from nasa that an asteroid is sterile is likely to attract less skepticism than a claimed discovery of evidence of intelligent alien life thereon.
in other words given two experimental results with the same p value the one that is less dissonant with our preconceptions viz.
less surprising will convince us more.
the use of the frequentist p value has recently come under attack most prominently by ioannidis et al with the publication of their alarmingly titled paper why most published scientific results are wrong .
the paper notes that quite a number of very prominently reported scientific results turn out to be wrong and are subsequently retracted.
.
ascertainment publication and media biases critiques and alternative perspectives on frequentist p values are having a strong impact in fields such as medicine these critiques have not yet made a strong impact in empirical software engineering.
we present an overview below.
at the outset we note that many of the arguments below are applicable in settings where experimental power viz the unlikelihood of a false negative finding is limited by practical considerations such as cost effort or the need for human subjects.
thus these arguments are applicable more in research settings where controlled experiments are done with human subjects.
in the currently more popular big data settings which are based on historical data mined from software repositories the following arguments are less of a concern.
these are essentially observational studies where large sample sizes and available variances in variables of interest enable sophisticated multiple regression analysis.
in these cases sample sizes in the thousands or even more in this paper we have sample sizes in the hundreds of thousands afford formidable experimental power even for effects that are statistically small and also yield very low p values false positive rates .
this power allows experimental p values to take a dominant role and attenuate the effect of prior beliefs.
however the following are still applicable in experimental settings in software engineering where human subjects may be used and samples are small and so are presented for completeness.
.
.
the problem with p values wacholder and later ioannidis have argued that frequentist p values are only one component of a rational approach to scientific knowledge.
their critiques have two main thrusts.
first is a purely bayesian argument if one assumes that the prior probabilities of a hypothesis being true or false are not equal and that the hypothesis is actually false then simple experimental error false positive rate or alpha as well as false negative ratebeta leads to a higher rate of erroneous alternative hypothesis confirmation false discovery as given by the formula more concretely if you give a hypothesis a prior chance of being true and even your false negative rate is vanishingly small then with a p value of .
there is an almost risk of false discovery.
this can be viewed as a bayesian account of the popular adage extraordinary claims require extra ordinary evidence the more extra ordinary the claim the lower the prior belief i.e.
the lower the value of .
the second argument is that the inherent variation in p values due to sampling error has an unfortunate interaction with the career incentives of scientists.
because of the desire to publish there is often a tendency to meander towards a favorable conclusion and stop there thus eg.
one might often unconsciously tend to redesign the experiment a few times when it appears that conclusions are not what is expected and stop the redesign when the conclusion i.e.
the p value is in the expected range for a significant finding in the desired direction.
another complication as pointed out in ionnides ethical imperatives that govern medical research might require the studies be halted when the treatment appears effective and the treatment be provided to all including the control group.
unfortunately first principle sampling probabilities indicates that the initial effect in the sample being observed in such early stop studies could by chance tend to be higher than the effect in the general population and thus the effect sizes observed upon replication would tend to be smaller.
the third and final point here is that the media focus on surprising results often emphasizes findings that might be false discoveries.
findings are surprising precisely when the prior subjective belief in them is low viz.
is small .
a purely bayesian analysis would lead one conclude that the risk of false discovery is high in this setting combining this with the career incentives mentioned above leads to an unfortunate mix of incentives and false discovery risk.
worst of all media coverage leads to greater public awareness and political influence!
as mentioned earlier this issue is more of a concern for cases where experimental power and sample sizes are limited so researchers human studies subjects for example should carefully consider the admonishments of ioannidis and wacholder.
.
.
bayesian experimental design a more constructive positivist bayesian analysis of prior beliefs can be found in the work of chaloner et al.
chaloner and her colleagues argue that practitioner belief matters.
even if an experiment has a true and therapeutically important finding unless medical practitioners buy into it they won t change their practice and the work will have no pragmatic effect.
thus an experimental design concerning a health outcome of great public value that ignores practitioners prior belief could be criticized as being unethical even if it has adequate experimental power large effect size and low p values if it fails to gather evidence to overcome practitioners prior beliefs if these are known a priori .in bayesian experimental design one decides ahead of time a desired level of utility to be gained from an experiment typically this the information gain with respect to the subjective distribution of an outcome of interest say duration over which a patient remains symptom free after treatment .
this gain corresponds to the net reduction of uncertainty increased knowledge as a result of the experiment.
next the prior belief of practitioners is gathered and aggregated usually using a survey methodology .
based on the information gain goals and the prior beliefs an optimization process chooses experimental parameters sample sizes treatment dosage levels etc.
.
if the practitioners are skeptical their prior belief is generally clustered around the belief that the treatment is ineffective then a high information gain viz.
high experimental power large effect sizes and low p values are required to overcome their skepticism.
thus when designing human studies experiments in software engineering on topics that inspire a great deal of passion among developers such as the role of programming languages in software quality see below it would be quite sensible to design experiments with large sample sizes and high power so as to provide evidence that would move the needle on practitioner belief.
.
from evidence to belief for society to reap maximum benefit scientific evidence must translate into practitioner belief.
this imperative to transmit research findings to practitioners has long been recognized in medicine.
however busy practitioners have trouble keeping up with research.
a great deal of effort has been made to digest and disseminate findings to practitioners in a brief digestible form.
online curated indexed catalogued collections of scientific results such as the cochrane collaboration1or the american college of physicians2provide practitioners a convenient reliable up to date and centralized means to access research findings on relevant topics.
kitchenham et al have been strong advocates of similar efforts in software engineering practitioners should be made more aware of the latest empirical findings!
their pioneering paper was published in .
since then and rather unexpectedly empirical work in se has accelerated gaining momentum from the flood of data in open source repositories.
hundreds of papers on empirical findings have been published in flagship conferences like icse fse ase pldi popl oopsla etc as well as in more specialized conferences on repository mining empirical work software maintenance and re engineering and others.
a broad set of aspects of software product and process has come under study.
secondarily as advocated by evidence based practice pioneers systematic literature reviews are starting to be published.
what has been the impact of all this activity?
have empirical findings translated into practitioner belief?
the enduring influence of kitchenham et al and the tremendous rate of research results coming forth in empirical software engineering makes this an opportune moment to study in the trenches as it were what developers actually believe and how this relates to the actual evidence.
this is the central goal of this paper.
what do programmers believe and how do these beliefs relate to the actual empirical evidence?
.
a research program 110question score variance code quality defect occurrence depends on which programming language is used .
.
fixing defects is riskier more likely to cause future defects than adding new features .
.
geographically distributed teams produce code whose quality defect occurrence is just as good as teams that are not geographically distributed .
.
when it comes to producing code with fewer defects specific experience in the project matters more than overall general experience in programming .
.
well commented code has fewer defects .
.
code written in a language with static typing e.g.
c tends to have fewer bugs than code written in a language with dynamic typing e.g.
python .
.
stronger code ownership i.e fewer people owning a module or file leads to better software quality .
.
merge commits are buggier than other commits.
.
.
components with more unit tests have fewer customer found defects .
.
.
more experienced programmers produce code with fewer defects.
.
.
more defects are found in more complex code.
.
.
factors affecting code quality defect occurrence vary from project to project.
.
.
using asserts improves code quality reduces defect occurrence .
.
the use of static analysis tools improves end user quality fewer defects are found by users .
.
coding standards help improve software quality .
.
code reviews improve software quality reduces defect occurrence .
.
table the four most controversial viz inciting the most disparity in agreement top above the first double line and least controversial below the 2nd double line statements in our survey.
the score is numerical strongly disgree to strongly agree .
answer score of indicates neutrality.
the variance is a measure of disagreement between respondents.
the citations indicate relevant work due to space reasons we preferred to cite only the most closely related works.
the item on merge commits was added opportunistically to help future research.
like medicine software engineering is highly consequential to personal health and safety social well being and the economy.
as in medicine outcomes of interest e.g.
cost quality and interval arise from the interaction of technical factors programming languages architectures designs software tools with human and social factors.
thus outcomes arising from any given factor e.g.
sound static typing may be quite different in practice than in theory and must be evaluated empirically using controlled or natural experiments.
researchers in ese now produce a steady stream of evidence based findings regarding the factors affecting cost quality and interval in software development.
however like medicine se is knowledge intensive software developers are skilled trained practitioners who can be expected to practice their craft based on a set of beliefs gleaned thoughtfully not only from their training but also from their own work experience.
prima facie there are good reasons to believe that many of the arguments quoted above which arise in the biological sciences and medicine apply equally well to software.
articles in trade magazines and in the blogosphere suggest that developers do often hold passionate opinions on such matters as static vs. dynamic typing compiled vs. scripting languages etc.
these opinions may be based actual experience or may be held for ideological reasons or selfinterest even in the face of evidence to the contrary.
regardless of the origins of prior beliefs there is good reason to believe that the way these practitioners respond to new evidence will be influenced by their prior beliefs.
given that developers are highly trained quantitatively oriented professionals one can expect them to have strong opinions that are both informed by and inform their practice.
the above discussion suggests a wide range of questions what opinions do programmers hold?
how do they come by this evidence?
do beliefs vary?
do they change?
why?
do beliefs and evidence contradict?
or re inforce?
how are we to combine the two in formulating research results?
if developers beliefs are dissonant with evidence why is that?
how can we change developers beliefs?
there many such questions we believe that the answers to these questions will play a vital role in ensuring that findings from empirical software engineering actually have an impact in the practice of software engineering.
note that this argument applies equally well to beliefs and findings that relate to artifacts and artifact performance language features static analysis tools verification algorithms etc.
as well as beliefs and findings that relate to process aspects distributed development agile methods team organization etc.
.
the nature and trajectory of the interactions between belief and evidence in software engineering practice is a complex important and impactful phenomenon worthy of sustained study.
prior work in this area of beliefs and evidence has been primarily qualitative in nature.
rainer et al s focus group studies find that when programmers form views about software process improvement they favour local opinion over independent empirical evidence .
passos using a qualitiative interview based approach that organizational and project contexts influence belief formation.
dyb et al s practice prescriptions for evidence based software engineering require see step that the presentation and incorporation of evidence is always contextualized within prior belief and experience.
j rgensen et al in a study of effort estimation practice found that manager s prior beliefs influenced how they interpreted neutral randomly generated data they also found more disturbingly evidence suggesting that findings in research papers could also have been affected by prior biases.
our work here is complementary to the above research we show quantitatively that practitioner beliefs can be inconsistent with project evidence which suggests the need for careful reconciliation.
.
research question and methodology the central question in our initial foray into the project described above is recapitulated below what do programmers believe and how do these beliefs relate to the actual empirical evidence?
our initial focus was to address these questions in the specific context of one large industrial organization microsoft and gather data on both programmers beliefs and secondly to perform a detailed case study to judge the relationship of these beliefs to actual evidence in some specific projects.
survey design the core of the survey started with a series of empirically falsiable claims mostly drawn from software engineering research.
we chose a number of claims for inclusion in our survey based on the following set of criteria the consequences of the claim being true or false are actionable viz consequential for software practice.
we believed that our target population microsoft developers would have opinions on these claims.
we believed that this population would have had experience with the tools or processes in question and would have been able to form not just an opinion but an informed one.
we believed that regardless of expressed opinion we would be able to gather evidence strongly relevant to the claims.
opportunistically we also added a few claims that we found interesting but about which as of yet we weren t aware of wellestablished results.
we added these as possible avenues of future study to take advantage of this survey instance to gather some more useful data on developer beliefs.
the full list of claims is in table .
for each of these claims we asked developers to respond on a point likert scale strongly disagree disagree neutral agree strongly agree .
finally in all cases we scripted the survey to choose questions on which developers expressed more polarized opinions and asked them to explain the origins of their view more details below section .
under opinion formation .
in addition they were also asked to provide a rationale in form of reasons for your answer .
this rationale was used as a way for us to understand the answers.
in addition we collected demographic evidence similar to lo et al .
the following information was gathered demographics age gender years at microsoft years as a developer highest level of schooling.
employment primary division years at current job job title whether they are managing anyone.
geographic primary work location.
target audience our target audience were people primarily in a software engineering discipline at microsoft this included developers testers program managers and their immediate supervisors.
these people we felt would have the opportunity to form informed opinions about the claims that were offered to them.
we identified about professionals from various locations around the world in various projects and sent an email with a link to the survey and solicited a response.
no identifying information was required or gathered from respondents they could separately and without connection to their answers volunteer to offer themselves for a follow up interview.
distinct from the survey the could also enter their email addresses to be entered into a raffle to win a gift card.
.
survey results we now present our main findings from the survey.
overall impressions we received a total of responses a response rate around .
survey respondents varied in age gender location etc.
the mean age was .
.
the respondents skewed male male female other and didn t state .
they were largely college educated.
of those that stated had bachelor s degrees had master s and had a phd the rest didn t respond.
respondents are from all locations of microsoft of the ones who stated location the largest cohort was from the us the rest were from india china europe and other locations .
while these demographics suggest capture of a broad cross section of the overall population of developers it should be noted that all respondents to one degree or another are influenced by the business context of microsoft and to a large extent the dominantly male north american software engineering culture.
we scored the likert scale from for strongly disagree to for strongly agree .
in table we present the average score and standard deviation for all the claims in our survey.
the higher the average the more the agreement with the claim the higher the variance the more the disagreement within respondents as to the claim.
we have listed the claims in table in descreasing order of variance thus we interpret the ordering as going from most controversial claim to least controversial.
overall the claim that people disagreed with most .
concerned the riskiness of fixing defects as compared with new features and the claim that most people agreed with concerned the benefits of code reviews .
.
.
.
controversial claims we turn now to the claims that incited the most disparity in the answers we take these to be controversial claims.
the most controversial claim of all relates to the effect of programming language choice on code quality.
most of the developers who disagreed with this statement focused on the notion that programmer s skill matters more than the language e.g.
every trade has its master.
it depends on who write the code .
some focused on application logic not programming language as the main determinant of quality most defects stem from the application logic rather than particular platform tools .
developers who agreed with this claim focused on language features such as static typing or memory management e.g.
because statically typed languages make mistakes more difficult managed code is designed to be less prone to defects .
interestingly as it turns out this is a topic on which there is limited literature with results just recently starting to emerge this certainly has long been a controversial topic and one mightn t expect developer opinion on this much debated topic to be moved towards consensus by just one publication.
moving through the most controversial list the next claim relates to defect repair commits being riskier than new feature additions.
developers who disagree felt that bug fixes involve smallscope changes which are less risky e.g.
defects are generally small and localized features are broader other felt that all types 112of changes are risky.
people in agreement felt that defect repair entails greater risk of regression failure and code decay.
previous work provides pretty strong evidence that defect repair changes are quite risky but this turns out to the claim that attracts the most disagreement from our survey respondents lowest average agreement score .
.
the next opinion relates to the effects of geographical distribution on software quality.
respondents who disagreed with the proposition that geographically distributed development doesn t affect software quality focused heavily on communication issues with distant team members e.g.
lack of easy communication is the reason.
time zone differences are a big hindrance for easy communication.
and the absence of face to face communication the inability to meet in the hallways talk over a whiteboard etc.
people who agreed thought that electronic collaboration tools email shared repositories distributed review tools made distributed development workable e.g.
we can communicated by code review and online meeting .
interestingly two studies both done at microsoft on different projects examined this very issue one found that distributed development had no effect on software quality and the other found a very small barely discernible effect.
we examine this specific issue in much greater depth below section .
the next claim states specific experience matters.
developers who disagreed stated several reasons first they believed that skill once developed was portable excellent engineering and coding practices are a skill that transfers between projects.
.
developers who agreed tended to focus on the importance of domain experience the domain experience helps alleviate common pattern of issues.
general experience in programming allows us to have strong grasp on design patterns.
however how that pattern translates to the problem at hand is a function of the specific project experience there is a strong evidence that specific experience matters more than general experience and also that minor contributors with little specific experience are strongly implicated in errors .
overall in the survey results considering the most controversial questions rather unexpectedly we find some supported by strong consistent empirical evidence3.
these are also questions which most would consider highly consequential and actionable indeed these are precisely the sorts of questions where one might most wish to find consistency between research findings and practitioner belief and also between practitioners.
.
.
un controversial claims we now turn to questions which incited the least disparity in responder agreement.
we note that the least controversial claim the one that most people agreed with .
variance of .
was that code reviews improve software quality.
it is interesting that this is perhaps one of the most well supported findings in empirical software engineering with numerous confirming their benefits going back to fagan s work at ibm in the 1970s.
it is heartening to note that these established findings from our field have taken hold in developers belief systems at least in this case.
the situation is more complex on the other beliefs.
thus programmers are strongly congruent on the belief .
variance of .
that coding standards help improve software quality.
the rationale comments from the programmers who answered this question clearly indicate that developers who agreed with this claim believed that coding standards reduced defect occurrence.
how3while the geographic distribution question has had some contradictory results the results within microsoft data are largely consistently supporting the claim that geographic distribution doesn t affect software quality.ever actual empirical evidence on this is quite limited we could find only one published result which examined a coding standard in the context of one industrial case study which found scant evidence that the coding standard was beneficial.
comments from programmers however clearly indicate that they believe coding standards make code easier to maintain e.g.
coding standards can help to make the code written by different developers easier to read and maintain and if everyone in the team follows coding standards it will be very easy to review others code and requires less time.
.
this relates coding standards to readability of code recent results on natural coding conventions and coding reviews in pull requests that predictable regular coding styles are preferred.
this finding suggests that more research in this area would be well warranted.
our survey respondents also widely believed that static analysis tools improve software quality.
this is another area where the results in the literature are not as consistent nor as strong as developer belief zheng et al report that static analysis tools are only about a third as effective as testing and no cheaper than inspections however they are helpful specially in identifying certain kinds of coding errors relating to error checking or assignments while rahmanet al report that while static bug finders are helpful they are not much better that statistical defect prediction which only depends on process measures and wagner et al report that static bug finders can find different errors but suffer from very high false positive rates.
the developers overall strong belief in static analysis tools however suggests that more study of their benefits would be valuable.
developers also believe that asserts are beneficial.
in their rationale they offer two distinct benefits the documentary function e.g.
well placed asserts make people aware of the assumptions they make when coding.
where asserts held understand code and the more common diagnostic function e.g.
using asserts usually helps to detect errors at the earliest point.
where asserts can help quickly detect violations of coding assumptions or interface pre conditions.
this is also an area where there is not a lot research into understanding what the precise role by the two functions documentary and diagnostic of asserts and the relative benefits of each.
finally we note another claim more defects are found in more complex code which has a high level of average agreement .
with some controversy .
.
developers repeatedly observe in the rationale that complex code is more difficult to maintain harder to understand debug and test complex code is harder to reason it hidden hides the purpose of the code and confuse reviewers or maintainers .
these beliefs suggest that metrics that can identify complex code could would be useful in predicting defects.
thus far attempts to define complexity metrics have been stymied by the fact that they are all strongly correlated with size so complexity metrics simply end up predicting that bigger files contain more bugs.
indeed recent work casts doubt on usefulness of any kind of product metric property of source code to usefully predict defects .
however programmers strong belief that complex code is buggy code suggests that further study perhaps to develop metrics that better isolate complexity somehow de correlated from size would be a helpful way to predict defective code.
.
.
opinion formation our survey did solicit as described earlier developers statements on how they formed their opinion.
in this section we present those results.
113figure factors stated as most influential on forming opinions of survey respondents.
for the two beliefs on which each developer expressed the strongest opinions either agreeing or disagreeing we asked them to rank possible factors in his her opinion formation4.
thus if the developer said they strongly disagreed with the claim that programming language choice affects defect occurrence they would be presented with this answer and asked what factors played a role in your previous answer?
please choose the relevant factors from the list below and rank them they were given a choice of personal experience what i hear from my peers what i hear from my mentors managers articles in industry magazines research papers .
and other .
we then gathered the ranks given for each of the above factor.
thus we had for each of the answers agreement disagreement with the claims and each of possible factors a collection of ranks.
if a particular factor is ranked more frequently more highly we would get a higher range of values for that factor.
thus for each factor we gathered a collection of ranks assigned to that factor.
for clarity so that higher ranks appear higher in the plot we inverted the rank so on the plot higher values correspond to higher ranks.
the results are in figure .
the highest ranked factor influencing respondents opinions on the given claims is personal experience which was chosen for ranking times.
a look at the box plot in figure shows that it was almost always ranked at the top and a handful times at other positions.
next was what i hear from my peers which was chosen for ranking times with a median second rank.
next was what i hear from my mentors managers chosen times for ranking and with a median third rank.
the lowest ranked was other chosen times.
just above that in fifth position was research papers chosen times for ranking.
we take a couple of conclusions from this.
first the factors affecting opinion are consistent with earlier work in social science the strength of influence on opinion formation decays with strength of social connection things we hear 4in case they expressed strong or equally strong opinions on more than claims we chose at random.from people closer to us matter more than others.
brown reingen for example found that stronger social ties are more influential in opinion formation than weaker ones.
this provides a reasonable framework to understand why developers give strongest weight to personal experience and then to peers and then to managers.
furthermore developers appear to be influenced by trade journals rather than research papers this may also be because they view trade journals as closer to their situation than research papers this requires further study.
secondly while this type of opinion formation might be acceptable in ordinary society this is hardly an ideal way for professionals to form opinions.
personal experience is highly isolated and doesn t provide a broad sample of experience.
a particular developer s experience may be based on recollections of his or her own work experience with his her code team project etc and have little to do with overall large scale trends.
furthermore what we remember can also be highly influenced by salience rather than frequency.
we tend to remember emotionally laden experiences and don t necessarily recall more mundane occurrences quite so well.
thus one developer might vividly recall having a very difficult time repairing another person s low quality bug fixes at one time and then conclude all defect repairs are risky she might not recall or even notice that most bug fixes were entirely adequate and never cause any trouble.
she might then strongly argue this view repeatedly that repairing bugs is risky however if a statistical analysis were done at large scale in her project of the entire population of bug fixes there might be a very different conclusion to be drawn.
in medicine the need to have therapeutic practice based on evidence is well recognized and there is a concerted well funded systematic effort to disseminate scientific evidence from research findings to physicians.
indeed most modern physicians if asked would profess to be strongly evidence and research based in their practice.
consider how you would react if your physician said that his or her medical decisions are most strongly based on personal experience and much less so on research ?
the current state of evidence based practice in medicine offers an inspiring model for more a more organized and effective dissemination of research results in software engineering.
.
evidence of the top most controversial statements we chose one of them geographically distributed teams produce code whose quality viz.
defect occurrence is just as good as teams that are not geographically distributed to examine in more detail we decided to compare the beliefs of programmers with evidence from actual project data drawn from two large projects which we denote as pr a andpr b .
they are both quite large pr a is an operating system and consists of about files with over 150m sloc and pr b is a web service and consists of about files with about million sloc.
our choice to delve into this particular question with these two particular projects was based on a curious phenomenon statistical analysis revealed pr a members tended to be ones who largely disagreed with the above statement while pr b members tended to largely agree with the statement p using pearson s chi squared test .
this difference in belief particularly striking given that projects practice widely distrib uted development both pr a andpr b have around developers located in over different buildings in dozens of cities in about a dozen different countries around the world.
in both projects a non trivial number of files received commit activity from multiple buildings cities regions and countries see table 114project commits commits commits commits building city region nation pr a pr b table proportion of files in projects with majority commits from one building one city one region and one nation.
clearly while pr a lives in more buildings pr b has substantively more activity outside of a single city region and country .
thus developers in both countries could be expected to have personal experience with distributed development and thus would have had the opportunity to form their beliefs based on their experiences.
the statistically significant differences that emerge in the survey therefore could be presumed to be based on intrinsic observable differences in the two projects.
perhaps pr a had encountered more quality difficulties in distributed development and pr b had none.
findings on this topic while by no means uniform tends to lean on the side of agreement with the statement above particularly with respect to teams at microsoft .
to examine these issues in more detail we gathered data on development histories who changed what file how much and when defect repair commits that marked as defective in the logs using techniques popularized by mockus et al and sliwerski et al as well as developer locations at the time changes were made using internal microsoft databases .
using this gathered data we used known techniques for studying the effects of geographical distribution based on measures used in earlier work .
our data was gathered on a per file basis pr a andpr b both had around files and the data comprised millions of changes performed starting in .
we gathered several metrics on these files described below.
since the goal of this study to gather quantitative project specific evidence on software quality the main phenomenon we were interested reflected the number of bug fix commits.
this then is our primary response variable nfix number of defect repairs associated to the file.
this data was gathered using project specific conventions on identifying defect repair changes.
one project used the convention that all bug fix logs began with bug .
the other project had a range of conventions for bug fix logs.
these conventions were known to the authors from prior investigations and informants in the respective development communities.
next since our goal is to attempt to isolate and measure the effect of geographic distribution it is important to control for known confounds that might affect the nfix outcome.
we use different control measures all chosen from prior work on the determinants of software quality.
meansize average size of the file in lines of code.
this is a control variable in general size is expected to be strongly correlated with number of fixes.
chgcnt number of commits made to the file.
prior work has established that change churn is strongly correlated with defects the more files change the more likely it is that defects are introduced .todc total number of distinct developers commiting to the file.
prior research as indicated that the number of developers involved in a file influences quality and can be a confounding factor in studies of the effect of distributed development on quality .
otop ownership percentage of commits made by the most frequent committer to this file.
strong dominant ownership i.e.
the proportion of commits made by the majority contributor to a file can influence software quality so we include this as a control.
after controlling for the known confounds we include the key experimental variables relating to degree of distribution.
following we consider several distinct levels of distributed development.
binary indicators of localization level of files we used binary variables indicating whether more than of the commits were made within one building in1b in one city in1c region in1r and nation in1n respectively.
this modeling approach and the threshold levels used were based on prior work by bird et al and kocaguneli et al .
as kocaguneli et al justify these variables indicate the smallest geographical entity within which developers account for of the edits to a file .
the variables capture different degrees to which a file can be distributed for example distances within a building are walkable within a city some transportation or a phone call may be involved outside of the same city personal contact is even harder and and once outside a country time zones complicate personal live communications.
as with kocaguneli et al we performed sensitivity analysis and got similar results for thresholds ranging from to table ?
?shows the level of distributed development activity in both pr a andpr b using the binary indicator variables described above.
thus for pr b of files have or more of their commits from a single city and of the files have or more of their commits from a single building.
as can be seen there are a non trivial number of files in both projects that have significant distributed development activity.
thus these projects are both reasonable settings to study the quality effects of distributed devlopment as well as being settings were developers can be expected to have had reasonable experience with the practice and consequences of distributed development.
we began our data analysis by modeling the nfix variable as a response against just the controls meansize chgcnt todc and otop .
all our models are linear regression models model diagnostics were performed using recommended criteria in all cases the residual distributions from the linear models were inspected using the qqnorm plots to ensure acceptable normality variance inflation was found to be in recommended ranges and outliers were removed to avoid high leverage points.
the data was reasonably balanced between zeros and non zeros and there was no indication of zero inflation.
in addition since the data were slighly overdispersed we compared the linear regression models with count quasi poisson models and got essentially the same results for simplicity we just present the results of linear regression.
the model for pr a model and pr b model are shown below.
the models show the direction and significance of the effect tvalue magnitude shows significance the sign shows the direction of the effect the p values are all highly significant and calculable from the t distribution .
we infer from the models above is that a all the controls are significant and b the effects are in the directions that we might 115model effect on number of repairs at each level of non distribution.
we show effect size measured using cohen s f2.
all effects much lower than the small effect threshold which is .
all effects however are statistically significant p .
except for the same city effect in pr b thanks to large sample sizes.
linear regression diagnostics normality of residuals vif heteroskedasticity etc are well controlled.
project same building same city same region same country model cohen s f2and t value cohen s f2and t value cohen s f2and t value cohen s f2and t value f significance pr a f2 .
f2 .
.
f2 .
.
f2 .
.
all p .
pr b f2 .
f2 .
p .
f2 .
f2 .
all p .
unless noted model pr a data controls only.
f statistic .5e p r2 .
linear regression diagnostics normality of residuals vif heteroskedasticity etc are well controlled and or within accepted limits variable t value significance intercept .
p meansize .
p chgcnt .
p todc .
p otop .
p model pr b data controls only.
f statistic .4e p r2 .
linear regression diagnostics normality of residuals vif heteroskedasticity etc are well controlled and or within acceptable limites variable t value significance intercept .
p meansize .
p chgcnt .
p todc .
p otop .
p expect viz.defects increase significantly with size of files churn total number of developers committing to a file defects decrease with ownership level.
to gauge the effect of the experimental variables we add the indicator variables for each distribution level as described above in turn to the above models.
in other words we built successive models for each of the two projects adding in turn the variables in1b in1c etc.
in total we have different models each consisting of the four control variables and one indicator variable.
each model would thus give us an indication of the effect on files which were mostly changed within the one geographic location indicated by the operative indicator variable.
the results are shown in model .
for each indicator variable we calculated the percentage difference in annual defect repair activity corresponding to that level of localization when controlling for file size change count number of developers and file ownership.
all levels of localization had a statistically significant impact on software quality.
all indicator variables showed statistically significant effects in the model.
given the large sample sizes several hundred thousand files we can expect to able to measure even small effects.
however the inclusion of the localization variables didn t change the explanatory power of the models in any instance in all cases the proportionate change in r2value was less than .
.
we used the cohen s f2measure to gauge the effect size of these indicator variables.
cohen s f2values are computed asr2 ab r2 a r2 abwhere the subscript indicates the regressors included in the model r2 abmeasures the multiple r2while including regressors bas well as regressors a whiler2 ais the value with just regressors a. thisf2is a measure of the additional variance explained by the addition of regressor binto the model.
in our cases ais just the controls used in models and above bis the binary indicator variable for each level of localization.
a threshold value of forf2is suggested5as a minimum value to determine that an effect size is small in all cases our computedf2values were a lot smaller than even that leading us to the conclusion the effect of localization on software quality at all levels in both pr a andpr b when controlling for confounding factors is minimal.
these findings are consistent with earlier findings within the microsoft setting by bird et al and kocaguneli et al.
another noteworthy aspect of the effect of distribution is thatit is not always in the same direction!.
thus for both pr a andpr b it appears clear that it is very slightly better to be in the same building negative t values .
and .
respectively and for pr b it is possibly very slightly better barely signfiicant t .
p .
negligible f2 to be in the same city.
for all other cases it appears consistently and statistically significantly very slightly better to be distributed!
although the f2for the effect in the positive direction in these cases is small the t values are all quite strongly positive indicating that files mostly committed in the same geographic area city region nation are actually very slightly more defect prone!!!
thus the respondents from pr b had formed beliefs that were consistent with the actual evidence from that project whereas the respondents from pr a had formed beliefs that were inconsistent with the actual data from that project.
this case study in conjunction with the responses to our survey suggests that developers form opinions subjectively and anecdotally based on personal experience.
one possible explanation for the difference in beliefs might be confirmation bias6.pr a see table is less distributed geographically than pr b .pr a started earlier with its beginnings in puget sound the long time headquarters of microsoft.
as a project that was initially developed in just one location developers from pr a may be more familiar comfortable and trusting with non distributed development whereas pr b members may have had richer experience with distributed development and might have a more realistic view.
indeed in the absence of controls as prior studies have noted it would appear that distributed files are indeed more defective bird see and the pwr package inr.
6confirmation bias is a kind of bias that connotes the seeking or interpreting of evidence in ways that are partial to existing beliefs expectations or a hypothesis in hand 116et al report that if one didn t control for the number of developers it appeared that binaries which weren t primarily developed in one building had more defects p than ones that were!
however once developer count was introduced as a control this effect vanished.
people do sometimes ignore confounding variables and jump to false conclusions in observational studies .
while software developers are in general quantitatively sophisticated and do engage in reflective practice it s unlikely that they would have taken care to engage in the kind of careful multipleregression analysis that is required to tease out the insignificance or in our projects the very small effect of distribution.
absent such careful analysis developers soldier on with their biases and misconceptions without the benefit of actual evidence.
again we see that by comparison with medicine which has been strongly evidence based for decades the impact of evidence on software engineering practice has quite some ground to cover.
threats to validity our formulation of distribution levels is based on prior analysis of the same data however our quantization of distribution might fail to capture more subtle effects such as those relating to personal relationships.
in addition we interpret software quality directly as relating to defects other aspects of quality such as maintainability readability etc are not modeled.
.
related work there have been several prior reports of surveys of developers in several settings.
surveys have been done to explore developer attitudes such as work habits or motivation .
others have explored what developers do .
most related to our work are studies of the epistemic attitudes of devleopers viz what they know believe or would like to know about.
begel zimmermann used a survey methodology to find questions that are of most interest to developers.
more recently lo et al surveyed developers as to their views on the relevance of various research results from software engineering.
that survey asked for developer views on the relevance of the research not on the correctness thereof.
to our knowledge we are the first to survey developers explicitly as to their agreement with claims from empirical software engineering and then attempt to relate some of the survey results with statistical analysis of data drawn directly from the project in which the respondents work.
there has been a considerable body of work on the factors that drive methodology adoption.
hardgrave et al find that developer s opinions play a strong role in choice of software development methodology than other factors including social and organizational pressure.
sultan chan study the influence of individual attributes on the adoption oo technologies.
others have studied how beliefs affect the adoption of c by cobol programmers .
roberts et al study the attributes of software development methods that influence adoption .
there has been considerable interest in the field of medicine on the interaction of belief and evidence which we discussed in the background section at the beginning of this paper.
the results of our study are very much in support of kitchenham et al s project to promote systematic prompt and wide dissemination of empirical study results.
.
conclusions our goal in this paper was to explore the relationship between quantitative evidence and practitioner belief in software engineering settings.
we conducted a survey of developer beliefs with respect to several claims of practical importance.
we found that some claims attracted more agreement and dissension than others.
sur prisingly the level of agreement didn t always correspond very well with the strength of evidence in regards to the claim.
indeed we found that programmers give personal experience as the strongest influence in forming their opinions.
interestingly research papers were ranked the second lowest just above other .
we also selected a specific question regarding the quality effects of geographic distribution where respondents from one team tended to believe that geographic distribution was bad for software quality and from a different team tended to believe it had no bad effect.
based on a quantitative analysis of the project repositories of both we found that geographic distribution had a barely measurable effect on quality it was statistically significant but only because of very large sample sizes in the hundreds of thousands .
furthermore the effect was not always in the expected direction sometimes the effect was good and sometimes bad.
thus we found that one team s beliefs were consistent with the evidence and another team s wasn t. this finding illustrates the risks that programmers might face by relying too much on their personal experience subjective personal recollection is notoriously error prone.
we draw two reccommendations from our findings dissemination our findings reinforce those of kitchenham et al in regards to evidence based software engineering.
given the volume of findings and publications in empirical software engineering greater efforts should be made to set up systematic ways to collect organize disseminate our research to practitioners so that they as do medical doctors come to rely on verified evidence rather than personal observation which can be biased error prone and spotty.
initiatives like the cochrane collaboration offer a practical model.
research directions however prior experience in medicine notably the work of ioannidis chaloner and colleagues suggests that practitioner belief should be given due attention.
specially in areas where research results are few and preliminary or where large sample sizes are hard won we would be well advised to take practitioner belief into account both in developing hypotheses for study as well as designing experimental methods.
in our study for example developers strongly endorse coding standards and the use static analysis tools there is limited empirical understanding of the effects of these practices and further study could well be warranted.
.