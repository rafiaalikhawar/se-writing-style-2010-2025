an empirical study on dependence clusters for effort aware fault proneness prediction yibiao y ang1 mark harman2 jens krinke2 syed islam3 david binkley4 yuming zhou1 and baowen xu1 1department of computer science and technology nanjing university china 2department of computer science university college london uk 3school of architecture computing and engineering university of east london uk 4department of computer science loyola university maryland usa abstract a dependence cluster is a set of mutually inter dependent program elements.
prior studies have found that large dependence clusters are prevalent in software systems.
it has been suggested that dependence clusters have potentially harmful e ects on software quality.
however little empirical evidence has been provided to support this claim.
the study presented in this paper investigates the relationship between dependence clusters and software quality at the function level with a focus on e ort aware fault proneness prediction.
the investigation rst analyzes whether or not larger dependence clusters tend to be more fault prone.
second it investigates whether the proportion of faulty functions inside dependence clusters is signi cantly di erent from the proportion of faulty functions outside dependence clusters.
third it examines whether or not functions inside dependence clusters playing a more important role than others are more fault prone.
finally based on two groups of functions i.e.
functions inside and outside dependence clusters the investigation considers a segmented fault proneness prediction model.
our experimental results based on ve well known open source systems show that larger dependence clusters tend to be more fault prone the proportion of faulty functions inside dependence clusters is signi cantly larger than the proportion of faulty functions outside dependence clusters functions inside dependence clusters that play more important roles are more fault prone our segmented prediction model can signi cantly improve the e ectiveness of e ort aware fault proneness prediction in both ranking and classi cation scenarios.
these ndings help us better understand how dependence clusters in uence software quality.
corresponding author zhouyuming nju.edu.cn.
permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
copyrights for components of this work owned by others than acm must be honored.
abstracting with credit is permitted.
to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
request permissions from permissions acm.org.
ase september singapore singapore c acm.
isbn .
.
.
.
concepts software and its engineering !abstraction modeling and modularity software development process management keywords dependence clusters fault proneness fault prediction network analysis .
introduction a dependence cluster is a set of program elements that all directly or transitively depend upon one another .
prior empirical studies found that large dependence clusters are highly prevalent in software systems and further complicate many software activities such as software maintenance testing and comprehension .
in the presence of a large dependence cluster an issue or a code change in one element likely has signi cant ripple e ects involving the other elements of the cluster .
hence there is a reason to believe that dependence clusters have potentially harmful e ects on software quality.
this suggests that the elements inside dependence clusters have relatively lower quality when compared to elements outside any dependence cluster.
given this observation dependence clusters should be useful in fault prediction.
however few empirical studies have investigated the e ect of dependence clusters on fault proneness prediction.
this paper presents an empirical study of the relationships between dependence clusters and fault proneness.
the concept of a dependence cluster was originally introduced by binkley and harman .
they treat program statements as basic units however they note that dependence clusters can be also de ned at coarser granularities such as at the function level .
for a given program the identi cation of function level dependence clusters consists of two steps.
the rst step generates a function level system dependence graph for all functions of the program.
in general these graphs involve two types of dependencies between functions call dependency i.e.
one function calls another function and data dependency e.g.
a global variable de ned in one function is used in another function .
in the system dependence graphs used in our study nodes denote functions and directed edges denote the dependencies between these functions.
in the second step a clustering algorithm is used permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
copyrights for components of this work owned by others than acm must be honored.
abstracting with credit is permitted.
to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
request permissions from permissions acm.org.
ase september singapore singapore c acm.
... .
to calculate all the maximal strongly connected components found in the system dependence graph sdg .
in functionlevel dependence clusters functions are regarded as the basic units and each cluster consists of at least two functions.
according to binkley et al.
the function level dependence clusters can o er an e ective proxy for the more expensive statement level dependence clusters.
based on this observation we investigate dependence clusters at the function level.
our main contributions are the following we investigate whether the qualities of dependence clusters are in uenced by their size.
our results show that larger dependence clusters tend to be more fault prone.
we examine whether functions inside dependence clusters are more fault prone than functions outside dependence clusters.
the results show that the proportion of faulty functions inside dependence clusters is signi cantly greater than that of functions outside all dependence clusters.
we examine whether functions playing more important roles inside dependence clusters are more fault prone.
our empirical results show that importance metrics are positively correlated with fault proneness.
finally we propose a segmented prediction model for fault proneness prediction.
more speci cally we build two di erent fault proneness prediction models respectively for functions inside and functions outside dependence clusters.
the empirical results show that our segmented prediction model can signi cantly improve the prediction performance in e ort aware evaluations.
the rest of this paper is organized as follows.
in section we summarize related work.
we present our research questions in section .
in section we describe the experimental setup including the subject systems and the data collection method used.
in section we describe the research method and report the detailed experimental results with respect to each of the research questions.
section discusses our ndings.
in section we examine threats to validity.
finally section concludes the paper and outlines directions for future work.
.
related work this section summarizes related work on dependence clusters and dependence analysis in fault proneness prediction.
.
dependence clusters binkley and harman originally introduced the concept of dependence clusters based on program slicing at the statement level.
they proposed a same slice size approach to identifying dependence clusters using the sdg.
later harman et al.
extended this initial study to include a larger set of programs.
their empirical results showed that the same slice size approach was extremely accurate.
in addition they found that large dependence clusters were surprisingly commonplace and consumed from more than of the program to in some cases of the whole program.
islam et al.
introduced the concept of coherent dependence clusters.
in a coherent dependence cluster all elements depend upon the same set of elements and also a ect a common set of elements.
they used coherent dependence clusters to identify logical functionality within programs.
binkley and harman introduced a method to measure the e ect of an sdg vertex or an edge on the formationof dependence clusters and then used this method to identify linchpins which e ectively hold a dependence cluster together.
their results showed that only a few vertices and edges act as linchpins.
after that binkley et al.
introduced a simple transformation based analysis algorithm to identify the impact of global variables on the presence of dependence clusters.
their results showed that over half of the studied programs include a global variable that was responsible for the formation of a dependence cluster.
besz edes et al.
conducted an empirical study into the properties of sea based dependence clusters.
such cluster are de ned at the function level and are based on the static execute after sea relation.
their empirical results showed that sea based dependence clusters occur frequently in programs regardless of their domain and size.
however the sea based relation only considers call structure information.
in other words data dependencies are not considered in their study.
in contrast we take the data dependency between functions into account in our study.
binkley et al.
compared the following two types of dependence clusters slice based dependence clusters at the statement level and sea based dependence clusters at the function level.
they found that the less expensive sea based dependence clusters could be used as an e ective proxy for the more expensive slice based dependence clusters.
unlike the above studies we investigate dependence clusters from the perspective of software quality.
more speci cally we investigate whether dependence clusters have practical value in e ort aware fault proneness prediction.
.
dependence analysis in fault proneness prediction zimmermann and nagappan calculated network metrics based on a dependence graph and used them to predict faults.
more speci cally they rst generate a sdg at the function level.
two kinds of dependencies between functions are then taken into account call dependencies and data dependencies.
they then lift this graph up to binary level since the defects were at the binary level.
they considered the presence of dependencies without considering the multiplicity of dependencies.
after that they compute network measures on the dependence graph and then evaluated their fault proneness prediction performance on windows server .
their results show that the recall of the model built from network measures was higher than the model built from complexity measures.
ma et al.
conducted an empirical study to examine the e ectiveness of network measures in the context of e ortaware fault proneness prediction taking into account the e ort required to inspect predicted faulty module.
they investigated dependence graphs at the le level and did not consider the multiplicity of dependencies between les.
they found that most network measures were of practical value in the context of e ort aware evaluations.
unlike these two studies our sdgs are ner grained i.e.
function level vs binary le level .
in addition we take into account the multiplicity of dependencies between functions.
cataldo et al.
compared the relative impact of the syntactic logical and work dependencies on fault proneness prediction.
syntactic dependencies are code dependencies e.g.
control and data dependencies .
logical dependencies focus on deducing dependencies between source code les that are changed together .
finally work dependencies 297account the human and organization of information .
their work showed that the logical dependencies explained most of the variance in fault proneness while work ow dependencies had more impact than code dependencies.
in our study we only investigate syntactic dependencies but do so at a ner granularity.
oyetoyan et al.
studied the impact of cyclic dependencies on fault proneness prediction.
they found that most defects and defective components were concentrated in cyclic dependent components .
the cyclic dependent components are those in call cycles in call dependence graph at the class level.
these structures can also be viewed as dependence clusters.
our study is di erent from their study mainly with respect to the following aspects our dependence clustering is at a ner granularity i.e.
function level while their study is at the le class level we take into account more types of dependencies including both call and data dependencies we study the fault proneness prediction model in e ortaware evaluations with respect to ranking and classi cation scenarios we propose a segmented fault proneness prediction model and compare our models with the traditional fault proneness prediction models.
.
research questions in this section we discuss our research questions and use the example sdg shown in figure to illustrate the questions.
in figure the nodes e.g.
f1andf2 are functions and the directed edges are dependencies between functions depicting data dependencies labeled d and function call dependencies labeled c respectively.
in this dependence graph there are functions and dependence clusters i.e.
dc1 dc2 anddc3 .
in figure dc1 dc2 anddc3are separate clusters since they are maximal strongly connected subgraphs.
the functions are divided into two groups functions inside dependence clusters and functions outside dependence clusters.
functions inside dependence clusters and functions outside dependence clusters form the subgraphs subg inand subgout respectively.
first because a code change to one element of a dependence cluster likely ripples to the others elements of the cluster our rst research question rq1 investigates the relationship between the size of dependence clusters and fault proneness rq1.
are larger dependence clusters more fault prone?
second functions in figure are classi ed into two groups functions inside and outside dependence clusters.
our second research question rq2 focuses on the quality of functions in these two groups.
rq2.
are functions inside dependence clusters more faultprone than functions outside dependence clusters?
third functions inside dependence clusters form a subdependence graph e.g.
subg inof figure .
di erent functions play di erent roles in this sub graph.
thus we set up rq3 for functions inside dependence clusters as follows rq3.
are functions playing more important roles inside dependence clusters more fault prone?
finally we aim to examine the usefulness of dependence clusters for fault proneness prediction.
therefore our last research question rq4 is set up as follows rq4.
are dependence clusters useful in fault proneness prediction?
these research questions are important to both software researchers and practitioners as they help us better underfigure an sdg with dependence clusters stand the e ects of dependence clusters on software quality.
little is currently known on this subject.
our study attempts to ll this gap.
.
experimental setup this section rst introduces the systems studied before describing the procedure used to collect the experimental data.
.
studied projects table summarizes the subjects used in the study.
the rst column is the system name.
we use ve well known open source projects as subject systems bash bash gcccore gcc gimp gimp glibc glib and gstreamer gstr .
bash is a command language interpreter gcc core is the gnu compiler collection gimp is the gnu image manipulation program glibc is the gnu project s implementation of the c standard library and gstreamer is a multimedia framework.
we chose these ve projects as subjects for two reasons.
first they are well known open source projects with a publicly available bug x history.
in particular the bug xing releases do not add any new features to the corresponding systems thus allowing us to collect accurate fault data at the function level.
for instance gcc distribution website states note that starting with version .
.
we provide bug releases for older release branches for those users who require a very high degree of stability .
second they are non trivial software systems belonging to several di erent domains.
in table the second to the seventh columns are respectively the version number the release date the total source lines of code in the subject release the number of functions the number of faulty functions and the percentage of faulty functions.
the eighth and the ninth columns are the version number and the release date of the previous version used for computing the process metrics in section .
.
the last two columns are the version number and the release 298table the subject systems systemsubject release previous release fixing release version release total functions faulty faulty version release version release date sloc functions functions date date bash .
.
.
.
.
gcc core .
.
.
.
.
.
.
gimp .
.
.
.
.
.
.
glibc .
.
.
.
.
.
.
gstreamer .
.
.
.
.
.
.
date of the xing release.
the subject projects are moderate to large scale software systems from to ksloc .
they have only a small number of faulty functions from approximately to of all functions .
furthermore on average the xing release comes out approximately years after the subject version is released.
we believe years is su ciently long for the majority of faulty functions to be identi ed and xed.
.
data collection procedure we collected data from the above mentioned ve projects.
for each subject system we obtained the fault data and identi ed dependence clusters for further analysis using the following steps.
at the rst step we determined the faulty or not faulty label for each function.
as mentioned before any of the bug xing releases did not add any new features to the corresponding system.
for each of the subject systems we compared these versions with the latest bug xing releases identi ed by the last two columns of table and determined which functions were changed.
if a function was changed it was marked as a faulty.
otherwise it was marked as not faulty.
this method has been used to determine faulty functions before .
our second step collected the dependence clusters for each system using the understand1tool and an r package igraph2.
for each subject system we rst generated an understand database.
then we extracted the call and data dependencies for all functions from the generated database.
in this way we obtained the sdg of the subject system.
after that we used the function cluster inigraph package to identify all dependence clusters.
each system s functions are divided into two groups functions inside and functions outside dependence clusters.
table the dependence clusters in subject systems functions size of system functions clusters inside clusters largest cluster bash .
gcc .
gimp .
glib .
gstr .
table describes the clusters in the subject projects.
the third to the fth columns respectively show the number of clusters the percentage of functions inside clusters and the size of the largest cluster in each subject project.
from table we can see that there exist many dependence clusters from to in these projects.
furthermore from .
to .
of the total functions are found inside dependence clusters.
additionally the size of the largest cluster in these spearman rank correlation clusters dc1 dc2 dc3 ...size m etric fault densityrq1figure overview of the analysis method for rq1 projects varied from to .
of these ve projects gcc has the largest dependence cluster that includes functions .
this to a certain extent indicates that gcc is more complex than the other systems.
.
methodology and results in the section we describe the research method and report the experimental results in detail with respect to each of the research questions.
.
rq1.
are larger dependence clusters more fault prone?
in the following we describe the research method used and report the experimental result to address rq1.
.
.
research method figure provides an overview of the analysis method used to address rq1.
as can be seen in order to answer rq1 we use spearman s rank correlation to investigate the relationship between the size of dependence clusters and the fault density of dependence clusters.
here fault density refers to the percentage of faulty functions in the dependence clusters.
there are two basic metrics to measure the size of a graph size and ties.
size is the number of functions within dependence clusters while ties is the number of edges between functions in dependence clusters.
in this study we rst use igraph to compute these two metrics for all dependence clusters in each subject system.
we choose spearman s rank correlation rather than pearson s linear correlation since the former is a non parametric method and makes no normality assumptions on variables .
according to ott and longnecker for correlation coe cient rho the correlation is considered either weak jrhoj moderate jrhoj or strong jrhoj .
table spearman correlation for dependence clusters size and fault density rq1 system clusterssize ties rho p rho p bash .
.
.
.
gcc .
.
.
.
gimp .
.
.
.
glib .
.
.
.
gstr .
.
.
.
299consistency table fisher s exact test and orrq2 f3 f1 f2 ... f5 f6 ... f4figure overview of the analysis method for rq2 .
.
experimental result in the following we describe the empirical results used to answer rq1.
table summarizes the spearman correlation coe cients relating the size metrics with fault density of dependence clusters.
in table the second column is the number of dependence clusters in each subject system.
the third and the fth columns respectively present the correlation coe cients for the size and the ties metrics from spearman s singed rank correlation.
the correlation coe cients which are not statistically signi cant at the signi cance level of are marked in gray.
in table we see that all the absolute values of the correlation coe cients are less than .
.
this indicates that there is only a weak correlation between these two size metrics i.e.
size and ties with fault density of dependence clusters.
however all the correlation coe cients are larger than and most of them are statistically signi cant at the signi cance level of .
this indicates that these size metrics are positively correlated with fault density.
in other words larger dependence clusters tend to be more fault prone.
thus large dependence clusters are likely more harmful and hence should be avoided advice that is consistent with prior studies .
.
rq2.
are functions inside dependence clusters more fault prone than functions outside dependence clusters?
in the following we describe the research method and the experimental result answering rq2.
.
.
research method figure provides an overview of the data analysis method for addressing rq2.
as can be seen in order to answer rq2 we use fisher s exact test and the odds ratio or to examine whether the proportion of faulty functions inside dependence clusters is statistically signi cantly di erent from the proportion of faulty functions outside dependence clusters.
fisher s exact test is a statistical signi cance test used in the analysis of contingency tables .
the contingency table is a matrix that displays the frequency distribution of variables.
in our study the contingency table has four types of functions functions inside dependence clusters that have faults functions inside dependence clusters that have no faults functions outside dependence clusters that have faults and functions outside dependence clusters that have no faults.
the orindicates the likelihood that an event e.g.
that a function is faulty occurs .
assume pis the proportion of faulty functions inside dependence clusters and qis the proportion of faulty functions outside dependence clusters.
then oris de ned asp p q q .
thus or indicates that faults are more likely to occur inside dependence clusters.
or indicates an equal probability.
.
.
experimental result table summarizes the results of the comparison of theproportions of faulty functions inside and outside dependence clusters.
in table the second and the third columns respectively represent the proportion of faulty functions inside and outside dependence clusters.
the fourth and the fth columns respectively show the bonferroni adjusted p value from fisher s exact test and or.
table the proportion of faulty functions inside vs. outside dependence clusters rq2 system functions is faulty fisher sorinside outside exact test bash .
.
.
.
gcc .
.
.
.
gimp .
.
.
.
glib .
.
.
.
gstr .
.
.
.
from table we can see that the proportion of faulty functions inside dependence clusters is larger than the proportion of faulty functions outside dependence clusters in all cases and signi cantly larger in all but one case.
all the p values are less than except in gimp which indicates statistically signi cant at the signi cance level of .
this indicates that the proportions of faulty functions between these two groups are signi cantly di erent.
meanwhile all theors are substantially greater than two are even greater than which con rms the results from fisher s exact test.
overall fisher s exact test and the ors consistently indicate that functions inside dependence clusters are more fault prone than functions outside dependence clusters.
.
rq3.
are functions playing more important roles inside dependence clusters more fault prone?
in the following we describe the corresponding research method and the experimental results that address rq3.
.
.
research method figure provides an overview of the analysis method for rq3.
functions inside dependence clusters form an independent dependence graph e.g.
subg inin figure .
in order to answer rq3 we rst use this graph to compute the importance metrics as described in table for the functions inside dependence clusters in the sub dependence graph.
the metrics in table are widely used networks metrics that measure the extent to which these functions contribute to the sub dependence graph.
for example the betweenness metric for a vertex measures how many shortest paths pass through the vertex for all pairs of vertices of the subgraph.
thus vertices with large betweenness indicates a large importance.
note that some of these importance metrics can be computed by one the following three methods in out and all .
the in method concerns all incoming edges.
the out method concerns all outgoing edges.
while the all method treats the graph as an undirected graph.
in this study we only compute the metrics using the out method.
after that we build univariate logistic regression models for each of these metrics with fault proneness.
similar to prior studies we use or the odds ratio associated with one standard deviation increase to quantify the e ect of these metrics on fault proneness.
oris de ned as follows or e .
here and are respectively the regression 300f3 f1 f2 ...metric fault labelrq3 or form univariate logistic regressionfigure overview of the analysis method for rq3 table summarization of the importance metrics metric description betweenness shortest paths through the vertex centr betw centrality score according to betweenness centr clo centrality score according to the closeness centr degree centrality score according to the degrees centr eigen centrality score according to eigenvector closeness how close to other vertices constraint the burt s constraint degree v s adjacent edges eccentricity maximum graph distance to other vertices page rank google page rank score coe cient from the univariate logistic regression and the standard deviation of the variable.
or indicates that the corresponding metric is positively associated with faultproneness while or indicates a negative association.
.
.
experimental result table summarizes the ors from univariate logistic regression analysis for the metrics of functions inside dependence clusters.
in table the second and the third rows respectively show the number of functions and faulty functions inside dependence clusters for each subject system.
after each ors indicate the ors is not statistically signi cant at a signi cance level of .
note that all thep values are corrected by the bonferroni correction method.
table results from univariate analysis for the importance metrics of functions inside dependence clusters in terms of or rq3 metric bash gcc gimp glib gstr n faulty functions betweenness .
.
.
.
.
centr betw .
.
.
.
.
centr clo .
.
.
.
.
centr degree .
.
.
.
.
centr eigen .
.
.
.
.
closeness .
.
.
.
.
constraint .
.
.
.
.
degree .
.
.
.
.
eccentricity .
.
.
.
.
page rank .
.
.
.
.
in table we see that the ors of the centr degree and degree metrics are larger than .
in all systems.
for other metrics the ors are larger than .
in most systems.
this indicates that they are positively associated with faultproneness.
overall this result indicates that functions that play a more important role in dependence clusters tend to be more fault prone.
.
rq4.
are dependence clusters useful in fault proneness prediction?
in the following we describe the research method and present the experimental results for rq4.
.
.
research methodfigure provides an overview of the analysis method for rq4.
in order to address rq4 we use aic as the criteria to perform a forward stepwise variable selection procedure to build the following two types of multivariate logistic regression models the b model and the b c model.
the logistic regression is a standard statistical modeling technique in which the dependent variable can take on only one of two di erent values .
it is suitable and widely used for building fault proneness prediction models .
we choose the forward rather than the backward variant because the former is less time consuming on stepwise variable selection especially on a large number of independent metrics.
aic is a widely used variable selection criteria .
table the most commonly used product process and network metrics in this study category description product sloc fanin fanout npath cyclomatic cyclomaticmodi ed cyclomaticstrict essential knots nesting maxessentialknots minessentialknots n1 n2 n1 n2 process added deleted modi ed network size ties pairs density nweakcomp pweakcomp 2stepreach reache c broker nbroker egobetw negobetw e size e ciency constraint degree closeness dwreach eigenvector betweenness power table description of the studied network metrics metric description size alters that ego is directly connected to ties ties in the ego network pairs pairs of alters in the ego network density possible ties that are actually present nweakcomp weak components in the ego network pweakcomp weak components normalized by size 2stepreach nodes ego can reach within two steps reache c 2stepreach normalized by sum of alters size broker pairs not directly connected to each other nbroker broker normalized by the number of pairs egobetw all shortest paths across ego negobetw normalized egobetween by ego size e size alters minus the average degree of alters e ciency e size divided by number of alters constraint the extent to which ego is constrained degree nodes adjacent to a given node closeness sum of the shortest paths to all other nodes dwreach nodes that can be reached eigenvector the in uence of node in the network betweenness shortest paths through the vertex power the connections of nodes in one s neighbors the b model.
the b model is used as the baseline model which is built with the most commonly used product process and network metrics.
in this study the product metrics consist of metrics including one code size metric complexity metrics and software science metrics.
the process metrics consist of code churn metrics .
the description for the product and the process metrics can be found in .
the network metrics consist of network metrics which are described in table .
we choose these metrics as the baseline metrics for the following reasons.
first the network analysis metrics are also computed from dependence graphs .
second these metrics are widely used and considered as useful indicators for fault proneness prediction .
third they can be cheaply collected from source code for large software systems.
301product process network importance metrics product process network importance metrics cin model cout model predicted risk 2evaluatecombined predicted risk performance stest set f s inside dcs training set fs inside dcs training set fs outside dcs test set f s outside dcs b c model our segmented modelcomparre rq4 predicted risk 1product process network metricspredicted risk evaluatetest set training set b modelperformance s the baseline modelf3 f1 f2 f4 f5 f6 f3 f1f2 ... f4f5f6...f3 f1f2 ... f4f5f6... f3 f1 f2 f4 f5 f6 figure overview of the analysis method for rq4 the b c model.
the b c model is our segmented model which consists of two independent models i.e.
the b cin model and the b c out model.
the b c in and the b c out models are respectively used for predicting the probability that a function inside and outside dependence clusters are faulty.
they are both built with the most commonly used product process network metrics and the importance metrics described in table .
for the b c in model the importance metrics are computed on the sub dependence graph for functions inside dependence clusters e.g.
subg in of figure .
while for the b c in model the importance metrics are computed on the sub dependence graph for functions outside dependence clusters e.g.
subg outof figure .
note that as mentioned in section .
.
some of the importance and the network metrics can be computed by the in out or the all method.
for the sake of simplicity we only use the out method.
after building the b and the b c models we compare the prediction performance of the b model and the b c model with respect to ranking and classi cation scenarios.
in the following we describe the performance indicators and the prediction settings respectively.
performance indicators .
in recent years e ortaware performance measures have been widely used for evaluating the fault proneness prediction models.
the reason is that e ort aware measures take into account the e ort required to inspect the predicted faulty functions and thus can provide a more realistic evaluation than non e ort aware measures .
in this study we thus compare the b and the b c models in e ort aware evaluations.
in greater detail the predictive e ectiveness is evaluated in the following two di erent scenarios ranking and classi cation.
in the ranking scenario the functions are ranked in a descending order by the degree of their predicted relative risk.
with such a ranking in hand software project managers can easily select as many high risk functions for inspecting or testing as available resources will allow.
in the classi cation scenario the functions are rst classi ed into two categories according to their predictive relative risk high risk and low risk.
the functions that are predicted as high risk will be focused on for software quality enhancement.
following previous work figure sloc based alberg diagram we also use sloc in a function fas the proxy of the e ort required to inspect or test the function and de ne the relative risk of function fasr f pr sloc f where pr is the predicted probability of function fbeing faulty.
in other words r f represents the predicted fault proneness per sloc.
in the following we describe the e ort aware predictive performance indicators used in this study with respect to ranking and classi cation.
ranking.
we usece which is the cost e ectiveness measure proposed by arisholm et al.
to evaluate the e ortaware ranking e ectiveness of a fault proneness prediction model.
the ce measure is based on the concept of the sloc based alberg diagram.
in this diagram the x axis and y axis are respectively the cumulative percentages of sloc of the functions and the cumulative percentage of faults found in selected from the function ranking list.
figure is an example sloc based alberg diagram showing the ranking performances of a prediction model m in our context the prediction model mcould be the b model and the b c model .
to compute ce we also include two additional curves the random model and the optimal model.
in the random model functions are randomly selected to inspect or test.
in the optimal model functions are sorted in decreasing order according to their actual fault densities.
based on this diagram the e ort aware ranking e ectiveness of the prediction model mis de ned as follows ce m area m area random area optimal area random here area m is the area under the curve corresponding to modelmfor a given top percentage of sloc.
the cut o value varies between and depending on the 302amount of available resource for inspecting functions.
as aforementioned practitioners are more interested in the ranking performance of a prediction model at the top fraction.
in this study we use the ce at the cut o indicated asce to evaluate the e ort aware ranking performance of a model.
classi cation.
we use e ort reduction in amount era a classi cation performance indicator adapted from the er measure used by zhou et al.
to evaluate the e ort aware classi cation e ectiveness of a fault proneness prediction model.
in the classi cation scenario only those functions predicted to be high risk will be inspected or tested for software quality enhancement.
the era measure denotes the amount of the reduced sloc i.e.
the amount of e ort reduction to be inspected by a model mcompared with the random model that achieves the same recall of faults.
therefore the e ort aware classi cation e ectiveness of the prediction model mcan be formally de ned as follows here e ort m is the ratio of the total sloc in those predicted faulty functions to the total sloc in the system.
e ort random is the ratio of sloc to inspect or test to the total sloc in the system that a random selection model needs to achieve the same recall of faults as the prediction model m. in this paper for the sake of simplicity we useera 2to evaluate the e ort aware classi cation performance.
in order to compute era we rst use the predicted fault proneness by the model to rank the modules in descending order.
then we classify the top modules into the fault prone category and the other modules into the defect free category.
finally we compute the e ort aware classi cation performance era as era .
here we use as the cut o value because many studies show that the distribution of fault data in a system generally follow the pareto principle .
the pareto principle also known as the rule states that for many phenomena percent of the consequences stem from percent of the causes .
in our context this means that by inspecting these predicted fault prone functions we expect that almost of faulty modules in a system will be found.
prediction settings .
to obtain a realistic comparison we evaluate the prediction performance under times fold cross validation.
we choose fold cross validation rather than fold cross validation due to the small percentage of faulty function in the data sets.
at each fold cross validation we randomize and then divide the data set into parts of approximately equal size.
then we test each part by the prediction model built with the remainder of the data set.
this process is repeated times to alleviate potential sampling bias.
note that for each fold of the times fold cross validation we use the same training test set to train test our segmented model i.e.
the b c model and the baseline model i.e.
the b model .
on each fold we rst divide the training set into two groups functions inside dependence clusters and functions outside dependence clusters.
then we train the b c in model and the b c out model respectively.
we also divide the test set into two groups and subsequently use the b c in model and the b cout model to predict the probability of those functions that contain faults.
after that we combine the predicted values to derive the nal predicted values to compute the performance indicators.
based on these predictive e ectiveness values we use the wilcoxon s signed rank test to examine whether two models ce bash gcc gimp glib gstr figure ranking performance comparison for the b and the b c model in terms of ce have a signi cant di erence in their predictive e ectiveness.
then we use the bonferroni correction method to adjust p values to examine whether a di erence is signi cant at the signi cance level of .
.
furthermore we use cli s to examine whether the magnitude of the di erence between the prediction performances of two models is important from the viewpoint of practical application .
cli s is widely used for median comparison.
by convention the magnitude of the di erence is considered either trivial j j small moderate or large .
.
.
.
experimental result this section presents the results with respect to ranking and classi cation scenarios to answer rq4.
ranking performance comparison figure employs the box plot to describe the distributions ofce 2obtained from times fold cross validation for the b and the b c models with respect to each of the subject systems.
for each model the box plot shows the median the horizontal line within the box the 25th percentile the lower side of the box and the 75th percentile the upper side of the box .
in figure a blue box indicates that the corresponding b c model performs signi cantly better than the b model according to the p values from wilcoxon signed rank test and the magnitude of the di erence between the corresponding b c model and the b is not trivial according to cli s i.e.j j .
table ranking comparison in terms of ce the b model vs the b c model system b b c j j bash .
.
.
.688p gcc .
.
.
.714p gimp .
.
.
.938p glib .
.
.
.194p gstr .
.
.
.426p average .
.
.
.
from figure it is obvious that the b c model performs substantially better than the b model in each of the subject systems.
table presents median ce 2for the b and the b c models.
in table the second and the third columns present the median ce respectively for the b and the b c model.
the fourth and the fth column are respectively the percentage of the improvement for the b c model over the b model and the e ect sizes in terms of the cli s .
in the last column p indicates that the b c model has signi cantly larger median ce 2than the b model by the wilcoxon s signed rank test.
the last row in table shows the average values for the ve projects.
from table we have the following observations.
for all systems the b c model has a larger median ce 2than 303era bash gcc gimp glib gstr figure classi cation performance comparison for the b and the b c model in terms of era the b model in terms of the median ce .
on average the b c model leads to about .
improvement over the b model in terms of the median ce .
the wilcoxon signedrank testp values are very signi cant .
furthermore the e ect sizes are moderate to large except in glib where the e ect size is small.
the core observation is that from the viewpoint of practical application the b c model has a substantially better ranking performance than the b model.
classi cation performance comparison figure employs box plots to describe the distributions ofera 2obtained from times fold cross validation for the b and the b c models with respect to each of the subject systems.
from figure we can nd that the b c models are also substantially better than the b model.
table classi cation comparison in term of era the b model vs the b c model system b b c j j bash .
.
.
.644p gcc .
.
.
.816p gimp .
.
.
.940p glib .
.
.
.462p gstr .
.
.
.551p average .
.
.
.
table presents the classi cation performance for the b and the b c models in terms of ce .
for all systems the b c model has a larger median era 2than the b model in terms of the median era .
on average the b c model leads to about .
improvement over the b model.
the p values are very signi cant .
.
besides the e ect sizes are moderate to large.
the core observation is that from the viewpoint of practical application the b c model has a substantially better classi cation performance than the b model.
overall the above observations suggest that the b c model outperforms the b model in e ort aware fault proneness prediction under both ranking and classi cation scenarios.
this indicates that dependence clusters are actually useful in e ort aware fault proneness prediction.
.
discussion in this section we further discuss our ndings.
first we analyze whether our conclusions will change if the potentially confounding e ect of module size is excluded for the b and the b c models.
then we analyze whether we have similar conclusions if the multiplicity of dependencies is not considered.
.
will our conclusions change if the potentially confounding effect of module size is excluded?
in our study when building a fault proneness prediction model we did not take into account the potentially con founding e ect of function size on the associations between those metrics with fault proneness .
therefore it is not readily known whether our conclusions will change if the potentially confounding e ect of module size is excluded.
in the following we use the method proposed by zhou et al.
to remove the confounding e ect of module size and then rerun the analyses for rq4.
table ranking comparison in terms of ce 2after excluding the potentially confounding e ect of module size the b model vs the b c model system b b c j j bash .
.
.
.
gcc .
.
.
.520p gimp .
.
.
.928p glib .
.
.
.
gstr .
.
.
.399p average .
.
.
.
table classi cation comparison in terms of era 2after excluding the potentially confounding e ect of module size the b model vs the b c model system b b c j j bash .
.
.
.
gcc .
.
.
.728p gimp .
.
.
.948p glib .
.
.
.446p gstr .
.
.
.444p average .
.
.
.
table and table respectively present the median ce 2andera 2for the b and the b c models after excluding the potentially confounding e ect of module size.
from table and table we nd that the b c models have both larger median ce 2and median era 2than the b model in all the ve subject systems except in bash.
this indicates that our proposed model still performs better than the baseline model in both of the ranking and classi cation scenarios in most cases.
overall after excluding the potentially confounding e ect of function size our conclusion on rq4 is mostly the same.
.
will our conclusions change if the multiplicity of dependencies is ignored?
as mentioned before in our study we take into account the multiplicity of dependencies between functions.
the multiplicity information is used as the weight of dependencies in the sdg.
however prior studies ignored this information.
therefore it is not readily answerable whether our conclusions will change if the multiplicity of dependencies is also ignored.
next we ignore the multiplicity of dependencies and rerun the analysis for rq4.
table and table respectively summarize the median ce 2and the median era 2for the b and the b c models when the multiplicity of dependencies is not considered.
from table and table we observe that the b c models have substantially larger median ce 2and medianera 2than the b model in all the ve subject systems.
this indicates that our proposed model still performs substantially better than the baseline model in both of the ranking and classi cation scenarios.
overall the above observations show that our conclusions 304on rq4 remain unchanged if the multiplicity of dependencies is not considered.
table ranking comparison in terms of ce when the multiplicity of dependencies is not considered the b model vs the b c model system b b c j j bash .
.
.
.313p gcc .
.
.
.576p gimp .
.
.
.986p glib .
.
.
.167p gstr .
.
.
.378p average .
.
.
.
table classi cation comparison in terms of era 2when the multiplicity of dependencies is not considered the b model vs the b c model system b b c j j bash .
.
.
.261p gcc .
.
.
.605p gimp .
.
.
.994p glib .
.
.
.402p gstr .
.
.
.501p average .
.
.
.
.
threats to validity this section analyzes the most important threats to the construct internal and external validity of our study.
.
construct validity there are two potential threats to the construct validity of our study.
the rst threat concerns the fault data.
in our study we collected fault data by comparing the latest bug xing version with the investigated version for each system.
bug xing version did not add new features to the corresponding systems.
thus the construct validity of the fault data can be considered acceptable.
the second threat concerns the method we used to compute the importance and the network metrics.
in our study we use the out method to compute those metrics which only concerns the outgoing degree.
in order to address this threat we recomputed those metrics by using the other two methods and reran the analysis for rq3 and rq4.
we found that the results were very similar.
.
internal validity there are three possible threats to the internal validity of our study.
the rst threat is the unknown e ect of the method to de ne the relative risk of a function in rq4.
in our study we use the ratio of the predicted value from a na ve logistic regression model to the functions sloc as the relative risk for each function.
however in the literature most studies use the predicted value from the na ve logistic regression model as the relative risk of a function.
in order to eliminate this threat we reran the analysis for rq4 by using the predicted value from the na ve logistic regression model as the relative risk.
we found that the relative performance of the b model and the b c model is not changed.
that is to say the b c model is still signi cantly better than the b model.
the second threat is from the speci c cut o value used for the performance indicator i.e.
the ceandera .
in our study .
is used as the cut o value for the computation of ceandera .
to eliminate this potential threat we rerun all the analyses using the following typical cut o values .
and .
.
we found our conclusion remains unchanged.
the third threat is the unknown e ect of the method for the stepwise variable selection in rq4.
in our study we use aic as the criteria to perform the stepwise variable selection.
bic is also a widely used method to perform stepwise variable selection .
we reran the analysis for rq4 using bic as the criteria to perform variable selection and found the results to be very similar.
.
external validity our experiments are based on ve long lived and widely used open source c systems.
the most important threat to the external validity of this study is that our ndings may not be generalized to other systems especially closed source systems.
the second threat to the external validity of this study is that our ndings are restricted to only one language.
these external threats are ever present in any empirical study concerning program analysis we hope that researchers will replicate our study across a wide variety of systems in the future.
.
conclusions and future work in this study we perform an extensive study to examine the relationships between function level dependence clusters and fault proneness.
our ndings from ve widely used industrial size systems show that larger dependence clusters tend to be more fault prone functions inside dependence clusters tend to be more fault prone than functions outside dependence clusters functions that play more important roles in dependence clusters are more fault prone our segmented prediction model can signi cantly improve the performance in e ort aware fault proneness prediction.
these results consistently suggest that large dependence clusters in software systems should be avoided when performing code refactoring we should pay more attention to dependence clusters.
these results provide valuable data for better understanding the properties of dependence clusters and its e ect on software quality.
this study focuses on function level dependence cluster for open source c software systems.
as future work we plan to replicate our experiments for dependence clusters at di erent granularities e.g.
statement level and on systems written in other languages and other programming paradigms.
.
repeatability we provide all data sets and rscripts that used to conduct this study at .