thread modular static analysis for relaxed memory models markus kusano virginia tech blacksburg va usachao wang university of southern california los angeles ca usa abstract we propose a memory model aware static program analysis method for accurately analyzing the behavior of concurrent software running on processors with weak consistency models such as x86 tso sparc pso and sparc rmo.
at the center of our method is a unified framework for deciding the feasibility of inter thread interferences to avoid propagating spurious data flows during static analysis and thus boost the performance of the static analyzer.
we formulate the checking of interference feasibility as a set of datalog rules which are both efficiently solvable and general enough to capture a range of hardware level memory models.
compared to existing techniques our method can significantly reduce the number of bogus alarms as well as unsound proofs.
we implemented the method and evaluated it on a large set of multithreaded c programs.
our experiments show the method significantly outperforms state of the art techniques in terms of accuracy with only moderate runtime overhead.
ccs concepts software and its engineering automated static analysis formal software verification keywords concurrency abstract interpretation thread modular reasoning datalog relaxed memory model tso pso rmo introduction concurrent software written for modern computer architectures though ubiquitous remains challenging for static program analysis.
although abstract interpretation is a powerful static analysis technique and prior thread modular methods mitigated interleaving explosion none was specifically designed for software running on weakly consistent memory.
this is a serious deficiency since weakly consistent memory may exhibit behaviors not permitted by uniprocessors.
for example slow memory accesses may be delayed increasing performance but also introducing additional inter thread non determinism.
thus multithreaded software running on such processors may exhibit erroneous behaviors not manifesting on sequentially consistent sc memory.
consider x86 tso total store order as an example.
under tso each processor has a store buffer caching memory write operations so they do not block the execution of subsequent instructions .
conceptually each processor has a queue of pending writes to be flushed to memory at a later time.
the flush occurs non deterministically at any time during the program s execution.
this delay between the time a write instruction executes and the time it takes effect may cause the write to appear reordered with subsequent instructions within the same thread.
figure shows an example where the assertion holds under sc but not tso.
since x andyare initialized to and they are notdefined as atomic variables the write operations x 1andy may be stored in buffers one for each thread and thus delayed after the read operations.void thread1 x a y void thread2 y b x assert !
a b figure the assertion holds under sc but not under x86tso sparc pso and sparc rmo memory models.
sparc pso partial store order permits even more non sc behaviors it uses a separate store buffer for each memory address.
that is x 1andy 1within the same thread may be cached in different store buffers and flushed to memory independently.
this permits the reordering of a write to xwith a subsequent read from y but also with a subsequent write e.g.
to variable z in the same thread.
the situation is similar under sparc rmo relaxed memory order .
we detail how such relaxation leads to errors in section .
broadly speaking existing thread modular abstract interpreters fall into two categories neither modeling weak memory related behaviors.
the first are sc specific they are designed to be flow sensitive in terms of modeling thread interactions but consider only behaviors compatible with the sc memory.
the second are oblivious to memory models mm oblivious they permit all orderings of memory writes across threads.
therefore mm oblivious methods may report spurious errors bogus alarms whereas sc specific methods although more accurate for sc memory may miss real errors on weaker memory bogus proofs .
this flaw is not easy to fix using conventional approaches .
for example maintaining relational invariants at all program points makes the analysis prohibitively expensive.
in section we use examples to illustrate issues related to these techniques.
we propose the first thread modular abstract interpreter for analyzing concurrent programs under weakly consistent memory.
our method models thread interactions with flow sensitivity and is memory model specific it models memory operations assuming a processor level memory model as shown in figure .
in this figure the boxes with bold text highlight our main contributions.
our method builds on a unified framework for modeling the memory consistency semantics.
specifically the feasibility of thread interactions is formulated as a constraint problem via datalog it is efficiently solvable in polynomial time and adaptable to various hardware level memory models.
additionally our method handles thread interactions in a flow sensitive fashion while being threadmodular.
analyzing one thread at a time as opposed to the entire program increases efficiency especially for large programs.
however unlike prior mm oblivious methods we do not join all the effects of remote stores before propagating them to a thread thus preserving accuracy.
overall our method differs from the state ofthe art which either are non thread modular or not specifically targeting weak memory .
our method also differs significantly from techniques designed for bug hunting as opposed to obtaining correctness proofs.
for example in concurrency testing stateless dynamic model checking was extended from sc to weaker memory models sep 2017thread modular analysis sequential abstract interpretationfeasibility of thread interferenceparameterized by memory models sc tso pso rmo etc.
figure fruittree our memory model aware threadmodular static program analysis procedure.
.
in bounded model checking alglave et al.
modeled weak memory through code transformation or direct symbolic encoding .
however these methods cannot be used to verify properties if they do not find bugs it does not mean the program is correct.
in contrast our method like other abstract interpreters is geared toward obtaining correctness proofs.
we implemented our new method in a tool named fruittree using clang llvm as the c front end apron for abstract domains and the z datalog engine in z3 .
we evaluated fruittree on litmus tests and larger multithreaded programs totaling of lines of c code.
reachability properties were expressed as embedded assertions.
our results show that fruittree is significantly more accurate than state of the art techniques with moderate runtime overhead.
specifically we compared fruittree against the mm oblivious analyzer of min the sc specific thread modular analyzer watts and a non thread modular analyzer named duet .
on the litmus tests fruittree is more accurate than the other three methods.
on the larger benchmarks including linux device drivers fruittree proved properties compared to proved by min s method.
to summarize we make the following contributions we propose a memory model aware static analysis method based on thread modular abstract interpretation.
we introduce a declarative analysis framework for deducing the feasibility of thread interferences on weak memory.
we implement and evaluate our method on a set of benchmarks to demonstrate its high accuracy and moderate runtime overhead.
the remainder of this paper is organized as follows.
first we motivate our technique via examples in section .
then we provide background on memory models and abstract interpretation in section .
we present our new declarative analysis for checking the feasibility of thread inferences in section followed by the main algorithm for thread modular abstract interpretation in section .
we present our experimental results in section review related work in section and conclude in section .
motivation consider the program in figure .
the assertion holds under sc tso pso and rmo.
but removing the fence causes it to fail under pso and rmo.
in this section we show why mm oblivious methods may generate bogus errors why sc specific ones may generate bogus proofs and how our new method fixes both issues.
.
behaviors under sc tso pso and rmo first note that the assertion in figure holds under sc since each thread executes its instructions in program order i.e.
x takesvoid thread1 x fence y void thread2 if y assert x figure the assertion always holds but if the fence is removed the assertion may fail under pso and rmo.
effect before y .
so thread two observing yto be implies x must have been set to .
next we explain why the assertion holds under tso .
tso permits the delay of a store after a subsequent load to a disjoint memory address as in figure .
this program order relaxation is a performance optimization e.g.
buffering slow stores to speed up subsequent loads.
however since all stores in a thread go into the same buffer tso does not allow the reordering of two stores thread figure .
thus even without the fence x always takes effect before y meaning the assertion holds.
next we show why removing the fence causes the assertion to fail under pso and rmo.
both permit store store reordering by allowing each processor to have a separate store buffer for each memory address.
thus xandyare in separate buffers.
since buffers are flushed to memory independently with the fence removed y may take effect before x as if the two instructions were reordered in this thread.
thus the second thread may read from ybefore is written to xin global memory thus causing the assertion to fail.
the fence is important because it forces all stores issued before the fence to be visible to all loads issued after the fence i.e.
x takes effect before y even under pso and rmo.
thus the assertion holds again.
.
ineffectiveness of existing methods mm oblivious methods report bogus alarms because they were not designed for weak memory and they ignore the causality of inter thread data flows.
thus they tend to drastically overapproximate the interferences between threads.
for example an mm oblivious static analysis may work as follows.
first it analyzes each thread as if it were a sequential program.
then it joins the effects of all stores on global memory known as thethread interferences .
next it individually analyzes each thread again this time in the presence of the thread interferences computed from the previous iteration when a thread performs a memory read the value may come from any one of these thread interferences.
this iterative process repeats until a fixed point is reached.
next we demonstrate how the mm oblivious analyzer works on figure .
consider the thread interferences to be a map from variables to abstract values in the interval domain .
thread generates interferences x7 and y7 .
within thread the load of ymay read from local memory or the interference .
thus y where is the joinoperator in the interval domain.
similarly the load of x may read from local memory or the interference i.e.
x .
thus the assertion is incorrectly reported as violated.
while our previous example used the non relational interval domain the bogus alarm remains when using a relational abstract domain the propagation of interferences in mm oblivious methods is inherently non relational.
inferences map variables to a single values causing all relations to be forgotten.
conventional approachesprogram in figure program in figure method with fences without fences with fences without fences sc tso pso rmo sc tso pso rmo sc tso pso rmo sc tso pso rmo bogus bogus bogus bogus bogus bogus bogus bogus bogus mm oblivious e.g.
alarm alarm alarm alarm alarm alarm alarm alarm alarm alarm alarm alarm bogus bogus bogus bogus bogus bogus bogus bogus sc specific e.g.
proof proof proof proof proof proof proof proof proof proof proof proof our method proof proof proof proof alarm alarm proof proof proof proof proof alarm figure comparing the effectiveness of various methods in handling the example programs in figure and figure .
cannot easily fix this since maintaining relational invariants at all global program points is prohibitively expensive.
in contrast prior sc specific methods do not report bogus alarms they assume x takes effect before y .
this leads to more accurate analysis results for sc but is unsound under weak memory e.g.
they miss the assertion failure in figure under pso or rmo when the fence is removed.
figure summarizes the ineffectiveness of prior techniques on the programs in figures and with and without fences.
note that in figure the fence instruction may be added between the write and read instructions of both threads.
the table in figure shows how prior mm oblivious methods report bogus alarms prior sc specific methods report bogus proofs while our new method eliminates both.
.
how our method handles memory models some prior techniques lead to bogus alarms because they overapproximate thread interferences i.e.
they allow a load to read from any remote store regardless of whether such a data flow or combination of flows is feasible while others lead to missed bugs because they under approximate thread interferences i.e.
they do not allow any non sc data flow.
consider figure the load of xmay read or and the load of ymay read or but the combination of xreading and yreading is infeasible.
realizing this our method checks the feasibility of interference combinations under weak memory semantics before propagating them.
toward this end we propose two new techniques.
the first is the flow sensitive propagation of thread interferences.
instead of eagerly joining all interfering stores we handle each combination separately.
the second is a declarative modeling of the memory consistency semantics general enough to capture sc tso pso and rmo .
together these techniques prune infeasible combinations of thread interferences such as xand y reading and respectively in figure .
our new method analyzes thread in figure by considering four different interference combinations 1 4 separately.
1 y7 andx7 2 y7 andx7 3 y7 andx7 4 y7 andx7 .
we gain accuracy in two ways.
first we remove spurious values caused by an eager join e.g.
we no longer have y .
second we query a lightweight constraint system to quickly deduce infeasibility of an interference combination on demand.
1 2 and 3are all feasible but they do not cause assertion failures.
our check for infeasibility of an interference combination is implemented using datalog horn clauses within finite domains solvable in polynomial time.
we will provides details of this constraint system in section .
for now consider 4in figure it is infeasible unless we assume the program runs under pso or rmo with the fence removed .
we deduce infeasibility as follows y has executed it is being read from thus x has executed due to the program order requirement on sc and tso and the fence on pso and rmo so the load of xmust not read from its initial value .
this deduction leads to a formal proof that 4can not exist in any concrete execution.
since the combinations 1 3do not violate the assertion and 4is proved to be infeasible the property is verified.
preliminaries in this section we review weak memory models at the processor level as opposed to the programming language level and static program analysis based on abstract interpretation.
.
concurrent programs we are concerned with a program consisting of a finite set of threads.
each thread assesses a set a b c .
.
.
of local variables.
all threads access a set x y z .
.
.
of global variables via load andstore instructions.
a thread creates a child thread with threadcreate and waits it to terminate with threadjoin .
we represent a program using a set g g1 .
.
.
gk of flow graphs.
each flow graph g g where g n n0 is a thread n nis the set of program locations of the thread n0 nis the entry point and is the transition relation.
that is n n iff there exists an edge from n ton.
each program location n nis associated with an atomic instruction that may be a load store orfence .
non atomic statements such as y x where both xandyare global variables can be transformed to a sequence of atomic instructions e.g.
the load a xfollowed by the store y a where ais a local variable in both cases.
when accessing variables on the global memory threads may use a special fence instruction to impose a strict program order between memory operations issued before and after the fence.
.
memory consistency models the simplest memory model is sequential consistency sc .
sc corresponds to a system running on a single coherent memory timeshared by operations executed from different threads.
there are two important characteristics of sc the program order requirement and thewrite atomicity requirement.
the program order requirement says that the processor must ensure that instructions within a thread take effect in the order they appear in the program.
the write atomicity requirement says that the processor must maintain the illusion of a single sequential order among operations from allwhich program order relaxation is allowed?
write atomicity memory model r v1 r v1 r v1 w v1 w v1 r v1 w v1 w v1 r v1 r v2 r v1 w v2 w v1 r v2 w v1 w v2 read own write early sc no no no no no no no no no tso no no no no no no yes no yes pso no no no no no no yes yes yes rmo no no no no yes yes yes yes yes figure allowed relaxations of various processor level memory models cf.
.
v1andv2are distinct variables and indicates rule needs to be relaxed to allow read own write early behaviors see section .
for explanation .
threads.
that is the effect of any store operation must take effect and become visible either to allthreads or to none of the threads.
sc is an ideal memory model in real cpus the hardware level memory models are often weaker than sc and can be characterized by their corresponding relaxations of the program order andwriteatomicity requirements as shown in figure .
here r v1 w v2 is a read of v1followed by a write of v2in the same thread.
specifically tso allows x a y to be reordered as a y x according to w v1 r v2 in column where v1isxandv2 isy.
pso further allows x y reordered to y x according to w v1 w v2 in column .
as shown in section these program order relaxations conceptually are the effect of store buffering which delay the stores past subsequent stores loads within a thread.
neither tso nor pso permits the delay of a load.
weaker still is rmo which permits the relaxations of r v1 r v2 and r v1 w v2 as shown in columns and of the table in figure .
by relaxing the write atomicity requirement all three weaker memory models allow a thread to read its own write early.
that is the thread can read a value it has written before the value reaches the global memory and hence becomes visible to other threads.
.
abstract interpretation abstract interpretation is a popular technique for conducting static program analysis .
in this context a numerical abstract domain defines for every n nof the program a memory environment s. it is a map from each program variable to its abstract value1.
consider intervals which map each variable to a region defined by the lower and upper bounds.
for a program with two integer variables xandywhere both may have any value initially the memory environment associated with the entry point n0 nis s0 x7 y7 where .
after executing x the memory environment becomes s1 x7 y7 .
the process of computing s1based on s0is represented by the transfer function of x .
additionally the join is defined as .
the partial order relation is defined as if and only if l1 l2andu1 u2.
for example and .
we use sto denote the set of all memory environments.
sis a lattice with properly defined top and bottom elements join partial order and a widening operator .
each node n nhas a transfer function t s s taking an environment s sas input before executing the atomic operation in n and returns a new environment s sas output.
lettfunc n s s be a map from each node to its transfer function.
for example given a node n nwhose operation 1for ease of presentation we assume a variable maps to a single value.
our analysis can trivially use relational domains.isx a ifs x7 a7 the new environment iss tfunc n s x7 a7 .
the goal of an abstract interpreter is to compute an environment map m n s over approximating the memory state at every program location.
m typically initially maps all variables in the entry node to and all variables in other nodes to .
then it iteratively applies the transfer function tfunc n and joins the resulting environments for all n until they reach a fixed point.
without getting into more details refer to the literature we define the sequential analyzer as a fixed point computation with respect to the function analyzeseq n s n s analyzeseq m n7 tfunc n n n m n here m n is the environment produced by a predecessor node n ofn and s n n m n is the join of these environments.
tfunc n s is the new memory environment produced by executing the operation in n. applying this function to all nodes of a sequential program until a fixed point leads to an over approximated memory state for each program location.
however directly applying the sequential analyzer to each execution of a multithreaded program is not practical because it leads to an exponential complexity.
instead thread modular techniques iteratively apply analyzeseq to each thread as if it were a sequential program and then merge propagate the global memory effects across threads.
the iterative process continues until memory environments in all threads stabilize.
since each thread is analyzed in isolation this approach is more scalable than non thread modular techniques.
however it may result in accuracy loss because the analyzer for each thread relies on a coarse grained abstraction of interferences from other threads.
when analyzing a thread tin the presence of a set of threads t for example the interferences are the effects of global memory stores from all t t. the interferences are a map v 2s from each variablev vread by thread tto the set of memory environments produced by interfering stores where vis the set of all program variables and 2sis the power set of s. prior thread modular techniques eagerly join all interfering memory states from the other threads in tbefore propagating them to the current thread t. as such they often introduce bogus store to load data flows into the static analysis or miss valid storeto load data flows.
in the remainder of this paper we present our method for mitigating this problem.
deciding interference feasibility in this section we describe our new method for quickly deciding the feasibility of a combination of store to load data flows under a given memory model.
an interference combination is a set ic l s .
.
.
where each l s icis a load land an interfering store s.checking the feasibility of icis formulated as a deductive analysis with inputs the flow graph of the current thread the flow graphs of all interfering threads and the existing set of store to load data flows represented by l s l s readsfrom .
the output of this deductive analysis is the relation mustnotreadfrom .
l s mustnotreadfrom means the load lmust not read from the store ssince our analysis proved the data flow from stol is infeasible given the input readsfrom relation in ic.
consider the program in figure as an example.
one thread interference combination we want to check is the load of yfrom y and the load of xfrom the initial value .
let these load and store instructions be denoted ly s10y lx and s0x respectively.
then the feasibility problem is stated as follows given ly s10y readsfrom check if lx s0x mustnotreadfrom .
.
notations before presenting the details of our feasibility checking procedure we define a set of unary and binary relations over instructions and program variables.
specifically s1 v1 isload denotes s1is a load of variablev1 and s2 v2 isstore denotes s2is a store to variable v2.
we use s1 isload if we do not care about the variable.
similarly we use f isfence to denote that fis a fence.
we also use isllmembar islsmembar isslmembar isssmembar to denote load load load store store load and store store memory barriers as defined in the sparc architecture for example a load store membar prevents loads before the barrier from being reordered with subsequent stores.
we define binary relations over instructions s1ands2 the first four relations dominates notreachablefrom threadcreates threadjoins are determined by the program s flow graphs.
based on them we deduce the mhb relation which must be satisfied by all program executions.
the readsfrom relation comes from the given ic from which we deduce the mustnotreadfrom relation.
s1 s2 dominates means that s1dominates s2in the control flow graph of a thread.
s1 s2 notreachablefrom means that s1cannot be reached from s2 in the control flow graph of a thread.
s1 s2 threadcreates means s1is the thread creation and s2is the first operation of the child thread.
s1 s2 threadjoins means s1is the thread join and s2is the last operation of the child thread.
s1 s2 mhb means that s1must happen before s2in all executions of the program.
s1 s2 readsfrom means that s1is a load that reads the value written by the store s2.
s1 s2 mustnotreadfrom means that s1must not read from the value written by s2.
consider figure again where we want to check if the load ofyin the second thread reads from y then is it possible for the load of xto read from the initial value ?
in this case we encode the assumption as ly s10y readsfrom .
next we deduce themustnotreadfrom relation.
finally we check if lx s0x mustnotreadfrom .
.
relaxing the program order requirement to model the program order imposed by different memory models we define a new relation noreorder such that s1 s2 noreorder if the reordering of s1ands2within the same thread is not allowed.
we define the rules for noreorder based on the allowed programorder relaxations for different memory models figure .for sc noreorder is defined as under sc s1 s2 noreorder that is no reordering is ever allowed under sc row sc figure .
for tso noreorder is defined as s1 isload under tso s1 s2 noreorder s2 isstore under tso s1 s2 noreorder under tso two operations s1 s2 can not reorder in six of the eight cases.
the first rule above disallows columns and figure while the second disallows columns and .
thus reordering is permitted in two cases columns and .
although this is counter intuitive note that w v1 r v1 column may be reordered in our analysis under tso and pso and rmo for soundness it permits read own write early behaviors.
we detail this shortly in section .
.
for pso noreorder is defined as s1 isload under pso s1 s2 noreorder s1 v1 isstore s2 v1 isstore under pso s1 s2 noreorder under pso two operations s1 s2 can not reorder in five of the eight cases.
the first rule above disallows columns and while the second disallows column .
thus reordering is permitted only in the remaining three cases columns and .
for rmo the inference rules are defined as s1 v1 isload s2 v1 isload under rmo s1 s2 noreorder s1 v1 isload s2 v1 isstore under rmo s1 s2 noreorder s1 v1 isstore s2 v1 isstore under rmo s1 s2 noreorder similarly the above inference rules can be directly translated from columns and of the table in figure .
.
handling fences and memory barriers next we present the ordering constraints imposed by fences and memory barriers.
we consider four variants of the membar instruction which prevents loads and or stores before the membar from being reordered with subsequent loads and or stores .
s1 m dominates m s2 dominatesm isllmembar s1 isload s2 isload s1 s2 noreorder s1 m dominates m s2 dominatesm islsmembar s1 isload s2 isstore s1 s2 noreorder s1 m dominates m s2 dominatesm isslmembar s1 isstore s2 isload s1 s2 noreorder s1 m dominates m s2 dominatesm isssmembar s1 isstore s2 isstore s1 s2 noreorder we also model fences in terms of membar s since they prevent loads and stores from being reordered with subsequent loads and stores as well.
s ssta threadcreates s ssta mhb s send threadjoins send s mhb s1 s2 noreorder s1 s2 dominates s2 s1 notreachablefrom s1 s2 mhb s1 s2 mhb s2 s3 mhb s1 s3 mhb l v isload s1 v isstore s2 v isstore l s1 readsfrom s1 s2 mhb l s2 mhb figure deduction rules for mhb must happen before .
l s mhb l s mustnotreadfrom l1 v isload l2 v isload s2 v isstore l1 s1 readsfrom l1 s2 mhb s2 l2 mhb l2 s1 mustnotreadfrom figure deduction rules for the mustnotreadfrom .
f isfence f isllmembarf isfence f islsmembar f isfence f isslmembarf isfence f isssmembar in addition to fences explicitly added to the program there are fences implicitly added to thread routines such as lock unlock and signal wait .
for example in the code snippet x lock lk a y unlock lk there is a fence inside lock lk to ensure x always takes effect before a y .
this is how most modern programming systems guarantee data race freedom to application level code i.e.
programs without data races have only sc behaviors .
thus we model every call scto a posix thread routine using sc isfence .
.
rules for deducing mustnotreadfrom we divide our inference rules into two groups.
the first figure use the relations threadcreates threadjoins dominates and noreorder to generate the must happen before mhb relation.
rule states that if the instruction screates a thread with entry instruction ssta then smust happen before ssta.
similarly if instruction sjoins a thread with exit instruction send then send must happen before s. rule states that if s1dominates s2within a thread s cfg ands1is not reachable from s2 i.e.
no loop encompasses both s1 ands2 then if permitted by the memory model s1must happen before s2.
figure exemplifies this rule the loop in the left cfg is outside the dominates edge thus s1 s2 notreachablefrom .
the loop in the right cfg encompasses the dominates edge thus s1 s2 notreachablefrom .
rule states that the mhb relation is transitive if s1must happen before s2 and s2must happen before s3 then s1must happen before s3.
correctness follows from the definition of mhb .
rule states that if a load lreads from the value written by the store s1 then lmust happen before some second store to the same variable s2takes effect.
this is intuitive because if s2takes effect s1 s2dominatess1 s2dominatesfigure example illustrating rule s1 lreadsfrom s2mhb mhbstore v load v store v figure example illustrating rule l1 s2mhb l2mustnotreadfrom mhbstore v load v store v s1 reads from load v figure example illustrating rule .
before l but after the first store s1 then lcan no longer read from s1.
figure exemplifies this rule.
its correctness is obvious.
the second group of inference rules figure takes the relations mhb andreadsfrom and generates the mustnotreadfrom relation.
recall that if a load store pair l s mustnotreadfrom the value stored by scan never flow to l. thus mustnotreadfrom may be used to eliminate infeasible data flows.
rule states that if a load lmust happen before a store s then l cannot read from s. this follows from the definition of mhb .
note that a store s happens when it propagates to main memory.
rule states that if a load l1reads from a store s1 and l1must happen before some other store s2 and s2must happen before a second load l2 then l2cannot read from s1.
figure exemplifies this rule.
this is correct because l2reading from s1would mean s1 takes effect after s2thus preventing l1from reading s1.
.
soundness and incompleteness when deciding the feasibility of an interference combination our analysis is designed to be sound but incomplete.
by sound we mean it permits all possible program behaviors allowed by a memory model.
therefore if it says a certain interference combination isinfeasible it must be infeasible.
however there is no guarantee every infeasible interference combination will be found.
incompleteness is expected the intent is a quick pruning of infeasible combinations before the computationally expensive threadlevel analysis.
the overhead of insisting on completeness would outweigh its benefit the feasibility checking problem in the worst case is as hard as program verification itself which is undecidable.
now we formally state the soundness of our deductive procedure.
first our deduction of the noreorder relation relaxing the program order requirement from figure is sound.
theorem .
.
lets1ands2be two instructions in the same thread.
if our rules deduce s1 s2 noreorder then the reordering of s1 ands2is not allowed by the corresponding memory model.
the proof of this theorem is straightforward since our inference rules for deducing noreorder directly follow the memory model semantics provided by adve and gharachorloo in figure .
next we note that given the readsfrom relation the deduction of the mustnotreadfrom relation is also sound.
theorem .
.
letlandsbe two instructions.
if our rules deduce to l s mustnotreadfrom then lcannot read from s. the proof of this theorem is straightforward it amounts to proofs of rules .
during the previous presentation we have argued why each rule is correct.
more formal proofs can be obtained via proof by contradiction which is straightforward.
we omit the details for brevity.
.
relaxing the write atomicity requirement our method soundly models buffer forwarding which corresponds to the write atomicity requirement column figure .
this allows a thread to read its own write before the written value is flushed to the memory thus becoming visible to other threads.
this is modeled in both the thread level analyzer analyzeseq and the deduction rules.
analyzeseq captures the relaxation for free.
during this analysis each thread is treated as a sequential program all loads read their values from the preceding writes within the same thread.
the deduction rules for noreorder section .
always permit the reordering of a store with a subsequent load of the same variable column figure .
that is if s1 v1 isstore and s2 v1 isload we do not deduce s1 s2 noreorder due to buffer forwarding even though it is counter intuitive .
within a thread t it may appear to be the case that the store and load are reordered from the perspective of all threads t t. forbidding this reordering would be equivalent to forcing a full flush of the store buffers before every load thus prohibiting any thread from reading its own store earlier than other threads.
void thread1 x s1 a x s2 b y s3 void thread2 y s4 fence s5 c x s6 assert !
a b c figure write atomicity example under tso.
figure exemplifies the requirement of this relaxation.
first the assertion may be violated under tso.
an error trace is x a b y flush y c flush x .
to permitthis trace we must allow the following interference combination s2reads from s1 s3reads from the initial value and s6reads from the initial value .
this combination is feasible only when we avoid enforcing the program order between s1ands2.
specifically the statements in thread follow program order s4 s5 s6 from the fence.
in thread s2ands3are ordered since they are added to noreorder under tso.
but statements s1ands2are not added to noreorder thus preventing the assertion from being incorrectly verified.
the thread modular analysis next we present the integration of our interference analysis section with a thread modular analyzer.
the thread modular analyzer itself is standard whose full details may be found in several prior works including and .
thus our presentation of the analyzer itself will be terse.
instead we shall focus on our main contribution which is adding the capability of deducing infeasible interference combinations for weak memory models our method is sound for not only sc but also tso pso and rmo.
prior techniques were either mm oblivious or sound only for sc.
given a load lofv the interferences onl within the threadmodular analysis are the environments after all stores to vfrom other threads.
the function n g takes a graph as input and returns the nodes of the graph.
the interferences on the loads in a thread gis the least fixed point of the function interfs .
interfs g m i l7 e i l where eis the environment after a remote store s n g to the same variable as loaded by load l n g interfs g m lfp interfs g m i we use interfs g m i as shorthand for interfs g m i where interfs g m is a partially applied function and use i as the initial map from loads to interfering environments i.e.
one mapping all nodes to .lfpcomputes the least fixed point.
interfs depends on the existence of m a map from each program location in all threads to an environment.
we show shortly that the computation ofmand the interferences is done in a nested fixed point.
we refer to an interference combination ic n7 s as a map from a load lto the memory environment after a store instruction from which lreads.
this differs slightly from the definition of section where it is defined as a set of load stores pairs.
the two can be easily converted as the analysis keeps track of all the environments associated with each store.
given the set of interferences ifrom interfs the set of all interference combinations are all permutations of selecting a single environment from ifor each load.
the iterative thread modular analysis separately considers each interference combination thus increasing accuracy.
thethread analyzer adapts the sequential analyzer analyzeseq section to use interference combinations.
analyzetm takes a thread gand an interference combination icand computes the input environment efor some node ningby joining the environment after the predecessors of nwith n s environment in ic denoted ic n .
then eis passed to n s transfer function to update m n .
analyzetm g ic m n7 tfunc n e where e n n t g m n ic n analyzetm g ic lfp analyzetm g ic m analyzetm is the least fixed point of analyzetm .t g returns the transition relation of a graph.
m is the initial memory map mapping the entry nodes of each thread to and all others to .
given a set of threads gsand a set of interference combinations i applying analyzetm to each g gsand each ic icomputes the analysis over all threads.
what remains is to show how the thread analyzer and the calculation of interferences can be done simultaneously since they are dependent the interference computation depends on the analysis result m and the analysis result depends on the set of interferences i. the solution is a nested fixed point the outer computation produces m and the inner computation produces i. the process iterates until m and thus i reach a fixed point.
analyze g m m where i interfs g m i filterfeasible i m joinmm map analyzetm g i analyzeall gs m joinmm map analyze m gs analyzeall gs lfp analyzeall gs m analyze operates as follows first it takes m the current analysis results over all threads and computes the interferences i wrt the thread under test g. the function filterfeasible integrates the thread level analyzer with the feasibility analysis of section .
it expands the interferences iinto a set of interference combinations i and filters any infeasible combination.
specifically given the interferences on a thread i l17 e1 e2 .
.
.
l27 e3 e4 .
.
.
.
.
.
filterfeasible creates all combinations of pairing each load to a single interfering environment e.g.
ie l1 e1 l2 e3 .
.
.
l1 e2 l2 e3 .
.
.
.
.
.
.
then it maps each environment in ieto the associated store generating the environment e.g.
is l1 s1 l2 s3 .
.
.
.
each set of pairs of load and store statements in isis then passed to the deduction analysis of section .
if it is infeasible it is discarded otherwise it is added to the set i returned by filterfeasible .
map analyzetm g i n7 s is the set of the results of applying analyzetm g i for each i i .
specifically map a b 2a 2btakes a function fand a set s and returns a set containing the application of fon each element of s. joinmm n7 s n7 s takes the join of memory environments on matching nodes across a set of maps to join them into a single map.
similarly analyzeall joins the results of applying analyze to the set gsof threads.
analyzeall computes the fixed point of analyzeall starting with the initial map m .
the following is a high level example.
initially each thread gis analyzed in the presence of m resulting in the set of interferences i being empty all stores map to .
the results of analyzing each thread are merged into a new map m. each thread is then analyzed using m resulting in the sets iandi to be potentially non empty causing analyzetm to be called once per combination.
within a thread the results of analyzetm are joined then across threads the results of analyze are joined creating m .
the procedure repeats thus growing the size of m i and i until m m .
we handle loops the same way as in prior techniques e.g.
.
given a load lwithin a loop the previously described analysis can generate an infinite number of interference combinations for l e.g.
when lis within an infinite loop.
loops are unrolled when possible and when not we join all the feasible interfering memoryenvironments into a single value.
an interfering environment eis infeasible to interfere on lif the store generating emust happen after l otherwise it is feasible.
this is sound for verifying assertions embedded in a concurrent program .
experiments we implemented our weak memory aware abstract interpreter in a tool named fruittree building upon open source platforms such as llvm apron and z .
specifically we use llvm to translate c programs into llvm bit code based on which we perform static analysis.
we use the apron library to manipulate abstract domains in the thread analyzer.
we use the z fixed point engine in z3 to solve datalog constraints that encode the feasibility of interference combinations.
we implemented the state of the art mm oblivious abstract interpretation method of min and the sc specific method watts on the same platform to facilitate experimental evaluation.
we also compared against a previously implemented version ofduet .
while duet may be unsound and watts is unsound we include their results because they are closely related to our new technique.
all methods implemented in fruittree use the clustering and property directed optimizations where clustering considers interferences only within sets of loads similar to the packing of relational domains and property direction filters interference combinations unrelated to properties under test.
these optimizations reduce the number of interference combinations which is crucial since it grows exponentially with respect to program s size.
we evaluated fruittree on a large set of programs written using the posix threads.
these benchmarks fall into two categories.
the first are litmus tests exposing non sc behaviors under various processor level memory models .
the second are larger applications including several linux device drivers.
the benchmarks total lines of code.
the properties under verification are assertions embedded in the program s source code a property is valid if and only if the assertion holds over all executions under a given memory model.
our experiments were designed to answer the following research questions is our new method more effective than prior techniques in obtaining correctness proofs on relaxed memory?
is our new method more accurate than prior techniques in detecting potential violations on relaxed memory?
is our new method reasonably efficient when used as a static program analysis technique?
we conducted all experiments on a linux computer with gb ram and a .
ghz cpu.
.
litmus test results first we present the litmus test results.
since these programs are small in terms of code size all methods under evaluation min watts duet and fruittree finished quickly.
thus our focus is not on comparing the runtime performance but comparing the accuracy of their results.
specifically we compare our method to these state of the art techniques in terms of the number of true proofs bogus proofs true alarms and bogus alarms.
here a bogus alarm is a valid property which cannot be proved.
a bogus proof is a property which may be violated yet is unsoundly and incorrectly proved.
the litmus tests are particularly useful not only because they cover corner cases but also because we know a priori if a property holds or not.table results on the litmus test programs under tso.
method true alarm bogus alarm true proof bogus proof time s min .
duet .
watts .
fruittree .
table summarizes the litmus test results under tso.
the first column shows the name of each method and the next four show the number of true alarms bogus alarms true proofs and bogus proofs generated by each method respectively.
since watts was designed to be sc specific it ignores non sc behaviors meaning its proofs are unsound under weaker memory marked by .
the last column is the total analysis time over all tests.
overall the results show the prior thread modular technique of min admits many infeasible executions thus leading to bogus alarms.
duet reported bogus alarms.
in contrast our method fruittree reported only bogus alarms together with true proofs.
therefore it is more accurate than these prior techniques.
although watts reported only bogus alarms it is unsound for tso it only considers sc behaviors and cannot be trusted.
furthermore the soundness of duet under tso or any other nonsc memory model was not clear since duet was only designed for sc .
thus in the result table its proofs are marked with .
table results on the litmus test programs under pso.
method true alarm bogus alarm true proof bogus proof time s min .
duet .
watts .
fruittree .
table summarizes the results under pso.
again watts may be unsound for weak memory.
the same litmus programs were used under pso as in tso but the properties changed i.e.
whether an alarm is true or bogus.
note that min only verified properties duet verified whereas our method verified .
table results on the litmus test programs under rmo.
method true alarm bogus alarm true proof bogus proof time s min .
duet .
watts .
fruittree .
table summarizes the results under rmo.
under rmo a different set of litmus programs were used since the instruction set for processors using rmo differs from tso and pso.
nevertheless we observed similar results fruittree obtained significantly more true proofs and fewer bogus alarms than the other methods.
in general our method was more accurate than prior techniques.
however since the analysis is over approximated it does not eliminate all bogus alarms.
currently most bogus alarms reported by fruittree require reasoning across more than two threads e.g.
the correctness of a property may require reasoning that thread t1 reading x 1from thread t2impliesy 1in thread t3.
since our method is thread modular threads are analyzed individually byabstracting all other threads into a set of interferences it cannot capture ordering constraints involving more than two threads.
in principle this limitation can be lifted by extending our interference feasibility analysis we leave this as future work.
.
results on larger applications next we present our results on the larger benchmark programs.
since execution time is no longer negligible we compare across methods both the run time and accuracy.
however since the programs are larger 60k lines of code and there are far too many properties to manually inspecting each case we do not report the number of bogus alarms and bogus proofs due to lack of the ground truth.
instead we compare the total number of proofs reported by each method to show our method is more accurate even though all methods are approximate.
table shows our results under tso where and mark the unsoundly verified properties.
since the results for pso and rmo are similar to table we omit them for brevity.
column of this table shows the name of the benchmark program.
columns and show the run time and number of properties verified by min duet watts and fruittree respectively.
again while the proofs reported by fruittree and min s method are sound the proofs reported by watts are not and the soundness of duet on weak memory is unclear.
overall fruittree proved properties compared to only proved by min an increase of .7x more properties relative to prior state of the art.
additionally though duet may be unsound it proved only properties.
the definitely unsound watts proved properties possibly including bogus proofs.
in terms of the run time fruittree took seconds which is similar to watts and slower than duet and min .
however the additional time is well justified due to the significant increase in the number of proofs.
furthermore the runtime performance proving property per second remains competitive as a static analysis technique.
to summarize our new method has modest runtime overhead compared to prior techniques but vastly improved accuracy in terms of the analysis results and is provably sound in handling not only sc but also three other processor level memory models.
related work we reviewed prior work on thread modular abstract interpretation which are either mm oblivious or sc specific in processor memory models.
there are also techniques that are not thread modular.
there are code transformation techniques that transform a non sc program into an sc program and then apply abstract interpretation.
they generally follow the sequentialization approach pioneered by lal and reps with a focus on code transformation as opposed to abstract interpretation.
to ensure termination they make various assumptions to bound the program s behavior.
furthermore they are not thread modular and often do not directly handle c code.
instead they admit only models of concurrent programs written in artificial languages because of this we were not able to perform a direct experimental comparison.
in the context of bounded model checking alglave et al.
proposed several methods for concurrent software on relaxed memory.
they are based on either sequentializing concurrent programs or encoding weak memory semantics using sat smt solvers .table results on larger applications total of loc .
min duet watts fruittree name time verif time verif time verif time verif thread00 .
.
.
.
threadcreate01 .
.
.
.
threadcreate02 .
.
.
.
sync 01 true .
.
.
.
sync 02 true .
.
.
.
intra01 .
.
.
.
dekker1 .
.
.
.
fk2012 v2 .
.
.
.
keybisr .
.
.
.
ib700wdt 01 .
.
.
.
ib700wdt 02 .
.
.
.
ib700wdt 03 .
.
.
.
i8xx tco 01 .
.
.
.
i8xx tco 02 .
.
.
.
i8xx tco 03 .
.
.
.
machzwd 01 .
.
.
.
machzwd 02 .
.
.
.
machzwd 03 .
.
.
.
mixcomwd 01 .
.
.
.
mixcomwd 02 .
.
.
.
mixcomwd 03 .
.
.
.
pcwd 01 .
.
.
.
pcwd 02 .
.
.
.
pcwd 03 .
.
.
.
pcwd 04 .
.
.
.
sbc60xxwdt 01 .
.
.
.
sbc60xxwdt 02 .
.
.
.
sbc60xxwdt 03 .
.
.
.
sc1200wdt 01 .
.
.
.
sc1200wdt 02 .
.
.
.
sc1200wdt 03 .
.
.
.
smsc37b787wdt 01 .
.
.
.
smsc37b787wdt 02 .
.
.
.
smsc37b787wdt 03 .
.
.
.
sc520wdt 01 .
.
.
.
sc520wdt 02 .
.
.
.
sc520wdt 03 .
.
.
.
w83877fwdt 01 .
.
.
.
w83877fwdt 02 .
.
.
.
w83877fwdt 03 .
.
.
.
wdt01 .
.
.
.
wdt02 .
.
.
.
wdt03 .
.
.
.
wdt977 01 .
.
.
.
wdt977 02 .
.
.
.
wdt977 03 .
.
.
.
wdt pci01 .
.
.
.
wdt pci02 .
.
.
.
wdt pci03 .
.
.
.
pcwd pci 01 .
.
.
.
pcwd pci 02 .
.
.
.
pcwd pci 03 .
.
.
.
total s s s s alglave et al.
also developed techniques for modeling and testing weak memory semantics of real processors and characterized the memory models of some gpus .
however these techniques are primarily for detecting buggy behaviors as opposed to proving that such behaviors do not exist.
in the context of systematic testing often based on stateless model checking or predictive analysis a number of methods have been proposed to handle weak memory such as tso pso powerpc and c .
however since they rely on concretely executing the program and require the user to provide test inputs they can only be used to detect bugs.
that is since testing does not cover all program behaviors if no bug is detected these methods cannot obtain a correctness proof.
in contrast our method is based on abstractinterpretation which covers all possible program behaviors and therefore is geared toward obtaining correctness proofs.
thread modular analysis was also used in model checking where it was combined with predicate abstraction to help mitigate state explosion and thus increase the scalability.
however model checking is significantly different from abstract interpretation in that each thread must be first abstracted into a finite state model.
thread modular analysis was also used to conduct shape analysis and prove thread termination .
hoenicke et al.
introduced a hierarchy of proof systems that leverage thread modularity in compositional verification on sc memory.
similar to the interference analysis in watts we check the feasibility of thread interactions using datalog.
datalog based declarative program analysis was a framework introduced by whaley and lam .
previously it has been used to implement pointsto dependency and change impact analyses uncover security bugs and detect data races .
in abstract interpretation of sequential programs min proposed a technique for abstracting the global memory into a set of byte level cells to support a variety of casts and union types.
ferrara et al.
integrated heap abstraction and numerical abstraction during static analysis where the heap is represented as disjunctions of points to constraints based on values.
jeannet and serwe also proposed a method for abstracting the data and control portions of a call stack for analyzing sequential programs with potentially infinite recursion.
subsequently jeannet extended the work to handle concurrent programs as well.
however none of these methods was designed specifically for handling weak memory models.
conclusions we have presented a thread modular static analysis method for concurrent programs under weak memory models building upon a lightweight constraint system for quickly identifying the infeasibility of thread interference combinations so they are skipped during the expensive abstract interpretation based analysis.
the constraint system is also general enough to handle a range of processor level memory models.
we have implemented the method and conducted experiments on a large number of benchmark programs.
we showed the new method significantly outperformed three state of the art techniques in terms of accuracy while maintaining only a moderate runtime overhead.