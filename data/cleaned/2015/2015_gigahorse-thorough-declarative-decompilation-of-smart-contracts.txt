gigahorse thorough declarative decompilation of smart contracts neville grech university of athens and university of malta greece and malta me nevillegrech.comlexi brent the university of sydney australia lexi.brent sydney.edu.aubernhard scholz the university of sydney australia bernhard.scholz sydney.edu.auyannis smaragdakis university of athens greece yannis smaragd.org abstract the rise of smart contracts autonomous applications running on blockchains has led to a growing number of threats necessitating sophisticated program analysis.
however smart contracts which transact valuable tokens and cryptocur rencies are compiled to very low level bytecode.
this bytecode isthe ultimate semantics and means of enforcement of the contract.
we present the gigahorse toolchain.
at its core is a reverse compiler i.e.
a decompiler that decompiles smart contractsfrom ethereum virtual machine evm bytecode into a high level address code representation.
the new intermediate rep resentation of smart contracts makes implicit data and control flow dependencies of the evm bytecode explicit.
decompilationobviates the need for a contract s source and allows the analysisof both new and deployed contracts.
gigahorse advances the state of the art on several fronts.
it gives the highest analysis precision and completeness amongdecompilers for ethereum smart contracts e.g.
gigahorse candecompile over .
of deployed contracts compared to for the recently published vandal decompiler and under for the state of the practice porosity decompiler.
importantly gigahorse offers a full featured toolchain for further analyses and a batteries included approach with multiple clientsalready implemented together with the highest performanceand scalability.
key to these improvements is gigahorse s use ofa declarative logic based specification which allows high levelinsights to inform low level decompilation.
index t erms ethereum blockchain decompilation program analysis security i. i ntroduction distributed blockchain platforms have captured the imagination of scientists and the public alike.
blockchain technology offers decentralized consensus mechanisms for any transac tions that in the past would have required a trusted central ized authority.
one of the most evident embodiments of thisvision is the development of smart contracts turing complete autonomous agents that run on distributed blockchains suchas ethereum or cardano.
a smart contract may for instance implement a lending policy a charging scheme for digitalgoods an auction the full set of operations of a bank andvirtually any other logic governing multi party transactions.
ethereum is the best known most popular blockchain platform that supports full featured smart contracts.
as of thiswriting the ethereum cryptocurrency market capitalizationis 13b.
ethereum offers an excellent demonstration ofthe potential for smart contracts as well as their technicalchallenges.
developers typically write smart contracts in ahigh level language called solidity which is compiled intoimmutable low level ethereum vm evm bytecode for theblockchain s distributed virtual machine.
the open nature of smart contracts as well as their role in handling high value currency raise the need for thorough con tract analysis and validation.
this task is hindered however bythe low level stack based design of the evm bytecode that hashardly any abstractions as found as in other languages suchas java s virtual machine.
for example there is no notion offunctions or calls a compiler that translates to evm bytecodeneeds to invent its own conventions for implementing localcalls over the stack.
it is telling that recent research has focused on decompiling smart contracts into a higher levelrepresentation before applying any further usually security oriented analysis.
past decompilation efforts have been atbest incomplete.
the best known decompiler largely definingthe state of the practice is porosity which in our studyfails to yield results for of deployed contracts of allsmart contracts on the block chain.
upcoming research toolsincluding the v andal decompiler still fail to decompile asignificant portion of real contracts around due to thecomplex task of converting evm s stack based operations toa register based intermediate representation.
such difficulties are much more than technicalities of the platform or idiosyncrasies of existing tools.
any current orfuture smart contract platform is likely to employ virtualmachines that are low level.
the designs of these virtualmachines are optimized for massively replicated execution ofsmart contracts.
the bytecode effectively represents an as sembly language designed for efficient execution and compactprogram representation since the bytecode must be stored onthe blockchain.
hence the bytecode for smart contracts willnever be optimal for human readability or reverse compilation.
for effective decompilation significant program comprehension of the bytecode is necessary.
a decompiler requiresdeep program understanding before it can reconstruct the bytecode to a high level representation.
for instance to recog nize which low level jumps correspond to high level functioncalls a decompiler must deduce possible addresses for jumpinstructions to be able to reconstruct the control flow of asmart contract.
such understanding is compounding once callsare recognized as calls and not just as a mere intra proceduraljump its decompilation precision can further improve bypruning impossible targets.
ieee acm 41st international conference on software engineering icse .
ieee authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
in this paper we introduce the gigahorse toolchain for analysis of ethereum smart contracts.
gigahorse addresses the above challenges making the following contributions it offers a highly effective decompiler yielding higher precision and completeness than the state of the art e.g.
decompiling virtually all existing contracts on the ethereum blockchain .
gigahorse anchors around it a full featured tool suite offering libraries for building analyses as well as readymade clients for existing analyses.
the gigahorse approach provides new decompilation insights possibly of value for many more platforms as higher level program features are discovered they feed back to lower level analyses.
e.g.
by discovering functions stack analyses are performed locally more precisely and the effects of function calls on the stack are also summarized enabling both more precise and more scalable analysis.
gigahorse showcases an unconventional decompilation approach which enables the above benefits the decompiler is specified declaratively using logic based datalog rules.
gigahorse is evaluated and its features illustrated on the full set of smart contracts of the ethereum blockchain.
gigahorse is powering the ongoing free contract library service which offers decompiled versions of all contracts on the ethereum blockchain.
contract library is a valuable service for ethereum security analysts and is currently receiving several tens of unique visitors and over a thousand page views per day.
ii.
b ackground we next present some background on the evm bytecode language and declarative static analysis.
a. low level bytecode in the ethereum blockchain the evm is a stack based low level intermediate representation ir .
in the bytecode form of a smart contract symbolic information has been replaced by numeric constants functions are fused together in a sea of instructions and control flow is obfuscated by jump addresses that are popped from the stack.
to highlight this issue it is instructive to compare the evm bytecode language to the best known bytecode java jvm bytecode a much higher level ir.
the differences include unlike jvm bytecode evm does not have the notion of structs or objects nor does it have a concept of methods.
java bytecode has a rich type system evm bytecode has a single type a 256bit word.
in jvm bytecode stack depth is fixed under different control flow paths execution cannot reach the same program point with different stack sizes.
in the evm bytecode no such execution constraints exist which make the identification of standard control flow constructs very hard.
all control flow edges i.e.
jumps are to variables not constants.
the destination of a jump is a value that is read from the stack.
therefore a value flow analysis is necessary even to determine the connectivity of basic blocks.
in contrast jvm bytecode has a clearly defined set of targets for every jump independent of value flow.
jvm bytecode has defined method invocation and return instructions.
in evm bytecode although calls to outside a smart contract can be resolved function calls inside a contract are translated to just jumps to variable destinations per the above point .
all functions of a contract are fused in one stream of instructions with low level jumps as the means to transfer control.
to call an intra contract function the code pushes a return address to the stack pushes arguments pushes the destination block s identifier a hash and performs a jump which pops the top stack element to use it as a jump destination .
to return the code pops the caller s basic block identifier from the stack and jumps to it.
b. declarative program analysis our work is based on declarative static program analysis applied to smart contract decompilation.
declarativeness refers to implementing an analysis as a collection of logical rules i.e.
simple implications that lead to inferences which in turn trigger more rule inferences up to the least fixpoint.
the datalog language is the most standard vehicle for declarative analysis approaches both low level and high level .
additionally datalogstyle inference rules have been used in formal specification tasks such as the official specification of the java vm verifier .
datalog is less of a programming language and more of a specification language since computation is based on two constructs logical implication rules and recursion.
a datalog rule c z x a x y b y z .
means that if a x y and b y z are both true for some values x y z then c z x can be inferred.
syntactically the left arrow symbol is a logical implication symbol and separates the inferred facts i.e.
the head of the rule from the previously established facts i.e.
the body of the rule .
recursion is the standard vehicle for expressing computations in datalog.
static analysis tasks are typically recursive with multiple sub algorithms collaborating towards a joint goal expressing the semantics of a program.
the sub algorithms have no clear stepwise order but instead all refer to yetincomplete results of other sub algorithm in a large recursive definition.
in this way the sub algorithms enhance each other s results each benefiting the others.
the declarative nature of the datalog language means that any order of firing of the rules and any order of evaluation of a rule s body will yield the same final result.
to maintain this property the implication in datalog has to be strictly monotonic each rule s firing can only introduce new facts and not hinder any of the previous inferences.
part of the appeal of the datalog language is that it currently enjoys several high performance implementations including souffl e .
besides high performance computation state ofthe art datalog engines offer extensions to the language expressiveness one can relax pure declarativeness and introduce ordering as well as invent new values via constructor functions.
we will refer to such non purely declarative facilities explicitly in our technical presentation.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
iii.
g igahorse decompila tion specifica tion in this section we present the core building blocks of the gigahorse decompiler.
we use datalog as a specification language for the decompiler.
the datalog rules are simplified but keep the essential complexity of their counterparts in the actual gigahorse implementation.
we attempt to provide as much technical detail as possible without sacrificing the readability and understandability of this paper.
in this effort the exposition will be uneven we give in depth details in the first few sub sections and elide technical details in later parts of both sections iii and iv when the reader will be able to fill the gaps.
a. overview of decompilation steps we next summarize the main decompilation actions performed by the gigahorse decompiler.
for the sake of exposition we describe a conceptual stepwise process even though the decompiler specification is declarative and does not have an explicit order of operations.
starting from the original bytecode the gigahorse decompiler finds basic block boundaries.
the output to the next step is the original bytecode split by basic blocks.
performs local analysis of stack effects of basic blocks.
the input of the next step attaches to the bytecode relevant summaries of stack effects per block.
performs whole contract context and flow sensitive dataflow analysis with on the fly control flow graph cfg construction.
this information is used to produce a address ir with global registers.
we refer to this ir asglobal address ir .
infers function boundaries heuristically i.e.
entry and exit blocks together with function calls for public and private functions.
the function boundaries enable the decompiler to transform the global cfg into local cfgs and a call graph.
infers function arguments and return arguments for all functions introduces fresh variables for these and performs an intra procedural flow sensitive analysis to infer the flow of these fresh variables.
the output form is afunctional address ir i.e.
all variables are local variables and are scoped.
data is passed around functions through formal arguments return arguments or external constructs like storage and memory.
all the above steps work in concert to derive a high level representation from the original bytecode.
in this section we focus on steps and and assume that the input is already parsed as statements in basic blocks step .
section iv focuses on steps and .
the original bytecode and our two irs the global address ir and the functional address ir have common elements but also differ in important ways.
throughout the descriptions of these we will override certain concepts such as statements or variables.
for instance variables in the global address ir are global variables whereas for the functional address ir they are all local.
the distinction between these should be clear from context.sis a set of statement identifiers s z cis a set of constants c z vis a set of new variables bis a set of basic block identifiers iis a set of stack indices from to push s s v a l c binop s s dup s s pop s s jumpdest s s jumpi s s next p r e v s n e x t s block stmt s block b block head block b stmt s block tail block b stmt s pushes andpops sorb s b pushes n pops n local defines stmt s var v local stack out stmt s index i vori v i local stack in s t m t s n i vori v i variable value var v val c newfresh var s t m t s n n variable v fig.
.
our domain input relations representing the original bytecode computed relations and outputs.
the input relations encode program instructions and other environment information.
b. input language figure describes the schema of the input and main intermediate relations together with the domains of the program representation at this level of abstraction.
stack indices iby definition are between and and we assume that all arithmetic operations on iare only defined in that range i.e.
no overflow or underflows .
notice that the original bytecode relations such as push or binop make no