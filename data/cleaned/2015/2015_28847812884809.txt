termination checking for llvm peephole optimizations david menendez department of computer science rutgers university davemm cs.rutgers.edusantosh nagarakatte department of computer science rutgers university santosh.nagarakatte cs.rutgers.edu abstract mainstream compilers contain a large number of peephole optimizations which perform algebraic simplification of the input program with local rewriting of the code.
these optimizations are a persistent source of bugs.
our recent research on alive a domainspecific language for expressing peephole optimizations in llvm addresses a part of the problem by automatically verifying the correctness of these optimizations and generating c code for use with llvm.
this paper identifies a class of non termination bugs that arise when a suite of peephole optimizations is executed until a fixed point.
an optimization can undo the effect of another optimization in the suite which results in non terminating compilation.
this paper proposes a methodology to detect non termination bugs with a suite of peephole optimizations identifies the necessary condition to ensure termination while composing peephole optimizations and provides debugging support by generating concrete input programs that cause non terminating compilation.
we have discovered optimization sequences involving optimizations that cause non terminating compilation in llvm with alive generated c code.
categories and subject descriptors d. .
software program verification d. .
processors compilers f. .
specifying and verifying and reasoning about programs keywords compiler verification peephole optimization alive termination .
introduction compilers translate source programs to multiple target architectures while preserving semantics.
modern compilers are complex because they perform numerous optimizations to obtain the best possible performance on modern architectures.
among them permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
copyrights for components of this work owned by others than acm must be honored.
abstracting with credit is permitted.
to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
request permissions from permissions acm.org.
icse may austin tx usa c acm.
isbn .
.
.
.
optimizations perform algebraic simplification with local rewriting of the input code.
peephole optimizations clean up code resulting from other optimizations and also canonicalize code which enables other optimizations.
the llvm compiler s main peephole optimization pass instcombine contains over a thousand optimizations.
typically the compiler developer observes a pattern that the compiler fails to optimize and adds a peephole optimization to handle it.
once the new optimization is added to the compiler the developer runs the regression test suites to ensure correctness.
unsurprisingly peephole optimizations are a common source of compiler bugs .
these bugs typically occur in corner cases especially in the presence of undefined behavior.
to address this problem of creating correct peephole optimizations we have developed alive a domain specific language for specifying peephole optimizations in llvm .
an alive optimization has the form source target with an optional precondition.
the optimization checks the input code for a pattern of the form source and replaces it with the target .
optimizations expressed in alive are automatically checked for correctness using a satisfiability modulo theory smt solver.
alive provides concrete counterexamples when verification fails which enables the compiler developer to fix the error.
further the alive framework generates c code for use within the llvm compiler to provide competitive compilation time while ensuring consistency of the specification and the implementation.
alive has already detected bugs in existing instcombine optimizations .
there is active interest to replace the instcombine pass with alive generated c code.
this paper describes a new class of non termination bugs with peephole optimizations discovered while translating instcombine optimizations in llvm to alive.
the llvm compiler runs a suite of instcombine optimizations multiple times until a fixed point.
figure provides a high level overview of the execution of instcombine optimizations.
we observed that certain instcombine optimizations can undo the effect of other instcombine optimizations which can result in non terminating compilation i.e.
the compiler hangs .
when iteratively applying hundreds of optimizations it is important to consider how they may interact.
a developer adding a new optimization cannot be certain of its interaction with existing optimizations without a global view of llvm s instcombine optimizations.
hence a non termination bug may be undetected for years until some unfortunate programmer discovers it.
further they manifest only when appropriate input code is provided for compilation.
this paper proposes a methodology to identify compiler nontermination bugs by extending alive to provide a global view of instcombine optimizations in llvm.
our approach explores sequences of optimizations from the alive suite to see whether they ieee acm 38th ieee international conference on software engineering function instcombine function f repeat add reachable instructions in ftoworklist remove unreachable blocks from f for alli2worklist do iftryopt1 imatchessource opt then add alli2target opt toworklist replaceiwithroot target opt else if tryopt2 imatchessource opt then add alli2target opt toworklist replaceiwithroot target opt else if tryopt3 imatchessource opt then add alli2target opt toworklist replaceiwithroot target opt end if end for until no changes made end function figure high level view of instcombine where opt1 opt2 opt3 and other optimizations are tried in order.
the root of the directed acyclic graph is represented as root .
can have bad interactions that cause non termination bugs when run until a fixed point.
figure illustrates the methodology for detecting compiler non termination bugs in instcombine which is based on composition of sequences of alive optimizations.
the composition of two optimizations is a new optimization that has the effect of applying the two optimizations to an input program one after the other.
our methodology enumerates all possible sequences of a given length.
for each sequence we determine if it is feasible to compose the sequence of optimizations into a single optimization that summarizes the sequence.
as we are specifically interested in the case where subsequent optimizations are enabled by previous ones we only consider cases where the source of a subsequent optimization matches at least one instruction created by the target of a previous optimization.
next we determine if the composed optimization can result in non termination.
the composition itself may be infeasible with some sequences.
even when the composition is feasible the precondition of the composed optimization of a sequence may not be satisfiable.
such sequences cannot cause compiler non termination for any input program.
when the optimization composes with itself with a satisfiable precondition the optimization can be applied infinitely many times when the self composition of the optimization consumes a source program no larger than original optimization see figure for an illustrative example .
hence the necessary conditions for non termination are the precondition of the selfcomposition is satisfiable and the length of the source of the self composition is smaller than or equal to the source of the original optimization.
for example let o1o2o3be an optimization sequence where o1 o2 ando3are individual peephole optimizations in the alive suite.
the composition phase generates a single optimization oz that summarizes o1o2o3.
the non termination checker checks if the precondition of ozozis satisfiable and the number of instructions in the source of ozozis smaller or equal to the number of instructions in the source of oz.
if both the conditions are satisfied the checker reports that the optimization sequence o1o2o3 causes compiler non termination.
when an optimization sequence can cause non termination the tool also generates a concrete input to aid debugging.
we have discovered optimization sequences involving optimizations that cause compiler non termination errors in alive s suite of inst combine optimizations.
we have demonstrated that these optimization sequences cause the generated c code for instcombine to loop indefinitely.
contributions.
this paper identifies a new class of compiler non termination bugs resulting from the lack of a global view of peephole optimizations in llvm.
proposes a methodology to detect compiler non termination bugs building on top of alive which checks the correctness of each individual instcombine transformation.
identifies non increasing source in the self composition of a sequence of optimizations as the necessary condition for non termination.
proposes a technique to generate concrete inputs to demonstrate non termination errors to aid debugging.
next we provide a brief background on alive because we build our termination checker on top of alive.
.
background on alive alive is a language for specifying peephole optimizations for llvm.
the alive interpreter automatically checks the correctness of the optimization using a smt solver and generates c code that implements the optimization for use in llvm.
alive syntax is similar to the llvm ir because the intended users of alive llvm developers are already familiar with it.
in contrast to the llvm ir alive optimizations are parametric over types and bit widths.
hence the alive interpreter checks the correctness of the optimization for all feasible types and bit widths up to a certain bound .
alive abstracts the various kinds of undefined behavior while the interpreter reasons about them during verification.
figure illustrates the process of verifying and generating c code with the alive.
.
instcombine optimizations in alive alive optimizations have the form source target with an optional precondition.
an alive optimization replaces the root of a directed acyclic graph dag of instructions in the source with the root of a new directed acyclic graph in the target.
hence the source dag and the target dag must have the same root variable r .
an example alive optimization is given below.
pre c2 c1 w or p c2 x xor w c1 y add x r add y q a and p c1 r sub q a in the optimization above the dag rooted at rin the source is replaced with the dag in the target when the precondition is satisfied i.e.
c2 c1 where c1andc2are symbolic constants .
in general alive preconditions consist of built in predicates equalities and signed unsigned inequalities.
the predicates in alive are used to represent the results of llvm s dataflow analyses.
the instructions in alive are similar to instructions in the llvm ir.
the variables in alive other than the root are either input variables or temporary variables generated in the source and target.
an 192precondition satisfiable loop sustainablea sequence of k optimizationscandidate optimization sequence generatoroptimization sequence compositorfeasibility and self loop checkerconcrete example generator cycle length k a suite of peephole optimizationscomposabletest case optimization sequence causing compiler nontermination self loop infeasible not composablefigure workflow of our termination checking algorithm.
alive z3 llvmsmt queries analysis c instcombine passalive dsl figure the figure illustrates how the optimization in alive domain specific language dsl is checked for correctness by the alive interpreter with queries to the z3 smt solver.
on successful verification the alive interpreter generates the c code for use in llvm.
if the verification is unsuccessful it generates counter examples with concrete values to illustrate the error.
alive optimization can also have symbolic and literal constants in the source target and precondition.
constant expressions may occur in the target and precondition and can contain constants arithmetic and bitwise operators and common math based built in functions.
in the example above ris the root of the dag pand q are input variables c1andc2are symbolic constants and w x y and aare temporary variables.
the target may refer to instructions defined in the source redefine them or create new instructions.
when the target redefines an instruction used in the source it indicates that the target instruction will replace the corresponding instruction in the source.
the root instruction in the source of an alive optimization will always be replaced in the target.
alive provides abstraction over types.
hence a single optimization can apply to a wide range of types constrained by the instructions present in the source and target.
for example binary operators require their arguments and their result to be integers of the same bit width.
the compiler writer can optionally provide types in alive to reduce verification time.
types in alive are a subset of llvm s type system including integers of various bit widths pointer types array types and void.
alive automatically determines the type constraints implicit in an optimization and then checks the validity of the optimization for various assignments of types which meet those constraints.
undefined behavior.
most compiler bugs are a result of misunderstanding semantics especially regarding various kinds of undefined behavior .
alive s verification engine reasons about the correctness of optimizations in the presence of undefined behavior which eases the job of the compiler writer.
alive s semantics for instructions is based on the semantics of the llvm ir.
the semantics of an instruction specify when the instruction is well defined.
llvm optimizes the program with the assumption that the pro grammer never intends to have undefined behavior in the program.
llvm instructions have attributes that modify the behavior of the instruction .
examples of such attributes are nsw no signed wrap nuw no unsigned wrap and exact.
an arithmetic instruction with the no signed wrap attribute produces a poison value on signed overflows .
poison values produce undefined behavior when such values are used in instructions with side effects.
the poison value propagates along dependencies.
hence any instruction that receives a poison value as input will produce a poison value as output.
.
alive semantics for pattern matching statements in alive have slightly different semantics depending on whether they occur in the source or in the target.
instructions occurring in the source act as patterns indicating the minimum requirements for a given input to match the source.
in particular the presence of an instruction attribute e.g.
nsw in the source means that the attribute must be present in the input for the pattern to match but a pattern not containing an attribute will match an instruction with the attribute.
in contrast instructions occurring in the target act as code.
the attributes present in the target are exactly those which will be present in the output of an optimization.
.
correctness and generating c code given an optimization the alive interpreter uses an smt solver to help instantiate candidate types for the optimization.
the alive interpreter encodes the alive optimization with concrete types into first order logic formulae.
the validity of the formulae imply the correctness of the optimization.
the interpreter generates the following validity checks under the conditions that the source is welldefined and poison free and the precondition is satisfied the target is well defined the target is poison free and the roots of the source and target compute the same value.
these checks are performed for each feasible type instantiation.
when verification succeeds the alive interpreter generates c code for the optimization using llvm s patternmatch support .
automatic generation of c code for the optimization provides competitive compilation time and ensures consistency of the specification and the implementation.
next we will discuss how to detect non termination bugs in a suite of alive instcombine optimizations.
.
non termination detection alive verifies the correctness of each individual optimization.
even when all optimizations are individually correct a suite of them can cause a compiler to experience a non termination bug.
an optimization in the suite can undo the work of other optimizations.
when such optimizations are run until a fixed point the compiler will not terminate.
consider the two optimizations o 1ando2 shown in figure a and figure b which we will use to illus193pre true p1 xor w c1 r1 and p1 c2 q1 and w c2 r1 xor q1 c1 c2 c optimization o3 the composition of o1 and o2 a optimization o1 b optimization o2 pre true p2 and x y r2 xor p2 y q2 xor x r2 and q2 ypre c2 c1 c2 p1 xor x c1 r1 and p1 c2 q2 xor x r1 and q2 c2 d self composition of o3 with itself compose o3 o3 pre c2 c1 c2 c2 c2 p1 xor x c1 r1 and p1 c2 q2 xor x r1 and q2 c2 e precondition of compose o3 o3 is satisfiable.
the source of the optimization compose o3 o3 does not increase compared to optimization o3 hence this optimization results in non terminating compilationdefine i8 foo i8 x entry p1 xor i8 x r1 and i8 p1 ret i8 r1 f concrete input in llvm intermediate representation to demonstrate non terminationfigure an example illustrating the process of non termination detection.
the optimization sequence generated is o1o2where o1ando2 are optimizations shown in a and b respectively.
optimization o3shown in c is the composition of o1ando2.
the self composition i.e.
the composition of o3with itself is presented in d .
the source of the self composition of o3has the same length as the source of o3 and its precondition is satisfiable.
hence optimization sequence o1o2can result in compiler non termination with an appropriate input.
the test case generated for debugging is shown in f .
trate our technique for detecting compiler non termination.
both optimizations are individually correct as indicated by the alive verification engine.
however the compiler will not terminate when the two optimizations are executed until a fixed point.
when an llvm developer proposes a new optimization for the instcombine suite it is necessary to determine whether the newly proposed optimization can interfere with existing optimizations.
llvm instcombine which is a collection of c code does not have a global view that could be used to identify non termination bugs.
with alive being adopted by llvm developers for instcombine verification our strategy is to use the alive suite to provide a global view of existing peephole optimizations and check if existing optimizations or the newly proposed optimization can cause compiler non termination.
the optimizations in instcombine are attempted sequentially one after the other as shown in figure .
suppose the optimizations in instcombine are o1 o2 o3.
first the optimization o1is attempted.
if it is successful then the newly created instruction is added to the work list and the entire suite of optimizations is tried again as shown in figure .
if it is not possible to apply optimizationo1 then optimization o2is attempted as described earlier.
if optimization o3is applicable in a subset of the cases where optimization o1is applicable then o3will never be invoked due to this structure of instcombine optimizations.
we say that optimizationo1shadows optimization o3.
in the absence of shadowing detecting non termination in instcombine reduces to the following problem given a suite of instcombine optimizations where no optimization shadows another do optimization sequences that cause compiler non termination exist?
our general strategy to detect compiler non termination bugs in the alive suite consists of three steps.
first we generate sequences of optimizations up to a certain bound o 1o2is the optimization sequence in figure .
second we compose the optimizations in the sequence to generate a resultant optimization that summarizes the effect of running all the constituent optimizations on the input code one after the other see figure c .
third we compose the resultant optimization from the previous step with itself and check if it consumes a larger source pattern and if its precondition is satisfiable see figure d and figure e .
we describe each of these steps in the following subsections.
.
generating candidate sequences our goal is to determine whether there exists a sequence of optimizations that can be performed indefinitely.
given a suite of noptimizations the number of possible optimization sequences with each optimization used exactly once has an upper bound of o n!
.
the space of optimization sequences with repetition is even larger.
the candidate optimization sequence generation phase explores this large state space in a systematic fashion by iteratively enumerating all sequences up to a certain length i.e.
we explore sequences of length length and so on .
we restrict ourselves to sequences where each optimization appears at most once.
each sequence may give rise to zero or more compositions see section .
.
our approach checks whether the composition of the candidate sequence is feasible.
in practice we have to explore a large number of optimization sequences to find a feasible composition for cycle lengths greater than .
.
composition optimization composition is a key step in our procedure for detecting non termination.
when composing two optimizations o1 ando2 we attempt to see if o2will match the result of applying o1to some input.
therefore we treat the target of o1ascode and the source of o2as apattern as described in section .
.
because the code and the pattern may have multiple instructions the composition can potentially take place in more than one way.
we are interested specifically in cases where o1enables o2 so we require thato2match at least one instruction created by o1.
figure presents the algorithm for the simple case of root toroot compositions.
extending the algorithm to handle non root to root and root to non root compositions is straightforward we omit the details due to space considerations.
the composition algorithm first determines which values in the source of o2 the pattern must unify with the target of o1 the code which is accomplished by aligning their respective dags.
dag alignment results in sets of values that must be identical for the composition to be feasible.
the sets generated from dag alignment are checked to ensure that the sets are valid e.g.
an instruction and a constant cannot be in the same set .
finally a new optimization is created by expanding the source of o1and the target of o2with appropriate representatives from the dag alignment step.
figure illustrates composition of optimizations with dag alignment.
194pre true p1 xor w c1 r1 and p1 c2 q1 and w c2 r1 xor q1 c1 c2 pre true p2 and x y r2 xor p2 y q2 xor x r2 and q2 y pre c2 c1 c2 p1 xor x c1 r1 and p1 c2 q2 xor x r1 and q2 c2optimization ocodepattern r1 xorr2 xor q1 andp2 and x y w c2c1 c2 r1 r2 q1 p2 w x c2 y c1 c2 sets from dag alignment with selected representativesoptimization o optimization osource from o with selected representatives target from o with selected representatives1 2figure composing two optimizations o1ando2to generateo3.
the dashed lines connect the nodes that align with each other in the respective dag s in the code and the pattern.
function compose o1 o2 sets aligndags o1 o2 checkvalidity sets for alls2sets do selectreplacement s end for src o graft root src o1 sets tgt o graft root tgt o sets pre o graft pre o sets graft pre o sets returno3 end function figure compose optimizations o1 o2 if possible.
.
.
dag alignment the dag alignment process finds all values in the pattern and the code that must unify for the composition to occur.
we perform dag alignment using a worklist based algorithm.
the worklist contains the list of values from the respective dags that should be processed for unification.
the result of the dag alignment stage is a collection of sets where each set contains values that must be unified for the composition to occur.
the algorithm for dag alignment maintains the invariant that any unified set contains at most one code instruction because a pattern variable cannot match more than one distinct code instruction.
figure provides the algorithm for dag alignment.
initially a pair consisting of roots of the respective dags in the code and the pattern is added to the worklist.
each value in the respective dags will be placed in exactly one set which will combine with other sets as the dag alignment proceeds.
when an item a b is processed from the worklist the algorithm retrieves the sets saand sbcorresponding to values aandb.
matching a code and a pattern instruction.
ifsaandsbhave one code instruction and one pattern instruction they are matched with each other.
the match algorithm in figure checks whether the opcodes of the code instruction and the pattern instruction in sa andsbare exactly the same.
the match algorithm rejects the composition otherwise.
the match algorithm rejects the compositionif the instruction attributes of the code instruction are not a subset of the instruction attributes of the pattern instruction according to the alive pattern matching semantics see section .
.
the match algorithm also adds a tuple for each operand of the matching instructions to the worklist.
merging pattern instructions.
ifsaandsbboth have pattern instructions they are merged according to the algorithm in figure .
the need for merging two pattern instructions arises because two distinct instructions in the pattern may map to the same value in the code e.g.when a code instruction add w w is matched with pattern add x y where xand yare distinct pattern instructions .
the pattern instructions are merged when they perform the same operation and the composition is rejected otherwise.
the union of the instruction attributes in the two pattern instructions is computed and used for the merged instruction based on the alive semantics.
the algorithm also adds a tuple for each operand of the merged instructions to the worklist.
finally the union of two sets saandsbis added to the list of unified sets and the sets saandsbare removed from the collection of sets as shown in figure .
we use the union find data structure for the operations on disjoint sets.
figure illustrates the process of dag alignment.
initially a tuple containing the roots r1 r2 is added to the worklist.
when r1 r2 is processed the instructions r1 and r2 are matched which results in tuples q1 p2 and c1 c2 y being added to the worklist and a set r1 r2 is created.
when q1 p2 is processed instructions q1 and p2 are matched which results in w x and c2 y being added to the worklist and a set q1 p2 is created.
the collection of unified sets generated when all the elements are processed is shown in figure .
.
.
validity of sets from dag alignment we check the collection of sets obtained from the dag alignment for well formedness checkv alidity call in figure .
we check that no instruction in a set has another value in the same set as the operand either directly or transitively.
we perform this check by detecting cycles in the dependency graph constructed between the sets.
the nodes of the dependency graph are sets from the dag alignment stage.
two nodes aandbhave an edge if an instruc195function align dag s o1 o2 sets worklist whileworklist not empty do ht1 t2i pop worklist fori2f1 2gdo if9s2sets such thatti2sthen si s else .create a new set for this value si ft ig sets sets fsig end if end for ifs16 s2then s3 s1 s2 ifs1ands2have code instructions then reject end if ifs1ands2have pattern instructions then hv pairsi merge patinstr s1 patinstr s2 worklist append worklist pairs patinstr s3 v end if ifs3has a new pattern code pair then pairs match patinstr s3 codeinstr s3 worklist append worklist pairs end if sets setsnfs1 s2g fs3g end if end while returnsets end function figure align two dags and return the sets of unified nodes.
codeinstr s andpatinstr s denote the code instruction and merged pattern instruction for s. function match vp vc ifopcode v p opcode v c then reject else ifflags vp flags vc then reject else return end if end function figure match a code instruction against a pattern instruction.
tion in set adepends on a value from set b. the composition is not feasible when such circular dependencies arise.
we reject such compositions.
we also ensure that no set from dag alignment has both instructions and constants.
furthermore no set may contain two distinct specific constant literals e.g.
1and2 .
when we are composing o1witho2with dag alignment we also check that no value in the source of o1is unified with an intermediate value generated in the target of o1.
these checks ensure that the collection of sets generated from dag alignment correspond to a possible sequence of alive optimization applications.
.
.
selection of replacement for the sets once the collection of sets from the dag alignment is checked for well formedness we select a replacement value for each set.
the replacement value will be used in the final stage when creating the composed optimization.
the goal of this selection step is to pick the most specific value according to alive semantics forfunction merge v1 v2 ifopcode v opcode v then reject else v3 copy v1 flags v3 flags v1 flags v2 returnhv3 i end if end function figure combine two patterns if possible.
function graft t sets if 9s2sets such thatt2s replacement s tthen returngraft replacement s sets else t0 copy t for all operandsido opi t0 graft op i t sets end for returnt0 end if end function figure create a new dag by recursively examining an existing dag.
values in a unified set are replaced by their representative.
each set.
if the set contains roots then the root of o1 s source is selected.
otherwise the replacement values are selected in the following priority order code instruction merged pattern instructions specific constants constant expressions symbolic constants and input variables.
constant expressions which don t include specific and symbolic constants cannot occur in the source of an optimization in alive.
when a set contains a constant expression and one of the values in the set occurs in the source of o1 we choose that value.
if the set contains constant expressions not selected as the replacement value we create equations for the new optimization s precondition.
in figure the selected replacement value for each set is in bold.
the set c2 y c1 c2 contains a symbolic constant an input variable and a constant expression.
the symbolic constant c2is present in the source of o1.
hence the symbolic constant c2 is chosen as the replacement and we introduce new clauses to the precondition of the composed optimization to enforce the equality of the symbolic constant and the constant expression.
in figure the new equation added is c2 c1 c2 .
.
.
creating the new composed optimization finally the fourth stage creates the new optimization.
the graft procedure shown in figure recursively walks through the dependency graph of its argument replacing any values from the matching set with the value selected for its set.
the graft procedure ensures that newly created instructions and symbolic constants have unique names.
if one or both optimizations includes a precondition then the graft procedure performs the same substitution on the input precondition s to form the new precondition along with any additional equations produced during selection.
figure presents the final optimization o3generated with the graft procedure.
.
necessary condition for non termination our general strategy for identifying non termination bugs is to compose a given optimization or a new composed optimization generated from a sequence with itself.
however the fact that an optimization or a sequence of optimizations can self compose p add a b r add p c q add b d r add a q a p1 add a1 b1 p add p1 b r add p c q add b c q1 add b1 q r add a1 q1 b figure a alive optimization that re associates addition.
b the self composition of the reassociate add optimization which does not cause nonterminating compilation because the source pattern of self composition is larger than the source pattern of the original optimization.
does not necessarily result in non terminating compilation.
although the self composition is feasible such a self composition may never be invoked if the precondition is not satisfiable.
moreover self composability is necessary but not sufficient to cause non termination.
consider the optimization from the alive suite shown in figure a which re associates addition.
the optimization can be self composed yielding the optimization shown in figure b .
the precondition of the self composition is trivially satisfiable.
however the optimization does not result in nonterminating compilation even though it can be run repeatedly because the optimization consumes a different fragment of input code each time it runs.
performing the re associate optimization twice will transform three instructions instead of two.
performing it three times will transform four instructions and so on.
thus it can only run a finite number of times on a finite input.
based on this observation we consider the size of the source pattern when the optimization is composed with itself to determine if the optimization can result in non terminating compilation rather than attempting to determine directly whether an optimization decreases code size.
hence the necessary conditions for nonterminating compilation are the precondition of the self composition is satisfiable.
the source pattern of the self composition is either of the same size or smaller than source pattern of the optimization before the self composition.
optimizations o1ando2in figure can cause non terminating compilation because the source pattern of the self composition in figure d is of the same size as the source pattern in figure c and the precondition of the self composition is satisfiable.
.
debugging non termination the approach described above generates a sequence of optimizations that can cause compiler non termination.
to enable the compiler writer to debug and diagnose the cause of non terminating compilation we also generate test cases that demonstrate these non termination errors.
the resultant composition generated from a sequence of optimizations already has sufficient information that can be leveraged to generate a test case which would enable the compiler developer to debug the error.
as the source and target of an alive optimization are written in a generalized superset of llvm ir specializing the source of the optimization will generate an example test case.
alive provides abstractions over bitwidths and constants in comparison to the llvm ir.
hence generating a test case requires identifying a bitwidth for each individual type and generating concrete values for the sym bolic constants and constant expressions.
further the test case must be a self contained llvm ir unit e.g.
a function .
the test case for the composed optimization representing the effect of optimizations in a sequence is generated in three steps.
first we specialize the types by choosing an arbitrary type assignment which meets the optimization s typing constraints.
the constraints are expressed in first order logic and the resulting formula is provided to an smt solver.
the model obtained from the solver provides the type instantiations for the values in the test case.
second we specialize the symbolic constants into concrete values respecting the constraints in the optimization s precondition.
similar to types we express the precondition in first order logic and query the smt solver with the resulting formula.
the model from the smt solver provides the concrete constants.
third we generate a self contained test case in the llvm intermediate representation.
the test case is structured as an llvm function with parameters corresponding to the optimization s input variables and return value corresponding to its root.
for each instruction in the source we generate a corresponding llvm instruction applying the types and constants obtained in the previous steps.
figure f shows the test case generated for the composed optimization in figure c .
the generated test case has i8as the type chosen for the source variables.
the symbolic constants c1and c2have been instantiated with and respectively because they satisfy the precondition.
optimizations using results from dataflow analyses.
alive optimizations can use the result of llvm data flow analyses.
generating test cases that satisfy the results of dataflow analyses is challenging.
for example if the precondition contains a predicate willnotoverflowsignedadd a b we cannot simply make aand bparameters to a function.
llvm will not be able show that their addition will not result in signed overflow and the optimization will not be applied.
to address this challenge we generate symbolic constants that satisfy the axiomatic specification of the dataflow analyses in alive.
one minor niggle with this approach is that we will have to disable constant folding before running instcombine in llvm.
for the example above our test case will contain concrete constants e.g.
and assuming the type of aand bisi8 whose addition does not result in signed overflow.
shadowing of optimizations.
an implicit precondition with our generated test case is that all optimizations other than the optimizations listed in the cycle do not run when executed with the alive instcombine suite.
in some cases the test case generated for a sequence of optimizations in a cycle will not result in compiler nontermination when run with a suite of instcombine optimizations.
in those cases an optimization not in the cycle has matched an input program intended for an optimization in the cycle effectively breaking the cycle.
this occurs if an optimization in the cycle is shadowed by another optimization.
we have extended our analyses to check whether an optimization shadows another.
figure provides an example of shadowing.
we evaluate the number of cycles that are shadowed in our experimental evaluation.
.
experiments in this section we describe and experimentally evaluate the prototype termination checker for alive instcombine optimizations.
the goal of this evaluation is to show that optimization sequences that cause non termination are common in the alive instcombine suite and the termination checker detects them the non termination bugs can be demonstrated in llvm with the test cases generated and parallelization speeds up the exploration of optimization sequences for non termination bugs.
197n optimization complete self com non in cycles sequences compo positions creasing found sitions total number of cycles table the first and second columns report the length of the cycle in the exploration and the number of optimization sequences that were explored when looking for the ncycle.
the third column reports the number of optimizations that result from a complete composition of the sequence.
the fourth column reports how many self compositions of the composed optimizations were possible.
the fifth column reports the number of selfcompositions that had a non increasing source.
the last column reports the cycles found.
a indicates a randomized search of optimization sequences until a million complete compositions were found.
optimization n cycles addsub addsub addsub addsub addsub addsub andorxor andorxor andorxor andorxor andorxor andorxor andorxor andorxor andorxor andorxor andorxor andorxor andorxor 22optimization n cycles andorxor andorxor andorxor muldivrem muldivrem muldivrem muldivrem muldivrem muldivrem muldivrem muldivrem muldivrem muldivrem select select shift shift shift shift table the optimizations from the instcombine suite and the number of distinctn cycles they participate in.
the optimizations are named based on the instcombine sources files where they occur in llvm.
.
alive termination checker prototype the termination checker uses the publicly available version of alive as its foundation.
the code generator and optimizations are compatible with the instcombine pass of llvm .
.
we extended alive to relax some of the typing restrictions to increase the expressivity of optimizations.
alive has rudimentary or no support for memory related optimizations getelementptr and floating point optimizations.
we excluded such optimizations for checking non termination bugs.
in total we used optimizations in the alive instcombine suite to generate optimization sequences for checking non termination.
the test cases to demonstrate cycles were generated for llvm3.
with alive generated code inserted into the instcombine pass.
we disabled constant folding in llvm because our test cases use concrete constants for the optimizations that use dataflow analyses as described in section .
we use the unstable branch of z3 which has better support for quantifiers for checking the constraints generated during cycle detection type checking and test case generation.
the alive non termination checker is about two thousand lines of python code and is available as open source1.
andorxor op or x c1 r and op c2 o or x c1 c2 r and o c2 a name andorxor pre c2 u c1 !
u c1 op lshr x c1 r and op c2 op lshr x c1 r and op c2 u c1 b name andorxor op0 or a c1 r or op0 op1 i or a op1 r or i c1 c name andorxor pre mviz a u clz c lhs sub a b r and lhs c neg sub b r and neg c d name select c icmp eq x c r select i1 c x y c icmp eq x c r select i1 c c y e name select c icmp ne x c r select i1 c y x c icmp ne x c r select i1 c y c f figure a sampling of the optimizations that cause cycles.
the preconditions in the optimizations are weak which causes non termination errors.
the optimization d uses results of two dataflow analyses mviz maskedvalueiszero and clz countleadingzeros .
methodology.
we will use the term n cycle for an optimization sequence of length nthat causes compiler non termination.
as discussed in section .
we restrict ourselves to examining simple n cycles where each optimization appears at most once.
there are m!
m n !npossible simple n cycles for a suite of moptimizations.
we cover all possible optimization sequences for small values of n. however the state space increases quickly for larger values of n. we perform memoization to prevent exploring the same optimization multiple times with large state spaces.
for example when generating the composed optimization for the sequence o1o2o3 we compose o1ando2intoo1o2 memoize this composition and later reuse this composition for all sequences starting with the prefixo1o2.
for larger values of n we randomly sample selected sequences to find a million distinct compositions.
we generate test cases for the detected cycles and process them with a version of llvm using alive generated c code for the instcombine optimizations.
all experiments were performed on a bit intel haswell machine with four cores and gb of ram.
parallelization of optimization sequence exploration.
the termination checker creates millions of alive optimizations in the course of its search.
to speed up this process we built a parallel version of the non termination detector that splits the checker into multiple processes with a master slave architecture.
a manager process divides the list of sequences to be explored into chunks that share a common prefix.
workers process chunks until they perform a predefined amount of activity and terminate.
the manager creates new workers based on the amount of work that still needs to be performed.
.
effectiveness in detecting cycles our prototype was effective in detecting optimization sequences that cause compiler non termination.
it detected distinct optimization sequences that can cause non termination.
table also reports the number of optimization sequences explored number 198name andorxor op0 xor nop0 op1 xor nop1 r and op0 op1 or or nop0 nop1 r xor or name andorxor op0 or x y r xor op0 nx xor x ny xor y r and nx ny a name andorxor na xor a nb xor b r or na nb a and a b r xor a name andorxor op0 and x y r xor op0 nx xor x ny xor y r or nx ny b figure a sampling of the optimizations that cause cycles.
optimizations a and b in figure also cause a cycle .
of complete compositions and the number of self compositions possible.
the number of feasible optimization sequences increase rapidly with the cycle length.
we performed complete exploration of the state space for small cycle lengths .
for larger cycle lengths we performed exploration of random optimization sequences of length nuntil we were able to create one million complete compositions.
although there are a larger number of optimization sequences a small number of them can be composed with each other.
even fewer of them produce a non increasing source.
analysis of cycles found.
table reports the optimizations in instcombine that participate in cycles and the number of distinct n cycles that they appear in.
a sampling of the cycles and the cycles that we discovered with our prototype is presented in figure and figure respectively.
detailed information about each optimization is available online.2there are distinct optimizations that participate in cycles.
a weak precondition in the optimization is the main reason for non termination errors in the majority of the cycles.
the optimization in figure a will not cause non termination if the precondition is strengthened to c1!
c1 c2 .
similarly the optimization in figure e will not cause non termination if the precondition ensures that the input variable xis not a constant.
another significant fraction of the cycles involved optimizations that introduced instruction attributes when the instruction already had those attributes.
compiler writers typically write weak preconditions which likely enables their optimization to run often.
our prototype checker detects non termination errors in such scenarios and prevents them from getting into the tool chain.
many of these optimizations participate in multiple cycles as shown in table .
further investigation revealed that many of the longer cycles consisted of multiple smaller cycles.
we found that majority of the and cycles were various different combinations of and cycles.
after isolating the smaller cycles from the longer cycles we were able to identify 32distinct cycles which do not contain any smaller cycles in them.
based on these observations and the difficulty in generating feasible complete compositions of an optimization sequence see table we hypothesize that majority of the non termination bugs can be discovered by exploring smaller cycles.
.
demonstration of errors with test cases to enable the compiler writer to debug the cycles our prototype generated concrete inputs in the llvm ir format for each these cycles.
when the generated test cases were compiled with llvm using an alive generated instcombine the compiler would not terminate for out of the cycles.
the remaining cases were not able to induce compiler non termination because the optimizations in the cycle were shadowed.
in these cases there was an optimization in the instcombine suite that ran before the optimizations in the cycle which disabled the cycle.
the optimization in figure a is a cycle when cisint min i.e.
minimum signed integer for a given bitwidth and its self composition is shown in figure b .
however the optimization in figure a is shadowed by the optimization in figure d for the input program shown in figure c .
.
execution time with parallelization figure presents the speedup with the parallelized versions of the termination checker when compared to the sequential version.
the total execution time for sequential complete exploration of cycles ranges from seconds for n to hours n .
we were not able to run sequential versions for cycle lengths greater than .
the parallel speedups are .
for exploring cycles and for exploring cycles on a core machine.
the speedups with the cycle are lower because the exploration has relatively little work.
the speedups are less than for execution on four cores while exploring larger cycles due to multiprocess communication overhead between the master and the workers and the additional parsing work performed by each worker thread.
the parallelized version attains almost linear speedups with the increase in the number of cores.
the parallelized version also enables exploration of cycles for higher cycle lengths.
.
threats to v alidity the termination checker is built on top of alive which models the semantics of the llvm ir.
the semantics of the llvm ir can change.
hence the composition stage in our termination checker will likely be impacted by the discrepancies between the llvm ir and the alive semantics.
the termination checker tries to accurately capture the structure and the fixed point computation of instcombine optimizations in llvm.
the infrastructure may need small modifications if instcombine uses a different structure for its peephole optimizations which can change the results.
the alive suite is a snapshot of the instcombine suite that has been aggregated over a period of time.
we noticed that developers have strengthened preconditions in many optimizations in the current production release of llvm in contrast to the alive suite.
hence the cycles reported probably may not occur in the production releases of llvm.
although we focused on cycle detection for existing optimizations the ideal use case for our termination checker is during the development of new optimizations especially with the interest in using alive generated c code.
.
related work we classify related prior research into following categories random testing for compiler bugs correct compilation termination checking for general purpose programs and performance bug identification.
random testing.
testing with randomly generated code is one way to discover compiler non termination errors .
random testing has been effective in finding compiler errors.
however it is unlikely to discover corner cases that occur with rare inputs e.g.
the optimization in figure a will only cause a loop when the constant chas a specific value .
199pre c ispowerof2 abs c p sub y x r mul p c q sub x y r mul q abs c a optimization is a cyclepre c ispowerof2 abs c abs c ispowerof2 abs abs c p sub y x r mul p c q sub x y r mul q abs abs c b self composition of a definite i4 foo i4 y i4 x entry p sub i4 y x r mul i4 p ret i4 r c generated test casepre ispowerof2 c1 r mul x c1 r shl x log2 c1 d optimization shadowing a figure the cycle in a is shadowed by the optimization in d for the input shown in c .
the optimization d appears earlier than optimization a in the alive instcombine suite.
note that the condition abs c is satisfied when cisint min.
number of cores01234speedup1 cycles cycles cycles cycles figure execution time speedups with parallel exploration of n cycles compared to the sequential exploration with increasing core count.
correct compilation.
several domain specific languages have been proposed for developing compiler optimizations .
prior approaches have typically focused on verifying individual optimizations.
they do not address non termination when a collection of optimizations are run until a fixed point.
superoptimizers that generate the shortest possible program for a particular code input typically avoid non termination with cost metrics.
however these metrics are not directly applicable to instcombine as it is both an optimization pass and a code normalization pass.
translation validators check whether the compilation of a given input program is correct.
translation validators need the output of the compiler to check correctness which is not available when the compiler does not terminate.
alternatively if a verified compiler e.g.
compcert vellvm is written completely in a proof assistant such as coq then compiler termination is ensured by the proof assistant.
termination checking.
detecting termination has been widely explored for a wide range of use cases such as imperative programs term rewriting systems specifications of systems and systems code .
these techniques attempt to identify invariants either statically or dynamically that can be used to prove termination e.g.
ranking function for a loop .
alivegenerated c code can probably be analyzed with these systems.
identifying ranking functions for such code is likely not feasible because it also involves the llvm infrastructure code.
more specifically llvm optimizations can be seen as a form of term rewriting systems.
there is extensive research for showing termination and non termination for term rewriting systems .
in contrast our proposed approach leverages the structure and domain specific knowledge of alive optimizations to detect non termination.
performance bugs.
alive generated code could be configured to stop operating on a basic block once the number of optimizations performed on it exceeds some threshold.
in such a scenario the compiler will terminate but with poor compilation times.
fur ther the generated code will likely have poor performance.
there is active research on detecting the causes of poor performance .
these techniques are dynamic analyses that require a concrete input which demonstrates a cycle.
in contrast the proposed termination checker detects these non termination errors statically and also generates inputs that demonstrate cycles.
.
conclusion we have shown that non termination bugs occur with peephole optimizations executed to a fixed point especially when compiler developers are not careful with preconditions.
our methodology for detecting non termination is based on composition of optimizations.
we identified non increasing source in self compositions as a necessary condition for non termination and generated inputs to demonstrate non termination with llvm.
our goal was to create a tool that llvm developers can use to check non termination before they commit a new peephole optimization.
although we describe the methodology in the context of llvm it can be extended to peephole optimization frameworks of other compilers.