training binary classifiers as data structure invariants facundo molina renzo degiovanni pablo ponzio germ an regis nazareno aguirre marcelo frias department of computer science fcefqyn university of rio cuarto argentina national council for scientific and technical research conicet argentina department of software engineering buenos aires institute of technology argentina snt university of luxembourg luxembourg abstract we present a technique to distinguish valid from invalid data structure objects.
the technique is based on building an artificial neural network more precisely a binary classifier and training it to identify valid and invalid instances of a data structure.
the obtained classifier can then be used in place of the data structure s invariant in order to attempt to identify in correct behaviors in programs manipulating the structure.
in order to produce the valid objects to train the network an assumed correct set of object building routines is randomly executed.
invalid instances are produced by generating values for object fields that break the collected valid values i.e.
that assign values to object fields that have not been observed as feasible in the assumed correct executions that led to the collected valid instances.
we experimentally assess this approach over a benchmark of data structures.
we show that this learning technique produces classifiers that achieve significantly better accuracy in classifying valid invalid objects compared to a technique for dynamic invariant detection and leads to improved bug finding.
i. i ntroduction given the current advances in automated program analysis it is now possible to efficiently produce large sets of program inputs as well as examining very large sets of program executions but effectively deciding whether the behavior of software is correct or not remains a problem in this context that mainly depends on the provision of software specifications i.e.
specified oracles in the terminology of .
v arious researchers have acknowledged this issue and developed techniques that are able to derive specifications that are implicit in the software being assessed.
examples of techniques that derive specifications implicit in code are daikon jwalk and related tools .
daikon produces a set of candidate properties from a program definition and infers likely invariants by observing program executions and checking which of the candidate properties were not falsified violated by any execution .
jwalk also infers properties from program executions but it does so by interacting with the user to confirm learned observations to incrementally produce a test oracle.
while both tools are very powerful they have limitations.
daikon is limited to relatively simple program properties and complex structural constraints such as acyclicity are beyond the scope this work was partially supported by anpcyt pict and by the inter anr sa tocross.of the technique .
jwalk also shares this limitation and the learned oracles are more scenario specific i.e.
closer to test assertions than those produced by daikon .
in this paper we deal with the specification inference problem in a way similar in motivation to techniques like daikon and jwalk but targeting object validity classifiers for complex objects like class invariants for data structures.
our technique differs from the mentioned ones in several respects.
firstly it is based on the use of neural networks for learning classifiers from valid and invalid objects obtained from program executions.
this implies that learned classifiers are not formed by explicit constraints that the user can inspect as opposed to traditional class invariants but at the same time our classifiers are able to recognize more complex data representation properties in particular structural properties of heap allocated linked data that other techniques cannot handle.
secondly we concentrate on object classifiers for bug detection so our aim is to produce classifiers that tend to over approximate data structure invariants i.e.
that identify invalid objects with high precision and recall.
thirdly as opposed to other techniques that infer properties from dynamic information our approach requires inferring such properties from positive as well as negative cases notice that both daikon and jwalk only consider positive cases since they explore executions of supposedly correct software to infer likely program properties .
positive cases are those that the classifying function we want to learn should satisfy while negative ones are invalid instances i.e.
objects for which the classifier should return false.
to produce positive cases we assume correct a set of object builders e.g.
constructor and insertion routines and use these to produce programs that build valid instances of the data structure of interest.
this is a standard approach in various contexts in particular in some program verification and test generation techniques daikon and jwalk in essence also work under this assumption .
on the other hand negative inputs are produced as follows.
as valid instances are generated the observed extensions of class fields composed of all observed values for each field are collected then invalid instances are generated by exploiting these field extensions by producing new instances in which a field is given a value that is either outside the corresponding field extension and thus guaranteeing that is indeed a new object or within the extension but whose ieee acm 41st international conference on software engineering icse .
ieee authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
value has not been seen in combination with the rest of the instance being altered within the valid ones.
we evaluate our learning approach in several ways.
first we assess the adequacy of our approach to generate invalid objects analyzing how many of our assumed invalid produced instances are indeed invalid violate a provided invariant .
second we take a benchmark of data structures for which class invariants and object builders constructors and insertion routines are provided we generate object classifiers using the provided builders and evaluate their precision and recall against the corresponding invariants on valid and invalid inputs as is customary in the context of automated learning .
in this context we compare our technique with daikon a tool for dynamic invariant discovery.
finally we also compare our object classifiers with invariants produced by daikon in bug finding through test generation for a number of case studies involving data structures taken from the literature schedule from the sir repository an implementation of n ary trees in the antlr parser generator a redblack tree implementation of integer sets introduced in binary search trees and binomial heaps from the evaluation performed in and fibonacci heaps from the graphmaker library .
our experiments show that our mechanism for producing invalid inputs is effective and that the learned classifiers achieve significantly better accuracy in identifying valid invalid instances compared to daikon high precision and recall both in negative and positive cases .
moreover learned classifiers allow a test generation tool to catch bugs if classifiers are used in place of invariants that the same tool cannot detect if the invariants produced by daikon are directly used instead indicating that learned classifiers are not trivial.
ii.
b ackground a. class invariants one of the keys of object orientation is the emphasis that this programming paradigm puts into data abstraction .
indeed the concept of class is a useful direct mechanism to define new datatypes that extend our programming language s set of predefined types with custom ones that allow us to better capture or deal with concepts from a particular problem domain.
a class defines the type of a set of objects whose internal representation is given by the fields that are part of the class definition.
this implementation of a new data abstraction in terms of provided data structures is often accompanied by a number of assumptions on how the data structure should be manipulated that capture the intention of the developer in his chosen representation.
these assumptions are often implicit since they are not a necessary part of the definition of the data representation in most programming languages .
consider as an example a representation of sequences of integers implemented using heap allocated singly linked lists.
the classes involved in this data abstraction are shown in figure .
clearly solely from the class s fields one cannot infer the intention of the developer in the representation.
whether these lists are going to be arranged cyclicly acyclicly with or without sentinel node with reserved nodes for some specialpublic class singlylinkedlist private node head private int size ... public class node private int value private node next ... fig.
.
java classes for singly linked lists.
l0 n0 0size head l0 n0 0size head 2n1l0 n0 0size head 1n1 l0 n0 0size head 2n1n2 1l0 n0 0size head 2n1n2 l0 n0 0size head 2n1n2 2l0 n0 0size head 2n1n2 2n3 l0 n0 0size head 1n1 fig.
.
v alid acyclic singly linked lists with dummy node.
information etc.
are all issues that are not an explicit part of the class s internal definition although of course one may infer such information from how the internal representation is used by the methods of the class.
aclass invariant or representation invariant is a predicate inv that given an object oof class c states whether ois a valid representation of the concept that c captures or not.
equivalently invcan be described as a boolean classifying function that decides whether an object osatisfies the representation assumptions in the implementation of c. for instance assume that the programmer s intention with singly linked lists is to represent sequences of integers using acyclic linked lists with a dummy sentinel node where size must hold the number of elements in the sequence i.e.
it must coincide with the number of non dummy nodes in the list.
samples of valid lists under this assumption are shown in figure .
the invariant forsinglylinkedlist should then check precisely the above constraint i.e.
it must be satisfied by all instances in fig.
and must not hold for say cyclic lists lists where head is null or where the dummy node has a value different from or where the size field does not hold the number of non dummy nodes in the list.
class invariants can be captured using different languages.
the eiffel programming language in particular includes authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
public boolean repok if this .head null return false if this .head.value!
return false int expectedsize this .size int currnode this .head while expectedsize currnode!
null expectedsize currnode currnode.next return expectedsize currnode null fig.
.
java invariant for acyclic singly linked lists.
built in support for expressing class invariants as assertions under a specific invariant clause.
other languages support design by contract and assertions invariants among them via special languages and libraries such as jml for java and code contracts for .net.
languages such as alloy have also been employed to express class invariants as done e.g.
in .
finally various programming methodologies e.g.
and analysis tools e.g.
can exploit class invariants expressed as java predicates i.e.
via boolean methods that check internal object consistency.
figure shows the class invariant for our singly linked list example expressed as a java predicate.
in this paper we will be capturing close approximations of class invariants for data structures through artificial neural networks that as a consequence will not be formed by explicit constraints as in the example in fig.
.
b. field extensions v arious tools for program analysis that employ sa t solving as underlying technology adopt a relational program state semantics e.g.
.
in this semantics a field fat a given program state is interpreted as the set of pairs angbracketleftid v angbracketright relating object identifier id representing a unique reference to an object oin the heap with the value vof the field in the corresponding object at that state i.e.
o.f vin the state .
then each program state corresponds to a set of functional binary relations one per field of the classes involved in the program.
for example fields head andnext of a program state containing the singly linked list at the top right of fig.
is represented by the following relations head angbracketleftl0 n0 angbracketright next angbracketleftn0 n1 angbracketright angbracketleftn1 n2 angbracketright angbracketleftn2 n3 angbracketright angbracketleftn3 null angbracketright notice that in the lists in fig.
we have consistently identified the objects involved in each example.
although in this example it is not evident due to the linear nature of the structure we choose to identify each object by the order in which it is visited in a breadth first traversal of the corresponding structure using different identifier sets for different classes lifor lists nifor nodes etc.
.
adopting this notion of object identifier allows us to have a canonical isomorphism free representation for each structure shape a similar symmetry breaking approach is also present in other approaches e.g.
.the notion of field extension is associated with a set of objects or program states.
it essentially corresponds to joining the above described relational interpretation of fields for various objects or program states.
for instance for the set of lists in fig.
the extensions for fields head andnext are the following head angbracketleftl0 n0 angbracketright next angbracketleftn0 n1 angbracketright angbracketleftn0 null angbracketright angbracketleftn1 n2 angbracketright angbracketleftn1 null angbracketright angbracketleftn2 n3 angbracketright angbracketleftn2 null angbracketright angbracketleftn3 null angbracketright this notion of field extension is related to the concept of upper bound in kodkod used with the purpose of optimizing the relational representation of fields in alloy analyses.
technically field extensions are partial bounds in the kodkod sense.
when field extensions are built from valid objects they capture the set of values for fields that have been identified as being feasible in the sense that at least one observed structure admits each value in the corresponding extension.
we will use these extensions to attempt to build invalid objects e.g.
considering pairs that are not in field extensions.
this demands defining a complement for the field extensions for which we have to consider domains and codomains for these relations.
this is typically achieved in the context of bounded analysis by a notion of scope in the sense of .
the scope often simplified as a number k defines a maximum number of objects for each class ci and finite ranges for basic datatypes usually as a function of k .
for a given scope k the set of allpossible structures or instances is composed of all possible assignments of values within the scope for fields of the scope s objects respecting the fields types and thus provides us with a notion of universe for the field extensions.
for instance if the scope for our analysis is list up to nodes size in the range .. and values in the range .. then pair angbracketleftn3 n4 angbracketrightis in the complement of the extension of next whereas if we instead consider up to nodes it is not.
c. feed f orward artificial neural networks artificial neural networks anns are a state of the art technique underlying many machine learning problems.
these algorithms offer a number of advantages including their remarkable ability to implicitly detect complex nonlinear relationships in data that are otherwise very complex to be noticed.
an ann is composed of a group of different nodes called neurons connected by directed weighted links.
each neuron is a simple computational unit that computes a weighted sum of its inputs and then applies an activation function gto produce an output that will be an input of another neuron.
neurons can be disposed respecting certain network architectures.
in particular in a feed forward neural network neurons are typically organized in layers.
each neuron in a layer has a link to each neuron of the next layer forming a directed acyclic graph.
the first layer is the input layer and its neurons receive a single value as an input and simply replicate the received value through their multiple outputs to the next layer.
the final layer is the output layer and its neurons authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
produce the output of the network computation.
in addition to these two layers there can be any number of intermediate layers called hidden layers.
often neural networks will have one hidden layer since one layer is enough to approximate many continuous functions .
the behavior of a neural network can be dynamically altered by changing the weights associated with the links in the network or by modifying some of the neural network socalled hyperparameters such as the number of neurons in the hidden layer.
assume that we want an artificial neural network to approximate a function f and that we can characterize the inputs of fas a vector of values to be fed in the input layer .
provided that one has a set of inputs for which the desired output is known i.e.
a set of known input output pairs for f one can train an artificial neural network to approximate function f by analyzing the difference between the expected output and the output obtained from the network for a known input and producing slight changes to the weights so that if the network would be fed with the same input again its output would be closer to the expected output a mechanism that is often employed for this task is backpropagation .
this approach is known as supervised learning and when the output has only two possible values it is a binary classification problem.
the problem we deal with in this paper namely the approximation of a class invariant to classify valid vs. invalid data structure objects clearly falls in the category of binary classification we want to learn a function fthat sends each valid instance to true and each invalid instance to false .w e will then need both valid and invalid instances to appropriately train a neural network to learn a class invariant.
section iv describes the details of our technique.
iii.
a nillustra ting example let us provide an overview of our approach through an illustrating example.
consider the java implementation of sequences of integers over singly linked lists discussed earlier in this paper.
we would like to check that this list implementation behaves as expected.
this includes guaranteeing that all public constructors in singlylinkedlist build objects that satisfy the previously stated class invariant and public methods in the class that may include various methods for element insertion deletion and retrieval preserve this invariant.
that is they all maintain acyclicity of the list with its number of nodes from head.next coinciding with the value of size etc.
if we had this invariant formally specified we may check that it is indeed preserved with the aid of some automated analysis tools e.g.
some run time assertion checker as that accompanying the jml toolset or a test generation tool like randoop .
but getting these invariants right and specifying them in some suitable language even if the language is the same programming language of the program implementation is difficult and time consuming and one does not always have such invariants available.
we would then like to approximate a class invariant inv c bool using a neural network from the implementation ofc.
in order to do so we need to train the neural network l0 n0 1size head l0 n0 1size head 2n1l0 n0 0size head l0 size headl0 n0 0size head 2n1n2 l0 n0 0size head 2n1n2 2l0 n0 0size head 2n1n2 2n3 l0 n0 0size head 1n1 fig.
.
potentially invalid list structures built by breaking field extensions.
with a sample for which we know the correct output.
in other words we need to train the neural network with a set ofvalid instances i.e.
objects that satisfy the invariant or equivalently for which the invariant should return true as well as a set of invalid instances i.e.
objects that do not satisfy the invariant for which the invariant should return false .
in order to do so we will ask the user to provide a subset of the class s methods that will be used as assumed correct builders i.e.
as methods that allow us to build correct instances.
for instance in our example the user may trust the implementation of the constructor and the insertion routine and thus all objects produced with these methods are assumed correct.
using these builders we can construct assumed correct instances by using e.g.
an automated test generation tool such as randoop.
a particular set of valid instances that we may obtain from this process could be the objects in fig.
.
building invalid instances is more difficult.
we may ask the user to manually provide such cases but the number of objects necessary to appropriately train the network would be large and thus this approach would seriously limit the efficacy of the approach.
we may also ask the user to provide methods to build incorrect objects but this would mean extra work it is not something that the user has already at hand and providing such methods is not in principle easy to do.
instead our approach is based on the use of field extensions .
we proceed as follows.
we have already run some input generation tool using the builders for some reasonable amount of time and have obtained a set of valid objects of class singlylinkedlist .
from these objects we can compute the field extensions for each field of the data structure.
the extensions for head and next are shown in the previous section the extensions for size andvalue are the following size angbracketleftl0 angbracketright angbracketleftl0 angbracketright angbracketleftl0 angbracketright angbracketleftl0 angbracketright value angbracketleftn0 angbracketright angbracketleftn1 angbracketright angbracketleftn1 angbracketright angbracketleftn2 angbracketright angbracketleftn2 angbracketright angbracketleftn3 angbracketright authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
source program anninstances generation learning phase object classi fierpositive cases negative casesfield extensions computation and object breakingexecution of assumed correct codeinstances as vectors positive vectors negative vectorsvector generation fig.
.
an overview of the technique we will build potentially invalid instances by changing field values in valid structures.
we have two possibilities for a change in a given object field we can go outside the extensions i.e.
assign a value to the field that has not been observed in any of the built valid structures and thus guaranteeing that is a new object or go inside the extensions i.e.
assign a value different from the original but within the feasible observed ones for the field.
in the former case we need to define a scope so that being outside the extension can be precisely defined.
assume for the sake of simplicity that we arbitrarily define the following scope exactly one list object l0 nodes n0 ... n3 size in the range .. andvalue in the range .. .
now we can build allegedly invalid instances by changing for each valid structure a value of some reachable field to some different value outside the corresponding extension or within it but different from the original.
in fig.
we show a sample of potentially invalid instances obtained from those in fig.
using this mechanism.
a few issues can be noticed from these examples.
first there is no guarantee that we actually build invalid instances with this process.
the top right object in fig.
is in fact a valid case.
artificial neural networks are however rather tolerant to noise during learning so as long as the number of spurious invalid objects is low learning may still work well.
second what we are able to build as potentially invalid instances greatly depends on what we produced as valid ones and what we define as the scope .
both issues are critical and we discuss these further in the next section.
third the specific mechanism for choosing a value within the corresponding field extension or outside it is not specified.
one may randomly choose on which direction to go and with which proportion to go inside or outside the extensions.
intuitively going outside the field extensions has better chances of producing invalid structures.
iv .
t hetechnique let us now present in more detail our approach to approximate class invariants using artificial neural networks.
the technique depicted in fig.
has three main steps i automatically generating valid and invalid data structure objects ii representing objects of the class both valid and invalid as numerical vectors to be able to feed these to a neural network and iii building an artificial neural network and training it with the produced valid and invalid objects to learn to classify data structure instances as valid or invalid.a.
generating instances for training assuming that we are given a class cfor which we want to learn to classify valid vs. invalid data structure objects our first step consists of generating instances that must and must not satisfy the intended invariant respectively.
as we mentioned before our first assumption is that a set mof methods of cis identified as the assumed correct builders of the class i.e.
a set of methods whose implementations are assumed correct and that thus can be used to build valid instances.
this assumption is in fact rather common in verification and test generation environments that produce instances from a class s public interface see e.g.
.
our second assumption is that a notion of scope is provided see previous section for an intuition of this requirement .
the scope provides a defined domain for each field of each class involved in the analysis and thus provides a domain where to search for field values when building potentially invalid objects from valid ones.
the scope is not only relevant in defining a finite universe to compute the complement of field extensions useful in building invalid instances it also bounds the instances to be considered allowing us to characterize them as fixed size vectors see next subsection .
in order to build valid instances any input generation technique that can produce objects from a class interface is suitable including model checking based ones and random generation for instance in our experiments we will use random generation .
using the produced valid instances we compute field extensions and generate potentially invalid instances by modifying valid ones as follows given a valid instance c an object oreachable from cand a field f ino we change the value of o.fto either a value within the extension of fwith respect to o or outside it but within the scope.
the latter is favored since it exploits field extensions guaranteeing that a new object is constructed.
from each valid structure we produce as many invalid objects as object fields are reachable in the structure using the above procedure to change a single object field in each case.
choosing to go within extensions or outside them can be done randomly.
in our experiments we change an object field going within the extensions with a probability of .
and outside these with a probability of .
.
the rationale for the selection is based on experimentation we tried for small scopes different probabilities and these were the ones that achieved better performance .
when an object is changed nodes are relabeled to preserve the breadth first canonical ordering mentioned in section .
finally we discard any potentially invalid object generated with the above procedure that is also within the set of valid objects so that there is no intersection between the valid and invalid objects used for training the network.
the generation technique for valid inputs is related to how the scope is chosen.
some techniques require the scope a priori for generation e.g.
while in others the scope can be derived from the generated instances e.g.
looking at the largest produced object or the range of produced values.
intuitively the scope should be at most slightly loose with authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
l0 n0 n1 n2 n3size head val.
next val.
next val.
next val.
next e head val next val next val next vrange .. for null n0 ... n3 fig.
.
instance vector for a singly linked list example.
respect to the field extensions corresponding to the generated valid instances in the sense that when building invalid objects it should prevail to form field associations that are not part of any valid object but that involve values that are part of valid objects.
in our experiments we chose the scope a priori and discarded any randomly generated object that lied outside the scope.
b. representing instances as v ectors neural networks receive as inputs vectors of values which are in general restricted to numeric types.
while for some datatypes an encoding is direct e.g.
characters enumerated types strings of a maximum length for objects of an arbitrary class cit is less straightforward.
in order to encode object states as vectors we adopt the candidate vector format of korat .
given a scope k that defines ranges for numeric types and maximum number of instances for reference types any instance oof class cwithin scope kcan be represented by a vector containing a cell for each field fof each object o prime reachable from o. the domain of each cell is a range of natural numbers where each value uniquely identifies an object value within the scope for the corresponding field.
for instance given a scope of exactly one list object nodes size in the range .. and value in the range .. for the singly linked list example the top right list of fig.
is represented by the instance vector shown in fig.
.
this representation implies that the maximum size considered for reference based types has to be set beforehand since it determines the vector length.
therefore we cannot in principle use a network trained for instances of size up to kwith structures of a greater size since the latter would be captured with different longer vectors.
it is worth remarking that our object encoding mechanism is deterministic.
structures are canonically represented by assigning identifiers to nodes by their order in breadth first traversal using an arbitrary but fixed order for fields .
also floating point fields are supported by our technique but are disregarded when generating invalid vectors i.e.
we never build invalid structures by modifying floating point fields .
c. building and training the neural net the vectors representing the positive and negative instances form the training set that we feed the network with.
the network that we build in order to learn to classify these instances as positive or negative is a feed forward artificial neural network .
firstly assuming that the size of the current vectors is n the input layer will contain ninput neurons each receiving a position of the vector and the output layerwill always have 1neuron since our classification problem involves two different classes.
only one hidden layer is used.
the number of hidden units i.e.
number of neurons in the hidden layer is a hyperparameter whose value can impact the network s effectiveness and can be set automatically.
known algorithms to automatically select hyperparameters are grid search and random search we use random search due to its ability to reduce the validation set error faster than grid search .
the parameter for the number of hidden layer units takes values in the range .
another hyperparameter that is usually considered and we consider in our work is the regularization term a penalty coefficient that affects the neural network s learning process values for this parameter were taken in the range evenly spaced in a logarithmic scale as is customary in various domains.
we launched 10random combinations of hyperparameter values and then selected the combination with the best performance to determine the final network architecture.
as we show in the following experimental evaluation the level of precision that we achieved did not demand further tuning of the neural network s hyperparameters.
we use the multi layer perceptron neural network implementation of the python scikit learn package .
v. e v alua tion the evaluation of our technique is driven by the following research questions rq1 is the technique for building potentially invalid instances suitable for this task?
rq2 how precise is the neural network in classifying valid invalid objects?
rq3 do our learned object classifiers help in capturing relevant information on expected class behaviors that can lead to improved bug finding?
to evaluate rq1 we need to assess every potentially invalid instance that we build with our technique based on field extensions to check if it is indeed invalid.
our experiment proceeded as follows.
we took all case studies accompanying the korat distribution available in that involve various data structures of varying complexities for which class invariants are provided notice that korat requires class invariants expressed as java predicates for test input generation .
we extended each class with a set of builders e.g.
constructor and insertion routines and used randoop to produce valid instances with these builders disregarding the invariant provided with korat for different scopes.
for each case we ran randoop with different seeds seconds each and collected all produced objects a total of over minutes input generation time per case study .
we then used our technique based on exploiting field extensions to produce potentially invalid objects and checked for their spuriousness using the corresponding invariant in the korat distribution.
in these experiments the object builders were straightforward to select mostly constructors and insertion routines but selecting a sufficient and at the same time small set of builders may be subtle.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
table i number of spurious inv alid objects genera ted by exploiting field extensions .
scope instances total positive negative false negative singly linked list singly sorted list doubly linked list binary tree binary search tree red black tree binomial heap the results are summarized in table i. this table shows for each case study and various scopes the total number of produced objects distinguishing between valid and invalid objects and for the latter the number of spurious cases i.e.
objects built by breaking objects using field extensions that actually satisfied the corresponding original repok provided with korat .
due to space reasons we show a sample of the structures and scopes.
further details can be found in the experiments site .
to evaluate rq2 we first performed the following experiment.
we again took korat case studies with our provided object builders and ran for each class c our technique obtaining a corresponding object classifier i prime.
in this step we used the object builders and disregarded the provided class invariants.
we then used for each class cits korat invariant ito generate allvalid objects within a given scope k i.e.
all valid objects of size at most k using the korat tool .
moreover we also collected the objects that korat produced in the search for valid objects that were deemed invalid i.e.
that did not satisfy the corresponding invariant .
this collection of valid and invalid objects was used for measuring the precision and recall in object classification as separate measures for valid and invalid objects.
this experiment was performed for increasingly larger scopes as long as the number of instances did not exceed million.
the results are summarized in table ii.
for each case study and scope we report the number of valid and invalid objects used for training as well as the training time notice that each training set was generated with randoop and the object builders the size ofthe sample used for measuring recall precision provided as total number of valid invalid objects notice that these were generated using korat the number of objects correctly and incorrectly classified tp tn for true positive negative fp fn for false positive negative and the corresponding precision and recall given as percentages.
notice that since the training and evaluation sets are generated independently some structures used in training may also appear in the evaluation set.
we have indicated between parentheses the number of new positive and negative instances in the evaluation set i.e.
those structures that have been used for evaluation but that were not part of the corresponding training sets.
again a sample of the structures and scopes is shown more information can be found in the experiments site .
in order to have a reference of the accuracy of our approach we compare our learned object classifiers with invariants generated using daikon .
the process we followed to produce invariants with daikon is the following.
for each case study we took the same tests used as a starting point for learning object classifiers with our approach and ran daikon using those.
daikon produced a list lof likely invariants which in all cases included invalid properties properties that were true of the provided tests but were not true in the general case for the corresponding structure .
from l we produced a list l prime by manually filtering invalid properties i.e.
properties that do not hold for all structures .
we measured the precision and recall of the obtained daikon invariants for the same objects used to measure precision recall of our technique.
the results are summarized in table iii.
rq3 is the only research question that does not demand a provided class invariant for assessment.
to evaluate it we took buggy implementations of data structures from the literature thescheduler implementation from the sir repository an implementation of n ary trees that is part of the antlr parser generator implementations of routines of a set of integers over red black trees with seeded bugs presented in binary search trees and binomial heaps used in the empirical evaluation in containing one real bug each and a fibonacci heap implementation taken from containing a real bug.
for each case study we took a set of builders these are provided as part of the corresponding implementations as opposed to the builders considered in rq1 and generated tests with randoop from which we learned an object classifier with our technique with a relatively small scope for all cases and produced likely invariants with daikon processed as for rq2.
we then compared randoop with invariant checking disabled and randoop with invariant checking enabled checkrep using i the learned classifier and ii the daikon filtered invariant only valid properties are kept to check in each case the bug finding ability.
every randoop execution for instance generation was run as for rq2 i.e.
with a scope of except for binheap where we used scope since a known bug is first exposed with such a scope.
for bug finding a timeout of minutes was set.
the results are summarized in table iv.
in the case of antlr randoop is not able to catch the bug under any configuration.
the authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
table ii precision and recall of classifying technique on complex da ta structures .
training testing scope instances time positive instances negative instances positive negative sec.
total tp fp precision recall total tn fn precision recall data structure singly linked list data structure singly sorted list data structure doubly linked list data structure binary tree data structure binary search tree data structure red black tree data structure binomial heap reason is that due to the mechanism that randoop uses for incrementally building test cases it cannot produce the aliasing situation that is necessary to catch the bug basically adding a node to itself as a child a situation that the class interface allows for but randoop cannot produce .
however when manually building this scenario the learned classifier detects the anomaly whereas no anomaly is detected without invariant checking i.e.
no exception or other obvious error is observed nor with the filtered daikon invariant.
we marked this case as manual to reflect this singularity.
all the experiments presented in this section can be reproduced following the instructions found in the site of the replication package of our approach .
a. discussion let us briefly discuss the results of our evaluation.
regarding rq1 our technique for producing invalid objects by exploiting field extensions worked reasonably well.
in general less than of the presumably invalid objects were actually valid with an effectiveness that increased for larger scopes.
a closer look at these cases shows that most spurious invalid cases have to do with producing changes in data fields that the neural network identifies as anomalous but the known invariant allows for.
that is when a change to a structure field is produced it mostly leads to an invalid object.
in other words field extensions seem to accurately summarize field value feasibility.
an issue that may affect this effectiveness is the budget set for generating valid instances and collecting field extensions .
the multiple randoop runs performed with different seeds produced sufficiently large samples of valid structures in our experiments but this budget may be extended to obtain more precise field extensions in other case studies.regarding rq2 our experimental results show that the artificial neural network produces object classifiers that closely approximate class invariants.
indeed the technique learns classifiers that achieve a very high precision and recall for negative cases and significantly better precision recall for positive ones compared with related techniques.
in other words misclassified cases are significantly more likely to be invalid inputs classified as valid rather than the opposite.
this is a positive fact for bug detection since it confirms that classifiers tend to over approximate class invariants they will produce fewer false negatives .
the case studies where we had less precision for positive cases were binary search tree and red black tree.
these cases classify various invalid objects as valid.
we confirmed that the reason for this observed learning limitation in these case studies has to do with the complexity of the invariants of these data structures regarding data objects more precisely sortedness indeed all invalid cases that were misclassified as valid were correct from a structural point of view but violated sortedness.
further experimentation with more complex network topologies larger number of hidden neurons may show a better performance in these cases.
still accuracy of our fully automated approach is significantly better than daikon s manually filtered invariants.
regarding rq3 let us remark that our comparison is between our technique that is fully automated and a manually filtered instance of daikon.
in particular for this research question the effort required to produce the filtered version of daikon produced invariants is significant since in most of these cases we did not have reference invariants to compare to and thus each likely invariant had to be carefully examined to decide whether it was valid invalid or valid for some cases.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
for instance for the binomial heap case study the resulting post processed daikon invariant has lines and involved going through likely invariants difficult to reason about it is a quite sophisticated data structure .
our results show that we achieve significantly better bug finding compared to no invariant and filtered daikon invariant analyses since our object classifiers catch out of bugs while with no invariant only bugs are detected and the filtered daikon invariant finds out of .
this is a very important result taking into account the effort required for the engineer to produce the processed daikon invariants and the fact that our technique is fully automated.
the bugs that in the case of schedule can be found with invariant checking disabled throw exceptions and thus do not need a specification to be caught.
the remaining bugs do not produce state changes and thus cannot be caught by invariant checking.
the additional bug that we found is in fact a bug that is not explicitly indicated in the repository.
this 9th bug was discovered in the supposedly correct version.
it is a bug in the upgrade process prio routine that moves a process to a queue of a higher priority but it does not update the process priority correctly.
indeed a line in this routine that performs the following assignment proc priority prio should instead be as follows proc priority prio the sir repository includes another scheduler implementation scheduler2 .
we did not include this case study in our evaluation because all seeded bugs correspond to routines that do not change object states and thus cannot be caught by just checking invariant preservation.
the bugs seeded in the red black tree implementation from all correspond to theinsert method.
we trained the neural network using a correct version of this method and then used it to attempt to catch the seeded bugs.
b. threats to v alidity our experimental evaluation is limited to data structures.
these are good representatives of data characterized by complex invariants which are beyond known invariant inference techniques such as daikon.
from the wide domain of data structures we have selected a large set for which invariants were provided elsewhere for answering rq1 and rq2 that required provided invariants.
this benchmark includes data structures of varying complexities including cyclic and acyclic topologies balance sortedness etc.
one may argue that restricting the analysis to these case studies might favor our results.
while an exhaustive evaluation of classes with complex constraints is infeasible we consider that invariant complexity especially for invariants whose expression goes beyond simple constraints such as linear comparisons is a crucial aspect we want our approach to target and designed the experiments taking this issue into account.
the evaluated structures correspond to a broad range of complexity goingfrom those with simple linear structures to other with treelike balanced shape.
for rq3 we did not need classes with provided invariants.
we chose to analyze buggy data structures taken from the literature as opposed to evaluating on our own seeded faults to avoid unintentional bias.
the evaluation is largely based on implementations taken from the literature.
korat case studies had to be extended however with builders.
our implementations were carefully examined as an attempt to make these respect the corresponding invariant and to remove possible defects that would affect our experiments.
we did not formally verify our implementations but errors in these would have implied invalid objects being generated as valid thus affecting the outcome of our whole learning approach.
that is errors in our implementations would have derived in less precision i.e.
they would hinder our results rather than favour them.
vi.
r ela ted work many tools for automated program analysis can profit from invariants.
some tools use invariants for run time checking notably the eiffel programming language that incorporates contracts as part of the programming language the runtime assertion checker and static verifiers that use jml code contracts for .net among others.
some techniques for automated test case generation also exploit these invariants for run time checking converting the corresponding techniques into bug finding approaches.
some examples are randoop and autotest .
our approach learns object classifiers that can be used in place of class invariants but which are are black box i.e.
are not composed of explicit constraints that can be inspected.
but since many of the above mentioned tools simply use invariants for object checking without any dependency on the internal structure of the invariant they are useful in these contexts.
however tools like korat and symbolic pathfinder that require class invariants in the form of repok routines to be provided cannot be used with our learned classifiers since they exploit the program structure of the invariant to drive the search for valid inputs .
the oracle problem has been studied by many researchers and techniques to tackling it in different ways have been proposed .
our approach is more closely related to techniques for oracle derivation more precisely for specification inference .
within this category tools that perform specification inference from executions like ours include daikon and jwalk .
both these tools attempt to infer invariants from positive executions as opposed to our case that also includes a mechanism to produce potentially invalid objects.
we have compared in this paper with daikon since jwalk tends to infer properties that are more scenario specific.
the use of artificial neural networks for inferring specifications has been proposed before these works however attempt to learn postcondition relations i o relations from golden versions of programs i.e.
assumed correct programs.
while this approach is useful e.g.
in regression testing or differential testing scenarios using it in our case would mean to learn the authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
table iii precision and recall of manuall y filtered daikon inv ariants on complex da ta structures .
testing scope instances positive instances negative instances positive negati ve total tp fp precision recall total tn fn precision recall data structure singly linked list data structure singly sorted list data structure doubly linked list data structure binary tree data structure binary search tree data structure red black tree data structure binomial heap table iv effectiveness of learned classifiers in bug finding .
case bugs found found found study no inv.
obj.
class.
filt.
daikon antlr man.
man.
man.
scheduler inttreeset bintree binheap fibheap i o relation for a repok having the repok in the first place a simpler problem compared to what we are tackling here.
the notion of field extension as a compact representation of a collection of generated structures was put forward in and originates in the relational semantics of signature fields in alloy and in the notions of upper and lower bounds introduced with the kodkod engine .
our use of field extensions in this work as a basis for the mechanism for breaking valid objects is different from the purpose of bounds and partial bounds in the above cited works.
vii.
c onclusions software specification plays a central role in various stages of software development.
in the context of program analysis there is an increasing availability of powerful techniques including test generation bug finding fault localization and program fixing for which the need for program specifications becomes crucial.
while many of these tools resort to tests as specifications they would in general greatly benefit from the availability of stronger more general specifications such as those that class invariants provide.
invariants are becoming more common in program development with methodologies that incorporate these and tools that can significantly exploit them when available for useful analyses.
we developed a technique based on neural networks for inferring object classifiers to be used in place of class invariants.
the technique is related to other similarly motivated approaches in the sense that it explores dynamic software behaviours for the inference but it also incorporates a technique for producing invalid objects enabling the training of a neural network.
we have analyzed the use of neural networks for learning object classifiers and showed that the learning process achieves very high accuracy compared to related approaches that our mechanism to build supposedly invalid objects is effective and that the learned object classifiers improve bug detection as evidenced by experiments on a benchmark of data structures of varying complexities.
this work opens several lines for future work.
our artificial neural network is built with rather standard parameters adjusting variables such as number of hidden layers activation function etc.
may be necessary especially when scaling to larger domains.
the performance of artificial neural networks can also be improved by feature engineering a mechanism we have not yet explored.
our experiments were based on the use of random generation for producing valid objects the initial stage of the technique.
using alternative generation approaches such as model checking and symbolic execution may lead to different possibly more precise results.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.