generating performance distributions via probabilistic symbolic execution bihuan chen y ang liu and wei ley school of computer engineering nanyang technological university singapore ydepartment of computer science iowa state university usa abstract analyzing performance and understanding the potential bestcase worst case and distribution of program execution times are very important software engineering tasks.
there have been model based and program analysis based approaches for performance analysis.
model based approaches rely on analytical or design models derived from mathematical theories or software architecture abstraction which are typically coarsegrained and could be imprecise.
program analysis based approaches collect program pro les to identify performance bottlenecks which often fail to capture the overall program performance.
in this paper we propose a performance analysis framework perfplotter .
it takes the program source code and usage pro le as inputs and generates a performance distributionthat captures the input probability distribution over execution times for the program.
it heuristically explores highprobability andlow probability paths through probabilistic symbolic execution.
once a path is explored it generates and runs a set of test inputs to model the performance of the path.
finally it constructs the performance distribution for the program.
we have implemented perfplotter based on the symbolic pathfinder infrastructure and experimentally demonstrated that perfplotter could accurately capture the bestcase worst case and distribution of program execution times.
we also show that performance distributions can be applied to various important tasks such as performance understanding bug validation and algorithm selection.
ccs concepts software and its engineering !software performance keywords performance analysis symbolic execution .
introduction understanding software performance is important.
developers want to know whether further optimizations or performance related software assurance tasks need to be done users are interested to know whether software may run too slowly to use.
up till today much of the software engineering research has been focusing on the functional correctness but not much work has been done for performance analysis.
permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
copyrights for components of this work owned by others than acm must be honored.
abstracting with credit is permitted.
to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
request permissions from permissions acm.org.
icse may austin tx usa c acm.
isbn .
.
.
.
are two types of existing techniques for performance analysis model based and program analysis based approaches.
model based approaches often rely on analytical models e.g.
petri nets derived from mathematical theories or design models e.g.
feature models derived from software architecture abstraction.
the problems are that constructing such models requires extensive domain knowledge the models are coarse grained and miss implementation details to derive best case and worst case execution times and it is also hard to keep the models and source code synchronized.
as a result the performance prediction can be imprecise.
on the other hand program analysis based approaches derive performance models from source code and program executions.
in particular there have been dynamic analyses that perform statistical inference and derive a performance model based on the measured execution time for each basic block under a set of test inputs .
the problem is that the accuracy of the performance model often relies on the given set of test inputs.
di erently symbolic execution and guided testing are used to automatically generate the test inputs that can lead to the worst case execution times .
their focus is to identify performance bottlenecks but not to characterize the overall performance of a program for all inputs.
to capture insightful and comprehensive characteristics of the performance of a program in this paper we propose the concept of performance distribution as well as a performance analysis framework perfplotter to generate the performance distribution for a program under a usage pro le.
the performance distribution plots the input probability over program execution times.
it shows the likely range of execution times including the best case and worst case execution times and it also visualizes how likely certain execution time will be exhibited.
such information can be used to understand the corner cases of a program reveal performance problems and prioritize their severity if any.
comparing the performance distributions for the two versions of a program before and after code changes we can track unexpected performance regressions or speedups and comparing the performance distributions for functionally equivalent programs we can learn the performance advantage of a program over others.
perfplotter leverages probabilistic symbolic execution to perform a selective exploration of program paths.
we classify two types of paths high probability andlow probability paths.
here the probability refers to how likely a path will be executed under a usage pro le.
in particular our path exploration process is divided into two phases.
in the rst phase we explore high probability paths while ensuring path diversity to uncover performance characteristics for frequently executed scenarios in a diverse way.
in the second phase we explore low probability paths to expose the performance of interest hidden in the less frequently executed paths.
in fact we ieee acm 38th ieee international conference on software engineering did nd in our experiments that such paths are very important for exposing best case and worst case execution times of a program.
in the presence of a loop only a subset of representative loop paths are explored to capture the overall performance of the loop while ensuring scalability.
for each explored path we generate multiple test inputs and model the performance of the path as their average execution time.
we implemented perfplotter using symbolic pathfinder spf and its probabilistic symbolic execution engine .
in our experiments we compared the performance distributions generated via perfplotter with those generated by three other approaches exhaustive symbolic execution random symbolic execution and random testing.
our results demonstrated that by heuristically exploring a small set of paths perfplotter can generate performance distributions that can capture the general trend of the actual ones and expose the bestcase and worst case execution times with high coverage and low overhead.
we also applied the performance distributions to assisting performance understanding bug validation and algorithm selection.
the main contributions of this paper are three introducing the concept of performance distribution designing a framework to automatically generate performance distributions and evaluating the proposed framework.
.
preliminaries in this section we provide the background on symbolic execution and probabilistic analysis in symbolic execution.
.
symbolic execution symbolic execution is a program analysis technique that systematically explores program execution paths .
it uses symbolic values in place of concrete data as inputs and produces symbolic expressions over symbolic inputs as outputs.
the state of a symbolically executed program is de ned by an instruction pointer symbolic expressions of program variables and a path condition.
the path condition is a conjunction of constraints over symbolic inputs which characterizes the inputs that would execute the path from the initial state to the current state.
during symbolic execution path conditions are checked for satis ability when a path condition is not satis able the path is infeasible and the symbolic execution stops exploring this path and backtracks.
the paths generated during symbolic execution are characterized by a symbolic execution tree .
the tree nodes represent states and the arcs represent transitions between states.
here we focus on sequential programs and hence distinguish two kinds of nodes branch nodes e.g loops and conditional statements and non branch nodes e.g.
method invocations and assignments .
the former has one or two outgoing transition s representing the true and or false branches and the latter has at most one outgoing transition.
branch nodes are the key to select paths of interest during path exploration.
several tools have been proposed for symbolic execution of programs written in di erent programming languages e.g.
klee for llvm and spf for java.
here we focus on java programs and use spf for implementation but our technique is general and independent of these tools.
.
probabilistic analysis symbolic execution uses satis ability checking to decide if a path is feasible or not.
a feasible path only implies that there is an element i.e.
a solution generated by a constraint solver in the input domain that satis es the path condition but gives no information on the exact number of such solutions.
probabilistic symbolic execution is proposed to allow such a quanti cation for calculating the probability of satisfying a path condition under uniformly distributed inputs .
since not all input values are equally likely a usage pro le is used to probabilistically characterize the program s interactions with the environment .
in particular each input variable is discretized by partitioning the input values into a set of intervals and assigning each of them a probability .
by this means arbitrarily complex probability distributions of the input variables can be handled.
given a speci c usage pro le a symbolic execution tree is constructed as follows.
whenever a condition is encountered a branch node is introduced and we compute a pair hpc probi.
pcis the path condition which is the conjunction of the conditions of the taken branches along the path from the initial node to the current one.
prob is the path probability which is the product of the conditional probabilities of the taken branches along the path from the initial node to the current one.
along with the branch node two transitions are introduced we compute hc pr ciandh c pr cifor the true and false branch respectively.
prcandpr care the branch probabilities the probability of the true or false branch taken under the usage pro le.
they can be computed using p cjpc andp cjpc as proposed in based on the law of total probability and conditional probability .
we assume the usage pro le is encoded in programs as proposed in .
several tools have been proposed to quantify the solution space of constraints over speci c domains which can be used to calculate branch probabilities e.g.
latte for linear integer constraints qcoral for arbitrary oat constraints smc for string constraints and korat for heap data structures .
in this paper we focus on the domains of nite integer and oat numbers and we use latte and qcoral in our implementation however our framework is potentially extensible to other domains and tools.
.
performance analysis in this section we provide an overview of perfplotter then we elaborate on the techniques for selective path exploration and path based performance modeling and nally we present the algorithms for generating performance distributions.
.
overview a program consists of a set of paths.
the performance of a program can be exactly captured by characterizing the performance of all program paths.
speci cally we de ne the performance of a path as a tuple pf hpc time probi where pcis the path condition that constraints the test inputs that lead to this path time is the average execution time that the program takes for all the inputs that exercise this path and prob is the probability of executing this path under a usage pro le.
then we de ne the performance distribution of a program as a function relating input probability with execution time where the input probability is the cumulative probability of a set of paths whose execution times fall into an interval.
the histogram at the rightmost of figure 1shows a performance distribution perfplotter generates.
the xandy axes denote the execution time and input probability.
the number of actual feasible execution paths can be very large and it is impossible to run tests for all the paths.
thus we select representative paths by classifying high probability 50figure the overview of our performance analysis framework.
and low probability paths during the path exploration.
the goal is to generate performance distributions that can expose the performance of interest and capture the general trend of the actual performance distributions over all feasible paths.
figure 1presents an overview of perfplotter .
it takes as inputs the java bytecode and the usage pro le of a program.
it generates a performance distribution of the program which highlights the performance of interest.
the internal design of perfplotter aims to address two key challenges how to select representative paths that can expose the performance of interest and how to generate the performance distribution based on the probability and execution time of the paths.
to address the rst challenge we employ symbolic execution to selectively explore two types of paths in two phases.
in the rst phase we explore high probability paths where the majority of inputs will execute.
understanding performance for these paths can help developers learn the performance characteristics of a program for the common inputs.
among these high probability paths we also seek their path diversity aiming to explore high probability paths with a diverse set of behaviors.
in the second phase we explore low probability paths.
our assumption is that these paths often lead to special execution conditions and thus can be useful to expose the performance of interest such as the best case and worst case execution times.
considering there potentially exists an exponential number of paths we de ne a stopping criterion for each phase to terminate see sections .
.
and3.
.
.
for handling loops we apply loop unrolling and a set of heuristics to selecting representative paths in loops see section .
.
.
to address the second challenge we apply path based performance modeling.
we run the generated test inputs for the selected paths and use the probabilities of the paths to construct the performance distribution see section .
.
.
selective path exploration we apply probabilistic analysis and compute the probabilities of outgoing transitions of each branch.
this is the key information used for path selection.
to determine which paths to select the symbolic execution makes two decisions.
first during the exploration of a path we need to decide which outgoing transition of each branch node along the path should be taken.
second after completing the exploration of a path we need to decide which unexplored outgoing transition of the branch nodes in the symbolic execution tree should be taken to start the exploration of a new path.
in the following subsections we explain how the two decisions are made in the two phases of our path exploration.
we will rst show how our approach handles the paths without loops and then we will discuss how to handle paths with loops.
.
.
exploring high probability paths the goal of the rst phase is to explore high probability paths and ensure the path diversity so that the performance characteristics for the frequently executed scenarios can be exposed in a diverse way.
for the rst decision of selecting the outgoing transition at each branch node when exploring a path we always select the outgoing transition that has the higher branch probability.
meanwhile the other outgoing transition that has the lower branch probability is stored in a list utc for further considerations when we make the second decision.
this list maintains all the unexplored outgoing transitions.
for the second decision we use heuristics to combine the goals of exploring high probability paths and ensuring the path diversity.
speci cally we construct an objective function f1 shown in equation .f1computes the tradeo of path probability and path diversity using the weight .
users can con gure dependent on how important the two factors are for a speci c application.
the transition with the highest value off1will be chosen from utcto explore a new path.
in equation the rst term measures the probability of the path for a transition tinutc wherepris the branch probability fort andprob is the probability of the path that leads to the branch node of t. the higher value the rst term results the higher path probability tleads to.
the second term quanti es the degree of path diversity timplies.
speci cally brrepresents the number of branches along the path from the initial node to transition tshared by the previously explored paths.
a smaller value of brindicates a shorter common prex with explored paths suggesting a higher path diversity.
to allow a uni ed measurement of the metrics independent of their units and ranges we scale path diversity into a value between and by comparing it with the minimum brmin and maximum brmax number of branches computed for all the transitions in utc.
f1 pr prob brmax br brmax brmin the path exploration in this phase terminates when the cumulative probability of all the explored paths reaches a coverage probability cp.
users can con gure cpfor speci c applications.
the intuition for this stopping criterion is the rule programs typically spend of the execution time within of the code.
once cpis reached we say the most frequently executed scenarios are covered by the selected paths.
.
.
exploring low probability paths the goal of the second phase is to explore low probability paths so that the performance of interest potentially hidden in the less frequently executed scenarios can be exposed.
following this goal the rst decision is made as follows during the exploration of a path at each branch node we always select the outgoing transition that has the lower branch probability.
at the same time the other outgoing transition that has the higher branch probability is stored in the list utc for further considerations.
for the second decision of selecting a transition to start a new path di erent heuristics can be used to explore paths that potentially expose di erent performance of interest.
we focus on the best case and worst case execution times of a program in this paper.
we construct two objective functions f2 for the best case execution time and f3 for the worst case execution time shown in equation to rank each unexplored transition tinutc.
we select the transition with the 51lowest rank as the starting point of the exploration of a new path with the goal of nding the transitions that most likely lead to the best case and worst case execution times.
shown in equation f2andf3introduce the weights and respectively to represent the tradeo between path probability and path performance.
similar to f1 path probability is de ned using pr prob and pr prob.
path performance is measured by the number of instructions in along the path from the initial node to transition t. a larger smaller value of inindicates a worse better performance.
here the number of instructions is used as a metric for performance with the assumption that the performance of a path is approximately proportional to the number of instructions executed in the path.
similar to path diversity path performance is also scaled into a value between and by comparing it with the minimum inmin and maximum inmax number of instructions for the transitions in utc.
f2 pr prob in inmin inmax inmin f3 pr prob inmax in inmax inmin the path exploration in this phase terminates when none of thelconsecutive selected paths can expose the performance of interest or no path can be further explored.
to do so we compare the real execution time of the path under consideration with the best case and worst case execution time among previously explored paths.
the intuition here is that we seem to already nd all the performance of interest as no performance of interest is exposed for a period of time.
.
.
handling loop structures here our goal is to select a set of representative paths to expose the performance of interest related to loops while capturing the overall performance of loops.
to expose performance of interest we aim to rst select a path with the maximum number of loop iterations when encountering a loop during the path exploration.
thus the rst decision is made as follows when a loop is encountered during the path exploration it is unrolled by selecting the branch transition that keeps the path traversing the loop and its inner loops.
in particular for a branch node resulting from the loop condition we will select the outgoing transition that can lead to the next loop iteration i.e.
selecting the true branch .
for a branch node resulting from a conditional statement inside the loop if either of the two out going transitions breaks out from the loop e.g.
due to break statements we will select the transition that keeps the exploration staying in the loop.
for the branch nodes that are not relevant to the loop termination conditions we will select the transition by the approach introduced in section .
.
and3.
.
depending on whether the exploration is in the rst or second phase.
meanwhile the transitions that represent the unexplored false branch of loop conditions and the transitions that break out from the loop are stored in a list utlfor further considerations.utlmaintains the unexplored transitions of a loop for a set of designated loop iterations.
since a path may sequentially have rloops and each loop needs a list to store its unexplored transitions we maintain futl ij1 i rg.
to capture the overall performance of a loop we need to select a set of paths that contain representative loop iterations.
thus for the second decision we select a set of transitions fromutl i i r as the starting points of the exploration using two sampling based heuristics we select the rst transition i.e.
having the minimum loop iteration and also everys th transition in utl i and we select the transitions with the lowest and highest path probability.
as a result these heuristics explore loop paths with the minimum maximum loop iterations and the lowest highest path probability and also explore other loop paths at intervals with respect to their loop iterations.
sis the sampling interval which can be tuned based on the time budget for performance analysis.
for example scould be set to a large value if the time budget is tight in this case less loop paths will be explored.
.
path based performance modeling a path may be in nite and thus an exploration depth limit i.e.
the number of transitions executed is usually set for a bounded symbolic execution .
when the limit is reached during our selective path exploration the exploration of one path terminates.
as a result we obtain three types of paths completed paths i.e.
paths that are completely explored terminated paths i.e.
paths that are partially explored and terminated due to reaching the limit and uncompleted paths i.e.
paths that are partially explored but not selected by perfplotter .
among them the completed and terminated paths are executed by testing to measure their real execution times.
di erent from a completed path a terminated path is actually a common pre x of a set of di erent paths.
therefore executing such a path using di erent test inputs we may get quite di erent execution times.
in other words the execution time of a terminated path is more volatile than that of a completed path.
for this reason we test each completed and terminated path by running the program respectively on d1 andd2 d1 d number of test inputs and calculating the average of measured execution times.
here d1andd2are the testing sizes which can be speci ed by users.
these test inputs are randomly generated from the path condition by the constraint solvers in spf .
we calculate the execution time of a path by amortizing the execution times from all the runs of the generated test inputs.
based on the data and the probabilities of paths we construct a performance distribution as a histogram to present developers with a graphical representation for a more readily understanding of the performance of a program see the example in figure .
in detail we divide the entire range of the measured execution times into a set of intervals and then draw a rectangle for each path with the height proportional to the path probability and put the rectangle into the interval that the execution time of the path falls into.
we also highlight the top kpaths that expose speci c performance of interest e.g.
worst case execution times .
.
the algorithm algorithm 1shows the detailed procedure of our performance analysis.
it takes program source code and the usage prole as inputs and reports a performance distribution perfdist .
it works through a number of iterations line .
at each iteration it has three steps explore a path starting from a transition sttran and if the path contains loops also explore the representative loop paths starting from the representatives from transl i.e.
futl ij1 i rg line decide if the exploration needs to be switched into the second phase line or if the exploration needs to be terminated line based on the two stopping criteria of each phase respectively and if not terminated select transition s from transc i.e.
utc based on the objective 52algorithm analyzeperformance input program source code usage pro le output perfdist 1phase phase of the exploration 2sttran null the starting transition 3transc fg a list of unexplored transitions 4transl fg lists of unexplored loop transitions 5ts fg a list of selected transitions 6repeat repeat pf explorepath phase sttran transc transl update perfdist with performance of the path pf ts ts frepresentatives from translg transl fg sttran ts.removefirst until sttran null ifphase and stopping criterion then phase else if phase and stopping criterion then return perfdist ifphase then ts ts ftran intransc that maximizes f1g transc transcnftrang else if phase then ts ts ftran intransc that minimizes f2g transc transcnftrang ts ts ftran intransc that minimizes f3g transc transcnftrang sttran ts.removefirst 27until sttran null 28return perfdist function s i.e.
f1 orf2andf3 to start the exploration of new path s line .
the algorithm terminates if the stopping criterion is satis ed or no path could be further explored and then returns the performance distribution.
speci cally in the second step at line algorithm 2is invoked for exploring a path starting from the transition sttran .
the goal of this step is to generate performance model for one path and the output pfreports the path condition path probability and execution time.
initially algorithm 2starts from the initial state of the program i.e.
sttran isnull .
whenever a condition is encountered it introduces one branch node and computes its path condition pcand path probability prob.
it also introduces two transitions and computes their probabilitiesprcandpr c line .
if the condition is from a conditional statement that might break out from a loop it aways selects the transition that keeps the exploration staying in the loop if feasible and stores the other one in transl i.e.
futl ij1 i r for further exploration line otherwise it selects a transition based on the speci c heuristic of each phase and stores the other one in transc i.e.
utc for further exploration line .
if the condition is from a loop structure it selects the true transition if feasible while stores the false one in transl for further exploration line .
whenever a new loop structure is encountered an empty list is inserted into transl for storing its unexplored transitions line .
the iteration stops if the path is completed or the exploration depth limit is reached line .
then the algorithm obtains the execution time of the explored path by testing generated inputs line and returns the performance of the path line .
.
implementation and evaluation we implemented perfplotter using java based on the spfalgorithm explorepath input phase sttran transc transl output pf 1start symbolic execution from sttran until a condition c 2repeat introduce a branch node compute its pcandprob introduce transitions tcandt c computeprcandpr c ifc is from a conditional statement then ifc may break out from a loop then select the transition that stays in loop if feasible and add the other transition to transl.last else if phase then transc transc ftransition with low prg select the transition with high pr else if phase then transc transc ftransition with high prg select the transition with low pr else if c is from a loop structure then ifc is feasible then ifloop entry then transl transl fg transl.last transl.last ft cg selecttc else selectt c continue symbolic execution until a condition c 23until the path is completed orthe limit is reached 24get the execution time time of the explored path by testing 25return pf hpc prob time i infrastructure and its probabilistic symbolic execution engine .
in perfplotter we use choco to solve linear integer constraints and coral to solve oating point constraints.
we use latte to compute the probability of conditional branches related to linear integer constraints and integrate qcoral to compute the probability of conditional branches related to oating point constraints.
perfplotter is available at our website with all the software artifacts and experimental data used in our evaluation.
.
evaluation setup to evaluate whether perfplotter is e ective and can compute meaningful performance distributions that highlight the performance of interest we compared the performance distributions generated by perfplotter with those generated by the exhaustive symbolic execution ese approach.
in the ese approach we use symbolic execution to exhaustively explore all program paths and generate performance distributions by testing all these program paths.
thus the ese approach can be regarded as the baseline.
to evaluate whether perfplotterperforms better than a random testing rt approach and thus can be considered worthwhile we compared perfplotterwith a rtapproach where we generate performance distributions using a set of randomly generated test inputs.
to evaluate if the heuristics applied in perfplotter are e ective in selecting the paths of interest we compared perfplotter with the random symbolic execution rse approach where the two decisions for the path exploration see section .
are made randomly.
note that to make a fair comparison across these approaches the rtandrseapproaches are limited to run the same amount of time as perfplotter .
we selected the following software artifacts as our experimental subjects.
note that our implementation is dependent on spf and spf is not yet able to handle large artifacts because of the challenges in symbolic execution similar expe53rience has been shown in other work .
to the best of our knowledge we have used all the largest and publicly available artifacts spf can handle.
quick sort this program performs the quick sort on an array of size n. it contains n!
feasible paths and there is only one path that leads to the worst case time complexity.
the performance of this program depends on the choice of pivot and we set the middle element as the pivot.
we analyzed a version forn with paths the number is reported by the exhaustive symbolic execution approach .
single loops this program contains two single loops executed in sequence.
the iterations of each loop depend on an input variable.
we limited the two input variables to .
this program contains a total of paths.
nested loop this program contains a nested loop.
the iterations of the inner and outer loop depend on two input variables.
we limited the two input variables to which leads to a total of paths.
treemap this program is the red black tree implementation in the java library.
we analyzed the performance of a sequence of calls to putandremove methods.
the program has .6k lines of code with paths.
apollo apollo lunar autopilot is a java program automatically translated from a simulink model .
the model is available from mathworks .
it decides the transition between reandcoast states as well as the reaction jet to re.
it contains .6k lines of code with paths.
cdx the cdx system is a simulator for aircraft collision detection.
the detector module detects collisions according to the current and next positions of the aircrafts which has .2k lines of code.
we analyzed this module for aircrafts which leads to a total of paths.
tsafe tactical separation assisted flight environment is designed by nasa and faa to predict ight con icts and alert air tra c controllers.
we analyzed the conformance monitor module which checks if a ight is conforming to the planned route and assigns or synthesizes a trajectory.
this module has .0k lines of code with paths.
in the evaluation we assumed a uniform usage pro le for all input variables.
to con gure perfplotter we set the weights and to .
and testing sizes d1andd2to and see section 3for details of the parameters .
we studied the settings of other three key parameters in our experiments cp the coverage probability for stopping exploring high probability paths l the number of consecutive paths executed but not exposing any best case or worst case execution times and s the sampling interval for selecting loop paths.
we report our empirical results regarding these parameter settings in the following sections.
we ran our experiments on a desktop with .
ghz intel xeon e5 v2 cpu and gb ram.
our evaluation answers the following research questions rq1 can perfplotter generate meaningful performance distributions that well capture the general trend of the actual performance distributions?
rq2 can perfplotter expose the performance of interest with high coverage and low overhead?
rq3 are the heuristics applied in perfplotter e ective in selecting the paths of interest?
rq4 what are the potential application scenarios of the generated performance distributions of perfplotter ?
.
performance distributions rq1 and rq3 figure 2shows the generated performance distributions for the subject programs by the ese rt rseand perfplotter approaches.
the xaxis denotes the execution time and the yaxis denotes the input probability i.e.
the cumulative probability of a set of paths whose execution time falls into an interval .
for clarity we compared the results of the approaches using the line charts.
the histogram versions of performance distributions are available at our website .
the rtapproach is expected to approximate the actual performance distributions generated by the eseapproach however figure 2shows that it greatly over under approximated the probability for certain execution time intervals e.g.
.
.
for quick sort for nested loop for cdx and for tsafe.
besides it falsely identi ed the execution time that most frequently occurs for single loops nested loop treemap apollo and cdx.
such deviations are caused by the stochastic nature of the test input generation where certain regions of the input domain might be densely sampled while others might be sparsely sampled.
moreover the rtapproach failed to capture the entire range of execution times for apollo i.e.
the execution times larger than nanoseconds and cdx i.e.
the execution times larger than nanoseconds because the corresponding test inputs are hard to hit during random testing.
the rseandperfplotter approaches are expected to generate similarly shaped performance distributions to the ese approach because they sample a much smaller space of the input domain than the eseapproach.
as shown in figure their cumulative probabilities for all inputs are less than the eseapproach.
however the rseapproach failed to capture the entire range of execution times i.e.
the worst execution times for single loops nested loop and treemap.
this is because of the fact that random symbolic execution often tends to uncover shorter paths more easily than longer paths due to the stochastic nature especially when the program has deep paths.
in addition the rseapproach produced much less complete performance distributions than perfplotter for treemap apollo cdx and tsafe since it often fails to explore highprobability paths due to its stochastic nature.
di erently figure 2demonstrates that perfplotter generated performance distributions that capture the entire range of execution times and the general trend of the actual one for all the programs.
the curves generated by perfplotter have similar shapes as the ones generated by the eseapproach.
further it better exposed the best case and worst case execution times than the rseapproach see details in section .
.
it indicated that by heuristically exploring high probability paths while seeking path diversity we are able to capture performance characteristics for a variety of most frequently executed paths and by heuristically exploring low probability paths while considering path performance we are able to expose corner cases hidden in less frequently executed paths.
apart from the comparisons with the three approaches we evaluated the con guration parameters of perfplotter and observed how di erent settings of cp landscould generate di erent performance distributions.
in figure a e g i and k we compared the two performance distributions generated when lwas xed and cpwas changed.
our nding is that when the value of cpincreases the performance distribution becomes more complete and captures the general trend more e ectively because more paths are explored in the rst phase.
similarly we xed cpand changed lin figure b a 4xlfn 6ruw execution time ms .
.
.
.
.
.
.
.
.
.8probability .
.
.
.
.
.
.
ese rt rse perfplotter cp .
l perfplotter cp .
l .
.
.
.
.
.
b 4xlfn 6ruw execution time ms .
.
.
.
.
.
.
.
.
.8probability .
.
.
.
.
.
.
ese rt rse perfplotter cp .
l perfplotter cp .
l .
.
.
.
.
.
c 6lqjoh rrsv execution time ms 230probability .
.
.
.
.
.
ese rt rse perfplotter s perfplotter s .
.
d 1hvwhg rrs execution time ms 1005probability .
.
.
.
.
.
ese rt rse perfplotter s perfplotter s .
.
.
e 7uhh0ds execution time ns .
.
.
.
.
.
.
.
.
.
.
.
.
.05probability .
.
.
.
.
.
.
.
.
ese rt rse perfplotter cp .
l perfplotter cp .
l .
.
.
.
.
.
.
f 7uhh0ds execution time ns .
.
.
.
.
.
.
.
.
.
.
.
.
.05probability .
.
.
.
.
.
.
.
.
ese rt rse perfplotter cp .
l perfplotter cp .
l .
.
.
.
.
.
.
g sroor execution time ns .
.
.
.
.
.
.
.
.
.
.
.
.25probability .
.
.
.
.5ese rt rse perfplotter cp .
l perfplotter cp .
l .
.
.
.
.
h sroor execution time ns .
.
.
.
.
.
.
.
.
.
.
.
.25probability .
.
.
.
.5ese rt rse perfplotter cp .
l perfplotter cp .
l .
.
.
.
.
i execution time ns .25x1040.50x1040.75x1041.00x1041.25x1041.50x1041.75x1042.00x1042.25x1042.50x1040.6x1081.2x1081.8x1082.4x1083.0x1083.6x1084.2x108probability .
.
.
.
.
.
.
.
.
ese rt rse perfplotter cp .
l perfplotter cp .
l .4x1083.0x1083.6x1084.2x108 j execution time ns .25x1040.50x1040.75x1041.00x1041.25x1041.50x1041.75x1042.00x1042.25x1042.50x1040.6x1081.2x1081.8x1082.4x1083.0x1083.6x1084.2x108probability .
.
.
.
.
.
.
.
.
ese rt rse perfplotter cp .
l perfplotter cp .
l .4x1083.0x1083.6x1084.2x108 k execution time ns 7250probability .
.
.
.
.
.
ese rt rse perfplotter cp .
l perfplotter cp .
l .
l execution time ns 7250probability .
.
.
.
.
.
ese rt rse perfplotter cp .
l perfplotter cp .
l .51f igure generated performance distributions for the software artifacts.
f h j and l .
we found that with the increase of l the generated performance distributions are similar but perfplotter can better expose the best case and worst case execution times.
the reason is that a stricter stopping criterion for exploring the low probability paths is used as lincreases which is helpful for nding corner cases.
finally we reported our experiments on di erent sampling intervals for the loops in figure c and d .
when sincreases a smaller subset of representative loop paths are selected as a result the generated performance distributions become less complete and capture the general trend of the actual ones less e ectively.
in summary the experimental results in figure 2demonstrated that the rtand rseapproaches are not dependable to compute performance distributions and their results may mislead users and developers about the performance of programs.
it also showed that the heuristics used in perfplotterare e ective in selecting paths of interest and thus perfplotter can generate meaningful performance distributions that capture the general trend and entire range of execution times with a small set of test inputs.
.
coverage and overhead rq2 and rq3 table 1reports the comparison of perfplotter and the rt andrseapproaches on two metrics the coverage for performance of interest and the time overhead used to generate the performance distributions.
under subject and approach we provide involved software artifacts and approaches with the setting of parameters for running perfplotter .
under path we report the percentage of the paths explored by the perfplotter andrseapproaches.
this dimension is not analyzed for the rtapproach because it is not path based.
under bestcase et and worst case et we show that among the top and best case or worst case paths found by the eseapproach the percentage of such paths that are explored by theperfplotter rtand rseapproaches.
in particular for perfplotter we provide further details the number before and after is respectively the percentage obtained during the rst and second phase.
under analysis time we give the total time used for each approach under total .
for the perfplotter andrseapproaches we distinguish the time for exploring paths under expand the time for running tests under test.
the performance is a relative measure and reports the percentage of the time of the eseapproach.
table 1indicates that the rtapproach achieved the lowest coverage for the best case and worst case paths.
in particular for the larger artifacts i.e.
treemap apollo cdx and tsafe it almost failed to expose any best case and worstcase paths.
this is because with the extremely large space of the input domain random testing often fails to hit the corner cases hidden in the extremely low probability paths.
the rseapproach achieved a higher coverage for the bestcase and worst case paths than the rtapproach.
in particular for single loops nested loop and treemap it achieved a very high coverage for best case paths but an extremely low coverage for worst case paths as illustrated in figure c f since the rseapproach tends to uncover shorter paths more easily than longer paths due to its stochastic nature.
however when a program does not have relatively shorter paths as in the case of apollo cdx and tsafe the rseapproach has a similar coverage for the best case and worst case paths.
perfplotter obtained a higher coverage for the best case and worst case paths than the rseapproach on average as illustrated in figure .
on average the rseandperfplotter approaches respectively found .
and .
of the top best case and worst case paths by exploring .
and .
of the total paths within the same amount of time.
this re55table comparison of perfplotter with the rtand rseapproaches on coverage and overhead subject approachpath best case et worst case et analysis time top top top top top top exp test total quick sortcp 3l .
.
.
.
l .
.
.
.
cp 4l .
.
.
.
l .
.
.
.
rt .
rse .
.
.
.
single loopss .
.
.
.
s .
.
.
.
rt .
rse .
.
.
.
nested loops .
.
.
.
s .
.
.
.
rt .
rse .
.
.
.
treemapcp 6l .
.
.
.
l .
.
.
.
cp 7l .
.
.
.
l .
.
.
.
rt .
rse .
.
.
.
apollocp 6l .
.
.
.
l .
.
.
.
cp 7l .
.
.
.
l .
.
.
.
rt .
rse .
.
.
.
cdxcp 6l .
.
.
.
l .
.
.
.
cp 7l .
.
.
.
l .
.
.
.
rt .
rse .
.
.
.
tsafecp 6l .
.
.
.
l .
.
.
.
cp 7l .
.
.
.
l .
.
.
.
rt .
rse .
.
.
.
sult also indicated the e ectiveness of the heuristics used in perfplotter to select paths of interest.
besides for the top and best and worst cases perfplotter had an increasing coverage which demonstrated that it uncovers the best and worst cases with a good accuracy.
ascpandlincreased in the case of quick sort treemap apollo cdx and tsafe the coverage for the best case and worst case paths also increased.
this is because the rst phase diversely explores more high probability paths as cpincreases and thus paves the way for the second phase and the second phase applies a stricter stopping criterion as lincreases and thus explores more paths of interest.
we also found that for these artifacts most best case and worst case paths were exposed in the second phase.
this empirically validates our assumption that corner cases like best case and worst case execution times likely occur in low probability paths and our path exploration in two phases is reasonable and e ective.
assincreased in the case of single loops and nested loop perfplotter exposed less best case and worst case paths as illustrated in figure c d .
this is reasonable because perfplotter selects a smaller set of representative loop paths for exploration as sincreases.
we found that for these two loop programs all the best and worst cases are uncovered in the rst phase.
the reason is that there are no other branches except for loop conditions in these two loop programs and all the representative loop paths are designed to be explored together to capture the overall performance of loops.
in terms of time overhead table 1shows that perfplot tertook .
of the total time of the eseapproach for exploring .
of the total paths on average since the path exploration in perfplotter is selective and thus needs more computation time than the eseapproach.
if the time for running tests is more dominant than that for path exploration which is the case for most artifacts except for quick sort and tsafe perfplotter s overhead for path exploration will be insigni cant.
note that we analyzed a version of quick sort forn the eseapproach ran out of memory while perfplotter produced a similar distribution to figure a here we omit the distribution but it is available at our website .
in summary our experimental data in table 1showed that perfplotter can nd the best case and worst case paths that manifest the best case and worst case execution times with high coverage and low overhead by heuristically exploring a small set of program paths and perfplotter is more accurate than the rtandrseapproaches and more time e cient than the eseapproach to expose the performance of interest and generate performance distributions.
.
application scenarios rq4 in this section we report our experience of applying performance distributions generated by perfplotter in three typical scenarios applying the performance distribution of a single version of a program to performance understanding comparing the two performance distributions generated from the two versions of a program to bug validation and comparing the performance distributions of functionally equivalent pro56 a 3huirupdqfh xj execution time ms 2250probability .
.
.
.
.
.
.
.
.
.2ese buggy perfplotter buggy ese fixed perfplotter fixed .
.
.
.
.
.
.
.
.
.
.
.
.
.
b 6ruwlqj 6hohfwlrq execution time ms probability .
.
.
.
.
.
.
ese quick sort perfplotter quick sort ese bubble sort perfplotter bubble sort ese merge sort perfplotter merge sortfigure application scenarios of perfplotter .
grams to algorithm selection.
performance understanding .
from the performance distribution of a program we can obtain various performance indicators such as best case worst case average most likely and least likely execution time as well as the corresponding test inputs.
these indicators especially the ones whose values are out of expectation can help reveal performance or even functional bugs.
for example the artifact cdx contains a divideby zero bug in method isinvoxel of class reducer reported by spf.
to x this bug we need to add an exception handling routine and either return true orfalse for the method.
however the code is complex and it is not straightforward on which value should be returned to x the bug.
we generated a performance distribution for the case we return true and discovered that cdx had abnormal worst case execution times that were extremely larger than the others see figure i .
by investigating the collected path conditions of those abnormal worst cases and running the generated corresponding test inputs we found that all those worst cases executed the true branch we added for xing the bug.
that is our x was the cause of those abnormal worst cases.
by closely looking into the code we found that the bug is complex and just adding a return true statement is not su cient to x it.
thus we have reported the bug to the authors.
bug validation.
fixing bugs that manifest for some inputs may slow down the executions for other inputs .
thus it is very important to comprehensively validate if a bug x will cause any performance regressions.
the performance distributions generated via perfplotter before and after the bug x can serve this purpose.
figure a shows such performance distributions for a program that has a performance bug in a nested loop.
the inner loop has a redundant and expensive computation that computes the same result in each iteration of the outer loop.
thus the redundant computation can be moved to the outer loop so that it is computed only once in each iteration of the outer loop.
this bug was a simpli ed version adapted from the example in .
from figure3 a we can observe that by comparing buggy and xed versions perfplotter accurately captured the performance speedup as the eseapproach did the worst case execution time sped up from to ms and the average execution time sped up from to ms. we also see that the probability of the most likely execution time increased.
note that perfplotter cannot validate the correctness of bug xes but it can provide some hints on how the bug x can impact the program performance in general from which we then can determine whether the bug x can be correct as shown for the divide by zero bug in cdx.
it is our future work to apply di erence algorithms to paths so that we can track pathbased performance regressions and locate their root cause.
algorithm selection .
developers often choose algorithms e.g.
sorting algorithms and data structures randomly or byexperience which may lead to performance bugs .
the performance distributions can help visually compare the performance of di erent algorithms and hence facilitate the selection.
figure b shows the performance distributions of quick sort bubble sort and merge sort.
compared to theoretical time complexity analysis perfplotter can provide more ne grained performance indicators as we use the implementation details that often deviate from the theoretical time complexity.
for example both quick sort and bubble sort have the worst time complexity of o n2 but perfplottershows that quick sort s worst case is faster than bubble sort s by around ms in this context i.e.
n .
this also indicates that the constant in algorithm analysis using bigonotation really matters for performance analysis.
by comparing their performance distributions merge sort is the better choice in this context.
note that perfplotter cannot guarantee that the worst case paths will actually be explored due to the heuristics nature.
another potential application is to apply perfplotter to con gurable systems for predicting the performance distributions under di erent con guration options and then helping select the optional con guration.
.
discussions there are two main threats in our evaluation.
first the target artifacts were not very large and the target input domain was bounded tightly.
further studies are required to generalize our ndings in real life programs.
second symbolic execution could fail to re ect real program execution behaviors due to the bounded exploration depth.
thanks to the impact of strati ed sampling as in the eseapproach can provide a satis able baseline.
in fact perfplotter which is based on symbolic execution can still improve the performance distributions over random testing.
perfplotter is con gurable via a set of parameters.
the testing sizes d1andd2can be tuned based on the variance of execution times as well as the number of solutions executing the path.
a larger variance or number may suggest a larger testing size.
for the key parameters cp lands our empirical results suggest that if a program contains paths that report high probability we need to set cpto a high value so that a su cient number of high probability paths are explored.
as in the case of apollo we set cpto .
.
meanwhile lshould be set to a large value e.g.
so that the low probability paths which may have extremely small probability in such programs could be su ciently explored.
if a program does not have paths of high probability cpandlshould be set to a small value as in the case of quick sort.
for s it can be set to a small value e.g.
if the time budget is loose otherwise it can be set to a large value but may reduce the coverage.
perfplotter has a few underlying assumptions which may limit its application and threat its validity.
first we focus on sequential programs with integer and oating point inputs.
we are extending perfplotter to support non deterministic programs with the advances in probabilistic symbolic execution for such programs and to support path conditions over strings with smc .
second we assume usage pro les can be provided by developers.
in fact such pro les can be inferred by formal speci cations or automatic extraction techniques .
lastly we assume the performance of a path is approximately proportional to the number of instructions executed in the path which is similarly done in the literature e.g.
but do not explicitly consider the impact of 57environments e.g.
instruction pipelines caches jvm optimizations or just in time compilation on performance.
as a result the generated performance distributions might not be accurate.
one remedy is to apply a more sophisticated performance model e.g.
incorporating low level details for the instructions.
another remedy is to model the performance of a path itself as a distribution which is more informative but not an average value.
this can also improve the applicability ofperfplotter to programs where black box apis are invoked and take a huge amount of time for speci c inputs.
.
related work instead of listing all related work we focus on the most related ones static and dynamic program analysis based performance analysis and probabilistic symbolic execution.
.
static analysis based approaches burnim et al.
use symbolic execution to generate worstcase test inputs for large input sizes and zhang et al.
propose a directed symbolic execution to derive high load test inputs.
in addition a large body of work analyzes the worstcase execution time for real time and embedded systems .
these approaches focus on the worst case performance while our framework derives a performance distribution.
zhang predicts the performance of a program in terms of some performance indicators as a weighted sum of the performance of all feasible program paths.
this work is the closest to ours.
however their description is quite general and exhaustive symbolic execution is used to explore all the paths while our framework partially explores the paths to generate a performance distribution and expose corner cases.
buse and weimer predict the relative frequency of control ow paths by machine learning techniques.
di erently our framework uses probabilistic symbolic execution to get the absolute path frequency which could be more accurate to construct the performance distribution.
gulwani et al.
compute an upper bound on the worst case computational complexity for a program while we generate a performance distribution of the actual execution times.
chattopadhyay et al.
analyze the cache performance of real time and embedded programs.
they partition the input domain by path programs and compute the bound on cache misses of each path program by static invariant generation.
similarly we also partition the input domain based on paths.
di erently we study execution time instead of cache misses and explore paths heuristically rather than exhaustively.
.
dynamic analysis based approaches several program pro ling techniques e.g.
have been proposed to analyze execution traces of an instrumented program for predicting execution frequency of program paths and identifying hot paths.
in contrast to our framework these techniques need a larger number of executions to statistically cover the input domain for a high accuracy and thus heavily rely on the given inputs.
moreover our framework can automatically generate the test inputs by constraint solving.
besides these path sensitive pro ling techniques there has been some recent work on input sensitive pro ling techniques e.g.
.
they run an instrumented program with a set of di erent input sizes measure the performance of each basic block and t a performance function with respect to input sizes.
the accuracy of the performance function heavily relies on the chosen inputs but our framework can automat ically generate the test inputs.
moreover di erent from their basic block pro ling we focus on paths because paths contain more information than individual basic blocks and pathbased frequency can be more useful for developers to understand a program see ball et al.
for a detailed discussion .
finally some research e orts have been made on identifying the critical path of distributed systems and mobile applications by analyzing execution traces.
critical path analysis is often used to nd performance bottlenecks.
they deal with non deterministic programs while we currently focus on deterministic programs.
in addition these approaches identify the critical path while our framework produces a performance distribution and exposes performance of interest with its probability of occurrence.
.
probabilistic symbolic execution probabilistic symbolic execution has been recently proposed to support probabilistic analysis at the source code level.
it has been applied to program understanding and debugging reliability analysis and quanti cation of information leaks and software changes .
here we apply probabilistic symbolic execution to performance analysis.
for the scalable probabilistic symbolic execution sankaranarayanan et al.
propose to compute interval bounds on the probability from an adequate set of paths and filieri et al.
propose a statistical symbolic execution.
their purpose is to compute the path probability e ciently while we use some performance speci c heuristics to partially explore the paths to generate a performance distribution.
further several advances have been made to quantify the solution space for constraints.
sankaranarayanan et al.
propose a volume computation technique to quantify the solution space for linear constraints over bounded integers and oats.
luu et al.
propose a model counter to quantify the solution space for constraints over unbounded strings.
these approaches are all orthogonal to our framework and we plan to integrate to support path constraints over strings.
.
conclusions in this paper we proposed the concept of performance distributions as well as a performance analysis framework perfplotter for automatically generating them.
perfplotter applies probabilistic symbolic execution to perform a selective path exploration and generate meaningful performance distributions for programs.
we have implemented perfplotter and experimentally demonstrated that by exploring a small set of program paths perfplotter can generate the performance distribution that captures the general trend of the actual one and exposes the performance of interest with high coverage and low overhead and such performance distributions can be useful in performance understanding bug validation and algorithm selection.
in the future we plan to extend our framework to detect performance bugs and understand other aspects of software qualities e.g.
energy .
.
acknowledgment this work is supported in part by the national research foundation prime minister s o ce singapore under its national cybersecurity r d program award nrf2014ncrncr001 and administered by the national cybersecurity r d directorate and by the us national science foundation nsf under award .
.