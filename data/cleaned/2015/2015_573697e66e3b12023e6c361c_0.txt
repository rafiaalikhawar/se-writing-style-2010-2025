reverse engineering mobile application user interfaces with remaui tuan anh nguyen christoph csallner computer science and engineering department the university of texas at arlington arlington tx usa email tanguyen mavs.uta.edu csallner uta.edu abstract when developing the user interface code of a mobile application in practice a big gap exists between the digital conceptual drawings of graphic artists and working user interface code.
currently programmers bridge this gap manually by reimplementing the conceptual drawings in code which is cumbersome and expensive.
to bridge this gap we introduce the first technique to automatically reverse engineer mobile application user interfaces remaui .
on a given input bitmap remaui identifies user interface elements such as images texts containers and lists via computer vision and optical character recognition ocr techniques.
in our experiments on screenshots of over popular third party android and ios applications remaui generated user interfaces were similar to the originals both pixel by pixel and in terms of their runtime user interface hierarchies.
remaui s average overall runtime on a standard desktop computer was seconds.
i. i ntroduction and motiv a tion developing the user interface code of mobile applications is cumbersome and expensive in practice.
due to the early consumer and entertainment focus of the two major platforms android and ios and the high competitive pressure in the mobile application market users have come to expect mobile user interfaces that are highly customized and optimized for the task at hand .
to satisfy this demand mobile user interfaces often deviate from their platforms standard user interface ui components and provide their own novel or customized ui elements such as buttons dividers and custom element positioning and grouping.
to create such optimized user interfaces the development process of mobile applications routinely incorporates nonprogrammers.
user experience ux designers and graphic artists design customize and optimize each screen of the user interface with a mix of prototyping techniques.
common prototyping techniques include paper and pencil and pixel based concept drawings created in photoshop or similar graphic design tools .
our key observation is that there is a gap in the production process as user interface concept drawings have to be converted into working user interface code.
currently these conversions are done manually by programmers which is cumbersome error prone and expensive.
while modern ides such as eclipse xcode and android studio have powerful interactive builders for graphical user interface gui code using such a gui builder to re create a complex user interface drawing is a complex task.
for example in an evaluation of gui builders on a set of small tasks subjectsusing apple s xcode gui builder introduced many bugs that later had to be corrected.
subjects produced these bugs even though the study s target layouts were much simpler than those commonly found in third party mobile applications .
this challenge is compounded in practice.
first custom layouts are often desired but it is harder to create them with a stock gui builder.
second the conversion from user interface concept drawing to user interface code is typically performed many times during an application s lifespan.
the reason is that many development teams follow an iterative approach in which a user interface may undergo many revisions during both initial software development and maintenance.
this gap in the mobile application development process is significant as many mobile applications are being developed and maintained.
for example in the usa over of consumers over years of age use a mobile phone and more than half of the mobile phones are smartphones mostly running android or ios .
on these smartphones people use mobile applications to perform many tasks that have traditionally been performed on desktop computers .
example tasks include reading and writing emails listening to music watching movies reading the news and consuming and producing social media.
to date more than one million mobile applications have been released1.
automating the conversion from user interface design drawings to working user interface code may therefore save a lot of time and money which could be put to better use.
converting a conceptual drawing of a screen into good user interface code is hard as it is essentially a reverse engineering task.
as in other reverse engineering tasks general principles have to be inferred from specific instances.
for example a suitable hierarchy of user interface elements has to be inferred from a flat set of concrete pixels.
compared to other reverse engineering tasks such as inferring design documents from code an unusual additional challenge is that the input i.e.
the pixels may originate from scanned handwriting and human sketches with all their imperfections .
this means that sets of pixels have to be grouped together and recognized heuristically as images or text.
then groups of similar images and text have to be recognized heuristically as example elements of collections.
and for the ui of innovative mobile applications at each step the recognized elements may diverge significantly from the platform s standard ui elements.
30th ieee acm international conference on automated software engineering .
ieee authorized licensed use limited to tsinghua university.
downloaded on october at utc from ieee xplore.
restrictions apply.
g10 g12 g34 g12 g22 g29 g12 g1 g12 g25 g20 g39 g1 g3 g21 g24 g2 g22 g23 g12 g1 g4 g12 g2 g23 g21 g3 g1 g41 g1 g10 g33 g25 g1 g2 g2 g2 g1 g11 g11 g22 g12 g12 g25 g29 g21 g21 g30 g1 g11 g21 g33 g22 g11 g12 g1 g3 g21 g1 g12 g1 g15 g25 g1 g1 g10 g12 g29 g21 g33 g22 g11 g12 g29 g1 g12 g12 g31 g30 g1 g2 g22 g29 g30 g1 g22 g30 g12 g24 g1 g13 g g1 g14 g22 g12 g35 g1 g1 g22 g12 g22 g15 g22 g11 g21 g3 g1 g g24 g15 g20 g12 g1 g3 g21 g25 g30 g15 g22 g25 g12 g22 g1 g11 g21 g33 g22 g11 g12 g1 g3 g21 g1 g12 g1 g41 g1 g2 g15 g3 g21 g33 g30 g1 g4 g12 g19 g25 g22 g31 g21 g25 g1 g40 g1 g g24 g15 g20 g12 g29 g1 g12 g12 g31 g30 g1 g6 g14 g16 g20 g1 g2 g8 g12 g12 g14 g19 g1 g10 g14 g17 g1 g7 g15 g8 g1 g18 g14 g16 g1 g2 g16 g14 g13 g9 g1 g4 g9 g16 g18 g8 g13 g1 g4 g14 g17 g1 g3 g11 g13 g9 g1 g5 g16 g1 g5 g31 g2 g21 g22 g30 g1 g22 g9 g11 g1 g6 g14 g16 g20 g1 g2 g11 g1 g10 g11 g1 fig.
.
example remaui use the ui designer provides a conceptual ui drawing left .
remaui identifies ui elements such as lists of text and images and arranges them in a suitable ui hierarchy.
remaui then exports the inferred ui as source code and resource files compiles them and runs them on a phone.
for professional application development one may wonder if this reverse engineering step is artificial.
that is why are meaning and source code hierarchy of screen elements notexplicitly encoded in the conceptual design drawings if theseare done in digital tools such as photoshop?
one reason is thatsome ux designers start with pencil on paper so it would be desirable to convert such drawings directly into working user interface code.
more significantly when ux designers create digital bitmap images typically by drawing them in photoshop thedigital design tools do not capture the hierarchy informationthat is needed by user interface code.
more importantly it isnot clear if ux designers and graphic artists want to think interms of source code hierarchies.
while this gap is most apparent in forward engineering there may also exist a traditional reverse engineering scenario.a developer may only have access to screenshots of a mobileapplication maybe after losing all other software artifacts suchas the source code.
in such a situation it would be desirableto automatically infer from the screenshots the user interface portion of the missing source code.
this paper therefore identifies and addresses three problems in mobile application development.
in reverse engineering we address the problem of inferring the user interfacecode of a mobile application from screenshots.
in forwardengineering we address the gap between scanned pencil on paper ui sketches and code as well as the gap between pixel based ui sketches and code.
while these problems occur atdifferent times in the development process they share the taskof pixels to code inference.
specifically this paper introduces the first technique to automatically reverse engineer mobile application user interfaces remaui .
remaui automatically infers the user interface portion of the source code of a mobile application fromscreenshots or conceptual drawings of the user interface.
on agiven input bitmap remaui identifies user interface elementssuch as images text containers and lists via computer visionand optical character recognition ocr techniques.
remauifurther infers a suitable user interface hierarchy and exportsthe results as source code that is ready for compilation andexecution.
the generated user interface closely mimics the userinterface of a corresponding real application.
to summarize the paper makes the following major contributions.
the paper describes remaui the first technique for inferring mobile application user interface code fromscreenshots or conceptual drawings.
to evaluate remaui we implemented a prototype toolthat generates the ui portion of android applications.this tool is freely available via the remaui web site.
in an evaluation on screenshots of over popularthird party mobile applications remaui generated uiswere similar to the originals pixel by pixel and in theirruntime ui hierarchy.
ii.
m otiv a ting example as a motivating example assume a ux designer has produced the screen design bitmap shown in the left of figure .the top of the screen contains the user s profile image and anicon.
below is a list in which each entry has a person s imageon the left the person s name and text message in the middle and the message date on the right.
list entries are separated by horizontal bars.
the bottom of the screen has four icons and their labels.
remaui infers from this bitmap working ui code by mimicking the steps a programmer would take.
remaui thususes vision and character recognition techniques to reasonabout the screen bitmap.
remaui groups related pixels intotext or images lines of text into text boxes related items intocontainers and repeated elements into list elements.
remauithus identifies non standard user interface components such asarbitrarily shaped items e.g.
the round images on the left andnon standard lists e.g.
using the special horizontal separator .
authorized licensed use limited to tsinghua university.
downloaded on october at utc from ieee xplore.
restrictions apply.
relativelayout !
list entry ... imageview !
horizontal bar ... imageview android id id imageview android layout width 59dip android layout height 61dip android layout marginleft 5dip android layout margintop 0dip android src drawable img android scaletype fitxy android layout alignparenttop true android layout alignparentleft true relativelayout !
nested text block center ... textview !
sender name ... textview !
message ... relativelayout textview !
message date right ... relativelayout listing .
remaui generated layout for each list entry of figure .
details are only shown for the left part of a list entry.
remaui generates several xml files to capture the screen s static properties.
in our example the main xml file declares and positions the elements of the top and bottom rows including icons and their labels.
this file also contains a list view for the bulk of the screen content.
the layout of each list entry is defined by the listing xml file.
for example it positions a contact s image and aligns it with the top left of its parent alignparenttop alignparentleft .
remaui recognizes aligned text blocks such as the sender s name and message groups them into a nested layout container listing and exports the recognized text fragments as an android resource file.
at application runtime the list entries are added by the also generated listing java source code.
public class mainactivity extends activity .. private void addlistview0 listview v listview findviewbyid r.id.listview final arraylist listi values new arraylist listi values.add new listi r.drawable.img r.drawable.img r. string.string r.string.string r.string.string .. .. listing .
remaui generated android i.e.
java source code that populates listing list entries at application runtime.
the generated ui code and layout definitions can be compiled with standard android development tools.
moreover the code is similar to how a professional developer would implement the screen.
for example the generated code uses the appropriate kinds of layout container such as relativelayout for the list entries.
a relativelayout can eliminate the need for some nested containers and thus keep the layout hierarchy relatively flat which improves rendering performance at application runtime.
iii.
b ackground this section contains necessary background information on gui programming modern mobile phone guis and computer vision and optical character recognition ocr .a.
gui view hierarchy declarative gui programming the graphical user interface gui of many modern desktop and mobile platforms is structured as a view hierarchy .
such a hierarchy has two types of nodes leaf nodes images buttons text etc.
and container nodes.
the root view represents an application s entire space on screen.
the root can have many transitive children.
each child typically occupies a rectangular sub region of its parent.
each view can have its own parameters such as height width background color and position.
a view can be positioned relative to the root or other views such as its parent or siblings.
mobile platforms such as android and ios render a parent view before its children on screen.
a child view thus hides parts of its parent.
siblings are drawn in the order they are defined.
a best practice is to minimize rendering time waste by keeping hierarchies flat and avoiding view overlap.
given the relatively small mobile phone screen size mobile platforms make it easy to hide their default screen elements such as the ios title bar or the android navigation bar.
applications often use this feature to maximize screen size.
to define basic gui aspects modern platforms provide two alternatives.
the traditional desktop approach is construction through regular program code .
the now widely recommended alternative is declarative e.g.
via xml layout definition files in android.
advanced gui aspects are then defined programmatically which typically leads to a combination of code and layout declaration files.
building an appealing user interface is hard .
besides understanding user needs the gui facilities of modern platforms are complex and offer many similar concepts to choose from.
this challenge is especially significant for developers new to their target platform.
while each platform provides standard documentation and sample code these samples often produce unappealing results.
b. example gui framework android the android standard libraries define various gui containers layout containers and leaf nodes widgets .
according to an august survey of the most popular non game applications in the google play app store the following containers were used most frequently linearlayout uses per application on average places its children in a single row or column relativelayout positions children relative to itself or each other framelayout typically has a single child scrollview is a scrollable framelayout and listview lays out children as a vertical scrollable list.
the following widgets were used most frequently textview is read only text imageview is a bitmap button is a device specific text button view is a generic view edittext is editable text and imagebutton is a device independent button that shows an image.
besides the above the android library documentation currently lists some additional two dozen widgets and some three dozen layout containers.
c. optical character recognition ocr to infer ui code that closely reproduces the input conceptual drawing remaui distinguishes text from images and authorized licensed use limited to tsinghua university.
downloaded on october at utc from ieee xplore.
restrictions apply.
fig.
.
example ocr performance at various granularity levels.
left to right ui drawing and tesseract detected words lines blocks and paragraphs.
captures the text as precisely as possible.
decades of research into optical character recognition ocr have produced specialized methods for recognizing various kinds of text such as text in different sizes fonts and orientation as well as handwritten text .
generally it is easier to recognize text online while it is being written than offline.
similarly it is easier to recognize print than handwriting.
existing ocr tools perform relatively well if the input consists of mostly text.
a good example is single column text with few images.
current ocr tools perform worse if the text density is lower and text is arranged more freely and combined with images .
a good representative ocr tool is the powerful and widely used open source ocr engine tesseract which for instance mathematica uses to recognize text.
in the closely related task of segmenting pages for example to distinguish images and individual text columns tesseract performs on par with commercial tools .
however the limitations of such a powerful ocr tool on complex inputs become apparent when subjecting it to screenshots or conceptual ui drawings.
for example figure shows from left to right a conceptual drawing and tesseract s results when detecting text at various granularity levels i.e.
words lines blocks and paragraphs.
in this example tesseract found all words but also classified as words non words such as the contacts images.
in general for the domain of conceptual screen drawings and screenshots tesseract s precision and recall are often both below one in all granularity levels.
so even a powerful ocr tool may miss some words and classify non text as words.
iv .
remaui o verview and design figure shows remaui s six main processing steps.
at the core is a powerful off the shelf optical character recognition ocr engine step .
since ocr produces false positive candidate words remaui filters the ocr results with its domain specific heuristics.
both to further compensate for ocr s limitations and to identify non text elements such as images remaui combines ocr with a powerful off the shelf computer vision system step .
in two dimensional images computer vision techniques can quickly detect features such as corners and edges.
computer vision has therefore been applied to diverse tasks such as recognizing faces in two dimensional images of the world or to allow self driving cars to detect the edge of the road .using computer vision remaui approximates the boundaries of each screen element such as text and images.
in its final steps remaui merges ocr and computer vision results step and in the merged data identifies structures such as lists step .
remaui then exports the inferred user interface as a combination of layout declarations and program source code for the given target mobile platform step compiles this combination to binaries and runs the binaries on an unmodified smartphone step .
not shown in figure is a pre processing step in which remaui removes standard operating system title and navigation bars if they are present.
since these screen areas are standardized it is relatively easy to detect and remove them.
a. optical character recognition step first remaui applies on the given input bitmap off theshelf ocr word detection.
since optical character recognition suffers from false positives remaui post processes ocr results to remove candidate words that likely do not reflect true words in the input.
figure visualizes this process on the example bitmap from figure .
at word level detection remaui s ocr system classifies several ui elements as a word that are not a word but an image or a part of an image.
to remove likely false positive words remaui encodes knowledge about its mobile phone ui domain as heuristics summarized in table i. as an example rule encodes that on a phone screen a word is likely not cut off and thus does not extend beyond the border of the screen.
this rule is specific to phone screens and does not apply in all the settings the offthe shelf ocr engine may be applied in outside remaui.
table i. h euristics for elimina ting likel y false positive candida te words from the ocr results .
name heuristic zero h w long w h .
h w .
cut off x y x w w y h h conf.
c .
content c .
eh ew h w max eh ew h w .
a e max a e .
no text the heuristics are given in terms of the input data the ocr results and heuristic values computed by remaui.
specifically from the input ui screen available are its width w and height h .
the ocr system produces for each of its candidate words the word s height h width w area a w h font family and size upper left corner coordinates x y text authorized licensed use limited to tsinghua university.
downloaded on october at utc from ieee xplore.
restrictions apply.
g3 g30 g29 g19 g21 g31 g34 g43 g1 g1 g1 g4 g32 g18 g32 g26 g29 g24 g1 g30 g32 g1 g1 g1 g13 g19 g32 g21 g21 g29 g33 g25 g30 g34 g1 g30 g32 g1 g11 g21 g29 g19 g26 g27 g1 g30 g29 g1 g11 g18 g31 g21 g32 g1 g44 g42 g45 g1 g1 g10 g3 g12 g1 g44 g49 g45 g1 g3 g30 g28 g31 g37 g34 g21 g32 g1 g16 g26 g33 g26 g30 g29 g1 g1 g44 g51 g45 g1 g g20 g21 g29 g35 g22 g40 g1 g27 g26 g33 g34 g33 g1 g6 g21 g29 g21 g32 g18 g34 g21 g20 g1 g18 g31 g31 g1 g32 g26 g34 g25 g1 g26 g29 g22 g21 g32 g32 g21 g20 g1 g15 g g1 g25 g26 g21 g32 g18 g32 g19 g25 g40 g1 g32 g37 g29 g29 g26 g29 g24 g1 g30 g29 g1 g18 g29 g1 g37 g29 g28 g30 g20 g26 g23 g21 g20 g1 g31 g25 g30 g29 g21 g1 g44 g53 g45 g1 g3 g30 g28 g31 g26 g27 g21 g42 g1 g4 g21 g31 g27 g30 g40 g1 g41 g1 g12 g37 g29 g1 g g28 g18 g24 g21 g33 g42 g1 g14 g21 g39 g34 g42 g1 g13 g30 g37 g32 g19 g21 g1 g3 g30 g20 g21 g42 g1 g2 g18 g40 g30 g37 g34 g1 g4 g21 g23 g29 g26 g35 g30 g29 g1 g2 g30 g39 g43 g1 g1 g17 g30 g32 g20 g1 g44 g50 g45 g1 g9 g21 g32 g24 g21 g1 g1 g2 g30 g39 g43 g1 g1 g2 g26 g29 g21 g1 g44 g52 g45 g1 g5 g39 g31 g30 g32 g34 g1 fig.
.
overview of remaui processing steps locate and extract candidate words and lines with ocr locate and extract candidate ui elements as a hierarchy of nested bounding boxes using computer vision merge the results to improve recognition quality identify repeated items and sum marize them as collections export the constructed ui as a mobile application for a given platform compile and execute.
content t and confidence level c .
the confidence level is derived from the distance of the word s characters from idealized characters .
remove invalid words ocr fig.
.
example results of the table i heuristics input from figure left candidate words from ocr framed middle and candidates eliminated by our heuristics solid rectangles right .
from the text content and font information produced by ocr for a given word remaui estimates the width ew height eh and area e the candidate word should occupy given the font size and family.
rule uses this information to remove a word if within bounds the text area estimated by remaui does not match the text area reported by ocr.
this rule removed all four candidate words that are removed in the right side of figure .
the other rules exclude words ocr is not confident about rule have a zero dimension rule or have an odd shape rule .
an odd shape likely does not capture an englishlanguage word as they are long and narrow vertically or horizontally.
finally rule removes words that only contain non ascii characters or only consist of control characters and whitespace.
the heuristics constants are derived through trial and error on a small set of third party bitmaps.
the resulting heuristics have held up reasonably well on the much larger set of thirdparty bitmaps used in the evaluation section vi .b.
computer vision step in this step remaui infers a first candidate view hierarchy.
two important observations are that many vastly different view hierarchies can lead to very similar if not identical onscreen appearances and a programmer will likely find some of these view hierarchies more valuable than others.
remaui therefore follows carefully chosen heuristics to produce desirable view hierarchies that balance the following two goals.
the first goal is a minimal hierarchy i.e.
having a minimum number of nodes.
from the programmer s perspective this is important to prevent clutter in the generated code.
more importantly drawing a large number of views slows down the application.
for example a programmer would not want a container that contains one child view for each character of every word displayed by the container.
however a competing goal is maximum flexibility of the inferred view hierarchy.
distinct ui elements should be represented by distinct views to allow the generated ui to be well displayed on various combinations of screen size and resolution.
thus a programmer would for instance not want to represent the four distinct buttons of the figure bottomscreen navigation bar as a single image.
however combining these four buttons into a single image and a single leaf view would reduce the number of views.
to infer a good candidate view hierarchy remaui first tries to identify all atomic visual elements in the input ui.
by atomic we mean a visual element that reasonably should not be divided further.
for example an icon is atomic but so can be an entire text paragraph.
for each identified atomic visual element remaui then computes its approximate view.
to achieve these tasks remaui leverages off the shelf computer vision.
figure illustrates remaui s key computer vision steps on the figure example input bitmap.
first we detect the edges of each image element via canny s widely used algorithm .
but these edges themselves are not good candidates for atomic elements as for example each character or even minor noise would become its own element.
authorized licensed use limited to tsinghua university.
downloaded on october at utc from ieee xplore.
restrictions apply.
g6 g17 g13 g11 g13 g15 g7 g14 g1 g4 g9 g11 g10 g18 g1 g23 g21 g13 g7 g1 g2 g7 g15 g15 g22 g24 g1 g3 g13 g14 g7 g19 g10 g9 g1 g4 g9 g11 g10 g18 g1 g2 g16 g15 g19 g16 g20 g17 g18 g1 g2 g16 g15 g19 g7 g13 g15 g10 g17 g1 g5 g13 g10 g17 g7 g17 g8 g12 g22 g1 fig.
.
computer vision processing steps from left to right original input bitmap edges detected via canny s algorithm as black and white dilated or broadened edges to swallow noise and join adjacent elements contours of the joined elements output hierarchy of the contours bounding boxes.
to merge close by elements with each other and with surrounding noise and to close almost closed contours remaui dilates its detected edges.
remaui uses a heuristic to for example allow a word s characters to merge but keep words separate.
remaui then computes the dilated edges contours.
each contour is a candidate atomic element.
figure also illustrates the heuristic nature of this process.
the last list entry shown in the input screen is cut off by a horizontal dividing line.
edge detection dilation and contour thus all merge the last list item with the dividing line reducing remaui s precision and recall of atomic visual elements.
finally remaui computes the bounding box of each candidate atomic element to approximate the element s view.
recall from section iii a that typically each view is rectangular and fully contained in its parent.
partially overlapping boxes are thus merged into a new bounding box.
a fully contained box becomes the child view of the containing box.
c. merging step in two sub steps remaui merges the results of ocr and computer vision to heuristically combine the best aspects of both and to integrate the ocr inferred text into the visioninferred candidate view hierarchy.
first remaui removes ocr detected words that conflict with vision inferred element bounding boxes.
this step addresses common ocr false positives such as classifying part of an image as a text fragment classifying bullet points as o or a similar character and merging lines of text that have too little spacing.
the resulting ocr extracted text is not useful and should instead be exported as an image.
specifically each ocr word is subjected to the table ii heuristics.
in addition to the ocr word s width w and height h we now also have the computer vision bounding box s width bw and height bh .
for example rule checks if an ocr word overlaps with two vision boxes whose ycoordinates do not overlap.
this happens if ocr merged two text lines whereas the vision results kept them separate.
remaui further removes ocr words that are not contained by an ocr line using the ocr lines from step .
remaui then merges ocr words and lines into text blocks.table ii.
h euristics for additional elimina tions of ocr words based on computer vision results .
description word aligns vertically overlapped with vision boxes that do not overlap each other word aligns horizontally overlapped with vision boxes distance between each pair of boxes each box s size word contains a non leaf vision box word contains only vision box box size .
word size non overlapped leaf vision box contains only word word size .
box size if leaf vision box s words are invalidated invalidate the rest 7i f words are the same text and size aligned left right top or bottom each has .
confidence and are non dictionary words leaf vision box contains a word m .
m .
m .
m .
m .
with m min w bw h bh m max w bw h bh ocr lines often blend together into a single line unrelated text that just happened to be printed on the same line.
for example the figure contact names left appear on the same line as message dates right .
however they are conceptually separate.
remaui thus splits a line if the word level ocr indicates that the distance between two words exceeds a heuristic threshold i.e.
their height .
figure shows this process for the figure example.
remaui adds the resulting text blocks to the view hierarchy and removes the vision boxes they overlap with.
valid words ocr lines text blocks fig.
.
example merging figure ocr lines with processed ocr words.
remaui aims at extracting text contents with high precision.
the employed ocr engine produces better text contents when treating its input as a single text line.
this way the ocr engine does not have to reason about which parts of the input are text versus non text.
remaui thus invokes ocr on each text block in line mode yielding text that resembles the text in the input relatively closely.
finally remaui groups closeby text blocks into a container if the vertical distance between text blocks is less than either of their heights.
authorized licensed use limited to tsinghua university.
downloaded on october at utc from ieee xplore.
restrictions apply.
d. identify lists step in this step remaui identifies repeated items and summarizes them as collections for two reasons.
first the final ui definition is more compact and efficient if each repeated resource is only represented once.
second this step allows remaui to generalize from a few instances to a generic collection.
remaui can then supply the observed instances as an example instantiation of the collection.
remaui identifies repeated instances by ordering the views by their relative location and searching them for identical sub trees.
a sub tree consists of a view and a subset of its transitive children.
two sub trees are identical if each of their child nodes has a peer in the other sub tree such that both nodes have the same number of children and the same width height type text or image and matching location within its parent each within a threshold .
neither text contents nor image bitmaps have to be identical as a list item may for example contain the face of a user as in figure .
if identical sub trees are found remaui creates a bounding box around each of them.
each box contained in such a bounding box that is not part of the sub tree belongs to the list item anchored by the sub tree.
however such an overlapping box varies across list elements and will be exported as an optional element of the list entry.
the properties of these optional elements are determined by overlaying all of them and using the resulting bounding boxes.
e. export step in this step remaui exports all results as an android project directory complete with relevant source code and resource files.
this directory can be compiled with standard android ides.
specifically remaui crops and extracts each identified image from the input screenshot only once for repeated images.
to provide a reasonable background color remaui uses as the container s background the dominant color of each container after extracting all identified images.
remaui exports all detected text content and format to android strings.xml and styles.xml files.
remaui exports layout files to the android layout directory for the layout shared between list entries and for the main screen.
finally remaui generates java code to fill lists with the identified entries at runtime.
v. r esearch questions to evaluate remaui we ask a if it is currently feasible to integrate remaui into a standard mobile application development setup and b if remaui generated user interfaces are useful in the sense that the generated ui is similar to the ui an expert developer would produce.
we therefore investigate the following three research questions rq expectations e and hypotheses h .
rq1 what is remaui s runtime in a standard development setup?
e1 given its expensive ocr and computer vision techniques we do not expect remaui to run interactively.
h1 remaui can run on a standard development machine in a similar amount of time as a softwareinstallation wizard which we approximate as up to one minute.
rq2 is a remaui generated ui visually pixel by pixel similar to a given third party input ui conceptual drawing?
e2 given their wide variety we do not expect remaui to work well for all applications.
h2 remaui produces a ui that is visually similar to an input ui conceptual drawing when running on non game mobile applications.
rq3 is the view hierarchy of a remaui generated ui similar to the view hierarchy of a given third party input application?
e3 given their wide variety we do not expect remaui to work well for all applications.
h3 remaui produces a ui whose view hierarchy is similar to the view hierarchy of a given handwritten non game mobile application.
vi.
e v alua tion to explore our research questions we implemented remaui for android.
our prototype generates android code and resource files that are ready to be compiled and executed.
our prototype supports among others android s three most popular layout containers and three most popular widgets section iii b .
for off the shelf ocr remaui uses the open source engine tesseract and tesseract s default version .
.
english language data trained model.
this means that remaui currently does not use tesseract s options for training its classifiers.
step uses tesseract s fastest mode2with fully automatic page segmentation.
for off theshelf computer vision remaui uses the open source engine opencv in its default configuration without training.
a remaui generated application s aspect ratio between output screen width and height is the same as the one of its input screenshot.
with this aspect ratio a remaui generated application supports many screen resolutions via android s standard density independent pixel dp scheme.
the android runtime thereby scales a remaui generated application s dp units based on a device s actual screen density.
the high level workflow of our experiment is as follows.
we first ran a subject android or ios application on a corresponding phone.
at some point we took a screenshot and at the same time captured the current ui hierarchy.
we only handed the captured screenshot to remaui and thus obtained a generated application.
we then ran the generated application on an android phone and at the same time took a screenshot and captured the runtime hierarchy.
to clarify no ui hierarchy information was provided to remaui.
obtaining the ui hierarchy at runtime required low level os access.
we thus used a rooted google nexus phone for android gb ram android .
.
and a jail broken iphone gb ram ios .
.
.
to obtain the view hierarchy on android we used android s uiautomator3via the android debug bridge adb shell uiautomator dump .
for ios we used cycript recursively starting from the root view.
2tesseract onl y psm auto authorized licensed use limited to tsinghua university.
downloaded on october at utc from ieee xplore.
restrictions apply.
for the evaluation remaui ran on a gb ram .
ghz core i7 macbook pro running os x .
.
.
a. subjects using existing third party applications to explore our research questions is a good fit for several reasons.
first it is straightforward to capture a screenshot of a running application and hand such a screenshot to remaui.
it is also straightforward to compare such screenshots pixel by pixel with remaui generated screenshots rq2 .
more importantly having a running application enables inspecting the application s ui hierarchy.
we can then compare this hierarchy with the corresponding ui hierarchy of the remauigenerated application rq3 .
since our remaui prototype is implemented for android our first group of subjects consists of third party non game android applications.
to sample popular applications we downloaded the top free android applications from the google play store as of november .
from these we excluded games as most games do not provide guis through a view hierarchy but through the native opengl library.
this left us with top applications covering except games all application categories present in the top such as ecommerce email maps media players productivity tools translation software and social media.
the remaui web site lists name and version of each subject application used in the evaluation.
from each application we captured the application s main screen in the form it appears after starting the application .
we refer to these subjects as group c. to broaden our set of subjects and since many developers first target ios we added ios applications.
we downloaded on august the top free ios applications from the apple app store.
the resulting non game top applications cover a range of categories similar to group c. we took a screenshot of every screen we could reach yielding screenshots group a .
for each application we took another screenshot showing the main screen with different data contents yielding subjects group b .
since ios defined a new design language and google and apple are major application developers we included from them screenshots of ios applications outside the top group d .
there may also be a use case of manually drawing designs and scanning them.
since such third party drawings are hard to obtain we created sketches of screenshots group e .
these screenshots are our manual renderings of the main screen of the alphabetically first of the top ios applications in the apple app store as of august .
b. rq1 remaui runtime figure shows the runtime of remaui s seven major processing steps i.e.
ocr computer vision 3a merging ocr text with vision boxes 3b splitting text lines 3c creating the view hierarchy identifying lists export and total runtime.
each step shows the runtimes of groups a e from left to right.
not surprisingly steps and 3b took longest as these are the only steps that call remaui s computer vision and ocr engines.
the cost of step 3b varied widely as the number of ocr calls depends on the number of identified text blocks.
step includes extracting a bitmap for each imagefig.
.
runtime of remaui s seven main processing steps on the subjects shown by group from left a to right e .
view which also takes time.
on a modern desktop computer total runtime was well within the one minute time frame with a second maximum and an average total runtime of seconds.
c. rq2 pixel by pixel similarity fig.
.
normalized pixel by pixel screenshot similarity between remaui input and generated application on the subjects shown by group a e from left to right.
higher values are better.
since remaui currently removes all standard os status and navigation bars from input screenshots we do the same to the screenshots of remaui generated applications.
to ensure that input and generated screenshots have the same dimensions we set the target application screen dimensions to account for subtracting the os navigation bar.
we used the open source photohawk4library to measure two widely used picture similarity metrics .
specifically following are the mean absolute error mae and the mean squared error mse over a screenshot s npixels ei jis the delta of one of the three color channels rgb of a given pixel in the original vs. the corresponding pixel in the remauigenerated screenshot.
mae 3nn summationdisplay i summationdisplay j ei j mse 3nn summationdisplay i summationdisplay j 1e2 i j figure shows the normalized to similarity measures for our subjects arranged by our five groups.
the results indicate that remaui generated applications achieved high average pixel by pixel similarity with the respective inputs on both metrics.
authorized licensed use limited to tsinghua university.
downloaded on october at utc from ieee xplore.
restrictions apply.
d. rq3 ui hierarchy similarity achieving high pixel by pixel similarity is not sufficient as it is trivially achieved by a ui that consists of a single bitmap i.e.
the input screenshot .
so in this section we also evaluate how closely the generated view hierarchy resembles the view hierarchy that produced remaui s input screenshot.
evaluating the quality of a given ui hierarchy is hard.
first there are often several different hierarchies of similar overall quality.
not having the application s specification it is not clear which alternative remaui should target.
second unlike for rq2 the input application s ui hierarchy is often not an obvious gold standard.
many of the subjects contained redundant intermediate containers that have the same dimension as their immediate parent and do not seem to serve a clear purpose.
other container hierarchies could have been refactored into fewer layers to speed up rendering.
fig.
.
part of a screenshot of google hangout top its ui hierarchy middle and the remaui generated hierarchy bottom .
each element is annotated at its center with its level in the ui hierarchy with root .
each number s color matches the color of its element s boundary.
figure shows an example of this challenge.
the original ui hierarchy and the remaui generated one differ in several aspects.
for example remaui puts the contact s name and message into two relatively small level text boxes.
the original application puts the same strings into much larger level text boxes.
similarly remaui groups name and message into a level container.
the original application groups them with the date into a level container.
this container is nested into a level container which is nested into a level container of the same dimensions.
the latter container thus seems redundant.
despite these differences screenshots of the two hierarchies are very similar pixel by pixel.
in our evaluation we side step these challenges by comparing ui hierarchies at the leaf level.
while this comparison does not capture the entire hierarchy it still captures parts of the ui s structure.
for example the boundary of each intermediate container node is represented by the leaf nodes it contains.
specifically for this experiment we analyzed each pixel in a remaui generated screenshot.
if a pixel belongs to a text box in both the original and the generated application then we consider the pixel correct.
similarly the pixel is correct if it belongs to an image view in both the original and in the generated application.
given these criteria we can define precision pand recall ras follows separately for images text and overall given the pixels iin an image view in the original application and in the generated application i prime as well as thepixels tin a text view in the original application and in the generated application t prime .
pi i i prime i prime pt t t prime t prime ri i i prime i rt t t prime t p i i prime t t prime i prime t prime r i i prime t t prime i t since in our setup this experiment required manual steps for capturing the ui hierarchies we restricted the scope of the experiment to our core group of android subjects group c and the relatively small group of ios subjects group b .
figure shows the experiment s results.
we found a moderate to high structural match in terms of the leaf nodes between original and remaui generated ui hierarchies.
fig.
.
image text and overall ui element precision p and recall r for groups b left and c right .
higher values are better.
the low recall in figure does not fully capture how remaui reproduced text or images.
on the contrary remaui s pixel by pixel similarity was high figure .
we suspect a culprit of low recall was white space.
remaui computes tight bounding boxes but a corresponding original text or image view may contain much additional white space and fill its parent container as the much larger text boxes in figure .
to explore this issue on the example of text we measured the levenshtein distance edit distance of text box strings between original and generated applications.
for the .4k string pairs of group c on average an original text was .
characters a generated text .
and the edit distance .
.
so on average it took only .
single character additions removals or substitutions to convert a string in the generated application back to the corresponding string in the original application.
for the .9k group b string pairs on average an original text was .
characters a generated text .
and the edit distance was only .
.
these results indicate a higher text recall than the pixel based recall of figure .
the following two trends emerged on manual inspection.
first precision suffered if a subject contains a bitmap that contained both text and non text imagery.
this is not surprising as for ocr it is hard to distinguish if a given text is plain text or belongs to a bitmap of text and other elements.
remaui typically decomposed such bitmaps into text and image views.
the resulting ui hierarchy should be relatively easy to fix manually.
a developer would just replace a generated container containing both text and images with a single bitmap.
overall these incorrectly detected views were small.
in figure their average area was less than .
of the input screen area.
the second observation is that low image recall occurred when images overlapped that were of similar color or where authorized licensed use limited to tsinghua university.
downloaded on october at utc from ieee xplore.
restrictions apply.
the top image is somewhat transparent.
these scenarios are challenging for edge detection.
similarly text recall was low if the text color was similar to the background color.
on the flip side with high contrast we observed high recall.
vii.
r ela ted work the gap between early prototyping and formal layout definition also exists in the related domain of web site development.
a study of designers at companies showed that all designers started with sketching the layout hierarchy and flow of web pages with pencil on paper and in graphical design tools such as photoshop .
a similar design process has been reported for desktop applications.
at apple user interface sketches were first created with a fat marker to prevent premature focus on details and later scanned .
separate studies of hundreds of professionals involved in ui design in various companies indicated heavy use of paper based sketches .
one of the reasons was that sketching on paper is familiar due to designers graphic design background.
despite much progress in tools for creating user interfaces that combine the unique talents of graphic designers and programmers much conceptual user interface design work is still being done by graphic designers with pencil on paper and digitally e.g.
in photoshop.
previous work has produced fundamentally different approaches to inferring user interface code as it was based on different assumptions.
following are the main changed assumptions for mobile application ui development and reverse engineering that motivate our work.
first many ux designers and graphic artists do not construct their conceptual drawings using a predefined visual language we could parse .
second while this was largely true for desktop development mobile application screens are not only composed of the platform s standard ui framework widgets .
finally we cannot apply runtime inspection as remaui runs early in the development cycle.
specifically the closest related work is mobidev which recognizes instances of a predefined visual language of standard ui elements.
for example a crossed out box is recognized as a text box.
but unlike remaui mobidev does not integrate well with a professional mobile application development process.
it would require ux designers and graphic artists to change the style of their paper and pencil prototypes for example to replace real text with crossed out boxes.
such changes may reduce the utility of the prototypes for other tasks such as eliciting feedback from project stakeholders.
in a traditional reverse engineering setting mobidev cannot convert screenshots into ui code.
silk and similar systems bridge the gap between penbased gui sketching and programming of desktop based guis .
designers use a mouse or stylus to sketch directly in the tool which recognizes certain stroke gestures as ui elements.
but these tools do not integrate well with current professional development processes as they do not work on paper on pencil scans or screenshots.
these tools also do not recognize handwritten text or arbitrary shapes.
ui reverse engineering techniques such as prefab depend on a predefined model of ui components.
the workassumes that the pixels that make up a particular widget are typically identical across applications.
however this is not true for a mobile application ui.
mobile applications often have their own unique non standard identity style and theme.
for prefab to work all possible widget styles and themes of millions of current and future mobile applications would need to be modeled.
pax heavily relies on the system accessibility api at program runtime.
at runtime pax queries the accessibility api to determine the location of text boxes.
the accessibility api also gives pax the text contents of the text box.
pax then applies computer vision techniques to determine the location of words in the text.
if a view does not provide accessibility pax falls back to a basic template matching approach.
pax thus cannot reverse engineer the ui structure of mobile applications from their screenshots or application design images alone.
recent work applies the ideas of silk and denim to mobile applications allowing the user to take a picture of a paper and pencil prototype.
the tool allows the user to place arbitrary rectangles on the scanned image and connect them with interaction events.
this idea is also implemented by commercial applications such as pop for ios.
as silk and denim this approach is orthogonal to remaui.
viii.
c onclusions and future work when developing the ui code of a mobile application a big gap exists between graphic artists conceptual drawings and working ui code.
programmers typically bridge this gap manually by reimplementing the conceptual drawings in code which is cumbersome and expensive.
to bridge this gap we introduced the first technique to automatically reverse engineer mobile application user interfaces remaui .
on a given input bitmap remaui identifies ui elements via computer vision and ocr techniques.
in our experiments on screenshots of over popular third party applications remaui generated uis were similar to the originals both pixel by pixel and in terms of their runtime ui hierarchies.
we plan to generalize the export step to additional platforms such as ios and cross platform javascript based frameworks.
remaui currently converts each input screen to a separate application.
we plan to provide a graphical notation to allow users to connect several input screens drawings which remaui could use to generate a single application with various screens and corresponding screen transitions.
we plan to integrate remaui with tools that generate mobile application functionality either via keyword based code search or from high level models or dsls .
we plan to index a screenshot corpus by running remaui on it and storing remaui s intermediate results.
exposing this index via a query interface would allow a user to search for screenshots by their structure and features.
the remaui prototype for android used in the evaluation is freely available at tuan remaui