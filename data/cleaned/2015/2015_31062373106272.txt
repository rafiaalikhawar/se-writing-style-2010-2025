the power of why and why not enriching scenario exploration with provenance tim nelson brown university usanatasha danas brown university usa daniel j. dougherty worcester polytechnic institute usashriram krishnamurthi brown university usa abstract scenario finding tools like the alloy analyzer are widely used in numerous concrete domains like security network analysis uml analysis and so on.
they can help to verify properties and more generally aid in exploring a system s behavior.
while scenario finders are valuable for their ability to produce concrete examples individual scenarios only give insight into what ispossible leaving the user to make their own conclusions about what might be necessary .
this paper enriches scenario finding by allowing users to ask why?
and why not?
questions about the examples they are given.
we show how to distinguish parts of an example that cannot be consistently removed or changed from those that merely reflect underconstraint in the specification.
in the former case we show how to determine which elements of the specification and which other components of the example together explain the presence of such facts.
this paper formalizes the act of computing provenance in scenariofinding.
we present amalgam an extension of the popular alloy scenario finder which implements these foundations and provides interactive exploration of examples.
we also evaluate amalgam s algorithmics on a variety of both textbook and real world examples.
ccs concepts software and its engineering formal methods keywords model finding formal methods provenance alloy analyzer acm reference format tim nelson natasha danas daniel j. dougherty and shriram krishnamurthi.
.
the power of why and why not enriching scenario exploration with provenance.
in proceedings of 11th joint meeting of the european software engineering conference and the acm sigsoft symposium on the foundations of software engineering paderborn germany september esec fse pages.
permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
copyrights for components of this work owned by others than the author s must be honored.
abstracting with credit is permitted.
to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
request permissions from permissions acm.org.
esec fse september paderborn germany copyright held by the owner author s .
publication rights licensed to association for computing machinery.
acm isbn .
.
.
.
introduction scenario finders produce concrete examples that satisfy formal specifications.
they have been popularized by tools like alloy which has been widely used in many domains to e.g.
debug and understand uml diagrams analyze firewall configurations security policies network switches and web security and discover an oversight in the chord distributed hashtable protocol.
scenarios found may correspond to examples of access requests class diagrams faulty protocol executions network topologies theorem counterexamples and so on.
since scenariofinders function even in the absence of formal correctness properties they are often used to help users understand a system by example discover new properties to check or perform property free analyses such as semantic differencing of systems.
it is crucial that tools empower users to understand the scenarios1 they are presented with rather than merely show them examples consistent with the original specification.
however currently there is only limited tool support for helping users understand scenarios.
for example the alloy analyzer provides an evaluator that allows users to evaluate expressions in the context of the currently shown scenario in this way users can answer what is true?
questions.
but users should also be able to ask the much more interesting why?
and why not?
questions.
for instance one might ask why does my network configuration take that action on this packet?
why doesn t this class implement an interface in this example?
or even what parts of my specification prevent me from adding another node to this binary search tree?
.
answering such questions is hard enough in the context of a deterministic system where behavior generally has one cause or chain of causes.
in scenario finding however why is this here?
may have zero answers i.e.
nothing forces that portion of the scenario to be present or more than one answer when multiple constraints in the specification make the element necessary .
moreover explanations will usually be contingent on what else is and is not present in the example shown.
giving users answers to such explanatory questions is therefore non trivial yet still vital for enabling productive disciplined use.
finally although the canonical use cases for scenario finding often involve human generated specifications many applications e.g.
compile software artifacts like uml diagrams 1scenario finding tools are also called model finders .
however the word model is heavily overloaded and can mean either a specification i.e.
model of software or a scenario found via logical methods.
throughout this paper we will always use the term in the latter logical sense an interpretation of relation symbols over a set of atoms to formalize our notion of scenario.
although they sometimes share internal strategies scenario or model finders like alloy are distinct from model checkers another class of tool that typically focuses on verifying that a system satisfies temporal properties.
esec fse september paderborn germany t. nelson n. danas d.j.
dougherty and s. krishnamurthi or firewall policies to specifications and invoke the scenario finder as a back end.
since the scenarios produced are then in terms of machine generated translations rather than meticulous humancrafted specifications alloy bears an even greater burden to help users understand the scenarios shown.
contributions.
in this paper we establish novel well defined notions of must this be here?
and why is this here?
for scenariofinding.
these ideas are realized in amalgam2 an enhanced version of the widely used alloy scenario finder.
we choose to build atop alloy because it is used by multiple and diverse communities and also due to its expressive power all of first order logic along with relational operators such as transitive closure .
amalgam s novel features comprise the ability to say what is and is not necessary in a scenario i.e.
cannot be changed without consequences elsewhere rigorous proof based explanations provenance for necessity and disciplined user guided scenario alteration that enables users to explain why elements of a scenario canbe altered.
amalgam facilitates a richer workflow than what alloy currently provides.
we illustrate this via a worked example in sec.
.
we then lay out the logical foundations sec.
and algorithmics sec.
for provenance generation before discussing amalgam s implementation sec.
.
we evaluate amalgam sec.
and contrast it to related work sec.
before concluding with discussion in sec.
.
worked example to illustrate how why?
and why not?
questions arise naturally in scenario finding we first introduce an example adapted from an exercise in jackson undirected trees with node coloring 1abstract sig color 2one sig red extends color 3one sig blue extends color 4sig node neighbors set node color one color 8fact undirected neighbors neighbors symmetric no iden neighbors antireflexive 12fact graphisconnected all n1 node all n2 node n1 n1inn2.
neighbors 15fact treeacyclic all n1 n2 node n1 inn2.neighbors implies n1not in n2.
neighbors n2 n1 lines declare the basic types in the problem a notion of color line sig denotes a type declaration and two concrete colors lines .
the abstract keyword enforces that the color type is the union of its subtypes red andblue .
theone keyword constrains the red andblue types to each contain a single distinct color atom.
node s each have a set of neighbors and a single color forced by the prior declarations to be either red orblue .
line enforces symmetry making the graph undirected line prevents self loops.
lines use transitive closure to force figure three example scenarios produced by alloy.
in alloy a k denotes the kthelement of the type a here indexes range from 0to .
colors are named in the same way and appear under the name of each node.
the edges show the neighbors relation.
the graph to be connected.
lines enforce acyclicity by saying that removing any edge disconnects its endpoints.
alloy converts this specification to a theory of first order logic with transitive closure with types as unary relations and neighbors andcolor each assigned a binary relation.
running the specification in alloy produces a stream of models that satisfy that theory up to a user specified size .
fig.
contains of many example models found up to a bound of node s. .
challenge detecting underconstraint it is easy to accidentally omit a constraint when writing a specification e.g.
the antireflexivity constraint on line .
if it is left out the specification is satisfiable but underconstrained it is satisfied by some models that contain self loops.
this error is revealed if alloy produces a cyclic model but since tool parameters like sat solver choice affect the order in which alloy generates models there is no guarantee that a cycle will be shown even after several invocations.
this issue illustrates a weakness of purely model based output vital information may be withheld well past the point where most human users stop requesting new models.
in contrast by giving additional information in the form of necessity andprovenance amalgam can reveal some bugs even if the model shown is correct .
consider the leftmost model of fig.
.
this model is a singleton tree that satisfies the specification.
however without an antireflexivity constraint the specification permits adding an edge from node to itself in spite of the acyclicity constraint .
by reporting what is and is not locally necessary sec.
in the model amalgam alerts the user to underconstraint without hiding the error in a stream of potentially complex models.
users can then instruct amalgam to augment the model with the new edge providing them with a counterexample to their expectation and then use alloy s evaluator to explore why existing constraints do not suffice.
.
challenge tracing overconstraint implicit assumptions in evolving specifications can lead to errors as we discover if we decide to allow self loops in our trees.
to do so we again remove the antireflexivity constraint on line .
unfortunately this edit reveals a subtle overconstraint self loops remain forbidden in models larger than node.
107the power of why and why not enriching scenario exploration with provenance esec fse september paderborn germany thetreeacyclic constraint is the culprit.
its formulation implicitly assumes irreflexivity i.e.
that n1 in n2.neighbors implies that n1andn2must be different nodes.
the fix is just to make that assumption explicit adding n1 !
n2 to the antecedent of the constraint.
but if the user is only presented with a series of models that look like valid trees some even with selfloops how can they discover the fix?
how will they even learn of the error without iterating until no more models are available remembering every detail of previous models seen and then mentally synthesizing the fact that some self loops were never shown?
in contrast amalgam can reveal the problem on the first model larger than 1node.
consider the middle node model in fig.
.
this is a valid tree but neither of the self loop edges can be added without consequences i.e.
adding or removing additional nodes or edges .
amalgam detects this reporting these edges absence as locally necessary.
furthermore amalgam can explain this necessity guiding the user to the appropriate fragment of the constraint.
the four panel fig.
shows how amalgam presents provenance as a deductive argument highlighting four crucial steps the first highlight is a top level constraint that leads to the local necessity of node having no self loop.
the next highlight shows the subformula after binding n1 n2 node possible since atom node is anode .
the right hand side of the implication is false under that instantiation whether or not node has a self loop.
finally since the right hand side of the implication is true amalgam concludes that the left hand side must be false not node node in neighbors .
.
challenge multiple explanations finally suppose we constrain node coloring by saying that leaf nodes ought to be colored blue and internal nodes red all n node n.color blue iff lone n.neighbors that is the node is blue if and only if it is connected to or other nodes.
in fig.
the middle model satisfies this constraint but the other do not.
revisiting the center model amalgam indicates that it is necessary for both nodes to be blue.
but why?
asking for a provenance of node s blue color actually yields a pair of provenances corresponding to the explanations the declaration of node said that every node has exactly one color we cannot remove node s color.
the new constraint forces node to be blue since it has no more than one neighbor.
each of these encapsulate a way that constraints and current scenario together imply sec.
that node s blue color cannot be removed without consequences elsewhere in the scenario.
different explanations may be useful in different situations either reminding the user that every node must have a color or pointing them to the coloring constraint.
for this reason amalgam generates setsof provenances rather than only single explanations.
comparison to unsatisfiable cores.
if a specification has no models alloy can obtain and highlight a minimal core of the specification that is itself unsatisfiable.
this allows the user to zero in on which constraints are mutually unsatisfiable under the current bounds.
for more information on the uses of unsatisfiable coresin alloy see torlak et al.
s insightful work.
however such cores can only be found when a specification is indeed unsatisfiable.
amalgam s provenance and necessity information give insight into overconstraint even when the specification can be satisfied making it useful for debugging subtle errors that may eliminate a handful of models but not all.
moreover amalgam produces a setof provenances that can be explored each of which provides different insight rather than a single core.
we discuss potential future applications of core extraction to provenance in sec.
.
foundations we now establish foundations for provenance.
although we use alloy syntax throughout our results apply to any scenario finding tool that uses bounded first order logic.
in this section as well as sec.
we will use the term model to formalize the notion of scenario as a logical structure over a relational language.
we also use theory to formalize the specification as a set of logical formulas.
.
syntax alloy s surface syntax includes the usual predicate logical operators quantification is sorted .
to these alloy adds relational operators join product transitive closure and others see fig.
for a full list .
these operators have the usual first order and relational semantics which we sketch in fig.
.
.
model finding the general model finding problem consists of satisfiability search finding a model that satisfies some theory.
a bounded model finding problem l t u lb ub comprises a languagel a theorytover the symbols in l a finite domain u the universe and upper and lower bound functions lbandub defined for each n ary relation r l such thatub r un lb r unandlb r ub r .
asolution to such a problem is a model mover the language l such that rmdenotes the interpretation of rinm m t m u and for each relation r l lb r rm ub r .
since the bounded model finding problem is restricted to searching for models with a specific finite domain u satisfiability and testing truth in a model are each decidable.
in fact bounded satisfiability can be checked by reducing the problem to the purely propositional domain with each possible tuple membership t r i.e.
each member of the problem s herbrand base being assigned a single boolean variable.
we embrace this perspective and will implicitly enrich lwith a distinct constant for every element e ofu.
for brevity we abuse notation somewhat and name these constants identically with the elements they represent.
thus all formulas we consider will be closed i.e.
without free variables.
example .
.
the undirected tree example of sec.
describes a theory over the language superscripts denote arity l node color red blue color neighbors 108esec fse september paderborn germany t. nelson n. danas d.j.
dougherty and s. krishnamurthi figure sample provenance and interaction for the node model in fig.
asking why node cannot have a self loop edge.
the right hand side of each of the four panels is a step by step deductive argument.
the left hand side highlights portions of the specification corresponding to where the user is pointing in the right hand pane.
yellow highlights shown in panel comprise the set of subformulas that force local necessity sec.
.
green highlights shown in panels and correspond to steps of the recursive descent algorithm we present in sec.
.
syntax meaning syntax meaning cartesian product relational join union intersection set difference overriding union retain rows in with first column in retain rows in with last column in transitive closure reflexive transitive closure inverse relational join relational transpose cardinality t t t set comprehension iden identity relation binary univ universe unary conjunction disjunction implication bi implication ?
if then else negation in relational containment x t x universal quantification x t x existential quantification one lone some no figure supported alloy surface syntax.
and denote formulas which evaluate to true or false.
and denote expressions which evaluate to relations.
for clarity we distinguish between relational containment in and tuple membership t although alloy uses identical syntax.
because there is exactly oneof each color one sig alloy computes thatub blue lb blue blue and similarly for red .
if the specification is run for up to nodes then lb node andub node node node node .uis therefore node node node blue red .
upper bounds for the binary relations include all well typed tuples.because we will always be interested in a bounded model finding problem when we speak of entailment it is always restricted to the models that respect the universe uand bounding functions lbandub of the current problem.
we reinforce this by writing entailment with a subscript u. fix a bounded model finding problem over l t andu.
109the power of why and why not enriching scenario exploration with provenance esec fse september paderborn germany definition .
literal diagram .
ifris a n ary relation in l c1 ... cnconstants for elements of u and t then the formulas t randt rareliterals.
the diagram of a model m denoted m is the set of literals true in m. we use the set containment idiom for literals rather than writing r c1 ... cn because it more closely reflects the syntax of alloy.
.
necessity and provenance we are interested in exploring why a given literal lmust hold in a model min order to satisfy theory t. in this section we make this notion of why precise.
at one extreme lmight be a logical consequence oft.
at the other extreme lmight be a gratuitous fact about m not contributing to making ma model oftat all here it is reasonable to report that there is no reason why lholds.
this is already useful information to a user of course.
the interesting case is the one in which lneed not hold in allmodels oft but in the context of the rest of the model m cannot be negated without falsifyingt.
our main goal is to analyze this latter situation closely.
definition .
l alternate local necessity .
fix a literal ltrue in m. the l alternate mlofmis the model with the same universe asmwhose diagram ml is m l l .
a literal ltrue in mislocally necessary fortinmifml t. note that this is a weaker condition than t entailment.
local necessity captures the fact that other literals in a particular model force lto hold it might be and is likely that t ulin general.
theorem .
.
lis locally necessary for tinmif and only if t m l ul.
proof.
iflis not locally necessary for tinm thenmlis a witness for the failure of t m l ul.
conversely to say thatt m l ulis to say thatt m l l has a model with universe uthat respectslbandub.
the only such model with diagram m l l isml thusml t and so lis not locally necessary for tinm.
we now formalize the notion of why via provenance .
definition .
provenance .
aprovenance forlinmwith respect totis a set of sentences 1 ... n n each true in both m andml such thatt 1 ... n ul.
the condition that each component iholds in mbinds the notion of provenance to m while requiring that each iholds in mlensures that no ientails lundert so that the provenance is non trivial.
there is an important aspect of provenance that would be tedious to make explicit in definition .
the way that the ipoint back to the specificationt.
each icomputed by the algorithm presented in sec.
is a substitution instance of a subformula of an axiom in t providing links to specific places in the specification that are to blame for the truth of l. in our implementation the formulas are those highlighted yellow .
example .
.
consider the theory x.r x x. p x q x over the language with three unary relations r p and q. suppose u and for all three relations lb andub .
ifm p q r then literals q andr have provenances p and respectively.
p has no provenance.the following is an easy consequence of theorem .
.
lemma .
.
lhas provenance in mwith respect totif and only iflis locally necessary for tinm.
algorithmics fix a bounded model finding problem over l t anduwith upper and lower bounds for each r l. letm tandlbe locally necessary fortinm.
to obtain a set of provenances for linm it is useful to define a desugaring function that instantiates and flattens formulas sec.
.
.
we then proceed by recursively evaluating the formulas intinmandml desugaring as necessary and recording subformulas that lead to t s failure in ml sec.
.
.
finally to further focus the provenance on elements of the model we expand each provenance generated into a literal provenance sec.
.
.
.
desugaring alloy alloy s syntax contains several operators that are effectively syntactic sugar and bounds enable even more simplification.
when generating provenance it will be useful to instantiate some quantifiers relational expressions and derived operators.
to do so we utilize the problem s upper and lower bounds to convert e.g.
universally quantified formulas to a conjunction over the upper bound of the quantified variable s type.
since variable types need not be basic relations we extend the notion of upper bound to include arbitrary relational expressions.
most of these details are routine but fig.
shows some of the more interesting cases like quantification where we must explicitly depend on the boundedness of the model finding problem to perform instantiation.
if a desugaring step produces an empty conjunction or disjunction it means that the bounds themselves are in some way incompatible and might need to be increased another useful distinction that the stream of models paradigm fails to make.
desugar x x v t t t ub desugar x x w t t t ub desugar in v t t t ub desugar a1 an w v ai ai i n is a path inub desugar t w t1 t2 t1 ub t2 ub t1 t2 t when cis a constant desugar c w n min n c desugar c c desugar c v t t ub t m ml t t ub t m ml v t t ub t m t ml t t ub t m t ml figure desugaring alloy operators and instantiation by upper bounds via desugar .
numeric operators are subject to bounds on bitwidth a bitwidth of e.g.
corresponds to the range 8through .
cardinality expressions desugar to formulas that express the failure of the expression in ml other operators which we elide for space are either routine or proceed similarly.
110esec fse september paderborn germany t. nelson n. danas d.j.
dougherty and s. krishnamurthi .
computing provenance to build intuition we first step through the concrete node coloring example from sec.
.
where we constrain each node s color depending on its neighbors.
recall that m the middle model of fig.
has two nodes node andnode .
we focus on the fact that node is blue the literal l color .
this literal is locally necessary since the l alternate model ml obtained by removing this tuple from the color relation fails two top level constraints in t all n node n.color blue iff lone n.neighbors all n node one n.color we obtain provenance for lby computing an explanation for why l fails inml.
since a conjunction fails if anyof its subformulas fail we extract independent provenances from the two failing constraints.
we start with the former axiom.
our algorithm instantiates the universal quantifier as a conjunction maintaining the sort restriction as a guard on each conjunct .
we then discover that only the following instantiation fails in ml node innode implies node .color blue iff lone node .neighbors the implication fails because the guard is true in either model but the consequent becomes false in ml.
because the obligation to make the consequent true is only triggered by the fact that node is a node we add that to the provenance then continue recursively explaining why the consequent fails in ml.
the bi implication desugars to a pair of implications with the if implication failing lone node .neighbors implies node .color blue as before we add the antecedent lone n.neighbors to the provenance.
we continue to recur until hitting bottom at the input literal l. the context collected comprises a provenance p1 node in node lone node .neighbors the latter axiom from talso produces a provenance.
we instantiate as before and desugar one according to the upper bounds eventually producing the following provenance p2 node in node not node red in color and node blue not in color since p1andp2arise from separate failing conjuncts the top level constraints int we present them separately.
pointing back tot.the remark following definition .
concerning the tight connection between provenance components and axioms oftcan be understood more clearly now that we see how the provenance computation works.
for each item we add to a provenance there is a subformula fromtsuch that is an instance of true in mand in ml.
by collecting these instances verbatim we are able to track failing sub constraints and present them to the user.
on the other hand sec.
.
explains how to break these formulas down into literals if desired.
the algorithm.
fig.
gives the recursive provenance function y defined on sentences whose interpretation changes from true inmto false in ml.
there is a function y for sentences falsey t r ifl t r undefined otherwise y 1 ... n s y i m i ml i y 1 ... n 1 ... m 1 ... n p p y 1 ... y m where m each iandm each j y y y y desugar in all other cases.
figure explanation function y. inmand true in ml whose definition is dual to y but omitted here for lack of space.
if is a literal yis only defined if l since otherwise m andmlcould not differ on the interpretation of the provenance here is empty since clearly l ul.
when is a negation we invoke y .
when is a conjunction the failure of any conjunct causes the overall formula to fail in ml.
the resulting provenance set is therefore the union of all explanations for each conjunct s failure.
when is a disjunction local necessity means that every disjunct must evaluate to false in mland at least one must hold in m. for intuition view the disjunction as an implication with the disjuncts false in mnegated in the antecedent.
it is these subformulas false in both mandml labeled iin fig.
that imply the others true in mand false in ml labeled iin fig.
and force the failure of the overall formula.
yrecurs for each failing i combines their provenances with union product and adds each i to every provenance in the resulting set.
here the union product of a pair of sets of sets a a1 ... an andb b1 ... bm is a b ai bj i n j m .
the union product operator is similar to cartesian product but rather than building ordered pairs of element sets it combines those elements with union.
otherwise we perform one desugaring step and recur.
one might initially expect the dual of the conjunctive case which uses union to use intersection .
however this would mean combining multiple provenances allof which must apply by discarding unshared components.
we therefore use union product to enforce that some full provenance for each subformula is respected.
complexity.
our algorithm amounts to a tree search of a partially desugaredt testing for truth in mandmlwhile descending.
both time and space complexity are therefore proportional to the size of the model mtimes the size of the theory tpost desugaring.
expanding a quantifier over produces one guarded instantiation per element in the upper bound of .
thus worst case quantifier elimination is exponential in the quantifier nesting depth oft.
expanding transitive closure enumerates possible paths and so there the worst case is superexponential the number of potential paths between a fixed source and destination in a complete n graph isp x n n x x!.
this challenge is shared by alloy s model finding engine as it passes to propositional logic and is thus not unique to provenance generation.
moreover in practice sec.
these worst cases rarely manifest.
this is because bounds tend to be both separated into disjoint types and small well under 10atoms 111the power of why and why not enriching scenario exploration with provenance esec fse september paderborn germany in keeping with jackson s small scope hypothesis which says that small examples usually suffice.
.
correctness fix a bounded model finding problem for toverl m tand l m .
first note thaty is defined and returns a non empty result if m butml .
thus a provenance is always produced iflis locally necessary in m i.e.
amalgam is complete .
it remains to show that the provenances produced are correct.
theorem .
correctness of provenance generation .
if the algorithm of fig.
produces a provenance 1 ... nforlwith respect totinmthent 1 ... n ul.
proof.
proceed by induction on ordered pairs consisting of the number of steps to fully desugar and the size of .
if is a literal yis only defined if l since otherwise mandmlcould not differ on the interpretation of and clearly l ul.
if is a negation the theorem holds by direct application of the inductive hypothesis.
if is a conjunction then the result is the union of all provenance sets obtained by calling yon s subformulas.
by the inductive hypothesis we have that for each provenance pin that union p ul.
if is a disjunction each disjunct must be false in mlor the formula would not fail.
let those true in m i.e.
that become false be 1 ... nand the others which remain false be 1 ... m. then is equivalent to 1 ... m 1 ... n. by the inductive hypothesis eachy i produces a set of provenances pisuch that i pi ul pi pi .
thus 1 ... n pconseq ulfor each pconseq p1 ... pn.
therefore 1 ... m pconseq ul.
in all other cases is desugared before yrecurs and the inductive hypothesis can be applied directly.
.
obtaining literal provenance the provenances generated in sec.
.
say which subformulas and instantiations are responsible for l s local necessity in m. however it is sometimes useful to see a provenance that focuses blame onto just the parts of mresponsible for local necessity.
this reveals a spectrum of provenance complexity higher level formulas can be concise but lower level formulas are tied more closely to the model being understood.
a literal provenance which contains only literals stands at the far end of that spectrum definition .
literal provenance .
aliteral provenance forlis a provenance 1 ... n ulwhere each iis a literal.
to obtain a literal provenance from an arbitrary provenance p we convert each non literal formula inpto a set of literals true in mthat force to hold.
to do this we traverse the negation normal form of seeking conjunctions of literals that entail it desugaring as needed.
this process amounts to evaluating the formula in reverse extracting pieces of the model responsible for s truth.
however this process can potentially return a conjunction of literals that contains lor l which would violate our definition of provenance since either is false in either morml.
even more some sentences may require contingent reasoning with different literals leading to truth in mversus ml.example .
.
let p q p r s m p q r and l p .
while holds in bothmandml neither branch suffices on its own both q and r must appear together.
to resolve this problem we search in parallel for a pair of conjunctions that satisfy in m and in ml .
if one conjunction does not involve lit explains s truth in both models since they differ only by l. otherwise one must contain land the other l in this case we combine them and remove both land l. this is sound since if l and l it holds that .
implementation amalgam is implemented as a drop in extension to alloy .
rather than a standalone tool.
this means that alloy users can experiment with new features and incrementally adopt them without any disruption of their workflow.
users can access amalgam s extensions via alloy s existing evaluator a prompt that allows them to evaluate expressions in the current scenario.
we extend this facility to give insight into local necessity via provenance.
users can either ask for a broad list of what is locally necessary or browse the set of all provenances generated for individual literals.
amalgam provides both basic provenance display as seen in fig.
and an expert interface that shows the details of every step of the recursive descent described in sec.
.
in both mousing over components of a provenance highlights the corresponding portions of the specification.
the tool also allows users to augment scenarios by adding or removing literals that are not locally constrained.
much like provenance can be helpful in cases of over constraint augmentation can be helpful if a specification is under constrained since it allows users to move quickly to surprising scenarios for further investigation.
our approach to augmentation is similar to other tools such as aluminum except that users can both add and remove elements of a scenario.
we discuss further differences in sec.
.
amalgam supports some alloy features that were unmentioned in fig.
such as multiplicity constrained type declarations and total ordering.
amalgam s support for numerics includes counting the cardinality of set expressions and inequalities it does not currently support arithmetic operations.
evaluation we evaluate amalgam quantitatively along five dimensions its performance the number of leaf formulas i.e.
s gathered by the algorithm in sec.
the depth of the recursive descent which directly affects the size of the tree displayed the character count of the largest highlight shown which also affects provenance display and the total number of provenances generated for each literal.
for each specification we take these measurements for each literal permitted by the specification s bounds asking why?
for literals that are present and why not?
for those that are absent.
we report results for the first twoscenarios returned by the scenario finder to mitigate bias in scenario ordering.
fig.
reports these results.
our evaluation suite consists of 22specifications and comprises a wide mixture of example educational and real world specifications.
address book addr grandpa grand and geneology gene are from alloy s example set.
grade book grade bad employee bempl and other groups other are alloy translations of 112esec fse september paderborn germany t. nelson n. danas d.j.
dougherty and s. krishnamurthi access control specifications used to benchmark existing scenariofinding work .
directed graph digraph is a non empty but otherwise unconstrained directed graph as a baseline for comparison.
directed tree dtree constrains the graph to be a tree.
dtbug injects a flaw in dtree s edge injectivity constraint.
the two colored undirected trees specifications ctrees andctreesb are the original shown in sec.
and the buggy modification with irreflexivity removed.
abc is a logic puzzle that requires hypothetical reasoning.
good will hunting gwh encodes a scenario finding problem popularized by the cinema searching for trees where no vertex has degree .
transitive closure and garbage collection lab tclab andgclab respectively are specifications from labs exercises in an introductory formal methods course.
the first gives practice with transitive closure the second models reference counting garbage collection and reveals its flaws.
the model of propositional resolution resfm comes from torlak et al.
.flow reveals a bug in a network program written in flowlog a language for programming software defined networks.
cdd1 andcdd2 are maoz et al.
s translation of two uml diagrams.
cddiff1 andcddiff2 are the semantic differences of those two models i.e.
cdd1 cdd2 and cdd2 cdd1 produced by cddiff .
we also include the authentication model web from akhawe et al.
.
together these cover a wide spectrum of complexity upper bounds and alloy features.
finally we note that flow cdd1 cdd2 cddiff1 and cddiff2 are all machine translations from software artifacts.
the compilers that implement these translations are non trivial so the specifications they produce call out for answers to why?
and why not?
questions from the compiler developers as well as their end users.
.
performance we measure performance by calculating the time and peak memory required to generate allprovenances for each literal by running the yfunction from sec.
.
to put these figures in context we compare this to the time alloy s scenario finding engine takes to produce the first two scenarios including the time taken to translate the specification to propositional logic.
provenance generation does not impact alloy s scenario finding approach in any way so there is no overhead to generating scenarios in amalgam.
to stabilize measurement variance we repeat our experiments times on each of our specifications.
all results were gathered on an ubuntu .
.60ghz i5 4278u cpu 16gb ram machine.
in most cases it takes less memory to compute provenance than scenarios however for larger examples provenance can use slightly more memory.
the worst case peak memory usage during provenance generation was mb for flow while the maximum during scenario generation was mb roughly a difference.
amalgam usually generates provenances no slower than alloy generates scenarios on the order of milliseconds .
indeed for web scenario generation is more than two orders of magnitude slower on average than provenance generation here the complexity is in producing a scenario not in explaining literals.
the only significant outlier is flow which takes on average .
times longer to explain a literal than to produce a scenario.
the difference is due to flow s complexity and the unusually large provenance count that some literals in flow have we address this second point further in sec.
.
.
.
explanation complexity for each specification we report three metrics as a surrogate for comprehensibility aggregated over all provenances produced the number of formulas gathered i.e.
the number of leaves in the tree shown the depth of recursive descent i.e.
the depth of the tree shown and the character count of the largest highlighted region.
.
.
depth.
in most cases the average depth does not exceed a dozen resulting in a fairly succinct derivation.
the tclab specification has a maximum depth of 17because it contains a deep tree of predicate calls the lab is designed to teach students to use helper predicates each of which contains several relational operators that all take a desugaring step.
.
.
highlighting.
since amalgam highlights concrete source locations in the original alloy file highlight size corresponds to the original not desugared or instantiated alloy specification.
amalgam thus produces small highlights in general most specifications see a maximum well under characters.
the largest highlight usually corresponds to the top level constraint in each provenance e.g.
the largest highlighted region in fig.
s provenance is shown in step .
large maximum highlights such as cddiff2 s arise when visiting large constraints in the specification and are greatly reduced in future steps from to in this particular case .
we also report the total number of characters in each specification through which we see that even the largest highlight is only roughly of the cddiff2 specification.
.
.
leaf count.
since new leaf formulas occur whenever branches of a disjunction are eliminated specifications with large disjunctions existential quantification with large bounds or transitiveclosure produce high counts.
the largest leaf counts appear in gwh andgclab both of which make heavy use of transitive closure pair with relatively large upper bounds.
in this case our algorithm produces provenances that enumerate all possible paths.
however a conversion to literal provenance greatly reduces leaf count from to on average for gwh and from to in the worst case for gclab .
further reduction is likely possible as we do not currently search for the smallest provenances.
in contrast provenances for authn flow grand and especially cddiff2 blow up significantly when converted to literal form.
this is because some formulas in these provenances depend on large swathes of the scenario.
for instance an that contains a universal quantifier implicitly depends on all its potential instantiations.
situations where literal provenances are smaller therefore indicate significant overlap in the parts of the scenario that make formulas true.
for example this happens in gwh because most s there are caused by transitive closure which desugars in a repetitive way.
flow specifies a state transition function that is defined by a disjunction over logic program fragments.
each fragment causes a set of literals to be true.
negative literals therefore have provenance encompassing the fact that none of these program fragments apply which is fairly large as fig.
reports.
this pattern of provenances that comprise multiple instantiated specification fragments persists ingene andresfm .
113the power of why and why not enriching scenario exploration with provenance esec fse september paderborn germany max prov trees tree depth tree leaves prov largest highlight chars runtime ms spec bnd med max med max med max med max spec pr m pr max mmax ctrees ctreesb digraph addr .1k other .5k grade .0k .1k abc bempl .4k dtbug .7k grand .7k flow 12k tclab .9k resfm .1k gene .5k gwh gclab .6k authn 19k .4k 31k cddiff1 .1k cddiff2 .1k dtree cdd .8k .5k cdd .1k figure number of provenances provenance complexity depth leaves highlighting and runtime for both provenance pr and scenario m generation.
for each row max bnd denotes the largest bound in the specification.
for provenance depth leaves highlighting and count we report median average and maximum we give median rather than standard deviation because we do not believe the non performance data are normally distributed.
for leaves we report a value for standard provenance trees and those expanded to a full literal provenance in .
for highlighting we also report the total specification size in characters for comparison.
where numbers exceed we divide by a thousand and add a k suffix.
.
number of explanations we measure the number of provenances generated because much like a stream of scenarios a large number of provenances may conceal the one or two that will uniquely inform the user.
for most specifications the numbers are promising with most literals having only one or two provenances even for flow web and the cddgroup.
some specifications have literals with many provenances.
this occurs when literals can affect the truth of many instantiations of top level constraints at once.
like the colored trees example in sec.
gwh has symmetry connectivity and acyclicity constraints.
removing an edge violates symmetry connectivity and possibly the added requirement that no nodes have degree .
breaking e.g.
connectivity generates one provenance for each pair of newly disconnected nodes up to pairs at an upper bound of nodes .
in the case of flow the literal with provenances is that a specific network packet exists.
much of the specification depends on that packet there are many reasons why it must exist in fact .
the other high provenance counts in fig.
occur for similar reasons.
related work scenario finding is an active research area with a rich history.
while satisfiability is undecidable for first order logic in general bounded or finite scenario finders achieve termination by searching only up to a bounded scenario size.
mace style scenario finders like kodkod alloy s internal engine translate bounded problems into propositional logic and then leverage sat solving technology.minimal and targeted model finding.
aluminum is a version of alloy that produces only minimal scenarios.
these minimal scenarios show only locally necessary positive literals i.e.
positive literals that have provenance .
however aluminum provides no provenance information at all and thus explains neither why the scenarios shown are minimal nor how individual literals interact with the rest of the scenario.
such explanations are amalgam s primary focus.
aluminum also allows users to augment scenarios by making currently false literals true then showing the consistent minimal scenarios that contain the original plus the added literal.
while this allows users to explore the consequences of the addition again it focuses solely on scenario generation and not on the proofs intrinsic to necessity in a scenario.
amalgam incorporates both augmentation and explanation.
moreover amalgam supports reasoning about arbitrary scenarios it can find provenances for negative information in the scenario and find justifications that involve positive literals neither of which would be possible if it enforced minimality.
the razor scenario finder likewise produces minimal scenarios.
by incorporating a notion of provenance into scenariogeneration razor is able to justify every positive literal in the scenarios it produces.
amalgam does not limit itself only to minimal scenarios and so is able to detect and explain local necessity ofnegative as well as positive literals.
razor also lacks support for transitive closure.
114esec fse september paderborn germany t. nelson n. danas d.j.
dougherty and s. krishnamurthi the cryptographic protocol shapes analyzer cpsa produces examples that show when cryptographic protocol specifications violate desired properties.
in contrast amalgam is built atop a domain independent scenario finder and answers why?
questions which cpsa does not consider.
target oriented model finding adds optimization targets to bounded scenario finding problems.
the tool then minimizes graph edit distance from targets enabling e.g.
maximization as well as minimization.
while powerful this approach is still limited to finding streams of scenarios rather than explaining them.
provenance for software and systems.
there has been some prior work on provenance for software.
whyline answers a limited set of why did... and why didn t... questions about java program behavior.
it records and then replays execution history to reconstruct provenance for events.
the y!
tool likewise traces both positive and negative provenance for events in network logs.
vermeer constructs reduced causal traces that explain assertion violations in c programs.
these tools extract provenance from runtime logs which are not available to a scenario finder and have temporal structure that alloy s scenarios need not possess.
fault localization techniques based on test spectra such as tarantula use test suites to produce causal information.
sattar uses alloy specifications to synthesize test inputs to aid localization further illustrating the flexibility of scenario finding .
such tools focus on using many tests to provide insight about a program whereas amalgam helps users understand how different parts of a single scenario interact.
moreover tools like tarantula sat tar and vermeer help explain program behavior amalgam helps users understand their logical specifications and overcome specification specific issues like under and over constraint.
sanity checking.
the need for sanity checking arises when a system may satisfy properties for uninteresting or erroneous reasons.
antecedent failure or vacuity was first investigated by beatty and bryant for model checking.
vacuity can point to subtle issues in either system or property specification as beer et al.
discuss.
hoskote et al.
introduce the notion of coverage in modelchecking to detect when properties fail to fully exercise the system.
kupferman unifies vacuity and coverage noting that both can be found by mutation of the property and system respectively.
since in scenario finding both system and property are combined in the specification our perspective is similar.
beer et al.
and chockler mutate counterexample traces to find causality .
their explanations are with respect to the property not the system amalgam provides causality information with respect to both.
these works also focus on counterexample traces but scenarios in amalgam need not be and often are not temporal.
we are not the first to apply static analysis techniques to alloy specifications.
heaven and russo detect vacuity for a rich subset of alloy.
while we likewise draw inspiration from sanity checking amalgam explains why literals are present in arbitrary scenarios regardless of vacuity.
uzuncaova and khurshid use slicing techniques to prioritize constraints in alloy and thereby improve performance.
the goal of their work is however orthogonal to ours.ghassabani et al.
explain why properties hold in a modelchecker.
this is analogous to alloy s unsat core highlighting feature.
amalgam focuses on the opposite situation explaining why portions of counterexamples are locally necessary.
one related classical technique for generating explanations is abduction .
crucially amalgam is based in understanding observation in a particular model as opposed to explaining deductions.
discussion amalgam takes a first step toward enriching scenario finding by answering why?
and why not?
questions.
we conclude with discussion qualitative experiences and future work.
weaknesses of local necessity.
amalgam s provenances can sometimes be excessively local.
for example when working with undirected trees sec.
it is easy to mistakenly use constraints that work only in the directed case.
in a directed graph acyclicity can be captured by no iden edge i.e.
that there are no identity tuples in the transitive closure of the edge relation.
however this rules out graphs larger than a single node when combined with axioms for symmetry and irreflexivity.
upon seeing the one node example we can ask amalgam why can t another node exist?
.
however we are then only told that the graph must be connected and there is no edge connecting this fresh node to the rest of the tree.
instead we would like a provenance for the combination of a new node and new connecting edges which would direct us to the buggy constraint.
contrasting local necessity and minimality.
in aluminum and razor positive literals are present if they cannot be consistently removed without adding other positive literals.
every positive literal in a minimal scenario is thus locally necessary but the converse does not hold.
consider the propositional theory t p q r and the scenario m p q r .mis not minimal since r also satisfiest but each literal in mis locally necessary r because it is an axiom and pandqbecause of each other s presence.
future work user studies.
concurrent work suggests that provenance can indeed be helpful to alloy users naturally we would like to further evaluate amalgam s effectiveness.
to do so we might manufacture a satisfiable but overconstrained specification as in sec.
.
.
we could then divide participants into a control group using alloy and an experimental group using amalgam and ask them to correct the error.
we might compare the time taken before effecting a fix but it would potentially be more interesting to also evaluate the quality of fixes made.
that is would either group be more prone to fixing the overconstraint while introducing new problems?
it is of course difficult to obtain large pools of alloy users who also possess the time and inclination to participate in user evaluations.
future work other implementation strategies.
one promising alternative to the approach in sec.
leverages unsat core extraction.
by theorem .
a literal lis locally necessary for for a specification tin a given scenario mif and only ift m l ul.
if this entailment holds an unsat core for its negation contains provenance information.
while cores are generally not iterable most solvers would in effect return only a single provenance tools such as camus escape this limitation.
115the power of why and why not enriching scenario exploration with provenance esec fse september paderborn germany we opted for recursive descent rather than an unsat core based approach for several reasons it avoids potential interference with other features of alloy such as symmetry breaking it eliminates confounding factors in evaluation sec.
that could be caused by altering alloy s scenario finding it allows our approach to potentially apply for other tools not based on sat solving and it allowed us to record why each portion of a provenance was generated improving output quality and easing debugging.
nevertheless a core based approach would likely be faster and thus appropriate for applications that make heavy use of provenance.