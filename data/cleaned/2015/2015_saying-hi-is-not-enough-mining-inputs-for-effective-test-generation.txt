saying hi!
is not enough mining inputs for effective test generation luca della toffola department of computer science eth zurich switzerlandcristian alexandru staicu department of computer science tu darmstadt germanymichael pradel department of computer science tu darmstadt germany abstract automatically generating unit tests is a powerful approach to exercise complex software.
unfortunately current techniques often fail to provide relevant input values such as strings that bypass domain specific sanity checks.
as a result state of the art techniques are effective for generic classes such as collections but less successful for domain specific software.
this paper presents testminer the first technique for mining a corpus of existing tests for input values to be used by test generators for effectively testing software not in the corpus.
the main idea is to extract literals from thousands of tests and to adapt information retrieval techniques to find values suitable for a particular domain.
evaluating the approach with java classes from different projects shows that testminer improves test coverage by over an existing test generator.
the approach can be integrated into various test generators in a straightforward way increasing their effectiveness on previously difficult to test classes.
i. i ntroduction automated test generation is a powerful approach to create inputs for exercising a software under test with minimal human effort.
existing approaches use a wide range of techniques ranging from feedback directed random test generation over search based approaches to symbolic reasoning based test generators .
despite all successes test generation still suffers from nontrivial limitations.
for example a study reports that only .
of bugs in a well known collection of existing faults are revealed by the test suites generated by three state of the art test generators .
an important limitation is that test generators often fail to cover a buggy statement because the inputs provided in the test do not enable the code to bypass sanity checks that reject invalid inputs.
in particular creating bug revealing inputs often requires suitable strings but creating such strings requires domain knowledge about the software under test which existing test generators do not have.
for example consider testing a class responsible for parsing sql statements.
testing the class with a randomly generated string is highly unlikely to reach deeply into the code because the invalid input is discarded quickly due to a parse error.
state of the art test generators obtain input data such as strings in various ways.
first most generators use randomly this work has been supported by the dfg within concsys and by the bmbf and the hmwk within crisp and in part by snf grant .generated values or values from a fixed pool which are cheap to obtain but unlikely to match domain specific data formats.
for example randoop often uses the value hi!
as a string value.
second some test generators extract constants e.g.
stored in fields of the class under test and return values of previously called methods and use these values as inputs.
this approach is effective if suitable constants and methods are available but fails otherwise.
third some test generators symbolically reason about expected values e.g.
based on a constraint solver able to reason about strings .
while effective this approach often suffers from scalability issues and may not provide the best cost benefit ratio which is crucial for testing .
finally some test generators rely on a grammar that describes expected string values .
however including grammars for all or even most domain specific input formats into a generalpurpose test generators is impractical.
this paper present testminer a novel technique to address the problem of generating domain specific input values suitable for a given software under test.
the key idea is to exploit the wealth of information available in existing code bases in particular in existing tests using an information retrieval inspired mining technique that predicts input values suitable for testing a particular method.
the approach consists of two phases.
at first the approach extracts literals from the source code of existing tests and indexes them for quick retrieval.
then a test generator queries the mined data for values suitable for a given method under test.
these predicted values are then used as test inputs during test generation.
our idea can be incorporated into any automated test generator that requires input values of primitive types or strings.
in summary this paper makes the following contributions information retrieval for test inputs.
we are the first to exploit the knowledge hidden in large amounts of existing code to address the problem of finding suitable input values for testing.
scalable and efficient prediction of domain specific values.
we present a scalable and efficient technique to predict input values suitable for a given method under test and show how to integrate the technique into an existing test generator.
more effective test generation.
we show empirically that the presented approach positively influences the effectiveness of a state of the art test generator.
.
c ieeease urbana champaign il usa technical research new ideas44 authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
ii.
a pproach this section presents testminer an approach for mining test input values from existing projects.
figure gives an overview of the main steps.
a. static analysis of test suites this first step extracts input values from a corpus of tests and associates to each literal value a context to be used later for retrieving values during test generation.
definition context value pair .
a context value pair c v consists of a context c s !n represented as a bag of words and a value v2v in some value domain.
the set s refers to the set of all strings.
the contextcmay be anything that can be represented as a bag of words.
there are various options for defining the context such as the calling context for the method under test the type hierarchy of the program or the signature of a method that is tested.
in this work we compute the context of a value from the fully qualified signature of the method that receives the value as an argument.
this notion of context works well because fully qualified method signatures often contain rich semantic information .
for each test in the corpus the static analysis collects the fully qualified method signature of all calls sites that pass a literal argument and it annotates each argument with its static type.
the analysis returns for each test a set of call site tuples.
definition call site tuple .
a call site tuple sc tc mc vc consists of a settcof fully qualified type names in which the method mcis defined the method name mc and a setvcof values passed as arguments at the call site.
for example suppose a test case calls sqlparser.parse select x from y .
then the static analysis extracts the following call site tuple forg sql sqlparserg parse f select x from y g .
the settcmay in principle contain multiple type names because a call may resolve to multiple methods.
our static analysis considers only the statically declared type of the base object of a call i.e.
jtcj .
completely resolving all possible call targets would require a whole program analysis which does not scale to a large corpus.
for the set vcof values we focus on string values in this work.
applying the idea to another value domain e.g.
integers is straightforward.
the reason is that finding suitable strings is a major obstacle for state of the art test generators .
finally the analysis transforms the tuples into contextvalue pairs.
for this purpose the approach tokenizes the type names intcand the method name at dot delimiters splitting strings based on the camelcase and snake case conventions and it normalizes the remaining tokens into lower case.
the resulting strings are then represented as a bag of words which represents the context c. for the above example the analysis yields this context value pair forg7!
sql7!
parser7!2g select x from y in the second step the approach summarizes and indexes context value pairs for a later retrieval.
the basic idea is to associate each input value with one or more hash values that summarize the context in which the input value occurs.
the resulting hash map then serves efficiently retrieving values suitable for a particular context.
these steps are summarezied in algorithm and explained in detail here.
algorithm summarize and index context value pairs.
input setpof context value pairs output index to values map m m empty map for all c v 2p do cweighted normalize t df c h simhash cweighted updatem h withv end for returnm assigning weights to context words while some words in the context convey useful information about the domain of the tested code others may be redundant.
for example the word sql is crucial to describe the context for a method that expects an sql query.
in contrast words such as org are very frequent and occur across unrelated domains.
to enable testminer to focus on the most relevant words in a context we compute a weight for each word using theterm frequency inverse document frequency tfidf .
which represents how important a word is to a document in a corpus of documents.
this measure is commonly used for information retrieval.
formally we compute tfidf as t df t d d ft d log jdj jfd2d t2dgj where document dis the contextc a term tis a context word inc the corpus dis the set of all contexts and where ft dis the frequency of term tin document d. for the above example a low weight is assigned to org because this word occurs frequently in the corpus and it assigns a relatively high weight to sql because this word is relatively uncommon but appears twice in the context.
as a result the approach champions the informative parts of the signature and penalizes the less informative ones.
indexing with locality sensitive hashing to index the context words we use the locality sensitive hash function simhashing .
this class of hash functions is designed to assign to similar values a similar hash value with high probability preserving the value similarity also in the hash space.
in addition to efficient retrieval through hashing this choice of hash function enables testminer to generalize beyond the exact contexts extracted from the corpus.
after assigning weights to context words testminer indexes the values for efficient retrieval line and stores values indexed by their hash value line .
the final result of the indexing step of testminer is a map that assigns hash values to test input values authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
static analysisindexing retrievaltest generatorcorpus of testscontextvalue pairsmap of input values queriesvalues fig.
.
overview of the testminer approach.
the blue components are part of the approach.
definition index to values map .
the index to values map m booleank!
v !
n assigns a bit vector of length kto a bag of values.
the bag of values is itself a map that assigns each value to its number of occurrences.
this representation summarizes the context value pairs extracted from different projects by grouping together all values with a similar context.
b. retrieval of values for test generation testminer provides values to a test generator.
when the test generator retrieves values e.g.
to pass them to constructor or method call it is crucial to a query in a timely manner because the time budget allocated for test generation is limited.
integration into test generator as a proof of concept we integrate testminer into the state of the art feedbackdirected random test generator randoop .
when randoop requires a string value e.g.
to pass it as an argument to a method under test we override its default behavior so that it queries testminer for vquery input values with a pquery probability.
retrieval of values algorithm summarizes how testminer retrieves test input values for a given query with a contextcq.
at first it assigns weights to the query context words incqusing the following weighting function 5ft q max tft q log jdj jfd2d t2dgj where ft qis the frequency of a context word in the query and all the other terms have the same meaning as in equation .
these weights give the same importance to the word frequency in the query and to its inverse document frequency in the corpus effectively prioritizing uncommon words.
the weighting function prevents bias towards longer signatures that may contain multiple similar words.
testminer matches the query contextcqagainst contexts that have similar bit vectors using the search algorithm presented in .
the search function searchsimhash returns a mapr string!nof indexed input values.
this function selects values from hash indices that differ at most in distbitsbits from the simhashinged query context.
the threshold distbitscontrols the number of input values returned to the test generator.
a high value for distbits matches against many contexts in the corpus at the cost of high query latency and possibly unrelated values.
finally the algorithm returns a map that represents a probability distribution across suggested values where the probability of a value is proportional to its frequency across all context value pairs.algorithm retrieve values from index to values map.
input query contextcqand index to values map m output probability distribution vresult of values cq weighted t dfweightsforquery cq r searchsimhash cq weighted m dist bits return probdistribution r m iii.
e valuation a. implementation we integrate testminer into randoop .
.
a state of theart feedback directed random test generator .
the retrieval part of our approach is implemented as a server application making easy to integrate it into other test generators.
the static analyses part of testminer is implemented on top of the eclipse jdt framework .
integrating testminer into randoop required only to change about lines in the forwardgenerator class and to add about lines of new code to communicate with testminer.
to query testminer for values to be passed to a method m the modified randoop performs multiple queries with different contextscq the package the class and the method name and the class and the method name the method name.
querying with multiple contexts allows the test generator to retrieve more diverse values than with a single query because different queries emphasize different domain specific terms.
we then combine all the returned values obtained from the three different queries into one set.
our implementation is publicly available at .
b. experimental setup data to learn from to learn about values suitable in a particular context we apply testminer to java projects from the the maven central repository .
we use all projects with source code of tests which yields string values used in different contexts.
classes under test to evaluate the effectiveness of tests generated with testminer we use classes from open source java projects.
of these classes have been previously used for evaluating test generators .
we further augment the existing benchmark classes with string manipulation classes from defects4j and with parsers of different text formats.
because the overall goal of testminer is to suggest values for classes beyond the corpus that the approach learns from we remove from the corpus all the call site tuples that contain a type name in the projects of the classes under test.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
test generation for each class under test we generate tests using both the default version of randoop and the testminer enhanced version.
we use a time budget of minutes per class and repeat each experiment times to account for the random based nature of randoop where each experiment uses a different random seed.
similar parameters were used in previous work .
we run the tests using junit and measure test coverage using the jacoco library.
the coverage is the ratio of executed branches and all branches in the source code of a class.
all experiments are performed on a machine with intel xeon e5 cpu cores and 64gb of memory.
c. effectiveness of generated tests to assess to what extent testminer increases the effectiveness of generated tests we measure the branch coverage in each class under test.
figure shows the average coverage over test suites generated for each class.
overall testminer improves the coverage for classes and decreases it for classes.
on average over all classes the relative improvement is increasing coverage from to .
a wilcoxon signed rank test shows this increase to be statistically significant p .
cohen s deffect size which is a statistical measure of the strength of the increase is which is considered large.
increased coverage testminer increases coverage from to more than for the classes pathurn resourceurl and urn because randoop is unable to instantiate these classes.
in contrast by using domain specific strings testminer helps instantiate these classes enabling the test generator to explore their behavior.
however for the utf8streamjsonparser class testminer also fails to instantiate the class.
manual inspection shows that the class requires a complicated iocontext object that reads json files and assumes such files to exist.
providing such files is out of reach for both randoop and testminer but may be addressed e.g.
by symbolic testing techniques .
decreased coverage testminer decreases the branch coverage for classes.
a manual inspection of the produced test suites for stringescapeutils shows that the constant retrieval fails due to an implementation error in our prototype caused by a non escaped unicode character that produces a communication error with the server.
for datetime and strtokenizer the decrease is on average but achieves higher coverage than randoop for some test suites as shown by the error bars.
besides a few classes most of the results do not show a significant difference in coverage across the repetitions i.e.
the error bars are moderately small.
the reason is the large timeout which allows the test generator to reach saturation.
d. query result examples testminer provides to the test generator semantically rich and diverse values.
the following values are examples from tests suites generated during our experiments iban scbl00000011234567022 sql abc like network address fe80 8ff fefa d1e3 e mail test example.org however there are also strings that do not help in testing a specific method such as foo or metadata .
fortunately due to the nature of feedback directed test generation these values are likely to be ignored in later stages of the generation process.
for example randoop filters already seen values that did not trigger any errors during execution.
e. performance analysis and indexing the static analysis takes several hours to process the entire corpus but finishes within a single day.
indexing the context value pairs takes about seconds.
retrieval retrieving values from testminer takes longer than using randoop s hard coded constants.
to measure slows down of test generation we compare the size of the test suites generated by randoop and testminer.
in the minutes time budget randoop generates tests whereas the testminer enhanced test generator creates only tests i.e.
a reduction.
during our evaluation millions of string values are requested by the test generator but the number of unique queries is only allowing our implementation to make extensive use of caching to keep the runtime overhead low.
overall testminer slows down the test generation but the increased runtime cost pays off because the tests generated with testminer are significantly more effective.
f .
influence of parameters testminer has three meta parameters which we set experimentally to maximize coverage increase distbits .
running testminer with distbits 8significantly reduces branch coverage because fewer strings are returned to randoop which often defaults to its built in strings.
setting distbits drastically increases query time and reduces the number of generated test in the time budget.
pquery .
running testminer with pquery provides a lower branch coverage.
vquery .
running testminer with vquery provides no significant difference in branch coverage.
iv.
r elated work test generation there are various approach for automatically generating test cases symbolic and concolic execution random based test generation and search based testing .
beyond unit tests automated testing has been applied e.g.
to concurrent software and to graphical user interfaces .
our work is orthogonal and could be integrated into many of these approaches.
learning from existing code to improve test generation liu et al.
train a neural network to suggest textual inputs for mobile apps .
similar to testminer they learn from existing tests how to create test inputs.
our work differs by using information retrieval instead of a neural network by learning authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
se.kth.cid.identity.mimetypese.kth.cid.identity.pathurn se.kth.cid.identity.resourceurlse.kth.cid.identity.urise.kth.cid.identity.urn org.openscience.cdk.index.casnumberorg.apache.commons.io.filenameutils org.apache.commons.lang3.stringescapeutilsorg.apache.commons.lang3.stringutilsorg.apache.commons.lang3.validate org.apache.commons.lang3.math.numberutilsorg.apache.commons.lang3.text.strtokenizerorg.apache.commons.lang3.text.wordutils org.apache.commons.validator.routines.datevalidatororg.apache.commons.validator.routines.emailvalidatororg.apache.commons.validator.routines.ibanvalidatororg.apache.commons.validator.routines.isbnvalidator org.apache.commons.validator.routines.inetaddressvalidatororg.apache.commons.validator.routines.urlvalidatornet.sf.dblp2db.dblpstat.db.fields.isbnnet.sf.dblp2db.dblpstat.db.fields.monthnet.sf.dblp2db.dblpstat.db.fields.yearcom.google.gson.jsonparser com.google.common.base.strings com.google.common.net.inetaddresses com.fasterxml.jackson.core.json.utf8streamjsonparserorg.joda.time.datetimeorg.jsoup.parser.parserorg.jxpfw.util.clocale org.jxpfw.util.internationalbankaccountnumbercom.efisto.util.util com.puzzlebazar.client.util.validateemailstempeluhr.validation.timechecker uk.gov.tameside.apps.validation.dateformatvalidatoruk.gov.tameside.apps.validation.numericvalidatoruk.gov.tameside.apps.validation.postcodevalidatorcom.facebook.presto.sql.parser.sqlparsercom.prowidesoftware.swift.model.biccom.prowidesoftware.swift.model.ibanwebwork.examples.userreg.validatoraveragecoverage randoop testminerfig.
.
coverage without and with testminer.
the colored bars represent the average coverage value over runs of the test generator.
the size of the error bars shows the difference between the first and the third quartile.
from already existing tests written by developers instead of writing tests specifically for learning and by generating unit tests instead of ui level tests.
testilizer mines ui tests for web applications by collecting input values for generating tests.
in contrast testminer statically collects input values from tests written for a different application.
the equivalence modulo input emi approach tests compilers by modifying existing tests i.e.
programs into new test.
our work also learns how to create new tests from existing tests but applies to various applications domains beyond compilers.
several approaches improve test generation by learning from existing code which methods to call .
testminer differs from these techniques by improving the selection of input values instead of the selection of calls.
domain knowledge for test generation studies show that providing domain knowledge to test generators improves testing effectiveness .
several approaches obtain domain specific inputs e.g.
by querying web sites web services or semantic knowledge graphs .
all these techniques require querying the internet for retrieving values.
to the best of our knowledge testminer is the first offline technique to suggest domain specific input values.
learning from existing source code existing work exploits natural language information in source code e.g.
to detect programming errors and suboptimal identifier names to cluster software systems to inferspecifications and to find inconsistencies between code and comments .
our work also exploits domain knowledge encoded in natural language specifically in identifier names to improve testing.
other work on learning from existing code includes learning a statistical language model for code completion and applying information retrieval to the problem of bug localization .
v. c onclusion test generation is a challenging problem and finding suitable input values is an important part of this challenge.
our work presents testminer a new approach that learns from a large corpus of existing tests which input values to use in newly generated tests based on the domain of the tested software.
the approach combines static analysis and information retrieval to extract input values to index them based on the context in which they occur and to provide values suitable for a specific domain to a test generator.
our evaluation shows that testminer improves test coverage from to on average over a set of classes that challenge state of the art test generators.
the approach scales to thousands of analyzed projects efficiently responds to queries for input values and generalizes beyond the software analyzed as part of the corpus.
the testminer approach provides a simple querying interface that enables existing test generators to benefit from domainspecific input values with little effort.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.