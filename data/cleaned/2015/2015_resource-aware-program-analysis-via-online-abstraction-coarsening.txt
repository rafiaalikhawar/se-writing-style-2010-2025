resource aware program analysis via online abstraction coarsening kihong heo university of pennsylvania kheo cis.upenn.eduhakjoo oh korea university hakjoo oh korea.ac.krhongseok yang kaist hongseok.yang kaist.ac.kr abstract we present a new technique for developing a resource aware program analysis.
such an analysis is aware of constraints on available physical resources such as memory size tracks its resource use and adjusts its behaviors during fixpoint computation in order to meet the constraint and achieve high precision.
our resource aware analysis adjusts behaviors by coarsening program abstraction which usually makes the analysis consume less memory and time until completion.
it does so multiple times during the analysis under the direction of what we call a controller.
the controller constantly intervenes in the fixpoint computation of the analysis and decides how much the analysis should coarsen the abstraction.
we present an algorithm for learning a good controller automatically from benchmark programs.
we applied our technique to a static analysis for c programs where we control the degree of flow sensitivity to meet a constraint on peak memory consumption.
the experimental results with real world programs show that our algorithm can learn a good controller and the analysis with this controller meets the constraint and utilizes available memory effectively.
index t erms static analysis resource constraint learning i. i ntroduction when a static program analysis aims at reasoning about deep semantic properties it typically requires a huge amount of resources such as memory .
the fixpoint computation of the analysis is usually neither compositional nor incremental.
as a result when the analysis runs out of memory or hits time limit its intermediate results are simply discarded.
some researchers have suggested to make the analysis store intermediate results and then resume it with more resources .
there has also been work on estimating the amount of resource use such as analysis time before the analysis begins .
however none of these existing techniques addresses the essence of the issue which asks for a new type of program analysis that is aware of a constraint on available resources and constantly controls its resource use during fixpoint computation.
the amount of resource that a program analysis needs for a given analysis task highly depends on the degree of program abstraction employed by the analysis such as flow sensitivity and context sensitivity.
for example a flow sensitive analysis stores different abstract states for different program points unlike its flow insensitive counterpart that computes only one abstract state which summarizes information for all program points .
in our experiments the flow insensitive interval analysis on emacs .
.
503kloc requires 18gb of memory but the flow sensitive counterpart needs more than 128gb.
unfortunately going beyond this general trend and predictingthe maximum amount of resource use is hard.
syntactic characteristics of an analyzed program are not enough.
for instance while vim60 227kloc is smaller than emacs26.
.
the flow insensitive analysis consumes more memory 33gb more on the former than on the latter.
in this paper we present a resource aware program analysis.
this analysis is aware of a given resource constraint tracks its resource use during fixpoint computation and constantly adjusts its behavior via online abstraction coarsening.
more concretely instead of fixing a program abstraction prior to the main part of the analysis i.e.
fixpoint computation our resource aware analysis starts with the most expensive abstraction and gradually coarsens the abstraction by observing the analysis behavior and its resource use.
this coarsening is directed by a controller which continually intervenes the fixpoint computation of the analysis monitors resource use and other status of the analysis such as workset size and decides how much the analysis should coarsen abstraction.
it is the quality of this controller that determines the success of our resource aware analysis in terms of analysis precision and conformance to resource constraint.
we present an algorithm for learning such a controller automatically from a given codebase.
the algorithm repeatedly runs the analysis with a gradually improving controller on all training programs in the codebase collects important parts of traces of these analysis runs and uses them to improve the controller.
we formalize our approach in a general setting so that it becomes applicable to a wide range of static program analyses.
we instantiated our approach with a partially flow sensitive analysis for c programs and evaluated it with large programs 503kloc .
this instantiated analysis adjusts the degree of flow sensitivity online under the direction of a controller that was learned from other smaller programs 80kloc .
we compared this analysis with a baseline analysis that does not control flow sensitivity online but picks the degree of flow sensitivity before the analysis begins.
both analyses control flow sensitivity by choosing a subset of variables in the program to be analyzed flow sensitively.
when this baseline analysis was set to choose the of variables for flow sensitivity as in it could not analyze out of the programs under the 128gb of memory budget.
it turns out that to do so the baseline should be set to choose less than a number difficult to find a priori.
meanwhile our analysis did not require any such predefined parameter.
once the 128gb ieee acm 41st international conference on software engineering icse .
ieee authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
limit was given it adapted program abstraction appropriately and completed all the analysis tasks.
the outcome was the same when we changed the budget to 64gb.
furthermore our analysis was more precise than the baseline that was set to use the of variables for flow sensitivity.
for null dereference it reported and fewer alarms under 64gb and 128gb budgets and for buffer overrun and fewer alarms.
we summarize our contributions below we present resource aware program analysis a new approach to meet a given resource requirement by constantly observing the use of physical resources and coarsening program abstraction online based on the observations.
we propose an algorithm for learning a controller for abstraction coarsening.
our learning algorithm is inspired by batch mode reinforcement learning .
we demonstrate the effectiveness of our approach with a real world static analyzer and large c programs.
ii.
o verview our main research question is how to build a program analysis that would work well under a given resource constraint.
in particular we are interested in constraints on memory.
in this section we illustrate this question and our learning based solution using partially flow sensitive interval analysis.
a. problem static analysis under resource constraint 1x y z v input w input 2x z 3z z 4y x 5assert y query hold 6assert z query hold 7assert v w query may fail consider the program above.
the series of assignments until the line set x yto1andzto2 while letting vandwkeep the values selected by the user.
as a result queries and hold but query may fail.
now consider the problem of developing a partially flowsensitive interval analysis that can prove queries and of our example but does not keep more than intervals during the analysis of the example.
here we do not regard latticetop meaning as interval.
more generally the analysis takes a program pand a bound bon the maximum number of intervals that can be kept in memory during the analysis ofp.1we want the analysis to prove as many queries in p as possible while respecting the constraint on memory.
this problem is an instance of a general resource constrained staticanalysis problem to which we will return later.
the problem cannot be solved by the standard flow sensitive or flow insensitive analysis.
the former does not meet the resource constraint.
when it does its best in terms of accuracy the flow sensitive analysis computes the following result that associates an abstract state at each program point 1for brevity we assume that a resource bound is given as the maximum number of intervals.
in our implementation however the analyzer takes the maximum amount of memory budget.line flow sensitive abstract state x mapsto y mapsto z mapsto v mapsto latticetop w mapsto latticetop x mapsto y mapsto z mapsto v mapsto latticetop w mapsto latticetop x mapsto y mapsto z mapsto v mapsto latticetop w mapsto latticetop x mapsto y mapsto z mapsto v mapsto latticetop w mapsto latticetop note that the analysis uses intervals two more than allowed .
the flow insensitive analysis on the other hand is not accurate enough although it meets the constraint.
it computes a single memory state where variables yand zhave the intervals and respectively which are not strong enough to prove query .
b. solution online abstraction coarsening our solution is a resource aware static analysis that coarsens program abstraction during analysis adaptively based on a given resource constraint the current resource usage and analysis states and the properties of the program.
this adaptive online coarsening is directed by two functions m and .
the first function m called model assigns a number between0and1 including boundary values to each variable.
the assigned number m v indicates how important it is to analyze the variable vflow sensitively in terms of removing false alarms.
we use m to rank variables.
for instance for our example program we may have a model m that satisfies m w m v m z m y m x .
the model m induces the ranking w v z y x which suggests among other things that the top two beneficiaries of flow sensitivity are variables xandy.
note that the suggestion is good for our goal of proving queries and it suffices to treat only xandyflow sensitively.
the second function called controller takes information about the current status of the analysis such as current memory usage and decides the number of program variables that are currently treated flow sensitively but should be treated otherwise.
that is it decides how to coarsen the current program abstraction.
note that analyzing fewer variables flowsensitively entails keeping fewer intervals in memory so that the analysis is more likely to meet the constraint i.e.
at most ten intervals in memory .
the function is at the heart of the analysis s effort for meeting the constraint.
our analysis uses these functions m and and analyzes our example program as follows.
in the beginning it treats all program variables flow sensitively.
but after a fixed amount of computation the analysis pauses the usual fixpoint computation gathers information about resource usage and abstract states and asks the controller how many more variables it should analyze flow insensitively.
for instance the analysis might pause at the line and the controller might instruct that .
of variables should be analyzed flowinsensitively.
using m the analysis ranks variables picks w at the bottom of the ranking as a variable to be analyzed flowinsensitively and coarsens the analysis results as follows line fs abstract state fi abstract state x mapsto y mapsto z mapsto v mapsto latticetop w mapsto latticetop x mapsto y mapsto z mapsto v mapsto latticetop authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
note that the analysis no longer keeps the abstract value ofwper program point but it maintains just a single flowinsensitive memory state for it.
this controller guided abstraction coarsening happens regularly.
suppose that the second one occurs when the analysis reaches line .
the analysis result at this moment is line fs abstract state fi abstract state x mapsto y mapsto z mapsto v mapsto latticetop x mapsto y mapsto z mapsto v mapsto latticetop w mapsto latticetop x mapsto y mapsto z mapsto v mapsto latticetop note that the analysis already uses nine intervals and is close to the resource limit.
the controller may act more aggressively now and instruct the analysis to coarsen the abstraction of the half of the remaining variables i.e.
to analyze two more variables flow insensitively.
if such an instruction is indeed given the analysis chooses variables zandvbased on their lowm ranking and changes the analysis result as follows line fs abstract state fi abstract state x mapsto y mapsto z mapsto v mapsto latticetop w mapsto latticetop x mapsto y mapsto x mapsto y mapsto the variables zand vare now treated flow insensitively and their abstract values are changed by flow independent counterparts.
note that the abstract values of xat lines and are updated as well.
these updates are due to the assignment x zat line which propagates to xthe change of z s abstract value from to .
finally the analysis reaches the fixpoint with the abstract state x mapsto y mapsto for the last line i.e.
lines .
note that the fixpoint is strong enough to prove queries and and that the resource constraint is also met.
c. learning a controller whether our analysis performs well or not depends on m and .
this naturally raises the question how to come up with goodmand ?
answering the question about mis relatively easy.
there already exist techniques for automatically learning a scoring function like m from a codebase .
the situation about is however not so simple.
a controller is an example of what reinforcement learning researchers call policy and learning it from a codebase requires solving an optimization problem more difficult than those involved in learning m. for this purpose we have developed an algorithm by altering the batch version of a sarsa style on policy algorithm from reinforcement learning .
for each program p let spbe a set of data structures that store all the runtime information of the analysis such as current abstract states memory usage and workset size.
we calls spanalysis state .
our algorithm is equipped with a feature map p sp ffor each program p where fis a subset of rnfor some n. the map ptakes an analysis state s sp which may refer to specific aspects of the program pbeing analyzed and returns a real valued vector f fthat may not make such reference.
given a collection ptrof programs our algorithm constructs a function f pr a which takes informa tion about the current status of the analysis in the featurevector form and returns a probability distribution on a ... .
elements in arepresent percentages of variables that have been treated flow sensitively so far by the analysis but will be treated differently in the future.
when analyzing a program p our analysis uses the function in conjunction with p. it first transforms s spto a featurevector representation p s then computes a probability distribution p s over the percentages in a and finally returnsa awith the highest probability.
in order to construct a controller our algorithm builds a functionq f a which assigns a score to every pair of feature vector fand percentage a. an ideal qassigns a high score to f a when the following property holds when the current analysis state sis abstracted to f i.e.
p s f treatinga more variables flow insensitively gives the best analysis outcome in terms of both proving queries and meeting the resource constraint.
once the algorithm finishes building q it defines a controller qby2 q f a q f a summationtext a prime aq f a prime which becomes the result of the algorithm.
the function qis built by an iterative process which involves the invocation of the analysis on the programs in the codebase ptr.
let us illustrate how this is done when our codebase is really simple ptr p0 .
recall that when the analysis is run on p0under a controller it may invoke p0multiple times with different analysis states.
when our algorithm starts it draws a probability on a from the uniform distribution on probabilities on a. this becomes the initial value of .
then the algorithm runs the analysis under the epsilon1 noise version of for some small epsilon1 .
it means that when the analysis calls the controller with the current analysis state s sp0 the controller picks argmaxa p0 s a with probability epsilon1 o r with probability epsilon1 it picks one of the rest a prime auniformly.
suppose that this run follows the trajectory and score angbracketlefts0 a1 s1 a1 s2 a1 s3 angbracketright .
the algorithm then replaces each siin the trajectory by p0 si and generates labeled data as follows d1 angbracketleft p0 si a1 angbracketright .
i .
next the algorithm uses d1as a training set and calls an offthe shelf supervised learning algorithm on it.
the result of this call becomes the intial q. our algorithm then repeats the steps just described but with the controller qinduced by qinstead of the randomly initialized one.
it runs the analysis with q. suppose that this time the analysis goes through the following path angbracketlefts0 a1 s1 a2 s4 angbracketright .
the algorithm generates labeled data from this pair of trajectory and score and adds them to its training set d2 d1 angbracketleft p0 s0 a1 angbracketright .
angbracketleft p0 s1 a2 angbracketright .
.
note that the algorithm reuses the training data from the previous iteration.
this accumulation is important for the 2for this construction to work we should have summationtext a prime aq f a prime .
the algorithm ensures this condition.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
efficiency of our learning algorithm and is a well known technique in reinforcement learning where d2is called replay buffer .
as before the algorithm invokes the off the shelf supervised learning algorithm on d2 setsqto the result of this invocation and defines q. this process of learning qis repeated until the algorithm reaches a fixpoint or hits upon its iteration limit.
the result of our algorithm is the controller qfor the last q. iii.
c ontrollable program analysis now we formalize our approach.
in this section we define a class of program analyses equipped and guided by controllers.
recall our notation spfor each program p. it is the set of analysis states that may arise during the analysis of p. a state s spcontains not only the usual logical information such as abstract states but also the information about the runtime status of the analysis such as memory usage and workset size.
we formalize a controllable program analysis as a collection of tuples ip tp bp rp indexed by a program p where the tuples have the following types ip sp tp sp a sp bp sp b andrp sp .
intuitively ipis the initial analysis state tpmodels a singe execution step of the analysis and bp s is a predicate for testing whether the analysis is finished at the state sor not.
the predicate bp s is true if the analysis reaches a fixpoint or runs out of a given resource budget.
the last rp s reports the ratio between the queries proved in sand all queries.
if the analysis stops at s because of a resource shortage then rp s .
note that in order to transform a state sto the next s prime the analysistpshould be given an additional parameter a a called action .
we assume that the set aof actions is finite.
the main responsibility of a controller is to select a good actionausing information stored in the current analysis state s.a trajectory pfor a program pis a finite alternating sequence of states and actions angbracketlefts0 a0 s1 a1 s2 ... a n sn angbracketright such that tp sk ak sk bp sn true and bp sk false for all0 k n. we say that starts ats0.i fs0is the initial state of the analysis ip we say that iscomplete .
we require that for every program p there should exist an upper bound n 0on the lengths of trajectories p. this requirement means that for each program p regardless of how a controller chooses an action in each analysis state the analysis of pterminates in less than n 2number of steps.
iv .
c ontroller a controller is our main addition to a static analysis and is in charge of selecting an appropriate action before each analysis step.
formally it is a tuple of a subset f rnthat consists of feature vectors a controller f pr a from feature vectors to probability distributions on a and a feature map p sp ffor each program p which abstracts analysis states to feature vectors.a good way to understand this definition is to go through the steps through which the analysis uses it.
assume that we are given a program pto analyze.
for brevity we further assume that the controller is used at each analysis step.
in the implementation however the controller is triggered when some particular events such as new memory allocation occur.
the details will appear in section vi.
the analysis uses the controller to define an action selector ap sp ato beap s argmaxa parenleftbig p s a parenrightbig .
given an analysis state the selector picks an action in three steps.
it first converts the state to a feature vector f then looks up thef th entry of and gets a probability distribution f over actions and finally picks an action that has the highest probability in f .
the analysis combines this selector and thetpfunction in order to define the transfer function fp s tp s ap s .
then it invokes the transfer function fpto carry out the analysis of p. in our instantiation of this framework we defined pusing manually crafted features.
the details of these features will appear in section v. for a controller however we found it automatically using an algorithm.
we considered a parameterized controller and formulated an optimization problem over whose objective function encourages the analysis with to perform well on a given set of benchmark programs i.e.
when running on those programs under a given resource constraint the analysis proves as many queries as possible and avoids violating the constraint as much as possible.
in the rest of this section we explain this learning algorithm in detail.
a. q function all the controllers that we consider are defined in terms of functions q f a .intuitively q f a predicts how well the analysis would perform if it takes an action a at an analysis state f. it is an estimate of the rpvalue of a programpthat the analysis would produce when i its starting analysis state is represented by the feature vector f ii it takes the action aat this starting point and iii after the action a the analysis chooses best actions for maximizing the rpvalue.
this function corresponds to the q function in reinforcement learning.
it gives rise to the following controller f a braceleftbigg1 a ifq f b for allb a q f a summationtext b aq f b otherwise .
b. learning a parameter we find automatically using a given set of training programs in ptr.
we set an optimization problem for which asks for finding that induces the best estimate q for programs in ptrin a sense.
then we solve the problem approximately.
a solution is a parameter of someq which is then turned into the controller by the recipe in .
let us go into the details of our algorithm for learning from ptr.
for a program pand an analysis state s sp let q p s a be the real number in the interval defined by q p s a s u p braceleftbig n rp last vextendsingle vextendsingle pstarts with s a and hasnactions.
bracerightbig .
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
algorithm controller learning input training set ptr exploration parameter epsilon1 discount factor output controller forf fdo set f to a uniform distribution on a end for d while timeout do forp ptrdo angbracketlefts0 a0 ... s n an sn angbracketright doanalysis p epsilon1 whereai braceleftbigg randoma with prob.
epsilon1 .99i argmaxa fi a otherwise andfi p si d prime angbracketleftbig angbracketleftfj aj angbracketright rj angbracketrightbig n j 0whererj rp sn n j d d d prime end for q dosupervisedlearning d construct fromqusing end while return here is a discount factor that penalizes long trajectories.
intuitively q p s a represents the best score that the analysis of pcan achieve by choosing actions carefully when it starts or resumes with taking the action aat the state s. also let sr pbe the analysis states that may be reached sr p braceleftbig s sp vextendsingle vextendsinglesappears in a complete trajectory p bracerightbig .
our algorithm tries to find q that approximates q well.
the following optimization problem formalizes what the algorithm aspires to achieve argmin summationdisplay p ptr s a sr p a parenleftbig q p s a q p s a parenrightbig2 .
intuitively the optimization objective says that q is the best estimate of q for all reachable analysis states.
unfortunately this is an intractable optimization problem.
just evaluating the objective in the problem is difficult because it involves q which is difficult to find and the index set sr p ain the summation is too large.
our algorithm solves the problem in approximately using heuristics from the reinforcement learning community.
it is given in algorithm .
on the high level the algorithm repeats the following two steps and improves the candidate .
first it runs the analysis on all the programs in the training setptrusing a slightly randomized version of the controller .
during this run the algorithm collects information about analysis states encountered actions taken at those states and qualities of analysis results measured by the rpfunctions.
second the algorithm uses the collected information to improve .
it uses the information not just from the analysis run in the first step but also from all the prior iterations.
then it invokes an off the shelf supervised learning algorithm with this information and computes a better parameter .
here is a more detailed explanation of our algorithm.
it starts with a randomly initialized controller lines .
for each program pinptr the algorithm generates a completetrajectory by running the static analysis with a slightlyrandomized variant of the controller line .
at each analysis state s sp this variant picks an action athat maximizes p s a with probability epsilon1 .99i where iis the number of iteration of the algorithm .
with the remaining epsilon1 .99iprobability the variant draws an action from the uniform distribution on a. this random draw part is introduced here mainly to encourage the analysis to explore and try new actions.
note that the degree of exploration is determined by the parameter epsilon1 in our experiment we use epsilon1 .
.
our variant of is an instance of the well known epsilon1 greedy exploration strategy in reinforcement learning .
every state action pair in the generated trajectory is stored indtogether with a discounted rpvalue of the trajectory after its state part is abstracted by the feature map p line .
thus dends up with containing angbracketleftx r angbracketrightwhere xis a pair of feature vector and action and ris a real number between 0and1.
note that the set daccumulates such angbracketleftx r angbracketrightfrom all the iterations of the algorithm so far.
this accumulation makes our algorithm more data efficient.
a similar technique called replay buffer is often used by offline algorithms in reinforcement learning.
we want to point out that x angbracketleftx r angbracketright d can be understood as an approximation of the set sr p a in and the rpart of each pair in dcan be viewed as an estimate of the value of q at a concretization of x. once our algorithm runs the analysis for all programs in ptr it invokes an off the shelf supervised learning algorithm line on d. in this invocation each angbracketleftx r angbracketrightindis treated as a data point xlabeled with r. the result of this supervised learning is then converted to the controller by our recipe in and our algorithm repeats what we have just described with this newly constructed .
v. a pplica tion to flow sensitive analysis we applied the method to a static analysis that checks buffer overrun and null dereference for c programs where the goal is to learn a controller that adjusts the degree of flowsensitivity online and makes the analysis work under a given constraint on memory usage.
we describe an existing partially flow sensitive analysis and explain how to learn a controller by following the recipe described in the previous sections.
the partially flow sensitive analysis by is defined with the semantic function gl d d where d c s denotes the abstract domain i.e.
maps from program points c to abstract states s .
an abstract state s s l v maps abstract locations in lto abstract values in v.i n our instance landvare the set of program variables and the lattice of intervals respectively.
note that the semantic function is parameterized by a set l lof abstract locations which controls the degree of flow sensitivity.
the analysis becomes fully flow sensitive when l l and becomes completely flow insensitive when l .
the fixpoint of gl can be computed by a standard workset algorithm.
using the partially flow sensitive analysis we construct its controllable counterpart ip tp bp rp in section iii for each program p. the analysis states in spare triples authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
table i features for our learning methods.
feature description membudget the inverse of memory budget memconsum current memory consumption divided by the total budget latticeheight current lattice position divided by the lattice height worksetsize current workset size divided by the total workset size l x y 2l d rt.
the first component lof a triple is a set of locations to be analyzed flow sensitively the next xis an element in the abstract domain d and the last y is a table in rt recording various information about analysis runtime such as memory usage and the size of the current workset.
the initial state is ip l d y0 where the table y0stores information at the start of the analysis.
we define the set aof actions to be natural numbers between and .
intuitively an action ainstructs the analysis to treata of program variables in lflow insensitively.
a single execution step of the analysis is modeled by tp tp l x y a reduce l a x unionsqgl x y prime first it computes a subset reduce l a ofl which determines how much to coarsen the flow sensitivity.
it calculates the subset by ranking the locations in lusingmpand picking only the a of them from the top of the ranking.
here mpis a map from abstract locations lto and estimates for eachl l the impact of analyzing lflow sensitively on proving queries.
we use this map constructed by which is available in the open source distribution of .
second tp computes the next abstract domain element by joining xand gl x we use widening if dhas an infinite height .
note that computing gl x involves running one fixpoint iteration.
third after this iteration is finished tpcollects the current runtime information about the analysis and stores it in y prime.
the predicate bpchecks whether the analysis terminates or not.
the analysis terminates if the abstract domain element is a fixpoint of the semantic function i.e.
gl x subsetsqequalx o rt h e given resource is exhausted.
the last rptakes an analysis state l x y sp examines the program pusing the current abstract domain element x and returns the ratio of proved queries over the total number of queries.
in our experiments we used buffer overrun and null dereference queries.
to use our framework we need to define a feature map p sp fthat converts analysis states to feature vectors.
in this instance analysis we use four features in table i which are all related to the memory usage of the analysis.
each feature denotes a real number between and .
the first memorybudget records information about a given memory bound.
it is one divided by the total memory budget given to the analysis.
here we take the multiplicative inverse for normalization.
the next memconsum is the ratio of the current memory usage to the total memory budget expressed in fraction.
the third feature is latticeheight which denotes the relative height of the current abstract domain element against the estimated total height of the lattice.
for finite abstract domains we directly compute both the height of the element and the total height and compute their ratio.table ii characteristics of benchmark programs for training and testing.
loc reports lines of code before pre processing.
var reports the number of variables in the program precisely abstract location .
training testing program loc var program loc var mp3c .
15k 5k sendmail .
.
129k 26k less 23k 3k redis .
.
148k 63k make .
.
27k 4k nethack .
.
209k 59k fpgatools 30k 12k git .
.
238k 69k exifprobe .
.
40k 13k vim60 226k 58k screen .
.
41k 10k python .
.
332k 42k clif .
42k 12k r .
.
376k 80k urjtag .
63k 14k emacs .
.
503k 129k gawk .
.
78k 28k uucp .
80k 15k for infinite abstract domains we use approximate heights.
in our experiments with interval analysis we approximated the heights of elements in the lattice of intervals using the method described in .
then for an abstract domain element x din this analysis we summed these estimated heights of the intervals in x and used their sum as our approximate height of x. the last feature is worksetsize and denotes the normalized size of the workset.
the last part needed to instantiate our framework is a controller .
we can generate it automatically by applying algorithm to a training set ptrof programs.
vi.
e xperimental ev alua tion we designed and carried out experiments that aim at answering the following research questions analysis precision how precise is our analysis that coarsens its program abstraction online with a learned controller compared with the existing offline approach ?
memory utilization how well do learned controllers utilize given memory budgets?
learning algorithm how effective is our algorithm for learning a controller?
how does the controller behave?
runtime overhead how much runtime overhead is incurred by coarsening program abstraction during analysis?
we implemented our technique on top of s parrow an open source state of the art static analyzer for c programs implemented in ocaml.
the analyzer is partially context sensitive and field sensitive and tracks both numeric and pointer values using the interval domain and allocationsite based heap abstraction.
we used the implementations of sparse analysis partially flow sensitive analysis and a pre trained model m for ranking locations which are available in the open source distribution of s parrow .
when measuring analysis precision we counted the numbers of buffer overrun alarms and null dereference alarms.
instead of invoking a controller and coarsening abstraction in every analysis step we triggered abstraction coarsening only when the ocaml runtime allocates memory in the major heap .
the decision tree algorithm in the scikit learn package was our choice of the supervised learner in algorithm .
we used the default hyper parameters of the decision tree library.
the exploration rate epsilon1and the discount authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
table iii effectiveness of our partially flow sensitive analysis with online abstraction coarsening.
baseline reports the performance of the baseline analysis with k .time reports the execution time of each analysis in minutes.
bo and nd report the number of buffer overrun alarms and that of null dereference alarms respectively.
mem reports memory consumption in gigabytes.
the numbers in parentheses represent memory utilization memory consumption divided by budget .
dashes mean that the analysis runs out of memory.
baseline offline online 64gb online 128gb program time bo nd mem time bo nd mem time bo nd mem sendmail .
.
.
redis .
.
.
nethack .
.
.
git .
.
.
vim60 python .
.
.
r .
.
emacs .
.
factor in algorithm were set to .
and .
.
we learned the controller by running the algorithm for iterations.
we used the programs in table ii.
the ten small programs 100kloc were used for training a controller and the remaining eight large programs 100kloc for evaluating the learned controller.
since the training programs are small even the flow sensitive analysis of them does not exhaust 64gb and 128gb memory budgets.
thus in the training phase we set the memory budget for each program based on information that we collected by running the partially flow sensitive analysis in the s parrow distribution whose degree of flow sensitivity had to be set manually.
more concretely for each training program p ptr we first ran sparrow s partial flow sensitive analysis four times with different degrees of flow sensitivity we made it track the and of variables flow sensitively in those runs.
the peak memory consumption of these analysis runs was then used as our memory budget for the program in the training phase.
in the testing phase we set the memory budget to 64gb or 128gb and measured the performance of the learned controller.
note that we did not use s parrow s partial flowsensitive analysis at all here.
using the programs in our testing set we compared our technique against the partially flow sensitive analysis in the s parrow distribution.
as we already mentioned this baseline analysis selects program abstraction offline and the percentage kof variables to be treated flow sensitively should be set manually before the analysis begins.
we used k as in the original work .
for detailed comparison we also used different kvalues with k .
a. analysis precision we experimentally compared the precision of our analysis with online abstraction coarsening with that of the baseline analysis with offline abstraction coarsening.
we measured the precision by counting the number of buffer overrun alarms and that of null dereference alarms lower is better .
the experimental results appear in table iii with further details shown in figure .
for redis .
.
our analysis with online abstraction coarsening reported and bufferoverrun alarms under 64gb and 128gb memory budgets respectively.
meanwhile the baseline analysis reported 977alarms.
for null dereference alarms our analysis reported and under 64gb and 128gb memory budgets respectively while the baseline reported alarms.
the baseline analysis with a higher kvalue may be able to report fewer alarms but it is difficult to manually pick the best kfor each memory budget.
for example when analyzing vim60 even the analysis with k ran out of memory.
even worse memory consumption is not proportional to program size analyzing larger programs such as python .
.
and r .
.
may consume less memory than analyzing smaller ones.
on the other hand by coarsening program abstraction online under the guidance of the learned controller our analysis was able to automatically meet the given memory budget and successfully analyzed those programs vim60 r .
.
and emacs .
.
that made the baseline analysis run out of memory.
b. memory utilization we now report what we found about the memory utilization of the learned controller.
these findings are based on our measurements on the peak memory consumption of our analysis and that of the baseline analysis.
the results of our experiments are given in figure .
the baseline analysis with ten different flow sensitivity settings i.e.
... of variables could not utilize the memory budget effectively.
it abstracted flow sensitivity too much when it started and under utilized a given memory budget.
or it abstracted flow sensitivity too little and exceeded the budget.
meanwhile for every test program our analysis met a given budget and never ran out of memory.
we want to make two further important points.
first when our analysis was applied to sendmail .
.
redis .
.
and git .
.
under the 128gb budget it used less than 64gb but this does not mean that our analysis under utilized its budget 128gb.
in all of these cases the analysis reported as few alarms as the one run under no abstraction coarsening at all.
second the learned controller guided the online coarsening of our analysis such that the given memory budget was never exceeded but well utilized.
when run on vim60 under 64gb and 128gb budgets our analysis used 63gb and 111gb respectively.
the experiments on other larger programs showed the similar high utilization of a given memory budget.
for the programs r .
.
and emacs .
.
our analysis utilized 53gb authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
fig.
precision of our partially flow sensitive analysis with online abstraction coarsening.
the x axis represents the percentage of variables for flow sensitivity.
the y axis reports the number of alarms.
the plain line shows the number of alarms by the baseline analysis.
the line with and represent the numbers of alarms by our analysis under 64gb and 128gb memory budgets respectively fig.
memory utilization of our partially flow sensitive analysis with online abstraction coarsening.
the x axis is the of variables for flow sensitivity.
the y axis reports the peak memory consumption.
and 57gb when run under the 64gb budget and 92gb and when run under the 128gb budget.
c. learning algorithm next we report on our evaluation of algorithm which learns a controller from given training programs.
we compared our learning algorithm with the naive algorithm based on random sampling.
the latter works as follows.
it fixes a controller that chooses the percentage of variables tocoarsen from the uniform distribution on ... .
the algorithm then instantiates our analysis with this controller analyzes all programs in the training set multiple times andcollects the trajectories of these runs.
the collected trajectoriesare converted to a labeled dataset by the methodology de scribed at the end of section iv b. finally the naive learningalgorithm calls an off the shelf supervised learner with thedataset and builds a controller from the output of the learner.
figure shows the learning curve of our algorithm for the first iterations.
it reports the numbers of alarms ina normalized form.
the number of alarms is bounded.
theupper bound is the number of alarms by the flow insensitiveanalysis.
the lower bound is the total number of alarms bythe partially flow sensitive analysis whose degree is manuallyset to or as described in section vi.
foreach number of alarms our normalization subtracts this lowerbound from it and divides the result by the difference betweenthe upper bound and the lower bound.
after this normalization all the numbers fall in the range .
the figure also shows how many alarms are raised by the analysis with a random controller used in the naive learning algorithm.
according to figure our learning algorithm improves a controller continuously with some noise due to epsilon1 random exploration and eventually ends up with a controller that removes up to the of all the removable alarms.
thegraph in the figure shows a sudden change in the learningcurve at iteration .
here is what happens.
at nearly everyiteration until the 29th our algorithm changes the controllersuch that the controller coarsens fewer variables and leads tothe decrease in the number of alarms.
but at the 30th iteration the algorithm finds that under the current controller most of the analysis runs with training programs exhaust memory.
this failure produces trajectories with very low scores and makesthe off the shelf supervised learning algorithm fix the issueswith the controller.
after around iterations the algorithmgets stabilized the fluctuations afterwards are mainly due tothe epsilon1 random exploration.
the figure also shows the score of the naive learning algorithm with the random con troller.
furthermore the random controller does not performwell in the test programs.
among the eight test programs theanalyzer ran out of memory for four under the 64gb budget and for five under the 128gb budget.
this indicates that the authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
fig.
learning curve of algorithm up to iterations.
random controller used by the naive algorithm does not try promising or informative trajectories often a situation different from the one experienced by our learning algorithm.
finally we found that the learned policy is interpretable and its reasoning can be read off as reasonable human readable rules.
this is one of the benefits of using the decision tree algorithm.
for example the learned policy uses the following rules discovered by the algorithm if the budget is enough membudget .
the memory consumption is low memconsum .
and the workset is small worksetsize .
coarsening a large percentage of variables would result in more alarms.
even with a small budget membudget .
if the lattice is high latticeheight .
and the workset is small worksetsize .
coarsening a small percentage of variables would result in fewer alarms.
d. runtime overhead we measured the runtime overhead of our approach.
the overhead includes extracting features from the current analysis states finding the most promising action using the controller and coarsening flow sensitivity.
overall the abstraction coarsening process took up to of the running time for all test programs.
however applying abstraction coarsening more aggressively did not always reduce the running time.
for example analyzing sendmail .
.
under the 64gb memory budget took longer than the same analysis with the 128gb memory budget even though the former is less precise.
such circumstances are not uncommon in program analysis because a less precise analysis may explore more spurious behaviors of a target program than the precise version.
e. limitations and threats to v alidity although our approach of developing a program analysis with online abstraction coarsening and learning its controller from a codebase can be applied to a wide range of program analysis problems in principle we admit that in practice such an application commonly requires further nontrivial engineering.
what we have shown in our experiments is limited to a particular analysis problem.
we list the specific aspects of this problem that may be absent in different analysis problems.
type of resource our instance analysis and controller are only concerned with memory consumption.
hence our experimental results and findings might not represent what would happen for constraints on different analysis resources such as time and hard disk usage.
type of abstraction our instance analysis only controls flow sensitivity.
if it is asked to control other abstraction techniques such as context sensitivity and relational analysis in addition then we might have to alter our approach especially our algorithm for learning a controller in order to get meaningful experimental results.
type of features to abstract analysis states we have used a set of features carefully designed for our constraint on memory consumption.
a new set of features will have to be designed for other types of analysis resources.
vii.
r ela ted work our work is related or influenced by several lines of prior research in program analysis and machine learning.
a. automatic abstraction finding one high level idea used by our work is to adapt program abstraction automatically to a given analysis task.
there are several realizations of this idea which let us automatically find good program abstraction that balances the precision and the cost of analysis.
well known examples include counterexample guided abstraction refinement cegar parametric program analysis based on pre analysis or dynamic analysis and program analysis tuned by machine learning algorithms .
although these techniques have been successful they are not designed with resource constraints in mind and cannot cope with them well.
for example the recent techniques for controlling flow and context sensitivity would abort without producing any results if there were no more memory available.
our aim is to address this resourceconstraint problem in the context of automatic abstraction finding or adjustment.
we equip a static analysis with the ability for coarsening abstraction online and let a controller direct this coarsening while learning a good controller automatically from a set of benchmark programs.
all of these make our analysis regard resource constraints on a par with analysis precision and cost when it adapts program abstraction.
b. resource bounded program analysis there have been a few studies on physical resources used by a program analyzer .
the technique by estimates the analysis time one form of physical resource before the analysis begins.
however it does not attempt to control the analysis so that it meets a constraint on resources while such a control is the focus of our work.
the bounded abstract interpretation provides one way of coping with a resource constraint.
it prepares the analysis for the case that all available resources are gone by making the analysis store intermediate results.
the analysis may resume from those stored results when more resources become available.
note that our goal is authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
different from that of this bounded abstract interpretation we want to prevent this resource exhaustion from happening.
c. data driven program analysis our work is data driven in that it learns a controller automatically from a set of benchmark programs.
such a datadriven approach has been pursued actively by program analysis researchers to learn program analysis heuristics also to predict program properties and sometimes to synthesize abstract semantics as well.
our work falls into the first heuristic learning category but addresses a more difficult learning problem than those considered in the existing work.
most of those works are concerned with analysis heuristics that are used once only at the beginning of the analysis.
thus it is feasible to solve optimization problems related to learning directly by bayesian optimization boolean formula learning decision tree learning and one class svm .
however in our case we have to learn a controller that will make a series of decisions and receive a feedback for not a single but a group of decisions.
the search space for learning in our case is much larger than that in the existing work.
the situation is similar to the difference between supervised and reinforcement learning in the difficulties of problems tackled by them.
in fact most of the techniques used in the existing work come from supervised learning while ours comes from reinforcement learning.
grigore et al.
s work in is one of the few exceptions where they presented a method to learn a model that guides abstraction refinement during analysis.
however their learning algorithm is restricted to datalog and so it cannot be applied to general non datalog program analyses.
d. reinforcement learning and transfer learning our approach can be understood as a variant of the batchmode reinforcement learning algorithm .
a controller in our work corresponds to a so called policy in reinforcement learning .
our algorithm for learning a controller uses reinforcement learning techniques for learning a good policy.
the idea of repeatedly executing a policy and improving it based on execution trajectories that of accumulating all the trajectories and using them for learning and the idea of approximating the ideal q function and defining a policy based on the approximation all of these are common techniques from reinforcement learning.
however our approach attempts to learn a controller from a collection of small programs and to apply the controller to different large programs.
typically the objectives of reinforcement learning algorithms are to learn a good policy for a given problem not to learn a policy from one problem that generalizes well to other similar but different problems.
the first point that we have just made is closely related to what so called transfer learning attempts to achieve.
transfer learning aims at developing techniques for automatically adapting a learned classifier or a model from one dataset or a problem domain to a different dataset or a new problem domain.
a wide variety of techniques have been developed inthe contexts of text classification natural language processing and software defect prediction just to name a few.
our work can be understood as an addition to this line of research on transfer learning.
in our case we encourage our controller learning algorithm to come up with a transferable controller by making it use a program independent carefully designed common feature space.
recently singh et al.
used reinforcement learning to select a series of cost effective abstract transformers during polyhedra analysis.
we tackle a different problem of analyzing programs under resource constraints which requires different instantiation and adaption of reinforcement learning techniques such as our on policy controller learning algorithm instead of approximate q learning algorithm used by them.
viii.
c onclusion we have presented a methodology for building a static program analysis that should work well under a resource constraint such as a limit on peak memory consumption.
our methodology suggests to design an analysis that continually adjusts its program abstraction online i.e.
during analysis in such a way to meet a given resource constraint and also to prove as many queries as possible.
the key component behind this online adjustment is a controller that takes runtime information about the current status of the analysis such as memory usage and workset size and instructs the analysis about how it has to change program abstraction.
the controller itself can be learned automatically from a collection of programs using our algorithm presented in the paper.
we illustrated our methodology with a partially flow sensitive analysis a constraint on peak memory consumption and two types of program queries and through experiments with this instantiation we showed the promise of our methodology.
let us finish this paper with one rather speculative remark.
a standard formalism for static program analysis does not pay enough attention on how the analysis uses its physical resources such as memory and time.
managing such resources well is typically regarded as a low level issue.
we think that it is worth revisiting this practice and we hope that our work encouraged a reader to do so.
if we extend the scope of highlevel analysis specification include resource management as its part and allow the part to interact with the rest of the analysis closely then we may be able to open up new ways of improving program analysis systematically with formal tools.
acknowledgment we thank mayur naik and kee eung kim for helpful comments.
oh was supported by samsung research funding incubation center of samsung electronics under project number srfc it1701 .
yang was supported by the engineering research center program through the national research foundation of korea nrf funded by the korean government msit nrf 2018r1a5a1059921 and also by next generation information computing development program through the national research foundation of korea nrf funded by the ministry of science ict 2017m3c4a7068177 .
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.