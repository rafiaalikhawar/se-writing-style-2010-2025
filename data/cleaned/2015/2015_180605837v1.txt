oreo detection of clones in the twilight zone vaibhav saini farima farmahinifarahani yadong lu pierre baldi and cristina lopes university of california irvine vpsaini farimaf yadongl1 pfbaldi lopes uci.edu abstract source code clones are categorized into four types of increasing difficulty of detection ranging from purely textual type to purely semantic type .
most clone detectors reported in the literature work well up to type which accounts for syntactic differences.
in between type and type however there lies a spectrum of clones that although still exhibiting some syntactic similarities are extremely hard to detect the twilight zone.
most clone detectors reported in the literature fail to operate in this zone.
we present oreo a novel approach to source code clone detection that not only detects type to type clones accurately but is also capable of detecting harder to detect clones in the twilight zone.
oreo is built using a combination of machine learning information retrieval and software metrics.
we evaluate the recall of oreo on bigclonebench and perform manual evaluation for precision.
oreo has both high recall and precision.
more importantly it pushes the boundary in detection of clones with moderate to weak syntactic similarity in a scalable manner.
keywords clone detection machine learning software metrics information retrieval acm reference format vaibhav saini farima farmahinifarahani yadong lu pierre baldi and cristina lopes .
.
oreo detection of clones in the twilight zone.
in proceedings of the 26th acm joint european software engineering conference and symposium on the foundations of software engineering esec fse .
acm new york ny usa pages.
nnnnnnn introduction clone detection is the process of locating exact or similar pieces of code within or between software systems.
over the past years clone detection has been the focus of increasing attention with many clone detectors having been proposed and implemented see for a recent survey on this topic .
these clone detection approaches and tools differ from each other depending on the goals and granularity of the detection.
there are four broad categories of permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
copyrights for components of this work owned by others than acm must be honored.
abstracting with credit is permitted.
to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
request permissions from permissions acm.org.
esec fse 4 9 november lake buena vista florida united states association for computing machinery.
acm isbn x xxxx xxxx x yy mm.
.
.
.
detection approaches ranging from easy to detect to harderto detect clones textual similarity lexical similarity syntactic similarity and semantic similarity.
the literature refers to them as the four commonly accepted types of clones type textual similarity identical code fragments except for differences in white space layout and comments.
type lexical or token based similarity identical code fragments except for differences in identifier names and literal values.
type syntactic similarity syntactically similar code fragments that differ at the statement level.
the fragments have statements added modified and or removed with respect to each other.
type semantic similarity code fragments that are semantically similar in terms of what they do but possibly different in how they do it.
this type of clones may have little or no lexical or syntactic similarity between them.
an extreme example of exact semantic similarity that has almost no syntactic similarity is that of two sort functions one implementing bubble sort and the other implementing selection sort.
clone detectors use a variety of signals from the code text tokens syntactic features program dependency graphs etc.
and tend to aim for detecting specific types of clones usually up to type .
very few of them attempt at detecting pure type clones since it requires analysis of the actual behavior a hard problem in general.
starting at type and onwards however lies a spectrum of clones that although still within the reach of automatic clone detection are increasingly hard to detect.
reflecting the vastness of this spectrum the popular clone benchmark bigclonebench includes subcategories between type and type namely very strongly type strongly type moderately type and weakly type which merges with type .
in order to illustrate the spectrum of clone detection and its challenges listing shows one example method followed by several clones of it from type to type .
the original method takes two numbers and returns a comma separated sequence of integers in between the two numbers as a string.
the type clone starting in line is syntactically identical and differs only in the identifiers used e.g.
begin instead of start .
it is very easy for clone detectors to identify this type of clones.
the very strong type clone starting in line has some lexical as well as syntactic differences namely the use of a for loop instead of a while loop.
altough harder than type this subcategory of type is still relatively easy to detect.
the moderate type clone starting in line differs even more from the original method the name of the method is different seq vs.sequence the comma is placed in its own local variable and the type string is used instead of stringbuilder.
this subcategory of type clones is much harder to detect than the previous ones.
the weak type clone starting in line differs from the original method by a combination of lexical syntactic and semantic changes string vs. stringbuilder a conditional whose logic has changed vs and it takes one additional input parameter that allows forarxiv .05837v1 jun 2018esec fse 4 9 november lake buena vista florida united states vaibhav saini farima farmahinifarahani yadong lu pierre baldi and cristina lopes listing sequence between two numbers original method string sequence int start int stop stringbuilder builder new stringbuilder int i start while i stop if i start builder .append builder .append i i return builder .
tostring type clone string sequence int begin int end stringbuilder builder new stringbuilder int n begin while n end if n begin builder .append builder .append n n return builder .
tostring very strongly type clone string sequence short start short stop stringbuilder builder new stringbuilder for short i start i stop i if i start builder .append builder .append i return builder .
tostring moderately type clone string seq int start int stop string sep string result integer .
tostring start for int i start i if i stop break result string .
join sep result integer .
tostring i return result weakly type clone string seq int begin int end string sep string result integer .
tostring begin for int n begin n if end n break result string .
join sep result integer .
tostring n return result type clone string range short n short m if n m return short .
tostring n return short .
tostring n range n m different separators.
the similarities here are weak and very hard to detect.
finally the type clone starting in line implements similar but not the exact same functionality in a completely different manner through recursion and it has almost no lexical or syntactic similarities to the original method.
detecting type clones in general requires a deep understanding of the intent of a piece of code especially because the goal of clone detection is similarity and not exact equivalence including for semantics .
clones that are moderately type and onward fall in the twilight zone of clone detection reported precision and recall of existing clone detectors drop dramatically for them.
for this reason they are the topic of our work and of this paper.
our goal is to improve the performance of clone detection for these hard to detect clones.
we present oreo a scalable method level clone detector that is capable of detecting not just type through strong type clones but also clones in the twilight zone.
in our experiments the recall values for oreo are similar to other state of the art tools in detecting type to strong type clones.
however oreo performs much better on clones where the syntactic similarity reduces below the area of clone detection where the vast majority of clone detectors do not operate.
the number of these harder to detect clones detected by oreo is one to two orders of magnitude higher than the other tools.
moreover oreo is scalable to very large datasets.
the key insights behind the development of oreo are twofold functionally similar pieces of code tend to do similar actions as embodied in the functions they call and the state they access and not all pieces of code that do similar actions are functionally similar however it is possible to learn by examples a combination of metric weights that can predict whether two pieces of code that do the same actions are clones of each other.
for semantic similarity we use a novel action filter to filter out a large number of method pairs that don t seem to be the same actions focusing only on the candidates that do.
for those potential clones we pass them through a supervised machine learning model that predicts whether they are clones or not.
a deep learning model is trained based on a set of metrics derived from source code.
we demonstrate that oreo is accurate and scalable.
the results presented in this paper were obtained by training the metrics similarity model using sourcerercc a state of the art clone detector that has been shown to have fairly good precision and recall up to type clones but not type .
however our approach is not tied to sourcerercc any accurate clone detector can be used to train the model.
specifically many clone detection techniques like graph based or ast based which are accurate but hard to scale can be used in the training phase.
the contributions of this paper are as follows detection of clones in the twilight zone .
compared to reported results of other clone detectors in the literature oreo s performance on hard to detect clones is the best so far.
analysis of clones in the twilight zone .
in addition to quantitative results we present analysis of examples of harder to detect clones a difficult task even for humans of deciding whether they are clones and the reasons why oreo succeeds where other clone detectors fail.
process pipeline to learn from slow but accurate clone detector tools and scale to large datasets .
many clone detection approaches like graph and ast based techniques are accurate but hard to scale.
we show how they can be used simply to train a model.
the trained model then can be used to predict clones on larger datasets in a scalable manner.
deep neural network with siamese architecture .
we propose siamese architecture to detect clone pairs.
an important characteristic of a deep neural network based upon siamese architecture is that it can handle the symmetry of its input vector in other words in training stage presenting the pair a b to the model will be the same as presenting the pair b a a desirable property in clone detection.
oreo is publicly available at all data used in this study is also publicly available and is submitted as supplementary data.
the remainder of this paper is organized as follows.
section presents three concepts that are parts of our proposed approach and are critical to its performance section explains the deep neural network model used in our approach and how it was selected and configured section .
describes the clone detection process usingoreo detection of clones in the twilight zone esec fse 4 9 november lake buena vista florida united states figure overview of oreo.
the concepts introduced in sections and section elaborates on the evaluation of our approach we present the manual analysis of clone pairs in section section discusses the related work in this area section presents the limitations of this study and finally section discusses conclusions and future work.
the oreo clone detector the goals driving the design of oreo are twofold we want to be able to detect clones in the twilight zone without hurting accuracy and we want to be able to process very large datasets consisting of hundreds of millions of methods.
in order to accomplish the first goal we introduce the concept of semantic signature based on actions performed by that method followed by an analysis of the methods software metrics.
in order to accomplish the second goal we first use a simple size based heuristic that eliminates a large number of unlikely clone pairs.
additionally the use of semantic signatures also allows us to eliminate unlikely clone pairs early on leaving the metrics analysis to only the most likely clone pairs.
figure gives an overview of oreo.
.
preprocessing one key strategy to scaling super linear analysis of large datasets is to preprocess the data as much as possible.
preprocessing consists of a one time linear scan of the data with the goal of extracting features from it that allow us to better organize and optimize the actual data processing.
in oreo we preprocess all the files for extraction of several pieces of information about the methods namely their semantic signature section .
and assorted software metrics.
table shows the 24method level metrics extracted from the source files.
a subset of these metrics is derived from the software quality observatory for open source software sqo oss .
the decision of which sqo oss metric to include is based on one simple condition a metric s correlation with the other metrics should not be higher than a certain threshold.
this was done because two highly correlated metrics will convey very similar information making the presence of one of them redundant.
from a pair of two correlated metrics we retain the metric that is faster to calculate.
additionally to sqo oss we extract a few more metrics that carry important information.
during our initial exploration of clones in the twilight zone we noticed many clone pairs where both methods are using the same type of literals even though the literals themselves are different.
for example there are many cases where both the methods are using either boolean literals or string literals.
capturing the types of these literals is important as they contain information that can be used to differentiate methods thattable method level software metrics name description xmet number of external methods called vref number of variables referenced vdec number of variables declared nos number of statements nopr total number of operators noa number of arguments nexp number of expressions nand total number of operands mdn method maximum depth of nesting loop number of loops for while lmet number of local methods called hvoc halstead vocabulary heff halstead effort to implement hdif halstead difficulty to implement exct number of exceptions thrown excr number of exceptions referenced cref number of classes referenced comp mccabes cyclomatic complexity cast number of class casts nbltrl number of boolean literals ncltrl number of character literals nsltrl number of string literals nnltrl number of numerical literals nnulltrl number of null literals operate on different types a signal that they may be implementing different functionality.
as a result we add a set of metrics marked with in the table that capture the information on how many times each type of literal is used in a method.
.
size similarity sharding when clone detection on real code the vast majority of method pairs are notclones of each other.
however the clone detector needs to process all possible pairs of methods in order to find out which ones are clones.
this can be extremely costly and even prohibitive on very large datasets when the technique used for detecting clones is cpu intensive.
a general strategy for speeding up clone detection is to aggressively eliminate unlikely clone pairs upfront based on very simple heuristics.
the first and simplest heuristic used by oreo is size.
the intuition is that two methods with considerably different sizes are very unlikely to implement the same or even similar functionality.
this heuristic can lead to some false negatives specifically in the case of type clones.
however in all our experiments we observed little to no impact on the recall of other clone types especially those in the twilight zone.
as a metric of method size we use the number of tokens in the method where tokens are language keywords literals strings literals are split on whitespace types and identifiers.
this is the same definition used in other clone detection work e.g.
.
given a similarity threshold tbetween and and a method m1with x tokens if a method m2is a clone of m1 then its number of tokens should be in the range provided in .
x t x t in oreo this size similarity filter is implemeted in the preprocessing phase by partitioning the dataset into shards based on the sizeesec fse 4 9 november lake buena vista florida united states vaibhav saini farima farmahinifarahani yadong lu pierre baldi and cristina lopes of the methods.
we divide the dataset into multiple partitions such that each partition contains only methods within certain lower and the upper size limits.
the partition s lower and upper limits for candidate methods are calculated using equation where xis substituted with the partition s lower and upper limits.
the partitions are made such that any given candidate method will at most belong to two partitions.
the remaining components for clone detection are performed only within shards and not between different shards.
besides acting as a static filter for eliminating unlikely clones size based sharding is also the basis for the creation of indexes that speed up clone detection in subsequent filters.
another important design detail is that oreo uses a secondlevel size based sharding within each top level shard for purposes of loading batches of candidate pairs into memory.
during clone detection we load each second level shard into the memory one by one and query it with all query methods in the shard s parent partition.
this leads to fast in memory lookups thereby increasing the overall speed of clone detection.
the idea of input partitioning is not new and has been used in information retrieval systems many times .
researchers in other fields have explored partitioning based on size and also horizontal partitioning to solve the scalability and speed issues .
here we apply those lessons to our clone detector.
.
semantic similarity the action filter clones in the twilight zone have low lexical and syntactic similarity but still perform similar functions.
in order to detect clones in this spectrum some sort of semantic comparison is necessary.
we capture the semantics of methods using a semantic signature consisting of what we call action tokens .
the action tokens of a method are the tokens corresponding to methods called and fields accessed by that method.
additionally we capture array accesses e.g.
filename and filename as arrayaccess andarrayaccessbinary actions respectively.
this is to capture this important semantic information that java encodes as syntax.
listing action filter example public static string getencryptedpassword string password throws infoexception stringbuffer buffer new stringbuffer try byte encrypt password.getbytes utf messagedigest md messagedigest.getinstance sha md.update encrypt byte hashedpasswd md.digest for int i i hashedpasswd.length i buffer .append byte.
tostring hashedpasswd catch exception e throw new infoexception languagetraslator .
traslate e return buffer .
tostring semantic signatures are extracted during preprocessing.
as an example of action tokens extraction consider the code in listing which converts its input argument to an encrypted format.
the resulting action tokens are getbytes getinstance update digest length append tostring translate arrayaccess and tostring .
these action tokens more than the identifiers chosen by the developer or the types used are a semantic signature of the method.
the intuition is that if two methods perform the same function they likely call the same library methods and refer the same object attributes even if the methods are lexically and syntactically different.
1thearrayaccess action token stands for hashedpasswd .modern libraries provide basic semantic abstractions that developers are likely to use oreo assumes the existence and use of these abstractions.
hence we utilize these tokens to compare semantic similarity between methods.
this is done in the first dynamic filter of oreo the action filter .
we use overlap similarity to calculate the similarity between the action tokens of two methods.
equation shows the function to calculate the overlap similarity where a1anda2are sets of action tokens in methods m1andm2respectively.
each element in these sets is defined as t f req where tis the action token and f req is the number of times this token appears in the method.
sim a1 a2 a1 a2 in order to speed up comparisons we create an inverted index of all the methods in a given shard using action tokens .
to detect clones for any method say m in the shard we query this inverted index for the action tokens of m. any method say n returned by this query becomes a candidate clone of m provided the overlapsimilarity between m and n is greater than a preset threshold.
we call m the query method n a candidate of m and the pair m n is called candidate pair.
besides serving as semantic scanner of clone pairs the action filter also contributes to making the proposed approach both fast and scalable.
this is because it allows us to eliminate early on clone pairs for which the likelihood of being clones is low.
the action filter eliminates these pairs prior to further analysis by other components of oreo.
using the notion of method calls to find code similarity has been previously explored by goffi et al.
where method invocation sequences in a code fragment are used to represent a method.
we are not interested in the sequence instead we use method invocations in a bag of words model as this model has been shown to be robust in detecting type clones .
.
metrics similarity method pairs that survive the size filter and the action filter are passed on to a more detailed analysis of their properties.
in the case of oreo that detailed analysis focuses on the methods software metrics.
here we explain the reasons for this decision.
the next section dives deeper into the metrics similarity component.
metrics based approaches for clone detection are known to work very well if the goal is to find only type and type clones .
this is understandable given the strict definitions of type and type the metrics values of such clone pairs should be mostly the same.
for type metrics might look like a good choice too because metrics are resilient to changes in identifiers and literals which is at the core of type cloning.
however the use of metrics for clones in the twilight zone is not straightforward because these clones may be syntactically different.
as such the use of metrics requires fine tuning over a large number of configurations between the thresholds of each individual metric.
finding the right balance manually can be hard for example is the number of conditionals more meaningful than the number of arguments?
after experimenting with manual tuning we decided to address this issue using a supervised machine learning approach which is explained in the next section.oreo detection of clones in the twilight zone esec fse 4 9 november lake buena vista florida united states figure clone detection pipeline process the method pairs that reach the metrics filter are already known to be similar in size and in their actions.
the intuition for using metrics as the final comparison is that methods that are of about the same size and that do similar actions but have quite different software metrics characteristics are unlikely to be clones.
.
clone detection pipeline figure shows oreo s pipeline in more detail including the major intermediary data structures.
this pipeline makes use of all components presented in this section.
source code files are first given to a metrics calculator to extract methods and their software metrics.
these metrics form the input to oreo.
then input partitioning is conducted as described in section .
which generates partitions containing query methods and possible candidate methods.
then for each partition we create inverted index of its candidates.
this inverted index is further partitioned into multiple shards also explained in section .
.
we then load one of its index shards into the memory.
this shard is then queried with all queries of this partition.
for each query method the index returns a list of candidate clone methods.
then the hash values of the metrics for each query and its candidates are compared.
if metric hash of the query and a candidate are equal we report them as clones this is because type1 and type clones have similar structures and thus equal metric values.
if the metric hash is not equal we pair the candidates with the query and create feature vectors for the candidate pairs.
these candidate pairs are then analyzed by the trained model which predicts if the pair is a clone pair or not.
this process is repeated for all partitions and their shards to identify all possible clone pairs.
we describe the trained model used in oreo s pipeline in section .
.
learning metrics for anything other than minor deviations from equality the use of software metrics for clone detection leads to an explosion of configuration options.
to address this issue we use a supervised machine learning approach.
the trained model learns the best configuration of the 24software metrics from a training set of clones and non clones.
in this section we first describe the dataset used to train the model.
then we describe the model and explain how it was selected.
.
dataset curation to prepare a dataset we download 50k java projects from github.
to ensure we have enough variability in the dataset the projects are selected randomly.
we then extract methods with or more tokens from these projects this ensures we do not have empty methods in the dataset.
also it is the standard minimum clone size for benchmarking .
to get isclone labels we used sourcerercc a state of the art type clone detector.
from this dataset we randomly sample a labeled dataset of 50m feature vectors where 25m vectors correspond to clone pairs and other 25m to non clone pairs.
each feature vector has metrics for each member in the pair and one binary label named isclone .
for model selection purposes we randomly divide the dataset into pairs for training and pairs for testing.
one million pairs from the training set are kept aside for validation and hyperparameter tuning purposes.
it should be noted that we do not use bigclonebench s dataset for training as this dataset is used for benchmarking purpose only.
training and testing on the benchmarking dataset will induce a significant favorable bias and we avoid that by creating a fresh dataset for training.
.
deep learning model while there exists many machine learning techniques here we are using deep learning to detect clone pairs.
neural networks or deep learning methods are among the most prominent machine learning methods that utilize multiple layers of neurons units in a network to achieve automatic learning.
each unit applies a nonlinear transformation to its inputs.
these methods provide effective solutions due to their powerful feature learning ability and universal approximation properties.
these approaches scale well to large datasets can take advantage of well maintained software libraries and can compute on clusters of cpus gpus and on the cloud.
deep neural networks have been successfully applied to many areas of science and technology such as computer vision natural language processing and even biology .
here we propose to use a siamese architecture neural network to detect clone pairs.
siamese architectures are best suited for problems where two objects must be compared in order to assess their similarity.
an example of such problems is comparing fingerprints .
another important characteristic of this architecture is that it can handle the symmetry of its input vector.
whichesec fse 4 9 november lake buena vista florida united states vaibhav saini farima farmahinifarahani yadong lu pierre baldi and cristina lopes 24features input 24features 200units 200units 200units 200units 200units 100units 50units 25units classificationunit two identical subnetworks comparator layer layer layer layer layer layer layer layer figure siamese architecture model trained for clone detection the model consists of two parts two identical subnetworks a comparator network and a classification unit.
means presenting the pair m1 m2 to the model will be the same as presenting the pair m2 m1 .
this is crucial to our problem as in clone detection the equality of clone pair m1 m2 with m2 m1 is an issue that should be addressed while detecting or reporting clone pairs.
the other benefit brought by siamese architectures is a reduction in the number of parameters.
since the weight parameters are shared within two identical sub neural networks the number of parameters are less than a plain architecture with same number of layers.
figure shows the siamese architecture model trained for oreo.
here the input to the model is a dimensional vector created using the metrics described in section .
.
this input vector is split into two input instances corresponding to two feature vectors associated with two methods.
the two identical subnetworks then apply the same transformations on both of these input vectors.
these two subnetworks have the same configuration and always share the same parameter values while the parameters are getting updated.
both have hidden layers of size with full connectivity the output of each neuron in layer n is taken as input of neurons in layer n .
the two outputs of the these subnetworks are then concatenated and fed to the comparator network which has four layers of sizes with full connectivity between the layers.
output of this comparator network is then fed to the classification unit which consists of a logistic unit shown in equation .
in this equation xi is the i th input of the final classification unit and wiis the weight parameter corresponding to xi.
the product wi xi is summed over iranging from to since we have units in layer the layer before classification unit .
the output of this unit is a value between and and can be interpreted as the probability of the input pair being a clone.
we claim that a clone pair is detected if this value is above .
.
f 25 i 1wi xi e 25 i 1wi xi all the neurons in the layers use relu activation function on i max in i where on i in iare respectively the output and input of the i th neuron in layer n to produce their output.
in this model to prevent overfitting a regularization technique called dropout is applied to every other layer.
in this technique during training a proportion of the neurons in a layer are randomlytable comparison of precision recall values for different models on test dataset model precision recall logistic regression .
.
shallow nn .
.
random forest .
.
plain dnn .
.
siamese dnn .
.
dropped along with their connections with other neurons.
in our experiment we achieve the best performance with dropout.
the loss function function that quantifies the difference between generated output and the correct label used to penalize the incorrect classification is the relative entropy between the distributions of the predicted output values and the binary target values for each training example.
relative entropy is commonly used to quantify the distance between two distributions.
training is carried out by stochastic gradient descent with the learning rate of .
.
the learning rate is reduced by after each training step epoch to improve the convergence of learning.
the parameters are initialized randomly using he normal a commonly used initialization technique in deep learning.
training is carried out in minibatches where the parameters are updated after training on each minibatch.
since the training set is large we use a relative large minibatch size of .
.
model selection to find the model we experiment with several architectures for each architecture several number of layers and units and several hyper parameter settings such as learning rate the rate for updating the weight parameters and loss function.
to compare these models we compute several classification metrics including accuracy the rate of correct predictions based on validation dataset labels precision the fraction of retrieved instances that are relevant recall the fraction of relevant instances that are retrieved receiver operating characteristic roc curve true positive rate against false positive rate and area under the roc curve auc .
the selection process is described in the rest of this section.
as mentioned in the process of selecting the best model we also train other models based on different architectures including a simple logistic regression model a shallow neural network shallow nn model with a single hidden layer and similar amount of parameters as in siamese model and a plain fully connected network plain dnn with the same layer sizes as the full siamese architecture.
for each architecture we train many models and for the sake of simplicity here we compare the best model from each mentioned architecture.
all models are trained on the same dataset for epochs and training is terminated if the validation loss stops increasing for two consecutive epochs.
results comparing the best model from each mentioned architecture are reported in figure to figure as well as table .
the siamese network model outperforms all other models in every metric.
figure illustrates the accuracy attained by each model through the epochs in training and figure shows the same concept in validation.
the siamese deep neural network dnn and plain dnn have better accuracy than other two models.
however the siamese dnn designed to accommodate the symmetry property oforeo detection of clones in the twilight zone esec fse 4 9 november lake buena vista florida united states epochs0.
.
.
.
.
.
.
.95training accuracy logistic regression shallow nn plain dnn siamese dnn figure training accuracy epochs0.
.
.
.
.95validation accuracylogistic regression shallow nn plain dnn siamese dnn figure validation accuracy epochs01234training losslogistic regression shallow nn plain dnn siamese dnn figure training loss epochs0.
.
.
.
.
.5validation losslogistic regression shallow nn plain dnn siamese dnn figure validation loss .
.
.
.
.
.
false positive rate0.
.
.
.
.
.0true positive ratelogistic regression auc .
shallow nn auc .
plain dnn auc .
siamese dnn auc .
figure roc plot and auc values its overall input outperforms the accuracy of the plain dnn.
more importantly this model is performing better than the plain dnn on the validation set despite using significantly less free parameters.
thus the siamese architecture is considered to have better generalization properties on new samples.
figure depicts how the training loss is decreased over the epochs for each model and figure shows the same concept for validation loss.
in figure we observe that the training loss for logistic regression and shallow nn models stops improving at around .
.
whereas the loss for plain nn and siamese dnn can go below .
as we train longer.
a similar pattern is observed for validation loss in figure .
the large fluctuations for shallow nn are due to the small size of the validation set.
figure shows the roc curves of the different classifiers and compares the corresponding auc values for validation dataset.
generally a good classifier has a high value of area under the roc curve measured by auc because a large area denotes a high true positive rate and low false negative rate.
as shown in figure the siamese architecture leads to the best auc value .
.
finally precision and recall performances on test dataset are compared in table .
the table shows that the siamese dnn has a recall comparable with the plain dnn but has a better precision .
vs .
.
totally siamese dnn outperforms other models in both precision and recall values.
other than the mentioned differences compared to the plain network the siamese architecture model has around parameters which is less than the plain structure which leads to less training time and less computation burden.
evaluation we compare oreo s detection performance against the latest versions of the four publicly available clone detection tools namely sourcerercc nicad cloneworks and deckard .
we also wanted to include tools such as sebyte kamino jsctracker agec and approaches presented in which claim to detect type clones.
on approaching the authors of these tools we were communicated that the tool implementation of their techniques currently does not exist and with some authors we failed to receive a response.
authors of and said that they do not have implementations for detecting java clones they work either on c or c clones .
as type and type clones are relatively easy to detect we focus primarily on type clone detectors.
the configurations of these tools shown in table are based on our discussions with their developers and also the configurations suggested in .
for oreo we carried out a sensitivity analysis of action filter threshold ranging from to at a step interval of .
we observed a good balance between recall and precision at the threshold.
in the table mit stands for minimum tokens stands for similarity threshold for nicad it is difference threshold and for oreo it is action filter threshold stands for threshold for input partition used in oreo and binandia respectively stand for blind identifier normalization and literal abstraction used in nicad.
.
recall the recall of these tools is measured using big cloneeval which performs clone detection tool evaluation experiments using bigclonebench a benchmark of real clones.
big cloneeval reports recall numbers for type t1 type t2 type andesec fse 4 9 november lake buena vista florida united states vaibhav saini farima farmahinifarahani yadong lu pierre baldi and cristina lopes table recall and precision measurements on bigclonebench toolrecall results precision results tool configuration t1 t2 vst3 st3 mt3 wt3 t4 sample strength based on communications with tool authors or based on oreo .
.
mit sourcerercc .
mit cloneworks .
mit mode aggressive nicad .
mil bin true ia true deckard .
mit stride absolute numbers for deckard are calculated based on the reported percentage values type clones.
for this experiment we consider all clones in bigclonebench that are lines and tokens in length or greater.
this is the standard minimum clone size for measuring recall .
to report numbers for type and type clones the tool further categorizes these types into four subcategories based on the syntactical similarity of the members in the clone pairs as follows i very strongly type vst3 where the similarity is between ii strongly type st3 where the similarity is between iii moderately type mt3 where the similarity is between and iv weakly type type wt3 where the similarity is between .
syntactical similarity is measured by line and by language token after type and type2 normalizations.
table summarizes the recall number for all tools.
the recall numbers are summarized per clone category.
the numbers in the parenthesis next to the category titles show the number of manually tagged clone pairs for that category in the benchmark dataset.
each clone category has two columns under it tilted where we show the recall percentage and where we show the number of manually tagged clones detected for that category by each tool.
the best recall numbers are presented in bold typeface .
we note that we couldn t run deckard on the bigcloneeval as deckard produced more than 400g of clone pairs and bigcloneeval failed to process this huge amount of data.
the recall numbers shown for deckard are taken from sourcerercc s paper where the authors evaluated deckard s recall on bigclonebench.
the total number of clone pairs are not available for deckard and for this reason we calculated them based on the reported percentage values.
as table shows oreo performs better than every other tool on most of the clone categories except for st3 and wt3 t4 categories.
cloneworks performs the best on st3 and deckard performs the best on wt3 t4.
performance of oreo is significantly better than other tools on the harder to detect clone categories like mt3 and wt3 t4 where oreo detects one to two orders of magnitude more clone pairs than sourcerercc cloneworks and nicad.
this is expected as these tools are not designed to detect harder to get clones in the twilight zone.
the recall numbers are very encouraging as they show that beside detecting easier to find clones such as t1 t2 and vst3 oreo has the capability of detecting clones that are hardly detected by other tools.
in future we would like to investigate deeper to understand why oreo did not perform as well as nicad or cloneworks on st3 category.
.
precision in the absence of any standard benchmark to measure precision of clone detectors we compare the precision of these tools manually which is a common practice used in measuring code clone detection tools precision .
methodology .
for each tool we randomly selected clone pairs a statistically significant sample with confidence level and confidence interval from the clone pairs detected by each tool in the recall experiment.
the validation of clones were done by two judges who are also the authors of this paper.
the judges were kept blind from the source of each clone pair.
unlike many classification tasks that require fuzzy human judgment this task required following very strict definitions of what constitutes type1 type type and type clones.
the conflicts in the judgments were resolved by discussions which always ended up in consensus simply by invoking the definitions.
table shows precision results for all tools.
we found that the precision of oreo is .
.
all other tools except deckard performed better than oreo.
deckard s precision is the lowest at .
and nicad s precision is the highest at .
while the precision of oreo is lower than the other three state of the art tools it is important to note that oreo pushes the boundaries of clone detection to the categories where other tools have almost negligible performance.
the recall and precision experiments demonstrate that oreo is an accurate clone detector capable of detecting clones in type type2 type and in the twilight zone.
also note that oreo is trained using the clone pairs produced by sourcerercc.
as sourcerercc does not perform well on harder to detect categories like st3 mt3 and wt3 t4 our current training dataset lacked such examples.
to address this issue in future we will train oreo with an ensemble of state of the art clone detectors.
.
scalability as mentioned before scalability is an important requirement for the design of oreo.
most metrics based clone detectors including the recent machine learning based ones tend to grow quadratically with the size of input which greatly limits the size of dataset to which they can be applied.
we demonstrate the scalability of oreo in two parts.
in the first part we show the impact of the two level input partitioning and action filter on the number of candidates to be processed.
as a reminder reducing the number of candidates early on in the pipeline greatly improves the scalability of clone detection tools.
the second part is a run time performance experiment.
dataset for scalability experiments we are using the entire ijadataset a large inter project java repository containing open source projects million source files 250mloc mined from sourceforge and google code.
only other toolsoreo detection of clones in the twilight zone esec fse 4 9 november lake buena vista florida united states table impact of action filter and input partitioning action filter input partitioning num candidates no filter no partitions on no partitions on sourcerercc and cloneworks have been shown to scale to this dataset.
.
.
number of candidates.
to measure the impact of the action filter and two level input partitioning on the number of candidates we selected random methods as queries from the dataset.
we then executed these queries on our system to see the impact of the action filter and input partitioning on the number of candidates to be sent to the metrics based dnn model.
the threshold for action filter was set to .
also we selected as the number of partitions for input partitioning.
table summarizes the impact.
the top row shows the base line case where each query is paired with every method in the dataset except for itself.
this is the modus operandi of many clone detection tools.
in the second row the action filter s similarity was set to to minimize it s impact however partitions were turned on.
for the results in third row we had kept the action filter on at similarity threshold but we switched off the partitioning.
the bottom row shows the results for number of candidates when both action filter and input partitioning were switched on.
we can see that action filter has a strong impact on reducing the number of candidate pairs.
the partitioning lets us do in memory computations together they both help us achieve high speed and scalability.
.
.
run time and resource demands.
machine and tool configurations we used an intel r xenon r cpu e5 .20ghz machine with cores 256g memory and 500g of solid state disk.
we modified the tool configurations to detect clones source lines of code and we also limited the memory usage of each tool to 12g and disk usage to 100g to simulate the scale experiment conditions as described in .
we did not run this experiment for nicad and deckard as they were previously shown to not scale to this input at the given scale experiment settings.
oreo scaled to this input taking hours and minutes.
sourcerercc took hours and minutes and cloneworks took hour and minutes to detect the clone pairs on this dataset.
the scalability experiment along with the recall and the precision experiments demonstrates that oreo is a scalable clone detector capable of detecting not just easy categories of clone but also in the twilight zone.
manual analysis of semantic clones during the precision study we saw some pairs which were very hard to classify into a specific class.
we also observed some examples where the code snippets had high syntactic similarity but semantically they were implementing different functionality and vice versa.
we saw an interesting pair in which one method s identifiers were written in spanish and the other s in english.
these methods offered very similar but not exactly the same functionality of copying content of a file into another file.
the method writtenlisting clone pair example private void sortbyname int i j string v for i i count i channelitem ch chans v ch.gettag j i while j collator .compare chans .
gettag v chans chans j chans ch public void bubblesort string filenames for int i filenames .
length i i for int j j i j string temp if filenames .
compareto filenames temp filenames filenames filenames filenames temp in english iterated on a collection of files and copied the contents of each file to an output stream.
the method in spanish copied the content of one file to an output stream.
action filter correctly identifies the semantic similarities in terms of the library calls of these methods and later our dnn model correctly recognizes the structural similarity ignoring the language differences.
here we present two examples of clone pairs with semantically similar but syntactically different weak methods.
listing shows one of the classical examples of type clone pairs reported by oreo.
as it can be observed though implemented differently both of these methods aim to do sorting.
the first one implements insertion sort and the second one implements bubble sort .
the action filter finds many common action tokens like three instances of arrayaccess action tokens and instances of arrayaccessbinary action tokens leading to a high semantic match.
please refer section .
for details about arrayaccess and arrayaccessbinary action tokens.
further the trained model finds high structural match as both models have two loops where one is nested inside another first method declares three variables whereas the second declares four.
of course oreo doesn t know that both functions are implementing different sorting algorithms and hence catching a type clone here can be attributed to chance.
nevertheless these two implementations share enough semantic and structural similarities to be classified as a clone pair by oreo.
another example is illustrated in listing where both methods attempt to extract the extension of a file name passed to them.
the functionality implemented by both methods is the same however the second method does an extra check for the presence of in its input string line .
we were not sure whether to classify this example as a wt3 t4 or a mt3 since although some statements are common in both they are placed in different positions.
moreover the syntactic similarity of tokens is also very less as both methods are using different variable names.
these examples very well demonstrate that oreo is capable of detecting semantically similar clone pairs that share very little syntactical information.
other than true positives we found some false positives too.
an example is shown in listing .
action filter captures similar occurrences of tostring andappend action tokensesec fse 4 9 november lake buena vista florida united states vaibhav saini farima farmahinifarahani yadong lu pierre baldi and cristina lopes listing clone pair example public static string getextension final string filename if filename null filename .
trim .
length !
filename .
contains .
return null int pos filename .
lastindexof .
return filename .
substring pos private static string getformatbyname string name if name !
null final int j name.lastindexof .
k name.lastindexof if j k j name.length return name.substring j return null listing false positive example public static string gethexstring byte bytes if bytes null return null stringbuilder hex new stringbuilder bytes .
length for byte b bytes hex.append hex chars .append hex chars return hex.
tostring string sequenceusingfor int start int stop stringbuilder builder new stringbuilder for int i start i stop i if i start builder .append builder .append i return builder .
tostring in both methods and finds a high semantic match.
the dnn model also finds the structures of both of these methods to be very similar as both contain a loop anif statement and both declare same number of variables leading to the false prediction.
having a list of stop words for action tokens that are repeated in many code fragments may help filter out such methods.
related work there are many clone detection techniques usually categorized intotext based token based tree based metrics based and graph based .
these are well known approches to source code clone detection details of these techniques can be be found in .
state of the art up to type clones .
currently nicad sourcerercc and cloneworks are the state of the art in detecting up to type clones.
while both sourcerercc and cloneworks use hybrid of token and index based techniques nicad uses a text based approach involving syntactic pretty printing with flexible code normalization and filtering.
deckard builds characteristic vectors to approximate the structural information in ast of source code and then clusters these vectors.
we provide a comparison of oreo with the detection and scalability of these approaches in section showing that it performs better than all of these for harder to detect clones.
techniques to detect type clones .
gabel et al.
find semantic clones by augmenting deckard with a step for generating vectors for semantic clones.
jiang et al.
proposed a method to detect semantic clones by executing code fragments against random inputs.
both of these techniques have been implemented to detect c clones.
unfortunately precision and recall are not reported so we cannot compare.
machine learning techniques .
white et al.
present an unsupervised deep learning approach to detect clones at method and file levels.
they explored the feasibility of their technique byautomatically learning discriminating features of source code.
they report the precision of their approach to be on files and method level pairs across eight java systems.
however recall is not reported on a standard benchmark like bigclonebench and there is no analysis of scalability.
in wei and li s supervised learning approach a long shortterm memory network is applied to learn representations of code fragments and also to learn the parameters of a hash function such that the hamming distance between the hash codes of clone pairs is very small.
they claim that they tested their approach on bigclonebench and ojclone datasets.
however it is unclear which dataset they have used for training and their technique s scalability is not reported.
sheneamer and kalita s work also uses a supervised learning approach where they use ast and pdg based techniques to generate features.
a model is then trained using both semantic and syntactic features.
our approach differs from theirs in the learning approach they have tried simple and ensemble methods whereas we are using deep learning.
the other difference is that our metrics are different from theirs and we do not use semantic features.
instead we use a semantic filter to filter out candidates that are not semantically similar to the query.
the dataset they used to train and test their model is unclear.
limitations of this study the training and evaluation of models is done only on the methods from open source software projects written in java.
adaptation to other languages is possible but requires careful consideration of the heuristics and the software metrics described here.
theaction filter we propose may not work for small methods that are very simple and neither make a call to other methods nor do they refer to any class properties.
in this study the minimum threshold of tokens removes the simpler methods making action filter work well.
if we decide to pursue clone detection in small methods we will explore the option of adding method names or their derivatives to mitigate this concern.
the clone detection studies are affected by the configuration of the tools .
we mitigate this risk by contacting the authors of different tools and use the configurations suggested by them.
conclusions and future work in this paper we introduced a novel approach for code clone detection.
oreo is a combination of information retrieval machinelearning and metric based approaches.
we introduced a novel action filter and a two level input partitioning strategy which reduces the number of candidates while maintaining good recall.
we also introduced a deep neural network with siamese architecture which can handle the symmetry of its input vector a desired characteristic for clone detection.
we demonstrated that oreo makes the metrics based approaches scalable faster and accurate.
we compared oreo 2we contacted the authors in order to get their tool and execute it on bigclonebench but they did not have a packaged tool available.
they provided us with their source code but it needed a considerable amount of effort to be used.
we were also not provided with their train dataset or their trained model.
under these circumstances we decided not to pursue a comparison of their approach with ours.
3we contacted the authors to get their tool but failed to get any response.
4here too we contacted the authors but did not receive any response.oreo detection of clones in the twilight zone esec fse 4 9 november lake buena vista florida united states with four other state of the art tools on a standard benchmark and demonstrated that oreo is scalable accurate and it significantly pushes the boundaries of clone detection to harder to detect clones in the twilight zone.
in future we will explore the possibilities and impacts of training more models at finer granularities and training using the clones detected by an ensemble of clone detection tools to improve both the recall and the precision of harder to detect semantic clones.