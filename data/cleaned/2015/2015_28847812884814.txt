reliability of run time quality of service evaluation using parametric model checking guoxin su national university of singapore sugx comp.nus.edu.sgdavid s. rosenblum national university of singapore david comp.nus.edu.sggiordano tamburrelli bestseller e commerce giordano.tamburrelli bestseller.com abstract run time quality of service qos assurance is crucial for business critical systems.
complex behavioral performancemetrics pms are useful but often di cult to monitor or measure.
probabilistic model checking especially parametric model checking can support the computation of aggregate functions for a broad range of those pms.
in practice those pms may be defined with parameters determined byrun time data.
in this paper we address the reliability of qos evaluation using parametric model checking.
due to the imprecision with the instantiation of parameters an evalua tion outcome may mislead the judgment about requirementviolations.
based on a general assumption of run time data distribution we present a novel framework that contains light weight statistical inference methods to analyze the re liability of a parametric model checking output with respectto an intuitive criterion.
we also present case studies inwhich we test the stability and accuracy of our inference methods and describe an application of our framework to a cloud server management problem.
ccs concepts mathematics of computing !markov processes multivariate statistics software and its engineering!state systems formal methods keywords data distribution probabilistic model checking quality of service reliability run time evaluation .
introduction with the rise of the service oriented business model e.g.
cloud computing it becomes increasingly important to en sure quality of service qos requirements throughout theperiod of service provision.
one notable example is the service level agreement sla between a service provider permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributedfor profit or commercial advantage and that copies bear this notice and the full cita tion on the first page.
copyrights for components of this work owned by others thanacm must be honored.
abstracting with credit is permitted.
to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
request permissions from permissions acm.org.
icse may austin tx usa c acm.
isbn .
.
.
.
a client which usually defines a set of performance metrics pms and their thresholds in qualitative and quantitative terms.
according to the pm structure pms can be categorized as atomic and composite .
typical examples of atomic pms are link failure delay and utiliza tion which can be determined by direct run time monitor ing.
one common form of pm compositions is the aggre gation of atomic pms over a specific time interval such as average availability maximum response time and top .
another and more complex form is behavioral aggregation such as failure rate in ten consecutive requests and expected time to reach maximum queue size .
extensive research e orts have been dedicated to qos management in the presence of uncertainty e.g.
.
we consider probabilistic model checking as a supporting technique for qos evaluation .
with this formal techniqueof probabilistic verification the model builder can representa broad range of complex behavioral pms as temporal logic formulas which are specified against a probabilistic system model e.g.
discrete time markov chain dtmc .
the structure i.e.
topology of the model is transformed fromthe system specification e.g.
uml activity diagram whereas the quantities in the model can be learned from the run time monitored data or estimated by the domain ex pert .
once the system model is built and the verificationformula is specified the reasoning can be automated andsupported by tools e.g.
prism reducing the manual e ort for evaluating those pms.
not surprisingly there are challenges in leveraging this traditionally design time technique in the run time setting and one problem is e ciency.
due to environmental variability the quantitative parameters in particular transitionprobabilities in the system model need to be repeatedlyevaluated over time.
to ensure the continual satisfaction of qos requirements the verification engine has to be triggered periodically.
standard numerical methods of probabilistic model checking on the other hand are computationintensive.
in view of this parametric model checking as parametric variants of probabilistic model checking isemployed in order to improve the run time e ciency.
with parametric model checking the model builder constructs a parametric dtmc where the parameters represent the undetermined transition probabilities.
the closed form aggregate function of a pm is pre computed and then evaluated promptly at run time after the parameters are instantiated .
prism also supports parametric model checking.
another problem is the influence of parameter instantiation on the quality of qos evaluation.
existing works have ieee acm 38th ieee international conference on software engineering considered the learning of parameters in a dtmc transition matrix from data .
di erent from the learning methods we focus on the e ect of the imprecision with the estimated values on the parametric model checking output namely the evaluation output.
for example to monitor the failure rate xof handling a request we observe nfailures in mrequests in a fixed time frame and estimate xas x n m. because xis usually not the exact value of x there may be a nonnegligible inaccuracy with the evaluation of a pm containingxas a parameter.
hence the analysis of the aforementioned e ect has as least two aspects of significance.
first we can estimate to what extent the evaluation output may misleadthe evaluation of qos assurance.
second the analysis resultcan be used as feedback to adjust the data sampling setup such as sampling time frame and frequency.
in this paper we assume that the sampled data of the parameters are randomly distributed between the numerical values and inclusive.
the joint distribution of thedata is largely unspecified and only subject to a normalization condition which is derived from the identities of those parameters as probabilities.
this results in a general parametric variant of dtmcs associated with random variables which can represent many uncertain markov models studiedin the literature e.g.
.
by treating the aggregatefunction as a transform of random variables we can analyze the reliability of the parametric model checking output with two light weight statistical inference methods.
1more specifically we present an intuitive format to characterize the reliability in the presence of randomized data and infer an approximately normal distribution of all possible outputs.
the output is reliable only if the inferred distribution satisfies the predefined reliability criterion.
based on theseconsiderations we present a novel framework of paramet ric model checking for qos evaluation based on run time data.
we also present case studies in which we conduct a performance test for our statistical inference methods anddescribe an application of our framework to a cloud servermanagement problem.
the remainder of the paper is organized as follows.
section presents the formal model and other definitions.
sec tion presents an example the framework and in particu lar the reliability analysis.
section presents the statisticalinfreference methods.
section presents the two case studies.
section discusses related work.
section concludes the paper.
section presents supplementary definitions.
.
model and definition .
formal model our formal model is built on dtmcs in two steps.
the first step is the parameterization of a dtmc resulting in a parametric markov chain pmc .
the second step is the association of parameters in a pmc with random variables.
tailored for expressing qos properties the dtmc in the following definition encompasses reward functions.
definition .a dtmc with rewards is a tuple m s sini p ri i2 l where sis a finite non empty state space withsini2sbeing aninitial state 1to avoid confusion we stress that our investigated object is the reliability of an evaluation method which is in contrast to reliability as a pm to be evaluated.
p s s!
is a transition probability function such that for each s2s p s forms an exit distribution n a m e l y p t2sp s t for each i2 with being a finite index set a reward function ri s!nassigns a reward ri s to each state s a n d l s!2apassigns a subset of atomic propositions l s apto each state s. a key component of a pmc is the parametric counterpart of a transition probability function in a dtmc.
a sequence or vector of distinct parameters are represented as x x1 ... x m for some mwhere xi6 xjifi6 j.l e t p be a parametrization of presulted from replacing the constant probabilities in specific entries in pwith variables inx.2in other words for each pair s t o fs t a t e si ns either p s t p s t o rp s t x ifor some index isuch that i m. further the occurrences of variables inp are required to satisfy the following three conditions .
for each s s0 t t02s ifp s t then p s t p s t i.e.
not parameterized .
in words only the truly probabilistictransitions can be parameterized.
ifp s t and p s t where t6 t0cannot be parameterized with one variable.
in words di erent entries in the same row of p must contain di erent parameters.
there is a partition ion ... m such that either no variable is contained in the s row of p o ra l l variables in the s row of p constituent xi xi i2i i.e.
a subsequence of x for some i2i.
in words any two rows of p either share no common variable or contain exactly the same sub set of variables.
let x2 m p i2ixi i2i and let ibe a projection of onto i. informally resp.
i is the data space of x resp.
xi .
asxiforms an exit distribution its state space of xiis defined with a normalization condition.
according to the three conditions above for each x2 p is a well defined transition probability function that inherits all and entries with p. definition .ap m cw i t hr e w a r d si sat u p l e m s sini p ri i2 l where p is a parameterization of the probability transition function pand the other components are defined as in definition .
a pmc example is semi formally depicted in figure .
we now associate random variables with parameters.letxbe a random vector i.e.
a vector of random variables x ... x m such that xi6 xjifi6 j. the support of xis or any measurable subset of .
thus pr for each i m.l e t xibe the subvector of xthat correspond to xi.
it is worthwhile to stress that our model has two levels of randomization.
the low level randomization is manifested by the dtmc pmc itself.the high level randomization is manifested by random variables associated with the model parameters.
the generality of our model comes from the largely non specification of the 2we use parameter andvariable interchangeably.
74s0 0s1 0s2 0s5 0s6 s3 0s4 40s8 0s9 0s7 0y1 y2y3 x3w1 w20.
serverunavailable cacheserver httpresponse fileserver toomanyconnectionsproxyserverwebserverapplicationserver cacheserver database .
.
x1x20.
.3z1 z2z3k1 k2 figure http request handling in a web application joint probability mass function pmf or joint probability density function pdf for the random variables.
we mention the following two models studied in the literature which can be represented by our model pmcs associated with bernoulli random variables where the joint pmf of xis defined on x2 m p i2ixi i2i .
interval valued dtmcs where a uniform joint pdf of xis defined on x2 xi2ci i m with each cibeing a sub interval of .
in ci is generalized to be a convex subset of ci.
it is also noteworthy that markov models with uncertain orimprecise probabilities are also extensively studied beyondthe context of probabilistic verification e.g.
.
.
logic and aggregate function we present a logic to formally specify complex behavioral pms.
the logic contains the most useful fragment of pctl which is a preeminent formalism for probabilistic modelchecking and the accumulated reward formulas.
its formal syntax is defined by the following rules p ?
ri ?
xa aua au na a aa a a a where aa 2ap i2 n2n xis the next operator uis the until connective and u nis the until withinn steps connective.
we call p ?
aprobability query formula which informally expresses the query of the probability that is satisfied.
we call ri ?
areward query formula which informally expresses the query of the accumulated reward for reaching states at which ais satisfied.
following the literature let fa uaandf na u na.
anaggregate function fois the semantic interpretation of a query formula j k. for readability we present the formal semantics of our logic and the formal definition of aggre gate functions in the appendix section .
with parametric model checking one can compute the closed form parametric expression of f o which is a rational function defined on o m. it is clear that jp ?
kis bounded on .
but this property does not hold for a reward query formular i ?
in general.
however to simplify the unnecessary technical trickiness we assume that each state in the model satisfying aisreachable almost surely i.e.
with probability from the initial state.
thus jri ?
kis also bounded ontable informal description of pm1 pm5 id informal description pm1 probability of handling a request without accessing the database or file server i.e.
cache hit probability pm2 probability of successfully handling a request pm3 probability of processing a request in four operations pm4 average cost of handling a request pm5 average time of handling a request .l e t fbe the continuous extension of foon .
for convenience we simply mention finstead of foas an aggregate function hereafter.
.
framework and example in this section we present a running example the qos evaluation framework the reliability analysis and the discussion on two practical matters.
.
web application example the running example is a simple web application system consisting of an http proxy server a web server and anapplication server .
to serve client requests the system accesses structured data and static content e.g.
text files and images stored in a database and on a file server respectively.
both types of contents are cached by cache servers.
the process of handling an http request by the web application is presented semi formally in figure .
the states represent the abstract system states.
the transitions between states represent possible evolutions of the system.there are two kinds of quantities in the model which arethe transition probabilities and the rewards.
the transition probabilities may be constant or undetermined.
the former may be determined based on the system specification sim ulation historical data etc.
whereas the latter are atomicpms evaluated based on run time data that are collected asthe system operates.
the rewards represent the cost or the time of visiting the associated states which may be determined based on the simulation knowledge of experts etc.
we assume that the run time data for determining the undetermined transition probabilities are randomly distributed as and where resp.
refers to an occurrence resp.
non occurrence of a transition.
for example the data forestimating x x2 x3 are of the form a1 i a2 i a3 i such that a1 i a2 i a3 i2 anda1 i a2 i a3 i where i nandnis the data size.
we evaluate five pms for the system denoted pm1 pm5 which capture di erent aspects of service level performance in the request processing and which are informally described in table .
.
evaluation framework the main goal of our framework is to formally evaluate complex behavioral pms that are di cult to monitor or evaluate directly and to analyze the reliability of the evaluation output.
figure depicts a flow of the framework when it is in application.
in general our framework contains two phases which are before orafter the system is deployed.
in the following we explain the two phases in detail.
.
.
pre deployment phase the first step in the pre deployment phase is the model building.
the to be evaluated pms called target pms here75 figure framework overview after e.g.
pm1 pm5 for the web application system are usually documented in the informal or semi formal language.with respect to the target pms we determine a suitable ab straction level to represent the system behavior.
the out come of the model building is a semi formal model not a pmc such as the one depicted in figure .
it is noteworthy that a system parameter may be an atomic pm or alow level composite pm that are evaluated independently.
the next step is to formally specify the system model as a pmc and the target pms as formulas in our tempo ral logic presented in section .
.
although a parametricmodel checking tool e.g.
prism may have its own mod eling language and property specification language to the extent that we are concerned with the semantics of the languages agrees with the pmc model and our temporal logic.
the translation of the semi formal model in figure to apmc is immediate.
the specification of pm1 pm5 in ourtemporal logic is presented in the second column of table .
the last step is to run the tool to generate the parametric expression of the aggregate function for each target pm.
the aggregate functions f pm1 fpm5for pm1 pm5 are in the last column of table .
parametric model checking may be costly especially when the model contains many parameter or is highly structural c.f.
section .
.
but an important merit of this technique is the reusability of parametric expressions in the post deployment phase.
.
.
post deployment phase the run time data for determining the model parameters are collected as the system operates.
we assume that thosedata are represented as tuples of non negative numerical values whose sum equals to one.
a more precise formulation of this assumption is presented later in section .
.
a particular case of this assumption for the web system has beenmentioned in section .
.
based on the collected data we derive point estimates of the parameters which are calculated by the standard av eraging method.
for example a mean estimate of x 1in the web system model is1 npn i 1a1 iwhere nis the data size.
after the parameters are instantiated the evaluation outcomes for the target pms are computed using the aggre gate functions.
for example the evaluated value of pm1 isf pm1 x1 y1 y2 z1 z2 where x1 y1 y2 z1and z2are point estimates of the correspondent variables.
because the parameters are elicited by their point estimates the evaluated values for the target pms may be im precise.
therefore the verification of a qos requirement based on the evaluation outcomes may be misleading.
in view of this we further analyze the reliability of the evaluation.
since this last step in the post deployment phase isalso the most important feature of our framework the nextsubsection is dedicated to explaining the reliability analysis.
we mention that the post deployment phase is usually cyclic because as mentioned the evaluation of the target pms is periodically and repeatedly as the system operatesand the environment changes.
.
assumption and reliability analysis ageneral assumption of data distribution in our framework is that the sampled data for the parameters are ran domly distributed on the numerical interval .
this assumption is formalized as the association of xinm w i t h a random vector xranging over in c.f.
section .
.
a particular case of this assumption is that x iis a bernoulli random variable for each i m that is the sample space of xis a subset of m. as an immediate consequence of the general or particular assumption pmevaluation is a ected by the randomness of parameter instantiation.
more precisely given an aggregate function f pre computed by parametric model checking and a sample mean denoted x o fx determined from run time data the evaluation output y f x is also a random variable.
as the absolute accuracy of evaluation is not achievable we turn to consider its reliability.
to characterize reliability suppose we make a judgment about whether the evaluation output ybreaches a specific threshold usually specified in the sla denoted q req.
it is natural to consider the expectation of x which equals to that of x as the unknown true values of the parameters namely xtrue e x e x .
thus ytrue f xtrue is the unknown true value of the pm under consideration.
the potential loss of the aforementioned judgment is related to two factors.
the first factor is the chance of loss col that is the probability that the judgment is incorrect.
symbolically col equals topr y q req i fy true q req o rpr i fy true qreq .
the second factor is the amount of loss aol that is the distance between the true value and the threshold.symbolically aol is represented as y true qreq .
ideally one wishes to minimize both col and aol simultaneously.
however the two factors are mutually dependent on each other.
for example when the sample size is fixed a small aol likely implies a large col and vice versa.
this motivates a format to define a criterion for the trade o of the two factors.
formally let c be a finite set for each a c 2c a criterion clause is defined as follows ifytrue qreq athen pr c ifytrue qreq athen pr c. in words the above propositions assert that if aol is largerthan athen col is smaller than c .
the evaluation is reliable if all clauses in the criterion w.r.t.
c are true.
to determine the criterion satisfaction one possible solution is to employ the probability distribution i.e.
cumu lative distribution function cdf of the possible evalua tion outcomes.
for a c 2c we compute the c percentile a 0and c percentile a00ofyusing the inverse cdf.
the a c clause of the criterion is satisfied if and only if max a0 a00 a. however because the cdf of xis usually not specified the derivation of the inverse cdf of y is impossible.
even if the cdf of xis given thus xtrue is given due to the possibly high nonlinearity of f the derivation of the inverse cdf of yis not practical.
76table probability reward query formulas and aggregate functions for pm1 pm5 id probability reward query formula aggregate function pm1 p ?
fpm1 y2x1 77z1y1 77z2y1 y1 pm2 p ?
fpm2 160w 1y2x1 160w 1y2x2 7k1z1y1 y2x1 77z1y1 77z2y1 w1y2 y1 pm3 p ?
fpm3 y1 y1z3 x1y2 y2x3w1 pm4 rc ?
httpresponse toomanyconnections serverunavailable fpm4 160y 2x1 160y 2x2 z1y1 y1 y2 pm5 rt ?
httpresponse toomanyconnections serverunavailable fpm5 640y 2x1 640y 2x2 z1y1 y2 in view of this our solution is to statistically infer an approximate normal distribution for y. based on two di erent interpretations of our data distribution assumption we present two light weight statistical inference methods.
the interpretations and methods are formally presented later in section .
for now we note that due to the approximationof our inference the absolute correctness of reliability analysis is not guaranteed.
in other words it is possible that the pm evaluation is asserted to be reliable by our analysis butstill leads to a misleading judgment.
however we present anempirical study to demonstrate the stability and accuracyof our analysis later in section .
.
.
practicality discussion in this subsection we reflect on two matters relevant to the practicality of our framework.
first in addition to the assumption on the data distribution our reliability analysis implicitly presumes that the unknown values of the parameters are fixed during the sampling process or equivalently the run time data collection.
the environment variability on the other hand implies the variation of the parameters.
so our reliability analysis is most useful in the situation that the parameters are relatively stable during each time of sam pling.
meanwhile we need to bear in mind that a too widesampling time frame may result in collecting dated data that on longer reflect the current parameter values.
the second matter is the practical significance of the reliability analysis.
in a sense our reliability analysis reveals a statistical relationship between the sample size and theevaluation reliability with respect to given pm thresholds.
if the evaluation is reliable with greater confidence we may accept the outcome.
if the evaluation is unreliable a natu ral subsequent measure is to increase the sampled data size such as widening the sampling time frame or increasing the sampling frequency.
however in practice it is not always a reasonable option to trade data size for high reliability.as mentioned previously a wider time frame may not besuitable to collect timely data.
sometimes even though ahigher sampling frequency is possible it may be a burden on the system performance or may cause extra cost e.g.
energy assumption .
based on these considerations our reliability analysis provides important feedback to rethink thedata size the pm thresholds and one s tolerance on the evaluation reliability.
however a systematic treatment of the trade o between those factors is left for future work.
.
statistical inference in this section we present the two light weight statistical inference methods in our framework.
the former employsthe well known multivariate method to infer an approximate output distribution.
the latter resorts to the first order approximation of the aggregate function to particu larly estimate the variance for the output distribution.
thetwo methods rely on two di erent interpretations of the data distribution assumption but can infer the same result if both interpretations are adopted.
.
assumption interpretations based on our general data distribution assumption on runtime data we associate xin the pmc m with a random vector xranging over on .f o r e a c h i2i the random variables in a random sub vector xirefer to an exit distribution from the same state s in m and thus are dependent but the in dependence between random variables in di erent random sub vectors are not specified.
as a consequence we have two following interpretations of the assumption.
the first interpretation is that xiandxi0are dependent for all i i02i and xis sampled as a single random vector.
the second interpretation is that xiandxi0are independent if i6 i0and are sampled independently.
the first interpretation is more general in theory but the second interpretation is more flexible in practice.
.
multivariate method we view an aggregate function fas a transform of random variables.
our goal is to infer an approximate normal distribution n ytrue y w i t hm e a ny trueand variance y of the following random variable y f x x xi i2i where each xiis the mean of a random sample of xi.
intuitively xiis a mean estimate of the run time data of xi.
based on the first interpretation xis the mean of a random sample of x. the satisfaction of a criterion c immediately follows the normal distribution n ytrue y as shown later.
notice that some variables of fmay be reducible due to the normalization condition.
for example for fpm3in table we can replace x3with x1 x2andz3with z1 z2.
it is clear that this simplification of fdoes not a ect our inference.
let b x f0 x ... f0 m x where f0 i x f x xi i ... k. in words f0 iis the derivative of fon the variable xi.
clearly f0 iis continuous on mfor all i m. if fdoes not contain xi by definition f0 i .
for convenience we use 1 ... m to denote xtrue which is also the expectation vector or mean vector e x 6666666664x1 x1 x1x2 x1x2 x2 x2 y1 y1 y1y2 y1y2 y2 y2 z1 z1 z1z2 z1z2 z2 z2 w1 w1 k1 k1 figure a consistent estimator of the covariance matrix for aggregate functions of pm1 pm5 ofx.
the following proposition contains the statistical concepts convergence in distribution and consistent estimator which can be found in the standard textbooks in statistics e.g.
.
we recall the following theorem inthe multi variate method which is a special case of th.
.
.
.
theorem .letn ibe the sample size of xand be the covariance matrix of x.i fb b t6 then as niincreases the random variable pni y ytrue converges to n b b t in distribution.
let 0be the sample covariance matrix of xbased on the same random sample whose sample mean is x. thus 0is a consistent estimator of .
because xis a consistent estimator of andbis continuous b x is a consistent estimator of b .
according to the above theorem in practice once we draw a concrete sample xsuch that b x 0b x t6 which given the supposition of the theorem is likely so for a large ni we can view yas approximately normally distributed with distribution n ytrue y where y n ib x 0b x t. note that in practice is unknown and so is ytrue which equals to f .
however an important gain of proposition is an approximate normaldistribution n y true y o fy where ycan be estimated.
despite ytrueis unknown we are able to determine whether the criterion cis satisfied.
specifically let a c 2cwhere a is an aol and c is a col. we infer the a percentile denoted c0 o fn ytrue y as the inferred aol and compare c0and cto decide whether a b clause of cis met.
recall that a quantity is the a percentile of a distribution if the probability that the outcome of a random variable with the same distribution is not larger than that quantity is a. if c0 c the a c clause is met.
if all clauses of care met c is satisfied otherwise it is not.
.
first order approximation based on the second interpretation we present an inference method using the first order approximation of fto infer an estimate of the variance ofy denoted var y .
clearly fis di erentiable on .
the first order approximation in the taylor expansion of fis as follows f x g x f xm i xi i f0 i .
for two random variables x x0 l e tcov x x0 denote their covariance .
notice that if xandx0are independent then cov x x0 and that cov x x var x .
proposition .letniis the sample size of xi.
var y x i2ivari y ni where vari y x i j2icov xi xj f0 i f0 j .
proof.
by the linear approximation in equation var y var g x var xk i xi i f0 i by definition xki j 1cov xi xj f0 i f0 j .
by the second interpretation if i2i j2i0andi6 i0 then cov xi xj and so cov xi xj .
a l s o i f i j2i then cov xi xj ni cov xi xj where niis the sample size.
the proposition follows.
proposition .for each i2i a sniincreases i x i j2icov xi xj f0 i x f0 j x converges to vari y in distribution.
proof.
for each i2i andi j2i a s niincreases f0 i x and f0 j x converge to f0 i and f0 j respectively and thus f0 i x f0 j x converges to f0 i f0 j .
the proposition follows immediately.
by propositions and niis an estimator of vari y for each i2i.
therefore the following quantity is an approximation of var y y x i2i i ni.
to determine whether the criterion cis satisfied we resort to the distribution of y. according to the central limit theorem each xiinxis approximately normally distributed.
the second interpretation says that xiis independent of other random samples in x. since gis a linear transform of x g x is approximately normal distributed.
therefore it is reasonable to assume that yis approximately normally distributed and has the distribution n ytrue y .
then the determination of the satisfaction of cbyn ytrue y is the same as in the previous inference method.
.
example of sample covariance the above two methods are based on two interpretations of the data distribution assumption.
in others words the two methods have di erent primitives and thus are incompatible.
but clearly both of them make use of the derivatives of the aggregate function the sample mean vector and the sample variance.
in particular the two methods are consis tent in the sense that the same result can be inferred fromthem if both interpretations are adopted.
to reveal this we present a sample covariance example in figure for our web application example as follows.
78let idenote an arbitrary variable in fpm1 fpm5 where ranges over x y z w k andi depending on ranges over some subset of .a l s o l e t x ibe a random variable corresponding to i. based on our particular assumption on the run time data for the web system i i resp.
i j is a consistent estimator of the variance var x i resp.
covariance cov x i x j .
thus a consistent estimator of the covariance matrix for fpm1 fpm5is the symbolic matrix in figure .
it is easy to verify y ywhere fis any one offpm1 fpm5.
.
computational overhead we discuss the computational overhead that our reliability analysis adds to standard parametric model checking applied to data driven qos evaluation.
the two inference methods are dependent on the derivatives of the aggregate function and the covariance sample matrix.
the former are pre computed and the latter is inferred at runtime.
therefore the computational overhead consists of a pre computation overhead and a run time overhead.
for the pre computational overhead clearly the number of thederivatives is the number of the variables in the aggregatefunction.
as the aggregate function is a rational function and in many cases also a polynomial function e.g.
f pm1 fpm5 the derivation of the derivatives is simple.
for the run time overhead compared with the complexity of computing the sample mean vector i.e.
o ni m where ni is the sample size and mis the number of variables the complexity of computing the sample covariance matrix iso n i m2 .
if all random variables in xare bernoulli random variables after the sample mean vector is computed the complexity upper bound for computing the sample covariance matrix is o m and regardless of the sample size n because the covariance of two bernoulli random variables can be calculated based on their means .
moreover the previous complexity upper bounds are true for both methods but if the second interpretation is adopted the sample covariance matrix may be sparse as observed from figure .
.
case studies in this section we present two case studies.
in the first case study we test the stability andaccuracy of our statistical inference methods for reliability analysis.
in the secondcase study we describe an application of our framework to a cloud server management problem from which we also learn lessons for our future work.
.
performance of inference methods .
.
experimental method and setup we analyze the evaluation reliability for pm1 pm5 for the web application example.
the tools that we employ areprism and matlab.
in particular we simulate the run time data collection for variables in f pm1 fpm5 using random sampling from independent multi dimensional bernoulli dis tributions in matlab.
to this end we select the following representative values for the parameters x .
x .
y .
y .
z1 .
z .
w .
k .
.
these numerical values are directly taken from a previous paper .
we emphasize that our statistical inference meth ods are independent of the selected parameter values.
more over as mentioned even if the parameter values are given due to the nonlinearity of the aggregate functions the true pm values still cannot be computed directly.
for simplicity we generate the same size samples for all parameters and thus both methods are applicable and infer the sameresults.
hence in the sequel we simply mention the inference without indicating the underlying method.
in practice for a given pm and a pair a c 2c we infer an aol called an inferred aol which is distinguished from the exact aol from a specified col c. we then compare the inferred aol and the specified aol a. but for testing purposes our experimental method is as follows instead of dealing with a particular reliability criterion we consider thestability and accuracy of the inference.
to test the stability we generate a population of the inferred aol called population a and derive some common statistical metrics e.g.
median max and min .
to test the accuracy sincethe exact aol i.e the ground truth is di cult to obtain we compare our inference with the monte carlo mc simulation.
specifically we generate a population of evaluated pm values called population b by repeating the computa tion.
we compare the inferred aol with an mc simulated aol derived based on population b. we test the stability and accuracy of the inference with respect to a selection of sample sizes and a selection of col values.
this results in two tests called test i and test ii.
in both tests we set the size of population a as and thesize of population b as because a relatively small population is su cient to test the stability of the inferred aol and a relatively large population can ensure high accuracy of the mc simulated aol against which we comparethe inferred aol.
the machine we used is an ms windows7 desktop with .4ghz cpu and 16gb ram.
the sourcecode is available on the first author s web site.
.
.
experimental data and discussion table summarizes the experimental data in test i with a selection of sample sizes between and and with a fixed col value .
.
the experimental data sug gest that no absolute correctness can be ensured.
in other words the reliability analysis may be misleading with an elaborately defined reliability criterion.
however those dataalso demonstrate that in general our methods can both sta bly and accurately infer whether the predefined reliability criterion is met for all selected sample sizes.
moreover as the sample size increases the stability and accuracy of ourinference are improved.
this is consistent with the follow ing intuition if a larger set of run time data is collected the quality of both the pm evaluation and the reliability analysis is better.
in particular the worst performance is manifested in pm2.
one reason is the number of variables in the ag gregate function f pm2.a s w e s e e fpm2has eight variables while other aggregate functions have at most five.
another reason is that the selection of relatively extreme values for variables z2 k1 w1which are all contained in fpm2.
for test ii due to space limitations we only present the experimental data for pm2.
the box plots and x markersrepresent the inferred aol and the mc simulated aol respectively.
the decreasing trends of box plots and x markers are consistent with the following intuition behind the trade o between aol and col if the sample size is fixed then sugx icse16 79table inferred aol and mc simulated aol with di erent sample size and a fixed col for pm1 pm5 idstatistics of sample size order of population a b magnitude pm1median a .
.
.
.
.
.
a .
.
.
.
.
.
.
.
.
.
.
.
max min a .
.
.
.
.
.
.
.
.
.
.
.
mc b .
.
.
.
.
.
pm2median a .
.
.
.
.
.
a .
.
.
.
.
.
.
.
.
.
.
.
max min a .
.
.
.
.
.
.
.
.
.
.
.
mc b .
.
.
.
.
.
pm3median a .
.
.
.
.
.
a .
.
.
.
.
.
.
.
.
.
.
.
max min a .
.
.
.
.
.
.
.
.
.
.
.
mc b .
.
.
.
.
.
pm4median a .
.
.
.
.
.
a .
.
.
.
.
.
.
.
.
.
.
.
max min a .
.
.
.
.
.
.
.
.
.
.
.
mc b .
.
.
.
.
.
pm5median a .
.
.
.
.
.
a .
.
.
.
.
.
.
.
.
.
.
.
max min a .
.
.
.
.
.
.
.
.
.
.
.
mc b .
.
.
.
.
.
.
.
.
.
.
.6x .
.
.
.
.
.
colinferred aol mc simulated aol figure inferred aol and mc simulated aol with di erent col and fixed sample size for pm2 a small aol resp.
col implies a large col resp.
aol .
the leftmost box plot and x marker in the figure correspond to the entry in the column of sample size for pm2in table .
another important indication is that the box plots demonstrate increasing stability and accuracy as the specified col increases from .
to .
.
the reason is that the possible evaluated values for pm2 and other pmsalike have an approximate normal distribution.
so as colis further away from the end points and i.e.
closerto it is less sensitive to aol.
this trend implies that the inferred aol in test i will be more stable and accurate for other values of col selected in this test.
we clarify two questions relevant to the significance of our performance test.
the first question is what is implied from the tests.
even though the experimental data in tests i and ii manifest increasing analysis quality with increas ing sample size we emphasize that a sample as large aspossible is notalways applicable because as mentioned in section .
the resizing of samples need to take otherpractical factors e.g.
timeliness of data and sampling cost into consideration.
hence our test results can provide useful feedback for the sample resizing.
the second question is how representative the tests are.
in particular the matlab simulation of the run time data collection uses multi dimensional bernoulli distributions which are consistent with our particular data distribution assumption for the example.
an immediate question is what ifgeneral data distributions are used for sampling .
the dis tribution of the possible evaluated values for pm1 pm5 is clearly relevant to the variances of the associated random variables of the parameters.
in an extreme and perhaps unrealistic case that all those random variables have zero variance and thus the only sampled value for each randomvariable is its mean the qos evaluation is absolutely stable and accurate.
this suggests that if the means are fixed and the variances get smaller the stability and accuracy of theinferred aol shall be improved.
in this sense the bernoullidistributions stand for the worst case .
.
application in server management .
.
problem description in an infrastructure as a service iaas cloud the job requests are processed by virtual machines vm deployed in the physical servers called servers hereafter .
to achieve the most cost e ective usage of servers e.g.
cpu ram and disk usage one usual strategy is to group the serversin di erent pools such as a working pool and a backup pool.
servers in the working pool are running.
the pre deployedvm instances in the running servers are ready to processjobs.
servers in the backup pool are standby or turned o .
the vm instances in the standby servers have to be instan tiated from the pre built images.
a further delay may be required to reboot the turned o servers.
80dtmc const int fixq fixq const double x probability parameter module queue s normal f a i l u r e q init s q fixq q x q q x q q s q fixq s q q s s to avoid deadlock endmodule rewards true assigning a reward of to every state of the model endrewards figure prism model of a job queue an important problem in server pool management is how to e ectively decide the number of working standby servers with respect to some pms measuring the service delay.
in many cases those pms contain parameters that are determined by the run time data collected by the cloud.
in the following we demonstrate how to evaluate a typical example of those pms how to analyze the reliability of the evaluation in our framework and the lessons that we learn.
.
.
evaluation and analysis for simplicity we do not consider sophisticated scheduling algorithms but assume that the arrived job requests joina fifo queue before being assigned to an available vminstance.
thus the queue size is an important indicator of the service delay.
we consider the mean time of reaching a prescribed queue size.
in the discrete time setting we represent the mean time by the expected transition number etn .
thus we specify an etn requirement as follows the etn to reach a queue size fixq is smaller than n q. to verify the above requirement we specify a prism pmc model for the job queue as figure and translate theformula r ?
to the prism property language.
the pmc is an embedded discrete time model of an m m queue.
the model parameter xis determined by the rates of job arrivals and job completions which are monitored by the cloud.
for any legal value of fixq in principle prism can compute the parametric expression of an aggregate functionfq j qk.
ifnjob arrivals and mjob completions are observed in a prescribed time frame then qmst fq r is returned where r n m n. ifqmst n q a requirement violation is reported.
letqtruedenote the exact etn value when it is evaluated .
to analyze the verification reliability suppose a predefined reliability criterion contains the following clause ifqtrue nq a then the probability that the computation returns qmst n qis smaller than c where a and c .
as explained in section .
the criterion expresses an intuitive constraint on the trade o between aol and col. if xis bernoulli distributed our framework infers an approximate normal distribution of the possibleevaluated etn with the variance f q r r r m n where f0 qis the derivative of fq.
following the procedure described in section we can determine whether the crite rion clause is true or not.
.
.
lessons learned although the above description demonstrates the applicability of our framework for qos evaluation involving run time data from the case study we also learn three lessonswhich motivate further research.
the first two lessons pro vide feedback to reflect on our parametrization of dtmcs but not our association of model parameters with random variables .
the third lesson is on the computational com plexity of parametric model checking.
first in order to manage the server pool we not only need to verify the etn requirement with respect to the currentset of working servers but also need to recommend a suitablenumber of working servers.
suppose the current number of working servers is iand we want to decrease the number to j i the increase case is similar and not discussed here .
the parametric expression of f qno longer indicates the desirable probability result for the new set of working servers.
however assuming all servers are identical the new enqueu ing probability is y i x j i j x .
replacing xwith yin figure we can compute a new aggregate function.
however di erent from x the new parameter yis composite and cannot be sampled directly.
this mismatch provides anopportunity to reflect on our pmc definition.
second for convenience we have used the etn to represent the mean time but the actual service delay is alsodependent on the job processing time.
it seems that onecan extend the model specification in figure by associat ing some states with a time value which may be di erent from .
however considering the possible heterogeneity ofthe jobs it is more reasonable to observe the job processingtime rather than to fix them as constants.
this again pro vides an opportunity to reflect on our pmc model definition in which only transition probabilities can be parameterized.
third the structural complexity of aggregate functions a ects not only the pre computation but also the run time function valuation and statistical inference.
the structuralcomplexity is clearly related to the number of variables contained in the aggregate function.
but from this case study we learn that even if the aggregate function is single variate it may be highly structural.
in particular as fixq increases the expressions of f qand its derivative become increasingly complex.
in this case the pre computation of a highly complex fqis extremely costly and the run time valuation of fqis ine cient because too many arithmetic operations are involved.
a possible solution is to employ an approximate or bounding expression rather than the exact closed form expression for the aggregate function which is much less complex but still meet sour stability and accuracy requirement on the inference results.
.
related work there is extensive literature on formal specification of and reasoning about qos properties of software systems e.g.
.
calinescu et al.
presented a systematicand comprehensive framework qosmos based on probabilistic model checking for qos management and optimization for service based systems.
qosmos integrates a suiteof tools that support all four run time stages in system self adaptation namely monitoring analyzing planning and ex4if the servers are di erent we need to estimate the reduced capacity of job processing based on the hardware specification maximum deployment numbers of vms etc.
81ecuting mape .
ghezzi et al.
proposed a model driven framework adam to aid the adaptation to non functional manifestations of uncertainty.
adam consists of a generator which generates a probabilistic model from the uml activity diagram and an interpreter which searches for an execution path in the model that satisfy the non functionalrequirements.
parametric model checking was introduced by daws with a state elimination algorithm which is a symbolic com putational method di erent from the numerical computational method used in probabilistic model checking.
in his pmc model parameters are presented as general rational functions including individual variables .
hahn et al.
improved and extended daws s method to cope with the ver ification of pmcs with parametric rewards and parametricmarkov decision processes mdps .
filieri et al.
described a run time quantitative verification technique to support the analyzing stage in the system self adaptation.
theirparametric model checking is underpinned by the gaussjordan elimination method.
they also use the derivatives of the parametric functions for sensitivity analysis.
moreover they presented an experiment to demonstrate an improvede ciency in the run time computation using their method compared with probabilistic model checking.
it is clear thatthe pre computation of aggregate functions in our framework is based on these literature.
we also can extend our parameterization of dtmcs based on daws s work .
calinescu et al.
proposed the framework fact which is the first approach that supports the formal verification of dtmcs that exploits confidence intervals.
both of our framework and fact characterize the uncertain model pa rameters by random variables and complement parametricmodel checking with the statistical inference.
but the dif ference is two fold.
first the data distribution assumption for the sampled data in our framework in more general than that in fact in which run time data must be representedas either or .
second we treat aggregate functions astransforms of random variables and infer approximate distributions for the possible evaluation outcomes while fact deals with the propagation of the confidence on the evalua tion output from the confidence on the parameter sampling.
because of the general data distribution assumption our statistical inference methods are applicable to the intervaland convex valued dtmcs studied in the literature .
mdps with uncertain probabilities are investigated inthe literature in ai and robust control .
also there are bayesian methods for learning parameters in a pmc from the historical data .
these parameter learning methods are complementary to our framework whichemploys simple point estimates for sample means and sam ple covariances of the parameters.
finally we mention thesimulation based approaches to probabilistic verification .
in those approaches the parameter sampling results in a set of paths of the markov model.
this is in sharp contrastto our data distribution assumption and that in fact.
.
conclusions we have presented a framework for qos evaluation involving the sampled data.
our framework is built on parametricmodel checking and is suitable for evaluating complex be havioral pms.
assuming the sampled data are randomly distributed our framework contains two light weight statistical inference methods to analyze the reliability of theevaluation output against an intuitive criterion.
therefore our work improves the applicability of standard parametricmodel checking.
for future work we will extend our framework to address the three problems explained in section .
.
.
we also planto systematize the use of the reliability analysis result asfeedback for reseting the sample size.
lastly we plan toenhance the parameter estimation with a learning method.
.
appendix complete definition for completeness we present all required definitions in section .
.
a path inm is an infinite sequence of states s0s1...such that for any x2 o p s i si .
we denote siin as .
for any s2s l e tpath s denote the set of paths inm such that s. a probability measure pronpath s is defined in the standard way c.f.
baier and katoen .
sisreachable almost surely from the initial state sini i fpr 2path sini sfor some n .
we now present the semantics of l. for the propositionlogic formula a the semantic relation s m a read as ais satisfied at state sinm is standard.
the semantic relation m for every oflis defined as follows .
m xai m a. m aua0i 9n 0s .
t .
m a0 m a j n .
m au na0i n0 ns.t.
m a0 m a j n0.
letri a pn i 0ri si where nis the least number such that sn m a if it exists.
if such ndoes not exist then let ri a .g i v e n s2s jp ?
ksand jri ?
ksare functions defined as follows.
jp ?
ks o!
such that 8x2 o jp ?
ks x pr 2path s m jri ?
ks o!r such that 8x2 o jri ?
ks x p1 i 0pr 2path s i ri a ifri a 2path s 1otherwise.
ifs sini we write jp ?
kand jri ?
kfor short.
an aggregate function fofor under pmc m i sj k. the possibility that jri ?
kis unbounded on ocauses unnecessary technical trickiness.
to avoid that for a given ri ?
we assume that each state s2ssuch that s m ais reachable almost surely from sini.
as a consequence it can be shown that jri ?
kis bounded in o.a s fois a bounded rational function focan be continuously extended to a function fthat defined on .
.
acknowledgement this work was partially supported by singapore ministry of education under grants r and moe2015t2 .
we thank the anonymous reviewers for their constructive comments on an earlier version of the paper.
.