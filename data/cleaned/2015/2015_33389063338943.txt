on usingmachine learningto identify knowledgein api reference documentation davide fucci universityof hamburg hamburg germany fucci informatik.uni hamburg.dealireza mollaalizadehbahnemiri universityof hamburg hamburg germany alirezam.alizadeh gmail.comwalidmaalej universityof hamburg hamburg germany maalej informatik.uni hamburg.de abstract usingapireferencedocumentationlikejavadocisanintegralpart ofsoftwaredevelopment.previousresearchintroducedagrounded taxonomythatorganizesapidocumentationknowledgein12types including knowledge about the functionality structure andqualityof an api.
we study how well modern text classification approachescanautomaticallyidentifydocumentationcontainingspecific knowledge types.wecompared conventionalmachine learning k nn and svm with deep learning approaches trained on manually annotated java and .net api documentation n .
whenclassifyingtheknowledgetypesindividually i.e.
multiple binaryclassifiers thebestauprcwasupto87 .thedeeplearning andsvmclassifiersseemcomplementary.forfourknowledgetypes concept control pattern andnon information svmclearly outperforms deep learning which on the other hand is more accurate for identifying the remaining types.
when considering multiple knowledge types at once i.e.
multi label classification deep learningoutperformsna vebaselinesandtraditionalmachinelearning achieving a macroauc up to .
we also compared classifiers usingembeddingspre trainedongenerictextcorporaandstackoverflow but did not observe significant improvements.
finally toassessthegeneralizabilityoftheclassifiers were testedthem ona different unseen pythondocumentationdataset.
classifiers forfunctionality concept purpose pattern anddirective seemto generalizefromjavaand.nettopythondocumentation.wediscuss our results and how they inform the development of tools for supportingdevelopers sharingandaccessingapi knowledge.
ccs concepts software andits engineering documentation .
keywords api documentation information needs machine learning permissionto make digitalor hard copies of allorpart ofthis work for personalor classroom use is granted without fee provided that copies are not made or distributed forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation on the first page.
copyrights for components of this work owned by others than acm mustbehonored.abstractingwithcreditispermitted.tocopyotherwise orrepublish topostonserversortoredistributetolists requirespriorspecificpermissionand ora fee.
request permissions from permissions acm.org.
esec fse august 26 30 tallinn estonia associationfor computing machinery.
acm isbn ... .
format davide fucci alireza mollaalizadehbahnemiri and walid maalej.
.
on usingmachinelearningtoidentifyknowledgeinapireferencedocumentation.
in proceedings of the 27th acm joint european software engineeringconferenceandsymposiumonthefoundationsofsoftwareengineering esec fse august 26 30 tallinn estonia.
acm new york ny usa 11pages.
introduction softwaredevelopersreuselibrariesandframeworksthroughapplicationprogramminginterfaces apis .theyoftenrelyonreference documentation to identify which api elements are relevant for the task at hand or how the api can be instantiated configured andcombined .comparedto otherknowledgesources suchas tutorialsandq aportals referencedocumentationlikejavadoc and pydoc are considered the official api technical documentation.
they provide detailed and fundamental information about api elements components operations andstructures .
as api documentation can be thousands of pages long accessing specific knowledge therein can be tedious and timeconsuming .theinformationnecessarytoaccomplishataskcan be scatteredacross thedocumentationpages ofmultipleelements such asclasses methods and properties.
thus developers try to useothersourcestofulfilltheirinformationneeds .forexample althoughthejavadevelopment kit jdk apidocumentation contains more than pages as of early there are more than3million stackoverflowposts taggedas java.
overthelastdecade softwareengineeringresearchersstudied whatinformationdevelopersneedwhenconsultingapidocumentation .onelineofresearchfocusesonmatchinginformation needs with the types of knowledge available in the documentation.
maalejandrobillard tookafirststepinthisdirectionbydevelopinganempirically validatedtaxonomyof12knowledgetypesfound within api reference documentation.
a single documentation page canincludeseveralknowledgetypes figure .functionality and directive are particular types of knowledge needed to accomplish a developmenttask whereasthe non information typecontainsonly uninformative boilerplate text .
maalej and robillard argue that their knowledge categorization allows for a understanding and improving the documentation quality and b satisfying developers information needs .
theresearchcommunitystudiedspecificknowledgetypesinapi referencedocumentation.forexample montperrusetal.
and seid etal.
studied directive to prevent the violation ofapi usage constraints.
robillard and chhetri filtered non information whenrecommendingapistodevelopers.automatedapproaches esec fse august tallinn estonia davidefucci alireza mollaalizadehbahnemiri andwalidmaalej directive figure a reference documentation page in the jdk api annotated with theknowledgetypesitcontains.
suggested so far are based either on linguistic features engineering oronsyntactic patterns .
thisworkinvestigateshowwellmoderntextclassificationapproachescanautomaticallyidentifytheknowledgetypessuggested by maalej and robillard in api documentation.
based on a dataset of labelled java and .net documentation we trained tested andcomparedconventionalmachinelearningapproaches i.e.
knearestneighbors k nn andsupportvectormachines svm as well as deep learning approaches i.e.
recurrent neural network rnn with a long short term memory lstm layer.
the rnn learns features from a semantic representation of general purpose text i.e.
embeddings .hence westudiedhowourresultsareimpactedbytrainingthenetworkusingsoftwaredevelopment specific corporafromstackoverflowasopposedtoageneralpurposeone.
finally westudiedthegeneralizabilityoftheclassifierstoanunseen dataset obtainedfrom the pythonstandardlibrary.
thispapermakesthreecontributions.first wepresentadetailed classification benchmark for api documentation.
the settings include different machine learning approaches and configurations different word embeddings different datasets for different apis as well as various evaluation metrics.
second as we share the code anddataofthisstudy 1severaltop performingclassifiers e.g.
auprc alreadyhavepracticalrelevance.third ourfindings and discussion of related work provide insights to researchers tool vendors and practitioners on how machine learning can help better organize access and share api knowledge e.g.
through tagging the documentation pages with the knowledge types.
while currentkeywords basedsearchescanhelpdevelopers e.g.
findthe documentationpageforamethod theycannotanswerquestions relatedtospecificinformationneeds e.g.infigure whathappensifipassa nullvaluetothe addpropertychangelistener ?.a developerisrequiredtoreadtheentirepage whichmayormaynot contain the answer to these questions.
machine learning classifiers canhelpnavigatingthedocumentationnotonlythroughkeywords can use the classifiers results to identify gaps of information needsintheirdocumentation.
therestofthepaperisorganizedasfollows.section 2describes ourresearchsettings section 3presentstheconfigurationsofthe classifiers and section 4reports their performance.
we discuss related work in section 5and the implications and limitations of our results insection .finally section 7concludes the paper.
research settings this section introduces the research questions method anddata.
.
research questionsandmethod maalej and robillard proposed an empirically validated taxonomy of knowledge types based on grounded theory and systematic content analysis experienced coders person hours effort .
table 1lists these knowledge types which represent the basisforthiswork.ourprimarygoalistostudyhowwellsimple machine learning for text classification without additional feature engineeringoradvancednaturallanguageprocessing nlp techniques can identify these knowledge types.
that is our classifiers label adocument withone ormore knowledge types.
table twelve knowledge types included in reference documentation adapted frommaalej and robillard .
knowledgetype brief description functionality describes the capabilities of the api and whathappenswhenitisused.
concept explains terms used to describe the api behavior or theapi implementation.
directive describe what the user is allowed not allowed todowith theapi.
purpose explainstherationaleforprovidingtheapi or for a design decision.
quality describesnon functionalattributesofthe api including itsimplementation.
control describeshowtheapimanagesthecontrolflow and sequence ofcalls.
structure describestheinternalorganizationofapi elementsincluding theirrelationships.
pattern explains how to get specific results using theapi.
example providesexamples abouttheapi usage.
environment describes theapi usageenvironment.
reference pointerstoexternal documents.
non information uninformative boilerplate text.
westudytwomaintextclassificationapproachesinthispaper.
traditional approaches usually learn the classes from the occurrencesofcertainkeywordsorphrasesinthetrainingset.computational intensive approaches often referred to as deep learning usethesemanticsofthekeywords i.e.
thecontextofthekeyword occurrences .
for traditional approaches we study two algorithms frequently used for text classification k nn and svm.
for deep learning weusedrnnwithanlstmlayer whichisparticularlyeffective for text categorization problems .
this architecture is recommendedover forexample convolutionalneuralnetwork cnn .
while the latter is more suited for image recognition rnn 110on usingmachinelearning to identifyknowledgein apireference documentation esec fse august tallinn estonia with lstm handles more efficiently the dependencies between features .
we alsocompare theseclassifiers to na ve baselines.
thetasktackledinthisstudyistoassignknowledgetypestoan apidocument.asthedocumentcancontainmorethanoneknowledgetype thistaskis modelled asamultiplebinary classification problem consisting of independently train one binary classifier for each knowledge type.
another approach is to train a multi label classifier i.e.
a classifier that outputs a set of knowledge types ratherthanasingleone.weanalyzeandreporttheresultsforboth approacheswhen answeringthe following researchquestion.
rq1.
how well can text based classifiers identify knowledge typesinapireferencedocumentation?inparticular candeep learningimprove over traditional approaches?
for text classification tasks the input layer of an rnn usually consistsofembeddingstrainedonlargeunlabeled textual corpora necessary to capture rich semanticfeatures .
pre trainedembeddings are available and caneasilybe plugged in the network withoutfurthereffort.however whiletheseembeddingssavecomputationaltimeandwellrepresentcommonlanguagetasks they can miss software engineering or api specific semantics.
this motivates our secondresearchquestion.
rq2.
do software development specific text embeddings improveclassificationresultscomparedtogeneralpurposeones?
finally a common question for machine learning evaluation is whetheramodeltrainedonacertaindatasetgeneralizestoother data.theoriginaldataset includesdocumentationofthestandard javaand.netlibraries .sinceweaimtoassessthegeneralizability of our approach to api reference documentation written in a differentstyle wemanuallyannotatedanewdatasetsampledfrom thedocumentationofpythonstandardlibrary.weusedthisdataset as an additionaltest setto report our classifiers performance.
rq3.
can documentation classification based on knowledge types be generalizedacrossapis?
weassessmodelsbasedon10 foldcross validationusing10 of thedatasetastestset.whencomparingindividualknowledgetypes classifiers we report area under precision recall curve auprc .
precision recallcurvesareacommonmetrictoevaluatebinaryclassificationandareobtainedbyplottingprecisionandrecallvaluesat differentprobabilitiesthresholds .inparticular theyareused to evaluate machine learning model trained on imbalanced data sets .therefore auprcisasummarymeasureofperformance irrespective ofaparticularthreshold.
whencomparingclassifiersformultipleknowledgetypes wereportperformanceaccordingtotwotypesofmetrics item basedand label based.theitem basedmetricsarea hammingloss namely theratioofwronglyclassifiedlabelstothetotalnumberoflabels its bestvalueiszero andb subsetaccuracy namelythepercentage ofexact matches between the predictedandthe actual labelset.the label based metrics are precision recall f1 measure formula1 andarea underreceivingoperator curve auc .
f1 truepositives truepositives falsepositives falsene atives the receiving operator curve is created by plotting recall against false positive rate fpr equation at different probability thresholds.
accordingly auc does not depend on a particular threshold .tocalculatethevalueoftruepositive falsepositives and falsenegatives we used0.
as probability threshold .
fpr truene atives truene atives falsepositives thelabel basedmetricsaremacro averaged.macro averaging applies the metric to the binary partition of each predicted label andthenaveragestheresults i.e.
labelshaveequalcontributionin the final result.
in contrast micro averaging first aggregates the individualmetriccomponents i.e.
truepositives falsepositives true negatives andfalsenegatives ofeachlabelandthenaveragesthem.
therefore micro averagingisbiasedtowardthemajorityclasses andshould be avoidedwhen evaluating unbalanceddatasets .
wecomparetheresultsoftheclassifierstona vebaselines mf1 mf2 andrand.thefirsttwoalwaysassignthefirst respectively oneofthefirsttwo most frequentlabelstoeachdocument whereas the latter assignsarandom label.
table overview ofthe cadodataset.
documents wordsmax.
wordsmean vocab.size .net jdk total .
research data we use the cadodatasetcreated by maalej and robillard as the result of their content analysis of the jdk and .net .
apireferencedocumentation.
cadocontains5 574observations.
the columns include the name of the api element e.g.
a class a method or a property its documentation text and binary values indicating the presence or absence of the corresponding knowledge type.
table 2summarizes the dataset textual properties.
themostfrequentknowledgetypesare functionality andnoninformation whereas qualityandenvironment are the least frequent.wedidnotmergesomeoftheknowledgetypesasmaalejand robillardreportednosignificantevidenceoftheirco occurence .
the majority of the documents .
contains one to five of the knowledge types.
we use the scumble score toreportthelevelofunbalancedness.foragivenlabel ahigh scumble score represents a large difference between the frequenciesofalltheotherco occurringlabels.ingeneral datasetswith highscoresareproblematicforclassificationtasks .however for datasets characterized by low scumble score resampling can reduce unbalancedness .cadomeanscumble score is0.
.
we applied random under and over sampling to of the dataset i.e.
the training set .
we did not resample the test set of the dataset to avoid sampling bias.
for resampling we removed 111esec fse august tallinn estonia davidefucci alireza mollaalizadehbahnemiri andwalidmaalej ofthedocumentscontaining functionality andnon information intheirlabelsetandduplicated50 ofthedocumentscontaining environment andquality.thethresholdswereobtainedempirically basedonthe scumble score.afterresampling thetrainingand testsetscontain3 876and430observationsrespectively.figure presents the label frequencies in the dataset we used to train the models after re sampling.
we prepareda new python datasetconsistingof 100apidocumentation pages i.e.
modules types attributes and methods from the python .
standard library.2we selected the python standard library since its code is organized differently than java or.netasitmakesextensiveuseofmodulesinwhichfunctions classes and variables are defined.
the python programmingparadigmis more functionalthan javaand .net which instead follow an object oriented paradigm.python is dynamically typed and its referencedocumentationtendstofocusonfunctions whereastypes documentationisembeddableinthesourcecode e.g.
throughdocstrings .
finally its development and documentation are driven by an open source non profit community the python software foundation whereas java and.netare ownedbycorporations.
we followed the sampling strategy suggested by maalej and robillard i.e.
stratified random sampling.
we first created strata for each of the base modules and then randomly sampled api documentation from each stratum proportionally to their frequencies.
twoph.d.studentsinsoftwareengineering accustomedtowork withpython manuallylabelledtheknowledgetypesineachdocument.forthistask weprovidedthemthesameguidelinesfrom maalej and robillard3with small adaptations such as providing examplesusingthepythonprogramminglanguage.theagreement on the label set was i.e.
out of the examples were labeled with the exact same set of knowledge types.
the overall agreement was i.e.
of the labels examples labels were conflicting.
two of the authors addressed the conflicts and created the final dataset.
figure 3shows the distribution of knowledge types in the pythondataset.functionality is the majority label.
pythonrepresents an additional test set i.e.
no figure knowledgetypesin cadoafter resampling.
figure knowledgetypesinthe python dataset.
examples from this dataset are used to train the classifiers which we didnot resample to avoid biasedresults.
for both datasets we performed several simple operations to clean and prepare the textual data.
we lower cased tokenized and applied stop words removal to the api documentation text.
then we transformedterms in an order preserving one hot vectors.forthedeeplearningclassifiersinourbenchmark wetrain glove embeddingsbasedonfourlargecorpora summarized in table3.
the common crawl cc is a pre trained embedding downloadedinmarch2018.4itincludes840btokensandavocabulary of .2m words.
the corpus contains high quality generalpurpose text crawled from the internet.
however the cccorpus is missingdomain specifictermspresentinthe cadodataset.accordingly inthe ccotfembeddings themissingwordsfromthe cc corpusaretrainedon the fly .finally weobtainedacompletely domain specificrepresentationoftheinputbytrainingembeddings on two additional corpora stackoverflow so and stackoverflow api soapi .
the former includes million posts while the latter includes 4million posts taggedas javaor.net.
classifiersconfiguration thissectionreportsinformationabouttheconfigurationofboth machine learninganddeep learningclassifiers usedinthis study.
.
traditional machine learning themachinelearningapproachesweselectedforourclassification task are svm andk nn as well as their adaptations to multi label problems namely one vs rest svm ovrsvm and multi label k nn ml knn .
we use unigrams and bigrams extracted from the cadodataset as their input features as n gram languagemodelsareeasytocomputeanduse.moreover theyhave been used in studies where machine learning and natural language processing are appliedto software engineeringcontexts .
svm is one of the most investigated approaches for statistical documentclassificationanditisconsideredstate of the art .
moreover it showed good results in software engineering specific text classification problems e.g.
.
svm finds the hyperplanemaximizingthemarginbetweentwoclassesinthefeature 112on usingmachinelearning to identifyknowledgein apireference documentation esec fse august tallinn estonia table summary ofthecorporaused to train theglove embedding.
id name corpusdescription docs vocabulary cc common crawl general purpose high qualitytextcrawledfrom internet pages .2m .
ccotf common crawlon the fly common crawlwhere missingwordsare learnedfrom cado .2m .
so stackoverflow stackoverflowquestionsandanswers 20m .
soapi stackoverflowjava and.netposts stackoverflowquestionsandanswers taggedas javaor.net 4m .
space and it can learn and generalize high dimensional features typical for text classification tasks .
when taking into account multipleknowledgetypesat once wetrainedandreported theresultsofasvmmodeladaptedtosuchproblem i.e.
ovrsvm usingbinary relevance .
ovrsvm considersadditional parametersandconstraintsnecessarytosolvetheoptimizationproblem withseveralclassesandto handletheseparationofseveralhyperplanes .
for the svm classifiers we report the best model after hyper parameterstuningusing gridsearch .
k nn is a widely used approach in machine learning .
it determines the knearest neighbors of a document using euclidean distance.thenitassignsthedocumentalabelbasedonthedocumentneighborsusingbayesdecisionrules .forthemulti label classification weuseml knn whichoutperformswell established multi label classifiers .
.
rnnwith lstmlayer deeplearninghasrecentlybroughtsubstantialimprovementsinthe fieldofmachinevisionandnaturallanguageprocessing nlp .
thelstmlayerextends rnncapabilitiesbyutilizingseveralgates andamemorycellintherecurrentmoduletoalleviatethevanishing gradient problem and to handle more efficiently the long term dependencies between features .
tanh relurelusigmoidinput lstm dense dense output figure architecture of the rnn used for classification of theknowledgetypes.
figure4shows the architecture we used in this work.
the network is composed of a single lstmlayer two dense layers and an output layer.
the number of units in the lstmlayer is proportionaltodimensionsofthevectorsusedtorepresenteach word.
the dense layers contain and unitsrespectively.
the number of units in the output layer is the number of knowledge types i.e.
units .
the core component of the lstmlayer is a memorycellwhichstorestheinformationrelatedtotheprevious analysis steps within the network.
at each step of the training thenetworkpredictstheoutputbasedona thenewinput b the previousstateoftheotherhiddenlayersofthe rnn andc andthe current state of the memory cell.
the gates learn how to modify the memory cell to enhance prediction accuracy see figure .theforget gate ft processes the information from the previous hidden state layer ht and the current input xt i.e.
a representation of the api documentation text.
it then decides what information should be discarded or kept from the previous state of the memory cell ct .
theinput gate it is responsible for selectingnewinformationfromtheinput xt thatshouldbestored inthecellstate.thethirdgateiscalled outputgate ot anddecides which part of the available information in the memory cell should be usedto produce the final output ht .
figure5 asinglelstmrecurrentmodulecontaininginput it output ot andforgets gates ft .
the role of the forget cell in our network is to optimally discard informationrelatedtopreviousknowledgetypeswhentheychange inthenewinput.forinstance whentheknowledgetypeinthenew inputisdirective theforgetgateremovesthepiecesofinformation associatedwithotherknowledgetypes.consequently theforget gatereducestheambiguityofthememorycellwhenlearningindividual types.
the features associated with the knowledge type in the currentinput document are moved intothe memory cell.
in thememorycell theinputgatedecideswhatinformationshould be stored.
for example when the current input contains directive itsfeatureswillbeextractedandstoredinthememorycellusing the input gate.finally the outputgate selects the most significant features associatedwiththe directive type.
theinputlayer forthernnconsistsofwordembeddingvectorstrainedusingglove .glovereliesontheglobaloccurrences of a word in a corpus by defining a word to word co occurrence matrix.eachvalueofthematrixcontainstheprobability pofword jappearinginthecontextofword i asreportedinequation .in particular xijdenotes the number of times word joccurs in the contextofword iandxidenotesthenumberoftimesthatanyword kappearsinthecontextofword i.namely glovedefinesalearning functionthatestimatestheprobabilityratiooftheco occurrence 113esec fse august tallinn estonia davidefucci alireza mollaalizadehbahnemiri andwalidmaalej oftwotarget words iandj given acontextword k .
pij p j i xij xi xi summationdisplay.
kxik.
asinputvectorswithidenticallengthspeeduptheprocessof buildingtheembeddinglayerof thernn weconsidered300 as the maximum vector length and padded shorter vectors with zeroes.
therefore our input layer is a 2d matrix where each row is a300 dimensionalunit artificialneuron .thenumberofunitsin the inputlayer depends onthe vocabulary size ofthe corpusused totraintheembeddings.whena documentis fed tothernn the unitsassociatedwiththe document terms willbe activated.
the firsthidden layer is alstmunit which learns textual featuresofaninputdocument.itissuitedtolearnlong termdependencies such asinthecaseofthelargeapi referencedocumentation text.toprevent over fitting we applied a dropouttechnique to the weightsmatrixandto the biasvector .
theoutputofthe lstmlayer i.e.
asetoffeaturesthatcanbeassociated with a knowledge type goes through two fully connected dense layers.
the dense layers provide deep representations of the features extracted by the lstmlayer and enable the network to learn their hierarchical and compositional characteristics.
to alleviate feature loss due to the projection of the features from a high dimensionalspacetothelow dimensionalspaceoftheoutput layer themodelsmoothlyreducesthenumberofunitsinthedense layers from to .
we use the relu activation function for the denselayers to preventover fitting .
theoutputlayer providesthepredictedknowledgetypesusing a sigmoid activation function.
hence the number of units in the outputlayeristhenumberoflabelsthatthemodellearns.asthe outputof thesigmoid isa probability valuebetween and each neuron in this layer learns to estimate the probability of observing one of the labels.
to binarize the predicted probabilities we used differentthresholds according to the differentmetrics.
we tuned the following network parameters.
epochis a complete pass back andforward of everysample throughtheneural network.ascustomary werun100epochs .batchsize isthe numberofsamplespassedthroughthenetworkatonce.ascustomary weusedabatchsizeof32 .optimizer istheoptimization methodminimizingtheprediction error.we useadam astate ofthe artalgorithmfortrainingrnn .lossfunction isthemeasure of the network prediction error.
we use sigmoidal cross entropy as it is efficient for text classification .learning rate controls the adjustmentstotheweightswithrespecttothepredictionerror.we usedacustomary learningrateof.
.
results in this section we compare the performance of rnn and traditional machine learning approaches for the classification of api reference documentation.
we contrast the performance of rnn classifiers trained using different embeddings.
moreover we assess the classifiers generalizabilityto anothertest set.
.
knowledge typesidentification individual knowledge types.
we trained two rnn based classifiers using a general purpose corpus to create the embeddings for theinput layer rnnccandrnnccotf.
table4reports the evaluation of our classifiers.
rnn and traditional machine learningapproaches improveover thena vebaselines for alltheindividual knowledge type classification by up to on average .
svm alwaysperformedbetterthan k nn.
deeplearningclassifies functionality example andenvironment with high precision and high recall at different probability thresholds auprc outperformingtraditionalmachinelearning approaches.
the rnns yields subpar results for directive purpose reference concept andcontrol auprc .
however the best svm outperforms the bestrnnonly for the latter twotypes.
the best classifiers for quality structure patterns andnoninformation yield an auprc between and .
also in this case thebestmachinelearningapproach i.e.
svm outperforms thebestrnnsclassifiersonlyforthelattertwotypes.compared to machine learning rnnsclassifybettereightknowledge types.
multipleknowledgetypes.
thesecondstepistoconsiderour task as a multi label classification problem rather than building individual classifiers for each knowledge type.
we compare the rnn classifierstothemulti labeladaptationofthesametwomachine learning models and two na ve baselines see table .
ml knn and ovrsvm perform worse than the baselines for the item based metrics whereasthernnsshowsthebestperformance.thernns outperformml knn ovrsvm andthebaselinesforlabel based metrics.
there is an improvement regarding the most strict metric i.e.
subsetaccuracy betweenthebestrnnandmachine learningclassifiers.regardingmacroprecision macrorecall and macrof1 there is an improvement between and for the rnn.
mf1 performs better than traditional machine learning regarding macroauc whichrnnsimproves by17 .
answer to rq1.
one third of the knowledge types can be automatically identified with good results i.e.
auprc .rnncanmoreaccurately identifyeightofthe knowledge type compared to traditional machine learningapproaches.whenconsideringmulti labelclassification rnnoutperformstraditionalmachinelearningapproaches for item andlabel basedmetrics.
.
softwaredevelopment specific corpus individualknowledgetypes.
onernnusesfreely available pretrained embeddings based on a general purpose textual corpus i.e.
rnncc whereas rnnccotfuses the same corpus but learns missing words on the fly from the cadodataset.
the assumption behind text statistical representations such as glove is that the meaningofadocumentisdeterminedbythemeaningofthewords that appear in it .
accordingly rnnsoandrnnsoapiuse corporainadomaincloser to the one of api documentation.
as shown in table the best among these rnns performs similarly to their general domain counterparts auprc .
for functionality purpose control andstructure thedifferencesareminimal .however for qualityandenvironment thereisasubstantialdecreaseinperformancewhenusingsoftwaredevelopmentspecificembeddings and14 respectively .overall theimprovement is rather limited given the overhead in obtaining the corpusandcomputing the embeddings.
114on usingmachinelearning to identifyknowledgein apireference documentation esec fse august tallinn estonia table4 comparisonbetweendeeplearningclassifiers trainedwithembeddingsfromgeneralpurposeandsoftwaredevelopment corpora traditional machine learning and na ve approaches for classifying individual knowledge types in the cado dataset.
values report thearea underprecision recallcurve auprc .
na vebaselines traditionalapproaches deeplearning general purpose deeplearning softwaredev.
knowledgetypemf1 mf2 rand k nn svm rnncc rnnccotf rnnso rnnsoapi functionality .
.
.
.
.
.
.
.
.
concept .
.
.
.
.
.
.
.
.
directive .
.
.
.
.
.
.
.
.
purpose .
.
.
.
.
.
.
.
.
quality .
.
.
.
.
.
.
.
.
control .
.
.
.
.
.
.
.
.
structure .
.
.
.
.
.
.
.
.
pattern .
.
.
.
.
.
.
.
.
example .
.
.
.
.
.
.
.
.
environment .
.
.
.
.
.
.
.
.
reference .
.
.
.
.
.
.
.
.
non information .
.
.
.
.
.
.
.
.
table5 comparisonbetweendeeplearningclassifiers trainedwithembeddingsfromgeneralpurposeandsoftwaredevelopment corpora traditionalmachinelearning andna ve approachesforclassifying multiple knowledgetypesin cado.
na vebaselines traditionalapproaches deeplearning general purpose deeplearning softwaredev.
metricmf1 mf2 ml knn ovrsvm rnn cc rnnccotf rnnso rnnsoapi hammingloss .
.
.
.
.
.
.
.
subsetaccuracy .
.
.
.
.
.
.
.
macroprecision .
.
.
.
.
.
.
.
macrorecall .
.
.
.
.
.
.
.
macrof1 .
.
.
.
.
.
.
.
macroauc .
.
.
.
.
.
.
.
multiple knowledge types.
table5shows that rnnccand rnnccotfoutperform rnnsoandrnnsoapiwhenconsideringlabel basedmetrics exceptformacroauc andperformsimilarly when considering item basedmetrics.
the rnn trained using javaand.netstackoverflowpostshasthebestmacroauc .
answer to rq2.
rnn using software development specific embeddings show slight to no improvement over rnn using generalpurposeembeddingsforclassificationofindividual knowledge types.
when considering multi label learning exceptformacroauc usinggeneralpurposeembeddingsyields betterresults acrossitem andlabel basedmetrics.
.
classifiersgeneralizability individualknowledgetypes.
table6reportstheperformanceof theindividualrnn basedclassifiers on the pythontest set.
also inthissetting nona vebaselineperformsbetterthantraditional or deep learning approaches.
the rnns are the best classifiers for seven knowledge types whereas svm shows the best results for the remaining five.
consistently with the cadosetting svm is the best classifier for concept pattern andnon information .
classifiersforfunctionality concept andpurposeshowsomeimproved performance comparedto the cadosettings auprc .
.
thereisalargeabsolutedifference auprc betweenthe twosettingswhenconsidering directive quality control structure example andenvironment suggesting that these knowledge typesare dependent on the settings.
on average the performance on the pythondataset decreaseby over the knowledge types.
multipleknowledgetypes.
table7presenttheresultsofthe multi labelclassificationtask.regardingitem basedmetrics our classifiers performworse oron parwith respect to the na ve baselines.
the classifiers show low precision for the best classifier svm and recall for the best classifiers rnnccotf andrnnsoapi .
svmalso achievesthe best f1 .
rnnsoapi showsthe bestperformance for macroauc .
answerto rq3.
classifiersfor functionality concept purpose pattern anddirective seem to generalizefrom javaand .net to python documentation.
the generalization for multiple knowledge types classifiers islimited.
related work to the best of our knowledge this is the first study addressing the automated identification of severalknowledge types within api referencedocumentation.inthissection wereportrelatedwork investigatingsomeoftheknowledgetypesindividually.wepresent studiescomparing traditionalmachine learningand deep learning approachesfor textclassification insoftware engineering.
.
knowledge typesin api documentation identifyingadocumentbasedontheknowledgetypesitcontains cansupportdocumentationqualityassessmentandimprovement.
115esec fse august tallinn estonia davidefucci alireza mollaalizadehbahnemiri andwalidmaalej table comparison between deep learning classifiers trained with embeddings from general purpose and domain specific corpora traditional machine learning and na ve approaches for classifying api documents based on individual knowledge type inthe python dataset.
values report thearea underprecision recallcurve auprc .
na vebaselines traditionalapproaches deeplearning general purpose deeplearning softwaredev.
knowledgetypemf1 mf2 rand k nn svm rnn cc rnnccotf rnnso rnnsoapi functionality .
.
.
.
.
.
.
.
.
concept .
.
.
.
.
.
.
.
.
directive .
.
.
.
.
.
.
.
.
purpose .
.
.
.
.
.
.
.
.
quality .
.
.
.
.
.
.
.
.
control .
.
.
.
.
.
.
.
.
structure .
.
.
.
.
.
.
.
.
pattern .
.
.
.
.
.
.
.
.
example .
.
.
.
.
.
.
.
.
environment .
.
.
.
.
.
.
.
.
reference .
.
.
.
.
.
.
.
.
non information .
.
.
.
.
.
.
.
.
table7 comparisonbetweendeeplearningclassifiers trainedwithembeddingsfromgeneralpurposeandsoftwaredevelopment corpora traditionalmachinelearning andna ve approachesforclassifying multiple knowledgetypesin python.
na ve traditionalapproaches deeplearning general purpose deeplearning softwaredev.
metricmf1 mf2 ml knn ovrsvm rnn cc rnnccotf rnnso rnnsoapi hammingloss .
.
.
.
.
.
.
.
subsetaccuracy .
.
.
.
.
.
.
.
macroprecision .
.
.
.
.
.
.
.
macrorecall .
.
.
.
.
.
.
.
macrof1 .
.
.
.
.
.
.
.
macroauc .
.
.
.
.
.
.
.
for example ding et al.
systematic review of primary studiesinvestigatesdocumentationqualityattributes.theauthorsfocus onknowledge basedapproachesusedtoaddressqualityissuesof api documentation.
although retrievability is reported as an essential quality attribute the authors show a lack of advanced ways toretrievespecificinformationfromapidocumentation.onthe onehand ourworkrepresentsafirststeptowardsdevelopingretrievalmechanismsfordocumentscontainingasetofknowledge types from the java and .net api reference documentation.
on the other hand the individual classifiers showinga performance e.g.
functionality control example andenvironment canbeused to retrieve documents containing a specific knowledge type.
moreover ourclassifierscanbeusedtoretrievedocumentscontaining functionality from the pythonstandardlibrary documentation.
previousresearchtriedtoautomaticallyretrieveparticularknowledge from api documentation.
robillard and chhetri presented an approach to identify api related information that developers shouldnotignoreaswellasnon criticalinformation.theirapproach based on natural language analysis i.e.
part of speech tagging word patterns shows precision and recall when applied to java documentation units.
however the authors needed to manually assess on top of the sensible knowledge items also obvious unsurprising andpredictabledocumentation i.e.
what we consider non information .
our svm classifier trained using simplefeatures identifies non information with71 accuracy.montperrus et al.
studied a particular knowledge type found in api reference documentation directive.
they analyzed more than api documentation from open source libraries.
to determinethedocumentscontaining directive theydevelopedasetof syntacticpatternsassociatedwithconcernsreportedinthedocumentation.finally theymanuallycreatedataxonomyof23directives.
pandita et al.
proposed an nlp based approach to verify the legal usage of api methods against its description extracted automatically from the documentation.
their approach uses features derivedfrompart of speechtaggingandchunkingtechniquesto semantically analyze text.
moreover using a domain dictionary the authors extracted methods specifications as first order logic expressionsto verifytheir legal usage inclientcode.
conversely inthiswork weattemptedasimpleapproachbased onlyonfeatureswhichcanbeautomaticallyextractedfromtheraw text.ourgoalwastocreateabenchmarkwhichcanbeimproved by including for example natural language patterns specific for eachknowledgetypesanddomain specificmodels.weshowthat someclassifiers have already practical relevance.
.
deep learning in softwareengineering xu et al.
use cnn to semantically link together knowledge units from stackoverflow.
their approach focuses on predicting severalclassesofrelatedness e.g.
duplicate relatedinformation .
the network input is the word2vec representation of javarelated posts from stackoverflow whereas the dataset includes 116on usingmachinelearning to identifyknowledgein apireference documentation esec fse august tallinn estonia 000knowledgeunitsbalancedamongrelatednesstypes.thecnn outperformed machine learning baselines i.e.
svm trained using tf idfandword2vec.however fuandmenzies replicatedxu et al.
study comparing their results to the same svm baselines optimized using hyper parameter tuning.
the authors showed improvedresultsforthebaselineswhichperformclosely ifnotbetter to the cnn although the latter required 84x more time to train.
in thiswork wealsoused adeeplearningapproachwith asemantic representationoftheinputbasedonstackoverflow.wefoundthat forourtask thereareonlyafewsmallimprovementsduetothe software development specific corpus which may not be worth whenconsidering theextraeffortrequiredtoobtainandtrainthe embeddings.wecomparedthedeeplearningapproachto among others svm models trained in line with the suggestions of fu and menzies .
we showed that the approaches are complementary as theirperformance depends onthe specific knowledge types.
fakhoury et al.
applied deep learning and traditional machinelearningtothedetectionoflanguageanti patternsinsoftware artifacts e.g.
poor naming conventions using a dataset of elements collected from large java system.
the authors showed thatusingbayesianoptimizationandmodelselection traditional machinelearningmodelscanoutperformdeeplearningnotonly in accuracybut also regarding the use of computationalresources.
theyadviseresearchersandpractitionerstoexploretraditionalmachinelearningmodelswithhyper parametertuningbeforeturning to deep learning approaches.
our results for individual knowledge typespartlysupportthisconclusion.however whentacklingmultilabel problems our work shows that deep learning performs better thantraditional machine learningfor allthe reportedmetrics.
discussion in this section we discuss the implications for practitioners and researchers.then we present the limitationsofthis study.
.
implications building automated knowledge extraction tools.
classifiers showing good performance auprc can already be used in practice to tag documents containing crucial information for developers.
moreover these classifiers are trained using either traditionalmachinelearningalgorithms withsimple text features or usingdeeplearningbutwithreadilyavailableembeddings.adocument containing functionality can answer developers information needsregardingwhattheapidoes whereas controlandexample addresshow toaccomplishataskusing theapi.theclassifier for functionality can be applied also to python documentation.
the environment classifierscanbeusedtogetinformationregarding an api usage context.
classifiers for qualityandnon information showed encouraging results auprc .
the former is relevanttounderstandapiperformance whereasthelatterisuseful for suggesting information that a developer can ignore.
moreover thenon information classifier showed promising results generalizing to the python documentation.
given its particular use case we suggestresearchtofocusonmaximizingrecalltoensurethat alluninformative documents can be tagged appropriately.
for theother knowledgetypes wesuggestmaximizingprecisiontoguarantee that fundamental information iscorrectlytagged.theresultsforotherknowledgetypescanbeimprovedbyadding nlp basedfeatures.forexample structure usuallycontainsreferencesto otherapielementsthat canbeidentifiedusingaspecific named entitytagger e.g.
.conceptandpatternarestrongly characterized by explanations of specific terms and sequence of steps.thesecanbeidentifiedthroughspecializedfeaturesbasedon linguisticinquiry suchas drives e.g.
dothistoachievethat andtimeorientation e.g.
dothis thendothat .astheseclassifiers showed similar results when applied to the python documentation theirimprovement can alsoincreasetheir generalizability.
the classifiers showed the worst results auprc fordirective purpose andreference knowledgetypes.thefirsttwocanbe thesubjectoffurtherresearch.inparticular featuresfora directive classifiercanbeextractedfrommaalejandrobillardwork as well as from the specific taxonomy developed by montperrus et al.
.furthermore previousworkonrationaleminingforother softwareengineeringtasks e.g.
canbeadaptedtoimprove the results for the purposeknowledge type.
the reference classifier showedsomeoftheweakestperformancebutitcanbeimproved withsimplesyntactical features e.g.
the presenceof links.
thereisavariationinperformancebetweentheclassifierconfigurations e.g.
traditional machine learning vs. deep learning and between the individual knowledge types.
we hypothesize that some knowledge typescan be sensitive tospecific keywords such as callback event and trigger in the case of control.
on the other hand knowledge types such as environment andexample are characterized by a change in the language context.
the former tendstointerpolatetextwithnumbers asitincludesinformation such as version and copyright year while the latter contains sequences that do not occur in natural language i.e.
source code .
we postulate that the rnn can capture this change of context.
however the explanations for some classifiers results are more subtle.
for example non information implies expressing in natural language informationalready provided by amethod signature.
this implies a mapping between source code tokens and natural language ones which need to be further investigated.
similarly the purposeknowledge type containsinformation i.e.
the answerto a why question which can be difficult to identify from a semantic perspective usingthesimpleconfigurationsofourclassifiers.arguably theintrinsicdifficultytoidentifyaknowledgetype even for a human expert can explain some of the poor results.
for instance maalejandrobillardreportlowagreementfor purpose a knowledge type showing subparresults auprc .
another explanation for the different performancebetweentraditional machine learning and deep learning can lay in the parametersusedtotunethelatter.asuggestedimprovementistocreate binary rnns one for each knowledge type and select different parameters for a the activation function of the output layer e.g.
softmax b the loss function e.g.
categorical crossentropy andc the optimizer e.g.
rmsproporada .
usingknowledgetypeswhendevelopingsoftware.
oneof themainapplicationsfortheclassifierspresentedinthisstudyis documentation filtering.
api websites can offer their users the possibilitytosearchdocumentationbasedonspecificknowledgetypes in addition to current options e.g.
by package or class .
for example adeveloperfixingaspecificperformancebug e.g.
relatedto wireless connectivity cansearchthe network apidocumentation 117esec fse august tallinn estonia davidefucci alireza mollaalizadehbahnemiri andwalidmaalej containingthe qualityknowledgetype.inthiscase theclassifier can be optimized for precision i.e.
the developer would consult a smallnumberofdocumentswhicharelikelytocontaintheinformationneeded.ontheotherhand developersexploringpossible usageofanewsetofapiscanfilterthemaccordingto functionality which describes their capabilities.
in this case the classifier can be optimized for recall i.e.
the developer consults a substantial amount of documents which give a complete overview of the api functionality evenif somemay beirrelevant.ourbenchmark isa startingpointforselectingtheclassifiertooptimizeaccordingto specific scenarios.
classifiers with auprc can be utilized in the scenarios above while the ones with auprc need furtheroptimization.theproposedbenchmarkisalsoastepping stone to support software developers filtering api documentation based on multipleknowledge types of interest.
given the complexity of such a task our best classifier rnnsoapi showed good results macroauc .
however when disregarding recall based on the assumption that a developer will not read a large number of documents the classifier with the highest precision is rnnccotf.
conversely when a developer can tolerate noisyyet comprehensiveresults werecommendusing rnncc i.e.
theclassifierwiththebestrecall.inbothcases theclassifiers relyon affordable embeddings.
using knowledge types when authoring documentation.
api documentation providers can leverage the results of this work tomonitortheirproduct.forexample theycanusesimplemachine learning models e.g.
svm to find documents containing noninformation andremoveirrelevanttextthatincreasethedevelopers cognitiveeffort e.g.
therepetitionofamethodsignatureintextual form .furthermore theycanmonitorthepresenceofknowledge types containing crucial information for software developers such asfunctionality control andexample.apidocumentationprovider canalsomonitorthedecreaseofimportantknowledgetypes e.g.
functionality or increase of harmful ones i.e.
non information before releasing new version of an api and its documentation.
api defects can be diagnosed by identifying and subsequently improving documentation containing directive andquality.
furtherresearchoutlets.
researchersinvestigatingdocumentationqualitycanbenefitfromtheresultsofourwork.forexample qualitymodelscanbedevisedbasedonthepresence orabsence of specific types.
a firststepistheidentification of knowledgetypes in a set of documents.
in our benchmark the rnnsoapimodel showed good results macroauc .
.
the classifier correctly identifies documents containing a set of knowledge types with false positives rate when maximizing recall.
researchers should also consider the trade off between using a pre trained embedding while losing some performance in terms of macroauc.
given theresultsobtainedonthepythonstandardlibrary werecommend researchers to be careful when applying our multi label models to differentapidocumentation.researchershaveshowninterestin studyinghowtheusageofparticularelementsinaframeworkis documented e.g.
.
this line of research can benefit from anapproachtoautomaticallyretrieveapireferencedocumentation containing the functionality knowledge type using the rnnso model as itshowedgoodperformance ondifferenttest sets.
.
threatsto validity the api reference documentation used to train our classifiers is basedontwolibraries jdkand.net.whilethelanguageparadigms aresimilar theirdocumentationstylesare different .moreover wedirectlyaddressedathreattogeneralizabilitybyinvestigating the less structured documentation of the python programming language api .
we acknowledge that our results may not hold for apireferencedocumentationinotherdomains e.g.
foraspecific framework orfor adifferentprogramming paradigm e.g.
declarativeprogramming .althoughmaalejandrobillardtaxonomyis general enough other knowledge types may exist.
the labeling ofournewtestsetcanintroduceathreattointernalvalidity.tomitigate such threat two raters independently labeled the documents using validated guidelines .
we reconciled the disagreements approximately were clear mistakes by discussing borderline cases and reaching consensus among the authors.
our benchmark only includes two traditional machine learning algorithms one specific deep learning architecture and four representations for the rnn input layer.
nevertheless there may be other algorithms embeddings andconfigurationsworthofinvestigation.theresults can be biased due to the unbalancedness of the dataset.
to reduce thisthreat weappliedcommonresamplingtechniquestothetraining set and reported the performance according to appropriate metrics.
we did not observe a correlation between the classifiers performance andthe distributionof the labels.
conclusion and futurework in this paper we built several classifiers using traditional machine learninganddeeplearningapproaches toautomaticallyidentifythe knowledge types in api documentation asproposed by maalej and robillard .
we used java and .net manually annotated api documentation pages n as a dataset for training and testing the classifiers.
we showed good results i.e.
auprc for one third of the knowledge types.
rnn identifies eight types more accurately than traditional machine learning.
when considering multipleknowledgetypesatonce i.e.
multi labelclassification rnn outperforms traditional machine learning approaches.
when wordembeddings i.e.
thernninputlayer arecreatedfromstackoverflow posts rather than from general purpose text there is slighttonoimprovementinperformance auprc .when considering multiple labels software development specific embeddings yield better results for macroauc vs. .
we applied the classifiers to a new test set n obtained from the python api documentation.
classifiers for functionality concept purpose pattern anddirective generalizetopython.however thegeneralizationofmulti labelclassifiersislimited.someoftheclassifiers presented in this work can be already used by practitioners e.g.
developers api providers in different application scenarios.
we propose possible improvements to the classifiers based on features specificforaknowledgetype.basedonourbenchmark weplanto implementatool e.g.
abrowserplugin tofilterapidocumentation basedonknowledge types andevaluate its usefulness.