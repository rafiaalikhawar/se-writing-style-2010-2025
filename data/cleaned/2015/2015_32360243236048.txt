concurrency verification with maximal path causality qiuping yi texas a m university college station texas usa qiuping tamu.edujeff huang texas a m university college station texas usa jeff cse.tamu.edu abstract we present a technique that systematically explores the state spaces of concurrent programs across both the schedule space and the input space.
the cornerstone is a new model called maximal path causality mpc which captures all combinations of thread schedules and program inputs that reach the same path as one equivalency class and generates a unique schedule input combination to explore each path.
moreover the exploration for different paths can be easily parallelized.
our extensive evaluation on both popular concurrency benchmarks and real world c c applications shows that mpc significantly improves the performance of existing techniques.
ccs concepts software and its engineering formal software verification software testing and debugging keywords concurrency verification dynamic symbolic execution acm reference format qiuping yi and jeff huang.
.
concurrency verification with maximal path causality.
in proceedings of the 26th acm joint european software engineering conference and symposium on the foundations of software engineering esec fse november lake buena vista fl usa.
acm new york ny usa pages.
introduction the challenge of interleaving explosion has inspired a number of significant work in testing and verification of concurrent programs.
an essential idea is to identify redundant interleavings which can be ignored because they produce equivalent program states.
for example in partial order reduction an interleaving is identified as redundant if it can be generated from another interleaving by swapping non conflicting events of different threads.
maximal causality reduction mcr is a more recent technique that minimizes redundant interleavings by exploiting the maximal causality between events in an execution trace with a constraint solver.
a key idea of mcr is to capture the value of reads permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
copyrights for components of this work owned by others than acm must be honored.
abstracting with credit is permitted.
to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
request permissions from permissions acm.org.
esec fse november lake buena vista fl usa association for computing machinery.
acm isbn .
.
.
.
t1 .i input .x i .x t2 .j input .x j .x t3 .if x .
error .else y figure an example with inputs iand j. and writes in a trace and use the value to drive new executions such that every new execution reaches a distinct program state.
mcr is shown effective for finding extremely subtle bugs in both sequential and weak consistency models such as tso and pso .
however all these techniques suffer from a serious limitation they only explore program state spaces under a fixed program input but leave the whole input space except the fixed input unverified.
in other words they may fail to verify states that can only be reached by a certain combination of schedule and input.
consider a simple example in figure with three threads and two inputs iandj.
there is an error state at line .
when input i j is fixed to there are 15interleavings totally.
por explores all the 15interleavings mcr explores only 4because the program has only four different values for the read of xat line written by the four writes to xat lines 3and5 .
however neither por nor mcr can find the error at line .
in fact the error can never be exposed with the input .
one way to find the error is to check all possible inputs and for each input use mcr to explore the interleavings.
unfortunately the input space is huge even if both iandjare restricted to to verify this program there are executions that must be explored.
it poses a significant challenge to verify both the input space m and schedule space n .
in theory the whole search space is m n where mis often infinite and nis exponential in the program size.
in this paper we present a new technique maximal path causality mpc that systematically explores the state spaces of concurrent programs while reducing redundant explorations across both the schedule space and the input space.
the key idea is to combine mcr with dynamic symbolic execution dse a well known systematic path exploration technique.
in dse each execution is symbolically analyzed to find the next input that triggers the execution of an unexplored path.
similar to that mcr analyzes each execution trace symbolically and generates thread schedules that are not explored before.
by combining these two techniques that have conceptual similarities mpc can systematically explore both the input space and the schedule space at the same time.
more specifically mpc captures both schedules and inputs as a set of constraints which encode all schedule input si combinations that drive the program to the same path as one equivalency class.
for each equivalency class it generates a unique si through solving the mpc constraints to explore each path once esec fse november lake buena vista fl usa qiuping yi and jeff huang only.
back to the example in figure .
for input i j all the 15schedules reach the same path which takes the false branch at line .mpc only explores the path p1 once and ignores the other 14schedules.
after p1is explored mpc generates a new sito explore an unexplored path with path condition r7x where r7xdenotes the value of xat line .
thus the schedule t1 t1 t1 t2 t2 t3 t3 t2 with input i j is generated to cover a new path p2 which triggers the error.
mpc terminates after two executions because no other reachable but unexplored paths exist.
moreover mpc can be easily parallelized with two types of parallelism.
first dynamic executions for different sis can be parallelized because each execution is independent with previously explored paths.
second the offline analysis for generating sis for different paths can be parallelized because the offline analysis only depends on the observed execution.
for the last decade dse has enabled addressing diverse software engineering problems not only software testing but also automated debugging and automated program repair .
we expect that mpc can be used to extend many of those work done for sequential programs to concurrent programs given the similarity of mpc to dse.
we highlight our contributions as follows to our knowledge mpc is the first technique that systematically explores state spaces of concurrent programs while reducing redundant explorations across both input and schedule spaces.
to ensure the verification soundness a key challenge in mpc is how to systematically explore all reachable program paths.
we present a sound path exploration algorithm based on the unsatisfiable cores of the mpc formulas.
we evaluate mpc extensively on both popular benchmarks and real world applications in c c .
we show that mpc is significantly more effective and efficient than mcr and con2colic .
ourmpc tool is open source .
overview we start with a motivating example in figure slightly more complicated than the example in figure to illustrate the challenges of verifying concurrent programs.
we then use this example to illustrate how mcr works and identify its advantages and limitations.
finally we show how mpc addresses these limitations and draw its overview.
.
motivating example as shown in figure a our motivating example contains three threads t1 t3 which access two shared variables xandy and use a lock lto synchronize some but not all accesses to y. the program has an error at line which crashes the program when both the two branch conditions at lines 11and12are satisfied.
the error however is difficult to manifest because it requires a specific combination of thread schedule and program input e.g.
i 3and j .
specifically to satisfy the branch condition at line line should be executed as the latest write to xbefore line meanwhileline11should be executed after line .
note that the condition at line 3must be true to execute line which requires the inputito be .
to satisfy the branch condition at line line must be followed by line and at the same time no other writes toyshould happen before line .
in addition the input jmust be larger or equal to 2to ensure that the while loop at line is executed at least twice.
one such error triggering schedule is t1 t1 t1 t1 t2 t3 t3 t1 t1 t1 t1 t2 t3 t3 t3 t3 t3t3 t3 t3 t3 t2 t2 t2 corresponding to a path denoted by lines .
to detect this error a technique must find both a correct schedule and a correct input.
for example the error can never be revealed if the program input is fixed to i j or i j no matter what thread schedule the program executes.
this example shows the importance of cross input verification of concurrent programs.
however existing state space exploration techniques all assume a fixed input.
.
maximal causality reduction mcr is an effective stateless model checking approach for concurrent programs under a fixed input.
a main advantage of mcr over the other popular approaches e.g.
dpor and context bounding is that it uses a maximal thread causality model mcm to capture redundant schedules such that only those unique schedules reaching distinct program states are explored.
in other words mcr never explores the same program state twice given a fixed input and it ensures a provably minimal number of program executions for exploring all program states under the given input.
more specifically mcr encodes each explored trace as a maximal causality formula mcm with first order logical constraints.
it uses mcm to generate new thread schedules to explore by enforcing a new state condition each new schedule must contain at least one new event i.e.
aread that returns a new value.
in mcm each event efrom an input trace is represented by an order variable oe and the order relation between oefor different events is used to capture all the possible thread schedules that the same program which generates can execute in alternative runs.
mcm is constructed by a conjunction of two subformulas mcm sync rw where synccaptures the ordering constraints determined by thread synchronizations and rwthe data validity constraints over read andwrite events determined by memory consistency requirements e.g.
sequential consistency or relaxed consistency .
synccan be further decomposed as a conjunction of the must happen before constraints mhb and the lock mutual exclusion constraints lock.
for space reasons we refer the readers to for the encodings of mhb and lock and focus on describing rw which is extended in our new model to handle program inputs.
data validity constraints rw .for an event eto be feasible in an inferred trace mcm requires every read event rthat musthappen before eto return the same value as that returned by rin the input trace.
otherwise emay become infeasible due to a conditional right after the read event r. for example if in an observed trace a read rreads value then in the inferred trace it must also read value .
however it can read the value written by any write on 367concurrency verification with maximal path causality esec fse november lake buena vista fl usa data validity constraints sx rx11 wx1 o11 o1 o9 o1 o9 o11 o14 o1 o14 o11 rx11 wx9 o11 o9 o1 o9 o1 o11 o14 o9 o14 o11 rx11 wx14 o11 o14 o1 o14 o1 o11 o9 o1 o9 o11 wx1 wx9 wx14 synchronization constraints tzod o0 o1 o2 o3 o9 o10 o11 o14 o15 o16 initially x y t1 t2 t3 i input x x x y j input y if x while j if i if y lock l x crash y lock l unlock l y unlock l a b path condition constraints qd i rx11 j t1 t2 t3 initially x .
i input .
j input .
if x .
x i .
x j .
error .
x .
x .
else y figure a the crash can only be triggered by a specific combination of schedule and input.
b the constraints generated by mcr and mpc based on an execution with input i j and a random schedule.
the same address as long as the written value is not necessarily the same write as in the observed trace .
we refer to this as the data validity condition .
more formally let edenote the set of events that must happenbefore an event e. consider a read rin ethat accesses a memory location xand returns value v and let wxdenote the set of writes in the trace that write to x and wxvthose writes inwxwith value v. the data validity constraint of an event e rw e is defined as r e value r where value r w wxv rw w ow or w w wx ow ow or ow the constraint value r enforces the read rto read the value vwritten by any write winwxv which writes vto the memory location x subject to the condition that the order of wis smaller than that of rand there are no other writes in between that write a different value to x. it is worth noting that rwis recursive.
because in value r to enforce a read rto read from a write w wmust be feasible which requires rw w to hold.
for this example suppose the given input is i j and the first schedule explored by mcr is 1 .
the formula mcm generated by mcr is shown in figure b ignore the path condition constraint pcfor now .
let wix andrixdenote the written and read values of xat line irespectively.
r11xmay return any value among w1x w9xandw14x.
ifr11xreturns w1x then line 11must be executed after line 1and no other writes toxshould happen between lines 1and11.
finally mcr explores three executions each corresponding to a schedule in which the only read at line is matched with one of the three writes at lines and .
unfortunately none of these three executions can trigger the crash at line .
to trigger the crash mcr would need a correct input e.g.
i j .
nevertheless even with the correct input to hit the bug mcr still needs to explore executions in our experiment.
schedulerstateless model checker path p trace path conditionwork list ... ...... program symbolic execution pathexplorer updateschedule spaceinput space figure overview of mpc .
.
mpc in a nutshell inspired by mcr our approach addresses two main problems.
first it extends mcr to handle program inputs i.e.
it not only generates new schedules but also new inputs.
second it advances mcr to capture not only redundant schedules but also redundant inputs and redundant combinations of schedules and inputs.
this is a major advance because the space of schedule input si combinations explodes much faster than the input space or the schedule space alone yet significant redundancy often exists across the two spaces.
we also note that our approach is applicable to a wide range of memory models such as tso and pso but we focus on sequential consistency sc in this paper.
figure shows an overview of mpc which systematically explores all reachable paths in the program.
at runtime mpc performs both dynamic scheduling and symbolic execution to explore new program paths.
offline it formulates constraints from the information observed at runtime and generates new si combinations 368esec fse november lake buena vista fl usa qiuping yi and jeff huang pathwork listbranchp0i1i2i3i4i5i6i7b300001111b1100110011b16101010101pathwork listbranchp0p1i2i3i4i5i6i7i8b3000011110b11001100110b161010101011b16201all explored pathsbranchp0p1p2p3p4p5p6p7p8p9b30011110111b110000110011b120001b1610101011111b1620111001initial input j j initial schedule empty input i j schedule o0 o1 o2 o9 o10 o11 o14 o15 o16 ...path prefix emptynew identified branch b3 b11 b161 path prefix i1new identified branch b162 a b c figure mpc on the motivating example in fig.
.
by solving the constraints to explore new paths.
by leveraging mcr the advantage of mpc over conventional symbolic execution is that it does not need to reason about symbolic pointers on shared data because concrete addresses of shared data accesses are all observed at runtime.
mpc maintains a worklist of the to be checked sis.
the worklistis initialized with a random si i.e.
an empty schedule and a random input and is augmented with new sis generated from each iteration.
in each iteration the scheduler consumes one si from the worklist to guide a concrete execution accompanied by a symbolic execution to collect the path condition.
then the offline pathexplorer finds unexplored paths or path prefixes across the schedule space and input space based on previously observed paths.
for each such path it further generates a corresponding si which is added to the worklist for exploring the path.
mpc terminates when the worklist is empty and there is no new si that can be generated meaning that all reachable paths have been explored.
figure illustrates mpc on the motivating example.
to ease the presentation we directly add the paths instead of the corresponding sis into the worklist .mpc starts with an input i j and an empty schedule which means the schedule can be arbitrary .
suppose path p0with the path condition i r11x j 0is explored in the first execution which exhibits three new branches b3 b11 b16 and for all these branches the false branch is taken denoted by in figure a .
1we use b16ito denote the ith instance of the branch at line .then based on p0 mpc identifies new path prefixes i1 i7 which are different combinations of the branch choices at b3 b11 andb16 and which have not been explored.
for each path prefix mpc then tries to generate a concrete si via a constraintbased approach to enforce an execution that follows the path prefix.
specifically mpc uses an smt solver to solve the formula mpc sync pc dc where mpc is the constraint constructed from the maximal path causality model which will be described in section .
.
compared to mcm in mcr mpc is a relaxation that captures the path condition pcand the data consistency dcover the reads and writes in the path prefix instead of the whole trace.
for example for i1which contains the false branch of b3 andb11and the true branch of b16 the path condition pcis i r11x j meaning that iis not equal to jis larger than and the value returned by the read of xat line r11x is not equal to .
the mpc constraints are shown in figure b .
the mpc constraint mpc is a conjunction of the path condition constraint pc the synchronization constraint sync and the dataconsistency constraint dc.
the synchronization constraints sync is the same as that in mcm .
the data consistency constraint dc concerns r11xand three writes to x w1x w9xandw14x.
for this example dc shown in the gray area is similar to the data validity constraint rw except that it does not enforce the values of the three writes i.e.
w1x w9x w14x .
one solution i.e.
an si combination to mpc is shown above figure b .
the solution drives mpc to explore a new path p1 which exhibits a new branch b16 2with its false branch taken.
again based on p1 mpc identifies a new path prefix i8 which extends i1with the true branch of b16 and generates a new si for it.
mpc repeats the previous analysis for each si until the worklist is empty.
for our motivating example mpc terminates after exploring 10paths including the crash triggering path p9 as shown in figure c .
the mpc approach in this section we present the mpc approach in detail including the basic definitions the mpc model the overall mpc algorithm the path exploration algorithms and the parallel mpc algorithm.
.
basic definitions a central notion of our approach is the path prefix of a multithreaded program definition .
.
path and path prefix .
a path pcorresponding to a complete execution trace is defined as p p t1 .
.
.
p tn where p ti is the executed path of thread ti.p p t1 .
.
.
p tn is a path prefix of p if for all threads ti i .
.
.
n p ti is a prefix of p ti .
thus p may be an incomplete path and p ti p ti where p ti represents the length of p ti .
each path pis also a path prefix of itself.
definition .
.
path subsumption .
let ps p denote the set of all paths with the same path prefix p. for two path prefixes p1andp2 we call p1subsumes p2 orp2is subsumed by p1 ifps p2 ps p1 .
369concurrency verification with maximal path causality esec fse november lake buena vista fl usa based on the path prefixes all paths can be organized into a path tree defined as follows definition .
.
path tree .
the path tree of a multithreaded program is a tree n e where the node set nrepresents path prefixes and the edge set erepresents the following relations between nodes for non leaf node n m children n nsubsumes m i.e.
ps m ps n .
for non leaf node n a b children n ps a ps b where a b. for non leaf node n ps n m children n ps m .
in a path tree the root represents all paths because all paths share an empty prefix .
each leaf node represents one concrete path or an unreachable path prefix and each non leaf node is a reachable path prefix which contains one or more paths.
for example figure shows the path three of the program in figure .
it contains three nodes the root node representing path prefix p0 true and two leaf nodes representing the paths p1 r7x 100andp2 r7x respectively.
p0 truep1 rx7 100p2 rx7 figure path tree of the example in figure .
.
maximal path causality in mcm a multithreaded program is modeled as a prefixclosed set of finite traces that can be produced when completely or partially executed.
a trace is abstracted as a sequence of events performed by threads on concurrent objects in a concrete execution such as read write lock unlock etc.
we note that the event value is also a part of the model.
if the value of an event e.g.
the value returned by a read is changed it becomes a different event such that a conditional branch after the event may produce a different trace.
compared to mcm a key difference of maximal path causality mpc is that the event value is ignored in mpc.
because the path condition of each thread is also captured in the trace to ensure the feasibility of an event it suffices to require that the path condition of the event is satisfied instead of requiring the data validity condition as in mcm .
this relaxation not only significantly increases the power of mcm but also reduces the complexity of the generated constraints.
consider an example in figure .
suppose the input trace follows lines then the two traces and3 1are also feasible in mcm.
however the trace is not feasible because in mcm the feasibility of the event at line requires the read at line to return the same value as that in the input trace which is but in the trace it returns the value written by line which is .
therefore to expose the assertion violation mcr based on mcm must enforce a new execution following which explores the trace .
however the trace is feasible in mpc.
the reason is that the path condition for the event at line is true because there is t1 t2 initially x .r1 x .
x .r2 x assert r1 r2 figure example of maximal path causality.
no branch so the event is feasible regardless of the value read by the event at line .
hence the assertion violation in this example can be directly exposed in mpc without requiring a new execution.
given a trace and the corresponding path condition for each thread the mpc constraint mpc captures the maximal path causality among events in the trace and is defined as mpc sync pc dc.
there are two types of symbolic variables in the path condition constraint pc the value of program inputs and the value of reads on shared data.
for example in the path condition i r11x j 0of our motivating example in figure i andjare program inputs and r11xis the symbolic value of reads.
the first type can get arbitrary value allowed by program inputs.
the second type can only choose certain values written by writes in the input trace which is constrained by the data consistency constraint dc.
more specifically consider a read r all the write events on the same memory location denoted by a set w and the possible value returned by r denoted by vr.
the data consistency constraint for ris defined as dc r wi w vr wi owi or wj wi owj owi owj or the constraint dc r states that if the read rreturns the value written by a write w then the write s order owmust be smaller than the read s order orand there are no other writes between them.
the value of any write wcan be either concrete or symbolic represented by the symbolic inputs or symbolic read values.
the size of dc in the worst case is cubic in the size of the whole trace i.e.
linear in the number of reads and quadratic in the number of writes .
compared to rwin mcm dcin mpc is much simpler and is not recursive.
there are two main differences.
first dconly specifies the possible values a read can return but does not enforce it to return a specific value as enforced in rw .
second dcis constructed over events in a given path instead of the whole trace .
since the path condition constraint pcensures the feasibility of all events in the path dcdoes not need the feasibility constraints for the matched writes as required in rw .
.
the basic mpc algorithm our goal is to effectively explore the path tree of a concurrent program.
algorithm describes the overall flow of our algorithm.
the basic idea is to incrementally construct the path tree based on the mpc model.
each item si pre f ix in the worklist is used to drive an execution to follow the path prefix pre f ix with the schedule input si combination si.
to start the worklist is initialized with an empty prefix i.e.
the root of the path tree a random input and an empty schedule.
in each iteration lines an si from the worklist is consumed and 370esec fse november lake buena vista fl usa qiuping yi and jeff huang algorithm the mpc algorithm si random input and empty schedule worklist .add si true while !worklist .empty si prefix worklist .pop guidedse si prefix list generatenewsi prefix worklist .add list end while algorithm generatenewsi prefix si p identifynewpathprefixes prefix for each p p extractsubtrace p pc pathconditionconstraints p sync synchronizationconstraints dc dataconsistencyconstraints mpc p pc sync dc si solve mpc p if si null then si.add si p return si.
two steps are performed dynamic path exploration and static pathprefix identification.
the first step carries out a guided symbolic execution along with the concrete execution triggered by the si to collect the trace together with the path condition.
in the second step there are two important tasks identifying new path prefixes e.g.
unexplored branches and generating new sis for each new path prefix.
task is crucial to the verification soundness and it turns out to be highly challenging which we will elaborate in the next subsection.
task is based on the mpc model for which we present our algorithm next.
algorithm describes our algorithm for generating the new sis from a trace and a path prefix prefix .
it first identifies a set of potential new path prefixes p based on andprefix recall section .
.
for each new path prefix pinp it constructs a formula mpc p of constraints to generate a corresponding si which should exist if pis feasible .
mpc p corresponds to the mpc constraints of the path prefix p which considers a subtrace of containing only those events in p. any solution to mpc p produces a concrete thread schedule and a concrete input that can drive the program to execute the path prefix p. it is important to note that the formula mpc p is sound i.e.
it only captures the space of feasible sis with respect to path prefix p. those events that are not on pare excluded from dcand sync.
consider an example in figure .
for exploring the path prefix ab with path condition r1y r3x the writes at lines and are not considered because they are not executed on this path prefix.
another advantage of mpc over mcr is that the complexity of generated constraints can be significantly reduced.
to generate a new schedule that manifests an event mcr has to ensure that all dependent reads of this event which are conservatively assumed in mcm as all events that must happen before this event must return t1 t2 initially x .
if x x a .
if x c else .
error .
if j x b .
else x t1 t2 t3 initially x .
if i a .
if j b .
if x c .
x .
x .
error t1 t2 initially x y .
if y x a .
if x y b .
else x .
else y figure example for explaining mpc p .
the same value as that in the observed execution.
this often leads to a large number of data validity constraints that are expensive to solve.
however such constraints are avoided in mpc .
.
path exploration the key challenge in mpc is how to systematically explore the path tree such that it does not miss any reachable path.
we first present an efficient and intuitively sound but in fact unsound algorithm.
we then present a sound algorithm based on the unsat core of unsatisfiable mpc formulas.
.
.
strategy combining unexplored path suffixes.
our first strategy is to combine unexplored path suffixes which are exposed in the newly observed execution trace.
this is a natural extension of how existing symbolic execution engine e.g.
klee explores paths for sequential programs.
for example consider a trace with two threads driven by a path prefix pre.
suppose preis extended with suffixes aandbfor each of the two threads respectively.
that is the newly explored path pispre a b. note that aandbare path conditions with respect to two branch choices.
hence there are three new possible path prefixes identified by combining different branch choices pre a b pre a bandpre a b where xmeans the negation of x i.e.
the path follows the opposite choice of the corresponding branch.
more generally let split pre p refer to the set of new path prefix combinations based on a newly explored path pand a corresponding path prefix pre and let suffix pre p ti suffix ti for short denote the path extension for thread tifrom pretop.
then split pre p contains new path prefixes formed by all combinations of suffix ti and its negations among all threads.
for each individual thread suffix ti may exhibit more than one new branch.
for example suppose suffix ti b1 b2 b3 then three path prefixes b1 b1 b2and b1 b2 b3are identified.
note that other combinations such as b1b2 b3are not valid because the execution of a branch may depend on the preceding branch choices.
in total split pre p contains n i suffix ti path prefixes where nis the number of threads and suffix ti the number of branches in suffix ti .
on the surface this strategy appears sound as it explores each combination of path prefixes once.
however it is unsound that it may miss certain reachable paths.
consider an example in figure a which contains two inputs iandj and one shared variable x. let a bandcdenote the branches at lines and respectively.
suppose the first explored path is p0 t1 a t2 c where the branch at line is true i and the branch at line is false r4x .
three unexplored path prefixes are identified p1 t1 a t2 c p2 t1 a t2 c and p3 t1 a t2 c .
among them both p1 371concurrency verification with maximal path causality esec fse november lake buena vista fl usa t1 t2 initially x i input j input .
if i x a .
if x c else .
error .
if j x b .
else x a truep1 acp2 acp4 abcp5 abcp0 acp3 ac b truep1 acp2 acp3 ac p4 abcp0 acp5 abcp6 abcp7 abc c figure a an example.
b strategy fails to explore the error path abc.
c strategy is sound.
andp3are unreachable based on the constraints generated from the observed trace and only p2is reachable.
hence p2is further explored which generates p4 t1 ab t2 c .
based on p4 a new path prefix p5 t1 ab t2 c is identified.
the final path tree constructed by strategy is depicted in figure b .
the error path abc is missed.
the reason is that strategy relies only on the observed trace to determine if a path prefix is reachable or not.
however the first trace 1only observes the true branch at line and thus does not provide any information along the false branch which affects the branch decision at line .
.
.
strategy unsat core uc based thread independent exploration.
the key idea behind strategy is to distinguish unreachable path prefixes from those overly subsuming path prefixes defined below .
for example the path prefix p3in figure b subsumes two concrete paths an unreachable path t1 ab t2 c and a reachable path t1 ab t2 c which is the error path.
strategy splits such overly subsuming path prefixes by discovering new behaviors through extending each thread independently.
more formally overly subsuming path prefixes can be defined as follows definition .
.
overly subsuming path prefix .
given a trace with nthreads and its corresponding path p and let p ti denote the path prefix along thread ti.
for path prefix pre p split pre p is an over subsuming path prefix if the following two conditions are satisfied c1 mpc p is unsatisfiable.
c2 there exists a thread set tset based on which a reachable path prefix pextcan be constructed where tset threads uc mpc p and for each ti pext ti is defined as follows pext ti pre ti ifti tset p ti otherwise .
the above conditions state that p is an overly subsuming path prefix if it is not reachable based on by satisfying c1 but there exists a reachable path pext in which each thread tiwhich follows pre ti orp ti by satisfying c2 .
we propose to identify the overly subsuming path prefixes based on the root causes of unsatisfiability i.e.
the ucs of the unsatisfiable formula .
an unsat core uc of a formula fis a subset of the clauses in fthat contribute to its unsatisfiability.
for example x y x y is an uc of the formula x y x y z .
condition z 0is excluded from the uc because it makes no contribution to the unsatisfiability.strategy identifies the ucs of formula mpc p for each unreachable path prefix p and maps them back to a thread set threads uc p which contains threads that contribute clauses to the ucs.
then it tries to explore a path prefix pextwhich extends the prefixes along all threads except those in threads uc .
we note that to ensure soundness all threads that contribute to the unsatisfiability of mpc p must be considered.
without the uc one would have to extend the path prefix along all possible thread combinations to check the reachability which may introduce many redundant explorations.
therefore the use of the ucs is important to both the soundness and the performance of strategy .
in our implementation we first consider the biggest uc because it may exclude the most threads from being extended and thus avoiding unnecessary redundant explorations.
when failed to guarantee the soundness we continue to consider the smaller ucs until it succeeds or no more ucs can be further identified.
consider again the example in figure .
although there exists no si to satisfy p3 t1 a t2 c strategy finds that p3is an overlysubsuming path prefix.
first the basic condition c1is satisfied because p3is unsatisfiable based on p0.
second c2is satisfied because it can generate an si to extend t1along the path prefix p3 t1 a. specifically when p3is identified as unreachable by checking that pc i r4x is unsatisfiable strategy checks conditionc2as follows.
first it computes uc pc which is r4x .
thus the corresponding threads uc is t2 which means that only thread t2contributes to the unsatisfiability.
then strategy constructs path condition of pextasp3 t1 true t2 .
finally a new si is generated to drive the program to explore path pext t1 ab t2 c which extends prefix aalong t1as expected.
then p3is split into two new path prefixes p6 t1 ab t2 c and p7 t1 ab t2 c .
at this time p6is a reachable path prefix based on pext.
thus it successfully generates a new si combination for triggering an execution along path prefix p6.
figure c shows the final path tree constructed by strategy for this example.
in total reachable paths are explored.
we next prove the soundness of strategy theorem soundness .
strategy will explore all reachable paths if the solver is sound i.e.
for a satisfiable constraint formula it always returns a correct solution.
proof .by contradiction.
suppose a reachable path pis missed by strategy s2 .
there are only two possible reasons.
first pis not identified.
this is impossible because upon observing any new path all possible path prefix combinations are identified in split pre p .
second pis determined to be unreachable.
for this since the solver 372esec fse november lake buena vista fl usa qiuping yi and jeff huang algorithm parallel mpc si prefix guidedse si prefix si parallel generatenewsi prefix par forall si p si parallel mpc si p is sound pmust not be an overly subsuming path prefix meaning thatpviolates c1 or c2.
if c1 is violated then an si can be directly generated.
if c2 is violated then s2 must have missed a certain way to break the identified unsat core.
however s2 has enumerated all possible ways to break the root cause of an unreachable path prefix.
thus pmust be unreachable when s2 fails to further extend it contradicting to the initial hypothesis.
.
the parallel mpc algorithm different from other state space exploration techniques which are difficult to parallelize the mpc algorithm can be easily parallelized.
specifically the online path exploration can be parallelized because it only depends on the provided si.
similarly the offline path identification can be parallelized because it only depends on the trace information collected from the observed execution.
algorithm describes the parallelized mpc algorithm.
for each si and the corresponding path prefix parallel mpc first carries out a guided symbolic execution as in the sequential algorithm and then invokes parallel generatenewsi to generate new sis and path prefixes in parallel.
for each new si and path prefix it then starts a parallel instance of parallel mpc to continue exploring.
evaluation we implemented mpc for pthread based c programs based on klee and z3 .mpc contains an application level scheduler a runtime tracer and an offline si generator.
the scheduler takes an si as input to guide the thread execution by intercepting critical events on shared variables.
the runtime tracer performs symbolic execution along the controlled execution to collect path conditions and the trace such as reads and writes on shared variables and synchronization operations by pthread library calls.
when a new execution is completed the offline generator reads the trace information and constructs the constraints.
then it invokes z3 to identify newly unexplored paths.
the output of the offline generator is a set of sis to trigger the iterative analysis process.
the parallelized implementation initializes a new iteration of path exploration whenever a new si is generated and an idle worker is available.
to compare mpc with mcr we also implemented mcr for checking c c programs the original mcr was implemented for java .
we evaluated mpc with three sets of experiments.
all experiments were run on a four core linux machine with .7ghz intel i5 cpu and 8gb ram.
the timeout for each benchmark was set to one hour.
.
finding tricky concurrency bugs we first evaluated mpc for finding tricky bugs in a set of microbenchmarks and a specially designed third party benchmark racey which contains intensive races for evaluating concurrency bug finding and reproduction techniques.
for the micro benchmarks code omitted due to page limit we generated nine variants m1 m9 of the example m0 in figure by varying the number of threads.
mirepresents the program that contains i 3threads including the original threads t1 t3 and iextra threads each of which executes code int k input if k x .
in addition the statement at line in figure is changed to if x i from if x .
with more threads involved the chance of triggering the crash at line becomes smaller.
to ensure program termination the maximal value of jis set to .
because mcr does not handle program inputs we conducted three types of experiments.
first providing mcr with a random input in each execution.
second providing it with a fixed but incorrect input that cannot trigger the error.
third providing it with a fixed correct input where iandjare set to and respectively and other inputs to .
this guarantees that mcr will trigger the error under certain schedules.
for the first two experiments our results confirm that mcr cannot find the error before timeout.
in fact when provided with a random input mcr often fails at the runtime scheduling phase because the seed interleavings which are used to control the schedule are computed for a different input.
table reports the results for the third experiment.
overall mpc with the sound path exploration strategy s2 outperforms mcr consistently by finding the error with significantly fewer executions and more identified paths.
in most cases m3 m9 mcr runs timeout without finding the error even though the bug triggering input is provided.
for mpc with the unsound strategy s1 although it is much faster than s2 due to the unsoundness it fails to find the tricky error.
for s2 it finds all the errors except the timeout case in m9.
forracey due to its intensive races it typically computes different outputs in different runs.
we seed an error by inserting an assertion at the end of the program to check if the program can produce a certain output.
to ensure termination we set the maximal number of checking the barrier states in each thread to .
all techniques explored the same number of paths but mcr took the longest time 4x slower than s1 and 2x slower than s2.
the reason is that compared to mpc mcr generates significantly more constraints and also more solver invocations due to more executions.
performance of parallel mpc.
table columns report the performance of the parallelized mpc on the same benchmarks.
compared to the sequential version the parallel mpc achieves as much as .3x speedup on the four core machine.
nevertheless we note that our current implementation is not fully optimized.
to balance parallelism and resource consumption the verification tasks are not totally parallelized.
in addition the task partition and thread dispatching in our implementation introduce additional overhead.
.
evaluation on concurrency libraries we next evaluated mpc on a collection of real world concurrency libraries including dekker s mutual exclusion algorithm dekker cas based spinlock spinlock linux reader write lock linuxrwlock michael and scott lock free queue msqueue linux readerwrite lock linuxrwlock and linux sequential lock seqlock .
for 373concurrency verification with maximal path causality esec fse november lake buena vista fl usa table results of finding tricky bugs.
to timeout of one hour.
the error is found not found .
benchmark paths time parallel time speedup mcr mpc s1 mpc s2 mcr mpc s1 mpc s2 mpc s1 mpc s2 mpc s1 mpc s2 m0 14s.
0s.
0s.
0s.
0s.
.
.
m1 2m13s.
0s.
1s.
0s.
0s.
.
.
m3 to 2s.
5s.
1s.
3s.
.
.
m5 to 16s.
38s.
8s.
20s.
.
.
m7 to 1m30s.
13m50s.
50s.
3m17s.
.
.
m9 to 8m27s.
to 5m21s.
22m42s.
.
.
racey 18m52s.
4m27s.
7m39s.
2m25s 3m23s .
.
table results on real world concurrency libraries.
program setting paths time mcr mpc mcr mpc dekker1 t p 2m13s.
1m24s.
dekker2 t p 12m52s.
5m46s.
spinlock1 t k 15m49s.
1m6s.
spinlock2 t k 20m53s.
3m28s.
linuxrwlock t k to 35m8s.
msqueue t k to 4m6s.
seqlock t k to 13m2s.
each concurrency library we wrote a driver such that their inputs can be configured i.e.
not fixed .
for all benchmarks we also compared with mcr by running it with a fixed correct input.
table summarizes the results.
tis the number of threads pis the maximal number of attempts to enter the critical section for dekker and kis the number of attempts to acquire and release the lock for the others .
overall mpc significantly outperforms mcr on all these benchmarks in terms of efficiency and effectiveness.
for most benchmarks mcr explores many redundant paths i.e.
repeatedly explores the same path because it generates schedules for unique states only but multiple states can be exhibited by the same path.
for mpc with the sound path exploration strategy it explores orders of magnitude more unique paths than mcr with less time or within the same timeout period.
.
comparison with con2colic we have also compared mpc with con2colic a concolic testing technique for concurrent programs.
con2colic maintains a list of interference scenarios that capture inter thread data flow and systematically explores program branches by enumerating all interference scenario candidates isc upto a degree k the number of inter thread data flow edges in the isc .
because an unrealizable isc may become realizable after new states are explored in the future a challenge faced by con2colic is memoizing all the unrealizable iscs.
it stores all iscs in a global interference forest and upon a new branch is explored it validates the realizability of each isc.
this incurs both a large memory overhead and expensive validations of unrealizable iscs.
differently mpc does not memorize any states but tracks the path prefixes through constraint solving and it models both the path condition constraints and thread interleavings in a uniform constraint formula thus simultaneously checking all si combinations that cover the same path.table mpc and con2colic on real applications.
programcon2colic mpc k runs success?
time paths success?
time aget 23s.
13s apache a 1m32s 9s.
apache b 3s.
1s.
bluetooth 0s.
2s.
ctrace1 0s.
3s.
ctrace2 to 2m23s pfsan oom 3m39s rbtree crash no bug 0s.
sor 0s.
1s.
splay no bug 4s.
no bug 2s.
table reports the results on the benchmarks collected from the concrest tool .
because con2colic is not parallel we compare it with the sequential mpc .
columns kand runs respectively report the largest degree of interferences and the number of executions explored by con2colic.
column paths reports the number of paths explored by mpc .
note that there is no correspondance between runs and paths .
because con2colic is driven by iscs rather than unique paths con2colic tends to explore many executions that exercise the same path.
column success?
reports if the technique detects the known bugs in the benchmark and if yes x y shows the first bug was identified in the xth execution and the second bug was identified in the yth execution etc.
column time reports the total exploration time for each technique.
overall mpc is more effective than con2colic for verification mpc finds more bugs than con2colic and incurs fewer executions to find the same bug.
our results also show that con2colic is unsound e.g.
it finishes without detecting the second bug in ctrace1 and it missed the bugs in pfscan due to out of memory.
although in three out of the ten cases mpc takes longer than con2colic to finish mpc always explores more unique paths than con2colic.
for example for apache a mpc explores unique paths but con2colic explores at most paths bounded by the executions explored by con2colic .
although mpc timeouts it is able to verify more paths than con2colic.
this also explains why mpc can find the second bug in ctrace1 whereas con2colic cannot.
we also designed a micro benchmark figure to quantify the performance differences between mpc and con2colic.
the assertion can only be violated if every execution of lines and in thread t1is interleaved by the execution of line from the same loop iteration in thread t2.
our results shows that mpc is more efficient and effective than con2colic.
when nis small from to 374esec fse november lake buena vista fl usa qiuping yi and jeff huang t1 t2 initially x .r1 x .
x .r2 x assert r1 r2 .
for int i i n i .
int tmp x .
tmp tmp .
x tmp .
if x tmp .
x .
.
for int i i n i .
x assert x!
n t1t2 1334esec fse november lake buena vista florida united states anon.
1392table results of mpcand con2colic on the micro benchmark in figure .
ncon2colic mpc k runs success?
time paths success?
time 0s.
0s.
1s 0s.
6m47s 0s.
to 1s.
to 4s.