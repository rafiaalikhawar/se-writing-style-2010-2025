guided stochastic model based gui testing of android apps ting su1 guozhu meng2 yuting chen3 ke wu1 weiming yang1 yao yao1 geguang pu1 yang liu2 zhendong su4 1school of computer science and software engineering east china normal university china 2school of computer engineering nanyang technological university singapore 3department of computer science and engineering shanghai jiao tong university china 4department of computer science university of california davis usa suting gzmeng ntu.edu.sg chenyt cs.sjtu.edu.cn sei wk2009 .com ywm0822 qq.com sei yaoyao .com ggpu sei.ecnu.edu.cn yangliu ntu.edu.sg su cs.ucdavis.edu abstract mobile apps are ubiquitous operate in complex environments and are developed under the time to market pressure.
ensuring their correctness and reliability thus becomes an important challenge.
this paper introduces stoat a novel guided approach to perform stochastic model based testing on android apps.
stoat operates in two phases given an app as input it uses dynamic analysis enhanced by a weighted ui exploration strategy and static analysis to reverse engineer a stochastic model of the app s gui interactions and it adapts gibbs sampling to iteratively mutate refine the stochastic model and guides test generation from the mutated models toward achieving high code and model coverage and exhibiting diverse sequences.
during testing system level events are randomly injected to further enhance the testing effectiveness.
stoat was evaluated on open source apps.
the results show the models produced by stoat cover more code than those by existing modeling tools stoat detects 3x more unique crashes than two state of the art testing tools monkey and sapienz.
furthermore stoat tested most popular google play apps and detected previously unknown and unique crashes.
so far developers have responded that they are investigating our reports.
of reported crashes have been confirmed and already fixed.
ccs concepts theory of computation program analysis software and its engineering software testing and debugging keywords mobile apps gui testing model based testing acm reference format ting su guozhu meng yuting chen ke wu weiming yang yao yao geguang pu yang liu and zhendong su.
.
guided stochastic modelbased gui testing of android apps.
in proceedings of 11th joint meeting of the european software engineering conference and the acm sigsoft geguang pu and yuting chen are the corresponding authors.
permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
copyrights for components of this work owned by others than acm must be honored.
abstracting with credit is permitted.
to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
request permissions from permissions acm.org.
esec fse september paderborn germany association for computing machinery.
acm isbn .
.
.
.
on the foundations of software engineering paderborn germany september esec fse pages.
introduction mobile apps have become ubiquitous and drastically increased in number over the recent years.
as recent statistics shows over 50k new android apps are submitted to google play each month.
however it is challenging to guarantee their quality.
first they are event centric programs with rich graphical user interfaces guis and interact with complex environments e.g.
users devices and other apps .
second they are typically developed under the time to market pressure thus may be inadequately tested before releases.
when performing testing developers tend to exercise those functionalities or usage scenarios that they believe to be important but may miss bugs that their designed tests fail to expose.
to tackle this challenge many techniques have been proposed.
symbolic execution tracks the origins and handles of events at source code level and generates tests by exhaustively exploring program paths.
random testing fuzzes apps by generating a stream of random events.
evolutionary algorithm generates tests by randomly mutating and crossovering event sequences to fullfill their optimization goals.
model based testing mbt is another popular approach to automating gui testing which abstracts the app behaviors by a model and then derives tests from it to validate apps.
however exhaustively generating tests from a model to validate app behavior is overwhelming.
for example bites is a simple cookbook app shown in figure 2a with lines of code and its model has states and transitions generated by our approach .
this model can generate one event sequences two event sequences 567k three event sequences which are rather time consuming to execute.
due to this path explosion problem it is practically infeasible to derive all potential tests and execute them.
as a result traditional mbt techniques choose to generate random tests and use modellevel coverage criteria e.g.
covering all transitions as testing goals.
however without a strong guidance such tests are often redundant and ineffective to detect bugs.
in addition the previous research on model based gui testing only considers ui level events e.g.
click edit and disregards system level events e.g.
screen rotation incoming calls during testing.
without combining both types of events the effectiveness of mbt may be further limited due to inadequate testing.
245esec fse september paderborn germany t. su g. meng y. chen k. wu w. yang y. yao g. pu y. liu and z. su furthermore most apps are developed without models in practice.
despite much effort in manually or automatically constructing models to represent gui interactions mbt s effectiveness is still limited due to incomplete ui exploration.
for example as a recent extensive study shows the models produced by existing gui exploration tools achieve fairly low coverage only half of the coverage achieved by monkey .
the aforementioned challenges underline the importance of developing effective model based testing techniques to unleash its potential.
to this end we propose a novel stochastic modelbased testing approach stoat1 stochastic model app tester to improve gui testing of android apps.
it aims to thoroughly test the functionalities of an app from the gui model and validate the app s behavior by enforcing various user system interactions .
given an app as input stoat operates in two phases.
first it generates a stochastic model from the app to describe its gui interactions.
in our setting a stochastic model for an app is a finite state machine fsm whose edges are associated with probabilities for test generation.
in particular stoat takes a dynamic analysis technique enhanced by a weighted ui exploration strategy and static analysis to explore the app s behaviors and construct the stochastic model.
second stoat iteratively mutates the stochastic model and generates tests from the model mutants.
by perturbing the probabilities stoat is able to generate tests with various compositions of events to sufficiently test the gui interactions and purposely steers testing toward less travelled paths to detect deep bugs.
in particular stoat takes a guided search algorithm inspired by markov chain monte carlo mcmc sampling to search for good models discussed in section .
the derived tests are expected to be diverse as well as achieve high code and model coverage.
moreover stoat adopts a simple yet effective strategy to enhance mbt randomly inject various system level events into ui tests during mcmc sampling.
it avoids the complexity of incorporating system level events into the behavior model and further imposes the influence from outside environment to detect intricate bugs.
in all this paper makes the following contributions model construction .
stoat employs a dynamic analysis technique enhanced by a weighted ui exploration strategy and static analysis to effectively explore app behaviors and construct models.
the enhancement helps achieve significantly more complete models which can cover more code than the models generated by existing gui exploration tools.
fault detection .
we employ gibbs sampling an instance of mcmc sampling to guide stochastic model based testing.
on the open source apps stoat achieves satisfactory coverage and detects about 3x more unique crashes than the state of the art testing tools monkey and sapienz which clearly demonstrates the benefits of our approach.
in particular stoat detects more crashes by injecting system level events during mbt.
implementation and evaluation .
we have implemented stoat as an automated tool and further evaluated it on most popular apps from google play.
stoat detects unique crashes from apps.
so far crashes are confirmed as real faults and are already fixed.
the results show that stoat is effective in testing real world apps.
1the early idea of stoat named fsmdroid was presented in .
app2.
dynamic ui exploration devices weighted ui exploration phase .
model construction1.
static event identification .
test generation .
gibbs samplingtest suitephase .
model mutation test generation and execution7.
test executiontest coverage diversity bug checkerbug report8.
output measuremnts probability based test generation .
bug diagnosisstochastic fsmp1p6p4p3p2p50.
.
.
.
.
.
eventsstatesconstruct model initial stochastic fsm .
mutate probabilitiessystem level events6.
inject eventssystem level events3.
static analysis figure stoat s workflow.
approach overview stoat operates in a unique two phase process to test an app.
figure shows its high level workflow.
phase model construction.
stoat first constructs a stochastic finite state machine fsm to describe the app s behaviors.
it uses a dynamic analysis technique enhanced by a weighted ui exploration strategy step in figure to efficiently explore app behaviors.
it infers input events by analyzing the ui hierarchy of app pages and dynamically prioritizes their executions to maximize code coverage.
in addition to identify some potentially missing events a static analysis step is performed to scan the registered event listeners in the app code.
stoat records the execution frequencies of all ui events during exploration and later uses them to generate the initial probability values of the transitions in the model.
the details will be explained in section .
phase model mutation test generation and execution.
to thoroughly test an app stoat leverages the model from phase to iteratively guide test generation toward yielding high coverage and exhibiting diverse event sequences.
in detail stoat works as a loop randomly mutate the transition probabilities of the current stochastic model step generate the tests from the model w.r.t.
the probabilities step randomly inject system level events analyzed by static analysis in step into these ui level tests to enhance mbt step replay them on the app step and collect test results such as code and model coverage and event sequence diversities step .
informed by the test results stoat exploits gibbs sampling to decide whether the newly proposed model should be accepted or rejected step the model with better objective value will be accepted for the next iteration of mutations and samplings otherwise it will be rejected with certain probability to avoid local optimal if rejected the original model will be reused .
once any bug is detected i.e.
crash or non responding further analysis will be performed to diagnose the bug with the corresponding test step .
the details will be explained in section .
an illustrative example.
bites is a simple cookbook app shown in figure 2a that supports recipe creation and sharing.
a user can create a recipe by clicking the insert menu item in the recipes page page a .
when the user taps the name of a recipe the app navigates to the ingredients page page b where he she can 246guided stochastic model based gui testing of android apps esec fse september paderborn germany insertpreferencesingredientsrecipemethod a recipes add shopping listrecipemethodingredients insertsendpreferenceseggstomatoes b ingredients recipeingredientsmethod insert1 wash tomatoes c method e insert methodinsert methodcrack eggsokcancel d insert method insert method2slice tomatoesokcancel f exceptionokunfortunately bites hasstopped.step number a screenshots of a cookbook app bites .
recipesingredientsmethodmethodmenuinsertmethodingredientmenurecipesmenurecipe nameentry e4 p4 e5 p5 e1 p1 e3 p3 e2 p2 ...e18 p18 e17 p17 ......e6 s e7 p7 e10 p10 e8 p8 e9 p9 e12 p12 e13 p13 e11 p11 ...e16 p16 e15 p15 e14 p14 b app model of bites .
figure example app bites and its app model.
view or add ingredients share them via sms or add them into a shopping list.
the user can also switch to the method page page c where the cooking methods can be viewed.
by clicking the insert menu item the user can fill in step number andmethod page d .
figure 2b shows a part of the constructed app model for bites where each node denotes an app state and each edge a state transition associated with a probability value .
for example recipes can be navigated to ingredients when e6occurs i.e.
click a recipe item on the recipes page with the probability p6.
stoat generates ui level tests from this model and randomly injects system level events into them during gibbs sampling.
for example bites can be activated by sms and browser to read the recipes shared by others.
during testing stoat simulates these system level events by sending specific broadcast intents to bites .
stochastic model based testing .
stochastic model stoat uses a stochastic finite state machine fsm model to represent an app s behaviors.
formally a stochastic fsm is defined as a tuple m q s0 f where qand are the sets of app states and input events respectively s0 qthe starting app state f q the set of final states and q p q the probabilistic transition function.
p is the powerset operator and each transition is of the form s e s p meaning that the probability of an event etriggering a state transition from stos isp.
let an app state shave kevent transitions say e1 .
.
.
ei .
.
.
ek i k andpiis the probability value of ei.
for s pk i 1pi 1holds.
in our setting an app state sis abstracted as an app page represented as a widget hierarchy tree where non leaf nodes denote layout widgets e.g.
linearlayout and leaf nodes executable widgets e.g.
button when a page s structure and properties changes a new state is created e.g.
in figure 2a the recipes page and the ingredients page correspond to two app states .
if the app exits crashes the ending state is treated as a final state e.g.
page f .
an edge corresponds to an input event edenoting a ui action e.g.
click edit .
an app moves from one state sto another state s by handling an input event e. for example when the user presses the menukey on the recipes page a menu will pop up and a new app state corresponding to recipes menu is created.
a probability value p is assigned to each transition e denoting the selection weight of e in test generation.
the initial probability values are determined by the execution frequency of each event during model construction pis initially assigned the ratio of e s observed execution times over the total execution times of all events w.r.t.
s e s .
test generation from the model.
stoat adopts a probabilistic strategy to generate event sequences from a stochastic model.
it starts from the entry state s0 and follows the probability values to select an event from the corresponding app state until the maximum sequence length or the ending state is reached.
the higher the event probability value is the more likely the event will be selected.
.
model construction stoat adopts a dynamic ui exploration strategy enhanced by static analysis to construct the stochastic model for the app under test.
dynamic ui exploration.
an app can navigate among various pages with different uis to provide its functionalities.
in order to efficiently construct more complete behavior models of apps we investigated most popular google play apps from top categories e.g.
education business tools and manually explored as many functionalities as possible.
at last we summarized three observations that are crucial to improve the exploration performance which constitute the basis of our weighted ui exploration strategy frequency of event execution.
all ui events are given opportunities to be executed.
the less frequently an event is executed the more likely it will be selected during subsequent exploration.
type of events.
different types of events are not equally selected.
for instance compared with normal ui events e.g.
click navigation events e.g.
back scroll and menu are given different priorities to ensure they are triggered at right timing otherwise they may drastically undermine the exploration efficiency.
number of unvisited children widgets.
if an event solicits more new ui widgets on the next page it will be prioritized since more efforts should be spent on pages with new functionalities.
247esec fse september paderborn germany t. su g. meng y. chen k. wu w. yang y. yao g. pu y. liu and z. su to realize these rules stoat assigns each event ean execution weight which is adjusted dynamically at runtime.
the weight of an event is defined as execution wei ht e te ce fe where teis determined by its event type for normal ui events .
forback andscroll for menu cedenotes the number of unvisited children widgets feis its history execution frequencies and and are the weight parameters.
algorithm outlines the stochastic model construction process.
it takes an app as input and outputs its corresponding model m. the algorithm infers the invocable events efrom the current app page s according to the ui widgets on it and then adds them into an event list storing all events during the dynamic analysis lines .
for example in the app page insert method d in figure 2a since there are two edittext s step number and method and two button s ok and cancel the clickable properties of them are true stoat infers four events i.e.
edit step number edit method click ok and click cancel .
before each execution the weights of all events in the list will be updated w.r.t.
formula lines .
an event ewith the maximum weight computed by function getmaxweightevent on the page sis chosen to execute lines .
the function expandfsm accepts the returned state and the executed event to construct the model line .
at last all transitions of mare assigned with the initial probability values according to their observed execution times lines and .
during the ui exploration if the app enters into an unknown state e.g.
the app crashes exits becomes non responding or navigates to an irrelevant app after some event is executed restoreapp will be executed to restart the app or navigate the app back to the previous page lines .
this unknown state is taken as a final state.
this event will be added in tabu and excluded from further executions line to prevent affecting modeling efficiency.
static event identification.
the dynamic analysis technique typically infers events from the ui hierarchy dumped by android uiautomator which only captures static gui layout information.
however it may miss some dynamic events e.g.
amenu action of an activity that can only be invoked by pressing the menu key or some events that are programmed in the app code e.g.
alongclick action registered on a textview .
to further improve modeling capability algorithm uses static analysis to identify these potential events that are missed by dynamic analysis line .
it detects events by scanning the event listeners in the app code and then associates these events to the widgets observed at runtime via their unique resource ids.
stoat detects the events that are registered on ui widgets e.g.
setonlongclicklistener and implemented by overriding class methods e.g.
oncreateoptionsmenu .
model compaction.
the number of an app s states and transitions can be large or even unbounded .
to improve the testing efficiency stoat compacts the model by identifying only structurally different pages as different states and merges similar ones.
in detail the hierarchy tree of an state is encoded into a string and converted into a hash value for efficiently detecting duplicate states minor ui information e.g.
text changes e.g.
2the weight parameters are tuned during our investigation on the google play apps but are kept unchanged for all the apps during the final evaluation.algorithm app stochastic model construction input the app under test a output the stochastic model m 1letwbe a list of events initialized as empty 2letsbe the starting page of the app 3lett abu be a tabu event list initialized as empty 4w w ui events identified by static analysis 5repeat letebe the set of invocable events inferred from s w w e foreach event e wdo updateweight e lete getmaxweightevent e t abu s lets execute e tabu special events that trigger unknown states ifsis an unknown state then t abu t abu e restoreapp restart recover the app to the previous page m expandfsm s e 16until timeout 17return assignprobability m 18procedure assignprobability m 19s getappstates m s s1 ... si ... sn assign the initial probability values for each transitions of si 20foreach state si sdo ei getevents si ei e1 ... ej ... ek foreach transition ej eido pjis the probability value of the transition ej totaltimes getallexecutiontimes e1 ... ej ... ek pj getexecutiontimes ej totaltimes 25return m the contents of textview s edittext s and ui property changes e.g.
the checked property of radiobutton s checkbox s is omitted without creating new states listview s are only differentiated as empty and non empty.
for example in figure 2a the app pages d and e correspond to the same state since only the contents in edittext s are different.
guided stochastic model mutation stoat exploits gibbs sampling to guide the mutation of the stochastic model so that a set of representative tests can be generated.
in our setting we intend to find good models from which the test suites can achieve our desired goal.
we view this problem as an optimization procedure guided by our fitness function.
.
gibbs sampling gibbs sampling is a special case of the metropolis hastings algorithm .
the metropolis hastings algorithm is one of markov chain monte carlo mcmc methods which are a class of algorithms to draw samples from a desired probability distribution p x for which direct sampling is difficult.
it iteratively generates samples from a function that is proportional to the density of p x .
the sampling process generates a markov chain where the selection of the current sample only depends on the previous one.
248guided stochastic model based gui testing of android apps esec fse september paderborn germany after a number of iterations these samples can closely approximate the desired distribution p x allowing more samples are generated from more important regions the regions with higher densities .
during sampling a candidate sample will be accepted or rejected with certain probability and this probability is determined by comparing the values between the current and the candidate sample.
formally in the tthiteration the candidate sample x is generated w.r.t.
a proposal density q x xt and its acceptance ratio is acceptratio x min p x q x xt p xt q xt x usually qis selected as a symmetric function.
thus formula can be simplified to acceptratio x min p x p x .
objective function we designed an objective function favoring test suites that can achieve high coverage and contain diverse event sequences .
such test suites are expected to trigger more program states and behaviors and thus increase the chance of detecting bugs.
our objective function combines three metrics namely code coverage model coverage and test diversity .
code coverage measures how thoroughly the app code is tested model coverage measures how completely the app model is covered and test diversity measures how diverse the event sequences are in the test suite which is a significant complement for the coverage metrics.
the objective function is formalized as f t codecovera e t modelcovera e t testdiversity t where tis the test suite generated from a stochastic model m and are the weights on these metrics3.
here code coverage is computed as either statement coverage for open source apps or method coverage for closed source apps .
for model coverage we use edge coverage to compute how many events are covered.
for test diversity we designed a lightweight yet effective metric to evaluate the diversity of test cases.
let tbe an n size test suite l1 .
.
.
li .
.
.ln where liis an event sequence.
a k length event sequence lcan be denoted as e1 .
.
.ei .
.
.ek where eiis an event.
the key idea is to compute the centroid of these nsequences and take the sum of their euclidean distances with the centroid as the diversity value of t. intuitively the larger the distance is the more diverse tis.
first we use a binary vector to present each sequence.
let the model mhasneunique events.
the event ecan be presented as a n dimensional vector e 1 .
.
.
i .
.
.
ne where iis if the event eis the i th event in the event list otherwise the values are set in this way to avoid the orthogonality of two vectors .
second letlbe an length sequence represented as l e1 e2 en.
we use the function below to recursively transform linto a vector lon the basis of its events and their orders l cos sim l l ei l ei 3the values of and are respectively set to .
.
and .
in the evaluation which give more weights on code coverage and test diversity without any tuning.where l is the i length prefix of l i.e.
e1 e2.
.
.
ei and l e1.
we use the cosine similarity between l and l ei i.e.
cos sim l l ei to encode the order relation l eiinto the vector l. by this way we can take both the contained events and their orders into consideration when computing test diversity.
after we obtain the vector set for t l1 .
.
.
li .
.
.
ln the centroid coftcan be computed as c pn i 1 li n. last the test diversity is computed by the formula testdiversity t pn i 1d li c n to fit into the objective function we scale the test diversity into the range of by dividing ne.
.
gibbs sampling guided model mutation in our problem we choose gibbs sampling instead of the standard metropolis hastings algorithm because it is specially designed to draw samples when p x is a joint distribution of multiple random variables.
in particular we let all transition probabilities be random variables and draw samples by iteratively mutating them.
it allows samples to be drawn more often from the region with good stochastic models.
we hypothesize that tests derived from the optimized model can achieve higher objective values.
for this reason we set the target probability density function p x by following a common method as p m zexp f tm where mis the stochastic model and za normalizing partition function a constant tmthe test suite generated from the current model m and fthe objective function.
according to formula the acceptance ratio4of the newly proposed model m can be reduced to acceptratio m m min exp f tm f t m stochastic model mutation.
algorithm gives the algorithm of gibbs sampling guided testing.
the search space is the domain of stochastic models in which each sample is one stochastic model.
at each iteration a new candidate model m is generated by mutating the transitions probability values in the current model m. let the app have napp states s1 .
.
.
si .
.
.
sn and each state si i n have kevent transitions e1 .
.
.
ej .
.
.
ek.
stoat randomly decides whether to mutate the transition probabilities or not of each app state si lines .
if the state siis selected stoat will randomly mutate the original probability value pjof the transition ejto a new probability value p j which is the result of pj msize orpj msize .
the intuition is that the newly generated probability value p jis around pj it can be higher or lower than pj so that the new model m can generate very different event sequences compared with m. to speed up the convergence msize is set as a fixed value e.g.
.
in implementation.
for the remaining transition probabilities a similar procedure is applied but the constraint p .
.
.
p j .
.
.
p k still holds.
for the other unselected states their transition probabilities are kept unchanged so that the new 4 is empirically selected as .
in our problem which is tuned to effectively differentiate acceptance ratio.
249esec fse september paderborn germany t. su g. meng y. chen k. wu w. yang y. yao g. pu y. liu and z. su algorithm gibbs sampling guided gui testing input the app under test a its stochastic model m and the related system level events set ks input the maximum iteration of gibbs sampling imax 1repeat s getappstates m s s1 ... si ... sn mis randomly mutated to m foreach state si sdo ifrand .5then ei getevents si ei e1 ... ej ... ek foreach transition ej eido pj getprobability ej p j randomlymutate pj msize pj p j p j and p ... p j ... p k t generatetestsuite m t t ... t i ... t n t is randomly injected with system level events foreach event sequence t i t do ifrand .5then i getrandomeventindex t i es selectonesystemevent ks injectevent t i es i insert esinto the event position i execute a t ifacrashes or is non responding then record the error stack ifacceptratio m m rand then m m 21until imax is reached or timeout model m conditionally depends on the previous model mby those mutated probability values.
to simulate the interactions of environment stoat randomly injects system level events into the generated tests t from the mutated model m lines .
then t is replayed on the app to validate its behaviors.
the test results of t are used to determine the acceptance ratio of m .
ift can improve the objective value m will be mutated in the next iteration lines .
otherwise the original mis mutated.
the algorithm continues until the testing budget is exhausted.
if the app crashes or becomes non responding a suspicious bug is recorded lines and the corresponding error stack is dumped for bug diagnosis.
.
system level events to incorporate system level events into mode based testing stoat adopts a simple yet effective strategy by randomly injecting them into ui level event sequences.
this strategy avoids the complexity of including system level events into the behavior model and further interleaves both types of events to detect intricate bugs.
currently stoat supports three sources of system level events user actions i.e.
screen rotation volume control phone calls smss app switch system wide broadcast intents e.g.
battery level change connection to network to simulate system messages the events that the apps are particularly interested in which are usually declared by the tags intent filter and service in their androidmanifest.xml files.
evaluation the evaluation aims to answer the four research questions rq1.
model construction .
compared with the existing model construction tools for gui testing how effective is stoat?
rq2.
code coverage .
compared with the state of the art testing tools how is the coverage achieved by stoat?
rq3.
fault detection .
compared with the state of the art testing tools how is the fault detection ability of stoat?
rq4.
usability and effectiveness .
how is the usability and effectiveness of stoat in testing real world apps?
.
tool implementation stoat is implemented as a fully automated app testing framework which reuses and extends several tools android ui automator and android debug bridge adb for automating test execution soot and dexpler for static analysis to identify potential input events androguard for analyzing the system level events that the apps are particularly interested in.
stoat currently supports click touch edit generate random texts of numbers or letters navigation e.g.
back scroll menu .
during gibbs sampling stoat generates a test suite with the maximum size of tests and each with a maximum length of events at each sampling iteration.
stoat instruments open source apps by emma to get line coverage and instruments closed source apps by ella to get method coverage.
to improve scalability stoat is designed as a server client mode where the server can parallelly control multiple android devices.
stoat is online available at .
.
evaluation setup environment.
stoat runs on a bit ubuntu .
physical machine with cores .50ghz intel xeon r cpu and 32gb ram and uses android emulators to run tests.
each emulator is configured with 2gb ram and x86 abi image kvm powered and the kitkat version sdk .
.
api level .
different types of external files including jpgs mp3s mp4s vcfs pdfs txts zips are stored in the sdcard to facilitate file access from apps.
subjects.
we conducted three case studies.
in study and2 to set up a fair comparison basis we chose benchmark apps which have been widely used in previous research work .
these apps come from f droid a popular opensource app repository.
to further reduce the potential bias we enriched them by randomly selecting new apps from f droid.
so we totally evaluated on apps.
in study stoat is applied to test most popular apps from google play of various categories.
instudy we answer rq1 by comparing stoat with mobiguitar and puma .
both tools produce similar fsm models.
mobiguitar implements a systematic and a random exploration strategies for constructing models the former visits widgets in a breadth first order and restarts the app when no widgets can be found and the latter randomly emits ui events.
puma uses uiautomator to sequentially explore guis and stops exploring when all app states have been visited.
stoat is not compared with other modelbased tools because they are either unavailable e.g.
orbit and amola or crash frequently e.g.
swifthand .
we run each tool on one emulator and test each app for hour and measure the code coverage to approximate the completeness of 250guided stochastic model based gui testing of android apps esec fse september paderborn germany the constructed models which is the basis of model based testing.
we also record the number of states and edges in the models to measure the complexity.
intuitively the higher the code coverage the more compact the model is the more effective the tool is.
instudy we answer rq2 andrq3 by comparing stoat with these tools monkey random fuzzing a3e systematic ui exploration and sapienz genetic algorithm .
moneky a3e and sapienz are the state of the art gui testing tools.
they have the best performance in their own approach categories .
specifically monkey emits a stream of random input events including both ui and system level events to maximize code coverage.
a3e systematically explores app pages and emits events by a depthfirst strategy which is also widely adopted in other gui testing tools .
sapienz uses monkey to generate the initial test population and adapts genetic algorithms to optimize the tests to maximize code coverage while minimizing test lengths.
we allocate hours for each tool to thoroughly test each app on one single emulator.
stoat allocates hour for model construction and hours for gibbs sampling.
we record code coverage and the number of unique crashes .
to eliminate randomness we run each app for five times and take the average values as the final results.
during testing we identify crashes by monitoring logcat messages.
note each unique crash has a unique error stack unrelated crashes e.g.
errors from android system test harness and caught exceptions are excluded.
if a tool covers more code and detects more unique crashes it is more effective.
instudy we answer rq4 by running stoat on most popular apps from google play.
stoat run each app for three hours with the same configuration in study .
stoat instruments these apps at the method level to collect code coverage for gibbs sampling.
.
study model construction model completeness figure a shows the achieved line coveragew.r.t.
the models constructed by puma denoted by pu mobiguitar systematic m s mobiguitar random m r and stoat st on the subjects listed in the first column of table .
on average stoat covers and more code respectively than m s and m r and more than puma.
it indicates that stoat can cover more app behaviors and produce more complete models.
mobiguitar cannot exhaustively explore app behaviors due to its simple exploration strategies.
for example the systematic strategy is surprisingly much less effective than the random strategy since it visits uis in a fixed order breadth first and wastes much time on restarting the app when no new ui widgets are found.
puma continues the exploration until all different app states have been visited which can save the exploration efforts but may also miss new ui pages due to its abstraction of states is too coarse.
model complexity figures b and c show the size of the models in terms of the number of states and transitions note the y axis uses a logarithmic scale .
we can see stoat achieves much higher code coverage than the other tools indicated by figure a but its models are more compact without states explosion figure b .
in addition stoat captures more app behaviors events one transition denotes one event in figure c than the other tools which indicates its models are more complete.
in detail mobiguitartable testing results on open source apps.
subject coverage crashes name eloc a m sa st a m sa st a2dp aarddict alogcat amazed anycut baterrydog swiftp book catalogue bites battery addi alarmclock manpages mileage autoanswer hndroid multismssender worldclock nectroid acal jamendo aka yahtzee aagtl counterdowntimer sanity dalvik explorer mirrored dialer2 divideandconquer fileexplorer gestures hotdeath adsdroid mylock lockpatterngenerator mnv agrep k9mail lolcatbuilder munchlife myexpenses lnm netcounter bomber frozenbubble fantastichmemo blokish zooborns importcontacts wikipedia passwordmaker passwordmanager photostream quicksettings randommusicplayer ringdroid soundboard spritemethodtest spritetext syncmypix tippy tomdroid translate triangle weight chart whohasmystuff wordpress babycaretimer yaab campyre urlazy arxiv h2droid cetoolbox currencyconverter charmp nanoconverter anarxiv kindmind urforms homemanager pockettalk rot13 angulo rightalert apptrack textedit diary rtltcp fakedawn klaxon imcktg3576 determines the equivalence of app states on the basis of the properties ids and types of their constitutive ui objects while puma differentiates states according to their ui features e.g.
the number of invocable events .
however these criteria are too coarse to construct representative models.
in contrast stoat uses the ui layout structures to decide the state similarity and merges states with neglectable differences.
therefore the models constructed by stoat would be more effective for gibbs sampling.
251esec fse september paderborn germany t. su g. meng y. chen k. wu w. yang y. yao g. pu y. liu and z. su line coverage model states0 pum sm rstpum sm rststm sm rpu a line coverage b model states c model transitions model transitions figure results of model construction.
line coverage d n dssv e n .
dssv f !
.
dssv g doo dssvastsamastsamastsamastsam figure results of code coverage grouped by app sizes.
.
study testing effectiveness code coverage table lists subjects and their executable lines of code eloc and shows the testing results of a3e a monkey m sapienz sa and stoat st in terms of line coverage and the number of unique crashes best results are highlighted .
on average they achieve and line coverage respectively.
in particular stoat achieves nearly higher coverage than a3e.
figure shows the line coverage of these tools grouped by app sizes.
it is clear that stoat has the best performance.
a3e achieves much lower coverage than the other three tools for two main reasons.
first a3e explores uis in a depth first order.
although this greedy strategy can reach deep ui pages at the beginning it may get stuck because the order of event execution is fixed at runtime.
second a3e does not explicitly revisit previously explored uis and thus may fail in covering new code that should be reached by different sequences.
we also note monkey s coverage is close to sapienz s when given enough testing time hours .
unique crashes table summarizes the statistics of the four tools in detecting app crashes.
stoat has detected unique crashes from buggy apps which is much more effective than a3e crashes monkey crashes and sapienz crashes .
we also find stoat has detected all the crashes that were found by a3e.
fig.
gives the pairwise comparison of crashes detected by monkey sapienz and stoat.
we can see the crashes detected by stoat have much less overlap with monkey and sapienz.
in detail stoat detected exclusive and crashes than monkey and sapienz respectively.
the crashes detected by monkey and sapienz are close in number and they have more overlap bugs are detected by both .
the fact that sapienz uses monkey to generate the initial population of event sequences may explain this phenomenon.
method of calculating unique crashes stoat identifies unique crashes in an accurate way remove all unrelated exceptions without the keyword of the app s package name extract the exception lines from the crash stack of the app use these lines to identify unique crashes.
different crashes should have different sequences of exception lines.
however we find sapienz simply uses text differences to count unique crashes which is inaccurate andtable testing statistics of a3e monkey sapienz and stoat.
tool buggy apps unique crashes a3e monkey sapienz stoat8 sapienz stoat monkey stoat monkey sapienz figure pairwise comparison of tools in detecting crashes.
thus may bring false positives.
to set up a fair comparison basis we modified sapienz s scripts to follow our method.
.
bug analysis to further investigate the effectiveness of stoat we analyzed several typical crashes that were found by stoat but missed by monkey and sapienz.
we summarized the following key findings.
finding stoat is more effective in ui exploration.
both stoat and sapienz are two phase testing techniques.
sapienz uses monkey to generate the initial population of event sequences including both ui and system level events before genetic optimization while stoat constructs app models only by ui events before gibbs sampling.
in figure a we show the coverage achieved by sapienz denoted by sa and stoat st on the subjects in their respective initial phases i.e.
the population generation phase and the model constructionphase .
by default setting sapienz and stoat on average take and minutes to finish the initial phase and require and minutes to reach peak coverage respectively.
we can see that stoat achieves higher coverage than sapienz which enables stoat to detect more crashes in the optimization phase.
for example stoat detects a cursorindexoutofboundsexception in the app bites figure 2a during model construction.
this crash can be revealed by a long event sequence create a recipe fill in names authors and descriptions long touch on it and then select the option of send by sms from the other fours.
however sapienz has never reached this usage scenario in the initial phase due to its randomness.
by utilizing this captured behavior stoat further detects a new crash during gibbs sampling which can only be revealed when the user fills the ingredients of this recipe but leaves its cooking methods empty and sends it by sms.
however sapienz has never detected this new crash during optimization.
finding stoat is more effective in detecting deep crashes.
both stoat and sapienz use optimization techniques to guide test generation.
however sapienz generates new tests by randomly crossovering and mutating sequences.
it may produce many infeasible ones and is less likely to reach deep code.
in contrast stoat guides test generation from an app s behavior model captures all possible compositions of events which is more likely to generate meaningful and diverse sequences to reveal deep bugs.
for example textedit is a text edit app.
stoat exposes a nullpointerexception by following a length event sequence.
252guided stochastic model based gui testing of android apps esec fse september paderborn germany sapienz stoat stoat wo sys a line coverage achievedin the initial phasesast b unique bugs detected in different phases unique crashesline coverage2246664583739initial phaseopt.phasebothphase133 figure comparison between sapienz and stoat the exception is thrown when a non existing file is accessed after the default file name prefix sdcard is removed.
the code snippet below shows when the user tries to access a non existing file the app will remind that the file cannot be found the case dialog notfound error at lines and reopen the previous dialog to accept new file names the case dialog open file at lines .
however the variable errorfname stores the previous non existing file name e.g.
test .
thus the app will call getparent at line and return null because the file does not exist.
the next call to tostring crashes the app.
the dialog for opening files case dialog open file i f o p e n i n g e r r o r f i l e f new f i l e errorfname .
t o s t r i n g i f f .
t o s t r i n g .
e q u a l s .
.
.
else i f f .
i s d i r e c t o r y .
.
.
else i f f.getparent .tostring .
e q u a l s .
.
.
.
.
.
the dialog for file not found case dialog notfound error .
.
.
showdialog dialog open file .
.
.
as figure b shows stoat detects many more crashes than sapienz in the optimization phase vs. .
the numbers of crashes in their initial phases are close but sapienz generates both ui and system level events while stoat only generates ui events.
finding system events can reveal more unexpected crashes.
during gibbs sampling stoat randomly injects system level events into ui level event sequences to enhance mbt.
as figure b shows by this enhancement stoat can detect additional crashes see the stoat and stoat wo sys columns in the optimization phase .
for example the app mileage was crashed by illegalar gumentexception when stoat launches its chart activities and sends them empty intents.
the app directly takes the null values to make database queries without any sanitization.
from the above analysis we can see stoat is more effective than the other tools in bug detection.
the models help stoat generate more meaningful event sequences and the tests are effectively guided to reach different corner cases.
however monkey sapienz can also detect some crashes that stoat cannot find.
we summarized two main reasons monkey supports irregular actions e.g.
pinchzoom flip which have not been included in our app models monkey can reveal some stress testing bugs it continuously emits events without waiting the previous ones take effect e.g.some concurrency crashes illegalstateexception s triggered by the synchronizations between listview s and their data adapters some illegalargumentexception s triggered bytable distribution of the detected crashes by stoat in google play apps.
id exception type number nullpointerexception windows leaked exception activitynotfoundexception sqlite related exception illegalstateexception illegalargumentexception runtimeexception classcastexception unsatisfiedlinkerror windowmanager badtokenexception other exceptions the mismatches of service binding unbinding due to quick switches of activity lifecycle callbacks and some outofmemoryerror s. .
study usability on real world apps to further validate the usability of stoat we apply it on the most popular apps from google play.
stoat was run on physical machines with emulators and phones allocate hours per app .
in one month it successfully tested apps and detected unique unknown crashes from apps crashes from model construction crashes from gibbs sampling and crashes are detected in both phases.
we have sent all the bug reports to the developers.
so far developers have replied that they are investigating our reports excluding auto replies .
of our reported crashes have been confirmed and have already been fixed.
table shows the parts of bugs found by stoat where we list the app names the categories the installations the crash types the brief descriptions of root causes and their statuses confirmed or fixed .
during the evaluation we totally found different types of crashes.
table shows the distribution of their numbers.
we can see nullpointerexception is the most common type of exceptions which aligns to previous case studies .
.
limitations and threats to validity stoat has some limitations.
first during testing stoat emits an event waits until it takes effect and then emits the next one.
this synchronization ensures test integrity but it may miss those bugs that can only be manifested by swift actions.
second stoat may generate infeasible event sequences from models.
to mitigate this problem stoat locates ui widgets by object indexes instead of some volatile properties e.g.
texts and skips events when the target ui cannot be located.
third the models produced by stoat are still not complete since it cannot capture all possible behaviors during ui exploration which is still an important research goal on gui testing .
for example stoat is ineffective on the apps with irregular gestures e.g.
pinchzoom drawing and specific input data formats.
future work may integrate symbolic execution string analysis or learning algorithm to tackle such issues.
we mitigate threats to validity in two aspects eliminate false positives by excluding irrelevant crashes and collecting unique ones manually inspecting all crashes from open source apps and refining crash reporting via developer feedback on the submitted crash reports.
apply each testing tool on each app multiple times to mitigate algorithm randomness future work may adopt statistical analysis to further strengthen the results .
253esec fse september paderborn germany t. su g. meng y. chen k. wu w. yang y. yao g. pu y. liu and z. su table parts of bugs found by stoat and confirmed as real faults.
id app name category installation crash exception description status p news 10m 50m nullpointerexception unable to destroy the premiumsettingsactivity activity confirmed m wallpapers 1m 5m instantiationexception fail to instantiate the cropimageview activity fixed pi pictures 1m 5m sqlitecantopendatabaseexception fail to open database files when an activity is launched confirmed a photography 50m 100m staledataexception attempted to access a database cursor after it has been closed fixed n email 1m 5m nullpointerexception unable to start the timechangereceiver receiver fixed ni navigator 5k 10k networkonmainthreadexception attempted to perform a networking operation on the main application thread confirmed z utility tool 10m 50m serviceconnectionleaked forget to call unbind to release the service resource fixed i browser 1m 5m nullpointerexception unable to start the orbotactivity activity confirmed c pictures 10m 50m activitynotfoundexception no activity found to handle the specified intent in the activity of imageselectactivity fixed a alarm clock 5m 10m windowmanager badtokenexception unable to add window when the checkshareservice notifies users from background fixed re life style 10m 50m indexoutofboundsexception access invalid index in the bottomsheet list fixed pl video 1m 5m nullpointerexception an error occured while executing invideossearchactivitytask confirmed he health 1m 5m nullpointerexception unable to start the activity of setweightgoalsuccessactivity fixed pt game 50m 100m activitynotfoundexception unable to find the explicit activity class mraidactivity confirmed t utility tool 10m 50m classcastexception android.text.spannablestring cannot be cast to java.lang.string confirmed related work model based gui testing.
model based testing mbt is a widely used testing approach.
one important task is to extract a suitable abstract behavior model for the system under test .
however in gui testing manually constructing models is timeconsuming and error prone .
extensive research has created several tools to automate this process.
android guitar uses event flow graph which only consists of events.
this graph usually generates many infeasible event sequences and reduces the effectiveness of mbt.
androidripper mobiguitar an extension of the former orbit and amola use state machines to represent app models.
however they achieve simple ui exploration e.g.
depth breadth first and thus their performance is limited.
swifthand uses machine learning techniques to dynamically learn models for apps but its aim is to improve the exploration strategy and reduce app restarts.
monkeylab records the execution traces from app users to mine statistical language models but aims to generate replayable event sequences.
another important activity in mbt is to generate tests from models.
traditional approaches employ graph traversal algorithms to generate tests and then fulfill various coverage metrics .
amalfitano et al.
randomly generate tests from models to satisfy pairwise coverage for apps.
nguyen et al.
combine modelbased testing and combinatorial testing and enhance the tests with domain input specifications.
brooks et al.
use probabilistic fsm models populated by software usage profiles to do regression testing of desktop applications.
hierons et al.
use an extended stochastic model to describe non deterministic systems and generate tests from the mutated models to check the conformance between system specifications and their implementations.
compared with these approaches stoat uses stochastic fsm models populated by execution profiles to generate tests.
the tests are iteratively optimized to detect app bugs with the feedback from test execution.
stoat further enhances mbt by injecting system level events which has not been considered by previous work.
other approaches also exist for app testing.
symbolic execution exhaustively explores program paths to test apps.
dynodroid enforces random testing enhanced with ui exploration heuristics to achieve gui testing.
appdoctor randomly invokes event handlers in the code rather than faithfully emitting events on the app screen to test the robustness of apps.
evodroid uses evolutionary algorithms to generate high coveragegui tests.
trimdroid optimizes combinatorial testing for app testing with smaller but effective test suites.
mcmc sampling driven testing.
markov chain monte carlo mcmc sampling techniques have been used for several software testing problems .
zhou et al.
propose a markov chain monte carlo random testing mcmcrt approach to enhance traditional random testing.
it utilizes the bayes approach to parametric models for testing and uses the prior knowledge and previous testing results to estimate parameters.
this technique can also improve the performance of random testing and prioritize test case selection .
chen and su introduce mucert an approach that adopts mcmc sampling to optimize test certificates for testing certificate validation in ssl tls implementations.
the test suite is generated and mutated to achieve higher coverage and reveal more discrepancies.
mcmc sampling is also used to guide fuzz testing of jvms startup process where mutators are selected on the basis of prior knowledge.
le et al.
adapt mcmc sampling to generate diverse program variants for finding deep compiler bugs.
compared with these mcmc based testing approaches stoat advocates the novel effective idea of mutating the app model so that tests derived from the model are diverse and lead to high code coverage.
conclusion we have introduced stoat a novel automated model based testing approach to improving gui testing.
stoat leverages the behavior models of apps to iteratively refine test generation toward high coverage as well as diverse event sequences.
our evaluation results on large sets of apps show that stoat is more effective than stateof the art techniques.
we believe that stoat s high level approach is general and can be fruitfully applied in other testing domains.