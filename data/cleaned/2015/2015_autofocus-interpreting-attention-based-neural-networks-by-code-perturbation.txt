autofocus interpreting attention based neural networks by code perturbation nghi d. q. bui school of information systems singapore management university dqnbui.
phdis.smu.edu.sgyijun yu school of computing communications the open university milton keynes uk y.yu open.ac.uklingxiao jiang school of information systems singapore management university lxjiang smu.edu.sg abstract despite being adopted in software engineering tasks deep neural networks are treated mostly as a black box due to the difficulty in interpreting how the networks infer the outputs from the inputs.
to address this problem we propose autofocus an automated approach for rating and visualizing the importance of input elements based on their effects on the outputs of the networks.
the approach is built on our hypotheses that attention mechanisms incorporated into neural networks can generate discriminative scores for various input elements and the discriminative scores reflect the effects of input elements on the outputs of the networks.
this paper verifies the hypotheses by applying autofocus on the task of algorithm classification i.e.
given a program source code as input determine the algorithm implemented by the program .
autofocus identifies and perturbs code elements in a program systematically and quantifies the effects of the perturbed elements on the network s classification results.
based on evaluation on more than programs for different sorting algorithms we observe that the attention scores are highly correlated to the effects of the perturbed code elements.
such a correlation provides a strong basis for the uses of attention scores to interpret the relations between code elements and the algorithm classification results of a neural network and we believe that visualizing code elements in an input program ranked according to their attention scores can facilitate faster program comprehension with reduced code.
index t erms attention mechanisms neural networks algorithm classification interpretability explainability code perturbation program comprehension i. i ntroduction deep learning techniques have been adapted for various software engineering tasks such as code completion bug prediction and program classification .
despite high prediction accuracies achieved deep neural networks are mostly treated as black boxes without explanation on why certain outputs are generated for certain inputs so that users lack of confidence in the results.
attention mechanisms have been proposed for neural networks to focus on certain input elements or features when making predictions and such elements or features are assumed to reflect certain interpretability of the networks.
however in many cases the features getting higher attentions may be implicit and the prediction outputs of the attention networks according to the features may disagree with human users understanding .
in this work we aim to justify and improve the interpretability of attention based neural networks with the autofocus approach.
the key idea of the approach is to reveal correlations between inputs and outputs of attention networks by perturbing inputs and observing the effects of perturbed inputs on the outputs.
in this paper we apply autofocus tothe attention networks trained for algorithm classification i.e.
networks that classify the algorithm implemented in a given input program .
it helps correlate attention scores of certain code elements e.g.
statements in a program with the importance of the elements in determining the program s algorithm class.
such a correlation provides us a strong basis for using attention scores of individual statements as a metric to visualize a program and helps users in interpreting the networks prediction outputs and understanding the program with increased focus saving the need to read through all code.
we combine two techniques to realize autofocus syntax directed attention we adapt attention mechanisms into the neural networks in the context of algorithm classification and generate attention scores for syntactically meaningful elements in input programs e.g.
statements instead of arbitrary elements code perturbation we systematically perturb input programs syntactically e.g.
deleting statements one by one to observe how the perturbations affect neural networks classification outputs and relate to the attention scores.
with respect to tree based and graph based algorithm classification neural networks tbcnn and ggnn our key research question here is can the syntax directed attention scores be used as a proxy to interpret the decisions made by the neural networks?
with evaluation on more than programs implementing different sorting algorithms we positively show that the attention scores of individual statements are strongly correlated with the effects of the statements on the classification results and thus can be used to interpret the input output behaviour of the networks.
furthermore the statements in a program can be visualized according to their attention scores to facilitate more focused and faster code comprehension.
more generally the interpretability produced by the autofocus approach technically only depends on the availability of attention scores and the interpretability of code elements that follow certain syntax and thus autofocus is likely applicable to many other neural networks for various code learning tasks.
ii.
r elated work interpretability is important for software mining and analysis in general .
in other domains various techniques have been proposed to interpret machine learning results such as by projecting outputs of cnn models through hidden neurons to input image pixels by quantifying the effects of different 34th ieee acm international conference on automated software engineering ase .
ieee authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
e e d d e e k s nj w w d w fig.
.
overview of autofocus approach compositions of english sentences on nlp models and by perturbing inputs for black box neural networks .
our work is unique in that it adapts the ideas of attention mechanisms and code perturbation to interpret the input output effects of algorithm classification neural networks via identification and visualization of meaningful code elements.
iii.
a uto focus approach overview figure gives an overview of the six major steps in autofocus.
next section explains the steps in more details.
training of attention based neural networks we add additional aggregation layers in conventional classification neural networks to generate attention scores for input elements using a global attention mechanism .
given training programs we obtain trained attention networks.
generation of classification confidence score c p for a test program pand attention scores a s for each suitable code element sinp given a test program p the classification confidence score c p is derived from the softmax layer of the attention networks indicating the likelihood for pto belong to a certain class.
for multi class classification tasks e.g.
there is a confidence score for each class while the correct class for poften but not necessarily has the highest confidence score.
in this work we always take the confidence score produced by the trained networks for the correct class of pas thec p .
meanwhile the attention networks produce an attention score for each input element and we aggregate the scores according to p s syntactical structure and produce an attention score for each statement sinp denote as a s .
perturbation of test program s each test program pis modified into a set of perturbed programs p prime p prime s wherep prime sindicates a perturbed program by deleting the statement sfromp.
for each perturbed program p prime s w e apply the attention networks to predict its class and obtain a new confidence score c p prime s .
impact measurement of perturbing statements g i v e n a set of perturbed programs p prime s we have a set of classification confidence scores c p prime s .
the differencesbetweenc p and c p prime s are denoted as p s c p prime s c p s p .
intuitively a higher s may indicate a statement sthat has more impact on the networks classification accuracies and thus may be more important.
correlating statement level attention scores a s and perturbed confidence scores s we analyze the pearson correlation coefficients between the two kinds of scores for various test programs so that we may use the perturbed classification confidence scores to justify the uses of attention scores to interpret the classification decisions made by the attention networks.
visualization of statements given the attention scores a s and perturbed confidence scores s as a proxy for the importance of individual statements in a program p we visualize pwith a spectrum of derived colours to facilitate focused view on more important statements for program comprehension.
iv .
a uto focus details a. building attention neural networks we choose state of the arts tree based and graph based neural networks for they yield accurate outputs for algorithm classification.
fig.
.
attention mechanism as the aggregation layer for the neural network figure illustrates the process of adding attention layers for algorithm classification neural networks.
first source code is parsed as an ast and a graph by connecting tree nodes to dependent ones.
then the neural networks are used as a feature extractor to update the information of each node following the edges.
an aggregation layer is used to combine the information about all of the nodes into one single vector as the representation for the code see section iv b .
since a graph is a more general form of a tree we summarize the design principle of both tbcnn and ggnn with graph notations.
a graph g v e x is composed of a set of nodes v a set of node features x and a list of directed edge sets e e1 ... ek wherekis the number of edge types.
initially we annotate each node v vwith a realvalued vector xv rdrepresenting the features of the node.
the node features xcome from a pretrained embedding .
we associate every node vwith a hidden state vector hv initialised from pretrained feature embedding xv.
the process of attention networks can be split into the feature extraction and the aggregation phases.
the feature extraction phase aims to propagate information from a node vto its neighbor.
specifically authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
the input to tbcnn is ast which is an undirected graph.
a function fconvo aggregates the information of the direct children of a node vto update its state vector hv fconvo hchildren ofv .
this process runs through a few time steps to update the state vector hvof nodev.
the input to ggnn is a graph representation of the ast plus additional edge types.
ggnn can be described as a message passing network where the messages of type kare sent from a node vto its neighbor u. herekrefers to the type of edges in the edge set ek.
the new state of the node vis computed from its current state vector its neighbor and the edge as hv fk hv hu ek whereek is the edge of type k. we choose a linear function for fk the same as .
once feature extraction finishes we have a matrix of dimensionm n wheremis the number of nodes and nis the length of node feature embeddings.
then the aggregation phase combines the hidden state vectors of all nodes in the graph into one single vector which computes a feature vector for the whole graph or tree using an aggregation function r such that y r hv v g andyis a vector of dimension n.rcan be a max pooling function which takes the max value of the features.
however it lacks the interpretability as one does not know which node contributes more to the classification result.
as such we use an attention mechanism as the aggregation function instead.
the attention layer will assign a score for each node in the input graph to represent its importance which may lead to better interpretability.
aggregation using attention mechanism formally a global attention vector a rdis initialised randomly and learned simultaneously with updates of the networks.
given n node state vectors h1 ... h n the attention weight iof each hiis computed as the normalised inner product between the node state vector and a i exp hit a summationtextn j 1exp hjt a .
the exponents are used to make the attention weights positive and they are divided by their sum to have max value of a s done by a standard softmax function.
an aggregated code vector y rdrepresents a whole code snippet.
the vector is a linear combination of the state vectors h1 ... h n of all nodes contained in the code weighted by their attention scores code vector y summationtextn e 1 e he.
objective function when training our networks for algorithm classification we use the cross entropy as the objective function.
it is defined as j x c summationtext logexp xc summationtext jexp xj where denotes parameters of all the weight matrices in our model xis the predicted classification vector for all the class labels and cis the true label.
b. deriving statement level attention scores the purpose of this step is to derive attention scores for code elements at specific levels of granularity.
in this work we consider the statement level .
the attention score for a statement node in an ast is obtained by a simple summation of the attention scores of all children of the statement node.
for later visualization of the program source code section iv d we also need to map the attention scores of statement nodes tothe actual tokens in the statements.
when a token belongs to multiple nested statements the attention score of the closest enclosing statement is used as the score for the token.
c. code perturbation the purpose of this step is to evaluate the effect of each code element on the networks classification results.
here we focus onperturbing statements in a program because a statement may be a reasonable level of granularity for developers to examine and understand and because a recent study shows that splitting asts at the statement level achieves better learning results than some other granularity levels.
we work on trees and graphs to perturb statements we traverse the ast of a program to identify the node sequence corresponding to statements in a post order and mutate the trees and relevant graphs to delete the statement nodes and related edges one by one.
for simplicity in this paper when a statement is deleted all nested substatements are also deleted.
although the deletion can introduce compilation errors in the programs e.g.
undeclared variables the tree or graph based neural networks can still be applied to the perturbed trees and graphs.
to limit the time needed for exploring the deletion of various combinations of statements we delete statements in the greedy post order and only backtracks one statement when deleting the current statement leads to a wrong classification.
d. visualisation we transform the attention scores of statements into colors to be shown on the foreground of the code tokens contained in the statements.
the rules of thumb for the color transformation is to ensure that the statements with higher attention scores get a higher contrast to the background color.
many color transformation schemes are possible.
in this work we use the grey scale to present colors from white attention to black attention .
since the score of each node ranges from to when we choose the sigmoid function for non linearity the darkness increases when the score is increased and vice versa.
v. e mpirical ev aluation we verify the capability of autofocus with respect to a graph based neural network trained for multi class algorithm classfication .
the data for the evaluation consists of unique java programs crawled from github for distinct sorting algorithms where about of the programs were used for training for validation and for testing.
first the settings described in ggnn are used to train a model of accuracy on the test programs the model is used as the ground truth for interpretation.
then we follow the steps in section iii to derive attention scores and deltas of deleting statements for each test program.
after that we conducted a statistical analysis on the correlation between the deltas and the attention scores of the statements deleted by code perturbation.
following step in section iii we obtain the pearson correlation ratio for each test program.
for all the test programs a list of pearson correlation ratios can be seen as a discrete variable p. figure shows the histogram of authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
fig.
.
histogram of pearson correlation coefficients of all test data fig.
.
autofocus visualization of attention scores in visual studio code p whose mean value is .65and standard deviation is .
.
this indicates a strong correlation between the attention scores and the deltas.
based on the intuition that statements are a reasonable granularity for developers to understand a program the strong correlation gives us a basis to use attention scores to interpret neural networks and build code visualizations for more focused views to facilitate program comprehension.
figure exemplifies the visualization of attention scores of statements inside visual studio code ide.
the left pane visualizes the statements according to their attention scores.
the higher the attention score the darker color the statement gets.
the right pane visualizes the statements according to their deltas which are similar but slightly different.
vi.
t hreats to validity f uture work our preliminary evaluation is limited and much future work can be performed to alleviate various threats to validity.
we only evaluate autofocus for algorithm classification.
the evaluation can go beyond tbcnn and ggnn to many other neural networks and other software engineering tasks such as bug prediction code search code summarization.
evaluations with real programmers can be more convincing in validating whether autofocus results match the actual importance viewed by human.
the attention scores and code perturbation can be applied to code granularity levels beyond statements such as expressions conditions functions files components and program slices for different code analysis tasks.
the current perturbation deletes one statement at a time.
it may be better to delete multiple code elements at once so that one can identify the minimal amount of code needed for correct algorithm classification.
more model visualization and interpretability techniques beyond attention scores e.g.
lime and gradient basedmeasures can be incorporated into autofocus too.
vii.
c onclusions this paper proposes autofocus a method to interpret the inference of a deep attention neural network for code learning tasks.
the approach is new in adapting attention mechanisms into an algorithm classification neural network to generate attention scores for individual statements in an input program and inducing syntax directed code perturbation to observe the effects of individual statements on the network s classification outputs.
it then shows that these two independently derived metrics have a strong correlation and can be used to produce a spectrum visualization of the perturbed program as a recommendation for programmers to identify the most relevant code elements when viewing the program.
acknowledgment this research is supported by the singapore ministry of education moe academic research fund acrf tier grant from sis at smu and epsrc and eu at the open university.
we also thank the anonymous reviewers for their insightful comments and suggestions for improving the paper.