ifixr bug report driven program repair anil koyuncu1 kui liu1 tegawend f. bissyand 1 dongsun kim1 martin monperrus3 jacques klein1 and yves le traon1 1university of luxembourg luxembourg anil.koyuncu kui.liu tegawende.bissyande jacques.klein yves.letraon uni.lu 2furiosa.ai republic of korea darkrsw furiosa.ai 3kth royal institute of technology sweden martin.monperrus csc.kth.se abstract issue tracking systems are commonly used in modern software development for collecting feedback from users and developers.
an ultimate automation target of software maintenance is then the systematization of patch generation for user reported bugs.
although this ambition is aligned with the momentum of automated program repair the literature has so far mostly focused on generate andvalidate setups where fault localization and patch generation are driven by a well defined test suite.
on the one hand however the common yet strong assumption on the existence of relevant test cases does not hold in practice for most development settings many bugs are reported without the available test suite being able to reveal them.
on the other hand for many projects the number of bug reports generally outstrips the resources available to triage them.
towards increasing the adoption of patch generation tools by practitioners we investigate a new repair pipeline ifixr driven by bug reports bug reports are fed to an ir based fault localizer patches are generated from fix patterns and validated via regression testing a prioritized list of generated patches is proposed to developers.
we evaluate ifixr on the defects4j dataset which we enriched i.e.
faults are linked to bug reports and carefullyreorganized i.e.
the timeline of test cases is naturally split .
ifixr generates genuine plausible patches for defects4j faults with its ir based fault localizer.
ifixr accurately places a genuine plausible patch among its top recommendation for of these faults without using future test cases in generation and validation .
ccs concepts software and its engineering software verification and validation software testing and debugging.
keywords information retrieval fault localization automatic patch generation.
acm reference format anil koyuncu1 kui liu1 tegawend f. bissyand 1 dongsun kim1 martin monperrus3 jacques klein1 and yves le traon1.
.
ifixr bug report corresponding author the same contribution as the first author.
permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
copyrights for components of this work owned by others than acm must be honored.
abstracting with credit is permitted.
to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
request permissions from permissions acm.org.
esec fse august tallinn estonia association for computing machinery.
acm isbn .
.
.
.
program repair.
in proceedings of the 27th acm joint european software engineering conference and symposium on the foundations of software engineering esec fse august tallinn estonia.
acm new york ny usa pages.
introduction automated program repair apr has gained incredible momentum in the last decade.
since the seminal work by weimer et al.
who relied on genetic programming to evolve program variants until one variant is found to satisfy the functional constraints of a test suite the community has been interested in test based techniques to repair programs without specifications .
thus various approaches have been proposed in the literature aiming at reducing manual debugging efforts through automatically generating patches.
beyond fixing syntactic errors i.e.
cases where the code violates some programming language specifications the current challenges lie in fixing semantic bugs i.e.
cases where implementation of program behavior deviates from developer s intention .
ten years ago the work of weimer et al.
was explicitly motivated by the fact that despite significant advances in specification mining e.g.
formal specifications are rarely available.
thus test suites represented an affordable approximation to program specifications.
unfortunately the assumption that test cases are readily available still does not hold in practice .
therefore while current test based apr approaches would be suitable in a test driven development setting their adoption by practitioners faces a simple reality developers majoritarily write few tests write tests after the source code and write tests to validate that bugs are indeed fixed and will not reoccur .
although apr bots can come in handy in a continuous integration environment the reality is that bug reports remain the main source of the stream of bugs that developers struggle to handle daily .
bugs are indeed reported in natural language where users tentatively describe the execution scenario that was being carried out and the unexpected outcome e.g.
crash stack traces .
such bug reports constitute an essential artifact within a software development cycle and can become an overwhelming concern for maintainers.
for example as early as in a triager of the mozilla project was reported in to have commented that everyday almost bugs appear that need triaging.
this is far too much for only the mozilla programmers to handle.
however very few studies have undertaken to automate patch generation based on bug reports.
to the best of our knowledge liu et al.
proposed the most advanced study in this direction.
unfortunately their r2fix approach carries several caveats as illustrated in figure it focuses on perfect bug reports arxiv .05620v1 jul 2019esec fse august tallinn estonia a. koyuncu et al.
r2fix automatically generating bug fixes from bug reportschen liu jinqiu yang and lin tanuniversity of waterloo on canada c92liu j223yang lintan uwaterloo.camunawar hafizauburn university al usamunawar auburn.eduabstract many bugs even those that are known anddocumented in bug reports remain in mature software fora long time due to the lack of the development resources to fixthem.
we propose a general approach r2fix to automaticallygenerate bug fixing patches from free form bug reports.
r2fixcombines past fix patterns machine learning techniques andsemantic patch generation techniques to fix bugs automatically.we evaluate r2fix on three projects i.e.
the linux kernel mozilla and apache for three important types of bugs buffer overflows null pointer bugs and memory leaks.
r2fixgenerates patches correctly of which are new patches forbugs that have not been fixed by developers yet.
we reported all5 new patches to the developers have already been acceptedand committed to the code repositories.
the correct patchesgenerated by r2fix could have shortened and saved up to anaverage of days of bug diagnosis and patch generation time.keywords automated bug fixing automated program repair bug report classification fix pattern studyi.
introductioneveryday an overwhelming number of bugs are reported.for example the mozilla bug database with a totalof bug reports receives an average of newbug reports daily.
the corresponding bugs hurt softwarereliability and security which are not improved until thebugs are fixed.upon receiving a bug report developersdiagnosethe rootcause of the bug produce a patchthat can fix the bug andcommitthe patch to the source code repository.
wecombine the first two steps diagnosis and patch generation under the label offixinga bug which is the focus of thispaper.
developers bug fixing process is primarily manual therefore the time required for producing a fix and itsaccuracy depend on the skill and experience of individuals.figure a shows a linux kernel buffer overflow overrunbug report.
the developers first need to understand thisbug report by reading the relevant code together with thisreport the bufferstatecontains only bytes but bytes off was written to the buffer wheredenotes onespace character and the single character is needed tomark the end of the string.
the developers then need tofigure out how to fix the bug e.g.
by reading the relevantcode and using a debugger to observe and modify theprogram execution .
why are more than bytes assignedto the buffer?
should bytes be allocated instead shoulddevelopers assign only bytes to the bufferstate did thebug buffer overrun description the trailing zero will be written to state which is out of bound.linux net mac80211 debugfs sta.c strcpy state off spaceopenbox strcpy state off a linux kernel bug report b patch to fix the bugremove the space characterfigure .
converting a bug report to a patch.
denotes a line to bedeleted denotes a line to be added and is one space character.developers forget to check if the array is long enough to holdthe content before the assignment or was the bug caused bymore complex reasons?
the developers then need to checkout the buggy version modify the buggy code to fix thebug and generate the patch that can be applied to the sharedsource code repository.the result of this challenging and time consuming processby developers for bug is the patch in figure b .
thepatch deletes the line that writes bytes to bufferstate denoted by strcpy state off and adds anew line to write only bytes tostate strcpy state off which fixes the overflow bug.developers often need to fix more bugs than their timeand resources allow .
although developers spend almosthalf of their time fixing bugs bugs takeyearsto befixed on average .therefore support to make it easier and faster for de velopers to fix bugs is in high demand.
the capability toautomatically generate patches e.g.
figure b from bugreports e.g.
figure a could save programmers time and effort in diagnosing bugs and generating patches allowing developers to fix more bugs or focus on otherdevelopment tasks and shorten the bug fixing time thusimprove software reliability and security.a.
ideal goal versus realistic goalideally we want to automatically generate patches for allbug reports.
realistically it is impossible.
we found thatonly .
.
of bug reports in the linux kernel mozilla and apache bug databases are fixed.
this is because manybug reports are invalid unreproducible incomplete etc.even among bugs that can be fixed some are too complexto be fixed automatically because they require redesign ofthe algorithm addition of new features etc.
ieee sixth international conference on software testing verification and validation .
ieee figure example of linux bug report addressed by r2fix.
which explicitly include localization information where the symptom e.g.
buffer overrun is explicitly indicated by the reporter and which are about one of the following three simple bug types buffer overflow null pointer dereference or memory leak.
r2fix runs a straightforward classification to identify the bug category and uses a match and transform engine e.g.
coccinelle to generate patches.
as the authors admitted their target space represents of bug reports in their dataset.
furthermore it should be noted that given the limited scope of the changes implemented in its fix patterns r2fix does not need to run tests for verifying that the generated patches do not break any functionality.
this paper.
we propose to investigate the feasibility of a program repair system driven by bug reports thus we replace classical spectrum based fault localization with information retrieval ir based fault localization.
eventually we propose ifixr a new program repair workflow which considers a practical repair setup by imitating the fundamental steps of manual debugging.
ifixr works under the following constraint when a bug report is submitted to the issue tracking system a relevant test case reproducing the bug may not be readily available.
therefore ifixr is leveraged in this study to assess to what extent an apr pipeline is feasible under the practical constraint of limited test suites .ifixr uses bug reports written in natural language as the main input.
eventually we make the following contributions we present the architecture of a program repair system adapted to the constraints of maintainers dealing with user reported bugs.
in particular ifixr replaces classical spectrum based fault localization with information retrieval ir based fault localization.
we propose a strategy to prioritize patches for recommendation to developers.
indeed given that we assume only the presence of regression test cases to validate patch candidates many of these patches may fail on the future test cases that are relevant to the reported bugs.
we order patches to present correct patches first.
we assess and discuss the performance of ifixr on the defects4j benchmark to compare with the state of the art apr tools.
to that end we provide a refined defects4j benchmark for apr targeting bug reports.
bugs are carefully linked with the corresponding bug reports and for each bug we are able to dissociate future test cases that were introduced after the relevant fixes.
overall experimental results show that there are promising research directions to further investigate towards the integration of automatic patch generation in actual software development cycles.
in particular our findings suggest that ir based fault localization errors lead less to overfitting patches than spectrum based fault localization errors.
furthermore ifixr offers provides comparable results to most state of the art apr tools although it is run under the constraint that post fix knowledge i.e.
future test cases is not available.
finally ifixr s prioritization strategy tends to place more correct plausible patches on top of the recommendation list.
motivation we motivate our work by revisiting two essential steps in apr during fault localization relevant program entities are identified as suspicious locations that must be changed.
commonly stateof the art apr tools leverage spectrum based fault localization sbfl which uses execution coverage information of passing and failing test cases to predict buggy statements.
we dissect the construction of the defects4j dataset to highlight the practical challenges of fault localization for user reported bugs.
once a patch candidate is generated the patch validation step ensures that it is actually relevant for repairing the program.
currently widespread test based apr techniques use test suites as the repair oracle.
this however is challenged by the incompleteness of test suites and may further not be inline with developer requirements expectations in the repair process.
.
fault localization challenges defects4j is a manual curated dataset widely used in the apr literature .
since defects4j was not initially built for apr the real order of precedence between the bug report the patch and the test case is being overlooked by the dataset users.
indeed defects4j offers a user friendly way of checking out buggy versions of programs with all relevant test cases for readily benchmarking test based systems.
we propose to carefully examine the actual bug fix commits associated with defects4j bugs and study how the test suite is evolved.
table provides detailed information.
table test case changes in fix commits of defects4j bugs.
test case related commits bugs commit does not alter test cases commit is inserting new test case s and updating previous test case s commit is updating previous test case s without inserting new test cases commit is inserting new test case s without updating previous test cases overall for bugs the relevant test cases are actually future data with respect to the bug discovery process.
this finding suggests that in practice even the fault localization may be challenged in the case of user reported bugs given the lack of relevant test cases.
the statistics listed in table indeed shows that if future test cases are dropped no test case is failing when executing buggy program versions for i.e.
bugs.
table failing test cases after removing future test cases.
failing test cases bugs failing test cases exist and no future test cases are committed failing test cases exist but future test cases update the test scenarios failing test cases exist but they are fewer when considering future test cases failing test cases exist but they differ from future test cases which trigger the bug no failing test case exists i.e.
only future test cases trigger the bug in the apr literature fault localization is generally performed using the gzoltar testing framework and a sbfl formula e.g.
ochiai .
to support our discussions we attempt to perform fault localization without the future test cases to evaluate the performance gap.
experimental results see details forward in table of section expectedly reveal that the majority of the defects4j bugs i.e.
cannot be localized by sbfl at the time the bug is reported by users.
it is necessary to investigate alternate fault localization approaches that build on bug report information since relevant test cases are often unavailable when users report bugs.ifixr bug report driven program repair esec fse august tallinn estonia irbl featuresstep bug reportssource code filesstep distribute to regions standard irbl ............ regionsstep step step step divide conquer best models leaf wise weights computations code changes insoftware repositoriesbug fix patchesenhanced ast diff representationsdiff hunk search space constructionrooted tree isomorphism computationclustering based onsubgraph identificationstep 0step 1step 2step 3step 4step 5iterative foldingpatchcandidatespatchgeneration patchvalidationregressiontestingfixpatternmatchingir based fault localization suspicious codelocationsbuggyprogram selectfixpatternmutatesuspiciouscodefaultlocalization bug report fixpatternsmanual validationdeveloper test code elements ast figure the ifixr program repair workflow.
.
patch validation in practice the repair community has started to reflect on the acceptability and correctness of the patches generated by apr tools.
notably various studies have raised concerns about overfitting patches a typical apr tool that uses a test suite as the correctness criterion can produce a patched program that actually overfits the test suite i.e.
the patch makes the program pass all test cases but does not actually repair it .
recently new research directions are being explored in the automation of test case generation for apr to overcome the overfitting issue.
nevertheless so far they have had minimal positive impact due to the oracle problem in automatic test generation.
at the same time the software industry takes a more systematic approach for patch validation by developers.
for instance in the open source community the linux development project has integrated a patch generation engine to automate collateral evolutions that are validated by maintainers .
in proprietary settings facebook has recently reported on their getafix tool which automatically suggests fixes to their developers.
similarly ubisoft developed clever to detect risky commits at commit time using patterns of programming mistakes from the code history.
patch recommendation for validation by developers is acceptable in the software development communities.
it may thus be worthwhile to focus on tractable techniques for recommending patches in the road to fully automated program repair.
the ifixr approach figure overviews the workflow of the proposed ifixr approach.
given a defective program we consider the following issues where is the bug?
we take as input the bug report in natural language submitted by the program user.
we rely on the information in this report to localize the bug positions.
how should we change the code?
we apply fix patterns that are recurrently found in real world bug fixes.
fix patterns are selected following the structure of the abstract syntax tree representing the code entity of the identified suspicious code.
which patches are valid?
we make no assumptions on the availability of positive test cases that encode functionality requirements at the time the bug is discovered.
nevertheless we leverage existing test cases to ensure at least that the patch does not regress the program.
which patches do we recommend first?
in the absence of a complete test suite we cannot guarantee that all patches that pass regression tests will fix the bug.
we rely on heuristics to re prioritize the validated patches in order to increase the probability of placing a correct patch on top of the list.
.
input bug reports issue tracking systems e.g.
jira are widely used by software development communities in the open source and commercial realms.
although they can be used by developers to keep track of the bugs that they encounter and the features to be implemented issue tracking systems allow for user participation as a communication channel for collecting feedback on software executions in production.
table illustrates a typical bug report when a user of the lang library code has encountered an issue while using the numberutils api.
a description of erroneous behavior is provided.
occasionally the user may include in the bug description some information on how to reproduce the bug.
oftentimes users simply insert code snippets or dump the execution stack traces.
in this study among our dataset of bug reports we note that only i.e.
are reported by users who are also developers1 contributing to the projects.
i.e.
bugs are reported and again fixed by the same project contributors.
these percentages suggest that for the majority of cases the bug reports are indeed genuinely submitted by users of the software who require project developers attention.
table example bug report defects4j lang .
issue no.
lang summary numberutils createnumber bad behaviour for leading description numberutils createnumber checks for a leading in the string and returns null if found.
this is documented as a work round for a bug in bigdecimal.
returning nulll is contrary to the javadoc and the behaviour for other methods which would throw numberformatexception.
it s not clear whether the bigdecimal problem still exists with recent versions of java.
however if it does exist then the check needs to be done for all invocations of bigdecimal i.e.
needs to be moved to createbigdecimal.
given the buggy program version and a bug report ifixr must unfold the workflow for precisely identifying at the statement level the buggy code locations.
we remind the reader that in this step future test cases cannot be relied upon.
we consider that if such test cases could have triggered the bug a continuous integration system would have helped developers deal with the bug before the software is shipped towards users.
.
fault localization w o test cases to identify buggy code locations within the source code of a program we resort to information retrieval ir based fault localization irfl .
the general objective is to leverage potential similarity between the terms used in a bug report and the source code to identify relevant buggy code locations.
the literature includes a large body of work on irfl where researchers systematically extract tokens from a given bug report to formulate a query to be matched in a search space of documents formed by the collections of source code files and indexed through 1we rely on email addresses of committers and issue reporters to intersect users and developersesec fse august tallinn estonia a. koyuncu et al.
tokens extracted from source code.
irfl approaches then rank the documents based on a probability of relevance often measured as a similarity score .
highly ranked files are predicted to be the ones that are likely to contain the buggy code.
despite recurring interest in the literature with numerous approaches continuously claiming new performance improvements over the state of the art we are not aware of any adoption in program repair research or practice.
we postulate that one of the reasons is that irfl techniques have so far focused on file level localization which is too coarse grained in comparison to spectrumbased fault localization output .
recently locus and blia are state of the art techniques which narrow down localization respectively to the code change or the method level.
nevertheless to the best of our knowledge no irfl technique has been proposed in the literature for statement level localization.
in this work we develop an algorithm to rank suspicious statements based on the output i.e.
files of a state of the art irfl tool thus yielding a fine grained ir based fault localizer which will then be readily integrated into a concrete patch generation pipeline.
.
.
ranking suspicious files.
we leverage an existing irfl tool.
given that expensive extractions of tokens from a large corpus of bug reports is often necessary to tune irfl tools we selected a tool for which the authors provide datasets and pre processed data.
we use the d c as the specific implementation of file level irfl available online which is a machine learning based irfl tool using a similarity matrix of dimension feature vectors features from bug reports and features from source code files d c uses multiple classifier models that are trained each for specific groups of bug reports.
given a bug report the different predictions of the different classifiers are merged to yield a single list of suspicious code files.
our execution of d c line in algorithm is tractable given that we only need to preprocess those bug reports that we must localize.
trained classifiers are already available.
we ensure that no data leakage is induced i.e.
the classifiers are not trained with bug reports that we want to localize in this work .
.
.
ranking suspicious statements.
patch generation requires fine grained information on code entities that must be changed.
for ifixr we propose to produce a standard output as for spectrumbased fault localization to facilitate integration and reuse of stateof the art patch generation techniques.
to start we build on the conclusions on a recent large scale study of bug fixes to limit the search space of suspicious locations to the statements that are more error prone.
after investigating in detail the abstract syntax tree ast based code differences of over real world patches from java projects liu et al.
reported that the following specific ast statement nodes were significantly more prone to be faulty than others ifstatements expressionstatements fielddeclarations returnstatements andvariabledeclarationstatements .
lines in algorithm detail the process to produce a ranked list of suspicious statements.
algorithm describes the process of our fault localization approach used in ifixr .
top kfiles are selected among the returned list of suspicious files of the irfl along with their computed suspiciousness scores.
then each file is parsed to retain only the relevant error prone statements from which textual tokens are extracted.
the summary and descriptions of the bug report are also analyzedalgorithm statement level ir based fault localization.
input br a bug report input irt ool irfl tool output sscor e suspicious statements with weight scores 1function main br irt ool f filelocalizations irt ool br f selecttop f k cb bagoftokens br cb bag of tokens of bug report c b preprocess cb tokenization stopword removal stemming vb tfidfvectorizer c b vb bug report feature vector forfinfdo s parse f s list of statements forsinsdo cs bagoftokens s cs bag of tokens of statements c s preprocess cs vs tfidfvectorizer c s vs statements feature vector cosine similarity between bug report and statement sim cos similarity cosine vb vs wscor e sim cos f.score score suspicious value wscor e .add s wscor e sscor e wscor e .sort return sscor e lexically to collect all its tokens.
due to the specific nature of stack traces and other code elements which may appear in the bug report we use regular expressions to detect stack traces and code elements to improve the tokenization process which is based on punctuations camel case splitting e.g.
findnumber splits into find number as well as snake case splitting e.g.
find number splits into find number .
stop word removal2is then applied before performing stemming using the porterstemmer on all tokens to create homogeneity with the term s root i.e.
by conflating variants of the same term .
each bag of tokens for the bug report and for each statement is then eventually used to build a feature vector.
we use cosine similarity among the vectors to rank the file statements that are relevant to the bug report.
given that we considered kfiles the statements of each having their own similarity score with respect to the bug report we weight these scores with the suspiciousness score of the associated file.
eventually we sort the statements using the weighted scores and produce a ranked list of code locations i.e.
statements in files to be recommended as candidate fault locations.
.
fix pattern based patch generation a common and reliable strategy in automatic program repair is to generate concrete patches based on fix patterns also referred to as fix templates or program transformation schemas .
several apr systems in the literature implement this strategy by using diverse sets of fix patterns obtained either via manual generation or automatic mining of bug fix datasets.
in this work we consider the pioneer par system by kim et al.
.
concretely we build on kpar an open source java implementation of par in which we included a diverse set of fix patterns collected from the literature.
table provides an enumeration of fix patterns used in this work.
for more implementation details we refer the reader to our replication package.
all tools and data are released as open source to the community to foster further research into these directions.
as illustrated in figure a fix pattern encodes the recipe of change actions that should be applied to mutate a code element.
2stop words are from the ntlk framework bug report driven program repair esec fse august tallinn estonia table fix patterns implemented in ifixr .
pattern description used by pattern description used by insert cast checker genesis mutate literal expression simfix insert null pointer checker npefix mutate method invocation elixir insert range checker sofix mutate operator jmutrepair insert missed statement hdrepair mutate return statement sketchfix mutate conditional expression ssfix mutate variable capgen mutate data type avatar move statement s par remove statement s fixminer we mention only one example tool even when several tools implement it.
if exp instanceof t ... t exp... ...... figure illustration of insert cast checker fix pattern.
for a given reported bug once our fault localizer yields its list of suspicious statements ifixr iteratively attempts to select fix patterns for each statement.
the selection of fix patterns is conducted in a na ve way based on the context information of each suspicious statement i.e.
all nodes in its abstract syntax tree ast .
specifically ifixr parses the code and traverses each node of the suspicious statement ast from its first child node to its last leaf node in a breadth first strategy i.e left to right and top to bottom .
if a node matches the context a fix pattern i.e.
same ast node types the fix pattern will be applied to generate patch candidates by mutating the matched code entity following the recipe in the fix pattern.
whether the node matches a fix pattern or not ifixr keeps traversing its children nodes and searches fix patterns for them to generate patch candidates successively.
this process is iteratively performed until leaf nodes are encountered.
consider the example of bug math illustrated in figure .
ifixr parses the buggy statement i.e.
statement at line in the filefrequency.java into an ast as illustrated by figure .
first ifixr matches a fix pattern that can mutate the expression in the return statement with other expression s returning data of type double .
it further selects fix patterns for the direct child node i.e.
method invocation getcumpct comparable ?
v of the return statement.
this method invocation can be matched against fix patterns with two contexts method name and parameter s .
with the breadth first strategy ifixr assigns a fix pattern calling another method with the same parameters cf.
par to mutate the method name and then selects fix patterns to mutate the parameter.
furthermore ifixr will match fix patterns for the type and variable of the cast expression respectively and successively.
file src main java org apache commons math stat frequency.java line public double getpct object v line return getcumpct comparable ?
v line figure buggy code of defects4j bug math .
.
patch validation with regression testing for every reported bug fault localization followed by pattern matching and code mutation will yield a set of patch candidates.
in a typical test based apr system these patch candidates must let the program pass all test cases including some positive test cases which encode the actual functional requirements relevant to the bug .
thus the patch candidates set is actively pruned to remove all patches that do not meet these requirements.
in our work in accordance with our investigation findings that such test cases may returnstatement raw code methodinvocation raw code methodname getcumpct castexpression raw code type comparable ?
variablename v raw code denotesthecorrespondingsourcecodeattherelatednodeposition.figure ast of bug math source code statement.
not be available at the time the bug is reported cf.
section we assume that ifixr cannot reason about future test cases to select patch candidates.
instead we rely only on past test cases which were available in the code base when the bug is reported.
such test cases are leveraged to perform regression testing which will ensure that at least the selected patches do not obstruct the behavior of the existing unchanged part of the software which is already explicitly encoded by developers in their current test suite.
.
output patch recommendation list eventually ifixr produces a ranked recommendation list of patch suggestions for developers.
until now the order of patches is influenced mainly by two steps in the workflow localization our statement level irfl yields a ranked list of statements to modify in priority.
pattern matching the ast node of the buggy code entity is broken down into its children and iteratively navigated in a breadth first manner to successively produce candidate patches.
eventually the produced list of patches has an order which carries the biases of fault localization and is noised by the pre set breadth first strategy for matching fix patterns.
we thus design an ordering process with a function3 frcmd 2p pk as follows frcmd patches pritype prisusp prichan e patches where pri are three heuristics based prioritization functions used inifixr .frcmd takes a set of patches validated via regression testing cf.
section .
and produces an ordered sequence of patches frcmd patches seqrcmd pk .
we propose the following heuristics to re prioritize the patch candidates we favor patches that minimize the differences between the patched program and the buggy program.
to that end patches are ordered following their ast edit script sizes.
formally we define prichan e 2p pn where n patches prichan e patches and holds p patches cchan e pi cchan e pi .
here cchan e p is a function that counts the number of deleted and inserted ast nodes by the change actions of p. when two patch candidates have equal edit script sizes the tie is broken by using the suspiciousness scores of the associated statements yielded during ir based fault localization.
thus when cchan e pi cchan e pi prisusp re orders the two patch candidates.
we define prisusp pn pnsuch that prisusp seqchan e holds ssusp pi ssusp pi where 3the domain of the function is a power set 2p and the co domain pk is a kdimensional vector space where kis the maximum number of recommended patches and pdenotes the set of all generated patches.esec fse august tallinn estonia a. koyuncu et al.
seqchan eis the result of prichan eandssusp returns a suspicious score of the statement that a given patch pichanges.
after a manual analysis of fix patterns and the performance of associated apr in the literature we empirically found that some change actions are irrelevant to bug fixing.
thus for the corresponding pre defined patterns ifixr systematically under prioritizes their generated patches against any other patches although among themselves the ranking obtained so far through prichan eandprisusp is preserved for those under prioritized patches.
these are patches generated by i mutating a literal expression ii mutating a variable into a method invocation or a final static variable or iii inserting a method invocation without parameter.
this prioritization is defined by pritype pn pk which returns a sequence of topkordered patches k n patches .
to define this prioritization function we assign natural numbers j1 j2 j3 j4 nto each patch generation types i.e.
j1 i j2 ii and j3 iii respectively and j4 everything else which strictly hold j4 j1 j4 j2 j4 j3.
this prioritization function takes the result of prisusp and returns another sequence that holds pi dtype pi dtype pi .dtypeis defined as dtype 2p j1 j2 j3 j4 and determines how a patch pihas been generated as defined above.
from the ordered sequence the function returns the leftmost i.e.
top kpatches as a result.
experimental setup we now provide details on the experiments that we carry out to assess the ifixr patch generation pipeline for user reported bugs.
notably we discuss the dataset and benchmark some implementation details before enumerating the research questions.
.
dataset benchmark to evaluate ifixr we propose to rely on the defects4j dataset which is widely used as a benchmark in the java apr literature.
nevertheless given that defects4j does not provide direct links to the bug reports that are associated with the benchmark bugs we must undertake a fairly accurate bug linking task .
furthermore to realistically evaluate ifixr we must reorganize the dataset test suites to accurately simulate the context at the time the bug report is submitted by users.
.
.
bug linking.
to identify the bug report describing a given bug in the defects4j dataset we focus on recovering the links between the bug fix commits and bug reports from the issue tracking system.
unfortunately projects joda time jfreechart and closure have migrated their source code repositories and issue tracking systems into github without a proper reassignment of bug report identifiers.
therefore for these projects bug ids referred to in the commit logs are ambiguous for some bugs this may match with the github issue tracking numbering while in others it refers to the original issue tracker .
to avoid introducing noise in our validation data we simply drop these projects.
for the remaining projects lang and math we leverage the bug linking strategies implemented in the jira issue tracking software.
we use a similar approach to fischer et al.
and thomas et al.
to link to commits to corresponding bug reports.
concretely we crawled the bug reports related to each project and assessed the links with a two step search strategy i we check commit logs to identify bug report ids and associate the corresponding changes as bug fix changes then ii we check for bug reports that are indeed considered as such i.e.
tagged as bug and are further marked as resolved i.e.
with tags resolved or fixed and completed i.e.
with status closed .
eventually our evaluation dataset includes faults i.e.
defects4j bugs .
actually for the considered projects defects4j enumerates bugs associated with bug reports bugs are indeed left out because either the corresponding bug reports are not in the desired status in the bug tracking system which may lead to noisy data or there is ambiguity in the buggy program version e.g.
some fixed files appear to be missing in the repository at the time of bug reporting .
.
.
test suite reorganization.
we ensure that the benchmark separates past test cases i.e.
regression test cases from future test cases i.e.
test cases that encode functional requirements specified after the bug is reported .
this timeline split is necessary to simulate the snapshot of the repository at the time the bug is reported.
as highlighted in section for over cases of bugs in the defects4j benchmark the test cases relevant to the defective behavior was actually provided along the bug fixing patches.
we have thus manually split the commits to identify test cases that should be considered as future test cases for each bug report.
.
implementation choices during implementation we have made the following parameter choices in the ifixr workflow ir fault localization considers the top i.e.
k 50in algorithm suspicious files for each bug report in order to search for buggy code locations.
for patch recommendation experiments we limit the search space to the top suspected buggy statements yielded by the fine grained ir based fault localization.
for comparison experiments we implement spectrum based fault localization using the gzoltar testing framework with the ochiai ranking strategy.
unless otherwise indicated gzoltar version .
.
is used as it is widely adopted in the literature by astor acs ssfix and capgen among others .
.
research questions the assessment objective is to assess the feasibility of automating the generation of patches for user reported bugs while investigating the foreseen bottlenecks as well as the research directions that the community must embrace to realize this long standing endeavor.
to that end we focus on the following research questions associated with the different steps in the ifixr workflow.
rq1 to what extent does ir based fault localization provide reliable results for an apr scenario?
in particular we investigate the performance differences when comparing our fine grained irfl implementation against the classical spectrumbased localization.
rq2 to what extent does ir based fault localization point to locations that are less subject to overfitting?
in particular we study the impact on the overfitting problem that incomplete test suites generally carry.ifixr bug report driven program repair esec fse august tallinn estonia rq3 what is the effectiveness of ifixr s patch ordering strategy?
in particular we investigate the overall workflow of ifixr by re simulating the real world cases of software maintenance cycle when a bug is reported future test cases are not available for patch validation.
assessment results in this section we present the results of the investigations for the previously enumerated research questions.
.
rq1 fault localization being the first step in program repair we evaluate the performance of the ir based fault localization developed within ifixr .
as recently thoroughly studied by liu et al.
an apr tool should not be expected to fix a bug that current fault localization systems fail to localize.
nevertheless with ifixr we must demonstrate that our fine grained irfl offers comparable performance with sbfl tools used in the apr literature.
table provides performance measurements on the localization of bugs.
sbfl is performed based on two different versions of the gzoltar testing framework but always based on the ochiai ranking metric.
finally because fault localization tools output a ranked list of suspicious statements results are provided in terms of whether the correct location is placed under the top k suspected statements.
in this work following the practice in the literature we consider that a bug is localized if any buggy statement is localized.
table fault localization results irfl ir based vs. sbfl spectrum based on defects4j math and lang bugs.
bugs top top top top top all irfl sbflgzv1 gzv2 gzv1and gz v2refer to gzoltar .
.
and .
.
respectively which are widely used in apr systems for java programs.
overall the results show that our irfl implementation is strictly comparable to the common implementation of spectrum based fault localization when applied on the defects4j bug dataset.
note that the comparison is conducted for bugs of math and lang given that these are the projects for which the bug linking can be reliably performed for applying the irfl.
although performance results are similar we remind the reader that sbfl is applied by considering future test cases.
to highlight a practical interest of irfl we compute for each bug localizable in the top the elapsed time between the bug report date and the date the relevant test case is submitted for this bug.
based on the distribution shown in figure on mean average irfl could reduce this time by days.
figure distribution of elapsed time in days between bug report submission and test case attachment.
finally to stress the importance of future test cases for spectrumbased fault localization we consider all defects4j bugs and compute localization performance with and without future test cases.
results listed in table confirms that in most bug cases the localization is impossible only bugs out of can be localized among the top suspicious statements of sbfl at the time thebug is reported.
in comparison our irfl locates bugs under the same conditions of having no relevant test cases to trigger the bugs.
table fault localization performance.
gzoltar ochiai bugs top top top top top all without future tests with future tests fine grained ir based fault localization in ifixr is as accurate as spectrum based fault localization in localizing defects4j bugs.
additionally it does not have the constraint of requiring test cases that may not be available when the bug is reported.
.
rq2 patch generation attempts to mutate suspected buggy code with suitable fix patterns.
aside from having adequate patterns or not which is out of the scope of our study a common challenge of apr lies in the effective selection of buggy statements.
in typical test based apr test cases drive the selection of these statements.
the incompleteness of test suites is however currently suspected to often lead to overfitting of generated patches .
we perform patch generation experiments to investigate the impact of localization bias.
we compare our irfl implementation against commonly used sbfl implementations in the literature of test based apr.
we recall that the patch validation step in these experiments makes no assumptions about future test cases i.e.
all test cases are leveraged as in classical apr pipeline .
for each bug depending on the rank of the buggy statements in the suspicious statements yielded the fault localization system either irfl or sbfl the patch generation can produce more or less relevant patches.
table details the repair performance in relation to the position of buggy statements in the output of fault localization.
results are provided in terms of numbers of plausible andcorrect patches that can be found by considering top kstatements returned by the fault localizer.
table irfl vs. sbfl impacts on the number of generated correct plausible patches for defects4j bugs.
lang math total irfl top sbfl top irfl top sbfl top irfl top sbfl top irfl top sbfl top irfl top sbfl top irfl top sbfl top irfl all sbfl all we indicate x y numbers of patches x is the number of bugs for which a correct patch is generated y is the number of bugs for which a plausible patch is generated.
overall we find that irfl and sbfl localization information lead to similar repair performance in terms of the number of fixed bugs plausibly correctly.
actually irfl supported apr outperforms sbfl supported apr on the lang project bugs and vice versa for math project bugs overall bugs that are fixed using irfl output cannot be fixed using sbfl output although assuming the availability of the bug triggering test cases to run the sbfl tool .esec fse august tallinn estonia a. koyuncu et al.
we investigate the cases of plausible patches in both localization scenarios to characterize the reasons why these patches appear to only be overfitting the test suites.
table details the overfitting reasons for the two scenarios.
table dissection of reasons why patches are plausible but not correct.
localization error pattern prioritization lack of fix ingredients w irfl w sbfl a plausible patch passes all test cases but may not be semantically equivalent to developer patch i.e.
correct .
we consider a plausible patch to be overfitted to the test suite among the plausible patches that are generated based on irfl identified code locations and that are not found to be correct are found to be caused by fault localization errors these bugs are plausibly fixed by mutating irrelevantlysuspicious statements that are placed before the actual buggy statements in the fault localization output list.
this phenomenon has been recently investigated in the literature as the problem of fault localization bias .
nevertheless we note that patches generated based on sbfl identified code locations suffer more of fault localization bias of the plausible patches are concerned by this issue.
pattern prioritization failures may also lead to plausible patches while a correct patch could have been generated using a specific pattern at a lower node in the ast another pattern leading to an only plausible patch was first found to be matching the statement during the iterative search of matching nodes cf.
section .
.
finally we note that both configurations yield plausible patches due to the lack of suitable patterns or due to a failed search for the adequate donor code i.e.
fix ingredient .
experiments with the defects4j dataset suggest that code locations provided by ir based fault localization lead less to overfitted patches than the code locations suggested by spectrum based fault localization cf.
localization error column in table .
.
rq3 while the previous experiment focused on patch generation our final experiment assesses the complete pipeline of ifixr as it was imagined for meeting the constraints that developers can face in practice future test cases i.e.
those which encode the functionality requirements that are not met by the buggy programs may not be available at the time the bug is reported.
we thus discard the future test cases of the defects4j dataset and generate patches that must be recommended to developers.
the evaluation protocol thus consists in assessing to what extent correct plausible patches are placed in the top of the recommendation list.
.
.
overall performance.
table details the performance of the patch recommendation by ifixr we present the number of bugs for which a correct plausible patch is generated and presented among the top kof the list of recommended patches.
in the absence of future test cases to drive the patch validation process we use heuristics cf.
section .
to re prioritize the patch candidates towards ensuring that patches which are recommended first will eventually be correct or at least plausible when relevant test casesare implemented .
we present results both for the case where we do not re prioritize and the case where we re prioritize.
recall that given that the re organized benchmark separately includes the future test cases we can leverage them to systematize the assessment of patch plausibility.
the correctness also referred to as correctness of patches however is still decided manually by comparing against the actual bug fix provided by developers and available in the benchmark.
overall we note that ifixr performance is promising as it manages for bugs to present a plausible patch among its top recommended patches per bug.
among those plausible patches are eventually found to be correct.
table overall performance of ifixr for patch recommendation on the defects4j benchmark.
recommendation rank top top top top all without patch re prioritization with patch re prioritization x y x is the number of bugs for which a correct patch is generated y is the number of bugs for which a plausible patch is generated.
.
.
comparison with the state of the art test based apr systems.
to objectively position the performance of ifixr which does not require future test cases to localize bugs generate patches and present a sorted recommendation list of patches we count the number of bugs for which ifixr can propose a correct plausible patch.
we consider three scenarios with ifixr developers will be provided with only top recommended patches which have been validated only with regression tests in this case ifixr outperforms about half of the state of the art in terms of numbers bugs fixed with both plausible or correct patches.
developers are presented with all i.e.
not only top generated patches validated with regression tests in this case only four out of sixteen state of the art apr techniques outperform ifixr .
developers are presented with all generated patches which have been validated with augmented test suites i.e.
optimistically with future test cases with this configuration ifixr outperforms all state of the art except simfix which uses sophisticated techniques to improve the fault localization accuracy and search for fix ingredients.
it should be noted that in this case our prioritization strategy is not applied to the generated patches.
ifixr optrepresents the reference performance for our experiment which assesses the prioritization.
table provides the comparison matrix.
information on stateof the art results are excerpted from their respective publications.
ifixr offers a reasonable performance in patch recommendation when we consider the number of defects4j bugs that are successfully patched among the top in a scenario where we assume not having relevant test cases to validate the patch candidates .
performance results are even comparable to many state of the art test based apr tools in the literature.
.
.
properties of ifixr s patches.
in table we characterize the correct and plausible patches recommended by ifixr top5.
overall update and insert changes have been successful most patches affect a single statement and impact precisely an expression entity within a statement.ifixr bug report driven program repair esec fse august tallinn estonia table ifixr vs state of the art apr tools.
apr tool lang math total jgenprog jkali jmutrepair hdrepair nopol acs elixir jaid ssfix capgen sketchfix fixminer lsrepair simfix kpar avatar ifixr opt ifixr all ifixr top x y x is the number of bugs for which a correct patch is generated y is the number of bugs for which a plausible patch is generated.
ifixr opt the version of ifixr where available test cases are relevant to the bugs.
ifixr all all recommended patches are considered.
ifixr top only top recommended patches are considered.
table change properties of ifixr s correct patches.
change action bugs impacted statement s bugs granularity bugs update single statement statement insert multiple statement expression delete x y for x bugs the patches are correct while for y bugs they are plausible.
.
.
diversity of ifixr s fixed bugs.
finally in table we dissect the nature of the bugs for which ifixr top5is able to recommend a correct or a plausible patch.
priority information about the bug report is collected from the issue tracking systems while the root cause is inferred by analyzing the bug reports and fixes.
table dissection of bugs successfully fixed by ifixr .
patch typedefect4j bug idissue id root cause priority g l lang string index out of bounds exception minor g l lang wrong behavior due missing condition major g l lang null pointer exception major g m math double precision floating point format error major g m math missing read only access to internal list major g m math range check major g m math wrong variable type truncates double value minor g m math method signature mismatch minor p l lang serialization error in primitive types major p l lang wrong date format in comparison major p l lang range check minor p l lang number formatting error major p m math integer overflow major g denotes correct patch and p means plausible patch.
overall we note that out of the bugs have been marked as major issues.
different bug types i.e.
root causes are addressed.
in contrast r2fix only focused on simple bug types.
discussion this study presents the conclusions of our investigation into the feasibility of generating patches automatically from bug reports.
we set strong constraints on the absence of test cases which are used in test based apr to approximate what the program is actually supposed to do and when the repair is completed .
our experiments on the widely used defects4j bugs eventually show that patch generation without bug triggering test cases is promising.
manually looking at the details of failures and success in generating patches with ifixr several insights can be drawn test cases can be buggy during manual analysis of results we noted that ifixr actually fails to generate correct patches for threebugs namely math math and math because even the test cases were buggy.
figure illustrates the example of bug math where its patch also updated the relevant test case.
this example supports our endeavor given that users would find and report bugs for which the appropriate test cases were never properly written.
patched source code a src main java org apache commons math3 complex complex.java b src main java org apache commons math3 complex complex.java public class complex if real .
imaginary .
return nan return inf patched test case a src test java org apache commons math3 complex complextest.java b src test java org apache commons math3 complex complextest.java public class complextest public void testreciprocalzero assert.assertequals complex.zero.reciprocal complex.nan assert.assertequals complex.zero.reciprocal complex.inf figure patched source code and test case of fixing math .
bug reports deserve more interest with ifixr we have shown that bug reports could be handled automatically for a variety of bugs.
this is an opportunity for issue trackers to add a recommendation layer to the bug triaging process by integrating patch generation techniques.
there are however several directions to further investigation among which help users write proper bug reports and re investigate irfl techniques at a finer grained level that is suitable for apr.
prioritization techniques must be investigated in the absence of complete test suites for validating every single patch candidate a recommendation system must ensure that patches presented first to the developers are the most likely to be plausible and even correct.
there are thus two directions of research that are promising ensure that fix patterns are properly prioritized to generate good patches and be able to early stop for not exploding the search space and ensure that candidate patches are effectively re prioritized.
these investigations must start with a thorough dissection of plausible patches for a deep understanding of plausibility factors.
more sophisticated approaches to triaging and selecting fix ingredients are necessary in its current form ifixr implements a na ve approach to patch generation ensuring that the performance is tractable.
however the literature already includes novel apr techniques that implement strategies for selecting donor code and filters patterns.
integrating such techniques into ifixr may lead to performance improvement.
more comprehensive benchmarks are needed due to bug linking challenges our experiments were only performed on half of the defects4j benchmark.
to drive strong research in patch generation for user reported bugs the community must build larger and reliable benchmarks potentially even linking several artifacts of continuous integration i.e build logs past execution traces etc.
.
in the future we plan to investigate the dataset of bugs.jar .
automatic test generation techniques could be used as a supplement our study tries to cope radically with the incompleteness of test suites.
in the future however we could investigate the use of automatic test generation techniques to supplement the regression test cases during patch validation.esec fse august tallinn estonia a. koyuncu et al.
threats to validity threats to external validity the bug reports used in this study may be of low quality i.e.
wrong links for corresponding bugs .
we reduced this threat by focusing only on bugs from the lang and math projects which kept a single issue tracking system.
we also manually verified the links between the bug reports and the defects4j bugs.
table characterizes the bug reports of our dataset following the criteria enumerated by zimmermann et al.
in their study of what makes a good bug report .
notably as illustrated by the distribution of comments in figure we note that the bug reports have been actively discussed before being resolved.
this suggests that they are not trivial cases cf.
on measuring bug report significance .
table dissection of bug reports related to defects4j bugs.
proj.unique bug reportsw patch attachedaverage commentsw stack tracesw hintsw code blocks lang .
math .
code related terms such as package class names found in the summary and description in addition to stack traces and code blocks as separate features referred to as hints.
figure distribution of of comments per bug report.
another threat to external validity relates to the diversity of the fix patterns used in this study.
ifixr currently may not implement a reasonable number of relevant fix patterns.
we minimize this threat by surveying the literature and considering patterns from several pattern based apr.
threats to internal validity our implementation of fine grained irfl carries some threats during the search of buggy statements we considered top suspicious buggy files from the file level irfl tool to limit the search space.
different threshold values may lead to different results.
we also considered only statement types as more bug prone.
this second threat is minimized by the empirical evidence provided by liu et al.
.
additionally another internal threat is in our patch generation steps ifixr only searches for donor code from the local code files which contain the buggy statement.
the adequate fix ingredient may however be located elsewhere.
threats to construct validity in this study we assumed that patch construction and test case creation are two separated tasks for developers.
this may not be the case in practice.
the threat is however mitigated given that in any case we have shown that the test cases are often unavailable when the bug is reported.
related work fault localization.
as stated in a recent study fault localization is a critical task affecting the effectiveness of automated program repair.
several techniques have been proposed and they use different information such as spectrum text slice and statistics .
the first two types of techniques are widely studies in the community.
sbfl techniques are widely adopted in apr pipelines since they identify bug positions at a fine grained level i.e.
statements .
however they have limitations on localizing buggy locations since it highly relies on the testsuite .
information retrieval based fault localization irfl leverages textual information in a bug report.
it is mainly used to help developers narrow down suspected buggy files in the absence of relevant test cases.
for the purpose of our study we have proposed an algorithm for further localizing the faulty code entities at the statement level.
patch generation.
patch generation is another key process of apr pipeline which is in other words a task searching for another shape of a program i.e.
a patch in the space of all possible programs .
to improve repair performance many apr systems have been explored to address the search space problem by using different information and approaches stochastic mutation synthesis pattern contract symbolic execution learning and donor code searching .
in this paper patch generation is implemented with fix patterns presented in the literature since it may make the generated patches more robust .
patch validation.
the ultimate goal of apr systems is to automatically generate a correct patch that can actually resolve the program defects rather than satisfying minimal functional constraints.
at the beginning patch correctness is evaluated by passing all test cases .
however these patches could be overfitting and even worse than the bug .
since then apr systems are evaluated with the precision of generating correct patches .
recently researchers explore automated frameworks that can identify patch correctness for apr systems automatically .
in this paper our approach validates generated patches with regression test suites since fail inducing test cases are readily available for most of bugs as described in section .
conclusion in this study we have investigated the feasibility of automating patch generation from bug reports.
to that end we implemented ifixr an apr pipeline variant adapted to the constraints of test cases unavailability when users report bugs.
the proposed system revisits the fundamental steps notably fault localization patch generation and patch validation which are all tightly dependent to thepositive test cases in a test based apr system.
without making any assumptions on the availability of test cases we demonstrate after re organizing the defects4j benchmark that ifixr can generate and recommend priority correct and more plausible patches for a diverse set of user reported bugs.
the repair performance of ifixr is even found to be comparable to that of the majority of test based apr systems on the defects4j dataset.
we open source ifixr s code and release all data of this study to facilitate replication and encourage further research in this direction which is promising for practical adoption in the software development community