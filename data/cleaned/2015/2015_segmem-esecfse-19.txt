a segmented memory model for symbolic execution timotej kapus imperial college london united kingdomcristian cadar imperial college london united kingdom abstract symbolic execution is an effective technique for exploring paths in a program and reasoning about all possible values on those paths.
however the technique still struggles with code that uses complex heap data structures in which a pointer is allowed to refer to more than one memory object.
in such cases symbolic execution typically forks execution into multiple states one for each object to which the pointer could refer.
in this paper we propose a technique that avoids this expensive forking by using a segmented memory model .
in this model memory is split into segments so that each symbolic pointer refers to objects in a single segment.
the size of the segments are bound by a threshold in order to avoid expensive constraints.
this results in a memory model where forking due to symbolic pointer dereferences is significantly reduced often completely.
we evaluate our segmented memory model on a mix of whole program benchmarks such as m4and make and library benchmarks such as sqlite and observe significant decreases in execution time and memory usage.
ccs concepts software and its engineering software testing and debugging .
keywords symbolic execution memory models pointer alias analysis klee acm reference format timotej kapus and cristian cadar.
.
a segmented memory model for symbolic execution.
in proceedings of the 27th acm joint european software engineering conference and symposium on the foundations of software engineering esec fse august tallinn estonia.
acm new york ny usa pages.
introduction symbolic execution has seen significant uptake recently in both research and industry with applications across many different areas such as test generation bug finding debugging program repair and vulnerability analysis .
permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
copyrights for components of this work owned by others than the author s must be honored.
abstracting with credit is permitted.
to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
request permissions from permissions acm.org.
esec fse august tallinn estonia copyright held by the owner author s .
publication rights licensed to acm.
acm isbn .
.
.
.
symbolic execution the program under analysis is run on a symbolic input i.e.
an input which is initially allowed to have any value.
as the program runs the operations on symbolic values are evaluated as symbolic expressions.
when the program branches on one of these symbolic expressions symbolic execution explores both branches if they are feasible adding corresponding symbolic constraints to the respective path conditions.
upon path termination symbolic execution can ask the solver for a solution to the current path conditions thus obtaining a concrete test input that will follow the same path when executed concretely.
one of the main strengths of symbolic execution is that it can reason precisely about allpossible values of each control flow execution path it explores through the code under testing.
this amplifies its ability of finding bugs and other corner cases in the code being analysed.
however symbolic execution still struggles to reason in this way about complex data structures that involve pointers that can refer to multiple memory objects at once.
to illustrate this problem consider the c code in figure where we set nto40.
whensingle obj is defined the program allocates on line a 2d matrix as a single object for which all elements are initially zero.
it then writes value into matrix on line .
on lines and it declares two symbolic indexes i jwhich are constrained to be in the range n .
finally on line it checks whether the element matrix is positive.
the program has two paths one on which matrix is positive which happens only when iandjare both zero and the other in which it is not which happens when either iorjare not zero .
unsurprisingly a symbolic execution tool like klee explores the two paths in a fraction of a second.
now consider the program in the same figure but without definingsingle obj .
now the matrix is allocated as multiple objects one for each row in the matrix.
in this case klee will explore n paths one for each row in the matrix and an additional one for the first row in which both sides of the ifstatement are feasible.
it will take klee significantly longer 12s instead of .3s in our experiments to explore all 41paths.
the reason is that klee as well as other symbolic executors use the concrete addresses of memory objects to determine to which objects a symbolic pointer could refer to.
in our example matrix is a symbolic pointer formed by adding a concrete base address the address of matrix with a symbolic offset i. when this pointer gets dereferenced on line klee needs to know to which memory object it points.
therefore klee scans all the memory objects and asks the solver if the symbolic pointer can be within its bounds.
if that is true for more than one object we are in what is called amultiple resolution case.
this is the case in our example where the pointer matrix can point to ndifferent objects namely those corresponding to the nrows of the matrix.
note that whenesec fse august tallinn estonia timotej kapus and cristian cadar 1intmain ifdefsingle obj intmatrix else int matrix malloc n sizeof int for inti i n i 7matrix calloc n sizeof int endif 10matrix inti klee range n i intj klee range n j if matrix 16printf found positive element n figure 2d matrix allocated as a single object when single obj is defined and as multiple objects when it is not.
single obj is defined this is not the case as the compiler allocates a 2d array as a 1d array indexed by n i j .
so klee forks one path for each of the nobjects constraining the pointer to refer to a single memory object in each case.
for the case where matrix refers to the first row of the matrix klee explores two paths one in which matrix is greater than zero and one where it is not.
for the cases in which matrix refers to one of the other rows only the case where matrix is not greater than zero is feasible.
this gives us a total of n 1paths.
this forking memory model for symbolic pointers has several important drawbacks.
first it leads to path explosion as each time the code dereferences a symbolic pointer the execution is forked into as many paths as there are objects to which the symbolic pointer could refer.
second and related to the first point it leads to memory exhaustion as each additional path requires a certain amount of space in memory.
third it disables the ability of symbolic execution to reason about all possible values on a certain controlflow program path.
in this paper we propose a novel approach that uses pointer alias analysis to group memory objects that may alias each other into a memory segment .
this avoids forking because conservative alias analysis guarantees that a symbolic pointer can only point to objects within a single memory segment.
we describe our technique in detail in section present its implementation in section and evaluate it in section .
we then discuss its trade offs in section present related work in section and conclude in section .
proposed memory model consider the program in figure with single obj not defined for n with a memory layout shown on the left hand side of figure .
matrix is an array of pointers allocated at 0x0100 that points to the rows of the matrix allocated at addresses 0x0200 0x0300 and 0x0400.
suppose that libc also allocates two memory objects in the background at addresses 0x0500 and0x0600 .
there are also two symbolic pointers matrix which is constrained to point to one figure a concrete memory layout for the program in figure when single obj is not defined illustrating the flat and segmented memory models.
of the three matrix rows and matrix which is constrained to point to one of the entries of the last row.
most symbolic executors reflect this memory layout in their internal memory model.
they record the start and end addresses of each memory block and associate a corresponding array in the constraint solver.
therefore they can handle symbolic pointers such asmatrix well because their value resolves to a single memory object.
the symbolic address then gets translated into a symbolic index into the solver array that is backing the memory object.
solvers can then solve the associated queries with the popular theory of arrays .
the problem arises when a symbolic pointer can point to multiple memory objects as is the case for pointer matrix .
this pointer resolves to three different memory objects the matrix rows backed by three different solver arrays.
the theory of arrays cannot be used here because it cannot express such constraints.
.
existing memory models there are several memory models for handling multiple resolution that have been considered in the context of symbolic execution single object forking flat memory and merging.
each memory model aims to resolve a dereference of a symbolic pointer to an access into a solver array.
single object model .
in this approach the pointer is resolved to one possible object and the other possibilities are discarded.
this is the model used by most concolic executors such as crest where the single object considered is the one given by the concrete input used in the current round of concolic execution.
this is also the model used by the dynamic symbolic executor exe where the pointer is concretised to one possible value.
fuzzball employs a more general version of this model in which the pointer is concretized to multiple values that are selected randomly.
this approach scales well but is incomplete and may miss important execution paths.
for instance both crest and fuzzball usually finish running the multi object version of the code in figure when slightly adapted to use the crest fuzzball apis without exploring the feasible path where found positive element is printed incorrectly giving the impression to the user that the statement is not reachable.a segmented memory model for symbolic execution esec fse august tallinn estonia algorithm forking model function forkingdereference pointer p foreach memoryobject odo forkpath addconstraint o.start p o.end solverarra y getsolverarray o return solverarra y end foreach end function forking model.
in this approach shown in algorithm execution is forked for each memory object to which the pointer can refer line and on each forked path the pointer is constrained to refer to that object only line .
addconstraint terminates the path if the added constraint is provably false in our case if p cannot refer to that object on that path .
finally the corresponding access into the solver array associated with that object is returned line .
as a detail forkpath uses the initial path for the last object instead of forking .
also for ease of exposition in this algorithm and the following ones we ignore out of bounds checking and assume dereferences of char pointers.
consider running algorithm on our running example from figure and the layout from figure with pbeingmatrix .
the loop will iterate six times forking for each of the six memory objects in the program.
in the first iteration the path will be immediately killed by addconstraint since pcannot point to object at 0x0100.
in the second iteration pwill be constrained to point to the first object it can point to 0x0200 and then the corresponding access into the solver array associated with that object is returned i.e.
solverarra y0x0200 .
the remaining iterations are similar resulting in three paths one for each of the three objects at 0x0200 0x0300 and0x0400 thatpcan point to.
figure shows the behaviour of the forking model compared to other solutions.
in particular it shows the behaviour of klee and symbolic pathfinder spf both of which implement the forking model.
figure 3a shows results for the code in figure with single obj not defined while figure 3b shows results for a variant of the code that performs two symbolic lookups into the matrix.
these figures show that the forking model scales poorly.
this is particularly clear when two symbolic accesses are performed where the execution time increases exponentially with the dimension of the matrix.
note that spf appears to have an efficient implementation of forking for a small number of paths which explains its good performance on the single lookup example.
merging model.
this approach keeps a single path and creates anorexpression with one disjunct for each possible object to which the pointer could refer.
for space reasons we omit the formal algorithm and illustrate how it works on our running example.
suppose that the symbolic executor encounters the expression p with pbeing again matrix .
this will be translated into a disjunction with one disjunct for each of the three memory objects to which pcan refer.
each disjunct will express the fact that ppoints to that object and will replace the pointer with the associated solver array for that object.
that is the expression p 1will be translated to the following disjunction where sastands for solverarra y algorithm flat memory model function naiveflatmemorydereference pointer p return memor ysolverarra y end function 0x0200 p 0x020c sa0x0200 0x0300 p 0x030c sa0x0300 0x0400 p 0x040c sa0x0400 approaches following this idea at a high level were proposed in the context of sage and angr .
as illustrated in figures 3a and 3b the scalability of this approach on the running example is similar or slightly better than that of forking.
in practice its performance is benchmark dependent.
flat memory model.
this approach tackles the multiple resolution problem by treating the whole memory as a single object backed by a single solver array.
therefore a solver can reason about symbolic dereferences using the theory of arrays because all queries are using a single flat array.
the algorithm for translating a dereference is straightforward and shown in algorithm .
any pointer in the program is an offset in the large solver array memor ysolverarra y. this approach is also illustrated in the top right of figure .
we are not aware of any symbolic execution engine that implements this approach.
however we explored this approach in the past and found it not to scale in the context of the symbolic executor exe the constraint solver stp and a bit address space a straightforward remedy to this problem of a symbolic pointer referring to multiple objects would be to model memory as a single stp array indexed by bit bitvectors but this approach is currently too slow to be practical .
as shown in figures 3a and 3b this approach achieves good scalability on our running example and the variant with two symbolic lookups.
however this is because these examples allocate little memory.
in an additional experiment we modify the example to perform an additional irrelevant allocation of 30kb which is meant to simulate a real application in which most of the memory is not involved in any single dereference.
the results in figure 3c show that the flat memory model also scales poorly.
.
segmented memory model the key idea behind our approach is the realisation that memory can be divided into multiple segments such that any symbolic pointer can only refer to memory objects in a single memory segment.
we can then associate one solver array per memory segment and translate the symbolic pointer to an offset into its associated memory segment.
as long as the individual memory segments are small enough the approach can scale while still handling the problem of symbolic pointers referring to multiple objects.
on our running example figure shows this approach has the advantages of the flat memory model in the first two cases while maintaining its good performance when irrelevant memory allocations are performed.
computing memory segments.
to divide memory objects into segments we use a conservative points to analysis .
theesec fse august tallinn estonia timotej kapus and cristian cadar 120time seconds nforking merging flat memory segmented forking spf a 2d matrix with symbolic lookup linear scale .
50time seconds nforking merging flat memory segmented forking spf b 2d matrix with symbolic lookups log scale 50time seconds nforking merging flat memory segmented forking spf c 2d matrix with symbolic lookup and extra allocation linear scale figure runtime of different memory models on a family of 2d matrix benchmarks based on figure with single obj undefined.
all memory models are implemented in klee except for the one explicitely mentioning symbolic pathfinder.
algorithm computing and using memory segments function computememorysegments performpointstoanalysis ptsets foreach pointer pdo ptsets ptsets pointstoset p end foreach while ptsets changes do foreach s ptsets do if s ptsets .s s s s then ptsets ptsets s s s s end if end foreach end while foreach s ptsets do se new memorysegment assocptset se s end foreach end function function getmemorysegment pointer p pts pointstoset p foreach memorysegment se do ifpts assocptset se then return se end if end foreach end function function handlealloc pointer p size sz se getmemorysegment p return allocatein se sz end function result of a points to analysis is a mapping between pointers and points to sets.
the points to set of a pointer pis a set of pointers and abstract memory objects to which pmay refer to during execution.
anabstract memory object is identified by the static allocation point in the program.
for instance in figure there are two abstract memory objects ao1 corresponding to the allocation at line and ao2 corresponding to the allocation at line .
the function computememorysegments in algorithm shows the algorithm for computing memory segments.
after running thepoints to analysis line the set ptsets is initialised to contain all the points to sets computed by the analysis lines .
then any two points to sets sands that overlap are merged until no such sets exist anymore lines .
finally for each of the resulting pointsto sets a new memory segment is created lines in which all the objects associated with that points to set will be allocated.
the map assocptsets remembers the points to set associated with each memory segment line .
in our example from figures and there are two pointers we consider matrix andmatrix .
pointer analysis tells us the points to set of matrix is a singleton set containing the abstract object ao1.
similarly the points to set of matrix is a singleton set containing ao2.
continuing with algorithm we therefore initialise ptsets ao1 ao2 lines .
in this case there are no common elements in those sets so lines have no effect.
finally we create two memory segments corresponding to the two elements in ptsets .ao1corresponds to the memory segment starting at 0xa100in figure where the array of pointers to the matrix rows will be allocated.
ao2corresponds to the memory segment starting at 0xd100 where the actual rows of the matrix will be allocated.
the function getmemorysegment in algorithm returns the memory segment associated with a pointer pin the program.
it does so by finding the memory segment whose associated points to set contains the points to set of p. we note that an implementation could be optimised by keeping a reverse mapping from points to sets to memory segments.
getmemorysegment is then used by handlealloc in algorithm to handle a heap allocation of the form p malloc sz in c. the function allocates memory for the target pointer pin its associated memory segment.
in our example it returns the memory segment starting at 0xa100when encountering the allocation for matrix on line .
for the allocation on line where row allocations are made it returns the memory segment starting at 0xd100.
finally algorithm shows how a dereference of a pointer pis handled.
we first obtain the memory segment associated with p line then we get the solver array associated with that segment line and return the corresponding solver array access line .
restricting segment size.
the approach of algorithm scales as long as the size of each memory segment remains small.
in practice some segments may become very large imposing significanta segmented memory model for symbolic execution esec fse august tallinn estonia algorithm pure segmented memory model function puresegmenteddereference pointer p se getmemorysegment p solverarra y getsolverarray se return solverarra y end function algorithm segmented memory model function segmentedmemorydereference pointer p foreach memorysegment se do forkpath addconstraint se .start p se .end solverarra y getsolverarray se return solverarra y end foreach end function function allocatein memorysegment se size sz ifse .size t hreshold then return extend se sz else se choosesegment return allocatein se sz end if end function overheads on the solver.
to ensure segment sizes remain small we refine the technique by imposing a threshold on the maximum segment size.
if the program tries to allocate memory in a certain segment and the current size of that segment already exceeds the threshold a new segment is used.
when this happens some pointers may now refer to several segments.
in that case dereferencing a pointer forks execution for each memory segment.
essentially the model becomes a hybrid between the pure segmented memory model of algorithm and the forking model of algorithm .
our finalised approach is illustrated in algorithm together with the previously discussed algorithm .
the dereference function segmentedmemorydereference is similar to that of the forking model only that now we iterate over all segments trying to find those to which pcould refer.
remember that the addconstraint function kills a path if the added constraint is false that is when the pointer cannot refer to that segment.
the other change is required in the allocation function.
instead of simply allocating the required memory in the given segment the modified allocatein function works as follows.
if the current size of the segment is under the threshold the allocation is performed in that segment lines .
otherwise we choose another segment which could either be a new segment or an existing one and we try to allocate in there .
another consequence of this hybrid model is that it is resilient to bugs in pointer alias analysis.
should it incorrectly report two pointers not aliasing each other putting them in different memory segments the hybrid approach would simply fork for the two cases without losing any precision.
conversely this kind of bug would cause the pure segmented memory model to miss paths.in practice the performance of the algorithm depends on the precision of the points to analysis.
if the analysis is extremely imprecise it may put all pointers into a single points to set and our model would degenerate to the flat memory model.
at the other extreme if the threshold is too small or the points to analysis extremely buggy our model would degenerate to the forking model.
implementation we implemented our approach on top of klee commit 0283175f configured to use llvm and the stp constraint solver .
.
.
below we provide additional details about our implementation.
points to analysis.
we use svf a scalable llvm based framework for value flow construction and pointer analysis.
in particular we use whole program wave propagation based andersen analysis a fast flow insensitive context insensitive inclusionbased points to analysis.
we found it to be significantly faster than the basic andersen analysis while maintaining precision.
it terminated in under two minutes for all our benchmarks.
compared to the high runtime of symbolic execution we found the analysis time to be insignificant.
memory segment implementation.
for each memory segment that needs to be created in algorithm line we reserve 200kb of address space using mmap .
at this point the segment has size but can hold an object of maximum size 200kb.
we use mmap instead of malloc to save memory as in practice many memory segments will be empty and will therefore not be mapped to physical memory.
the threshold size for the hybrid approach was set to 10kb which was small enough for stp to be reasonably performant while still being large enough to significantly limit forking.
we write the size of each allocation just before the returned pointer to enable realloc andfree .
therealloc function is handled with an llvm pass that runs before the execution and replaces all calls to realloc withmalloc memcpy andfree .
we use the previously stored allocation size information to determine the size of the region to copy with memcpy .
the memory freed by calls to free is added to a list of free space in each memory segment.
that list is then scanned before a memory segment is extended for allocation.
we try to find the smallest gap that fits the requested size and if such a gap is found we perform the allocation there.
we found this to be an important optimisation to keep the sizes of memory segments small.
constants and local variables.
a common performance optimisation in pointer alias analysis is to model all constant objects such as constant strings as single memory objects .
we similarly adopt a scheme in which constant objects are disregarded by the alias analysis and allocated in their own memory segments.
we make the same choice for local memory objects namely objects allocated on the stack.
we found only one program where constant objects are involved in multiple resolution but this was a case where the forking model would work well too as the pointer could only refer to two different objects.
we found no programs where local objects were involved in multiple resolution.
of course the approach presented here is easily adapted to support these kind of objects should a need for it arise.esec fse august tallinn estonia timotej kapus and cristian cadar flat memory model.
we found it easy to implement the flat memory model in klee by making all allocations into a single memory segment backed by a single solver array.
merging model.
the merging model is implemented by leveraging klee s ability to merge states.
upon hitting a multiple resolution we let klee fork as usual and then immediately merge all the states thus creating the orexpression of their path conditions.
we note that this approach might not be optimal however klee spent most of the time in constraint solving activities in the merging runs in our evaluation.
therefore we believe the threat to validity against this implementation choice is minimal.
evaluation symbolic pointer dereferences that trigger multiple resolutions often make existing symbolic execution tools unusable.
however only some types of programs trigger such dereferences and we discovered that benchmark suites used in the past to evaluate symbolic execution such as gnu coreutils do not trigger many multiple resolutions.
in general benchmarks which are prone to trigger multiple resolutions are those where a symbolic input e.g.
coming from files command line arguments or environment variables flows into a data structure indexed by that input.
hash tables are the prime example of such benchmarks widely used in a variety of programs.
therefore we selected several large programs that use hash tables m4 make apr andsqlite and used test harnesses that drive execution toward the parts of the code employing these hash tables.
essentially our evaluation is meant to show that our model can make a big difference in such cases while acknowledging that it is not relevant all the time.
we further discuss this aspect in .
ideally we would like to compare the fraction of the search space explored in these programs under each memory model.
unfortunately this is challenging to do especially since the number of explored paths changes across models due to forking and merging.
therefore we decided to build our test harnesses in such a way that programs terminate.
then we can simply compare the time needed to finish the exploration under different memory models.
for one program where we didn t manage to write such a driver make we measure how quickly each memory model reaches coverage saturation.
as a sanity check we made sure that terminating benchmarks reach the same coverage at the end under all memory models and that the flat memory model and the two variants of the segmented memory model explore the same number of paths recall that we didn t see any forking in these benchmarks with the hybrid segmented memory model .
we also measure the memory consumption of klee under each memory model as a proxy for how many states klee has to keep in memory at each point and to illustrate a further tangible benefit of choosing the right memory model.
we observed that execution time and memory consumption can vary significantly with different search strategies.
therefore we conducted our experiments using three different strategies dfs and bfs representing extreme behaviors in terms of memory consumption and klee s default search heuristic representing a good general strategy.
klee s default heuristic interleaves random path selection with a heuristic that aims to maximize coverage .table impact of points to analysis on our benchmarks and its runtime.
benchmarktotal mem.
bytes max.
segment size bytes analysis runtime s ideal svf apr .
gnu m4 .
gnu make .
sqlite .
1define a l 2define p ?
?
5ifelse ?
l ifelse ?
p eval n failed figure symbolic input to m4 where ?
denotes a symbolic character.
the experiments were run on an intel r core tm i7 at .40ghz with 16gb of memory.
we use a timeout of two hours in our experiments and a memory limit of 4gb.
.
impact of points to analysis the performance of the segmented memory model is highly dependent on the size of the segments which is directly related to the precision of the points to analysis.
in order to understand by how much our results would be improved by a more precise points to analysis we decided to approximate a best case points to analysis.
to do so we run the forking approach on our benchmarks until it hits the first multiple resolution where we record the allocation sites with allocation context of all the objects involved in the multiple resolution and terminate the execution.
we then restart the execution placing all objects allocated at those allocation sites in the appropriate contexts into a segment.
should a new multiple resolution be encountered we again record the allocation site and its context create a new segment and merge any segments if needed and repeat this process until no more multiple resolutions are encountered within a certain timeout .
in practice we only needed fewer than five iterations for our benchmarks.
essentially we group into segments only the objects actually involved in multiple resolutions in a given execution.
this gives us results which are at least as good as the most precise points to analysis possible.
table shows the impact of the pointer alias analysis on the benchmarks we use in our evaluation and which will be described in detail in .
to .
.
the first column shows the total memory used by the dynamically allocated memory objects in each program.
this is the size of the flat memory segment.
the next two columns show the maximum segment sizes for both the svf pointer analysis and our idealized analysis.
for all benchmarks the points to analysis significantly reduces the largest segment size.
the maximum segment size of the ideal analysis is significantly smaller than for the svf analysis suggesting there are important opportunities for improving the precision of svf.a segmented memory model for symbolic execution esec fse august tallinn estonia using the svf analysis the apr andsqlite benchmarks reach the maximum threshold of 10kb for our segments and get split.
despite this split we did not observe any forking in the segmented memory model for apr.
for sqlite we observed forks into paths each.
the last column of table shows the runtime of the svf points to analysis.
for all benchmarks but sqlite the analysis took less than seconds which is insignificant compared to the cost of symbolic execution.
even for complex programs like sqlite the analysis took 70s which is noticeable but still little in a symbolic execution context.
.
gnu m4 gnu m4 is a popular implementation of the m4macro processor included in most unix based operating systems.
it is a relatively small program consisting of about lines of code which makes extensive use of hash tables to look up strings.
in a nutshell m4 operates by reading in the input text as a sequence of tokens.
it then looks up each token in a hash table.
if the token is found it replaces it with the value in the hash table.
otherwise it outputs the token and continues with the next one.
that makes it a good candidate to benefit from the proposed memory model as a significant part ofm4 s computation consists of hash table lookups which trigger forking due to multiple resolution.
to run m4using symbolic execution we need to make its input symbolic.
to reach deeper parts of the code where m4operates as described in the paragraph above we run m4on a partially symbolic input.
the outline of the input we used is shown in figure .
we define several concrete one character macros using the define keyword.
then we expand two macros with the name of the macro being symbolic which results in a symbolic lookup in the hash table.
finally we expand two more macros inside ifelse constructs.
the example is set in a way that illustrates the multiple dereference problem but we believe it is quite representative of how m4is used.
we ran klee on m4for two hours under dfs bfs and klee s default strategy with forking merging flat and segmented memory models.
the segmented memory model is further broken down into two runs.
the first one is using points to information computed from svf.
the second one uses ideal points to information which was obtained with a pre run as described in .
.
figure shows for each search strategy klee s termination time and memory usage for each of the five memory models.
the forking and flat memory models do not terminate before the hour timeout.
the segmented memory model using svf terminates in around one hour with the ideal version a few minutes earlier.
in contrast to the segmented memory model which is only mildly influenced by the search strategy the performance of the merging model heavily depends on the search strategy for dfs it terminates in only minutes for bfs in minutes while with klee s default strategy it times out after hours.
under dfs the memory consumption is unsurprisingly low as only a small number of states are kept in memory at one time note that the y axis has a different scale for dfs compared to bfs and the default klee strategy .
the svf segmented memory has slightly higher overall memory usage due to the fixed memory cost of keeping all points to information.
for bfs and the default search1a word1 2b word2 3d ?
4e ?
figure symbolic input to gnu make where ?
denotes a symbolic character.
strategy all memory models have low memory usage except for the forking model which quickly reaches the 4gb memory limit.
.
gnu make gnu make is a popular build system used extensively in the open source community.
it is a larger program consisting of about lines of code.
it uses significantly more memory during runtime than m4.
to make execution easier for klee we reduced the sizes of several caches in make .
our evaluation focused on the variable expansion capabilities ofmake .
similarly to m4 we made the makefiles only partially symbolic.
figure illustrates the makefile we used as symbolic input in our experiments.
figure shows the memory consumption of the different memory models.
this benchmark was the only one where none of the runs terminated before reaching the timeout.
unsurprisingly the forking model s memory consumption grows the quickest.
the two segmented memory models behave similarly with the svf version consuming a constant amount of additional memory due to holding the whole points to set.
the merging model appears to have the best memory consumption but this is only because it executes two times fewer instructions than the next slowest approach svf segmented memory .
when compared to m4 the make runs are slower execute fewer instructions per second therefore the differences between the memory models are also smaller.
since this benchmark is not terminating we report the coverage.
for dfs and bfs the coverage was the same across all memory memory models at .
for the default heuristic the forking and ideal segmented memory models had the highest coverage at .
followed by svf segmented memory model at .
and the flat memory model at .
.
merging only achieved .
coverage.
.
sqlite sqlite is a sql database engine library written in c which claims to be the most used database in the world.
it has a big codebase with over lines of code.
we focused our evaluation on a part of sqlite that triggers multiple resolutions in symbolic execution.
in particular sqlite uses a hash table to keep track of all triggers associated with a table.
we create several triggers with concrete names and then try to create a trigger with symbolic name which should involve a lookup of a symbolic key in the hash table of triggers.
we use an in memory database create a table with two int columns and add triggers to this table.
we need to create more than triggers as the sqlite hash table is optimized to be just a linked list when there are fewer than elements.
choosing aesec fse august tallinn estonia timotej kapus and cristian cadar .
.
.
.
.
.
120memory gb time minutes forking flat memorymerging segmented svf segmented ideal 59min52min25min a dfs .
.
.
.
.
120memory gb time minutes forking flat memorymerging segmented svf segmented ideal 59min53min88min b bfs .
.
.
.
.
120memory gb time minutes forking flat memorymerging segmented svf segmented ideal 63min61min c default figure runtime and memory consumption of the different memory models for gnu m4 across different search strategies.
.
.
.
.
.
.
.
.
.
.
.
120memory gb time minutes forking flat memorymerging segmented svf segmented ideal a dfs .
.
.
.
.
.
.
120memory gb time minutes forking flat memorymerging segmented svf segmented ideal b bfs .
.
.
.
.
.
.
120memory gb time minutes forking flat memorymerging segmented svf segmented ideal c default figure memory consumption of the different memory models for gnu make across different search strategies.
.
.
.
.
.
.
.
120memory gb time minutes forking flat memorymerging segmented svf segmented ideal 21min 12min a dfs .
.
.
.
.
.
.
120memory gb time minutes forking flat memorymerging segmented svf segmented ideal 22min 16min b bfs .
.
.
.
.
.
.
.
120memory gb time minutes forking flat memorymerging segmented svf segmented ideal 22min 13min c default figure runtime and memory consumption of the different memory models for sqlite across different search strategies.
.
.
.
.
.
.
.
.
120memory gb time minutes forking flat memorymerging segmented svf segmented ideal 9min 16min12min114min 99min a dfs .
.
.
.
.
.
.
.
120memory gb time minutes forking flat memorymerging segmented svf segmented ideal 8min 18min11min 80min b bfs .
.
.
.
.
.
.
.
120memory gb time minutes forking flat memorymerging segmented svf segmented ideal 13min 21min20min 83min c default figure runtime and memory consumption of the different memory models for apr across different search strategies.
higher amount of triggers would tilt the results against the forking model but we believe triggers is a good trade off between showcasing the multiple dereference issue and a realistic use of the library.
finally we create two more triggers whose names are symbolic.figure shows the results.
the forking approach terminates in minutes the ideal segmented memory model terminates in 1these sqlite graphs have been amended to correct a mistake found after publication.
we thank david trabish for his feedback while reproducing our experiments.a segmented memory model for symbolic execution esec fse august tallinn estonia 1apr hash t ht apr hash make 2for inti i i int key malloc sizeof int key i 5apr hash set ht key sizeof int a value 8inti j symbolic 9apr hash get ht i sizeof int 10apr hash get ht j sizeof int figure apache portable runtime baseline benchmark.
minutes while the svf segmented memory flat memory and merging models don t terminate within the hour time budget.
there are no significant differences in memory consumption across search strategies.
svf segmented memory uses a constant additional amount of memory since it needs to be holding the pointsto sets in memory.
the flat memory model uses more memory due to holding expressions over large arrays in memory.
this case study raises two interesting points.
first the precision of the points to analysis significantly impacts the performance of the segmented memory model.
as can be seen in table the difference in the size of the computed segments between ideal points to analysis and svf is huge.
this is has an immediate impact on the performance of the segmented memory model as illustrated in figure .
therefore improving the precision of the points to analysis is a promising future avenue for improving the segmented memory model.
second the segmented memory model performs worse than forking when there is little or no forking in the program.
this is because grouping memory objects together increases the size of solver arrays which makes constraints harder.
this is a price the segmented memory approach has to pay regardless of whether the program causes multiple resolutions.
in this case the constraints in the forking model can be solved relatively fast so forking can brute force its way through multiple resolutions.
we note that increasing the number of triggers in the benchmarks would likely tilt results against the forking model but our choice of triggers was so that at least some runs finish within the hour time budget.
.
apache portable runtime apache portable runtime apr is a c library that provides cross platform functionality for memory allocation file operations containers networking and threads among others.
it was initially used by apache http server but its use now extends to projects such as libreoffice and apache subversion.
we focused our evaluation on apr s hash table api.
at a high level we add elements to a hash table and then do two symbolic lookups in this table.
the number of keys and lookups was chosen to be the same as for sqlite .
the skeleton code is shown in figure .
we used the default hashing algorithm for the intkeys which is the popular times algorithm used by perl for example.
figure shows the results.
all runs terminate except for merging under bfs and the default search strategy.
merging is also the slowest under dfs taking minutes to terminate.
forking terminates in minutes depending on the strategy.
flat memoryperforms well on this benchmark terminating in minutes.
the segmented memory models svf perform the best terminating in minutes.
memory consumption is small overall.
the most interesting observation about this benchmark is that the segmented memory model with ideal points to analysis performs slightly worse than the one with svf analysis.
this is due to an interesting interaction with the solver.
to understand why we need to describe the relevant memory objects involved.
these are a large .2kb memory object and several small objects totalling about bytes in size.
the ideal points to analysis groups the small objects into a single segment and puts the large .2kb object into a separate segment.
the svf analysis bundles both the .2kb object and the small objects into a single segment.
during execution there are queries involving arrays associated with both the .2kb object and the small objects.
the ideal segmented memory model generates constraints with two arrays one with bytes and one with .2kb.
the svf segmented memory model generates constraints with only a single array.
this gives better solver query caching for svf segmented memory model which results in a quicker runtime.
however we note that this was the only benchmark where such a difference is observed and a more precise points to analysis is otherwise associated with better runtime performance.
however this case study suggest that there is future work in improving caching in symbolic execution which would have implications beyond this memory model.
discussion our experience shows that our segmented memory model can effectively deal with multiple resolutions that occur in the context of complex data structures such as hash tables.
however the model is only useful to the extent that the code triggers such symbolic dereferences.
to get an idea of how our model performs when there are no multiple resolutions we performed an experiment on gnu coreutils version .
.
we first ran all utilities for minutes with klee under the default forking model using depth first search strategy and recorded the number of instructions klee executed for each utility.
then we ran each utility again up to the number of recorded instructions with both the forking model as a sanity check and our segmented memory model using a larger timeout of minutes.
a total of utilities timed out after minutes with the segmented memory model.
for the remaining utilities the segmented memory model was between slower and faster but on average slower.
gnu coreutils are an unfavorable case for our memory model because the lack of multiple resolutions means that the model incurs a cost without any benefits.
while for most utilities the impact is not significant for utilities it is.
the cost is due to the grouping of arrays into memory segments which can significantly increase the difficulty of the constraints sent to the solver.
therefore we believe that our approach should be enabled on demand one would first run the forking approach and only if that run reports several multiple resolution cases with large branching factors switch to the segmented memory approach.
in our experience anything with more than occurrences of multiple resolution with a branching factor of moreesec fse august tallinn estonia timotej kapus and cristian cadar than should be sufficient for our proposed model to become beneficial.
furthermore the approach is particularly useful when one is interested in reasoning about properties requiring all value analysis for the paths explored.
when forking is used such reasoning is not possible as individual control flow paths are split.
if only high coverage is of interest the single object or forking models might sometimes be more appropriate.
our approach also provides a convenient way to trade off forking and all value reasoning by adjusting the threshold for the size of memory segments.
we also note that the flat memory and merging approaches can also perform all value analysis.
we found the merging approach to be a competitive alternative to segmented memory.
however in our experiments the merging approach performed worse overall e.g.
unlike the segmented memory approach merging timed out for all three sqlite experiments and on two out of the three apr experiments and was more sensitive to the search heuristic used.
however in some cases it performed better than the segmented approach e.g.
m4with dfs .
as a threat to validity as mentioned before we note that our implementation of merging might not be optimal but we believe this threat to be small see .
our comparison between the two versions of the segmented memory model one using svf and the other an approximation of the ideal points to sets shows that the precision of the points to analysis directly influences the performance of our approach.
however we found an interesting case where better precision slightly decreased performance suggesting that in some cases merging arrays could be beneficial.
related work symbolic execution has attracted a lot of attention recently with different tools implemented for several different languages .
these tools use different memory models which influence both their power and scalability.
cute introduced a simple memory model which only handles equalities and inequalities for symbolic pointers.
as discussed in .
exe and crest implement the single memory model fuzzball a generalisation of it klee the forking model and an extension of sage and angr the merging model.
a recent idea paper proposes a model that associates symbolic addresses with values along with a time stamp and a condition.
the symbolic memory is then represented as a list of these associations.
when a read occurs the most recent value matching the address and the condition is returned.
esbmc uses a similar technique of chaining if then else expressions to model pointers that can point to multiple objects in the context of model checking.
mayhem creates a new memory object on each read operation which is a subset of the whole memory that the read operation can alias.
this approach is at a high level similar to ours but there are important differences.
in particular the approach does not handle writes via symbolic pointers that may refer to multiple objects instead these pointers are concretised as in the single object model.
furthermore the approach still involves solver queries as in the forking model to determine the objects to which the pointer mayrefer.
unfortunately a direct comparison with mayhem is not possible as the code is closed source and the memory model is complex enough to make a reimplementation difficult.
david et al.
summarise the concretisation approaches such as the ones employed by mayhem and exe by proposing a framework for specifying concretization symbolisation policies.
while our approach strives to avoid the need for concretisation it still uses concrete addresses to identify memory objects.
trt k and strej ek present a fully symbolic segment offsetplane memory model.
they split memory operations involving different types such as ints orfloats into different planes which resemble memory segments but their solution may group together memory objects which would have been separated in our model.
research on lazy initialisation for symbolic execution of java code explores different ways of initialising symbolic memory object