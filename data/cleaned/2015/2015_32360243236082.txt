mode automated neural network model debugging via state differential analysis and input selection shiqing ma purdue university usa ma229 purdue.eduyingqi liu purdue university usa liu1751 purdue.eduwen chuan lee purdue university usa lee1938 purdue.edu xiangyu zhang purdue university usa xyzhang cs.purdue.eduananth grama purdue university usa ayg purdue.edu abstract artificial intelligence models are becoming an integral part of modern computing systems.
just like software inevitably has bugs models have bugs too leading to poor classification prediction accuracy.
unlike software bugs model bugs cannot be easily fixed by directly modifying models.
existing solutions work by providing additional training inputs.
however they have limited effectiveness due to the lack of understanding of model misbehaviors and hence the incapability of selecting proper inputs.
inspired by software debugging we propose a novel model debugging technique that works by first conducting model state differential analysis to identify the internal features of the model that are responsible for model bugs and then performing training input selection that is similar to program input selection in regression testing.
our evaluation results on different models for different applications show that our technique can fix model bugs effectively and efficiently without introducing new bugs.
for simple applications e.g.
digit recognition mode improves the test accuracy from to on average whereas the state of the art can only improve to with times more training time.
for complex applications and models e.g.
object recognition mode is able to improve the accuracy from to over in minutes to a few hours whereas state of the art fails to fix the bug or even degrades the test accuracy.
ccs concepts computing methodologies neural networks software and its engineering software testing and debugging keywords deep neural network debugging differential analysis acm reference format shiqing ma yingqi liu wen chuan lee xiangyu zhang and ananth grama.
.
mode automated neural network model debugging via state differential analysis and input selection.
in proceedings of the 26th acm joint european software engineering conference and symposium on permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
copyrights for components of this work owned by others than the author s must be honored.
abstracting with credit is permitted.
to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
request permissions from permissions acm.org.
esec fse november lake buena vista fl usa copyright held by the owner author s .
publication rights licensed to acm.
acm isbn .
.
.
.
foundations of software engineering esec fse november lake buena vista fl usa.
acm new york ny usa pages.
https introduction artificial intelligence ai especially machine learning ml are becoming an essential part of our daily life evidenced by self driving cars apple face id digital assistants and even the web page advertisements.
increasingly computing systems are becoming a cohesive integration of ai models and deterministic logic just like a human is composed of the brain for intelligence and the body for actions rendering a view of intelligent system orintelligentsoftware that is substantially more capable than traditional computing systems.
for example autonomous robotic systems use ai navigation together with deterministic lower level control algorithms e.g.
pid controller .
alaphago is a computer program that combines traditional program primitives i.e.
tree based search algorithms and deep neural networks nn .
deterministic push down automata are seamlessly combined with nn in machine translation in order to handle recursive natural language structures .
ais are an integral part of computer games which are largely deterministic computing systems .
similar to traditional software component sharing and reusing data engineers also train models and share them on model repositories for reuse in various applications.
for example the python face recognition package has been used in a number of applications.
we envision that data engineering e.g.
ai model training tuning maintenance will become an essential step of software engineering .
just like software inevitably contains bugs and software debugging is a key step in software development process ai ml models may have undesirable behaviors which we call model bugs in this paper and model debugging will be an essential step in intelligent software engineering.
for example a state of the art object classification model can get only accuracy on the imagenet classification challenge and a state of art natural language processing nlp model can get only accuracy on the children s book test challenge .
although these models are dealing with problems with inherent uncertainty such that accuracy is often not achievable there have been research showing that much higher accuracy can be achieved for the aforementioned challenges .
in other words the original models have bugs.
just like that software bugs might have severe consequences model bugs could be catastrophic.
incorrect decisions could cause financial loss e.g.
model driven stock exchange various security and safety esec fse november lake buena vista fl usa s. ma y. liu w.c. lee x. zhang and a. grama issues and even endanger human lives.
for example the newly released iphone x uses a nn based face recognition system known as the face id to unlock the phone and authenticate purchases etc.
however it can be subverted by 3d printed faces .
there are many accidents reported involving self driving cars which use neural network models to replace human drivers .
model bugs can be divided into two categories.
one type is caused by the sub optimal model structures such as the number of hidden layers in a nn model the number of neurons in each layer and neuron connectivity.
we call them the structural bugs .
a lot of existing research falls into addressing these bugs .
the other type is caused by the mis conducted training process e.g.
using biased training inputs .
we call them the training bugs .
our paper focuses on training bugs.
in the rest of the paper we will simply call them model bugs.
machine learning algorithms assume that the training dataset and the real world data follow the same or similar distribution so that the trained models can use features extracted from training data to properly predict unknown real world cases.
unfortunately this is usually not the case.
the distribution of real world data is in general impossible to obtain.
as such a lot of extracted features are problematic e.g.
too specific for certain inputs or do not possess sufficient discriminating capabilities .
however model interpretability is a well known problem in data engineering which states that extracted features are so abstract that humans cannot understand them .
as such unlike software bug fixing which can be achieved by directly changing source code model bug fixing cannot be achieved by directly modifying individual weight parameter values in the model.
the only way to fix model bugs is to provide more training samples trying to make the training data less biased.
existing works use generative machine learning models such as generative adversarial networks gan which can generate input samples similar to real world samples .
however this has limited effectiveness see due to the many inherent challenges such as having a good mechanism to ensure the generated samples are not biased.
software debugging has been intensively studied and there have been many highly effective methods such as delta debugging fault localization slicing and automated bug repairs .
all these techniques work by first identifying the root cause of the bug through some kind of execution state analysis such as contrasting states of failing execution with those of a very similar but passing execution.
as such patching becomes very targeted and hence highly effective.
however such a root cause identification step is missing in existing model debugging techniques .
inspired by the success of software debugging we propose a novel model debugging technique for neural network models.
neural network models can be considered as layers of internal state variables called neurons connected by matrices.
the knowledge acquired in training is encoded in the parameter values of the matrices.
during application given an input a sequence of matrix multiplication operations together with some specially designed thresholding functions e.g.
sigmoid and softmax are applied to classify the input to one of the output labels.
the layers in between the input and output layer are called the hidden layer whose neurons are considered representing abstract features e.g.
shape of a nose .
given a model bug such as poor classification accuracy for a particular output label our technique performs state differential input layer neuron 1st hidden layer neuron 2nd hidden layer neuron output layer neuron terms of neural network models raw input data features relatively primitive features relatively abstract output results figure a simple neural network model analysis that identifies the neurons that are responsible for the misclassification called the faulty neurons .
then an input selection algorithm similar to input selection in regression testing is used to select new input samples that can have substantial influence on the faulty neurons for retraining.
in particular our technique first identifies a hidden layer that is critical for fixing the model bug by measuring if the abstraction denoted by the layer can have substantial impact on classification accuracy.
once the layer is identified our technique further measures the importance of individual neurons features in the layer for correct and faulty classification results of the buggy output label.
for example assume a digit recognition model has a bug in which other digits such as are often misclassified as .
our technique determines the neurons features that are critical for correctly recognizing and those critical for misclassifying others to .
a differential analysis e.g.
the latter subtracts the former is then conducted to identify the features that are uniquely important for misclassification.
we then select inputs that have strong presence of such features for bug fixing.
various differential analysis and input selection strategies are developed for different kinds of bugs.
details are disclosed later in the paper.
our paper makes the following contributions.
we identify that existing model debugging process is not effective due to the lack of understanding or analyzing the root causes of the model bugs.
inspired by state differential analysis and input selection in software debugging and regression testing we propose a novel technique to measure importance of features for classification results locate faulty neurons and select high quality training samples for fixing model bugs.
we develop a prototype mode based on proposed idea and evaluate it on different models.
the results show that mode can effectively and efficiently fix all the model bugs improving accuracy from to on average without introducing new bugs whereas existing methods only work for some cases potentially degrade the model performance and require 11x more training time for the cases it works.
background and motivation .
neural network models and model bugs nn models.
nn models usually has a connected and layered structure with each layer containing a set of neurons .
neurons in two consecutive layers are connected and can transmit signals through their connections.
such connections are represented by a set of matrices.
the values of the matrices are called weight parameters .
training a neural network model is essentially to update weight parameters so that the last layer neurons can produce the expected prediction outputs.
the core technique used for training is known as the backward propagation .
it calculates the gradients of output error with respect to weight parameters.
intuitively a large gradient value indicates changing the corresponding weight can 176mode automated neural network model debugging via ... esec fse november lake buena vista fl usa lead to substantial output variation.
the gradients are fed backward to update the matrices.
training nns is a slow and expensive process.
hence the training dataset is usually divided into multiple batches and the whole training consists of many epochs.
figure shows a very simple neural network model with layers left to right input layer two hidden layers and the output layer .
the input layer takes the raw inputs and passes them to the next layer.
hidden layers are used to extract the features of the input such as nose shape for face recognition.
intuitively each neuron can be considered denoting one special feature.
a hidden layer constructs more abstract features from the features denoted by its preceding hidden or input layer.
in the typical case of a fully connected nn each neuron feature is dependent on connected to all the neurons features in the preceding layer.
in general it is very difficult for data engineers to interpret the meanings of features represented by individual neurons.
after feature extraction the output layer is trained to use the features for application specific tasks such as face recognition or object recognition.
model bugs.
intuitively machine learning extracts features from a given input and compares them with existing knowledge encoded in the model to make decisions.
the quality of the model highly depends on the quantity and quality of the training data.
unfortunately it is very challenging if not impossible to have training data that precisely represent the distribution of real world data.
as such models usually have undesirable behaviors which we call model bugs in this paper.
more formally given a model with specific structural configuration we say that the model is defective buggy if its test accuracy for a specific output label is lower than the ideal accuracy which is achieved when training inputs perfectly model the real world distribution.
note that in this paper we assume the model structure is given and unchangeable.
we do not deal with sub optimal model structure .
instead we investigate if better accuracy can be achieved for the given model structure.
note that many machine learning problems e.g.
face recognition have inherent uncertainty such that accuracy is infeasible.
for example even humans mis recognize faces occasionally.
second since the ideal accuracy is not computable we consider any improvement on the test score a meaningful bug fix .
the effectiveness of a bug fix is measured in two aspects the test score improvement andthe efforts needed to achieve the improvement e.g.
additional training time .
.
model debugging existing model debugging.
as discussed before the only way to fix nn model bugs is to provide more training data.
to overcome the problem of lacking representative data researchers proposed many data augmentation or generation techniques which generates new training samples that are similar to the provided input data samples.
state of the art generative model generative adversarial networks gans mainly consists of two parts the generator and the discriminator .
the generator is responsible for generating artifacts.
it takes a random input e.g.
a noise vector and changes it to something that looks real e.g.
a hand written digit image .
the discriminator is used to determine if the generated artifacts are similar to provided real samples.
it takes the generated samples and real world samples as input and tries to determine which ones are the real world samples.
these networks are trained figure samples generated by different gans together.
when the discriminator cannot tell the difference between real world samples and generated samples the training terminates and the generated samples are used for training the buggy model.
unfortunately existing model debugging techniques have limited effectiveness.
they sometimes even lead to degenerated models.
firstly generative machine learning is highly challenging and current solutions have various limitations .
for example as shown in gans fall short of learning the target distribution and cannot avoid mode collapse i.e.
generator only outputs part of the target distribution.
such generated samples would make the training dataset more biased if added leading to more model bugs.
secondly even if the generated samples were similar to real world samples gan would have difficulty ensuring that the generated samples provide the needed discriminating capabilities for fixing model bugs as it does not look into the reasons why a nn misbehaves .
instead existing works just simply use all generated data or randomly select some samples to fix the bug.
we test different gans for the mnist dataset on a trained model which has problems in recognizing digit .
while the accuracy for the whole dataset is the accuracy for digit is only .
for each gan we generate new samples as the new training data and use all of them to fix the model bug.
the results show that half of the new training sets fail to improve the accuracy for either the model or digit and of them improve the accuracy for the model but not digit .
only gans are able to improve the accuracy for both.
however none of them can improve the accuracy for digit to or higher even after running for hour with all new samples whereas the accuracy can be as high as in minutes using our approach.
note that the original training process finishes within minutes.
such results demonstrate the limitations of existing works.
figure shows some samples generated by different gans.
the right three are those generated by the three gans i.e.
cgan acgan and infogan that achieved improvement.
observe that some samples e.g.
the left three contain substantial noises and are even difficult for humans to recognize.
training with these samples may instead degrade the accuracy of the original model.
another observation is that these samples are very general do not target on fixing the specific defective behavior misrecognizing to .
however without understanding why a digit is mis recognized the generated images of the digit have limited effectiveness in fixing the problem.
software debugging.
our over arching idea is to learn from the substantial experience of software debugging that is built up by the software engineering community over decades of intensive research e.g.
and develop new techniques to address the model debugging problem.
as shown in figure a typical software debugging procedure is as follows.
the developer executes the program with a failure inducing input.
she then inspects the execution state and compares with the ideal correct state that may be derived from her domain knowledge or extracted from similar passing execution s .
we call 177esec fse november lake buena vista fl usa s. ma y. liu w.c. lee x. zhang and a. grama programs state di eren al analysisfault localiza oncode fix random training datainputs models state di eren al analysisfaulty feature localiza onhigh quality training dataprogram debugging exis ng model debugging mode figure software debugging model debugging and mode it the state differential analysis stage.
in this stage she could use simple methods such as gdb or advanced techniques such as delta debugging and spectrum based fault localization that compares states of failing execution s and passing execution s .
through differential analysis the developer locates the root cause and understands the propagation of faulty states.
the root cause could be a single line fault or a more complex fault e.g.
missing functionality .
she then fixes the bug by changing the code.
figure also shows the procedure of existing model debugging in which the data engineer simply feeds more and more training data hoping that the misbehavior could be fixed by the new data.
as explained before neural networks are composed of highly complex inter connected matrices.
a misbehavior is usually due to not just one but a large set of neurons.
furthermore due to the difficulties to understand or interpret neurons it is impossible to directly change weight parameters in a nn like patching source code line s in software debugging.
note that a naive approach that simply adds the failure inducing input and its clones to the training set is very problematic .
this is because nn works by extracting general features from the training data.
adding many copies of an input to the training set causes the over fitting problem meaning that the extracted features are very specific to some inputs and will have poor performance for general inputs.
analogously in human education educators cannot fix a student s misunderstanding by asking her to repeatedly work on the same problem.
otherwise she may just simply memorize the problem and its answer without correcting the underlying misconception.
our idea.
inspired by software debugging we propose a novel neural network model debugging technique that works as follows.
as shown in figure given the inputs related to an output label with buggy behavior e.g.
digit to which many other digits are misclassified model state differential analysis is performed to identify the features that are critical for the misbehavior similar to fault localization in software debugging by program state differential analysis .
we call these features faulty features .
specifically given the buggy output label and a hidden layer we develop a light weight method to determine the importance of each neuron in the hidden layer for the output.
we call it a heat map .
intuitively it is an image whose size equals to the number of neurons and the color of a pixel represents the importance of a neuron for the output .
red denotes thepositive importance i.e.
the presence of the feature is important for the output and blue denotes the negative importance i.e.
the absence of the feature is important .
to facilitate differential analysis we generate two heat maps for an output label l. one is called thebenign heat map that is computed from all the inputs that are correctly classified as land the other the faulty heat map computed a benign b faulty c dhm d failing case e good sample f bad sample figure samples and heat maps from all the inputs that are misclassified as l e.g.
images of and 8in figure d that are misclassified as .
given a specific bug such as under fitting of label the training and testing scores for label 1are both low differential analysis is performed to identify thefaulty neurons that are responsible.
for instance figure a and figure b show the benign and faulty heat maps of label respectively.
observe that the red areas of the benign heat map roughly show the general shape of the digit and the blue areas are the regions that are not part of the digit.
we find the neurons that are present in the faulty heat map but not in the benign heat map as shown in figure c called the differential heat map .
intuitively the highlighted red ones in this differential heat map are the neurons that should be responsible for the misclassification.
this is analogous to that in human education the educator needs to first locate the misconception based on the misbehavior symptom.
after identifying the root cause the next challenge is how to fix it.
as mentioned earlier a prominent difference between model debugging and software debugging is that one cannot directly modify the faulty neurons.
instead we shall reduce their relative influence on the corresponding output label by providing inputs that target training these neurons.
it is a challenge similar to input generation selection in software regression testing.
specifically when changes are made to a software test cases are generated selected to reach the modified code locations to stress test the new logic.
this is achieved by cross checking the coverage of a test case and the target code locations.
therefore in model debugging we generate new inputs using gan or select inputs from the remaining unused training inputs based on the differential heat map .
for instance to fix under fitting of label we generate select images of digit that do not contain features in the differential heat map.
intuitively we are coaching the model to ignore those features that lead to mistakes when recognizing .
figure e shows images that have high priority and are more likely to be selected for further training and figure f shows images that have low priority and less likely selected.
observe that the latter possesses the faulty features the circled areas recognized by our differential analysis.
note that the selected inputs do not necessarily cause misclassification in the original model .
this is critical as using only misclassified inputs would lead to over fitting.
in our example after using selected additional images for digit along with other random samples in training we have improved the test accuracy from to whereas using randomly generated images including over for digit can only achieve .
simply training on all the misclassified images of digit lowers the test accuracy to .
this step is analogous to that in human education the educator provides additional material exercises to correct the student s mis behaviors based on the identified misconception.
these material exercises may not be the ones that the student made mistakes on.
different types of bugs have different kinds of differential analysis.
even for the same kind bug e.g.
under fitting we have multiple patching strategies.
more details can be found in .
178mode automated neural network model debugging via ... esec fse november lake buena vista fl usa design .
overview figure presents the overview of mode .
given a buggy model namely it has over fitting or under fitting problems for a label mode first performs the model state differential analysis with the correctly classified inputs and misclassified inputs for the label and generates the benign and faulty heat maps for a selected hidden layer .
.
the heap maps denote the importance of features for the correct faulty classification results.
as a nn has many hidden layers that represent various levels of abstraction in feature selection we need to select a layer that likely provides the strongest guidance for fixing the bug.
selecting a layer that is too primitive or too abstract may lead to sub optimal results.
in particular the features in a primitive layer close to the input layer may be too general contributing to many output labels .
retraining them may not have unique effect on the target label.
on the other hand the features in a very abstract layer close to the output layer may be too specific so that it is difficult to identify the faulty features e.g.
each feature may abstract part of the faulty behaviors in the earlier layers and contribute a little bit to the misclassification but none of them is dominating.
we develop an algorithm to select the layer that strikes a balance between the two depending on the bug type algorithm .
based on the generated benign and faulty heat maps for the selected layer mode performs various differential analyses according to the bug type to generate the differential heat map which highlights the target features for retraining.
the differential heat map is used as guidance to select existing or new inputs generated by gans or collected from the real world to form a new training dataset which is then used to retrain the model and fix the bug .
.
.
model bug types and fixes as discussed in in this paper a model bug refers to that the test accuracy of a specific label in the model with a fixed structure is lower than the best possible accuracy.
note that the best possible accuracy is usually not due to the inherent uncertainty of the application.
since the ideal accuracy is unknown in practice we consider a model is buggy if its test accuracy can be improved.
for a given model mwith a set lof all possible labels each input can be tagged with a tuple p where is the groundtruth label andpis the predicted label.
based on these tuples the test results can be classified to two categories the correctly predicted inputs p and mis predicted inputs p .
we use si pto represent the input subset whose groundtruth label is and the predicted label ispwith the input dataset i. standard machine learning process involves at least two sets of data the training dataset t and the test dataset dwhich is unknown while training.
sometimes it involves one more validation set.
to measure the performance of the model we define a few terms.
tracc mt st st teacc md sd sd tracc mt calculates the percentage of correctly predicted cases for label on the training dataset known as the training accuracy for label and teacc md measures that on the test dataset known as the test accuracy for label .under fitting bugs.
since the best possible accuracy is unknown in practice we say that a model has an under fitting bug if tracc mt teacc md where is a pre defined value based on concrete applications.
such values can be derived from the statistics of similar models in the wild.
for image processing applications such as face recognition this value can be relatively high e.g.
as neural networks are good at such tasks.
and for many other applications e.g.
natural language processing nlp the value is relatively lower e.g.
.
under fitting bugs mean that the model can neither properly model the training data nor generalize to new data .
this is usually because the unique features for this category are not appropriately extracted or the connections between the unique features to the output label are too weak.
from the training perspective this is because the training samples are too diverse containing many noisy harmful training samples .
to fix the problem we need to provide enough high quality new training inputs.
mode aims to improve the quality of selected input samples.
high quality samples contain a lot of label unique features e.g.
figure e while noisy harmful training samples introduce a lot confusing features to the model e.g.
figure f which are responsible for many mis predicated cases e.g.
figure d .
take the circled red areas in figure f as an example.
they will not help improve model precision but rather induce mis classification.
over fitting bugs.
we say that a model has an over fitting bug if tracc mt teacc md where is a pre defined value based on concrete use scenarios.
the rule means that the training accuracy for label is much higher than the test accuracy.
this indicates that mcan model existing known data very well but cannot generalize to new data.
in other words the model is over trained on some features.
to fix the problem we ought to add samples to the training dataset to downplay such features.
figure shows an over fitting example for digit .
the heat map representation and one example is shown in figure a .
as we can see the model is over fitted to a specific handwritten style that has a cross bar.
as a comparison the heat map of a well trained model with more different handwritten styles of digit and one example style is shown in figure b .
.
model state differential analysis the model state differential analysis is mainly to help data engineers understand bugs in the model that is what features are important for a bug.
in particular it includes selecting the layer whose features are likely to provide the strongest guidance in bug fixing analyzing the importance of the features in the layer for correct faulty classification and generating the heat maps.
layer selection.
as discussed in neural network models extract features through the hidden layers.
a hidden layer closer to the output layer contains features that are more abstract.
the goal of layer selection is to find the layer that is most susceptible for improvement.
the key observation is that the level of abstraction denoted by different layers have various effects for model accuracy.
figure a and figure b show the typical effect test accuracy of using different number of layers.
the solid lines show the accuracy 179esec fse november lake buena vista fl usa s. ma y. liu w.c. lee x. zhang and a. grama differential analysis input selection available new inputs selected inputs training set traget model feature model results heat maps data source gans or real world feature measure traditional neural network training and testing figure overview of mode using mnist as an example a over fitting b normal figure over fitting and normal cases for a under fitting bug b over fitting bug figure test accuracy v.s.
number of layers change along with the number of layers.
at the beginning having more layers leads to significant accuracy improvement because more abstract features are discovered.
at a certain point called the saturation point as shown in the figure the accuracy reaches the proximity of the peak value and the line becomes flat.
this is usually because the extracted features are good enough general as well as unique for a specific task and adding more hidden layers can hardly improve the accuracy.
at the tail of the line as shown in figure b we may observe that adding too many layers leads to accuracy degradation as the features become too specific to the given training data and the neural network is just remembering the training data without generalizing due to the larger capacity provided by the additional layers causing over fitting.
such situations have been well studied by previous research .
it is important for mode to choose a proper layer for the further analysis we call it the target layer .
in particular mode chooses the layer that the accuracy reaches or leaves the saturation point e.g.
the layer denoted by the red lines in figure indicating the edge to advance e.g.
the dotted lines represent the expected performance after bug fixing .
that is mode chooses the first layer that has a limited test accuracy difference with its previously analyzed layer.
intuitively analyzing features in this layer would give us the most prominent evidence of the bug as it denotes the turning point of accuracy improvement.
we have slightly different methods to choose the target layer based on the bug type.
for under fitting bugs mode performs the forward analysis with the direction from the input layer to the output layer whereas for over fitting bugs mode performs the backward analysis with the direction from the output layer to the input layer.
intuitively for under fitting selecting the forward saturation point allows us toidentify the layer where abstraction is about to saturate so that we can add more inputs to enrich the features.
in contrast selecting the backward saturation point allows us to identify the place that the model is about to become over abstracted so that we can add more inputs to suppress faulty features.
algorithm layer selection for under fitting function selectlayer model m dataset ds i m.inputlayer o m.outputlayer lastdis init foreach hidden layer lfrom itowards odo m m.submodel i l m.f reeze lf m m.add o.copystructure lf m .train ds .trainin set ldis lf m .test ds .testset lsimscore bhattachar yyadistance lastdis ldis iflsimscore then return m.layer bef ore l else lastdis ldis return o the algorithm of selecting the target layer for fixing an underfitting bug is presented in algorithm .
it loops over each hidden layer in the forward fashion.
for each layer l it extracts a sub model which contains all the layers up to land then freezes the weight parameters in the corresponding matrices so that the later training would not change their values.
then a new output layer is added that has the same output labels as the original model to construct a new model and this model is known as the feature model figure .
we retrain the feature model with the same training data.
notice that only the last layer is updated during retraining and hence the training efforts are small i.e.
seconds to a few minutes .
intuitively we are trying to use part of the original model and hence the features abstracted by the submodel to make predictions.
it then tests the trained feature model and compares with the result by the previous feature model using the bhattacharyya distance line which is widely used to measure the similarity between probability distributions .
if they are very similar the layer before lis considered the target layer.
the algorithm for over fitting is similar and hence omitted.
measuring feature importance.
after identifying the target layer the next step is to measure the importance of individual features or neurons in this layer for correct and faulty output results.
note that although the nn training process inherently computes certain sensitivity information called gradients which predict how much output changes may be caused by certain weight parameter 180mode automated neural network model debugging via ... esec fse november lake buena vista fl usa changes.
however importance is different from sensitivity .
the former is global and with respect to features whereas the latter is local and with respect to weight parameters i.e.
the connections between features across layers .
specifically sensitivity measures that given the current weight value how much output change can be induced by a small of the weight value.
in contrast importance measures how much influence does a feature have on the classification result of an output label.
an important feature may not have sensitive weights.
for example the red region in figure a denotes the features that are important for recognizing digit .
but their parameters may not have large sensitivity that is small changes to the parameters can hardly impact the classification results.
original model feature modeltarget layer figure overview of feature model generation to measure importance our idea is to leverage the feature model.
recall that the feature model reuses part of the feature selection layers in the original model from the input layer up to the target layer and retrains the output layer which can be considered making predictions based on the features in the target layer e.g.
through the softmax function .
the boxed area in figure represents the selected sub model.
as shown on the right hand side the feature model directly connects the target layer with a new output layer.
the green lines in the feature model connecting the target layer and the output layer are retrained.
after retraining the weight values of the connections from the individual feature neurons in the target layer to a label in the output layer essentially denote the importance of the features for the output label.
specifically we use the matrix representing the connections from the target layer to the output layer to construct a heat map by normalizing the weights to the range .
the absolute value of a weight hence represents the importance of the corresponding feature.
for example in figure the green lines are retrained and represent the importance of individual features for output labels.
the values are hence normalized and used for generating the heat map.
images in figure and figure visualize feature importance.
the red color represents the positive values and the blue color represents the negative values .
features of no or little importance close to are in white.
the number of heat maps equals to the number of output labels and the size of each heat map equals to the size of features neurons .
formally we use hl andwi lto represent the weight value of the ith feature for the label l and a heat map for label l hlcan be represented as hl w0 l w1 l .
.
.
wn l .
differential heat map and input selection differential heat map identifies the features that are critical for the faulty behavior called the faulty features .
this is achieved by contrasting heat maps for correctly classified and mis classified inputs.
specifically given an output label lthat we aim to debug there are two groups of inputs cilrepresents correctly predicated inputs for l and milandw ilcontaining mis predicated inputs with a h1 b h2 c dhci d good e bad figure dhci for digits and mildenoting cases that are misclassified as l and w ildenoting cases of lthat are misclassified as others.
mode generates a heat map for each group hci lforcil hmi lformilandhw i lforw il.
under fitting bugs.
to understand and patch an under fitting bug of label l we need to provide more inputs of label lwith features that are unique for land suppress the faulty features causing misprediction .
to enhance unique features for label l we perform a differential analysis on the correctly predicated dataset cito get the differential heat map dhci which is computed as follows.
dhci l k hci l hci k dhci l dhci l k with k l k l abs dhci l k is min dhci l k computes the importance difference of the feature i between the label landk and dhci l records the smallest difference.
if the value is very small it means feature iis equally important for both land another feature and hence not so unique.
otherwise the feature is very unique to l. figure shows an example of computing dhci 2for the mnist dataset.
in figure c the differential heat map the red color represents the uniquely important features for digit which are not in digit and the blue color denotes the features that are unique for but not for digit .
as we can see the shared important features are now white as the distance is almost .
thus to enhance the unique features we ought to select samples with strong presence of features in the red areas e.g.
figure d and lower the priority of selecting the samples with strong presence of features in the blue areas e.g.
figure e .
to suppress faulty features for label l we perform differential analysis on the mis predicted dataset mil those misclassified as l andcilto acquire a heat map dhmi las follows dhmi l hmi l hci l dhmi l denotes the importance difference of the feature ifor faulty and correct classifications of l. a small absolute value means the feature ileads to similar behaviors in both categories and is hence not very relevant.
a large positive value red indicates that iis particularly important for misclassification and hence faulty.
an example is shown in figure figure a hci figure b hmi and figure c dhmi .
over fitting bugs.
as over fitting bugs are essentially caused by biased training samples whose features are too specific we need more samples especially the ones with more diversity to fix the bug.
the failing samples for the over fitted label tells the most needed features.
thus we perform a differential analysis on these inputs which computes a differential heat map dhw i las follows mhw i l hw i l k with k l k l abs hw i l k is max dhw i l mhw i l hci l hw i l kdenotes the heat map for the inputs of lthat are misclassified as label k.mhw i l computes the maximal importance value that feature ihas for some misclassification.
hence large values 181esec fse november lake buena vista fl usa s. ma y. liu w.c. lee x. zhang and a. grama a benign b faulty c dhmi d good e bad figure differential heat map for over fitted red areas in dhmi lrepresent the features that are unique for the misclassified cases and currently ignored by the model and hence potentially important for generalization.
as a result we ought to select samples with strong presence of such features.
figure shows an over fitting bug.
figure a shows the heat map of the model for digit hci and figure b shows the heat map for cases of that are misclassified as other hw i .
the generated differential heat map dhw i is figure c .
its red areas denote the potential new features for generalizing the model and its blue color areas denote the existing over fitted features.
as we can see in this case the model was trained on small sized digit images and hence large sized digit are mis predicted to other digits e.g.
.
the differential heat map provides clear suggestion that larger digit images shall be used.
input selection.
with the generated differential heat maps we can perform input selection from the available new inputs.
for each new input s we first feed it to the feature model without running through the output layer to acquire a feature value vector vs. for a given input and a differential heat map dh we calculate a score rsl by computing the dot product rsl vs dh.
intuitively the differential heat map is a vector pointing to the most effective direction to fix the bug and thus the score measures the contribution of the input along the direction.
note that mode does not exclusively use new samples based on the scores as we do not want to overfit for the buggy label.
hence we also use additional random samples.
in this paper the ratio between selected and random samples is .
our experiments show that adding too many high scored samples may degrade the final accuracy.
evaluation we implement a prototype on tensorflow .
in the evaluation we aim to address the following research questions rq1 how effective and efficient is mode in fixing model bugs?
rq2 how does mode compare to using random samples or faulty samples to fix model bugs?
rq3 what is the impact of different parameters?
.
fixing model bugs to answer rq1 and rq2 we collect multiple models for a few applications.
these models may be trained on the same dataset with different hyper parameters model structures e.g.
number of layers and activation loss functions etc.
the models have various sizes ranging from 7k parameters e.g.
to over 20m parameters e.g.
.
part of the models and their stats are shown in table .
mnist we use the mnist handwritten digit dataset training and testing samples and collect different nn models from github published by various groups such as google .
fashion mnist fm we use the fashion mnist dataset training and testing samples and models a fm b cifar c od d ac figure samples for evaluated application published on its web page.
figure a shows an example of the application.
cifar for object recognition we use the cifar dataset training and testing samples which contains different images for types of objects with equal number of training and testing samples per type.
we use different classifier implementations from github .
examples are shown in figure b .
we split the original dataset into four parts training set validation set test set and bug fixing set .
the bug fixing set is reserved for fixing the buggy model the training set is used for training only the validation set is used for validating the trained model during training and the test set is assumed unknown during training and only used to test the performance of the trained model.
in order to compare with existing data augmentation generation solutions we collect a large number of gan implementations as well.
for mnist we find different gan implementations for fm we collect different gan implementations from for cifar we find three gan implementations .
also we compare mode with a naive approach that reuses the mis classified data as new inputs.
for each model we select an under fitting bug i.e.
the output label with the lowest training and testing accuracy and an overfitting bug i.e.
the label with good training accuracy but the lowest test accuracy.
the retraining proceeds in batches each having new samples.
after each batch we evaluate the updated model on the test dataset.
if the test accuracy for both the whole model and for the specific buggy label become higher and the accuracy of the label is no longer substantially lower than the model accuracy we consider the bug is fixed.
otherwise we continue training with more batches.
we set a limit of samples or hours for mnist models and all fashion mnist models mnist to mnist5 and fm to fm in table and samples or hours for the remaining mnist models mnist to mnist and cifar models cifar to cifar in table .
for the other two cifar models cifar and cifar as they are extremely large with over million parameters to train for each model we set the constraint to be samples or hours.
if the retraining is not able to finish fixing a bug within the limit according to the aforementioned standard we report the results upon termination.
table shows the experimental results including left to right the model and its size measured by the number of parameters to train the bug type and the accuracy for both the model and the specific buggy label.
for mode we show the number of samples used to fix the bug selected random samples the time used for retraining the test accuracy for the model and the buggy label.
for the gan approach we show the number of gan models that improve the test accuracy by and the highest test accuracy for the model and the buggy label the number of samples used to train this model and the training time.
the last two columns present the results of using all the mis predicated samples to fix bugs.
182mode automated neural network model debugging via ... esec fse november lake buena vista fl usa table fixing model bugs summary model size bug typemacc laccmode randomly selecting gan failing s t macc lacc ?
macc lacc s t macc lacc mnist u 5m 1h2m 7k o 6m 1h4m mnist u 5m 57m 185k o 5m 1h4m mnist u 5m 1h10m 185k o 5m 55m mnist u 5m 56m 185k o 5m 50m mnist u 5m 54m 122k o 5m 54m mnist u 10m 1h58m 244k o 9m 2h mnist u 9m 2h9m 185k o 9m 2h4m mnist u 10m 1h54m 185k o 12m 2h6m mnist u 9m 2h 257k o 9m 2h3m fm u 5m 1h2m 493k o 5m 1h4m fm u 5m 1h9m .2m o 5m 1h3m fm u 10m 1h12m .2m o 9m 1h7m fm u 5m 1h3m 765k o 5m 1h9m fm u 5m 1h3m 113k o 5m 1h fm u 5m 1h3m 26m o 9m 1h2m avg 7m 78m cifar u 6m 1h14m 62k o 7m 1h21m cifar u 15m 2h40m .97m o 21m 2h50m cifar u 30m 4h10m .7m o 24m 4h9m cifar u 12h40m 24h 20m o 12h9m 24h cifar u 10h 24h 20m o 9h40m 24h avg from table we make a few observations.
firstly compared with the other two approaches mode is more effective higher test accuracy and efficient less training time and fewer samples in fixing the model bugs.
in the meantime the model test accuracy is also improved after mode fixing the bugs indicating that mode does not degrade the effectiveness of the whole model.
thus we can say that mode can effectively and efficiently fix model bugs without introducing new bugs.
secondly randomly selecting gan generated inputs can fix some bugs but fails on many others.
also it can potentially introduce new bugs causing the degradation of model accuracy.
even in cases where this approach can fix bugs it requires 11x longer training time and more data samples leading to larger overhead.
figure shows the test accuracy change along with the number of new samples for model mnist during retraining.
as we can see mode can improve the accuracy quickly because of the high quality data samples.
using random selected gan samples can sometimes improve the accuracy but in many other cases it may degrade the accuracy as ineffective bad samples are chosen.
we consider the feature of quick improvement is very important when the retraining budget is limited.
furthermore directly re using mis predicted samples as the new training samples to fix bugs in most cases leads to the over fitting problem causing the degradation of test accuracy.
another observation we have is that even though the buggy model is trained with less training data the root cause of the bug is not because of lacking training figure test accuracy vs. training samples table accuracy improvement without gans model bugoriginal mode random macc lacc macc lacc macc lacc fr of .1m uf od of .2m uf ac of 30m uf data.
notice that even after mode fixes the bug with new training data the total training data is still smaller than the original dataset.
however many models actually achieves better performance than training with the original dataset.
for example the mnist model achieves test accuracy on the training samples while mode achieves with of this plus new samples.
applications without inputs by gans.
we also evaluate rq1 and rq2 for applications and models without available gans to generate new inputs.
we divided the dataset into parts as described before.
given a model bug we use mode and the random selection approach to select the same number of inputs from the reserved dataset as the new training data to fix the bug and measure the improvement of each method.
here we select inputs to retrain.
the retraining time ranges from minutes to minutes.
due to the space limit we only use one model for each application face recognition fr we use the labeled faces in the wild lfw dataset training and testing samples and the model is directly obtained from github .
object detection od this model tries to detect the existence of eyeglasses.
the images are from the celeba dataset training validation and testing samples .
age classification ac this classifier predicts the age group of a person based on the dataset from the oui adience face image project training and testing samples .
the ages are divided into groups.
as this is a very difficult problem even with human intelligence the model is measured not only by accuracy but also by off one accuracy meaning that a prediction result is considered correct if it is the ground truth or a one step neighbor of the ground truth.
the experimental results are shown in table .
for ac both accuracy and one step accuracy are reported.
observe that for these applications mode is still highly effective in improving the accuracy for over fitting of or under fitting uf bugs for both the model and the buggy label.
randomly selected inputs are helpful in general.
but they are less effective.
sometimes they lead to accuracy degradation e.g.
the over fitting bug for the age classification .
debugging pre trained models.
another experiment we did is to apply mode onmodels that have relatively high accuracy and do not have obvious bugs in output classes.
we use an iterative method to fix the bugs.
during each iteration we first identify the most buggy 183esec fse november lake buena vista fl usa s. ma y. liu w.c. lee x. zhang and a. grama table real world models bug fix dataset model original acc.
samples mode acc.
random acc.
mnistmnist .
.
.
mnist .
.
.
fashion mnistfm .
.
.
fm .
.
.
cifarcifar .
.
.
cifar .
.
.
figure effects of selecting different target layers figure effects of using different output class by calculating the difference between the training accuracy and validation accuracy and use mode to fix the bug.
the procedure continues until the accuracies for each output class are above a threshold or the model accuracy cannot be improved.
we use real world pre trained models that are trained on the original dataset with relatively high test accuracy and no obvious bugs for all output classes.
to fix these model bugs we use collected gans to generate the validation dataset and bug fix datasets and compare mode with the random input selection approach.
table summaries the results.
for each model we show the original model accuracy column the number of new samples used to fix the model for both approaches column the new accuracy using mode column and the average accuracy of using the random approach times column .
from the table we can clearly see that mode is more effective and efficient than using the random approach in all cases.
.
design choices to answer rq3 we perform a number of experiments using different parameters to see how this affects the performance of mode .
effects of layer selection.
in we discussed choosing different layers to generate heat maps may affect the effectiveness of mode .
in this experiment we study such effects.
figure shows cases under fitting bugs and over fitting bugs on different models mnist to mnist .
all these four models have layers.
as we can see there is always an optimal layer that leads to the best test accuracy.
also our proposed method algorithm is able to select the optimal layer for all cases.
this demonstrates the effectiveness of layer selection.
the experiments on a few other applications and models demonstrate the same result.
details are elided.
ratio between selected data and random data another important parameter in mode is the percentage of selected data samples in the new training dataset.
due to space limitations weonly show the results of the mnist model and the conclusion is applicable for other models.
figure shows the test accuracy change for both the model and the buggy label during training using three different values .
.
and .
.
when the value is very small .
mode can still fix the model but requires a lot more training samples and time.
when using a proper value in this case .
mode can fix the model bugs with the minimal training efforts.
when the value is too large such as .
mode can quickly improve the test accuracy for the buggy label but in the meantime easily triggers over fitting leading to degradation of test accuracy for both the model and the buggy label.
related work our work is inspired by software engineering techniques especially software debugging and regression testing.
software debugging has been extensively studied producing a large number of highly effective techniques see .
many of these techniques work by performing differential analysis on program execution states e.g.
comparing variable values in passing and failing runs .
the success of these techniques inspires us to contrast nn model states.
however different from software debugging model bugs cannot be fixed by directly changing model parameters but rather through retraining.
the inter dependencies of model internal states are much more complex compared to program dependencies requiring different solutions.
in regression testing how to efficiently select prioritize test cases is an important challenge.
there are also many highly effective solutions the basic idea is to check the correlations between individual test cases and code modifications.
this inspires us to select inputs for model debugging by comparing the strong features possessed by individual inputs and the features that we target to modify.
machine learning techniques are widely used in various software engineering applications .mode has the potential to facilitate researchers to debug their models.
in recent years researchers proposed various methods to address the machine learning model debugging problem .
however these techniques are limited to specific machine learning model types and cannot handle complex models like neural networks.
furthermore they do not perform differential analysis to identify faulty features before fixing them.
in researchers aim to identify incorrect items in the training set and clean up training data.
here incorrect data means corrupted data e.g.
illformatted xml files .
these work are orthogonal to mode .
there are also works aiming at providing provenance information and explanation of models to data engineers to help them understand or debug the models.
they require human inspection while mode is an automated technique.
conclusion inspired by software debugging and regression testing techniques we propose and develop mode an automated neural network debugging technique powered by state differential analysis and input selection.
it can help identify buggy neurons and measure their importance to guide the new input sample selection.
mode can construct high quality training datasets that effectively and efficiently fix model bugs without introducing new bugs.
184mode automated neural network model debugging via ... esec fse november lake buena vista fl usa