automatically assessing crashes from heap overflows liang he yan caiy hong huz purui su yx zhenkai liangz yi yang huafeng huang jia yan xiangkun jia dengguo feng y trusted computing and information assurance laboratory institute of software chinese academy of sciences beijing china ystate key laboratory of computer science institute of software chinese academy of sciences beijing china zdepartment of computer science national university of singapore fheliang purui yangyi yanjia huafengg iscas.ac.cn liangzk comp.nus.edu.sg fycai.mail huhong789 ajiahitg gmail.com fengdg .net abstract heap overflow is one of the most widely exploited vulnerabilities with a large number of heap overflow instances reported every year.
it is important to decide whether a crash caused by heap overflow can be turned into an exploit.
efficient and effective assessment of exploitability of crashes facilitates to identify severe vulnerabilities and thus prioritize resources.
in this paper we propose the first metrics to assess heap overflow crashes based on both the attack aspect and the feasibility aspect.
we further present hcs ifter a novel solution to automatically assess the exploitability of heap overflow instances under our metrics.
given a heap based crash hcs ifter accurately detects heap overflows through dynamic execution without any source code or debugging information.
then it uses several novel methods to extract program execution information needed to quantify the severity of the heap overflow using our metrics.
we have implemented a prototype hcs ifter and applied it to assess nine programs with heap overflow vulnerabilities.
hcs ifter successfully reports that five heap overflow vulnerabilities are highly exploitable and two overflow vulnerabilities are unlikely exploitable.
it also gave quantitatively assessments for other two programs.
on average it only takes about two minutes to assess one heap overflow crash.
the evaluation result demonstrates both effectiveness and efficiency of hcs ifter .
index terms memory error heap overflow vulnerability assessment i. i ntroduction heap based buffer overflow is one of the most widely exploited vulnerabilities in recent security incidents.
highrisk heap overflow errors can be leveraged by attackers to execute arbitrary code or leak sensitive information such as passwords and encryption keys while low risk heap overflow errors may only lead to denial of service attack dos .
given the large number of heap overflow errors reported every year it is ideal to assess their severity efficiently and effectively so that resources can be allocated towards high risk ones for timely analysis and patching.
the representative assessment of the severity is the exploitability the likelihood that a heap xcorresponding author.overflow error can be utilized to launch the attacks to run arbitrary code.
an ultimate way to demonstrate the exploitability of a vulnerability is to generate working exploits.
previous works study the practical viability to automatically generate exploits.
one mechanism is to symbolically execute the whole program and capture the program constraints as predicates.
then it generates working exploits by solving the constraints.
aeg and mayhem are representative ones in this category.
though using exploit generation as a way for assessment is accurate they cannot generate exploits for all potential vulnerabilities due to the limitation in program analysis techniques.
another assessment method is to analyze the code executed after the crash point the instruction leading to the program crash.
for example the !exploitable tool developed by microsoft checks all instructions in the same basic block as the crash point to find exploit points the exploitable specialpurposed instructions like control flow transfer instructions e.g.
call andjmp or condition affecting instructions e.g.
cmp followed by jnz .
crax takes a mixed method with these two techniques starting from the crash point it symbolically executes the program to find exploit points.
the weakness of this type of solutions is the correctness of results.
the corruption usually affects the original program behavior e.g.
due to crashes on dereferencing pointers from the overflowed memory preventing these techniques from finding any exploitable points.
moreover these tools will stop work when a crash occurs leading missed potential exploit points.
in this paper we aim to address the challenge in automatically assessing the exploitability of crashes caused by heap overflow when no working exploits can be easily generated.
we propose a set of metrics to quantify the exploitability of heap overflows.
to the best of our knowledge this is the first approach that aims to automatically assess the exploitability of heap overflows.
our metrics are based on two aspects .
c ieeease urbana champaign il usa technical research new ideas274 authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
theattack metrics and the feasibility metrics.
the former measures the potential threats of a heap overflow and the latter measures the specific difficulties to build a real working exploit.
based on the metrics we present a framework hcs ifter1 for automatic heap overflow crash assessment.
hcs ifter accurately detects heap overflow errors through dynamic program analysis.
it tracks all heap objects and checks related operations to find the out of bound heap memory accesses.
the detection happens right before the real execution of the corruption point the instruction leading to the heap overflow.
to extract features of the overflow s impact on the program execution hcs ifter dynamically carries out data recovery in the corrupted memory region so that the program can continue its normal execution for our analysis.
note that compared with other dynamic approaches this is a key step to continue the execution after a heap overflow occurrence without any crashes enabling hcs ifter to explore additional exploitable points.
during the dynamic subsequent execution hcs ifter tracks all recovery memory regions and detects exploits based on exploit patterns.
we also identify several novel strategies that enable hcs ifter to detect exploit points missed by other techniques.
in this paper we aim to assess a single path from a given crash.
if multiple paths exist our technique can be applied on each path separately.
it is possible to find other paths from a crash with fuzzing tools or symbolic execution tools .
in summary the contributions of this paper include we propose a set of novel metrics for quantifying the severeness of heap overflow crashes.
our metrics measures the challenges to convert crashes into exploits including both the potential attack aspect and the feasibility aspect.
we design and implement a prototype tool hcs ifter which automatically assesses the exploitability of given heap overflows based on our metrics.
hcs ifter introduces dynamic memory recovery and second order overflow to automatically assess the difficulties for exploit generation.
we evaluated hcs ifter using real world vulnerable programs.
the results demonstrated both the effectiveness and efficiency of hcs ifter .
ii.
p roblem definition and challenges in this paper we aim to assess the exploitability of given heap overflow errors.
we define the problem as follows assessment of heap overflow crash given a binary with a heap overflow bug and a proof of concept poc that crashes the program we aim to quantify the severeness of the error i.e.
the likelihood for attackers to further develop this crash into a working exploit such as arbitrary memory access or code execution attacks.
1standing for heap crash sifter.table i exploit point types.
taint means user input data.
exploit points description call jmp taint directly call jump into the tainted target call jmp indirectly call jump into the target with a tainted address mov taint2 write a tainted value taint2 into the memory location with a tainted address taint1 mov read the value at a tainted address taint1 and write it to the tainted address taint2 critical func taint control the arguments of security critical functions different from exploit generation which generates a concrete working exploit we aim to estimate the level of difficulty for attackers to build a working exploit.
the output should be a quantitative assessment that describes the severity of the error.
for example program developers can use the assessment result to prioritize the fix of highly exploitable overflows considering the limited human resources.
further the assessment result can also be used by exploit generation tools to focus on overflows with high exploitability.
challenges in assessment our approach is based on dynamic program analysis to address the problems.
several challenges must be resolved c1 preserving the program execution.
in the dynamic code analysis the first consideration is to continue the program execution after the corruption point which is required by our approach to further analyze the impact of the overflow.
directly continuing the execution after a heap overflow is infeasible as the subsequent execution usually crashes due to invalid memory access.
c2 bypassing the integrity checks.
it is problematic if a heap overflow overwrites the meta data of free heap chunks such as the backward and forward pointers which are protected by heap manager.
if the overflow has to overwrite the meta data to reach one exploit point the attack needs to bypass the integrity checks of heap data structure.
c3 preserving the memory layout.
heap memory is dynamically allocated by the heap manager.
the order of heap allocation and free significantly affects the memory layout.
analysis code in the same memory space with the vulnerable program may change the memory layout and thus affect the assessment of the exploitability.
the analysis should be performed in a different memory space from the vulnerable program.
iii.
e xploitability metrics as one of our main contributions we first propose two kinds of metrics to measure the severity of heap overflow crashes.
the metrics should not only reflect the possible exploit methods an attacker may choose but also the difficulty to build working exploit in real world programs.
specifically we define two types of metrics to assess the features of the crashing program attack metrics andfeasibility metrics.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
a. attack metrics attack metrics describe the potential risks that a heap overflow may introduce.
intuitively if a heap overflow introduces more risks e.g.
corrupt more function pointers it becomes easier for attackers to utilize the overflow.
exploit point exp as different exploit points have different attack power we define five types of exploit points as shown in table i where taint1 and taint2 indicates the user input data.
this metric is crucial as more exploit points means higher exploitability of the error.
overflow bytes ob a larger memory area corrupted by a heap overflow usually means a higher threat.
and it also means that more exploit points may be found.
we use the number of the overflowed bytes to depict the basic information of a heap overflow.
taint bytes tb for attackers who exploit a heap overflow to execute arbitrary code usually need to fill a proper length of payload within the input data.
it is a common fact that a more complex payload needs more space to be filled with.
so having more taint bytes means the ability to fill more complicate payload.
taint relation tr we need to confirm that the overflow bytes are tainted i.e.
from user input data .
if so attackers could provide arbitrary payload i.e.
malicious code to fill with them.
we use this metric as the basic information of heap overflow.
b. feasibility metrics feasibility metrics depict the difficulties to build a real working exploit.
we define two kinds of feasibility metrics.
the first one is the count of various pointers corrupted by heap overflow and the second one is the value constraint of overflowed bytes.
intuitively if a heap overflow involves more such elements e.g.
more pointers that will be dereferenced it becomes more difficult to exploit the overflow.
pointer dereference count pdc as one main challenge faced by attackers is to ensure that all the memory accesses along the program path during an attack are not affected.
otherwise memory dereference may lead to the program crash due to corrupted pointers.
based on the types of pointers possibly corrupted we define the pointer dereference count as a four tuple which includes the counts of four types of pointers index pointer ip where the corrupted data is an index pointer offset of a memory access for example mov eax .
the register esi is used as the index pointer in the memory access and a memory access error will happen if esi is loaded with a large number.
however it is not difficult for attackers to preserve the correctness of such memory accesses e.g.
set the register esi to be .
base pointer bp where the corrupted data is a base of a memory access for fetching data forexample mov eax .
the register ebx is used as the base pointer for memory access.
due to the address randomization it is challenging to guess all the randomized pointer values correctly to avoid the crash.
multilevel pointer mp where the corrupted data is an pointer to another pointer.
compared to bp where attackers can search and use any existed memory it is more challenging for attackers to find a proper pointer s pointer.
protected pointer pp os or special program logic checks or protects whether a pointer is corrupted such as the safe unlinking of windows .
this usually means that the exploiting process is very difficult and attackers have to bypass the protection checking.
specifically based on the real world situation we define the order of difficulty levels for these metrics as follows with increasing difficulty to exploit ip bp mp pp value constraint vc different applications usually have their own strategies to check the validation of various input data.
in this work we only extract the value constraints for the data used to overwrite heap memory.
note that vc does not directly affect our assessment however it plays an important role in building working exploits as it strictly indicates that some characters e.g.
0x0 0xa cannot appear in the designed payload by attackers.
iv.
hcs ifter framework we present the design details of our framework hcs ifter .
as shown in figure hcs ifter works in three steps heap overflow identification exploit point shortlisting and exploitability assessment.
it tracks all heap related operations with a multi semantic taint analysis engine which treats the input poc heap object and recovery memory as different kinds of taint data.
then hcs ifter detects cross boundary heap accesses at both the instruction level and the function level section iv a .
it then identifies memory objects that can be exploited by attackers section iv b .
we further analyze exploitable code patterns and identify second order overflow attack techniques.
in the last step for each exploitable code pattern hcs ifter analyzes related memory operations to evaluate the difficulty level of exploitability section iv c .
a. heap overflow identification the goal of this step is to identify the location of the heap overflow vulnerability so that we can record and recover the corrupted data by heap overflow.
hcs ifter utilizes dynamic taint analysis to identify heap overflows.
we firstly taint the base address and the size of the allocated heap blocks.
when accessing tainted memory addresses we check whether the access is out of the bound of the allocated heap blocks.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
exploitability assessmentexploit point shortlistingheap overflow identificationprogram input multi semantic taint analysisrecoveryheap allocation exploitability exploit points?
yesassess... snapshotfig.
.
the hcs ifter framework.
hcs ifter takes as inputs the binary of the vulnerable program and the error exhibiting input.
it executes the program in a virtual environment to detect the heap overflow at run time.
then hcs ifter restores the memory to continue the execution.
at last it detects the exploit points and evaluates the exploitability.
taint source.
to label information of the allocated heap blocks as tainted hcs ifter hooks the heap allocation functions e.g.
rtlallocateheap on windows system .
taint propagation.
hcs ifter propagates the taint value at the instruction level using the standard taint propagation mechanism.
due to taint explosion hcs ifter does not take control flow dependencies into account.
more details on taint analysis can be found in .
taint checking.
with the base address and the size information propagated by taint analysis hcs ifter checks every memory access to identify heap overflows.
specifically for an instruction involving a pointer it retrieves the taint value of the pointer operand used for the memory access.
from the taint value it restores the base address of the heap object and the allocated size.
it then checks whether the pointer value falls into the base address and the end address of the heap object.
b. exploit point shortlisting once the heap overflow vulnerability is detected hcsifter analyzes the heap memory that can be corrupted by the overflow to identify data types discussed in the second point below that can be exploited by attackers.
we first present the techniques for recovering the program s execution after the heap overflow.
dynamic heap data recovery as discussed in section ii the first challenge to detect exploit points is to preserve the program execution after the memory corruption.
to address this challenge c1 hcs ifter recovers the corrupted data back to the uncorrupted version so that the program can continue its execution without any crash.
by watching the following executed instructions we can find the usage of the corruptible data.
the usage of the data is important to assess the exploitability.
we use dynamic taint analysis to track the corruptible data.
during the dynamic data recovery we label each recovered data with the offset from the first overflowed bytes.
in the following execution we propagate the taint value as for the heap pointers.
exploit point detection we aim to detect the exploit points the instructions that can be used by attackers to launch attacks based on the data type affected by the heap overflow.
we classify data into types like code pointers data pointers loop bounds.
the data type can be inferred by the program s behavior.
a heap data can directly affect program s code execution or the memory access if some program variables derived from it tainted by its offset are used as pointers to code and data.
in addition a heap object can indirectly affect memory accesses if memory addresses are control dependent on it.
control dependent means the heap object affects the control flow and at the same time the memory access happens inside the code under the control.
for example if a heap data is used as a counter of one loop the memory access in the loop body is control dependent on this heap data.
exploitability by second order overflow to address the challenge c2 we identify an interesting heap meta data that can cause second order heap overflows.
it is the size field in the header of a free chunk.
the method to trigger the secondorder overflow is to change the value of size field into a larger value.
we call this method sizeoverflow.
the basic idea is during heap allocation if the heap manager checks the value of size field in the header of the overflowed free chunk whose value has been tampered be to a larger one e.g.
0xffff then this free chunk will be allocated.
the following memory access into this chunk may lead to new buffer overflows as its size is believed to be larger than the actual one.
this opens a new chance to explore additional exploit points.
compared with the exploit type defined in section iii a which are direct exploit point dexp we call this data as indirect exploit point iexp .
c. exploitability assessment besides the exploit points hcs ifter collects the feasibility metrics especially the count of pointer dereferences from the corruption points to exploit points.
this kind of metrics will depict the real difficulty to reach the exploit points.
we assess the exploitability with two basic rules as follows rule if there is no pointer dereference from the corruption point to any direct exploit point we treat it as an exploitable error.
if there is any pointer dereference from the corruption point to any exploit point we treat it as a difficult error and we use nearest exploit point s highest difficulty level defined in section iii b as the assessment result.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
table ii exploitability assessment overview.
the 2nd main columns give the details of heap overflow.
means indirect table look up operation b!0x0 means each byte cannot be 0x0 b!0xa means each byte cannot be 0xa.
means further exploitability is possible with a higher order 2nd order overflow.
programsheap ov erflow information basic metrics exploitability assessment instruction function ob tb tr vc !exploitable hc sifter 1clickunzip mov al lstrcp ya b!0x0 acousitca con verter mov cl lstrcp ya b!0x0 unkno wn coreftp client repmo vsd recv b!0xa unkno wn foxitreader mov al lstrcp ya b!0x0 httpdx repmo vsd memcp y b!0xa unkno wn python repmo vsd memcp y b!0x0 vallen zipper mov al lstrcp ya b!0x0 unkno wn wmplayer repmo vsd zipitf ast readfile rule if the error is reported as difficult according to rule and there exists any indirect exploit point from corruption point to the nearest exploit point we enable the second order overflow and repeat the assessment with the rule above.
we measure the pointer dereference as follows we collect all instructions between the corruption point and the exploit point that access tainted address to deference memories and put them into a set s. we retrieve the offsets of the bytes that affect the exploit point and find the maximum offset max.
for any instruction inside s if its memory operand is tainted with offset off andoff max we count the dereferences by its types.
the final value of the derefcount is the number of necessary tainted dereferences.
v. i mplementation and evaluation summary a. implementation we extend qemu to support the instruction instrumentation and the dynamic taint analysis outside the guest system.
unlike the temu that needs to install extra drivers into guest system we only use the emulated hardware information provided by qemu to implement our system.
by so we can preserve the memory layout of guest system c3 .
hcs ifter uses the udis86 library to help disassemble x86 instructions.
our implementation supports about x86 instructions for dynamic taint analysis including the special support for float point registers fpu and sse registers xmm mmx .
our implementation totally contains more than lines of code including lines of c code for dynamic instruction instrumentation and data recovery in qemu and lines of c c code for multi semantic taint analysis and exploitability assessment.
b. summary of evaluation benchmarks and experiment setup we configure hcsifter to run on a platform with core cpu 8gb ram installed with ubuntu .
x86 system.
we run windows xp sp2 as a guest virtual machine to execute the vulnerableprograms.
to evaluate hcs ifter we collect windows programs with heap overflows from exploit db .
all these programs are available either on the exploit db site or at their official websites.
efficacy in exploitability assessment we apply hcsifter on the nine real world heap overflow programs with crash pocs and compare the result with the widely used tool !exploitable.
hcs ifter demonstrates its ability to accurately locate heap overflow instructions which is the base of our assessment.
as shown in the column of heap overflow information hcs ifter confirms all nine known heap overflows.
the major column basic metrics in table ii shows the assessment reported by hcs ifter .
in the column exploitability assement of table ii we show the exploitability assessment for all nine programs.
it reports that five programs can be directly exploited and two programs almost cannot be exploited unless the attackers have the ability to bypass the integrity checker .
besides there are two easily exploited 1clickunzip and coreftp client as the attack is constrained only by index pointers .
importance of indirect exploit points and sizeoverflow indirect exploit points play an important role in the exploitability assessment.
among five exploitable programs one of them i.e.
foxitreader can only be easily attacked with the indirect exploit points as it has one bpbefore the direct exploit point in the first round.
two programs the 1clickunzip and the coreftp client only leave the exploit chance in the indirect exploit points.
for 1clickunzip the indirect exploit points in the second round provides further exploitability.
assessment performance our performance evaluation shows that hcs ifter can finish one assessment efficiently with less than minutes on average and at most minutes.
for the memory overhead hcs ifter uses mb more memory on average than the original qemu execution.
such a memory consumption is acceptable on modern systems.
vi.
r elated work there are two main aspects related to our work in this paper.
the first one is the automatic exploitation generation.
the authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
second is the detection of software overflows especially the heap overflow as focused in this paper.
automatic exploitation generation.
brumley et al.
proposed the first patch based automated exploitation of software vulnerabilities.
later by integrating preconditioned symbolic execution and dynamic instruction instrumentation avgerinos et al.
implemented the first end to end system for fully automatic exploit generation.
in practice it is common that program source code is unavailable.
therefore binary code based exploit generation is required.
mayhem is the first one practically targeting on binary programs to automatically generate exploitation.
polyaeg further targets to generate multiple exploits for a given vulnerable program based on control flow hijacking and redirection.
flowstitch targets to automatically generate data oriented exploits by searching ways to join program data flows.
detection of heap overflows.
robertson et al.
proposed to append additional protection data at the head or the tail of a heap to detect buffer overflows .
during a buffer overflow the protection data is broken and can then be detected.
besides the protect data inaccessible memory pages could also be allocated to detect buffer overflows .
low fat pointer takes a method to detect heap overflow at run time.
it encodes the heap object information in addresses to propagate the information and to detect the buffer overflow.
the most related work to our approach is proposed by slowinska et al.
which is based on binary data structure reversal.
the approach assigns different colors to different heaps and monitors each heap access.
however this approach heavily relies on binary data reversal which will result in imprecision i.e.
false negatives .
vii.
c onclusion heap overflow is a severe threat to computer programs.
however it is a tedious work to determine whether a heap overflow is exploitable or not.
in this paper we propose hcs ifter a platform that automatically evaluates the exploitability of given heap overflows.
hcs ifter incorporates two kinds of metrics proposed in this paper to assess a heap overflow crash.
we implement hcs ifter as a prototype and evaluate it with nine real world vulnerable programs.
the experimental results show that hcs ifter is effective and efficient on evaluating heap overflows.
acknowledgment this work was supported by the national natural science foundation of china no.
national program of china 2014cb340702 and the youth innovation promotion association of the chinese academy of sciences yicas .