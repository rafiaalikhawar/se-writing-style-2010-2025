cradle cr oss backend va lidation to d etect and localize bugs in de ep learning libraries hung viet pham thibaud lutellier university of waterloo canada hvpham tlutelli uwaterloo.caweizhen qi ustc china zkdqwz mail.ustc.edu.cnlin tan purdue university usa lintan purdue.edu abstract deep learning dl systems are widely used in domains including aircraft collision avoidance systems alzheimer s disease diagnosis and autonomous driving cars.
despite the requirement for high reliability dl systems are difficult to test.
existing dl testing work focuses on testing the dl models not the implementations e.g.
dl software libraries of the models.
one key challenge of testing dl libraries is the difficulty of knowing the expected output of dl libraries given an input instance.
fortunately there are multiple implementations of the same dl algorithms in different dl libraries.
thus we propose cradle a new approach that focuses on finding and localizing bugs in dl software libraries.
cradle performs cross implementation inconsistency checking to detect bugs in dl libraries and leverages anomaly propagation tracking and analysis to localize faulty functions in dl libraries that cause the bugs.
we evaluate cradle on three libraries tensorflow cntk and theano datasets including imagenet mnist and kgs go game and pre trained models.
cradle detects bugs and unique inconsistencies and highlights functions relevant to the causes of inconsistencies for all unique inconsistencies.
index t erms deep learning software testing crossimplementation testing bugs detection software testing i. i ntroduction deep learning dl is widely used in many domains including aircraft collision avoidance systems alzheimer s disease diagnosis autonomous driving cars and romance storytelling .
bugs in such systems can cause disastrous consequences e.g.
a software bug in uber s self driving car dl system has resulted in the death of a pedestrian .
users of dl systems have a diverse range of background including people with little technical backgrounds e.g.
singers songwriters have used dl to compose music .
the pervasive use of dl systems requires them to be highly reliable.
unfortunately dl algorithms are complex to understand and use.
average users do not know all the details of dl algorithms.
high level dl application programming interfaces apis have been developed to enable users to build dl systems without knowledge of the inner working of neural networks.
these high level apis rely on lower level libraries that implement dl algorithms.
figure presents the structure of typical dl libraries.
developers write code using high level library apis e.g.
keras api .
these apis invoke low level libraries that implement specific dl algorithms.
low level libraries suche e b y ?
y h fig.
overview of dl libraries.
as tensorflow google theano and cntk microsoft implement the same algorithms e.g.
convolutional neural network cnn and recurrent neural network rnn .
low level libraries use different input formats and provide different apis while a high level library allows users to seamlessly switch among different low level libraries.
the components that invoke low level libraries are referred to as the interfaces between the high level libraries and the lowlevel libraries.
each interface and low level library referred to as a backend provides an implementation of dl algorithms.
the backend trains and tests dl models.
a dl model contains a dl network and parameters also known as weights .
keras is the most popular high level library for deep learning .
keras has been used to implement neural networks in critical domains including aircraft collision avoidance systems inflammatory bowel disease diagnosis chemical reaction predictions medical imaging air quality control and computer network security .
the backends and the high level libraries contain bugs which are particularly challenging to find and fix .
one key challenge is that it is difficult for developers to know the expected output given an input instance.
dl backends implement dl models that use complex networks and mathematical formula.
thus it is hard for humans to produce the expected output of a dl backend given an arbitrary input instance if possible at all.
for example given an input image of digit ground truth and a digit classification model the expected output of that model on that image is not necessarily as it is common for a model to misclassify due to its limitations classification accuracy is rarely achieved .
existing dl testing work focuses on generating input instances that make the ground truth and the model output disagree so that dl users and builders can improve the model.
ieee acm 41st international conference on software engineering icse .
ieee authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
a input image petri dish b top inceptionresnetv2 return x mean c.sqrt var epsilon gamma beta return x mean c.sqrt var epsilon gamma beta c bug fix in batch normalization in the cntk backend.
fig.
a bug found by cradle in the cntk backend which has been fixed after we reported it.
models must be implemented by backend libraries.
if the backend libraries fail to faithfully implement a model e.g.
due to a bug in the backend the output from the backend can be wrong even if the model is correct and vice versa.
an incorrectly implemented dl backend may cause the aforementioned digit classification model to output for the same image of even if the expected output of the dl model is .
alternatively the dl backend may output accidentally matching the ground truth.
the wrong outputs could mislead dl users and builders in their debugging and fixing process.
the output masks the implementation bug which makes it challenging to be detected.
there has been little attention to testing the correctness of the models implementation .
instead many techniques test the correctness of the models which assume that the backend implementation is correct.
both the model and the backend implementation need to be correct for dl algorithms to produce a correct output.
the critically important task of testing dl backend implementation is challenging since the expected output of the backend is hard to obtain as explained.
the multiple implementations i.e.
the dl backends of the same functionality i.e.
the same dl algorithm provide us a unique opportunity to detect inconsistencies among these implementations to find bugs in dl backend libraries.
for example if the same cnn model which is the same cnn network with identical weights behaves differently when running on the two cnn implementations e.g.
tensorflow and cntk one of the cnn implementations is likely to be incorrect without knowing the expected output.
figure shows a bug that causes two backends to be inconsistent.
the input image figure 2a is manually labeled as a petri dish the ground truth in imagenet a popular dataset of manually labeled images .
figure 2b shows the classification results of this image by the pre trained model inceptionresnetv2 on keras .
.
with tensorflow and cntk backends respectively.
while the model with tensorflow backend classifies the image as a petri dish correctly as its first choice the same model with cntk classifies the image as an analog clock with petri dish not in the top .once an inconsistency is detected a big challenge is to identify the faulty functions among many functions in the dl backend libraries.
for example one run that exposes the inconsistency bug in figure contains invocations of backend functions.
following the complex invocation path of the inceptionresnetv2 model it is difficult for developers to tease out that the batch normalization function is faulty.
to automatically detect and localize such inconsistencies across dl backends we propose and implement a novel approach cradle .
given a dl model and its input data cradle uses two distance metrics to compare the output of a model on different backends to detect inconsistent output and identifies the location of the inconsistency by tracking the anomaly propagation through the execution graph.
by identifying the spike in the magnitude of the difference between two backends cradle points out the inconsistent functions in the backend that introduces the inconsistency which should be very useful for developers to debug and understand the bug.
including the example in figure cradle identifies images out of a random sample from imagenet that trigger inconsistent classifications for inceptionresnetv2 model.
cradle then successfully localizes the faulty function bath normalization .
after we reported this bug in the interface developers have fixed the bug since keras .
.
.
figure 2c shows the fix.
the batch normalization formula was implemented incorrectly in cntk backend s function batch normalization it should take the square root of var epsilon instead of the square root of var .
to evaluate the effectiveness of cradle we answer the following research questions rq1 can cradle detect bugs and inconsistencies in deep learning backends?
rq2 can cradle localize the source of inconsistencies?
rq3 what is cradle s detection and localization time?
in this paper we make the following contributions a new approach to testing dl software by cross checking multiple implementations of the same model to detect inconsistencies and bugs the first approach to localizing the faulty function of a cross model inconsistency using anomaly propagation tracking and analysis and an evaluation of the testing and localization technique on dl models datasets including imagenet mnist udacity challenge and kgs go game and keras versions including the latest version .
our results show that cradle detects bugs have been fixed by developers in dl software that cause inconsistencies for out of models of which are previously unknown bugs of which have already been confirmed by developers rq1 .
cradle highlights functions relevant to the causes of inconsistencies for all unique inconsistencies rq2 .
cradle s median end to end running time is less than minutes suggesting that cradle is practical rq3 .
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
h a h 2 e e h s h fig.
overview of cradle.
red boxes indicate cradle outputs.
ii.
b ackground ad l network is a structure i.e.
a graph that contains nodes or layers that are stacked to perform a specific task e.g.
regression or classification .
each layer represents a specific low level transformation e.g.
convolution pooling etc.
of the input data with specific parameters e.g.
weights .
each layer maps to a function invocation that converts weight and the input data to output.
while multiple layers in a network can have the same type the operation performed is generally different because the parameters of these layers are different.
this is analogous to in a traditional program the same methods functions defined in one specific place in the source code are called many times with different input parameters.
similarly in a dl network the same layer type can be called several times i.e.
in multiple layers with different input parameters i.e.
weights .
fed with one input instance a model maps to an execution graph of those lowlevel functions i.e.
layers .
as a dl network generally consists of more than two layers there are many intermediate layers.
each intermediate layer produces an internal state that is fed to the next layers.
we call such states hidden states because they are internal to which normal users have no access.
to obtain the correct weights for each layer the network needs to be trained on a training set .
we call this phase the training phase.
once the training phase is over the weights or parameters of each layer are fixed and do not change and the model can be used in the inference phase.
a validation set is a set of input different from the training set that is used to tune a model.
in this work we use it as input to the models because we know the ground truth labels of such input.
apre trained model is a network that had been trained and saved in prior work.
its network structure and weights are fixed and do not change.
in the context of this paper a trained model also refers to a pre trained model.
while the training phase is often non deterministic e.g.
the weights of the network can be initialized randomly a pre trained model is expected to behave deterministically in the inference phase because the weights of each layer do not change.
iii.
a pproach in this section we describe how cradle detects and localizes inconsistencies among multiple backends.
recall that a backend consists of low level libraries and the interface to high level libraries e.g.
keras .
for example the tensorflowbackend contains the tensorflow library the interface between keras and tensorflow and the gpu computation library nvidia cuda invoked by tensorflow.
a. overview and challenges figure shows the two phases of cradle the detection phase and the localization phase.
the detection phase takes pre trained dl models and their corresponding validation data as input.
we focus only on the inference stage because of the non deterministic nature of dl training.
cradle runs a pre trained model using multiple dl backends.
specifically the output extractor feeds the validation set to the trained model as input and extracts the sets of output from the model on multiple backends.
in general we represent the output as a matrix of numbers.
if a dl backend crashes during this extraction stage the failure is recorded and later reviewed and reported.
otherwise the output comparator performs pairwise comparisons of the output for each model evaluated on different backends to detect inconsistencies.
once an inconsistency is detected cradle performs the localization phase.
specifically the hidden states extractor records hidden states of each inconsistent model on different backends.
these hidden states are fed to the inconsistency localizer which produces localization maps where significant spikes in deviations propagating between hidden states on different backends are highlighted indicating faulty locations.
to detect and localize cross backend inconsistencies and bugs effectively we need to address two main challenges .
how to determine if a model s outputs with two backends are inconsistent?
since different backends optimize the computational process differently the results of the same calculation are almost always slightly different .
a naive approach that expects the output to be identical will detect inconsistencies for practically all models on all backends which will not be useful for identifying bugs in dl systems.
as shown by our experiment theano and cntk backends always output slightly different values the differences vary from 5to less than .
it is difficult to know how big of a difference indicates a bug revealing inconsistency due to the diversity of models dl tasks and datasets.
it is not possible to have a single threshold to distinguish between bug revealing inconsistencies and uninteresting inconsistencies for all models and datasets.
for example lenet1 a model performing a simple image classification task has an average top confidence level of authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
.
this means that for this model a small variation e.g.
a change in confidence level from to is unlikely to make the label change.
on the other hand betago is a model performing a complex task i.e.
playing go .
for this model the average top confidence level is only .
in this case the same output variation from to might change the predicted label.
therefore different models need different thresholds.
determining the correct threshold is a challenging problem as it depends on many parameters e.g.
dataset model structure training etc.
.
to address this challenge of identifying bug revealing inconsistencies without the need for complex hard coded heuristics we use two distance metrics refer to later sections for details that emphasize the deviation between the output of both backends and the ground truth.
these metrics effectively differentiate bug revealing inconsistent runs from consistent runs and uninteresting inconsistent runs.
for these metrics we compare the differences of outputs against the ground truth instead of comparing individual outputs directly to the expected output.
recall that it is difficult to obtain the expected output as explained in the introduction.
we cannot directly compare the output of one backend to the ground truth to detect bugs because when one backend produces a wrong label it does not necessarily indicate a bug in the backend as it is common for dl models to produce incorrect labels for some inputs e.g.
due to the limitation of the algorithm model not a bug in the implementation .
.
how to precisely localize the source of an inconsistency?
after an inconsistency is detected the internal source of the inconsistency is often challenging to localize due to the complexity of dl backends.
for example one run that exposes the inconsistency bug in figure contains invocations of backend functions that have complex mathematical connections.
we propose a novel localization and visualization method that localizes faulty functions in the backend library which introduces inconsistencies by analyzing internal input and output of these backend functions and localizing the error spikes that propagate through the execution graph.
b. detection phase in the detection phase cradle identifies pairs of backends that are inconsistent for a specific model.
output extractor takes as input a pre trained model and its corresponding validation instances.
it loads the provided weights no training required and performs classification or regression tasks using the loaded models.
it produces the model output using all backends under test for each input instance.
for example comparing validation instances and one associated model on different backends will generate output vectors.
during this phase cradle detects crashes on specific backends and we report them to developers.
output comparator loads previously stored output matrices and performs pair wise comparisons for each given validation instance to detect inconsistencies.
these pair wise comparisons are between a specific pair of backends using a particularmodel its associated validation data and a particular keras version.
the output comparator then groups inconsistencies into unique inconsistencies.
we use two metrics to compare a pair of backends the class based distance for classification and the mad based distance for regression.
a straightforward metric to use is top k accuracy on the entire validation set.
top k accuracy calculates the portion of correct instances an instance s ground truth label is within the top k predicted labels among the total number of instances classified.
top k accuracy could fail to identify certain inconsistencies.
for example the dog species classification model affected by the presented batch normalization bug induces inconsistency between tensorflow and cntk.
however when ran on those backends the model has identical top .
and top .
accuracies.
to overcome this problem we calculate the portion of inconsistent input instances over the validation set.
because of the way inconsistent input instances are detected we will not aggregate inconsistencies in the same way as top k accuracy metric.
in the following sections we introduce class based and mad based distances as the ways to measure the severity of inconsistent instances.
once we have the severities of all validation instances between a pair of backends we can apply two thresholds to see if that pair of backends is inconsistent.
class based distance is specific to classification models.
it calculates the distance between two classifications based on the relative distances of the ground truth label ranks in the output matrices.
here we leverage the mapping between the syntax of the model output the output vector and its semantic meaning the classification .
without this mapping it would be difficult to come up with a universal metric and threshold that could work across different model configurations e.g.
the output vector size of a classifier can vary from for imagenet models to for binary classifiers .
a classification model with nclasses outputs a vector of sizencontaining confidence level picorresponding to class ci where i n. confidence level pishows how confident the model is in predicting class cias the correct label for that input instance.
given an output vector of a classification model as yand the ground truth label cof the input we calculate the score of classification c y as c y braceleftbigg 2k rank c y ifrank c y k otherwise rank c y is the rank of the ground truth label cin the classification y. for example rank c y ifcis predicted as top in classification y. the score c y emphasizes on classifications that predict ground truth label with higher rank.
we consider rank c y out of top k not interesting.
given the confidence level output of the same model on a different backend as y prime the class based distance dclass c y y primeis calculated as the absolute difference between two scores c y and c y prime dclass c y y prime c y c y prime authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
table i example of inconsistencies found using the classbased metric.
tf is tensorflow and cn is cntk.
inconsistency pattern id keras backends model .
.
tf cn xception .
.
tf cn nasnetlarge .
.
tf cn xception .
.
tf cn nasnetlarge we define our class based metric based on the top k rankings with k .
for example in figure petridish y tf 16as the rank of petri dish label by the tensorflow backendrank petridish y tfis .
similarly petridish y cn because petri dish is not in cntk s top for that image.
then the class based distance d class petridish y tf ycn is .
if another backend generates the ground truth label in rank then its petridish y is and d class petridish y tf yis .
the maximum value of d class c y y primeis and the minimum is with k .
mean absolute deviation mad based distance is a metric that could be used for both classification and regression models.
however the main purpose of the mad based distance is detecting inconsistencies in regression models where our class based distance would not work.
given two predicted vectors yandy primeof sizenfor a pair of backends using a model and an input instance we first calculate the mean absolute distance mad y o and y prime o between the two output vectors and the ground truth vectoro.
y o is calculated as followed y o n summationdisplay n i yi oi the mad based distance d mad o y y primeis calculated as dmad o y y prime y o y prime o y o y prime o mad is used here instead of the more common euclidean distance because it does not inflate due to outliers.
for example dave is a model that outputs the steering angle measured in radian of a car given a dashboard camera image as input.
for a given input image i the recorded ground truth steering angle is o .
.
using the same image as input dave outputs y .4andy prime .1using two different backends.
we have y o .
.
.
and y o .
.
.
.
we can then calculate dmad o y y primeas .
.
.
.
.
.
mad based metric produces values between and .
before we can use this metric with classification models we first need to convert the ground truth labels to one hot vectors.
in multi class classification a one hot vector is a vector of all zero except the value at the ground truth label index is .
this vector indicates a perfect classification with confidence in the ground truth label.
identifying inconsistencies given a model and its validation set two backends and one version of keras we consider this pair of backends inconsistent if at least p of validation input instances cause the distance between those two sets of output to be larger than a given threshold t tcdenotes thethreshold for the class based metric and tmfor mad based metric .
we call such input instances inconsistency triggering .
for class based metric with k using threshold tc 16is the most strict.
this means that an input instance is considered inconsistency triggering if one backend ranks the ground truth label top while the other ranks it outside of the top .
using threshold tc means that an input instance is inconsistency triggering if there is any difference in the top labels of the two backends and the ground truth label is in the top of at least one backend e.g.
if one backend ranks the ground truth label in the top while the other backend ranks it outside of the top .
in figure the petri dish image is an inconsistency triggering input instance.
similarly for mad based metric using tm is the most strict.
for example with the dave model an input image is inconsistency triggering withtm if it causes one backend to predict an angle matching the recorded angle exactly while causing the other to predict a different angle.
on the other hand using tm means that we consider any input image inconsistency triggering.
the stricter the thresholds are the fewer inconsistencies are detected however the detected inconsistencies will be more severe higher tcortmmeans each inconsistency triggering instance is more severe while higher pmeans more output instances are inconsistent .
if covering all inconsistencies is the priority lower and more relaxed thresholds should be used e.g.
the recommended thresholds in section iv .
however if finding severe bugs that significantly affect models accuracies is the priority then stricter settings would ensure that those severe bugs will be found and fixed quicker with less inspection effort.
identifying unique inconsistencies table i shows four examples of inconsistencies.
these inconsistencies are identified using the class based metric.
column is the number of validation input instances that cause the two backends to have class based distances of or .
inconsistency in row one inconsistency indicates that the model xception is inconsistent between tensorflow and cntk keras .
.
on its associated imagenet validation set where input instances trigger a class based distance of instances trigger distances in the range of etc.
the same inconsistencies may exist in different keras versions different interface versions in the backend .
to avoid finding duplicate inconsistencies the output comparator also automatically groups certain inconsistencies together into unique inconsistencies based on inconsistency patterns.
aninconsistency pattern is the distribution of the distances over the entire validation data.
it expresses the characteristics of the inconsistencies.
table i shows two unique inconsistency patterns pattern for inconsistencies and and pattern for inconsistencies and .
since the range of mad based metric is between and we choose equal sized bins between and to calculate the inconsistency patterns.
similar to class based metric the number in bin .
.
is the number of input instances that authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
trigger the mad based distance .
dmad .8for each pairwise comparison.
c. localization phase given each unique inconsistency the hidden states extractor and the inconsistency localizer produce a localization map.
a localization map is an execution deviation graph of two implementations backends which highlights inconsistent executions hidden states of a function layer type pointing to potential faulty functions in one of the backends.
recall that an execution of a model produces one execution graph section ii .
each execution graph contains connected layers where the output of one layer is the input of subsequent layers.
given a model and an input instance there is one execution graph for each implementation of libraries.
an execution deviation graph is a graph that represents the differences between two execution graphs of the same model.
since both execution graphs are from executions of the same model they have the same structure i.e.
the network structure.
thus the execution deviation graph also has that same structure but contains the deviation between each pair of layer type executions.
we describe the deviation calculation below.
for each unique inconsistency we only perform localization on the most inconsistent input instance.
the most inconsistent input instance triggers the largest class based distance classification tasks or mad based distance regression tasks between the output of two backends.
hidden states extractor produces execution graphs in a similar way to the output extractor described previously.
both execute the model on validation input instances to extract output.
however the latter also retrieves the intermediate function output hidden state of each hidden layer internal execution in the model.
hidden states are presented as vectors of floating point numbers.
inconsistency localizer produces a localization map for each unique inconsistency by first extracting the execution deviation graphs.
it does this by calculating the mean absolute deviation mad between each pair of corresponding hidden state from two executions of the same layer type on two different backends.
it is important not to confuse the usages of mad here to the mad based metrics mentioned previously.
here mad is used to calculate the distances between corresponding intermediate outputs of hidden layers to represent the internal deviations of two execution graphs.
given the intermediate statesslands primelof layerlexecuted on two backends the deviation is calculated using equation as sl s primel.
due to the sequential nature of a model a noticeable mad deviation at a particular layer does not indicate inconsistency at that layer as deviation can propagate through the execution graph and get amplified along the way.
ideally we want to localize the source of the inconsistency.
to do this the inconsistency localizer calculates the rate of change in deviation between consecutive function executions.
finally it generates the localization maps by highlighting functions in the execution deviation graph that have inconsistent executions.to calculate the rate of change we first need to calculate the mad deviation for all executions layers output in the setpre l as sl s primelwithl pre l pre l is the set of inbound layers which hidden states are the input to layer l .
we calculate the representative deviation of inbound executions pre simply as the maximum deviation pre m a x l pre l sl s primel the rate of change in deviations at layer lis rl sl s primel pre pre epsilon1 we use a smoothing constant epsilon1 7to prevent rl in the case where pre e.g.
lis the first layer .
we callrlthe inconsistency introduction rate of a layer l i.e.
how much diversion layer l executions of a pair of function implementations introduces due to inconsistent implementations.
rlvalues of all layers provide an overall picture of how the inconsistency is introduced through the model so that we can localize the function that is the source of the inconsistency.
to generate the localization map we overlay the mad and rlvalues for each layer on the model structure graph e.g.
maps in figure .
a node representing a layer l shows the layer type i.e.
low level transformation function the mad value and the inconsistency introduction rate rl.
we select the third quantile of rldistribution of all nodes in each map as the highlighting threshold.
we highlight a node red if its rlis higher than this threshold.
iv .
d a tasets and experimental settings trained models and datasets to evaluate cradle we collect public datasets and dl models that are pretrained from these datasets.
table ii lists the datasets.
we collected the models by looking for pre trained models compatible with keras from prior work and github.
to avoid low quality models e.g.
class projects and simple demos we only examine repositories with at least two stars.
overall we collected imagenet models xception vgg16 resnet50 inceptionv3 inceptionresnetv2 mobilenetv1v2 densenet121 nasnetlarge mobile selfdriving models used in previous work daveorig norminitdropout mnist models lenet1 and various models trained for other tasks thai number detector thaimnist go game player betago anime faces recognition animefaces cat and dog classifiers catdog basic augmented dog species classifier dog gender detection gender pokemon classifier pokedex and gtsrb traffic sign recognition trafficsigns .
we use provided validation dataset for each model to run our experiment.
for imagenet we use a random sample of images from over provided cropped validation images.
experimental settings we run cradle on versions of keras .
.
.
.
.
for the low level libraries we use the latest versions of cntk .
.
theano .
.
and authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
dwfk1rup rqy fwlydwlrq rqy or yj3rro od huv rplwwhg fwlydwlrq hqvh 7hqvru orz mhdq .
pdloedj qsxw mhdq rqy dwfk1rup fig.
batch normalization bug s localization map for inceptionresnetv2 between tensorflow and cntk with keras .
.
.
table ii number of inconsistencies found by cradle.
the numbers outside and inside brackets are the unique and total number of inconsistencies respectively.
tf is tensor flow th is theano and cn is cntk.
dataset instances of inconsistencies th tf tf cn cn th imagenet driving mnist thai mnist kgs go game anime faces dogs vs cats dog species faces pokedex gtsrb sign total18 tensorflow .
.
.
for regression models i.e.
dave variants we only use the mad based metric because the class basedmetric does not apply.
for the classification models we useboth class and mad based metrics.
some models are notsupported with older versions of keras and result in crashes.since the crash is the expected behavior we do not consider them as bugs and exclude those runs from our experiment.
we vary the thresholds t c tm andp and found the optimal setting covering the most inconsistency without false positives and false negatives for class based metric are tc 8andp and for mad based metric are tm .2and p .
we use cross validation with of models to confirm that the thresholds consistently perform across all 5folds.
these are the thresholds we use in rq1 and rq2.
hardware and infrastructure we utilize multiple anaconda environments to switch between multiple versions of keras and different backends.
we run all experiments on an intel xeon e5 machine with gb of ram and two nvidiatitan xp gpus.
for the performance analysis we run theoutput extraction step utilizing a single gpu.
v. r esults a. rq1 can cradle detect bugs and inconsistencies indeep learning backends?
cradle detects bugs in dl software for out of models that cause unique inconsistencies.
the bugs have been fixed consist of inconsistency bugs 3previously unknown out of have already been confirmedby developers e.g.
the bug in figure has been fixed by developers after we reported it and crash bugs that crash either keras or one of the backend libraries.
none of the bugstensorflow groom theano indian elephant tensorflow banana cntk tennis ball tensorflow hen cntk arabian camel fig.
inconsistency triggering inputs for the pooling bug leftcolumn the padding bug middle column and the batchnormalization bug right column .
correct backends are bold.
is detected by the test cases that come with keras including the interface which does simple unit and integration testing.the results demonstrate that cross backend inconsistencies are frequent and cradle is effective in detecting them.
our approach does not report false inconsistencies as it is a dynamic approach for each inconsistency we have inputs that trigger two backends to disagree.
theoretically speaking some true inconsistencies may indicate a false bug as ourapproach may identify uninteresting inconsistencies e.g.
nat ural computation difference explained in section iii a .
in ourexperiment all bugs are real i.e.
no false bugs detected .
inconsistencies and inconsistency triggering input using the class based metric on classification tasks and the madbased metric on regression tasks cradle detected a totalof inconsistencies.
based on the inconsistency patterns cradle automatically groups the inconsistencies into unique inconsistencies section iii b .
table ii shows the number of inconsistencies found by cradle for each dataset and pair of backends.
for example cradle detects inconsistencies between the twobackends tensorflow and cntk triggered by imagenetmodels.
here indicates that cradle detects 54inconsistencies which map to unique inconsistencies cor responding to unique inconsistency patterns.
table i showstwo of such patterns the first and second rows .
on average these inconsistencies are triggered by .
of input instances in a dataset .
for classification tasksand .
for regression tasks .
figure provides examples of inconsistency triggering inputs.
the image of a groom was identified correctly by tensorflow but incorrectly as an indianelephant by the faulty theano.
in some extreme cases thefaulty tensorflow backend accidentally labels an image of bananas correctly while cntk identifies it as tennis balls.
inconsistency bugs we use cradle to localize the source function of all detected unique inconsistencies detailed authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
table iii bugs found by cradle.
inc. bugs indicates the number of inconsistency bugs per root inconsistency.
root inconsistency localized layers functions affected backends affected models inc. bugs batch normalization batchnomalization cntk padding scheme conv2d depthwiseconv2d separatableconv2d tensorflow theano pooling scheme averagepooling2d theano parameter organization trainable convolution cntk theano localization results are in section v b .
we find that they are caused by bugs in the backend libraries table iii .
some bugs have the same root inconsistency because they are either different bugs in the same function or affect several backends which required multiple fixes to multiple backends.
for example in addition to the batch normalization bug we presented earlier we found another bug in the batch normalization function affecting an older version of keras.
we manually check the fault localization maps for each cluster of inconsistencies and confirm whether it indicates a bug.
if we find a corresponding bug fixing commit in a more recent version we consider the bug has been fixed by developers.
if not we consider it previously unknown.
once two authors agree that it is a bug we report it to developers.
if the same invocation of functions is identified for multiple bugs that are triggered by the same model in the same pair of backends across successive keras versions which affect the interface code between keras and low level libraries we consider them one unique bug.
however if the bugs are in nonconsecutive versions and the inconsistency pattern changes for some versions of keras this indicates that the issue was partially fixed or a new bug introduced in some keras versions then we consider them different bugs e.g.
the new inconsistency is likely to be a regression bug .
in addition to the batch normalization bug in figure we detail two additional confirmed bugs that cradle found.
padding scheme bugs padding artificially increases the size of an input image so that a kernel function can be applied to all the pixels of the original image and produces an output of the same shape as the input.
the same padding scheme behaves inconsistently across backends when applied on different combination of odd or even sizes of input and kernel.
this creates a shift in the input that propagates through the model and caused the model to sometimes completely miss some of the shapes it was trained to recognize.
eventually it results in inconsistencies between theano or tensorflow depends on the different combination of input and kernel sizes and the other two backends.
the middle column of figure shows an example of input images revealing this bug.
although it has not been fixed yet in the interface source code this bug has been confirmed to be a significant problem because various models i.e.
resnet50 mobilenet nasnetslarge mobile and mobilenetv2 have been updated by their developers to include workarounds that makes their models consistent across backends.
pooling scheme bug this bug in theano backend causes gender inceptionresnetv2 and inceptionv3 models to misbehave.
in keras .
.
and earlier the 2d pooling layer in theano interface determined the average pooling scheme based on the padding scheme.
if the padding is same i t if padding same th avg pool mode average inc pad elif padding valid th avg pool mode average exc pad ... mode th avg pool mode mode average exc pad fig.
pooling scheme bug fix in pool2d in theano backend.
used the pooling average inc pad scheme which includes padding in the average calculation.
however if there is no padding then they use the average exc pad scheme.
this creates inconsistencies for models that use the averagepooling layer with same padding.
figure presents the fix where average exc pad is used regardless of the padding scheme.
crashes bugs excluding crashes caused by unsupported models we encounter crashes out of possible runs.
we identified keras bugs happened with all backends and specific backend bugs.
in total of the crash bugs have already been fixed and a workaround has been added to the crashing model to address the last issue.
they are often caused by incorrect object s shape e.g.
incorrect weight or convolution kernel shapes .
comparison between class based metric and top k accuracy one alternative to our class based metric is top k accuracy.
to measure its effectiveness in detecting inconsistencies we integrate it into cradle by calculating the top k accuracy differences between pairs of backends.
a pair is considered inconsistent if the accuracy difference is larger than a threshold tac.
we vary k to and accuracy threshold tac between and .
usingtac andk the accuracy metric detects the most number of inconsistencies but still misses inconsistencies found by our class based metric.
these are valuable test cases that developers could use to test localize and fix detected bugs.
in addition our class based metric enables the generation of inconsistency patterns which help remove duplicates to reduce detected inconsistencies to unique inconsistencies.
this reduction is not possible with top k accuracy.
the results show that our class based metric is more effective than top k accuracy.
mad based metric usage for classification models to demonstrate the usefulness of our class based metric we compare the ability of both metrics in detecting unique inconsistencies for classification models.
using the mad based metric for classification tasks cradle can only find unique inconsistencies of which are inconsistent in confident level but do not trigger inconsistent classifications.
on the other hand with the class based metrics cradle correctly identifies unique inconsistencies in classification models including all inconsistencies correctly authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
found using the mad based metric.
these results show that class based metric help cradle find more inconsistencieswith no false positive.
b. rq2 can cradle localize the source of inconsistencies?
for each of the unique inconsistencies cradle generates a localization map for the most inconsistent input instance section iii c .
by focusing on the first localizedinconsistent execution and executions with high inconsistencyintroduction rates in each map we manually cluster the 104unique inconsistencies into bugs.
cradle s localizationmaps enable us to do this clustering.
this manual processtakes hours per bug.
a technique to automatically clusterunique inconsistencies based on the first localized functionexecutions or similarity between localization maps remains asfuture work.
overall cradle highlights executions that are relevant to the causes of inconsistencies for all unique incon sistencies.
for of the bugs the first localized inconsistentexecutions are exactly the executions of faulty functions thatwere fixed by developers.
this suggests that the localizationtechnique is effective in pinpointing the faulty functions whichshould help developers to understand and fix the bugs.
forexample the reduction is to in one case meaning thatthe developers only need to examine one function instead of13 functions with complicated formula and interactions tounderstand and fix the bug.
when we consider all insteadof only the first localized inconsistent executions the faultymethods are invoked in one of the localized inconsistentexecutions for of the bugs.
for the fifth bug this represents areduction of for the number of functions to examine.for the remaining bugs the localized inconsistent executionsare related to the bug fixes.
in fact the localized executionshelped us tremendously in understanding the bugs so that wewere able to write good bug reports.
figure shows a part of a localization map for the batch normalization bug for the unique inconsistency involvinginceptionresnetv2 tensorflow and cntk backends andkeras .
.
.
the input image shown is the most inconsistentinput instance for this unique inconsistency.
the dense boxshows the output jean from tensorflow and mailbag from cntk while the ground truth is jean .
the mapincludes invocations of backend functions for presentationpurposes of which are omitted.
each box represents aninvocation of a neural network function the arrows indicate theflow of data.
function names are indicated in each box while is the mad distance between the hidden states defined in equation and ris the inconsistency introduction rate defined in equation .
in this example executions of function batch normalization are localized as faulty shown in red .
the white boxes indicate executions with low or negativer i.e.
they are unlikely the source of inconsistency .
this map correctly highlights the earliest invocation of the function batch normalization as the source of inconsistency.
we examine localization maps for the other affected models e.g.
inceptionv3 densenets and notice that they rqy 0d 3rro rqy yj3rro od huv rplwwhg od huv rplwwhg rqy dwfk1rup fig.
pooling scheme bug s localization map for modelinceptionv3 between tensorflow and theano with keras2.
.
on the groom input image in figure .
all point to the batch normalization function.
we reported this bug to developers and it has been fixed in keras .
.
.
figure shows a section of the localization map highlighting the faulty executions for pooling scheme bug with model inceptionv3 between tensorflow and theano on keras .
.
.the first highlighted execution indicate correctly the source ofthis unique inconsistency as the function average pooling .
we look at the source code of average pooling which points to the faulty pool2d function in the theano backend.
figure shows the fix for keras .
.
in the theano backendsource code where the average pooling scheme is set to average exc pad regardless of the padding scheme.
c. rq3 what is cradle s detection and localization time?
we measure the execution time of cradle on the latest version of keras .
.
using all models.
overall cra dle s detection and localization time is quite reasonable witha typical end to end execution time lower than minutes.
the running times of output extractor and hidden states extractor are dominantly the model execution times which depends on the model complexity validation dataset size andperformance of the backend.
the extractor is slow in rarecases e.g.
nearly hours with the large nasnetlarge modelcontaining over layers.
however the typical runningtime is within minutes with the median of less than minutes.
the output comparator and inconsistency localizer are much faster with the median running time of less than 20seconds and the maximum of less than minutes.
the runningtime is independent of the backend implementation it dependson the dataset size and the model complexity respectively.
vi.
l imita tions and threa ts to validity since we focus on detecting bug revealing inconsistencies cradle may miss inconsistencies that cause internal errorsbut not failures i.e.
incorrect external behaviors .
this is ourdesign choice to avoid detecting too many false alarms.
we assume that the same algorithms are implemented with similar specifications in all backends due to the interchange ability of dl backends.
in theory it is possible for ourtechnique to find false positive inconsistencies because of thisassumption.
however our results show that the inconsistenciesfound by our approach indicate real bugs because of themhave already been confirmed or fixed by developers.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
our approach might not be generalizable to other models or dl libraries.
to mitigate this threat we use models extracted from different github projects and evaluate our approach on keras the most popular high level dl library and three popular backends.
our approach of detecting and localizing inconsistencies should be applicable to other models and libraries with little work.
it is possible that some complex dl systems contain nondeterministic layers so that given the same input the output might be slightly different.
to mitigate this issue we make sure none of the layers contains intentional sources of randomness and we apply two metrics that are designed to be robust even in the existence of small inconsistencies.
our approach uses pre trained models which is our design choice in believing that those pre trained models that are used by real users are likely to cause bugs that developers care.
alternatively we can use dummy models or mutated models to test backends in order to find more bugs which remains as future work.
vii.
r ela ted work to the best our knowledge we are the first to detect and localize inconsistencies between dl backends.
testing machine learning ml libraries recently automatic testing of ml libraries becomes active .
srisakaokul et al.
detect inconsistencies between multiple implementations of common ml algorithms i.e.
knn or naive bayes nb .
this approach uses majority votes to estimate the expected output.
however it requires many implementations of the same algorithm knns and nbs used with the assumption that most of them are correctly implemented.
in contrast cradle performs pairwise comparisons which as shown by our experiments detects inconsistencies without knowing the expected output and works with a minimum of two implementations.
another major difference is that srisakaokul et al.
define deviation based on the inconsistency of top classifications without comparing them to the ground truth.
cradle on the other hand define inconsistency as deviations in predicted ranks of the ground truth label because we want to focus on inconsistent implementations that affect the performance of dl models on real world validation dataset.
dwarakanath et al.
test ml libraries by applying transformations on the training and testing data to detect inconsistencies.
however they were only able to identify artificially injected bugs.
dutta et al.
used fuzzing to test probabilistic programming systems.
none of these techniques performs localization.
benchmarking dl libraries liu et al.
observe that the same dl algorithm with identical configurations such as training set and learning rate produces different execution time and accuracy when trained with different low level dl libraries.
however this work aims to benchmark dl libraries not to detect or localize inconsistency bugs as it does not compare the exact same model on different backends.
since each model is re trained on each backend and the trainingprocess contains non determinism e.g.
the seed for the optimization function small accuracy differences are expected.
dl libraries have been compared in the literature .
however the prior work focuses on performance comparison only and does not detect or localize non performance bugs in dl libraries.
adversarial testing of dl models much recent work focuses on testing dl models .
many techniques generate adversarial examples .
some work verifies dl software.
deepxplore introduces neuron coverage to measure testing coverage in cnn models.
these approaches are orthogonal to our work as they test the correctness of dl models while we test the correctness of the implementations of models in the dl software libraries.
differential testing and inconsistency detection differential testing consists of testing whether different compilers produce the same results.
much work uses differential testing to find bugs in compilers by comparing the output of multiple compilers or different compiler optimization levels .
inconsistency detection has been used in other domains such as cross platform web browsers or document readers .
our work is a new application of differential testing and inconsistency detection for dl software which has its unique challenges such as identifying bug triggering inconsistencies section iii a .
in addition we localize the inconsistencies to the faulty functions.
debugging and fault localization we are not aware of prior work that localizes inconsistency bugs in dl libraries despite the large volume of debugging and fault localization work for general software bugs .
while these approaches could be used to debug dl networks applying such techniques to localize faulty functions in dl networks may have unique challenges such as scalability which remains as future work.
viii.
c onclusion we propose cradle a new approach to find and localize bugs in the implementations of dl models by cross checking multiple backends.
we evaluate cradle on three backends and pre trained models and find bugs and unique inconsistencies in the backends for models.
this paper calls for attention for testing dl implementations not just dl models.
in the future we plan to design approaches to identify bugs even if they do not cause observable differences in backends.
it is also conceivable to expand the set of trained models with mutants for cradle to find more bugs.
acknowledgment the authors thank carmen kwan for her contribution in collecting evaluation models from github yitong li for the reproduction and validation of experimental results and the anonymous reviewers for their invaluable feedback.
this work has been partially supported by the natural sciences and engineering research council of canada.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.