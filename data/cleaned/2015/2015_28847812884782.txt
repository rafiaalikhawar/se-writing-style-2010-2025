mining sandboxes konrad jamrozik philipp von styp rekowsky andreas zeller center for it security privacy and accountability cisp a saarbr cken germany jamrozik styp rekowsky zeller cs.uni saarland.de abstract we present sandbox mining a technique to confine an application to resources accessed during automatic testing.
sandbox mining first explores software behavior by means of automatic test generation and extracts the set of resources accessed during these tests.
this set is then used as a sandbox blocking access to resources not used during testing.
the mined sandbox thus protects against behavior changes such as the activation of latent malware infections targeted attacks or malicious updates.
the use of test generation makes sandbox mining a fully automatic process that can be run by vendors and end users alike.
our boxma te prototype requires less than one hour to extract a sandbox from an android app with few to no confirmations required for frequently used functionality.
.
introduction how can i protect my computer from malicious programs?
one way is to place the program in a sandbox restraining its access to potentially sensitive resources and services.
on the android platform for instance developers have to declare that an application henceforth referred to as an app needs access to specific resources.
the popular snapcha t picture messaging application for instance requires permissions to access the internet the cam era and the user s contacts.
to install the app the user has to grantsuch permissions.
if an application fails to declare a permission the operating system denies access to the respective resource if the snapcha t app attempted to access e mail or text messages the respective api call would be denied by the android system.
while such permissions are transparent to users they may be toocoarse grained to prevent misuse.
for instance snapcha t offers a feature to find friends on snapcha t based on their phone number.
to do this snapcha t accesses the phone numbers of the user s contacts and sends them to the snapcha t servers.
the permission given by the android sandbox allows snapcha t to do much more than that namely unlimited access to all contacts at any time.
an attacker thus could inject malware into a snapcha t binary that compromises all contact details the permissions couldstay unchanged.
the issue could be addressed by tightening the permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributedfor profit or commercial advantage and that copies bear this notice and the full citationon the first page.
copyrights for components of this work owned by others than theauthor s must be honored.
abstracting with credit is permitted.
to copy otherwise orrepublish to post on servers or to redistribute to lists requires prior specific permissionand or a fee.
request permissions from permissions acm.org.
icse may austin tx usa c circlecopyrt copyright held by the owner author s .
publication rights licensed to acm.
isbn .
.
.
.
1. mining test generator app apis used .
sandboxing user app apis permitted monitor sandbox figure sandbox mining in a nutshell.
the mining phase automatically generates tests for an application monitoring theaccessed apis and resources.
these make up the sandbox for the app which later prohibits access to resources not accessedduring testing.
sandbox for instance by constraining the conditions under which the app can send the message.
but then someone has to specify andvalidate these rules and repeat this with each change to the app as a sandbox that is too tight could disable important functionality.
in this paper we present sandbox mining a technique to automatically extract sandbox rules from a given program.
the core idea illustrated in figure brings together two techniques namelytest generation and enforcement in a principle called test complement exclusion disallowing behavior not seen during testing mining.
in the first phase we mine the rules that will make the sandbox.
we use an automatic test generator to systematically explore program behavior monitoring all accesses to sensitive resources.
sandboxing.
in the second phase we assume that resources not accessed during testing should not be accessed in produc tion either .
consequently if the app unexpectedly requires access to a new resource the sandbox will prohibit access or put the request on hold until the user explicitly allows it.
to illustrate how test complement exclusion works in practice let us mine a sandbox from our snapcha t example application.
during systematic gui testing the mining phase determines that snapcha t indeed requires access to the camera location internet and so on.
we associate these accesses with the event that triggers them that is the individual gui elements.
thus we would find that snapcha t accesses contacts only when the user presses the find friends gui button and it only accesses the friends phone numbers.
likewise accessing the microphone or the loca tion would only take place when a message is actually sent.
ieee acm 38th ieee international conference on software engineering the resulting sandbox is much more fine grained than the original android sandbox and easily prevents a number of otherwise permitted attack schemes.
compromising all contact data sending text messages in the background continuously monitoring the au dio or the current location would all be disallowed simply becausethis behavior is not what we find during testing.
even more important though is that the sandbox also protects the user against unexpected behavior changes.
assume an app like snapcha t was malicious in the first place and placed in an app store.
then the attacker would face a dilemma.
if the app ac cesses all contacts right after the start this would be detected in the mining phase and thus made explicit as a sandbox rule permitting behavior such a rule this app reads all contact detailsin the background could raise suspicions even with non expertusers because there is no apparent functionality in snapcha t that requires this.
if however the app stayed benign during mining it would be disallowed from accessing contact details in production except for phone numbers during the find friends functionality.
to the best of our knowledge ours is the first approach to leverage test generation to automatically extract sandbox rules from general purpose applications.
sandbox mining has a number of compelling features preventing behavior changes.
the mined sandbox detects behavior not seen during mining reducing the attack surface for infections as well as for latent malicious behavior that otherwise would activate later.
fully automatic.
as soon as an interface for automatic test generation is available such as a gui sandbox mining also becomes fully automatic.
developers can easily mine and re mine sandboxes at any time.
no training in production.
in contrast to anomaly detection systems we need no training in production as the normal be havior would already be explored during testing.
detailed analysis.
mined sandboxes provide a much finer level of detail than what would normally be specified or documentedin practice.
as they refer to user resources and user actions they are readable and understandable even by non experts.
adverse and obscure code.
in contrast to static code analysis test generation and monitoring are neither challenged by large programs nor thwarted by code that would be deobfuscated decrypted interpreted or downloaded at runtime only.
guarantees from testing.
the key issue with testing is that it is incomplete by construction.
we turn it to our advantage by considering the tested behavior a safe subset of all possibleapp behaviors guaranteeing the user will be explicitly asked to allow behaviors not seen during testing.
certification.
anyone can mine a sandbox for a given app and compare its rules against the sandboxes provided by others or those of previous versions.
all of this however depends on a number of assumptions that canonly be assessed in a practical setting.
our boxma te tool1implements sandbox mining for the android platform in a user friendlypackage consisting of the droidma te test generator and the boxify approach to privacy enforcement.
after discussing related work in section we address three key questions q1 can test generators sufficiently cover behavior?
if some resource ris not accessed during mining later non malicious access to rwould require user confirmation the sandbox is too tight.
we run the droidma te test generator on a set of 1boxma te sandbox mining a nalysis t esting and e nforcementandroid apps checking api coverage section and check when the sandbox would trigger which alarms section .
q2 can we sufficiently reduce the attack surface?
if the rules we mine are too general there might still be too many ways for applications to behave maliciously the sandbox is too coarse.
to this end we associate resource access with the gui elements that trigger them section further reducing the attack surface.
q3 can sandbox rules help experts to assess behavior?
if the analyzed app is overtly malicious the mined sandbox will not prevent this.
section shows how mined sandbox rules help in assessing and comparing behavior in the first place reduc ing the risk of missing an attack.
after discussing threats to validity and limitations section sec tion closes with conclusion and future work.
.
background .
sandboxing the idea of restricting program operation to only the information and resources necessary to complete its operation goes back to the 1970s.
as principle of least privilege it has influenced the design of computer systems operating systems and informa tion systems to improve stability safety security and privacy.
onthe android platform least privilege is realized through sandboxing first no application can access the data of other applications.
second access to shared user resources such as location contacts etc.
is available through dedicated apis only which are guarded bypermissions.
each application declares the permissions it needs the operating system blocks access to other apis and resources.
in a landmark paper felt et al.
systematically tested android apis to check which permissions would refer to which api.
besides producing a map between apis and permissions they also found that of android apps investigated were overprivileged that is they requested more permissions than their apis would actually require.
pscout uses a combination of static analysis and fuzz testing to extend this mapping to undocumented apis and found that of permission requests were unnecessary if app de velopers confined themselves to documented apis.
these android permissions have to be acknowledged by a user upon app installation the google play store also lists each app withthe requested permissions.
however in a survey of androidusers felt et al.
found that only paid attention to per missions during installation and only of all respondents could correctly answer three questions regarding permissions.
the latestandroid version therefore adopts the i ossecurity model asking for permission interactively and in context at the very moment the app accesses a sensitive resource.
most permissions such as inter net access are granted by default though and the set of confirmations is limited to the most sensitive resources only.
the android permission model is coarse grained.
.
analyzing apps in contrast to specified rules and permissions the alternative of extracting these from an existing system has always been compelling.
in a short paper comparing the permission systems of mobile platforms au et al.
call for a tool that can automat ically determine the permissions an application needs.
this question generalizes into what does an application do?
which is the general problem of program analysis.
38program analysis falls into two categories static analysis of program code and dynamic analysis of executions.
static code analysis sets an upper bound to what a program can do if static analysis determines some behavior is impossible it can be safely excluded.
tools like chex and flowdroid check android apps for information flow between sensitive sources and sinks.
the copes framework uses static analysis to eliminate unneeded permissions for a given android app.
the challenge of static analysis isoverapproximation the analysis must often assume that more behaviors are possible than actually would be.
the analysis is undecidable in all generality due to the halting problem.
also static analysis is challenged by code that is decrypted interpreted or downloaded at runtime only techniques used by benign and malicious android apps alike.
if static analysis can safely determine that some behavior is impossi ble though the behavior no longer needs to be checked at runtime.
static analysis produces overapproximation.
dynamic analysis works on actual executions and thus is not limited by code properties.
in terms of program behavior it sets alower bound any benign behavior seen in past executions should be allowed in the future too.
consequently given a set of execu tions one can learn program behavior from these and infer security policies.
however obfuscated or encrypted code makes it harder toinfer the behavior s intent.
in their seminal paper forrestet al.
learned normal behavior as short range correlations in the system calls of a unix process and were successfully able to detect common intrusions on the sendmail and lpr programs.
since then a number of techniques have been used for automatic anomaly detection chandola et al.
provide a detailed survey.
most related to boxma te is the work of provos learning and enforcing policies for system calls on unix systems.
since android programs come in interpretable byte code the platform offers several opportunities to monitor dynamic behav ior including system calls aasandbox data flow t aint droid traces crowdroid or cpu and network activity andromal y all these platforms can be used both to monitor application behavior and report results to the user as well as to detect malicious behavior as a violation of explicit rules or as determined by a trained classifier .
neuner et al.
as well aslindorfer et al.
provide a comprehensive survey of trends andavailable techniques.
dynamic behavior can also be abstracted and summarized usinginternal state following the pioneering work of ernst et al.
on dynamic invariants and the suggestion of engler et al.
thatdeviations in behavior would help in inferring errors .
baligaet al.
for instance would learn kernel data structure invariants todetect rootkits .
as they refer to internal state the diagnostics of these approaches cater more to developers than to users or administrators though however they also share the general idea oflearning normal behavior to detect abnormal behaviors.
the joint problem of all these approaches is the fundamental limitation of dynamic analysis namely incompleteness if some behavior has not been observed so far there is no guarantee that it may not occur in the future.
given the high cost of false alarms this implies that a sufficiently large set of executions must be avail able that covers known behaviors.
such a set can either come from tests which then typically would be written or conducted at substantial effort or from production which then requires a training phase possibly involving classification by humans .
in the domain of network intrusion detection the large variation of benign traf fic in operational real world settings is seen as a prime reason why machine learning is rarely employed in practice .dynamic analysis requires sufficiently many normal executions to be trained with.
.
test generation rather than write tests or collect executions during production one can also generate them.
in the security domain the main purpose of such generated executions is to find bugs.
introduced by miller et al.
fuzz testing automatically exercises sensitive tools and apis with random inputs no interaction or annotation is required.
today fuzz testing is one of the prime methods to findvulnerabilities the microsoft sage fuzzing tool for instance has saved millions of dollars to microsoft as well as to the world in time and energy by avoiding expensive security patches to more than billion pcs.
.
for the android platform recent years have seen a raise of powerful test generators exercising android apps.
monkey is a simple fuzz tester generating random streams of user events such as clicks touches or gestures although typically used as robustness tester it has been used to find gui bugs and security bugs .
while monkey generates pure random events the dynodroid tool focuses on those events handled by an app getting higher coverage while needing only of the events.
givenan app all these tools run fully automatically no model app code or annotation is required.
other recent android test generators like puma or andlantis achieve high levels of robustness while brahmastra is good at covering 3rd party components.
all these testing tools still share the fundamental limitation of execution analysis if a behavior has not been found during test ing there is no guarantee it will not occur in the future.
attackerscan easily exploit this by making malicious behavior latent for instance our malicious snapcha t variant would start sending malicious text messages only after some time or in a specific network or when no dynamic analysis tool is run each of which would de feat observation during testing.
testing cannot guarantee the absence of malicious behavior .
.
consequences program analysis sandboxing and test generation are all mature technologies that are sufficiently robust to be applied on alarge scale.
however each of them has fundamental limitations sandboxes need rules dynamic analysis needs executions and test ing does not provide guarantees.
combining the three however not only mitigates these weaknesses it even turns them into a strength.
the argument first presented in a keynote at the icpc conference is as follows with modern test generators we can generate as many executions as needed.
these executions can feed dynamic analysis pro viding and summarizing insights into what happens in them.
by construction these insights are incomplete and other in particularmalicious behavior is still possible.
the key idea of this paper istoturn the incompleteness of dynamic analysis into a guarantee namely by having a sandbox enforce that anything not seen yet will not happen.
to the best of our knowledge this is the first work bringing together test generation dynamic analysis and sandbox ing it is their combined strength we explore in this paper.
.
generating app tests let us now detail how droidma te the test generator of boxma te operates.
conceptually droidma te generates tests by exploring theapplication under test aut that is by interacting at 39runtime with its gui elements called views in android and reasoning about the aut behavior to influence further gui interaction.
droidma te installs on an android device an .apk file containing the aut and then launches the aut s main activity.2during start and then again after each generated interaction droidma te monitors which sensitive android apis and user resources the aut accesses.
as the exploration progresses all the observed and monitored behavior of the aut is being used to decide which gui element to interact with next or if to terminate the exploration.
the data from the exploration is sufficient to replay the test either man ually or automatically.
the exploration takes place in a loop between an exploration strategy and an exploration driver.
the exploration strategy algorithm is given in algorithm .
it operates on a high abstractionlevel taking as input the gui state and returning an exploration action.
the gui state contains an abstract representation of the gui hiding all the implementation details irrelevant for deciding what toexplore next.
the exploration action in turn is an abstract represen tation of a possibly multi step operation on the android device likeclick long click reset orterminate.
the exploration driver then translates this abstract representation into actual operations on the device executes them reads the resulting gui state and api calls logs and returns control to the exploration strategy.
the actual exploration strategy currently implemented in droidma te is inspired by dynodroid .
the key idea is to interact with views gui elements randomly but give precedence to views that have been interacted with the least amount of times so far.
if multiple views have been interacted with minimal amount of times we pick one randomly.
a view interaction is either a click or a long click seconds .
interaction can happen only with views that are enabled as well as clickable long clickable o rcheckable.
each view is considered unique in its given context that is within the set of views that can be interacted with and appear onthe same screen.
thus if a view appears in different contexts i.e.
surrounded by different gui elements it will be explored again in each of them.
contexts are different if they differ by at least one view.
a view can differ by its fully qualified class name itsresource id if any its content description if any and the rectangle describing its location on the screen.
it can also differ by its label unless the view s class has switch ortoggle in its name.
every interactions droidma te restarts the aut .
we thus avoid getting stuck in abnormal situations such as no views beingavailable for interaction the app having crashed or another app having been launched.
a view that led to a reset gets black listed and will not be interacted with again.
the exploration terminateswhen the configured time limit is reached or when there are noviews that can be interacted with after two resets in a row.
.
distinguishing resources while running droidma te monitors sensitive android apicalls using the monitoring techniques discussed in section .
an api is sensitive if it is governed by a permission.
we use the set of sensitive apis used in the appguard privacy control framework .
this set of apis focuses on crucial privacy related resources an average user should be concerned about.
for each call of a monitored api droidma te records .
the fully qualified name of the api called including class and method name and parameter and return types 2if the aut accesses an external account such as snapcha t its login and password must be provided.
3the full api list is provided in the linked experimental data package section .algorithm exploration strategy.
require gui state s ensure exploration action a procedure decide s iftermina te s then a terminate exploration else ifreset s then a reset exploration else a explore forw ard s end if end if u pda te internal stat e s a return a end procedure procedure explore forw ard s c view context of s vs views in cwith minimal number of interactions so far v pick at random from vs a choose interaction action with v u pda te known view contexts c u pda te interactions count v c return a end procedure .
the thread idand the entire thread call stack trace of the api call starting at thread.run or dalvik s native main .
properties of the triggering view like displayed text associated resource id screen bounds etc.
as most android resources are uniquely identified by their spe cific set of apis we can ignore parameter values in most cases they determine irrelevant details e.g.
a call to locationmanager .requestlocationupdates listener determines which listener to inform when a location has changed.
y et we are interested only ifappropriate call to locationmanager was made at all.
however one set of android api methods heavily depend on the parameter values to identify the correct resource accessed and therefore get special treatment.
these are contentresolvers that is database equivalents frequently used in android.
knowing only that contentresolver .query was called is not enough as the query may relate to all kinds of sensitive resources.
for contentresolver calls droidma te therefore also monitors the uri identifying the exact database e.g.
content com.android.contacts data phones.
sometimes uri s end with the numeric identifier of particular instance of the resource being accessed we consider all api calls differing only by this number as equivalent.
.
mining snapchat as an example of how droidma te explores application behavior let us again consider the snapcha t application.
figure lists the number of unique apis discovered during testing the actual apis in order of discovery are listed in figure including the identifiers of the gui elements that triggered them api 1after a click on the login button on the start view snapcha t opens a socket api which allows establishing a connection to a http server.
it also opens the camera api queries the current location api and accesses account info via a url connection api .
secondsapis seen snapcha t .
.
appguard api s figure droidmate per app api saturation.
after minutes seconds droidmate has discovered sensitive apis used by snapchat .
api 5taking a picture camera take snap button starts monitoring the current location.
api 6recording a video sets the video and audio sources for recording initializing the media recorder.
api 8later droidma te finds the snapcha t my friends button the unlabeled element which requires accesses to the image library.
api 9snapcha t allows for finding friends based on their phone number requiring access to contacts.
api saving a picture stores it to a database.
api previewing a snap deletes it after the preview is done.
java.net.socket void init android.hardware.camera.open android.location.locationmanager.getlastknownlocation java.net.urlconnection openconnection button com.snapchat.android id camera take snap button android.location.locationmanager.isproviderenabled button com.snapchat.android id camera take snap button long click android.media.mediarecorder.setaudiosource android.media.mediarecorder.setvideosource android.content.contentresolver.query uri content media external images media button com.snapchat.android id contacts permission button android.content.contentresolver.query uri content com.android.contacts data phones imagebutton com.snapchat.android id picture save pic android.content.contentresolver.insert uri content media external images media relativelayout com.snapchat.android id snap preview relative layout android.content.contentresolver.delete uri content media external images media number figure the snapchat calls to sensitive apis discovered bydroidmate and the events in that first trigger them.
these apis characterize the resources that snapcha t accesses or more precisely the resources it accessed in our droidma te run.
so are these apis an exhaustive list?
this is the problem of testing which does not give guarantee of whether all has been seen and this is why we use sandboxing to prevent yet unseen potentially malicious behavior.
.
monitoring and enforcing besides a test generator the second component of boxma te is the sandbox mechanism itself monitoring and possibly preventing program behavior.
just as with test generation we wanted a technique that allows any user to sandbox any application on an figure the boxmate sandbox in action.
calling a sensitive api not seen during mining requires confirmation by the user.
to facilitate readability api names are automatically mapped into the respective android permissions which are then shown in user readable form.
unmodified android device.
to this end we leveraged the boxify tool by backes et al.
.
.
monitoring in a nutshell the boxma te monitoring component uses the boxify framework for fine grained policy enforcement .
boxify is a novel approach for android application sandboxing which provides tamperprotected reference monitoring for stock android without the needfor root privileges.
boxify uses app virtualization and processbased privilege separation to encapsulate untrusted applications in a restricted execution environment within the context of another trusted sandbox application.
to establish a restricted execution en vironment boxify leverages android s isolated process feature which allows apps to completely de privilege selected components.by loading untrusted apps into de privileged isolated processes boxify avoids modifying apps and provides strong security guarantees.
sensitive i o operations are relayed through a separate privileged broker process monitoring and enforcing policies.
the boxma te sandbox works in two modes.
during mining it records and distinguishes all calls to sensitive apis as discussed in section .
this recording includes the current call stack thethread idas well as security relevant parameter values.
during enforcement it checks whether the api call is allowed by the mined sandbox rules if not it can either have the call return a mock object containing fake data or flag the call asking the user for permission naming the api and possible relevant arguments figure .
if the user declines permission the call is denied.
being based on boxify only calls to sensitive methods incur an overhead of per call resulting in practically no runtime performance overhead.
as an example of how the boxma te sandbox operates again consider the snapcha t saturation curve in figure .
any sensitive api not accessed during testing that is any call to an api not listed in figure would be flagged by the boxma te sandbox.
note how the boxma te sandbox is already much more fine grained than say the standard android permission model.
in the android per mission model for instance snapcha t would simply get arbitrary access to all contacts.
in the boxma te model though snapcha t is only allowed to read contact phone numbers any other informa tion is neither accessed nor changed.
these are important featuresto know and possibly to enforce too.
.
evaluation since any sensitive api not explored during testing implies a potential false alarm during production we evaluate the risk of false 41table evaluation subjects.
open angbracketleftidentifier angbracketrightfor details.
name version category rank identifier links to web page adobe reader .
.
productivity com.adobe.reader antivirus security free .
communication com.antivirus barcode qr scanner barcoo .
shopping de.barcoo.android cleanmaster free optimizer .
.
tool com.cleanmaster.security currency converter .
finance com.frank weber.forex2 ebay .
.
.
shopping com.ebay.mobile es task manager task killer .
.
business com.estrongs.android.taskmanager expense manager .
.
finance at.markushi.expensemanager file manager explorer .
.
business com.rhmsoft.fm firefox browser for android .
.
communication org.mozilla.firefox job search .
business com.indeed.android.jobsearch picsart photo studio .
.
photography com.picsart.studio snapchat .
.
social com.snapchat.android adobe reader03 antivirus03 barcoo03 cleanmaster03 currency cvtr03 ebay es task manager03 expense mgr03 file manager03 firefox03 job search03 picsart figure per app saturation for the apps in table .
as in figure the y axis is apis seen the x axis is seconds spent.
alarms how likely is it that sandbox mining misses functionality and how frequently will users thus encounter false alarms?
we address this issue from two angles we evaluate how quickly the setof apis is saturated section .
.
and we check boxma te against use cases reflecting typical app usage section .
.
.
.
.
exploration while a finer grained access model reduces the attack surface it also brings the risk of false alarms.
in figure just minutes of mining is enough.
the question is whether other apps can bealso quickly mined covering all the frequently used functions.
tothis end we computed the same api saturation for twelve more apps from the top downloads of the google play store.figure shows the respective api saturation charts these are the same charts as we have already seen for snapcha t in figure .
we see that ten charts flatten before one hour mark and the remainingtwo before two hours.
automatic test generation can quickly cover resource usage.
.
.
use cases we now know droidma te stops discovering new calls to sensitive apis before two hours pass.
but does this mean that the most important functionality is actually found at all?
to answerthis question we defined use cases for each of the analyzed apps reflecting their most important usages.
we derived the use casesfrom the app s main purpose as stated in its description viewinga pdf document with adobe reader scanning the system with antivirus security sending a picture with snapcha t and so on.
table provides a full list of the defined use cases.we implemented all these use cases as automated test cases allowing for easy assessment and replication of our experiments.
onaverage implementing a single use case and having it replay re liably took us hours of work.
this perhaps surprisingly highimplementation effort was due to inaccuracies in the uiautomator framework as well as the general difficulty of hand scripting userinteractions which in turn may further motivate the use of auto mated exploration frameworks such as droidma te .
after having boxma te extract the sandbox for a given app the central question for the evaluation would be whether and if so how these use cases would be impacted by the sandbox.
the app column in table summarizes the number of confirmations a user has to provide in the appguard api s set.
the picsart apply effect accesses an existing photo from sd card whichwas not found during testing.
the ebay find by search use case requires login credentials while we explicitly didn t gave them to droidma te forcing it to explore only the functionality available without logging.
the use case in turn explores gui parts available only after logging causing the need for confirmation.
this answers q1 only in out of use cases each encompassing up to dozens of sensitive api calls would a user need to confirm api access.
this is actually fewer confirmations than in android where first access to every permission group has to be explicitly confirmed once per app .
mined sandboxes require fewer user confirmations than standard os security facilities.
4despite our best efforts neither we nor droidma te could get barcoo .
to use the camera and scan something on our devices.
42table use cases.
confirmations required with appguard api calls app column and event api pairs event column .
app use case functions confirmations per app event adobe reader view document what s new help open first document antivirus scan activate scan now view scan results barcoo search for product search pillow in search box view results4 cleanmaster scan scan system resolve all report currency cvtr convert currency enter swap currencies ebay find by search accept terms sign in search pillow view first search result es task mgr kill task kill first listed task expense mgr add and edit expense add an expense of .
for pills in category health delete expense open history delete first entry view and set budget set a total budget of .
in the other category file manager view and create dir view directories create new directory temp utc firefox open url go to google.com job search search for job search a job for sales in new y ork ny select first result picsart apply effect apply twilight effect on recent photo save on sd card snapchat take snap log in take snap add caption set retention send snap to self view it take video log in take video pick color draw line save to gallery add to story find friend log in add friend from contacts allow access edit friend log in search friend abc block abc unblock abc delete abc total confirmations required out of use cases allowed during sandboxingprohibitedduring sandboxing benignbehavior malicious behaviortrue negative false negative true positivefalse positive benign behavior seen or allowed malicious behavior seen or allowed benign behavior raising a false alarm malicious behavior detected and prevented figure confusion matrix.
program behavior is either be nign or malicious if it is not seen during mining test gener ation it is prohibited during sandboxing.
the three risks arefalse positives benign behavior not seen during testing and thus requiring confirmation during sandboxing false negatives allowed malicious behavior allowed because of too coarse sandbox rules and false negatives seen malicious behavior seen during mining but not recognized as such and thus allowed .
.
fine grained access control .
the risks of misclassification user confirmations as evaluated in section .
is only the first of the key questions we have to assess.
in all generality boxma te is an automatic system that decides on whether behavior should be allowed or not.
as we do not assume a specification of what makesbenign or malicious behavior user confirmations or false positives is just one of two essential risks illustrated in figure false positive.
afalse positive occurs when benign behavior is mistakenly prohibited by the sandbox degrading user experience and functionality.
in our setting a false alarm comes to be if some benign behavior is not seen during mining andthus not added as allowed to the sandbox rules it induces theaccess to be confirmed by the user.
the number of confirmations can be reduced by better testing as well as coarsergrained sandbox rules as evaluated in section .
.false negative.
afalse negative occurs when malicious behavior is mistakenly allowed by the sandbox thus increasing the attack surface.
in our setting a false negative can come to bein two ways false negative allowed.
the inferred sandbox rule may be too coarse and thus allow future malicious behavior.
this issue can be addressed by having finer grained sandbox rules as evaluated in section .
.
false negative seen.
the application may be malicious in the first place.
then we risk to mine this maliciousbehavior during testing such that it would get includedin the sandbox rules.
this issue can be addressed byidentifying malicious behavior during testing already a task made considerably simpler through the discloseor die principle imposed by boxma te section .
as with any classifier a measure that decreases the rate of falsenegatives typically leads to a greater rate of false positives andvice versa.
generally the more benign behavior we see during min ing and allow in our rules true negatives the fewer false alarmswe will encounter during sandboxing.
however if the mined rules overapproximate and thus also allow possible malicious behavior we increase the risk of false negatives.
if the mined rules are too specific though say only allow the exact behavior seen during mining we again encounter false positives during sandboxing.
in this section we thus evaluate more fine grained rules with the aim of reducing the risk of a false negative allowed figure .
.
user driven access control by default boxma te simply checks whether the app as a whole uses the same apis as found and distinguished during recording we call this per app access control.
this policy allows for quick saturation during mining and thus few false alarms during enforce ment however it may be too coarse to prevent some attacks.
for instance once we have seen that snapcha t can read contact phone numbers any function within snapcha t including background tasks would be allowed to do that.
however as we have seen in figure snapcha t accesses phone numbers only to allow the user to find other snapcha t users among his friends.
how about restricting contact access to this functionality only?
43to this end boxma te implements a more fine grained access control policy.
during sandboxing per event access control also verifies whether the api call was triggered by the same event as during mining .
during mining boxma te records pairs event api where event is the identifier of the event triggering gui element and api is the sensitive api called by the event handler.
.
during sandboxing upon each call to a sensitive api api prime triggered by a gui element event prime boxma te checks whether event prime api prime was already found during mining if not the call is flagged.
since our events are interactions with named gui elements and as our api calls all refer to user owned resources the boxma te perevent access control realizes the principle of user driven access control namely tying access to user owned resources to user actions in the context of an application.
.
distinguishing events since we want to recognize earlier events we need a means to uniquely identify an event.
to this end boxma te applies the following rules to identify events.
all views gui elements in android have three features aresource identifier rthat associates views and programmatic actions login button atext label lpossibly displayed on the screen login acontent description dthat can be read out loud to the user as an accessibility feature login .
while most of these features are defined in an xml layout file all of them can also be defined or changed at run time hence the need for a dynamic analysis.
boxma te stores an event eas a tuple e id action idby default is the resource identifier r i fris empty id d instead and if dis empty as well id linstead.
we prefer identifiers to labels since the latter may change during operation for instance when changing the app s language.
action is the user interaction that triggers the event for buttons this is either a click or a long click.
with these rules two buttons are different even if they sport the same text ok as long as they have different resource identifiers.
the following rules apply for special events if all of r l and dare empty ehas the special value unlabeled .
allunlabeled events are treated as one.
if the thread idis not equal to the gui thread ehas the special value background .
again all background events are treated as one.
if the app is reset restarted ehas the special value reset .
this captures events occurring during the program start.
.
evaluation let us see how per event access control works in our snapcha t example.
within snapcha t the contacts permission button api in figure is the only trigger we found for accessing contacts or their phone numbers.
hence enforcing per event access controlwould always require that the user press this specific button beforecontacts can be accessed.
finding friends on snapcha t is probably a rare if not one time only event for most users.
thus even if an attacker worked around the restriction by manipulating this very03 seconds event api pairs seen snapcha t .
.
appguard api s figure droidmate per event api saturation.
after minutes seconds droidmate has discovered unique event api pairs used by snapchat .
functionality say by sending contact data to a different address the attack surface is still greatly reduced.
the downside of per event access control is that it may raise false alarms more easily.
this either translates into a longer mining phase allowing droidma te to find more event api pairs or into a greater risk of false alarms.
this is illustrated in figure show ing the saturation of event api pairs during mining.
in contrast to figure we see that it takes more than an hour of testing until thechart flattens at over of all event api pairs ever explored.
a similar late saturation can also be seen when mining event api pairs for the other twelve apps as summarized in figure .
fine grained policies take longer to mine.
how does the finer granularity impact false alarms?
in table the event column shows the set of alarms encountered.
we seethat the higher granularity comes at the expense of six more con firmations in the barcoo search for product use case an unlabeled button not triggered during testing requests the current loca tion.
cleanmaster requires three confirmations two for changes to configuration when a scan is started or a report is sent andone when a handle to powermanager wakelock is acquired after the scan is finished.
picsart registers a content observer of content com.picsart.studio.provider user .update when a gallery button is pressed.
in the snapcha t take video use case a status button accesses the external media the video is saved in.
inall cases the alarm would be raised right after the user presses the appropriate button the user thus is in the appropriate context to understand why the respective function requires access to say the lo cation or the external media and thus make an informed decision.this is similar to the model imposed upon users in android except that with boxma te we can already eliminate most alarms during testing.
also we require the permission anew for each but ton not only once per app thus further reducing attack surface.
fine grained policies increase the risk of false alarms.
on top our model brings several additional benefits.
by tying api calls to user interaction any stealthy call from the background would be automatically prohibited.
thus none of the apps couldsuddenly start sending text messages turn the microphone on trackthe location or access sensitive contact or calendar data without theuser initiating or acknowledging access.
5we find this a nice thing to have and answer q2 fine grained policies reduce the attack surface.
5the exception is if this is already part of the app s normal operation as in cleanmaster and virusscan.
adobe reader03 antivirus03 barcoo03 cleanmaster03 currency cvtr03 ebay es task manager03 expense mgr03 file manager03 firefox03 job search03 picsart figure per event saturation for the apps in table .
as in figure the y axis is event api pairs the x axis is seconds spent.
.
assessing sandboxes at this point we have one risk left namely the risk of a false negative seen figure if malicious behavior is already present during mining the mined sandbox will not prevent it in the future.
this feature is actually a strength of boxma te as it puts malware writers into a disclose or die dilemma either the malware writer activates the malicious behavior during testing already and onlythen will it be allowed during production or she does not activate the behavior and then the sandbox will prohibit it in the future.
in practice this means that even an attempt for malicious behavioralways will be detectable in the first place as the appropriate api calls will have to be made during testing and mining already andeventually show up as sandbox rules.
while mined sandbox rules by themselves do not and cannot tell whether behavior is malicious or benign or intended or unin tended they do explicitly record what an application does and what not as it comes to privacy.
mined sandboxes can thus assist in wellestablished techniques to assess behavior and establish trust checking behavior.
anyone can mine a sandbox from a given app checking which apis are being used by which functionality this alone already gives a useful overview about what the app does and why.
as these rules come from con crete executions one could easily assess concrete resourceidentifiers such as file or host names or url s accessed.
a mined sandbox easily serves as input for manual and automatic threat assessment.
comparing and certifying sandboxes.
as users and experts alike can mine sandboxes they can also publish and compare their findings.
this allows for independent certification and reval idation schemes as well as trust networks.
again anything not found will automatically be prohibited by the sandbox.
open privacy.
with the disclose or die dilemma vendors would also be motivated to disclose app behavior as it comes to resources being accessed.
in the long run this would lead toopen discussions of what all apps do in terms of privacy verymuch as in the open source movement but without forcing vendors to disclose their source code.
mining normal behavior.
we have designed boxma te to be easily applicable to arbitrary binaries.
we can thus automatically assess large sets of apps extracting rules of normal behavior that may even be tied to app descriptions .
these features can all be helpful in answering the third and lastkey question namely whether mined sandboxes can help to assessbehavior and thus prevent the risk of a false negatives seen figure .
since at this point the ability of sandboxes to assess and compare behavior is only secondary a full fledged evaluation is03 secondsapis seen snapcha t .
.
appguard api s snapcha t .
.
.
appguard api s figure droidmate per app api saturation comparing snapchat versions.
the upper thin red line is the newer snapchat version.
beyond the scope of this paper.
however let us give an example of how sandbox mining helps to assess program behavior.
snapcha t version released in february is a redesign of the original snapcha t version described in this paper.
we have run boxma te on the new snapcha t version comparing the resulting sandbox with the original sandbox as mined for version .
figure contrasts the api saturation charts for the two versions we can see that the new snapcha t accesses the same amount of sensitive resources as the old snapcha t version but the apis are somewhat different.
overall we found snapcha t accesses four sensitive apis not seen during the exploration of snapcha t .
usage of the android .x audiorecord interface the old version used the android .x mediarecorder interface instead .
read write access to image thumbnails through methods of contentresolver interface like query openfiledescriptor and insert while reading the snapcha t privacy policy.
.
access of the user s line1 phone number after clicking on themobile number button .
usage of the android .x powermanager interface forcing the device screen to stay on while the message is sent send to bottom panel send button button .
since droidma te records the events associated with each call we can place each api into context and thus determine why they would be required.
the most sensitive data the user s phone num ber is only accessed after the user has clicked on the appropriatebutton acknowledging access.
just as we compared the respective sandboxes to determine what has changed in snapcha t a n y expert could also have determined other changes between old and new versions of possibly less trustable programs the differencescould even be presented in a form amenable for end users.
a user wishing to preserve privacy settings could also run the untrusted snapcha t version within the trusted sandbox mined 45from snapcha t with any new api accesses being detected by the snapcha t sandbox.
then she would have to confirm access once in each of the four situations .
when recording audio for the audiorecord interface .
when sending a message for the powermanager interface .
when reading the snapcha t privacy policy and .
when sending the message forcing the device to stay on.
each case would inform the user that there is a new feature and thus enable her to detect assess and prevent potentially maliciousbehavior changes.
6our answer to q3 is thus positive mined sandboxes can help in assessing and comparing app behavior .
.
threats and limitations although our results demonstrate the principal feasibility of sandbox mining we would not generalize our findings into external va lidity.
our sample of programs is small is all on android and all gui based.
for other programs and platforms we may have to devise different or additional test generators possibly requiring models of the program input structure as well as the sensitive re sources to be monitored and protected.
these test generators may be less successful in exploring program behavior leading to more false alarms.
the set of use cases we have compiled for assessing the risk of false alarms does not and cannot cover the entire range offunctionality of the analyzed apps.
while we assume that the listed use cases represent the most important functionality other usage profiles may yield different results.
finally keep in mind that in the absence of a specification a mined policy can never express whether behavior is benign or malicious and thus our approach cannot eliminate the risks of both false alarms and missed attacks.
however by detecting and pre venting unexpected changes our approach is set to reduce boththese risks even in the absence of specifications.
on top exist ing specifications for benign or malicious behavior would be very easily integrated.
.
conclusion and future work the purpose of testing always has been to detect abnormal behavior.
in this work we give testing a new purpose namely to extract normal behavior a task that testing arguably is much better suited to and even more so in the security domain.
by exclud ing behavior not seen during testing we turn the incompleteness of testing into a guarantee that bad things not seen so far cannothappen.
this principle of test complement exclusion works well in practice in our experiments automatic test generators sufficientlycovered program behavior reducing the risk of false alarms.
fur thermore fine grained per event access rules can be used to furtherreduce the attack surface and the mined sandbox rules can helpto assess program behavior both reducing the risk of false negatives.
all in all we thus obtain a fully automatic solution to security promising several benefits at little cost.
besides general goals such as robustness and scalability our future work will focus on the following topics better test generation.
any improvement in automatic test generation where improvement is not so much the ability to 6note that whether the user sees these alarms as false entirely depends on the trust the user puts in the new snapcha t version.detect bugs but rather coverage of normal behavior will decrease the number of false alarms.
the long term goal is to explore behavior as quickly as a human tester would.
alternate input sources.
test generation for android apps is made easy by the fact that the gui and its structure are easily accessible and explorable for test generators.
we are investigating novel ways of inferring input structure from arbitrary pro grams and input sources such that these input sources canbe triggered too.
access control policies.
mining tighter and more detailed security policies will catch more unexpected abnormal behavior.we are exploring further policies involving file or networknames accessed callers call sequences gui sequences or information and data flow from and to sensitive resources and in all cases we have to search for sweet spots that mini mize both the attack surface and the number of false alarms.
remining at runtime.
if some application functionality is available only after specific interaction e.g.
a login password combination an in app purchase or a special code to enter a maintenance mode we might not see it during mining.
onepossible way to overcome this issue could be to re mine newfunctionality once user executes the interaction.
computed resources.
on platforms like unix and windows sensitive resources are accessed as files whose paths would be computed at runtime from configuration files environmentvariables and other external influences.
we are working onsandbox rules that express variability across configurations yet are tight enough to keep the attack surface small.
threat models.
the evaluation of all these options will require systematic and objective evaluation.
besides further expand ing our use cases we are working on creating benchmarksfor typical threats such that we can automatically assess theeffectiveness of the above options.
for more information on droidma te and boxma te including source code as well as all experimental data see our site