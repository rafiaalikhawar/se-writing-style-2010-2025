adaptive coverage and operational profile based testing for reliability improvement antonia bertolino breno miranda isti cnr via g. moruzzi pisa italy antonia.bertolino breno.miranda isti.cnr.itroberto pietrantuono stefano russo universit a degli studi di napoli federico ii via claudio napoli italy roberto.pietrantuono stefano.russo unina.it abstract we introduce covrel an adaptive software testing approach based on the combined use of operational profile and coverage spectrum with the ultimate goal of improving the delivered reliability of the program under test.
operational profile based testing is a black box technique that selects test cases having the largest impact on failure probability in operation as such it is considered well suited when reliability is a major concern.
program spectrum is a characterization of a program s behavior in terms of the code entities e.g.
branches statements functions that are covered as the program executes.
the driving idea of covrel is to complement operational profile information with white box coverage measures based on count spectra so as to dynamically select the most effective test cases for reliability improvement.
in particular we bias operational profile based test selection towards those entities covered less frequently.
we assess the approach by experiments with versions from subjects commonly used in software testing research comparing results with traditional operational and coverage testing.
results show that exploiting operational and coverage data in a combined adaptive way actually pays in terms of reliability improvement with covrel overcoming conventional operational testing in more than of the cases.
keywords testing reliability operational profile program count spectrum operational coverage test case selection.
i. i ntroduction testing based on the operational profile i.e.
as if it were in the field is a fundamental technique in software reliability engineering practice .
the aim is to select those test inputs that can expose failures having a higher occurrence probability based on the known or estimated operational profile and hence contributing more to program unreliability.
operational profile based testing is widely used for both reliability assessment and reliability improvement e.g.
within the sret technique .
in this paper we address the latter goal.
several studies document the effectiveness of operational profile based testing for reliability improvement .
however as for any test selection technique it may suffer from the saturation effect chapter due to which its continued application will eventually lose efficacy.
in other words to further improve reliability beyond a certain point testing should try to expose also those failures having low probability of occurrence based on the operational profile .
in the authors provide a formal reasoning model to support the intuition that since different techniques are effective at discovering different faults it is better to use a combinationof approaches rather than relying on one technique alone.
this is discussed also in arguing that the combination of techniques should aim at exposing high occurrence failure regions but also as many failure regions as possible.
here we apply the intuition of combining techniques by mixing operational profile based and coverage testing into a novel hybrid technique named covrel .
the approach is inspired by the notion of operational coverage introduced in which clusters entities into different importance groups according to their count spectra and assigns them different weights while computing coverage.
a spectrum provides a signature of a program s behaviour by tracking the coverage of entities e.g.
statements branches or even whole paths during execution .
traditionally coverage based testing approaches consider hit spectra i.e.
they only measure which entities have been executed at least once .
count spectra provide richer information by also measuring the number of times each entity is executed and are typically used in program optimization .
in operational coverage was studied as an adequacy criterion for operational profile based testing.
here we exploit operational coverage to support test selection precisely we propose that among several test cases that would have a same estimated usage probability in the operational profile we select those that exercise entities yielding so far a low count spectrum.
moreover the approach is adaptive in that testing proceeds in iterations as previously done in and at each iteration both the profile based allocation of number of tests to partitions and operational coverage measures are dynamically updated.
as a result covrel selects the test cases according to the black box operational profile i.e.
the input domain partitions more often invoked in operation are more exercised and among the inputs within a same partition covrel selects those that exercise the least covered entities.
to the best of our knowledge this is the first proposal encompassing the usage of coverage spectra to guide test selection in the framework of a reliability oriented testing technique.
the type of software systems targeted in covrel ing are those for which reliability is a driving concern of testing activities.
examples are large scale mission critical systems for which the time and cost of executing individual tests is high due to configuration set up execution and shutdown .
ieee acm 39th international conference on software engineering ieee acm 39th international conference on software engineering .
ieee authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
for instance a study conducted in an industrial context in has shown that the fault detection rate for complex components may decrease significantly over time giving rise to the need to improve the trend of testing efficacy i.e.
of the level of defectiveness exposed by testers .
for such industrial applications it is particularly important that when operational testing enters the saturation area the marginal cost of executing additional tests pays in terms of reliability improvement.
in covrel we pay the potential improvement in reliability with the cost of measuring coverage.
we experimented covrel on a number of subjects from the public software artifact infrastructure repository sir widely used in software testing research .
we compare covrel with traditional operational and coverage testing on the basis of several metrics.
as we expected the results show that covrel generally outperforms each of them used in isolation when targeting reliability improvement.
in summary this paper provides the following contributions we develop the covrel approach to testing which combines operational profile and coverage spectrum information for improvement of delivered reliability we evaluate covrel with several subjects from the wellknown sir repository and compare it empirically against traditional operational and coverage testing we provide a prototypal implementation of covrel for repeatability and independent verifiability.
the rest of the paper is structured as follows.
section ii provides background information and overviews related work.
section iii presents the proposed covrel technique.
section iv describes the experiments.
section v discusses the results and their statistical significance as well as the threats to validity it also describes the artifacts we produced for implementing covrel which we make available with the aim to support verifiability.
section vi contains concluding remarks and future work.
ii.
r elated work the literature of software reliability and operational profilebased testing is huge.
the underlying idea is to test a program by selecting an input taccording to a probability ptderived from the operational profile distribution.
an operational profile is a quantitative characterization of how a system will be used and is usually built by assigning probability values to inputs representing the probability that each will occur in operation e.g.
by historical data by design level information by expert judgment .
we refer to the highly referenced and still relevant lyu s handbook for a comprehensive overview of the topic and for the rest of this section we focus on related works that from different perspectives explore the relation between reliability and code coverage.
many empirical studies e.g.
among the most recent ones assess the effectiveness of coverage based testing.
however only a few of them measure test effectiveness in terms of delivered reliability as we do here.
among the earliest studies del frate and coauthors found a correlation between increase decrease in reliability and increase decrease in at least one code coverage measure.
in a later work frankl and deng performed a case study comparing various approaches and showed that as coverage increases the probability to achieve high reliability targets increases as well.
however they show also that the probability to reach very high reliability values would require extremely large test sets and it is doubtful whether the improvement is worth the cost.
this is what motivates our work covrel explores the usage of coverage in combination with traditional operational testing for reliability improvement.
several authors have proposed to integrate test coverage information into models used to evaluate reliability as faults are found and removed a.k.a.
software reliability growth models or srgms .
a recent short compendium of such coverageintegrated srgms is given by alrmuny .
although the basic motivation is the same i.e.
that reliability improvement can be impacted by observed coverage measures the usage that we make of such measures is different.
in srgms coverage information is used to better tune reliability estimation as in in covrel we use coverage information for driving test selection building on the concept that coverage measures can provide guidance in identifying what parts of a program should be exercised when augmenting a test suite .
program spectra are used extensively in software analysis and testing .
beyond their original application in program optimization in reps et al.
introduced the idea that differences between path spectra can be used for identifying changes in program behaviour.
following code profiling information has been actively used to analyze the executions of different versions of programs e.g.
in regression testing or to compare traces of failed and successful runs in fault diagnosis .
differently from these approaches we do not use spectra to differentiate behaviors but are interested in identifying which entities have been less exercised.
iii.
a pproach a. assumptions let us denote the input domain of the program under test asd.
suppose a tester has a budget of ttest cases to select from a test suite.
we make the following assumptions the input domain dcan be decomposed into msubdomains hereafter also called partitions d1 ... d m. these are divided according to some partitioning criterion e.g.
functional or structural usually depending on the information available to test designers and on testing objectives.
the operational profile can be described as a probability distribution over partitions di.
we denote with pithe probability that an input is selected from diin operation and summationtextm i 1pi .
inputs within a partition have the same probability of runtime occurrence.
a test case leads to failure or success we are able to determine when it is successful or not perfect oracle .
test case runs are independent i.e.
all the non executed test cases are admissible each time.
the execution of a authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
test case is not constrained by the execution of some other test case before.
this affects the way in which a test case is defined since when test cases are sequences of tasks they can be grouped together in a single test case so that at the end of the test case the system goes back to the initial state .
the output of a test case is independent of the history of testing in other words a failing test case is always such independently of the previously run test cases.
a test suite from which test cases can be selected exists and coverage information of such test cases is available or can be obtained.
b. the covrel strategy overview the objective of covrel is to improve delivered reliability efficiently by means of a focused test case selection strategy.
the strategy proceeds adaptively in subsequent iterations and the underlying idea is to dynamically gain knowledge along testing execution about i which regions of the input space and then ii which specific test cases within each region are expected to contribute more to reliability improvement at the next iteration.
in line with reliability is defined as r summationtext t fpt wherefis the set of inputs leading to failure i.e.
the failure points and ptis the expected probability of occurrence in operation of input t. thus the reliability contribution of a set of test cases depends on the number and size of the detected failure regions1 i.e.
how many failure points are corrected by the removal of the detected faults and on their expected probability of execution in operation.
it may well happen that eliminating few but frequent failure points is better than eliminating many infrequent ones so a balance between these two contrasting objectives is needed.
as detected failure points are removed during the testing and debugging process the status of the input domain changes this requires adaptivity if we want to look always for the best balance along the entire process.
covrel is designed to iteratively search for those test cases with potentially the highest contribution to un reliability by combining the ability of finding still undetected faults with the ability of finding high occurrence ones.
it uses learning and adaptation to dynamically characterize the input domain partitions and select test cases from them.
the strategy is sketched in figure .
the iterative process foresees two main phases the allocation of test cases to partitions di and the selection of test cases within each partition.
it is conceived to exploit the results of test execution per partition namely number of exposed failures and current coverage at each iteration in order to drive test allocation and selection at successive iterations.
the steps are described in detail in the following.
1a failure region is the set of failure points eliminated by a program change .
fig.
the covrel strategy c. phase allocation of test cases to partitions covrel s adaptiveness aims at periodically re allocating test cases depending on where more tests are actually needed.
this is accomplished by means of an algorithm based on the importance sampling is method which is an inference method to approximate the true distribution of a variable of interest that we also used in previous work .
in covrel the true unknown distribution of interest is the best number of test cases for each partition that would maximize the delivered reliability.
the algorithm represents the beliefs i.e.
hypotheses about this distribution by means of sets of samples .
each sample is associated with a probability that the belief is true at each iteration these probabilities are updated by examining some new samples of that hypothesis and a larger number of samples are drawn from hypotheses with a larger probability.
the goal is to converge in few iterations to the true best distribution of test cases.
to establish how the probability of each hypothesis is updated based on new collected samples an update rule is defined.
at a given iteration k the is based algorithm exploits information from previous iterations about the observed failing tests.
the failure rate denoted with i defined as number of failing tests over number of executed ones is used to smoothly direct testing toward the partitions with a high expected un reliability contribution in the next iteration.
specifically let us denote with k the probability vector representing for each partition iand at iteration k the likelihoods that testing from that partition contributes to improve delivered reliability .
denoting with i pi ithe weighted failure rate normalized authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
so that summationtext i i the update rule for the values k iforming the probability vector is defined as k i k i k i .
such assignment tends to explore the input domain by progressively moving tests to partitions where unreliability contribution was still small this allows detecting hard to find faults after easier ones have been found.
the smoothness of adaptiveness is determined by the parameter regulating how the algorithm considers past iterations results with respect to current ones2.
note that the k ivalues are normalized since they are probabilities k i k i summationtext i d k i .
starting from k i t k i tests are allocated to partition di at iteration kby a simple procedure to assign proportionally more tests to domains with higher pivalues so as t k i t k k i. to determine the best t k at each iteration we consider an adaptive implementation of importance sampling .
based on a desired error and confidence this variant tends to progressively reduce the number of required samples as more information becomes available using the formula t k 2 2 2 radicalbig z1 where is the error we want to tolerate between the samplingbased estimate and the true distribution is the desired confidence in this approximation is the number of partitions from which at least one test case has been drawn in the kth iteration z1 is the normal distribution evaluated with significance level .
the algorithm is triggered by an initial static allocation of t tests at iteration .
several alternatives can be chosen for such initial allocation depending on the initial knowledge about failure likelihood of partitions e.g.
via expert judgment about partition criticality .
we assume that no information is available and allocate tests proportionally to the expected usage of the partition pi so giving more tests to partitions whose inputs are expected to be more exercised.
the number of testst must be a small subset of t as it is just required to trigger the allocation algorithm .
summarizing the output of this phase is the computation of the most proper number of test cases t k to run and their allocation to partition di namely t k i. in the following we detail how these tests are selected within partitions.
d. phase selection of test cases within a partition while the previous allocation step suggests the number t k iof test cases to execute for each partition the selection step cares about picking these t k itest cases among the ones not yet executed without replacement selection in an effective way.
2we set at .
in our experiments.
3in general the bigger t is the better the initial learning could be but the later the adaptation will start.
in our experiment we opted for t equal to the number of partitions.as we assume that no initial knowledge is available about the failure likelihood of partitions at the first iteration of covrel the test cases are selected following a traditional operational profile based testing i.e.
they are just randomly selected according to occurrence probability of each partition di.
however while the test cases are executed their traces are tracked as in any white box testing strategy.
at the end of each iteration the learning phase takes place the covrel approach computes the cumulative count spectrum achieved during the execution of the selected test cases and uses it to drive the selection strategy for the next iteration.
more precisely the cumulative count spectrum is used to identify the frequency with which entities have been exercised.
for the experiments we report in section iv we classified the entities into three different importance groups high medium and low.
to obtain such groups we ordered the entities available in the count spectrum according to their frequency of usage and assigned the top entities to the high frequency group the second entities to the medium frequency group and the last entities to the lowfrequency group.
next our approach evaluates each test case that belongs to the target partition diand ranks them according to how they cover the program entities.
for computing the test case rank we assign weights to each importance group.
as we are interested in selecting test cases that cover entities so far rarely exercised we assign the weights for the importance groups in such a way that the medium group is one order of magnitude more important than the high and the low group on its turn is one order of magnitude more important than the medium group e.g.
whigh wmedium andwlow .
for a given partition di the test cases with the highest ranks are the ones selected to compose the t k iset.
in the case of a tie i.e.
multiple test cases would achieve the same rank our heuristic randomly selects one test case among the tied ones.
the allocation and selection steps are repeated in covrel until the number of available test cases thas been run as depicted in figure .
iv .
e xperiments we performed a controlled experiment to assess the effectiveness of covrel in reliability improvement.
the experiment aimed at answering the following research question is covrel more effective at reliability improvement than traditional operational profile based testing?
for our setting more effective means being able to deliver a given reliability value with fewer test cases.
we consider various testing scenarios under different operational profiles each scenario is determined by the subject program under test the coverage criterion adopted by the covreltest selection algorithm e.g.
function branch or statement coverage and the selection of seeded faults.
these factors are described in the remainder of this section.
a. study subjects we evaluate covrel on a total of versions from four subjects taken from sir grep gzip sed and flex.
grep authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
is a command line utility for searching lines matching a given regular expression in the provided file s gzip is an application used for file compression and decompression flex is used for generating scanners that are able to recognize lexical patterns in text and sed is a stream editor that performs text transformations on an input stream.
three of these programs grep gzip and flex are available from sir with variant versions containing seeded faults whereas sed contains variant versions.
all of them have test suites derived according to the category partition method available via tsl test specification language files.
because our study required us to measure the reliability delivered by the evaluated approaches at different stages of the test execution we excluded the versions where the test suite available from sir could not identify any of the seeded faults available for that particular version.
this happened for grep v5 gzip v3 and sed v1.
besides that we also excluded version of flex due to its anomalous characteristics faults could be revealed by more than of the test cases while other faults could be revealed by of tests the vast majority of the test cases available in the test suite would be able to reveal of the seeded faults so all the faults would be detected after few tests.
additional details about our study subjects are displayed in table i. column loc shows the lines of code4of each variant version.
the column detectable faults contains the number of faults from the set of seeded faults that could be detected by the sir test suite whereas the column hard faults refers to the subset of detectable faults that could be revealed by less than of the available test cases.
table i study subjects considered in our investigations subject loctest suiteseeded faultsdetectable faults hard faults grep v1 grep v2 grep v3 grep v4 gzip v1 gzip v2 gzip v4 gzip v5 sed v2 sed v3 sed v4 sed v5 sed v6 sed v7 flex v1 flex v2 flex v3 flex v4 total b. study settings besides the study subjects acquired from sir our experiments required the following additional artifacts.
4collected using the cloc utility suite .
we used the test suites from sir that are available along with each one of the subjects investigated in our study.
the number of test cases available in each test suite is provided in table i. partitions.
we assign each test case in the test suite to a different partition based on the functionality exercised by the test input.
to this aim we inspected the tsl test specification language file made available with the subject which specifies the function units and their input space features in terms of parameters categories and choices according to categorypartition testing terminology along with the user manual in order to infer the main functionalities.
each functionality is associated with a partition we ended up with partitions for grep for gzip for sed and for flex.
we then derived a script to automatically parse the available test cases and allocate each test case to its respective partition based on the functionality it exercises.
fault matrix.
for each subject and version we run the available test suite and with the support of sir tools we extracted the fault matrix i.e.
a mapping that tells us which faults can be revealed by which test cases.
because in our study we want to evaluate the effectiveness of the proposed approach to reveal the most relevant faults besides the original fault matrix we derived a second modified one we refer to it as hard fault matrix by excluding the easy to find faults that could be revealed by or more test cases.
operational profile.
atesting configuration is a combination of the fault matrix and the coverage criteria adopted by covrel i.e.
function branch and statement .
a testing scenario is a testing configuration applied to a program version pair.
for each testing scenario we derived operational profiles.
an operational profile is a quantitative characterization of how a system will be used it can be described as a set of values pi denoting the probability that an input is selected from partition iand such that summationtextm i 1pi withmbeing the number of partitions .
profiles are built by generating thepivalues according to a uniform distribution in then normalizing the values so that they sum up to .
c. compared techniques we compare covrel against conventional operational testing where test cases are selected based exclusively on the operational profile estimate .
the implemented operational testing technique hereafter ot selects a partition difrom the given test suite at random in accordance with its usage probability pi .
a test within the partition is then selected with equal probability i.e.
by a uniform distribution similarly to related literature e.g.
.
we examined covrel while targeting different coverage criteria function branch and statement .
as we want covrel to bias the test selection towards test cases covering entities more rarely exercised we set the weights for the importance groups as whigh wmedium andwlow .
the importance sampling parameters see section iii c are set as follows the learning factor is .
the confidence is .
the desired maximum error is .2for authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
grep sed and flex and .1for gzip as the lower ratio of test cases over partitions suggests a faster adaptation.
d. number of runs considering the above factors we have fault matrices x coverage criteria testing configurations each applied to the program version pairs getting to different testing scenarios .
in each testing scenario we compare the two testing techniques covrel and operational testing by running testing sessions are performed one per generated operational profile .
the total number of runs thus is testing scenarios x profiles x compared techniques runs.
e. evaluation metrics to address the research question we compare the techniques in terms of testing reliability namely probability of not failing during testing 5vsnumber of test cases.
specifically in each testing session we measure the number of test cases required to achieve reliability i.e.
to reveal all the faults that can be detected by that test suite by the two compared techniques let us denote them as ncovrel and not respectively.
then as a summary metric in each given testing scenario we count the number of times ncovrel not i.e.
covrel achieves reliability with fewer test cases than traditional operational testing or the vice versa over the repetitions.
moreover in order to evaluate how the techniques perform during a testing session we assess the reliability growth at different checkpoints.
specifically we observe delivered reliability after the execution of and of total executed test cases to achieve reliability .
we count the number of wins in this case in terms of achieved reliability of each technique at every checkpoint.
f .
experiment procedure the automated procedure followed for each testing session includes these steps generate the operational profile as explained above.
select the test case according to the technique under evaluation covrel and ot and observe if it exposes a failure or not.
the detection of failures is done by considering the fault matrices.
if a failure occurs remove the fault7.
repeat from step until ttest cases are executed.
at the end of the session compute the metrics presented above useful for evaluation.
5in general the available test cases are not able to detect all the faults like in the experimented subjects cf.
with table i so even when testing reliability is i.e.
all faults detectable by the test suite are detected the actual operational reliability is likely not because undetected faults could be exposed in operation.
since operational reliability is hard to measure testing reliability is adopted for comparison purposes.
6we take the minimum of ncovrel andnot and consider the and of it.
7note that for one failure the tester could remove more faults failure regions may not be disjoint in our case we choose to remove all the faults i.e.
the repetition of the test case must no longer lead to failurev.
r esults in this section we report the results from the experiments performed to answer our research question whether covrel is more effective at reliability improvement than ot.
we measure effectiveness in reliability improvement in two different manners respective number of test cases required to reach a same high reliability value fixed to in the reported study section v a and respective values of reliability achieved with a same fixed number of test cases section v b .
although coverage based testing has a different objective by discovering faults it can improve reliability.
as covrel combines operational and coverage information we would like to compare it not only with ot but also with coveragebased testing to assess if our combination outperforms each of the two approaches taken alone in improving reliability.
the results of a further evaluation assessing covrel vs traditional coverage based selection are reported in section v c. a. which approach achieves reliability faster?
in table ii we report the results from the six configurations tested combinations of coverage strategy and fault matrix see section iv f counting for each the number of times out of different observations in which covrel outperforms ot and wins in column w the number of times covrel loses in column l the ties in column t. at bottom of the same table two rows report the mean and median values for each column.
as evident by the mean and median values our approach is generally more effective in reaching maximum reliability.
in all cases the mean and median of win counts are much higher than losses and also higher considering losses and ties summed together.
looking more in detail we can observe that if we consider each pair subject configuration i.e.
what we called a testing scenario as a distinct experiment we got valid results pairs among the possible ones are marked as n a because for such cases the hard fault matrix and the original one were the same see section iv a .
among these covrel wins i.e.
achieves reliability with a lower number of test cases than ot in cases i.e.
more than of the times.
the above result does not distinguish between clear and tight wins i.e.
regardless whether the result is wins over losses e.g.
as for grep v1 in configurations and or wins against losses as for flex v1 in configuration it is anyhow counted as .
if we consider each repetition on a different profile as a different observation and consider the sum of wins against sum of losses then we can observe that covrel outperforms ot in all configurations i.e.
summing the results per columns and for subjects out of i.e.
summing the results per rows .
precisely covrel cumulatively loses with grep v2 gzip v2 sed v7 and flex v3 and wins for all other subjects.
it is interesting to look at the cases where covrel performs worse than ot.
in general with the only exception of sed v3 for which covrel loses only in configuration when this happens it happens consistently in all configurations authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
table ii number of wins losses ties over repetitions in terms of number of required test cases to achieve reliability subjectconfig.
function hard fmconfig.
branch hard fmconfig.
statement hard fmconfig.
function default fmconfig.
branch default fmconfig.
statement default fm wl t wlt wlt wl t wlt wl t grep v1 grep v2 n a n a n a n a n a n a n a n a n a grep v3 grep v4 n a n a n a n a n a n a n a n a n a gzip v1 gzip v2 gzip v4 gzip v5 sed v2 sed v3 sed v4 n a n a n a n a n a n a n a n a n a sed v5 sed v6 sed v7 flex v1 flex v2 flex v3 n a n a n a n a n a n a n a n a n a flex v4 mean .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
median .
.
.
.
.
hinting at a possible explanation that perhaps there are types of failure regions for which our approach does not perform well.however further empirical investigation is required before ageneral conclusion can be drawn.
on the other hand especially interesting for us is the overall good result over configurations.
this result shows that the idea of combining operational profile based testing with coverage spectra is promising across different coverage criteria and forboth easy and hard faults.
we further evaluated the above results with statistical analysis.
given a testing scenario we consider the above number oftimes a technique wins as our performance measure.
we usedthe wilcoxon signed rank test 8to assess the null hypothesis that the difference between the number of wins in the twocompared cases follows a symmetric distribution around zero namely they are statistically equivalent.
results are displayedin table iiia and they clearly show the high confidence onrejecting the null hypothesis as well as the big difference between the overall mean and median values of the number of wins.
b. how do covrel and ot compare in terms of delivered reliability evolution?
in practice it may not be realistic to assume that testing can continue until reliability achieves .
so it may be alsointeresting to look at the results achieved at intermediatestages of testing.
we thus compared the effectiveness of covrel against ot at three intermediate checkpoints namely after the execution of and of tests run to get reliability as defined in section iv e. at each checkpoint we measuredthe achieved reliability by either approach and counted whichone is yielding a higher value.
for the sake of space we report 8we could alternatively apply multiple sign wins loss ties tests with multiple comparison protection procedure but we opted for wilcoxon signedrank test by treating the number of wins as our performance variable sinceit is indeed more powerful .table iii hypothesis tests.
text in boldface indicates that the difference is significant at least at .
a number of wins in terms of test cases to achieve reliability pairwise comparison covrel ot mean .
.
median .
.
p value .1270e b number of wins in terms of reliability at checkpoints pairwise comparison covrel mean .
.
.
otmean .
.
.
covrel median otmedian covrel ot p value0.
.
.
the mean and median results of the number of wins and losses ofcovrel against ot table iv .
figure shows a sample of cases specifically we observed the delivered reliability of all subjects at and we pickedthe version in which covrel performs best on the left and the version in which performs worst on the right .
from this figure we can see that on flex covrel tends to be consistently better than ot the opposite happens on sed and finally on grep and gzip the results vary across versions.
so again theseresults hint at the need to continue experimentation of furthersubject programs for generalization.
in this experiment we are interested to observe the trend while reliability grows.
our expectation is that covrel would yield better results in comparison with ot for higher values ofreliability i.e.
when ot starts suffering from the saturationeffect .
although results are again promising the mean values authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
table iv mean and median values of wins losses of covrel in terms of delivered reliability over repetitions at three different checkpoints and subject resultmean median grep v1wins losses grep v2wins losses grep v3wins losses grep v4wins losses gzip v1wins losses gzip v2wins losses gzip v4wins losses gzip v5wins losses sed v2wins losses sed v3wins losses sed v4wins losses sed v5wins losses sed v6wins losses sed v7wins losses flex v1wins losses flex v2wins losses flex v3wins losses flex v4wins losses at each checkpoint of covrel s wins over subjects in a given configuration are bigger than corresponding losses in all the configurations x checkpoints cases we did not observe such an increasing trend across checkpoints on the contrary covrel wins more often at the checkpoint.
in particular if we take the mean values of the number of wins at the three checkpoints reported in the first two rows of table iiib we see that at the the difference between covrel and ot is around .
at the it is about .
and at the the gain reduces to .
similar considerations stand for medians .
the hypothesis test compares the number of wins of the two approaches at the three checkpoints.
results are displayed in table iiib the test achieved .
p value only at the while in the other two cases the average values of covrel and ot wins are not significantly different.
this confirms that there is not a clear trend of covrel improvement across checkpoints and since the final differences i.e.
at of test cases are much more pronounced in favor of covrel it means that most of the work by covrel is done between and .
this is likely due to a greater ability to uncover more subtle rare faults ah ypothesis also corroborated by observing that the10 a grep v110 b grep v2 c gzip v410 d gzip v1 e sed v510 f sed v7 g flex v210 0win loss tie h flex v1 fig.
covrel vs ot at checkpoints average among the three means differences covrel ot in the configurations with hard faults is bigger than the same average with all the faults inside .
vs19.
.
c. how does covrel compare with traditional white box coverage based selection heuristics?
as we make use of coverage information to drive the selection phase of our approach we performed further evaluations to investigate the effectiveness of covrel when compared with traditional white box coverage based selection.
for so we adopted the greedy total and greedy additional heuristics as they are often considered the baseline for coverage based selection approaches due to their high cost effectiveness ratio .
in making such a comparison we need to consider though that test selection driven by reliability or by coverage set quite different targets.
as said already the former aims at selecting test cases so to reproduce usage in operation whereas the latter aims at exploring exhaustively the program under test.
because of such different goals the stopping criteria for reliability testing is achieving an acceptable estimation of reliability in operation while the greedy coverage approaches when applied for selection purposes stop when the maximum authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
coverage that can be attainable by the set of tests available for selection is reached.
therefore the notion of operational profile and consequently the notion of fault importance that we applied in the comparison between covrel and ot is not applicable to traditional coverage based selection heuristics.
thus it does not make sense to measure the delivered reliability at different points of the selection task.
however if the test suite derived by the selection approach is able to identify all the faults that could be possibly revealed we can at least be sure that the maximum feasible reliability was achieved.
along these lines to have comparable results we performed the following steps we compute from the runs reported in table ii the average number of test cases required by covrel to achieve the maximum attainable reliability for each combination of subject version fault matrix and coverage criterion we use the greedy total and greedy additional heuristics to derive test suites targeting the maximum coverage that could be achieved by the subjects test pool we stop the greedy selection when i all the faults are revealed or ii the maximum attained coverage is achieved and we save the number of test cases selected.
in our experiments in the vast majority of the observations it was the case that either the selection heuristic finished the iterations being able to achieve maximum reliability in all the cases or it was never able to reveal all the faults before reaching the maximum achievable coverage.
for the exceptional cases if all the faults were revealed in at least observations we computed the average number of test cases required to achieve the maximum reliability if not we considered that the selection approach was not able to achieve maximum delivered reliability for that particular combination of subject version fault matrix and coverage criterion.
table v average number of test cases required by covrel and the greedy total heuristic to achieve the maximum attainable reliability subjectfunction branch statement covrel total covrel total covrel total grep v1 grep v2 grep v3 grep v4 gzip v1 gzip v2 gzip v4 gzip v5 sed v2 sed v3 sed v4 sed v5 sed v6 sed v7 flex v1 flex v2 flex v3 flex v4 4due to space limits in table v we report only the results of our evaluation when considering the greedy total approach and the default fault matrix9.
precisely table v gives the average number of test cases required to achieve the maximum attainable reliability.
for interpreting the results the lower the number the better.
the cases in which the traditional coverage based selection approach was not able to reveal all the faults is represented by a dash .
this happened in of the cases out of reported in table v. the covrel approach performed better in of the cases out of .
for ease of readability we highlight in bold the cases in which covrel performed better than the greedy total approach.
when considering the same setting the greedy additional approach was not able to achieve the maximum attainable reliability in of the cases out of and it was defeated by covrel in of the cases.
d. threats to validity beyond our best efforts in the accurate design and execution of experiments our results might still suffer from validity threats.
as for internal validity the selection of tests by covrel and operational profile based technique includes in either case some random step and thus without proper controlling the experiment settings an observed difference in the outcomes might be due to random variability and not to actual differences in effectiveness.
to prevent this for each configuration we repeated the experiment times and in sections v a and v b we reported the average outcomes over all repetitions.
a similar reasoning applies to our derivation of the operational profile partitions for each subject these are used as proxies for true operational profiles but if our approximation is not good the observed results might not be related to reliability.
using averaged data over executions corresponding to as many profiles helps to mitigate this risk but further experiments with true profiles may be needed to fully neutralize it.
another threat to internal validity might derive from the usage of the test suites available in the sir repository which i do not achieve full coverage and ii do not detect all faults in the repository.
therefore we might have observed outcomes that are impacted by such characteristics of the test suites rather than by the treatment under study.
to mitigate this risk we could have manipulated the test suite e.g.
by adding more test cases.
however the sir repository data represent a golden standard for benchmarking purposes and are used in several similar studies.
thus to make the study more objective and repeatable we preferred to undergo this potential threat and use each subject as it is provided with all of its artifacts.
concerning construct validity assessing which technique between covrel and ot reaches testing reliability faster i.e.
9detailed results when considering the greedy additional approach and also the hard fault matrix are available at authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
finds all detectable failure regions might not be a proper measure of effectiveness in reliability improvement.
in real practice it would not be possible to conclude that reliability has been reached because obviously we do not know a priori how many failure points exist.
thus other stopping rules to compare the treatment covrel against the baseline might produce different outcomes.
to mitigate such threat we fixed three checkpoints to complement the above result and compared the techniques at such intermediate values.
however a true confirmation could only be achieved through reliability assessment either in production or under a real operational profile in the context of the present study we could not perform either but the experimentation of covrel within an industrial context is planned as future work.
finally concerning threats to external validity the study results may suffer of representativeness of the used subjects and faults.
with reference to subject representativeness our study covered in total variant versions of four c programs.
even though those versions belong to four subjects only it is well known that for those four subjects from sir the differences between versions may be quite significant and this is also visible from variations of results across versions in figure .
as for sed for instance the development of v5 spans almost years and the differences with respect to v4 are impressive nearly every major function changed significantly.
so they could be considered as different programs.
a similar case of fairly significant differences happened between versions v6 and v7 as reported in the accompanying material from sir .
nevertheless before the results can be generalized additional studies with a range of diversified subjects should be conducted.
with reference to faults representativeness as said in our study we considered seeded faults subjects with real faults might yield different results.
control for this threat can be achieved only by conducting additional studies using subjects with real faults.
e. v erifiability it is a goal of this study to support independent verification of the experiments as well as repeatability with other subject programs also in consideration of the discussed threats to external validity.
to these aim in addition to using subjects from the sir repository we developed artifacts for automating the execution of the experiments and we make them available to the scientific community10.
the artifacts consist of a prototypal covrel application with several modules written in the java and python programming languages the prototype delivered in a .jar file takes as input the subject program and its version and the desired number of repetitions i.e.
of profiles to generate the detailed results of the experiments.
these are packaged in a number of files in csv format each experiment 10the covrel artifacts and detailed results of this study are available at the url the six configurations described in section iv three coverage criteria by two types of fault matrix and produces five csv files with many more details than those presented here plus a textual file with the console output which allows post execution reconstruction of the progress of the experiment.
operating instructions for running the prototype of covrel are provided in the readme files accompanying it.
vi.
c onclusions when product reliability is a major concern software testing is often based on the operational profile i.e.
it exploits data on typical product usage so as to expose failures and then remove the causing bugs that will occur in operation with higher probability thus contributing more to the delivered un reliability.
one criticism to operational testing is that it pays too little attention to failures with low probability of occurrence hence as testing proceeds reliability achieves some stable level that becomes difficult to improve further.
in this paper we have introduced covrel a reliability driven adaptive testing technique that is hybrid in that first in its kind it complements black box operational profile information with white box coverage measures based on count spectra.
this way test selection is dynamically adapted towards those program entities that have been less frequently covered ultimately yielding improved reliability.
with regards to scalability of covrel the cost of collecting coverage information is certainly a concern.
the covrel technique is meant for practitioners who need to improve reliability beyond saturation of conventional operational testing in such a context the relevant cost is the high number of tests required to meet the reliability target rather than the overhead of each test execution namely coverage costs .
it is also worth noting that the use of count spectra and associated cost may compensate the availability of a not very detailed operational profile which is a common situation and a known limitation of operational testing from the point of view of its practical industrial application.
however we cannot state that in general the benefits of covrel warrant coverage collection costs as this will depend on trade offs to be assessed on a case by case basis and on how much the case under testing falls in the mentioned target context.
in the future our aim is to adapt covrel fortest generation e.g.
deriving the next test based on coverage spectra of tests executed up to a certain time other than for test selection as we have done here.
moreover further experiments with large scale applications need to be conducted in order to finetune the adaptation criteria and of course to provide a more comprehensive assessment of the proposed technique.
acknowledgment this work has been partially supported by the gauss national research project which has been funded by the miur under the prin program.
breno miranda wishes to thank the brazilian national council for scientific and technological development cnpq for providing his scholarship grant.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.