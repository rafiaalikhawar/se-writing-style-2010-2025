quality and productivity outcomes relating to continuous integration in github bogdan vasilescuy yue yuzy huaimin wangz premkumar devanbuy vladimir filkovy ydepartment of computer sciencezcollege of computer university of california davis national university of defense technology davis ca usa changsha china vasilescu ptdevanbu vfilkov ucdavis.edu yuyue hmwang nudt.edu.cn abstract software processes comprise many steps coding is followed by building integration testing system testing deployment operations among others.
software process integration and automation have been areas of key concern in software engineering ever since the pioneering work of osterweil market pressures for agility and open decentralized software development have provided additional pressures for progress in this area.
but do these innovations actually help projects?
given the numerous confounding factors that can in uence project performance it can be a challenge to discern the effects of process integration and automation.
software project ecosystems such as github provide a new opportunity in this regard one can readily nd large numbers of projects in various stages of process integration and automation and gather data on various in uencing factors as well as productivity and quality outcomes.
in this paper we use large historical data on process metrics and outcomes in github projects to discern the e ects of one speci c innovation in process automation continuous integration .
our main nding is that continuous integration improves the productivity of project teams who can integrate more outside contributions without an observable diminishment in code quality.
categories and subject descriptors d. .
testing and debugging testing tools general terms experimentation human factors keywords continuous integration github pull requests bogdan vasilescu and yue yu are both rst authors and contributed equally to the work.
.
introduction innovations in software technology are central to economic growth.
people place ever increasing demands on software in terms of features security reliability cost and ubiquity and these demands come at an increasingly faster rate.
as the appetites grow for ever more powerful software the human teams working on them have to grow and work more e ciently together.
modern games for example require very large bodies of code matched by teams in the tens and hundreds of developers and development time in years.
meanwhile teams are globally distributed and sometimes e.g.
with open source software development even have no centralized control.
keeping up with market demands in an agile organized repeatable fashion with little or no centralized control requires a variety of approaches including the adoption of technology to enable process automation.
process automation per se is an old idea going back to the pioneering work of osterweil but recent trends such as open source distributed development cloud computing and software as a service have increased demands for this technology and led to many innovations.
examples of such innovations are distributed collaborative technologies like git repositories forking pull requests continuous integration and the devops movement .
despite rapid changes it is di cult to know how much these innovations are helping improve project outcomes such as productivity and quality.
a great many factors such as code size age team size and user interest can in uence outcomes therefore teasing out the e ect of any kind of technological or process innovation can be a challenge.
thegithub ecosystem provides a very timely opportunity for study of this speci c issue.
it is very popular increasingly so and hosts a tremendous diversity of projects.
github also comprises a variety of technologies for distributed decentralized social software development comprising version control social networking features and process automation.
the development process on github is more democratic than most open source projects anyone can submit contributions in the form of pull requests .
a pull request is a candidate proposed code change sometimes responsive to a previously submitted modi cation request orissue .
these pull requests are reviewed by project insiders akacore developers or integrators and accepted if deemed of su cient quality and utility.
projects that are more popular and widely used can be expected to attract more interest and more pull requests these will have to bebuilt tested and reviewed by core developers prior to actual inclusion.
this process can slow down given the limited bandwidth of core developers thus popular innovative and agile projects need process automation.
one key innovation is the idea of continuous integration ci essentially ciattempts to automatically build and deploy the software in a sandbox and automatically run a collection of tests when the pull request is received.
by automating these steps a project can hope to gain both productivity more pull requests accepted and quality the accepted pull requests are prescreened by the automation provided by ci .
starting from a newly mined data set of the usage of ci ingithub projects in this paper we looked at the software engineering outcomes which present di erentially with the introduction of civersus without.
in particular our contributions are we collected a comprehensive data set of github projects which at some point in their history added the travis ci functionality to the development process.
our data is available online at yuyue pullreq ci .
we found that after ciis added more pull requests from core developers are accepted and fewer are rejected and fewer submissions from non core developers get rejected.
this suggests that ciboth improves the handling of pull requests from insiders and has an overall positive e ect on the initial quality of outside submissions.
despite the increased volume of pull requests accepted we found that introduction of ciisnotassociated with any diminishment of user reported bugs thus suggesting that user experienced quality is not negatively affected.
we did see an increase in developer reported bugs which suggests that ciis helping developers discover more defects.
.
background the focus of our work is the e ect of continuous integration in the context of open source projects that use the pull request based model of development.
we begin with some background.
.
continuous integration the concept ofciis often attributed to martin fowler based on a blog entry .
the basic notion is that all developers work within a team is continually compiled built and tested.
this process is a perpetual check on the quality of contributed code and mitigates the risk of breaking the build or worse because of major incompatible changes by di erent people or di erent sub teams.
arguably cioriginated from the imperatives of agility viz.
responding quickly to customer requirements.
it can be viewed as a type of process automation rather than wait for some sort of human controlled gate keeping of code prior to building and integration testing automated mechanisms are incorporated into the development environment to carry out these steps continually and automatically.
in software engineering continuous integration is viewed as a paradigm shift perhaps as important as using version control .
withoutci software is considered broken until proven to work typically during a testing or integration stage.
withci assuming a comprehensive automated test suite software is proven to work with every new change and serious regressions can be detected and xed immediately.
in the context of distributed globalized development cultural geographical and time di erences raise the spectre of process variation and non repeatability and thus amplify the imperatives to adopt process automation.
this applies even more strongly to open source software oss projects where in addition to the above issues volunteers are involved and there is also a lack of centralized control .cihas become quite popular in oss projects and many projects in github are using it .
numerous tools that supportciexist .
therefore one might expect that these teams are seeing bene ts from adopting ci and that one could obtain quantitative evidence of these bene ts.
.
pull based software development the pull based development model used to integrate incoming changes into a project s codebase is becoming the de facto contribution model in distributed software teams .
enabled by git pull based development means that contributors to a software project can propose changes without the need for them to share access to a central repository instead contributors can work locally in a di erent branch or fork local clone of the central repository and whenever ready request to have their changes merged into the main branch by submitting a pull request .
compared to patch submission and acceptance via mailing lists and issue tracking systems which has been the traditional model of collaboration in open source the pullbased model o ers several advantages including centralization of information e.g.
the contributed code the patch resides in the same source control management system as the rest of the system therefore authorship information is e ortlessly maintained on modern collaborative coding platforms such as bitbucket gitorius and github a wealth of data about the submitter s track record is publicly available to project managers via user pro le pages and process automation e.g.
github provides integrated functionality for pull request generation automatic testing contextual discussion in line code review and merger .
by decoupling the development e ort from the decision to incorporate the results of the development in the code base the pull based model also o ers an unprecedentedly low barrier to entry for potential contributors i.e.
the so called drive by commits since anyone can fork and submit pull requests to any repository.
therefore projects can use pull requests complementarily to the shared repository model such that core team members push their changes directly and outside contributors submit changes via pull requests.
however projects can also use pull requests in many scenarios beyond basic patch submission e.g.
for conducting code reviews and discussing new features .
as a result in many projects all contributions are submitted as pull requests irrespective of whether they come from core developers with write access to the repository or from outsiders which ensures they adhere to the same evaluation process e.g.
only reviewed code gets merged .
the pull based model is widely used.
for example on github alone almost half of all collaborative projects use pull requests and this number is only expected to grow.
ruby on rails 1one of the most popular projects on github submitting profile social activities contributionsevaluate contributor patch size qualitypull requestissue tracker prpr prprpr pr discussingcontinuous integration system merging core team management workload team size priority inputtesting branch build test notifyingoutputfigure overview of the pull request evaluation process receives upwards of three hundred new pull requests each month.
the high volume of incoming pull requests poses a serious challenge to project integrators i.e.
the core team members responsible for evaluating the proposed changes deciding whether to apply them or not and integrating them into the main development branch .
integrators play a crucial role in pull based development .
dabbish et al.
identify management of pull requests as the most important project activity on github .
gousios et al.
consider integrators to be guardians for the project s quality .
they must ensure not only that pull requests are evaluated in a timely matter and eventually accepted to secure the project s growth but also that all contributions meet the project s quality standards.
.
pull request evaluation prior work on pull request evaluation on social coding platforms like github points to a complex process in uenced by a multitude of social and technical factors.
the level of transparency available on github where a number of social signals become more readily available has shaped the way developers make inferences about each other and their work .
for example the integrated social media features e.g.
following other developers watchingrepositories and commenting on pull requests enable participants in these communities to build social relationships while public pro le pages make salient information about one s track record as developer and even demographic features e.g.
gender .
integrators use social signals to build trust in the submitted contributions e.g.
they build mental pro les of the submitters competence by evaluating their track record and they base judgements of the contributions on personal relationships with the submitters .
prior work has also uncovered which technical factors are associated with contribution acceptance e.g.
code quality adherence to coding styles and project conventions existence of testing code in the pull request and how active the particular project area a ected by the pull request is .
in trying to handle pull requests e ciently without compromising software quality especially when faced with an increasing volume of incoming pull requests integrators of ten resort to automated testing as supported by ciservices .
on github of projects that use pull requests frequently also use ci either in hosted services e.g.
travis ci jenkins or in standalone setups .
in prior work we found that presence of ciplays a prominent role in the pull request evaluation process being a strong positive predictor of pull request evaluation latency.
the following is a simpli ed description of how ciis involved in pull request evaluation from .
whenever a new pull request is received by a project using ci the contribution is merged automatically into a testing branch and the existing test suites are run.
if tests fail the pull request is typically rejected closed and not merged in github parlance by one of the integrators who may also comment on why it is inappropriate and how it can be improved.
if tests pass core team members proceed to do a team wide code review by commenting inline on parts of the code including requests for modi cations to be carried out by the submitter who can then update the pull request with new code if necessary.
after a cycle of comments and revisions and if everyone is satis ed the pull request is closed and merged.
in rare cases pull requests are merged even if some tests failed.
only core team members integrators and the submitter can close to merge or reject integrators to withdraw submitter and reopen pull requests.
the process is summarized in figure .
the continuous application of quality control checks as imposed byci aims to speed up the development process and to ultimately improve software quality .
for example addam hardy a developer active on github explains in his blog enables us to automate more of our process which frees us up to focus on the important things like implementing and shipping features!
the integration of ci in github enables the team to rapidly nd integration errors or regression failures in the test suite.
this tightens the feedback loop and not only enables more defect free code but greatly speeds up our process.
research questions prior work in evaluating such beliefs has been mostly qualitative and survey based.
based on the conceptual foundation laid by these studies reviewed above the central aim of this paper is to quantitatively explore e ects associated with the adoption of ciingithub projects that use the pull request model.
we explicate our research questions.
to begin there is a strong and immediate expectation that ci should improve productivity of both teams and individuals.
staal and bosch for example argue with some surveybased evidence that build and test automation saves programmers time for more creative work and thus should increase productivity.
stolberg argues that cileads to improved integration intervals and thus faster delivery of software.
miller reports the experiences with ciof one distributed team at microsoft in and estimates that moving to aci driven process may achieve a reduction in check in overhead when compared to a check in process that doesn t leverage ci for the same code base and product quality.
bhattacharya reports on an industrial case study from an insurance company where developer productivity increases through the usage of ci.
however not all studies agree on e ects associated with adoption of ci e.g.
parsons et al.
nd no clear bene ts of cion either productivity or quality.
these prior studies prompt a largescale quantitative analysis to determine the productivity e ects ofcion distributed teams.
we ask rq1.
productivity.
how is the productivity of teams a ected by ci?
a key aspect ofciistesting integration and unit and perhaps other tests are run automatically with every change.
testing is after all all about nding bugs.
indeed fowler one of early proponents of ci has emphasized the bene ts to software quality .
other researchers make supporting claims about automated testing.
for example karhu et al.
report on an industrial case study conducted in ve commercial organizations and nd using interview data that testing automation leads to fewer defects.
rady and co n claim without providing additional details that many software development teams have recognized the design and quality bene ts of creating automated test suites .
the literature also points to indirect bene ts of using ci on software quality related to test quality increases e.g.
through test coverage increases .
fortunately in github there are a range of projects that have adopted ci to varying degrees making it possible to study the e ects of cion quality.
we ask rq2.
quality.
what is the e ect of cion software quality?
it should be noted here that there are many factors that could in uence productivity and quality in software projects and if we are to tease out the e ect of ciper se we shall need enough data to provide adequate controls for all these factors.
furthermore the introduction of cicould be expected to a ect productivity and quality in a variety of complex ways including second order e ects.
for example the use cimight attract more people to the project if pull requests are accepted expediently more contributions might arrive and more people might be induced to contribute.
the testautomation convenience of cimight encourage people to write more tests contrariwise the very ability of cito de tect more defects might lead people to inaccurately perceive a diminishment of quality it might also encourage people to submit higher quality pull requests for fear of failing a lot of tests and thus losing hard won community status.
for the purposes of this study we adopt two experimental postures discussed in more detail below .
first we gather metrics on a large number of projects over a signi cant period of time focusing on a broad set of aspects that are known to a ect the rate of growth of projects source base and the quality thereof.
by controlling for several known factors that a ect productivity and quality we hope to discern the e ects ofciper se .
second in this paper we consider speci cally the overall quality and productivity e ects of ci without delving into further causal analysis as to whether the e ects are rst or second order that is left for future work.
.
methods .
data collection .
.
selecting projects our goal was to identify projects with su ciently long historical records which had also switched to continuous integration at some point this would enable us to model the effects ofci.
we began with the ghtorrent dump dated .
we focused on main line projects i.e.
not forks written in the most popular languages34ongithub ruby python javascript php java scala c and c .
we excluded projects with fewer than pull requests we only focused on projects where pull requests were integral to the development e ort rather than being an infrequent modality adopted by occasional external contributors.
this set of selection criteria resulted in a candidate set of projects.
then for each of them we checked whether it used aciservice or not.
there are two popular ciservices used by projects in github travis ci and jenkins in addition to others used less frequently .
travis ci is a hosted service i.e.
it is supported by a remote build server integrated with github i.e.
pull requests can be tested automatically by travis ci and the github pull request ui is updated automatically with test results therefore all projects using it operate in the same context.
the entire build history of projects using travis ci is available through the travis ci api.
jenkins is a self hosted system i.e.
projects using it set up their ciservice locally.
typically only data on recent builds is stored by jenkins.
to reduce potentially confounding e ects based on variations in how jenkins is implemented by each project and in order to have access to complete build histories to be able to discern e ects associated with adoption ofci we restrict our attention in this study to the projects using travis ci.
we used the available travis ci api to detect whether a given project used travis ci or not .
we found projects .
of that used travis ci.
for each project we collected data about closed pull requests i.e.
ignoring pull requests that are still open from ghtorrent.
the data we collected included metadata e.g.
number of comments on the pull request as well as the title descrip3 programming language statistics for the selected 246github projects.
approximately half of all pull requests closed column pull reqs arrived after projects adopted travis ci pull reqs after ci most of these underwent ci testing pull reqs citested .
language n pull reqs pull reqs pull reqs after ci ci tested javascript python ruby php java c c scala total tion body and the actual code contents collected separately from the github api we also collected travis ci data e.g.
the timestamps and outcomes of each build .
a further step of ltering was required to select projects where the use of travis ci had endured long enough to reach some kind of steady state.
some pull request based projects had usedcisince the outset while others had only been using it a few months at the time of our observation furthermore some projects made inconsistent use of cion their pull requests i.e.
despite adopting travis ci they only used it sporadically on few of their incoming pull requests .5we therefore selected projects that had a good level of activity after the adoption ofci.
speci cally we selected projects where between and of the pull requests were received after the adoption of ci to ensure su cient history both before and after ci and .
of the pull requests received after the adoption of ciwere actually tested using ci.
the .
threshold was chosen to cover of the projects that were plausibly in a steadystate use ofci.
the nal dataset consisted of projects javascript python ruby php java c c and scala balanced with respect to use of ci .
out of of pull requests were submitted after the adoption of travis ci computed as the date of the earliest pull request tested by ci and .
before as shown in table .
.
.
collecting data on source and test files starting with the creation date of each project we collected month snapshots6of their source code repository by obtaining the identifying commit hashes shavalues for the most recent commit in each snapshot and performing subsequent git reset commands .
for each snapshot we identi ed source and test les using standard lename extension conversions on github .
finally we used cloc7to calculate the number of les and the number of executable lines of code.
5travis ci does not attempt to build pull requests having the ag anywhere in the commit message.
6we resorted to this approximation due to the otherwise much greater computational e ort required to reset each project s repository to its state at the time of each incoming pull request before computing the metrics.
summary statistics on the various metrics related to productivity for the selected github projects for a period of months centered around adoption of travisci rows of monthly project data outliers removed as described in section .
.
statistic mean st. dev.
min median max proj age nsrcloc ntestloc nstars nforks ciuse team size npropen nprmerged nprrejected nprcore ncore merged ncore rejected nissues open .
.
collecting productivity data to reason about productivity generally understood as the amount of output per unit input e.g.
work per unit time we focused on integrator productivity i.e.
the number of pull requests merged per month.
we computed various related metrics at monthly intervals for a period of months centered on the adoption date of travis ci i.e.
months prior and months after adoption of ci we ignored the actual adoption month .
we recorded the project age proj age in months the project size nsrcloc the number of source lines of code in source les ntestloc the number of source lines of code in test les 8the number of forks nforks and the number of stars nstars of the project s main repository as measures of popularity cumulative count since the project s creation until the current month whether the project uses ciat this time ciuse binary 9the team size team size the number of core developers active each month 10the number of pull requests received and the number of issues opened during the current month as measures of activity npropen nissues open the number of merged nprmerged and rejected nprrejected pull requests we further distinguished between pull requests submitted by core developers and those submitted by external contributors.
the data is summarized in table .
.
.
collecting quality data we operationalize code quality by the number of bugs per unit time a commonly used measure .
there are two main ways to identify the incidence of bugs when mining software repositories.
first given that it is common practice for developers to describe their work in commit messages one way to reason about the rate of bugs is to identify bug8nsrc les the number of source les and ntest les the number of test les yielded qualitatively similar results therefore we exclude them from presentation.
9we also recorded a project s ciage ciage in months ranging from to but did not nd its e ects to be statistically signi cant.
10we identi ed core developers as those developers who either had write access to a project s code repository or had closed issues and pull requests submitted by others.table summary statistics on the various metrics related to quality for the github projects we found to use issue tagging consistently for a period of months centered around adoption of travis ci rows of monthly project data outliers removed as described in section .
.
statistic mean st. dev.
min median max proj age nsrcloc ntestloc nstars nforks ciuse npropen nissues open nbugissues ncore bugs nuser bugs x commits e.g.
by searching for defect related keywords error bug x etc.
in commit messages .
however this approach may have low accuracy even when augmented with a topic based prediction model .
second in some projects developers assign labels to issues reported in the project s issue trackers e.g.
bug feature request for easier coordination and management which may enable a more accurate identi cation of bugs.
however on github and its integrated issue tracker the use of tagging is not enforced and consequently only few projects tag their issue reports .
in the current study we adopt a conservative stance and trade scale for accuracy relying on heuristics for identifying bug x commits would allow us to perform the analysis on more projects larger scale but would arguably be less accurate instead we choose to investigate a smaller sample of github projects i.e.
those that use issue tagging consistently in trying to maximize data quality accuracy .
from our list of candidate projects that adopted travisci we select those that use the github issue tracker at least issues reported and tag their issues at least of issues have tags for a total of projects.11for each project we separate bugissues indicative of quality from other issue types e.g.
discussions feature requests as follows.
since tagging is project speci c we start by manually reviewing how project managers use tags to label bugs in some highly active github projects e.g.
rails scipy and compile a list of bug related keywords i.e.
defect error bug issue mistake incorrect fault and aw after lowercasing and porter stemming.
we then search for these stems in issue tags in all projects and label the issue as bugif any of its tags potentially multiple contains at least one stem.
we further distinguish between core developer bugs i.e.
those reported internally by core developers and user bugs i.e.
those reported externally by users.
as discussed in section adoption of ciis expected to shorten the feedback loop and allow developers to discover bugs quicker.
at the same time the e ects of this should be positive on external software quality i.e.
users should not experience an increasing number of defects.
the distinction between internallyreported and externally reported bugs should allow us to more clearly observe e ects associated with adoption of ci projects met these criteria but one was additionally removed because we did not nd any of its test les.on external quality.
note that we again adopt a conservative stance and label as core developer bugs those issues reported by people who eventually became core developers for that project even if they were not yet core developers at the time of reporting the issue.
this ensures that user bugs are in fact bugs reported by people that have never been directly a liated with the project i.e.
part of its core team at least by the end date of our data collection e orts.
then similarly as before we compute monthly projectlevel data for a period of months centered around the adoption date of travis ci for a total of rows of data summarized in table .
in addition to measures described above we recorded the number of bugs reported during the current month nbugissues broken down by reporter ncore bugs nuser bugs .
.
analysis to answer each of our research questions we use multiple regression modeling to describe the relationship between a set of explanatory variables predictors e.g.
usage ofci and a response outcome e.g.
number of bugs reported per unit time while controlling for known covariates that might in uence the response.
our data is challenging in two ways i most of our predictors and all our response variables are counts e.g.
of bugs reported pull requests merged developers etc.
some outcome variables are over dispersed i.e.
the variance is much larger than the mean and ii some response variables present an excess number of zeros e.g.
when modeling the number of bugs reported by external developers in a given project per month as a measure of quality there is an overabundance of months during which no bug issues had been submitted i.e.
an excess number of zero values compared to non zero values .
to deal with the former we use negative binomial nb regression a class of generalized linear models used to model non negative integer responses suitable for modeling over dispersed count data .
in the latter case tting a single model on the whole data would assume that both the zero and non zero values come from the same distribution which may not be the case e.g.
zeros might be due to core developers not being active during those months or to them being busy with other activities .
we deal with this issue by using zero in ated models i.e.
mixture models capable of dealing with excess zero counts by combining a count component we use nb and a point mass at zero we use a logit model to model which of the two processes the zero outcome is associated with .
in r zero in ated models are implemented in thepscl package .
to ensure that using zero in ated models is necessary having many zeros doesn t necessarily mean that they were generated by di erent processes i.e.
that they come from di erent distributions we compare the t of the zero in ated model to that of a conventional nb model using vuong s test of non nested model t .
where appropriate we also log transform predictors to stabilize the variance and improve model t .
to avoid multicollinearity between explanatory variables we consider the vif variance in ation factor of the set of predictors comparing against the recommended maximum of in our case all remained well below indicating absence of multicollinearity .
in regression analysis few data points may sometimes have disproportionate e ects on the slope of the regressionequation arti cially in ating the model s t. this is a common occurrence when explanatory variables have highly skewed distributions as most of ours do e.g.
very few projects have an extremely large number of forks .
whenever one of our variables xis well tted by an exponential distribution we identify and reject as outliers values that exceedk n median x where is the exponential parameter and kis computed such that not more than of values are labeled as outliers.
this reduces slightly the size of the data sets onto which we build the regression models but ensures that our models are robust against outliers.
.
results and discussion .
team productivity rq1 the rst question we address pertains to team level i.e.
project level productivity understood here as the ability of core team members integrators to handle pull requests e ectively and e ciently.
as discussed in section a desirable pull based development work ow should be both effective in that pull requests are eventually accepted i.e.
merged into the codebase and e cient in that a large volume of incoming pull requests can be handled quickly by core developers without compromising quality .
to address this question we model the number of pull requests merged per month as a response against explanatory variables that measure test coverage measured as a count of the number of source lines of code in test les ntestloc and usage ofci ciuse binary variable that encodes whether or not the current project month falls after the date of adoption of travis ci while controlling for various confounds which we recall below see also the discussion in section .
.
.
team size is the number of developers on the project s core team at that time larger teams are expected to be able to handle a higher volume of pull requests.
nforks the number of project forks at that time we use this as a proxy measure for the size of the contributor base contributors create forks and contributions in the form of pull requests arise from forks.
nsrcloc the number of source lines of code in source code les at that time after excluding documentation les test les etc larger projects are expected to receive and merge more pull requests.
proj age the number of months since the project s creation growth dynamics may be di erent in younger vs. older projects.
nstars the number of stars received by the project s main repository by that time used as a proxy for project popularity.
starring is one of the github speci c social media features that allows anyone to ag i.e.
star projects they nd interesting more popular projects can be expected to receive more pull requests.
modeling considerations.
our primary measure of project performance is the number of pull requests received and processed by the project s core team.
there are two possible outcomes of each pullrequest merged andrejected .
these are two distinct process outcomes it is quite reasonable to expect that the processes that lead to them and their determinants are di erent viz.
timenumber of pull requests received .
.
.
.
.
.
timefraction of core developer pull requests 11figure top number of pull requests received monthly per project excluding outliers log y axis .
bottom fraction of core developer pull requests.
drawn from di erent samples.
therefore we create separate models for merged accepted and rejected pull requests.
in addition we expect that pull request processing would function di erently for insiders and outsiders.
prior work suggests that the strength of the social relationship between submitter and evaluators plays an important role in contribution acceptance and that pull requests submitted by core developers are treated preferentially.
with time an increasingly larger fraction of the pull requests received each month by projects are submitted by core developers figure .
we therefore split the data into two groups by pull request submitter core developers versus non core developers or external contributors and present separate sets of models for each group.
results and discussion.
table presents the zero in ated negative binomial zinb core developer models for merged left and rejected right pull requests.
similarly table presents the zero in ated negative binomial zinb external contributor i.e.
non core developer models for merged left and rejected right pull requests.
in both cases all models merged and rejected t the data signi cantly better than the corresponding null models i.e.
the intercept only models as evident from chi squared tests on the di erence of log likelihoods.
additionally both models represent improvements over a standard nb regression as con rmed by vuong tests zinb nb in each case.
each model consists of two parts a count part the columns count and a zero in ation part the columns zero in .
in the count part we present the negative binomial regression coe cients for each of the variables along with their standard errors.
in the in ation part similarly we present the logit coe cients for predicting excess zeros along with their standard errors.
the statistical signi cance of coe cients is indicated by stars.
we discuss the e ects of each explanatory variable across all models.
the coe cient for team size is statisticallytable zero in ated core developer pull request models.
the response is the number of core developer pull requests merged left and rejected right per month.
merged prs rejected prs count zero in count zero in intercept team size proj age log n stars .
log n forks .
log n srcloc .
log n testloc .
ciusetrue log theta aic log likelihood num.
obs.
p p p signi cant in the core developer models .
as expected we can see a positive relationship between team size and number of pull requests merged the expected increase in the response for a one unit increase in team size is .
e0 holding other variables constant.
stated di erently adding one member enables the team to merge .
more core developer pull requests.
team size also has a signi cant positive relationship with the number of pull requests rejected i.e.
larger teams also tend to reject more pull requests.
taken together the two results con rm the expected e ect of team size larger teams are able to process more pull requests irrespective of whether these will be eventually merged or rejected.
interestingly this is not the case in the external contributor models where the coe cient for team size is not signi cant in the merged part i.e.
larger teams do not also merge more external contributions in fact they reject more.
in the core developer models team size is also signi cant and has a negative e ect in the zero in ation models.
the log odds of being an excessive zero for merged pull requests would decrease by .
.
for rejected pull requests for every additional team member.
overall the larger the team the less likely that the zero would be due to core developers not submitting pull requests.
put plainly the larger the team the more likely that core developers would submit pull requests and also the more likely that these would be merged.
in the core developer models project age has a signi cant negative e ect on merged pull requests and a signi cant positive e ect on rejected ones.
older projects accept fewer reject more pull requests from core members.
the expected decrease in the number of pull requests merged for a one month increase in project age holding other variables constant is however very small .
in both zero in ation parts the relationship is positive and signi cant suggesting also that it is more likely that core developers would not submit pull requests in older projects.
this can be explained perhaps by individual core developer activitytable zero in ated external contributor pull request models.
the response is the number of external contributor pull requests merged left and rejected right per month.
merged prs rejected prs count zero in count zero in intercept team size proj age log n stars .
log n forks .
log n srcloc .
log n testloc .
ciusetrue log theta aic log likelihood num.
obs.
p p p generally diminishing with time.
in the external pull request models project age has a signi cant negative effect on both merged and rejected pull requests.
the older the projects the fewer external pull requests they merge and also the fewer they reject.
stated di erently the older the projects the fewer external pull requests they receive.
project popularity nstars has a signi cant e ect only in the merged in ation part in the core developer models .
the log odds of being an excessive zero would increase in more popular projects.
there is no signi cant e ect of popularity on rejected prs in either count or zeroin ation nor on the number of merged prs.
only the number of periods with zero merged pull requests increases.
this suggests that the more popular the project the less the core developers are likely to submit pull requests.
this can be explained by the presence of larger pools of external contributors in these projects.
indeed we can see in the in ation parts of the external contributor pull request models that external contributors are more likely to submit pull requests in more popular projects the coe cients are negative and signi cant in the in ation parts of both the merged and the rejected models .
the negative e ect of number of forks in the count part in both core developer models can be explained by the relatively small size of a project s core team compared to the size of its community of external contributors who create forks of the project in order to submit pull requests.
the more forks a project has the fewer pull requests are submitted by core developers.
indeed we can see very clearly in the external contributor models that the more forks a project has the more pull requests are submitted by non core developers.
project size nsrcloc has an expected positive e ect on the number of core developer pull requests being merged .
naturally the project size grows as a result of core developers integrating their contributions.
in the rejected model project size is not signi cant.
in contrast projectsize has a signi cant positive e ect on both merged and rejected pull requests by external contributors i.e.
larger projects simply receive more external contributions.
however the disparate signi cance of project size in the merged and rejected models con rms that core developer pull requests are accepted preferentially.
next we turn our attention to the main explanatory variables ciuse and test coverage.
naturally the e ectiveness ofcidepends on the availability and scale of existing test suites.
in the core developer models the size of test les ntestloc has a signi cant positive e ect on the pull request count in both the merged and the rejected models.
that is having more tests allows team members to process more core developer pull requests but there is no di erential e ect on their acceptance and rejection due to testing alone.
interestingly the external contributor models show that having more tests is associated with fewer pull requests by non core members being accepted and more being rejected.
this suggests that the availability and coverage of tests enables team members to nd more defects in code submitted by external contributors which results in fewer of their pull requests being accepted.
however these e ects are mediated by the presence of ci as we discuss next.
ciuse has a signi cant positive e ect on the number of merged pull requests and a signi cant negative e ect on the number of rejected pull requests in the core developer models .
holding other variables constant the expected increase in the number of merged core developer pull requests in projects that use ci i.e.
a one unit increase in ciuse from false encoded as to true encoded as is .
.
similarly the expected decrease in the number of rejected pull requests in projects that use ciis .
.
in the external contributor models ciuse has a negative e ect on the count of pull requests rejected with a sizable e ect.
this suggests that external contributors may also bene t from the availability of ci by being able to receive immediate feedback on whether their contributions can be merged i.e.
pass integration testing they can more easily improve their code if necessary i.e.
if tests fail and update the pull request resulting in overall fewer of their pull requests being rejected.
result teams usingciare signi cantly more e ective at merging pull requests submitted by core members.
availability ofciis also associated with external contributors having fewer pull requests rejected.
.
code quality rq2 to address this question we model the number of bug reports i.e.
issues clearly labeled as bugs as discussed in section .
.
raised in a project each month as a response against explanatory variables that measure test coverage measured as a count of the number of source lines of code in test les ntestloc and usage ofci ciuse binary variable that encodes whether or not the current project month falls after adoption of travis ci .
similarly as in the previous research question we control for various confounds the size of of the project s contributor base number of project forks nforks the size of the project number of source lines of code in source code les nsrcloc the project s age proj age and the project s popularity number of stars nstars .
in addition we control for the number of non bug issue reports received that month nnonbugissues as a measure of activity or general interest in the project.
we model separately the counts of bugs reported by core developers and those reported by external contributors since we expect adoption of cimay impact these sub populations di erently.
for example core developers may report bugs regularly as part of their development process while external contributors may be more inclined to report bugs when they experience defects while using the software.
table presents the zero in ated negative binomial zinb models for bugs reported by core developers left denoted core dev.
bugs and external contributors right denoted external bugs .
both models provide a signi cantly better t for the data than the corresponding null models i.e.
the intercept only models as evident from chi squared tests on the di erence of log likelihoods.
additionally both models represent improvements over a standard nb regression as con rmed by vuong tests zinb nb in each case.
we start by discussing the e ects associated with our controls.
as expected the number of non bug issue reports has a signi cant and positive e ect on the response in both models.
projects with an increased activity on the issue tracker are more likely to receive more bug reports both from external contributors as well as from core developers.
project age has a signi cant negative e ect on the count of bugs reported by core developers.
the older the project the fewer bug reports it receives from core developers.
similarly the project s popularity has a signi cant negative e ect on the count of bugs reported by core developers i.e.
the more popular the project the fewer bug reports it receives from internal developers.
these two results indicate an increasing reliance of the core team on external contributors with time and as the project becomes more popular and has access to a larger pool of external contributors or perhaps a shifting focus in the core team from xing bugs to implementing new features.
the number of forks has a signi cant positive e ect on the bug report count in both models supporting the popularity result.
the more forks a project has the more contributors is has both internal and external and therefore the more bug reports it receives.
thesize of test les is signi cant in the in ation part of the external bugs model and has a negative e ect.
the log odds of being an excessive zero for external bug reports would decrease by .
for every unit increase in the log of the number of test lines.
in other words the larger the test suite the less likely that the zero would be due to external contributors not submitting bug reports i.e.
the more likely that external contributors would report bugs.
we attribute this association to the post hoc addition of test cases by developers when a bug is reported by users it is good practice to augment the repaired code with an automated test to ensure that this bug doesn t re occur by progression.
since we cumulate our variables monthly we observe an association between increased test cases and the presence or rather non absence of user reported bugs.
ciusehas a signi cant positive e ect on the count of bug reports by core developers.
holding other variables constant the expected increase in the number of bug reports by core developers in projects that use ciis .
in contrast ci use does not have any e ect on the count of bug reports by external contributors.
that is all other things being equal table zero in ated project quality models.
the response is the number of bugs reported per project each month by core developers left and external contributors right .
core dev.
bugs external bugs count zero in count zero in intercept nnonbugissues proj age log n stars .
log n forks .
log n srcloc .
log n testloc .
ciusetrue log theta aic log likelihood num.
obs.
p p p adoption ofcienables team members to discover more bugs but this does not seem to have any in uence on the project s external quality as indicated by the count of bug reports by non core developers.
as observed earlier the overall number of pull requests managed both merged and rejected increases afterci and this increased volume is being managed by the core developers without a corresponding increase in the number of user reported bugs.
this suggests that ci allows an increase in productivity as per result without a signi cant negative e ect on user experienced quality.
result core developers in teams using ciare able to discover signi cantly more bugs than in teams not using ci.
this does not come at a cost to external software quality as external contributors do not experience an increasing number of defects.
.
concluding remarks process integration and automation have been an important topic of late specially with the rise of devops.
in this paper we leverage the growth and diversity of the projects ongithub to study the e ect of one aspect of process integration and automation the e ect of introducing continuous integration to the pull request process.
our ndings clearly point to the bene ts of ci more pull requests get processed more are being accepted and merged and more are also being rejected.
moreover this increased productivity doesn t appear to be gained at the expense of quality.
this must be considered a preliminary study.
the exact mechanisms that allow developers to process more pull requests need to be better understood perhaps viadetailed case studies.
however our models yield results of quantitative signi cance indicating that the ndings are robustly manifested in our data.several threats should be noted.
first some of the relevant properties such as popularity of projects with users and developer interest in the project are clearly confounds that a ect our outcomes.
more user attention will certainly lead to more bugs and more non core developer interest will increase project productivity.
however both are di cult to measure directly so we measure both indirectly.
user attention is measured using the stars awarded in github nstars we assume that more stars are a good proxy for more user interest.
likewise we use the number of forks nforks as a proxy for developer interest.
while these measures are intuitively justi able the use of such indirect measures is a potential internal validity threat.
second one might like to take the experimental posture thatciintroduction is an independent causal factor and seek to identify the e ects thereof.
however some projects may have introduced cibecause they were experiencing high interest also they may have introduced cibecause they already had a strong quality culture.
it s also possible that the introduction ofcicauses people to behave di erently for example to maintain reputations in the face of more rigorous testing.
our study cannot distinguish between these various e ects all we can study with our modeling is the quality and productivity e ects associated with the introduction of ci.
perhaps in the end whatever be the modality of the e ects our ndings that ciuse appears to be associated with productivity gains without signi cantly sacri cing quality is per se good enough to support its use.
third the data we gathered comes from a relatively small number of projects compared to the size of github .
one of the reasons was that we set on the travis ci system while others are available and in use in github we wanted to make sure the comparison was fair and even across projects.
the amount of data we did get guarantees su cient power for our models and results however it is always possible that our sample was biased in some unknown way thus diminishing the generalizability of our results independent replication remains the best way to mitigate this threat.
.