concolic testing with adaptively changing search heuristics sooyoung cha korea university republicof korea sooyoungcha korea.ac.krhakjoo oh korea university republicof korea hakjoo oh korea.ac.kr abstract we present chameleon a new approach for adaptively changing search heuristics during concolic testing.
search heuristicsplay a central role in concolic testing as they mitigate the path explosion problem by focusing on particular program paths that arelikelytoincreasecodecoverageasquicklyaspossible.avariety of techniques for search heuristics have been proposed over the past decade.
however existing approaches are limited in that they use the same search heuristics throughout the entire testing process which is inherently insufficient to exercise various execution paths.chameleon overcomes this limitation by adapting search heuristicsontheflyviaanalgorithmthatlearnsnewsearchheuristicsbasedontheknowledgeaccumulatedduringconcolictesting.
experimental results show that the transition from the traditional non adaptive approaches to ours greatly improves the practicality of concolic testing in terms of both code coverage and bug finding.
ccsconcepts software and its engineering software testing and debugging.
keywords concolictesting dynamic symbolic execution online learning acm reference format sooyoung cha and hakjoo oh.
.
concolic testing with adaptively changing search heuristics.
in proceedings of the 27th acm joint european software engineering conference and symposium on the foundations of software engineering esec fse august tallinn estonia.
acm new york ny usa 11pages.
introduction concolic testing is a promising software testing technique popular in both academia and industry .
thetechniqueaimstoincreasecodecoverageasquicklyaspossible ultimatelyenablingeffectivebug findinginalimitedtimebudget.
to do so unlike random testing or fuzzing concolic testing systematicallygeneratestest casesbyrepeatingthefollowingprocess itconcolically executesthesubjectprogramtocollectthepath corresponding author permissionto make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation on the first page.
copyrights for components of this work owned by others than acm mustbehonored.abstractingwithcreditispermitted.tocopyotherwise orrepublish topostonserversortoredistributetolists requirespriorspecificpermissionand ora fee.
request permissions from permissions acm.org.
esec fse august tallinn estonia association for computing machinery.
acm isbn ... .
i.e.
the sequence of symbolic branch conditions exercised by the current program execution it produces a new path conditionbyselectingandnegatingabranchofthecurrentpath condition and it solves the resulting path condition to generate anewtest casethatguidesthenextprogramexecutiontowardsthe opposite ofthe selectedbranch.
becauseof this systematicnature concolic testing is increasingly used in diverse domains including operatingsystems embeddedsystems andevenneural networks among others.
concolictestingincludessearchheuristicsasacriticalingredient.
to be practical for real world applications concolic testing must be able to adequately address the path explosion problem because real world programs exhibit infinitely many different paths it is impossibletoexerciseallofthembytesting.toaddressthischallenge concolictestingusesasearchheuristic abranchselection strategy that takes a path condition and selects a branch based on itsowncriterion itisusedinthesecondstepoftheconcolictesting process described in the preceding paragraph .
search heuristics allow concolic testing to preferentially explore particular classes ofexecutionpathsthattheythinkaremosteffectivetomaximize code coverage within a given time limit.
it has been well known thathowtochooseandusesearchheuristicsiscriticallyimportant and diverse approaches have been proposed to improve concolic testingin practice over the past decade .
in this paper we propose a new approach called chameleon for effectively employing search heuristics during concolic testing.
the key novelty of chameleon isadaptively changing search heuristics on the fly so that the branch selection criterion changes as necessary throughout concolic testing in a way that maximizes thefinalperformance.bycontrast alloftheexistingapproaches foremployingsearchheuristics arenotadaptive as they use the same search heuristics over the whole process of concolictesting.inthispaper wedemonstratethatthisisakeylimitingfactoroftheexistingapproaches andwecanmakeconcolic testingmuchmorepracticalforreal worldapplicationsbybeing adaptive.weillustratethelimitationofexistingsearchheuristics in more detail in section .
toenableadaptation wepresentanalgorithmthatautomatically learnsandswitchessearchheuristicsduringconcolictesting.the algorithm maintains a set of search heuristics and continuously changesthem duringthetestingprocess.
todoso wefirstdefine the space of possible search heuristics using the idea of parametric searchheuristicrecentlyproposedinpriorwork .atechnical challengeishow toadaptively switchsearch heuristicsin thepredefinedspace.weaddressthischallengewithanewconcolictesting algorithmthat accumulatestheknowledgeaboutthepreviouslyevaluatedsearchheuristics learnstheprobabilisticdistributions oftheeffectiveandineffectivesearchheuristicsfromtheaccumulated knowledge and samples a new set of search heuristicsesec fse august tallinn estonia sooyoung cha and hakjoo oh from the distributions.
the algorithm iteratively performs these three steps until it exhausts a given time budget.
experimentalresultsdemonstratethatshiftingfromtheclassical non adaptive approaches to ours is essential for improving the practicality of concolic testing.
we implemented chameleon on top of crest and compared it with six existing approaches on open source c programs up to 165kloc .
for all benchmarks chameleon outperformed all existing non adaptive search heuristicsintermsofbothbranchcoverageandbug findinginapractical setting.inparticular chameleon washighlyeffectiveinfinding various types of bugs including segmentation faults abnormal termination and memory exhaustion.
for the latest versions of vim gawk andgrep chameleon succeeded to trigger those bugs whereas all non adaptive techniques failed to do so.
contributions .our contributionsare as follows we present chameleon a new approach for performing concolictesting whichadaptivelylearnsandchangessearch heuristics online.
to our knowledge our work is the first thatraises theneed foradapting searchheuristics.
existing workshavefocusedoncomingupwithnewbutnon adaptive search heuristics .
we provide extensive evaluation by comparing chameleon with six existing search heuristics in terms of branch coverageandbug finding.wemakeourtool1anddatapublicly available.
conventional concolic testing in this section we describe traditional concolic testing and explain in what sense it is non adaptive.
algorithm 1and2describe a conventional method for performing concolic testing which encapsulates the commonality of the approaches used in prior work .
theprocedure concolic inalgorithm 1takesasinputaprogram p under test and a search heuristic heuristic runs the program concolically withthegivensearchheuristic andproducesasoutput the set b of branches covered during the concolic execution.
we assumethataninitialinput v0isfixedandgivenforthesubjectprogramp line2 .thealgorithminitiallysets btotheemptyset line and repeats the body of the loop at lines for ntimes where ndetermines the number of times to execute the program with the current search heuristic.
at line the program is concolically executedwiththecurrentinputvector v i.e.
execute p v which producesthepathcondition 1 n i.e.
aconjunction of symbolic branch conditions taken in the current execution.
for instance assumethatthetwobranchconditionsexercisedbythe execution are x and x .
when the symbolic variable forxis the path condition is 1 2 where 1 and 2 .
at line the algorithm accumulates the covered branches in the set b where we write branches for the branch ids covered by the current execution path .
at line the algorithm uses the search heuristic heuristic to choose a branch ito be negated in the next iteration.
then at line we generate a new input vector vby finding a model of the constraint logicalandtext.
j i j i 1chameleon basic concolictesting procedure input a program p under test and a search heuristic heuristic output the set b of covered branches procedure concolic p heuristic v v0 initial input v0 b form 1tondo execute p v 1 n b b branches i heuristic choose a branch v model logicalandtext.
j i j i end for returnb end procedure viaansmt solver.2thealgorithmrepeats theprocessdescribedso far and returns the set bupon termination.
algorithm2 conventional method for running concolic testing input programp a sethof search heuristics output the settof covered branches procedure run p h t repeat for eachh hdo b concolic p h t t b end for untiltimeout returnt end procedure algorithm 2describes how the procedure concolic is used in practice.
the procedure runtakes a program punder test.
also in ordertogeneralizeexistingapproaches ittakes a finite set hof search heuristics as input.
then the algorithm repeats the following process it performs concolic with each heuristic hinh line and it adds covered branches b t o the settof total branches line .
when the given time budget is exhausted the algorithm returns the set of branches covered so far.
readersmightwonder why we use algorithm 2insteadof simply using algorithm 1with larger n. in practice running algorithm typically performs better than running algorithm 1alone because oftherandomnessofsearchheuristics.weempiricallycorroborate this claimin section .
.
existingapproachesforperformingconcolictestingcanbeunderstood as instances of algorithm .
most of the existing approaches to concolic testing use the algorithm with a single search heuristic.forexample burnimandsen performconcolictesting by running run p cfds wherecfdsis a search heuristic that exploits the control flow information of the program.
seo and kim propose to run run p cgs wherecgsis a search heuristic that performs the context guided breadth first search on the execution tree.
cha et al.
also use the algorithm with a single heuristic i.e.
run p param whereparamis a search 2if the constraint is unsatisfiable the algorithm uses the search heuristic again to choose another branch which we omit in algorithm 1for simplicity.concolic testing with adaptively changing search heuristics esec fse august tallinn estonia figure1 venndiagramsofthenumberofbranchescovered by each search heuristic.
heuristicgeneratedautomaticallybyalearningalgorithm.afew approaches usethealgorithmwithanumberofsearchheuristics e.g.
run p cfds cgs soastocombineexistingheuristics in a round robin fashion.
note that the conventional approach to concolic testing i.e.
algorithm isnon adaptive inthatitusesthesameset hofsearch heuristicsineveryiterationoftheouterloopatlines3 .inthispa per wearguethatthisisakeylimitingfactorinexistingapproaches.usingafixedsetofsearchheuristicsimpliesfixedbranch selectioncriteria whichisessentiallylimitedtofavoringspecificareasoftheprogramonly.inotherwords differentsearchheuristicsarelargelyincomparableintermsofthebranchsetsthattheycancoverduring concolic testing.
for example figure 1shows that there is no clear winneramongthetopthreeheuristicsforeachprogram wherewe ranalgorithm 2for24hoursperheuristictocomparethesetsof branches covered by them.
in this paper we aim to mitigate this problemby adaptively changingsearchheuristicsduringconcolic testing.
our approach to concolic testing unlike conventional concolic testing our approach is adaptive and changestheset hofsearchheuristicsoverthecourseofthetesting process.toachievethis weneedtodefineaspaceofpossiblesearch heuristics and to develop an algorithm that can continuously learn anewsetofsearchheuristicsfromthespaceduringtheconcolic testingprocess.
thelatter constitutes thekey contributionofthis paper section .
.fortheformer weusetheideaofparametric search heuristic recently proposed in prior work .
.
parametricsearch heuristics our work builds on the idea of parametric search heuristics whichdefinesthespaceofpossiblesearchheuristicsusedinourapproach.chaetal.
definedasearchheuristic denoted heuristic w whichhas a parameter was follows heuristic w argmax j score w j 1 n where the parameter w angbracketleft 1 ... d angbracketrightis ad dimensional vector of real numbers.
heuristic wtakes a path condition and selects a branch jwiththehighestscore.tocomputescoresofbranches each branch is represented by a feature vector.
a feature featialgorithm3 our approach to concolic testing input programp output the settof covered branches angbracketleftk t angbracketright angbracketleft angbracketright h h1 ... h 1 hi u d repeat g for each h hdo b concolic p heuristic h t t b g g h b end for k ifk thengelserefine k g h k1 k2 select k h switch k1 k2 untiltimeout returnt denotes a predicate describing characteristics of branches feati b .
wherebisthesetofbranchesintheprogram.forinstance afeature maydescribewhetherthebranch islocatedinsidealoopbodyor not.iftrue the feati is1 otherwise itis0.withapredefinedset ofdfeatures we are able to represent a branch by a d dimensional boolean vector as follows feat angbracketleftfeat1 feat2 ... featd angbracketright.
in this paper we reused the features i.e.
d presented in where these are divided into static and dynamic features.
using the predefined features we transform each branch in a pathconditionintoafeaturevector.then thescoreforeachbranch iscalculatedbyalinearcombinationofthefeaturevector feat and a given d dimensionalweight vector w score w feat w. lastly we choose a branch jwith thehighestscore in .
withtheparametricsearch heuristic described above a search heuristicscorresponds to a d dimensionalweight vector.
thus in therestofthispaper wewillcallthe d dimensionalreal number vectors search heuristics when there is no confusion.
with this convention we write h rdfor the space of possible search heuristics where rdenotes real numbers between and .
.
overall algorithm ourapproachreusesalgorithm 1withoutmodificationbutreplaces algorithm 2by algorithm .
unlike algorithm our algorithm doesnottakesearchheuristicsasinput instead itadaptivelylearns andchangesthemthroughouttheprocessofconcolictesting.at eachiterationoftheouterloop i.e.
therepeat untilloopatlines thealgorithmevolvesthreesets h h hisasetofsearch heuristics k h b theaccumulatedknowledgeaboutprevious searchheuristicsfromwhichwelearnnewheuristics and t b thesetofbranchescoveredsofar.ouralgorithmrepresentsasearch heuristic by a pair h prime h in order to keep track of the birthplace information the second component his the actual heuristic that weareinterestedinthecurrentiterationwhilethefirstcomponent h primeis theparentofhthat gave rise to hin the previous iteration.esec fse august tallinn estonia sooyoung cha and hakjoo oh the algorithm begins with 1randomly generated heuristics line we fixed 1 in experiments h h1 h2 ... h 1 whereh1 ... h 1areindependentrandomsamplesfromtheuniform distribution u d and indicates that the initial search heuristics do not have parents.
initially kandtare empty line1 .withtheinnerloopatlines5 thealgorithmperforms concolic testing i.e.
concolic p heuristic h with each heuristic inhand generatesthe data gas follows g h1 b1 ... h h b h wherehiisthecurrentheuristic i.e.
h prime hi inhandbiistheset ofbranchescoveredbyrunningconcolictestingwith hi.atthefirst iteration kbecomesgatline10since kisinitiallyempty.starting with this initial knowledge and search heuristics the algorithm keeps updating them.
the knowledge is refined at line usingtheprocedure refine andatlines11and12 anewsetofsearch heuristicsisgeneratedfromtheknowledgeusingtheprocedures selectandswitch.thealgorithmrepeatstheprocessaboveuntil a given time budget is exhausted.
upon termination it returns the settof covered branches.
example .
.
suppose that we have a set hof four initial heuristics h1 h2 h3andh4 and running the concolic procedure with each heuristicproduces the following data g h1 h2 h3 h4 thesetgmeansthattheheuristic h1succeedsincoveringbranches 3and4 theheuristic h2coveredbranches1 and3 andso on.
notethatat the end of the firstiteration the knowledge kis identical to g. this way the algorithm accumulates kthat will be usedinlateriterationstoadaptivelyproducenewsearchheuristics.
inessence ouralgorithmaimstocontinuouslyswitchthecurrent sethof search heuristics to a new one h prime so that concolic testing with h primecan exercise new branches that were not explored in previous iterations.
that is we would like to find a sequence of sets of search heuristics h0 h1 h2 ...suchthat uniondisplay.
h h0concolic p h uniondisplay.
h h1concolic p h ismaximizedwithinagiventimebudget.algorithm 3canbeunderstood as a practical solution for this problem which does so by combining the three procedures refine select andswitch described below.
.
select letusfirstdescribetheprocedure select.thegoalof selectisto select two sets namely k1andk2 of search heuristics from k select k k1 k2 .
intuitively k1andk2representthemosteffectiveandmostineffectivecombinationsofsearchheuristicsin kthatcollectivelyachieve thehighestandlowestcoverages respectively wherethesizesof k1andk2are fixed to 2 a predetermined hyperparameter of our algorithm.
in practice we set 2to be k .
selecting of k. formally k1is defined to be a set satisfying the two conditions k1is a subset of ksuchthat k1 2 and for all k prime s.t.
k prime 2 barex barex uniondisplay.
h b k prime 1b barex barex barex barex uniondisplay.
h b k1b barex barex.
similarly k2isasubsetof ksuchthat k2 2and uniontext.
h b k2b isminimized.thesetop 2andbottom 2heuristicswillbeusedfor adaptivelylearningthedistributionsoftheeffectiveandineffective search heuristics in the next step.
example .
.
consider example .
where the current knowledgekis identical to the set gin .
then select k produces the following k1andk2when 2 k1 h1 h3 k2 h2 h4 inwords h1andh3aretop 2heuristicsthatcancoverasdiverse branches as possible.
on the other hand h2andh4are bottom heuristicsthatcovertheleastnumberofbranches.thebranches covered by k1andk2are and respectively.
findingthesets k1andk2correspondstosolvingthemaximum coverageproblem mcp whichisnp hard.weuseasimplegreedy algorithm thatprogressivelyselectssetelementsthatcollectivelymaximize orminimize thenumberofbranchescoveredat each step.
.
switch once we select k1andk2 we learn new search heuristics based on the distributions of k1andk2.
the idea is to produce search heuristics that are statistically similar to those in k1but dissimilar to those in k2.
to do so we collect the following set uniondisplay.
h b k1offspring h k2 .
that is we consider each heuristic h k1in turn and produce its offspringas follows offspring h k2 h h1 ... h h 3 .
3is a hyperparameter that determines the number of offspring of each parent h k1 we set 3 in experiments .
to generate his that are similar to hbut dissimilar to those in k2 we randomly sampleeachheuristic hi whichisa d dimensionalvectorofweights fromthesamplespace s1 s2 sd wheresjisasetofreal numbersdefined as follows sj sample hj sample h primej h prime k2 wherehjdenotes the j th component of vector handsample r samples real numbers from the truncated normal distribution with mean r standard deviation r and the interval sample r r1 r2 ... rn ri n r r .
where the number n of samples unless too small does not matter and r and r denotethemedianandstandarddeviationofthe setrof real numbers r summationdisplay.
r rr r r radicalbigg summationtext.
r r r r r if r otherwise ands s primecomputesthefollowing s s prime e e s e e s prime .concolic testing with adaptively changing search heuristics esec fse august tallinn estonia thenotation indicatesthat thesetsare multisetsallowingduplicated elements.
for instance for s .
.
.
.
and s prime .
.
.
.
s s prime .
notethat whenweconstructthesamplespacein wegenerate distributionsbyconsidering allweightsofthe j thfeaturevector h prime ink2 i.e.
sample h primej h prime k2 whereaswetreatheuristics ink1separately.
the intuition is to maintain the relationships between the features that each top heuristic in k1mayhave while maintaining the relationships between the features that all bottom ones ink2musthave.
we found that this is an important choice for our algorithm to fully exploit the current knowledge it enables thealgorithmtoproducenewheuristicsthatresemblegoodones whileeffectivelyavoiding bad ones.
with the set collected in the procedure switch k1 k2 is defined as follows switch k1 k2 exploit explore whereexploitis the set that contains 1 4heuristics selected from the set in andexploreis the set of 1 4 randomly generated heuristics to enable exploration explore h1 ... h 1 4 hi u d where 4is the hyperparameter that controls the tradeoff between exploitation and exploration.
we set 4to .
in experiments.
feature selection .toreducethespaceofcandidatesearchheuristics wecanoptimizetheprocedure switchviafeatureselection.
when we construct the sample space sjfor thej th weights in wesimplydefine sj ifthej thfeatureisuninformative.we consider the i th feature is uninformative if the weights of that feature in k1are statistically similar to those in k2.
to calculate the similarity we first define the two sets giandbi as follows gi i angbracketleft 1 2 d angbracketright k1 bi i angbracketleft 1 2 d angbracketright k2 wheregiandbiaresetsconsistingofthe i thcomponentsofthe weight vectors in k1andk2 respectively.
second we collect the features whose weights are similar in k1andk2 f i similar gi bi wheresimilar gi bi is true when the distributions of giandbi are similar in the following sense similar gi bi gi bi gi bi .
once we compute the set fof uninformative features we define sj ifj f. .
refine the role of refinerefines the current knowledge kto make learningmoreeffective.theprocedure refinetakesthreesets k g and h wherekis the knowledge from the previous iteration gis the newlygeneratedknowledgefromthecurrentiteration and histhe current set of search heuristics.
given k g h refine k g h produces the refined knowledge k primeas follows k prime k g kill itfirstaugmentsthepreviousknowledge kwiththenewone gand thenremovestheset killfromtheresult.intuitively killdenotesthe parent heuristics that are turned out to be no longer useful atthecurrentiterationofthealgorithm killisthesetofparents whoseoffspringtotallyfailedtocovernewbranches.weremove thoseheuristicsin kinordernottoexploittheminvainagainin lateriterations whichmakes the overall learning process smarter.
formally killis defined as follows kill h prime b prime k h prime h uniondisplay.
h prime h h h b gb uniondisplay.
h b kb .
in words h prime b prime inkis removed if h primeis a parent of some current search heuristics in h i.e.
h prime h and the offspring of h primefail to exercise new branches over the current knowledge i.e.
uniontext.
h prime h h h b gb uniontext.
h b kb.
example3.
.
consider thesecond iteration of algorithm 3and the set in is the previous knowledge k h1 h2 h3 h4 andthecurrent h with 3 is h1 h5 h1 h6 h3 h7 h3 h8 with thefollowingprofiles g h5 h6 h7 h8 then the set killis as follows kill h1 becausetheoffspringof h1areh5andh6 andtheset of branches covered by h1andh5according to gis subsumed by the set of branches contained in the previous knowledge k. the refined knowledge is k prime h2 h3 h4 h5 h6 h7 h8 .
note that h1is removed from k so it will not be selected for exploitationin the future iterations of algorithm .
hyperparameters .ouralgorithminvolvesfourhyperparameters 1 2 3 and 4 forwhichappropriatevaluesareassumedto begivenbeforehand.thefirsthyperparameter 1determinesthe poolsizeofsearchheuristics.
2intheselectproceduredenotes the number of effective and ineffective search heuristics to be selectedfromtheknowledge k.theremainingtwohyperparameters arerequiredinthe switchprocedure 3determinesthenumber ofoffspringtobegeneratedfromeacheffectiveheuristicandthe lastone 4isthe exploitationrate.inexperiments weset 1 2 k .
3 and 4 .
.
basically we decided these hyperparameters by trial and error but found that most of them require no fine tuning.
an exception was 4 for which choosing a rightvalue wasimportantfortheperformance.insection .
w e discuss how the performance changes with different values of 4. experiments inthissection weevaluatetheeffectivenessofourapproach.we implemented our approach in a tool called chameleon on top ofcrest andparadyse .crestisanopen sourceframework for concolic testing of c programs widely used in prior work e.g.
.
paradyse provides a publicly available implementation3oftheparametricsearchheuristicinsection .
.
we evaluatechameleonfrom the three perspectives august tallinn estonia sooyoung cha and hakjoo oh table benchmark programs program branches loc source vim .
165k gawk .
.
30k grep .
15k sed .
9k cdaudio 3k floppy 2k kbfiltr 1k replace .5k branch coverage how effectively does chameleon increase branch coverage?
how does it compare to conven tional concolic testing with existing non adaptive search heuristics?
section .
bug finding how effectively does chameleon find bugs?
doesitfindmorebugsthanconventionalconcolictesting?
doesitfindnontrivialbugsthatarehardtofix?
section .
efficacyoflearningalgorithm isourlearningalgorithm section3 essential for achieving the desired results?
how effective is it compared to simpler techniques?
section .
.
experimentalsetup benchmarks .weevaluated chameleon on8open sourceprograms in table .
we used these benchmarks because they were commonlyusedinpreviousworksonconcolictesting .thesebenchmarks aredividedinto4largeand 4small programs.
the former consists of vim gawk grep andsed which haveatleast2 000branches thelatterincludes cdaudio floppy kbfiltr andreplace.
we did not use expat .
which is used in becausewefounditislesssuitableforconcolictesting withoutpriorknowledge about the input format xml .
existing search heuristics .we compared chameleon with six recent or well known search heuristics param parametric search cgs context guided search cfds control flow directed search gen generational search andrandom randombranchsearch androundrobin rr .roundrobin is a combination of the first five heuristics which uses them in a round robin fashion.
cfdsandrandomare available in crest and param genandcgsareavailableinparadyse.wedidnotconsider naive heuristics such as dfsandbfs because their performance is not competitive as shown in the prior works .
time budget .weallocated 24hours asatesting budgetto the fourlargeprogramswhileallocatingonehourtothefoursmallones.
forthelargeprograms wegaveenoughtimebudget i.e.
24hours to compare the performance of chameleon and existing search heuristicsinatrulypracticalsetting.bycontrast weobservedthat thetimebudgetscommonlyusedinpreviousworksarenotvery realistic.forexample previousworksonsearchheuristics conducted experiments with small time budgets needed to execute each program4 times which correspondsto 30minutes for thebenchmarkprogramsintable 1inourenvironment.according to our experience these budgets are too small to appropriatelytable average branch coverage achieved by chameleon and search heuristics on small benchmarks chameleon rr cfds cgs param gen random cdaudio floppy 196replace 181kbfiltr table the number of branches exclusively covered by each technique on large benchmarks chameleon rr cfds cgs param gen random vim .
gawk .
.
grep .
sed .
total evaluatethepracticalperformanceofconcolictesting especially for large programs such as vim.
others.all experiments were conducted under the same settings.
first we used the same initial inputs provided together with eachbenchmarkprogram.second weconductedallexperiments on the same machine withtwo intel xeon processors e5 and 192gb ram.
third we performed concolic testing on a single core forallbenchmarksexceptfor vim.thisisbecausewefoundthat the branch coverage did not converge within hours for vim.w e accelerated the convergence by running concolic testing for vim using10coresinparallel whichmeansatotalof240hoursarein fact spent for testing vim.4forth we set nin algorithm 1to .
finally to calculate the average performance of the six existing heuristicsand chameleon werepeatedalltheexperiments3times and averaged the results.
.
branchcoverage let us first compare chameleon and conventional concolic testing in terms of branch coverage.
we use two metrics average branchcoverageandexclusivelycoveredbranches.inbothcases chameleonperforms much better than existing approaches.
average branch coverage .figure2compares average branch coverageachievedby chameleon andconventionalapproacheson four large benchmarks.
the results show that chameleon impressivelyoutperformstheexistingapproachesinallcases.inparticular theresultsforthetwolargestprograms vimandgawk arenoteworthy chameleon was able to reach branches covering morebranchesthan param astate of the artthatalreadycovers283 more branches over roundrobin .
forgawk chameleon covered branches while the second best heuristic roundrobin managedtoexercise3 350brancheswithinthesametimebudget.for grepandsed chameleon was the clear winner as well covering 271and1 696branches respectively.forthesmallbenchmarks 4algorithms 2and3are easily parallelizable without dependency between parallel tasks.concolic testing with adaptively changing search heuristics esec fse august tallinn estonia figure average branch coverage achieved bychameleonand search heuristics on large benchmarks figure venn diagrams depicting the sets of branches covered by the top heuristics for each large benchmark chameleon andothers exceptfor random achievedexactlythe same branchcoverage within the hour time budget .
exclusively covered branches .wealsocompared chameleon andtheexistingapproachesintermsofthesetofcoveredbranches.
table3reports the number of branches that each technique exclusivelycovered over the other techniques.
in this metric as well chameleon ismuchbetterthantheexistingsearchheuristics.in total branches were covered exclusively by chameleon .i n particular notethat forallbenchmarksexceptfor vim thenumber ofuniquebranchescoveredby chameleon aloneisgreaterthanthenumberofuniquebranchescoveredby alltheothertechniques which implies that chameleon is better than anycombinations ofthesixexistingheuristics.forexample for gawk theformeris while thelatteris .
similarly for grep the number ofunique branches covered by chameleon is about times more than the numberofbranchesthatalltheothertechniquesexclusivelycan cover.for vim chameleon isstillthebestbutitisnotenoughto say it is a clear winner.
this is because the size of vimis so large that all the techniques including chameleon have not converged yet even though we performed concolic testing for hours usingesec fse august tallinn estonia sooyoung cha and hakjoo oh table comparison of bug finding ability of ours chameleon and existing approaches on large benchmarks.
benchmarks versions error types bug triggering inputs ours param rr cgs cfds gen random vim8.
non termination k1!
.7abnormal termination h w segmentation fault ipi qoqw non termination v ipaprq t t gawk4.
.
memory exhaustion e q h w 6e8 .
.3abnormal termination f non termination g?e2 e ?
?
grep3.
abnormal termination ?
?
w 1w segmentation fault ?
?
.2segmentation fault non termination sed .
segmentation fault c b cores in parallel.
figure 3shows the venn diagrams that depict the relationships between the branches covered by each technique where we only consider top techniques for each benchmark.
.
bug finding nowwecompare chameleon andconventionalconcolictesting in terms of bug finding.
in short chameleon is highly effective in finding real bugs for the latest versions of vim gawk andgrep chameleon succeeded to generate bug triggering inputs while all the othertechniques failed to do so.
setup.while conducting the experiments in section .
w e monitoredprogram executionand collectedbug triggering inputs generatedby chameleon andothersixtechniques.specifically we consideredtwotypesofbugs programcrashesandperformance bugs.
first to collect crashing inputs we monitored the system signals e.g.
sigsegv afterexecutingtheprogramwitheachinput thatchameleon and othertechniques generated.second we collected the performance bugs by checking if the program execution with each input would exhaust a time or memory bound.
after collecting the bug triggering inputs for each technique we filtered the genuine bugs that are reproducible on the original binary of each benchmark program without annotations for concolic testing andexcludedirreproducibleones.finally wefurtherclassifythe collected bugs into categories segmentation fault sigsegv abnormal termination sigabrt non termination and memoryexhaustion.
results.table4showstheresultsontwoversionsofeachbenchmarkprogram theoriginalversionusedinsection .
onwhich we found bugs and the latest version at the time of writing.
for eachbenchmark thetableshowstheprogramversion versions the error type error types one of the bug triggering inputs generatedby chameleon bug triggeringinputs andthesuccess and failure results for each technique.
the success mark for atechniqueindicatesthatthetechniquesucceededtogenerateatleastoneinputthatcausesthecorrespondingerrortype whereas the failure mark means the technique totally failed to trigger the error type.
the results show that chameleon outperforms the existing techniques in terms of bug finding.
in particular chameleon was uniqueinfindingbugsthatcanbetriggeredinthelatestversionsof vim gawk andgrep.furthermore chameleon wasabletofindvarioustypesoferrors includingnon termination vim .
memoryexhaustion gawk .
and abnormal termination grep .
.
in total chameleon couldtrigger12differenttypesoferrorsacross all programs and their versions.
on the other hand the other techniquesmanagedtotrigger6typesoferrorsatbest.theperformance ofexistingtechniquesvarieddependingonthebenchmarkwhile chameleonconsistentlyperformed well on large benchmarks.
we found that chameleon is effective in finding hard to find bugs.forexample theinput ?
?
w 1w generated bychameleon causesasegmentationfaultin grep .
.surprisingly thisbugsurvivedoverthelast20yearsfrom grep .
togrep .
.chameleon also found deadly bugs.
for example on gawk .
the input e q h w 6e8 found bychameleon causes a serious performance bug that may consume all the memory of the machine.
all the bug triggering inputs intable4areeasilyreproducible.forinstance on grep .
the command .
grep ?
?
w 1w file wherefileis an arbitrary file immediately aborts the program execution.
figure4alsoaddstoevidencethat chameleon isgoodatfinding difficultbugs.thefiguresshowhowmanybug triggeringinputs foundbyeachtechniqueintheinitialprogramssurviveasprograms evolve wherethe hypothesis isthatdifficultbugs wouldsurvive longer than shallow bugs.
in the case of grep chameleon consistently achieves the highest number of reproducible bug triggering inputs over the subsequent program versions.
meanwhile all bugs found by other techniques except for cgs did not survive after grep .
and only a single bug triggering input found by cgs remains in grep .
.
forgawk .
.
the initial version noteconcolic testing with adaptively changing search heuristics esec fse august tallinn estonia .
.
.
.
.
of bug triggering inputs grep version chameleon roundrobin cfds gen cgs random param .
.
.
.
.
.
.
.
.
.
chameleon roundrobin cfds gen cgs random param of bug triggering inputs gawk version figure comparison of the number of bug triggering inputs that survive over program evolution of covered branches iterations randomsamping learningvim .
of covered branches iterations randomsampling learning sed .
figure comparison between random sampling and our learning algorithm thatchameleon isnotthewinneras randomandcfdsfindmore bug triggering inputs.
however as the program evolves the situationis completely reversed all of the bug triggering inputs generatedby randomintheoriginalversionfailedtosurviveinthe next version gawk .
.
.
that is randomis likely to find bugs that are comparatively easy to fix.
on the other hand inputs discovered by chameleon are reproducible until the version .
.
withoutbeing fixed for more than years.
.
efficacyof learning algorithm we evaluated the efficacy of our algorithm by comparing it with a muchsimpleralgorithmthatrandomlychangessearchheuristics.
the naive algorithm can be easily implemented by sampling the sethrandomly before line of algorithm 3and ignoring the lines for refine select andswitch.
for each iteration of the outer loop of algorithm we compared the cumulative branch coverage achieved by our algorithm and the naive algorithm for vim .
andsed .
.figure5showsthatourlearningalgorithmfor adaptively changingsearchheuristicsisessential.for vim .
whenthetestingbudget 24h isexhausted ouralgorithmisabletocover15 468branches covering more branches than the random sampling method.
in thefirstiterationwherebothalgorithmsreliedonrandomsampling ouralgorithmunfortunatelystartedwithinitialsearchheuristics withlowerqualitycomparedtothenaivealgorithm.however in the next iteration our algorithm immediately succeeded in switching search heuristics that can cover more branches than the naive one.
as the iteration of both algorithms goes on the differencein branch coverage achieved by each algorithm becomes larger as follows i2 i3 i4 i13 .
forsed .
w e obtained the similar conclusion until the fourth iteration at which the knowledge k was not accumulated sufficiently our algorithm hadsimilarperformancecomparedtotherandomsamplingmethod.
however ours covered around branches in the end where it learns to increase the branch coverage over the random method by around .esec fse august tallinn estonia sooyoung cha and hakjoo oh table coverage variation by exploitation rate sed .
exploitation rate branches table average branch coverage achieved by each heuristic on algorithm 1and2 24h .
we set nto and for algorithm a1 and algorithm a2 respectively.
gawk .
.
grep .
sed .
a1a2a1a2a1a2 cfds cgs random gen param total .
discussions exploration and exploitation .in our algorithm section the hyperparameter 4for balancing exploration and exploitation wascrucialforobtainingthedesiredresults.forexample table showsthat chameleon achievesthehighestbranchcoverageon sed .
whentheexploitationrateisaround80 .weobtained similarresultsforotherprogramsandset 4to0.
.inexperiments wefoundhyperparametersbytrialanderror.tobesystematic it would be possible to use algorithms for tuning hyperparameters automaticallyfrom the machine learning community e.g.
.
algorithm 1vs algorithm .inpractice withinthesametime budget performingconcolictestingwithasmallbudgetmultiple times i.e.
algorithm is more effective than performing algorithm1alone with large nuntil timeout.
table 6shows that using algorithm1with n isfarinferiortousingalgorithm2with smalln on large benchmarks.
for instance for gawk runningalgorithm 2covered15 658branchesintotal whilerunning algorithm 1covered branches only.
threats to validity .first our evaluation used benchmark programsthathavebeencommonlyusedinpriorworks .
however these programs may not be sufficient to draw afirmconclusioningeneral.second torun chameleon wemanuallytunedthehyper parametersthatworkwellonourbenchmarks.
however these values may not suit arbitrary programs.
related work in this section we discuss two lines of researches that are most relatedtoours techniquesforemployingsearchheuristics andcombininglearningandsoftwaretesting .theformeraimstomitigatethepath explosionproblem of concolic testing by presenting search heuristics.
the latter aims to solve various problems of software testing with learning.
search heuristics .all previous works on search heuristics havefocusedoncomingupwithanewbranchselection strategy.
however in this paper we claim that any single searchheuristicsortheirlimitedcombinationsarenotsufficient.theselectioncriterionof cfds istorandomlypickoneofthebranches thatareclosesttouncoveredbranchesinthecurrentexecutionpath.
thecgs heuristic is to randomly select one of the branches at the same depth of execution tree by bfsheuristic while excluding brancheswithalreadyexplored context .thestrategyof param is toselect thebranch with thehighest score inthe current path whereeachbranchscoreiscalculatedasalinearcombinationofthe branchfeaturevectorandagivenweightvector.todoso thetechniqueworksintwosteps offlineandonlinephases.intheoffline phase a learning algorithm is run to produce a search heuristic thatisoptimalforasubjectprogram.then thelearnedheuristic param isusedfortestingthesubjectprogram theonlinephase .
note that the paramheuristic does not change during the online phaseand therefore wecall it non adaptive.
in contrast ourwork focusesonadaptingsearchheuristicsduringconcolictesting i.e.
chameleoncan be used without the offline learning phase .
combining testing and learning .atahigh level ourwork belongs to the techniques that combine software testing and learning which leverage machine learning technologies to solve various problems of software testing.
contest aimstoreducethesearchspaceofconcolictestingbyonline learning where the goal is to selectively generate symbolic variables.
in continuous integration ci rectecs first uses a reinforcement learning to effectively select and prioritize failingtest cases.
in android gui testing qbe also employs a reinforcement learning algorithm q learning to learn the gui actions thatarelikelytoincreaseactivitycoverage enablingcrashdetection.
in fuzzing learn fuzz aims to learn the structure of pdf objects to increase the effectiveness of input fuzzing by using neural network basedlearningtechniques.similarly forfuzzing skyfire aims to generate well distributed seed inputs thereby achieving the highest code coverage.
to do so it learns a proba bilisticcontext sensitivegrammarfromlargeamountofexisting samples.
unlike the previous works our work employs a learning algorithm to adaptively change search heuristics online in concolic testing.
conclusion designing effective ways of employing search heuristic is an on going challenge in concolic testing.
in this paper we presented chameleon to adaptively learn and change search heuristics duringconcolictesting.experimentswithopen sourceprogramsshowthat chameleon outperformsanumberofstate of the art yetnonadaptive approachesinbothcodecoverageandbugdetection.ourresultssuggestthat unlikeexistingapproachesthatrelyonspecific heuristics searchheuristicsshouldbechangedadaptivelyduring concolictesting.