assessing the quality of the steps to reproduce in bug reports oscar chaparro1 carlos bernal c rdenas1 jing lu2 kevin moran1 andrian marcus2 massimiliano di penta3 denys poshyvanyk1 vincent ng2 1college of william and mary usa 2the university of texas at dallas usa 3university of sannio italy abstract a major problem with user written bug reports indicated by developers and documented by researchers is the lack of high quality of the reported steps to reproduce the bugs.
low quality steps to reproduce lead to excessive manual effort spent on bug triage and resolution.
this paper proposes euler an approach that automatically identifies and assesses the quality of the steps to reproduce in a bug report providing feedback to the reporters which they can use to improve the bug report.
the feedback provided by euler was assessed by external evaluators and the results indicate that euler correctly identified of the existing steps to reproduce and of the missing ones while of its quality annotations are correct.
ccs concepts software and its engineering maintaining software .
keywords bug report quality textual analysis dynamic software analysis acm reference format oscar chaparro carlos bernal c rdenas jing lu kevin moran andrian marcus massimiliano di penta denys poshyvanyk and vincent ng.
.
assessing the quality of the steps to reproduce in bug reports.
in proceedings of the 27th acm joint european software engineering conference and symposium on the foundations of software engineering esec fse august tallinn estonia.
acm new york ny usa pages.
introduction when software does not behave as expected users and or developers report the problems using issue trackers .
specifically problems are frequently reported as bug reports i.e.
documents that describe software bugs and are expected to contain the information needed by the developers to triage and fix the bugs in the software.
along with the observed and expected behavior bug reports often contain the steps to reproduce s2rs the bug.
the s2rs are essential in helping developers to replicate and correct the bugs .
unfortunately in many cases the s2rs are unclear incomplete and or ambiguous.
so much so that developers are often unable to replicate the problems let alone fix the bugs in the software .
recently developers from more than .3k open source projects wrote a letter to github expressing permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
copyrights for components of this work owned by others than acm must be honored.
abstracting with credit is permitted.
to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
request permissions from permissions acm.org.
esec fse august tallinn estonia association for computing machinery.
acm isbn .
.
.
.
frustration that the s2rs are often missing in bug reports and asking for a solution that would make reporters include them in the reports.
in addition prior research found that low quality s2rs lead to non reproducible bugs unfixed bugs and excessive manual effort spent on bug triage and resolution .
low quality s2rs are also the main problem with automated approaches attempting to generate test cases from bug reports .
for example fazzini et al.
report that a s2r may refer to an interaction outside the system or it may be ambiguous and correspond to multiple interactions.
similar problems were encountered by karag z et al.
who even proposed the adoption of a semiformal format to express s2rs attempting to alleviate such issues.
ideally low quality s2rs in bug reports should be identified at reporting time such that reporters would have a chance to correct them.
with that in mind we propose euler an approach that automatically analyzes the textual description of a bug report assesses the quality of the s2rs and provides actionable feedback to reporters about ambiguous steps steps described with unexpected vocabulary and steps missing in the report.
in this paper we present the approach and evaluate an implementation geared towards s2rs corresponding to gui level interactions in android applications.
euler can be adapted to support any gui based system.
euler leverages neural sequence labeling in combination with discourse patterns and dependency parsing to identify s2r sentences and individual s2rs.
next it matches the s2rs to program states and gui level application interactions represented in a graph based execution model.
a successful match indicates that the s2r precisely corresponds to an app interaction i.e.
it is of high quality .
conversely a low quality s2r may match to multiple screen components or app events may not match any application state or interaction or it may require the execution of additional steps.
euler assigns to each s2r quality annotations that provide specific feedback to the reporter about problems with the s2rs.
we asked external evaluators to assess the accuracy and completeness of the quality reports produced by euler for bug reports of six android applications.
the results indicate that eulercorrectly identifies of the s2rs of euler s quality annotations are correct and euler successfully identifies of the missing s2rs.
the evaluators also provided feedback on the perceived usefulness of the information included in the quality reports on the additional information that should be in them as well as on usability.
the quantitative results of the evaluation and qualitative analysis of the feedback allowed us to define specific future work for further improving euler .
we envision euler being successfully used in three different scenarios providing automated feedback to the bug reporter at reporting time prompting a rewrite of the bug report providing useful information e.g.
the missing s2rs to the developers attempting to reproduce the bug and supporting automated approaches for test case generation e.g.
yakusu .arxiv .07107v1 jun 2019esec fse august tallinn estoniao.
chaparro c. bernal c rdenas j. lu k. moran a. marcus m. di penta d. poshyvanyk and v. ng s2r identification execution model generationsentence identification individual s2r identification bug report systematic explorationquality report generation s2r resolution quality report2.
graph based modelingevent resolutiongui component resolutioninput resolution random explorationquality assessmentsteps to reproduce step execution and inference s1 s2 sn execution model step matching s3 3s2 2s1 1quality annotations s2r .
.
.
app installer figure euler s workflow and main components.
assessing s2r quality we describe euler assessing the q uality of the steps to reproduce in bug reports an approach that automatically identifies and assesses the quality of the steps to reproduce s2rs in bug reports.
in this paper we focus on bug reports for gui based android apps yet euler can be adapted to work for other platforms.
the input of euler is the textual description of a bug report and the executable file of the android application affected by the reported bug.
the output is a quality report qr which contains a set of quality annotations qas for each s2r automatically identified from the bug description.
the qas are described in table of sec.
.
.
figure shows euler s main components and workflow which are described in the following subsections.
.
identifying s2rs the first step in euler s workflow is the automated identification of sentences describing s2rs.
then euler performs a grammatical analysis on these sentences to identify individual s2rs.
the output is a list of individual s2rs identified from the bug report.
.
.
identification of s2r sentences.
euler identifies s2r sentences in a bug report using a neural sequence labeling model which contains the following components model input.
the model input consists of paragraphs in the bug report.
each paragraph is a sequence of sentences and each sentence is a sequence of words.
as there are dependencies between s2r sentences i.e.
often they appear in sentence groups we use the beginning inside outside bio tagging approach where for each sentence in a paragraph we assign the label if the sentence begins a s2r description the label if the sentence is inside the s2r description or the label if it is outside i.e.
not part of the s2r description.
word representations.
we represent each word by concatenating two components word and character embeddings.
we use pre trained word vectors from a corpus of 819k bug reports collected from open source projects to capture word level representations.
in order to handle vocabulary outside of this corpus we use a one layer convolutional neural network cnn with maxpooling to capture character level representations .
we model word sequences in a sentence by feeding the above word representations into a bidirectional long short term memory bi lstm which has been shown to outperform alternative structures .the hidden states of the forward backward lstms are concatenated for each word to obtain the final word sequence representation.
sentence representations.
as suggested by conneau et al.
we adopt the simple yet effective approach of averaging the vectors of words composing a sentence for capturing sentence level properties.
we represent each sentence by concatenating the averaged word representations from the previous step and a one hot feature vector that encodes the discourse patterns inferred by chaparro et al.
which capture the syntax and semantics of s2r descriptions as well as sentences describing the system s observed behavior ob and expected behavior eb .
inference layer.
in order to model label dependencies we use a conditional random field crf for inference instead of classifying each sentence independently.
crfs have been found to outperform alternative models .
the output of the inference layer is a label for each sentence where the labels indicate a s2r sentence and the label indicates a non s2r sentence.
section .
details the model implementation training and evaluation.
.
.
identification of individual s2rs.
once the s2r sentences are identified euler uses dependency parsing to determine the grammatical relations between the words in each sentence and extract the individual s2r from them.
euler utilizes the stanford corenlp toolkit for extracting the grammatical dependency tree of s2r sentences.
this tree varies across different types of sentences e.g.
conditional imperative passive voice etc.
.
therefore euler implements a set of algorithms that extract the relevant terms from the dependency trees of each sentence type.
an individual s2r complies with the following format where the is the operation performed by the user e.g.
tap minimize display etc.
the is an entity directly affected by the and is another entity related to the by the .
an entity is a noun phrase that may represent numeric and textual system input domain concepts gui components etc.a s2r example is .
we illustrate euler s algorithm to identify individual s2rs from conditional s2r sentences.
the bug report from gnucash contains the conditional s2r sentence when i create an entry for a purchase the autocomplete list shows up .
to extract the s2r from the parsed grammatical tree euler first locates the adverb when that is the adverbial modifier advmod of the verb create .
then euler verifies the existence of an adverbial clause modifier advcl between the verb and its parent word.
next euler captures the verb create as the s2r s .
otherwise the sentence is discarded as it does not follow the grammatical structure of a conditional sentence.
next euler locates the nominal subject nsubj in this case the word i .euler captures the by locating the verb s direct object dobj entry in the example and identifies the nominal modifier of the direct object nmod for as the and the of the nominal modifier case .
the resulting s2r is .
the final result of the s2r identification is a sequence of s2rs extracted from the bug report s2rs s1 s2 s3 ... sn .
the sequence order is determined by the order in which the s2rs appear in the bug description from top to down and left to right except for a few cases such as i do xafter i do y where the order is right to left.assessing the quality of the steps to reproduce in bug reports esec fse august tallinn estonia .
execution model generation euler s quality assessment strategy is based on an execution model that captures sequential gui level application interactions and the application s response to those interactions.
in its current implementation euler utilizes a modified version ofcrashscope sgui ripping engine to generate a database of application execution data in the form of sequential interactions.
this engine is an automated system for dynamic analysis of android applications that utilizes a set of systematic exploration strategies and has been shown to exhibit comparable coverage to other automated mobile testing techniques .
a detailed description of the engine can be found in moran et al.
s previous work .
euler s next task is the generation of a graph that abstracts the sequential execution database produced by crashscope s engine.
the granularity of states in this graph is important as it will serve as an index for matching the identified natural language s2rs with execution information.
for instance if the graph were built at the activity level meaning that each activity recorded by crashscope represents a unique state in the graph then there is potential for information loss as the gui hierarchy of a single activity may change as a result of actions performed on it .
to avoid information loss euler generates a directed graph g v e where vis the set of unique application screens with complete gui hierarchies and eis a set of application interactions performed on the screens gui components.
in this model two screens with the same number type size and hierarchical structure of gui components are considered a single vertex.
eis a set of unique tuples of the form vx vy e c where eis an application event e.g.
tap type swipe etc.
performed on a gui component cfrom screen vx and vyis the resulting screen right after the interaction execution.
similar execution models have been proposed in prior research on mobile app testing .
each edge stores additional information about the interaction such as the data input only for type events and the interaction execution order dictated by the systematic exploration.
the graph s starting node has one outgoing interaction only which corresponds to the application launch.
a gui component is uniquely represented by a type e.g.
a button or a text field an identifier a label ok or cancel and its size position in the screen.
additional information about a component is stored in the graph for example the component description given by the developer and the parent children components.
.
s2r resolution euler needs to identify the application interaction that most likely corresponds to a s2r a.k.a.
step resolution .
given a s2r sand program state vx i.e.
graph vertex or screen euler determines the most likely interaction i vx vy null e c fors where eis an event performed on component cfrom the screen vx.
for type events i.e.
text entry events euler identifies the input value specified by s if any.
step resolution can fail to resolve the interaction fors.
in that case the result is either a mismatch i.e.
sdoes not match a possible interaction in the current screen or a multiplematch i.e.
smatches multiple events or screen components .
.
.
event resolution.
the first step in the euler s step resolution workflow is determining the event ethat a s2r refers to.
euler supports the following android events tap long tap open app tapback menu button type swipe up down left right and rotate to landscape portrait orientation.
first euler finds the action group that the from the s2r corresponds to.
an action group is a category for verbs having a similar meaning used to express an app interaction.
euler finds the action group by matching the s lemma to the lemma of each verb in the group.
euler supports six action groups namely open long click click swipe type and rotate.
each group has a set of verbs e.g.
edit input enter insert etc.for type .
we defined the groups by analyzing the vocabulary used in the bug reports and applications used by moran et al.
.
when the maps to multiple action groups euler resolves the correct group by analyzing the and from the s2r e.g.
by identifying gui component types in them or matching these to screen components using the matching algorithm described in sec.
.
.
.
only the groups type click and rotate have common verbs.
if euler fails to disambiguate the action group then it flags the s2r s as matching multiple events and saves the corresponding action groups for providing user feedback.
if the does not match an action group then the verb is likely to refer to a generic interaction or an application feature e.g.
.
in this case euler assumes the is expressed in the properties of a gui component i.e.
its id description or label .
then euler attempts to resolve a gui component that matches the whole s2r or the by using the matching approach define in sec.
.
.
.
if there is a matched component the action group is determined as click if the component is tappable as long click if the component is long tappable or type if the component is type able .
otherwise the event resolution process fails with an event mismatch result.
once the action group is determined euler proceeds with translating such a group into an event.
the open action group is translated as an open app event if the matches app the current app name or a synonym e.g.
application .
otherwise it is resolved as a tap event.
the click group is translated as a tap back button event if the or contains the terms back leave or related terms and as a tap menu button event if the or contains the terms menu more options three dots etc.otherwise it translated as a tap event.
the rest of the action groups are translated to their corresponding event e.g.
type as type .
we also use keywords to determine the direction of swipes and rotations e.g.
landscape portrait up right etc.
.
all the keywords mentioned in this section are based on our experience with android apps and the analysis of moran et al.
s bug reports and apps .
.
.
gui component resolution.
the next step in euler s step resolution workflow is determining the gui component in the current screen that the event should perform on according to the s2r.
this step is completed only for tap long tap tap on menu button and type events as they are the only ones that require a component.
before describing how the gui component resolution works we describe the base algorithm used to match a textual sequence i.e.
a query to a gui component.
matching algorithm.
the algorithm s input is a textual query q i.e.
a sequence of terms a list of gui components gc sorted in the order of appearance in a screen and the application event eesec fse august tallinn estoniao.
chaparro c. bernal c rdenas j. lu k. moran a. marcus m. di penta d. poshyvanyk and v. ng identified from the s2r.
the output is the gui component from gc most relevant to the query.
the relevancy is determined by a set of heuristics and a scoring mechanism based on textual similarity.
the algorithm comprises the following steps ifqcontains terms referring to the application or device screen e.g.
screen phone etc.
then the first non tappable component of the current screen from top to down is selected and returned as the most relevant component.
ifqcontains terms that refer to a component type such as text field orbutton then euler checks if there is only one component in gcof that type the first type found in the query .
if that is the case then the algorithm selects and returns such a component as the most relevant component.
ifqdoes not contain any terms related to component types then euler computes a similarity score between qand each component cfrom gcand selects a set of candidates mostrelevant to the query.
the similarity score is computed as similarit y s1 s2 lcs s1 s2 av s1 s2 where s1ands2are two term sequences lcs s1 s2 is the longest common substring between the sequences at term level as opposed to character level and av s1 s2 is the average length of both sequences.
if any of the sequences is empty then the similarity score is zero.
if two sequences are exactly the same then the score is i.e.
the maximum score otherwise the score varies from to .
the similarity score accounts for common terms between the sequences and the order in which they appear.
the order is important because the matching process should be as precise as possible for producing an accurate s2r quality assessment.
before computing the similarity euler applies lemmatization to the input word sequences using the stanford corenlp toolkit .
the similarity between qand each component cingcis taken from the similarity computed between qand the component label description and id in that order.
specifically the first non zero similarity score obtained from these sources is taken as the similarity between qandc.
only the components whose similarity with qis .
or greater are considered similar to the query yet euler recommends candidates in the order of their similarity score with the highest first.
from the candidate list euler determines the component that is most relevant to the query.
there are three cases to consider there is one candidate.
euler returns such a component and the matching algorithm ends.
there is more than one candidate.
to determine the mostrelevant component euler executes a set of heuristics.
for each component if its type is layout and it has only one child in the gui hierarchy then the child is returned and the process ends.
if none of the candidates satisfy the condition above but all candidates are of the same type e.g.
text fields then the component with the highest similarity score is returned.
otherwise euler analyzes the candidates with respect to the event e. ifeis a typing event and there is one text field among the candidates then field is returned.
otherwise if eis a tap or long tap and there is only onebutton among the candidates then euler returns such a component.
otherwise the algorithm ends with a multiplematch result and the candidates are saved for providing the quality feedback to the user.
there are no candidates.
euler reformulates the query following a query replacement approach where a set of predefined synonyms for query terms are used as new queries.
if there are no synonyms for the query terms then the algorithm stops and returns a mismatch result.
each query is executed and if any matches a component then it is returned.
otherwise the process ends with a mismatch.
query formulation and component resolution.
euler uses the s2r constituents as queries depending on the identified event e for a s2r.
these queries are executed using the matching algorithm to find the gui component that the s2r most likely refers to.
for the tap long tap and tap on menu button events the first formulated and executed query is the entire s2r i.e.
the concatenation of the s2r s and .
if the matching algorithm fails to return a component only or are executed as queries.
in both cases if the corresponds to a verb that means selecting e.g.
select choose pick mark etc.
then only checkable or pickable components e.g.
drop down lists or check boxes in the current screen are used as search space.
the based query is executed only if the based one fails.
if both queries fail then the query is reformulated and executed.
if any of these queries fail to match a gui component then the step finishes with either a mismatch or a multiple match depending on the last matching result obtained.
fortype events euler considers the following s2r cases a s2r with a literal in a non literal in and the is one of the following on in into for of as etc.for these cases the is used as query.
for example for the s2r the term price is used as query.
a s2r with a non literal in a literal in and the is one of the following to or with .
then the is used as query.
for example for the s2r the term price is used as query.
a s2r where the is a literal and the and are null e.g.
euler selects and returns the focused component in the current screen if any.
in any case the resolution process ends with either a resolved gui component or a mismatch multiple match result.
.
.
application input resolution.
fortype events euler extracts the input values from the or .
specifically euler identifies literal values or quoted text.
if the input value is missing or generic i.e.
not a literal or text then euler generates a numeric input value from a counter a simple yet effective approach .
.
quality report generation euler s s2r quality assessment algorithm receives as input the identified s2rs from the bug report and the system execution graph g. the output is a quality report qr providing an assessment and feedback for each s2r.
the algorithm comprises four major steps assessing the quality of the steps to reproduce in bug reports esec fse august tallinn estonia step matching step execution and inference random application exploration and quality assessment.
.
.
step matching.
euler attempts to match the s2rs with application states and interactions.
starting with the first identified s2r euler resolves an interaction using a set of screens from the graph.
first euler verifies if the first s2r corresponds to an open app interaction.
if it does then euler marks the s2r as analyzed and proceeds to the next s2r.
otherwise euler builds the interaction.
either way euler executes an open app event and the target state from this interaction is marked as the current execution state.
euler makes sure that the current state corresponds to the screen shown on the device.
starting from the current state euler traverses the graph in a depth first manner until nlevels have been reached.
euler performs step resolution on each state sec.
.
.
the result is a set of resolved interactions for the s2r on the selected states.
if the s2r resolution fails for these states either with a mismatch or a multiple match result then it means that either more states in the graph need to be inspected hence the parameter nshould increase there are app states uncovered by the systematic exploration i.e.
not present in the execution model or the s2r is of low quality.
the parameter nneeds to be calibrated per each app.
euler discovers additional app states via random app exploration sec.
.
.
.
ideally only one interaction is resolved for the s2r i.e.
on one state only .
however it is possible to resolve multiple interactions each one on different app states.
this is due to variations in the states resulting from different interactions.
for example when providing various app inputs one screen could have a slightly different gui hierarchy.
the resolved interactions are matched against the interactions from the graph by matching their source state vx the event e and the component c. if a pair of interactions match on these properties then they are considered to be the same interaction.
the matching returns a set of interactions from the graph that match the resolved ones.
if this set is empty then it means that the resolved interactions were not covered by the systematic exploration approach and euler assumes they are new interactions in the graph.
euler proceeds with selecting the most relevant interaction that corresponds to the s2r by selecting the one whose source state is the nearest to the current execution state in the graph.
in particular euler computes a relevant score d for each interaction where dis the distance in terms of number of levels apart in the graph between the current state and the source state of the interaction.
euler selects the interaction with the highest score as the one that matches the s2r.
this decision is made to minimize the number of steps required for reaching the state where the interaction is executed as described below.
.
.
step execution and inference.
each identified interaction from the graph is executed in the device.
any new application screens interactions are added to the graph during the execution.
the identified interaction in the graph for a s2r could be located in a state far away from the current state.
this means that euler needs to execute intermediate interactions for reaching the state where the interaction is executed on.
there may be more than one way to reach such a state.
therefore euler selects the shortest path between the current state and the state where the interaction occurs.
the interactions in the shortest path are assumed by eulertable quality annotations for the s2rs in bug reports high quality hq a step that precisely matches an application interaction low quality lq ambiguous step as a step that matches more than one gui component or event low quality lq vocabulary mismatch vm a step that does not match any application interaction missing step ms a step required to reproduce the bug not described in the bug report as inferred steps missing in the bug report.
euler executes each one of the interactions in the shortest path.
at each state euler determines the enabled components in the device screen and only the interactions to such components are executed in the order that they were executed by the systematic exploration approach or the current execution.
all the interactions executed correspond to the list of inferred interactions or missing steps in the bug report.
.
.
random system exploration.
as mentioned before if the step resolution fails for all the inspected states then it means that the systematic app execution approach sec.
.
failed to discover app states screens.
to address this issue euler performs a random app exploration starting from the current app screen shown on the device .
the goal is to discover additional app states that could lead to successfully resolving the interaction for a s2r.
to do so euler identifies the components different than layouts and list views that have not been executed in the current screen and randomly selects and executes one clickable component from this set.
the random exploration is performed iteratively ytimes.
at each iteration xinteractions are executed unless there are no components left to interact with in the current screen.
right after each iteration euler updates the graph the app is restored to the state before the random execution and the s2r matching execution and inference are performed again on the graph s new version.
if the s2r is matched against the graph sec.
.
.
then no more iterations are executed.
else the random exploration process continues.
.
.
quality assessment.
euler assigns a set of quality annotations qas to each s2r.
the qas are defined in table .
if the s2r is resolved matched against the execution model successfully then euler labels the s2r as high quality hq a.k.a.
exact match em .
if there are inferred application interactions between the previous s2r and the current one then the current s2r is labeled with missing steps ms .
the inferred steps are attached to the annotation for informing the reporter about them.
the feedback given to the users is that there are application interactions missing in the bug report that should be executed before the current s2r.
note that the ms annotation does not indicate a problem about this s2r but about the entire list of s2rs.
if a s2r is not resolved in any of the graph states because of a multiple component or event match then it is labeled as an ambiguous step as .
the feedback given to the users is that either the s2r s corresponds to multiple events or the or match multiples gui components.
examples of matched events or components are shown to the user.
if a s2r is not resolved in any of the graph states because of a mismatch of the s2r with the application then it is labeled with vocabulary mismatch vm .
in the feedback given to the user euleresec fse august tallinn estoniao.
chaparro c. bernal c rdenas j. lu k. moran a. marcus m. di penta d. poshyvanyk and v. ng specifies the problematic vocabulary from the s2r constituents i.e.
the or any combination of these .
euler generates a web based quality report qr with the quality assessment for the s2rs in a bug report containing the feedback described above .
the user can click on the matched inferred interactions to open a pop up window showing a screen capture of the app highlighting the gui component being interacted with.
legend for the quality annotations identified s2rquality annotations1add favoritesemthis s2r matches the following app interaction .tap the item fav add to favorites text viewmsthere are app interactions that are missing in the bug report and should be executed before this s2r .tap the image button2.tap the chaos communication camp opening view2go into favoritesemthis s2r matches the following app interaction .tap the item starred list show favorites text viewmsthere are app interactions that are missing in the bug report and should be executed before this s2r .tap the navigate up image button2.tap the image button3.tap the drop down list4.tap the list view3select eventasthis s2r matches multiple actions e.g.
long click or click .4remove event in event detailsscreenvmthe term event in event details screen does not match a gui component from the app.5hit back button to returnemthis s2r matches the following app interaction .tap the back buttonexact match emambiguous step asvocabulary mismatch vmmissing steps ms figure euler s quality report for schedule .
empirical evaluation we conducted an empirical evaluation to determine how accurately euler identifies and assesses the quality of s2rs in bug reports and to understand the perceived usefulness readability and understandability of the information included in euler s quality reports qrs .
we aim to answer the following research questions rqs rq 1what is the accuracy of euler in identifying and assessing the quality of the s2rs in bug reports?
rq 2what is the perceived usefulness and quality of the information provided in euler s quality reports?
the answer to rq 1will inform us on improvements to euler s accuracy.
rq 2will inform us on the presentation and perceived usefulness of the information provided by the qrs.
in order to answer the rqs we selected a set of bug reports sec.
.
collected human produced reproduction scenarios for them sec.
.
used euler to identify and assess the quality of each s2r sec.
.
and asked external evaluators to assess euler s qrs sec.
.
.
we analyze the resulting evaluation data and answer the rqs using a set of evaluation metrics defined in sec.
.
.
.
bug report sample we used bug reports from six android apps aard dictionary a dictionary and wikipedia reader droid weight a body weight tracker gnucash a finance expense manager mileage a vehicle mileage tracker schedule a conference scheduler and a time tracker .
the apps were selectedto cover different domains as well as involve multiple events e.g.
taps types swipes etc.
for using their functionality.
these apps are also well studied having been utilized in several past works on mobile testing and bug reporting .
we collected the entire set of issues i.e.
excluding pull requests from the issue trackers of the six apps.
we randomly sampled issues i.e.
about of the data for each app except gnucash which had the largest issue set and its sample amounts to of the issues .
we read the issues and discarded which correspond to new feature requests enhancements etc.
or bug reports with no s2rs included.
the remaining issues correspond to bug reports and out of these describe reproducible bugs and describe non reproducible bugs.
the reports describe different types of bugs namely crashes reports functional problems reports and look and feel problems reports .
the reports include s2rs total s2rs per report on avg.
with min.
and max.
.
we manually inspected the s2rs and estimated that steps are of high quality are ambiguous and four use unexpected vocabulary while there are many missing steps.
.
ideal reproduction scenarios in order to assess the quality of the s2rs from the sampled reports we need a baseline the ideal list of s2rs a.k.a.
ideal reproduction scenarios .
to build the scenarios we asked six graduate students to reproduce the reported bugs by following the s2rs provided in the reports.
each bug was reproduced by two students.
for each bug report a student had to re install the buggy version of the app on an android emulator and try to replicate the reported bug while writing in a spreadsheet each specific step followed.
in some cases the students attempted to replicate the bug more than once.
on each attempt they annotated the detailed reproduction sequence including any missing steps in the bug report.
in most cases the students succeeded reproducing the reported bug on their second attempt for the reproducible bugs .
the scenarios across the two students per report were highly similar if not the same.
we found only small variations in the scenarios for a single bug e.g.
input values or cases such as tap back button vs.tap cancel button .
from the collected reproduction scenarios we created the ideal reproduction scenario i.e.
the ideal s2rs for each bug report which includes the set of missing steps in the report and the correspondence for each app interaction step in the scenario with the s2rs from the report.
for each reproducible bug we selected the steps that are more clearly written among the submitted scenarios.
when necessary we decomposed the steps into atomic app interactions and added step details e.g.
the location of the guicomponents .
we also normalized the vocabulary e.g.
hit or press are changed to tap .
for each report describing a non reproducible bug we selected the two most similar scenarios to the bug report scenario and performed the same normalization procedure.
.
euler implementation and calibration we implemented euler s s2r identification component by adapting the ncrf toolkit .
we trained the word embeddings with dimension on 819k bug reports collected from open source projects using the fasttext s skip gram model implementation .
we used data from chaparro et al.
to train the model usingassessing the quality of the steps to reproduce in bug reports esec fse august tallinn estonia data from gui based systems only.
the character embedding layer consists of one convolution layer with kernel size of .
the size of the character vectors is the size of bi lstm vectors is and the size of the discourse patterns vector is .
for learning we use a mini batch of size using stochastic gradient descent with a .
decayed learning rate to update the parameters.
the learning rate is .
.
we apply .
dropout to the word embeddings and character cnn outputs.
we find the best hyperparameters by performing a fold cross validation with and of the data for model training validation and testing respectively.
the model is trained for up to epochs with early stopping if the performance based on f1 score on the validation set does not change within epochs.
the model achieves precision and recall at identifying s2r sentences.
we implemented the remaining euler components using the stanford corenlp library chaparro et al.
s implementation of the discourse patterns and crashscope .
we used the bug reports by moran et al.
to test our implementation and calibrate the parameters.
in particular euler executes random exploration iterations with steps each.
the depth of graph exploration for the step matching is levels from the current program state.
these represent the best parameters according to our tests.
.
methodology to address our rqs we asked human evaluators to assess the quality reports generated by euler .
the study subjects a.k.a.
participants are six phd students one business analyst three professors one postdoc and one msc student.
the participants have been selected through direct contacts of the authors taking into account that i participants require to have some development experience and ii they need to be available for a task of about two hours.
based on the ideal reproduction scenario we created a reproduction screencast showing how the bug can be reproduced or for the non reproducible bugs how the sequence of steps could be followed.
for each bug report each participant had the following information available the original bug report the quality report generated by euler the ideal reproduction scenario and a screencast showing how the bug can be reproduced on a device.
before starting the task we instructed the participants in a training session also made available to them through a video in which we explained the quality annotations and the task to be performed.
we randomly assigned six bug reports to each participant for which he she had to evaluate the qr each qr is evaluated by three participants.
the survey questionnaire implemented through qualtrics consists of a demographics section and a section for each qrs to evaluate.
in the demographics section we ask questions about years of experience on i non mobile app development ii mobile app development iii android app development in particular and iv use of android phone.
we also ask approximately how many bug reports the participant has ever reported.
for each qr the questionnaire contains two sections.
the first section contains for each s2r three questions for answering rq a yes no question for checking whether euler correctly identified the s2r in case of a negative answer questions and are skipped .
for each annotation produced by euler for a given s2r an agree disagree question aimed at checking its correctness.
in case the answer was negative the respondents were instructed to explain their answer in a free text form.
in case of missing steps a third four check box question is formulated for assessing whether euler s suggested list of missing steps is i correct ii contains extra steps iii is lacking one or more steps or iv some steps are incorrectly ordered.
we ask the respondents to use a free text form to provide an explanation for their answer.
the second section of the survey addresses rq by asking whether euler s quality report is easy to read and understand using a level likert scale .
whether the quality report is likely to help users to better write bug reports using a level likert scale .
four free text questions to indicate what information was perceived useful useless and what information should be added to or dropped from the qr.
.
metrics for addressing rq we measure euler s precision and recall at identifying the s2rs from the bug report by comparing euler s output with the ideal reproduction scenario sec.
.
.
we also measure the proportion of correctly identified s2rs judged by the participants.
since we involve three participants for each bug report we consider the correctness assessment provided by the majority.
regarding the qas for each step we compute for each qa type tab.
the proportion of annotations judged as correct.
we consider the assessment of the majority of participants requiring at least two positive answers.
note that in this case a respondent might not have answered question if she judged the s2r as incorrectly identified.
for ms annotations we measure the proportion of ms annotations suggesting correct extra lacking and unordered missing steps.
we also use majority assessment.
to address rq for each bug report we have two questions expressed in a level likert scale.
we compute the cumulative number of responses for each of the five levels and we represent them using an asymmetric stacked bar chart.
regarding the free text questions related to the usability quality of the qrs information we categorized the responses using a cardsorting approach and analyzed each category.
.
results and analysis table summarizes the evaluation results of euler s quality assessment and feedback1.
it reports the number of s2rs identified by euler for each bug report 3rd column s2rs the correct total number of quality annotations for all s2rs 4th column qas the correct total number of annotations across the quality categories from table 5th 10th columns and the number of ms annotations for which there are unreported and extra steps in the list of missing inferred steps 8th and 9th columns respectively .
1our replication package contains evaluation data and additional results that enable the replication of the evaluation.
the package includes bug reports ideal reproduction scenarios identified s2rs in the reports euler s quality reports study survey euler s calibration data and detailed results.esec fse august tallinn estoniao.
chaparro c. bernal c rdenas j. lu k. moran a. marcus m. di penta d. poshyvanyk and v. ng table accuracy results for euler s quality annotations qas .
app of s2rs qas as hq ms vm bug rep. correct tot.
correct tot.
correct tot.
correct tot.
not reported extra correct tot.
aard dictionary a time tracker droid weight gnucash mileage schedule total .
.
s2r identification results.
euler identified s2rs in the bug reports .
only four s2rs were judged as incorrect resulting in overall precision.
more specifically the precision is for bug reports with the exception of four aard dict.
a time tracker gnucash and schedule .
in i.e.
answers there is a perfect consensus among the evaluators across bug reports.
we also found that two s2rs were not identified by euler i.e.
recall .
we manually analyzed the four misidentified s2rs and found that the sentences where they were identified from follow the grammatical structure of an s2r i.e.
conditional imperative etc.
but either they do not describe an s2r e.g.
change so the week... is restored from a time tracker is addressed to the developer for fixing the bug they indicate an app behavior e.g.
when dictionary is being verified from aard dict.
they are generic actions e.g.
when i perform these sequences of events or they indicate steps to further show how the app correctly behaves in certain circumstances e.g.
it shows up again when you leave the account... from gnucash .
the two s2rs not identified by euler are misspelled or written using noun phrases.
.
.
quality assessment results.
table shows that overall of the provided qas feedback were considered correct by the evaluators with a percentage ranging between and of correct ms and vm annotations respectively.
the participants reached a perfect consensus in of the cases.
for bug reports euler achieves accuracy.
for the remaining reports euler s accuracy ranged from to .
we determined the causes of such performance by manually analyzing the participants answers and euler s algorithm for those cases across the qa types.
for two bug reports i.e.
aard dict.
and gnucash euler incorrectly produced two as annotations i.e.
for two s2rs .
according to the participants explanations of their judgment we found that the annotations were confusing to them specifically it was not clear which components euler s feedback was referring to.
for instance for the aard dict.
s only s2r tap link to another wikipedia article euler produced the as annotation this s2r matches multiple gui components e.g.
the 1st link and 2st link views .
in this case euler reached a wikipedia webpage with multiple links having the labels shown in the annotation.
this webpage was unknown to the participants as it was not shown in the video hence they did not understand the suggested matched components.
in addition we found that the as annotationproduced for gnucash s 1st s2r set the color of an account did not suggest the correct gui component i.e.
the color picker in the creating editing accounts screens .
the cause for such a mismatch lies in the priority that euler gives to resolved interactions from program states closer to the current one.
one possible improvement is to weight in the similarity score obtained by the resolved components across multiple program states in such a way that candidates with higher similarity in screens further away from the current one are more likely to be suggested.
in six bug reports euler incorrectly assessed the quality of s2rs as high quality hq which means that the interactions matched suggested by euler do not correspond to the s2rs.
we manually analyzed these cases and found four main reasons the similarity threshold defined in sec.
.
.
i.e.
.
is too restrictive for some reports the similarity used to resolve an s2r to a screen i.e.
formula does not account for small term differences between the s2r i.e.
the query and gui components the synonyms for some terms used to reformulate the query may incorrectly boost the similarity score of unexpected gui components and the quality of screen information for some applications is low.
we illustrate the first three problems with the report a time tracker .
the first s2r for this report was identified as restore backup and the expected component for the s2r is the menu option restore from backup whose similarity to the s2r is .
the lcs is restore and the average size of both strings is .
see formula .
because the similarity is lower than the threshold the component is not returned as a candidate.
next using the predefined query synonyms euler reformulates the query by expanding the s2r to restore back up which returns the menu option back up to sd card whose similarity to the query is .
.
in this case the synonym for backup back up boosted the similarity of the menu option which was returned as most similar to the s2r.
to address these problems we plan to improve euler s similarity formula for cases with little term variations by utilizing shared term frequency and how many terms are in between the shared terms.
to illustrate the fourth problem consider the case of the 5th s2r from gnucash click save .
the incorrect matched component for this s2r was the button delete from the delete account screen.
the component id given by gnucash developers was btn save which matches the query.
in this case the mismatch could be used as feedback for developers about problems with the app screens information.
studying the impact of low quality app information on euler is subject of future work.assessing the quality of the steps to reproduce in bug reports esec fse august tallinn estonia the three s2rs from three bug reports for which euler incorrectly detected a vocabulary mismatch vm involve more than one interaction.
for instance for the 2nd s2r from gnucash select export to google drive euler failed to match google drive because of uncovered application states screen and imprecise s2r parsing and matching.
.
.
analysis of ms annotations.
we analyze the results for the ms annotations which include the steps inferred by euler .
the participants reached a perfect consensus in of the cases with ms annotations.
for six bug reports euler incorrectly flagged s2rs as having missing steps i.e.
they were assigned an ms annotation .
for the remaining s2rs i.e.
.
from bug reports the ms annotation was correct i.e.
indeed there are missing steps .
for the s2rs with incorrect ms annotations all the mss suggested by euler are unnecessary for bug reproduction.
for the s2rs with correct ms annotation euler suggested extra mss for of them i.e.
according to the external evaluators.
this means that s2rs in total were judged to have extra missing steps see the 9th column of table which represents of the cases.
in addition for s2rs total the list of suggested missing steps lacks additional steps i.e.
not detected by euler which represents .
in all ms annotations the order of the suggested mss is correct meaning that euler suggests feasible execution paths.
however in all cases the suggested mss lack some or have extra steps.
in order to further understand the ability of euler at inferring and detecting missing steps mss we compared the steps suggested byeuler against the mss from the ideal bug reproduction scenarios and computed precision and recall.
euler is designed to favor high recall because it would be easier for a reporter to just select from the list of missing steps the ones she actually did and failed to report as opposed to trying to infer what steps may be missing.
across the bug reports euler inferred and suggested mss steps per bug report on avg.
and there are mss .
steps on avg.
in the ideal reproduction scenarios.
our analysis reveals that .
on avg.
suggested mss are correct i.e.
true positives which represents precision recall.
the results mean that euler was able to infer more than half of the expected mss.
we analyzed the cases from bug reports for which euler incorrectly indicated missing steps and from the correct ms cases the cases with extra steps.
our analysis reveals two main reasons for such cases namely excessive application exploration and imprecise s2r resolution matching.
regarding the first limitation we found that the systematic and random exploration strategies execute more interactions than needed.
while this is done by design trying to uncover as many program states screens as possible it leads to excessive inferred steps.
regarding the second problem any mismatch in the first s2rs from a bug report can divert euler s execution thus producing even more mismatches or no matching at all for the remaining s2rs.
in the latter case the random exploration takes place thus producing unnecessary inferred steps.
we found that the reason for such mismatches comes from the inability of the similarity scoring formula i.e.
formula to match the query with single term text sequences from the components and also from the fact that in some cases the random exploration is executed late after the first s2r matching fails and unexpected components with similar vocabulary to the s2r are returned.
improving the comp.
useful.
percentage response disagree somewhat disagree not agree nor disagree somewhat agree agreefigure perceived comprehensibility usefulness of qrs systematic application exploration to uncover as many program states as possible may help to alleviate this problem.
finally we manually analyzed bug reports for which euler obtained the lowest recall within the range when inferring the expected mss.
the main reasons for these cases include incorrect detection of the s2rs order from the bug report and failing to handle special s2rs.
we illustrate the first issue with a time tracker .
the s2r sentence if i press the back button while viewing the preferences implies the s2rs view preferences and press back button are executed in that order.
euler failed to identify the correct order in this case provoking to not execute one of the mss click ok button .
one exemplar of the second problem is repetitive s2rs e.g.
enter few fill ups from mileage which in its current version euler does not support.
.
.
perceived usefulness.
figure shows an asymmetric stacked bar chart depicting the perceived comprehensibility and usefulness ofeuler s quality reports.
the figure shows positive results.
in particular the study participants agree and somewhat agree that the quality reports are easy to understand in and of the cases respectively on aggregate .
the quality report can help users write better bug reports in and of the cases respectively on aggregate .
to better understand these results we analyzed the participants answers to the open ended questions about useful useless information in the qas and information that should be added removed.
our card sorting analysis resulted in the following categories of useful information produced by euler explicit clear and fine grained s2r feedback.
one participant mentions that the matched suggested s2rs are pretty descriptive and would guide the user to complete better the bug description .
another participant states that the suggested s2rs are a good example of how to write steps to reproduce .
another person acknowledges that developers maintainers would find this tool very useful for their debugging process .
finally one participant mentions that euler provides detailed feedback for every single step not just the overall feedback on all steps feedback about incorrect s2r vocabulary.
for example one participant indicated that the tool correctly flags words such as find and fix that do not directly translate to an app action .
another person notes that euler detects cases that the user could improve including some more details in his error report .
feedback about missing steps.
for instance one participant mentions that the suggested missing steps can guide the user to list them better in the report.
another person mentions that they help avoid the guessing part when reproducing the bug .
screenshots for the matched interactions.
some evaluators considered the screenshots helpful for identifying the right scenarioesec fse august tallinn estoniao.
chaparro c. bernal c rdenas j. lu k. moran a. marcus m. di penta d. poshyvanyk and v. ng for reproducing the bug and they were found to complement the description of each suggested missing step .
regarding information that should be added to euler s quality reports some participants suggest that euler should assess the quality of the application observed and expected behaviors because the user described them but they are not clear .
other participants suggest clearer wording of the s2rs e.g.
instead of tap the menu save export text view tap export in menu and visual improvements to the quality report e.g.
adding image or some sort of representation of navigation drawer to help locate the button .
the participants also provided feedback about useless unclear information in euler s qas that should be improved or discarded.
besides incorrect feedback resulting from euler s inaccuracy the participants remarked that some feedback is unclear.
for example one participant mentions that some missing steps have strange names .
we confirmed that some as annotations are confusing and found that the suggested missing steps may be give little information so the user always needs to click on them and see the image to fully understand the nature of the step .euler phrases the suggested matched s2rs based on the app internal data.
in some cases this information is not available or may be only clear for the developer i.e.
using btn save instead save button .
setup application steps are not needed.
one participant commented that some steps that describe the app initial configuration... are not needed to reproduce the bug .
another participant says they are irrelevant for the bug .
.
threats to validity we discuss the threats that may affect the validity of the evaluation.
the main threat to the construct validity is the subjectivity introduced in the ideal bug reproduction scenarios given to the study participants.
to minimize bias we created them based on the bug reproduction performed by third parties i.e.
a group of graduate students.
another threat concerns the procedure to assess euler s usefulness.
our methodology only assesses the perceived usefulness of euler .
investigating how users actually benefit from euler when reporting bugs is subject of future work.
euler s calibration impacts the internal validity of our conclusions.
as explained in sec.
.
we used different bug reports to the ones used in the evaluation to test and find the best parameters of the approach.
another threat is subjectivity and error proneness of the human based evaluation.
to mitigate this threat we relied on three evaluators per bug report and decided upon majority.
given a relatively expensive nature of our evaluation we limited it to bug reports and three evaluators for each report which affects the external validity of our conclusions.
a larger evaluation possibly performed by a diverse in terms of experience sample of evaluators on additional bug reports would be desirable.
related work bug report quality assessment.
zimmermann et al.
conducted a survey exploring the most useful information in bug reports and proposed a supervised approach to predict the overall quality level of a bug report i.e.
bad neutral or good .
this approach relies on features such as readability presence of certainkeywords code snippets etc.ditet al.
and linstead et al.
measured the semantic coherence in bug report discussions based on textual similarity and topic models.
hooimeijer et al.
measured quality properties of bug reports e.g.
readability to predict when a report would be triaged.
zanetti et al.
identified valid bug reports as opposed to duplicate invalid or incomplete by relying on reporters collaboration information.
to enhance bug reports moran et al.
focused on augmenting s2rs via screenshots and gui component images .
zhang et al.
enriched new bug reports with textually similar sentences from past reports.
textual analysis of bug reports.
existing research focused on determining the structure of bug reports and its importance in bug triaging and fixing .
the work by ko et al.
on linguistic analysis of bug report titles is complemented by discourse pattern identification in bug descriptions .
sureka et al.
analyzed the part of speech and distribution of words in titles to find vocabulary patterns for predicting bug severity.
test case generation and crash reproduction from bug reports.
fazzini et al.
and karag z et al.
proposed approaches to generate executable test cases from bug reports.
zhao et al.
proposed a technique to reproduce crashes from bug reports.
different from these approaches euler is capable of automatically identifying s2rs in free form bug report text and inferring steps missing in the report.
euler is complementary to these techniques as it is aimed at improving the quality of reported s2rs.
high quality s2rs can help improve the effectiveness of these approaches.
conclusions and future work euler is an approach for the automated quality assessment of the steps to reproduce s2rs in bug reports.
euler identifies individual s2rs in bug reports with high accuracy and produces a quality report qr where for each s2r provides quality annotations qas indicating whether the s2r is well written ambiguous or uses unusual vocabulary.
the qr includes a list of missing s2rs automatically inferred by euler that are needed for reproducing the reported bug.
external evaluators found the qrs easy to understand they agreed in of the cases while they rated the accuracy of the qas.
of the qas were deemed accurate while euler reported of the missing s2rs albeit with a precision .
the evaluators consider euler to be potentially useful they agreed in of the cases in helping reporters improve their bug reports.
future extrinsic studies will confirm the reported perceived usefulness.
before such studies improvements to euler s accuracy and to the information included in the qrs are planned based on the evaluators feedback.
specifically we plan to improve the quality ofeuler s qr with i more complete application step sequences and ii additional screenshots to help guide reporters.
we also plan to tune euler s matching algorithm to account for minor variations between text sequences and matches in different parts of the execution model.
as discussed in section .
optimizations to the application exploration strategies are also planned.