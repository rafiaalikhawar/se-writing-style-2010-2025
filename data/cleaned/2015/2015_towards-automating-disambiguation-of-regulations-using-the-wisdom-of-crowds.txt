towards automating disambiguation of regulations using the wisdom of crowds manasi patwardhan tcs research trddc 54hadapsarindustrialestate pune maharashtra india manasi.patwardhan tcs.comabhishek sainani tcs research trddc 54hadapsarindustrialestate pune maharashtra india a.sainani tcs.comricha sharma tcs research trddc 54hadapsarindustrialestate pune maharashtra india sharma.richa5 tcs.com shirish karande tcs research trddc 54hadapsarindustrialestate pune maharashtra india shirish.karande tcs.comsmita ghaisas tcs research trddc 54hadapsarindustrialestate pune maharashtra india smita.ghaisas tcs.com abstract compliant software is a critical need of all modern businesses.
disambiguating regulations to derive requirements is therefore an important software engineering activity.
regulations however are riddenwithambiguitiesthatmaketheircomprehensionachallenge seemingly surmountable only by legal experts.
since legal experts involvement in every project is expensive approaches to automate thedisambiguationneedtobeexplored.theseapproacheshowever require a large amount of annotated data.
collecting data exclusively from experts is not a scalable and affordable solution.
in this paper we present the results of a crowd sourcing experiment to collect annotations on ambiguities in regulations from profes sional software engineers.
we discuss an approach to automate thearduousandcriticalstepofidentifyinggroundtruthlabelsby employing crowd consensus using expectation maximization em .
we demonstratethat the annotations reachinga consensus match those of experts with an accuracy of .
ccs concepts socialandprofessionaltopics governmentalregulations software and its engineering requirements analysis keywords regulatorycompliance ambiguities disambiguation crowdsourcing expectation maximization acm reference format manasi patwardhan abhishek sainani richa sharma shirish karande andsmitaghaisas.
.towardsautomatingdisambiguationofregulations usingthewisdomofcrowds.in proceedings of the 33rd acm ieee permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation on the first page.
copyrights for components of this work owned by others than acmmustbehonored.abstractingwithcreditispermitted.tocopyotherwise orrepublish topostonserversortoredistributetolists requirespriorspecificpermissionand ora fee.
request permissions from permissions acm.org.
ase september montpellier france association for computing machinery.
acm isbn ... .
conference on automated software engineering ase september montpellier france.
acm new york ny usa 6pages.
introduction ambiguitiesinregulations whetherintentionalorunintentional poseachallengetoorganizationsthatmustcomplywiththem.the processofderivingsystemrequirementsfromregulationstherefore tends to be error prone and regulations are increasingly seen to be subject to misuse abuse and violation .
to minimize ambiguity inregulations hoefleretal.
restrictedthevocabulary syntax and orsemanticsofswisslegalgerman.similarly cecietal.
devised an approach that enables machine readable representation of regulatory requirements while maintaining precision and specific semanticsoflegalknowledge.ghaisasetal.
haveemployeddeep learningtechniquestoresolveambiguitiesinregulationstatements by augmenting the statements with relevant additional information.
apart from these there has been work done on automatically identifyingambiguitiesinrequirementsdocuments minimizing ambiguities in requirements documents and identifying and minimizing ambiguities in policy statements .
massey et al.
have created a legal ambiguity taxonomy to identify and classify ambiguities in regulations .
they call for strategies for organizations to efficiently resolve ambiguities in legal text becausetheirresultssuggestthatsoftwareengineers graduateand undergraduate students need expert inputs tovalidate their interpretations of ambiguities .
since experts involvement in every software engineering project is expensive approaches to automate the disambiguation need to be explored.
models for automation requirealargeamountofannotateddataandcollectingthisdata fromexpertsisnotascalablesolutioneither.weinvestigatethis line of research further by aiming to automate the disambiguation of regulation statements with a reduced involvement of experts.
understandingregulatoryrequirementsisanimportantsoftware engineering activity for professional software engineers who need tobuildlargesystemscompliantwithregulations.forthispurpose ecantapintothepotentialofcrowdsourcingisyettobefullyexplored inthe field of softwareengineering .
inthis paper we presentour work on apreliminary crowdsourcing experiment authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
ase september montpellier france m. patwardhan et al.
table ambiguity examples type of regulatory statement question answers ambiguity marked term in bold valid answers in bold lexically ambiguousimplementhardware software and orprocedural mechanisms that recordand examine activity in informationsystemsthatcontainoruseelectronic protected health information.in the given sentence what is the meaning of word record ?
a to put in writing or digital form for futureuse b informationstoredonacomputer c best performance.
d to make a permanent or official noteof e a piece of evidence from the past lexically unambiguousa group health plan must ensure that its plan documentsprovidethattheplansponsorwillreasonably and appropriately safeguard electronicprotected health information created received maintained or transmitted to or by the plan sponsor on behalf of the group health plan.in the given sen tence what is themeaning of word transmit ?
a totransfersomethingfromoneperson to another b to be a medium for an idea or emotion c to broadcast something d topassonsomethingfromparenttochild e tocausetopassthroughairorsomeother medium syntactically ambiguousimplementpoliciesandprocedurestoaddressthe final disposition of electronic protected health information and or the hardware or electronic media on which it is stored.in the given sen tence the phrase final disposition of refers to?
a electronicprotectedhealthinformation b policies c hardware d address e electronic media syntactically unambiguousimplementsecuritymeasurestoensurethat electronically transmitted electronic protected health information is not improperly modified without detection until disposed of.in the given sen tence the phrase electronically transmitted refers to?
a improperlymodified b electronicprotected health information c detection d security measures e disposed of semantically ambiguousa covered entity may obtain consent of the individualtouseordiscloseprotectedhealthinformation to carry out treatment payment or health care operations.what does consent mean?
a permission to share b permission to dispose c permissiontopublicize d permission to use in court e permission to use for the stated purpose semantically unambiguousa covered entity may use professional judgment anditsexperiencewithcommonpracticetomake reasonableinferencesoftheindividual sbestinterest in allowing a person to act on behalf of theindividualtopickupfilledprescriptions medical supplies x rays or other similar forms of protected health information.what does xrays mean?
a x raydiffractionspectrumplots b electromagnetic radiations of high energy c images of internal organs in a humanbody d multipliereffect e unknownrays to collect disambiguation data from a crowd of professional softwareengineers.however crowdsourcingposeschallengesinterms of malicious labeling and arriving at consensus.
such challengescan be mitigated by using majority voting or aggregation methodslikeexpectationmaximization em whichallows measurement of various parameters relevant to the crowdsouring experiment such as workers competence intention task difficulty etc.
we prefer em over majority voting as along with providingground truth labels for disambiguation em allows us to model ambiguity intensities as reflected in inter annotator disagreements and worker skills spam.
responses in terms of valid invalid set of answers for which consensusisachieved provideannotationsfordisambiguationofregulationstatements.inourwork annotations areseentomatchthe groundtruthlabelsprovidedbytheexpertswithahighaccuracy of indicating that the wisdom of software engineers crowd canbeleveragedforthispurpose.ifcollectedonalargescale these annotations along with the regulation statements can be furtherused as a training dataset for automating the disambiguation ofregulations.
to the best of our knowledge ours is the first attempt to employ crowdsourcing and em to obtain ground truth labels towards automating the disambiguation of regulation statements.
the rest of the paper is organized as follows.
in section ii we describethedetailsofexpertannotateddata.sectioniiipresents discussiononthecrowdsourcingexperimentconductedfollowed bytheformulationoftheemmodelforachievingcrowdconsensus insection iv.in sectionv wediscussour preliminaryresults and section vi concludes the paper.
expert annotated ground truth data forourstudy wesoughtgroundtruthinputsfromthreeexperts whohave workedwith healthinsuranceportability andaccountabilityact hipaa regulations for morethan3years.
while identifyingambiguitiesinregulationstatements theexpertsused massey s definitions and examples as guidelines .
there are six distincttypesofregulationambiguitiesdefinedbymasseyetal.
viz.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
towards automating disambiguation of regulations using the wisdom of crowds ase september montpellier france lexical syntactic semantic incompleteness vagueness and referential.
we havefocusedon thefirst three.the expertsidentified a totalof38regulationstatementscontainingoneormoretypeofambiguities.
for each ambiguity type they selected i statements each containingan ambiguousterm phrase and ii statements containingaterm phrasewhichisunambiguousorlessambiguous from the perspective of that ambiguity type.
a term phrase in a regulationstatementislexicallyambiguousifithasmultipledictionarymeanings.disambiguationherewouldmeanexplicatingthe exact meaning as applicable to the statement from among those multiple meanings.
syntactic ambiguity points at multiple word associations leading to multiple parse trees and disambiguation here amounts to clarifying the scope of the word association.
semantic ambiguity occurs if a statement is not self contained and disambiguationwouldmeanprovidingadditionalcontextualinformation for interpretation.
in addition to the marking of the term phrase the experts posed a question about the term phrase which when answered wouldlead to disambiguation of the term and thus the statement.
theexperts also provided a list of five a mix of valid and invalid possibleanswerstoeachoftheposedquestions.invalidanswers areasimportantasvalidanswersfordisambiguation tofindout ifthecrowd canreachconsensusindistinguishingbetweenthem.
also incaseofautomaticdisambiguation alongwiththevaliddata which helps with disambiguation the machine learning models will need invalid or negative data as well.
table1illustrates examples for ambiguous and unambiguous regulation statements for each of the three types of ambiguities along with the marked term the question posed and the answers provided.asevidentfromtable forambiguoustermsthenumber of valid answers are more than that of unambiguous terms.
one regulation statement may have more than one type of ambiguities caused by distinct set of terms phrases in the regulation statement and thus may appear in the dataset of more than one ambiguitytypes.forexample forthestatement implement hardware software and or procedural mechanisms that record and examine activityin information systems that contain or use electronic protected health information the terms phrases record mechanisms examine activity are lexically syntactically and semantically ambiguous respectivelyandthus thestatementiscommonforeachambiguitytype.however thequestionsposedandthecorrespondingset of valid invalid answers are different for each ambiguity type as shown in table .
crowdsourcing experiment the expert annotated data as discussed in section ii above served as the basis for generating crowd tasks for our crowdsourcing experiment.
a task consisted of i a regulation statement ii a term phrase marked iii a question posed on the term phrase for disambiguation and iv asetoffiveanswers.foreachambiguity type we created such tasks giving us a total of tasks.
we targeted a crowd of professional software engineers with to years ofexperience henceforthreferredtoascrowdworkers .theywere askedtodothetasksduringtheirwork hourssothattheyperceivetheworkasaseriousprofessionalcontribution andnotasaleisure activity.acrowdworkerisaskedto i readthegivenregulatorytable a regulation statement having distinct types of ambiguities ambiguity question answers type valid answers in bold lexical what is the meaning ofthe word record ?a to put in writing or digital form forfuture use b information stored on a computer c best performance d to make a permanent or official note of e a piece of evidence from the past syntactic what word words refer to the term mechanisms ?a record b procedural c softwared examine e hardware semantic what does examine activity mean?
a keepalogofwhatwasdone b notifyadminthatsomethingwas done c stop block what is be ing done d identify what was done e classify what was done statement along with the marked term or phrase ii read the question posed on the marked term phrase and iii choose any subset of the answers as valid answers to the posed question consider ing the given regulation statement and the marked term phrase.
acrowdworker sresponsetoananswerwouldbe yes ifhe she thinks that the answer is valid else the response would be no .
we collected data using our indigenous crowdsourcing platform.
a clear set of instructions specific to an ambiguity type was provided to the workers.
along with instructions we also provided an example of the task and the correct set of responses for refer ence.
we highlighted the term phrase that is creating ambiguityin the statement so that a crowd worker could easily focus onthat term phrase within the regulation statement as the contextfor providing responses.
the question posed on the term phrase in thetask had fivepossible answers whereeach answer iseither valid or invalid.
each crowd worker was given tasks to perform sequentially.basedontheirunderstanding foreachtasktheworker was to label each valid answer as yes and each invalid answer as no .weachievedredundancybycollectingresponsesfrom15 crowdworkersforeachtask.inall 116crowdworkersparticipated in our experiment.
crowd consensus using expectation maximization wehaveusedexpectationmaximization em techniquetoachieve consensusoncrowdresponses.themoreambiguousatermora phraseinaregulationstatement thelargerwouldbethenumberof different interpretations crowd workers are likely to come up with.
this inter annotator disagreement for ambiguous terms or phrases among crowd workers is expected to be high and it represents the extent or intensity of the ambiguity in the term or phrase.
inouremmodel theobservablevariableisthelabel true false providedbythecrowdworkers.thelatentvariablesincludetask authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
ase september montpellier france m. patwardhan et al.
figure plate representation of the em model ambiguity level probability of a worker being spammer or nonspammer and a small factor which reduces the probability with whichaworkerlabelsanambiguousanswercorrectly.intheexpectation step e step thelatent variables are assigned some seed values and probability of a label being true or false is calculated taking into account the crowd resp onses.
in the maximization step m step combinations of latent variables that maximize the likelihood of observable variable being true or false is calculated.
these values are fed into the latent variables in successive iteration until the values converge.
aroyoet.alin threesidesofcrowd truth indicatethatthe inter annotatordisagreementcanbearesultof i ambiguityinthe task which in our case is the regulation statement with the term phrasemarkedandtheanswersprovidedtotheposedquestion ii workerspamduetoattitudinalproblemsorlackofrequired skillsorfatigue iii ambiguityinthetaskdesign.wehavealready modeledforambiguityandworkerspam expertiseaslatentparame ters andthustakenintoaccountfactors i and ii whilecomputing consensus annotator agreement .
to eliminate the effect of iii above weensureunambiguoustaskdesignbyprovidingdetailed instructions with examples to the crowd workers as discussed earlier in section .
for checking validity of answer we provide only twochoices yes or no withthemeaningofthechoicesbeing simple and clear and explained as a part of the instructions.
we build upon for our em formulation.
table 3provides notation used for the em model.
given the observed variables l we would like to estimate the parameters z. the set of latent parameters are k tij p0 p1 a .
these are explained in table3.
thecausalmodeloftheannotationprocessofthecrowdsourcing task is shown schematically in fig.
.
the task target values zand allthelatentparameters areassumedtobegeneratedindependently.toensurethattheestimationprocessdegradesgracefully withlessavailabledata wetakebayesianpointofviewwithpriors on the target values and the latent parameters as represented in fig.
.thepriorsencodeourpriorbeliefsaboutthetargetvalues andthelatent parameters.forexample the prior onthetarget valueszijbelievesthat50 ofthetargetvaluesare1 validanswer and50 are0 invalidanswer formingauniformdistributionwith probability .
.
our prior belief of the type of crowd worker is modeled using a beta distribution having beta densities that are increasingly peaked towards .
indicating that most of the honest workers are experts having high true positive p1 and true negative p0 rates.
also p1 p0 are kept common across all the crowd workers and are not made crowd worker specific to avoid largetable em notation notation meaning z zij set of target values parameters to be estimated .
zij is the target value of jthanswer for ith regulatorystatement.1indicatesvalidanswerand0 indicatesinvalidanswer.
i nindicatingthere arentasks regulationstatementswithatermmarked and a question posed on the term and j m indicating there are manswers provided to each task.
forsimplicity wehavefixedthenumberofanswers as m. l lijk set of annotations labels where lijkis the label provided to answer jof taskiby crowd worker k. k pindicatingthereare pnumberofworkers who have provided labels to this task.
pcan vary per task.lijk where indicates valid answer and indicates invalid answer.
ai set of crowd workers who have provided labels to all answers of task i tk set of tasks annotated by worker k k probability that a worker kis a spammer k tij probabilitythatthe jthansweroftask iisambiguous.
p0 probability that an honest crowd worker nonspammer labelsanunambiguousinvalidanswerwithgroundtruthas0correctly.thisrepresentstruenegative tn rate of a worker with p0 .
this parameter is common across all the crowd workers.
p1 probability that an honest crowd worker nonspammer labelsanunambiguousvalidanswerwith ground truth as correctly.
this represents true positive tp rate of a worker with p1 .
this parameter is same across all the crowd workers.
a a factor which reduces the probability with which a worker labels an ambiguous answer correctly a numberofparameters.thiswouldallowemtoconvergewellwith thesmallamountofdataavailable.ourpriorbeliefofspammers ismodeledusingabeta distributionhavingbetadensitiesthat areincreasingly peakedtowards .3indicating mostof annotators are honest.
our prior belief of task ambiguity is modeled using a beta distributionhavingbetadensitiesthatareincreasinglypeaked towards .
indicating of the tasks are ambiguous.
the joint probability distribution can be factorized as p l z p a p p0 p p1 n productdisplay.
i 1m productdisplay.
j 1p tij p zij p productdisplay.
k 1p k productdisplay.
lijk lp lijk zij giventheobservedvariables l wewouldliketoinfer z asw ell as latent parameters .
this can be done using bayesian treatment of the expectation maximization em algorithm.
e step assumingthatwehavethecurrentestimate ofthelatent parameters we compute the posterior on target values by using authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
towards automating disambiguation of regulations using the wisdom of crowds ase september montpellier france equation .
p z n productdisplay.
i 1m productdisplay.
j 1 p zij p zij p zij productdisplay.
k aip lijk zij equation 3can be rewritten for distinct values of zijas p zij .
p lijk zij p lijk zij p zij .
p lijk zij p lijk zij our model is depicted by equations 6through9below.
p lijk zij k tij k tij k tij p1 a k tij p1 p lijk zij k tij k tij k tij p0 a k tij p0 p lijk zij k tij k tij k tij p1 a k tij p1 p lijk zij k tji k tij k tij p0 a k tij p0 m steptoestimatethelatentparameters wemaximizetheexpectation of the logarithm of the posterior on with respect to p zij from the e step.
we can call auxiliary function being maximized asq .
in practice we estimate parameters using alternating maximizationalgorithms whereweoptimizewithrespecttothe parameters of a task or an annotator one at a time.
the optimal can be found from equation .
argmax q where is the estimation from the previous iteration and q ez p summationdisplay.
k 1q k k whereez istheexpectationwithrespectto pzandq k k is defined by equation .
q k k argmax kp k productdisplay.
i tkp lijk zij hence the optimization can be carried out separately for each crowd worker and relies only on the responses that the workerprovided.theauxiliaryfunctionsforothersetoflatentparameters can be defined by equations 13to16below q tij tij argmaxtijp tij productdisplay.
k aip lijk zij q a a argmaxap a productdisplay.
lijk lp lijk zij q p1 p1 argmaxp1p p1 productdisplay.
lijk lp lijk zij q p0 p0 argmaxp0p p0 productdisplay.
lijk lp lijk zij theoutcomeofemismulti fold i itestimatestheanswervalidity based on the resultant target values zij estimated parameters for each answer which define if an answer provided to a given to aquestion is valid or invalid ii it quantifies the ambiguity of an answer to the posed question of a term in the regulatory statement latentparameter tij .theaverageoftheambiguityvaluesforall the answers of a task provide the ambiguity of the term marked iii itidentifiesthespammersorreluctantworkersbymeasuring theprobabilityofspammingforeachworker latentparameter k indicating no spammer indicating spammer iv it identifies the average skill level of all the crowd workers latent parameters p0andp1 intermsoftheirconfusionmatrixforambiguousaswell as non ambiguous tasks.
for ambiguous tasks the true positive rate isp1 aand true negative rate is p0 a .
results and discussion we executed em on all the tasks answers together and then individually for sets of tasks answers belonging to eachambiguitytype viz lexical syntacticandsemantic.thetargetvaluesestimatedasanoutcomeofemarecomparedwiththe groundtruth valuesprovided bythe experts.theaccuracy results are shown in the table .
table disambiguation accuracy task type precision recall f score lexical .
.
syntactic .
.
semantic .
.
all .
.
.
it is evident that crowd of software engineers is good at disambiguating the lexical and syntactic type of ambiguities.
however acomparativelylowrecallvalueforsemanticambiguitytasks indicates that this type is difficult to disambiguate.
to measure table correlations task ambiguity and worker spam correlation task ambiguity worker spam lexical ambiguity .
.
semantic ambiguity .
.780syntactic ambiguity .
.
all .
.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
ase september montpellier france m. patwardhan et al.
table ambiguity intensity of terms task type ambiguous tasksunambiguous tasksall lexical .
.
.
syntactic .
.
.
semantic .
.
.
all .
.
.
ambiguity of an answer we measured the inter annotator disagreementintermsofweightedbernoullivarianceofthe15responses receivedforeveryanswer.theweightsofthebernoullivariance were decided by worker expertise percentage of correct inputs provided by a worker .
we established a correlation of these values with the ambiguity values tijestimated by the em model using pearson s correlation coefficient.
the high correlations illustrated intable5depictthecapabilityofemtoautomaticallyquantifythe intensity of ambiguity.
we also computed the spam of a crowd workerbyfindingpercentageofincorrectinputsprovidedbythe worker.
we established a correlation of these values with the k values estimated by em.
the correlations are illustrated in table .
it shows that the spam is easier to identify for syntactic ambiguity types whereas difficult for lexical ambiguity.
for each type of ambiguity we had tasks having ambiguous terms and having less ambiguous or unambiguous terms.
wecomputedtheambiguityofatermastheaverageofalltheambiguityintensitiesofeveryanswer ti m summationtext.1m j 1tij totheposed questionforthatterm.table 6showstheaveragedambiguityintensities for all the terms which constitute the ambiguous and less ambiguous tasks.
it can be seen that the average ambiguity in tensity of ambiguous terms .
is more than that of the less ambiguousorunambiguousterms .
.asshownintable the intensity for syntactic ambiguity is the least .
of the three.
this observation is consistent with the f score for disambiguation forsyntacticambiguity .
whichishighestofthethree .
the relation between ambiguity intensities and disambiguation f scores is also valid for the other two ambiguity types.
conclusion and future work wereportearlyindicationsonpossibilitiesfordisambiguatingregulationsbyemployingacrowdofsoftwareengineers.dataprovided bylegalexpertswasusedforgeneratingcrowdsourcingtasks so that we can validate the consensus outcome of software engineers inputsagainstthoseofexperts .
tounderstand iftheengineerscan indeed provideoriginal disambiguation data as opposed to just identifycorrect answers from multiple choices we conducted a pilotwith5hipaaregulationstatements.givenaregulationstatement crowd workers were to mark a term phrase they perceive tobeambiguous poseaquestiononthatterm andprovideaset ofanswers resultingindisambiguation.
theyidentified 46unique terms with on an average questions posed on each term and onanaverage 3answerstoeachquestion.thecrowdresponses containedbothvalidandinvalidanswers.werealizethatthescope andsizeofourearlyexperimentsistoolimitedtoallowforanygeneralization.however wealsonotethatexperienced professional software engineers get to work closely with legal experts whiledevelopinglargecompliantsystemsandintheprocessarelikely toimplicitlyacquireasignificantamountof knowledgeaboutthe disambiguation of regulations.
can they retain and retrieve this knowledgeforsubsequentuseinotherprojectsinthesamedomain?
canweexplicateandharnesstheirknowledgethroughcrowdsourc ingandreducetheeffortonpartofexperts?thisinquirymotivates our research.
the empirical observation about the difference in ambiguity intensities of the three types needs to be investigated further by designing experiments that employ psycho linguisticanalyses.
in future we intend to extend this work to other ambiguity types ref erential incompletenessandvagueness.wewillemploytechniques which could help acquire annotations on a large scale so that machine deep learning algorithms can be trained for an automated disambiguation of regulations.