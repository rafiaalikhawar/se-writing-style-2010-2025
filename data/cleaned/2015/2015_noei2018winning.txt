winning the app production rally ehsan noei queen s university kingston ontario canada e.noei queensu.cadaniel alencar da costa queen s university kingston ontario canada daniel.alencar queensu.caying zou queen s university kingston ontario canada ying.zou queensu.ca abstract when a user looks for an android app in google play store a number of apps appear in a specific rank.
mobile apps with higher ranks are more likely to be noticed and downloaded by users.
the goal of this work is to understand the evolution of ranks and identify the variables that share a strong relationship with ranks.
we explore 900apps with a total of 011user reviews in 30app development areas.
we discover 13clusters of rank trends.
we observe that the majority of the subject apps i.e.
dropped in the rankings over the two years of our study.
by applying a regression model we find the variables that statistically significantly explain the rank trends such as the number of releases.
moreover we build a mixed effects model to study the changes in ranks across apps and various versions of each app.
we find that not all the variables that common wisdom would deem important have a significant relationship with ranks.
furthermore app developers should not be afraid of a late entry into the market as new apps can achieve higher ranks than existing apps.
finally we present the findings to51developers.
according to the feedback the findings can help app developers to achieve better ranks in google play store.
ccs concepts applied computing software and its engineering theory of computation theory and algorithms for application domains keywords mobile application rank application market empirical study acm reference format ehsan noei daniel alencar da costa and ying zou.
.
winning the app production rally.
in proceedings of the 26th acm joint european software engineering conference and symposium on the foundations of software engineering esec fse november lake buena vista fl usa.
acm new york ny usa pages.
introduction app markets such as google play store are becoming more competitive year by year .
when it comes to users choice when downloading an app the app ranks play a major role .
when a permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
copyrights for components of this work owned by others than acm must be honored.
abstracting with credit is permitted.
to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
request permissions from permissions acm.org.
esec fse november lake buena vista fl usa association for computing machinery.
acm isbn .
.
.
.
looks for a particular sort of app i.e.
area google play store lists the most related apps with respect to the app ranks .
improving the rank of an app increases the chance of being noticed and downloaded by users.
having a higher number of users is desired as it can increase the revenue of app development companies .
prior work estimates app success by studying different factors such as star ratings and the number of downloads .
the relationship between the star ratings and various variables such as the number of functions has been thoroughly explored by prior research .
for example bavota et al.
show the correlation between the star ratings of an app and the fault and change proneness of the apis that are used by the app.
although star ratings and the number of downloads may express the success of an app they might be misleading in some cases.
for example a star app could be downloaded only a couple of times as opposed to star app with thousands of downloads.
conversely app ranks clearly express the likelihood that an app will attract more users.
moreover it is known that google considers star ratings and the number of downloads when calculating the ranks .
we define rank trend as an evolution of ranks i.e.
declines and inclines over time that happens similarly among a set of apps.
we study the rank trends and highlight the variables that are statistically significantly related to the rank trends.
in addition we conduct fine grained analyses per app and per version of each app over time.
our goal is to find the most important variables that share a significant relationship with the changes in the ranks beside star ratings and the number of downloads .
we investigate 900apps in 30different areas that are associated with user reviews in two years.
our findings reveal various practical variables such as the appearance of new topics which share a significant relationship with the ranks.
such findings can help both developers of currently published apps and developers of start up apps by providing actionable guidelines to achieve higher ranks.
we address the following research questions rq1 what are the rank trends of mobile apps?
we identify rank trends i.e.
evolutions of ranks by applying a fuzzy clustering on the ranks.
we observe that in some areas falling in the ranks is more likely to happen than rising in the ranks.
moreover competing in the areas with dominant high ranked apps i.e.
the apps that maintain their ranks constantly on top such as budget might be harder than competing in areas with fewer dominant apps.
rq2 which variables can improve the rank trends?
we apply a regression model to explain the identified rank trends .
we identify actionable ways such as introducing new features to achieve better ranks over time.esec fse november lake buena vista fl usa ehsan noei daniel alencar da costa and ying zou preprocess data preprocessed app details rq2 and rq3 cluster ranks rq1 google play store preprocessed user reviews ranks trendsapp details user reviews rankscollect data figure overview of the study design process.
rq3 what variables have a significant relationship with the ranks over time?
we build a mixed effects model to quantify the ranks across apps and different versions of each app.
a mixed effects model allows us to explain the ranks across various trends areas and app versions.
we observe that developer related activities such as release latency play an important role.
we also find that not all the variables that common wisdom would deem important such as the number of pictures share a significant relationship with the ranks.
rq4 how do app developers evaluate the findings?
we asked app developers to evaluate our findings.
.
.
and .
of the developers strongly agree that the findings of each research question can be useful and practical for the industry respectively.
the feedback indicates that higher ranks can be achieved by following our guidelines when developing an app.
the contributions of this paper include we identify the evolution of ranks over time i.e.
rank trends .
the majority of the apps that are subject of our study tend to fall in the ranks over time.
we determine the variables that share a significant relationship with the changes in the ranks.
developers can improve the ranks with respect to our findings.
we find that not all the variables that may be considered as important variables by developers can statistically significantly explain the changes in the ranks.
therefore by focusing on our findings developers can have the rank of an app improved more efficiently.
data preparation figure shows the major steps of the study design process.
as shown in figure we collect the required data such as release notes and user reviews from google play store .
then we preprocess the collected data.
.
data collection google play store has the largest number of apps and users .
when it comes to success in the app markets the reachability of apps speaks first.
therefore the most effective data collection scenario comes from an ordinary user side.
we impersonate an ordinary user by using google play store search engine to find apps although every user is subject to different attitudes .
an area such as calculator is a subset of apps that share similar purposes and functionalities.
we collect the most searched areas using the semrush service which tracks the popular searchtable list of the areas with the number of versions and user reviews.
there are apps in each area.
area versions user area versions userreviews reviews airline health bible mailbox budget messaging calculator movie calling news camera paint chess piano cloud radio coupon reminder dating sleep dictionary spy phone emoji talking pet fitness translator gps weather grocery list weight loss engines such as the google search engine.
we look for the top keywords that are mostly searched via the mobile devices for finding apps.
table shows the list of 30top searched keywords i.e.
top wanted areas .
the list is determined by manually removing brand names such as amazon and porn related keywords.
by removing brand names i we can focus on the areas that share similar applications purposes and functionalities and ii we mitigate the skewness of the collected apps towards certain apps.
like an ordinary user who uses the search bar to find the desired app we search each area in google play store.
since the majority of queries are generated by users we searched the exact identified area names in google play store.
we scroll down each search result to the end.
for each area we find a median of 250app.
we randomly select 30apps from each area to perform our analysis.
considering a higher number of apps i.e.
more than 30for each area was not feasible in this study because i not all the areas have over 30different apps and ii not all the apps can be studied for two years since some apps are periodically cleaned up from the store .
having 30apps for each of our 30subject areas allows us to investigate 900apps.
moreover our random selection provides a better combination of apps than picking only the top apps.
we retrieve the app details e.g.
releases notes and descriptions the user reviews and the ranks of the selected apps from google play store.
we implemented a crawler to automatically fetch the information of our subject apps on a daily basis for two years since march tomarch .
we retrieved all the details of our subject apps and the associated user reviews.
we collect 011user reviews for 508distinct versions of our 900apps.
the number of app versions and informative user reviews see section .
are listed in table for each area.
.
preprocessing data in this subsection we explain all the steps that are taken to preprocess the app details and the user reviews.
removing non english user reviews.
we remove i.e.
user reviews that were written in a non english language using language detector .
filtering out uninformative user reviews.
users do not always leave an informative review.
for instance ok app provides minor information for app developers .
we rely on the ar miner to filter out uninformative user reviews.
in total winning the app production rally esec fse november lake buena vista fl usa we identified 691informative user reviews i.e.
of the english user reviews .
table shows the number of informative user reviews in each area.
correcting typos and informal vocabularies.
user reviews potentially suffer from typos that can taint the results of text analysis techniques .
we fix the typos in user reviews app descriptions and release notes using jazzy spell checker with a dictionary of 289english words.
based on manually investigating 384user reviews with a confidence level of and a confidence interval of jazzy corrects of incorrect words.
in addition we replace the abbreviations and informal vocabularies that are commonly used by users with the right words.
we retrieve the abbreviations and informal vocabularies from the available online sources .
breaking down app descriptions and release notes.
unlike user reviews app descriptions and release notes benefit from a structured form of writing.
google play store demonstrates app descriptions and release notes using the standard html format .
we extract each item from each release note.
we also break app descriptions into separate paragraphs and items of the existing lists in the descriptions.
organizing app descriptions and release notes allows us to measure the variables more accurately see table .
resolving synonyms.
general purpose thesaurus such as wordnet is not adequate to resolve the synonyms of informal texts such as user reviews .
we build a dictionary of words by manually studying 000randomly selected sample user reviews app descriptions and release notes .
from each set of synonyms we pick one as the representative word.
for example great awesome anddope belong to the same group of words.
resolving negations.
negations in user reviews app descriptions and release notes can disturb the text processing techniques.
for example not good should be replaced by bad .
to avoid such an issue we use the stanford natural language processing toolkit to resolve the negated terms .
topic modeling.
we apply topic modeling on app description release notes and user reviews for two reasons.
first we would be able to unify all the user reviews app descriptions and release notes within a certain number of topics and assign mathematically comparable vectors to each user review app description and releases note.
therefore we could measure the introduction of new topics and the similarity of release notes and app descriptions with user reviews see table .
second using topic modeling helps us to mitigate the lack of up to date dictionary of words for the terms that are used by users .
similarly noei and heydarnoori proposed a tool called exaf that helps developers find sample applications that implement a desired framework provided concept.
exaf employs topic modeling for finding the software engineering terms that represent the same concepts.
we build a corpus using user reviews app description and release notes.
before building the corpus we remove the stopwords and stem the words .
for example installed and installing have the same word stem which is install .
we apply the latent dirichlet allocation lda technique on the user reviews app descriptions the release notes.
each document in the corpus is considered as a combination of a number of topics .
prior to the topic modeling lda parameters need to be set up.
is the parameter on the per document topicdistributions and is the parameter on the per topic word distribution .
furthermore we employ three latest approaches i.e.
griffiths et al.
deveaud et al.
and cao et al.
to estimate the optimum number of topics.
the summary of the outputs of the three approaches i.e.
griffiths deveaud and cao suggests that the optimum number of topics is between 25and .
to avoid losing any potential topic we pick i.e.
maximum as the optimum number of topics.
we run the lda with 000gibbs sampling iterations .
with 000iterations we can achieve a high accuracy of lda .
.
measuring variables we use the goal question metric gqm paradigm to capture the required variables.
our goal is to understand ranks and rank trends using the available data.
it is known that google considers star ratings and the number of downloads when calculating the ranks .
therefore we consider star ratings and the number of downloads as control variables in our study.
table shows the list of our 45variables followed by a motivation a brief description and the number of sub variables for each variable.
approach and results in this section we present the approach and the findings of the research questions.
rq1 what are the rank trends of mobile apps?
motivation.
when searching for new apps google play store shows a ranked list of apps.
apps with higher ranks are more likely to be downloaded and installed .
observing the evolution of ranks helps developers to see the odds of rising and falling in ranks over time.
moreover we can discover the areas where apps tend to change or tend to maintain their ranks.
thus developers can take a wiser decision when implementing a new app or trying to improve the ranks of the currently published apps.
approach.
we apply time series clustering to identify the rank trends.
time series clustering requires i a clustering algorithm ii a distance measurement method and iii the number of clusters.
we apply a fuzzy clustering algorithm with dynamic time warping dtw as the method of measuring the distance between the time series of ranks.
fuzzy clustering.
partition clusterings such as k means build npartitions where each cluster contains at least one object and each object belongs to one cluster.
fuzzy clustering inherits from the fuzzy logic and fuzzy sets where the truth values of variables can be real numbers between 0and 1instead of being exactly 0or .
therefore with fuzzy clustering a rank trend can belong to more than one cluster .
for example if a rank is fluctuating while declining over time the fuzzy algorithm can put such a rank into two clusters.
therefore the variables associated with such a trend can contribute to both clusters of ranks.
the fuzzy algorithms can be set with a level of fuzziness mwhere m .
a larger m makes the clustering fuzzier while when m the fuzzy algorithm works like a partition algorithm .
dynamic time warping dtw .
dtw aligns two time series rank trends in a way that the differences between the two trends are minimized .
the euclidean distance that is commonly usedesec fse november lake buena vista fl usa ehsan noei daniel alencar da costa and ying zou table details of the independent variables including motivations descriptions and the numbers of variables.
variable s motivation m description d count star ratingsm.google play store provides a star rating mechanism with which users can rate each app from 1star worst to 5stars best .
we consider star rating in our study as a control variable because google uses star ratings as one of the factors to calculate the ranks .
d.we collect the star ratings that are associated with each version of the subject apps.
downloadsm.we measure the number of downloads as a control variable as google uses the number of downloads to calculate the ranks .1d.for each version of an app we retrieve the latest number of downloads from google play store.
user reviewsm.the number of user reviews can represent the interest of users in an app .1d.for each version of an app we count the number of user reviews since the last version to the current version.
sentiment scoresm.as the interpretation of different users is not the same regarding the number of stars measuring the sentiment scores of the user reviews is an alternative to measure the user perceived quality.
d.we measure the average of sentiment scores of the user reviews for each version using the sentistrength se tool .
unlike star ratings that are explicitly given by end users sentiment scores cannot be measured directly from google play store.
we manually analyzed the output of the sentistrength se on a sample of 384user reviews with the confidence level of and the confidence interval of .
sentistrength se gives correct sentiment scores.
proportion of user reviewsm.to capture the diversity of user reviews we measure the proportion of negative positive and neutral user reviews from two perspectives i star ratings and ii sentiment scores.6d.users usually do not install the apps with a star rating of less than .
we consider user reviews with star ratings equal to greater than and less than 3as neutral positive and negative user reviews respectively .
app pricem.the price of an app can encourage or dissuade a user to download an app .1d.we catch the price of each app from google play store.
releasesm.the process of changing the code integrating with the older versions and releasing as a new version is called release engineering .
the higher number of releases can indicate an active release cycle.
d.we collect the number of releases for each app.
release latencym.different apps might have differing release cycles that may affect the ranks .2d.we measure the time between two releases as an indicator of the release cycle latency for each version.
we also measure the average of latencies for each app.
text sizem.larger app descriptions can give users more information about an app while users may be interested in brief descriptions and release notes.
7d.we measure the following variables to capture the size of app details i the number of words of app names ii the number of words of app descriptions iii the number of sentences of app descriptions iv the number of words of release notes and v the number of sentences of release notes.
moreover the size of a user review can indicate its helpfulness .
for each version of an app we calculate the average of vi the number of words and vii the number sentences of the user reviews that are posted for the corresponding version.
we use the stanford parser and tokenizer to count the number of words and sentences.
app details similaritym.the first impression of an app might lie upon its name and description.
a relevant name and description can motivate more users to download an app.2d.we measure the similarity of app names and app descriptions with our 30subject areas using the wordnet similarity package .
picturesm.every app on google play store can be associated with some pictures .
the pictures may influence the users decision.1d.we count the number of pictures on the page of each app.
installation file sizem.users may refrain to download a big application due to network and storage limitations .1d.for each version of an app we collect the size of the installation file.
launch datem.an app that has been released prior to other competitors may have a better chance to get the attention of users.1d.we measure the first release date of each app.
addressing user reviewsm.recent studies investigate the importance of user reviews in the deployment of mobile apps .
some researchers focus on the user reviews to help developers in the process of app deployment.
therefore we quantify the degrees to which app developers address the user reviews.2d.for each version of apps we measure the cosine similarity of the app description with the user reviews that are posted from the last version to the current version.
we also measure the similarity of release notes with the corresponding user reviews .
introduction of new topicsm.different apps may introduce new features and functionalities in their new versions.
we estimate the addition of new functionalities by counting the number of topics that are added to a newer version of an app in comparison with the preceding versions.4d.for each version we count i the number of added topics to the description ii the number of removed topics from the description iii the number of added topics to the release note and iv the number of removed topics from the release note.
companym.a reputation of a company may impact all the apps that belong to the same company.
for example having a successful app can motivate users to try other products.
d.for each company we measure the number of published apps on google play store star ratings of the apps the number of downloads of the apps the number of paid apps the average price of the paid apps and the ratio of paid app per total apps.
aream.an area with plenty of dominant apps might be hard to compete in.
this can influence other apps within the same area.1d.for each app we consider its area of development see table .
categorym.a category in which an app is released might affect its rank.
some categories may be very competitive with a large number of popular apps.
d.for each app we retrieve its category from google play store.
in addition for each category we measure the number of published apps on google play store star ratings of the apps the number of paid apps the average price of the paid apps and the ratio of paid apps per total apps.
total in clustering algorithms such as k means assumes that theithpoint in one trend should be aligned with the ithpoints of other trends.
dtw alignment allows the offsets in the rank trends to be varied .
for example suppose two rank trends r1 r11 r12 ... r1n andr2 r21 r22 ... r2m where nis the number of time points in r1andmis the number of time points inr2.
if the trends are very similar but with an offset of ddays euclidean distance fails to converge.
however dtw can fit such trends in one cluster.
equation shows the distance of warping path between two trends.
distdtw i 1 i dtw build a warping path w 1 2 ... where denotes the number of points in wandmax m n m n .
number of clusters.
prior to applying a clustering algorithm it is required to determine the number of clusters to obtain the highest clustering quality .
to calculate the number of clusters we follow two approaches.
first we run the clustering algorithm with different numbers of clusters from 2to50and visually inspect the results until we achieve crisp distinguishable clusters .
we find 13as the best number of clusters.
second we employ the gap statistic approach to estimate the optimum number of clusters.
the gap statistic uses the output of the clustering algorithm and compares it with the change in a within cluster dispersion.
the procedure tries different numbers of clusters to maximize the gap statistic value.
we apply the gap statistics algorithm with the number of clusters ranging from 2to50.
the best result achieved with 13clusters.
both approaches i.e.
visual inspection and statistical analysis suggest 13as the optimum number of clusters.
findings.
in this section we explain our findings and observations regarding clustering the rank trends.
observation 1a there are rank trends and three general trends.
figure shows the centroids of the 13identified rank trends.
as it is shown in figure three general trends among the rank trends can be observed i falling ii rising and iii maintaining.
inwinning the app production rally esec fse november lake buena vista fl usa falling maintaining rising0 100slow fast top middle figure centroids of each cluster of rank trends.
x axis denotes the time day and y axis shows the ranks.
airlinebiblebudgetcalculatorcallingcamerachesscloudcoupondatingdictionaryemojifitnessgpsgrocery listhealthmailboxmessagingmovienewspaintpianoradioremindersleepspy phonetalking pettranslatorweatherweight loss rank trendarea 0510value figure distribution of apps in each cluster of rank trends x axis versus areas y axis .
a darker shaded red indicates a higher number of a cluster in a given area.
our experiments we tried increasing the fuzziness of the clustering.
however rank trends tend to stay categorized in only one cluster.
this can confirm that the number of clusters is set optimally.
observation 1b of the studied apps fell in the rankings over time.
by comparing the number of apps that lay on each of the three general trends we note that the majority of the apps i.e.
had a falling trend which may implicitly denote the competitive nature of app markets.
only of the subject apps could have improved the ranks during the studied period.
finally of our subject apps have maintained their ranks with very slight fluctuations.
observation 1c some areas such as news and budget are harder to compete than other areas.
figure shows the distribution of the rank trends for each area.
news andbudget are twotable list of correlated variables.
selected variable correlated variables description similarity words in description user reviews downloads average downloads company negative positive and neutral user reviews user reviews with negative positive and neutral sentiment scores average rating company apps company address user reviews release note address user reviews description average price company paid apps company price releases average time between releases apps category paid apps category areas with the highest number of apps that could have maintained their ranks among the top apps i.e.
cluster while only 3apps improved their ranks in the news andbudget areas.
this observation can suggest that it is harder for newcomers to compete in such areas since there are dominant apps that could have maintained the ranks during the studied period.
cluster 11contains the most number of apps i.e.
in comparison with other clusters.
the apps that are in cluster 11maintained the ranks in the middle.
the radio apps failed more in maintaining the ranks in comparison with other areas.
on the other hand the chess andcloud areas have the most number of apps with a rising trend.
such a result suggests that entering into chess andcloud areas might be a wiser choice to succeed in the competitive market of mobile apps.
most of the subject apps tend to fall in the ranks within the duration of our study.
in some areas such as chess it is easier to compete and improve the ranks.
however having a large number of dominant apps in some areas such as news and budget makes it harder for developers of new apps to compete with the existing apps.
rq2 which variables can improve the rank trends?
motivation.
inrq1 we identified the rank trends.
although one could speculate that the area is an important variable to explain the rank trends see figure it is unclear what variables share a strong relationship with the rank trends.
discovering such variables is important to help developers and app development companies to improve the ranks of their apps proactively.
approach.
we treat variables as i nominal variables that include two or more categories such as the category in which an app is published ii ordinal variables that are nominal variables for which the order of values matters and iii numeric variables such as the number of releases.
we also normalize the independent variables to bring the values into the same scale.
before building a model we identify the correlated variables.
having correlated variables negatively affects the results of our model .
we apply variable clustering analysis to build a hierarchical overview of the correlation between the independent variables .
we choose the variables that are more intuitive for inclusion in our model from each sub hierarchy of variables with spearman s .
.
the correlated variables are listed in table .
studying rank trends to get practical results requires ordering them from the worst to the best.
however there is no standardesec fse november lake buena vista fl usa ehsan noei daniel alencar da costa and ying zou definition of the goodness of a rank trend to treat the trends as an ordinal variable.
therefore we mitigate the bias of judging the superiority of each rank trend over another by breaking the trends into two groups of optimistic rank trends and pessimistic rank trends.
we define optimistic rank trends as i the ranks that are maintained among top apps during our study i.e.
trend and ii the ranks with a rising trend i.e.
trend .
otherwise a rank trend is considered as a pessimistic trend.
having two groups of trends allows us to build an ordered regression model to determine the odds ratios of the variables that play a significant role in explaining the two groups of trends i.e.
optimistic and pessimistic .
logistic regression model and probit regression model are both appropriate approaches to explain an ordered dichotomous dependent variable i.e.
optimistic vs. pessimistic .
the main differences between logit andprobit regression models are the link function and the assumption of each model about the distribution of the errors .
as we are interested to observe the odds ratios we report the output of the ordered logistic regression model in this paper.
nonetheless both approaches i.e.
logit andprobit produce the same results with our data.
we use variables that are introduced in table as the independent variables.
our logistic regression model obtains a great fit with the mcfadden s 2 .
.
the mcfadden s 2compares the loglikelihood of the model with the nullmodel to measure the level of improvement of the model .
moreover the number of events per variables epv of our model is .
which indicates that our model has a low risk of over fitting .
we determine the significant variables using the anova 2 test .
the significant variables have pr 2 less than .
.
pr 2 is the p value that is associated with the statistic .
findings.
table shows the results of our ordered logistic regression model.
the likelihood ratio 2 p value and effect of each independent variables are shown in table .
the significant variables are marked with asterisks.
observation 2a the launch date shares a significant relationship with the rank trends.
interestingly we observe that the apps that are launched later tend to be more successful in the market.
this is good news for newcomers and start up companies not to be hopeless when launching an app for the first time.
although the initial idea and innovation are essential to succeed competitors might overcome the seminal apps over time if the necessary effort is invested.
this observation led us to check how the launch date works when comparing top apps and rising apps only.
we observe that the launch date no longer appears as a significant variable when rising apps and top apps are compared.
observation 2b developers of published apps should constantly work on improving their apps to strive.
the appearance of new topics see section .
in the release notes and the descriptions are two significant variables of the model.
a release note usually contains a report of the fixed issues and the addition of new features .
a description usually describes the functionality and the purpose of an app .
the addition of new topics has a positive relationship with the success of an app.
observation 2c more releases are encouraged.
some users may feel frustrated when apps get frequently updated .
when it comes to statistical observations we note that the number of releases has a positive relationship with the success of apps.
therefore table logistic regression model of rank trends sorted by p value .
an upward arrow indicates that when the value of the associated variable increases the rank trend is more likely to fall into optimistic trends.
variable lr 2pr 2 effect launch date .
.49e appearance of new topics release note .
.12e releases .
.85e category .
.13e star rating .
.00e area .
.18e appearance of new topics description .
.61e average rating company .
.76e user reviews .
.44e description similarity .
.57e .
name size .
.92e .
pictures .
.80e .
address user reviews release note .
.22e sentiment score .
.31e sentences description .
.71e average price company .
.86e installation file size .
.81e name similarity .
.17e average star rating category .
.95e average price category .
.00e apps category .
.00e p value codes .
.
.
.
developers should not be afraid of keeping their apps up to date.
the average of days between releases for the top and rising apps is 14days.
however developers should be cautious about the quality of the app version they are about to release as ruiz et al.
find that releasing a low quality app endangers the survival of the app.
observation 2d developers especially from start up companies should carefully consider the area and the category on which they intend to work.
both the area and the category of apps have a significant relationship with the success of an app.
a chess cloud radio spy phone weather news orbudget app has a higher chance to lie upon optimistic trends by a positive effect .
in addition when we compare only the rising and top maintaining apps we note that among the aforementioned areas the ranks of chess cloud radio and spy phone apps are more likely to rise.
app developers should not be afraid of a late entry into the market as newer apps achieved higher ranks during the period of our study.
there is a chance of winning the market by constantly improving an app such as adding new features and fixing bugs.
however developers should be careful in choosing the area in which they intend to succeed.
rq3 what variables have a significant relationship with the ranks over time?
motivation.
inrq2 we identify the variables that have a significant relationship with the rank trends.
however an app can face various rises and falls over time.
we break the timeline of our subject apps with respect to the release dates of each app.
therefore we can identify the variables that have a significant relationship with the ups and downs of the ranks over time.
in this research question we study the ranks with a finer grain version while in the previous research question we study the ranks with a broader view i.e.
rank trends .winning the app production rally esec fse november lake buena vista fl usa table list of correlated variables.
selected variable correlated variables apps category paid apps category user reviews negative positive and neutral user reviews userreviews with negative positive and neutral sentiment scores address user reviewsaddress user reviews description release note releases average time between releases downloads average downloads company description similarity words in description average price company price paid apps company average rating company apps company approach.
first we remove the correlated variables with spearman s .
.
table shows the list of the correlated variables.
then we build a mixed effects model to determine the variables that have a significant relationship with the ranks.
a mixed effects model contains both fixed effect variables and random effect variables .
a fixed effects variable is treated with a constant coefficient and intercept for all the observations while the coefficient and the intercept of a random effect variable can vary across individual observations .
by applying a mixed effects model we can explain the relationships between a dependent variable and the independent variables that are grouped according to one or more grouping factor s .
the mixed effects model can assume different intercepts or coefficients for each group .
equation shows the mixed effects model formula .
in equation shows the grouping factor nis the total number of variables andmis the number of variables with fixed coefficients.
y holds the dependent variable.
0is the constant intercept and 0 is the intercept that varies across each grouping factor .
let xidenote theithindependent variable i 1 and iindicate the coefficients of the xiwhere 1 can vary across groups.
is the indicator of errors.
by having 1 only the intercepts can vary.
by setting 0 only the coefficients can vary.
by having both 0 0and 1 the model would become a fixed effects model.
y 0 0 m i 1 ixi n i m i 1 xi we let the dependent variable to be the rank of each version of the apps.
we set the independent variables to have random intercepts while keeping the coefficient of the independent variables fixed.
thus we give a chance to the mixed effect model to tune variable intercepts according to the grouping factors but keep the coefficients union across different observations.
therefore independent variables can contribute equally to the observations with a minor tune with respect to the grouping factors.
we group the independent variables according to i 13rank trends and ii 30areas nested within various versions of each individual app.
setting a grouping factor for rank trends gives a fair comparison between the apps.
instead of comparing all the apps together we compare an app with its own competitors.
a good analogy is the different weight classes in wrestling competitions.
by having different weight classes competitors can be judged on their techniques rather than their weights.
with a similar reasoning as above we set another grouping factor to the area of the app.
we let different versions have varying intercepts as there might betable mixed effects model of ranks sorted by p value .
variable 2pr f estimate effect sentiment score .
.55e .14e .45e sentences description .
.19e .08e .48e name similarity .
.47e .18e .08e sentiment score total .
.49e .76e .73e release latency .
.13e .01e .78e installation file size .
.41e .79e .88e star rating .
.15e .20e .21e appearance of new topics release note .
.20e .75e .20e downloads .
.11e .88e .82e average star rating category .
.60e .93e .42e address userreviews release note .
.71e .89e .51e description similarity .
.76e .
.98e .80e average price category .
.14e .31e .28e appearance of new topics description .
.41e .23e .37e releases .
.97e .65e .93e launch date .
.38e .91e .62e pictures .
.56e .77e .08e name size .
.70e .34e .84e ratio of paid apps per total category .
.02e .35e .38e apps category .
.28e .54e .60e average star rating company .
.62e .19e .49e deletion of previous topics0.
.70e .28e .80e average price company .
.75e .41e .25e user reviews .
.49e .18e .22e p value codes .
.
.
.
other factors for each version but cannot be considered in a noncontrolled empirical study such as contextual requirements of the time in which a version is released.
to estimate the goodness of fit of a mixed effects model two measures are used i marginal r2and ii conditional r2.
the marginal r2describes the proportion of the variance explained by the fixed effects variables while the conditional r2describes the proportion of the variance explained by both fixed and random effects variables.
the marginal r2of our model is .
but the conditional r2is0.
.
the lower value of the marginal r2compared to the conditional r2denotes that the proportion of the variance explained by both fixed and random variables is considerably higher than the proportion of the variance explained by the fixed variables.
thus modeling the random effects greatly improves the explanatory power of our model .
findings.
table shows the output of the mixed effects model.
significant variables are highlighted with asterisks along with their effects on the ranks.
observation 3a user reviews are important artifacts to explain the ranks.
the sentiment scores have a significant relationship with the ranks.
developers should take care of user reviews and keep the users happy to achieve better ranks.
for example developers can resolve the bugs that are reported in the user reviews.
for extracting bug reports developers can refer to the related work on this matter such as chen et al.
villarroel et al.
and sorbo et al.
.
observation 3b apps should be assigned with a proper name and description.
name and description of an app should be related to the area of the app.
although there exist some apps such as facebook whose own commercial name may not reflect their trueesec fse november lake buena vista fl usa ehsan noei daniel alencar da costa and ying zou area less famous apps should either find a way to advertise their apps or keep the similarity of names in mind.
observation 3c developers should not wait too long to publish an update.
as the latency of an update increases for an app the app tends to lose ranks.
such behavior might be caused by a probable google s ranking strategy as henze et al.
observed that releasing new updates is an effective strategy for increasing apps in app store.
another possible explanation can be the users preferences on seeing an updated version of an app earlier.
future studies should look into this matter more in depth.
also it is better to keep the installation files as small as possible.
observation 3d introducing new topics such as new features helps developers to improve the ranks.
we observe that the introduction of new topics in the release notes has a significant positive relationship with the ranks.
developers can refer to the related work such as villarroel et al.
and sorbo et al.
to mine the user reviews and get some idea on the topics that they may want to add to the next versions.
observation 3e the common wisdom does not always hold when it comes to improving the ranks.
various variables such as the number of pictures and the number of apps in a given category may sound critical to have a better rank.
for example tian et al.
observed that the number of pictures is an influential variable for receiving higher star ratings.
conversely as shown in table the number of pictures does not have a significant relationship with the ranks.
in fact only 11variables share a significant relationship with the ranks.
app developers should take care of user reviews and constantly improve the apps e.g.
introducing new features to achieve higher ranks.
developers should be careful not to spend too much budget and time on the variables that sound important but actually do not share a significant relationship with the changes in the ranks.
rq4 how do app developers evaluate the findings?
motivation.
to better understand the practical value of our findings we conducted a survey and in depth interviews with app developers discussing our findings.
approach.
in this section we describe our participants the design of the survey and the procedure of the survey.
participants.
the participants of our survey are mobile app developers.
to find the participants we contacted four app development companies that agreed to cooperate with us in conducting the survey.
finally 51app developers participated in our survey.
we also had the opportunity to discuss our observations in detail with two developers from two different companies one with over four years of app development experience and the other one with over five years.
design.
we gathered the developers opinions using questionnaires.
we asked five questions regarding the usefulness of our findings.
the questions are listed in table .
also for each question we asked the developers to provide further comments in case they did not agree with our findings or in case they would like totable list of the survey questions.
question 1do you think that the studied areas are the top areas of mobile apps?
2are the considered variables reasonable and sufficient for explaining ranks and rank trends?
3do you think the findings of rq1 are useful and practical for the industry?
4do you think the findings of rq2 are useful and practical for the industry?
5do you think the findings of rq3 are useful and practical for the industry?
provide additional feedback follow up comments .
we asked the developers to answer the questions on a five point likert scale i strongly agree ii agree iii neutral iv disagree and v strongly disagree .
table shows the median and the distribution of the responses.
procedure.
for each company we presented our research and our results to the developers.
it took around 30minutes to do each presentation using slides.
there was no time limit for developers to finish the survey.
however it took less than 15minutes to have the questionnaires filled out by all the developers.
regarding the indepth discussions the first author conducted the interviews.
each interview took around 60minutes.
findings.
the majority of the developers agree with our findings.
for each question first we present the result of the survey.
then we summarize our in depth discussion with two developers.
i do you think that the studied areas are the top areas of mobile apps?
survey.
as shown in table developers agree that the investigated areas are the hot areas of mobiles apps.
on the other hand .
and .
of the developers disagree and strongly disagree with the question respectively.
according to the follow up comments one developer thinks that the area of photography might be important too.
two developers think that social networking is missing.
however as we look for the top keywords that are searched by real users the exact name of the dominant social networking apps such as facebook are more likely to be searched rather than searching for other alternative apps.
in depth discussions.
both developers approved the areas subject of our study with agree andstrongly agree .
one developer said you have covered all the top areas such as dating coupons weather apps health and messaging .
ii are the considered variables reasonable and sufficient for explaining ranks and rank trends?
survey.
as shown in table .
and .
of the developers strongly agree and agree with the considered variables respectively.
however .
and .
of the developers disagree with the variables.
summarizing the follow up comments developers that do not agree with our variables suggested the following variables i code variables ii team size iii communication between the development team iv expertness of developers v marketing and advertisement vi project plan and vii the novelty of an app.
although we agree with the developers suggestions it is challenging to add more details about the code variables and team characteristics as such data is not publicly available.
future studies should look into the suggested variables in more details.
in depth discussions.
both developers confirmed our variables with strongly agree .
they indicated that we have considered almost all the important variables.
iii do you think the findings of rq1 are useful and practical for the industry?winning the app production rally esec fse november lake buena vista fl usa table median of the responses to each question the distribution of the responses.
the number of the responses received for each item is reported in the parentheses.
mediandistribution of the responses strongly agreeagree neutral disagreestrongly disagree 1agree .
.
.
.
.
2agree .
.
.
.
.
3strongly agree .
.
.
.
.
4strongly agree .
.
.
.
.
5strongly agree .
.
.
.
.
survey.
as shown in table .
of the developer strongly agree with the findings of the first research question.
on the other hand according to the follow up comments one developer found the drops from the ranks very challenging for the developers of existing apps.
this is due to our observation that most of the apps tend to fall in the ranks.
in depth discussions.
both developers confirmed the question with strongly agree .
one developer mentioned i think the reason that most apps have fallen in the ranking is the introduction of new apps to the market .
regarding competitiveness of different areas he said as an example in the area of chess new apps do not have serious barrier entry and can easily take the position of older apps by introducing new features .
the other developer mentioned that seeing different rank trends in different areas is very interesting.
it shows that choosing an area is an important decision.
iv do you think the findings of rq2 are useful and practical for the industry?
survey.
.
of the developers strongly agree that the findings can be useful in practice.
in depth discussions.
both developers strongly agreed with the question.
they said we do not launch an app unless we make sure that our app can receive high star ratings.
releasing newer versions normally include adding new features fixing bugs and improvement in the app that all improve users trust in our app.
i think this is why the number of releases is an important variable.
i also think there are a variety of apps that are better than the older ones so the launch date makes much sense to me and i agree that the developers tasks such as constantly working on an app introducing new topics and releasing an updated version lead to better ranks .
v do you think the findings of rq3 are useful and practical for the industry?
survey.
as shown in table .
of the developers strongly agree with the findings.
however one developer thinks some suggestions such as addressing user reviews may need a lot of effort.
in depth discussions.
both developers strongly agreed with the question.
they said even not all the famous app names are irrelevant.
for example the names of famous apps such as facebook and whatsapp are quite relevant to their area and the highlighted factors including the sentiment scores and installation file size correctly show that the users need to be satisfied.
moreover the release latency is an important issue.
developers need to address the issues quickly and release a newer version .
the majority of the developers agree that our findings can be very useful in practice.
implications for new app developers newcomers to the app production rally including start up founders entrepreneurs and even a small team of developers may be worried about the competitive nature of app markets .
an important message of our paper for newcomers is that app developers should not stop improving their apps as they have a great chance to win the rally!
see observations 2aand 2b .
unfortunately even if developers start with a novel idea they are in danger of losing their ranks by other companies as soon as they reveal their idea see observation 1b .
in other words newcomers need to have a strong personal drive to success .
it is not surprising that the lack of discipline and work could make it infeasible to succeed .
the key points for newcomers that are discussed in this paper can show them the right path.
i developers should carefully select the area in which they intend to work.
developers should do their homework and see if there is a huge number of dominant apps in an area or not.
the most wanted areas of apps can be a decent start see observations 1cand 2d .
ii never is late as in the past two years many apps other than our subject apps have achieved higher ranks in google play store see observation 2a .
iii investing time and money on the user reviews adding new features and releasing improved versions can give developers a higher chance to win the rally see observations 2b 3a 3c and 3d .
iv developer should work on the variables that can potentially improve the rank of an app.
developers should not be distracted by the variables that sound critical but are not much important see observation 3e .
developers of new apps with no or a limited number of userreviews can study the user reviews features and descriptions of other apps to get some hints.
we investigate the descriptions and release notes of each app in each area and compare them with the user reviews of other apps in the same area.
we notice that on average there is a similarity of between the descriptions and release notes of each app and the user reviews of other apps.
newcomers can identify popular and repelling features by studying other apps within the same area.
threats to validity in this section we discuss the potential threats to the validity of our experiments .
.
construct validity martin et al.
reported that using an incomplete set of userreviews in blackberry world app store can introduce bias to the findings.
to mitigate such a threat we gradually retrieved all the user reviews of our subject apps for two years.
moreover google play store does not reveal the information about all the available apps.
we mitigate this limitation by clicking on show more button as many times as possible to retrieve all the accessible apps.
one way to capture app features is decompiling installation files to byte codes.
unfortunately google play store only reveals theesec fse november lake buena vista fl usa ehsan noei daniel alencar da costa and ying zou latest version of the apps.
we captured the concepts of features by breaking down the release notes and descriptions as johann et al.
reported a precision of up to for app descriptions in identifying app features.
.
external validity we rely on google to get the app rankings.
our findings and experiments will be still useful even if google completely changes the ranking algorithm in the future for three main reasons.
first the majority of our variables are related to users and developers activities such as addressing user reviews and introducing new topics.
second the same approach can be used to find the most important variables in the future with the most current data.
third google improves the ranking algorithm over time .
however the variables that are identified in this paper have constantly appeared as the variables that share a significant relationship with the ranks for two years.
we retrieve the apps that can be accessed via google play store.
fortunately google gives a chance to all apps to appear in the rankings as we published a sample app in google play store with no download and no star rating.
regardless as our app was published recently in google play store we could have it on our radar of ranks.
therefore we believe that our set of apps is a combination of all sort of apps.
in addition the top areas may be subject to change in different geographical locations and time.
however the emphasis of our work is on the differences in areas.
if a company is not interested in the ranks the result of our study may not be generalized to the usage of such a company.
however it would be still a great opportunity for such a company to improve its rank and attract more customers.
.
internal validity we study 45variables to explain the ranks.
however we do not claim an exhaustive list of explanatory variables.
future work can shed more light on explaining the ranks by taking more variables into consideration.
some variables may not directly impact the ranks.
for example adding a new feature to an app may make its users more satisfied.
as a result the rank of the app can be improved.
related work in this section we summarize the related work along two research directions i empirical studies and ii user review analyses.
.
empirical studies several studies have been conducted to identify the variables that share significant relationships with the number of downloads or star ratings .
kim et al.
studied star ratings of mobile apps.
they showed that the star ratings could affect the users decision in downloading an app.
linares vasquez et al.
showed that the quality of the apis affects the star ratings of the apps.
bavota et al.
indicated the high correlation between the star ratings of the apps and the fault and change proneness of the apis used by apps.
noei et al.
observe that not only the app variables can impact the star ratings but also some device variables such as display size have a strong relationship with star ratings.
lee etal.
mined 300free and paid ios apps.
they observed a positive relationship between the download ranks and app page contents.
henze and boll studied the relationship between the release time and user activities in app store.
they observe that releasing new updates can improve the ranks in app store.
coelho et al.
mined app issues to investigate the exceptions that happen in apps.
fuet al.
analyzed star ratings and user reviews by applying topic modeling techniques.
linares vasquez et al.
noticed that anti patterns in source code negatively affect app quality.
ruiz et al.
recommend developers not to release incomplete apps too early to avoid receiving low star ratings.
none of the earlier work has clustered and investigated the app ranks.
collecting a large data and considering each release of apps in two years allows us to provide practical guidelines for improving a rank.
.
user review analyses many researchers aim to study the user reviews and give developers some insight regarding users demands and experience .
ciurumelea et al.
organized user reviews concerning the users requests.
they recommend source code to developers using code localization.
palomba et al.
propose a solution to recommend the source code changes that are needed to address the user reviews by measuring the asymmetric dice similarity coefficient between the words in user reviews and source code.
villarroel et al.
sorbo et al.
panichella et al chen et al.
and gu and kim aim to cluster the user reviews into meaningful groups.
for instance villarroel et al.
provided a solution to classify the user reviews into groups of bug reports and feature requests.
the above solutions can help developers to get the most out of the user reviews of their own apps.
developers can use such solutions along with our findings.
conclusion in this paper we study the evolution of ranks in google play store.
we observe that there are 13trends in the ranks including falling maintaining and rising trends.
in some areas such as budget existing apps tend to maintain their ranks.
therefore it is harder for newer apps to compete with the existing apps.
however by drawing a regression model we observe that app developers should not be afraid of a late entry into the market since the apps that appeared later achieved higher ranks during our study.
there is a chance of improving the ranks by continuously improving the app such as adding new features and fixing bugs.
we also model the ranks across apps and versions of each app.
we identified variables that share a significant relationship with the changes in the ranks such as the name and the appearance of new topics.
furthermore developers should not be distracted by some variables that sound important but do not share a significant relationship with the ranks such as the number of pictures.
finally the feedback obtained from 51app developers confirms that our findings can help app developers to achieve higher ranks in google play store.
future work should study the ranks in other app markets such as apple app store.
the differences and the similarities of various app markets can give insights to cross platform app developers.winning the app production rally esec fse november lake buena vista fl usa