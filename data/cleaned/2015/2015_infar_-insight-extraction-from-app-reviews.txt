singapor e management univ ersity singapor e management univ ersity institutional k nowledge at singapor e management univ ersity institutional k nowledge at singapor e management univ ersity resear ch collection school of computing and information systems school of computing and information systems infar insight extr action fr om app r eviews infar insight extr action fr om app r eviews cuiyun ga o jichuan zeng david l o singapor e management univ ersity davidlo smu.edu.sg chin y ew lin michael r. l yu see next page for additional authors follow this and additional works at https ink.libr ary.smu.edu.sg sis r esear ch part of the programming languages and compilers commons and the softwar e engineering commons citation citation gao cuiyun zeng jichuan l o david lin chin y ew l yu michael r. and king ir win.
inf ar insight extraction fr om app r eviews.
.
proceedings of the a cm joint meeting on e uropean softwar e engineering con f erence and symposium on the f oundations of softwar e engineering esec sigsof t fse lak e buena vista fl usa no vember .
.
available at available at https ink.libr ary.smu.edu.sg sis r esear ch this conf erence pr oceeding ar ticle is br ought t o you for fr ee and open access b y the school of computing and information systems at institutional k nowledge at singapor e management univ ersity .
it has been accepted for inclusion in resear ch collection school of computing and information systems b y an authoriz ed administr ator of institutional k nowledge at singapor e management univ ersity .
for mor e information please email cher ylds smu.edu.sg .
author author cuiyun ga o jichuan zeng da vid l o chin y ew lin michael r. l yu and ir win king this conf erence pr oceeding ar ticle is a vailable at institutional k nowledge at singapor e management univ ersity https ink.libr ary.smu.edu.sg sis r esear ch infar insight extraction from app reviews cuiyun gao shenzhen research institute the chinese university of hong kong shenzhen china cygao cse.cuhk.edu.hkjichuan zeng shenzhen research institute the chinese university of hong kong shenzhen china jczeng cse.cuhk.edu.hkdavid lo singapore management university singapore davidlo smu.edu.sg chin yew lin microsoft research beijing china cyl microsoft.commichael r. lyu the chinese university of hong kong hong kong china lyu cse.cuhk.edu.hkirwin king the chinese university of hong kong hong kong china king cse.cuhk.edu.hk abstract app reviews play an essential role for users to convey their feedback about using the app.
the critical information contained in app reviews can assist app developers for maintaining and updating mobile apps.
however the noisy nature and large quantity of daily generated app reviews make it difficult to understand essential information carried in app reviews.
several prior studies have proposed methods that can automatically classify or cluster user reviews into a few app topics e.g.
security .
these methods usually act on a static collection of user reviews.
however due to the dynamic nature of user feedback i.e.
reviews keep coming as new users register or new app versions being released and multiple analysis dimensions e.g.
review quantity and user rating developers still need to spend substantial effort in extracting contrastive information that can only be teased out by comparing data from multiple time periods or analysis dimensions.
this is needed to answer questions such as what kind of issues users are experiencing most?
is there an unexpected rise in a particular kind of issue?
etc.
to address this need in this paper we introduce infar a tool that automatically extracts insights fromappreviews across time periods and analysis dimensions and presents them in natural language supported by an interactive chart.
the insights infar extracts include several perspectives salient topics i.e.
issue topics with significantly lower ratings abnormal topics i.e.
issue topics that experience a rapid rise in volume during a time period correlations between two topics and causal factors to rating or review quantity changes.
to evaluate our tool we conduct an empirical evaluation by involving six popular apps and industrial practitioners and of them approve the practical usefulness of the insights summarized by infar.
demo tool website demo video permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
copyrights for components of this work owned by others than acm must be honored.
abstracting with credit is permitted.
to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
request permissions from permissions acm.org.
esec fse november lake buena vista fl usa association for computing machinery.
acm isbn .
.
.
.
concepts software and its engineering software functional properties information systems information integration keywords app review review topic insight extraction acm reference format cuiyun gao jichuan zeng david lo chin yew lin michael r. lyu and irwin king.
.
infar insight extraction from app reviews.
in proceedings of the 26th acm joint european software engineering conference and symposium on the foundations of software engineering esec fse november lake buena vista fl usa.
acm new york ny usa pages.
introduction user reviews play an important role in mobile software development.
they serve as an essential channel between app developers and users and deliver users recent experience with the apps.
by analyzing app reviews developers can gain valuable information for app updates including the features to improve new functionalities sought after by users and also functional and non functional issues to be rectified.
thus app review analysis is one step that can be highly beneficial in agile mobile app development.
despite its benefits analyzing app reviews often poses a challenge to developers.
the number of such reviews is often voluminous which is true especially for popular apps.
to deal with this challenge several studies have proposed methods to help developers better manage app reviews.
these include studies that categorize app reviews into several topics prioritize reviews of different topics or allow developers to search for reviews of interest given some keywords .
although the current techniques assist in review analysis they are mostly focusing on analyzing a static review collection and provide little support for contrasting reviews across multiple time periods and dimensions.
developers need to put non trivial amount of effort to produce contrastive insights from results of existing tools.
as an example consider developer a who is responsible for analyzing user reviews and reporting critical user feedback to other developers.
let s consider her employing surf a popular review 904esec fse november lake buena vista fl usa c. gao et al.
app reviews reviews avg.
ratingsquantitative results classifierimportant insights trend analysissalient topics topic 1overall ratingrating version version reviews topic version reviews topic topic anomaly causality correlationtext template database trend analysis engineinputs insight summary figure workflow of infar.
classification tool to classify the collected reviews into topics1.
with the categorization of reviews she is able to identify reviews for a given topic.
however a non trivial amount of manual work is still needed to answer questions such as what are the abnormal topics in the current version?
which topic impacts a significant decrease in current review rating?
etc.
these questions are important for developers to take corrective actions to improve the satisfaction of app users and they cannot be derived easily using surf which does not support analysis comparing reviews from multiple time periods.
in the paper we aim to fill the gap of existing research by distilling insights that are not produced by existing tools.
specifically we build a tool to extract four types of contrastive insights from different time periods and two analysis dimensions i.e.
review quantity and user rating .
the insights include salient topics i.e.
issue topics with significantly lower ratings abnormal topics i.e.
issue topics that experience a rapid rise in volume during a time period correlations between two topics and causal factors to rating or review quantity changes.
we name our tool infar for automatic insight extraction fromappreviews.
to evaluate our tool we conduct an empirical evaluation by involving six popular apps and industrial practitioners and of them approve the practical usefulness of the insights summarized by infar.
methodology figure depicts the workflow of infar which consists of two major steps.
with raw reviews as input infar first preprocesses the raw reviews and classifies the reviews according to predefined topics.
given the classification results infar captures four types of insights and explains the insights with chart visualization.
the insight types are salient topics s abnormal topics a causal factors y and correlated topics e among which the latter three are extracted by a trend analysis engine.
after these insights are extracted infar presents them in natural language using a set of text templates.
in this paper we employ surf as the classifier to group reviews into intention types and topic clusters.
for simplicity we refer to these as topics in this paper.
1surp defines review topics and four types.
the topics are app gui contents pricing feature or functionality improvement updates versions resources security download model and company.
the types include bug request question and info.
.
insight extraction we define insight scores to measure each insight s significance to developers denoted as sigt wheretis the insight type .
we use x x1 x2 ... xm to be the set of numeric values in the input where xcan be the review quantity nor user rating .
r .
we use .
r as the formula to represent user rating since developers are typically more interested with topics with lower ratings.
the following paragraphs describe how we extract the various insights.
three of the insights salient topics abnormal topics and correlated topics are extracted following a recently proposed data mining method in .
salient topics salient topics are the topics that occupy significantly large proportions or significantly low user ratings in current versions.
we hypothesize that the values in xfollow a power law distribution with gaussian noises.
after sorting xin the descending order and removing the maximum value xmax we fit the remaining values i.e.
x xmax to a power law distribution shown in figure a and use the prediction errors of xi x xmax to approximate the gaussian distribution n 2 .
with the power law distribution we obtain the predicted error of the maximum xmax by max xmax xmax.
then based on the gaussian distribution shown in figure b we calculate the probability to achieve the predicted error max byp pr max n 2 .
finally we compute the significance of the maximum xmax assigs p. xmax xmax maxpn 2 a power law distribution b probability of predicted error max measured values power law distribution figure significance of salient topics.
abnormal topics abnormal topics are the topics that exhibit significant increases in review numbers or significant drops in user ratings when compared with previous versions.
let wbe the window size which is the number of previous versions to analyze.
for example w 5means that whether the topics are anomalies in current versions are determined by the previous five versions.
given the observed values in a windows size xw xv w ... xv xv wherevdenotes the current version we first fit xwto a line by linear regression and compute its slope slope and the goodnessof fit value r2.
similarly we obtain the slope of each topic in versionv.
we then use gaussian distribution n 2 to model the distributions of slopes based on which we compute the probability of the slope value sequal to or larger than the observed slope by p pr s slope n 2 .
finally we define the significance of each slope as siga r2 p .
causal factors causal factors are extracted when the overall ratings or total review numbers for the current app version are significantly different than the previous version.
the aim of capturing such insights is to dig out the factors that dominate the changes.
letx x1 x2 ... xt be the time series of measured values e.g.
overall ratings or total review numbers of an app.
we first use the convolution based moving average method to detect the significant values in the time sequence as shown in figure a .
the moving average is predicted based on discrete linear convolution 905infar insight extraction from app reviews esec fse november lake buena vista fl usa i.e.
av n pt i 1xi n i where rt w w ... w andwis the predefined window size.
then we calculate the standard deviation of residuals between the moving averages and observations i.e.
x av n 2 .
finally version vis considered to have significant change if xv av v as illustrated in figure b .
the causal factor yis determined as the topic with the largest increase rate in review quantity or the largest decrease rate in user rating .
correlated topics correlated topics are the topics that exhibit strong correlations with respect to their review quantity or user ratings.
extracting such topics can help developers discover the topics that may impact certain app issues.
we use x1andx2to denote the measured values of two topics in consecutive versions.
we first compute the pearson correlation between these two sequences x1 x2 and obtain the p value.
then we hypothesize that the correlation coefficient follows the normal distribution n 2 where .
.
thus the significance sigeof the correlation of two topics can be calculated by pr x1 x2 n 2 .
.
text template definition the descriptions of insight summary should not only cover the insight types but also explain the importance to developers in a comprehensible manner.
therefore the insights generated by infar is designed to contain both the important topics and the corresponding reasons.
in this work we define a few text templates specific to each insight type.
for example we have version ...has abnormal topic ...in review number which shows the review number increases ...compared with the last version.
for describing the abnormal topics.
.
user review prioritization when retrieving user reviews relevant to specific topic or word infar will display the reviews ranked by their importance.
we use the similar prioritization method in which involves two aspects i.e.
review length hand user rating r. the importance score of one review is defined as exp r log h which means that reviews with longer lengths and lower ratings will be ranked higher.
how to use infar infar is web based application that analyzes raw user reviews and generates an insight summary of the reviews.
infar takes the output of surf as its input surf will parse the input data predict the topics of each review the raw reviews in the input file is saved as per line using to space these review attributes.
one example review from youtube of ios is .
unable to restart delete or download again.
what s up?
mar .
.
we define such input format due to its simplicity.
after uploading the raw t a moving averagesmeasured values moving averagesavg xvavgv v xv avgv n 2 b probability of residuals xv avgv figure significance of causal factors.
figure interface for parameter selection.
reviews through the entry page the server side of infar will parse the input data predict the topics of each review using surf prioritize the reviews with the method described in section .
and save the processed reviews into app version sqlite database.
infar automatically identifies the app version of these reviews correspond to and provides the interface for parameter selection depicted in fig.
.
the parameters include window size w significance threshold for salient topic significance threshold for abnormal topic and threshold for causal factor .
with all parameters set infar can then generate insight summary based on the techniques described in section .
the insight summary includes two large parts one for word distributions in user reviews and another for extracted insights2.
fig.
illustrates the word distributions using word cloud where the font size indicates the word importance i.e.
tf idf value3 and the font color denotes which type of reviews the word generally appears in.
users can click specific words to see the related prioritized reviews.
the review lists also support basic retrieval such as filtering reviews of specified types and topics.
the salient topic is explained with pie chart for review quantity or bar chart for user rating.
by clicking one topic users can also observe corresponding prioritized reviews.
all the other topics are described with line charts for users to observe the trends of these topics along versions.
case study to evaluate the usefulness of the insight summary generated by infar we have conducted empirical evaluation involving six popular apps publicly available and staff in several large it companies.
the six subject apps have been utilized in our previous work .
they are distributed in two different app stores i.e.
google play and app store and span across the app stores six different categories.
these app received a total of reviews that we collected from august to april .
for the participants of them have over four years of engineering experience and only two of them have fewer than one year of engineering experience.
they are one product manager two testing engineers four development engineers two researchers and one intern.
for evaluating infar we i prepared the input for each subject app ii randomly assigned the input file of an app to each participant for practicing infar and iii invited participants to answer questions of one short survey.
the demo tool website depicts the questions of the survey with aggregated data regarding the answers provided by participants.
2note that there would be types of insights for each version.
906esec fse november lake buena vista fl usa c. gao et al.
figure word cloud provided by infar where the font size indicates the word frequency and the color denotes which type of reviews the word usually appear.
by clicking some word users will see the prioritized relevant reviews below.
the majority of participants agreed that whole provided insights useful with of them judging these insights to be highly useful.
also the majority of them .
totally approved that the insight summaries are comprehensible while the rest of them partially agreed with that.
all the participants said that analyzing user reviews is very hard or hard without infar.
moreover of subjects declared that infar summaries allow them to save at least of the time as compared to manually analyzing user reviews.
regarding the quality of the extracted insights of them said that the insights do not contain any unnecessary information while the rest of them stated that they contain partially unnecessary information.
by looking deeply at the usefulness of each insight type and agreed with the usefulness of word cloud salient topics abnormal topics causal factors and correlated topics respectively.
also over of participants approved that all these displayed insights are highly useful for them except for causal factors with approval.
overall infar is affirmed to be useful for app development and save the total time for analyzing user reviews.
related work infar is mainly related to tools for assisting user review analysis.
we briefly describe the tools below.
mark is one tool that supports keyword based search.
mark retrieves keywords similar to the query keyword and lists the most relevant reviews.
arminer and paid are techniques for prioritizing app reviews.
the closest tool to infar surf is a popular tool for app review classification built by di sorbo et al.
given a set of reviews surf can visualize the number of reviews that fall under different topics as interactive bar charts.
although their tool can assist developers in identifying topics of interest e.g.
the ones involving more reviews the tool cannot produce issue topic comparison from multiple time periods.
different from infar the above mentioned studies are unable to produce contrastive summaries capturing the four insight types considered in this work.
the closest work to infar are mark and surf .
different from infar mark cannot capturetable example insight of youtube.
insight type example insight salient topicversion .
has explainable topic feature functionality with review number which accounts for significant proportion .
in that version.
abnormal topicversion .
has abnormal topics gui contents feature functionality in review number which shows the review number increases .
.
.
compared with the last version.
causal factorversion .
experiences significant increase in the review number by .
.
this is mainly attributed to topics gui which show an increase of .
compared with the last version.
correlated topicversion .
observes two topics app model that present strong correlations in review number with maximum correlation values at .
.
review topics and produce contrastive summaries in terms of these topics.
also different from infar surf cannot compare topics across multiple time periods.
surf also does not produce natural language summaries.
conclusion in this work we create one tool for extracting four kinds of important insights that capture contrastive information summarized from app reviews for developers.
our empirical evaluation shows that infar is promising in helping developers efficiently compare user reviews across time periods and analysis dimensions.
in future we are interested in extending infar to capture more insight types and in evaluating infar through a more comprehensive user study involving more industrial participants.
acknowledgment the work was fully supported by microsoft research asia microsoft research asia collaborative research award the research grants council of the hong kong special administrative region china no.
cuhk of the general research fund and the national natural science foundation of china no.
.