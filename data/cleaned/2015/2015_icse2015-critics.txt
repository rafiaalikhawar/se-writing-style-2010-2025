interactive code review for systematic changes tianyi zhang myoungkyu songyjoseph pinedoymiryung kim university of california los angeles yuniversity of texas at austin tianyi.zhang cs.ucla.edu fmksong1117 joep24 g utexas.edu miryung cs.ucla.edu abstract developers often inspect a diff patch during peer code reviews.
diff patches show low level program differences per file without summarizing systematic changes similar related changes to multiple contexts.
we present critics an interactive approach for inspecting systematic changes.
when a developer specifies code change within a diff patch critics allows developers to customize the change template by iteratively generalizing change content and context.
by matching a generalized template against the codebase it summarizes similar changes and detects potential mistakes.
we evaluated critics using two methods.
first we conducted a user study at salesforce.com where professional engineers used critics to investigate diff patches authored by their own team.
after using critics all six participants indicated that they would like critics to be integrated into their current code review environment.
this also attests to the fact that critics scales to an industry scale project and can be easily adopted by professional engineers.
second we conducted a user study where twelve participants reviewed diff patches using critics and eclipse diff.
the results show that human subjects using critics answer questions about systematic changes .
more correctly with .
saving in time during code review tasks in comparison to the baseline use of eclipse diff.
these results show that critics should improve developer productivity in inspecting systematic changes during peer code reviews.
i. i ntroduction code reviews are one of the most important quality assurance activities in software development .
according to a recent study developers spend a significant amount of time and effort to comprehend code changes during peer code reviews .
when the information required to inspect code changes is distributed across multiple files developers find it difficult to inspect a diff patch .
suppose that an api gets modified in the latest release.
all call sites using this api must be updated correctly .
such edits tend to be systematic involving similar but not identical edits to multiple locations.
as another example when programmers make changes to non functional requirements such as security and persistence these changes tend to be crosscutting edits to multiple locations .
popular code review tools phabricator 1gerrit 2collaborator 3and codeflow all compute differences per file.
this obliges the programmer to read changed lines file file even when those cross file changes are done systematically with respect to the program s structure.
therefore programmers are left to manually inspect individual edits to answer questions such as what other code locations are changed similar to this change?
and are there any other locations that are similar to this code but are not updated?
clone detection code search and matching approaches can locate similar code fragments but they do not directly work with diff patches.
they do not summarize similar edits nor report change anomalies in a diff patch.
these approaches also do not empower users to interactively investigate systematic changes as they do not give users the control to iteratively generalize the search template.
lsdiff automatically summarizes coarse grained structural differences but naively enumerates all possible systematic change patterns as rules.
this leads to the issue of poor scalability and a high rate of false positives.
in section vi we discuss related work in detail.
this paper presents critics a new approach for interactively inspecting systematic changes during peer code reviews.
given a specified change critics creates a context aware change template extracting the surrounding control and data flow context.
this approach models the template as abstract syntax tree ast edits and allows reviewers to iteratively customize the template by parameterizing its content or by excluding certain statements.
it then matches the customized template against the codebase to summarize systematic edits and locate potential inconsistent or missing edits.
our user study participants report that this interactive feature allows reviewers with little knowledge of a codebase to flexibly explore the diff patch with a desired pattern.
they can incrementally refine the template and progressively search for systematic changes.
to demonstrate the benefits of our approach we conducted two studies.
first professional software engineers at salesforce.com used critics to investigate diff patches authored by their own team.
after they finished a hands on trial of using critics we conducted semi structured interviews with individual participants to understand the current challenges that they face during code reviews and whether and how critics could help.
the interviews helped us gather insights about the usability and benefit of critics in an industry setting.
all six participants said that they would like to have critics integrated into their current code review environment collaborator .critics s feature to detect missing or inconsistent edits was valuable to their team and its interactiveusage was appropriate for novice developers to learn about the codebase.
in our second study twelve participants reviewed diff patches using both critics and eclipse diff.
this controlled experiment found that human subjects answered questions about systematic changes .
more correctly and .
faster on average with the assistance of critics in comparison to the baseline use of eclipse diff.
in addition to these two studies we also compared the accuracy of critics with our prior work lase.
the comparison found that in five out of six cases interactively customizing a change template using critics could achieve the same or even higher accuracy than lasewithin a few iterations showing the benefit of interactive template generation as opposed to fixed template generation.
in summary our paper makes the following contributions.
a new approach for interactively inspecting diff outputs.
critics provides a novel integration of program differencing and interactive code pattern search to locate and examine systematic changes.
it is instantiated as an eclipse plug in and the tool is available online.
our replication package also includes tutorial materials study tasks and survey questions used for a lab study.
a user study with six professional software engineers at salesforce.com.
after using critics to investigate the patches authored by their own team the participants reported that critics is helpful for inspecting system wide changes and noticing oversight errors.
all participants said they would like critics to be integrated into their current code review environment.
the study also shows that critics is a mature tool that scales to an industry project and can be easily used by professional engineers.
a lab study with twelve students at the university of texas.
students answered questions about systematic changes more correctly and quickly using critics than using eclipse diff.
the rest of this paper is organized as follows.
section ii illustrates our approach using a motivating example.
section iii describes how critics models code change as context aware ast edits using static program analysis and how it matches a generalized change template using an adapted robust tree edit distance algorithm.
section iv a describes a study with software engineers at salesforce.com.
section iv b describes our controlled experiment where participants complete code review tasks with and without critics .
section v discusses the comparison between critics and our prior work laseand threats to validity.
section vi describes related work.
ii.
m otivating scenario this section overviews critics with a real world example drawn from eclipse standard widget toolkit swt project.
swt is an open source widget toolkit with 400k lines of source code over files.
this example is based on a diff patch at revision as shown in figure .
the patch is adapted and simplified for presentation purposes.
alice updates the program to use the new sendevent api.
barry needs to review alice s changes to ensure all locations using sendevent are updated correctly and to check if there is any location that alice forgot to change.
the diff patch authored by alice is over lines of changes distributed across different locations.
in order to find incorrect edits barry needs to inspect line level differences file by file.
in particular to identify missing updates he must also inspect unchanged code as well since the original diff patch does not show what did notchange.
the following shows how barry may iteratively use critics to inspect systematic changes and to detect potential missing or inconsistent updates.
iteration .
suppose barry first inspects changes in the keydownevent method in figure a .
he wonders whether there are other methods that are changed similarly to keydownevent .
so he selects the changed code in the diff patch.
given the selected change critics identifies the change context unchanged surrounding code relevant to these edits in terms of control and data dependences which further serves as an anchor to locate missing updates during the searching process.
so the default template generated by critics consists of both the initial edit selection and the change context.
using the template critics locates code that matches the change context but is missing the update shown in figure b .
iteration .
after examining the search result in the first iteration barry wants to explore further since he suspects other locations may use different identifier names.
to match similar but not identical changes critics allows barry to generalize the change template by parameterizing type variable and method names.
so barry generalizes the variable name event and searches again.
this time the location in figure c is summarized although it uses a different variable name ev.
iteration .
critics includes the change context such as theswitch andcase statements from lines to in figure a in the current template.
barry wonders if there are similar changes in different control flow contexts such as afor loop or an if else branch.
he excludes the switch statement.
using the new refined template critics locates buttonupevent in figure d .
this location uses an if statement instead of a switch statement.
however critics flags this location as a potential inconsistent change since alice mistakenly swapped the two expressions expand and collapse .
such mistake is usually hard for the reviewer to detect during code inspection.
iii.
a pproach critics provides a novel integration of program differencing and pattern based interactive code search to help developers note inconsistent or missing changes during peer code reviews.
it consists of the following three phases.
phase i takes a user specified change region and extracts the relevant context.
phase ii allows developers to customize the change template by interactively generalizing its content.
phase iii matches a template against the codebase to summarize similar changes and to detect potential anomalies.
the reviewer can1int keydownevent int wparam int lparam expanditem item items 3switch wparam 4case os.vk space 5case os.vk return event event new event event.item item sendevent true event event.item focusitem sendevent focusitem.expanded ?
collapse expand event refreshitem focusitem ... a a changed region selected by barry1int keypressedevent int wparam int lparam 2expanditem item items 3switch wparam 4case os.vk space 5case os.vk return event event new event event.item item sendevent true event ... b code location with exactly the same context but missing the update 1int keyreleaseevent int wparam int lparam expanditem item items 3switch wparam 4case os.gdk return 5case os.gdk space event ev new event ev.item item sendevent true ev ev.item focusitem sendevent focusitem.expanded ?
collapse expand ev refreshitem focusitem ... c a similar but not identical change using a different variable name ev instead of event1int buttonupevent int wparam int lparam expanditem item items 3if lparam hover event bevent new event bevent.item item sendevent true bevent bevent.item focusitem sendevent focusitem.expanded ?
expand collapse bevent refreshitem focusitem ... d inconsistent change by mistakenly swapping two expressions expand andcollapse fig.
simplified examples of systematic changes inconsistent changes and missing updates.
code deletions are marked with and additions are marked with .
investigate the diff patch and achieve the desired result by iteratively refining the change template phase ii and searching change locations phase iii .
a. context extraction critics parses the selected changed fragments into abstract syntax tree ast edits and extracts the change context surrounding unchanged code on which the selected edits are control and data dependent by performing static intra procedural slicing .
it selects all upstream dependent ast nodes based on a transitive relation within a method.
the context could indicate where edits should be applied and serve as an anchor to locate systematic edits and to identify potential mistakes.
data dependence ast node njis data dependent on node ni if node njuses a variable whose value is defined in node ni.
for example by analyzing data dependencies between edits and surrounding unchanged code critics includes a variable declaration at line whose variable event is referenced from the deleted line in figure a .
control dependence ast node njis control dependent on node ni if node njmay or may not execute depending on a decision made by node ni.
for example the switch andcase statements from lines to in figure a are included since the execution of the changed code depends on these control predicates.b.
change template customization critics creates a default change template including the initial selected fragments and the change context.
a reviewer can customize the template by generalizing its content and to iteratively refine the template.
parameterizing identifiers.
critics allows a developer to parameterize type variable and method names so that they can be regarded as equivalent to different identifiers during the matching process.
suppose that there is a statement char data foo in the change template.
by parameterizing the variable name data critics automatically propagates the parameterization to all statements referencing data and this statement can be matched to any other statements in the form of char v1 foo where v1 represents any variable name.
excluding statements.
critics allows a user to exclude certain statements in the change template.
specially by excluding contextual statements critics is able to find similar changes in multiple contexts.
an excluded statement is mapped to a parameter excluded in a generalized change template.
for example by converting switch x to excluded it can match if x in line in figure d .
c. matching and anomaly detection given a customized change template critics searches and summarizes systematic changes.
tree matching.
to compute the similarity between different locations critics parses methods to abstract syntax trees and searches for similar subtrees by matching the template againstother methods in the codebase.
critics extracts a query tree from an abstract diff template.
this query tree is then matched against a target tree of the rest of the codebase.
critics applies an efficient and worst case optimal tree matching algorithm robust tree edit distance rted which combines the strengths of zhang s algorithm and demaine s algorithm .
zhang s algorithm is efficient for trees witho log n depth but has the worst case time complexity o n4 .
demaine s algorithm has a better worst case time complexity o n3 but runs into the worst case frequently.
rted recursively decomposes the input trees into sub forests either removing the leftmost or the rightmost root node.
it then computes the tree edit distance recursively by finding structural alignment.
rted then provides a list of matching node pairs with node edit operations that transform one tree into another.
the original rted algorithm finds node level alignment by calculating the minimum edit distance producing many false positives.
therefore critics further computes token level alignment between two matching ast nodes as described in procedure tokenmatch in algorithm .
given a list of token level matches critics checks whether a parameterized name is mapped to a concrete name.
if the token labels are exactly the same critics considers them to be equivalent.
while matching labels we match the parameterized names such as v1 in the query tree with any concrete name in the target tree to support flexible matching.
suppose that rted aligns two nodes t v m y and int x foo y .
critics produces token level alignment f t int v x m y foo y g. because these token level mappings are allowed via explicit parameterization in the previous step critics considers the aligned two nodes as identical and continues to check the next aligned pair.
as another adaptation to rted critics checks whether there is an excluded node in the list of the aligned nodes computed by rted.
if rted aligns an excluded node with another node critics allows such matching as described in line in algorithm .
suppose that critics takes a node pairswitch x in a query tree and if x y in a target tree.
if the node switch x is excluded by a user critics matches the two nodes.
figure shows an example of node level and token level alignment.
critics improves the performance of search by caching relevant data to reduce search load.
critics maps an identifier name to a set of source files using the identifier name and stores the mappings in a hash table.
before running rted critics inspects each identifier name in a query tree and identifies a set of files using the same set of identifier names by looking up the hash table.
then it only scans through the searched source files to avoid unnecessary matching.
change summarization and anomaly detection.
each template consists of a before state and an after state.
the before state refers to code before edits.
conversely the after state refers to the code after edits.
using the tree matching algorithm critics finds two sets of similar subtrees matching the old and the new version respectively.
if a method matches the before state but not the after state it implies that the n1 m1 int x int y n4 if x excluded n5 char buf foo t1 v1 m1 n6 string c baz buf b string c baz v1 b n2 int a y n3 int b a a query tree.
m1 m2 int x int y m4 switch x m5 case m6 byte buffer bar m7 string c baz buffer b m2 int a y m3 int b b a target tree matched with the above query tree.
fig.
rted matches nodes such as n1 m1 n2 m2 n3 m3 n4 m4 n5 m6 and n6 m7 and c critics matches tokens in the labels of two matched nodes n5andm6 such as t1 byte v1 buffer and m2 bar .
programmer either made an incorrect edit or forgot to update the code.
similarly if a method matches the after state but not the before state critics reports it as an anomaly as well because similar edits are made to different contexts.
we report two types of change anomalies inconsistent changes where edits are applied but partially incorrect and missing updates where the required edits are completely missing.
this feature of detecting change anomalies distinguishes critics from other pattern mining and anomaly detection approaches that work with a single program version as opposed to a diff patch.
to summarize the matching systematic changes critics shows the individual matching locations and summarizes the similar edits using a change template derived from matching locations.
our implementation leverages changedistiller to compute ast edits crystal6for data and control flow program analysis and rted for computing tree edit distance.
iv.
e valuation we evaluated critics using two different methods.
first we conducted a user study with professional software engineers to understand how critics can help them during code reviews.
engineers at salesforce.com used critics to investigate the real patches found in their version history authored by their own team.
this study emulates the realistic code review scenarios and solicits authentic feedback on the searching similar subtrees.
input let ast be an abstract syntax tree for a program.
input let qtbe a query tree from a customized change template.
output let mts be a collection of the matched subtrees.
algorithm searchsimilarsubtrees qt mts foreach node ifromast do t getsubtree node i tis a target tree ifrted.match qt t true then nodepairs nodepairs nodepairs f ni mi ni2qt mi2t where ni mi is a pair of nodes that rted matches and aligns.
g iftokenmatch nodepairs true then mts mts ftg end end end return mts procedure tokenmatch nodepairs foreach pair i2nodepairs do ifpair i nis excluded then continue end ifmatch pair i n label pair i m label false then pair i n label is different from pair i m label .
tokenpairs tokenpairs tokenpairs f tj uj tj2pair i n label uj2pair i m label where tj uj is a pair of a deleted token and an inserted token that c ritics matches and aligns.g if8tj2tokenpairs tjis parameterized then continue end else return false end end end return true use of critics in the real world.
second we conducted a lab study at the university of texas at austin where twelve participants investigated diff patches using both critics and eclipse diff and search.
we selected eclipse diff and search as a baseline because they are default features in eclipse.
we cannot use existing clone based search tools as a baseline because they are not designed for inspecting diff patches and thus participants cannot use them without adapting the tools to inspect diff patches.
these two evaluation methods hands on trials followed by semi structured interviews and a controlled experiment using human subjects complement each other by assessing the benefits of critics both qualitatively and quantitatively.
a. user study with professional developers at salesforce we recruited six participants from salesforce.com.
the participants included two software developers three quality engineers and a project manager from the same team.
this team develops a platform for other teams to process and manage big data stored in the cloud.
the participant names and the product name are anonymized.
all six participants had at least three years of java development experience in industry.
five reported that they conduct code reviews at least weekly using collaborator a defaultcode review tool at salesforce.7although one manager said he seldom reviews others changes we still interviewed him because he could provide valuable feedback from a manager s perspective.
table i shows the demographic information about the six participants.
in terms of a study procedure we first gave a presentation to introduce critics s features to the participants.
this presentation included a twenty minute live demo of how to use critics eclipse plug in.
to get accurate and comprehensive feedback participants were then asked to use critics to investigate one of the four diff patches authored by their colleagues.
this could simulate hands on experience of using critics in a real world setting because the participants reviewed patches from their own system.
the four patches came directly from the version history of the salesforce codebase that they currently work on.
we selected the patches that include similar changes to multiple files because the goal of critics is to help developers examine systematic changes and find potential anomalies.
table ii describes the associated commit log descriptions the size of the patches in terms of changed lines of code and the number of changed files from the actual version history.
while we do not disclose the size of the salesforce codebase for confidentiality we report that critics is a mature tool that scales to an industrial scale project and the participants did not have any problems running critics on their codebase and patches.
for individual participants the hands on use of critics lasted about to minutes.
afterward we conducted a semi structured interview to solicit their feedback on the utility of critics .
the advantage of semi structured interviews is that they are flexible enough to allow unforeseen types of information to be recorded .
the interviews were audio recorded and transcribed later for further analysis.
the interview questions are described below.
what kind of challenges do you face when you conduct code reviews?
in which situation do you think critics can help improve code reviews in your team?
would you like to have critics be integrated with the code review tool you are currently using?
how do you like or dislike critics ?
subject role gender agejava experiencecode review frequency developers male weekly 2quality engineerfemale weekly manager male seldom 4quality engineermale weekly 5quality engineerfemale weekly developers male daily table i the demographic information of study participants commit descriptionchanged locnum of changed files 1refactor test cases by moving bean maps to respective utils classes743 2refactoring the api to get versioned field values by passing the version context as a parameter943 3refactor tests by using try withresources statements to ensure the resource object is released after the program484 4update common search tests by getting versioned test data2224 table ii diff patches from salesforce.com used for the study the interview results are organized by the questions raised during the interviews.
what kind of challenges do you face when you conduct peer code review?
collaborator allows developers to upload compare and comment patches during code reviews.
however participants find it hard to review systematic changes since collaborator only highlights differences on the uploaded patches lacking the ability to identify underlying similar change patterns and pinpoint overlooked mistakes.
since rest apis across different versions generally share similar code snippets refactoring on versioned apis often involves similar changes.
unfortunately these changes are not always exactly the same including subtle differences in different locations.
it is hard for us to find missing updates especially if the reviewer is not familiar with the codebase.
so we totally depend on regression testing to check if there is any location we forgot to change assuming it the overlooked change will break test cases.
but honestly it does not work very well.
in which situations do you think critics can help improve code reviews in your team?
the participants mentioned that critics can help them inspect system wide changes so that they do not need to manually walk through each changed location line by line.
they also discussed that code reviews are usually assigned to senior developers and consequently piled up on them since they are familiar with the codebase and are more likely to notice oversight errors.
they believed that the interactive search process of critics is an efficient method for novices to perform code reviews unleashing the burdens of senior developers and spreading knowledge between team members.
because currently in our company reviewers only ensure the logic correctness and coding style in uploaded patches.
they barely check if there is any missing update unless a reviewer is very familiar with the codebase and knows where the developer should update.
that is also why we always assign code reviews to senior developers in the scrum team.
the feature in your tool can free us from piling code review tasks on our senior developers since it can do the inspection automatically without requiring deep knowledge of the codebase.
critics would be helpful to check some api updates inour projects.
for example an api from one team is updated and the old api is deprecated.
since people only change the locations they know and reviewers usually do not intentionally check unchanged areas we cannot guarantee all locations are updated as expected.
so using critics could help us find out all the locations that need to be updated in the early stage so that we do not need to wait for regression testing or even worse the customer to tell us if there is any place that we updated incorrectly or forgot to update.
would you like to have critics be integrated with your current code review tool?
all six participants provided strong positive answers and believed that it would be useful to have critics integrated to their code review tool collaborator .
definitely.
it makes sense to integrate it with collabora tor since it will save a lot of time for code review.
of course.
currently collaborator only highlights the changed location in a very naive way.
a feature like extracting and visualizing the change context can help us better understand the change itself as well as find some underlying change patterns between related changes.
how do you like or dislike critics ?they thought critics would be a good time saving tool for code reviews.
four participants replied that they like the search feature a lot because of its flexibility and interactivity compared with existing textual search.
two participants shared the ui is not very intuitive at a first glance and it took some time for them to grasp the ui.
i like it since it is a great time saving tool for code review and i think its ability to find similar changes can be useful in our work.
it will be more interesting if you can provide the change skeleton by default in the tree graph and enable users to expand a node to see details if they want to.
in summary after using critics to investigate their own team s patches participants told us that critics can improve developer productivity in code reviews and should be integrated to collaborator .
professional engineers encounter challenges when reviewing system wide code changes.
currently in their work environment they barely have any reliable mechanism to guarantee all locations are correctly modified.
participants think critics would help them detect unnoticed locations.
its interactive search feature also makes it easier for less experienced developers to use the tool.
all participants strongly affirmed that they would like to have critics s features as a part of their current code review environment.
b. lab study comparison with eclipse diff and search we conducted a user study with participants to further evaluate the efficiency and usability of critics .
rq1 how accurately does a reviewer locate similar changes with critics in comparison to eclipse diff and search?
rq2 how correctly can a reviewer detect change anomalies with critics in comparison to eclipse diff and search?versions change description similar change inconsistent change missing update size loc patch1 simple jdt vs. jdt 9801initiate a variable in a for loop instead of using a hashmapgettrailingcomments astnode getleadingcomments astnode getextendedend astnode getextendedstartposition astnode getcomments astnode getcommentsrange astnode q1.
given the change in the method gettrailingcomments what other methods containing similar changes can you find?
count the number.
a. b. c. d. or more answer c. getleadingcomments andgetextendedend .
q2.
which of the following methods contains inconsistent changes compared with the change in gettrailingcomments ?
a.storetrailingcomments b.getextendedend c.getleadingcomments d.getextendedstartposition answer it uses a wrong expression i this.leadingptr instead of range null i this.trailingptr .
q3.
how many methods share context similar to the change in gettrailingcomment but missed the similar update?
a. b. c. d. or more answer c. getcomments andgetcommentsrange .
versions change description similar change inconsistent change missing update size loc patch2 complex jdt vs. jdt 10611extract the logic of unicode traitement to a methodgetnextchar getnextcharasdigit getnexttoken ... locations in totalgetnextcharasjavaidentiferpart jumpovermethodbody getnextchar char char getnexttoken ... locations in total all located in another file680 q1.
given the change in the method getnextchar what other methods containing similar changes can you find?
a. b. c. d. or more answer c. getnextcharasdigit andgetnexttoken ... methods in total q2.
which of the following methods contains inconsistent change compared with the change in getnextchar ?
a.getnextcharasdigit b.getnextcharasjavaidentiferpart c.jumovermethodbody d.jumpoverunicodewhitespace answer it invokes a wrong method jumpovermethodbody instead of getnextunicodechar .
q3.
how many methods share context similar to the change in getnextchar but missed the similar update?
a. b. c. d. or more answer d. jumpovermethodbody getnexttoken ... methods in total.
table iii the description of two patches and corresponding questions for code review tasks.
rq3 how much time can a reviewer save in a code review task when using critics ?
in this study we used counterbalancing to control the order effect.
each participant carried out two different code review tasks patch and patch once using critics and once with eclipse diff and search.
in this section we refer to the setting of eclipse without critics asdiffin short.
patch is a simple patch with changed lines and patch is a complex patch with changed lines.
both the order of the assigned tools and the order of the assigned tasks were randomized to mitigate the learning effect.
table iii describes the patches in terms of data source patch size loc change description as well as the number of methods that contain similar changes inconsistent changes and missing updates.
it also describes the user study questions for each patch.
four of the twelve participants were electrical and computer engineering undergraduate students and the other eight were all graduate students in software engineering.
all participants had at least one year experience in using the eclipse ide.
all but one participant had code review experience with diff tools such as eclipse diff and git svn diff.
participation was strictly voluntary with no compensation offered.
prior to each study session all participants were given a twenty minute tutorial to learn how to use critics .
we gave them a live demo about inspecting a diff patch with critics .
the participants first answered two warm up questions about the assigned diff patch.
then they were given a time to inspect a diff patch and answer three questions about systematic changes.
all study tasks concern answering questions about similar changes because the goal of critics is to supportinspection of similar changes not all types of code changes.
the questions required participants to identify methods that were changed similarly to a given location and to search for potential anomalous locations where similar edits were incorrect or completely missing.
the three questions are described in table iii.
table iv shows the percentage of correct answers for each tool.
to measure efficiency we recorded the task completion time from when participants started to inspect source code to the time when they submitted the answers.
at the end of the user study each participant was asked to complete a post study survey to evaluate their experience with critics and eclipse diff.
first they were asked to rate critics and eclipse diff separately on the aspects of relevance clarity and usefulness for locating similar changes and detecting anomalies.
the survey also included open ended questions to solicit qualitative feedback on how the users like or dislike critics and the suggestions for improving critics .
we recorded each user study session with screen capture software for further analysis.
the participants were encouraged to speak out their thoughts when conducting the code review tasks.
regarding multiple choice questions about the locations of systematic changes and anomalies we asked the participants to explicitly identify individual method locations.
the quotes from the study participants are extracted from these conversations.
the data and transcript are anonymized.
identifying similar changes.
out of participants answered the question q1 about similarly changed locations correctly with critics .
out of did with eclipse diff.
we observe that patch usually required more template configuration and search iterations in critics and participantsq1 similar changes q2 inconsistent changes q3 missing updates time critics diff critics diff critics diff critics diff patch simple patch complex table iv average correctness of participants answers with and without critics .
for example means two out of six participants answered the question correctly.
.
.
.
.
.
relevance clarity usefulness of finding changes usefulness of detecting anomalies critics diff fig.
subjective ratings for critics and eclipse diff often stopped refining the template after two or three iterations.
at that point the customized template was still not general enough to find all similar changes.
using eclipse search with a few keywords extracted from the patch often produced unstable search results depending on the choice of the keywords.
detecting inconsistent changes.
all participants found inconsistent change locations q2 correctly with critics as opposed to out of with eclipse diff.
we observed that critics can help detecting inconsistent changes for both simple and complex patches.
detecting missing updates.
out of participants pinpointed all missing updates correctly with critics while only out of found missing updates with eclipse diff.
we observed that eclipse diff was comparable to critics when inspecting a simple small patch patch with line changes while participants could locate a missed update more accurately when using critics than eclipse diff for the complex one patch with line changes .
task completion time.
participants saved minutes and seconds with critics on average completing the tasks .
faster than eclipse diff.
for the simple patch patch critics reduced task completion time by .
on average at most.
but for the complex patch patch it reduced time by .
on average at most.
consistent with the goal ofcritics to support investigation of systematic changes it was more useful when a patch consists of a large amount of scattered similar edits.
user feedback.
after completing the user study participants completed a brief questionnaire to rate critics and eclipse diff based on their experience.
figure shows the subjective ratings from the survey.
critics received higher ratings than eclipse diff from all participants including how relevant the found locations are how clear the tool is and how useful thetool is in locating similar edits and detecting anomalies.
we also solicited qualitative feedback from the participants.
they appreciated that critics reduces the effort to investigate similar changes especially in a large system.
using critics they only needed to inspect one location as opposed to reading changed lines file by file without having the global context of what they are reviewing.
i like the way it critics automatically identifies possible similar edits that i could miss and detects anomalous changes.
it really speeds up the code review process.
however opinions were divided on the usability of critics s ui.
three participants mentioned that its user interface is not intuitive and would benefit from extra visual options or instructions.
they also suggested that critics should provide configuration hints e.g.
which identifier should be generalized.
it would be much more straightforward if critics gave some hints about which identifiers should be generalized.
currently it seems totally depends on developer s sense.
in conclusion participants were able to locate systematic changes and detect anomalies more correctly and quickly in code review tasks using critics .
they believed that critics could complement the use of diff during inspection of systematic changes.
v. d iscussion comparison with lase.
our prior work lase automates systematic editing by searching for locations and applying custom edits to individual locations.
it requires multiple change examples as input to generate abstract transformation.
it is challenging to directly compare critics with lase because lase s template generation requires multiple examples apriori and is fixed while critics is an interactive tool that a human can iteratively configure a template.
therefore we simulate a human driven template configuration process incritics .
from the lab study described in the previous section we find that users follow common patterns while interactively generalizing the selected edit content and context.
they usually generalize one identifier or statement at a time and re run the search if the search result degrades they undo the generalization and try a different identifier or statement.
in other words their generalization strategy is similar to the typical greedy search .
when generalizing identifiers users first generalize a variable with a long name rather than a short one.
when excluding statements users prefer to exclude the context node on which a change is control dependent such as ifand for.
we encode these patterns in a test script to simulate the interactive use of critics .
then we compare lase s accuracy with critics s accuracy at each iteration.
a f1 score for finding similar edit locations by excluding statements.
b f1 score for finding similar edit locations by parameterizing identifiers.
fig.
f1 score on change template customization.
the oracle test suite is drawn from the systematic edits identified by park et al.
in eclipse jdt and eclipse swt and consists six sets of systematic changes.
in this test suite the patch size ranges from to lines of edits.
the number of locations with systematic changes ranges from three to ten locations.
the first two changed locations are used as input examples to lase using the same approach described in meng et al.
.
figure describes the accuracy variation in critics s simulation.
figure 4a represents f score a harmonic mean of precision and recall for finding similar changes while varying the number of excluded nodes.
figure 4b represents f 1score for finding similar changes while varying the number of generalized identifiers.
table v shows the comparison of search accuracy between critics and lase including the iteration numbers till critics achieves the best result and the average execution time for each iteration.
in five out of six cases critics achieves the same or higher accuracy than lase within a few iterations showing the benefit of interactive template configuration as opposed to fixed template configuration.
threats to validity.
in terms of construct validity in our lab study we measured the correctness of the answers and the time taken to answer questions to measure developer productivity in inspecting systematic changes.
other measures such as the number of potential bugs detected could be used to measurecritics lase precision recall iteration time sec precision recall patch .
patch .
.
.
.
patch .
patch .
.
patch .
patch .
.
average .
.
.
.
table v comparison between critics and lase developer productivity for peer code reviews.
in our user study we used both large and small patches and counterbalanced the order and task assignment to mitigate learning effect.
because the goal of critics is to help inspect systematic changes the questions mainly pertain to the questions about similar scattered changes not general program comprehension questions.
in terms of external validity in our lab study twelve student developers were not familiar with eclipse jdt from where patches are drawn.
the lab study may not generalize to professional developers who are familiar with their codebase.
to overcome this limitation in our user study at salesforce.com six engineers investigated the patches from their own system.
the study at salesforce is a qualitative study based on six interviews.
because of the qualitative nature of the study we do not make any quantitative statements about how much productivity gain critics can provide in comparison to their current code review tool collaborator .
the study was conducted only in one company.
we do not believe this is a significant limitation because the background of the participants and the code review practice at salesforce.com are similar to other large software companies.
in the comparison with lase our test suite of systematic changes includes only patches from park et al.
s data set and may not generalize to projects other than eclipse jdt and swt.
to mitigate internal validity in our lab study before the participants started the task we asked them to inspect the change example first and answer two questions to calibrate their understanding.
the first question required them to choose true or false about detailed statements about the change to ensure that they have carefully inspected the example.
the second question required them to identify changes similar to the given example.
the warm up questions helped them better understand change similarity.
vi.
r elated work modern code reviews and code change comprehension.
rigby et al.
conduct an investigation into code review practices in open source development and find that developers can understand small logical coherent units of code changes better rather than large unrelated changes .
rigby et al.
also find general principles of code review practices and the benefit of code review for knowledge sharing among developers .
bacchelli and bird study modern code review practices and find that a key challenge is lacking tool supportfor code change comprehension .
tao et al.
also study the challenges that developers face when they comprehend code changes and find that modern code review tools must support the capability to divide a large chunk of code changes into sub logical groupings and to filter non essential changes .
these findings motivate critics .
barnett et al.
also design a static analysis technique to help developers to understand code changes during code reviews .
they decompose composite changes and cluster relevant ones using dependence analysis.
while our work shares the same goal of assisting code change comprehension our work focuses on inspecting similar changes and detecting anomalies.
code search and anomaly detection.
chang et al.
use graph mining to detect implicit programming rules from system dependence graphs and use these rules to find violations .
wang et al.
propose a dependence based code search technique .
their query language is capable of capturing control and data dependences.
their work is later enhanced with semantic topic modeling .
instant code search techniques take a code example as input and return other similar code examples on demand .
in particular cbcd detects recurring clone related bugs by finding similar asts with program dependence information.
these techniques are based on code clone mining .
several approaches detect inconsistencies among code clones.
cp miner securesync and jiang et al.
s work find cloning related inconsistencies by searching for duplicated code.
spa categorizes four common types of porting inconsistencies and detects discrepancies between the surrounding context of systematic changes .
lo et al.
actively incorporate incremental user feedback to continually refine clone based anomaly reports and selectively present clone based bugs .
lin et al.
detect differences across multiple clone instances to help with clone comprehension .
critics differs from these code search and clone detection techniques in two ways.
first critics directly target investigation of diff patches as opposed to a single program version.
due to these differences in our lab study we could not directly compare with existing clone based search tools because these tools are not designed for inspecting diff patches.
second critics allows users to interactively generalize a search template to provide flexibility.
systematic change inference.
reffinder finds the types and locations of refactoring edits using pre defined refactoring rules .
lsdiff infers systematic change patterns at a coarse granularity and summarizes them as logic rules .
it also detects potential inconsistencies that violate the systematic change patterns.
lsdiff supports only coarse grained analysis at the level of method calls and field accesses.
it also does not leverage any human input and therefore it often discovers a large amount of rules in an inefficient top down manner while discarding most of them in a post processing step.
in contrast critics allows a user to interactively refine an abstract diff template to be used.
chianti groups related code changes at a coarse granularity using predefined rules.
to ourknowledge none of these were evaluated with a user study unlike ours .
automating systematic edits.
andersen et al.
propose generic patch inference which takes a set of example program transformations and generate a generic patch to automate similar edits to multiple locations .
libsync recommends similar api usage adaptation patterns but does not automate complex edits .
sydit takes a single code change as input and replicates similar change to a user provided target .
lase uses multiple change examples to automate similar changes to multiple code fragments .
however these approaches do not provide users interactivity and flexibility to tune change templates.
in the comparison between critics and our prior work lase section v we show that this interactive feature ofcritics allows users to achieve high accuracy within a few iterations.
this paper makes a unique contribution of conducting two rigorous user studies to assess the effectiveness of critics during peer code reviews.
the above prior work on automated systematic editing was not evaluated using user studies.
the demonstration paper on critics describes the user interface features of critics and does not include any technical algorithm description and user studies .
vii.
c onclusion we present critics a novel approach for searching systematic changes and detecting potential anomalies during peer code reviews.
it takes as input a selected sub region of diff patch and allows a reviewer to customize a change template by interactively generalizing the ast edits and surrounding context.
a user study at salesforce.com shows that after using critics to investigate their own team s patches all six participants said they would like critics to be integrated into their current code review environment collaborator .
the participants saw the benefit of using critics in detecting missing or inconsistent updates which is difficult to find using their current code review tool.
they also thought its interactive template configuration and search feature was appropriate for developers without deep knowledge of the codebase to gradually learn about the codebase.
the lab study shows that human subjects could answer questions about systematic changes .
more correctly and .
faster on average with the assistance of critics in comparison to the baseline use of eclipse diff.
these results indicate that critics should help developers comprehend an underlying latent structure of a diff patch and locate missed or inconsistent updates during peer code reviews.
acknowledgment the authors would like to thank anonymous participants from salesforce.com and university of texas at austin for their participation in the user study and their valuable insights and feedback.
this work was supported in part by national science foundation under grants ccf ccf1149391 shf cns and a google faculty award.