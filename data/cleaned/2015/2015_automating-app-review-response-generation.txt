automating app review response generation cuiyun gao jichuan zeng xin xia david lo michael r. lyu irwin king department of computer science and engineering the chinese university of hong kong hong kong china faculty of information technology monash university australia school of information systems singapore management university singapore cygao jczeng lyu king cse.cuhk.edu.hk xin.xia monash.edu davidlo smu.edu.sg abstract previous studies showed that replying to a user review usually has a positive effect on the rating that is givenby the user to the app.
for example hassan et al.
foundthat responding to a review increases the chances of a userupdating their given rating by up to six times compared to not responding.
to alleviate the labor burden in replying to the bulk of user reviews developers usually adopt a template basedstrategy where the templates can express appreciation for usingthe app or mention the company email address for users to followup.
however reading a large number of user reviews every dayis not an easy task for developers.
thus there is a need for more automation to help developers respond to user reviews.
addressing the aforementioned need in this work we propose a novel approach rrgen that automatically generates reviewresponses by learning knowledge relations between reviews andtheir responses.
rrgen explicitly incorporates review attributes such as user rating and review length and learns the relationsbetween reviews and corresponding responses in a supervised way from the available training data.
experiments on apps and review response pairs highlight that rrgen out performs the baselines by at least .
in terms of bleu an accuracy measure that is widely used to evaluate dialogueresponse generation systems .
qualitative analysis also confirmsthe effectiveness of rrgen in generating relevant and accurate responses.
index t erms app reviews response generation neural machine translation.
i. i ntroduction mobile apps are software applications designed to run on smartphones tablets and other mobile devices.
they alreadyserve as an integral part of people s daily life and continuouslygain traction over the last few years.
the apps are typicallyavailable from app stores such as apple s app store and google play.
these app stores allow users to express their opinions to apps by writing reviews and giving ratings.
userexperience determines if users will keep using an app or unin stall it possibly posting favorable or unfavorable feedbacks.for example a survey in reported that users chose to leave a rating or review after a negative experience and only users would consider downloading an app witha star rating.
to compete with the bulk of the apps offeringsimilar functionalities ensuring good user experience is crucialfor app developers.
app reviews act as one direct communication channel between developers and users delivering users instant ex perience after their interactions with apps.
analysis on appreviews can assist developers in discovering in a timely mannerimportant app issues such as bugs to fix or requested features for app maintenance and development .
currently both apple s app store and google play provide a review responsesystem for developers to manually respond to a review afterwhich the corresponding user who posted the review will be notified and have the option to update their reviews .
in the response developers can talk about the roadmap aboutusers proposed feature requests explain the usage of appfunctionalities or just thank users for their shared opinions.
empirical studies that analyze the interactions between users and developers demonstrate that responding touser feedback in a timely and accurate manner can enhance app development and improve user experience.specifically nayebi et al.
automatically summarized userrequests which was proven to shorten the cycle between issueescalation and developers fix.
mcilroy et al.
observed that users change their rating .
of the time following a developer response.
hassan et al.
found that developers of34.
of the apps they analyzed respond to at least one review and also confirmed the positive effect of the responses onrating change.
for example they discovered that the number of users who increases their ratings after receiving a response are six times more than those who receive no response.
appdevelopers can also solve of the reported issues withoutdeploying an update.
in spite of the benefits of the review response mechanism due to the large and ever increasingnumber of reviews received daily many reviews still did notreceive timely response .
this highlights the necessityand importance of automatic response generation which is thefocus of our work.
dialogue generation has been extensively studied in the natural language processing field for facilitating social conversations e.g.
the microsoft xiaoice chatbot .
such work is generally grounded in the basic rnn encoder decoder model or neural machine translation model ab breviated as nmt where the context and corre sponding response are regarded as source and target sequencesrespectively.
the rnn encoder decoder model is an endto end learning approach for automated translation.
it has been applied to a number of software engineering tasks suchas producing a sequence of apis given a natural languagequery parsing natural language into machine interpretablesequences e.g.
database queries generating commit messages according to code changes and inferring variable types based on contextual code snippets .however the applicability of the nmt model for app review ui .
oufsobujpobm pogfsfodf po vupnbufe 4pguxb sf ohjoffsjoh authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
response generation has not been studied.
to fill in this gap we explore the usability of the nmt model in the app review response dialogue scenario here by regarding user reviews andthe corresponding replies as the source and target sequencesrespectively.
directly applying the nmt model to app dialogue generation may not be appropriate since the app review responsedialogues and social conversations are different in many ways.first the purpose of app dialogues is to further understandusers complaints or solve user requests while social conver sations are mainly for entertainment purpose.
this implies thatapp reviews require more accurate and clearer response .second users sentiment expressed in reviews should beprecisely identified.
although reviews contain the informationof star ratings the ratings and actual emotions may not betotally consistent .
for example one user may write positive feedback like great but only give one star rating.
third app reviews are generally short in length and usuallywith only one round of dialogue.
according to hassen etal.
.
of the app dialogues end after one iteration.such limited context increases the difficulty of generating aconcise response.
in this paper we propose an improved nmt model named rrgen for accurate review response gen eration.
we extend basic nmt by incorporating review specific characteristics e.g.
star ratings and review lengths to capture user s senti ment and complaint topics.
to evaluate the effectiveness of our model we collected review response pairs from 58popular apps published on google play.
for a comprehensivecomparison besides the basic nmt model we also choose the state of the art approach in commit message generationbased on code changes named nngen as one baselinemodel.
because nngen adopts basic information retrieval technique which is commonly used in traditional dialogue generation tasks and claims better performancethan the basic nmt model.
our experimental results showthat rrgen significantly outperforms the baseline models by67.
in terms of bleu score an accuracy measure that is widely used to evaluate dialogue response generation systems .
human evaluation done through a userstudy also indicates that rrgen can generate a more rele vant and accurate response than nngen.
besides reportingthe promising results we investigate the reason behind the superior performance of our model and the key constraints on automatic response generation.
the main contributions of our work are as follows to our knowledge we are the first to consider the problem of automatic review response generation and propose adeep neural network technique for solving the problem.we propose a novel neural machine translation model rrgen to learn both topics and sentiments of reviews for a accurate response generation.
the accuracy of rrgen is empirically evaluated using a corpus of more than thousand real life review1available at pairs.
a user study was also conducted to verifyrrgen s effectiveness in generating reasonable reviews.
paper structure.
section ii illustrates the background of review response system and neural encoder decoder model.section iii presents our proposed model for user reviewresponse generation.
section iv and section v describe ourexperimental setup and the quantitative evaluation results.section vi details the results of a human evaluation of ourproposed model.
section vii discusses the advantages limita tion and threats of our work.
related work and final remarksare discussed in section viii and section ix respectively.
ii.
b ackground our work adopts and augments advanced techniques from deep learning and neural machine translations .
inthis section we introduce the user developer dialogue anddiscuss the background of these techniques.
a. user developer dialogue figure depicts an example of the user developer dialogue of the ted app in google play.
a user initiates the dialogueby posting a review including a star rating for an app.user reviews convey valuable information to developers such as major bugs feature requests and simple complaints or praise about the experience .
as encouraged by the appstore responding to feedback in a timely and consistentmanner can improve user experience and an app s ranking.for example the review in fig.
was complaining about theunclear functionality usage related to adding video subtitles .
the ted developer then responded with detailed steps for putting subtitles and later the user changed the star rating tofive.
generally developers could not reply to all app reviews due to their limited time and efforts and also a large number ofreviews.
as studied by hassan et al.
developers respondto .
of the collected user reviews and they tend to replyreviews with low ratings and long contents.
the app storealso suggests developers to consider prioritizing reviews with the lowest star ratings or those mentioning technical issues for responding .
however ranking reviews for developers reply is out of the scope of this work and the related studiescan be found in .
we focus on alleviating the manuallabor in responding to feedback and aim at automating the process.
moreover since .
of the app dialogues end after one round in this study we concentrate on one iterationof user review reply.
b. rnn encoder decoder model the rnn encoder decoder model is an effective and standard approach for neural machine translation and sequence to sequence seq2seq prediction.
in general the rnn encoder decoder models aim at generating a targetsequence y y y2 ... yty given a source sequence x x1 x2 ... xtx wheretxandtyare sequence lengths of the source and target respectively.
fig.
illustrates an overallarchitecture of the rnn encoder decoder model.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
february february 2019hey how do you put subtitles on videos?
i get a hard time understanding english without subtitles even if i know how to speak it.
thanks!
will give stars if you can help me.
to use subtitles on the android app open the talk g92 g82 g88 g182 g71 like to watch g177 tap the play arrow g177 tap the g179 g85 g72 g71 g78 g72 g92 g69 g82 g68 g85 g71 g180 icon at the bottom of the video page g177 choose your language g177 return to the talk if g92 g82 g88 g182 g85 g72 trying to add subtitles to a download follow the above steps first before you download the video.
ihope this helps!
fig.
example of ted developer s response to one user review.
the red underlines highlight some topical words of the dialogue.
lot of ad !sorry for the inconvenience s g22 g135 g147 g151 g135 g144 g133 g135 g3 g8 g144 g133 g145 g134 g135 g148 g22 g135 g147 g151 g135 g144 g133 g135 g3 g7 g135 g133 g145 g134 g135 g148 .
g2205 g2869 g2205 g2870 g2205 g2871 g2205 g2872 g2190 g2869 g2190 g2870 g2190 g2871 g2190 g2872 g2190 g1314 g2869 g2190 g1314 g2870 g2190 g1314 g2871 g2190 g1314 g2872 g2190 g1314 g2873 g2190 g1314 g2874 g2205 g1314 g2869 g2205 g1314 g2870 g2205 g1314 g2871 g2205 g1314 g2872 g2205 g1314 g2873 g2205 g1314 g2874 g2185 g2206 g483 g2207 g483 sorry for theinconvenience .
s fig.
an overall architecture of rnn encoder decoder model.
to do so an encoder first converts the source sequence xinto a set of hidden vectors h1 h2 ... htx whose size varies regarding the source sequence length.
the con text representation cis generated using a recurrent neural network rnn .
the encoder rnn reads the sourcesentences from the first token until the last one where h t f ht wt andc htx.
here wtis the word embedding of the source token xt where word embeddings are distributed representations of words in a continuous vector space and trained with a text corpus.
the fis a non linear function that maps a the word embedding wtinto a hidden statehtby considering the previous hidden state ht .
then the decoder which is also implemented as an rnn generates one word ytat each time stamp tbased on the hidden stateh prime tas well as the previous predicted word yt pr yt yt ... y1 c g h prime t yt c wheregis a non linear mapping function and the context vectorcreturned by the encoder is set as an initial hidden state i.e.
h prime c. the decoder stops when generating the end of sequence word s .
the two rnn encoder decoder models are jointly trained to maximize the conditional log likelihood l max 1 nn summationdisplay i 1logp yi xi where is the set of the model parameters e.g.
weights in the neural network and each xi yi is a source sequence target sequence pair from the training set.
the p yi xi denotes the likelihood of generating the i th target sequence yigiventhe source sequence xiaccording to the model parameters .
through optimizing the loss function using optimization algorithms such as gradient descent the optimum values can be estimated.
c. attention mechanism a potential issue with the rnn encoder decoder model is that a neural network needs to compress all the necessary information of a source sequence into a fixed length vector.
toalleviate this issue bahdanau et al.
proposed the attentionmechanism to focus on relevant parts of the source sequenceduring decoding.
we use the attention mechanism in our work because previous studies prove that attention based models can better capture the key information e.g.
topicalor emotional tokens in the source sequence.
fig.
shows agraphical illustration of the attentional rnn encoder decodermodel.
during decoding besides the hidden state h prime tand previous predicted word yt an attention vector atis also involved for generating one word ytat each time stamp t pr yt yt ... y1 c g h prime t yt c at .
the attention vector atdepends on the relevance between the hidden state h prime tand the encoded source sequence h1 ... htx at tx summationdisplay j 1 tjhj wheretxis the length of the source sequence and the attention weight tjmeasures how helpful the j th hidden state of the source sequence hjis in predicting next word ytwith respect to the previous hidden state h prime t .
in this way the decoder decides parts of the source sentence to pay attention to.
g2190 g2869 g2190 g2870 g2190 g2871 g2190 g2872 g2190 g1314 g2869 g2190 g1314 g2870 g2205 g1314 g2869 g2205 g1314 g2870 g2009 g2869 g2869 g4 g150 g150 g135 g144 g150 g139 g145 g144 g3 g25 g135 g133 g150 g145 g148 g2009 g2869 g2870 g2009 g2869 g2871 g2009 g2869 g2872 g2183 g2869 g1855 fig.
graphical illustration of the attentional rnn encoder decoder model.
the dotted line without arrow marks the division between theencoder left and decoder right and the dotted lines with arrowsindicate that we simplify the rnn encoder decoder steps forclearness.
iii.
rrg en a ppreview response genera tion in this section we present the design of rrgen that extends the basic attentional rnn encoder decoder model for app review response generation.
we regard user reviews asthe source sequence and developers response as the targetsequence.
fig.
shows an example of the rnn encoder decoder model for generating a sequence of tokens as adeveloper s response from a sequence of tokens that constitute a user review lot of ad!
.
for accurately capturing the topics authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
user review repository g39 g72 g89 g72 g79 g82 g83 g72 g85 g86 g182 g3 response g155 user reviewsrating sentimentlengthcategory g4 g3 g6 g145 g143 g146 g145 g144 g135 g144 g150 g28433 g4 g150 g150 g148 g139 g132 g151 g150 g135 g149 g28434 g14 g3 g6 g145 g143 g146 g145 g144 g135 g144 g150 g523 g14 g135 g155 g153 g145 g148 g134 g149 g524keywordlot ofad !
encoder o o c o g2205 g2869 g2205 g2870 g2205 g2871 g2205 g2872 g2193 g2869 g2193 g2870 g2193 g2871 g2193 g2872 g2204 g2869 g2204 g2870 g2204 g2871 g2204 g2872 g2206 g483 g2244 g483sorry for s sorry forthedecoder attention vector g2207 g483 g485 g485 g485 s .
modeltraininguser review review responsea.
data preparationb.
data parsing c. model training d. response generation g2028 g1864 g1870 g1871 g2244 g2028 g1864 g1870 g1871 g2206 a overall architecture of rrgenlot ofad !
encoder o o c o g2205 g2869 g2205 g2870 g2205 g2871 g2205 g2872 g2193 g2869 g2193 g2870 g2193 g2871 g2193 g2872 g2204 g2869 g2204 g2870 g2204 g2871 g2204 g2872 g2206 g483 g2244 g483sorry for s sorry forthedecoder g4 g150 g150 g135 g144 g150 g139 g145 g144 g3 g25 g135 g133 g150 g145 g148 g2207 g483 g485 g485 g485 s .
g14 g3 g6 g145 g143 g146 g145 g144 g135 g144 g150 g2028 g1864 g1870 g1871 g2190 g3099 g2190 g3039 g2190 g3045 g2190 g3046 g16 g15 g19 g16 g15 g19 g4 g3 g6 g145 g143 g146 g145 g144 g135 g144 g150 g2185 g2185 g4593 g2190 g2869 g2190 g2870 g2190 g2871 g2190 g2872 g16 g15 g19 b detailed structure of rrgen fig.
structure of the review response generative model.
and sentiment embedded in the input review sequence we explicitly incorporate both high level attributes e.g.
app cat egory review length user rating and sentiment and keywordsinto the original rnn encoder decoder model.
we adopt thekeywords provided by di sorbo et al.
which were manuallycurated to identify topics e.g.
gui contents pricing etc.
commonly covered in user reviews.
we refer to the high levelattributes and keywords extracted from a review as its a and k components respectively.
figure a shows the overall architecture of our rrgen model.
rrgen mainly consists of four stages data prepara tion data parsing model training and response generation.
we first collect app reviews and their responses from google play and conduct preprocessing.
the preprocessed data are parsedinto a parallel corpus of user reviews and their corresponding responses during which the two components of reviews are also extracted and processed.
based on the parallel corpus ofapp reviews and responses we build and train a generativeneural model with the two pieces of extracted information high level attributes and keywords holistically considered.the major challenge during the training process lies in the effective consideration of both components of reviews for effective response generation.
in the following we will introducethe details of the rrgen model and the approach we proposeto resolve the challenge.
a. component incorporation here we elaborate on how we incorporate the two components including high level attributes or a component and keywords or k component into rrgen.
the detailed structure of rrgen is displayed in fig.
b .
a component the a component contains four attributes of one user review app category review length user rating and sentiment.
we choose app category considering that appsof different categories generally contain different functionalities and major topics delivered by their reviews would be different.
review length is involved because it is an importantindex of whether the review is informative or not i.e.
longerreviews usually convey richer information .
we takeuser rating into account since it can directly impact the response style of developers e.g.
expressing an apology fornegative feedback or thanks for the positive feedback.
as userratings may not be consistent with the sentiment described by the reviews we also regard the predicted actual usersentiment as one attribute.
review attributes such as app category review length and user rating are easy to acquire.
for predicting user sentiment we exploit sentistrength a lexical sentiment extractiontool specialized in handling short and low quality texts.
we first divide review text into sentences and then assigns a positive integer value in the range and a negative integervalue within the range based on stentistrength toeach sentence because users may express both positive andnegative sentiments in the same sentence.
a higher absolute sentiment score indicates that the corresponding sentiment isstronger.
following guzman and maalej s work when the sentence s negative score multiplied by .
is less than thepositive score we assign the sentence a negative sentimentscore otherwise the sentence is assigned a positive sentimentscore .
the sentiment of an entire review is computed based on the rounded average sentiment scores of all sentences in the review.
we denote the app category review length user rating and sentiment score of the source sequence xas l r and s respectively.
to incorporate these attributes into rrgen we first represent the attribute values into continuous vectorsvia multilayer perceptions mlps i.e.
the conventional fullyconnected layer .
we call the vector representations ofthe attributes as attribute embeddings.
the embedding of appcategory is defined as h tanh w emb ... n wherew is the matrix of trainable parameters in the mlp andh g ... n are the embedding vectors of all individual categories.
emb rn is the vector representation of andemb indicates one general embedding layer to obtain authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
the latent features of .
similarly we obtain the embedding vectors for user rating rand sentiment score s hr tanh wremb r r ... nr hs tanh wsemb s s ... ns wherehrandhsare embeddings for the attribute values rand s respectively.
for review length l we convert the continuous variable into its categorical form l primeusing the pandas package2 before feeding into mlp .
hl tanh wlemb l prime l prime ... nl.
we integrate the embedded attribute values at review level by concatenating together with the last hidden state cof the encoder i.e.
c prime tanh wh where is the concatenation of these two vectors.
whis the matrix of trainable parameters in the mlp and his the number of hidden units.
the output vector c primeindicates the final hidden state or context vector of the encoder.
for simplicity we assume that the dimensions of all attribute embeddings i.e.
h hl hr andhs are the same.
k component k component specifically refers to keywords in the input review sequence since the keywords generally relate to the review topic or sentiment and arepotentially helpful to learn which word to attend to duringresponse generation.
t able i one example of topic keywords pair in the keyword dictionary provided by di sorbo et al.
.
topic keywords guiscreen trajectory button white background interface usability tap switch icon orientation picture show list category cover scroll touch clink snap underside backside witness rotation ui gui ... we adopt the keyword dictionary provided by di sorbo et al.
.
di sorbo et al.
summarize topics3commonly covered by user reviews based on manual analysis and build a keyword dictionary based on wordnet to extract relatedwords for each topic.
one topic keywords pair can be seenin table i. di sorbo et al.
utilized the dictionary to predicttopics of user reviews and achieved classification accuracy this indicates the semantic representativeness of these keywords for each topic.
this motivates us to use the keywords too in our work.
to explicitly integrate the keyword information into rrgen we establish a keyword sequence 2 ... tx for each input review sequence x. specifically for the token xtinx we check the keyword dictionary to determine its subordinate topic i.e.
t. for example as shown in fig.
b the keyword sequence corresponding to the source sequence 3the topics are app gui contents pricing feature improvement updates versions resources security download model and company.
lot of ad !
i s o o c o where we denote the keyword symbol for the token ad a s c since ad i s one keyword for topic contents .
the keyword symbols of nontopical words e.g.
of are labeled as o .
we finally integrate the embedded keyword sequence and the sourcesequence at token level via mlp k tanh wkemb ... nk vt tanh wv wherek ... nkare the embedding vectors of all individual keyword symbols wkandwvare the matrices of trainable parameters in the mlps and vtis the keywordenhanced embedding for the t th token xtin the source sequence.
the dimension of k is similar to the attribute embeddings in the a component e.g h .
b. model training and testing training we adopt the attention mechanism described in section ii c for review response generation.
the rnn hasvarious implementations we use bidirectional gated recurrentunits grus which is a popular rnn encoder decodermodel and performs well in many tasks .
all grushave hidden units in each direction.
each attribute in the two components is encoded into an embedding with dimension at i.e.
the embedding size of h hl hr hs andk .
word embeddings are initiated with pre trained dimensionalglov e vectors .
we set the maximum sequence length at200 and save the model every batches.
we discuss thedetails of parameter tuning in section v c. the training goalis cross entropy minimization based on equ.
l max 1 nn summationdisplay i 1logp yi xi l r s i where l r s icorrespond to the app category review length user rating sentiment score and keyword sequence ofthei th source sequence x i respectively.
the whole model is trained using the minibatch adam a stochastic optimiza tion approach and automatically adjusting the learning rate.
we set the batch size i.e.
number of review instances per batch as .
for training the neural networks we limit the sourceand target vocabulary to the top words that are mostfrequently used in user reviews and developers responses.
for implementation we use pytorch an open source deep learning framework.
we train our model in a server withone nvidia tit an v gpu with 12gb memory.
the training lasts hours with two epochs.
testing we evaluate on the test set when the trained model after one batch shows an improvement on the validation set regarding bleu score .
we take the highest test scoreand corresponding generated response as the evaluation result.we use the same gpu as we used in training.
the testingprocess took around minutes.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
iv .
e xperiment al setup a. data preparation data collection we select the subject apps for collecting the user developer dialogues from google play based onapp popularity.
we focus on popular apps since they contain more reviews than unpopular apps which should facilitate enough data for studying user developer dialogues.
we selectthe top free apps in according to app annie an app analytics platform as these apps were top apps twoyears prior to the start of our study.
the decision was made to ensure the studied apps had enough reviews to collect and also avoid the influence of an app s price on developers reviewresponse behavior .
we further remove the apps that are nolonger available in google play on april and those withfewer than user reviews which leaves us with appsthat match our selection criteria.
for each selected app we created a google play crawler to collect user developer dialogues from google play specifically including review title review text review post time user name rating developer response time and the text in the developerresponse.
we run our crawler from april to april .during that period we collected reviews for the 72apps.
we find that apps and collected reviews have received a response from the app developer.
table ii describes the statistics of the subject apps which belong to15 app categories.
data preprocessing since app reviews are generally submitted via mobile terminals and written using limitedkeyboards they contain massive noisy words such as repet itive words and misspelled words .
we first convert allthe words in the reviews and their response into lowercase and adopt the method in for lemmatization.
we thenreplace all digits with digit .
we also detect email address and url with regular expressions and substitute them into email and url respectively.
besides we build an app list containing all the app names and a user list with all the user names.
for the app names and user names mentioned in the dialogue corpus we replace them with app and user respectively.
we finally adopt the rule based methods based on to rectify repetitivewords and misspelled words.
after removing empty review texts or review texts with only one single alphabet we obtained review response pairs.
we randomly split the datasetby as the training validation and test sets i.e.
there are279 and pairs in the training validation and test sets respectively.
t able ii mean and five number summary of collected data for every studied app.
avg.
min.
1st qu.
med.
3rd qu.
max.
reviews per app reviews with5 165responses per app b. similarity measure bleu bleu is a standard automatic metric for evaluating dialogue response generation systems.
it analyzes the co occurrences of n grams in the ground truth yand the generatedresponses y wherencan be or .
bleu n where nis the maximum length of n grams considered measures the proportion of co occurrences of nconsecutive tokens between the ground truth yand generated response y. the most commonly used version of bleu uses n i.e.
bleu .
also bleu is usually calculated at thecorpus level which is demonstrated to be more correlated withhuman judgments than other evaluation metrics .
thus weuse corpus level bleu as our evaluation metric.
c. baseline approaches we compare the performance of our model with a random selection approach the basic attentional rnn encoder decoder nmt model as introduced in section ii c and a state of the art approach for code commit message generation namely nngen.
in the following we elaborate on the first and last baselines random selection this is a strawman baseline.
this baseline randomly picks a response in the training set and uses it as a response to a review in the test set.
nngen we choose nngen as one comparing approach since it is demonstrated to perform better than the basic nmt model in producing code commit message based on code changes.
nngen leverages the nearest neighbor nn algorithm to retrieve the most relevant developer response.based on the training set and the new user review nngen firstrepresents them as vectors in the form of bags of words and then selects the top five training user reviews which present highest cosine similarities to the new review.
afterthat the bleu score between the new review and eachof the top five training reviews is computed.
nngen finallyregards the response of the training review with the highestbleu score as the result.
v. e v alua tion using anautoma tic metric in this section we conduct quantitative analysis to evaluate the effectiveness of rrgen.
in particular we intend to answerthe following research questions.
rq1 what is the accuracy of rrgen?
rq2 what is the impact of different component attributes on the performance of rrgen?
rq3 how accurate is rrgen under different parameter settings?
a. rq1 what is the accuracy of rrgen?
the comparison results with baseline approaches are shown in table iii.
we can see that our rrgen approach outperformsall the three baselines.
specifically the result that random se lection approach achieves the lowest bleu score .
indicates that learning knowledge from existing review response pairs can facilitate generating the response for a newly arrivedreview.
also we find that the nmt model performs better thanthe non deep learning based nngen model which shows anincreasing rate of .
in terms of bleu score.
this is opposite to the conclusion achieved by liu et al.
.
one possible reason is that the tasks between ours and liu authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
et al.
s are different i.e.
liu et al.
aim at producing texts based on code while we focus on generating textsfor dialogues and modeling code is different from modelingdialogue texts .
the higher bleu score of theproposed rrgen model than that of the nmt model explainsthat the response generated by the rrgen model is moresimilar to developers response than the response generated bythe nmt model.
we then use wilcoxon signed rank test for statistical significance test and cliff s delta or d t o measure the effect size .
the significance test result p value .
and large effect size on bleu scores d .
of rrgen and nmt confirm the superiority of rrgen over nmt.
t able iii comparison results with baseline approaches.
the pn indicates the n gram precision when comparing the ground truth and generated responses.
statistical significance results are indicated with p value .
.
approach bleu p1 p2 p3 p4 random .
.
.
.
.
nngen .
.
.
.
.59nmt .
.
.
.
.
rrgen .
.
.
.
.
b. rq2 what is the impact of different component attributes on the performance of rrgen?
to evaluate the effectiveness of different component attributes in response generation we perform contrastive exper iments in which only a single component attribute is added tothe basic nmt model .
table iv shows the results.
unsurprisingly the combination of all component attributes gives the highest improvements and all the attributes arebeneficial on their own.
user sentiment gives the lowestimprovement .
in terms of bleu score comparingto the nmt model while the app category yields highestimprovement .
in terms of bleu score .
also theresult that user rating contributed more on the bleu scorethan user sentiment indicates that user ratings would be more helpful in review response generation.
moreover the gain from different component attributes is not fully cumulativesince the information encoded in these component attributesoverlaps.
for instance both the user sentiment and user ratingattributes encode the user emotion expressed by user reviews.
also the keywords in the k component highlights the words belonging to the same topics and such information may bealready captured by the word embeddings .
t able iv contrastive experiments with individual component attributes.
approach bleu p1 p2 p3 p4 nmt .
.
.
.
.
a component app category .
.
.
.
.
review length .
.
.
.
.
rating .
.
.
.
.
sentiment .
.
.
.
.
k component keyword .
.
.
.
.
rrgen .
.
.
.
.04dimension of word embeddingbleu p1 p2 p3 p4 .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
a different dimensions of word embedding.
hidden unitsbleu b different numbers of hidden units.
bleu attribute dimension c different dimensions of component attribute embedding.
fig.
bleu scores of different parameter settings.
c. rq3 how accurate is rrgen under different parameter settings?
we also quantitatively compare the accuracy of rrgen in different parameter settings.
we analyze three parameters that is the dimension of word embeddings the number ofhidden units and also the dimension of component attributeembeddings.
we vary the values of these three parameters andevaluate their impact on the bleu scores.
figure shows the influence of different parameter settings on the test set.
we choose the four different dimensionsof word embeddings provided by glov e i.e.
and and the result in fig.
a indicates that the rrgen model achieves the best bleu score when the wordembedding size equals to .
for the number of hidden units we can see that more hidden units may not be helpful forimproving accuracy as shown in fig.
b .
rrgen generatesthe best result when we define the number of hidden units as .
fig.
c shows that the accuracy of rrgen also changes along with the variations of attribute embedding dimension.the optimum dimension of attribute embedding is around .
vi.
h uman ev alua tion in this section we conduct a human evaluation to complement the evaluation in section v that uses bleu since bleuonly measures the textual similarity between the generatedresponses and ground truth while the human study can evaluateusers general satisfaction on the responses.
a. survey procedure we conduct a human evaluation to evaluate the outputs of rrgen and compare rrgen with nmt and nngen.
weinvite participants including phd students two master students one bachelor and three senior researchers all of whom are not co authors and major in computer science.among the participants of them have industrial experiencein software development for at least a year and eight of themhave developed one or two mobile apps.
each participantis asked to read user reviews and assess the responses generated by nngen nmt rrgen and the app developers.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
b. survey design we randomly selected review response pairs in total divide them evenly into four groups and make a questionnairefor each group.
we ensure that each review response pair isevaluated by five different participants.
in our questionnaire each question presents the information of one review responsepair i.e.
its user review the developer s response its outputfrom nngen and its responses generated by nmt andrrgen.
the order of the responses from nngen nmt rrgen and official developers is randomly decided for eachquestion.
inspired by all the response types are evaluated considering three aspects grammatical fluency relevance and accuracy .
we provided the following instructions at the beginning of each questionnaire to guide partic ipants the grammatical fluency or readability measures the degree of whether a text is easy to understand the metric relevance relates to the extent of topical relevance between the user review and response and the metric accuracy estimates the degree of the response accurately answering auser review.
all the three metrics are rated on a scale for fully satisfying the rating scheme for completely not satisfying therating scheme and for the borderline cases since a pointscale is widely used in prior software engineering studies .
besides the three metrics each participant is asked to rank responses generated by the three tools and those fromdevelopers based on their preference.
the preference rank score is rated on a scale for the most preferred .
fig.
6shows one question in our survey.
participants do not knowwhich response is generated by which approach or whether it is written by developers and they are asked to enter to score each response separately.
c. results we obtained sets of scores from the human evaluation.
each set contains scores for the three metrics regarding theresponse of nngen nmt rrgen and official developersrespectively and also a ranking score of the four typesof responses.
the median time cost for one participant tocomplete his her questionnaire is .
hour with an averagevalue of .
hours.
we compute the agreement rate on the thepreference ranks given by the participants and find that of the total review response pairs received at least three identical preference ranks from the participants.
specifically and were given the same preference ranks bythree four and five participants respectively.
this indicatesthat the participants achieved reasonable agreement on theperformance of the generated responses.
table v shows the results of human evaluation.
bold indicates top scores.
as expected we can see that the response from official developers is preferred over the three approaches outputs which can be observed given the example in fig.
.specifically the developers response response is morerelevant to the user review and provides more accurate solutionto the app issue e.g.
reduced picture clarity complaineduser review picclarityisreduced g87 g75 g68 g87 g182 g86whygiveonly digit star.
response hello user thanksforyourhonestreview!youcaneasilysolve thisissuebygoing toyour g31 g68 g83 g83 g33 g182 g86settingmaximagesizeandclickingonthepreferableimagesize.iftheproblemstillcontinues pleaseemailusat email .
response hey user thanksforyourreview.weapologizefortheissueyou arefacingandweareheretohelp.pleasesendourteamyourdevicemodel app versionand app osversionto email .oursupportteamwillfurtherassistyou onthematter.
response hi g44 g182 g80dianafrom app .couldyoutell app whatkindofads youdonotlike?whatarethelocationsofthem?
response hi user thanksforyourreview.wearereallysorrythatyoufeel thiswayabouttheapp.
note this is a photography app and the user rating is one star.
in the sentences the symbols digit user email and app denote one digit user name email address and app name respectively.
very dissatisfied very satisfied g53 g72 g86 g83 g82 g81 g86 g72 g3 g20 g182 g86 g3 g41 g79 g88 g72 g81 g70 g92 g53 g72 g86 g83 g82 g81 g86 g72 g3 g20 g182 g86 g3 g53 g72 g79 g72 g89 g68 g81 g70 g72 g53 g72 g86 g83 g82 g81 g86 g72 g3 g20 g182 g86 g3 g36 g70 g70 g88 g85 g68 g70 g92 your preference rank of the four responses ............ fig.
a question in our survey.
response and correspond to the developer s response the outputs of our rrgen model and the responses produced by nngen and nmt respectively.
participants do not know the order of the four types of response during the survey and are asked to score the three metrics for each response type.
thetwo dot symbols indicate the simplified grading schemes of response2 and .
the words highlighted in yellow are topical words in thedescriptions and the double underlined words mean they are topically irrelevant to the user review.
by the user.
in terms of grammatical fluency however the rrgen model does quite well achieving scores that arerather close to those of developers responses as shown in table v. in addition we see that our rrgen model performssignificantly better across all the metrics in comparison to the baseline approaches which further indicates the effectivenessof rrgen in review response generation.
t able v human evaluation results for review response generation.
bold indicates top scores.
two tailed t test results are shown for our rrgen approach compared to nngen and nmt statisticalsignificance is indicated with p value .
.
.
grammatical fluencyrelevance accuracypreference rank nngen .
.
.
.339nmt .
.
.
.
rrgen .
.
.
.
developer .
.
.
.
vii.
d iscussion a. why does our model work?
we have identified three advantages of rrgen that may explain its effectiveness in review response generation.
observation rrgen can better capture salient topics of user reviews.
unlike bag of words based techniques rrgen learns review and response representations with atten tional deep learning.
characteristics of reviews such as topicalwords and word orders are naturally considered in these models .
moreover keywords that are indicative of review topics are explicitly incorporated into the deep learning model which would be helpful to better recognize the semantics ofreview and response.
for example it can learn that the review authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
user review toomanyadsandslow.
g39 g72 g89 g72 g79 g82 g83 g72 g85 g182 g86 response dearuser thanksforsupportinguc.ifyoumeantheads inwebsitethenplsmakesureyou veenabledtheadblockpowerfuladblock frommenuadblock.ifnouse plssendthespecificlinkandscreenshotofads andotherquestionviamenufeedbackpageopeninuctohelpyou.wereally appreciateyour digit starvote!niceday.
nngen sorry about that.
could you please email us email ?
tell more information relate to your problem when do you notice app is making your systemslow.alsotrycheckoutourfaq url .thankyouverymuch.
nmt hi thanksforusing app andsorryfortheads.
app isfreeweneed supportfromadstodevelopnewproductandtoimproveexistproduct.weare strive to balance user satisfaction and ads.
thus if you feel there are any inappropriate ads or any ads you hate please contact us email much appreciate.
rrgen hi dearfriendsorrytohearthat.youcanalsosendusad slinkand screenshottou3menufeedbackpageopeninuc?herewecanhelpyousolve theproblemfasterok?waitforyourinformationand digit starvote!niceday!
a first example.
user review itsuckssomuchthatmyphonealmostoverheat.thisbattery saverisstupidanddumb.
g39 g82 g81 g182 g87wasteurtime.
g39 g72 g89 g72 g79 g82 g83 g72 g85 g182 g86 response hi user .thanksforyourfeedbackandnowweare workingonthecoolertoimprovethisissue.couldyoupleasesendyourdetail problemtoouremail email sowhenwefigureoutthesolutionwecancontact youimmediately?
nngen hi thanks for trying clean master.
we hope you have a good experiencewithourappifyouhaveanyproblemorsuggestionyoucancontact mevia email .
g44 g182 g80readytohelp.
nmt dearuserwearesorryforads.however app isafreeapplication.to keepitfreewhileofferagreatservice weneedtopublishadsasanalternative source of income.
if you see any ads that are inappropriate please take a screenshotofthemandsendthroughthefeedbackoptionfindintheapplication.
rrgen dear user sorry for the inconvenience.
we notice you have some concerns about battery.
could you tell us what happened and provide some informationincludingscreencontrastscreensh otsofbatterystatusofyourphone settinggt.batterygt.
?pleasesendusviaemail email muchappreciated.
b second example.
fig.
two sample review response pairs where rrgen can generate responses with more related topic.
the meanings of the highlightedwords and double underlined words are the same as fig.
.
too many ads and slow is talking about the ad issue and generate response related to the in app ads as shown in fig.
a .
in the example in fig.
b rrgen can well learn that thereview is discussing about the battery issue while nmt infersthe topic wrongly.
for the bag of words approach nngen itmay be easily confused by non topical words.
for the example in fig.
nngen i.e.
response focuses more on the words give digit and star and selects the closest review if it has no advertising i will give digit star which has totally different topics comparing to the given review.
observation rrgen can generate responses with more accurate sentiment.
user sentiment can be explicitly e.g.
the horrible word in fig.
a or implicitly e.g.
the slow word in fig.
a reflected in user reviews.
for the bag of words approach the effect of sentiment words may beweakened by other words since their occurrence frequencies are similar.
as can be seen in fig.
a nngen fails toinfer the negative sentiment expressed by the review and considers it as an endorsement message while rrgen canaccurately capture the negative information embedded in thereview.
another example can be found in fig.
b where bothnngen and nmt do not recognize that the positive sentiment of the given review.
without review attributes such as useruser review whathappenedtothelauncher?allmyappnamesgotvanished and there is no setting to show the name as well.
kindly help or else.
g44 g87 g182 g86 ahorribleapp.
g39 g72 g89 g72 g79 g82 g83 g72 g85 g182 g86 response dear user youcansetappnamebyfollowingstep launcher seticon thenyoucanfindtherightoptiontoshowyourappnamesup.bestregard.
nngen hi user thanksforyourawesomesupportandendorsement.letus know if you have suggestions for us to improve the app for you by email email .
nmt dearuser sorryfortheinconveniencecauseforyou.pleasesendusa note url contactsowecanfollowup.
rrgen dear user sorry for your inconvenience.
thank you for your descriptionandi llforwardyourfeedbacktoourteam.we llchecktheproblem whichyoumentionedassoonaspossible.pleasekeepusing app forthebest foryou.thankyouforyoursupport.bestregard.
a first example.
user review nicebrowserwithgreatspeedandsomanyshortcutswhichsave minetime.thankyouteamuc.theonlythingiwantyouto mode.
i have to make my note from internet only and read too much causingpaininmyeyes soitsmyhumblerequesttoyou.plzaddreadmodein nextupdate.thankyou.
g39 g72 g89 g72 g79 g82 g83 g72 g85 g182 g86 response dear friend we are so happy to get your approval!
wouldyoupleasegiveus digit star!itmeansalottous.wearewaitingfor your digit star.thanksforsupport.
nngen sorryfortheproblem.weneedyourcooperation.couldyougiveus thedetails thanks!
nmt dearfriend weapologizefortheinconvenienceyoumeet.wouldyou pleasetellusmoreinformationabouttheerrorcode?
rrgen hidearfriendthanksforsupportingourbrowser!yoursatisfactionis whatwebecaremost.weareveryeagerforyour digit starrating.thanksforsupport.
b second example.
fig.
two sample review response pairs where rrgen can generate responses with more accurate sentiment.
the words underlined in red are indicative of the description sentiments and the meanings of the highlighted and double underlined words are the same as fig.
.
ratings involved nmt also fails to ask the user to increase his her given rating.
observation rrgen can effectively capture knowledge relations between reviews and their correspondingresponses.
rrgen learns the correspondence between reviews and response mainly through the high dimensional hidden units and attention layer.
the topical words in reviews tendto produce hidden states of semantically similar words inthe rnn decoder.
fig.
visualizes the latent alignment overthe user review to help generate the response based on theattention weights tjfrom equ.
.
each column indicates the weight distribution over the user review for generating eachword.
from this we can see which words in the user reviewwere considered more important when generating the targetword in the response.
we can observe the obvious correlationsbetween the word save in the review and save in the response hd in the review and max in the response and pixel in the review and image in the response as shown in fig.
.
this illustrates that rrgen is able to build implicit relations between the topical words in reviews and corresponding responses which can help generate relevant andaccurate response given a review.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
b. post processing steps rrgen generates responses with placeholders e.g.
email url etc.
moreover rrgen may not generate perfect responses and developers may want to ver ify rrgen responses for some more sensitive cases.to partially address the above mentioned limitations wepropose several post processing steps.
first we build aplaceholder value dictionary for automatically replacing place holders e.g.
url with corresponding values e.g.
for eachapp.
second we design a quality assurance filter to automati cally detect the generated responses that require further check .
the placeholder value dictionary for each app is saved during preprocessing and for simplicity only the most commonvalue for each placeholder is saved.
we define a generated response requiring further check based on its token length l the overlapped keyword ratio with the corresponding review and also the review rating r. specifically we define responses that satisfy the following constraint i.e.
.
or l 38andr to require further check.
the thresholds are determined as follows .
is determined by following the keyword overlapping threshold in is the first quartile ofresponse token lengths in the whole dataset and the constraintfor review rating is set as such as reviews with lower ratings e.g.
tend to express users strong dissatisfaction withcertain aspects of apps .
we evaluate our solution after the above mentioned postprocessing strategy using a similar experiment setting used to produce results presented in section v a. we find that the bleu score is .
.
it is only slightly lower than thebleu score .
reported in our earlier experiment usingground truths with placeholders rather than actual values.
c. limitations although our proposed rrgen model aims at producing accurate responses to user reviews not all the reviews require responses some reviews require carefully crafted replies and some other reviews can be delegated to an automated bot.we have tried to address this issue partially by adding somepreliminary post processing steps see section vii b .
admittedly our post processing steps are not perfect.
first our preliminary post processing steps may generateresponses with inappropriate values due to the coarsely definedplaceholder value dictionary.
this issue can be improved bycreating a context sensitive dictionary for each app.
also oursimple rule based detection of responses that require furthercheck can be improved further.
for this we can learn thethresholds of the rule conditions or design new detection cri teria.
we leave the design implementation and evaluation ofa full fledged system that can route reviews to do not respond require human careful response and can be responded by an automated bot queues for future work.
as our work is the first to automate app review generation although it is not perfect it opens up way for future research to continue our study andimprove it further.d.
threats to v alidity one of the threats to validity is about the limited number of studied apps.
we studied developer responses for reviewsof free apps only.
one of the main reasons for removing non free apps is that the pricing of an app is likely to impactdevelopers response behavior .
also we only considergoogle play apps in this work because apple s app storestarted to support review response from while the featurehas been standard in google play since .
althoughour study is based on apps from various categories and largenumbers of review response pairs future work can be extendedto multiple app stores and paid apps.
the second threat to validity is about the component attributes incorporated into our proposed model.
although weinvolve both high level attributes and keywords some other characteristics such as review title length and post date which would be helpful for response generation are not considered.besides the review sentiment predicted by sentistrength might not be reliable and could influence the generatedresponse.
however accurate sentiment prediction based on re views is out of the scope of this paper and the effectiveness of stentistrength in detecting user sentiment about app features has been demonstrated in .
in the future we will explorethe impact of more review characteristics on automatic reviewresponse generation.
another threat to validity is about manual inspection in section vi.
the results of the human evaluation are impactedby the experience of the participants and their intuition of theevaluation metrics.
to reduce the errors in the manual analysis we ensure that each review response pair was evaluated by fivedifferent participants.
as our participants are mainly students they may not be representative of crm professionals whoare likely to benefit from our tools in practice .
wetry to mitigate this threat by inviting the students with at least one year of software development experience.
in addition we randomly disrupt the order of the three types of responsefor each question so that the results are not influenced byparticipants prior knowledge about the response orders.
viii.
r ela ted work a. user review mining identifying the complaint topics expressed by user reviews is the basis for user review mining .
iacob et al.
manually label reviews and discover the most recurringissues users report through reviews.
to alleviate the laborin manual labeling many studies focus on automating theprocess.
for example iacob and harrison design marafor retrieving app feature requests based on linguistic rules.maalej and nabil adopt probabilistic techniques to classify reviews.
di sorbo et al.
separately categorize user intentions and topics delivered by app reviews.
understandinguser sentiment about specific app aspects is another typicaldirection of review mining.
guzman and maalej usetopic modeling approach and stentistrength a lexical sentiment extraction tool to predict sentiment of app features.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
user reviewgenerated response by rrgen fig.
a heatmap representing the alignment between the user review left and generated response by rrgen top .
the columns represent the distribution over the user review after generating each word.
each pixel shows the weight tjof the annotation of the j th source word for thet th target word see equ.
.
a higher attention weight indicated in darker color manifests a stronger correlation between the target word and source word.
the red dotted rectangles highlight partial topical words in corresponding descriptions.
gu and kim propose sur miner to exploit grammatical structures for aspect opinion identification.
more research ofmobile review analysis can be found in .
different from these existing review analysis research we contribute to facili tating the bidirectional dialogue between users and developersinstead of analyzing only the feedback from user side.
b. analysis of user developer dialogues in app stores oh et al.
conduct a survey on smartphone users to understand how developers and users interact.
they find that most users tend to take a passive action such as uninstalling apps and the main reason for such behavior isthat these users think that their inquiries e.g.
user reviews would take long time to be responded or receive no response.mcilroy et al.
analyze reviews of free google play apps and find that .
of the apps respond to at least one review.
they also observe that users would change theirratings .
of the time following a response.
such positiveimpact of developers response is also confirmed by hassan etal.
.
although these studies do highlight the importance ofresponding to user reviews they do not provide an explicit method to alleviate the burden in the responding process which is the focus of this work.
c. short text dialogue analysis short text dialogue analysis is one popular topic in the field of natural language processing in which given a messagefrom human the computer returns a reasonable response tothe message .
short text dialogue can be formalizedas a search or a generation problem.
the former formalization is based on a knowledge base consisting of a large number of message response pairs.
information retrieval techniques are generally utilized to select the most suitable response tothe current message from the knowledge base.
the majorbottleneck for search based approaches is the creation of the knowledge base .
ritter et al.
and vinyals and le are the first to treat generation of conversational dialogas a data driven statistical machine translation smt problem.
their results show that the machine translation based approach works better than one ir approach vector space model vsm in terms of bleu score .
however generation based approaches cannot guarantee thatthe response is a legitimate natural language text.
in this work we propose to integrate app reviews unique characteristics foraccurate response generation.
ix.
c onclusion and future work replying to user reviews can help app developers create a better user experience and improve apps ratings.
due tothe large numbers of reviews received for popular apps each day automating the review response process is useful for app developers.
in this work we propose a novel approach namedrrgen by explicitly incorporating review attributes and oc currences of specific keywords into the basic nmt model.analysis using automated metric and human evaluation shows that our proposed model outperforms baseline approaches.
infuture we will conduct evaluation using a larger dataset and deploy the model with our industry partners.
a cknowledgement the work described in this paper was supported by the research grants council of the hong kong special adminis trative region china no.
cuhk and no.
cuhk14208815 of the general research fund and microsoftresearch asia microsoft research asia collaborativeresearch a ward .
r eferences survey on user ratings and reviews app store ratings reviews guide .
c. gao j. zeng m. r. lyu and i. king online app review analysis for identifying emerging issues in proceedings of the 40th international conference on software engineering icse .
acm pp.
.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
a. di sorbo s. panichella c. v .
alexandru j. shimagaki c. a. visaggio g. canfora and h. c. gall what would users change in myapp?
summarizing app reviews for recommending software changes inproceedings of the 24th sigsoft international symposium on f oundations of software engineering fse .
acm pp.
.
ratings reviews and responses in app store com app store ratings and reviews .
view and analyze your app s ratings and reviews google.com googleplay android developer answer ?hl en.
j. oh d. kim u. lee j. lee and j. song facilitating developer user interactions with mobile app review digests in acm sigchi conference on human factors in computing systems chi paris france april may extended abstracts pp.
.
s. mcilroy w .
shang n. ali and a. e. hassan is it worth responding to reviews?
studying the top free apps in google play ieee software vol.
no.
pp.
.
s. hassan c. tantithamthavorn c. bezemer and a. e. hassan studying the dialogue between users and developers of free apps in the googleplay store empirical software engineering vol.
no.
pp.
.
m. nayebi l. dicke r. ittyipe c. carlson and g. ruhe essmart way to manage user requests corr vol.
abs .
.
d. wang n. jojic c. brockett and e. nyberg steering output style and topic in neural response generation in proceedings of the conference on empirical methods in natural language processing emnlp copenhagen denmark september pp.
.
j. li and x. sun a syntactically constrained bidirectionalasynchronous approach for emotional conversation generation in proceedings of the conference on empirical methods in natural language processing brussels belgium october november pp.
.
a. sordoni m. galley m. auli c. brockett y .
ji m. mitchell j. nie j. gao and b. dolan a neural network approach to context sensitive generation of conversational responses in naacl hlt the conference of the north american chapter of the associationfor computational linguistics human language technologies denver colorado usa may june pp.
.
l. zhou j. gao d. li and h. shum the design and implementation of xiaoice an empathetic social chatbot corr vol.
abs .
.
k. cho b. van merrienboer c .
g ulc ehre d. bahdanau f. bougares h. schwenk and y .
bengio learning phrase representations usingrnn encoder decoder for statistical machine translation in proceedings of the conference on empirical methods in natural language processing emnlp october doha qatar a meeting of sigdat a special interest group of the acl pp.
.
i. sutskever o. vinyals and q. v .
le sequence to sequence learning with neural networks corr vol.
abs .
.
x. gu h. zhang d. zhang and s. kim deep api learning in proceedings of the 24th acm sigsoft international symposium onf oundations of software engineering fse seattle wa usa november pp.
.
l. dong and m. lapata language to logical form with neural attention in proceedings of the 54th annual meeting of the association for computational linguistics acl august berlin germany v olume long papers .
s. jiang and c. mcmillan towards automatic generation of short summaries of commits in proceedings of the 25th international conference on program comprehension icpc buenos aires argentina may22 pp.
.
s. jiang a. armaly and c. mcmillan automatically generating commit messages from diffs using neural machine translation in proceedings of the 32nd ieee acm international conference on automatedsoftware engineering ase urbana il usa october november pp.
.
v .
j. hellendoorn c. bird e. t. barr and m. allamanis deep learning type inference in proceedings of the acm joint meeting on european software engineering conference and symposium on thef oundations of software engineering esec sigsoft fse lake buena vista fl usa november pp.
.
m. r. islam numeric rating of apps on google play store by sentiment analysis on user reviews in international conference onelectrical engineering and information communication technology .
ieee pp.
.
k. sharma and k. lin review spam detector with rating consistency check in acm southeast regional conference acm se savannah ga usa april pp.
.
z. liu x. xia a. e. hassan d. lo z. xing and x. wang neuralmachine translation based commit message generation how far arewe?
in proceedings of the 33rd acm ieee international conference on automated software engineering ase montpellier france september pp.
.
z. ji z. lu and h. li an information retrieval approach to short text conversation corr vol.
abs .
.
y .
song c. li j. nie m. zhang d. zhao and r. y an an ensemble of retrieval based and generation based human computer conversationsystems in proceedings of the twenty seventh international joint conference on artificial intelligence ijcai july stockholm sweden.
pp.
.
c. d. manning p .
raghavan and h. sch utze introduction to information retrieval .
cambridge university press .
k. papineni s. roukos t. ward and w .
zhu bleu a method for automatic evaluation of machine translation in proceedings of the 40th annual meeting of the association for computational linguistics july6 philadelphia pa usa.
pp.
.
d. bahdanau k. cho and y .
bengio neural machine translation by jointly learning to align and translate corr vol.
abs .
.
r. collobert and s. bengio links between perceptrons mlps and svms in machine learning proceedings of the twenty first international conference icml banff alberta canada july .
t. luong h. pham and c. d. manning effective approaches to attention based neural machine translation in proceedings of the conference on empirical methods in natural language processing emnlp lisbon portugal september pp.
.
w .
maalej and h. nabil bug report feature request or simply praise?
on automatically classifying app reviews in 23rd ieee international requirements engineering conference re ottawa on canada au gust pp.
.
i. sutskever o. vinyals and q. v .
le sequence to sequence learning with neural networks in advances in neural information processing systems annual conference on neural information processing systems december montreal quebec canada pp.
.
t. mikolov m. karafi at l. burget j. cernock y and s. khudanpur recurrent neural network based language model in interspeech 11th annual conference of the international speech communi cation association makuhari chiba japan september pp.
.
t. mikolov i. sutskever k. chen g. s. corrado and j. dean distributed representations of words and phrases and their composi tionality in advances in neural information processing systems 27th annual conference on neural information processing systems2013.
proceedings of a meeting held december lake tahoe nevada united states.
pp.
.
a. m. rush s. chopra and j. weston a neural attention model for abstractive sentence summarization in proceedings of the conference on empirical methods in natural language processing emnlp lisbon portugal september pp.
.
z. lin m. feng c. n. dos santos m. y u b. xiang b. zhou and y .
bengio a structured self attentive sentence embedding corr vol.
abs .
.
j. zeng j. li y .
song c. gao m. r. lyu and i. king topic memory networks for short text classification in proceedings of the conference on empirical methods in natural language processing brussels belgium october november pp.
.
n. chen j. lin s. c. hoi x. xiao and b. zhang ar miner mining informative reviews for developers from mobile app marketplace inproceedings of the 36th international conference on software engineering icse .
acm pp.
.
e. guzman and w .
maalej how do users like this feature?
a fine grained sentiment analysis of app reviews in proceedings of the 22nd international conference on requirements engineering re .
ieee pp.
.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
m. thelwall k. buckley g. paltoglou d. cai and a. kappas sentiment in short strength detection informal text jasist vol.
no.
pp.
.
d. j. montana and l. davis training feedforward neural networks using genetic algorithms in proceedings of the 11th international joint conference on artificial intelligence.
detroit mi usa august pp.
.
g. a. miller wordnet a lexical database for english commun.
acm vol.
no.
pp.
.
j. chung c .
g ulc ehre k. cho and y .
bengio empirical evaluation of gated recurrent neural networks on sequence modeling corr vol.
abs .
.
z. wu and s. king investigating gated recurrent networks for speech synthesis in ieee international conference on acoustics speech and signal processing icassp shanghai china march pp.
.
glove global vectors for word representation projects glove .
d. p .
kingma and j. ba adam a method for stochastic optimization in3rd international conference on learning representations iclr san diego ca usa may conference track proceedings .
pytorch m. harman y .
jia and y .
zhang app store mining and analysis msr for app stores in 9th ieee working conference of mining software repositories msr june zurich switzerland pp.
.
app annie y .
man c. gao m. r. lyu and j. jiang experience report understanding cross platform app issues from user reviews in 27th ieee international symposium on software reliability engineering issre2016 ottawa on canada october pp.
.
p .
m. vu t. t. nguyen h. v .
pham and t. t. nguyen mining user opinions in mobile app reviews a keyword based approach t in30th ieee acm international conference on automated software engineering ase lincoln ne usa november pp.
.
c. liu r. lowe i. serban m. noseworthy l. charlin and j. pineau how not to evaluate your dialogue system an empirical study ofunsupervised evaluation metrics for dialogue response generation inproceedings of the conference on empirical methods in naturallanguage processing emnlp austin texas usa november pp.
.
p .
yin and g. neubig a syntactic neural model for general purpose code generation in proceedings of the 55th annual meeting of the association for computational linguistics acl v ancouver canada july august v olume long papers pp.
.
s. liu h. chen z. ren y .
feng q. liu and d. yin knowledge diffusion for neural dialogue generation in proceedings of the 56th annual meeting of the association for computational linguistics acl2018 melbourne australia july v olume long papers pp.
.
f. wilcoxon individual comparisons by ranking methods biometrics bulletin vol.
no.
pp.
.
s. e. ahmed effect sizes for research a broad application approach technometrics vol.
no.
p. .
x. du and c. cardie harvesting paragraph level question answer pairs from wikipedia in proceedings of the 56th annual meeting of the association for computational linguistics acl melbourne australia july v olume long papers pp.
.
p .
s. kochhar x. xia d. lo and s. li practitioners expectations on automated fault localization in proceedings of the 25th international symposium on software testing and analysis issta saarbr ucken germany july pp.
.
c. gao h. xu j. hu and y .
zhou ar tracker track the dynamics of mobile apps via user review mining in ieee symposium on service oriented system engineering sose san francisco bay ca usa march april pp.
.
n. novielli d. girardi and f. lanubile a benchmark study on sentiment analysis for software engineering research in proceedings developers can finally respond to app store reviews developers can finally respond to app store reviews heres how it works .
of the 15th international conference on mining software repositories msr gothenburg sweden may pp.
.
i. salman a. t. misirli and n. j. juzgado are students representatives of professionals in software engineering experiments?
in 37th ieee acm international conference on software engineering icse florence italy may v olume pp.
.
r. feldt t. zimmermann g. r. bergersen d. falessi a. jedlitschka n. juristo j. m unch m. oivo p .
runeson m. j. shepperd d. i. k. sj berg and b. turhan four commentaries on the use of students andprofessionals in empirical software engineering experiments empirical software engineering vol.
no.
pp.
.
f. palomba p .
salza a. ciurumelea s. panichella h. gall f. ferrucci and a. d. lucia recommending and localizing change requests formobile apps based on user reviews in ieee acm 39th international conference on software engineering icse pp.
.
g. grano a. ciurumelea s. panichella f. palomba and h. c. gall exploring the integration of user feedback in automated testing of an droid applications in ieee 25th international conference on software analysis evolution and reengineering saner pp.
.
c. gao w .
zheng y .
deng d. lo j. zeng m. r. lyu and i. king emerging app issue identification from user feedback experienceon wechat in proceedings of the 41st international conference on software engineering software engineering in practice icse seip montreal qc canada may pp.
.
c. iacob v .
v eerappa and r. harrison what are you complaining about?
a study of online reviews of mobile applications in bcshci proceedings of the 27th international bcs human computerinteraction conference brunel university london uk september2013 p. .
c. iacob and r. harrison retrieving and analyzing mobile apps feature requests from online reviews in proceedings of the 10th working conference on mining software repositories msr san francisco ca usa may pp.
.
x. gu and s. kim what parts of your apps are loved by users?
t in30th ieee acm international conference on automated software engineering ase lincoln ne usa november pp.
.
w .
martin f. sarro y .
jia y .
zhang and m. harman a survey of app store analysis for software engineering ieee trans.
software eng.
vol.
no.
pp.
.
j. zeng j. li y .
he c. gao m. r. lyu and i. king what you say and how you say it joint modeling of topics and discourse in microblogconversations tacl vol.
pp.
.
g. chen e. tosch r. artstein a. leuski and d. r. traum evaluating conversational characters created through question generation inproceedings of the twenty f ourth international florida artificial intel ligence research society conference may palm beach florida usa .
a. ritter c. cherry and w .
b. dolan data driven response generation in social media in proceedings of the conference on empirical methods in natural language processing emnlp july2011 john mcintyre conference centre edinburgh uk a meeting ofsigdat a special interest group of the acl pp.
.
o. vinyals and q. v .
le a neural conversational model corr vol.
abs .
.
.
available p .
koehn h. hoang a. birch c. callison burch m. federico n. bertoldi b. cowan w .
shen c. moran r. zens c. dyer o. bojar a. constantin and e. herbst moses open source toolkit for statisticalmachine translation in acl proceedings of the 45th annual meeting of the association for computational linguistics june prague czech republic .
g. salton a. wong and c. y ang a vector space model for automatic indexing commun.
acm vol.
no.
pp.
.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.