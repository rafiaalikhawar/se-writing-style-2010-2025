webranz web page randomization for better advertisement delivery and web bot prevention weihang wang1 yunhui zheng2 xinyu xing3 y onghwi kwon1 xiangyu zhang1 patrick eugster1 1purdue university usa2ibm t.j. watson research center usa3the pennsylvania state university usa 4tu darmstadt germany wang1315 kwon58 xyzhang p cs.purdue.edu zhengyu us.ibm.com uxx16 psu.edu abstract nowadays a rapidly increasing number of web users are using ad blockers to block online advertisements.
ad blockers are browser based software that can block most ads on the websites speeding up web browsers and saving bandwidth.
despite these bene ts to end users ad blockers could be catastrophic for the economic structure underlying the web especially considering the rise of ad blocking as well as the number of technologies and services that rely exclusively on ads to compensate their cost.
in this paper we introduce webranz that utilizes a randomization mechanism to circumvent ad blocking.
using webranz content publishers can constantly mutate the internal html elements and element attributes of their web pages without a ecting their visual appearances and functionalities.
randomization invalidates the pre de ned patterns that ad blockers use to lter out ads.
though the design of webranz is motivated by evading ad blockers webranz also bene ts the defense against bot scripts.
we evaluate the e ectiveness of webranz and its overhead using randomly sampled top alexa web pages and representative bot scripts.
ccs concepts information systems !display advertising security and privacy!web application security keywords ad blockers randomization web bots .
introduction online advertising is the primary source of income for many internet companies such as the it giants google and facebook.
according to the revenue of u.s. web advertising is as large as billion in q3 .
with ad supports online services give us instant access to more information than was ever stored in the entirety of the world s libraries just a few decades ago.
ad supported services alsocreate and maintain systems that allow for instant communication and organization between more than a billion people.
without web advertising many of the world s most useful technologies may never have occurred.
ad blocker is a piece of software that allows a user to roam the web without encountering any ads.
in particular it utilizes network control and in page manipulation to help users block most online advertisements.
network control barricades http requests to ads and thus prevents them from loading.
in page manipulation looks up ads based on pre determined patterns and makes them invisible.
with ad blockers web browsers generally run faster and waste less bandwidth downloading ads and the users are no longer distracted by the ads.
not surprisingly ad blocking is gaining popularity with an astonishing pace.
according to a survey by adobe and an ad blocking measurement service pagefair of the us internet users run ad blocking software in their browsers .
approximately million active users globally used ad blocking tools in up by compared to .
adblock plus a leading adblocker claims that their product has been downloaded at an average rate of million times per week since and it is at a steady clip .
in addition more iphone and ipad users start running ad blockers thanks to the built in capacities in the latest ios .
despite its tangible convenience to the customers adblocking could devastate the economic structure underlying the web in the long run.
this is because many content publishers make their primary legitimate income from ads but ad blocking is destroying this ecosystem.
in google made billion from advertising but lost billion due to ad blocking .
during ad blocking has cost internet companies almost billion .
the number will rise to billion in .
many games related websites currently encounter about revenue loss due to ad blocking .
it is suggested that if everybody used adblockers ad supported internet services would vanish.
it s the websites that ad block users most love that are going out of business rst.
this is to no one s bene t .
furthermore since ad blockers use pre de ned patterns to identify and suppress dom objects that appear to be ads it is often the case that the patterns are so general that part of the regular content is also blocked.
as shown in fig.
the text links marked in the red circle on the homepage of as part of the regular content are inappropriately blocked by adblock.
to damp the negative e ect of ad blockers on the web ecosystem tech companies and service providers introduce permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
copyrights for components of this work owned by others than acm must be honored.
abstracting with credit is permitted.
to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
request permissions from permissions acm.org.
fse november seattle wa usa c acm.
... .
artifact evaluated by fse figure non ads on blocked.
left no adblock.
right with adblock.
many solutions .
for example one common approach is to integrate to a web page an in page javascript snippet that examines the presentation of ads and identi es the presence of ad blocker.
furthermore such approaches often demand the users turn o their ad blockers or subscribe to a website s paywall.
despite the e ectiveness in detecting ad blocker s presence such technologies often substantially degrade the user experience with websites.
more importantly they still fail to punch through ad blockers to serve the originally intended ads.
in this paper we develop a technique that allows the content publishers to deliver their ads without being blocked.
our goal is to retain a healthy web ecosystem by providing an option for the content publishers to protect their legitimate right.
our technique webranz circumvents ad blocking using a content and url randomization mechanism.
with webranz the publishers can constantly mutate their web content including html css and javascript so that ad blockers cannot nd the pre determined patterns to lter out ads.
more importantly webranz retains the functionalities of the original page and minimizes the visual di erences caused by randomization so that the user experience is not a ected.
webranz ensures that multiple accesses of the same website return di erent content pages that have the same appearances and functionalities.
speci cally since a lot of ads are loaded by third party javascript on the client side without going through the original content publisher server the pages returned by the server need to be instrumented so that the ad contents generated on the client side can be randomized.
webranz overwrites native javascript apis so that dynamic dom objects can be randomized on the y when they are generated through the overwritten apis.
besides ad blockers also cancel network requests to blacklisted urls by comparing urls against pre de ned patterns.
to bypass webranz randomizes the urls and resource requested is fetched via a transparent proxy hosted by content publishers.
while webranz is developed for circumventing ad blocker scourges last but not the least our design principle also bene ts the defense against many unwanted bot scripts that launch automated attacks on websites as these bots also manipulate dom objects using pre determined patterns.
in summary this paper makes the following contributions.
we propose a web page randomization technique webranz that prevents ad blockers from expunging ads on web pages and helps defending against web bots.
at the same time webranz preserves page appearances and functionalities.
we address the challenges entailed by url and web page randomization such as preserving dependencies between dom objects and css selectors between dom elements and javascript and handling dynamic generated elements as well as resolving randomized urls.
.
div id j id 1 20n ... .
div class atcui column atcui span ... .
img src alt trade in .
... .
div .
div class atcui column atcui span ... .
img src alt sell your car .
... .
div .
div figure static ads on figure page the ad is enclosed by div id div gpt ad in the red cycle.
we implement webranz and it s publically available at .
we evaluate it using randomly sampled top alexa web pages and real world bot scripts.
we show that webranz is e ective in circumventing adblockers with negligible overhead.
it also defeats all the tested bot scripts.
.
motivation in this section we show how ad blockers and web bots work in practice.
we explain how pattern matching based page element lookup plays an important role in these two.
we then overview our approach.
.
ad blocking web advertising is one of the foundations of internet economy.
most content publishers earn their revenue by delivering ads.
when a page is loaded the ads loaded often go through many layers of delegations and redirections.
we call it the ad delivery path .
we classify ads into two categories based on the loading procedure.
those that are literally included by the content page are called the static ads and those dynamically loaded are called the dynamic ads .
static ads.
static ads are usually served by the content publishers and delivered from a central domain.
for example fig.
shows two static ads on the home page of they are two images with their urls at lines and in the html le.
observe that the urls are explicitly encoded in the source code.
in other words the ads are not dynamically loaded by javascript.
dynamic ads.
dynamic ads are usually provided by online advertisement vendors or ad networks and hosted on servers other than the publisher server.
compared to static ads they can be served from multiple domains owned by various ad networks.
they are usually dynamically loaded and may be di erent in each load.
hence ads networks are able to deliver customized ads to maximize their revenue.
we use as an example to illustrate dynamic ad delivery.
it serves the latest music videos and entertainment news.
it ranks in the category music insert an external image insert an external js request image added in homepage gpt.js pubads impl 69r.js securepubads.g.doubleclick.net ads?gdfp req ... request js inserted in bs.servin g sys.com adserver.bs?cn ... ads imagefigure an example of dynamic ads loading.
videos of alexa top sites .
fig.
shows the top portion of the website.
the ad marked in the red cycle is dynamically loaded from google doubleclick ad exchange service.
fig.
shows its loading procedure which consists of steps each loading and executing some javascript until the ad is nally displayed.
the related source code is shown in fig.
.
the code is substantially simpli ed for readability.
the html after ad loading is shown in fig.
.
the script in blue in fig.
is replaced with the script in blue in fig.
after loading.
the divin red in the original page is replaced with that in red after loading containing an iframe with the ad image.
particularly the loading procedure contains the following steps steps .
the browser loads the home page.
the html returned by the server is shown lines in fig.
.
when the script in lines is executed a new script element is added to the page line in fig.
.
steps .
the browser parses the new script element and then executes gpt.js from com.
the script i.e.
line in fig.
inserts another script pubads impl 69r.js to the page line in fig.
.
steps .
the browser loads pubads impl 69r.js from partner.googleadservices.com.
this script creates an iframe lines and adds it to the divat line in the original page lines .
in lines the script writes two new script elements to the iframe.
at line it adds the de nition of a function cbproxy to the iframe .
the function writes an ad provided as the parameter to the page.
at line the script adds a new script element whose source is hosted by securepubads.g.doubleclick.net a google ad service provider.
the url is parameterized for targeted advertising.
in particular the server side logic takes the parameters and identify the ad s that should be pushed to a particular client.
steps .
the script is loaded from securepubads.g.
doubleclick.net.
the source code is shown in line .
the script invokes cbproxy which is supposed to be de ned by other scripts in the earlier steps to write an ad image url to the page.
the image is hosted by the mediamind advertising server serving sys.com owned by an advertising company sizmek.
this leads to the iframe in red in fig.
.
steps .
finally the browser loads and renders the actual ad image.
.
.
how ads are blocked from the previous discussion the ad delivery path may be long and complex.
if any of the steps along the path are broken the ad is blocked.
most ad blockers leverages this characteristics.
they recognize steps on ad delivery .
head .
script type text javascript .
var gads document.createelement script .
gads.src .
var node document.getelementsbytagname script .
node.parentnode.insertbefore gads node .
script .
head .
... .
body .
... .
div id div gpt ad 300 250 div .
... .
body .
gpt.js .
.
...document.write script type text javascript src ads impl 69r.js script .
... .
pubads impl 69r.js .
.
add iframe to the children list of a div .
... .
f document.createelement iframe .
f.id google ads iframe ... .
f.contentwindow.document.write script function cbproxy ad ...document.write ad script .
f.contentwindow.document.write script src securepubads.g.doubleclick.net ...
ads?...
.
e document.getelementbyid div gpt ad 300 250 .
e.appendchild f .
securepubads.g.doubleclick.net ...ads ?
.
.
insert the actual ad image .
cbproxy ... img src figure dynamic ads loading on .
head .
... .
script src .
script src .
... .
head .
body .
div id div gpt ad 300 250 .
iframe id google ads iframe ... .
img src .
... .
iframe .
div .
body figure html after loading.
paths by pattern matching.
they maintain a long list of patterns that can be used to distinguish ads from normal page content.
take adblock plus as an example.
ads are usually blocked by the following two means.
network control by url filtering .
since advertising companies serve ads on a limited number of servers it s possible to collect a set of domain names and block requests sent to domains on the url blacklist.
for example the request to ... sent in step in fig.
will be blocked by a url based rule securepubads.
.
as a result the loading procedure is interrupted since the browser cannot obtain the actual ads enclosed in the response.
in page manipulation by selector based filtering .
elements not blocked by network control can be successfully loaded from the remote servers.
however they can still be blocked before they are rendered by the browser.
this is done by identifying ad elements inside the browser using selector patterns and setting these elements to invisible.
for example in fig.
two ad related dom elements are set to invisible based on the following two selectors.
consequently the ad image is not rendered.
selector div matches the div element with idthat starts with div gpt ad .
as such thediv line in fig.
is set to invisible.
selector iframe selects the iframe with idbegins with google adsiframe .
therefore the iframe at line in fig.
is hidden.
.
content sensitive web bots web bots are programs that simulate user browsing behavior.
they read the html code analyze the content and interact with the web app just like humans.
web bots are commonly used for various purposes such as searching scraping and impersonation.
according to a recent study on .
html .
... .
a class button called out button full href outlet.lenovo.com ... ?sb 000001bd 0002f49b add to cart a .
... .
html figure the source of the add to cart button.
the page has totally a elements.
.
content open url item url full ... .
tmp found re.findall r a class button called out buttonfull .
?
add to cart content ... .
if len tmp found !
.
itemid re.findall r ?sb .
?
tmp found ... .
new addtocart url outlet.lenovo.com ...addtocart?
addtocart itemid itemid .
webbrowser.open new addtocart url figure a web bot for the lenovo outlet.
popular websites by incapsula inc. out of billion visits observed of all tra c is generated by bots .
bots can be roughly classi ed into two groups based on the targets.
some do not focus on particular items but grab all contents.
bots targeting search engines are examples of this type.
the bots in the other group focus on speci c elements.
they parse the html and locate the targets using prede ned patterns.
once found they either simulate human behaviors e.g.
clicking buttons or extract valuable data.
data theft by web scraping and human impersonators are typical examples.
since being able to locate the targets is important we dub them content sensitive web bots .
content sensitive web bots such as scrappers have caused substantial loss.
according to scrapesentry of booking tra c on travel industry websites is generated by scraping bots .
as a result airlines have increased booking fees to balance the cost .
a scraper also demonstrated its capabilities in causing damages through the twitter earnings leak incident .
in april twitter planed to release its q1 earning report after the stock market was closed.
however the report link was mistakenly posted online before the schedule.
although it was deleted immediately it stayed online for 45s.
a nancial scraper owned by selerity discovered the report in such a short time and tweeted twitter s disappointing result when the market was still open.
as a result shares of twitter fell as much as .
content sensitive web bots are also widely used on ecommerce websites.
take a bot targeting at the lenovo outlet store as an example.
the lenovo outlet store o ers substantially discounted computers but the quantity is limited.
it is usually hard to get one since many people keep refreshing the inventory and grab a deal as soon as it becomes available.
while it is tedious for a human to repeat this procedure a bot was programmed to monitor the store and add deals to the shopping cart automatically.
fig.
shows the html code of the add to cart button.
it is an a element representing a link.
there are totally a elements on this page.
fig.
shows a snippet of the web bot.
the script loads a product page at line .
it hence tries to locate the add to cart link.
since there are many a elements the script has to distinguish the target from the others.
it does so by comparing the style class name and the element id of a candidate link with some patterns.
in this case at line the script uses two style class names button called out and button full as the signature.
if such an a is found at line it further extracts the id from the content after sb in the link.
in this example the itemid is 000001bd 0002f49b .
then it constructs the actual addto cart link at line and invokes the browser at line to add the item to the shopping cart.
client siderandomizer properties urloriginal javascript randomized html cssrandomized html css loaded dynamically element selector helper id classdynamically loaded javascript 3rd party ... server siderandomizer properties urloriginal html css randomized html cssclient side randomizer javascript original javascript element selector helper javascript transparent proxy transparent proxy......figure overview of the web page randomization.
as observed above a critical precondition for contentsensitive web bots is that they identify important dom objects by pattern matching which is similar to ad blockers.
.
our solution web page randomization webranz is a technique that randomizes both urls and content in web pages so that ad blockers and content based web bots can no longer use pattern matching to identify and manipulate dom elements.
as mentioned before web pages may be changed dynamically on the client side.
therefore the randomization is performed not only on the server side by the content publisher but also on the client side through javascript instrumentation added to the page by the content publisher.
in particular upon receiving a client side request the publisher prepares the page as usual.
before delivering it to the client webranz randomizes the page by randomizing the element ids style sheets urls and so on.
the randomization is designed in such a way that it does not change the visual e ects and functionalities of the page but rather the internal representations of the page.
as such the changes are transparent to the end user.
webranz also inserts javascript code to the page to randomize the page content dynamically generated on the client side.
fig.
shows the overview of the web page randomization procedure.
webranz is deployed on the server side publishers .
the input is an html le and its corresponding external css style sheets.
the html le can be a static html page or the output of a dynamic server side script before being sent out.
the existing external javascript and other resource les e.g.
images are untouched.
they will be sent to the clients upon requests.
we randomize the attributes e.g.
element id or style class name and urls in html and external css style sheets.
as such the selector based and url based lters used in ad blockers and web bots can no longer identify the page elements.
the output is a randomized version of the input html page and css style sheets.
in the html we also append utilities that redirect the dom selectors in the existing javascript to the corresponding randomized html elements and handle dom elements dynamically inserted in the browser.
the former is to make sure the javascript in the original page can work properly with the randomized version especially when the script accesses dom elements.
the latter is to handle dom elements we do not see during the server side randomization.
for the example the divand iframe in red in fig.
are given random ids such that the aforementioned 208table adblock plus easylist filters url blocking rules element exception domain only resource only hiding rules rules adblock plus patterns fail to locate and suppress the ad image.
for the lenovo web bot example the class name at line of fig.
button called out button full is replaced with a random string that changes each time the page is loaded.
as such the web bot in fig.
cannot identify the link and fail to put the product in cart.
besides to resolve the randomized urls we leverage transparent proxies deployed on the publisher side.
in particular all urls either statically embedded or dynamically loaded randomized by server side and client side randomizer point to publisher s transparent proxies.
note that the proxy url can be arbitrary and di erent in each load.
or we may just use the publisher s top level domain e.g.
cnn.com to bypass the url lter.
once requested the transparent proxies recover the real urls fetch the resource requested and send them to the client.
.
web page randomization as third party contents including ads are usually loaded dynamically and could be di erent in each load a publisher may not be able to determine which elements should be randomized or which paths should be changed in advance.
in order to achieve practical web page randomization webranz needs to handle a few technical challenges randomization causes inconsistencies between dom objects and their style speci cation between html elements and javascript.
client side randomization should be supported by instrumenting the page with the randomization logic in javascript executed on the client side.
the server side needs to be extended to resolve the randomized urls that change constantly.
in the following subsections we rst discuss what elements should be randomized.
we then discuss how they are randomized.
the discussion is divided into two parts randomization performed on the publisher server side and that on the client side by the javascript instrumentation.
.
what to randomize one of the most important design goals of webranz is to retain the appearances and functionalities of web pages while breaking the patterns used by ad blockers and web bots.
hence not all html elements or element attributes are subject to randomization.
for example changing the type of a dom object e.g.
a radio box to a check box or changing the style may cause undesirable visual di erences.
to identify randomization candidates we perform the following two studies first we analyze easylist the blacklist used by adblock plus to select important attributes.
second we visit the home pages of alexa top websites using di erent blacklist settings and evaluate the e ectivenesses of url based and element hiding lters.
.
.
interpreting patterns in blacklisting rules adblock plus works based on a set of rules.
we classify these rules to three categories as shown in table the url blocking rules specify url lters for network control.
any requests to blacklisted urls aretable element hiding filters selectors id classidandidorclassclass general rule site speci c total table elements blocked on alexa top sites full easylist domain resource element hiding url hiding only only rules only min max average .
.
.
.
.
canceled.
they can be further divided into two subgroups domain only patterns e.g.
com and resource patterns with both domains and resource paths e.g.
the exception rules disable existing rules on particular domains.
filters are not applied on domains that match the whitelist.
the element hiding rules specify selector based lters.
the html elements on the page that match the rules are prevented from rendering.
observe that the url blocking and element hiding rules are dominant and most url blocking rules are those that contain both the domain and the resource path.
each element hiding rule is a selector de ned by one or more attributes.
to determine the attributes that are important for randomization we further study the element hiding rules in the adblock plus s list.
the results are presented in table .
we observe that attributes idand class are most commonly used idis a unique identi er of an html element in the document class provides a class name for one or more html elements.
ad blockers hide elements using style rules.
a style rule consists of a selector and a declaration block.
the selector points to the html element s where the style declared is applied to.
the declaration block contains visual e ect speci cations such as size and layout.
the style rules can be a piece of in line script in html or an external stylesheet css le.
examples of element hiding rules are shown as follows.
.googleads container matches elements with class googleads container .
a composite hiding rule resultspanel topads is to select the element that has id topads and is enclosed in an element with id resultpanel .
.
.
evaluating filters on popular websites in the second study we collect the number of elements removed by the url blocking rules and the element hiding rules and evaluate their e ectiveness on real world websites.
we rst collect the data using the original full easylist.
as the url blocking rules and element hiding rules are not orthogonal we repeat the experiment using di erent subset rules in easylist url blocking rules that only contain domains domain only url blocking rules that have both domain and resource paths resource only and element hiding rules.
the results are shown in table .
on the one hand the url based rules block more than times elements than the element hiding rules on popular web pages.
on the other hand the fact that more than half rules are element hiding rules shows that they are important as url blocking rules cannot handle all cases without any overkills.
as suggested by above two studies idand class are critical attributes used by selectors in the element hiding rules.
besides bypassing the url blocking rules is crucial.
there209fore webranz aims to randomize id class and urls.
that would allow us to counter of all rules which represent the dominating majority applied in practice.
.
server side randomization webranz is deployed on the publisher server.
part of the randomization is performed directly on the server side.
in this subsection we discuss the server side randomization.
it mainly consists of randomizing the idand class attributes xing styling rules and randomizing urls.
.
.
randomizing element id and class before a page retrieved generated by the publisher server is returned to the client webranz parses the page and then traverses the dom tree.
during traversal it replaces each idorclass name encountered with some random value.
it also maintains a one to one mapping between the original id class name and its randomized counter part.
this mapping is the key to preserving the semantics and functionalities and will be used in later steps.
note that it is possible that multiple html elements have the same id.
in this case webranz also projects them to the same random value.
we also want to point out that the server does not need to keep the mapping in any permanent storage as it is never reused.
in other words each page returned to some client is randomized independently.
.
.
fixing static html style rules style rules determine the visual e ects of a class of dom elements.
styles can be speci ed in the following ways an inline attribute is de ned along with the dom element.
e.g.
div style border 10pt speci es that the div element has a border of points.
an internal style is de ned in the header.
e.g.
style type text css .sidebarfwidth g style sets the width of element s with class of sidebar .
an external rule is speci ed in a css le and embedded in the html.
e.g.
link rel stylesheet href .css includes style rules de ned in .css.
a style can be dynamically de ned by a property setter in javascript.
e.g.
getelementbyid x1 .style fborder 1ptgsets the border of the element with idof x1 .
this is often used to de ne styles on the client side.
the inlined style is not a ected by randomization.
in contrast the internal and external rules have to be updated since the id class names in those style rules need to be made consistent with the randomized id class names.
example .
in fig.
the html code contains a div lines whose style is speci ed in lines .
observe that the strings u7n231k and hcd1nc are the randomized values for o ce sessions widget and video item respectively.
since the rule name and the class name of the html element are updated consistently the visual representation is preserved.
.
style type text css .
.office sessions widget .video item ... .
style .
div class office sessions widget .
div class video item ... div .
div .
style type text css .
.u7n231k .hcd1nc ... .
style .
div class u7n231k .
div class hcd1nc ... div .
div .
style type text css .
.office sessions widget .video item ... .
style .
div class office sessions widget .
div class video item ... div .
div .
style type text css .
.u7n231k .hcd1nc ... .
style .
div class u7n231k .
div class hcd1nc ... div .
div figure an example of class randomization.
webranz only xes static style rules on the server side.for dynamic styles that are de ned by property setters or inserted by in page javascript webranz relies on the javascript instrumentation to ensure consistency on the client side .
more details can be found in section .
.
.
.
randomizing static urls as mentioned earlier ad blockers work by blocking urls or hiding elements.
randomizing id class prevents element lookup by selectors.
webranz also performs url randomization to evade url blocking.
webranz traverses the dom tree of the page and identies all urls in the page.
for those that can be matched by url blocking rules webranz randomizes the whole url including domain resource path and all parameters.
in particular it takes the whole url and randomize the string using public key cryptography.
this is to make sure that the ad blocker on the client side cannot recover the original url for the randomized version as the private key will not be sent to the client.
original version .
script src script randomized version .
script src http proxy url proxy script name .php?
para name lahrcs229bprslk06fyhcdnnivf1hnavymtfv1t0zicy8d5flrsl5cz4p68nqymirztj5z5d igjk89 8nkjmsulbokkjxniixeg5dkx3bd2jo0t4a0nq4rhvwfsezyny6aqoznqjcvabkol2 dxxati17uk44t6hqdj5km879yu0 script note proxy url proxy script name and para name can be different in each load figure an example of url randomization.
fig.
shows an example of url randomization.
line is an external script.
line is the corresponding randomized version.
the randomized url is sent to proxy url a url pointing to the transparent proxy as a request parameter.
the original url is replaced with this randomized version.
please note that the proxy url proxy url and proxy script name can be arbitrary valid url pointing to a publisher s proxy.
we can make it a moving target or simply use the publisher s top level domain to host a pool of proxy scripts.
therefore blocking the url to transparent proxies is impractical .
otherwise all content hosted by this publisher will be blocked.
.
.
transparent proxy the original urls are reshaped to evade url blocking rules by randomization.
since domain names are also changed to make sure the client can correctly load the original resource we use a group of transparent proxies deployed on the publisher side to fetch the resource for the client.
in particular when the transparent proxy receives a request it decodes the parameter and recovers the original url.
it then sends a request with original data from the client including cookies to the original destination.
once the response arrives the proxy forwards it to the client.
note that if the requested url points to a local resource the proxy directly loads and returns it to the client in order to minimize the performance overhead.
in addition besides url the srcof an image or script may be a data uri that is the le content itself .
data uris are also randomized as they can be used to deliver ads.
when the proxy receives such data uri request it directly returns the decoded data with its corresponding header.
for example if a data uri request is an image type the proxy decodes the image data in the request and adds an image header to the response.
.
preserving client side functionalities and handling dynamically loaded elements both the dom interface and third party libraries e.g.
jquery provide many ways to access html elements.
after randomization the original attribute values are replaced with the random ones.
however the dom element selectors in existing javascript still use the original values such that they cannot locate the correct elements anymore.
in order to provide consistent accesses to randomized dom elements one way is to scan the javascript in the page and update all the selector values similar to xing the static style rules.
however since third party javascript les are loaded dynamically on the y it is infeasible to update all these les during the server side randomization.
instead we choose to override the relevant javascript apis and map the original attribute values to their corresponding randomized versions at runtime whenever the attributes are accessed.
.
.
overriding element selectors the document object model dom de nes a programming interface to access and manipulate html elements and their properties.
speci cally the reference to an html element can be acquired using an idselector getelementbyid or a class selector getelementsbyclassname .
.
var byid document.
proto .getelementbyid .
document.
proto .getelementbyid function id .
if idmap .
return byid.call document idmap .
.
else return byid.call document id .
figure override document.getelementbyid .
therefore webranz overrides these two methods.
it projects the original attribute value to the corresponding randomized value as follows if a value has been randomized the original selector value is replaced by the corresponding randomized value.
otherwise the same value is used.
the overridden version of document.getelementbyid is shown in fig.
.
at line the original document.getelementbyid is saved in variable byid.
line checks if a mapping exists.
if so it calls byid with the corresponding randomized value.
note that idmap projects an original value to its randomized version.
the overridden functions and the mappings are inserted to the page and sent over to the client.
as such the element access redirection happens at runtime on the client side.
webranz uses a prede ned set of obfuscations for preventing the mappings from being automatically reverse engineered.
for example idmap is encrypted di erently each time the page is loaded and the overridden element lookup functions have the corresponding decryption methods.
even though in theory the attackers to our approach can still inject some exhaustive scanning javascript to the page to repetitively call the overridden api functions to reverse engineer the mappings the cost is so high that the user experience of the page would be substantially degraded.
more discussion can be found in section .
.
.
overriding third party javascript library apis although third party javascript libraries can provide various element access interfaces using di erent kinds of selectors many of them eventually need to invoke some primitive dom interface function.
take jquery one of the most popular third party js libraries as an example.
jquery provides e cient ways to access html elementsthrough web api functions.
for example .classname selects all elements with class classname .
its underlying implementation is based on the primitive api getelementsbyclassname .
since webranz has overridden the primitive element lookup functions the corresponding jquery selectors can locate the correct html elements as well.
.
hasclass function a .
if classmap .
a classmap .
the actual html element look up .
figure override jquery .hasclass .
besides the two primitive element look up functions webranz also overrides a set of higher level dom manipulation apis such as .addclass .attr and .hasclass .
fig.
shows the handling of .hasclass provided by jquery .
in lines classmap maps a class name to its randomized version.
the actual look up is done using the value after mapping.
obfuscation is also used to protect classmap .
.
.
randomizing dynamically generated elements elements dynamically generated are common on the client side.
the script manipulating them may be from the publisher or third parties such as ad networks.
the new elements and the modi ed element attributes need to be randomized as well otherwise ad blockers may block them.
.
var idsetter idproperty element.
proto .
proto .set .
var idgetter idproperty element.
proto .
proto .get .
object.defineproperty element.
proto .
proto id .
set function arg .
randid randidgenerator ... .
idsetter.call this randid .
.
get function .
return reverseidmap .
.
figure override the setter and getter of id.
overriding property setters and getters .
existing javascript may modify or read attribute values such as the values of idand class.
for example element.id id1 sets id1 as the idof an html element.
to make them consistent we also need to provide bi directional mappings between the original values and the corresponding randomized versions.
fig.
shows an example of such wrappers.
the