isneuroncoveragea meaningful measurefortesting deep neural networks?
fabrice harel canada fabricehc cs.ucla.edu ucla usalingxiao wang lingxw cs.ucla.edu ucla usamuhammadali gulzar gulzar cs.vt.edu virgina tech usa quanquan gu qgu cs.ucla.edu ucla usamiryungkim miryung cs.ucla.edu ucla usa abstract recentefforttotestdeeplearningsystemshasproducedanintuitive andcompellingtestcriterioncalledneuroncoverage nc which resemblesthenotionoftraditionalcodecoverage.ncmeasuresthe proportionofneuronsactivatedinaneuralnetworkanditisimplicitlyassumedthatincreasingncimprovesthequalityofatestsuite.
inanattempttoautomaticallygenerateatestsuitethatincreases nc we design a novel diversity promoting regularizer that can be pluggedinto existing adversarialattack algorithms.we then assess whethersuchattemptstoincreasenccouldgenerateatestsuite that detects adversarial attacks successfully produces natural inputs and is unbiased to particular class predictions.
contrary toexpectation ourextensiveevaluationfindsthatincreasingnc actuallymakesitharder to generate aneffective test suite higher neuroncoverageleadstofewerdefectsdetected lessnaturalinputs andmorebiasedpredictionpreferences.ourresultsinvokeskepticismthatincreasingneuroncoveragemaynotbeameaningful objective for generating tests for deep neural networks and call for a new test generation technique that considers defect detection naturalness andoutputimpartiality in tandem.
ccs concepts software and its engineering software testing and debugging software reliability computing methodologies neuralnetworks.
keywords testing software engineering machine learning neuron coverage adversarial attack acm reference format fabrice harel canada lingxiao wang muhammad ali gulzar quanquan gu and miryung kim.
.
is neuron coverage a meaningful measure for testing deep neural networks?.
in proceedings of the 28th acm joint european software engineering conference and symposium on the foundations of software engineering esec fse november 8 13 virtual event usa.
acm new york ny usa pages.
esec fse november 8 13 virtual event usa copyright held by the owner author s .
acm isbn .
introduction extensive progress in machine learning has enabled computers to model expected behavior with minimal human guidance and hasledtoitsintegrationintomanysafety criticalsystems .
sinceallsoftwareispronetounanticipatedandundesirabledefects creating test suites and assessing their quality is an important part of building confidence duringthe software lifecycle.
to assess the test adequacy of neural networks prior work proposed neuron coverage nc and its variants .
this notionofncbuildsontheintuitionofcodecoverage whilstrecognizing the unique challenges and structures of neural networks.
ncdescribestheproportionofneuronsactivatedbeyondagiven threshold.
the intuition here is that nc captures the magnitude of individual neuron activations independently and thus serves as a proxy for observing model behavior.
based on the implicit assumptionthatincreasingnccanimprovetestsuitequality ncwas usedtoguidetestgeneration .priorworkfoundpreliminary evidencethatnciscorrelatedwithdefectdetectioncapability .
to systematically increase nc during test generation we developanovel diversity promotingregularizer thatcanbeplugged into existing adversarial attack algorithms such as pgd and cw .thisregularizerpenalizesskewedlayer wiseactivationsto promotemorediverseneuronactivationdistributions.asaresult our regularizer can be added to augment existing adversarial attack methods so that these methods can induce previously inactive neurons to fire and thereby increase nc.
while prior work has attempted to improve a few neurons activation magnitudes at each optimization step our diversity promoting regularizer makes this process more systematic by incorporating nc increase and diversification intothe optimization objective.
wethenassessthegeneratedtestsuitesusingthreecriteria.the first isdefect detection capability i.e.
the ability to detect adversarialattacks.thesecondisthe naturalness ofthegeneratedtest inputsandweusetheinceptionscore is andthefr chet inception distance fid to assess how realistic the generatedtestinputsare.thethirdcriterionis outputimpartiality the degreetowhichmodelpredictionsarebiased orunbiased towards particular class labels.
assessing impartiality is inspired by the output uniqueness test selection criteria as the test suite must exercisediverseoutputbehaviorandshouldnotpreferonlyafew outputvalues.wequantifyoutputimpartialityviapielou sevenness an entr opy based measure from the field of ecology.
thisresearchwas donewhile the third authorwas a graduate studentat ucla.
851this work is licensed under a creative commons attribution international .
license.
esec fse november8 13 virtualevent usa fabriceharel canada lingxiao wang muhammadaligulzar quanquangu andmiryungkim equipped with the above evaluation metrics and the novel diversity promoting input generation method we investigate the trade offs between neuron coverage defect detection naturalness andoutputimpartiality.westudytwoimageclassificationdatasets mnist and cifar10 one autonomous vehicle dataset udacity self driving car six classification based dnn models two regression baseddnnmodels andtwoattackalgorithms cwand pgd .
in total test suites over images are generated.
each test suite represents a different configuration of models datasets attackalgorithms andhyperparametercombinationsused for targeting certain layers and promoting diversity in neuron activations.thisextensiveanalysisfindsthatincreasingncactually makesitharder to generatean effective test suite.
defect detection only out of experimental results supported the hypothesis that nc is both strongly and positivelycorrelatedwithdefectdetection i.e.
adversarialattack success whereas were negatively correlated implying that increasing nc islikely to harmdefectdetection.
naturalness only1outof64resultssupportedthehypothesisthatncisbothstronglyand positivelycorrelated with therealismandnaturalnessoftheinputs whereas44were negativelycorrelated implyingthat increasing nc islikely to make the generatedinputsmore unnatural.
outputimpartiality only3outof64resultssupportedthe hypothesisthatncisbothstronglyandpositivelycorrelated with impartiality in output predictions whereas were negatively correlated.
certain class labels have higher nc by default and the process of increasing nc in fact biases perturbations towardsthoseoutputclass labels.
our key contributionsare summarizedas follows we develop a novel regularization technique that can be seamlessly integrated into existing adversarial attack methods to promote neural activation diversity and increase neuroncoverageduringtest suite generation.
weadopttheinceptionscore is andfr chetinception distance fid asgeneric scalable andautomaticmeans ofevaluatingnaturalness.weare thefirsttoapplypielou s evenness to examine the previously under investigated issueofoutputimpartiality intest suites.
we conduct extensive evaluations to show that nc is neitherpositivelynorstronglycorrelatedwithattacksuccess inputrealism andoutputimpartiality whichweargueare importantpropertiesto considerwhen testingdl systems.
we put forwardthe completecodeand artifactsto automaticallygeneratetestsuitesandreplicateourempiricalanalysis at overall our findings invoke skepticism that neuron coverage maynotbeameaningfulmeasurefortestingdeepneuralnetworks.
thisresultisalignedwithrecentskepticismthat whilecodecoverageremainsawidelyusedtestadequacycriterion code coveragemaynotbecorrelatedwithdefectdetection andthus maynotbeameaningfulmetricbyitself.similartohowinozemsevaetal.
highlightanempiricallackofcorrelationbetween traditionalcode coverage and defect defection our result is about a lack of correlation not causation.
we do not claim that nc is useless rather we warn researchersabout thepotentialmisuse ofncastheobjective fortestgenerationbecauseanaiveattemptto increasenc could sacrificeotherdesiredproperties.
these findings call for a new test generation method that not only improves defect detection but also promotes naturalness and output impartiality to create realisticinputs and to exercise diverse outputbehavior.thisargumenttoincorporateadditionalobjectives is aligned with a recent survey of testing ml based systems that lists multiple desired testing properties including correctness model relevance robustness security efficiency fairness interpretability privacy andsurpriseadequacy.satisfyingsuchmultiple objectivesmaynecessitatetheuseofmulti objectivesearchtechniques orenableuserstoeasilyadddomain specificconstraints toguidemeaningfulinputtransformationandoraclecheckingin metamorphic testing .
related work thissectionreviewsrelatedworkondlsystems dnntesting and adversarial attacks.
work relevant to our methodology is described ingreater detailinsection .
deeplearningsystems.
dnnshaveachievedmanybreakthroughs inthefieldofartificialintelligence suchasspeechrecognition imageprocessing statisticalmachinetranslation andgame playing .
eachdnn contains basiccomputational unitscalled neurons which are connected with one another via edges of varying importance or weight.
neurons apply a nonlinear activation function to the inner product of their inputs and weights to output avalue whichbecomestheinputtoasubsequentneuron.layers areusedtoorganizethedirectedconnectionsbetweenneuronsand thereisalwaysoneormorehiddenlayersbetweenoneinputand one output layer.
overall a dnn can be viewed as a meta function that aggregates the weighted contributions from its neural subfunctionstomapsomeinputintosometargetoutput.suboptimally set weights make the dl system vulnerable to erroneous behaviors and the opacity of these numerically derived rules make them difficult to understandanddebug.
dnn testing.
withthesuccessofdeeplearning thereemerged a line of research into testing dnns by leveraging the ideas in traditional software testing methods .
we discuss several of the most relevantdnntesting methodsthatutilizethenc based criteriaas follows.
deepxplore isawhite boxdifferentialtestingalgorithmthat leverages nc to guide systematic exploration of dnn s internal logic.inputimagesare modifiedby severaldomain specific transformations and a transformed imageisselected for inclusion into a test suite if it fools at least one of several similarly trained dnns.
theirstudyfindsthatncisabettermetricthancodecoverageand increasing nc tendsto increase l1 distanceamong inputs.
deeptest is a gray box nc guided test suite generation approachusingmetamorphicrelations.thiseffortintroducedawider range of affine transformations to predict the steering angle of an autonomous vehicle.
deeproad is a gan based metamorphic testing approach that utilizes a shared latent space representation to perform a sophisticated style transfer of some target road condition i.e.
rain snow etc.
toagivensourceimage.deeproadmakes noattempttosystematicallyexplorethepossibleinputspacevia ametriclikencbutfindsthatgan basedtransformationscould expose newfaultybehaviors.
852is neuroncoverage ameaningfulmeasure fortestingdeep neuralnetworks?
esec fse november8 13 virtualevent usa deepgaugeexpandsontheideaofnc byintroducingthree new neuron level coverage criteria and two layer level coverage criteriatoproduceamulti granularsetofdnncoveragemetrics.
to argue for the utility of these metrics deepgauge uses standard adversarial attack techniques to generate test suites.
itthencomparesthencoftheoriginaltestsuiteagainstthatofthe new augmented test suite boosted by the generated adversarial examples.by examples tends to increase nc in terms of most of the proposed criteria.
in section we report our results that explicit effort to increasencactuallydoesnotimprovedefectdetectionandisoften harmfulinterms ofnaturalness andoutputimpartiality.
recenton goingwork foundpreliminaryevidence that the correlation between nc and dnn robustness is rather limitedandthatsimilarstructuralcoveragemetricsfordnnscould be misleading.
specifically their test suites are generated using the standardadversarialattackmethods andtheirevaluationislimited to defect detection only.
our study scope is more comprehensive weuseautomated quantitativemeasuresofnaturalnessandoutput impartialityin addition to defect detection and systematically investigatethetrade offs wedesignanoveldiversitypromoting regularizertoextendexistingadversarialattackalgorithms andwe include both classification modelsand regression models 8models intotal as opposedto classification models only.
while our evaluation focuses on generating test suites others focusonselectingexistingtestsbasedonmodeluncertainty or surprise adequacy i.e.
significantly differentand adversarial .
finally it is worth noting that our proposed output impartiality criteria discussed in section .3is different from the concept of fairness in machine learning .
fairness in ml is concerned with thebiasofanmlmodelwithrespecttosensitiveattributes such asgenderorrace.alongasimilarvein themis asoftwarefairness testing tool by galhotra et al.
automatically detects causal discrimination between input output pairs for user specified attributes.insharpcontrastwiththesenotionsoffairness ouroutput impartiality isameasure ofthe bias onhow a testsuite exercises diverseoutputbehaviors inan ml model.
adversarial attacks.
recent studies show that dnns are vulnerabletoadversarialexamples i.e.
byaddingaverysmall often visually imperceptible perturbation to an input a well trained dnn may produce misclassifications.
while adversarial attacks employ a variety of methods to induce erroneous behavior their effectivenessislargelymeasuredbytheattacksuccessrateofthe perturbedinputsanditsdistortionfromtheoriginalinputs.most optimization based adversarial attacks are based onl2or l norm based perturbation.
some work has attempted toimproveorsidestepthenormconstraintwithdomainspecific transformations.
in our evaluation of neuron coverage we use the standardattackmethodswith l normconstraint becausethese methodsare efficient andcan generatenaturalexamples.
adversarialattackalgorithmsofferbothtargetedanduntargeted attacks for perturbing inputs to be predicted as some other class.
untargeted attacks aim to turn the prediction into any incorrect class whiletargetedattacksaimtoturnthepredictionintoaspecific class.
we use untargeted attacks to give them more freedom to perturb the input in whichever way nc maximization incentivizes.table dnn architectural details dnns datasetprimary layertype layers neurons fcnet5 mnist fully connected fcnet10 mnist fully connected conv1dnet mnist conv1d conv2dnet mnist conv2d resnet56 cifar10 conv2d densenet121 cifar10 conv2d dave2 driving conv2d dave2 n driving conv2d studymethods thissectiondescribesthedatasets dnnmodels andadversarial attackalgorithmsusedforourempiricalstudyanddescribesour diversitypromoting regularizer to increaseneuroncoverage.
.
datasetsanddnns table1summarizesarchitecturaldetailsofallthednnsundertest.
cifar10 isadatasetcontaining32x32x3rgbpixelimages representingtenmutually exclusive classes of naturallyoccurring entitiesthataresuitableforisandfidrealismmeasurement.weuse two well known pre trained dnns a layer resnet and a121 layerdensenet bothofwhichachievecompetitive performance onthis dataset.
mnist is a large well studied dataset containing 28x28x1 gray scalepixelimagesrepresentinghandwrittendigitsfrom0to .
for this dataset we consider two fully connected neural networks fcnet5with5hiddenlayersandfcnet10with10hidden layers and two convolutional neural networks conv1dnet and conv2dnet.
both convolutional neural networks have convolutionallayersfollowedby2fullyconnectedlayers butvarythe primary convolutional layer type from 1d to 2d.
all mnist dnns were trainedfor epochsusing an adam optimizer .
thetworealismmetricsweemploy is andfid are tuned on the internal structures of natural images which generally have both foregrounds and backgrounds.
because such naturalism is not applicable to a digit recognition task we exclude mnist when studyingthe relationship between nc andnaturalness.
udacityself drivingcar isadatasetcontaining480 rgb pixel images extracted from video footage shot by a camera mounted to the front of a moving vehicle and the corresponding angle of the steering wheel for each frame.
we use two pretrained dnns dave2 anddave2 norminit abbreviated dave2n usedbydeepxplore andoriginallyfrom nvidia .
.
measuringneuron coverage peiet al.
formally defineneuroncoveragebythe following neuron cov t x t n x t out n x t n wheren n1 n2 ... represents all the neurons in the dnn t x1 x2 ... represents all test inputs i.e.
those to be perturbed out n x is a function that returns the output value of neuron n for a given test input xscaledto be between and based on the minimum and maximum neuron activations for the layer and 853esec fse november8 13 virtualevent usa fabriceharel canada lingxiao wang muhammadaligulzar quanquangu andmiryungkim .
.
.
.
.
.
.
figure single layer dnn.
represents inputs i.e.
pixels features etc.
.
representsahiddenlayerof5neurons where parentheses denote activations scaled between and for comparison against a nc threshold.
represents an outputlayerof1neuron i.e.
classlogits probabilities etc.
.
tis the user set threshold for determining whether a neuron is sufficiently activated.
figure1depicts an example neural network with a single hidden layer.eachcircular node corresponds to a neuronorganized and color coded by layer.
the hidden layer neurons also contain theirlayer wisescaledactivationsinparenthesesforcomparison against a chosen threshold t. ift thennct .
or ift .
thennct .
.
.
selecting an appropriatethreshold twasanopenissueinearlyncresearch.when measuringnc wevaryathreshold tfortherangeusedbyprior work t .
.
.
.
.
adversarialattackalgorithms usingadversarialattacksfortestgenerationisanalogoustofuzzing in software testing and acts as a means of introducing targeted perturbations.
we select the following two adversarial attack algorithms dueto theirwidespread usage inthe ml literature.
carlini wagner cw constructstheadversarialexample x wherexistheoriginalinputtoattack istheadversarial perturbation bysolving the following optimization problem min l parenleftbigh x y parenrightbig psubjectto x n whereyisthelabelof x lisasuitablelossfunction histhetarget model pdenotes thelp norm such asl l0 l2norms and isascalingconstanttobalancethetheloss landthelp norm.the intuition behindthe cw attack isto find somesmall perturbation thatwecanaddtotheoriginal input xsuchthatit willleadthe targetmodeltochangeitsclassification.toachievethis thecw attack exploits the loss function lto guide the generation of thatwillmakethetargetmodel sclassificationon x different fromx.byminimizingthe lp normof thecwattackcanensure that such perturbation issmall.
in this effort we use the l norm wheredistanceismeasuredbythepixelwiththegreatestmagnitude changefromitsoriginalvalue.as forthelossfunction l we usethelossfunctionprovidedbycarliniandwagner forour classification tasks.
for our regression models we substitute the standardcwlossfunctionforacustomlossdesignedforregression tasksbymeng et al.
.
figure neural activation before and after regularization our regularization significantly promotes nc at t .
.
projected gradient descent pgd finds the adversarial examplex bysolving the following maximization problem max l parenleftbigh x y parenrightbigsubjectto p whereyis the label of x hrepresents the target model lis the loss function for training h is the perturbation limit.
the maximization step will guide us to find the adversarial example and thelpnormconstraintwillmaketheperturbationsmall.forthe pgdattack projectedgradientdescentisperformedtosolvethe aboveconstrainedoptimizationproblem.weconsiderthe l norm constraint as in the cw attack and use the sign of the gradient to efficiently solve the maximization problem.
for the loss functionl wechoosethecross entropylossforclassificationtasks and mean square error for regression tasks.
we vary a different perturbation limit .
.
.
for the norm bounds to explore its possible effectsonnc.
.
extending attacksto increase nc adversarial attacks aim at creating perturbed inputs to achieve twoprimaryobjectives maximizinglosswhilekeeping lp norm distancefromtheoriginalinputssmall.previous research foundthatthesealgorithmsdonotproduceanysignificantvariationinnc.toincreasencwhileleveragingtheskeletonofexisting adversarialattacks wedesignanoveladversarialattackregularizer toincorporatethemaximizationofncasanadditionalobjective.
our regularizer works by penalizing skewed layer wise activations and thuspromotesmore diverseneural activation distributions.diversity promotion has the effect gravitating all neurons toward the average magnitude ofactivation.
here we show theextendedcw attack augmentedwithour newdiversity promoting regularizer min l parenleftbigh x y parenrightbig p summationdisplay.
ldiv outl x u subjectto x n where isa user set diversity weight to controlhowstrongly wewishtoinducehighernc div isadivergencefunction outl isa function that returns the neuralactivations from the lthlayer of the dnn for the perturbed inputs x urepresents a uniform distribution andweconsider l norminourmethod i.e.
choosing p .
we use the kullback leibler kl divergence to implement our div function but any other measure of the distance betweentwoprobabilitydistributionscouldbesuitable.kldivergence measures how much information islost by approximating theneuralactivationsasiftheywereperfectlyuniform thehigher the loss the less diverse the activations.
with a sufficiently high 854is neuroncoverage ameaningfulmeasure fortestingdeep neuralnetworks?
esec fse november8 13 virtualevent usa table originalnc average increase fromoriginal nc andmaximum increase fromoriginal nc nct nct .
nct .
nct .
dnns orig avg max orig avg max orig avg max orig avg max fcnet5 .
.
.
.
.
.
.
.
.
.
.
.
fcnet10 .
.
.
.
.
.
.
.
.
.
.
.
conv1dnet .
.
.
.
.
.
.
.
.
.
.
.
conv2dnet .
.
.
.
.
.
.
.
.
.
.
.
resnet56 .
.
.
.
.
.
.
.
.
.
.
.
densenet121 .
.
.
.
.
.
.
.
.
.
.
.
dave2 .
.
.
.
.
.
.
.
.
.
.
.
dave2 n .
.
.
.
.
.
.
.
.
.
.
.
average .
.
.
.
.
.
.
.
.
.
.
.
table experimentalvariables variable values adversarial attacks cw pgd dnns fcnet5 fcnet10 conv1dnet conv2dnet resnet56 densenet121 datasets mnist cifar10 target layers varies diversity weights cconfidence cw limit pgd .
.
.
regularization weight placed on this objective diversity promotion caninducepreviouslyinactiveneuronstofireandincreasenc.itis important tonote thataddingtheregularizer doesnot necessarily harmtheattacksuccessrateasapproximately23 ofourgenerated suites have attack success.
however there tends to be an inverse relationship between the regularization weight and the attack success rate.
for example the average attack success rate is when is and with increasing to and the average attack success rate is and demonstratingsomedecrease.figure 2showshowourregularization promoteshighernc byhavingmore neurons activated byvisualizingneuronactivation at agiven layer inconv2dnet.
table2shows our regularizer s effectiveness in terms of the averageandmaximumpercentincreasesinncoverthebaseline ncoftheoriginaltestsuiteimagesforallmodels.naturally already highlyactivateddnnsaremoredifficulttoactivatefurther making nct 0undesirable for comparison purposes.
on the other hand nct .5andnct .75activatesignificantlysmallerportionsofthe network.
we report primarilyonnc t .2for visual figures.
as an implementation note our diversity promoting regularizer can target a specific layer contiguous and non contiguous layer subsets oralllayerssimultaneously.inourexperiments wevary thetargetlayerone atatime primarily toevaluatethe sensitivity ofnctothisregularization.forthemnistmodels wetargeteach layerinturn.however forlargermodels wetarget klayers default k evenly spaced in the model starting from the first hidden layer andendingat the outputlayer.
figure nc t .2vs asr the results show that nc does not consistentlycorrelate with defect detection.
findings foreachconfiguration weconstructatestsuiteof100randomly selected images such that each class is equally represented.
this isto ensurethat the suite has complete outputimpartiality before perturbation.
we then use the nc augmented adversarial attack algorithm to perturb the original tests before computing nc at threshold t .
.
.
defectdetection is fid andoutput impartiality.
finally we perform an analysis of test suitesto measurethestrength direction andsignificanceofcorrelation.the experimental conditions are listedintable .
1theparameter cencouragesthesolvertofindanadversarialinstancethatisclassified as aspecificclass with high confidence seecarliniand wagner for detail.
855esec fse november8 13 virtualevent usa fabriceharel canada lingxiao wang muhammadaligulzar quanquangu andmiryungkim table correlation between nc asr grayindicates ap value .
cw asrcorrelations pgd asrcorrelations dnns nc t 0nct .2nct .5nct .75nct 0nct .2nct .5nct .
fcnet5 .
.
.
.
.
.
.
.
fcnet10 .
.
.
.
.
.
.
.
conv1dnet na na na na .
.
.
.
conv2dnet .
.
.
.
.
.
.
.
resnet56 .
.
.
.
.
.
.
.
densenet121 .
.
.
.
.
.
.
.
dave2 .
.
.
.
.
.
.
.
dave2 n na na na na .
.
.
.
average .
.
.
.
.
.
.
.
allcorrelations are presentedina tabularform andwevisualize a sample of the nc t .2results for pgd for presentation purposes.
we adopt a standardized delineation of correlative significance laidoutbyratner tocharacterizevaluesbetween0and .
as weak .
to .
as moderate and .
to .
as strong.
correlation coefficients are alsocolor coded according to whether or not they are statistically significant.
grayindicates a p value .05andsuch valuesare discountedin oursubsequent analysis.
emboldened valuesindicatethattheresultssupporttheassociated hypothesisandallothersdonot.
.
defect detection .
.
studymethod.
sinceourapproachreliesonadversarialattacks to generate test suites we equate the attack success rate asr withdefectdetectionrate ddr andusebothmeasuresinterchangeably.
let pert accrepresent the classification accuracy on the adversarially perturbed suite of test inputs t then ddr is simply asr t pert acc.
in order to use the same metric fortheregressiondrivingmodels wediscretizetheircontinuous outputsinto25equal widthintervals eachrepresentinga2 difference insteeringangle.
.
.
results.
figure3visualizestherelationshipbetweenncand asr brokendownbydnn for the pgd attack whichshowsthat ncisvolatileandncdoesnotconsistentlycorrelatewithdefect detection.evenformodelsthatsharealargedegreeofarchitectural similarity likethefcnet5andfcnet10models thecorrelationsdiffer in both strength and direction reinforcing the unpredictability ofnc.
table4showstheresultsofallconfigurationsbrokendownby an attack algorithm network and tthreshold.
only out of correlationssatisfythehypothesisthatncisbothpositivelyand strongly correlated with defect detection.
independent of direction ofexperimentalconfigurationsshowaweakcorrelation while aremerelymoderate.thecorrelationispositiveinonly36 of configurations negative in52 andnon existent in12 .
defectdetection.
ourfindingsrejectthehypothesisthat nc is strongly and positively correlated with defect detection.only3 ofthe configurationssupportedthis.
.
naturalness dlsystemsaredesignedtosolvereal worldproblemsandtherefore a test suite must have realistic and natural inputs.
in fact several prior techniques are motivated by this naturalness goal and state this requirement.
for example deepxplore uses domain specificconstraintstogeneratetestimagesthatare valid andrealistic .deeptestalsostatesthatitseekstoapplywell behaved transformations to preserve realism .
we explicitly investigatewhethermaximizingnccangeneratetestsuitesreflecting the naturalness ofthe expectedinputspace.
.
.
studymethod.
appraisingthevisualqualityofanimagecan be highly subjective and there is still no definitive solution on how toformalizeitsnaturalness.fortunately researchintogenerative adversarial networks gans has produced several popular metricsforthispurpose.weselectthetwomosthighlycitedmetrics from the gan literature to objectivelymeasure naturalness.
theinceptionscore is formalizesthe conceptof naturalnessbydecomposing itintothe following twosub concepts salience.
of the possible class labels that could be applied to an individual image only one has a highprobability and theothersareverylow.thiscorrespondstotheimagebeing highly recognizable.
diversity.
there are many different kinds of classes present acrossallimagesinthe set.
thefr chet inception distance fid is a measure of similarity between two datasets of images.
it is calculated by computing the fr chet distance between two gaussians fitted to feature representations of the final average pooling layer within the inceptionv3 network .
the inventors heusel et al.
find evidence that fid captures the similarities of generated images better than is and that fid correlates well with human judgement of visual quality.
unlike is the lower the fid value the more realistic the imagesare sincethe distance from theoriginal imagesis smaller.therefore weinvestigatewhethernchasastrong negative correlation withfid.
in the ml community imagenet is considered as a comprehensivedatasetforimageclassifications.thus theauthorsof is and fid derived these metrics based on the models trained on imagenet and demonstrated generalizability to other datasets such assvhn celeba cifar10 andlsunbedrooms .
856is neuroncoverage ameaningfulmeasure fortestingdeep neuralnetworks?
esec fse november8 13 virtualevent usa table correlation between nc naturalness grayindicates ap value .
cw is fid correlations pgd is fid correlations dnns nc t 0nct .2nct .5nct .75nct 0nct .2nct .5nct .
resnet56 .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
densenet121 .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
dave2 .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
dave2 n .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
average .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
figure nc t .2vs naturalness is fid the results show bothstronglynegative andstronglypositive correlations.
therefore we usethe same method that the authorsof fid and is used.
in our experiments we exclude mnist from the measurementofisandfid sinceitisinapplicabletodiscussnaturalnessof highly pre processed mnistdigitrecognition.therefore weuse only cifar10and drivingdatasets for examiningthe relationship between nc andnaturalness.
.
.
results.
figure4depictstherelationshipbetweenncandis andfid brokendownby metric modelfor thepgd attack.once again thewide fluctuationof stronglynegative and stronglypositive correlations underscore the volatility of nc.
table 5shows the resultsforeachattackalgorithm model and tthreshold.only1out of 64correlations satisfy thehypothesis that nc is both positively andstronglycorrelatedwithimprovinginputnaturalness.independentofdirection ofconfigurationsshowaweakcorrelation whileanother45 aremerelymoderate.independentofstrength the correlation ispositive inonly ofcases.unlike the mixed results for is increasing nc invariably increases fid making the inputs less natural.
in fact not a single configurationinthe fidexperiment supports the hypothesis.
morethanhalfofthepgdresultsacrossbothisandfidarestatistically insignificant.
this is because pgd attacks enforce a more strict perturbationlimit whiletheperturbationsofcwattacks are theoretically unbounded and thus minimize the distortion as much as possible.
since this limit tightly constrains the range of measurements itisdifficult to assessthe correlation withnc.
figure test suite .nc t .
.
is .
fid .
figure test suite .
nc t .
.
is .
fid .
figures5and6show a sample of two test suites with a ncdifference.whilebothsetsofimagesarenoticeablydistorted testsuite 140isclearlymoreunnatural.testsuite 33hasanis about33 higherandanfid about29x smaller bothconfirming the intuition that figure 5withnc .
is more natural than figure6withnc .
.here increasingncmakesnoisierand more noticeably perturbedinputs thus aless valuable test suite.
naturalness.
only .
of all experimental results supportedthehypothesisthatncisstronglyandpositively correlatedwithnaturalness.
ofthetestsuitesareactually negatively correlated implying that maximizing neuroncoverageislikely to undermine naturalness.
.
outputimpartiality the final dimension of our investigation probes the relationship between nc and the bias in model predictions.
this idea of measuring the impartiality of model predictions is motivated by the 857esec fse november8 13 virtualevent usa fabriceharel canada lingxiao wang muhammadaligulzar quanquangu andmiryungkim table correlation between nc outputimpartiality grayindicates ap value .
cw oi correlations pgd oi correlations dnns nc t 0nct .2nct .5nct .75nct 0nct .2nct .5nct .
fcnet5 .
.
.
.
.
.
.
.
fcnet10 .
.
.
.
.
.
.
.
conv1dnet .
.
.
.
.
.
.
.
conv2dnet .
.
.
.
.
.
.
.
resnet56 .
.
.
.
.
.
.
.
densenet121 .
.
.
.
.
.
.
.
dave2 na na na na .
.
.
.
dave2 n .
.
.
.
.
.
.
.
average .
.
.
.
.
.
.
.
figure nc t .2vs output impartiality the results show that increasing nc createsbias inoutputbehavior.
output uniqueness test selection criteria in traditional software testing which argues that a test suite must exercise diverse output behaviorandshouldnotpreferonlyafewoutputvalues.investigating the relationship between nc and output impartiality is also motivated by several observations about dnn behavior by prior work.ilyas etal.
foundthatadversarialexamplescanbecreated byincorporating unnoticeable featuresofother classes to confuse thedlmodel.similarly pei etal.foundthatdifferentclassesare associatedwithdistinctive neuronactivation patterns .
considerabalancedtestsuitecomprisedofinputsevenlydrawn from multiple classes.
suppose that the test suite is fed to a model andthe modelpredicts alwaysthe sameclass label.
this indicates output skew.
since one important aspect of testing is to exercise as much diverse output behavior as possible weinvestigate the relationshipbetween nc andthe impartiality ofpredictedoutcomes.
.
.
study method.
we take inspiration for measuring impartialityfromadjacentworkonecologicalbiodiversity .insteadof considering a distribution of species we recast impartiality as a measure of the distribution of class predictions under a uniform inputdistribution i.e.theinitialtestsuitecontainsanequalnumber ofinputsfromeachclass .weusepielou s evennessscore atheoreticallygroundedmeasureofbiodiversity toassesstheskew of the output class distribution.
it uses a normalized shannon s entropy scaledtoarangeof0and1bydividingtheentropyof eachtestsuite soutputdistributionbythemaximumentropygiven the total number of classes.
a high evenness score entails high impartiality low bias .
we define an output impartiality metric for atest suite twith c possible classes indexedby k output impartiality t summationtext.
t ckpt cklogpt ck log c where c is the cardinality of classes and pt ckrepresents the percentageofthetestcases tpredictedtobelongtoclass ck.for theregressionmodels weusethesamediscretizationmethodas before to enable the use of this metric.
.
.
results.
figure7visualizestherelationshipbetweenncand output impartiality by dnn for cw.
the results show that increasingnccreatesbiasinoutputbehavior.table 6showstheresultsof allconfigurationsbyanattackalgorithmand tthreshold.only3out of64 configurationsshowthat ncisboth positivelyandstrongly correlatedwithoutputimpartiality.independentofstrength the correlation is negative in of correlations.
independent of direction of experimentalconfigurations show a weak correlation while32 are moderate.
.
.
investigatingoutputbiascausedbync.
inadditiontothe previoussection scorrelationanalysis wedesignanotherexperiment to investigate which classes are likely to be over represented intheoutputsafteratestsuitehasbeenperturbedtomaximizenc.
the idea of maximizing nc during test suite generation does not take into account that different classes of inputs can already havedifferentbaselinenclevels.forexample itmaybethecase that a set of inputs containing only the dog class in cifar10 hasnct .9whileanothersetofinputscontainingthesame number of cars has nc t .
.
increasing nc may then bias theperturbations andthereforetheoutputpredictions towards 858is neuroncoverage ameaningfulmeasure fortestingdeep neuralnetworks?
esec fse november8 13 virtualevent usa figure output prediction distribution histogram left andcross classprediction heatmap right the class car with the higher nc baseline instead of dog .
below wedescribeanexperimentconductedwiththemnistdatasetto investigate this further.
wegenerate10partitionsofthetestdata onepartitionforeach class byrandomlyselecting100instancesofthatclassfromthe test set.
these partitions are then used to calculate a class specific nc baseline.
since nc depends on the choice of t we repeat nc baselinecalculationfor eachclasslabel while varying tfrom0to .
in an increment of .
.
this process reveals which class label hasthehighestncbaseline thesecondhighestncbaseline and so on.
in other words we rank class labels from the highest nc rank1 to the lowestnc rank10 .
supposethatclasslabel8hasarank andclasslabel1has arank respectivelyfor t .
.
.alowaveragerank forclass8 .
indicatesthatclass8tendstohaveahighncbaseline regardlessof t.ontheotherhand ahighaveragerankforclass1 indicatesthatclass1tendstohavealowncbaseline.therefore during nc maximization the perturbation process may favor overrepresentingclass8intheoutputpredictions.however suppose that class has an average ranking closer to 5 the midpoint of possible labels.
that implies that class may have a high nc baselineunderacertainthreshold butmayhavealowncbaseline under another threshold or places the fifth for all t etc.
thus it would be unlikely for nc maximization to consistently prefer over representation of outputs associated with class label in the resultingtest suite.
table mnist classandaverage rank ofnc baseline class average rank2.
.
.
.
.
.
.
.
.
.
concretely an average rank closer to indicates a greater likelihood of being over represented in the output distribution through nc maximization.table 7reportstheaverageclassranksforthe 10classlabelsofmnist.here wecanseethatclasslabel8tends to have a high nc baseline and that class label tends to have a lowncbaselineacrossdifferentthresholds.thereforeinthencmaximized test suite class is likely to be over represented and class islikely tobe under represented in the outputdistribution.
we first construct a group of inputs with an output impartiality by drawing inputs per class label every class is equally represented in the output distribution because all are correctlypredictedbytheconv2dnettrainedformnist.wethenuseour testgenerationalgorithmwithadiversity promotingregularizer toperturbtheinputsettoincreaseitsnc.thehistogramonthe left in figure 8shows the percentage of model predictions for each class.
the heatmap on the right details how many of the inputs belongingtoeachclassintheoriginalgroupwereperturbedinto to predicting another class label.
this perturbed test suite had a nct .2of .34 about higher than the original images but of all predictions are now for class demonstrating output skew a low impartiality score of .
.
as expected the classes with the low nc baselines e.g.
and are among the most under represented.thisshowsthat whenncmaximizationisused asaguidancecriterion atest generation technique can easily satisfy this criterion by simply perturbing inputs towards the class label withthe highestnc baseline.
outputimpartiality.
only5 ofallexperimentalresults supportthehypothesisthatncisbothstronglyandpositively correlated with output impartiality.
when a few class labels have highernc baselinesthanthe otherclass labels increasingncbiasesthetestsuitetopredominantly incorporatethe features of this preferredsubset.
discussion thissectionincludesadditionalevidenceandrationalethatquestionsthe meaningfulness of neuroncoverage.
.
deepxplore deeptestcomparison it is certainly possible that another method may create a natural test suite with high nc.
therefore we perform similar analysis on the test suites generated by deepxplore and deeptest to see whether similar trade offs exist.
we utilize the authors publicly available implementations to generate tests for the mnist anddrivingdatasets.fordeepxplore notasingle correlationis sufficientlystrongenoughtosupportthethreehypothesesthatnc is positively related withdefect detection naturalness and output impartiality.fordeeptest onlyonecorrelationforoutputimpartiality at nct .5is strongly positive.
in fact our investigation finds that many images generated by deepxplore and deeptest turnrichdrivingscenesintocompletelywhiteimages yetretain theiroriginallabels.nohumanorprogramcanpredictasteering angle from such an unnatural input.
whiletheresultsfromdeepxploreanddeeptestmayhavebeen sufficient to warrant skepticism about nc our nc maximizing approach is easily applicable and systematic.
first it can probe the behavior of a single model while deepxplore s differential testing requires multiple models.
as dnns become large and costly to train differential testing may become less practical.
second by directly extendingadversarial attacks thatmaximizedefective behaviorandminimizethenorm distancefromtheiroriginalsources thegeneratedtestsuiteisordersofmagnitudemorenatural.for instance our test suites have average fid scores and higherthanthosecreatedbydeepxploreanddeeptestrespectively.
whileitiscertainlypossiblethatyetanothermethodmaycreate 859esec fse november8 13 virtualevent usa fabriceharel canada lingxiao wang muhammadaligulzar quanquangu andmiryungkim anaturaltestsuitewithhighnc ourcomprehensiveexperimentation of test configurations suggests that increasing nc is unlikely to correlate with defect detection naturalness and outputimpartiality.triangulationbetweentheseapproachesincreases confidence aboutthe external validity ofour findings.
.
howmeaningful isaneuron?
the viability of nc as a dnn testing metric is underpinned by the idea that each neuron independently extracts a specific input feature ratherthancollaboratingwithotherneurons.however recent research into dnnvisualization techniques has demonstratedthatthisisnotso neuronindependenceandlocal feature extraction do not accurately characterize dnn behavior.
instead the neurons in a layer interact with one another to pass information to subsequent layers and nc does not capture the richnessofsuchneuroninteractions.whiletheprobabilitythata neuron distinctly encodes a specific feature increases the deeper it issituatedinthednn manyoftheneuronsrepresentanamalgam ofverydifferentabstractconcepts likethevisualizationofpixels leadingtohighactivationsofcertainneuronsinfigure .this observation raises serious doubts about whether neurons are even the right semantic units for understanding dnn behavior further questioning the viabilityofnc as ameaningfultest metric.
figure visualization of neuron activations shows mixed concepts cats foxes andcars .
doesnc maximizationmake sensefor testingdnns?
assumingthebestcasescenarioofneuronsindependentlyencoding specificfeatures ismaximizationofncevendesirable?consider eachneuronina dnn as a binaryclassifier checkingfor thepresenceorabsenceofaspecificfeaturewithintheinput.for nneurons in a dnn there are 2npossible activation patterns.
in general establishing a single objective to maximize nc could easily target having onepossible pattern where all neurons are activated.
as asimplifiedexample consider twoneurons ina dnntrained for autonomousdriving.
supposethat one detectsthe presence of vehicles and the other detects stop signs.
nc maximization as a single objective in test generation can be easily satisfied with a single image containing both a vehicle and a stop sign together.
subsequently such limited focus on nc could easily produce a test suite that does not cover other interesting portions of the potential inputspace.
conclusion recentefforttotestdeeplearningsystemshasproducedanintuitive testing adequacy metric called neuron coverage nc and its severalvariants.
prior work has also produced severaltestgenerationtechniquesthatusencasaguidancecriterionandsomehasfound evidence that adding adversarial inputs to an existing test suite tendsto increasenc.
tosystematicallyincorporatencmaximizationtoexistingadversarialattackalgorithms wedesignedanoveldiversitypromoting regularizerthatcanbepluggedintoexistingattackalgorithmsto increasenc.wethenassessedthequalityoftheresultingtestsuites intermsofdefectdetection naturalness andoutputimpartiality.
fromourevaluationof2 095experimentalconfigurationsinvolving dnns datasets and adversarial attack algorithms we conclude that nc should notbe blindly trusted as a guidance metric for dnntesting .whilewe do notclaimthat ncis useless increasing ncactuallyhasaharmfuleffectbyproducinglessnaturalinputs andbycreatingaskewinoutputdistribution.thisresultisaligned withrecentskepticismthatcodecoverageintraditionalsoftware testingisnotstronglycorrelatedwithtestsuiteeffectivenessand thus maynot be ameaningfulmetric byitself .
wethereforeadvocateincorporatingothertestobjectivessuchas naturalness andoutputimpartiality andusemulti objectivesearch techniquesfortestingdlsystems.ourexperienceofadaptingexistingadversarialattackalgorithmsfortestgenerationhasshownthat itisfairlyeasytocreateinputsthatleadtomispredictionbysacrificing naturalness and that it is also fairly easy to perturb a test suite toproduceahighncscorebyskewingtheoutputdistribution.our results call for more systematic research on how to generate realisticinputsthatreveal meaningful undesiredbehaviorindlsystems.
sucharesearchdirectionmayrequirenewmethodstoempower userstoeasilyspecifydomainspecificconstraintsexpressivelyand to leveragethoseconstraintsto guide test generation.
peropensciencepolicy thecodeanddataisavailableat https .
acknowledgement we thank anonymous reviewers for their comments.
the participants of this research are in part supported by nsf grants ccf1764077 ccf ccf satc onr grant n00014 intelcapa grant samsunggrant googlephd fellowship andthe alexander vonhumboldtfoundation.