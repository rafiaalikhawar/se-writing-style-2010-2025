singapor e management univ ersity singapor e management univ ersity institutional k nowledge at singapor e management univ ersity institutional k nowledge at singapor e management univ ersity resear ch collection school of computing and information systems school of computing and information systems api method r ecommendation via explicit matching of api method r ecommendation via explicit matching of functionality v erb phr ases functionality v erb phr ases wenkai xie xin peng mingwei liu christ oph treude singapor e management univ ersity ctreude smu.edu.sg zhenchang xing see next page for additional authors follow this and additional works at https ink.libr ary.smu.edu.sg sis r esear ch part of the softwar e engineering commons citation citation xie w enkai peng xin liu mingwei treude christ oph xing zhenchang zh ang xiao xin and zh ao wenyun.
api method r ecommendation via explicit matching of functionality v erb phr ases.
.
esec fse pr oceedings of the 28th a cm joint e uropean softwar e engineering conf erence and symposium on the f oundations of softwar e engineering vir tual no vember .
.
available at available at https ink.libr ary.smu.edu.sg sis r esear ch this conf erence pr oceeding ar ticle is br ought t o you for fr ee and open access b y the school of computing and information systems at institutional k nowledge at singapor e management univ ersity .
it has been accepted for inclusion in resear ch collection school of computing and information systems b y an authoriz ed administr ator of institutional k nowledge at singapor e management univ ersity .
for mor e information please email cher ylds smu.edu.sg .
author author wenkai xie xin peng mingwei liu christ oph treude zhenchang xing xiao xin zh ang and w enyun zhao this conf erence pr oceeding ar ticle is a vailable at institutional k nowledge at singapor e management univ ersity https ink.libr ary.smu.edu.sg sis r esear ch api method recommendation via explicit matching of functionality verb phrases wenkai xie fudan university chinaxin peng fudan university chinamingwei liu fudan university china christoph treude the university of adelaide australiazhenchang xing australian national university australiaxiaoxin zhang fudan university china wenyun zhao fudan university china abstract due to the lexical gap between functionality descriptions and user queries documentation based api retrieval often produces poor results.
verb phrases and their phrase patterns are essential in both describing api functionalities and interpreting user queries.
thus we hypothesize that api retrieval can be facilitated by explicitly recognizing and matching between the fine grained structures of functionality descriptions and user queries.
to verify this hypothesis we conducted a large scale empirical study on the functionality descriptions of jdk and android api methods.
we identified different functionality verbs from the descriptions which were grouped into functionality categories and we extracted phrase patterns from the verb phrases of the descriptions.
building on these findings we propose an api method recommendation approach based on explicit matching of functionality verb phrases in functionality descriptions and user queries called prema.
our evaluation shows that prema can accurately recognize the functionality categories .
and phrase patterns .
of functionality description sentences and when used for api retrieval tasks prema can help participants complete their tasks more accurately and with fewer retries compared to a baseline approach.
ccs concepts software and its engineering documentation software development techniques information systems query representation document representation .
w. xie x. peng m. liu x. zhang and w. zhao are with the school of computer science and shanghai key laboratory of data science fudan university and the shanghai institute of intelligent electronics systems china.
x. peng is the corresponding author pengxin fudan.edu.cn .
permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
copyrights for components of this work owned by others than acm must be honored.
abstracting with credit is permitted.
to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
request permissions from permissions acm.org.
esec fse november virtual event usa association for computing machinery.
acm isbn .
.
.
.
api retrieval api documentation functionality description acm reference format wenkai xie xin peng mingwei liu christoph treude zhenchang xing xiaoxin zhang and wenyun zhao.
.
api method recommendation via explicit matching of functionality verb phrases.
in proceedings of the 28th acm joint european software engineering conference and symposium on the foundations of software engineering esec fse november virtual event usa.
acm new york ny usa pages.
https introduction finding the right apis that provide the desired functionalities is essential in many software development tasks.
popular api libraries such as jdk and android provide reference documentation which includes functionality descriptions for api classes and methods.
however due to the lexical gap between functionality descriptions provided by api developers and search queries by api users documentation based api retrieval often produces poor results.
researchers have tried to use word embedding techniques to bridge the lexical gap by learning the statistical relevance between words such as convert and transform image and color json and xml .
however these methods do not explicitly parse the fine grained structures of functionality descriptions and user queries neither do they explicitly match the semantic roles of different parts of functionality descriptions and user queries.
as such these methods may lead to poor matching results when fine grained linguistic details of functionality descriptions and user queries must be taken into account to produce satisfactory matching.
for example existing methods cannot distinguish convert integer to string from convert string to integer because they do not understand the source andgoal roles of the two descriptions.
to battle this issue some methods use more advanced deep learning models e.g.
recurrent neural network to learn sequential patterns of natural language descriptions and api call sequences.
they map the query api matching problem as a machine translation task.
however these methods are supervised learning methods which require large scale training data pairs of method comments 1015esec fse november virtual event usa wenkai xie xin peng mingwei liu christoph treude zhenchang xing xiaoxin zhang and wenyun zhao and api call sequences and can capture only the most frequent queries and api usage patterns.
therefore for the long tail of less frequently used apis developers still have to resort to other means such as documentation based retrieval.
the lexical gap between api functionality descriptions and user queries is much wider than just sequence mismatching.
for example the api java.lang.integer.parseint string is the correct api for the query convert string to integer .
unfortunately the functionality description of this api is parses the string argument as a signed decimal integer.
.
none of the deep learning methods can handle this wide gap between the functionality description and the user query.
to match functionality descriptions and user queries on either side of this gap we must understand the fine grained structures of the sentences and the semantic roles of their parts for example the key verb phrases and the semantic roles source and goal involved in the phrases convert source to goal and parse source as goal .
some researchers have attempted to address this gap by demanding external resources e.g.
stack overflow discussions to augment user queries for example biker and qeck but these can only capture the most discussed apis in external resources and suffer from information noise in these external resources.
in this work we consider that verb phrases and their phrase patterns are essential in both describing the functionality of api methods and interpreting user queries.
we call the verbs used to describe the method functionalities functionality verbs .
consequently we argue that user queries and api descriptions should be matched in terms of functionality verbs and phrase patterns according to the semantics they express rather than their lexical similarity.
previous research has also considered the importance of verb object structures in source code identifiers and for software documentation treude et al.
focused on extracting development tasks which are described by verbs from a predefined list associated with a direct object and or a prepositional phrase.
however little is known about how verb phrases are used in api functionality descriptions and user queries and how inconsistencies in their use influence api retrieval.
we hypothesize that most api functionalities can be described with a limited number of commonly used functionality verbs and that the functionalities can be further classified into a small number offunctionality categories .
for example the verb return when used in the phrase return source as goal expresses the functionalities of transformation and conversion and these functionalities can be classified into the same category.
we further hypothesize that thefunctionality categories andphrase patterns of user queries and api descriptions can be automatically recognized.
finally we argue that fine grained matching can be performed between user queries and api descriptions by aligning their functionality categories and phrase patterns .
for example both the query convert string to integer and the api description parses the string argument as a signed decimal integer can be classified into the same functionality category convert transform turn and the participants i.e.
source and goal of their phrase pattens can be aligned by explicit matching.
in order to verify our hypotheses we conduct an empirical study to investigate the functionality verbs andfunctionality categories as well as the phrase patterns present in the api functionality descriptions from the reference documentation of jdk and android.we manually analyzed the functionality descriptions of jdk and android api methods.
these descriptions contain different functionality verbs and these verbs can be grouped into functionality categories based on their semantics in the description context.
each functionality category contains to .
on average and .
on median different functionality verbs .
for all functionality categories of the api descriptions are described by phrase patterns mean .
median .
building on our empirical findings on functionality verbs we propose an api method recommendation approach based on explicit matching of functionality verb phrases in user queries and api descriptions which is called prema.
the approach trains a classifier to predict the functionality categories summarized in our empirical study of api descriptions.
it then matches the description sentences with the phrase patterns of the corresponding functionality categories to determine the adopted phrase patterns .
to recommend api methods prema parses the api query issued by the user in the same way.
it then matches the parsed user query with the parsed api description sentence by aligning their functionality categories andphrase patterns .
finally prema returns completely or partially e.g.
the same functionality categories but different operation objects matched apis as the query results together with a linguistic explanation of the matching.
we evaluated the sentence analysis accuracy of prema based on the data annotated in the empirical study.
the results show that the accuracy of functionality category classification and phrase pattern recognition is high .
and .
respectively .
we also evaluated the performance of prema in documentation based api retrieval by comparing it with a word2vec based approach.
the results show that the participants using prema completed their tasks more accurately .
versus .
with fewer retries .
versus .
and using less time .29s versus .42s .
overall this paper makes the following contributions we conducted a large scale empirical study on the functionality descriptions of jdk and android api methods.
we identified commonly used functionality verbs functionality categories and phrase patterns from the descriptions.
we propose an api method recommendation approach based on explicit matching of functionality verb phrases in user queries and api descriptions.
we evaluated the proposed approach in terms of the accuracy of api functionality description analysis and the performance of api retrieval.
the data and analysis results of the empirical study and evaluation are included in the replication package .
definitions we define the main concepts and relationships used for the explicit modeling of api functionality descriptions as shown in figure .
the reference documentation contains for each api method a description of its main purpose.
we call this description the api functionality description orf description for short .
the f description may include several sentences that describe the functionalities of the method which we call functionality sentences orf sentences .
each f sentence may include several verbs or verb phrases but 1016api method recommendation via explicit matching of functionality verb phrases esec fse november virtual event usa exactly one functionality verb orf verb which denotes the main action of the functionality.
for example the f sentence attempts to cancel the execution of this task includes two verbs attempt and cancel while only cancel is the f verb .
for a compound sentence that describes multiple functionalities we can split it into several f sentences each describing only one functionality.
figure terminology model af sentence can be classified into a functionality category or f category based on the meaning of its f verb in the current context.
for example the api org.omg.cosnaming.namingcontextextoperations.to name string contains this f sentence in its f description this operation converts a stringfield name into an equivalent array of name components.
it includes the convert f verb underlined and belongs to the convert transform turn f category defined as transform something into other forms .
two f sentences may be classified into two distinct f categories even if they share the same f verb .
that is because the f verb may have different meanings in different contexts.
for example return is widely used in f sentences asf verbs with different meanings that are denoting different f categories such as get return obtain e.g.
returns the state of this thread check test determine e.g.
return if the type is a cube map or convert transform parse e.g.
returns the bigdecimal as a character array .
at the same time one f category can correspond to several distinct f verbs that share meaning in different contexts.
for example in the jdk and android reference documentation there are many f verbs with the meaning captured by the create build construct f category such as create build produce construct generate establish make instantiate etc.
the f sentences from a f category share a set of phrase patterns orp patterns and each sentence conforms to one of them.
a p pattern consists of the following elements a f category e.g.
convert transform turn prepositions e.g.
in at from semantic roles which depict conceptual relations among participants in the p pattern e.g.
location patient source goal clause leaders e.g.
that whether clauses e.g.
a clause led by whether infinitives e.g.
to be called and gerunds e.g.
reading a file .
for example the f sentence this operation converts a stringfield name into an equivalent array of name components.
follows the v source to as into goal p pattern where v indicates the f category while source and goal denote semantic roles.
note that semantic roles are consistent despite the alternations in the syntax thus it is possible to align the semantic roles between different p patterns .
verbnet is a domain independent and broad coverage verb lexicon for english.
it contains about verbs.
they are classified into over classes and each class contains a set of syntactic frames that the members of the class commonly use.
we did not use the verbnet classes and frames as our f categories andp patterns for thefollowing two reasons.
first some verbs used in the api f sentences e.g.
unmarshal iterate are not included in verbnet.
second the verbnet classes are not defined by the meanings of verbs.
for example open and close are both in the same class crane in verbnet but are classified into different f categories .
we decided to annotate our own f categories and p patterns but use the semantic roles defined in verbnet duration location goal source patient instrument beneficiary attribute theme material topic product .
empirical study we conducted an empirical study to understand what f verbs p patterns and f categories are present in api f sentences .
specifically we focus on answering the following research questions rq1.
what verbs are used in the api f sentences ?
rq2.
what f categories can the f sentences be classified into?
rq3.
what p patterns are used in the f sentences from each f category ?
we focus on jdk and android apis based on the reference documentation of jdk .
and android .
we present and analyze the results of the empirical study in order to answer the three research questions.
complete data and analysis results corresponding to the empirical study are included in the replication package including complete f sentences f verbs f categories andp patterns .
.
study design .
.
verb analysis rq1 .
from the semi structured api declarations in the jdk and android reference documentations we extracted and api methods including constructors respectively using beautifulsoup .
we filtered out the methods that have no f description or with a f description that meets one of the following conditions stating a method overriding e.g.
overrides hashcode stating a method deprecation e.g.
deprecated.
use gettimetolive instead suggesting to check the description of another api e.g.
see getenv suggesting another api with the same functionality e.g.
same as charcount int .
after the filtering we obtained methods jdk and android .
for each remaining method we extract the first sentence of its description from the reference documentation as its f sentence .
if the sentence is a compound sentence we split it into multiple f sentences .
we used spacy an open source library for natural language processing to parse the f sentence of each api method and identify the verbs used in the sentence.
if a f sentence includes more than one verb we considered all of them for answering the first research question.
we used spacy to lemmatize the identified verbs to their normal forms.
once extracted we analyze the frequency and distribution of the verbs.
.
.
functionality category analysis rq2 .
the identification of the f categories and f verbs from jdk and android was done via the qualitative analysis of the f sentences using open coding.
the coding was done in two phases coding protocol definition phase and annotation phase.
in the first phase experts identified and defined a set of f categories i.e.
codes based on a subset of api 1017esec fse november virtual event usa wenkai xie xin peng mingwei liu christoph treude zhenchang xing xiaoxin zhang and wenyun zhao descriptions.
in the annotation phase a larger group of annotators were trained to use the coding protocol developed in the first phase to code a larger set of f sentences .
selecting random f sentences for annotation would likely result in a large number of sentences with get set verbs given their prevalence.
instead for the first coding phase we randomly sampled 10f sentences for each of the most frequently used verbs at the root of the parse tree i.e.
the verbs of the main clause .
we focus on these verbs as they are more likely to be f verbs remember that rq1 considered all verbs in the f sentences .
this number of verbs i.e.
is selected based on the results of rq1 see section .
.
these verbs cover of the f sentences used in rq1 all of the most frequent verbs identified in rq1 are root node verbs.
after eliminating duplicates we obtained f sentences from jdk and from android used for the initial coding phase.
for the annotation phase we randomly sampled another apif sentences regardless of the frequency of the verbs.
to have a more balanced dataset i.e.
not too many get set sentences we further refined the samples based on their root node verb.
if a rootnode verb appears in more than of the sampled f sentences then we randomly selected and kept of those f sentences .
we kept all the f sentences for the root node verbs that occur in fewer than samples.
in this way f sentences using unpopular verbs may also be included.
finally we obtained f sentences for the annotation phase from jdk and from android .
the initial coding was done by three of the authors who are experts in java and android development as follows.
first an api f sentence is randomly allocated to an annotator.
second the annotator examines the api and its f sentence and identifies the f verb used in it.
third the annotator attempts to classify i.e.
annotate the api f sentence into an existing f category i.e.
existing code .
if no code is found then a new code i.e.
f category is created and a definition provided.
a special code unknown is created to accommodate the sentences that were not actually f sentences e.g.
equivalent to the codepointcount char int int method for convenience .
each f sentence is coded by two annotators independently and if their annotations f verb orf category are different then a third annotator is assigned to resolve the conflict.
the above process was repeated until all the samples were annotated.
the annotation was done by students phd and ms students who are familiar with java and android development.
before annotation the students were trained by the experts who defined the coding instrument.
the training was conducted in group and took more than one hour.
more material about training including examples is available in the replication package .
the annotation was done using the codes i.e.
f categories identified in the coding protocol definition phase and followed the same process.
as in the first phase the annotators could create new codes when needed.
the code for each f category is one of the f verbs named thelabel f verb which is frequently used but not necessarily the most frequently used best reflects the meaning of the f category and is not used to label another f category .
to facilitate the coding we developed a web based annotation tool.
the gui of the annotation tool is available on the web .
.
.
phrase pattern analysis rq3 .
as mentioned above in order to capture the functionality of a method the f verb is not enough andp patterns are important to establish the context.
we investigate the p patterns used in each f category identified in rq2 by annotating all the initial coding phase and annotation phase f sentences .
for each f sentence two authors annotated the p pattern independently based on the verbnet annotation guidelines .
if the annotations are different a third author was assigned to resolve the conflict by majority voting strategy.
.
verb analysis results rq1 we identify different verbs from the f sentences of the jdk and android api methods.
table shows the top most frequently used verbs and their occurrences.
return is by far the most used verb followed by set and get .
these are not surprising based on our experience with the code and documentation.
an interesting observation is that these top verbs are not domain specific which implies that we expect them to occur in other libraries from different domains as well.
we inspected all the verbs and we found that most of them are not domain specific to android or java .
for example dial is a domain specific verb to android.
followings are some of the identified domain specific verbs and their frequency mute denigrate suffix prefix negotiate dial snooze absorb advertise roam introspect .
table top most frequently used verbs verb occu verb occu verb occu return indicate do set determine retrieve get write give call change contain have obtain support create read specify use check convert add insert update remove perform describe invoke start notify figure shows the distribution of the verbs y axis in log scale .
the distribution analysis reveals that the .
most frequent verbs appear in of the api f sentences .
if we exclude return as outlier then the .
most frequent verbs appear in of the api f sentences that do not include return .
if we include return then the .
most frequent verbs appear in .
of the api f sentences .
in other words a relatively small number of verbs covers almost all api f sentences .
.
functionality categories rq2 given the number of annotators and codes we used cohen s kappa coefficient to measure the agreement rate between the annotators.
for the initial coding phase kappa is .
and for the second annotation phase it is .
.
the annotators identified f categories not including unknown of which were identified in first coding phase and in the second one.
among the f categories cover both jdk apis and android apis cover only jdk apis and cover only android apis.
1018api method recommendation via explicit matching of functionality verb phrases esec fse november virtual event usa figure distribution of the verb occurrences the f categories contain f verbs eight of which appear in more than two f categories .
return appears in seven f categories determine appears in six f categories indicate appears in five tell retrieve and give appear in four while get and notify appear in three.
there are f verbs that appear in two f categories .
all other appear in a single f category .
on average a f category contains .
f verbs median .
.
the convert transform ... f category contains the most f verbs i.e.
while .
f categories contain a single f verb .
note that unpopular verbs may be included in a f category together with popular verbs.
we compared the f verbs with the list of programming actions published by treude et al.
.
their programming tasks have similar semantics to our f verbs but are based on a much smaller data set.
we find that of our f verbs .
were also identified by them as programming actions while our empirical study identified an additional f verbs .
we define the label f verb as a representative f verb of one f category .
for each f category three of the co authors chose the one f verb from all f verbs in this f category as the label f verb of this f category through discussion.
two heuristics were used for choosing the label f verb the co authors check f verbs in thef category by frequency from high to low until the label f verb is determined.
a f verb is only considered as label f verb if its meaning covers the meaning of the f category and there is no confusion with another f category .
the top f categories based on the number of f sentences and their label f verbs are shown in table .
.
phrase patterns rq3 two annotators were considered to reach an agreement if their p pattern annotations for a f sentence are the same.
as a result the agreement rate for p pattern annotation is .
i.e.
almost perfect agreement .
the p patterns identified from the f sentences of the same f category are aggregated to get the p patterns of each f category .
note that p patterns that belong to the same f category and only differ in prepositions or clause leaders were merged into one for example v source to as into goal for the convert transform parse f category .table top most frequently used f categories f categories label f verb f sentences get return obtain ... get set control configure ... set check test determine ... check create build construct ... create append add insert ... append call invoke notify ... call perform execute run ... perform convert transform parse ... convert remove delete exclude ... remove write record output .. write figure distribution of p pattern over f categories figure shows the distribution of p pattern numbers over f categories .
the number of p patterns for each of the f categories varies between and mean median .
the top f categories that have the most p patterns are set control configure append put add and get return obtain .
there are f categories that have only one p pattern e.g.
lock touch press collect recycle sample .
for each f category we analyzed the number of p patterns that cover of the f sentences indicated by the red line in figure .
we found that for all the f categories of the f sentences are described by p patterns mean .
median .
for example the append add insert f category has p patterns while of them cover of the f sentences .
the identified p patterns have semantic roles.
the numbers ofp patterns that have semantic roles are .
.
.
.
and .
respectively.
we can see that of p patterns are simple ones with or semantic roles.
an example of p patterns with semantic roles is v patient from source as into to goal for the convert transform parse f category af sentence following this p pattern is convert a long datetime from the given time scale to the universal time scale.
.
approach our empirical study shows that most of the jdk and android api functionality sentences can be classified into a limited set of f categories with p patterns .
on average used for each f category .
these findings imply how verb analysis can be used 1019esec fse november virtual event usa wenkai xie xin peng mingwei liu christoph treude zhenchang xing xiaoxin zhang and wenyun zhao for matching between an api query and a f sentence first recognize their f categories and p patterns then align them based on f categories andp patterns for fine grained matching between corresponding participants.
based on this idea we propose an approach prema for matching of api functionality descriptions as shown in figure .
given f sentences from api reference documentation the approach parses the sentences by analyzing their f categories andp patterns .
the parsed f sentences are then stored for further analysis.
when used for api searching prema parses the api query issued by the developer in a similar way.
it then matches the parsed api query with the parsed f sentences by aligning them based on f categories and p patterns .
the api matching results include completely or partially e.g.
the same f categories but different participants matched apis and their f sentences together with explanations of the matching.
our implementation uses beautifulsoup to parse the html pages of api reference documentation.
it extracts all api methods with their f description and filters out invalid api methods using rules same as in section .
.
.
for each remaining method we extract the first sentence of its description from the reference documentation as its f sentence for functionality sentence parsing.
figure overview of prema .
functionality category classification the f categories and annotated f sentences provided by our empirical study enable automated classification of f sentences into f categories .
we treat f category classification as a text classification task and use the f sentence annotation data to train a classifier for the task.
the classifier takes a sentence f sentence or query as input and returns one of the f categories or the category unknown as the output.
we implement the classifier based on bert bidirectional encoder representations from transformers a state of the art language model.
the model is used for learning representations of sentences it takes as input a sequence of words and outputs the distributed vector representation of the word sequence .
google provides two pre trained bert models bert base bert large which were trained on a large scale unlabelled corpus to capture rich semantic features.
the pre trained models can be customized by adding an output layer and fine tuned based on labelled data for specific nlp natural language processing tasks such as text classification and question answering.
we use the pre trained bertbase model and add a classification layer fully connected layer with the f categories identified in our empirical study and then fine tune the model based on a set of training data consisting of f sentence f category pairs.
.
phrase pattern analysis given a sentence f sentence or query and its f category phrase pattern analysis determines the p pattern used in it.
as our empirical study has identified a set of p patterns for each f category the analysis only needs to match the sentence with the p patterns of thef category that it belongs to.
we use spacy which performs well on java api documentation to do pos part of speech tagging and dependency parsing of the sentence.
after that we identify the f verb used in the sentence and then the p pattern .
.
.
functionality verb identification.
the functionality category classification does not identify the f verb used in the sentence so we need to identify the f verb based on pos tagging and dependency parsing.
our empirical study identified a set of f verbs for each f category and multiple of them may appear in the sentence.
thus functionality verb identification just needs to choose from thef verbs of the f category that the given sentence belongs to.
we use a heuristic based approach to choose from the candidate verbs.
given a sentence we traverse its dependency tree in preorder.
the first candidate verb that is traversed is considered as the f verb of the sentence.
if no candidate verb is found after traversing the entire dependency tree the first verb traversed in the sentence is considered as the f verb indicating a new f verb for the f category that was not identified in the empirical study.
figure shows a dependency tree used as an example of functionality verb identification.
the sentence belongs to the f category get return obtain .
the arrows from a token indicate the syntactic children that appear before and after the token and the labels on the arrows indicate the dependency types.
for example dobj pobj and xcomp refer to direct object object of the preposition and open clausal complement respectively.
this sentence has two verbs i.e.
use and get .
when traversing the dependency tree in preorder use is the first traversed verb as it is the root node but it is not in the f verb set of the f category get return obtain get is the second traversed verb and it is in the f verb set of the f category so we choose it as the f verb of the sentence.
figure an example of functionality verb identification .
.
phrase pattern identification.
to identify the p pattern we need to match the given sentence with the p patterns of the f category that the sentence belongs to.
to do so we need to first identify the core clause of the given sentence that describes the functionality of the api method.
this can be done by finding the subtree of the dependency tree rooted at the f verb .
for example for the f sentence shown in figure the get clause underlined is the core clause that describes the functionality.
then from the core clause we extract the syntactic pattern spby analyzing the dependency tree of the core clause.
we replace the words in the core clause with a placeholder for 1020api method recommendation via explicit matching of functionality verb phrases esec fse november virtual event usa syntactic components using the following rules replace verb with v replace nouns and noun phrases with np replace the object clause and adverbial clause with s replace gerunds with s ing and replace infinitive with s inf .
clause leaders e.g.
that whether and prepositions e.g.
in at to in the core clause are retained.
the replacement is done by recursively visiting the subtree of the core clause.
for example the syntactic pattern identified for this method will start profiling if isprofiling returns true.
is v s ing if s rule and and the syntactic pattern identified for registers the parameter named parametername to be of jdbc type sqltype.
is v np s inf rule and .
after obtaining the syntactic pattern spof a sentence we find the most similar p pattern among candidate p patterns which are all p patterns of the f category .
we split spandp patterns into small components for this comparison.
prepositions with subsequent np or semantic roles are considered as a component.
for example v patient for beneficiary can be split into three components v patient and for beneficiary .
we compare each p pattern with spby the order of components to get the matching number of components in the sp.
np could match with any semantic role in p pattern .
if not all components in p pattern could be matched in sp we remove this p pattern from the candidate p patterns .
finally we choose the p pattern from the candidate p patterns with the highest number of matching components as the p pattern of the sentence.
for example for the sentence in figure after matching v np for np with all p patterns in the f category get return obtain we obtain two candidates v patient and v patient for beneficiary and the matched number of components is and respectively.
thus we choose v patient for beneficiary as the p pattern .
.
sentence alignment and api matching given a parsed api query qwe match it with each parsed f sentence fsand calculate their matching score by aligning them based on f categories andp patterns .
the matching score is calculated with equation by combining three different similarities f category similarity semantic role similarity and text similarity.
then we rank api methods by matching score and generate the explanation for each method.
score q fs simc q fs simr q fs simt q fs .
.
functionality category similarity calculation.
thef category similarity simc q fs measures whether the f categories ofqand fsare the same.
if qandfsare classified into the same f category simc q fs otherwise simc q fs .
.
.
semantic role similarity calculation.
the semantic role similarity simr q fs measures the similarity between corresponding semantic roles of qandfsusing entity based matching.
if qand fsare classified into different f categories simr q fs .
otherwise we calculate simr q fs in three steps i.e.
entity alignment entity linking and entity matching.
first we align the corresponding entities between qandfs based on semantic roles.
an entity is a noun phrase in qorfs.
an entity eqinqand an entity efsinfscan be aligned if and only if they play the same semantic role in qandfs.
figure shows an example of entity alignment.
in this example the string argument figure an example of entity alignment in the f sentence is aligned with a string in query and int in query a signed decimal integer in the f sentence is aligned with an int in query and string in query .
in this way it is easy to determine that query matches better with the f sentence than query .
if an entity eqinqhas two corresponding entities efs1 andefs2infs eqis aligned with both efs1andefs2 and vice versa.
second we link entities in qandfsto the corresponding entities in a general knowledge graph wikidata in the current implementation .
based on the linking we can use the knowledge in the general knowledge graph to calculate the similarity between the entities in qandfs.
for example wikidata provides knowledge like string is a sequence of characters and a data type and str is an alias of string .
to consider the linking between an entity esin qorfsand an entity ewin the general knowledge graph we first do preprocessing tokenization stop word removal and lemmatization on the noun phrase of esand then calculate the following two similarities between esandew morphological similarity that can be measured based on the minimum edit distance between the preprocessed noun phrase of esand any alias of ew context similarity that can be measured by the text similarity between the sentence that esappears in i.e.
qorfs and the definition sentences of ewprovided by the general knowledge graph.
finally esis linked to an entity in the general knowledge graph that has the highest combined similarity with es.
third we match between the aligned entities based on entity linking results.
for an entity eqinqand an aligned entity efsin fs we calculate their matching score in the following way if eqandefsare linked to the same entity in the general knowledge graph e.g.
string and char sequence they are equal and their matching score is if eqandefsare linked to two entities with hyponymy e.g.
instance of subclass of or part of relationship in the general knowledge graph e.g.
int and primary type their matching score is if one of eqandefsis the prefix or suffix of the other one e.g.
integer value and integer they are in a hyponymy relationship and their matching score is otherwise the matching score is .
finally simr q fs is calculated by summing the matching scores of all the aligned entity pairs between qandfs.
note that if an entity einq orfs has several aligned entities in fs orq we only consider the entity pair that has the highest matching score.
.
.
text similarity calculation.
the text similarity simt q fs measures the overall text similarity between qandfsto cover other sentence parts e.g.
clauses gerunds and infinitive .
the similarity is calculated based on the word2vec model.
we use a dimensional word2vec model pre trained on the wikipedia corpus and tune the model based on the corpus of all f sentences extracted in our empirical study using gensim .
then we calculate the similarity in the following way preprocess qandfsby 1021esec fse november virtual event usa wenkai xie xin peng mingwei liu christoph treude zhenchang xing xiaoxin zhang and wenyun zhao tokenization stop word removal and lemmatization generate a vector for qandfsrespectively by averaging the vectors of all their words produced by the word2vec model calculate the normalized cosine similarity between the vectors of qandfs.
.
.
matching result generation.
given a query we rank the f sentences by their matching scores from high to low.
for each f sentence we generate a linguistic explanation for matching by describing the f category that the query and the f sentence belong to the semantic roles in the query and the f sentence and all matched entity pairs and their matching degrees.
for example one matching result for the query how do you crash a jvm?
would be terminates the currently running java virtual machine ofjava.lang.system.exit int .
we can explain this matching as follows both belong to the f category stop quit terminate jvm matches with java virtual machine at an equal level and they share the semantic role patient .
evaluation our evaluation includes two parts.
in the first part we evaluate the accuracy of f sentence parsing including f category classification andp pattern analysis.
in the second part we evaluate the performance of prema in documentation based api retrieval tasks by comparing it with a deep learning based approach.
.
accuracy of functionality sentence parsing to evaluate the accuracy of the f category classification we used the f sentences annotated in the empirical study to do a fold cross validation.
the average accuracy on the test set is .
with .
minimum accuracy .
our analysis shows that most of the misclassified f sentences use rare verbs such as pin and compile which have very few samples in the annotated f sentences .
to evaluate the accuracy of the p pattern analysis we removed those belonging to the unknown f category from the f sentences and used the remaining f sentences and their annotated p patterns as the data set.
for each f sentence we used our approach to identify the p pattern and compared it with the annotation.
the results show that the accuracy of the p pattern analysis is .
.
our analysis shows that most of the mistakes were caused by the pos tagging and dependency parsing implemented by spacy.
for example gerunds are sometimes recognized as noun phrases e.g.
starts looping playback from the current position and to in an infinitives is sometimes recognized as preposition e.g.
marshals to output the value in the holder .
the above evaluation is based on the f sentences extracted from the jdk and android reference documentation.
to confirm whether the classifier and analyzer can be applied to other libraries we further evaluate the accuracy of f sentence parsing on apache poi a java library for processing microsoft office documents .
we randomly selected f sentences from the poi reference documentation and invited three ms students to annotate their f categories and p patterns in a similar way to the empirical study.
the annotation process did not produce new f categories .
we used all the f sentences annotated in the empirical study to train a f category classifier and used it to classify the poi sentences.
the f category classification accuracy on poi sentences is .
wefurther use prema to analyze the p patterns of the poi sentences and the accuracy is .
the results show that the f category classifier and the p pattern analyzer trained on jdk and android reference documentation also work well for poi.
table shows results of functionality sentence parsing produced by prema where the bold italic words and subscripts in f sentences denote the skeletons and semantic roles clauses of p patterns .
we can see that f sentences with the same f verbs e.g.
return can be classified into different f categories .
the p patterns of the same f categories may have different numbers of semantic roles for example the f category convert transform turn has both p patterns with and semantic roles.
based on the recognized p patterns the participants of different f sentences of the same f categories can be aligned based on semantic roles e.g.
source goal and clauses.
.
performance of api method retrieval we implemented a deep learning based approach as the baseline tool for api method retrieval.
the tool uses word2vec to produce vector representation of words and sentences.
it matches a user query with an api description without explicit analysis of functionality verb phrases.
it uses a dimensional word2vec model pre trained on the wikipedia corpus and tunes the model based on the corpus of all f sentences using gensim .
it generates a vector for the user query by averaging the vectors of all its words after preprocessing i.e.
tokenization stop word removal and lemmatization and a vector for the api description in a similar way.
finally it calculates the cosine similarity between the vector of the query and the vector of the description of each api method and ranks the candidate api methods by the similarity.
we tried and tested two strategies for api matching i.e.
using the full description of each api method or only the first sentence of its description based on a manually constructed dataset of user query and api method pairs.
the results show that the implementation using the first sentence of each method description has better performance thus we chose it as the baseline.
we did not consider bert based approach as baseline as we need to train a binary classifier for query document relevance based on fine tuned bert model and additional training data of relevant irrelevant query document pairs.
we selected api retrieval tasks from stack overflow questions that are tagged with java or android based on the following criteria the questions ask for apis implementing specific functionalities and have at least one accepted answer that recommends a single jdk or android api method.
we ranked the questions meeting the above criteria by their votes and randomly selected questions from the highly ranked ones.
for each selected question we generated an api retrieval task that uses the question title and body as the task description.
we invited two phd and ten ms students who are familiar with java and android development to complete the tasks.
for each task they can formulate and try different queries based on their understanding of the task description.
both prema and the baseline approach return the top api methods together with their class descriptions as the context for the user to select.
the participants finish a task when they find an api method that matches the task description.
they were divided into two groups g1andg2 based 1022api method recommendation via explicit matching of functionality verb phrases esec fse november virtual event usa table examples of functionality sentence parsing api method f sentence f category library javax.xml.transform.transformer.transform transform the xml source sto a result g. convert transform turn jdk android.graphics.color.hsvtocolor convert hsv components sto an argb color g. convert transform turn android org.apache.poi.hpsf.propertyset.toinputstream returns the contents of this property set stream sas an input stream g. convert transform turn poi android.icu.util.universaltimescale.from convert a long datetime pfrom the given time scale sto the universal time scale g. convert transform turn android java.text.characteriterator.getbeginindex returns the start index of the text p. get return obtain jdk java.sql.statement.getresultsettype retrieves the result set type pfor resultset objects generated by this statement object b. get return obtain jdk org.apache.poi.ss.formula.eval.areaeval.containscolumn returns true pif the specified col is in range c. check test determine poi org.apache.poi.xssf.usermodel.xssfworkbook.issheethidden check whether a sheet is very hidden c. check test determine poi participants of p patterns s source g goal p patient b beneficiary c clause .
on a pre experiment survey on their programming experience balancing the experience in both groups.
the tasks were randomly divided into two groups t1andt2 .
the experiment was conducted in two phases.
in the first phase the participants in g1andg2were asked to complete the tasks in t1with prema and the baseline tool respectively.
in the second phase the two groups exchanged the tools to complete the tasks in t2.
all participants were required to run a full screen recorder to record their api retrieval processes.
for each task we recorded the correctness number of retries and completion time of each participant and calculated the accuracy i.e.
the ratio of participants who selected the right api for the task and average number of retries and completion time of the two participant groups.
figure shows the performance of the groups using prema and the baseline tool over the tasks.
participants using prema completed the tasks more accurately required fewer retries and used less time than those using the baseline tool.
on average the accuracy number of retires and completion time by seconds of the participants using prema and the baseline tool are .
.
.
versus .
.
.
respectively.
we used welch s t test for verifying the statistical significance of the differences and the p values for accuracy number of retires and time are .
.
and .
respectively.
we can see the differences in accuracy and number of retires are statistically significant p .
while the difference in time is not significant.
figure performance of api method retrieval the analysis of the screen recordings revealed that our tool performs particularly well for tasks that are order sensitive.
for example for the task converting array to list in java participants were able to find correct apis quickly with our tool while the results returned by the baseline tool included apis that turn lists into arrays i.e.
the reverse order .
for tasks that involve concepts related to the software domain our approach can also recommend better results.
for example for the task how do you crash a jvm our tool can correctly recommend the apis java.lang.system.exit int and java.lang.runtime.halt int while the results returned by the baseline tool are not related to jvm .
we also found f categories to be helpful for solving tasks.
for example for the task check whethera string is not null and not empty the f sentences recommended by our tool are in the same f category check test determine as the question.
however f sentences recommended by the baseline tool tend to contain the keyword null and the verb used in the question is ignored.
one concern is that our approach may not be able to search for apis that use unpopular verbs.
some unpopular verbs express domain specific meanings e.g.
mute roam dial and can be easily discriminated by themselves.
some other unpopular verbs can be categorized together with more popular verbs and thus can also be supported.
among the tasks there are tasks whose corresponding apis i.e.
java.util.collections.sort java.lang.system.exit java.
lang.string.split use unpopular verbs i.e.
sort terminate split .
these verbs have been included in the identified f categories for example terminate is included in a f category with popular verbs stop and end .
from interviewing participants after the experiment we learned that they perceived our tool to provide them with correct and relevant answers more easily while the baseline tool required more queries.
a participant said that our tool could understand queries better than the baseline tool.
for example when participants entered check as part of a query our tool is able to recommend apis whose f sentences contain verbs such as test and determine .
participants also suggested improvements to the tool such as better ranking of results and showing all variants of overloaded methods.
threats to validity internal validity.
a potential threat to internal validity stems from the use of the natural language processing library spacy.
some of our analyses are based on spacy s natural language processing of sentences e.g.
rq1 and rq3 .
no natural language processing library achieves accuracy on any large data set and spacy s perfomance was found to be on par with the state of the art and outperforming other libraries when applied to software documentation .
spacy was not designed specifically for software text i.e.
text containing code elements incomplete sentences or grammar errors which are common on stack overflow.
currently there is no natural language processing tool specialized for parsing software development related text and we have to rely on general purpose natural language processing tools.
to mitigate this threat we use heuristic rules to correct some common mistakes.
this process is similar to related work .
another threat may arise from the scale of the open coding.
for the analysis of f categories in rq2 we only coded the f sentences of jdk and android api methods not all of the f sentences .
one concern is that the f verbs and f categories we identified may not cover all f verbs and f categories in jdk and 1023esec fse november virtual event usa wenkai xie xin peng mingwei liu christoph treude zhenchang xing xiaoxin zhang and wenyun zhao android.
open coding of the full set is beyond our capabilities and we try our best to cover as many f verbs andf categories as possible by our sampling strategy.
based on the findings of rq1 the most frequent verbs appear in approximately of the f sentences .
thus in the initial coding phase we sample sentences for each of the most frequent verbs to cover as many common f verbs and f categories as possible with a relatively small sampling size .
in the second phase we create a larger random sample to cover uncommon f verbs andf categories that were not covered by the first sample.
an additional threat is related to the quality of open coding.
we mitigate this by separating the two phases of coding and training all coders before coding.
we report cohen s kappa for all open coding to provide evidence that our coding results are reliable.
external validity.
a major concern is the extent to which our automated detection tools are generalizable.
we provide evidence for their generalizability by evaluating them on jdk and android f sentences stack overflow questions and poi f sentences .
new f categories andf patterns may need to be revealed using similar empirical study process when using our approach for other libraries.
related work .
knowledge about functionality functionality is an important knowledge type required for software development tasks such as features implementation and maintenance.
kirk et al.
studied the reuse problems faced when developing applications based on a framework and identified four main categories of framework reuse problems functionality is one of them.
erdos and sneed identified seven questions developers need to ask during software maintenance tasks.
all questions are about understanding the behavior of the program and therefore about functional knowledge.
other related work targets functionality descriptions in software documentation.
maalej and robillard reported on a study of knowledge patterns in api documentation such as functionality concepts and directives.
the authors found that functionality accounts for a large part of api documentation but they do not offer further categorization of the functionality descriptions in api documentation.
based on maalej and robillard s results fucci et al.
attempted to use machine learning techniques to classify the knowledge types of sentences in api documentation.
they reported that the most frequent knowledge types are functionality and noninformation.
in our work we focus on the most common knowledge type functionality and classify and analyze api functionality descriptions based on functionality verbs.
.
verb phrases in software engineering in many programming languages method names are used to describe the implementation of a method at a high level.
past research has found that source code will be more readable if every method has an appropriate name .
since the method name usually consists of verb phrases h st and stvold constructed a lexicon containing frequently used verbs in java method names and reported characteristics of method names based on their verbs.
hayase et al.
built a domain specific dictionary of verb object relationsfrom identifiers appearing in source code files.
kashiwabara et al.
focused on recommending similar verbs for a method name so that developers can use consistent verbs for method names.
however their focus was on method names instead of natural language descriptions of methods.
shepherd et al.
proposed an approach for query expansion and code search.
this method uses verb direct object v do pairs from method signatures and comments to find actions that cross cut object oriented systems.
hill et al.
proposed an approach to automatically extract and generate noun verb and prepositional phrases from method and field signatures capturing word context of natural language queries for maintenance and reuse.
treude et al.
focused on natural language descriptions and extracted development task phrases from software documentation.
however they extracted all task phrases from sentences.
in their work one sentence can contain more than one task phrase and they did not distinguish them based on importance.
also they only used a small set of predefined verbs to define task phrases and did not consider synonyms in a systematic way.
in this work we focus on functionality descriptions of java and android api methods from api reference documentation and classify functionality verbs into functionality categories thus providing a systematic way for exploring synonyms in a functionality category.
.
api recommendation current api recommendation approaches typically use context information to recommend apis e.g.
api dependency graphs feature request history and question and answer websites and documents .
current approaches can not only recommend api methods and classes from third party libraries but also support project specific apis .
rahman et al.
proposed an approach called rack and also constructed a corpus to map keywords from stack overflow questions to api documentation.
based on this corpus rack can recommend apis for a given query.
huang et al.
combined stack overflow knowledge with api documentation and proposed biker which can also recommend apis for a given query.
however these approaches can only work for apis which have been discussed extensively on sites such as stack overflow and suffer from information noise in these external resources.
previous work has shown that stack overflow tends to be slow at covering new apis and can ignore significant parts of an api.
in contrast our approach does not rely on external resources.
the approach by hill et al.
can automatically categorize extracted phrases into a hierarchy based on partial phrase matching to help software maintainers quickly discriminate between relevant and irrelevant search results and reformulate queries.
however their approach can not deal with the problem of lexical gaps between queries and documentation.
other approaches in the area of api recommendations do not focus on recommending methods but for example on code snippets or parameters instead.
conclusion in this paper we conducted a large scale empirical study on the functionality descriptions of jdk and android api methods.
1024api method recommendation via explicit matching of functionality verb phrases esec fse november virtual event usa we identified different functionality verbs from the descriptions and these verbs can be grouped into functionality categories based on their semantics in the description context.
we also extracted phrase patterns from the verb phrases of the descriptions.
building on these findings we propose an api method recommendation approach based on explicit matching of functionality verb phrases in functionality descriptions and user queries which is called prema.
we conducted experimental studies to evaluate the functionality analysis accuracy and api retrieval performance of prema.
the results show that prema can accurately recognize the functionality categories .
and phrase patterns .
of functionality description sentences and the participants using prema completed their tasks more accurately .
versus .
with fewer retries .
versus .
and using less time .29s versus .42s .
future work will be devoted to applying the approaches for automatically recognizing functionality categories and associated functionality verbs andphrase patterns to other software engineering problems such as documentation quality and information retrieval.
in addition we will further improve the context analysis capability e.g.
by considering the class descriptions and method descriptions beyond functionalities prema to achieve more precise api matching.
all data from this work will be turned into archived open data after acceptance.