first come first served theimpact offile position oncodereview enrico fregnan fregnan ifi.uzh.ch universityof zurich switzerlandlarissa braz larissa ifi.uzh.ch universityof zurich switzerlandmarcod ambros marco.dambros usi.ch codelounge at softwareinstitute universit dellasvizzera italiana switzerland g l al kl handangul.calikli glasgow.ac.uk universityof glasgow scotlandalbertobacchelli bacchelli ifi.uzh.ch universityof zurich switzerland abstract themostpopularcodereviewtools e.g.
gerritandgithub present the files to review sorted in alphabetical order.
could this choice or more generally the relative position in which a file is presented biastheoutcome of code reviews?we investigatethis hypothesis bytriangulating complementary evidenceinatwo step study.
first weobservedevelopers codereviewactivity.weanalyze thereviewcommentspertainingto219 476pullrequests prs from popular java projects on github.
we found files shown earlier inaprtoreceivemorecommentsthanfilesshownlater alsowhen controllingforpossibleconfoundingfactors e.g.
thepresenceof discussion threads or the lines added in a file.
second we measure theimpactoffilepositionondefectfindingincodereview.recruiting106participants weconductanonlinecontrolledexperiment inwhichwemeasureparticipants performanceindetectingtwo unrelated defects seeded into two different files.
participants are assigned to one of two treatments in which the position of the defective filesis switched.for onetype ofdefect participantsare notaffectedbyitsfile sposition fortheother theyhave64 lower oddstoidentifyitwhenitsfileislastasopposedtofirst.overall our findingsprovideevidencethattherelativepositioninwhichfiles are presented has an impact on code reviews outcome we discuss theseresults andimplicationsfor tooldesignandcode review.
preprint data andmaterials ccs concepts software and its engineering empirical software validation .
keywords code review controlledexperiment cognitive bias permissionto make digitalor hard copies of allorpart ofthis work for personalor classroom use is granted without fee provided that copies are not made or distributed forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation onthefirstpage.copyrights forcomponentsofthisworkownedbyothersthanthe author s mustbehonored.abstractingwithcreditispermitted.tocopyotherwise or republish topostonserversortoredistributetolists requirespriorspecificpermission and or a fee.
request permissions from permissions acm.org.
esec fse november 14 18 singapore singapore copyright heldby the owner author s .
publicationrightslicensed to acm.
acm isbn .
format enrico fregnan larissa braz marco d ambros g l al kl and alberto bacchelli.
.firstcomefirstserved theimpactoffilepositiononcode review.
in proceedingsofthe30th acmjoint europeansoftware engineering conferenceandsymposium on the foundationsof softwareengineering esec fse november14 18 singapore singapore.
acm newyork ny usa 12pages.
introduction code review is a popular software engineering practice where developers manually inspect the code written by a peer .
code reviewaimstofinddefects improvesoftwarequality and transfer knowledge .
over the years code review has evolved from a formal strictly regulated process into a less strictpractice.contemporarycodereviewingisinformal asynchronous change based andsupportedbytools .
the tools used to conduct code reviews share many similarities .
in particular the vast majority of tools including the populargerrit andgithub presentthechangestoreview asalist sequenceofdiffhunks groupedbythefiletheybelong to.
tools sort these files alphabetically therefore the changes to a file named org controller.java are always presented before those to a file named org model.java .
could this choice or more generally therelativepositioninwhichafileispresentedinfluence the outcome ofcode review?
this hypothesis seems to be supported by at least two factors.
first mostdeveloperstendtostarttheirreviewsintheorderpresentedbythereviewtool .second codereviewisacognitively demanding task whose outcome might be influenced by cognitive factors also related to the position of the file.
for example developersmaybeinfluencedby attentiondecrement a decreaseinattentionwhenexposedtoalistofelements ormay depletetheir workingmemorycapacity thememoryforshort term storage during ongoing tasks near theend oflongerreviews.
inthispaper wesettoinvestigatethishypothesis.wedothis bytriangulating complementary evidenceinatwo step study.
inthefirststep wefocusontherelationbetweenfilepositionand reviewers activity.wecollectandanalyze219 476pullrequests prs from138githubopen sourcejavaprojectsandinvestigate whetherthepositioninwhichafileispresentedinaprisassociated with the number of comments the file receives.
in fact the number ofcommentscanbeusedtoapproximatereviewers effectiveness esec fse november14 18 singapore singapore enrico fregnan larissabraz marco d ambros g l al kl andalberto bacchelli andactivity .wefindasignificantcorrelationbetweenthefile s positionandthenumberofcommentsthisfilereceives filesshown laterinapr receive fewer comments thanfilesshownearlier.
in the second step we focus on the influence of file position on defect finding incode review.
we design and conduct a controlled experiment with developers who have to review code in which we seeded two unrelated bugs a corner case defect and a missing breakdefect intotwodifferentfiles.bycreatingtwotreatments that switch the position of the defective files first corner case defectandlastmissingbreakdefect orviceversa wemeasurethe influence of file position.
while we see no effect for the missing break defect we find that developers have lower odds to identify the corner case defect when the file containing it is displayed last as opposed to first.
to further confirm our findings we look atthe files displayed on the participants screenduring the review task.
we detect a statistically significant difference between the time participants spend viewing the firstfile andthe last one.
overall our findings suggest that the relative position in which files are presented in a code review has an impact on the code review s outcome.
this result has important implications for code review practiceand fortool design.
for instance code review tool designersmayconsiderrethinking alphabeticallyordering filesin favor of a more principled approach e.g.
showing first the most problematicfilestoreview .alternatively codechangeauthorsmay considerclearlysignalingdeveloperswheretostarttheirreview for example through the use of self comments or in the change description when they implementedmore challenging parts.
backgroundand related work inthissection wepresentrelevantliteratureoncognitiveaspectsin moderncodereview.then weillustratethepsychologicalconcepts that might constitute the underlying causes of the effect of file position on code review.
finally we report possible competing argumentsagainstthehypothesisthatfilepositionplaysarolein reviewing.
.
cognitiveaspects in codereview codereviewisacollaborativeprocesswherehumanfactorsplay a crucial role .
previous studies conducted at companies such asmicrosoft andgoogle revealedhowcodereviewcould fosterknowledgetransferamongdevelopersinateamandimprove shared code ownership.
however code review is not only a collaborativeprocess butitisalsoacognitivelydemandingtaskforthe single reviewer.
in particular a vast amount of research focused on reducing developers cognitive load to improve reviewers performance .
for instance baum et al .
conducted a controlledexperimenttoinvestigate howdevelopers codereview performancerelatestotheircognitiveloadandworkingmemory capacity.theirfindingshighlightedhowworkingmemoryisassociated with finding delocalized defects while only weakly associated withthe abilityto detectotherdefecttypes.
another group of studies addresses developers cognitive biases that might affect code review outcome .huang et al .
investigated how cognitive biases relate to code review process in acontrolledexperimentusingmedicalimagingandeye tracking.
chattopadhyay et al .synthesized helpful practices to reduce theeffectofcognitivebiasesonsoftwaredevelopmentactivities includingcodereview.intheirtwo partfieldstudy theauthorsidentified themanifestationofvariouscognitivebiasesduringcodereviews e.g.
representativeness availability anchoring confirmation bias .
spadini et al .
investigated the effect of primingon reviewers ability to detect bugs due to their proneness to availability bias.inthecontrolledexperiment areviewcommentwasusedto prime the participants to look for defects of the same type.
the authorsinitiallyhypothesizedthattheparticipantswouldoverlook defects of other types present in the code due to their proneness to availability bias.
however the experiment results show that the presence of a review comment identifying a bug does not prime reviewerstowardslookingfordefectsofsimilartypeoverlooking otherdefecttypes.onthecontrary suchareviewcommentactsas areminderforbugsdevelopersusuallydonotlookforduringtheir daily practices.
.
psychologicalfactors relatedto position basedonthefindingsof baumetal .
whichsuggestthatdevelopersstartacodereviewfromthefirstfileinthechange set the followingpsychologicalfactorsseemplausibleexplanationsbehind the potentialeffectoffiles position oncode review.
attention decrement.
attention decrement is defined as the tendency for people to pay less attention to stimuli coming later in asequentialoccurrenceorpresentationandthustorememberthem lesswell .togiveapracticalexample astudentgivenalistof terms to memorize is likely to have more difficulties committing to memorythoseattheend.
hendricketal .
identifiedattention decrementasthemostfeasibleexplanationofwhypeopletendto remember the firstinformation they see the most.
during codereview developers mightbesubjected to this phenomenon slowly decreasing their attention the more the review continues.
as the majority of reviewers begin their review from the first file in a change set this decrease in attention is more likely to impact the last files in a review change set.
this would sustain our hypothesis that the position of the files in code review matters.
working memory.
working memory is defined as the part of humanmemoryneededforshort termstorageduringongoingcognitive processes .
however although the working memory capacity varies from individual to individual its amount is still limited .
in software engineering the study of bergersen and gustafssoninvestigatedthe effect ofworking memory on programming performance .theirfindingsshowedhowworkingmemoryinfluences performance albeit mediated by the developers programmingknowledge .
baumetal .studiedtheeffectofworkingmemory oncodereviewperformance .theirexperimentshowedacorrelationbetweenworkingmemoryandthereviewers effectivenessin finding delocalized defects.
reviewers might deplete their working memory looking at the first files in a review change set leading toanexhaustionofthisresourcethatmightnegativelyinfluence theircode reviewperformance onthe last filesthey inspect.
484firstcome firstserved theimpact of fileposition oncode review esec fse november14 18 singapore singapore .
relatedcompetingarguments althoughpreviousevidence suggeststhatdevelopersstarta codereviewfromthefirstfileinthechange set somefactorsmight affecttheorderinwhichdevelopersreviewfilesduringcodereview.
given the findings of some eye tracking studies e.g.
itseemsplausibletothinkthatsomefilesinacodechangemight attract reviewers attention more due to their content e.g.
files thatcontainmorecallterms controlflowterms regardlessoftheir position.forinstance abidetal .
foundthatdevelopersvisitcall termsmoreoftenthannon calltermsandspendthelongesttime readingcallterms.thenextmostvisitedandreadlocationswere control flow terms and signatures.
furthermore in an earlier study rodegheroetal .
found thatdevelopers considermethodsignatures as the most important section of the code followed by call terms andthecontrol flow terms.
moreover token lengthandfrequency in a source code might also influence developers attention.
the results al madi et al .
obtained indicate that participants fixate longer low frequency tokens and tokens containing more characters.
furthermore inaneye trackingstudy busjahnetal .
showed thatpeoplereadsourcecodeinamorenon linearfashionthanreading natural language.
however thefindings by busjahn et al .only explain how developers read code in a single code file the authors showedtheparticipantsjavaclassesandpseudocodesrangingfrom afewlinesofcodetoanentirescreenfulloftext.therefore whether developersnavigate filesinacode changeina non linearfashion during code review and how this is related to file position need further investigation.
inthepresenceoftheseargumentsintheliteraturecompeting with the hypothesis that file location may influence code review outcome our study aims to investigate this topic in depth from complementary angles.
methodology inthisstudy weaimtounderstandwhethertherelativepositionin whichafileisshownforreviewinfluencesthecodereviewprocess.
.
research questions we structured our investigation in two steps which seek to collect complementary evidence.
first we investigate the relationship betweenfilepositionandreviewers activity.wedosobymining datafromprsbelongingtoavastsetofopensourceprojectsand answer the following researchquestion rq1.towhatextentistherelativepositionofafileinareview associatedwiththeamountofcommentsthefilereceives?
second we focus on the influence of file position on defect findingincodereview.wedosobyperforminganonlinecontrolled experimentwithsoftwaredeveloperswhohavetoconductareview ofcode andanswer the following question rq2.what is the effect of the relative position of a defective file inareviewonbugdetection?
.
rq file positionandreviewactivity subject projects.
for our analysis we select open source projectsfromgithub focusingonjavaprojectswithastar count above .
as previously reported the number of stars of a project can be effectively used as an indication of the projects popularityandhealth.wefocusonjavaas itisawidelypopular programming language and focusing on one programming language might reduce potential bias introduced by different review practicesofprojectsbasedonotherprogramminglanguages.
moreover we investigate large projects to reduce potential bias causedbyproject specific reviewpolicies orcharacteristics.
data collection.
using pygithub1a python library to access the github rest api for each pr we extract the position of each file andthenumberofcommentsitreceives.moreover wecollectother factorsthatcaninfluencethenumberofcommentsafilereceives i.e.
confounding factors .
we consider the number of lines added and deleted ina filebecause larger changesmay require morecomments whetherthefileisatest becausethesetendto receive less comments and to be ordered last alphabetically and thenumberofcommenters becausemoreparticipantsin the reviewofapr mightleadto more comments.
datafiltering.
asthepresenceofabotmightintroducebiasin our analysis we exclude bot comments from our analysis.
to do so weflagalluserscontainingtheword bot asbotsandcreate a list of commonly used bots in github extracted from relevant grayliterature andremovethem.thepresenceofdiscussion threads i.e.
a series of comments where the reviewers and theauthordiscusssolutionsorimprovementstothecode might act as a confounding factor in our analysis a discussion thread canfacilitatedevelopers engagementinaddingcommentstothe thread regardless of the file s position.
therefore we focus our investigationonlyonthefirstcommentofathread disregarding subsequentones.moreover thenumberoffilesinapullrequest mightinfluencethecomments distribution.therefore wegroup theprsaccordingtothenumberoffilestheycontaintoconduct initialanalyses e.g.
see figure 4for prs withfive files .
dataanalysis.
toanalyzetheimpactoftheaforementionedfactors on the number of commentsin a file dependent variable we build ahurdle model a statistical model that specifies two processes one for zero counts and another for positive counts.
we choose this model as it handles excess zeros in the dependent variables in fact a vast number of files in the collected prs receive zerocomments.tomodelthepositivecounts weemploya negative binomial distribution.furthermore wecheckthemulti collinearity acrossthevariablesinthemodelcomputingtheirvarianceinflation factor vif andremovingthosewithavif higher thanfive.
.
rq file positionanddefect finding our controlled experiment is organized as an online experiment in which participants are asked to complete a review of a code changeinvolvingfivefiles.amongthesefiles weseedtwounrelatedsoftwaredefects2intotwodifferentfiles.werandomlyassign participants to one of the following two treatments one file 1pygithub 2the participants arenot informed about the presence of these defects.
485esec fse november14 18 singapore singapore enrico fregnan larissabraz marco d ambros g l al kl andalberto bacchelli withabugispresentedfirstandtheotherfilewiththeotherbug ispresentedlast i.e.
fifth or theorderofthefiles hencethe bugs isreversed i.e.
thefifthfileisnowfirstandviceversa .we measurethespecificbugsdetectedbyeachparticipant aswellas howlongeachfile isvisibleonthe participants screen.
in the following we provide more details on the experimental objects i.e.
code change to review and seeded defects and the experimental design i.e.
online platform and experiment flow .
we conclude by describing thepilots we conducted how we recruited participants and how we analyzed the collected experimental data.
.
.
experimental objects.
code change.
for the review task wecreateacodechangethatsatisfiesthefollowingrequirements not belonging to any existing project to avoid introducing bias caused by participants previous knowledge of the review changeset written in java one of the most popular programming languages self contained to minimize the previous knowledgeparticipantsneedtounderstandthechangefully and close to an actual code reviewscenario toincreaserealism .
wecreateacodechangespanningfivefilesasatrade offbetween small change sets e.g.
three files and more complex reviews.
for smaller code changes e.g.
two files we expect a smaller effectof a file s position.
in contrast even thoughlarger code changes may presentastrongereffect morecomplexreviewsrequirealonger reviewtime thuslikelyleadingtomoreparticipantsabandoning the experiment.
allfileshavesimilarsizes rangingfrom44to63lines .inparticular weensurethatthetwofilescontainingthedefectsaresimilarly sized lines in the corner case defect file and lines in the missing break defect to minimize the potential bias introduced by the file length.
we devise the code change to minimize links e.g.
method calls between non adjacentfiles.
in particular we checked that no connectionexistedbetweenthetwodefectivefiles i.e.
firstandlast .
our goal is to increase the control on how participants navigate the change thus makingthe file position effectclearer if any.
finally tore positionthefilesforthetwodifferenttreatments werenamethem.thisensuresthatthereviewersarenotinfluenced by a tool behavior that is unexpectedly different than what they are used to in common review platforms where files are displayed inalphabeticalorder .
seeded defects.
in our experiment we investigate if the given treatmentinfluencesparticipants abilitytofindbugs.inthereview task we seedthe following twounrelatedfunctional defects cornercase cc acornercaseconditioninan ifstatementis leftunchecked thusnotrespectingthedocumentation figure .
we select this bug because it represents an issue developers typicallycheckfor andfrequentlyexistsinpractice .
missing break mb a missing breakstatement in a switch constructmakestheexecutionincorrectlyfallthroughthedefault case figure .
we select this defect because it is reported as a common java mistake by relevant gray literature alsoresonating withthe infamous apple gotofail .
we use two defects to make the review task as realistic as possible bypreventingparticipants from focusing exclusivelyonone bug.
figure cornercase defect cc used inour experiment.
figure missing break defect mb used in our experiment.
.
.
experimental design.
experiment platform.
we implementourexperimentasanonlineplatform.tothisaim weemploy a publiclyavailable tool crexperiment alreadysuccessfully used inpreviouscodereview experiments .crexperiment allowsparticipantstoreviewcodedisplayingareviewchange setin two panediffs asdoneinpopularcodereviewtools e.g.
gerrit or github .
moreover the user interface ui of crexperiment adopts similar design choices e.g.
the color scheme as the one of for instance gerrit.
this mitigates possible bias with the users not being familiar withthe experiment platform.
crexperimentalsologsparticipants interactions e.g.
scrolling and the time participants spend in each phase of the study e.g.
in the review tasks .
to collect information on which files in the change set the participants focus on during code review we extendedthebaseexperimentplatformtorecordthefilesvisibleon the participants screen during the review.
for each file the experimenttoolrecordsifthiswasontheparticipants screen displayed partially displayed or not displayed at a given time.
we store all the collecteddata anonymously.
experiment flow.
we organize the flow of our experiment as depictedinfigure 3andas describedinthe following i welcome page.
ontheexperiment slandingpage weprovide participants with information on the type of study and our data 486firstcome firstserved theimpact of fileposition oncode review esec fse november14 18 singapore singapore v closing page ii code review taskrandom assignment to a treatment file file file file file file file file file file file file file file iii post review questionnaire!
i welcome page iv demographics welcome!
file figure designandflow oftheonlineexperiment.
handling policy.
moreover we ask for their consent to collect anduse theirdata before proceeding inthe experiment.
ii codereview task.
participants are asked to perform a code review task.before starting we instruct participants to perform a code review as they would typically do in their normal practice.participantsarerandomlyassignedtooneoftwopossible treatments ccf mbl the file containing the corner case defect is shownfirst in the code change while the one containing the missingbreakdefectisshown last.
mbf ccl the file containing the missing break defect is shownfirst while the one with the corner case defect is shownlast.
toavoidbias wedonotinformparticipantsaboutthefunctional defects thetreatments andtherecordedmetricsbeforethereview task.
at the end of the task we ask participants whether andfor howlongthey were interruptedduringthe review.
iii post review questionnaire.
after participants declare their review task is completed they are shown the code change again with the location and explanation of the defects figure 1and figure2 .
we ask participants whether they found each of the two defects and the cause that in their opinion influenced their result.inasubsequentpage asnottoinfluencetheirprevious answers weaskparticipantsiftheythinkthepositionofthefile containingthe bugsmighthave impactedtheirresults.
iv demographics.
afterward wecollectinformationaboutparticipants gender education occupation and experience with java and code review.
we analyze this information to guaranteethatthegroupsofparticipantsassignedtodifferenttreatments arehomogeneous asconfoundingfactorsintheanalysisof the experiment results and to describe the population representedinour results.
v closing page.
onthefinalpageoftheexperiment wedisclose thegoalofourstudyandaskparticipantsforanyfinalremark.
wealsocollectparticipants consenttosharetheiranswersinan anonymized yetpubliclyavailable researchdataset.
.
.
pilot runs.
before publicly releasing the online experiment weconductapilotstudyto verifytheabsenceoftechnicalissues withexperimentsettings e.g.
theonlineplatform andinstructions checkthegoodnessofthedevisedreviewtaskandseededdefects and improvetheexperimentbasedontheparticipants feedback.
weconductfouriterationsofourpilotstudywithatotalamount of participants.
after each iteration the authors discuss theresultsand feedback obtained and improve theexperiment design accordingly.afterthelastiteration theexperimentisdeemedready tobe released sincethe participants detected no significant issues.
we excluded the data gathered from the participants in the pilot study from the analysisof the experiment results.
.
.
dataanalysis.
toanalyzethedatacollectedinourexperiment weperforma chi square testtoassessthecorrelationbetween filespositionandparticipants detectionofthedefects.weevaluatethestrengthofthecorrelationusingthe phi coefficient .then we buildtwo logistic regression modelsconsideringas dependent variables ccfound whether the participants found the corner case defect and mbfound whether the participants found the missingbreakdefect respectively.
toidentifyifaparticipantfoundadefect wefollowtheguidelinesofpreviousstudies .wemanuallyinspecttheremarks left by the participants and classify a defect as found when a remark is placed in proximity of the defect and clearly describes the defect in the code.
the first author performs this inspection andasecondauthorcheckslaterthefirstauthor sinspection results.
tobuildourmodels wefollowthefollowingproceduretoensure the goodness of our results we use the varclus procedure toidentifyand removevariablesfromthe modelwithspearman s correlation higher than .
.
we compute the variance inflation factors vif amongthevariablestoensurenonehadavifvalue above .
if a variable with a higher vif is detected we remove it from the model.
finally we build the models adding each variable one by one and checking that the coefficient remained stable showing littleinterference amongthe considered variables.
we aim to evaluate if the position of the defect in the first or last file impacts participants abilitytofindit.
forthis reason we includethevariable positionamongtheindependentvariablesinour model.wealsoconsiderthepotentialeffectofotherconfounding factors such as the participants experience with java and code review.furthermore wecomputethetimeparticipantsspendon the review task and include this variable in the model.
table presentsallthevariablesincludedinourlogisticregressionmodels.
.
.
number ofrequiredparticipants.
we performed an a priori poweranalysistocomputetheminimumsamplesizeneededforour experiment.weusedtheg powersoftware andemployeda two tailtest with a manual distribution having odds ration .
.
power .
andr2 .
.
the results of this analysis showedourexperimentneededaminimumof92validparticipants.
487esec fse november14 18 singapore singapore enrico fregnan larissabraz marco d ambros g l al kl andalberto bacchelli table variablesused inthelogisticregressionmodels.
metric description dependentvariables ccfound the participant foundthe corner casedefect.
mbfound theparticipantfoundthemissingbreakdefect.
independentvariables position the relative position of the bug first or last in the code changeto review.
control variables crduration the time spentonthe code reviewtask.
devexp theparticipant sdevelopmentexperienceina professional setting.
javaexp the participant s experience withjava.
crexp the participant s experience incode review.
oftenprog howoftentheparticipantprogrammedinthe three months prior to the experiment.
oftencr how often the participant reviewed code in the three months prior to the experiment.
interruptions howoftenandforhowlongtheparticipantwas interruptedduringthe reviewtask.
figure distribution ofcomments inaprwith five files.
.
.
participants recruitment.
we disseminated an invite to conducttheonlineexperimentthroughtheauthors professionalnetworkandsocialmediaaccounts e.g.
linkedin aswellasondevelopers webforumsandcommunicationchannels e.g.
reddit .
to prevent any bias in the results we do not disclose the experiment saimtoparticipantsintheinvite.toencouragedevelopers participation we commit to donate usd to a charity for each valid participant inthe experiment.
results we present the results ofour investigation byresearchquestion.
.
rq file positionandreviewactivity our first research question seeks to investigate the relationship betweenrelativefilepositionandreviewers activity focusingontable hurdlemodels forprsummary.
positive count zerocount estim.
sig.estim.
sig.
intercept .
.
position .
.
linesadded .
.
linesdeleted .
.
istest .
.
n.commenters .
.
sig.
codes p .
p .
p .
thecommentsleftduringcodereview.weanalyzeatotalof219 pull requests pertaining to popular java projects on github.
among these pull requests received at least one review comment whichwe computedexcluding comments left bybots .
asthe vastmajority ofprs .
containbetween oneand ten files we focused our investigation on this subset of prs.
we excludedfromouranalysisprscontainingonlyonefileastheeffect ofthe position insuch casesisnot relevant.
codereviewongithubisaniterativeprocess.whenadeveloper uploadsacommit thisisreviewedbyfellowdeveloperswhomay askthecommitauthortoperformsomechanges.thesechangesare addressed in a subsequent commit and the process continues iterativelyuntilthe code isaccepted.tobothconsider andexcludethe effect of the review process itself we analyzed the data concerning twodifferentmoments inthe history of pull requests pull request summary we consider the code change as it appearsattheend ofthe review processand allthe comments that the code has receivedduringthe entire process.
first commit we consider only the code as initially submittedinthepullrequestandthecommentsitreceives.thus we excludechangesandcommentsinducedbythereviewprocess.
.
.
pullrequestsummary.
ourinitialinvestigationshowedthat thenumberofcommentsonthefilesinaprishigherinthefirst filesandprogressivelydecreasestowardsthelastfiles.forinstance figure4showsthedistributionofthecommentsinprswithfive files.asimilarpatternwasobservedalsoforalltheothergroups ofprs e.g.
withsixfiles.wefoundsimilarresultsalsowhenwe restrict our investigation to the prs that contain only java files.
to confirm and quantify the correlation between the relative positionofafileinapullrequestandthenumberofcommentsitreceives weperformeda spearmancorrelationtest anon parametric test that measures the strength of the association between ordinal orcontinuousvariables .weobtainedap valueof .
anda .
thusconfirmingastatisticallysignificantnegative relation between thesetwovariables.
subsequently weperformedregressionmodeling toverifythis association also when controlling for the other factors that may influencethe number ofreviewcomments onafile.
table2shows the hurdlemodelpredicting the number of comments in a file.
we included in the model prs containing only java filestoremovepotentialbiasintroducedbymultiplefileformats.
3ouronlineappendix provides graphs for allthe cases wemention.
488firstcome firstserved theimpact of fileposition oncode review esec fse november14 18 singapore singapore moreover we excluded prs having less than three files since in these cases the effect of the file position is likely to be negligible.
to remove outliers we limited our analysis to files that have fewer than1 000linesadded.finally wenormalizedeachfile sposition over thenumber of filesin the pr to allow for comparison among prswithadifferentnumberoffiles.themodelissummarizedin table2andshowshowthepositionofafileisnegativelycorrelated with the number of comments it receives confirming how the last filesinareviewchange settendtoreceivelessreviewcomments from developers alsowhen controlling for otherfactors.
table2alsoshowsthattheotherindependentvariablesincluded inthemodelarestatisticallysignificantpredictorsofthenumber of comments in a file.
the sign of the estimates show that the direction of the relationship follows the expected direction.
for instance a larger number of changed lines added or deleted is relatedtomorereviewers comments.onthecontrary theexpected number of comments decreases when the file is a test this result is inlinewithpreviousresearch sfindings .finally thenumberof commenters is positively correlated with the number of comments.
.
.
first commit.
by restricting our analysis to only the first commitsofoursetofpullrequests wenoticedasimilarpatternas the one reported for the pr summary.
the first files in a commit receive more comments compared to the last ones.
we analyzed commits with number of files ranging from two to ten noticing similar patterns to the pr summary available in the replication package .
asfortheprsummary wecorroboratedourfindingsbyrestrictingouranalysistocommitscontainingonlyjavafilestomitigate potential bias caused by multiple types of files.
this verification however did not reveal any significant difference from the general case confirming our observations that a higher number of comments concentrates onthe firstfilesinacommit.
we performed a spearman correlation test to verify the presence of a correlation between the number of review comments a file receives and the file s position.
the test achieved a p value of .
16and a .
showing how the two variables are correlated although this correlation isweaker .
tobuildthehurdlemodelinthisscenario wefollowedthesame stepsastheonereportedforthepullrequestsummary.ourresults reported in table confirm how later files in a review change set tendtoreceivealowernumberofcomments.concerningtheother independentvariablesincludedinourmodel weachievedresults similar to the ones presentedfor the pr summary section .
.
.
finding1 .thenumberofcommentsacrossthefilesinthe analyzedpullrequestsisassociatedwiththerelativeposition of each file.
specifically the later a file is presented in a pull request thefewer thecommentsit receives.
.
rq file positionanddefect finding encouragedbythefindingsforrq wedevisedacontrolledexperiment to test this hypothesis with complementary evidence.
our second research question seeks to investigate the effect of files position ondevelopers revieweffectiveness.table hurdlemodels forpr s firstcommit.
positive count zerocount estim.
sig.
estim.
sig.
intercept .
.
.
position .
.
linesadded .
.
linesdeleted .
.
istest .
.
n.commenters .
.
sig.
codes p .
p .
p .
.p .
a total of participants accessed the online experiment.
of these weconsideredonlytheparticipantswhocompletedallthe steps.furthermore weremovedparticipantswholeftnoremarks andspentlessthantenminutes 106participants.
the vast majority of the participants .
have at least a b.sc.
degree mostly in computer science .
overall participants reported to be software developers.
moreover participants selfdescribed as male four as female two as non binary and preferred not to disclose.
figure 5reports participants experience and practicelevels.
intotal 56participantswereintreatment ccf mbl while50 were in treatment mbf ccl.
we compared the experience and practices e.g.
java experience oftheparticipantsassignedtothe twogroupsandfoundnostatisticallysignificant difference.
.
.
defect finding.
overall participants found the corner case defect while detected the missing break defect.
table reportsthenumberofparticipantswhofoundnodefect onlyone defect or both defects in the review task by treatment.
table reportshowmanyparticipantsidentifiedeachtypeofbug bytreatment.
table participants who found no defects only the corner case defect cc only the missing break defect mb and bothdefects.
nodefect ccmbcc mb total ccf mbl13 mbf ccl17 total these results show how participants found more the first bug shown in the review task compared to the bug shown last.
the corner case defect was found times when the file containing it wasshownfirstandonly18whenthefilewasshownlast.asimilar albeit weaker trend seems to appear for the missingbreakdefect.
to verify the presence of a relation between the position of a bug and its detection we performed a chi square test.
in the caseofthecornercasedefect thistestachieved 2 df n .
p value .
rejecting the null hypothesis thatno relationship exists between files position and the detection of the cornercasedefect.however inthecaseofmissingbreakdefect our test achieved 2 df n .
p value .
.
489esec fse november14 18 singapore singapore enrico fregnan larissabraz marco d ambros g l al kl andalberto bacchelli figure participants experienceandpractice.
table participants who found not found each bug divided by treatment corner case defect cc first or missing break defect mb first.
cornercase missing break found not found found not found ccf mbl34 mbf ccl18 p value .
p value .
phi coefficient .
phi coefficient .
odds ratio .
odds ratio .
therefore for this defect we could not draw any conclusion on the fact that its position influenceddevelopers abilityto find it.
forthecornercasedefect wealsocomputedthephi coefficient tomeasurethestrengthoftheassociationobtainingavalueof0.
whichisclose to amoderatepositive correlation .
to investigate the association between the detection of a defect its position in the code change and other possible confounding factors reportedintable webuilttwologisticregressionmodels whoseresultsareshownintable .thesefindingsarealignedwith the results ofthe chi square test the position of the corner case defect is statistically significant correlated with developers ability to find it p value .
.
finding .
the relative position of the file containing the cornercasedefectinfluencesthelikelihoodofparticipants in detecting the defect.
participants are less likely to find the defect when its file is presented last.
this effect is not significant forthemissing breakdefect.table logistic regressionmodels forrq2.
dep.var.
cc found dep.var.
mb found estim.
s.e.sig.estim.
s.e.sig.
intercept .
.
.
.
position .
.
.
.
crdur.
.
.
.
devexp .
.
.
.
javaexp .
.
.
.
crexp .
.
.
.
oftenprog .
.
.
.
oftencr .
.
.
.
interrupt.
.
.
.
.
sig.
codes p .
at the end of the code review task we asked participants if they thought the position of the defect had an influence on their ability tofindit.thevastmajorityofthemrepliednegatively .
for the corner case defect and .
for the missing break defect .
however our results showed how on the contrary the position of the bug had an effect on participants ability to find it.
this shows a mismatch between what developers thinkaffects the code review outcome andwhichfactors actuallyplay arole init.
.
.
visible files.
in the experiment we measured the time that eachfilewasvisible ontheparticipants screenasaway toinvestigatefurthertheeffectoffiles positiononcodereview.figure reportsthetime inseconds thatparticipantsinthetwotreatments spent with each file visible on the screen.
we removed from this analysis participants who declared to have been interrupted for more than ten minutes during the review task as their data may biasthis analysis.
490firstcome firstserved theimpact of fileposition oncode review esec fse november14 18 singapore singapore figure6 time inseconds participantsvisualizedeachfile.
toimprove theclarity we limited thesize ofthey axis.
onaverage participantsregardlessoftheirtreatment ccf mblor mbf ccl spentmoretimelookingatthefirstfilecomparedtothe last one.
on average participants spent .
minutes with the first file displayedas opposedto .09for the last file.
toverifywhether thedifferencebetweenthetimeparticipants visualized the first and last file is statistically significant we performeda mann whitneyutest .forthewholeparticipants without dividingthembythetreatment ourtestobtainedap valueof0.
thereforeshowingthatthetwovariablesareindeeddifferent.dividing the participants by treatment our test achieved a p value of .022forthetreatment ccf mbl and0.031fortreatment mbf ccl.
theseresults confirmthosefor the generalpopulation.
finding .
during the review task participants spent significantlymoretimewiththefirstfilebeingvisiblecompared to thelast file.
.
.
robustness testing.
to challenge the validity of our findings andstrengthentheirgoodness weemployed robustnesstesting .
participants groups are not homogeneous.
participants experience in programming and reviewing might impact their performance during code review and therefore influencethe results.
to verify that the participants assigned to the two treatments have similar characteristics we performed a chi square test of homogeneityon the variables measuring participants experience and practice e.g.
participants experiencewithjava .weobtainedpvalues above .
therefore not revealing significant differences between the twosamples ofparticipants.
moreover we compared the timespent on the code reviewtask of participants belonging to thetwo treatments.to this aim we performeda mann whitney u test p value of .
which did not detect any difference between the twogroups.one defect might influence participants in finding the other.
finding one defect might have biased participants towards finding the other one.
for instance participants who found one bug might have stopped looking for other defects assuming they found the only issue in the code.
another possibility is that one defect can give unintentional indications to participants to identify the other one.
however the results reported in table 4counter the existence ofsuchbias thenumberofparticipantswhofoundonlyonebug is similar to the one of those who found both bugs.
we further performeda chi square testto verifyif findingone defectledparticipants to also find the second one.
our test obtained a p value of .
thus suggesting this biasnot to affectthe experiment.
the defects are too easy difficult.
the selected defects might have been too easy or on the contrary too hard to identify for the participants.tomitigatethispossiblebiaswe selecteddefects amongcommonjavamistakesbasedonrelevantliterature and discussed them among the authors and verified our choicethroughapilotstudy.despitethesemeasures participants intheexperimentmighthavestillfaceddifficultiesfindingthese defects oridentifiedthemtooeasily .however theresultsreported in table4show that the number of participants who found no defects onlyonedefect orbothdefectsisalmostevenlydistributed showing that nodefectwastootrivial orhardto find.
alownumberofparticipants.
anumberofparticipantstoolow might bias the significance of our findings.
the power analysis we run section .
showed that we needed at least participants.
our experiment exceeded this number it was conducted by a total of106valid participants.
threats to validity construct validity.
the codechanges selectedfor the reviewtask might have introduced bias in the experiment.
to mitigate this threat the first and second authors prepared the code changes and selected the defects contained in them.
the other authors also checkedthe goodness ofthe code reviewtask.
the scenario represented in our experiment might differ from a real world review.
to reduce this threat we adopted the following measures we created a code change as similar as possible to real ones e.g.
including documentation seeded defects that commonly happen in real world scenarios and used a reviewinterfacesimilar to widely usedcode reviewtools.
internal validity.
during code review developers instead of writing multiple similar comments might leave only one comment requiring changes in all similar subsequent instances of an issue.
suchcommentsmightintroducebiasintheresultsofourinvestigationinrq .forthisreason oneoftheauthorsmanuallyinspected a randomly selected subset of prs looking for such comments.
onlyeightprscontainedinstancesofthesecomments.considering this proportion we computed a statistically significant sample size with confidence level and margin of error obtaining a sample size of which confirmed that prs are sufficient to establishthe proportionof this factor inour results.
in rq2 before analyzing the results we manually inspected the participants logs.weremovedallparticipantsthatdidnottakethe reviewtaskseriously participantswhospentlessthantenminutes onthereviewandleftnoremarks.sinceourexperimentreliedonan 491esec fse november14 18 singapore singapore enrico fregnan larissabraz marco d ambros g l al kl andalberto bacchelli online platform the participants might have completed the review taskwithdifferentset upsandindifferentenvironments.however thisreflectsthevariousconditionsinwhichdevelopersworkinrealworldscenarios.tomitigatethethreatsthatinterruptionsmight constitute for the validity of our study we asked participants to state howlongthey were interruptedduringthe code reviewtask andincludedtheiranswers inour statisticalanalyses.
external validity.
in rq1 the selection of the projects might have introduced bias in our investigation.
to reduce potential bias caused by the choice of a specific project we considered a vast set of projects from different domains all with star count above .however wecannotexcludethepossibilitythatthechoice of different projects might lead todifferent results.
further studies are neededto verifythe generalizabilityofour findings.
participants in our experiment possess a vast set of different backgrounds yet our sample is not representative of all developers.
moreover the specific defects we chose might have influenced the experimentresults.althoughthesedefectshavebeenreportedin the literature as common defects they have specific characteristics that donot generalize to allothertypes ofdefects.
furthermore the size of the code change contained in the review task might have influenced the observed results.
we carefully chosethereview codechange size to be atrade off betweenatoo small review where the effect of the files positions is likely not to matter andatoo largetask whichwouldhaveresultedinahigher participants drop out rate.
although the results of rq 1suggest that this effect should be present also in the code change with a highernumberoffiles furtherstudiesareneededtocorroborate our findingsindifferentscenarios.
inourexperiment weconsideredonlycodewritteninjava.this wasdonetokeepthenecessarynumberofparticipants section .
within an achievable range.
in fact considering multiple programming languages would have required to significantly extend the numberofparticipantsduetothefollowingreasons.first although languages such asjava c andpython canbe used to writecode in a similar way in reality they tend to follow different coding conventionsandidioms .therefore usingmultiplelanguagesposestheissueofeithernotfollowingthelanguage sidioms thus making the code snippet less natural or having snippets substantially different across languages.
second past research has provided evidence on different programmers behavior when comprehendingcodewrittenindifferentlanguages .third workon programming languages learning shows that novices face different difficultylevelswithdifferentprogramminglanguages .this might be caused by the different cognitive load that each language poses.forthesereasons wecannotexcludethatdifferentprogramming languages might lead to different results.
further studies can bedevisedandconductedtoinvestigatewhetherandhowtheresults of our experiment change considering different programming languages.
discussion in this section we discuss the main implicationsofour findings.
theimportanceofbeingfirst.
ourinvestigationprovidesevidence that the position of a file influences developers review effectiveness developershave64 loweroddstofindadefectwhenitisin the file shown last.
currently code review tools e.g.
github or phabricator display files in alphabetical order.
our results suggest that more principled ways of presenting the files in a code review can be usedto support reviewers effectiveness.
for example tools could display first those files that are more critical.previousworkfocusedonidentifyingsalientclassesina codechange i.e.
classesthatsubsequently causethemodification of other classes in the change set .
such classes can be used as the point from which developers should start a revision.
on the contrary another possibility would be to focus on identifying arid filesandplacingthemlastinacodereview takinginspirationfrom the approachdeveloped at googleto identify aridlines .
such an approach would allow developers to prioritize the review of more relevantfiles.
other studies proposed an ordering approach to re organize files in a code change to support reviewers preferences .
thisapproachfocusesonhowfilestoreviewshouldbegrouped suggestingtoshowfilessequentiallysharingalink e.g.
method call method declaration .
however this ordering theory does not consider the absolute position of the files i.e.
which ones shouldbeshownfirst .theorderingtheorycanbeexpandedtotake intoaccountourfindings.moreover previouswork reported howdevelopersadoptdifferenttacticswhenreviewingcode e.g.
startingfromnewlyaddedfilesorfilesperceivedaseasiertoreview .
forthisreason futurecodereviewtoolsmightincludeawaytolet reviewers customize the order of the files to review to fit different reviewers needsandcountertheeffectoftherelativepositionof the files.
finally ifchangingthealphabeticalorderofthefilesinacode reviewtoolistoounnaturalforreviewers onecouldconsiderusingwarningsto pointreviewerstowardsthefilefromwhichthey should start the review.
to this aim new solutions could be devisedtakinginspirationfrompreviousstudiesonprogram analysis tools wheretheauthorsinvestigatedhowwarningsshould be displayed to be welcomed by developers.
these warnings could forinstance makedevelopersawareofbiasesduringcodereview e.g.
as created by the relative file position .
future studies can be designed andcarried outto comparethe effectiveness ofusing warnings as opposed to changing the position of files in a code reviewtool.
not all defects are the same.
in our experiment participants effectiveness in detecting the corner case defect was influenced by the relative position of the defective file.
however this was not the casefor the missingbreakdefect.
if we consider the nature of these bugs we notice that they may require a different effort to be found even though they were found withthesameprobabilityoverall asreportedintable .onthe one hand the corner case defect requires the reviewer to read andunderstandthedocumentation thencomprehendthecodeand identify a mismatch in the corresponding implementation.
as one participantexplainedwhenaskedwhytheydidnotfindthecorner case defect i didn t read the javadoc carefully enough and there was not anything obviously wrong with the code.
on the other hand themissingbreakdefectcanberecognizedasapattern even if one does not fully understand the semantic of the code.
one participantwhofounditexplained iamaccustomedtolooking 492firstcome firstserved theimpact of fileposition oncode review esec fse november14 18 singapore singapore for break statements on every switch expression because i have missedtheminmyowncode inthe past.
therefore the underlying reason for the difference in files positioneffectcouldbethatthesetwobugsrequireadifferentcognitive effort to be found.
these bugs could impose a different load on participants working memory making in turn the effect of the defect position more or less prominent.
we did not investigate this further butstudiescaninvestigatethishypothesisanddetermine the role ofcognitive effortindefectfindingduringreview.
thehiddenpsychologicalfactorsofcodereview.
attheendof our experiment we showed the participants the defects we seeded in the code.
when asked whether the position of the bugs might havehadanimpactontheirabilitytodetectthem avastamountof the developers replied negatively.
a total of .
participants rejected theideathat files position influenced theirabilitytofind for the corner case defect.
however the results of our experiment foundevidenceofthecontrary.theimpactoffilepositiononreviewers was also corroborated by the first part of our study when associatingfile position andreviewactivity.
this mismatch between participants perceptions and actual results contributes to the discourse around the importance and the impact of cognitive biases that may affect developers during differentsoftwareengineeringactivities .afterall codereview isahumaneffortandashumansweareinfluencedbybiasesand hidden psychological factors of which we are not naturally aware.
beyond code review.
our results provided initial evidence on the effect of files position on developers activity and effectiveness in code review.
however this phenomenon might also affect other aspectsofsoftware engineering.
previous studies investigated factors affecting developers adoption of program analysis tools showing that the way in which warningsaredisplayediscritical .amongthemanyfactors identified to improve how warnings are displayed e.g.
warning should be well motivated our results may indicate that the position of the warning can play a role.
similarly to files the positionof thewarning mightaffect forinstance theattentionthat developerspaytothem.futurestudiescanevaluatewhetherthe effectofwarnings positioninfluencesdevelopers.thiseffectmight beparticularlysignificant forinstance forthosecomplexwarnings that require developers effortto be understoodandsolved.
conclusion in this study we investigated whether the relative position of a file has an impact on code review.
to do so we devised a two step investigation to collect complementary evidence we collected andanalyzeddatafrom219 476pullrequests prs belongingto138 open sourcejavaprojectsand conductedanonlinecontrolled experiment with106participants.
inthefirststepofourinvestigation wefocusedonreviewers activity investigatingtherelationshipbetweentherelativeposition of file in a pr and the number of comments it receives.
having found evidence of a significant correlation between file position andreviewactivity wemovedtothesecondstepofourstudyto collect different evidence.
we devised an online experiment where participantshadto performreviewacodechange inwhichwetwo seeded defects corner case and missing break .
participants wererandomly assigned to one of two possible treatments ccf mbl where the file with the corner case defect was shown first while theonewiththemissingbreakdefectwasshownlast and mbf ccl where the order ofthe fileswasreversed .
ourexperimentfoundthatthepositionofthefilecontainingthe corner case defect influences the likelihood offinding this defect.
specifically participants found the corner case defect when in thefirstfile whileonly18founditinthelast.thiseffectwasnot significantforthelesscognitivedemandingmissingbreakdefect.
overall ourstudyprovidesevidencethatthepositioninwhichfiles arepresentedduringcodereviewhasanimpactoncodereview s outcome.thisfindinghasimplicationsforcodereviewpractices andreview tool design andmaysuggestthat asimilareffect may be present inothersoftware engineeringcontexts.
data availabilitystatement the data collected in our investigation the tools and analysis scriptsareavailableinourreplicationpackage .thisversion ofthereplicationpackagecontainsboththepullrequestdataset and the remaining material in a unique archive.
to ease the download thesematerialsarealsoavailableseparatelyatthefollowing link .