specgen automated generation of formal program specifications via large language models lezhi ma1 shangqing liu1 yi li2 xiaofei xie3 and lei bu1 1state key laboratory for novel software technology nanjing university p.r.
china 2nanyang technological university singapore 3singapore management university singapore lezhima hotmail.com shangqingliu666 gmail.com yi li ntu.edu.sg xfxie smu.edu.sg bulei nju.edu.cn abstract in the software development process formal program specifications play a crucial role in various stages including requirement analysis software testing and verification.
however manually crafting formal program specifications is rather difficult making the job time consuming and labor intensive.
moreover it is even more challenging to write specifications that correctly and comprehensively describe the semantics of complex programs.
to reduce the burden on software developers automated specification generation methods have emerged.
however existing methods usually rely on predefined templates or grammar making them struggle to accurately describe the behavior and functionality of complex real world programs.
to tackle this challenge we introduce specgen a novel technique for formal program specification generation based on large language models llms .
our key insight is to overcome the limitations of existing methods by leveraging the code comprehension capability of llms.
the process of specgen consists of two phases.
the first phase employs a conversational approach that guides the llm in generating appropriate specifications for a given program aiming to utilize the ability of llm to generate high quality specifications.
the second phase designed for where the llm fails to generate correct specifications applies four mutation operators to the model generated specifications and selects verifiable specifications from the mutated ones through a novel heuristic selection strategy by assigning different weights of variants in an efficient manner.
we evaluate specgen on two datasets including the sv comp java category benchmark and a manually constructed dataset containing programs.
experimental results demonstrate that specgen succeeds in generating verifiable specifications for out of programs outperforming the existing llm based approaches and conventional specification generation tools like houdini and daikon.
further investigations on the quality of generated specifications indicate that specgen can comprehensively articulate the behaviors of the input program.
index terms program verification specification inference large language model i. i ntroduction formal specifications play a central role in describing understanding and reasoning about program behaviors.
they capture the intended or actual program behaviors in terms of formal languages with precise semantics.
formal specifications may take various forms such as procedure pre postconditions loop invariants and assertions at specific program locations.
they are essential in a variety of software quality assurance tasks including software testing model checking and program verification .
corresponding author.yet a practical challenge is the absence of documented formal specifications in most real world software projects since manually writing high quality specifications is highly nontrivial.
to alleviate the burden on software developers several tools have been introduced for generating program specifications automatically including houdini and daikon two most representative ones for java programs.
however these tools rely heavily on predefined templates or grammars during the specification generation process.
as claimed by molina et al.
the fixed templates involved result in a limited range of specifications covered usually yielding overly simplistic specifications that struggle to capture the complex behaviors and functionalities of real world programs accurately.
this phenomenon poses non negligible limitations for these tools consequently hindering their applications in the actual software development process .
to address this challenge we introduce specgen an automated technique for java program specification generation based on the large language models llms .
with the rise of llms extensive research has attempted to apply them in software engineering and llms exhibit outstanding performance in various tasks where llms have demonstrated remarkable capabilities on code comprehension and summarization .
inspired by this insight we believe that llms can serve as a potent solution to overcome the limitations of existing program specification generation methods.
the core idea of this work is to leverage llms to generate specifications that accurately capture the real behaviors of input programs thus imbuing these specifications with richer semantics for further practical use.
the workflow of specgen comes in two phases.
in the first phase conversation driven specification generation we aim to query the output specifications by conducting a conversation with the llm.
to start the conversation a prompt is constructed with several few shot examples for the initial query.
during the conversation process we utilize the verification failure information from the specification verifier as the feedback prompt for the next round of the conversation.
in this way llms receive more cues facilitating them to better generate accurate specifications.
nevertheless despite the powerful code understanding and generation capabilities of large language models they still struggle to handle complex programs effectively i.e.
generating accurate specifications for complex programs.
through our repeated observation andarxiv .08807v5 feb 2025testing of the model generated results we found that although the generated content is not highly accurate it is already very close to the oracle which motivates us to design the second phase mutation based specification generation .
it focuses on generating accurate specifications where the llm fails to provide verifiable results.
specifically given a verification failure result by the llm specgen endeavors to combine four different kinds of mutation operators to modify it and obtain all potential variants.
a selector adopting a heuristic selection strategy by assigning different weights of variants further repeatedly chooses a subset of these mutated variants deemed most likely to pass the verification until the results are successfully verified.
to evaluate specgen we conduct experiments on two datasets.
we first evaluate specgen on the benchmark for the java category of sv comp .
to further evaluate the performance of specgen on different kinds of programs we constructed another dataset containing java programs with manually written ground truth specifications.
the selected programs are highly representative encompassing different control flow structures and various data structures to avoid any bias in our evaluation.
we compared the performance ofspecgen on the dataset against multiple baselines.
the results of our evaluation demonstrate that specgen significantly outperforms the baseline methods.
specgen successfully generated verifiable specifications for out of the total programs outweighing for autospec the best performing llm based approach and for houdini the best performing non llm method.
an ablation study on mutations was also conducted proving the effectiveness of all four types of mutation operators.
additionally the results of evaluations on the heuristic selection strategy suggested that our strategy effectively improves the efficiency of specgen compared to the random selection strategy.
furthermore a user study was conducted to evaluate the semantic quality of the generated specifications illustrating the ability of specgen to accurately and comprehensively characterize program behaviors.
the main contributions are summarized as follows a novel approach for formal program specification generation and corresponding prototype tool leveraging the large language models to generate accurate and comprehensive specifications to describe program behaviors.
benefiting from the code comprehension ability of llms our approach is capable of generating specifications with high quality overcoming the limitations of existing methods in generating simplistic and basic specifications.
a mutation based generation approach to enrich the diversity of the llm output consisting of a set of mutation operators and a novel heuristic selection strategy proposed to improve the efficiency of the verification that existing works fail to consider.
a dataset named specgenbench with hand written specifications by experts facilitating follow up research.
other than the established benchmark sv comp we collected programs on a more diverse spectrum for deeper insights.
a comprehensive evaluation to evaluate our approach in all aspects.
we compare specgen against purely llm based approaches and representative non llm approaches.
specgen succeeds in out of the programs significantly outperforming the baseline approaches.
ii.
b ackground and motivation a. specification generation and verification program specifications encompass precise statements that describe the intended or actual behaviors of a particular program either in its entirety or in distinct parts.
in this work we focus on generating specifications for the actual behaviors of input programs.
a large proportion of program specifications are expressed in formal languages such as mathematical expressions to describe the constraints on the behaviors of a program.
there are different kinds of specifications such as pre conditions which establish constraints on function parameters ensuring proper execution of the function post conditions which delineate the properties of a set of variables that persist after a function is executed and loop invariants which represent a specialized form of specification detailing properties that consistently hold before executing the loop body.
for different programming languages the specifications may have different implementation forms.
for example in java the specifications can be expressed in java modeling language i.e.
jml where requires statements denote the pre conditions of a function ensures statements represent the post conditions of a function and maintaining statements specify the loop invariants.
a series of automated program specification generation tools have been developed to reduce the burden on software developers.
two representative works are houdini and daikon .
both rely on templates defined by human experts to generate a massive amount of candidate specifications which verifiers then filter to eliminate incorrect candidate specifications until the remaining candidates are successfully verified.
in particular the template usually involves two or three variables and their corresponding operators i.e.
var op var where var should be filled in with variable names and op should be an operator.
for example if a function contains two integer parameters xandyand an integer return value houdini may generate candidate preconditions and post conditions for this function in the form ofx y x y result result etc.
where result is the defined variable denoting the return value in jml.
for a program all available variables within the scope such as class members function parameters and return values are taken to generate candidate specifications based on the defined templates and instrumented into corresponding points of the input program to verify the correctness of the specifications.
the main difference between houdini and daikon lies in the design of the verifier where houdini adopts a jml specification verifier openjml which is designed from constraint solving for verifying.
yet daikon is based on the runtime checking which compares each candidate specification with the runtime execution traces.fig.
an example program and corresponding specifications generated by specgen for which existing tools cannot generate comprehensive specifications to describe the program behaviors.
b. motivation the existing automated program specification generation tools have limitations hindering real world deployment and application.
they rely on templates defined by human experts to generate specifications which results in simple and trivial specifications.
we present an example program on the left of figure for illustration.
this program aims to search in the given integer array for the indexes of two separated elements of which the sum is exactly the given target value and is implemented in two nested loops.
if there do not exist such elements in the array the program returns an empty array.
to fully articulate the behaviors of the program such properties must be specified where daikon and houdini fail.
in particular both houdini and daikon can only generate trivial post conditions such as nums !
null and result for the method twosum as a whole.
as for the outer layer loop only some simple loop invariants are generated describing trivial numerical relationships between variables such asi andi arr.length .
for the inner layer loop the generated specifications are j i j and j nums.length which are similar to the out layer.
the generated specifications are too trivial without detailed information to accurately capture the program s functionality.
recently large language models i.e.
llms have exhibited powerful capacities in coding .
the emergence of these models may greatly compensate for the limitations of traditional software analysis tools in code understanding.
a significant amount of work attempts to leverage large language models in software engineering and we have witnessed substantial progress brought about by the introduction of llms.
inspired by these works in this work we aim to leverage the large language models in the automated generation of formal program specifications to address the limitations of conventional template based approaches.
from this perspective we innovate our approach specgen which generated three parts of specifications for the example presented in the right part of figure .
the first part is to describe the method twosum as a whole specifying its pre conditions and post conditions.
the specifications in lines a and b claim that the input array must not be null before and after the method is executed.
the post condition in line c specifies that the target value equals the sum of the two elements corresponding to the indexes stored in the returned array.
the post condition at line d specifies that there doesnot exist such a pair of elements that satisfies the constraint when the length of the returned array is zero.
these generated specifications can fully articulate the functionality of method twosum .
furthermore the loop invariants in the second and third parts specify corresponding constraints that must be met within a certain range in the array.
these specifications generated by specgen comprehensively describe the semantics of this function and their correctness is verifiable.
iii.
a pproach a. overview the overview of specgen is presented in figure which consists of two components i.e.
conversation driven specification generation and mutation based specification generation.
the former is designed to communicate with the large language model to query the output in a conversational manner.
in particular a prompt is constructed with some few shot examples for the initial query.
the verification failure information provided by the verifier is further used as the prompt for the next round of conversation if the model generated results are incorrect.
the conversation will be repeated iteratively until the generated specifications successfully pass the verifier or a maximum number of iterations is reached.
the latter aims at generating the specifications of a program that the large language model fails to generate.
four kinds of mutation operators are adopted to mutate the specification that failed verification by the verifier and obtain all potential variants.
a heuristic selector is further designed to efficiently choose a set of mutated variants most likely to pass verification.
b. conversation driven specification generation engaging in conversation with large models can fully leverage their capabilities better assisting them in generating the desired content and avoiding potential errors .
inspired by xia et al.
we propose our conversationdriven specification generation in specgen to interact with the llm conversationally to generate specifications.
there are two main benefits firstly the conversational manner aids the large model in automatically correcting potential syntax errors in the generated content secondly providing the model with the verification failures information by the verifier in the conversation helps it generate more accurate specifications.
the design mainly consists of two sequential components initial prompt construction which pre defined an initial prompt to prepare for querying with the llm and conversationalspecificationsfailinput code promptverifierllmconversationmutator verifierselectormutation based specification generationconversation driven specification generation fig.
overview of our specgen .
assistant class inputcode spec ....... ...... user the jml specifications you generated fail verification with error information as follows please generate again.
to fix such error you may consider guidance inputcode.java linenum1 ...... inputcode.java linenum2 ...... fig.
conversational generation.
system you are a jml specification generator for java programs.
user please generate jml specifications for the java program given below assistant class samplecode ...... class samplecode spec ....... ...... user please generate jml specifications for the java program given below class inputcode ...... ...... fig.
illustration of the initial prompt construction.
specification generation which communicates to the llm by incorporating verification failure information produced by the verifier in the conversation manner to generate verifiable specifications.
the conversation will be repeated iteratively until the generated specifications pass the verifier or a maximum number of iterations is reached.
initial prompt construction we need to define the initial prompt to query with llm to obtain the model output.
after multiple attempts to assess the impact of different prompts on the quality of generated program specifications we ultimately chose to follow xia et al.
in designing our prompt.
the prompt is presented in fig.
illustrating the components of the initial prompt which consists of three different parts the system role few shot examples and the queried program.
the system s role aims to inform llms about our application scenario which is to generate jml specifications.
we further add some few shot examples.
the reasons are two fold.
on one hand few shot examples can help the model to generate more accurate outputs .
on the other hand llms can generate the desired output format that is learned from these examples.
each example is a pair of a program and its corresponding specifications.
we randomly select it from our collected dataset to construct the few shot examples.
the last component is the queried program which requires the model to generate the output.
conversational specification generation given the initial prompt llm can obtain the initial output for the input program.
as the output of the llm in the first attempt may not successfully pass the validation of the verifier we interleave the process of specification generation with verification failurefeedback to prompt future generation in a conversational manner which is illustrated in fig.
.
in particular each generated specification by the model is verified by a jml verifier to test whether the generated result can pass the verifier.
if the verification fails we construct feedback information using the reported error message from the verifier as the prompt for the next generation.
the verification error message can help the model understand the reason for failure and provide guidance for generating correct specifications.
in addition to avoid the verifier providing excessively long error messages we configure the verifier to report only one verification failure message per attempt.
furthermore through a massive amount of experiments we summarize several types of common verification failures reported by the verifier.
for each kind of error we provide guidance in the natural language to facilitate the model in generating correct specifications.
upon encountering these types of verification failures reported by the verifier we will insert corresponding guidance information into the prompt e.g.
guidance in fig.
to assist the model in resolving the issues.
the conversation will be repeated iteratively until the specifications are successfully verified or a maximum number of iterations is reached.
c. mutation based specification generation in the conversation driven generation process some fewshot examples are provided in the initial prompt to start the query with the llm.
to further stimulate the potential of the llm multi turn conversation continually guides the llm in approaching the accurate specification more closely.
yet they still struggle to generate fully correct specifications for some complex programs.
the reasons are two fold.
on the one hand in comparison to code generation specification generation poses greater challenges for llms due to the limited corpora related to program specifications for the model to learn from.
on the other hand although the verification failure information provided by the verifier can assist llms in providing higher quality responses to some extent as the error messages are highly abstract and generalized llms still struggle to accurately understand the semantic information within error messages for complex programs.
while llms may not accurately generate specifications for complex programs the generated results are already highly close to the oracle inspiring us to design mutation based generation.
in particular the mutation based specification generation component takes the output generated by the large language model that fails to pass the verifier through the multi round conversation as the input.
we further define a set of mutation operators to modify these generated outputs to obtain morediverse results.
then a heuristic strategy is adopted for efficient verification.
the workflow is presented in algorithm .
specifically we define the specifications generated by llm that fail verification as the set of template specifications et which consists of different specifications generated for different locations in a program and a set of mutation operators as m. the mutationbasedgen takes etandmas the input and outputs a set of correct specifications as e. the function specmutation corresponds to the mutation operation of et where each kind of mutation operator will be performed through the mutation function mutate section iii c1 on a template specification e e et to obtain a set of candidates emutated lines and line .
after the mutation operations are performed we further design the specification selection algorithm to select a subset eselected of mutated specifications that can pass the verification.
the selected subset eselected is initialized with et.
we then iteratively require the verifier to check the correctness of eselected and obtain a set of refuted specifications denoted aserefuted from eselected that the verifier fails to verify.
after that we need to replace the failed specifications from erefuted with another mutated variant for the next iteration of verification.
the reselect function is presented from line to line .
for each refuted specification er erefuted we first remove it from the mutation set emutated and the selected seteselected .
then we replace erwith another mutated variant ethat comes from the same family by a heuristic selection strategy section iii c2 from line to line .
here the family refers to a set of mutated specifications efthat come from the same template specification.
finally we add eto the selected set eselected to prepare for the next iteration of verification.
the above process will be repeated until all candidates in eselected are successfully verified i.e.
erefuted is empty line .
note that if all candidates are refuted the process will finally select an empty set of candidates guaranteeing the termination of the whole process.
template specification mutation as shown in table i we define four kinds of mutation operators including predicative logical comparative and arithmetic.
each type of mutation corresponds to one type of operator supported by jml.
llms perform well in formulating the overall syntactical structure of specifications but they often make mistakes in grasping the fine grained relationships between variables resulting in incorrect operators used to describe the relationships between variables which is why our mutation design is centered around the operators.
a mutation operation substitutes the operators of the corresponding type in the specification with another of the same type.
for example after applying a predicative mutation a exists predicate within a specification may be substituted with forall .
note that the mutation for a certain type of operator does not necessarily create only one mutated candidate.
for example the expression a b may be mutated to a b ora b .
if multiple mutations can be applied to a specification at the same time we try to exhaust each combination of different types of mutations to get all potential variants.
since the set of allalgorithm mutation based specification generation input set of template specification et set of mutations m output set of verified specifications e 1function mutationbasedgen et m emutated specmutation et m e specselection emutated et m return e 5function specmutation et m emutated fore etdo emutated emutated mutate e m return emutated 10function specselection emutated et m eselected et erefuted repeat erefuted verify eselected eselected reselect eselected emutated erefuted m untilerefuted is return eselected 18function reselect eselected emutated erefuted m forer erefuted do emutated emutated er eselected eselected er ef getfamilyof er emutated e selectbyheuristic ef m eselected eselected e return eselected table i the defined mutation operators.
mutation type original operator mutated operators predicative forall exists exists forall logical comparative !
!
arithmetic potential variants of a certain template is determined the exhaustive searching process is deterministic.
for instance the expression x n can be mutated to x n from the comparative type x n from the arithmetic type or x n by combining them.
mutated specification selection typically for a program houdini verifies all generated specifications at one time.
however similar practice cannot be applied in specgen as we exhaust all potential combinations of mutations for a template specification.
the set of the obtained specifications for verification is considerably large posing a much greater burden for the verifier within a single verification process.
to address this challenge we innovate a heuristic selection strategy to improve the stability and efficiency of verification.
in general the heuristic selection algorithm finds a specification esuch that e arg max e efx m m times m e e t weight m where efdenotes a family of mutated specifications that comefrom the same template specification et andmdenotes the set of all mutations.
given ef et andm we design the heuristic selection logic to prioritize selecting important candidates for verification.
in particular we assign scores for each mutated candidate e efand select the candidate with the highest score as the output.
to calculate the score of a candidate e for all types of mutations m m we sum up all the values of times m e e t multiplied by weight m where times m e e t calculates how many times the mutation m is performed when etmutates into e and weight m denotes the corresponding weight of m. iv.
e xperimental setup we design the following four research questions for evaluation rq1 how does specgen compare with the baseline approaches?
rq2 how does each type of mutation contribute to the effectiveness of specgen ?
rq3 how do different candidate selection strategies affect the efficiency of specgen ?
rq4 to what extent can the generated specification contain the semantic information of the input program?
a. implementation we use the api provided by openai to communicate with the large language model of gpt .
turbo for the experiments.
temperature is set to .
to balance the diversity and rigorousness of the outputs of gpt.
fewshot examples are used during the prompt construction to balance the input length and response time.
the maximum number of rounds of conversation is set to .
the verifier is openjml the most recent jml specification verification tool to check the consistency between java source code and jml specifications.
due to the incompleteness in the implementations of openjml we set a timeout limit of minutes for a single verification in our implementation to avoid unexpected situations such as the non responding of openjml.
all experiments are conducted on an core workstation with intel core i7 12700h cpu .30ghz and 32gb ram running ubuntu .
.
lts.
the version of openjdk is .
.
for all experiments except for houdini which has to run under openjdk .
.
.
we set the weight of comparative logical arithmetic and predicative mutation to and respectively as the comparative mutation is more likely to pass the verification followed by the logical mutation.
the predicative and arithmetic mutations are the least important through our observations from extensive experiments.
note that the weights are defined with negative values leading to negative calculated scores as well.
the reason for the design is to prioritize the specification candidates with fewer mutations.
b. dataset to comprehensively evaluate the effectiveness of specgen following previous work we first use an established dataset the benchmark of sv comp for evaluation.specifically we used class definitions in the java category of sv comp benchmark and conducted the necessary modifications on part of these programs referred to as dataset sv comp hereinafter for ease of evaluation.
the remaining data in the benchmark cannot be applied for specification generation even with our modification.
we made minimal modifications to sv comp programs to ensure they can be executed outside the sv comp environment.
specifically the programs destined to trigger false assertions have to be modified so that the programs can exit properly.
also those library calls specific to the competition settings e.g.
verifier.nondetint are replaced with equivalent java library calls so that they can be successfully compiled.
it is ensured that the semantics of the modified programs remain unchanged.
as calculated by tool jacoco these programs have an average line of code loc of .
along with an average cyclomatic complexity cc of .
.
however after a deep analysis of the characteristics of the data from sv comp we find that .
programs are loop free indicating that the samples with more complex program structures cannot be covered by this dataset inducing limitations on the evaluation.
also very few datasets have been established specifically for specification generation tasks so far.
to remedy this gap we further collect another dataset specgenbench containing samples as a supplement where programs including the corresponding specifications from the dataset constructed by nilizadeh et al.
and programs from leetcode .
the selected programs are assured of the feasibility of expressing their behaviors as jml specified verifiable specifications.
these programs involve a variety of control flow structures and encompass multiple data structures such as arrays strings and other data structures supported by the java library.
they also cover a diverse set of specifications including post conditions and loop invariants involving both linear and nonlinear relationships between variables making them representative of a broad spectrum of scenarios.
they can be categorized into five categories according to their types of control flow structures .
specifically sequential denotes the programs without branches or loops.
branched represents the loop free programs that will contain branches like if else or switch structures.
single path loop contains the simplest type of loop with only one layer of loop structure without branches in their loop bodies.
in contrast multi path loop denotes the loops that have branches in the loop bodies.
lastly nested loop denotes the programs with multiple layers of loop structure where each layer may have a branch.
the quantity of programs for sequential branched single path loop multi path loop andnested loop is and respectively.
programs in specgenbench have an average loc of .
and an average cc of .
.
to obtain the ground truth specifications for the java programs from leetcode we follow a similar procedure in nilizadeh et al.
with the help of human experts.
three experts with rich experience in formal verification were employed to manually write specifications for each program.
each expert is required to write the specifications that can besuccessfully verified to describe the functionality and behavior of the program as accurately and comprehensively as possible.
for a single program if multiple experts have written verifiable specifications another expert is responsible for selecting one of them as the ground truth.
as daikon requires a set of test suites instrumented into the source code to execute the code we manually write these test suites for it.
a small test suite is initialized first on which daikon is invoked to generate specifications.
if the results fail verification the counterexample produced by the verifier will be added to the test suite.
the procedure is repeated until no new specifications are generated.
the test suites achieve an average instruction coverage of .
branch coverage of .
and line coverage of .
.
lastly we instrument dummy function calls at the top of each loop body in a program to ensure houdini and daikon can generate the specifications at these program points.
c. baselines we select two conventional approaches and several llmbased approaches as the baselines for comparison.
houdini .
it is a template based jml annotation generator that relies on a series of pre defined templates to generate candidate specifications.
given the input program it first generates candidate specifications by filling in the templates with available variables and all kinds of operators.
afterward it iteratively invokes a jml specification verifier to check their correctness and removes the refuted ones.
the process will be repeated until the remaining candidates are all verified.
daikon .
it is a classic tool for the dynamic detection of program specifications which relies on the dynamic execution trace of the target program to infer likely specifications.
given the input program it first instruments the target program to trace certain variables and extracts execution traces.
then the inference engine reads the trace data and infers the potential invariants with a generate and check algorithm.
daikon supports dynamic detection for java c c c and perl programs along with various formats such as dbc format jml format and csharpcontract format .
apart from the conventional approaches for specification generation we further add the llm based approaches.
few shot llm .
they refer to the large language model i.e.
gpt .
with few shot settings in our work to generate specifications.
under the few shot settings the llm is queried only once to obtain the final result.
we set shot shot and shot for few shot comparison.
conversational .
it refers to the generation technique described in section iii b. conversational generation iteratively queries the llm to refine its results with error information provided to the llm as feedback on each iteration.
the conversational setting is based on shot examples.
other settings remain the same with specgen .
autospec .
it is a recent technique for specification generation combining llms and static analysis.
autospec first decomposes the input program into its components upon which a hierarchy graph is built.
for each component autospec queries the llm for corresponding specifications respectively.
eventually specifications for all components are combined to obtain the overall result which is presented to a verifier for correctness validation.
the progress is repeated iteratively until the result is successfully verified.
d. evaluation metrics following the previous works we use the metric of number of passes for assessment.
we further add more metrics for comprehensive evaluation.
number of passes .
it defines the number of programs for which the generated specifications of an approach pass the validation by the verifier.
for a program we consider the specifications that pass the verifier as the correct specifications.
success probability .
it is used to evaluate the model based approaches.
the randomness inherent in the content generated by large language models may introduce a certain level of contingency in a successful generation.
thus we use the success probability for the measurement.
for a test program it is calculated bynsucess nattemptwhere nsucess denotes the number of successful generations of verifiable specifications and nattemp denotes a fixed number of trials in total times in specgen .
number of verifier calls .
it is used to evaluate the efficiency of our approach.
we propose a heuristic selection algorithm to prioritize the important candidates for the verifier to verify.
to evaluate the effectiveness of the proposed selection algorithm we use the number of verifier calls as the evaluation metric.
user rating .
it aims to measure the semantic quality of the generated specifications.
we invited ph.d. students who are experts in java programming language to rate the specifications generated by different approaches.
the research is conducted using the likert scale where students are required to give a rating from one point to five points for each case according to a reference rating criteria.
v. e xperimental results a. rq1 comparison with baselines the experimental results are presented in table ii where num.
denotes the number of successfully handled programs andprob.
denotes the average success probability.
each llmbased approach is granted trials for each program.
performance on sv comp.
from table ii we can find that on the sv comp dataset programs in total houdini handled programs which is more than daikon.
however both underperform llm based approaches even in llm s simplest setting i.e.
shot setting which handled programs demonstrating the feasibility of employing llms for formal program specification generation.
among the llm based approaches with few shot settings as the number of given fewshot examples increases the number of programs that llm can generate verifiable specifications is also increased substantiating the effectiveness of the few shot examples.
based on the shots examples in the initial prompt the multi turn conversational manner in section iii b can further improve the performance with programs handled compared to programs of shot llm.
combining llm generated resultstable ii number of programs that successfully pass the verifier and average success probability.
approachsv comp specgenbench overall sequential branched single path loop multi path loop nested loop num.
prob.
num.
prob.
num.
prob.
num.
prob.
num.
prob.
num.
prob.
num.
prob.
daikon houdini few shot llm0 shot .
.
.
.
.
.
.
shot .
.
.
.
.
.
.
shot .
.
.
.
.
.
.
conversational .
.
.
.
.
.
.
autospec .
.
.
.
.
.
.
specgen .
.
.
.
.
.
.
and static analysis techniques autospec achieves enhanced results with more programs handled.
lastly specgen outperforms all baseline approaches with the number of programs that generated verifiable specifications increasing to .
performance on specgenbench .for deeper insights into the performance of different approaches on different types of programs we further investigate the results on specgenbench .
similar to sv comp houdini outperforms daikon especially in generating specifications for complex program structures such as loops houdini exhibits certain abilities.
in terms of the llm based approaches we find that specgen autospec and the conversational approach are all competent in generating specifications for relatively simple programs such as sequential and branched.
autospec also demonstrates impressive ability on programs with single path loops benefiting from the code decomposition technique adopted.
however when it comes to generating specifications for programs with more complex structures such as multi path loops and nested loops specgen has a clear advantage.
the benefits are from our designed mutation based specification generation section iii c which can correct the erroneous output of the large language model to generate the verifiable specifications.
although specgen can generate more accurate specifications for different loop structures it has a relatively poor performance in generating verifiable specifications for programs with nested loops.
for llm based approaches we further use success probability to evaluate the probability of successful generation for a program in times trials due to the randomness inherent in the generated content by llms.
we can observe that specgen achieves an overall success probability of .
which is significantly higher than the values of conversational generation and autospec .
and .
respectively .
autospec is not equipped with any feedbackrefine mechanism.
although conversational generation can refine the intermediate results through conversation with llm there still exists detailed errors that cannot be fixed since root causes of errors are difficult for llms to reason.
compared to these approaches specgen equipped with conversational generation and mutation based generation is more reliable with higher probabilities and lower chances of randomness to generate verifiable specifications.
from the results from sv comp and specgenbench we can find that our proposed approach is orthogonal to different datasets.
i255 i255 3fig.
venn diagram of verifiable programs.
presented in fig.
is the venn diagram of the programs in specgenbench for which specgen and baseline approaches successfully generated verifiable specifications.
it is noteworthy that specgen generates verifiable specifications for programs that other baselines fail to yield where are from the nested loop with the rest from the single path loop.
further investigation of these programs reveals that they are relatively complicated and challenging to handle.
overall it takes on average .
verifier calls for the conversational approach per execution whereas the figure is .
and .
for autospec and specgen respectively.
under our experimental settings the maximum number of rounds for conversation is set to so conversational generation naturally finishes execution faster than the other two approaches but with relatively poor performance.
in comparison autospec and specgen take more verifier calls to filter the llmgenerated results and produce more reliable results.
specifically specgen displays a slight advantage over autospec indicating that specgen can achieve better performance compared to autospec in the same or even shorter period of time.
rq1 specgen outperforms all baselines on two different datasets generating verifiable specifications for out of programs with the highest success probability among all llm based approaches.
in comparison the number of programs handled by daikon houdini conversational generation and autospec is and respectively.table iii effectiveness of different types of mutations.
approachspecgenbench sv comp total sequential branched single path multi path nested w o predicative w o logical w o comparative w o arithmetic specgen b. rq2 ablation study on mutation types we conduct an ablation study to evaluate the effectiveness of different mutation types in specgen .
the results are shown in table iii where w o denotes the disabled mutation type.
we can find that specgen successfully generates verifiable specifications for out of a total of programs.
specgen w o comparative addresses the least number of programs i.e.
indicating that the comparative mutation is the most important in the defined mutation operations.
the main reason is the frequent usage of numerical variables in programs and the recurring need to bound their range in the specifications.
specgen w o logical has the second least number of programs i.e.
indicating that the logical operators are also important to generate verifiable specifications.
this is due to the necessity of combining two or more expressions for different properties with logical operations when specifying complex behaviors.
specgen w o predicative and specgen w o arithmetic have the most number of programs and respectively which means both of them are less important than the comparative and logical mutation.
we still consider them as they are applicable in certain situations.
in some complex programs specifications generated by the llm are prone to have predicate errors.
hence the predicative mutation will be useful.
similar cases exist when there are complicated numerical constraints on variables where mutations on arithmetic operators turn out to be helpful.
further analyzing the effectiveness of the mutation type for different kinds of programs we can find that specgen w o comparative handles an especially lower number of programs in the loop category including single path multi path and nested loop.
it is due to the rigid demand of scope bounding for loop variables when loops are involved.
scope bounding for loop variables is an intricate work where llms frequently make mistakes substantiating the importance of comparative mutations.
the performance of specgen w o predicative also drops on programs with nested loop because of the relatively higher quantity and complexity of forall and exists statements involved in these nested programs.
rq2 each type of mutations contributes differently tospecgen .
the comparative mutation contributes the most to the performance while the predicative and arithmetic are less important.
when combining them together specgen achieves the best performance.
c. rq3 effectiveness of selection strategy in section iii c2 we design the heuristic selection strategy to improve the efficiency of verification.
we also conduct antable iv average numbers of verifier calls in a single run under different specification selection strategies in section iii c2.
strategy sv compspecgenbench totalsequential branched single path multi path nested random .
.
.
.
.
.
.
heuristic .
.
.
.
.
.
.
experiment to compare with the random selection strategy.
specifically when a candidate specification is refuted by the verifier we randomly select another specification from effor replacement.
to compare with different strategies for each program that successfully generates verifiable specifications byspecgen we run specgen times to obtain the average number of verifier calls as the evaluation metric.
performance on sv comp.
using the random selection strategy makes .
verifier calls on average while the heuristic selection strategy takes .
calls resulting in an improvement of .
.
the improvement is relatively modest and the values denote that only less than verifier calls on average are used to generate verifiable specifications for programs in svcomp.
the main reason is that the number of rounds for conversation is set to in specgen the specifications for these programs tend to be successfully generated within the conversation module section iii b .
it is before the selection strategy used in the mutation based specification generation section iii c comes into effect.
performance on specgenbench .using the random selection strategy takes .
verifier calls on average while the heuristic selection strategy takes .
calls in terms of five categories in specgenbench .
hence the heuristic selection strategy achieves an improvement of .
.
furthermore we can observe that the improvements in different categories of programs vary significantly.
the improvements in the loop categories including single path multi path and nested loop are more significant than sequential and branched.
the main reason is that generating specifications for loop containing programs is challenging and usually requires more iterations to obtain verifiable specifications.
in this case a good selection strategy often highlights advantages more effectively.
however the improvements in sequential and branched categories are fewer.
the reason is similar to sv comp where the high efficiency of conversational generation on sequential and branched programs makes the selection strategies invalid.
nevertheless loop structures are common in programs thus a heuristic selection strategy to improve the validation efficiency is still helpful and necessary.
rq3 the heuristic selection strategy effectively improves the efficiency of specgen .
it is especially useful when generating specifications for programs with more complex structures such as loops.
d. rq4 user study on the quality of specifications a user study is conducted to evaluate the semantic quality of the generated specifications.
ph.d. students are invitedtable v average rating scores on the generated specifications by different approaches.
test case houdini daikon specgen oracle absolute .
.
.
.
addloop .
.
.
.
conjunction .
.
.
.
converttemperature .
.
.
.
disjunction .
.
.
.
fizzbuzz .
.
.
.
iscommonfactor .
.
.
.
ispalindrome .
.
.
.
issubsequence .
.
.
.
issuffix .
.
.
.
mulloop .
.
.
.
mysqrt .
.
.
.
perimeter .
.
.
.
smallestevenmul .
.
.
.
swap .
.
.
.
average .
.
.
.
to rate the specifications generated by different approaches.
a detailed description of the rating process is given in section iv d. we selected the programs from the dataset of specgenbench that can be handled by all of houdini daikon andspecgen .
apart from the specifications generated by these approaches we also add the ground truth as a reference.
the specifications are kept anonymous to the students disclosing no information about the sources of the specifications.
the rating scores are presented in table v where the score for full marks is .
we can observe that the ground truth specifications oracle receive an average rating score of .
indicating that the semantics of these programs can be described comprehensively through jml specifications.
furthermore the specifications generated by specgen received a rating score of .
which is close to the oracle indicating that the generated specifications byspecgen can also describe the real behaviors of the input program more fully.
among the programs all rating scores given to specgen are above with the lowest rating being .
meaning that in the worst case specgen can still generate non trivial specifications about the properties of the input program.
in comparison the specifications generated by houdini and daikon received an average rating score of .
reflecting the semantic weakness in these specifications.
houdini and daikon rely on pre defined templates which are in fact independent from the input program and can only cover a limited number of specification patterns.
consequently the specifications produced are often simplistic and trivial involving only a narrow range of variables and operators making it difficult to capture the actual behavior and functionality of the input program precisely.
unlike traditional approaches that rely on a fixed set of templates specgen utilizes the code comprehension capabilities of llms which can cover a larger range of scenarios and generate targeted specifications that more closely match the semantics of the input program.
rq4 specgen received an average rating score of .
which is close to the .
of the oracle specifications demonstrating the ability to accurately characterize the real program behaviors and generate specifications with comprehensive program semantics.vi.
d iscussion a. performance on real world programs to further evaluate the performance of specgen on real world programs we collect programs involved in defects4j a well known dataset of reproducible bugs within open source repositories.
during the collection process we only consider individual files with no dependency on thirdparty libraries or other files in the repository.
this ensures that all the collected files can be properly executed and verified outside the repository.
eventually java source files from repositories are collected.
the average line of code and cyclomatic complexity of the collected programs are .
and .
respectively.
we follow the same experimental settings in section iv a for experiments.
note that we only aim to evaluate the verifiability of the generated specifications in the same way section v a does so the ground truth specifications of the programs are not prepared.
table vi shows the performance of specgen and other baseline methods on the programs extracted from defects4j.
although daikon underperforms the llm based approaches it still exhibits certain abilities in processing real world programs.
this is due to the existence of some simplistic methods within real world class definitions such as those retrieving the value of a certain class member without anything else which daikon is capable of handling.
compared to daikon the llm based approach with the simplest setting i.e.
4shot achieved more programs handled.
based on the fewshot learning technique the conversational approach further achieved programs handled.
lastly specgen succeeds in handling out of the programs with an average success probability of .
displaying decent capabilities in handling real world programs.
b. threats to validity internal validity.
first the prompts we used to communicate with the llm may affect our results.
to mitigate it we refer to xia et al.
to design the prompt.
we plan to investigate the effect of different prompts in the future.
second a potential threat lies in the risk of data leakage.
our constructed dataset specgenbench consists of programs with expert written specifications and programs with their corresponding specifications from nilizadeh et al.
.
the former does not have the issue of data leakage as the specifications are written by experts in our research.
however since gpt .
does not release its model as well as the training data the latter programs from the existing dataset may have the risk.
the used dataset sv comp also has this risk.
nevertheless through our observation of specgen on these programs we have never spotted a situation where the output of specgen is the same as the existing oracle.
hence we believe this threat is limited.
furthermore even if we remove these potentially risky programs specgen still successfully handles programs in the remaining programs which is also the best.
external validity.
one of the external threats lies in the accuracy of the verifier openjml .
due to the implementation flaws in openjml there may be cases where some correcttable vi performance on programs collected from repositories in defects4j.
approacheschart cli codec compress jackson jxpath lang math time total num.
prob.
num.
prob.
num.
prob.
num.
prob.
num.
prob.
num.
prob.
num.
prob.
num.
prob.
num.
prob.
num.
prob.
daikon shot llm .
.
.
.
.
.
.
.
.
.
conversational .
.
.
.
.
.
.
.
.
.
specgen .
.
.
.
.
.
.
.
.
.
specifications fail to pass verification.
this is an inevitable problem that other verifiers have to face as well.
the reason lies in the undecidability of automatic software verification .
even in such a situation specgen achieves impressive performance with the majority of testcases successfully generated verifiable specifications.
another threat is the potential bias of the hand written specifications by experts.
to mitigate this we follow the procedure in nilizadeh et al.
.
first the selected experts should have rich experience in writing specifications.
second the initially chosen specifications should be verifiable by the verifier.
last if multiple experts have written the specifications that pass the verifier another expert is responsible for selecting one.
vii.
r elated work large language models.
with the advancement of generative ai large language models llms have emerged as a formidable force and have quickly found widespread applications.
llms are characterized by their immense parameter scale and training dataset size .
an important feature of llms is their ability for in context learning which enhances the coherence between the context and the output of llms.
the learning ability gives rise to a unique usage of llms known as prompting where a natural language description of the intended downstream task is provided to the llm before assigning it the task.
llms initially demonstrated remarkable capabilities in the field of natural language processing nlp excelling in tasks such as document classification text summarization and machine translation .
they are also widely deployed in various software engineering tasks including software testing code generation and code summarization .
compared with these works our goal is to employ llms for the automated generation of program specifications which is important in formal methods.
program specification generation.
the research on program specification generation can be categorized into two types natural language specification generation and formal specification generation.
natural language specification generation primarily manifests as code summarization a process of automatically generating accurate human readable descriptions of code functionality.
numerous efforts have been made to utilize machine learning methods for code summarization .
formal specification generation primarily takes the form of the generation of program invariants the formal language representations of properties that a program is guaranteed to satisfy at a certain program point.
in invariant generation a large amount of research focuses on the generation of loop invariants while the restof the works attempt to generate invariants of other forms e.g.
pre conditions post conditions assertion based invariants and finite automata .
with the development of large language models there have also been efforts employing llms to generate program specifications.
wen et al.
combine llms with static analysis techniques including code decomposition to generate verifiable program specifications.
pei et al.
utilize fine tuning to enhance the performance of llms on specification generation tasks.
concerning the difficulty of selecting correct specifications from the massive llm generated results chakraborty et al.
propose a ranking algorithm that can distinguish correct inductive invariants from incorrect attempts based on the problem definition.
among these works artifacts of ghosal et al.
and pei et al.
are not publicly available the artifact of alshnakat et al.
is built for c code and framac contracts and the grammar for specifications of molina et al.
involves specific features which cannot be trivially translated into equivalent jml thus we cannot include them for comparison.
compared to these works specgen utilizes the code comprehension capability of llms for program specification generation in a conversational manner further followed by the mutation based approach for enhancement.
viii.
c onclusion in this paper we introduced specgen a novel approach that utilizes the large language model for formal program specification generation.
leveraging the code comprehension ability of llms as well as the well designed mutation based specification generation component our approach is capable of accurately capturing the behaviour and functionality of input programs to generate accurate specifications.
a comprehensive evaluation between specgen and other baselines is conducted on two different datasets the benchmark for the java category of sv comp and a more diverse and manually constructed dataset containing programs.
the extensive experimental results haver demonstrated that our approach significantly outperforms the baseline approaches with the ability to effectively articulate program behaviors.
acknowledgment we are grateful for the constructive feedback of all the anonymous reviewers to improve this manuscript.
the authors from nanjing university are supported in part by the leadingedge technology program of jiangsu natural science foundation no.
bk20202001 the national natural science foundation of china no.
and the postgraduate research practice innovation program of jiangsu province no.
kycx24 .