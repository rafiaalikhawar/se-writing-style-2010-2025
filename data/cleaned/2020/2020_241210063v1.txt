unveiling the energy vampires a methodology for debugging software energy consumption enrique barba roque delft university of technology delft the netherlands enrique ebarba.comluis cruz delft university of technology delft the netherlands l.cruz tudelft.nlthomas durieux delft university of technology delft the netherlands thomas durieux.me abstract energy consumption in software systems is becoming increasingly important especially in large scale deployments.
however debugging energy related issues remains challenging due to the lack of specialized tools.
this paper presents an energy debugging methodology for identifying and isolating energy consumption hotspots in software systems.
we demonstrate the methodology s effectiveness through a case study of redis a popular in memory database.
our analysis reveals significant energy consumption differences between alpine and ubuntu distributions with alpine consuming up to .
more power in certain operations.
we trace this difference to the implementation of the memcpy function in different c standard libraries musl vs. glibc .
by isolating and benchmarking memcpy we confirm it as the primary cause of the energy discrepancy.
our findings highlight the importance of considering energy efficiency in software dependencies and demonstrate the capability to assist developers in identifying and addressing energy related issues.
this work contributes to the growing field of sustainable software engineering by providing a systematic approach to energy debugging and using it to unveil unexpected energy behaviors in alpine.
i. i ntroduction in recent years the demand for computing power has grown exponentially leading to a rapid increase in the number and size of data centers.
this growth is accompanied by a significant increase in energy consumption.
it is estimated that by data centers will consume of global electricity and account for5.
of global emissions .
while sustainable software engineering and energy efficiency studies have gained traction in mobile development due to battery life concerns energy optimization for server deployment remains relatively unexplored.
this gap stems from several factors server systems lack of reliance on batteries makes energy reduction less immediately impactful clients do not directly pay for server energy costs and there s a scarcity of tools for debugging energy consumption in server environments.
these circumstances have led to a situation where server side energy optimization lags behind mobile computing despite the significant environmental and economic impact of data center energy consumption.
addressing this disparity requires both technological advancements and a shift in perspective regarding the importance of energy efficiency in server side software engineering.
one of the main components of server software is the linux distribution over which software runs.
in modern server deployments they are typically bundled with the software intoa docker container and provide shared libraries over which other technologies run like the c standard library.
one important criteria for choosing a distribution is image size which makes images like alpine extremely popular with over a billion downloads on dockerhub.
however aspects like energy efficiency are often ignored or unknown by the community.
in this paper we present a methodology to help developers trace and identify energy consumption hotspots in server systems.
our work is motivated by the findings of tjiong who demonstrated that the base image of a dockerfile impacts the energy consumption of the running application.
however the root cause of this energy consumption difference remained an open question.
we introduce a methodology designed to locate the causes of energy consumption discrepancies.
this formal approach provides a systematic way for researchers and developers to investigate energy inefficiencies and regressions in workloads that use different libraries or technologies.
to demonstrate the effectiveness of the approach we present a case study investigating why the redis database consumes more energy on alpine than ubuntu.
this study addresses the following research questions rq1 does redis exhibit different energy consumption patterns on different operating systems?
rq2 is our approach capable of identifying the cause of energy consumption differences?
rq3 can the cause for the energy differences be isolated?
our evaluation reveals a difference of .
in total energy consumption and up to .
in power usage during redis execution on two different operating systems.
we attribute this difference to the use of different libc implementations musl versus glibc .
specifically we successfully identify the cause of this discrepancy in the memcpy function which is less performant and more energy intensive in musl .
in summary the contributions of this paper are a methodology for investigating energy regressions in software an empirical study highlighting significant energy regressions in the alpine distribution a set of scripts and benchmarks for investigating energy regressions in softwarearxiv .10063v1 dec 2024ii.
b ackground this section provides essential background information to understand the execution and analysis of our energy experiments.
we cover three key areas containerization technology c standard library implementations and energy profiling tools.
a. containerization and docker containerization is a virtualization technology designed to offer an efficient and streamlined approach to software deployment.
unlike traditional virtual machines containers encapsulate applications and their dependencies ensuring consistency across different environments and enhancing portability.
docker the most popular container platform facilitates the creation deployment and execution of containerized applications.
it uses the host machine s kernel providing a lightweight alternative to full virtualization.
this approach allows for seamless movement of applications between development testing and production environments addressing many challenges in modern software deployment pipelines.
b. c standard library implementations the c standard library libc api is defined by the international organization for standardization but multiple implementations exist.
the most widely used implementation is the gnu c library glibc created in and part of most linux distributions including ubuntu.
despite its popularity it has faced criticism for being bloated and slow with notable figures like linus torvalds expressing concerns .
an alternative implementation is musl introduced in .
it aims to be lightweight fast simple and standardscompliant and is the default implementation in alpine linux.
while musl offers performance benefits it can face compatibility issues with binaries compiled against glibc potentially affecting performance in certain scenarios such as with some python libraries .
c. energy profiling tools energy consumption measurement can be performed using physical power meters or software profilers.
each approach has distinct advantages and limitations physical power meters traditionally used for energy measurement especially in mobile device studies .
they provide accurate measurements but may lack granularity in component level energy consumption.
software profilers modern cpus allow energy measurements through cpu registers.
while less reliable than physical meters they offer component level energy consumption data including individual cpu cores.
the most common interface for these measurements is intel s running average power limit rapl .
notable software profiling tools include perf measures both computing performance and energy consumption.
powertop provides detailed power consumption analysis.
powerstat offers power consumption statistics and reporting.
while rapl is an intel implementation amd provides its own version with partial compatibility with intel s interface.
step collect energy datastep collect tracing data step synchronize foo step pinpoint energy hotspotslogsfig.
visual representation of the energy debugging methodology amd s implementation offers more fine grained details such as the energy consumption of individual cpu cores.
iii.
e nergy debugging methodology this section presents our main contribution the energy debugging methodology which simplifies the localization of energy consumption hotspots in software systems.
this methodology is designed to be a systematic approach that can be applied to any software system that has different versions or configurations that can be tested and it is the first step in the goal of automating the energy debugging task.
the methodology is divided into four steps energy measurement software tracing aligning trace and energy data and interpreting results.
to support the methodology we provide a script to automate the process in our replication package a. requirements and framework to debug energy consumption using our proposed methodology a few requirements ought to be considered.
first we require at least two versions of the software or system to study.
the differences between the two versions help localize potential energy hotspots.
energy consumption varies depending on the environment and absolute values of energy consumption alone provide meaningless insights.
it is therefore required to have a reference software that acts as a baseline to compare the energy consumption.
second we require an execution benchmark that performs an execution load on the software.
the more representative the benchmark is the more accurate the results will be.
i.e.
if the benchmark has a very homogeneous execution it is unlikely that energy hotspots will stand out.
finally we require a server that is ready for reliable energy data collection.
we recommend looking at the setup that we use for our evaluation see section iv a .figure figure depicts the methodology used for our measurements.
it can be summarized in the following steps.
run energy benchmarks to identify energy inefficiencies in different sets of dependencies run the software with tracing to obtain usage data on the functions from the dependency libraries apply log alignment to fix the time dilation introduced by the tracing latency.
analyze your data.
with the normalized data you can identify the most used functions during the timeframes where higher power usage is observed which can help identify the function responsible for the difference.
this section details each of these steps illustrating them by testing a postgresql workload.
section iv presents the redis case study and applies the methodology to obtain answers to our research questions.
b. energy measurement the first step of the methodology is to measure the energy consumption of the different versions of the software.
more specifically our methodology is designed to highlight the energy consumption differences between two different versions of the software.
the difference between these versions do not have to be limited to the software itself but it can also test different dependencies versions or forks.
we recommend isolating the versions of the software inside a docker container.
this allows the two versions of the software to run in the same environment while isolating execution to a single core and facilitates switching between versions.
additionally it is important that the execution of the software happens in the most systematic way possible.
the executions need to be replicated multiple times and in different order.
we use the framework provided by tjiong designed to assist in this process.
it follows the recommended best practices for energy measurements such as preload of the system execution repetition 30x rest between the executions randomization of the execution log management and energy measurements management.
it also integrates a cross platform energy measurement tool.
additionally we made small modifications to increase the information and timestamps printed in the logs to facilitate the log alignment step.
our fork for this framework is available in our replication package at the end of this step we obtain a list of power consumption over time for every version execution.
figure presents a visual representation of the collected data.
in this case we compare the energy consumption of postgresql on ubuntu vs. alpine operating systems.
this figure presents a line with the median power consumption for each operating system and illustrates the variability of the energy consumption with a shading area around the line between the 25th and 75th quartiles.
the median energy consumption is the area under the line of the respective operating system.
c. software tracing in the previous step we collected the energy consumption.
however it indicates a general behavior of energy consumption.
fig.
energy consumption of postgresql on alpine vs. ubuntu.
it is difficult to pinpoint the cause of the energy consumption.
this step aims at collecting software behavior to understand what is happening during the execution.
in this contribution we collect this software behavior by tracing the function execution of the software.
we use the uftrace tracer .uftrace is an analyzer and tracer for c c rust and python programs.
it can track both user space functions and calls to dynamically linked shared libraries.
the tool reports each call to a function and the duration of said call.
the program under study normally needs to be compiled using specific options like instrumentation but the tool also provides the option of dynamically patching certain functions during runtime.
this patching approach works well for simple shared libraries like the standard library but it has more problems when trying to trace internal function calls of complex software.
we collect the trace of the software by running the execution benchmark using uftrace once for each version of the software.
we do not need to repeat to step multiple times as this step is very time consuming and produces a very large quantity of data.
hence we separate this execution for trace data collection from the executions for energy data collection.
figure presents the trace report of uftrace .
it shows the execution time and the number of calls of each function of the program.
this information is collected by executing the benchmark with the tracing enabled.
this view offers a summary of the execution of the software.
however akin to our example if we want to identify the behavior of the software around a specific time this view does not help even if uftrace collects the temporal information.
indeed function tracing impact drastically the execution time in a nonuniform manner.
it is therefore impossible to directly compare tracing data with energy data.
however the function tracing can still be used as a large grain analysis to get the main suspects for the energy hotspot.
d. pinpoint energy hotspots in the previous steps we collected the energy consumption and executed functions.
however it indicates a general behavior of the software.
it is difficult to pinpoint the cause of the energy consumption hotspots.
for example in figure we see thatfig.
uftrace report of top used functions.
fig.
example of a checkpoint line in postgresql logs.
at the beginning of the execution postgresql consumes the same amount of energy but it changes from timestamp approximately.
what happens after ?
this step aims at providing some suspects.
the objective of this idea is to combine energy tracing with function tracers.
the energy tracer aims to measure the energy consumption as accurately as possible while the function tracer aims to identify what is happening during the execution.
the raw outputs of tracers provide temporary evolution function executions.
however an additional problem with this function tracing is that it had a non uniform overhead during the tracing.
this means that not only are the tracers not timesynced but a linear adjustment for time alignment is also not suitable.
consequently it is not possible to align the energy and function tracings directly using the raw data.
to solve this problem we use the execution log as a reference for time alignment.
for example if you have a benchmark that executes two tests and at the beginning of each test the benchmark prints test x .
those lines can be used as anchors to align the executions.
our framework of execution prepends the line with the timestamp it is therefore possible to know the execution time of each block on our logs and observe the energy consumption and the executed functions during those moments.
this key stoning method uses the execution logs provided to align logically equivalent points.
to relate the time points in energy data to time points in tracing data we find checkpoints in the logs.
for our study we define a checkpoint as a relevant and unique or almost unique line in the logs that marks the beginning or end of a section of the workload.
in other words checkpoints are progress marks for the benchmark.
an example of a checkpoint from redis is shown in figure .
redis marks the end of each tested command with some statistics of the execution preceded by a header that is unique in the logs.
the log alignment process consists of three steps and is designed to work without prior knowledge clean the logs by removing elements that vary over time fig.
evolution of the function usage over time with the vertical red lines as the identified checkpoints in the logs.
e.g.
dates times ids number of requests to avoid considering periodically reported measurements as unique.
identify relevant lines in the log that can serve as checkpoints.
this is an iterative process starting with unique lines that appear in both logs then progressively considering lines that appear or more times in both logs until obtaining enough well distributed checkpoints along the executions.
log lines near the beginning and end of the file are discarded.
align the tracer information by treating time regions between checkpoints as equivalent in terms of execution.
the distribution of calls is considered the same in both runs regardless of timing differences.
function tracing data between each checkpoint is agglomerated and presented as a histogram on the energy measurement tracing graph.
the result of this step is a graph similar to the one in figure it shows the evolution over time of the most used functions and it can be compared with the plot of power consumption over time in figure to identify potential energy draining suspects.
the dashed vertical lines depict the checkpoints used in log alignment.
e. interpretation results the final step of our methodology involves interpreting the tracer results.
this step is challenging to automate fully so we present an example of how to interpret these results.
comparing figures and we observe that the pwrite function dominates the beginning of the execution when there is no difference between ubuntu and alpine.
however around the millisecond mark when the epoll wait function starts to appear in the execution we observe a difference in energy consumption.
we also note that the send function is frequent and warrants consideration.
based on these results we would investigate epoll wait andsend by isolating them and performing micro energy benchmarks as we will present in rq3 iv d. iv.
e valuation in this section we evaluate our methodology by applying it to redis a popular in memory database that is downloaded around m times a week on dockerhub .rq1 does redis exhibit different energy consumption patterns on different operating systems?
the first research question aims to confirm the observation from the literature that observed energy consumption can vary depending on the operating system while preserving the performance.
we will focus on the redis case.
rq2 is our approach able to locate the cause of the energy consumption difference?
the relevance of the second research question is to highlight the performance regression in a system.
rq3 can the cause for the energy differences be isolated?
in the final research question we confirm the observation of rq2 by isolating and testing the identified cause of the energy regression.
a. experimental setup study subject for this evaluation we chose to evaluate our approach on the redis database.
we chose redis because it is a popular database that is used by millions of services and has been downloaded more than m times a week on dockerhub.
additionally redis was one of the workloads that showed a significant energy usage difference between alpine and ubuntu in previous work .
moreover redis does not have dependencies if we compile under the same compiler version and configurations the energy regression can be isolated in terms of software code being executed.
for our workflow we use redis benchmark which is the benchmark provided by redis.
this benchmark simulates the usage of redis by nclients to a total of mrequests allowing nandmto be parameterized.
tool energy measurement we chose energibridge to measure the energy consumption because it allows us to measure the energy consumption of one specific core on an amd cpu.
this feature allows the isolation of the measurements and reduces the impact of other running processes.
additionally this tool compared to others allows us to provide energy measurements at regular intervals as well as the cpu memory usage and temperature.
energibridge is also compatible with multiplatform windows linux osx and cpus intel amd mac arm .
protocol energy measurement measuring the energy consumption of software is difficult because software cannot run in a vacuum they depend on their environment to be able to be executed operating system dependencies virtualization memory hardware.
additionally the hardware can also be impacted by external constraints such as the temperature of the room.
consequently obtaining a precise measurement with a single execution is not guaranteed.
we follow existing guidelines that aim to mitigate those external factors .
before each experiment we execute a cpu intensive task for minutes using sysbench to warm up the cpu and have a consistent temperature.
the next mitigation is to run the energy measurements multiple times in a randomized order with a short pause between them.
the impact of possible variations introduced by unexpected variables like services in the system is reduced.
we perform executions as recommended by existing guidelines .table i the different setup configurations.
the marked cases with a are the original configuration used in .
label os compiler redis allocator ubuntupack ubuntu glibc .
.
jemalloc alpinepack alpine musl .
.
musl ubuntulibc ubuntu glibc .
.
jemalloc alpineglibc alpine glibc .
.
jemalloc alpinejem alpine musl .
.
jemalloc alpinemusl alpine musl .
.
musl alpinemusl6 alpine musl .
.
musl additionally we isolate the workload to a single cpu core and prioritize other processes to run on the other cpu core and measure the energy used by that core.
for example the energy collection tool will run on a different cpu core and therefore has a limited impact on the energy consumption of the experiment.
finally we fixed the cpu frequency and cpu voltage limited the access to a single user and limited the number of software installed on the server.
the experiments are run on a server equipped with an amd ryzen 7900x processor gb of ram and an nvidia geforce rtx gpu.
the server runs ubuntu .
.
with linux kernel version .
.
and docker .
.
.
b. rq1.
redis energy consumption as previously mentioned tjiong shows that different operating systems have an impact on the energy consumption of different software partially in the case of the redis database.
we identified multiple limitations in the existing study the version of redis is not consistent between operating systems different memory allocators were used and different compilers.
those changes could explain the differences.
to answer rq1 and confirm the difference in energy consumption between operating systems we replicate the redis experiments from the previous work .
table i shows the different configurations that are tested.
we extended the number of cases to standardize the running environment and isolate the potential cause of the energy difference.
for each of our scenarios we detail the redis version used the compiler and the memory allocator used by redis.
figure shows the violin plots for the total energy consumption of each image and table ii shows the total duration time and average energy usage energy .
a violin plot is similar to a box plot in the sense that it aggregates the measurements done showing mean and quartiles.
however instead of having a box shape it takes the form of the probability distribution of the data.
we chose this because it lets us check easily if the experiments are correct.
if the shape is symmetrical in the shape of a gauss bell we see that the results follow a normal distribution meaning that the variations in our energy readings are mostly due to random noise rather than systematic errors or unexpected factors.
the first thing we notice in this graph of figure is the energy difference between the images of redis in ubuntu and alpine.
the alpine version uses around .
more energy than the ubuntu version while taking roughly the same time tofig.
energy consumption of redis for the different configurations table ii average completion time and energy consumption for the different redis configurations image time s energy j ubuntupack .
.
alpinepack .
.
ubuntulibc .
.
alpineglibc .
.
alpinejem .
.
alpinemusl .
.
alpinemusl6 .
.
complete.
these are similar results to the one obtained in which validates their experiments.
when fixing and using the latest version of redis ubuntu andalpinemusl images instead of default package manager installations ubuntupack andalpinepack the energy gap gets smaller but remains significant.
average consumption improves slightly in ubuntu between both versions .
better and more considerably in alpine .
better .
this might indicate that there were some performance improvements in redis between versions.
however there is still a significant gap between alpine and ubuntu with alpine using around more energy than ubuntu.
this indicates that the discrepancies in redis versions from the original experiment are not the only reason for the energy performance difference observed.
we can also see how using the custom allocator alpinejem which was disabled in the alpine packaged installation slightly improves energy usage with respect to the standard library allocator from alpinemusl better .
however there is still a significant performance difference of8.
between alpinejem andubuntu meaning that this configuration difference is also not the main reason for the energy performance difference.
finally we look at the energy consumption of alpine with glibc alpineglibc image .
for this image results showcase a similar performance between alpineglibc and the ubuntu images.
except for some outliers the image performs at around the same level as the old ubuntu version with an observed .
improvement and slightly worse than the most recent ubuntu using .
more energy.
however the image performs considerably better than any of the alpine images with musl .
we further inspect these differences by comparing the fig.
cpu power usage w against runtime of redis for the different configurations.
power consumption throughout the different executions of the benchmark.
figure shows the median cpu power usage over time for the runs of each image across time during the execution.
in this image we can see that power usage is similar in all experiments for most of the redis benchmarks hovering at around 5w.
after a certain point power usage goes up for all images boxed region .
however this increase is not uniform and it affects musl images the most.
if we compare power usage between ubuntu andalpinejem images where all configurations are equal except for libc we obtain a difference of up to .17win the larger gap around .
difference .
this indicates that the main reason for the total energy difference is happening in this part.
we further investigate this pattern and manually check the logs.
we can observe that the operations that are running at this point are lrange operations from redis.
the lrange command is a simple instruction that given a key and a pair of start and end indices recovers the elements between those two indices.
in our benchmark elements from the database have a default size of bytes and the lrange instruction is tested for different numbers of elements and elements.
the power usage graph of figure reveals step increases highlighted by the blue arrows that correspond to the increase in the size of the responses from redis.
this correlation and the fact that energy consumption is similar to the rest of the benchmark suggests that power consumption depends on workload size.
the energy demands of the underlying functions vary linearly with either the argument size or the call number.
answer to rq1 .
alpine and ubuntu have a substantial difference in power usage and total energy consumption.
we confirm that this difference has its origin in the different libc implementations provided by the distributions by introducing glibc into the alpine distribution.
with every other redis configuration except for libc fixed we observe a difference of .
in total energy consumption and up to20.
in power usage.table iii summary of libc function calls and runtimes for redis function runtime calls memcpy .
.
write .
.
read .
.
epoll wait .
.
strchr .
.
strcasecmp .
.
gettimeofday .
.
memcmp .
.
clock gettime .
.
localtime r .
.
c. rq2.
pinpoint the energy hotspot now we want to find out the reason behind the difference.
to do so we apply our approach described in section iii.
the first step is to collect the energy measurements.
we can reuse the measurements from rq1 iv b .
the second step is to collect the execution trace to identify the location of the energy difference.
tracing is expensive and produces a large amount of data therefore based on the results of rq1 we focus the tracing on the libc since it was the main factor of difference.
we also adapted the size of the execution from to iterations to make the tracing execution manageable.
table iii shows the summary of the trace with the top functions that accumulate the longest runtime across the whole benchmark.
we see that the most called function memcpy .
however the software spends a similar time in the write and read functions with a much lower number of calls.
to gain additional insight into the cause of the energy difference we perform the third step localize energy hotspots cf.
section iii d .
this step revolves around applying a technique we coined as log alignment to synchronize the trace on the energy graph allowing us to study the lrange portion of the benchmark in detail.
figure shows the result of applying this process to the redis experiment.
the dashed vertical lines depict the checkpoints used in log alignment.
between each pair of checkpoints we draw a bar plot with the distribution of execution time across the most used functions.
on top of that we plot the lines of the power usage of the execution in alpine the line at the top colored in orange and ubuntu the line below colored in blue .
with this plot we can easily identify the main functions in the areas of the execution where the difference in energy consumption is more significant incidentally within the lrange portion of the benchmark .
we observe that memcpy is consistently the most used function in those areas.
redis uses memcpy to move that element to a memory buffer that is later sent to the client through tcp.
most of the functions tested in the benchmark only recover one element.
however lrange has multiple tests that recover up to elements which is done through an iterator that copies the elements to the buffer one by one.
this means that a single lrange request has up to more memcpy calls than other commands from the benchmark increasing the usage of the function.
we performed the same analysis for the postgresql database and identified the write function as the most likely source fig.
power usage of redis for ubuntu and alpine and histogram showing function runtime in each region between checkpoints.
of the issue.
to maintain clarity we have not included the postgresql analysis in this paper but the results are available in our replication package cf.
data availability section .
those results seem to indicate a difference in energy performance between glibc andmusl .
interestingly enough even with an energy difference it does not seem to have an important performance difference between the two implementations at least according to this benchmark .
energy debugging could be used to identify different behaviors between different implementations where execution time does not seem to be identified.
answer to rq2 .
our methodology was able to identify thememcpy function from musl as the main suspect for the higher energy consumption for redis.
we also identified the function write as another potential source of energy inefficiencies in postgresql d. rq3.
isolate energy hotspot in rq2 iv c we identify memcpy function as the main suspect.
this research question aims to isolate the difference in energy consumption of memcpy to prove it is the cause of the difference.
to do so we benchmark the memcpy function and measure the energy consumption.
the first benchmark consists of a simple memcpy benchmark written in c adapted from an existing benchmark .
this benchmark allocates a random memory buffer of gb and performs the following operations copy all gb to another point in memory with a single memcpy call copy all gb with multithreading to measure multithreaded performance.
copy all gb in small sequential batches using 220calls tomemcpy .
this is more similar to the behavior observed in redis each of the operations is repeated times to elongate the duration of the benchmark and be able to take proper energy measurements.
before starting a repetition the buffers get allocated with malloc and they are freed after each repetition.fig.
power usage of the memcpy benchmark with gb.
table iv average completion time and energy consumption for the memcpy benchmark with gb image time s energy j alpine .
.
ubuntu .
.
alpineglibc .
.
figure shows the power usage of this experiment for alpine and ubuntu and table iv shows average time and consumption.
we can observe a slight difference in power usage with alpine using slightly more power than ubuntu with a difference of around .5wor9.
for most of the benchmark.
at the final step of the benchmark where we divide the memcpy into220 sequential calls energy usage for the glibc based images goes up a bit while alpine usage remains the same.
the higher power usage in alpine is translated into a faster runtime and the alpine image ends up taking slightly less overall energy to complete the task.
this result is not the same as the one observed in rq2.
the discrepancy arises because this benchmark does not reflect the usage of redis.
further analysis reveals that the difference is due to the size of the memcopy .
in the redis benchmark only bytes of data are copied while in the previous benchmark a big chunk of data is transferred.
this detail is important because of memory alignment.
in bit architectures data in memory is required to be byte aligned .
this means that moving multiples of bytes is usually less expensive than moving less than bytes since the latter requires additional instructions to guarantee proper alignment.
we designed a new experiment that mimics redis s usage.
in this experiment we initialize a memory buffer destination of bytes and perform memcpy operations with smallsized elements.
for each of the sizes defined in the lrange benchmark and we copy that number of elements of size bytes and repeat for a large number of times to simulate the high number of calls in redis and to have a long enough benchmark so we can measure the energy accurately.
the dummy element we use for this experiment is the literal vkx the same dummy data that redis uses.
we provide this data to memcpy in two different ways in the first experiment fig.
power usage against time of the memcpy benchmark from memory to memory.
table v average completion time and energy consumption for the memcpy benchmark from memory to memory and cache to memory imagememory to memory cache to memory time s energy j time s energy j alpine .
.
.
.
ubuntu .
.
.
.
alpineglibc .
.
.
.
we initialize a second buffer of the same size source with the literal repeated over and over.
then we call memcpy using two moving pointers one to destination and another to source .
in the second experiment we use a cached literal and copy it over and over until filling the requested number of elements with a single moving pointer to the destination buffer.
while these two experiments might look functionally the same they change the data structures used and the information known by the compiler which changes the version of memcpy that is used for glibc .
figure shows power usage over time of the memoryto memory memcpy experiment and table v shows average runtimes and energy usage.
in this experiment we observe how the power usage of all images escalates to approximately 11w.
we can also see how in this case the glibc images are using more power than musl and unlike the previous experiment this is not translated to a shorter runtime.
indeed now all images take a similar time to complete and the alpine image uses 10jless to complete the task.
we can also notice the small step ups in power usage as the number of elements to copy goes up resembling the behavior observed in redis.
figure shows the power usage of the cached experiment and table v compares the runtime and total energy consumption of this experiment.
for this benchmark we obtain completely different results from the previous two benchmarks.
here musl is much more power hungry than glibc with a difference of around .1wor15.
difference closer to the difference observed in redis.
interestingly this difference does not translate into more performance with alpine taking almost more time to complete the task resulting in a much higher total consumption.fig.
power usage against of the memcpy benchmark from cached to memory.
these benchmarks show that the behavior of memcpy can vary wildly depending on what information is available in compile time.
we also notice how some of the benchmarks move in different power usage ranges to redis.
this can be explained because redis has network communication features.
in this benchmark all memcpy calls are done without pause.
however in redis once the memcpy calls for a request are finished the response has to be sent through tcp an i o operation in which the cpu does not have to be used as heavily.
we looked at memcpy implementation in glibc andmusl .
glibc seems to have additional optimization with some assembly code while musl does not .musl made the decision to have all its implementation in c however these results showcase an energy hotspot in musl that could be addressed by their developers.
answer to rq3 .
we successfully isolated the energy difference between operating systems.
this confirms that our approach is actually able to locate energy regression.
we also notice that the behavior and energy efficiency of memcpy can vary wildly depending on the information available at compile time.
v. d iscussion a. complexity of energy debugging energy debugging a subset of runtime analysis presents unique challenges that surpass those of traditional performance profiling in both complexity and time intensity.
several factors contribute to this complexity.
first there is a lack of mature profilers.
currently there are no sophisticated tools to assist developers in identifying energy hotspots effectively.
secondly a non linear relationship exists between performance and energy.
as our research questions demonstrated performance and energy consumption do not always correlate directly which can be counterintuitive.
additionally while execution time can give hints about the total energy consumption of software it is not always a good proxy and direct energy measurements should be used when possible.
finally modern cpus introducea masking effect.
the ability of current processors to execute multiple operations per cycle can obscure energy increases without corresponding changes in performance metrics.
our approach represents an initial step towards simplifying software energy debugging.
however it primarily aids in identifying potential suspects with manual work still required for confirmation.
the design of rq3 exemplifies this need for manual intervention.
domain knowledge remains crucial for isolating software components that might introduce energy regressions.
as shown in rq3 the same logical operations can have different energy impacts in different contexts which makes energy debugging a difficult task.
energy benchmarks can easily overlook less performant cases and there is a gap in research on best practices for benchmarking energy efficiency.
additionally this variety in scenarios makes improving energy efficiency a hand tailored process that can hardly be generalized to multiple technologies.
on top of this building software with code simplicity and clarity in mind can compromise energy efficiency .
this is reflected in the memcpy implementation from musl where the choice for simple code led to energy performance loss in certain scenarios.
as part of our study we also reached out to the kde eco community and presented our results in one of their meetups with senior people from the open source development community.1they confirmed the relevance of our findings and the lack of awareness regarding energy performance in the musl library.
furthermore our approach relies on programming languagedependent tracers highlighting the need for standardization in this area.
while we have made progress there is still a considerable path ahead to streamline energy debugging effectively.
b. generalization of our approach the complexity of energy consumption debugging is evident in our extensive analysis of redis and the partial analysis of postgresql.
these case studies demonstrate both the potential for generalizing our approach and the need for further automation in the field.
future research could explore automatic test generation techniques to repeatedly execute suspect functions potentially automating the isolation of energy regressions.
while such automations are beyond the scope of this paper they represent promising avenues for advancement.
our primary aim was to demonstrate the feasibility of energy debugging highlight its challenges and present a case study that current techniques would struggle to detect and debug.
notably the authors conducted the debugging of redis andlibc without prior internal knowledge of these systems underscoring our approach s capacity to assist even those unfamiliar with the target software.
1kde meetup minutes master community meetups 12 online community meetup.md retrieved on december 2024c.
use of docker for energy measurements our evaluation utilized docker environments to facilitate easy operating system changes through modifications to the dockerfile base image.
while the methodology could be applied to bare metal systems containerization simplifies the isolation of multiple instances of the same software and enables easier automation of energy measurements particularly given the need for repeated executions to ensure accurate observations.
as noted in related work vii docker introduces only a marginal energy increase compared to bare metal setups and this increase remains consistent across executions.
moreover as mentioned in the background section ii docker images share the same kernel thereby reducing variability between executions compared to full virtualization approaches.
vi.
t hreats to validity a. internal validity internal validity concerns the extent to which our study design supports the conclusions drawn.
representativeness of the benchmark the redis benchmark used in our study may not fully represent real world usage patterns and it may not capture all possible redis use cases.
to mitigate this we used the official redis benchmark tool which is designed to simulate typical workloads.
measurement accuracy the accuracy of our energy measurements could be affected by background processes or system noise.
to address this we followed established guidelines for energy measurements including multiple runs randomized order and cpu warm up periods.
b. external validity external validity concerns the extent to which our findings can be generalized to other contexts.
hardware dependence our experiments were conducted on a specific hardware configuration amd ryzen 7900x processor .
the energy consumption patterns and differences observed might vary on different hardware.
future work could replicate the study on diverse hardware to assess the consistency of our findings.
operating system versions we tested specific versions of alpine and ubuntu.
the energy consumption differences might vary with different os versions or distributions.
to partially mitigate this we tested multiple configurations including custom compiled versions of redis to isolate the impact of thelibc implementation.
single core isolation to properly isolate the redis server usage from the client or other processes we ran the server in a single cpu core following recommended practices.
additionally our study only measures cpu consumption and not other components like memory or i o. while it might not reflect the real life behavior of redis our experiments still uncover inefficient behaviors in musl smemcpy implementation that could appear in other applications.
software versions our study focused on specific versions of redis and the libc implementations.
the energy consumption patterns might change with future software updates.c.
construct validity construct validity concerns whether we are measuring what we intend to measure.
energy consumption metrics we primarily used cpu power usage as a proxy for overall energy consumption which may not capture all aspects of system wide energy usage.
however given that our focus was on cpu bound operations likememcpy this metric is likely to be representative of the energy differences we aimed to study.
use of docker while docker introduces minimal overhead and allows for easy comparison between different os configurations it may introduce some level of abstraction from baremetal performance.
we mitigated this by ensuring consistent docker configurations across all test cases and by isolating the workload to a single cpu core.
vii.
r elated work a. energy optimization for docker images existing tools use ast parsing of dockerfiles to provide base image suggestions through neural networks or to detect and warn developers about bad practices .
other studies propose techniques to assess image quality size and build times based on evolutionary trajectories or docker smells .
while these studies contribute significantly to their fields they do not address docker from an energy perspective.
several studies compare energy consumption for virtualization and containerization.
morabito found that for cpuheavy workloads power usage is similar across technologies while container based technologies show better performance for network tasks.
tadesse et al .
compared virtualbox and docker confirming similar cpu usage for cpu intensive tasks but showed that hypervisor based virtualization accomplishes less in the same time frame.
santos et al .
compared docker s energy efficiency to bare metal linux using applications like redis postgresql and wordpress finding that containers introduce a small often negligible energy overhead.
in general docker demonstrates better energy performance and lower cpu usage compared to virtual machines.
however these studies focus on comparing bare metal virtual machines and docker without exploring how docker s energy performance varies with different configurations or base images.
tjiong investigated how base image selection affects docker containers energy consumption for various workloads.
they tested multiple popular base images like ubuntu debian and alpine providing a framework for running and creating tests.
however their study is limited to reporting energy experiment results without delving into the underlying causes of the observed differences.
b. energy efficiency of languages and compilers pereira et al .
compared the energy efficiency of a wide range of programming languages using diverse programming problem benchmarks.
they found that compiled languages like c c and rust are the most energy efficient while interpreted languages like python or lua are the least efficient.
for compiled languages zambreno et al .
showed that producing more time efficient code does not always leadto better energy efficiency especially for memory performance.
pallister et al .
studied different combinations of gcc compiler optimization flags and their impact on energy consumption.
they found that while compiler optimizations generally improve performance and energy efficiency some combinations can increase energy usage without improving runtime performance concluding that no universally optimal set of optimization options exists.
c. energy efficiency in other software fields research has identified inefficiencies introduced by commonly used design patterns of reusability and object oriented programming.
xu et al .
demonstrated how using java collection objects like hashmap for simple data structures can introduce unnecessary complexity and performance issues.
bhattacharya et al .
highlighted how modern large scale applications built on deeply layered frameworks often include unused functionalities that can be an energy burden.
both studies agree that bloated software is a problem exacerbated by diminishing returns from moore s law .
in mobile software development where battery life optimization is crucial dornauer and felderer surveyed elements impacting energy consumption in mobile devices.
they found that the main research focus has been on optimizing cpu cycles through efficient scheduling with hardware improvements for wireless communication also being relevant.
cruz and abreu studied the effect of mobile software performance best practices on energy consumption.
their experimental study found that following these recommended practices generally leads to improved energy performance.
they later expanded this research into a catalog of energy patterns for mobile applications analyzing commonly applied patterns in android and ios applications by collecting commits in open source projects.
d. software energy profiling other works have previously studied energy usage at a function or library level.
schubert et al .
proposed eprof as a software profiler that can attribute energy consumption to code locations.
however the energy measurements for the cpu obtained from this tool are based on linear models which might not accurately reflect the energy usage of current cpus.
additionally it requires changes to the os kernel which can be difficult to perform for a developer due to technical expertise or lack of privileges over the machine used for experimentation and these changes might break with newer kernel versions.
noureddine et al .
introduce jalenunit a unit testing framework to compare the energy efficiency of java libraries in java using tracing and instrumentation.
while this technique is interesting the usage is limited to java workloads and uses statistical sampling to estimate energy consumption rather than directly measuring energy consumption.
viii.
c onclusion the increasing demand for computing power coupled with slowing efficiency gains in hardware has brought software energy efficiency to the forefront of computational challenges.this shift necessitates addressing previously overlooked inefficiencies in software libraries and implementations.
our research contributes a systematic methodology for identifying energy hotspots in software systems and their dependencies.
by effectively pruning libraries under study and pinpointing specific functions or sections with the greatest impact on energy consumption we significantly narrow the scope of investigation for developers and researchers addressing inefficiencies.
we demonstrated the efficacy of our approach through a case study with redis uncovering a notable energy inefficiency in alpine s musl library.
specifically we found that certain uses of the memcpy function in musl consume up to .
more power compared to ubuntu s glibc with a difference in a custom benchmark without runtime improvements.
this finding highlights a critical gap in current performance evaluations which typically focus solely on runtime metrics.
while the linux and c communities acknowledge performance differences between these libraries the energy consumption aspect has been largely overlooked.
the relevance of these findings where confirmed by experts during our outreach to the kde eco community.
although the observed difference may seem small for a single instance its significance amplifies when scaled to thousands or millions of instances across data centers.
this research underscores the importance of considering energy efficiency in software development and library choices particularly in large scale deployments where cumulative energy savings can have substantial environmental and economic impacts.