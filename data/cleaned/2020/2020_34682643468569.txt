validation on machine reading comprehension software without annotated labels a property based method songqiang chen i9schen gmail.com school of computer science wuhan university chinashuo jin imjinshuo whu.edu.cn school of computer science wuhan university chinaxiaoyuan xie xxie whu.edu.cn school of computer science wuhan university china abstract machine reading comprehension mrc in natural language processing has seen great progress recently.
but almost all the current mrc software is validated with a reference based method which requires well annotated labels for test cases and tests the software by checking the consistency between the labels and the outputs.
however labeling test cases of mrc could be very costly due to their complexity which makes reference based validation hard to be extensible and sufficient.
furthermore solely checking the consistency and measuring the overall score may not be sensible and flexible for assessing the language understanding capability.
in this paper we propose a property based validation method for mrc software with metamorphic testing to supplement the referencebased validation.
it does not refer to the labels and hence can make much data available for testing.
besides it validates mrc software against various linguistic properties to give a specific and in depth picture on linguistic capabilities of mrc software.
comprehensive experimental results show that our method can successfully reveal violations to the target linguistic properties without the labels.
moreover it can reveal problems that have been concealed by the traditional validation.
comparison according to the properties provides deeper and more concrete ideas about different language understanding capabilities of the mrc software.
ccs concepts software and its engineering software verification and validation .
keywords machine reading comprehension metamorphic relation propertybased validation language understanding capability acm reference format songqiang chen shuo jin and xiaoyuan xie.
.
validation on machine reading comprehension software without annotated labels a propertybased method.
in proceedings of the 29th acm joint european software these authors contribute equally to this research and are the co first authors.
xiaoyuan xie is the corresponding author.
permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
copyrights for components of this work owned by others than acm must be honored.
abstracting with credit is permitted.
to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
request permissions from permissions acm.org.
esec fse august athens greece association for computing machinery.
acm isbn .
.
.
.
conference and symposium on the foundations of software engineering esec fse august athens greece.
acm new york ny usa pages.
introduction with the development of natural language processing nlp techniques machines have been able to solve many textual tasks some of which even involve the human level language understanding .
one of the popular domains is machine reading comprehension mrc .
it requires the machines to read textual materials and answer questions based on the facts in the given materials just as humans do with reading comprehension tasks .
to boost the development of mrc on one hand many works proposed novel algorithms by enhancing its language representation and designing special neural networks .
on the other hand researchers built various benchmark datasets in various forms such as boolean question multiple choice and span extraction to test different natural language understanding nlu capabilities of mrc software.
there are also many leaderboards to record the state of the art performance of mrc software and inspire researchers to improve the algorithms .
while mrc has seen substantial progress in the above directions its validation method has not received much attention.
almost all the current mrc software1is validated with the reference based measures such as accuracy.
specifically given a trained mrc model researchers or engineers first need to obtain a well annotated dataset where each sample is with a ground truth label.
then the model is validated by checking the consistency between the label2and the actual output answer given by the model.
though being widely adopted such a validation method has its limitations from a practical perspective.
firstly the well annotated labels for test data are compulsory in current validation paradigm.
however due to the complexity of mrc tasks it usually costs quite a lot of human efforts to label these data.
thus many mrc datasets include even less than 10k samples which are much smaller than those ordinary deep learning datasets.
as a result given an mrc model the validation process will be always restricted to the current benchmarks which cannot properly reflect the real performance of the model when facing various data in plentiful real life application scenarios.
in other words it is very possible that many issues cannot be touched and detected by the the limited labeled test cases.
therefore it would be of great help if we are able to break the dependency on the annotated labels such 1in this paper mrc software refers to the implemented mrc model.
2in this paper label refers specifically to manually annotated label .
esec fse august athens greece songqiang chen shuo jin and xiaoyuan xie that the validation method is no longer restricted to existing benchmarks and more comprehensive and adequate validation processes are possible to be performed to examine the potential issues in mrc software.
secondly checking the consistency between the actual outputs and the ground truth labels may not be a sensible way to assess the language understanding capability of mrc software.
it is generally uncertain whether an observed consistency is obtained through truly understanding and inference or some trickeries like recognizing keywords.
besides the consistency only reports an overall performance of the tested mrc software from which we can hardly understand its true and specific strength and weakness.
this limitation is also realized by the nlp community recently .
as a result a validation method that can assess to what extent an mrc model can truly approximate different language understanding capabilities of human beings as well as reveal its specific strength and weakness is desired.
therefore in this paper we propose a property based validation method for mrc software to supplement the reference based one where the data whether labeled or not can be used as test cases for a much broader range of validation and the true performance of tested software regarding specific linguistic capabilities can be assessed.
specifically we first formulate the linguistic properties that the mrc software should follow into metamorphic relations mrs .
we then use each mr to construct the follow up inputs from the source inputs in the dataset and check whether violations to the mr can be observed between the source and follow up outputs.
with the violation rate on all the test cases the language understanding ability regarding each specific linguistic property can then be estimated accordingly.
in this work we propose seven mrs to evaluate the mrc software that solves boolean question task from basic linguistic properties such as the reactions with synonym tense and negation.
we conduct a comprehensive experiment to evaluate the effectiveness of our method.
specifically we use it to validate four mrc models built upon mainstream mrc algorithms i.e.
rnn bert roberta and t5 respectively on the boolean question mrc task boolq .
the results show that our method can successfully reveal violations to the seven linguistic properties on the four models without the need of labels rq1 .
as compared with the traditional reference based measure accuracy our method can still reveal several problems on the test data that software have given consistent answers as the labels rq2 .
based on the observed violations using our method the strength and weakness of the objective models in their language understanding abilities could be analyzed rq3 .
finally we show that our method has better effectiveness than the traditional accuracy measure in revealing the seeded mutants in the mrc models rq4 .
in summary this work makes the following contributions we propose a property based method to validate the machine reading comprehension mrc software against the linguistic properties that mrc software should follow.
by bypassing annotations and using various transformations it can perform broader validation on more data and assess the performance on various linguistic capabilities more deeply.
we propose and implement seven metamorphic relations to validate the capabilities of mrc software in understanding the transformation for some basic linguistic properties.
we conduct comprehensive experiments and found that our method can well supplement the reference based validation via stably and effectively revealing erroneous behaviors of the tested mrc software that have been concealed by the traditional validation method under a label free setting.
besides it can also give detailed evaluation results in terms of different linguistic properties for better evaluating the mrc model s language understanding capabilities.
the rest of the paper is structured as follows.
section illustrates the limitations of current validation methods for mrc software which motivates this work.
section introduces the target task and the methodology background.
then section elaborates the property based validation method in details with seven mrs proposed.
section and section describe the settings and the results of the experiment to evaluate the effectiveness of the proposed method respectively.
after that section analyzes the threats to validity and section discusses some related works.
finally section draws a conclusion and gives ideas on future work.
the tool dataset replication package and detailed results for this paper are available online at .
limitations of the current validation method for mrc currently almost every mrc software is validated with a referencebased method.
however such a reference based validation method has very obvious limitations.
.
compulsory labels in test set as mentioned in section a well annotated dataset is always a prerequisite in the current validation method.
however such a requirement has limited the application of this validation method mainly due to the difficulty in constructing well annotated mrc benchmark datasets .
as compared with label annotation for other ordinary deep learning tasks such as image classification assigning labels for mrc tasks generally involves much more human efforts.
for instance to create a labeled boolean question sample after providing the question and corresponding related article the annotator has to carefully read the article and deduce the answer yesorno of the question from the complicated facts reported in the article .
obviously the cost of this process is much higher than that for annotating an image.
taking two mrc datasets as specific examples swag cost about man hours labour to annotate 113k inference based multiple choice questions approx.
.
minutes per sample dureader spent even about 51k man hours to construct 200k fairly complex mrc test cases approx.
.
minutes per sample which involves workers and experts.
they are obviously much more costly than the annotation for the commonlyseen image classification and sentiment analysis samples which only require a simple glance from the annotators in general.
as a consequence many mrc datasets include even less than 10k samples which is generally much smaller than those ordinary deep learning datasets.
it is generally acknowledged that the more data adopted in validation the better that we can reveal the generalization capability of the learning based software.
however the compulsory labels force the current validation method 591validation on machine reading comprehension software without annotated labels a property based method esec fse august athens greece to be restricted to existing well annotated mrc benchmark datasets which cannot properly reflect the real performance of the model when facing plentiful real life application scenarios.
besides it is inevitable to have incorrectly labeled sample which introduces unreliability to the validation results as well.
therefore it would be very helpful if we can propose a new mrc validation method where the labels are no longer mandatory such that eligible test data for validation are no longer restricted to existing labeled benchmarks and a broader range of validation processes are possible to be performed.
.
limitation on revealing the understanding capability with reference based validation building models with good language understanding capability such as inference is always a core purpose of mrc tasks.
however current reference based validation method is not effective or efficient to evaluate the models from this perspective.
consider an example of boolean question will be introduced in section .
shown in figure a where a roberta based mrc software easily gives a correct answer when compared with the ground truth label of this sample.
with many similar samples giving correct answers this model can deliver fairly promising accuracy.
however as shown in figure b when we simply rephrase the question by changing the word social to its synonym societal or transform the question into a negative declarative sentence form and followed by a tag question is it right the model gets confused and outputs answers that violate the expected relations with the original source output.
in fact the above examples are not rare in mrc application scenarios.
in many cases the software may infer very complex facts but meanwhile is insensitive to simple linguistic phenomena.
it may also easily give a correct guess by memorizing some patterns or keywords rather than truly understand and deduce the answer .
at the meantime the traditional reference based validation method which simply reports how consistent the actual outputs and the ground truth labels are is not effective in revealing the actual language understanding capability of the model .
it is true that some researchers try to build datasets that test for more diverse and complex language understanding capabilities .
this can alleviate the above non effective issue to some extent.
however as introduced in section .
this idea that keeps using reference based validation can be very costly and hence not efficient enough.
therefore apart from evaluating the traditional reference based measures to provide the most basic understanding on the model s performance it is also necessary to have a validation method that can effectively and efficiently assess to what extent an mrc model can approximate the language understanding capability of human beings as well as reveal specific strength and weakness in the model s capability.
preliminaries in this paper we propose a property based method to validate mrc tasks which does not require any labels in testing dataset and aims to evaluate the mrc model in terms of its language understanding capability.
with this method many data without labels becomeinput article social studies in the united states education system social studies is the integrated study of multiple fields of social science and the humanities including history geography and political science.
the term was first coined by american educators around the turn of .
.
.
input question are social studies and social science the same ground truth label no output of roberta no a a boolean question sample source case validation with synonym input article same as the source input article input question are societal studies and societal science the same expected relation with the source output consistent output as the output of roberta in a output of roberta yes validation with negation input article same as the source input article input question social studies and social science are not the same is it right expected relation with the source output inversed output as the output of roberta in a output of roberta no b follow up cases with violation figure a validation example on boolq dev set eligible test data and hence the validation becomes much more comprehensive than the traditional reference based method.
.
target mrc task boolean question as a pioneer study in this paper we focus on the boolean question task which is a common and important mrc task .
figure a shows an example of boolean question.
one boolean question sample includes a question and an article that provides the evidence for deducing the answer to the question.
the mrc software with trained mrc model takes the article and question as one piece of test datum and is expected to answer yesornoto the question.
since the answer of a boolean question is either yesorno it is usually solved with a binary classification model .
such model is usually built upon some general language models or special reading models .
according to the superglue leaderboard the models based on some general language models like roberta and t5 have already shown fairly comparable performance as humans in terms of accuracy.
boolean questions make up an important subset in many popular mrc benchmark datasets .
among them boolq is a dataset fully made up of boolean questions which contains 16k boolean questions obtained from google search queries and paired with paragraphs from wikipedia that are recognized as sufficient to deduce the answer.
these questions are split into a train set a dev set and a test set.
since it is a benchmark dataset the authors of boolq only publish the ground truth labels for the questions in the train set and the dev set.
due to the representativeness boolq is also adopted as a standard benchmark task in a widely known mrc software benchmark platform superglue .
considering the popularity and the volume of boolean questions in boolq we use boolq as our dataset in this paper as well.
recently gardner et al.
proposed contrastset which gives more rigorous test cases that cover diverse and meaningful distribution near the model s decision boundary for nlp tasks including 592esec fse august athens greece songqiang chen shuo jin and xiaoyuan xie boolq.
all the samples in contrastset have manually annotated labels.
thus we also adopt the boolq part of contrastset as a more challenging and another fully labeled test set.
as a reminder contrastset aims to test the trained model more rigorously.
therefore the models tested with contrastset is the same as the ones tested with boolq dev set and test set.
.
property based validation method with metamorphic testing in order to break the dependency on the annotated labels we adopt a property based method metamorphic testing.
metamorphic testing mt was proposed to alleviate the oracle problem during software testing .
instead of checking the correctness of each individual testing output mt compares relations among multiple inputs and outputs against a list of properties which are also known as metamorphic relations mrs .
a commonly adopted example of mt is sinfunction.
it is very difficult to verify the correctness of an arbitrary sin x .
but we know the property that sin x sin x should always be held.
accordingly an mr that when x x sin x sin x can be derived where x is the source test case and x is the follow up test case.
usually the process of mt can be automated including generation of the follow up test cases based on the mr execution of the source and follow up test cases as well as checking the relation between the source and follow up outputs against the mr. because of the usefulness in alleviating the oracle problem mt has been widely applied in testing and validating various machine learning ml and deep learning dl applications where the labels of test data are generally hard to obtain.
an early study by xie et al.
presented and proved a list of mrs to test supervised ml software .
in recent years mt has seen successful applications in autonomous driving systems that are based on deep learning algorithms .
besides mt shows promising results in language translation services .
apart from bypassing the prerequisite of test data labels mt is also helpful in revealing various properties of the objective system.
in xie et al.
gave the first evidence to demonstrate the insufficiency of solely relying on the accuracy in testing and validating supervised machine learning programs.
in a tool named mettle was proposed to provide an extensible checklist of properties formulated in mrs for validating assessing and selecting unsupervised ml clustering systems.
in people from the nlp community started to realize the insufficiency of referencebased metrics and implemented a tool checklist .
checklist mainly proposes a guidance that refers to some commonly accepted basic linguistic properties to test nlp models.
this guidance includes two parts namely inv dir mt based testing and mft template based unit testing .
but in the mt based part checklist only realizes two primitive mrs for mrc task by referring to two widely used robustness related properties namely adding typos and irrelevant sentences .
other properties are merely referred by the mft part which provides abstract guidelines to help users define their templates for unit testing.
besides this work performs a very sketchy experiment on mrc which does not give a comprehensive or detailed understanding about the benefits for using properties.in this paper we adopt mt to break the dependency on the labels as well as to assess more linguistic properties of the boolean question mrc software via mrs. comprehensive experiments are also conducted to give in depth understanding on how our proposed method supplements reference based validation.
methodology as mentioned above we propose to validate mrc software with test cases regardless label existence by considering a list of linguistic properties that the software should follow.
the basic idea comes from how a human being will react when facing two statements with a relationship of some linguistic properties like negation synonyms and tense.
for example if a person has really comprehended the given article and the boolean question expected to be judged as yesorno then when the question is negated the person should give an inversed judgment as the previous one.
these linguistic properties are formulated in metamorphic relations mrs denoted as mr mr mr ... mr n .
eachmri ti ri defines a transformation tiand an output relation ri which requires that the outputs of the mrc software before and after applyingtion the article and question in the input should satisfy ri.
more specifically given an input s a q whereaandqare the article and the question of s respectively we denote the output of sas the source output o. we modify aandqaccording to the transformation defined by tiand obtain a follow up input s a q .
we denote the corresponding follow up output as o .
finally the relation between oando is checked against ri.
if the relation riis not held a violation is reported.
it can be found that the above process does not require any annotated labels since we do not check the correctness of either ooro but only check their relations.
in our method if an mrc software is always able to give responses that satisfy the required relation with transformations on a set of test data it is said to have a good capability to understand the given article and the contents depicted by one question and its variants as well as to recognize the semantic differences caused by the corresponding linguistic properties.
consequently the language understanding abilities can be estimated accordingly.
with the above property based validation method we can tackle the two limitations in section .
firstly this method can validate mrc software without depending on the ground truth labels of inputs which does not require laborious manual annotation and hence can efficiently provide an extensible validation and tackle the first limitation in section .
.
secondly the method automatically constructs test cases regarding diverse forms of language expression to validate specific linguistic capabilities of the mrc software.
and instead of simply checking the correctness of one output against the reference i.e.
the ground truth label the method examines various relations among the outputs of related inputs which correspond to different linguistic capabilities which can help further reveal problems in those test cases passed in the reference based validation by some trickery rather than inference.
therefore this method is helpful in tackling limitation in section .
.
as a reminder our method differs from the simple data augmentation in two folds.
on one hand data augmentation still requires the labels for the original samples while our method dynamically 593validation on machine reading comprehension software without annotated labels a property based method esec fse august athens greece extends the dataset without the requirement of the labels for either the source or the follow up outputs.
on the other hand the augmented test samples are simply added to the original test set and still utilized in a reference based validation.
in contrast our method aims to reveal the specific linguistic properties on which the mrc software delivers poor performance.
in this paper we propose seven mrs from two perspectives.
this list of mrs can be easily expanded by experts or users during the usage of this method.
.
mrs with inversed outputs mr1 invertion with antonymous adjective.
it is known that vocabulary is the unit block to form a sentence.
in the first mr we conduct a antonym recognition test on adjectives.
specifically suppose there is a boolean question input sj aj qj and we denote its output as oj whereojisyesand the question qj matches one of the following sentential forms be noun.
adj.
.
.
.
be noun1.
adj.
noun2.
.
.
.
be noun1.
adj.
noun2.
.
.
.
be noun1.
prep.
adj.noun2.
.
.
.
be noun1.
done prep.
adj.
noun2.
.
.
.
if we replace the first adjective in qjwith its antonym the follow up outputo jshould be inversed into no.
as shown in the example1 when scott and sid is based on a true story they cannot be based on a false story at the same time.
therefore when both the source output and the follow up output areyes there must be a mistake between them.
that is the model can not give the correct answer to at least one of the questions.
example1 question of source input is scott and sid based on a true story question of follow up input is scott and sid based on a false story as a reminder in this mr a source input will be transformed only when its output is yes3.
but this is different from checking the correctness of this output.
in fact regardless of the correctness of this output as long as its judgment is yes then the corresponding input is always eligible for mr transformation.
similar requirement can also be found in the following mr1 and mr1 .
mr1 invertion with tense change.
tense is a mechanism to deliver different temporal information and indicate the status of a particular event action.
suppose there is a boolean question input sj aj qj whose output ojisyes the answer should be inversed after we change the tense of the question qj.
in this paper we only consider the changes among three tenses namely past tense present perfect tense and future tense because the relationship of correctness among them is relatively clear.
the three tenses are recognized according to some widely seen patterns as follows past tense didnoun.
.
.
.
present perfect tense have has noun.
done .
.
.
future tense isnoun.
going to will noun.
.
.
.
3if the source output is no this mr is not applicable since it is not guaranteed to have inversed output in such cases.we transform the question written in past tense andpresent perfect tense into future tense and future tense into present perfect tense .
example1 question of source input will there be a fifth season of mom question of follow up input has there ever been a fifth season of mom in example if the question of source input is yes it claims that the fifth season of the film mom will be put on in the future.
in contrast the question of the follow up input adopts the present perfect tense to express the existence of the film by now.
these two statements should be contradicted with each other.
as a result there must be at least one mistake if both the source output and the follow up output are yes.
as a reminder we only consider the above three patterns because we found others may introduce ambiguity.
for example a pattern like was noun.
... does not guarantee an inversed output after changing the tense.
consider a sample question was the dog black if its output is yes we cannot expect a question is the dog black gives noanswer.
mr1 invertion with order change.
as we know the word before and after indicate opposite temporal or spatial orders between two things.
inspired by this we design this mr to inspect the capability of mrc software in understanding the order relation in the natural language.
specifically suppose there is a boolean question input sj aj qj whose questionqjcontains before or after and output ojisyes the answer should be inversed if we swap before and after inqj.
if there are more than one before or after inqj we only change the first before or after .
example1 gives a case to illustrate this mr from the perspective of temporal order.
in this example the peloponnesian war cannot happen both before and after the persian war.
therefore there must be at least one mistake once both the source output and the follow up output are yes.
example1 question of source input was the peloponnesian war before the persian war question of follow up input was the peloponnesian war after the persian war mr1 invertion with negation and tag question.
negation is also a basic grammatical transformation thus we set up an mr with inversed output by negating a statement.
specifically suppose there is a boolean question input sj aj qj the answer should be inversed if we negate qj.
as a reminder to avoid ambiguity we negate the question into a negative declarative sentence followed by a tag question is it right .
considering the boolq task allows questions in free forms such forms of negations should be also valid inputs under the context of boolq .
example is to illustrate this mr. if the outputs of the source input and the follow up input are consistent either both are yesor both are no the model should make one wrong judgment.
example1 question of source input is there such thing as a black card question of follow up input there is not such thing as a black card is it right 594esec fse august athens greece songqiang chen shuo jin and xiaoyuan xie .
mrs with consistent outputs mr2 consistence with synonymous adjective.
in addition to mr1 we also consider to build the follow up inputs through adjective synonym substitution to validate mrc software s understanding on adjectives.
this mr is similar to mr1 in form but does not further demand for the restriction on the source output as yes.
specifically suppose there is a boolean question input sj aj qj whereqjmatches one of the patterns introduced in the definition of mr1 if we replace all the adjectives in qjwith their corresponding synonyms the answer should be consistent.
example2 question of source input can a tight hat give you a headache question of follow up input can a taut hat give you a headache example2 gives an example to illustrate this mr. since the two questions express the same meaning there must be an error if the model outputs differently on the two inputs.
mr2 consistence with adverbial clause position change.
since the position of adverbial clause could be flexible in a sentence we construct an mr by changing the position of the adverbial clause to validate the capability of not affected by this changing for mrc software.
given a boolean question input sj aj qj where qjincludes an adverbial clause starting with when in at on or if the answer should be consistent if we change the position of the adverbial clause in the question.
specifically if the adverbial clause is at the beginning of the question we move it to the tail.
otherwise we move it to the beginning of the question.
example2 gives an example to illustrate this transformation.
example2 question of source input can you turn left on red in canada question of follow up input in canada can you turn left on red mr2 consistence with active passive voice change.
this mr validates the capability to understand voice for mrc software.
although the change on the voice may affect the result of some nlp tasks like sentiment analysis it would not affect the fact it describes.
as a consequence it is also a reasonable option to produce an mr with consistent output accordingly.
different from the other six mrs we apply this transformation on the article ajrather than the question qjof the samples because the article has much higher chance to contain modifiable sentences than the question.
given a boolean question input sj aj qj this mr requires the answer should be consistent if we change the voice of all the modifiable sentences in aj.
example2 is an example to illustrate this transformation.
example2 article of source input ...the company now uses the sse brand throughout the uk.... article of follow up input ...the sse brand is now used by the company throughout the uk.... .
validation process based on mrs given an mrc software m the entire validation process is as follows.
specifically as shown in figure for each mri ti ri and a test set s s1 s2 ... s n we first construct the input set figure visualization of validation process si si si si si ... sim si m wheresi jis an eligible source input from sandsi jis the corresponding follow up input constructed from si j based ontiofmri.
each pair of si jandsi jis tested onm and their outputs are compared against riofmri.
the validation result of mis then measured with its violation rate vr which shows to what extent mgives reactions unsatisfyingri.
specifically for each pair si j si j insi letoi jbe the source output and oi jbe the follow up output.
if mriis an mr with inversed output mr1 to mr1 the violation state on si j si j is recorded as vsi j 1ifoi j oi j otherwise vsi j .
ifmriis an mr with consistent output mr2 to mr2 the violation state on si j si j is recorded as vsi j 1ifoi j oi j otherwisevsi j .
then the violation rate on siin terms ofmriis defined as vi r si j 1vsi j si different from traditional reference based measures such as accuracy vris expected to be as low as possible .
the lower vr that an mrc software can give the less error it makes and hence better performance it delivers.
based the above description it is not difficult to find that our method has higher level of automation than the traditional manual label annotation and hence can be more efficient during the validation.
thus we are now particularly interested in the effectiveness of this method and conduct an experiment accordingly.
experimental setup .
research questions in this experiment we aim to address four research questions rq1 overall effectiveness of the proposed property based validation method.
this rq aims to give a global picture on the usefulness of our method in assessing language understanding capabilities of the mrc models to tackle limitation without using any annotated labels to tackle limitation .
rq2 comparison with traditional reference based validation.
in this rq we aim to understand how the proposed property based method supplements the reference based validation.
specifically we will investigate the relation between the violation rate vrand traditional accuracy to see the further benefits of using our method.
rq3 performance comparison on mrc models from seven linguistic properties.
as introduced in section .
it is also desired to understand detailed strength and weakness of the mrc models in terms of their language understanding capabilities.
thus in this rq 595validation on machine reading comprehension software without annotated labels a property based method esec fse august athens greece we compare the mrc models adopted in our experiment from the seven mrs that correspond to seven different linguistic properties .
rq4 effectiveness of revealing disturbance on mrc models.
in this rq we perform a mutation analysis to further compare the effectiveness of our method and the traditional reference based method in revealing the seeded mutants.
.
validation objects in this paper we pick four typical algorithms namely rnn bert roberta and t5 to construct corresponding mrc models as our validation objects.
among them roberta and t5 have achieved comparable accuracy as humans do .
the four objective models are described and built as follows rnn rnn is a classic method used in early mrc works .
we build a bi lstm rnn based model for text pair classification as suggested in boolq paper .
the model includes two bi lstm layers with cells and co attention mechanism which are then followed by two fully connected linear layers.
bert bert is the first large scale transformer based pretrained language model ptm .
when proposed it outperforms the other methods by large margins on nlp tasks including many mrc tasks like squad .
we build a model based on the base size bert to show the early performance of such huge ptms.
roberta roberta is an improved version of bert and shows more robust and even better performance than bert on many tasks such as squad and race .
we construct a binary classification model based on the large size roberta as the corresponding objective model.
t5 t5 is a transformer based encoder decoder model that creatively solves all textual tasks in a text to text form.
for example the boolean question will be solved by generating the string yes.
or no.
after getting the input.
due to the limited gpu memory we use the base size t5 to build the objective model.
the rnn model is built with the implementation from and trained with a batch size at and a learning rate at .
.
the other three models are built with the transformers library and fine tuned with a batch size at and a learning rate at .
.
training and fine tuning are performed on boolq train set that contains samples.
for each algorithm the checkpoint with the best accuracy on boolq dev set is picked as the ultimate objective model to avoid overfitting .
.
data preparation as introduced in section .
we have three datasets for validation namely boolq dev set including samples boolq test set including samples and the boolq part of contrastset denoted as contrastset for short in the following experiment including samples .
among these three datasets only boolq dev set and contrastset are released with annotated labels.
therefore the accuracy could only be calculated on these two sample sets while our method could be conducted on all these three datasets.
before conducting the validation with the proposed method we first construct the follow up inputs from the source inputs which has been introduced in section .
.
during this process the adjectives are recognized with spacy toolkit and their antonyms and synonyms are generated with wordnet dictionary .
for mr1 and mr2 we use the pattern library to obtain the verbs in the required tense and voice.
and for mr1 and mr23 the subjective and predicative clause of one sentence are also extracted with spacy toolkit .
to ensure the validity of the generated follow up cases we manually inspected all the generated inputs.
we inspected the syntactic validity of the generated follow up inputs with respect to grammar and semantic meanings.
in total we found less than of the follow up inputs with slight errors.
we repaired all of them and put their correct version back to the input set.
as a reminder this inspection is not aiming to give the answer of the question the label for the test case .
instead it shows a tolerably low error rate compared with such that users can skip this manual inspection in their real usage.
.
mutant generation in rq4 we investigate whether our method is sensitive enough in revealing the seeded mutants in the objective models.
since the mrc software is based on deep learning models we adopt the mutation operators specially designed for neural networks.
ma et al.
proposed eight types of operators to mutate the models of fully connected linear layers.
however none of the objective models in our experiment uses fully connected linear layers as the core functional layers.
therefore we adopt four out of the eight operators that can be transferred to rnn and transformer as our mutation operators .
the details of the operators are as follows operator gaussian fuzzing.
weights of the neurons act as the key to control the decision logic of the neural networks.
this operator fuzzes the values of the weights for all the target neurons to change the connection importance they represent which is achieved through adding gaussian noise n 2 .
we set to be and to be .
as suggested .
operator weight shuffling.
the output of a neuron is usually determined by the neurons in the previous layer through the connections with weights.
this operator shuffles the weights of x randomly picked target neurons to disturb their connections with their previous layers.
we set xto be as suggested .
operator neuron effect blocking.
every neuron in a neural network contributes to its final decision to some extent.
this operator removes the influence of y randomly picked target neurons to the final decision which is achieved by resetting their connection weights of the next layers to zeros to block the propagation of their effects.
the yis set to be as suggested .
operator neuron switch.
different neurons in one neural network layer usually play different roles on the connected neurons in the next layer.
this operator switches the weights of two neurons in the same layer to exchange their effects for next layer.
such exchange is performed on z randomly chosen target neurons for each layer and zis also set to be as suggested .
since the core functional neurons in rnn and the other three objective models are lstm cells and transformer cells respectively we hence regard the lstm cells and the transformer cells as the target neurons during mutation.
specifically we perform the operators on the weights of the input modulation gate input gate forget gate and output gate for an lstm cell and the query weight key weight and the value weight for a transformer cell.
596esec fse august athens greece songqiang chen shuo jin and xiaoyuan xie results and analysis .
rq1 overall effectiveness of the proposed property based validation method in this rq we study the overall effectiveness of our method for validating mrc models.
table shows the violation rate vr of each objective model on the three adopted datasets.
generally speaking our method delivers fairly good performance to reveal the erroneous behavior of the objective models.
all the vrin table are greater than out of the total trials have their vrhigher than and somevrcan achieve as high as .
bert and rnn with boolq test and contrastset under mr1 .
table violation rate vr of each objective model dataset model mr1 mr1 mr1 mr1 mr2 mr2 mr2 boolq devroberta .
.
.
.
.
.
.
t5 .
.
.
.
.
.
.
bert .
.
.
.
.
.
.
rnn .
.
.
.
.
.
.
boolq testroberta .
.
.
.
.
.
.
t5 .
.
.
.
.
.
.
bert .
.
.
.
.
.
.
rnn .
.
.
.
.
.
.
contrastsetroberta .
.
.
.
.
.
.
t5 .
.
.
.
.
.
.
bert .
.
.
.
.
.
.
rnn .
.
.
.
.
.
.
more specifically we found that on the boolq test set row to row that lacks ground truth labels for accuracy calculation our method can find many violations as on the fully labeled boolq dev set row to row and contrastset row to row .
this demonstrates that our method can validate the mrc software under a label free setting which effectively addresses limitation .
and the observed violations to each mr clearly demonstrate the shortcomings of each mrc model in the corresponding linguistic properties which shows the effectiveness of our method in alleviating limitation .
.
rq2 comparison with traditional reference based validation in this rq we aim to study the relation between the violation rate vr in our method and the traditional accuracy to understand the further benefit of using our validation method.
therefore we compare vrand traditional accuracy of each objective model on different datasets.
since boolq test set does not provide labels for accuracy calculation we only conduct this comparison on boolq dev set and contrastset.
due to the limited space we only demonstrate the results with roberta and t5 which are shown in figure .
comparisons for the other two models give similar conclusions.
for all the detailed data please refer to .
in figure the left seven clusters of bars each cluster contains two bars corresponding to contrastset and boolq dev datasets show the vrof the seven mrs. and the right most cluster of bars present the values of accuracy that mean the rates of samples having inconsistent labels as the given