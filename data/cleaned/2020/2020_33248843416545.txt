problems and opportunities in training deep learning software systems an analysis of variance hung viet pham university of waterloo waterloo on canada hvpham uwaterloo.cashangshu qian purdue university west lafayette in usa qian151 purdue.edujiannan wang purdue university west lafayette in usa wang4524 purdue.eduthibaud lutellier university of waterloo waterloo on canada tlutelli uwaterloo.ca jonathan rosenthal purdue university west lafayette in usa rosenth0 purdue.edulin tan purdue university west lafayette in usa lintan purdue.eduyaoliang yu university of waterloo waterloo on canada yaoliang.yu uwaterloo.canachiappan nagappan microsoft research redmond wa usa nachin microsoft.com abstract deep learning dl training algorithms utilize nondeterminism to improve models accuracy and training efficiency.
hence multipleidenticaltrainingruns e.g.
identicaltrainingdata algorithm and network produce different models with different accuracies andtrainingtimes.inadditiontothesealgorithmicfactors dllibraries e.g.
tensorflowandcudnn introduceadditionalvariance referredtoasimplementation levelvariance duetoparallelism optimization and floating point computation.
this work is the first to study the variance of dl systems and theawarenessofthisvarianceamongresearchersandpractitioners.ourexperimentsonthreedatasetswithsixpopularnetworks showlargeoverallaccuracydifferencesamongidenticaltraining runs.
even after excluding weak models the accuracy difference is10.
.inaddition implementation level factorsalonecausethe accuracydifference acrossidenticaltraining runstobeup to2.
theper classaccuracydifferencetobeupto52.
andthetraining timedifferencetobeupto145.
.allcorelibraries tensorflow cntk andtheano andlow levellibraries e.g.
cudnn exhibit implementation level variance across all evaluated versions.
our researcherand practitioner survey showsthat .
ofthe 901participantsareunawareoforunsureaboutanyimplementation level variance.
in addition our literature survey shows thatonly .
of papers in recent top software engineering se artificial intelligence ai and systems conferences use multipleidentical training runs to quantify the variance of their dl approaches.thispaperraisesawarenessofdlvarianceanddirects se researchers to challenging tasks such as creating deterministic dl implementations to facilitate debugging and improving the reproducibility of dl software and results.
permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation onthe firstpage.copyrights forcomponentsof thisworkowned byothersthan the author s mustbehonored.abstractingwithcreditispermitted.tocopyotherwise or republish topostonserversortoredistributetolists requirespriorspecificpermission and or a fee.
request permissions from permissions acm.org.
ase september virtual event australia copyright held by the owner author s .
publication rights licensed to acm.
acm isbn ... .
concepts softwareanditsengineering empiricalsoftwarevalidation general and reference empirical studies .
keywords deep learning variance nondeterminism acm reference format hungvietpham shangshuqian jiannanwang thibaudlutellier jonathan rosenthal lintan yaoliangyu andnachiappannagappan.
.problems and opportunities in training deep learning software systems an analysisofvariance.in 35thieee acminternationalconferenceonautomated softwareengineering ase september21 virtualevent australia.acm new york ny usa pages.
introduction deep learning is widely used in many fields including autonomous drivingcars diabeticbloodglucoseprediction andsoftware engineering .
dl training algorithmsutilizenondeterminismtoimprovetrainingefficiency and model accuracy e.g.
using shuffled batch ordering of training data to prevent overfitting andspeed up training .
thesenondeterminism introducing ni factors cause multiple identical training runs i.e.
training runs with the samesettings e.g.
identical training data identical algorithm and identical network toproducedifferentdlmodelswithsignificantlydifferent accuracies and training times .
forexample ourexperimentsshowthatfor16identicaltraining runs of a popular dl network lenet5 the accuracy of the resulting16modelsrangesfrom8.
to99.
alargeaccuracy differenceof90.
.fouroftheseidenticaltrainingrunsresultedin weakmodels accuracybelow20 .evenifweexcludesuchmodels theaccuracydifferenceisstillupto10.
withlenet1betweenthe most accurate run .
and the least accurate run .
.
one can eliminate the variance introduced by algorithmic nifactors e.g.
shuffled batch ordering using fixed random seeds.
for example with a fixed seed for batch ordering multiple identical training runs will have the same batch ordering.
we refer to these runs asfixed seed identical training runs.
in addition to these algorithmic ni factors dl libraries e.g.
tensorflow and cudnn introduce additional variance.
35th ieee acm international conference on automated software engineering ase forexample bydefault coredllibraries e.g.
tensorfloworpytorch performdatapreprocessing inparallelforspeed which changestheorderoftrainingdata evenifalgorithmicallythebatch orderisfixed.inaddition coredllibraries bydefault leverage autotuneto automatically benchmark several modes of operation i.e.
underlying algorithms for computations such as addition for each primitivecudnnfunction e.g.
poolingandnormalization inits firstcall.thefastestmodeofoperationisthenusedforthatcudnn function in subsequent calls.
different identical runs sometimes use different modes of operation introducing variance.
ourexperiments section .
showthatthese implementationlevel ni factors alone cause an overall accuracy difference of up to .
.
specifically we train the popular wideresnet or wrn 10forshort dlnetworkfor imageclassification16 times using the same default training configuration e.g.
same cifar100 trainingdata batchsize optimizer andlearningrate schedule identicalmodelselectioncriteria i.e.
selectingmodels with the lowest loss on a validation set the same dl libraries i.e.
keras .
.
tensorflow .
.
cuda .
and cudnn .
andidenticalhardware i.e.
thesamenvidiartx2080tigpu while disabling all algorithmic ni factors i.e.
using fixed random seedstoensureidenticalinitialweights identicalbatchordering deterministicdropoutlayers anddeterministicdataaugmentation .
this processgenerates 16models.
sinceall algorithmicni factors are disabled one may expect little variance across the runs.however we found that the accuracies of these models vary between .
and .
a .
difference .
these implementation level ni factors and differences are often characteristicsandconsequencesofthedl softwareimplementations whichcreateuniquechallengesforseresearchersandpractitioners section while dl researchers have paid little attention toimplementation levelni factors thefocusisontheoreticalanalyses of dl training .
to see whether such difference is known we conduct a survey section which surprisingly shows that .
of the responded researchers and practitioners with dl experience areunaware of .
or unsure about .
any implementation level variance!
of the respondents only .
expect or more accuracy difference across fixed seed identical training runs.
wealsoperformaliteraturesurveyof454papers randomly sampled from recent top se ai andsystemsconferences to understand the awareness and practices of handling dl system variance in research papers.
of papers that train and evaluate dl systems only19.
usemultipleidenticaltrainingrunstoquantifythe variance of their dl approaches.
the per class accuracy exhibits a much larger difference among the fixed seed identical training runs.
for example in the previouslydescribed wrn 10runs forthe camel class allimages withtheground truthlabelof camel themodels accuracyvaries from .
to .
a .
difference .
in addition there are large differences in convergence time.
for example the time to convergence of the fixed seed identicaltrainingrunsofanotherpopularnetwork resnet56 ranges from2 986to7 324seconds aonehourand12minutesdifference a .
relative time difference.
we also observe a discrepancybetween the empirical per class accuracy and convergence timeand the corresponding estimates from the surveyed researchers and practitioners.
thus it isimportant tostudy andquantify thevarianceof dl systems especially the implementation level variance.
on the one hand some practitioners whose primary goal is to obtain the best model maybeabletotakeadvantageofthevariancebyrunning multiple identical runs to achieve their goal.
ontheotherhand se ai andsystemsresearcherswhopropose new dl architectures and models that outperform existing ones may need toexecute multiple identical runs to ensurethe validityof their experiments.
for example a recent research paper proposed a new approach with a reported .
accuracy improvement over the standard wrn .
our experiments show that this network s ac curacy can vary by up to .
.
therefore the reported accuracy improvement may not be statistically significant when considering theaforementionedni factorsinthetrainingalgorithmandtheim plementation.inotherwords ifonerunsthetwoapproachesagain the resulting mode of may not outperform the wrn model.atbest thecomparisonresultsstillhold butthecurrentex perimentsfailtoprovideevidencetodemonstratetheimprovement given the possible variance.
there are existing theoretical analyses of dl training that study how well optimizers find good local optima given algorithmic ni factors.
such work fails to study the nondeterminism in the underlying dl implementation.
tofillthisgap first wesystematicallystudyandquantifythe accuracy and time variance of dl systems across identical runs using6widely usednetworksand3datasets.second weconductasurveyto ascertainwhetherdl varianceandtheir implicationsare known to researchers and practitioners with dl experience.
third we conduct a literature review of the most recent editions of top se ai and systems conferences to understand the awareness andpractices of coping with dl variance in research papers.
in this paper we make the following contributions diamondsolidfinding a list of implementation level ni factors parallel process auto selectionofprimitiveoperations andscheduling and floating point precision and algorithmic ni factors nondeterministicdllayers weightinitializationapproach dataaugmentationapproach andbatchordering andtechniquesthat controltheseni factorstoremoveorreducevariance section2 .
diamondsolida dl variance study of hours over .
months of gpu time on widely used datasets mnist cifar10 cifar100 with popular models lenet1 letnet4 letnet5 resnet38 resnet56 and wideresnet on three core dl libraries tensorflow cntk and theano finding the accuracy of models from identical training runs varies by as much as .
even after removing weak models.
finding with algorithmic ni factors disabled dl model accuracy varies by as much as .
an accuracy difference caused solely by implementation level nondeterminism.
finding implementation level ni factors cause a per class accuracy difference up to .
while the per class difference is upto with defaultsettings i.e.
withalgorithmic and implementation level nondeterminism .
finding4 trainingtimevariesbyasmuchas145.
1hour and minutes among fixed seed identical training runs whilethetrainingtimedifferenceisupto4 .
withdefault settings.
diamondsolida researcher and practitioner survey with valid replies reveals that finding5 a large percentage of respondents are unaware of .
orunsureabout .
anyvariance ofdlsystems there is no correlation between dl experience and awareness of dl variance.
finding even more researchers and practitioners .
are unaware or uncertain of implementation level nondeterminism in dl systems.
finding only .
of respondents expect or more accuracy difference across fixed seed identical training runs.
finding8 most .
participantsestimatetheconvergence timedifferencestobelessthan10 acrossidenticaltraining runs and the majority of respondents .
estimates a similar or lessconvergence timedifferenceamong fixed seed identical training runs.
diamondsolidfinding9 aliteraturesurveyofarandomsampleof454papers fromthemostrecenteditionsoftopse icse fse and ase ai neurips nips iclr icml cvpr and iccv and systems asplos sosp and mlsys conferences showsthat225paperstrainandevaluatedl systems only19.
of whichusemultipleidenticaltraining runs to evaluate their approaches.
diamondsolidimplications and suggestions for researchers and practitioners and raising awareness of dl variance section .
code and data are available in a github repository1.
nondeterminism introducing ni factors many factors affect dl systems results and training time.
the first set of factors is the inputto a system.
such input includes the trainingdataandhyper parameters e.g.
numberoflayers dropout rate optimizer learning rate batch size and data augmentation method and settings .
it is expected that models with different inputs perform differently and there is a flurry of work on how to select the best input e.g.
hyper parameter tuning .
however several factors e.g.
shuffled batch ordering independentofthesystem sinputaffectthetrainingandaccuracyofthe final models.
we call these factors ni factors.
we divide ni factors into two categories algorithmic ni factors which are introducedtoimprovetheeffectivenessofthetrainingalgorithm and implementation level ni factors which are the byproduct of optimizations to improve dl implementations efficiency.
.
definitions in this study we define a dl system as the composition of a dl algorithm and adl implementation.
dl algorithm is the theory portion of dl and consists of model definition hyper parameters and theoretical training process.
dl implementation consists of dl libraries e.g.
keras core dl libraries e.g.
tensorflowandpytorch low levelcomputationlibraries e.g.
cudnnand cuda and hardware e.g.
gpu cpu and tpu .
the dl training process spans across the dl algorithm and dl implementation.
.
algorithmic ni factors themostcommonalgorithmicni factorsincludenondeterministic dllayers e.g.
dropoutlayer weightinitialization dataaugmentation and batch ordering.
nondeterministicdl layers dl architectures can contain nondeterministiclayers.forexample dropoutlayers arecommonly usedtopreventoverfitting.theyrandomlysetpartsoftheinput tensor to zero during training and guide each neuron to be trained withdifferentportionsofthetrainingdata.
dropouttensorsarechosenrandomlyon the flyduringtraining whichmeanstwoidentical runs could produce two different models with different accuracies and different training times.
weight initialization weightinitialization i sa n important step in dl training .
random weight initialization samples the initial dl model weights from a predefined distribution.
goodfellow et al.
state that random initialization breaksthesymmetry acrossalltheweighttensors.thisprocess helpssimilarlystructuredneuronslearndifferentfunctionsinstead of repeating each other.
thus they learn different aspects of the trainingdata andhelp toincreasethe model sgeneralization.
however differentinitialweightsmayresultinconvergencetodifferent local minima .
therefore random initialization can lead to variance in model accuracy across identical runs.
data augmentation dl training algorithms also utilize the randomnessin dataaugmentation toimprove theireffectiveness i.e.
producemoreaccuratemodels .dataaugmentation isaninexpensivemethodthatrandomlytransformstheinputtoincreasethe input s diversity.
it has been shownto improve the generalization ofthefinaltrainedmodel.randomlytransformingthetrainingdata will result in nondeterministic identical training runs.
batch ordering random batch ordering also improves the generalization of dl models.
it breaks up the order of the training datatopreventthemodelfromquicklyoverfittingtoaparticular label .
reordering training batches at each epoch results in nondeterministic identical training runs.
.
implementation level ni factors implementation levelni factorsarecausedbylibraries e.g.
tensorflow cuda andcudnn .themostcommonimplementation level ni factors are parallel computation nondeterministic primitive operations and rounding errors due to scheduling.
parallel processes core dl libraries e.g.
tensorflow and pytorch provide options to use multiple processes to improve the efficiencyofdlsystems.forexample thecorelibraries bydefault run the data preprocessing task in parallel to prepare the training datafaster.however duetotherandomcompletionorderofparalleltasks theorderoftrainingdatamaychangeandimpactthe optimizationpathofthetrainingprocess resultinginvarianceeven if data preprocessing itself is deterministic.
773figure overview of the experimental method auto selection of primitive operations core dl libraries implementdlalgorithmsbyleveragingthegpu optimizeddlprimitivesprovidedbylow levellibraries e.g.
cudnnandcuda .when usedwith nvidia gpus cudnnprovides hardware accelerated primitives for common dl operations such as forward and backward convolution pooling normalization and activation layers.
cudnn provides several modes of operation i.e.
different computational algorithms for primitive functions.
by default core dl libraries enable autotune which automatically benchmarks several modes of operation for each primitivecudnn function in its first call.
the fastest mode of operation is thenusedforthatcudnnfunctioninsubsequentcalls.theexact mode of operation for each primitive used in each run changes depending on the dynamic benchmark result.
different identical runs sometimes use different modes of operation introducing variance.
furthermore somemodesofoperationarenondeterministicdue to rounding errors introduced by scheduling see below .
scheduling and floating point precision gpu programming useswarpasaunitofcomputation.awarpconsistsof32parallel threads with concurrent memory access.
due to the limited precision bits ofdlmodels roundingerrorsareintroducedatevery step of floating point calculation.
in the gpu model concurrent accesses to a single memory address must be serialized to prevent race conditions with no guaranteed order of access.
therefore the roundingerrorintroducedineachwarpmayvaryacrossfixed seed identical training runs due to the different accessing orders.
for example matrix reduction operations such as atomicadd used in depthwise convolution layers are affected by the varying serialization order.
since floating point operations are not associativeduetoroundingerrors varyingordersofadditionsmay produce nondeterministic output a b c nequalb c a .
.
controlling ni factors for determinism removing algorithmic ni factors enables us to study the nondeterminismintroducedbyimplementation levelni factors.inaddition deterministic training may be desirable for debugging and other purposes.
thus we identify techniques that control algorithmic and implementation level ni factors to remove or reduce variance.
controllingalgorithmic ni factors allalgorithmicni factors arecontrolledbypseudo randomnumbergenerators.thus wecancontroltheseni factorsbyfixingtherandomseedsatthebeginningofeachruntoachievealgorithmicdeterminismacrossidenticalruns while still maintaining the pseudo random characteristic within a single run.
we defined this as fixed seed identical training runs.controllingimplementation levelni factors tocontrolthese ni factors weneedtotakeseveralsteps.first thedlsystemshould not use multiple processes that cannot guarantee data order.
forexample using more than one worker in the data generator to feed training data would shuffle the batch ordering even with fixed random seeds.
second the autotune mechanism should choose deterministic implementations of primitive operations only.
for example in tensorflow1.
.
iftheenvironmentflag tf cudnn deterministic is setto1 theautotunemechanismwillnotconsiderthenondeterministic modes for cudnn primitive functions.
third since some operations e.g.
atomicadd are nondeterministic when used on a gpu due to nondeterministic serialization theinputoftheseoperationsshouldbeserializedafterallparallel executions i.e.
to ensure a deterministic ordering of input .
then the operations should be executed on a single cpu thread.
finally one solution to achieve complete deterministic training is forcing the dl system to run completely in a serial manner i.e.
runningonasinglecputhread .however thisoptionpreventsdl systemstoutilizethehardwareefficientlyandmaybeunrealistic as many models would take months or years to train on a single cputhread.asfuturework deterministicmultithreading may be promising for more realistic deterministic dl systems.
amajorgoalofthispaperistoquantifythevarianceintroduced by implementation level ni factors.
experimental method first weextractthe defaultinput i.e.
trainingdata hyper parameters andoptimizers ofadlsystemfromexistingwork section4 .
figure shows an overview of our experimental method.
we generatedifferent environments thatcombine differentversions ofdl libraries e.g.
high level libraries core libraries and low level libraries .
for all environments the hardware is the same details in section4 .forexample onesuchenvironmentincludeskeras2.
.
tensorflow .
.
cudnn .
and cuda .
.
each network is coupled with its default input.
for example the cifar dataset including training validation and test data is used to train the wrn 10networkwithstochasticgradientdescent sgd optimizer in epochs.
table shows the corresponding default input foreachnetwork.eachnetwork includingitsdefaultinput combinedwithone nondeterminismsetting detailsbelow isdefinedasa setofsetting.forexample onesetofsettingsthatweuseistraining thewrn 10networkwithallalgorithmicni factorsdisabled i.e.
fixed seednondeterminismsetting .foreachenvironmentand 774setting combination we perform an experimental set and measure the accuracy and time variance across nidentical training runs.
to ensure a valid study we address one main challenge to measurerealisticvariance theexperimentsneedtoreflecttherealusage ofdlsystems.wepicktrainingfrom scratchasourscenariofor thetrainingphasebecauseitisacommonandfundamentaltraining scenario i.e.
wetrainanewdlmodel from the beginning starting from randomly initialized weights.
inaddition wefocusonstudyingthevarianceofmodels overall accuracy per classaccuracy andtrainingtime asthesearecommon metricsthatdlresearchersandpractitionersuse andtherehave beenmanytechniques proposedtoimprove on these metrics.
further to make sure the accuracy and time that we observe are valid we check that our results are equivalent to the ones reported in the original papers.
training inputs e.g.
training data prepossessing methods and optimizer are chosen to match asclosely as possible those reported or used in the authors code.
whileacompletereproductionisoftenimpossible wereproduce previousworkasfaithfullyaspossiblebyusingreportedsettings and ensuring at least one of our runs can reach almost identical accuracy to that of the original work.
finally weperformtwostatisticaltests levene stestforvarianceandmann whitneyu testformean toensurethatwe draw statistically significant conclusions.
.
experimentalsetsofidenticaltrainingruns thetrainingphaseisaniterativeprocessandaftereachiteration i.e.
epoch a checkpoint of the model is stored.
after the training finishes thebestcheckpointisselectedbasedonafinal modelselectioncriterion.
we focus on two common .
of the respondents in our survey use one of these criteria model selection criteria best loss selection criterion the final model is the checkpoint with the best i.e.
lowest validation loss.
best accuracyselectioncriterion thefinalmodelisthecheckpoint with the best i.e.
highest validation accuracy.
validation loss and accuracy are calculated on the validation set i.e.
unseen data different from the training data and used to tune the model .
we report the test accuracy of the selected best model whichiscalculatedonthetestdata i.e.
unseendata differentfrom the training and validation data .
inpractice thetrainingrunswouldendiftheselectionmetric i.e.
validationlossoraccuracy didnotimproveafterasetnumber ofepochs i.e.
patience .inthisstudy weinsteadrunthetrainingtoamaximumnumberofepochswhilestoringthemodelcheckpoints.oncethetrainingisdone weselectthemodelbasedontheselection criterion and then compute the training time as if the training had stoppedatthebestcheckpoint.thisisanestimationoftrainingtime without running a separate set of experiments for each criterion.
we define identical training runs as training runs executed with thesame environment i.e.
hardware and dl libraries the same network architecture and the same inputs i.e.
training data hyperparameters andoptimizers .eachidenticaltrainingrunisfollowedbyaninferencerunonthetestdatatocomputethemodelaccuracy.
anexperimentalset isagroupofidenticaltrainingruns.wemake sure to avoid measurement bias as much as we could by usingthesame machinealongwith dockerenvironments thatarebuilt fromthesamebaseimage.
theonlychangesacrossexperimental setsarethedllibrarycombinationsandthesetofsettings i.e.
the nondeterminism level the network and its default input .
in each experimental set we perform n 16runs.
.
nondeterminism level settings we perform two categories of experiments with different nondeterminism levels the default and fixed seed settings.
default identical training runs are experiments that do not enforcedeterminism i.e.
noneoftheni factorsarecontrolled .theseareidenticaltrainingrunswiththedefaultinput trainingdataand hyper parameters .
fixed seedidenticaltrainingruns areexperimentsforwhichalgorithmic ni factors are disabled i.e.
we use the same randomgenerator and the same seed.
for example with the tensorflowcorelibrary wesettheglobalpythonrandomseed pythonhash seed numpy random seed and the tensorflow random seed to be identical.
initializing all random number generators with identical seed disables all algorithmic ni factors i.e.
dropout layers initial weights data augmentation and batch ordering .
.
metrics and measurements tomeasurethevarianceacrossidenticaltrainingruns wemeasure amodel soverallandper classaccuracyonthetestset.the overall accuracymeasurestheportionofcorrectclassificationsthatamodel makes on test samples.
the per class accuracy splits the overall accuracy into separate classes based on the ground truth class labels i.e.
theaccuracyofthemodelforeachclass .forexample the mnist dataset has classes so an mnist model would have 10per classaccuracyvalues oneforeachdigit .forallidentical training runs we measure the total training time as well as thenumber of epochs until convergence i.e.
until the checkpoints specified by the selection criterion .
for each experimental set the maximumdifferenceshowsthemostextremegapofmodelaccuracy and training time between the best and the worst runs.
.
statistical tests levene stest is a statistical test to assess the equality of variance oftwosamples.specifically whentestingaccuracyvariance thenull hypothesis is that the accuracy variance of set a is equal to the accuracyvariance ofset b. ifwe findthat p value .
then wecanconfirmwith95 confidencetheaccuracyvarianceofset a is different from set b. thus if the accuracy variance of set a is smaller then runs in set a are more stable than in b. mann whitney u test is astatistical testto assessthe similarity of sample distributions.
we run the u test instead of the t test because the u test does not assume normality while the t testdoes.
for example when comparing two sets of runs a and b the null hypothesis is that the accuracies of set a are similar to set b. if we find that p value .
then we can confirm with confidence that our alternative hypothesis is true which means set a hasstatistically differentaccuracies than setb.
wecompute the effect size as the cohen s d to check if the difference has a meaningful effect d no effect and d huge effect .
775table datasets networks and training settings dataset samples network settings train val test name parameters epochs optimizer mnist 500lenet1 sgd lenet4 lenet5 cifar10 500resnet38 adamresnet56 cifar100 wrn sgd experimental settings datasets and models we perform our experiments using three popular datasets mnist cifar10 and cifar100 .
we choose image classification architectures as they are often used as test subjects in recent se papers that test verify andimprove dl models and libraries.
table shows each dataset with thecorrespondingnumbersofinstancesineachsubset training validation and test .
the training set is used to train the model.
following common practice we use the validation set to select the best model.
the test set is used to evaluate the final model.
wechoosetoexperimentonlenet resnet andwideresnet architectures as they are popular networks for image classification.inourliteraturereview ofthe225relevantpapers of papers use or compare to one of these architectures.
table alsoshowsthenumberoftrainableparametersforeachnetwork.
our networks are diverse in size from lenet1 to parameters wrn .
wereproducepreviousworkasfaithfullyaspossiblebyusing networks and settings recorded by previous work and ensuring some of our runs have a similar within accuracy as that in the originalwork.wealsouse whenavailable theoriginalimplementationoftheapproachfromtheauthorandthekerasimplementation if available to reduce the risk of introducing new bugs.
welistthetrainingconfigurationsusedintable1.toensurethat the model will converge i.e.
training loss stops improving within the maximum number of epochs we empirically choose a maximumnumberofepochslargerthanthenumberofepochsto convergence using both selection criteria.
wecannotusenetworksfrompriorwork sincethey onlyprovidepre trainedmodelsanddonotprovideenoughdetails for us to reproduce the training runs.
dl libraries we use keras version .
.
as our high level library since it provides us with the ability to transparently switch between three dl core libraries tensorflow cntk and theano .thisensuresthatthecomparisonacrosscorelibraries is fair and the least affected by our code.
we perform our experimentswiththeofficialtensorflowversions includingthelatest .
.
and1.
cntkversion .
andtheanoversion .
.
.
we pair each version of the core libraries with the officially supported low level cudnn and cuda versions.
for example tensorflow .
supports cudnn .
to .
coupled with cuda .
while tensorflow .
supports only cudnn .
to .
coupledwithcuda10.
.sinceitisnotpracticaltoperformexperimentstable maximum differences of overallandper class accuracy among defaultandfixed seed identical training runs setting networkoverall per class diff sdev sdevci diff sdev sdevci defaultlenet1 .
.
.
.
.
.
.
.
lenet4 .
.
.
.
.
.
.
.
lenet5 .
.
.
.
.
.
.
.
resnet38 .
.
.
.
.
.
.
.
resnet56 .
.
.
.
.
.
.
.
wrn .
.
.
.
.
.
.
.
fixed seedlenet1 .
.
.
.
.
.
.
lenet4 .
.
.
.
.
.
.
.
lenet5 .
.
.
.
.
.
.
.
resnet38 .
.
.
.
.
.
.
.
resnet56 .
.
.
.
.
.
.
.
wrn .
.
.
.
.
.
.
.
runs produce weak models that have lower than accuracy figure2 boxplotsoftheoverallaccuracyfordefaultidentical runs with the largest overall accuracy difference on all library combinations we use library combinations for tensorflow one combination each for cntk and theano.
infrastructure wecarryoutallexperimentsonamachinewith cores 384gb of ram and rtx 2080ti graphic cards each with 11gbmemory.toaccommodatemultiplecombinationsoflibraries we use anaconda .
.
with python .
and docker .
.
results and findings we perform identical training runs experimental sets with16runseach ofsixnetworksonthreedatasets withtwolevels of nondeterminism using three core libraries tensorflow cntk and theano which is hours over6.5months of gpu time.
.
rq1 how much accuracy variance do ni factors introduce?
to investigate the variance caused by ni factors we run default identical training runs for each of the experimental sets i.e.
combinations of networks and environments .
recall that defaultidentical trainingrunsaredefined astrainingruns withthe samedefaultinputs wherenoni factorsare disabled section3.
.
toestimatethe extremecase wecomputethemaximumdifference of accuracy overall and per class between the least accurate andthemostaccuratedefaultidenticaltrainingrunsofanexperimental set while the standard deviation estimates the average case.
table default shows results for rq1.
columns diffshow the maximumdifferencesofaccuracywhilecolumns sdevand sdevci shows the standard deviationof accuracy among identical training runs and corresponding confidence interval i.e.
with confidence theconfidenceintervalwouldcontainthepopulation standard deviation .
we only show the larger accuracy differences whenusingeitherselectioncriterion best lossorbest accuracy astheresultsaresimilarbetweenthecriteria.figure2showsthe 776boxplots of the overall accuracy of each network.
the triangles represent the mean accuracy and the orange line is the median.
dots outside of the whiskers are outliers.
acrossdefaultidenticaltrainingruns theaccuracydifferenceis as big as .
even after removing weak models.
finding .
specifically inthelenet5defaulttrainingexperimentalset with tensorflow .
.
cuda .
cudnn .
and loss selection criterion the most and least accurate runs have an overall accuracy of .
and .
respectively a .
difference .
the worst model saccuracyislowerthanrandomguesses i.e.
becausethemnist dataset has classes .
this large accuracy difference is caused by therandominitializationoftheweights .particularly four runs do not improve much after training with the final models accuraciesbeing8.
.
.
and19.
theoutliersshownascirclesinfigure2 .whilethefourrunsproduceweakmodels they arefaithfulreproductionsoftrainingwithwidely usednetworks and algorithms using realistic data and settings.
the fact that outof16runsfailtoimprovesignificantly showsthe importance ofreportingthevariance betweenmultipleidenticaltrainingruns so thatthe dl approaches can be evaluated on not just their best accuracy but also on how stable the training process is.
if we exclude networks with such weak models we still see an accuracy difference up to .
with lenet1 the difference between87.
and98.
.forwrn thelargestdifference is .
between .
and .
respectively.
although these differences may seem small researchers report improvements of0.
whencomparingagainstwrn 10withoutaccounting forni factors.atbest thecomparisonconclusionsstillhold but the papers fail to provide evidence for that.
the per class accuracy differences are even larger compared to theoverallaccuracydifferences table2 column default overall versus column default per class .
on the least accurate run of lenet5 thetrainedmodelfailscompletelyonasingleclass i.e.
the prediction accuracy for the class digit is while for otherruns the highest prediction accuracy for the same class is .
digit has261testimages allclasseshavesimilarnumbers so such single class failures are not due to insufficient instances or biasdistributionofthatclass.asimilarsingle classfailurehappens for lenet1 and lenet4 training runs.
the standard deviation is smallerforthesenetworks .
and24.
comparingto44.
because only one run completely fails.
as another example wrn default identical training runs usinglibrarycombinationtensorflow1.
.
cuda9.
cudnn .
and best accuracy selection criteria incur a maximum overall accuracydifferenceof2.
.withthesamesettings theper class accuracy difference is .
dropping from .
to .
for theclass bee with22testsamples .per classaccuracyvariance can be problematic for applications where the accuracy of specific classes is critical.
for example the accuracy variance of the pedestrian class of a self driving car s object classification system could vary pedestrian prediction reliability.
this in turn could endanger pedestrians even if the overall variance of the model is small.
ni factors cause a complete single class failure where thebiggest per class accuracy difference is with a standard deviation of .
finding a .figure boxplots of the overall accuracy for fixed seedidentical runs with the largest overall accuracy difference .
rq2 how much accuracy variance do implementation level ni factors cause?
accuracy variance we analyze nondeterminism introduced by implementation level ni factors by performing experimentalsets i.e.
combinations of networks with environments of fixed seedidenticaltrainingruns eachwith16runs .
recallthat fixed seedidenticaltrainingrunsaredefaultidenticaltrainingruns withalgorithmicni factorsdisabledusingfixedrandomseedinitialization section .
.
table fixed seed shows the largest accuracy differences of the overall and per class accuracy of all models for any library combinationsandselectioncriteria withdisabledalgorithmicnifactors i.e.
among fixed seed identical training runs .
implementation levelni factorscauseaccuracydifferencesas large as .
finding while per class accuracy differences are up to .
finding b .
among the fixed seed identical training runs of wrn withtensorflow1.
.
cuda10 cudnn7.
andlossselection criterion the most and the least accurate runs have an overall accuracyof .
and .
respectively.
inthe same experimental set the implementation level ni factors cause a per class accuracy difference of .
the camel class with test samples has .
and .
accuracies in the most and least accurate run .
all other classes have similar numbers of test samples so the large per class accuracy difference is not due to insufficient instances or bias distribution classes.
thelackofcompletefailurecausedbytherandomweightinitialization analgorithmicni factors inlenettraining figure3 indicatesthattrainingismorestablewithoutalgorithmicni factors.
when comparing the results of setting defaultandfixed seed in table lenet and resnet56 have smaller overall and per class accuracy differences among default identical training runs.
while for resnet38andwrn theaccuracydifferencesamongfixedseed identical training runs are smaller.
levene s test cannot statisticallyconfirmthesignificance p value .
ofthesedifferences in variance for all networks except for lenet5 where there are complete failures in identical training runs with default setting .
table fixed seed shows that except for resnet38 the more complexanetworkis i.e.
moretrainableparameters thelarger the accuracy overall and per class variance exists across fixedseed identical training runs.
for more complex networks the error introduced by nondeterminism might propagate further.
to demonstrate the importance of performing identical training runswhen comparingdifferent dlapproaches weconsider ascenariowhereresnet56isabaselineapproachtothecifar10image classification problem and resnet38 is the proposed improvement.
777figure4 boxplotsoftheoverallaccuracyoffixed seedidentical training runs with different core libraries figure5 boxplotsoftheoverallaccuracydifferenceoffixed seedidenticaltrainingrunswith11low levellibraryversioncombinations for each network among fixed seed identical training runs resnet56 averages .
intestaccuracywhileresnet38averages90.
.theu test confirms withp value .
thatresnet56 has0.
highertest accuracy than resnet38 with an effect size cohen s d of .
very large effect .
hence there is no improvement from the proposedtechnique resnet38 over the baseline resnet56 .
however if each approach only runs once in the most extreme case resnet56 accuracy is reported with its worse run .
and resnet38 with its best run .
the researchers might have come to an invalid conclusionthatresnet38has1 higheraccuracythanresnet56.re searchersandpractitionersshouldbeawareofdlsystemvariance evenwithonlyimplementation levelni factors sotheywouldperform multiple identical training runs when comparing approaches.
differentcorelibraries weinvestigateifswitchingcorelibraries leads to different accuracy variance among fixed seed identical trainingruns.sinceitisprohibitivelyexpensivetorunallcombinations of core and low level library versions our experiments gpu timeare alreadyover .5months wecompare thelatest versions of core and low level libraries at the time of the experiment i.e.
inaddition werun12moreexperimentsets combinationsof6 models with environments .
figure4showstheboxplotsoftheoverallaccuracyoffixed seed identical training runs for the experimental set of each network with the best loss selection criterion across three different core libraries.
the accuracy variance is similar across different core libraries.forexample forresnet56theaccuracydifferencewith cntkis1.
between91.
and90.
and1.
withtensorflow.
all core libraries are affected similarly by implementation level ni factors aslevene stestcannotrejectthenullhypothesisthat each core library has a different accuracy variance p value .
.
different low level libraries versions we analyze the overall accuracy differences of the low level library combinations cudnn and cuda with tensorflow to see if there is still variancewhenswitchingversionsofthelow levellibraries.figure5shows the boxplots of the overall accuracy differences of fixedseed identical training runs when training each network with each of the library combinations.
all training runs are affected bytable3 runningtimetoconvergencedifferencesamong defaultandfixed seed identical training runs setting networktime loss seconds time acc seconds diff reldiff relsdev diff reldiff relsdevdefaultlenet1 .
.
.
.
lenet4 .
.
.
.
lenet5 .
.
.
.
resnet38 .
.
.
.
resnet56 .
.
.
.
wrn .
.
.
.
fixed seedlenet1 .
.
.
.
lenet4 .
.
.
.
lenet5 .
.
.
.
resnet38 .
.
.
.
resnet56 .
.
.
.
wrn .
.
.
.
runs stuck at the first epoch implementation level ni factors independently from the low level libraries used.
for example with wrn the largest overall accuracydifferenceis2.
reportedintable2 .onaverage across experimental sets the accuracy difference for this network is over while the smallest accuracy difference is .
.
.
rq3 how much training time variance do ni factors introduce?
westudythevarianceinoveralltrainingtimetoconvergenceof default identical training runs and fixed seed identical training runs which is often the primary variance that researchers and practitioners care about.
we measure training time to convergence with respect to best loss and best accuracy selection criteria.
table3showstheanalysisoftherunningtimetoconvergencefor defaultidenticaltrainingrunsandfixed seedidenticaltrainingruns.
time lossandtime accdenotethetrainingtimeusingtwopopular model selectioncriteria best loss and best accuracy respectively.
for each selection criterion the table shows the time differencebetween the slowest and the fastest runs columns diff .
since the running time is very different across networks we computethe relative time difference columns reldiff the ratio of the timedifferenceovertherunningtimeofthefastest.togivesome indicationofanaveragecase columns relsdevshowtherelative standard deviation i.e.
coefficient of variation of the runs.
among default identical training runs lenet5 has the largest relativetrainingtimedifferenceof4 .
usingthebest accuracy selection criterion.
as discussed in rq1 three runs fail to improve after the first epoch .
seconds for the fastest creating such a largetimedifference.however sinceonlythreerunsgotstuckat the first epoch the relative standard deviation is .
.
thelargesttrainingtimedifferenceamongdefaultidenticaltrainingrunsis6 316seconds 1hourand40minutes forthewrn 10networkwiththebest accuracyselectioncriterion relativetraining time difference of .
.
given how expensive dl training can be .
of training time difference could mean days or longer.
amongfixed seedidenticaltrainingruns resnet56incursthe largest relative training time difference .
when using thebest accuracy selection criterion.
this means that the deviationcaused by random computation errors can lead to significantly different optimization paths hence different convergence time.
778finding4 trainingtimevariesbyasmuchas145.
1hour and12minutes amongfixed seedidenticaltrainingruns while the training time difference is up to .
with default identical training runs.
researcher and practitioner survey we conducta survey tounderstand ifresearchersand practitioners are aware of the ni factors and if they correctly estimate how much impact ni factors have on dl experiments.
.
survey design and deployment we conduct an anonymous online survey over a period of two weeksinfebruary2020.wetargetgithubuserswhocommitted code to popular public dl projects under the topics tensorflow pytorch cntk theano deeplearning and neural network .wesend emails using qualtrics services and receive responses .
response rate of which are valid.
many of the email addresses are from industry from microsoft from google and80fromnvidia andfromacademia 797fromu.s.universities .
wetakethefollowingstepstoensureoursurveyof29questions is valid and not biased.
first we conduct three rounds of in person pilotstudieswithtengraduatestudentswhohaveworkedondl projects and use their feedback to remove ambiguity and biases in our initial design.
the pilot studies participants do not participate in the actual survey.
second to ensure participant s understanding we define importantterms e.g.
deeplearning determinism identicaltrainingruns and fixed seed identical training runs in the context of our survey before the questions.
for example we give a clear definition of a deterministic dl system before survey questions we define a systemasdeterministicifthesystemhasidenticalaccuracyorsimilar running time between multiple identical runs.
in the case of a dl system identical trainingruns havethe sametraining dataset data preprocessing method e.g.
same transformationoperations weight initializer i.e.
drawnfromthesamerandomdistribution network structure loss function optimizer lower libraries and hardware.
all questions and definitions are included in the github repository whose link is provided in section .
.
survey results and findings participant experience and statistics of the responses work in industry and work in academia.
participants have an average work experience of .
years and a maximum of 47years.
the average dl experience is .
years.
over .
learn ai formally e.g.
undergraduate andgraduate school and32 are involved with or more ai projects.
awarenessofni factorsindlsystems weaskquestion20 in youropinion aredlsystemsdeterministic?
togaugetheawareness that participants have of the ni factors results in figure .
many respondentsare unaware .
or uncertain .
of anyvarianceofdlsystems andthereisnocorrelationbetween dl experience and awareness of dl variance finding .figure distribution of responses to question defaultidentical runs and question fixed seed identical runs figure7 estimationof overallandper class accuracydifference across default and fixed seed identical training runs to measure the correlation between different factors we use the pearson correlation coefficient r a statistical indicator oflinear correlation between two variables r means no correlation while r 1suggestsastrongcorrelation .thereisnocorrelation between awareness of dl variance and dl experience r .
dl educational background r .
or job position r .
.
these resultssuggestlimitedawarenessofvarianceindlsystemsregardless of experience and educational background.
awarenessofimplementation levelni factorsindlsystems wedesignquestions26 doyouexpectfixed seedidenticaldltrainingrunsto bedeterministic?
tostudyhow awarerespondentsare with implementation level ni factors results in figure .
most .
out of of our surveyed researchers and practitionersareunawareoforunsureaboutimplementationlevel ni factors finding .
thereisnocorrelationbetweenawarenessofimplementationlevelni factorsanddlexperience r .
dleducationalbackground r .
or job position r .
.
estimate of accuracy difference we ask participants who answered yes or maybe to question to answer question from your experience in the worst case by how much would you expectthefinaloverallaccuracy e.g.
inclassificationtask tovaryin terms of absolute value between identical training runs?
.
also after question26 weaskparticipantsasimilarquestion27regarding fixed seed identical training runs.
those who answer maybe i.e.
unsure about dl system variance we still ask them to estimate themagnitudeofthevariance.
other isanoptiontospecifyan explanation if no estimate is given.
figure7showsparticipants estimationsoftheoverallandperclass accuracy differences across default identical training runs default overall anddefault per class and fixed seed identical training runs fixed seed overall andfixed seed per class .no varianceindicatesparticipantsthatareunawareofthenondeterminism ofdlsystems.someparticipantschoose others andstatethatthe accuracy difference depends on the task and network architecture.
researchersandpractitionersunderestimatethemagnitudeof accuracy differences.
most .
responses estimate an accuracy difference across default identical training runs to be less than .
779finding2indicatesthattheaccuracydifferenceisupto2.
with implementation level ni factors alone.
however only .
of respondentsexpect2 ormoreaccuracydifferenceacrossfixedseed identical training runs and they estimate similarly for per class accuracy differences finding .
estimateoftrainingtimedifference weaskparticipantstoestimatehowmuchthe runningtimeto convergencevaries across default and fixed seed identical training runs to see if their esti mation matches the results from rq3 i.e.
the convergence time differencesareupto4 .
amongdefaultidenticaltrainingruns and up to .
among fixed seed identical training runs .
most .
participants estimate the convergence time differences to be less than across default identical training runs and the majority of .
respondents estimate a similar or less convergence time difference among fixed seed identical training runs finding .
dl training paper survey weconductaliteraturesurveytostudytheawarenessofandthe practice of handling dl variance in research papers.
paper selection criteria and study approach we extract researcharticlesfromthemostrecenttopse icse fse ase machinelearning neurips nips iclr andicml computer vision cvpr and iccv and systems sosp asplos mlsys conferences.
we focus on articles that were acceptedfororalpresentations i.e.
weexcludepostersandspotlight articles to keep the amount of manual examination realistic consideringthatover1 000papersareacceptedperyearforconferences such as neurips nips.
in total articles meet the above criterion.
we split conferences into se systems focused se and systems andai focused machinelearningandcomputervision conferences to investigate whether ai papers are more likely to consider this variance in their evaluation.
two authors independently check each of the randomly sampled papers to see if it is relevant i.e.
papers that train dl models .
ofagreement .with95 confidence 28outof202 papersfromse systemsconferences .
versus197outof papers from ai conferences .
are relevant.
paper survey results we present the survey result as follows.
of the relevant papers only .
use multiple identical trainingrunstoevaluatetheirapproaches finding9 .
for se systems conferences and .
for ai conferences.
these results corroborate our online survey findings indicatingthatresearchersrarelyconsider orhavenoclearsolutionsto measure the impact of ni factors.
in addition papers in our sample use the same models we evaluated and report an accuracy improvementlowerthanthevariancethatweobservedacrossmultiple fixed seed identical training runs .
.
most of these studies do not report validation using multiple identical training runs.thus theconclusionsofthese23studiesarelikelyaffected by the variance in multiple identical training runs.
this is a conservativeestimateasweusetheimplementation levelonlyvariance .
instead of the overall variance .
as the criterion.
implications suggestions and future work improving the stability of training implementations practitioners may need to control ni factors or replay dl training deterministically to facilitate debugging which are challenging tasks.
as discussed in section .
algorithmic ni factors are generally straightforwardtocontrolastheyareintroducedexplicitlyusing pseudo random number generators which can be seeded beforeeach run.
practitioners may benefit from new methods e.g.
deterministicgpu tocontrolimplementation levelni factors whicharemuchhardertocontrolbecausetheyareoftenthebyproduct of optimization.
research reproducibilityand validity variance introduced by ni factorsreducesthereproducibilityofdl relatedexperiments.
researchers should check if multiple identical training runs are needed to ensure the validity of their experiments and comparison.
itisnontrivialtodeterminethenumberofidenticalrunsneeded whichdependsontheapproachesandthebaselines.onesolutionis iteratively performing more replication runs when comparing to a selected baseline.
the replication process can stop when statistical tests e.g.
u test confirmthesignificance e.g.
p value .
of the difference between the new approach and the baseline.
if after a large number of replication runs e.g.
more than runs theimprovementisnotstatisticallysignificant thenthevariance mightbelargeenoughsuchthatastatisticallysignificantconclusion about the difference between the two techniques might not be possible.wearedevelopingsuchatechniquetohelpresearchers and practitionerswith thisprocess toreduce themanual effortto conduct valid experiments and replicate experiments.
approachestoimprovereproducibilitysuggestedbythesecommunity needtoalsoconsidertrainingvariance.new approaches such as efficient checkpointing may be desirable.
transparencyisimportantinmakingsurethatresearchisreproducible and valid.
recently the dl research community promoted sharing artifacts and results transparently .
since dl systemsarenondeterministic itisimportanttosharethedatafromthe replication runs as well.
one solution is maintaining a centralized trusted database that stores these replication runs and provides authorsofnewapproacheswithbaselineresultsthattheycandirectly compare to without rerunning the baseline approaches.
we are developing a tool that helps users to measure the variance of their approachesandfacilitatesthecomparisonacrossapproaches.userscanuploadtheirreplicationpackagesandresultstoadatabase that is provided by our tool to be curated for comparison.
producing better models when a dl model is the contribution e.g.
defect prediction or program repair practitioners could leverage variance to obtain a more accurate model.less expensive training and variance estimation since dl training is expensive an important research direction could be less expensivevarianceestimationandtrainingapproachessuch as software support for incremental training .
threats to validity external validity observed results might be different for other networks.weuse6verypopularnetworkswithdiversecomplexity from to parameters to mitigate this issue.
we encourageothers andourselves toreplicateandenrichourstudies with different dl networks dl training approaches and dl librariestobuildanempiricalbodyofknowledgeaboutvariancein dl systems.
we are building a replication tool to help the research communitytoshareandreplicateresearchexperimentsandresults.
new algorithmic ni factors can be added e.g.
new nondeterministiclayers soourlistofalgorithmic ni factorscouldbecome incomplete in the future.
for fixed seed identical training runs we ensure that all algorithmic ni factors of the dl networks we evaluate are disabled.
internal validity our implementation or the libraries we used mighthavebugs.thisshouldbealleviatedbythat allourcodeis reviewed by most authors our results show that variance exists for allversions of alllibraries we evaluate thus unlikely thatthey arecausedbylibrarybugs wefocusonofficialreleasesofdl libraries soourrunsshouldstillberepresentativeofrealdlusage and we analyze all results especially outliers to ensure there were no implementation bugs.
multiple identical training runs might produce different models i.e.
models with different weights with identical accuracy and running time.
our study focuses on accuracy and time variance since these are the end results that users care about.
construct validity weensuretotargetrelevantparticipantsin oursurveybyspecificallyinvitingcodecontributorstodlprojects and asking them to confirm that they work with dl.
respondents might not have wanted to show any perceived ignorance which could have biased their responses.
however the strength of the responses .
beingunawareoruncertainaboutimplementationlevel nondeterminism in dl systems helps alleviate this issue.
related work our paper is unique because we study and quantify dl variance caused by ni factors and conduct surveys to check its awareness.
variancestudyofreinforcementlearning rl closesttoour workisthestudy thatmeasurestheimpactofsomeimplementation level ni factors on rl experiments.
we study the general dl variance while they focus on rl variance only.
in addition we measure the awareness by conducting a survey and a literaturereview.
furthermore while they focus on one network for one task i.e.
playing the atari game breakout and one version of one corelibrary pytorch westudytheimpactofni factorsusing6 networks trained on datasets and multiple versions of three core libraries.
papers that investigates the impact of random seedsonrlaredifferentfromours sincetheyonlyconsiderthe impact of random seeds i.e.
algorithmic ni factors while we also study the variance caused by implementation level ni factors.
awareness of the impact of nondeterminism arecentliterature survey on papers on the topic of text mining confirms the results of our literature survey.
none of the investigated papersreportusingdifferentrandomseeds.ourliteraturesurvey investigates dl training in general not just text mining papers and examines papers.
furthermore our overall contribution is differentsincewealsoquantifythedifferencesintrainingaccuracyandtimeacrossidenticaltrainingruns.anotherpaper states thatsmallchangesintheexperimentalsetupcangeneratemeasure mentbias.itfocusesonstandardcpucomputationbenchmark and does not study the nonderterminism of dl systems.
anecdotalevidenceofni factors somestudies quantifythevarianceintheirresultscausedbyni factors.however these are only anecdotal evidence and none attempts to system atically study the variance introduced by algorithmic and imple mentation level ni factors.
in addition our surveys show that awareness is still very low in the research community.
nondeterminisminstochasticgradientdescent sgd much workinvestigatesvariancecausedbysgd .while these papers quantify nondeterminism caused by sgd they ignore all other sources of nondeterminism described in section .impact of weight initialization prior work measure the impact of different initial weights on models training time.whilesuchanissueisknown implementation levelni factors have not been studied and our surveys show that they are often not considered when evaluating dl systems.controllingimplementation levelnondeterminism jooybar etal.
proposeahardwaremechanismtointroducedeterminism in gpu based algorithms.
in our work we do not focus on the hardware itself and measure the variance caused by ni factors using popular gpus without special hardware modifications.
dl system benchmarking muchworkfocusesonbenchmarking dl systems.
however their target is finding the best networks hardware hyper parameters and framework .suchapproachesdonotconsider the impact of ni factors on multiple identical training runs.
conclusions thisworkstudiesthevarianceintroducedbynondeterminismin dl systems and the awareness of this variance among researchers and practitioners.
we perform experiments on three datasets with six popular networks and find up to .
accuracy differences among identical training runs when excluding weak models.
even with fixed seeds the accuracy differences are as large as .
.
our surveys show that .
of surveyed researchers and practitioners are unaware of or unsure about implementation level variance and only .
of papers in recent relevant top conferences use multiple identical training runs to quantify the variance of their dlapproaches.thus weraisetheawarenessofdlvariance for better research validity and reproducibility more accurate models deterministicdebugging newresearchontrainingstability efficient training and fast variance estimation.