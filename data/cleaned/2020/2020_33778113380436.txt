taming behavioral backward incompatibilities via cross project testing and analysis lingchao chen the university of texas at dallas lxc170330 utdallas.edufoyzul hassan the university of texas at san antonio foyzul.hassan my.utsa.edu xiaoyin wang the university of texas at san antonio xiaoyin.wang utsa.edulingming zhang the university of texas at dallas lingming.zhang utdallas.edu abstract in modern software development software libraries play a crucial role in reducing software development effort and improving software quality.
however at the same time the asynchronous upgrades of software libraries and client software projects often result in incompatibilities between different versions of libraries and client projects.
when libraries evolve it is often very challenging for library developers to maintain the so called backward compatibility and keep all their external behavior untouched and behavioral backward incompatibilities bbis may occur.
in practice the regression test suites of library projects often fail to detect all bbis.
therefore in this paper we propose debbi to detect bbis viacross project testing and analysis i.e.
using the test suites of various client projects to detect library bbis.
since executing all the possible client projects can be extremely time consuming debbi transforms the problem of cross project bbi detection into a traditional information retrieval ir problem to execute the client projects with higher probability to detect bbis earlier.
furthermore debbi considers project diversity and test relevance information for even faster bbi detection.
the experimental results show that debbi can reduce the end to end testing time for detecting the first and average unique bbis by .
and .
for jdk compared to naive cross project bbi detection.
also debbi has been applied to other popular 3rd party libraries.
to date debbi has detected bbi bugs with already confirmed as previously unknown bugs.
acm reference format lingchao chen foyzul hassan xiaoyin wang and lingming zhang.
.
taming behavioral backward incompatibilities via cross project testing and analysis.
in 42nd international conference on software engineering icse may seoul republic of korea.
acm new york ny usa pages.
introduction as software products become larger and more complicated library code plays an important role in almost any software.
for example permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
copyrights for components of this work owned by others than acm must be honored.
abstracting with credit is permitted.
to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
request permissions from permissions acm.org.
icse may seoul republic of korea association for computing machinery.
acm isbn .
.
.
.
the sample android app hello world contains only several lines of source code when it is executed on an android mobile phone it actually invokes libraries from the android software development kit sdk java development kit jdk as well as the underlying linux system.
third party libraries such as apache and square libraries are also widely used in both open source and commercial software projects.
the prevalent usage of software libraries has significantly reduced the software development cost and improved software quality.
at the same time the asynchronous upgrades of software libraries and client software often result in incompatibilities between different library versions and client software.
as techniques of computation evolve faster and faster libraries are also upgraded more frequently so do the occurrences of software incompatibilities.
for example google releases a new major version of android averagely every months.
after each major release an outbreak of incompatibility related bug reports will occur in github so do the version upgrade related negative reviews in the google play market .
to avoid incompatibilities for decades backward compatibility has been well known as a major requirement in the upgrades of software libraries.
however in reality backward compatibility is seldom fully achieved even in widely used libraries.
some early research efforts e.g.
chow and notkin balaban et al.
and dig and johnson have confirmed the prevalence of backward incompatibility between two consecutive releases of software libraries.
more recently cossette and walker identified signature level backward incompatibilities in consecutive version pairs from popular java libraries struts log4j and jdom .
mcdonnell et al.
identified changes on method signatures in consecutive android api level pairs from api level to api level .
these studies all show that backward incompatibilities are prevalent.
furthermore a recent study found averagely over test errors failures from each version pair when performing cross version testing on consecutive version pairs of popular java libraries.
this fact shows that on top of signature level backward incompatibilities behavioral backward incompatibilities that may cause runtime errors instead of compilation errors are also prevalent.
library incompatibilities may result in runtime failures both during the software development phase and after the software distribution.
if the upgraded library is statically packaged in the client software product the client developers may face some test ieee acm 42nd international conference on software engineering icse icse may seoul republic of korea lingchao chen foyzul hassan xiaoyin wang and lingming zhang failures when they try to incorporate the new release of the library.
thus they must perform extra changes and bug fixes if they want to take advantage of the new release of the library.
in such a case client developers may not be affected because they can still build the software product with the earlier library version.
the case becomes worse when the upgraded library belongs to the runtime environment e.g.
operating system libraries java runtime libraries platform libraries for plug ins such as chrome firefox eclipse libraries .
in such cases a software user may simply perform a system platform update the user may even not notice it if she turns on automatic updates during the night and suddenly find one or more software applications no longer working next morning.
for example windows vista is considered to be not very successful and its failure has been largely ascribed to its backward incompatibility with windows xp .
more recently an upgrade of android platform from .
to .
broke sougouinput the most popular chinese input software with more than million users .
users could not input any chinese character after they upgraded to android .
until a patch was released days later.
this paper proposes to apply cross project testing and analysis to overcome the challenges in bbi detection with the following two insights.
first the large number of open source client software projects residing in open software repositories can serve as a natural knowledge base of common usage scenario and expected semantics of software library apis.
second it is difficult for natural language documents e.g.
release notes to achieve comprehensiveness and preciseness in describing semantic changes of library apis.
in contrast code including library and client code source and test code can be better media to transfer knowledge from the library side to the client side.
in particular to avoid bbi related software runtime failures to accelerate software upgrading process and to reduce developer s effort in software migration we propose debbi to detect bbis on library side.
simple cross version regression testing with built in library test code may miss a lot of bbis.
for better detection of bbis debbi leverages the large number of existing client software projects in open software repositories and performs large scale testing on these projects with their built in test code on the newer library version.
such largely expanded test suites may incur high costs.
therefore we propose to transform the problem of crossproject bbi detection into a traditional information retrieval ir problem.
more specifically we treat the library side api upgrades as the query and the project side usage of the library apis as the document collection.
then the projects with more intensively upgraded api uses will be prioritized for early execution to detect potential bbis faster.
also different projects may share similar api uses and thus detect similar bbis.
thus we further consider the diversity between client projects using the diversified maximal marginal relevance mmr technique .
finally for each client project we also optimize test executions by skipping the tests that may not touch the upgraded apis.
the paper makes the following contributions idea.
we propose to solve the bbi detection problem via cross project testing and analysis and further transform the problem into a traditional ir problem.
figure debbi structure implementation.
we implement the proposed approach for testing library bbis based on the asm bytecode analysis framework and the indri ir framework .
optimization.
we further propose to use mmr to consider the diversity of different client projects and also extend traditional static regression test selection to the cross project scenario to automatically skip the tests useless for bbi detection.
study.
we present an extensive study on testing jdk and other popular 3rd party library such as apache libraries upgrades using tens of thousands of github client java projects.
the experimental results show that debbi can reduce the end to end testing time for detecting the first and average bbi clusters by .
and .
for jdk and detect real bbi bugs has been confirmed as previously unknown bugs .
approach in this section we first present the overview of our debbi approach section .
.
then we illustrate how to apply ir techniques for efficient and effective bbi detection section .
.
finally we present how to extend traditional regression test selection rts to the cross project setting to further speed up debbi section .
.
.
overview our debbi is a general approach for taming bbis via cross project testing and can be applied to any library including android software development kit sdk java development kit jdk and third party libraries such as apache software .
figure shows the overall architecture of our debbi.
debbi takes two versions of the library under test and a set of client projects that directly use the library as input to find bbis.
debbi first extracts the changes e.g.
file changes among the two library versions via static analysis.
they are considered as queries in our ir model.
meanwhile debbi preprocesses the source code for all the client projects to obtain the library apis used by each project and uses that to serve as the document for each project during ir.
then debbi queries the library changes against the source code for all the client projects 113taming behavioral backward incompatibilities via cross project testing and analysis icse may seoul republic of korea so that the client projects accessing more changed apis are tested earlier to detect bbis faster.
following prior work we performed stop word removal stemming for the ir document preparation.
note that we use all java key words as our stop word since they are common for all java projects.
for each client project we consider the class file level dependencies on the library under test as the document contents.
for each class file we split its fully qualified name into different words in the document or query.
for example we split java.lang.string into java lang andstring .
these three words are all fed into our document or query.
to ensure debbi effectiveness and efficiency we further explore various ir models in this work including traditional and topic model based ir models details shown in section .
.
furthermore the client projects ranked high in the prioritization results may reveal similar or even the same bbis.
therefore we further consider the diversity of the ir results to detect different unique bbis faster.
to this end we further use the maximal marginal relevance mmr algorithm to rank client projects with diverse library api uses.
ir models can help greatly reduce the number of client projects for finding bbis.
however for each client project all its tests are still executed.
therefore in section .
we further use static analysis to compute the library apis reachable from each test and then compute the subset of tests which can potentially access changed library apis as affected tests.
in this way for each client project we only execute the affected tests to further speed up bbi detection.
.
debbi via information retrieval various ir models have been applied to solve software engineering problems such as the vector space model vsm latent semantic indexing lsi and latent dirichlet allocation lda .
in theory any ir model can be applied to debbi.
in this work we mainly consider two widely used ir models vsm and lda due to their effectiveness .
for each model we studied state ofthe art variants for effective bbi detection.
furthermore for each studied variant we further apply the maximal marginal relevance mmr algorithm to rank client projects with diverse library api uses.
.
.
vector space model.
vector space model vsm is an algebraic model for representing text documents and queries as vectors of indexed terms.
tf.idf short for term frequencyinverse document frequency is a numerical statistic widely used to reflect word importance for a document under vsm.
to date tf.idf and its variants e.g.
state of the art okapi bm25 have been widely recognized as robust and effective ir models .
therefore it has been widely studied and used in both ir and software engineering areas .
formally assume that each document and query are represented by a term frequency vector dand qrespectively and nis the total number of terms or the size of vocabulary d x1 x2 .
.
.
xn q y1 y2 .
.
.
yn element xiandyiare the frequency of term tiin document dand query qrespectively.
generally query and document terms are weighted not just by their raw frequencies.
there is a heuristictf.idf weighting formula to weight query and document term frequency tf .
also the inverse document frequency idf is used to increase the weight of terms with low frequencies in the document and diminish the weight of terms which have high frequencies.
weighted vectors for dand qare computed as dw tfd x1 idf t1 tfd x2 idf t2 .
.
.
tfd xn idf tn qw tfd y1 idf t1 tfd y2 idf t2 .
.
.
tfd yn idf tn given a set dof source files for the client projects considered by debbi the simplest and classic tf formulation just uses the raw count of each term in the document i.e.
the number of times that term toccurs in a document which is given by ft d. similarly one simplest way to calculate idf is given by id f t logn nt where nt is the number of documents with term tandnis the total number of documents in document collection d. thus one of the simplest ways to get tf.idf score is to just multiply ft dandlogn ntto get term t s score in document d and then compute the vector similarity with query qto get document d s priority.
as we mentioned before various tf.idf variants have been proposed in practice.
in this work we use the indri framework which includes various advanced algorithms to achieve more accurate models.
the indri s tf.idf variant is based on okapi bm25 which is a probabilistic retrieval framework model initially developed by robertson et al.
.
as to avoid division by zero when a particular term appears in all documents the idf value here is id f t logn nt .
.
meanwhile the tf value is t fd x k1x x k1 b blend lend there are two tuning parameters k1andb.k1is used to calibrate document term frequency scaling.
when k1is just a small value the term frequency value will quickly saturate on the contrary a large k1value corresponds to using raw term frequency.
b b is used to determine the scaling by document length.
when value bis it corresponds to fully scaling the term weight by the document length while b 0corresponds to no length scaling.
finally lendandlendrepresent the current document length and average document length for the entire document collection respectively.
meanwhile for the query s tf function the length normalization is unnecessary because retrieval is applied with respect to a single fixed query.
therefore we just set bas0here t fq y k3y x k3 thus the similarity score of document dagainst query qis s d q n i 1t fd xi t fq yi id f ti there are various configurations that we can choose in the indri framework.
one of them is the basic tf.idf variant using bm25tf term weighting.
it sets k3as in the equation .
the only two parameters left for tuning are k1 for term weight and b for term weight .
we directly use their default values i.e.
.2and0.
respectively.
another variant is okapi which performs retrieval via okapi scoring.
there are three parameters k1 for term weight b 114icse may seoul republic of korea lingchao chen foyzul hassan xiaoyin wang and lingming zhang for term weight and k3 for query term weight in the variant.
the default value of them are .
.75and7respectively.
we also use these default values in our experiment.
in this work we use both models and denote them as tf.idf and okapi respectively.
.
.
latent dirichlet allocation.
different from vsm that directly represents documents with indexed terms lda further implements topic modeling in the retrieval process and computes generative statistical models to split a set of documents into corresponding topics with certain probabilities.
in this way each document is represented by the set of relevant abstract topics rather than the raw indexed terms.
in the software engineering literature researchers have applied lda to deal with bug localization software categorization or software repository analysis .
in those prior work project source code is usually treated as lda input documents.
in contrast in this work debbi treats each client project s class level dependency on the library under test as lda input documents.
based on the input documents lda computes different topics for each of the client projects.
the different topics indicate that there are different clusters of projects.
when projects use very similar library apis they are assigned into similar topics.
figure shows the graphical model of lda.
the outer box d represents the documents.
the inner box trepresents the repeated choice of topics and words in a document.
the generative process of model can be described as follows choose t poisson choose a topic vector dir for document d for each of the t terms wi a choose a topic zj multinomial d b choose a term wifrom p wi zj for here is a smoothing parameter for document topic distributions and is a smoothing parameter for topic term distributions.
the multinomial probability function pis p z w p t n 1p zn p wn zn figure graphical model for ldain this way given a set of client projects we first generate a term bydocument matrix m. then we use wijto represent the weight of ith term in the jthdocument.
note that following prior work we take tf.idf as our weighting function which can give more importance to words with high frequency in the current document and appearing in a small number of documents.
lda further takes the mas input and produces a topic bydocument matrix r. for here the probability that the jthdocument belongs to the ithtopic is denoted by rijin this matrix.
because the number of topics is much smaller than the number of indexed terms in the corpus.
lda is mapping a high dimensional space of documents into a low dimensional space represented using topics .
the latent topics can be clustered by shared topics.in the implementation we apply the fast collapsed gibbs sampling generative model for lda.
the reason is that it is much faster and has the same accuracy compared against the standard lda implementation .
there are the following parameters in the model which may affect its performance t which is the number of topics in the result.
follow the prior work we set topic number as in our experiment.
n which denotes the number of gibbs iterations to train our model.
and we set it as in the experiment following prior work .
which influences the topic distributions per document.
the topics will have a better smoothing effect when the value is higher.
we use the default value of .
.
which influences the term s distribution per topic.
the distribution of terms per topic will be more uniform with a higher value.
we use the default value of .
.
.
.
maximal marginal relevance.
both the vsm and lda techniques above will aggressively rank the most relevant client projects high in the list.
however the highly ranked projects may access similar library apis and reveal the same bbis repetitively.
therefore in this work we further consider the diversity among the search results to detect different unique bbis faster.
more specifically we combine both vsm and lda models with maximal marginal relevance mmr to solve this diversity issue to explore their performance.
mmr has been widely studied in the ir community for diversified searching .
traditional ir models rank the retrieved documents in the descending order of relevance to the user s query.
in contrast mmr tries to measure relevance and novelty independently and consider them together via a linear combination to solve the diversity problem.
for example it maximizes marginal relevance in retrieval and summarization when a document is both relevant to the query and contains minimal similarity to the previously ranked documents.
the mmr score equation can be formally defined as ar max di d s sim di q max dj ssim di dj where dis the document collection i.e.
the set of considered client projects for testing a library using debbi and qis the query i.e.
the changes among different library versions .
sis the subset of documents which are already selected by ir.
d sis the set of not yet selected documents in d.sim 1andsim 2are the methods to measure similarity between documents and query.
they can be the same or different.
for here we uniformly use bm25 as our similarity calculation method.
in the above definition when parameter mmr gives us a standard relevance ranked list.
on the contrary when mmr gives us a maximal diversity result.
in addition the sample information space is around the query when is a small number whereas the larger value of will produce a result focusing on multiple potentially overlapping or reinforcing relevant documents.
in our experiment we set as0.5which gives documents and queries the same weight.
.
faster debbi via testing selection since the basic debbi only ranks client projects all the tests within each tested projects still have to be executed.
therefore we further 115taming behavioral backward incompatibilities via cross project testing and analysis icse may seoul republic of korea extend debbi to reduce the number of test executions within each project.
more specifically we extend the traditional regression test selection rts approach to further enable even faster bbi detection.
to date various static and dynamic rts techniques have been proposed in the literature .
in this work we build debbi on top of state of the art static rts technique starts .
we chose starts since it has been demonstrated to be state of the art static file level rts technique and can be competitive to state of the art dynamic rts technique ekstazi .
also starts does not require prior dynamic execution information for each client project which may not be available during bbi detection.
starts is based on the traditional class firewall analysis firstly proposed by leung et al.
.
to further consider the specific features of the java programming language starts performs class firewall analysis on the intertype relation graph irg defined by orso et al.
.
the following presents the formal definition definition .
intertype relation graph .
the intertype relation graph of a given java program can be formulated as a triple ni nu .
in the triple ndenotes the set of nodes representing all programs classes or interfaces.
i n ndenotes the set of inheritance edges.
there exists an inheritance edge n1 n2 iif typen1inherits from class n2 or implements interface n2.
u n n denotes the set of use edges.
there exists an edge n1 n2 uif type n1accesses any element of n2 e.g.
field