on multi modal learning of editing source code saikat chakraborty department of computer science columbia university new y ork ny usa saikatc cs.columbia.edubaishakhi ray department of computer science columbia university new y ork ny usa rayb cs.columbia.edu abstract in recent years neural machine translator nmt has shown promise in automatically editing source code.
typical nmt based code editor only considers the code that needs tobe changed as input and suggests developers with a ranked listof patched code to choose from where the correct one maynot always be at the top of the list.
while nmt based codeediting systems generate a broad spectrum of plausible patches the correct one depends on the developers requirement and oftenon the context where the patch is applied.
thus if developersprovide some hints using natural language or providing patchcontext nmt models can benefit from them.
as a proof of concept in this research we leverage three modalities of information edit location edit code context commitmessages as a proxy of developers hint in natural language to automatically generate edits with nmt models.
to thatend we build m odit a multi modal nmt based code editing engine.
with in depth investigation and analysis we show thatdevelopers hint as an input modality can narrow the search spacefor patches and outperform state of the art models to generatecorrectly patched code in top position.
index t erms source code edit neural networks automated programming neural machine translator pretraining trans formers i. i ntroduction programmers often develop software incrementally adding gradual changes to the source code.
in a continuous software development environment programmers modify their sourcecode for various reasons including adding additional func tionality fixing bugs refactoring etc.
it turns out that many ofthese changes follow repetitive edit patterns resultingin a surge of research effort to automatically generate code changes learned from past examples .
in particular neural machine translation nmt models have been successful in learning automatic code changes .
at the core these models contain an encoder and adecoder the encoder encodes the code that needs to beedited and the decoder sequentially generates the edited code.such nmt models are trained with a large corpus of previousedits to learn generic code change patterns.
in the inferencetime given a code fragment that needs to be edited a trainednmt model should automatically generate the correspondingedited code.
however learning such generic code changes is challenging.
a programmer may change an identical pieceof code in different ways in two different contexts bothcan potentially be correct patches see figure .
for guidance use linkedlist and fix sublist problem ... public void addpicture string picture if pictures null pictures new arraylist pictures new linkedlist correct patch pictures new hashset plausible patch pictures.add picture fig.
example of an identical code marked in red changed in two different ways green and blue in two different contexts where both can be correct patches.
however based on developers guidance top line to fix a list related problem green is the correct patch in this context.
example an identical code fragment pictures new arraylist was changed in two different ways pictures new hashset andpictures new linkedlist in two different code contexts.
without knowing the developers intention and the edit context the automated code editing tools have no way to predictthe most intended patches.
for instance in the above example linkedlist was used to fix a sublist related problem.
once such an intention is known it is easy to choose a linkedlist related patch from the alternate options.
thus such an addi tional modality of information can reinforce the performanceof automated code editing tools.
guidance fix problem which occurred when the resulting json is empty ... private string generateresultingjsonstring char wrappingquote map string object jsonmap jsonobject jsonobject new jsonobject jsonmap string newjson jsonobject.tojsonstring lt compress if newjson.charat !
wrappingquote !
jsonobject.is empty newjson.charat !
wrappingquote return replaceunescaped newjson newjson .charat qrappingquote return newjson guidance context fig.
a motivating example.
the guidance provides a brief summary of what needs to be changes.
the underlined tokens are directly copied from guidance and context into the patched code.
in fact given just a piece of code without any additional information it is perhaps unlikely that even a human developer can comprehend how to change it.
consider another real life 36th ieee acm international conference on automated software engineering ase 36th ieee acm international conference on automated software engineering ase .
ieee .
ase51524.
.
.
ieee example shown in figure .
if a programmer only considers the edited expression in line it is difficult to decide how to modify it.
however with additional information modalities i.e.
the guidance line and the context the whole method before the patch the correct patch often becomesevident to the programmer since the guidance effectivelysummarises how to change the code and the context providesnecessary ingredients for generating a concretely patched code.we hypothesize that such multi modal information could bebeneficial to an automated code editing tool.
to that end wedesign m odit a multi modal code editing engine that is based on three information modalities i the code fragment thatneeds to be edited ii developers intention written in naturallanguage and iii explicitly given edit context.
in particular m odit is based on a transformer based nmt model.
as input m odit takes the code that needs to be edited e.g.
the lines that need to be patched additional guidance describing developers intent and the context of theedits that are explicitly identified by the developer e.g.
the surrounding method body or surrounding lines of code etc.
.note that previous works also provided context andthe edit location while generating edits however they are fedtogether to the model as a unified code element.
thus themodel had the burden of identifying the edit location and thengenerating the patch.
in contrast isolating the context fromthe edit location and feeding them to the model as differentmodalities provides m odit with additional information about the edits.
curating developers intent for a large number of edits that can train the model is non trivial.
as a proof of concept we leverage the commit messages associated with the editsto simulate developers intent automatically.
we acknowledgethat commit messages could be noisy and may not alwaysreflect the change summary .
nonetheless our extensiveempirical result shows that even with such noisy guidance m odit performs better in generating correctly edited code.
being a model that encodes and generates source code modit needs to both clearly understand and correctly generate programming languages pl .
while several previous ap proaches designed sophisticated tree grammar basedmodels to embed the knowledge of pl into the model themost recent transformer based approaches showedconsiderable promise with pre training with a large volume ofsource code.
since these models are pre trained with billionsof source code written by actual developers and transformersare known to learn distant dependencies between the nodes these models can learn about code structures during the pre training step.
among such pre trained models plbart learns jointly to understand and generate source code andshowed much promise in generative tasks.
thus we choseplbart as the starting point to train m odit i.e.
we initialize modit s model with learned parameters from plbart.
we evaluate m odit on two different datasets b2fs andb2fm proposed by tufano et al.
consisting of an extensive collection of bug fix commits from github.
ourempirical investigation shows that a summary of the changewritten in natural language as additional guidance from thedeveloper improves m odit s performance by narrowing down the search space for change patterns.
the code edit context presented as a separate information modality helps m odit to generate edited code correctly by providing necessary codeingredients e.g.
variable names method names etc.
.
m odit generates .
times more correct patches than c odit showing that m odit is robust enough to learn pl syntax implicitly.
furthermore m odit generates two times as many correct patches as a large transformer model could generate.
additionally our empirical investigation reveals that when we use one encoder to encode all information modalities ratherthan learning from individual modalities separately the modellearns representation based on inter modality reasoning.
incontrast a dedicated encoder for each individual modalityonly learns intra modality reasoning.
our experiment showsthat a multi modal single encoder model outperforms multi modal multi encoder model by up to .
.
we summarize our main contributions in this paper as follows.
we propose m odit a novel multi modal nmt based tool for automatic code editing.
our extensive empiricalevaluation shows that automatic code editing can bevastly improved with additional information modalitieslike code context and developer guidance.
we empirically investigate different design choices for modit .
we provide a summary of the lessons that we learned in our experiments.
we believe such lessons arevaluable for guiding future research.
we prototype and build m odit and open source all our code data in ii.
b ackground a. neural machine translation neural machine translation nmt is a very well studied field which has been very successful in translatinga sentence from one language to another.
at a very high level input to an nmt model is a sentence x x x2 ... x n which is usually a sequence of tokens x i and the output is also a sentence y y1 y2 ... y m sequence of tokens yi .
while learning to translate from xtoy nmt models learn conditional probability distribution p y x .
such probability distributions are learned w.r .t.
model parameters where model training process optimizes in such a way that maximizes the expected probability distribution of a dataset.an nmt model usually contains an encoder and a decoder.the encoder processes understands and generates vectorrepresentations of the input sentence.
the decoder starts afterthe encoder and sequentially generates the target sentence byreasoning about the encoder generated input representation.while sequentially generating the target sentence the decoderusually performs different heuristic searches for instance beam search to balance exploration and exploitation.
in recent few years software engineering has seen a wide spectrum of adaptation of nmt.
some prominent application 444of nmt is se include program synthesis code summarization edit summarization code editgeneration automatic program repair etc.
these research efforts capitalize on nmts capability tounderstand and generate complex patterns and establish nmtas a viable tool for se related tasks.
b. transformer model for sequence processing transformer model revolutionized sequence processing with attention mechanism.
unlike the traditional rnn based model where input tokens are processed sequentially the trans former assumes soft dependency between each pair of tokensin a sequence.
such dependency weights are learned in theform of attention weights based on the task of the transformer.while learning the representation of a token the transformerlearns to attend to all the input tokens.
from a conceptual pointof view the transformer converts a sequence to a completegraph where each node is a token.
the weights of the edges are attention weights between tokens which are learnedbased on the task of the transformer.
the transformer encodeseach token s position in the sequence positional encoding as part of the input.
in such a way the transformer learnslong range dependency.
since its inception the transformer isvery successful in different nlp understanding and generationtasks.
transformers ability of reasoning about long rangedependency is proved useful for several source code processingtask including code completions code generation code summarization .
c. transfer learning for source code in recent few years transfer learning shows promise for a wide variety of se tasks.
such transfer learning aims at learning task agnostic representation of source code and reusesuch knowledge for different tasks.
one way to learn such taskagnostic representation of input is pre training a model with alarge collection of source code.
the learning objective of suchpre training is often understanding the code or generating thecorrect code.
a pre trained model is expected to embed theknowledge about source code through its parameters.
suchpre trained models are later fine tuned for task specific objec tives.
cubert codebert graphcodebert are all transformer based encoder models which are pre trainedto understand code.
such models are primarily trained usingmasked language model replaced token prediction semantic link prediction etc.
for code generation codegpt pre trains a transformer based model to generate general purpose codesequentially.
more recently plbart pre trainedtransformer based model jointly for understanding and gen erating code with denoising auto encoding .
plbartconsists of an encoder and a decoder.
the encoder is presentedwith slight noise for instance token replacement inducedcode and the decoder is expected to generate noise free code.since code editing task requires both the understanding of code graphand code generation we chose plbart as the base model for modit .
iii.
m odit figure shows an overview of m odit s working procedure.
modit is a multi layer encoder decoder based model consisting of a transformer based encoder and a transformer baseddecoder.
both the encoder and decoder consist of layers.
m odit works on three different modalities of information i code that needs to be edited e p ii natural language guidance from the developer g and iii the context code where the patch is applied c .
we acknowledge that epis essentially a substring of c. however by explicitly extracting and presenting epto m odit we provide m odit with additional information about the change location.
thus despitebeing a part of the context we consider e pa separate modality.
nevertheless m odit consists of three steps.
first the preprocessing step processes and tokenizes these input modalities iii a .
then the encoder in m odit encodes the processed input and the decoder sequentially generates the patched codeas a sequence of tokens iii b .
at final step m odit postprocesses the decoder generated output and prepares the editedcode iii c .
a. pre processing input consolidation.
in the pre processing step m odit generates consolidated multi modal input x from the three input modalities i.e.
ep g andc .
m odit combines these input modalities as a sequence separated by a special s token i.e.
x ep s g s c. in the example shown in figure episnewjson.charat !
wrappingquote gisfix problem which occurred when the resulting json is empty andcis the whole function before the edit see input modalities in figure .
m odit generates a consolidates multi modal input sequence as newjson.charat ... s fix problem which occurred ... s private string ... .
tokenization.
m odit uses sentence piece tokenizer .
sentence piece tokenizer divides every token into sequenceof subtokens.
such subword tokenization is similar to pre viously used byte pair encoding in automatic code edit ing literature .
we use plbart s sentence piece tokenizer which is trained on billions of codefrom github.
after tokenizing the consolidated input x from figure we get new json .
char at ... s fix problem which oc cur red ... s private string ... .
b. encoder decoder model the input to m odit s encoder decoder model is a sequence of subtokens generated in the previous step.
445input modalities private string ... char ... map string object jsonmap ... fix problem which occurred when the resulting json is empty newjson.charat !
wrappingquotemodality code to be edited modality guidance modality contextnewjson... s fix problem ... s private string ... s new json ... s fix problem ... s private string ... combined multi modal inputpre processing tokenization tokenized inputencoder decoder model transformer encoder transformer decoderoutput generation !
jsonobject .
is empty ... s top candidate code post processing edited code!
json.isempty newjson.charat !
wrappingquote fig.
overview of m odit pipeline transformer encoder .
given an input sequence x x1 x1 ... x n the encoder learns the representation of every token at layer lasre l xi using self attention computed as re l xi n summationdisplay j iai j re l xj wherere l xj is the representation of subtoken xjas generated by layer l andai jis the attention weight of subtoken xitoxj.
such attention weights are learned by multi head attention .
final layer generated representation i.e.
re xi is the final representation for every subtoken xi in the input.
note that the encoder learns the representationof equation of a subtoken using all subtokens in thesequence.
thus the learned representation of every subtokencontains information about the whole input sequence.
sincewe encode all the information modalities in one sequence thelearned representation of every subtoken encodes informationabout other modalities.
transformer decoder .
the decoder in m odit is a transformerbased sequential left to right decoder consisting of layers.
it sequentially generates one subtoken at a time using previouslygenerated subtokens and the final representation r e l xi from the encoder.
the decoder contains two modules i self attention and ii cross attention.
the self attention layer worksimilar to the self attention in the encoder.
first with selfattention decoder generates representation r dl yi of last generated token yiwith self attention on all previously generated tokens y1 y2 ... y i .
this self attention follows same mechanism described in equation .
after learning decoderrepresentation by self attention decoder applies attention ofencoder generated input representation using the followingequation d l yi n summationdisplay j i l i j re xj where l i j softmax parenleftbig dot parenleftbig re xj rdl yi parenrightbig parenrightbig is the attention weight between output subtoken yito input subtoken xj.
the softmax generates an attention probability distribution over the length of input tokens.
finally the decoder learnedrepresentation d l yi is projected to the vocabulary to predict maximally likely subtoken from the vocabulary as next token.
in summary the encoder learns representation of every subtokens in the input using all input subtoken essentiallyencoding the whole input information in every input subtokenrepresentation.
the decoder s self attention mechanism allowsthe decoder to attend to all previously generated subtokensallowing the decoder decide on generating correct token atcorrect place.
the cross attention allows the decoder to attendto encoded representation implicitly letting the model decidewhere to copy from the input where to choose from newtokens in the vocabulary.
we initialize the end to end encoder decoder in m odit using pre trained weights of plbart .
c. output generation the decoder in m odit continue predicting subtoken until it predicts the end of sequence s token.
during inference modit uses beam search to generate sequence of subtokens.
once the decoder finishes m odit post processes the top ranked sequence in the beam search.
first m odit removes the end of sequence s token.
it then detokenizes the subtokens sequence to code token sequence.
in this step modit merges generated subtokens that are fragments of a code token into one code token.
for the example shown infigure m odit generates the subtoken sequence !
json .
is empty new json .
char at !
wrap ping quote s .
after detokenization m odit generates !json.isempty newjson.charat !
wrappingquote .
iv .
e xperimental design a. dataset table i statistics of the datasets studied.
datasetavg.
avg.
avg.
tokens examples tokens change size inguidance train valid test b2fs .
.
.
b2fm .
.
.
change size measured as token edit distance.
to prove our concept of m odit we experiment on two different datasets i.e.
b2fs andb2fm proposed by tufano et al.
.
in these two datasets they collected large collections of bug fix code changes along with commit mes sages from java projects in github.
each example in thesedatasets contains the java method before the change c p the method after the change c n and the commit message for 446the change.
there are some examples with corrupted bytes in the commit message which we could not process.
we excluded such examples from the dataset.
table i showsstatistics of the two datasets we used in this paper.
b2f s contains smaller methods with maximum token length andb2f mcontains bigger methods with up to tokens in length.
the average size of the change edit distance is .
and .
respectively in b2f sandb2fm.
b. data preparation for the datasets described in section iv a we extract the input modalities and the expected output to train m odit .f o r every method pair i.e.
before edit cp after edit cn i n those dataset we use gumtree to extract a sequenceof tree edit locations.
we identify the root of the smallestsubtree of c p s ast that encompasses all the edit operations.
we call the code fragment corresponding to that subtree ascode to be edited e p and used as m odit s first modality.
similarly we extract the code corresponding to the smallestsubtree encompassing all the edit operations from c nand use that as code after edit e n .
we use the commit message associated with the function pair as m odit s second modality guidance g .
finally we use the full method before edit c p as m odit s third modality context c .
c. training after combining every example in the datasets in m odit s input e p g c and expected output e n we use this combined dataset to train m odit .
for training m odit w e use label smoothed cross entropy as loss function.
weuse adam optimizer with a learning rate of 5e .
we train modit for epochs after every epoch we run beam search inference on the validation dataset.
we stop training if thevalidation performance does not improve for five consecutivevalidations.
d. evaluation metric we use the top accuracy as the evaluation metric throughout the paper.
for proof of concept we evaluate all techniques with beam size .
when the generated patched code matchesexactly with the expected patched code e n it is correct incorrect otherwise.
note that this is the most stringent metricfor evaluation.
previous approaches talked aboutfiltering out infeasible patches from a ranked list of top kpatches using test cases.
however we conjecture that suchtest cases may not always be available for general purposecode edits.
thus we only compare top accuracy.
e. research questions m odit contains several design components i use of multimodal information ii use of transformer and initializing it with the pre trained model and iii use of end to end encoder decoder using plbart to generate patchesinstead of separately using pre trained encoder or pre traineddecoder as used by previous tools.
first we are interested inevaluating m odit w.r .t.
state of the art methods.
in particular we evaluate how these three design choices effect m odit s performance.
so we start with investigating rq1.
how accurately does m odit generate edited code w.r.t.
other techniques?
modit uses three input modalities.
our next evaluation target is how these individual modalities effect m odit s performance?
thus we ask rq2.
what are the contribution of different input modalities in m odit s performance?
finally recall from section iii a m odit proposes to encode all the input modalities as a sequence and use oneencoder for the consolidated multi modal input.
an alternativeto this encoding mechanism is to encode individual inputmodality with dedicated input encoder.
our next evaluationaims at finding out the best strategy to encode input modalities.hence we investigate rq3.
what is the best strategy to encode multiple input modalities?
v. e mpirical results in our first research question we evaluate m odit s performance w.r .t.
other techniques and the effect of m odit s design components.
rq1.
how accurately does m odit generate edited code w.r.t.
other techniques?
experimental setup.
we carefully chose the baselines to understand the contribution from different design choices of modit .
we evaluated our model in two experimental settings.
first we train different baseline models where the full modelis trained from scratch.
in this setting the first baselinewe consider is an lstm with attention nmt model.v arious existing code patching approaches used such settings.
second baseline is transformer baseds2s model.
we consider two different sized transformers.
this enables us to contrast effect of model size in code editing performance.
the transformer base model consists of six encoder layers and six decoder layers.
the transformerbase model s architecture is the same as m odit s architecture.
furthermore we consider another transformer with a muchlarger architecture.
transformer large contains twelve encoder layers and twelve decoder layers with three times as manylearnable parameters as the transformer base model.
the final baseline in this group is c odit which is a tree based model.
comparison w.r .t.
codit allows us to contrast externally given syntax information in the form of cfg and learnedsyntax by transformers i.e.
m odit .
we use all three input modalities see figure for example as input to the lstmand transformer.
using auxiliary modalities is non trivial with c odit since the input to c odit must be a syntax tree.
thus we use uni modal input e p with c odit .
in the second setting we consider different pre trained models which we used to fine tune for patch generation.figure shows schematic diagrams of the pre trained modelswe compared in this evaluation.
first two models we consid ered are codebert and graphcodebert .
both s if first... s first s first null null decoder trained from scratchpretrained bidirectional encoder a codebert consist of bidirectional pretrained encoder and a decoder trained from scratch.
sep first s first null null sep if ... first... s if pretrained left to right decoder b codegpt one pretrained single decoder processesthe input and output sequentially from left to right.
s if first... s first s first null null pretrained bidirectional encoderpretrained left toright decoder c plbart consist of pretrained bidirectional encoderand pretrained left to right decoder.
fig.
schematic diagram of the three types of pre trained models.
used to evaluate m odit .
of these models are pretrained encoders primarily trained to understand code.
to use these for the patching task we add asix layered transformer based decoder along with the encoder.the decoder is trained from scratch see figure 4a .
anotherpre trained baseline is codegpt .
gpt is a single left to right decoder model primarily pre trained to generate code.for the code editing task a special token sep combines the input and the output as a sequence separated.
jiang et al.
showed the effectiveness of gpt for the source code patchingtask see figure 4b .
in contrast to these pre trained models m odit uses plbart an end to end encoder decoder model trained to understand and generate code simultaneously seefigure 4c .
to compare from a fairground we evaluate thesepre trained models with uni modal input e p and multi modal input e p s g s c separately.
table ii top accuracies of different models w.r.t.
their training type model sizes input modality.
training model of multi accuracy type name params m modal b2fs b2fm lstm .
.
.
transformer base .
.
.
transformer large .
.
.63from scratch codit .
.
.
.
.
codeber t .
.
.
.
.
graphcodeber t .
.
.
.
.
codegpt .
.
.
.
.79fine tuned modit .
.
.
results.
table ii shows the accuracy in top predictedpatch by m odit along with different baselines.
lstm based s2s model predicted .
and .
correct patches in b2fsandb2fmrespectively.
the transformer base model achieves .
and .
top accuracy in those datasets which improves further to .
and .
with thetransformer large model.
c odit predicts .
and .
correct patches in b2fsandb2fm respectively.
note that codit takes the external information in the form of cfg thus the patches c odit generate are syntactically correct.
nevertheless the transformers even the smaller model per form better to predict the correct patch.
we conjecture that thetransformer model can implicitly learn the code syntax withoutdirect supervision.
in contrast to the models trained from scratch when we fine tune a pretrained model it generates significantly more correct patches than models trained from scratch.
for instance m odit initialized with pretrained plbart generates and more correct patches than the transformer base model with randomly initialized parameters despite bothof these models having the same architecture and the samenumber of parameters.
in fact the smallest fine tuned model codegpt performs much better than the larger model trainedfrom scratch transformer large .
all the fine tuned models exhibit better performance when the input data are multi modal with various degrees of im provement.
with all three input modalities codebert generates and .
more correct patches in b2f sand b2fm respectively compared to a unimodal codebert model.
in case of m odit such improvement is .
in b2fsand .
in b2fm.
thegin the multi modal data often contains explicit hints about how to change the code.
forinstance consider the example shown in figure the guidanceexplicitly says there is a problem with the json when it is empty.
furthermore with the presence of cin the input the model can identify different variables methods used inthe method and potentially copy something from the context.we conjecture that such additional information from thesetwo additional input modalities i reduce the search spacefor change patterns ii help models copy relevant identifiersfrom the context.
among the fine tuned models multi modalities m odit generates .
more correct patches than codebert .
than graphcodebert and .
than codegpt inb2f s. in the case of b2fmdataset m odit s improvement in performance is .
.
.
higher thancodebert graphcodebert and codegpt respectively.
tounderstand these results better let us look at some of theexamples.
figure shows an example patch where m odit correctly generated the expected patch but codegpt could not.
if welook closely we can see that the code to be changed e p i sa boolean expression where the two clauses are combines with .
while only the first clause one.issimilar two is the expected output codegpt chooses the second clause one .tostring .equals two.tostring from the original.
recall from figure 4b codegpt processes the com448 guidance merging of items that aren t actually equal public static boolean equals itemstack one itemstack two return one.issimilar two one.tostring .equals two.tostring return one.issimilar two modit generated codegpt generated return one.tostring .equals two.tostring fig.
example patch where m odit was able to generate correct patch but codegpt could not.
m odit s patch is shown in green and codegpt generated patch is shown in blue .
bined input and output sequence separated by special sep token in left to right fashion.
thus encodes representation of the input tokens do not contain information about the whole input sequence.
in contrast the m odit uses a pre trained bidirection encoder which helps m odit to understand the input fully.
based on the examples we have seen and the empiricalresult we conjecture that for code editing tasks the modelmust fully understand the input in a bi directional fashion.
guidance ... code refactoring ... public boolean isempty if first null return true return false return first null modit predicts codebert generated return first null first.get null fig.
correctly predicted patch by m odit .
codebert could not understand and reason about the textual hint to predict the correct patch.
figure shows an example where m odit generated correct patch codebert could not.
note that the guidancetext explicitly asks about code refactoring implying that the patched code should be semantically similar to the originalcode.
similar to the original code patched could should returntrue when first null otherwise it should return false .
an automated code change tool should not add additional code features when the refactoring.
however codebert generated patch which introduced an additionalclause first.get null in the return expression which make codebert s generate code semantically differentfrom the original.
m odit was able to generate the correct patch for this example.
finally we summarize the empirical lessons we learned in this research question as multi modal input improves code editing capability ir respective of the underlying model used.
the guidanceoften narrows the edit pattern search space and thecontext narrows down the token generation search space.
transformer models especially larger ones are robustenough to learn the code s syntax information withoutdirect supervision.
when a pre trained model is usedto initialize transformer parameters the improvement isnotably higher.
for code editing task both understanding the input and correctly generated output are important.
while a pre trained encoder understands the code and a pre traineddecoder generates correct code an end to end pre trainedencoder decoder model e.g.
plbart the best choice to fine tune for this task.
result modit generates .
and .
correct patches in top position for two different datasets outper forming codebert by up to .
graphcodebert byup to .
and codegpt by up to .
.
pre trainedmodels tend to be more effective than models trained fromscratch for code editing m odit improves the performance by than the best model trained from the scratch.
modit combines multiple modalities of information to generate patches.
now we investigate rq2.
what are the contribution of different input modalities in m odit s performance?
experimental setup.
in this experiment we investigate the contribution of different input modalities in m odit s performance.
recall from section iii a that we use three inputs in m odit i.e.
ep c g .
here we investigate different combinations of such input modalities.
more precisely weinvestigate the influence of three information sources i code that needs to be changed e p ii context c and iii guidance g .
note that by presenting epas a separate information modality we are essentially providing m odit with the information about the location of the change.
to studythe effect of such presentation we study another alternativeexperimental setup where we annotate the change locationinside the context with two unique tokens start and end .
table iii contribution of different input modalities in m odit s performance.
indicates that corresponding input modality is used as encoder input indicates otherwise.
we report top accuracy as performance measure.
exp.
id is used later to refer to corresponding experiment result.
exp.
id denotes an experiment with as input modalities.
exp.
idinputs accuracy ep c g b2fs b2fm c .
.
cg .
.
c .
.
cg .
.
e .
.
eg .
.
ec .
.
ecg .
.
epis surrounded by two special tokens start and end inside the context.
result.
table iii shows m odit s performance with different combination of input modalities.
when we present only the context to m odit it predicts .
correct patches in b2fs and .
in the b2fm which improves further to .
and .
in those two datasets respectively when we add g. note that in these two scenarios the model does not explicitlyknow which portion of the code needs to be edited it sees the 449whole method and predicts only the patched code e n .
in addition to learning how to patch the model implicitly learns where to apply the patch in this setup.
to test whether theidentification of such location is the performance bottleneck we surround the code that needs to be patched with twospecial tokens start and end .
sequencer also proposed such annotation of buggy code.
surprisingly suchannotation resulted in comparable slightly worse in one case performance by m odit .
in the next set of experiments we extract the code that needs to be edited e p and present it as a separate input modality.
first we only present the epwithout the other two modalities.
when we only present the epand generate the edited code e n it results in .
top accuracy in theb2fsand .
in the b2fm.
ding et al.
attributed such improvement to the reduced search space due toshorter input.
our result corroborates their empirical findings.nevertheless when we add the gmodality with the e p modit s performance improves to .
and .
in b2fsandb2fm respectively.
in our final set of experiments in this research question we augment epwith the c. in this evaluation setup m odit predicts .
correct patches in the b2fsand .
in theb2fm which is improved further to .
and .
correct patches in those two datasets when we add g. guidance fixed some bugs in type checking improved performance by caching types of expressions private typecheckinfo gettype sadluniontype expression ... return new typecheckinfo declarationconceptname declarationconceptname modit generated patch with guidance declarationconceptname declarationconceptname this expression modit generated patch without guidance this.declarationconceptname this.declarationconceptname fig.
example showing the effect of textual guidance in m odit s performance.
m odit produced the correct patch with guidance without guidance as input m odit s produced patch is essentially refactored version of original input.
figure shows an example where m odit with all modalities could successfully generate correct patch.
thetext guidance g provides hint that variable expression should somehow associate with the construction of typecheckinfo in the patched code.
however without this guidance m odit generated a wrong patch by accessing existing parameters from this object.
essentially without the guidance m odit refactored the input code.
figure shows the effect of context as input modality to modit .
the before edit version of the code e p passed the wrong parameter m t o sendmessage function.
when the context c is presented to m odit it saw another variable sent in the context.
in contrast without context c m odit indeed changed the parameter but sent m.tostring resulting in a wrong patch.
guidance fix bug of sending wrong message public void setpredecessor model.message m this.predecessor integer.valueof m.content model.message sent new model.message sent.to m.origin sendmessage m modit generates with the context.
sendmessage sent modit generates without context as input.
sendmessage m.tostring fig.
example showing the necessity of context information in predicting the correct patch.
m odit s generated correct patch with the context as input.
without context m odit received sendmessage m and the guidance as input did not know the variable sent could be the parameter of the function sendmessage and predicted a wrong patch .
when we extract the buggy code and present the buggy code along with the context we see a big performanceimprovement see the difference between c and ecin table iii .
we hypothesize that when only context i.e.
full code is presented c the model gets confused to identify which portion from the context needs to be edited since anyportion of the code is a likely candidate for patching.
however when we extract the exact code that needs to be edited andpresent as a separate input modality to m odit it can focus on patching just that code using other modalities including thecontext as a supporting source of information.
in a recentstudy ding et al.
pointed out the need for effective ways to include context in the nmt based code editors.
ourempirical results show that m odit s way of including context as a separate modality is a potential solution to that problem.
in summary each of the modalities contribute to the overall performances of m odit .
lessons learned in these experiments are additional textual guidance helps the patch generation.such guidance can provide important clue about howto modify the code and sometimes provide ingredientsnecessary for the change.
adding context explicitly in the input enables the modelto select appropriate identifiers for patching.
isolating buggy code help the model put proper focus onthe necessary part of the code while leveraging auxiliaryinformation from other modalities.
result all three modalities code to be edited context and guidance are essential for modit to perform the best.
without either one of those performance decreases.
modit s performance improves up to .
when additional textual guidance is used as an input modality.
contextmodality improves m odit s performance up to .
.
we investigate alternative ways to combine multiple input modalities.
we ask rq3.
what is the best strategy to encode multiple input modalities?
experimental setup.
to validate m odit s design choice of appending all input modalities into one sequence we test ... s if first ... code encoder s public boolean isempty... context encoder s code refactoring...guidance encoder s first s first null null decoder fig.
an alternative architecture of code editing with multi encoder model.
we initialize each of the encoders with pre trained encoder model.
alternative ways to combine input modalities.
in particular we follow the design choice proposed by lutellier et al.
where they used multiple encoders to encode the epand thec.
tufano et al.
also leverages a similar idea to encode input code and code review messages.
nevertheless we use a multi encoder model shown in figure .
in a multi encoder setting we first encode each input modality with acorresponding dedicated encoder.
after the encoder finishesencoding we concatenate the encoded representations and passthose to the decoder for generating patched code.
to retainmaximum effectiveness we initialize each individual encoderwith pretrained weights from codebert .
we considera single encoder model also initialized with codebert asa baseline to compare on the fairground.
while presentingthe inputs to the single encoder model we concatenate inputmodalities with a unique separator token s .
finally to test the robustness of our empirical finding we propose twodifferent experimental settings.
in the first evaluation setup weuse all three input modalities.
we compare a tri encoder modelwith a single encoder model.
next we consider bimodal inputdata e pandg.
we use a dual encoder model and compare it with a single encoder model in this setup.
table iv comparison of multi encoder model.
o f o f accuracy modalities encoders b2fs b2fm ep g c .
.
.
.
ep g .
.
.
.
result.
table iv shows the result of multi encoder models.
for tri modal input data if we use three different encoders the model can predict .
correct patches in the b2f sand .
correct patches in the b2fm.
in contrast if we use a single encoder the model s predictive performance increasesto .
and .
top accuracy in the b2f sand the b2fm respectively.
in the bimodal dataset where the input modalities are epandg the dual encoder model predicts .
correct patches in the top position for the b2fsand .
correct for theb2fm.
the single encoder counterpart in this setup predicts .
correct patches for the b2fsand .
for theb2fm.
the empirical results show that the single encoder model performs better in both the experimental setupthan the multi encoder setup.
we find similar results withgraphcodebert .
y1 x1x2y2decoder single encoder a single encoder for encoding multiple modalities.
encoder can learn representation w.r.t.
all modalities.
y1y2x1x2 decoder encoder encoder b dual encoder for encoding individual modalities separately.
rep resentation of tokens from a particular modality is learned w.r.t.
only other tokens from the same modality.
fig.
input token representation generation in single encoder and multiple encoder.
to explain why single encoder is performing better than multi encoder let us look at the encoders working procedure.
figure depicts how the encoder generates representation forinput tokens.
note that the encoders we used in this researchquestion are transformer based and recall from the section ii transformer generates representation for an input token bylearning its dependency on all other tokens in the sequence.when we present all the input modalities to a single encoder it generates input representation for those tokens w.r .t.
and other tokens in the same modality and tokens from othermodalities.
for instance in figure 10a the encoder generatesx s representation considering x1 y1 andy2.
in contrast in figure x2 s representation is learned only w.r .t.x1 since encoder1 does not see the input modality y. thus when we present all the input modalities to one single encoder weconjecture that learned representations are more robust thanthat of learning with multi encoder.
finally we summarize the lessons we learned in this research question as in multi modal translation using single encoder resultsin better performance than using a separate encoder foreach modality.
single encoder generates input representation by inter modality reasoning attention hence learns more robustrepresentation than that of multi encoder.
result encoding all the input modalities by a single encoder is the best way to learn in a multi modal setting.a single encoder improves code editing performance by upto .
than the corresponding multi encoder setting.
vi.
d iscussion a. localization of code edit site an alternative modeling approach for code editing is to generate the sequence of edit operations i.e.
insert delete update where the model mustknow the precise location of an edit operation often a node in 451the ast before applying it.
throughout this paper we also assumed that such edit location is known to m odit .
this assumption may pose a threat to the usefulness of m odit in a real development scenario.
to mitigate such a threat weperform an experiment where we pass the whole function asinput to m odit and expect the whole edited function to be generated.
table v shows the top accuracy in the b2fsand table v performance of m odit when the input in the full code and the output is patched full code.
inputs accuracy full code guidance b2fs b2fm .
.
.
.
theb2fm.m odit generates correctly patched full code in .
cases for the b2fsand .
cases for the b2fm.
with additional textual guidance the performance is furtherimproved to .
and .
in the b2f sandb2fm respectively.
while textual guidance helps in this experimentalsetup we notice a big drop in performance than the resultsshown in table iii.
this is because the benchmark datasets weused contain small edits see table i .
thus while generatingthe full code the model wastes a large amount of efforttrying to generate things that did not change.
nevertheless our hypothesis external guidance improves code editing holds even when the model generates full code.
b. tokenization for source code processing table vi comparison between concrete tokenization and abstract tokenization alongside pre trained models.
results are shown as top accuracy of full code generation in b2fs b2fmdatasets.
token type codebert graphcodebert plbart abstract .
.
.
.
.
.
concrete .
.
.
.
.
.
the possible number of source code can be virtually infinite.
v ocabulary explosion has been a big challenge while processing source code with machine learning technique .previous research efforts have addressed this problem usingseveral different heuristics.
for instance tufano et al.
identifiers abstraction which drastically reduces the vocabu lary size considered making it easier to learn patterns by themodel.
recent studies found that byte pairencoding partially solves the open vocabulary problemby sub dividing rare words into relatively less rare sub words.such sub division is also learned from large corpora of data.all the pre trained models used in this paper used sub word to kenization techniques.
codebert and graphcodebert usedroberta tokenizer codegpt used gpt tokenizer and plbart used sentence piece tokenizer .
the use ofsuch tokenizers strips away the burden of identifier abstraction.our investigation shows that in some cases pre trained mod els perform better with concrete tokens than abstract tokens see table vi for detailed result .
thus we champion usinginput and outputs with concrete tokens when a pre trainedmodel is used.
vii.
r ela ted works a. automatic code change there are a lot of research efforts to capture repetitiveness of developers way of editing source code.
these researches showthe potential of automatic refactoring boilerplatecode etc.
these research efforts include semi automatictools involving traditional program analysis techniques e.g.
clone detection dependency analysis graph matching .
other research direction aims at learning source code editfrom previous edits and applying those edit patterns in similarcontext .
some of these efforts targets very specificcode changes for example nguyen et al.
proposed a graph matching based approach for automatically updatingapi usage.
tansey et al.
semantic preserving transformation of java classes for automated refactoring.
other directionsof works address more general purpose code change learnedfrom open source repositories .
such approaches tar get solving automated code editing tasks in a data drivenapproach and the edit patterns are learned from examplechanges.
in this research we also investigated general purposesource code changes in the wild.
more closely to m odit rolim et al.
s proposed technique constraints source code generation with additional input output specification or testcases.
nevertheless we argue that textual guidance could bea very good surrogate specification.
b. nmt for code change modeling nmt has been studied for past couple of years to learn automatic source code change modeling.
tufano et al.
presented initial investigation of using nmt in learning general purpose code changes.
chakraborty et al.
proposed a tree based hierarchical nmt model for general purposesource code change.
instead of viewing code as sequenceof tokens they first generated syntax tree by sampling fromcontext free grammar and then another model to fill up thegaps for identifier.
to reduce the search space they performedscope analysis to search for suitable identifier.
chen et al.
proposed a copy mechanism based nmt model for aprwhere the input is the code before change along with thecontext and the output is the code after change.
their worktreated the input as uni modal way where the whole code isone singe modality.
in this work we consider multi modal wayof modeling where we isolate the code fragment that needsto be changed from its context and present that code fragmentconcatenated with context to the model.
lutellier et al.
treated code needs to be changed and the context as twodifference modalities and use separate encoders.
however ourempirical evidence showed that using one encoder to encodeall the modalities result in the best performance.
more recently ding et al.
presented empirical evidence that instead of generating a whole code element i.e.
context change of the target version only generating the sequence of changes mightperform better for code change modeling.
recent works proposed models for generating such edit sequence.
such models may augment or outperform nmt based code editing we leave such investigation as future work.
c. machine learning for source code analysis in recent years machine learning especially deep learning has been widely adopted across different area of software engineering due to availability of large collection ofsource code in open source platforms e.g.
github bitbucket etc.
application of ml based source code analysis includebug detection in code clone detection code com pletion vulnerability detection code summariza tion code translation etc.
recent works also ap proached to learn general purpose transferable representationlearning for source code which can later be used for varioussource code related tasks .
the approachesfor learning such transferable representations can be broadlycategorized in two ways.
the first category of approaches e.g.
code2v ec aims at learning explicit representation for tokens in the code.
another category of approaches e.g.
codebert transfers syntactic and semantic interactionbetween code components in the form of pre trained models.in this approach a model for a specific task is initialized witha general purpose pre trained model trained to understand andgenerate code.
in this paper we empirically found that suchpre trained models plbart increase accuracy upto in patch generation.
viii.
t hrea ts to validity a. external v alidity bias in the dataset.
bothb2fs andb2fmare collection of bug fix commits and thus there is a threat that these dataset may exhibit specific bias towards bug fix patches.
while thecommits in these datasets are filtered and classified as bug fixcommits these changes are made by real developers as partof development life cycle.
unlike other bugfix datasets b2f sandb2fmdo not isolate the bug.
thus we conjecture that possibility of existence of any such bias is minimal.
noise in commit message.
we used commit message as a guidance for code editing.
while previous research efforts showed that commit messages are very usefulto summarize the changes in a commit other research ef forts also elucidated noises present in the commitmessage.
to mitigate this threat we carefully chose the datasetwe tested m odit on.
the original authors of the the dataset reported that they carefully investigated the datasetand after manual investigation they reported that .
ofthe commits in their datasets are true positive.
despite thisthreat m odit s performance seems to improve with commit message as additional input.
b. construct v alidity in general developers write commit message after they edited the code in theory summarizing the edits they made.
in this paper we assumed an experimental setup where developerwould write the summary before editing the code.
suchassumption may pose a threat to the applicability of m odit in real world since in some cases the developer may not knowwhat edits they are going to make prior to the actual editing.regardless we consider m odit as a proof of concept where empirically we show that if a developer had the idea of changein mind that could help an automated code editor.
c. internal threat all deep learning based techniques are sensitive to hyperparameters.
thus using a sub optimal hyper parameter can pose a threat to the validity of m odit especially while comparing with other baselines.
as we compared with otherpre trained models we cannot really modify the architectureand dimensions of other pre trained models.
as for otherhyper parameters i.e.
learning rate batch size etc.
we use the exact same hyper parameters described by respectivepaper.
nevertheless we open source out code and data forbroader dissemination.
ix.
c onclusion in this paper we highlight that an automatic code edit tool should possess knowledge about the underlying programminglanguage in general.
also it can benefit from additionalinformation such as edit context and developers intentionexpressed in natural language.
to that end we design present and evaluate m odit a multi modal nmt based automated code editor.
our in depth evaluation shows that m odit improves code editing by leveraging knowledge about program ming language through pre training.
in addition we showedthat leveraging additional modalities of information couldbenefit the source code editor.
our empirical evaluation revealssome critical lessons about the design choices of buildingan automated code editor that we believe will guide futureresearch in automatic code editing.
a cknowledgement this work is supported in part by nsf grants shf shf iis ibm and vmware.
any opin ions findings conclusions or recommendations expressedherein are those of the authors and do not necessarily reflectthose of the us government nsf ibm or vmware.
r eferences b. ray m. nagappan c. bird n. nagappan and t. zimmermann the uniqueness of changes characteristics and applications ser.
msr .
acm .
n. meng m. kim and k. s. mckinley systematic editing generating program transformations from an example acm sigplan notices vol.
no.
pp.
.
lase locating and applying systematic edits by learning from examples in proceedings of 35th international conference on software engineering icse pp.
.
r. rolim g. soares l. d antoni o. polozov s. gulwani r. gheyi r. suzuki and b. hartmann learning syntactic program transfor mations from examples in proceedings of the 39th international conference on software engineering.
ieee press pp.
.
m. tufano j. pantiuchina c. watson g. bavota and d. poshyvanyk on learning meaningful code changes via neural machine translation arxiv preprint arxiv .
.
s. chakraborty y .
ding m. allamanis and b. ray codit code editing with tree based neural models ieee transactions on software engineering vol.
pp.
.
m. tufano c. watson g. bavota m. di penta m. white and d. poshyvanyk an empirical investigation into learning bug fixing patches in the wild via neural machine translation .
m. tufano c. watson g. bavota m. d. penta m. white and d. poshyvanyk an empirical study on learning bug fixing patches inthe wild via neural machine translation acm transactions on software engineering and methodology tosem vol.
no.
pp.
.
n. jiang t. lutellier and l. tan cure code aware neural machine translation for automatic program repair arxiv preprint arxiv .
.
t. lutellier h. v .
pham l. pang y .
li m. wei and l. tan coconut combining context aware neural translation models using ensemble forprogram repair in proceedings of the 29th acm sigsoft international symposium on software testing and analysis pp.
.
z. chen s. j. kommrusch m. tufano l. n. pouchet d. poshyvanyk and m. monperrus sequencer sequence to sequence learning for end to end program repair ieee transactions on software engineering .
a. v aswani n. shazeer n. parmar j. uszkoreit l. jones a. n. gomez l. u. kaiser and i. polosukhin attention is all you need in advances in neural information processing systems pp.
.
z. liu x. xia a. e. hassan d. lo z. xing and x. wang neuralmachine translation based commit message generation how far arewe?
in 33rd ieee acm international conference on automated software engineering ase pp.
.
w. wang g. li s. shen x. xia and z. jin modular tree network for source code representation learning acm transactions on software engineering and methodology tosem vol.
no.
pp.
.
z. feng d. guo d. tang n. duan x. feng m. gong l. shou b. qin t. liu d. jiang and m. zhou codebert a pre trained model forprogramming and natural languages in findings of the association for computational linguistics emnlp nov. pp.
.
d. guo s. ren s. lu z. feng d. tang s. liu l. zhou n. duan j. yin d. jiang et al.
graphcodebert pre training code representations with data flow in international conference on learning representations .
w. u. ahmad s. chakraborty b. ray and k. w. chang unified pretraining for program understanding and generation in annual conference of the north american chapter of the association forcomputational linguistics naacl .
d. bahdanau k. cho and y .
bengio neural machine translation by jointly learning to align and translate in international conference on learning representations .
p .
yin and g. neubig a syntactic neural model for general purpose code generation in proceedings of the 55th annual meeting of the association for computational linguistics v olume long papers vol.
pp.
.
b. wei g. li x. xia z. fu and z. jin code generation as a dual task of code summarization in advances in neural information processing systems pp.
.
w. u. ahmad s. chakraborty b. ray and k. w. chang a transformer based approach for source code summarization in proceedings of the 58th annual meeting of the association for computationallinguistics acl .
s. kim j. zhao y .
tian and s. chandra code prediction by feeding trees to transformers arxiv preprint arxiv .
.
a. svyatkovskiy s. k. deng s. fu and n. sundaresan intellicode compose code generation using transformer in proceedings of the 28th acm joint meeting on european software engineering conferenceand symposium on the f oundations of software engineering pp.
.
a. kanade p .
maniatis g. balakrishnan and k. shi pre trained contextual embedding of source code arxiv preprint arxiv .
.
l. dong n. yang w. wang f. wei x. liu y .
wang j. gao m. zhou and h. w. hon unified language model pre training for natural lan guage understanding and generation arxiv preprint arxiv .
.
s. lu d. guo s. ren j. huang a. svyatkovskiy a. blanco c. clement d. drain d. jiang d. tang et al.
codexglue a machine learning benchmark dataset for code understandingand generation arxiv preprint arxiv .
.
.
available m. lewis y .
liu n. goyal m. ghazvininejad a. mohamed o. levy v .
stoyanov and l. zettlemoyer bart denoising sequence to sequencepre training for natural language generation translation and comprehen sion arxiv preprint arxiv .
.
t. kudo and j. richardson sentencepiece a simple and language independent subword tokenizer and detokenizer for neural text process ing in proceedings of the conference on empirical methods in natural language processing system demonstrations nov. pp.
.
r. m. karampatsis h. babii r. robbes c. sutton and a. janes big code!
big vocabulary open vocabulary models for source code in2020 ieee acm 42nd international conference on software engineer ing icse .
ieee pp.
.
j. r. falleri f. morandat x. blanc m. martinez and m. monperrus fine grained and accurate source code differencing in proceedings of the 29th acm ieee international conference on automated softwareengineering.
acm pp.
.
r. m uller s. kornblith and g. hinton when does label smoothing help?
arxiv preprint arxiv .
.
y .
ding b. ray p .
devanbu and v .
j. hellendoorn patching as translation the data and the metaphor in 35th ieee acm international conference on automated software engineering ase .ieee pp.
.
r. tufano l. pascarella m. tufano d. poshyvanyk and g. bavota towards automating code review activities arxiv preprint arxiv .
.
e. dinella h. dai z. li m. naik l. song and k. wang hoppity learning graph transformations to detect and fix bugs in programs ininternational conference on learning representations .
d. tarlow s. moitra a. rice z. chen p .
a. manzagol c. sutton and e. aftandilian learning to fix build errors with graph2diff neural net works in proceedings of the ieee acm 42nd international conference on software engineering workshops pp.
.
z. yao f. f. xu p .
yin h. sun and g. neubig learning structural edits via incremental tree transformations arxiv preprint arxiv .
.
r. m. karampatsis and c. sutton how often do single statement bugs occur?
the manysstubs4j dataset arxiv preprint arxiv .
.
r. sennrich b. haddow and a. birch neural machine translation of rare words with subword units arxiv preprint arxiv .
.
y .
liu m. ott n. goyal j. du m. joshi d. chen o. levy m. lewis l. zettlemoyer and v .
stoyanov roberta a robustlyoptimized bert pretraining approach arxiv preprint arxiv .
.
.
available a. radford j. wu r. child d. luan d. amodei and i. sutskever language models are unsupervised multitask learners openai blog vol.
no.
p. .
x. ge q. l. dubose and e. murphy hill reconciling manual and automatic refactoring in proceedings of the 34th international conference on software engineering.
ieee press pp.
.
v .
raychev m. sch afer m. sridharan and m. v echev refactoring with synthesis in acm sigplan notices vol.
no.
.
acm pp.
.
n. meng l. hua m. kim and k. s. mckinley does automated refactoring obviate systematic editing?
in proceedings of the 37th international conference on software engineering v olume .
ieeepress pp.
.
r. robbes and m. lanza example based program transformation in international conference on model driven engineering languages andsystems.
springer pp.
.
h. a. nguyen a. t. nguyen t. t. nguyen t. n. nguyen and h. rajan a study of repetitiveness of code changes in software evolution inproceedings of the 28th ieee acm international conference on automated software engineering.
ieee press pp.
.
h. a. nguyen t. t. nguyen g. wilson jr a. t. nguyen m. kim and t. n. nguyen a graph based approach to api usage adaptation inacm sigplan notices vol.
no.
.
acm pp.
.
w. tansey and e. tilevich annotation refactoring inferring upgrade transformations for legacy applications in acm sigplan notices vol.
no.
.
acm pp.
.
b. ray v .
hellendoorn s. godhane z. tu a. bacchelli and p .
devanbu on the naturalness of buggy code in ieee acm 38th international conference on software engineering icse .
ieee pp.
.
w. wang g. li b. ma x. xia and z. jin detecting code clones with graph neural network and flow augmented abstract syntax tree in ieee 27th international conference on software analysis evolutionand reengineering saner .
ieee pp.
.
m. r. parvez s. chakraborty b. ray and k. w. chang building language models for text with named entities .
s. chakraborty r. krishna y .
ding and b. ray deep learning based vulnerability detection are we there yet ieee transactions on software engineering pp.
.
h. xu s. fan y .
wang z. huang h. xu and p .
xie tree2tree structural language modeling for compiler fuzzing in international conference on algorithms and architectures for parallel processing .
springer pp.
.
u. alon m. zilberstein o. levy and e. yahav code2vec learning distributed representations of code in proceedings of the acm on programming languages vol.
.
acm p. .
.available r. just d. jalali and m. d. ernst defects4j a database of existing faults to enable controlled testing studies for java programs in proceedings of the international symposium on software testing andanalysis.
acm pp.
.
y .
zhou s. liu j. siow x. du and y .
liu devign effective vulnerability identification by learning comprehensive program semantics viagraph neural networks in advances in neural information processing systems vol.
pp.
.
y .
zhou and a. sharma automated identification of security issues from commit messages and bug reports in proceedings of the 11th joint meeting on foundations of software engineering pp.
.
k. gallaba c. macho m. pinzger and s. mcintosh noise and heterogeneity in historical build data an empirical study of travis ci inproceedings of the 33rd acm ieee international conference on automated software engineering pp.
.
s. kim h. zhang r. wu and l. gong dealing with noise in defect prediction in 33rd international conference on software engineering icse .
ieee pp.
.