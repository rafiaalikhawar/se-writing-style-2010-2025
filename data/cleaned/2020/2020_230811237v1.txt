distinguishing look alike innocent and vulnerable code by subtle semantic representation learning and explanation chao ni school of software technology zhejiang university hangzhou zhejiang china chaoni zju.edu.cnxin yin school of software technology zhejiang university hangzhou zhejiang china xyin zju.edu.cnkaiwen yang college of computer science and technology zhejiang university hangzhou zhejiang china kwyang zju.edu.cn dehai zhao data61 csiro sydney australia dehai.zhao data61.csiro.auzhenchang xing research school of computer science australian national university and data61 csiro canberra australia zhenchang.xing anu.edu.auxin xia zhejiang university hangzhou zhejiang china xin.xia acm.org abstract though many deep learning dl based vulnerability detection approaches have been proposed and indeed achieved remarkable performance they still have limitations in the generalization as well as the practical usage.
more precisely existing dl based approaches perform negatively on prediction tasks among functions that are lexically similar but have contrary semantics provide no intuitive developer oriented explanations to the detected results.
in this paper we propose a novel approach named svuld a function level subtle semantic embedding for vulnerability detection along with intuitive explanations to alleviate the above limitations.
specifically svuld firstly trains a model to learn distinguishing semantic representations of functions regardless of their lexical similarity.
then for the detected vulnerable functions svuld provides natural language explanations e.g.
root cause of results to help developers intuitively understand the vulnerabilities.
to evaluate the effectiveness of svuld we conduct large scale experiments on a widely used practical vulnerability dataset and compare it with four state of the art sota approaches by considering five performance measures.
the experimental results indicate that svuld outperforms all sotas with a substantial improvement i.e.
.
.
in terms of f1 score .
.
in terms of pr auc and .
.
in terms of accuracy .
besides we conduct a user case study to evaluate the usefulness of svuld for developers on understanding the vulnerable code and the participants feedback demonstrates that svuld is helpful for development practice.
xin xia is the corresponding author.
permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
copyrights for components of this work owned by others than the author s must be honored.
abstracting with credit is permitted.
to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
request permissions from permissions acm.org.
esec fse december san francisco ca usa copyright held by the owner author s .
publication rights licensed to acm.
acm isbn .
.
.
.
concepts security and privacy software security engineering .
keywords vulnerability detection developer oriented explanation subtle semantic difference contrastive learning acm reference format chao ni xin yin kaiwen yang dehai zhao zhenchang xing and xin xia.
.
distinguishing look alike innocent and vulnerable code by subtle semantic representation learning and explanation .
in proceedings of the 31st acm joint european software engineering conference and symposium on the foundations of software engineering esec fse december san francisco ca usa.
acm new york ny usa pages.
https introduction software vulnerabilities have caused massive damage to software systems and many automatic vulnerability detection approaches have been proposed to prevent software systems from severity attacks and indeed achieved promising results which can be broadly classified into two categories static analysis approaches and deep learning dl approaches .
the static analysis approaches focus on detecting type specific vulnerabilities i.e.
user after free with the help of user defined rules or patterns which highly depend on expert knowledge and have little chance to find a wider range of vulnerabilities .
the deep learning approaches benefiting from the powerful learning ability of deep neural networks aim at leveraging advanced models to capture program semantics to identify potential type agnostic software vulnerabilities.
that is these approaches automatically extract implicit vulnerability patterns from previous vulnerable code instead of requiring expert involvement which makes deep learning become a good choice to solve vulnerability detection problems.
however the existing dl based approaches still have two limitations that affect their effectiveness of generalization and the usefulness of development practice.
the first problem is that existing dl based approaches have limited ability to distinguish subtle semantic differences amongarxiv .11237v1 aug 2023esec fse december san francisco ca usa chao ni xin yin kaiwen yang dehai zhao zhenchang xing and xin xia lexically similar functions.
for a specific version of a vulnerable function the vulnerabilities are usually fixed with a few modifications to it i.e.
.
vulnerable functions can be fixed within .
within lines of code in our dataset .
the fixed functions can be conceptually treated as non vulnerable functions.
meanwhile we find that the vulnerable function and its corresponding fixed function are extremely lexically similar i.e.
fixing a vulnerability by modifying less than chars accounts for .
for .
but they have significant semantic differences i.e.
vulnerable or nonvulnerable .
ideally we expect that a good performing dl based approach can perform equally well in detecting vulnerable functions and their corresponding fixing patches.
however we find that the sota dl based approaches perform negatively on the fixed functions i.e.
non vulnerable ones and incorrectly classify the fixed version as vulnerable ones .
.
false positive .
thus it is urgently required to pay more attention to semantic differences among lexically similar functions with contrasting semantics.
the second problem is that existing vulnerability detection approaches focus on giving binary detection results i.e.
vulnerable or not and ignore the importance of providing developer oriented natural language explanations for the results.
for example what is the possible root cause of such vulnerability?
what impacts will be caused by this vulnerability?
those explanations may help developers to have a better understanding of the detected vulnerable code.
however considering the concealment of software vulnerabilities it is hard to observe two identical vulnerabilities.
it is believed that similar homogeneous vulnerabilities have similar root causes or lead to similar impacts.
intuitively we find that many publicly available developer forums i.e.
stack overflow share semantically similar problematic source code and some of the responses provide useful and understandable natural language explanations about the issues which help developers to intuitively figure out the potential root cause inside their problematic code.
to mitigate the above two limitations we propose a novel approach named svuld which is a function level subtle semantic embedding for vulnerability detection along with intuitive explanations.
it is technically based on pre trained semantic embedding as well as contrastive learning .
specifically to solve the first issue svuld adopts contrastive learning to train the unixcoder semantic embedding model in order to learn the semantic representation of functions regardless of their lexically similar information.
to address the second issue we build a knowledge based crowdsource dataset by crawling problematic codes from stack overflow and fine tune a bert question answering model on manually labeled posts to automatically extract the key information from high quality answers which can provide developers with intuitive explanations and help them to understand the detected vulnerable code.
to evaluate the effectiveness of svuld we conduct extensive experiments on widely used practical vulnerability dataset .
particularly our svuld is compared with four sota approaches i.e.
devign reveal ivdetect and linevul by five performance measures i.e.
accuracy precision recall f1 score and pr auc .
the experimental results indicate that svuld outperforms all sota baselines with a substantial improvement i.e.
.
.
in terms of f1 score .
.
in terms of pr auc and .
.
in terms of accuracy .
besides to provide developers with an intuitive 35lookup bytestring netdissect options ndo registerconstu char bs constunsignedintnlen structbsnamemem tp ......while tp bs nxt if nlen tp bs nbytes tp bs addr0 i tp bs addr1 j tp bs addr2 k memcmp constchar bs constchar tp bs bytes nlen returntp elsetp tp bs nxt tp bs addr0 i tp bs addr1 j tp bs addr2 k tp bs bytes u char calloc nlen if tp bs bytes null ndo ndo error ndo lookup bytestring calloc memcpy tp bs bytes bs nlen tp bs nbytes nlen tp bs nxt structbsnamemem calloc sizeof tp if tp bs nxt null ndo ndo error ndo lookup bytestring calloc returntp fixed cleanfunctionlookup bytestring netdissect options ndo registerconstu char bs constunsignedintnlen structenamemem tp ......while tp e nxt if tp e addr0 i tp e addr1 j tp e addr2 k memcmp constchar bs constchar tp e bs nlen returntp elsetp tp e nxt tp e addr0 i tp e addr1 j tp e addr2 k tp e bs u char calloc nlen if tp e bs null ndo ndo error ndo lookup bytestring calloc memcpy tp e bs bs nlen tp e nxt structenamemem calloc sizeof tp if tp e nxt null ndo ndo error ndo lookup bytestring calloc returntp vulnerablefunction0102031617181920242526272831323323figure an out of bounds read vulnerability cve in tcpdump explanation of the detected vulnerable code we design a qualityfirst sorting strategy to prioritize the retrieved semantic related post answers.
we conduct a user case study to evaluate whether our tool can help developers understand the problems in code intuitively and the participants feedback demonstrates the usefulness of svuld.
finally this paper makes the main contributions as below we propose svuld a novel function level approach for vulnerability detection with intuitive explanations based on the pre trained semantic embedding model which leverages contrastive learning technology to obtain the distinguishing semantic representations among lexically similar functions.
we comprehensively investigate the effectiveness of svuld on vulnerability detection and the generalization of fixed functions.
the experiment results indicate that svuld outperforms sotas with a substantial improvement e.g.
.
.
in terms of f1 score .
.
in terms of pr auc .
especially svuld has better generalization performance on fixed functions e.g.
.
.
in terms of accuracy .
to the best of our knowledge we are first to provide an intuitive explanation of the results given by a vulnerability detection approach and a user case study confirms the feasibility of intuitively explaining the results with crowdsourced knowledge.
motivating example functions usually consist of several lines of code for implementing a specific program semantic i.e.
functionality and we use different labels i.e.
vulnerable non vulnerable to describe the security status of functions.
a vulnerable function includes security defects e.g.
cwe out of bounds read in its codes while a non vulnerable function is clean.
a fixed function previously contains vulnerable codes but these codes have been fixed with some modifications on the vulnerable code snippets.
therefore the fixed functions can be conceptually treated as non vulnerable functions.
fig.
shows two versions the left one is for the vulnerable version while the right one is for the non vulnerable version of a specific function in tcpdump project .
this function containsdistinguishing look alike innocent and vulnerable code... esec fse december san francisco ca usa a typical out of bounds read vulnerability cve .
the if condition statement does not detect the length of the address at line .
comparing the left vulnerable one with the right nonvulnerable fixed one we find that the two versions are lexically similar but have distinguishing semantic differences from the security perspective which is not an accidental phenomenon.
we conduct statistical analysis about the vulnerable functions as well as their corresponding fixed functions on the widely used dataset named big vul vulnerable functions collected by fan et al.
and find that .
vulnerable functions can be fixed within five lines of codes locs added or deleted lines and .
functions can be fixed with less than locs.
from the view of modified chars fixing a vulnerability by modifying less than chars accounts for .
chars for .
.
meanwhile a function has a ratio of no more than accounts for .
for .
between the number of modified chars and the whole number of chars.
all these statistical results indicate that the vulnerable function and the corresponding fixed function are extremely lexically similar.
recently benefiting from the powerful learning ability of deep neural networks many sota dl based vulnerability detection approaches e.g.
devign reveal ivdetect and linevul have been proposed to capture program semantics in order to identify potential software vulnerabilities and these approaches have achieved promising performance.
ideally a goodperforming dl based approach is expected to have a good generalization ability which means that the approach should work well on both vulnerable and corresponding fixed non vulnerable functions.
however a large scale experiment on big vul shows that all these sota approaches have negative performance on predicting the fixed functions i.e.
non vulnerable ones .
specifically they incorrectly classify the fixed functions as vulnerable ones .
.
false positive cf.
section .
for details .
meanwhile almost all existing vulnerability detection approaches focus on classifying whether a function is vulnerable but do not provide developer oriented natural language explanations to help developers understand the detected vulnerable code.
for example what is the possible root cause of such vulnerability?
what impacts will be caused by this vulnerability?
such types of explanations may at least intuitively help developers to have a deeper understanding of the detected vulnerable code.
intuitively many publicly available user forums i.e.
stack overflow share similar problematic source code and their corresponding responses may provide useful and understandable natural language explanations about the issues which can intuitively help developers to figure out the potential root cause inside the vulnerable code.
as shown in fig.
this code snippet has a similar root cause with the vulnerable function in fig.
.
it crashes because of the limited size of defined arrays i.e.
teams and wongames which results in an out of bounds error when reading and writing content to the last element.
similarly the function in fig.
will crash when the last element in their address array does not satisfy the length of a legal internet address.
if developers are provided with a natural language explanation of the root cause referring to the answer in fig.
the problem in fig.
will be easier to solve.motivating.
two code snippets may be lexically similar but have distinct security semantics vulnerable or non vulnerable which needs to embed their semantic difference in a better way.
meanwhile similar vulnerabilities may have a similar root cause which can help participants understand the problematic codes better.
stringteams for a a a printf what is team d s name?
a teams getline answer odd runtime error in c?forsomereasonikeepgettinganoddruntimeerrorwhenirunthisprogram.itcompilesfine andmostoftheprogramworks.
include...... main printf this program will show you the scores of the basketball games for season.
n printf what is the name of the basketball league?
stringleague getline printf how may games were played by the group?
intgamesplayed getinteger stringteams intwongames a b c for a a a printf what is team d s name?
a teams getline for b b b printf how many times did team swin?
teams wongames getinteger printf n n n league printf team name games played games won percentage for c c c doublepercent wongames gamesplayed printf s d d lf teams gamesplayed wongames percent products search... theproblemseemstobewithprintingteams inthelastforloop.nomatterwhati root causeyouaregoingoutofbounds sinceteamshassize3andawilleventuallygetthevalue3.indexingstartsfrom0tosizeofarray .solutionsochange4with3 orincreasethesizebyone.dothesameforwongames.similarly theloopwiththecountercshouldbemodifiedtoo ifthesizeofthearrayisnotincreased .
homepublicquestionstagscompaniescollectivesexplorecollectivesteamscreatefreeteam figure a simple but similar problematic code along with an accepted answer in stack overflow.
our approach svuld to investigate the feasibility of our intuitive hypothesis we propose a novel framework named svuld which integrates software vulnerability detection and intuitive natural language explanation.
as illustrated in fig.
svuld consists of two main phases training phase where the vulnerability detector is trained on the highquality dataset and vulnerability explainer is constructed on crowdsourced knowledge inference phase where a specific function is classified as vulnerable or not by the trained vulnerability detector and provide several developer oriented explanations to the detected vulnerable function.
we present the details of svuld in the following subsections.esec fse december san francisco ca usa chao ni xin yin kaiwen yang dehai zhao zhenchang xing and xin xia flattenedastt00...... t1unixcoder pre trainedwithcontrastivelearning 12m 1mt2tm 1tm te......functionpost content crowdsourcedknowledgeexplainableknowledge extractorvulnerability explainer post codeanswerrootimpactsolution vulnerability detector function vulnerability detectorvulnerability explainerrootimpactsolution developer oriented outputsnon vulnerablevulnerabletrainingphase inference phaseresponse content key knowledgesbert qape figure the framework of svuld.
.
vulnerability detection in order to discriminate the semantic difference among lexically similar functions effectively svuld adopts contrastive learning framework with the pre trained model unixcoder as the semantic encoder.
the architecture for contrastively training the unixcoder based semantic embedding model is illustrated in fig.
.
contrastive learning is a kind of deep neural network training process that takes paired functions as input and uses the similarity between the paired functions as labels.
the training objective of contrastive learning is to learn whether two functions are semantically similar regardless of their lexical similarity.
elaborately the contrastive learning framework utilizes the encoder to embed source code into their semantic representations i.e.
hidden vectors and aims at minimizing the distance between similar functions while maximizing the distance between dissimilar functions.
there are two important components of the proposed model an encoder for embedding functions semantics and a learning strategy for discriminating differences.
.
.
semantic encoder.
considering many successful applications of pre trained models in software engineering e.g.
defect prediction and code summarization especially the recent work on vulnerability detection we leverage unixcoder as our semantic encoder.
it is a unified cross modal i.e.
code comment and abstract syntax tree ast pre trained model for programming language and utilizes mask attention matrices with prefix adapters i.e.
to control the behavior of the model i.e.
encoder only decoder only or encoder decoder .
for each input function unixcoder encodes the ast of it into a sequence while retaining all structural information of the tree.
meanwhile in our binary classification setting we set as and fine tune it on our studied datasets to learn a better representation of source codes semantic information.
.
.
semantic difference learning.
our goal is to discriminate the semantic difference among lexical similar functions which is consistent with the target of contrastive learning.
that is minimize the distance between similar objects i.e.
the function in our study while maximizing the distance between dissimilar objects.
hofferet al.
proposed the triplet network for contrastive learning which requires a triplet f p n as the input where fcorresponds to the original source code of the function prefers to the positive equivalent of f andnis the negative one.
in our work for a given functionfin the training data its positive functions are the varying representation of the same functions and the negative functions are functions that are different from the given one.
therefore with a good semantic presentation similar functions stay close to each other while dissimilar ones are far apart.
fig.
shows the architecture of the contrastive learning used in this work in which the unixcoder is the base model for semantic embedding.
we use a pooling layer to connect the unixcoder model and the triple network.
the triple network has two layers.
the first layer is three identical deep neural networks for feature extraction of input functions which can be easily replaced with other semantic learning models.
the second layer of the triplet network is a loss function based on the cosine distance operator with transformation operations of projector which is used to minimize the distance between similar functions and maximize the distance between dissimilar functions.
the training objective is to fine tune the network so that the distance between the functions fand the positive functions pis closer than the distance between the functions fand the negative functions n which is illustrated below max ef ep ef en whereef ep andenare the semantic embeddings of function s p andnrespectively.
is the margin of the distance between s andn.
by default is set to which means the cosine distance between a function and its irrelevant function should be .
.
vulnerability explanation vulnerability explanation aims to provide developer oriented natural language descriptions for problematic source code which involves two aspects building a code related crowdsourced knowledge database and extracting key aspects for understanding vulnerable functions.distinguishing look alike innocent and vulnerable code... esec fse december san francisco ca usa functionfencoder batchcontrastiveloss encoderencoderprojectorprojectorprojectorg e g g e e efepensim ef ep sim ef en cos funcfpositiveequivalentfuncpnegativeirrelevantfuncn...... figure architecture for contrastively training unixcoder based semantic embedding model .
.
crowdsourced knowledge database.
this phase aims at managing diverse and useful information from developer forums i.e.
stack overflow since the developer forums provide a lot of information in the form of question and answer q a about usually problematic codes.
meanwhile users can also vote on the answers to distinguish the value of the questions and the corresponding answers.
in our knowledge database we focus on two objects questions posts about a technical problem and answers for solving this problem.
for a question post it usually contains a title for concisely describing a problem the details of the question the source codes involved as well as an optional tag.
for an answer it has a label to indicate whether it is a suggested one.
meanwhile the answer may give a detailed description about why it arises the problem where the root cause exists and how to solve it especially for the suggested one .
the descriptions are usually presented in the form of natural language while the code presents the potential correctness solutions.
the solution does not always work successfully for each user who is facing a similar problem because of environmental differences.
however an explanation of problematic codes will inspire other users who encounter similar problems to understand the root cause.
additionally we connect posts with the same tags for retrieving answers more efficiently in the next phase i.e.
results explainer as this process can fuse related posts with relevant problems.
.
.
result explainer.
the crowdsourced code knowledge database helps to fuse useful information when addressing similar problems while the result explainer aims at both retrieving relevant questions posts involving similar source codes and extracting key aspects of the problems from the suggested answers.
the first step is to figure out the most especially semantically relevant source codes explicitly.
in this paper for retrieving the most semantically similar problematic functions we adopt unixcoder to obtain semantic embedding of functions since the model has been well pre trained with contrastive learning technology.
additionally for a given retrieved post there usually exists many responses from different users with varying experiences.
all the diverse responses can be useful since different developers may give their responses in different development environments i.e.
issues that occurred in windows os or linux os .
therefore apart from retrieving similar problematic functions we also design an effectivequality first sorting strategy as follows to prioritize the most useful response explanation.
rankingscore func sim scorei n j 1scorej asps.
asps.
.
i cau.
.
i imp.
.
i sol.
.
i acpt.
wherefunc simrepresents the similarity between the code in a given post and the vulnerable function scoreimeans the score of an answeriin a post which is voted by users.
a high score usually reflects the high quality of the answer.
nrepresents the number of answers in the given post and i is an indicator function.
it equals if the condition is satisfied else it equals .
for example i cau.
equals when the answer contains the root cause description to explain a problem.
in addition it is possible that the root cause cau.
the impact imp.
and the potential solution sol.
provide different information for developers to understand the problems in codes.
therefore we assign different weights to indicate their priority.
finally if an answer is marked as accept acpt.
it means the answer has high quality for solving the problem and we take it into consideration and assign the weight to .
.
the second step is to extract the key aspects for understanding the problem.
as introduced in the crowdsourced knowledge database the suggested answer may contain a detailed description that explains key aspects e.g.
root cause impact solution etc.
of the problem in source codes.
in our explanation model we focus on the following three aspects root cause impact and solution which are usually long clauses or sentences.
to extract the root cause impact and solution we leverage the bert based question answering model which is based on a pre trained bert model for retrieving questions and answers in a given content scope.
the input of the model includes a question and the scope for answering the question.
the model outputs the start and end word index as the answer clause.
in our application of bert qa we adopt the content of a suggested answer as the scope of question answering and we input three what is questions i.e.
what is root cause what is impact and what is the solution into the model to find corresponding answers.
benefiting from the language modeling capability of bert bert qa can handle complex clauses of the root cause impact and solution and select the most appropriate information from the long response texts.
we train the bert qa model with question answer pairs of reasons of impacts and of solutions which is constructed manually from posts answers in stack overflow.
we build both positive and negative questions for which the answers can or cannot be found in the given posts.
the negative questions help the model to learn when it fails to find any answer in the scope.
this characteristic is extremely important for extracting the root cause impact and solution since not all posts exactly and completely describe all three aspects.
otherwise the bert qa model will have no ability to handle negative questions and extract some irrelevant content as the answer for a question.
experimental design in this section we first present features of the studied datasets and then introduce the baseline approaches.
following that we describe the performance metrics as well as the experimental settings.esec fse december san francisco ca usa chao ni xin yin kaiwen yang dehai zhao zhenchang xing and xin xia .
datasets vulnerability dataset .
we use the benchmark dataset provided by fan et al.
due to the following reasons.
the first one is to establish a fair comparison with existing approaches e.g.
ivdetect linevul .
the second one is to evaluate whether existing approaches have a good generalization performance on detecting the fixed functions since fan et al.
s dataset is the only one vulnerability dataset that provides the fixed version of vulnerable functions.
the last one is to satisfy the distinct characteristics of the real world as well as the diversity in the dataset which is suggested by previous works .
fan et al.
built the large scale c c vulnerability dataset named big vul from common vulnerabilities and exposures cve database and open source projects.
big vul totally contains code vulnerabilities collected from open source projects spanning different vulnerability types from to .
it has c c functions with a vulnerable ratio of .
i.e.
vulnerability functions .
the authors linked the code changes with cves as well as their descriptive information to enable a deeper analysis of the vulnerabilities.
in our work some baselines need to obtain the structure information e.g.
control flow graph cfg data flow graph dfg of the studied functions.
therefore we adopt the same toolkit with joern to transform functions.
the functions are dropped out directly if they cannot be transformed byjoern successfully.
we also remove the duplicated functions and the statistics of the studied dataset are shown in table .
table the statistic of studied dataset datasets vul.
non vul.
total vul.
non vul.
original big vul .
filtered big vul .
training validating .
testing .
crowdsourced dataset .
apart from the widely used vulnerability dataset we also need to build a crowdsourced dataset manually in order to provide explanations for the detected vulnerabilities.
in this paper we crawl posts as well as their answers from stack overflow where the posts are labeled with c or c and there is at least one code snippet in their content.
finally we obtain posts with answers which are further used to build a knowledge database.
.
baselines to comprehensively compare the performance of svuld with existing work in this paper we consider the four sota approaches devign reveal ivdetect and linevul .
we briefly introduce them as follows.
devign proposed by zhou et al.
is a general graph neural network based model for graph level classification through learning on a rich set of code semantic representations including ast cfg dfg and code sequences.
it uses a novel conv module to efficiently extract useful features in the learned rich node representations for graph level classification.reveal proposed by chakraborty et al.
contains two main phases feature extraction and training.
in the former phase reveal translates code into a graph embedding and in the latter phase reveal trains a representation learner on the extracted features to obtain a model that can distinguish the vulnerable functions from non vulnerable ones.
ivdetect proposed by li et al.
involves two components coarse grained vulnerability detection and fine grained interpretation.
as for vulnerability detection they process the vulnerable code and the surrounding contextual code in a function distinctively which can help to discriminate the vulnerable code and the benign ones.
in particular ivdetect represents source code in the form of a program dependence graph pdg and treats the vulnerability detection problem as graph based classification via graph convolution network with feature attention.
as for interpretation ivdetect adopts a gnnexplainer to provide fine grained interpretations that include the sub graph in pdg with crucial statements that are relevant to the detected vulnerability.
linevul proposed by fu et al.
is a transformer based linelevel vulnerability prediction approach.
linevul leverages bert architecture with self attention layers which can capture long term dependencies within a long sequence.
besides benefiting from the large scale pre trained model linevul can intrinsically capture more lexical and logical semantics for the given code input.
moreover linevul adopts the attention mechanism of bert architecture to locate the vulnerable lines for finer grained detection.
.
evaluation measures to evaluate the effectiveness of svuld on vulnerability detection we consider the following five metrics accuracy precision recall f1 score and pr auc.
accuracy evaluates the performance that how many functions can be correctly labeled.
it is calculated as tp tn tp fp tn fn.
precision is the fraction of true vulnerabilities among the detected ones.
it is defined as tp tp fp.
recall measures how many vulnerabilities can be correctly detected.
it is defined as tp tp fn.
f1 score is a harmonic mean of precision andrecall and can be calculated as p r p r. pr auc is the area under the precision recall curve and is a useful metric of successful prediction when the class distribution is very imbalanced .
the precision recall curve shows the tradeoff between precision and recall for different thresholds.
a high area under the curve indicates both high recall and high precision where high precision corresponds to a low false positive rate and high recall corresponds to a low false negative rate.
.
experimental setting we implement our vulnerability detection and explanation model svuld in python with the help of pytorch framework.
besides we utilize unixcoder base nine from huggingface as our basic model which is a pre trained model on nl pl pairs of codesearchnet dataset and additional .5m nl pl pairs of c c and c programming language.
we fine tune svuld on the studied datasets to obtain a set of suitable parameters for the vulnerabilitydistinguishing look alike innocent and vulnerable code... esec fse december san francisco ca usa detection task and fine tune bert qa model on the manually labeled question answer datasets.
all the models are fine tuned on four nvidia geforce rtx graphic cards.
during the training phase we use adam with a batch size of to optimize the parameters of svuld.
we also leverage gelu as the activation function.
a dropout of .
is used for dense layers before calculating the final probability.
we set the maximum number of epochs in our experiment as and adopt an early stop mechanism to obtain good parameters.
the models i.e.
svuld and baselines with the best performance on the validation set are used for the evaluations.
experimental results to investigate the feasibility of svuld on software vulnerability detection and detection result explanation our experiments focus on the following four research questions rq .to what extent can the function level vulnerability detection performance svuld achieve?
rq .how does the paired instance building strategy impact the performance of svuld?
rq .how does the size of paired instance impact the performance of svuld?
rq .how well does svuld perform on explaining the detection results?
in rq1 we aim to investigate the performance of the svuld on vulnerability detection by considering it with sota baselines cf.
section .
.
in rq2 and rq3 we explore the impact of design options of contrastive learning on the performance of svuld cf.
section .
.
.
in rq4 we explore the svuld s usefulness for helping developers understand vulnerable functions cf.
section .
.
.
effectiveness on vulnerability detection.
objective.
benefiting from the powerful representation capability of deep neural networks many dl based vulnerability detection approaches have been proposed .
however as vulnerable functions are usually fixed with a few modifications .
vulnerable functions can be fixed within .
for lines of codes they have subtle lexical differences with the non vulnerable functions.
existing sota deep learning approaches i.e.
devign reveal ivdetect etc.
cannot perform well on the fixed functions nonvulnerable .
the main reason falls into the limitations of effective semantic embedding among lexical similar functions.
in this paper we propose a novel approach svuld which is built on a contrastive learning framework with a pre trained model as a semantic encoder as suggested by previous work .
the experiments are conducted to investigate whether svuld outperforms sota function level vulnerability detection approaches.
experimental design.
we consider the four sota baselines devign reveal ivdetect and linevul .
these approaches can be divided into two categories gnn based one i.e.
devign reveal andivdetect and pre trained based one i.e.
linevul .
besides in order to comprehensively compare the performance among baselines and svuld we consider five widely used performance measures and conduct experiments on the popular dataset.
since gnn based approaches usually need to obtain the structure information of the function e.g.
cfg dfg we adopt thesame toolkit with joern to transform functions.
finally the filtered dataset shown in table is used for evaluation.
we follow the same strategy to build the training data validating data and testing data from the original dataset with previous work does .
specifically of functions are treated as training data of functions are treated as validation data and the left of functions are treated as testing data.
we also keep the distribution as same as the original ones in training validating and testing data.
meanwhile for a specific function svuld needs to select appropriate positive instances and negative instances.
for the positive instances we adopt the different embedding vectors of the same function by randomly dropping out some weights in the network of the semantic encoder.
for the negative instances we consider all the other instances i.e.
functions in the same mini batch with the given instance and use the average semantic vector representation.
we consider three types of paired instances selection strategies i.e.
simcl simdfe andr drop .
cf.
section .
and in this rq we adopt the r drop strategy since it has overall best performance.
finally since our target is to build an effective vulnerability detection model especially for discriminating lexically similar but semantically distinct functions we further conduct an analysis on how svuld performs on the fixed version of vulnerable functions in the testing dataset.
table vulnerability detection results of svuld compared against four baselines.
methods f1 score recall precision pr auc devign .
.
.
.
reveal .
.
.
.
ivdetect .
.
.
.
linevul .
.
.
.
svuld .
.
.
.
improv.
.
.
.
.
.
.
results.
the evaluation results are reported in table and the best performances are highlighted in bold.
according to the results we find that our approach svuld outperforms all sota baseline methods on almost all performance measures except recall .
in particular svuld obtains .
.
and .
in terms of f1 score precision and pr auc which improves baselines by .
.
.
.
and .
.
in terms of f1 score precision and pr auc respectively.
in terms of recall devign performs the best .
and linevul performs similarly with devign .
which means that both the pre trained model and the gnn based model can achieve better performance of recall .
the performance comparisons of svuld and four sotas on the fixed functions are presented in table .
according to table we find that all sotas have poor performance on classifying the fixed versions i.e.
the clean version in the testing dataset i.e.
vulnerable functions while svuld can achieve the best performance.
more precisely svuld can correctly classify fixed versions of functions as clean ones which outperforms devign i.e.
reveal i.e.
ivdetect i.e.
and linevul i.e.
by .
.
.
and .
respectively.
the results indicateesec fse december san francisco ca usa chao ni xin yin kaiwen yang dehai zhao zhenchang xing and xin xia enegative instancepositive instance......ebuggyfunc.cleanfunc.efunc1 b simdfefuncjbatchbuggyfunc.pfnfunci a simcl......efunc1funcjbatchfunci c r drop pfnnpfnn figure three different contrastive paired instances construction table the effectiveness of svuld compared against four baselines on fixed functions in testing dataset methods correct accuracy improv.
improv.
devign .
.
reveal .
.
ivdetect .
.
linevul .
.
svuld .
.
.
that svuld has a better representation of learning ability than the four baselines.
answer to rq svuld outperforms the sota baselines at the function level software vulnerability detection.
particularly it achieves overwhelming results at both f1 score and pr auc which indicates that svuld equipped with contrastive learning as well as pre trained model has a stronger ability to learn the semantics of functions especially for those functions with lexical similarity but have distinct semantics.
.
impacts of contrastive paired instances construction.
objective.
the contrastive learning framework needs to build triplet paired instances which are used to measure how close the two similar instances are and how far the two dissimilar instances are.
therefore it is important to conduct a study on how the constructed positive instances and negative instances of a given function affect the learning of semantic representation.
experimental design.
we consider three types i.e.
simcl simdfe andr drop of paired instances i.e.
positive instances and negative instances building strategies to train our proposed approach svuld.
the differences among these strategies are illustrated in fig.
and we introduce them in detail as follows.
simcl simple contrastive learning means building the negative instance of a vulnerable function with its corresponding fixed version.
for its positive equivalent function we input the original function twice into the same encoder with different weights i.e.
dropout used as noise inside the model and obtain two embedded vectors.
the two vectors are interchangeably treated as positive instances.
simdfe simple duplicate function embedding means inputting all functions noted as f1 f2 fn nis the size of batch in a batch twice into the same encoder with different weights whichis inspired by .
that is each function will have two embedded vectors noted as f11 f12 f21 f22 fn1 fn2.
takef1as an example f11andf12are interchangeably treated as positive instances and fijare treated as negative instances where i andj .
we use the average difference between f1and all negative instances as their dissimilarity.
r drop random dropout means to input one function noted asf1 f2 fn nis the size of batch in a batch twice and the rest function in the same batch once into the same encoder.
for the given function embedded with an encoder twice we adopt the random dropout operation to the network to obtain the equivalent positive embedding.
take f1as an example f11andf12are interchangeably treated as positive instances and fi i are treated as negative instances.
we use the average difference between f1with all negative instances as their dissimilarity.
the experimental dataset is set the same as the experiment of rq1 i.e.
for training for validating and for testing .
we also consider the five performance measures i.e.
precision recall f1 score pr auc and accuracy for comprehensively studying the impact of different paired instances building strategies.
additionally in this study we set the batch size nas .
table the performance difference among three different paired instances construction strategies strategytesting data fixed function f1 score recall precision pr auc num accuracy svuld .
.
.
.
.
svuldsimcl .
.
.
.
.
svuldsimdfe .
.
.
.
.
svuldr drop .
.
.
.
.
improv.
.
to .
.
to .
.
to .
.
to .
results.
the comparison results are reported in table and the best performances are highlighted in bold for each performance measure.
according to the results we can obtain the following observations all paired instance construction strategies have the advantage of learning function semantic embedding in the scenario of vulnerability detection.
particularly simcl simdfe andr drop improve the baseline unixcoder without contrastive learning by .
.
.
.
.
.
and .
.
in terms of f1 score precision pr auc and accuracy.
the simdfe performs better than the simcl and the r drop is the dominated one among the three strategies.
the simcl performsdistinguishing look alike innocent and vulnerable code... esec fse december san francisco ca usa figure the varying performance of svuld with different batch size worse than the other two strategies and the main reason may come from the small size of negative instances i.e.
only one negative instance which limits the information for svuld to discriminate the difference between positive instances and negative instances.
the contrastive learning strategy to some degree can decrease the performance of recall .
however it has an improvement on two comprehensive performance measures i.e.
f1 score andpr auc especially for distinguishing two lexically similar functions with distinct semantics i.e.
an improvement on accuracy .
answer to rq all paired instance construction strategies present their own advantages in learning function semantic embedding and the r drop strategy performs the best.
.
impacts of paired instances size.
objective.
in rq we find that the number of negative instances has an impact on svuld s performance of learning semantic embedding.
therefore we want to conduct a deeper experiment on how the batch size i.e.
the number of negative instances impacts the performance of svuld on discriminating dissimilar instances from similar ones.
experimental design.
according to rq we find that the rdrop strategy has an overall better performance than the others.
meanwhile considering the fact that the larger the batch size is the more memory svuld consumes we re run svuld with r drop strategy on the following varying settings of batch size and .
because of the limitation of graph memory i.e.
four nvidia rtx and the size of functions we cannot perform larger batch sizes i.e.
or .
besides the experimental dataset is set as same as that in previous rqs.
we evaluate the performance of svuld on testing data with two comprehensive performance measures i.e.
f1 score and pr auc and we adopt accuracy to evaluate the performance on the fixed version of vulnerable functions.results.
the evaluation results of svuld with varying batch size are illustrated in fig.
.
according to the results we have the following research findings different number of negative instance has varying impact on svuld s performance.
almost all the metrics of svuld except accuracy go up with the increasing of negative instances when batch size is no larger than .
when batch size equals all the performances drop to different degrees.
larger batch size may not lead to better performance and assigning a batch size of is a good choice.
answer to rq the number of negative instances has an impact on svuld s performance and the larger number may not always guarantee better performance.
in our setting a median size i.e.
is more appropriate.
.
usefulness for developers.
objective.
though many novel approaches have been proposed and indeed achieved remarkable performance existing methods cannot provide a developer oriented natural language described explanation.
for example what is the possible root cause of such vulnerability?
such types of explanations may at least intuitively help developers understand the identified vulnerability better.
however considering the concealment of software vulnerabilities we cannot observe two identical vulnerabilities.
it is possible that similar homogeneous vulnerabilities have similar root causes or lead to similar impacts.
meanwhile many publicly available developer forums i.e.
stack overflow share similar problems and their responses may provide understandable natural language explanations about the issues.
therefore we want to further utilize this useful and diverse information to provide participants with detailed explanations about the identified problematic codes.
experimental design.
we first crawl posts labeled with c c from stack overflow and build a database cf.
section .
to fuse all crowdsourced knowledge for retrieving important explainable information.
considering that our work focuses on code related problems we filter those posts with no code snippet in their post content since the code snippet is the critical connective element when retrieving similar problematic codes.
in addition for retrieving the most semantically similar problematic functions we adopt svuld to obtain semantic embedding of both vulnerable function and code snippet in post since our model has been well pre trained with contrastive learning technology.
then we adopt the designed quality first sorting strategy cf.
section .
to prioritize the retrieved answers.
finally the well pre trained bert qa model cf.
section .
is adopted to extract three optional important descriptions i.e.
root cause impact and solution inside the answer.
finally we randomly select vulnerable functions in testing datasets and invite developers from a prominent it company who have to years of experience in software security as our participants.
each developer is asked to finish an experiment task that includes two vulnerable functions as well as their corresponding explanation recommended by svuld.
we evaluate the usefulness of our approach by analyzing the answers to the following questions given by participants.
more precisely svuld presents each vulnerable function with five retrieved answers from crowdsourced knowledge.esec fse december san francisco ca usa chao ni xin yin kaiwen yang dehai zhao zhenchang xing and xin xia a devign b reveal c ivdetect d linevul e unixcoder f svuld figure visualization of the separation between vulnerable denoted by and non vulnerable denoted by .
q1 is the explanation related to the vulnerable function?
q2 is the explanation comprehensive i.e.
the root cause the impacts and the suggestion.
score low middle high ?
which part is most important?
q3 is the explanation useful to understand the vulnerability?
q4 in which result do you find the most desired answer?
score means no desired answer.
q5 please sort the explanations according to their usefulness.
for q1 and q2 we aim to verify the relatedness and comprehensiveness of svuld s recommendation.
for q3 and q4 we aim to evaluate the usefulness of svuld and q5 is designed to evaluate the difference between the recommendations and developers expectations.
results.
in q1 except for negative responses i.e.
providing unrelated explanations responses are positive to indicate the relatedness of recommended posts.
in q2 the majority i.e.
with larger than agrees that svuld s recommended posts provide the reasons root cause for problematic codes.
besides all responses i.e.
are positive with the suggestion .
however about half of the participants give less than scores to the impacts of problematic code which is consistent with our manually labeled data the impacts of problematic code have the least number .
meanwhile everyone believes that giving the explanation of root cause is most important for explaining a problematic code.
in q3 participants agree that the explanation extracted by svuld can help them intuitively understand the vulnerable code and the remaining responses have negative feedback which also confirms the concealment of vulnerability.
in q4 we find that responses rank at top for top for top and for top and responses are scored with which means that none of the recommended explanations are related to the vulnerable function.
finally in q5 we use mean average precision map to qualify the gap between our recommendation and developers expectations.
we get .
of map which means svuld to some degree can give an acceptable recommendation list.
we analyze the negative responses about svuld and find that the biggest problem falls into the completeness of our dataset as svuld cannot find the most semantic similar problematic codes with vulnerable functions in the built dataset i.e.
similarity .
.
answer to rq our user study reveals to some extent that svuld presents the potential feasibility of assisting developers to intuitively understand the detected vulnerability.
discussion this section discusses open questions regarding the performance and threads to the validity of svuld.
.
why svuld outperforms existing baselines?
dl based vulnerability detection approaches have a strong ability to learn a feature representation to distinguish vulnerable functions and non vulnerable ones.
therefore the efficacy of the models vulnerability detection depends largely on how separable the feature representation of the two types of functions i.e.
vulnerable and non vulnerable are.
the greater the separability of the two functions the easier it is for a model to distinguish between them.
we adopt principal components analysis pca to inspect the separability of the studied models.
pca is a popular dimensionality reduction technique and is suited for projecting the original feature embedding into two principal dimensional embeddings.
besides we randomly sample the same number of non vulnerable functions with vulnerable functions in the testing dataset for more clear visualization.
fig.
illustrates the separability of the studied approaches.
from the visualization results fig.
a d we can see that the majority of the functions are mixed and the boundary of each function is not clear which indicates the difficulty of baselines in drawing the decision boundary.
in contrast unixcoder shown in fig.
e has better separability than baselines which indicates the large scale pre trained language model specially trained on c c codes has a stronger ability to understand the semantic of codes.
lastly fig.
f shows the separability of our svuld.
we can observe that svuld has the best performance in distinguishing vulnerable functions from non vulnerable ones.
equipped with contrastive learning svuld can learn better semantic embedding of functions.
.
threats to validity threats to internal validity mainly correspond to the potential mistakes in the implementation of our approach and other baselines.
to minimize such a threat we first implement our model by pair programming and directly utilize the pre trained models for building vulnerability detectors.
we also use the original source code of baselines from the github repositories shared by corresponding authors and use the same hyperparameters in the original papers.
the authors also carefully review the experimental scripts to ensure their correctness.
threats to external validity mainly correspond to the studied dataset.
even though we have evaluated models on those widely used vulnerability datasets in literature to ensure a fair comparisondistinguishing look alike innocent and vulnerable code... esec fse december san francisco ca usa with baselines the diversity of projects is also limited in the following aspects.
firstly all the studied projects i.e.
functions are developed in c c programming language.
therefore projects developed in other popular programming languages e.g.
java and python have not been considered.
secondly all the studied datasets are collected from open source projects and the performance of svuld on commercial projects is unknown.
thus more diverse datasets should be collected and explored in future work.
threats to construct validity mainly correspond to the performance metrics used in our evaluations.
to minimize such a threat we adopt a few performance metrics widely used in existing work.
in particular we totally consider five performance metrics including accuracy precision recall f1 score and pr auc.
related work .
ai based software vulnerability detection software vulnerability detection has attracted much attention from researchers and many dl based approaches have been proposed to automatically learn the vulnerability patterns from historical data since the powerful learning ability of deep neural networks has been verified in many software engineering scenarios e.g.
defect prediction defect repair .
dam et al.
proposed a vulnerability detector with lstmbased architecture.
russell et al.
proposed another rnn based architecture to automatically extract features from source code for vulnerability detection.
however these approaches assume source code is a sequence of tokens which ignores the graph structure of the source code.
therefore li et al.
sequentially proposed two slice based vulnerability detection approaches vuldeepecker and sysevr to learn the syntax and semantic information of vulnerable code.
following that many graph neural network gnn based models are proposed.
cheng et al.
proposed deepwukong by embedding both textual and structural information of code into a comprehensive code representation.
wang et al.
proposed funded by combining nine mainstream graphs.
cao et al.
proposed mvd to detect finegrained memory related vulnerability.
apart from the coarse grained models e.g.
function level researchers also proposed many fine grained models.
li et al.
proposed vuldeelocator by adopting a program slicing technique to narrow down the scope of vulnerability prone lines of code.
fu et al.
proposed linevul by leveraging the attention mechanism inside the bert architecture for line level vulnerability detection.
hin et al.
proposed linevd to formulate statement level vulnerability detection as a node classification task.
different from previous work our paper focuses on the effective semantic embedding of functions especially those that are lexically similar.
.
interpretation for ai based software vulnerability detection developing explainable models is one of the ways for vulnerability detection which could provide a fine grained vulnerability prediction outcome.
specifically many works have attempted to detect line level information by leveraging explainable ai for software engineering tasks such as detecting source code lines for defectprediction .
this raises the importance of research for interpretable ai based models.
however existing studies are limited to providing partial information for the explanation generation.
zou et al.
introduced a high fidelity token level explanation framework which aims at identifying a small number of tokens that make significant contributions to a detector s prediction.
li et al.
proposed vuldeelocator to simultaneously achieve high detection capability and high locating precision and it explains detection results at intermediate code.
ding et al.
proposed a statement level model via localizing the specific vulnerable statements with the assumption of receiving vulnerable source codes at the function level.
li et al.
adopted explainable gnn to propose ivdetect and provided finegrained interpretations.
fu et al.
proposed a transformer based line level model named linevul and leveraged the attention mechanism of bert architecture to explain the vulnerable code lines.
recently sun et al.
conducted the first research work on the application of explainable ai in silent dependency alert prediction which opens the door to the related domains.
different from existing works that focus on explaining why aimodels give out the predicted results our paper aims at making an explanation for the detected results by providing a develop oriented natural language described explanation in order to heuristically help developers understand the root cause of the detected vulnerabilities.
conclusion and future work this paper proposes a novel approach svuld which is a functionlevel subtle semantic embedding for vulnerability detection along with heuristic explanations technically based on pre trained semantic embedding as well as contrastive learning.
svuld firstly adopts contrastive learning to train the unixcoder semantic embedding model for learning distinguishing semantic representation of functions regardless of their lexically similar information.
svuld secondly builds a knowledge based crowdsource dataset by crawling problematic codes in stack overflow to provide developers with heuristic explanations of the detected problematic codes.
the experimental results show the effectiveness of svuld by comparing it with four sota deep learning based approaches.
our future work will investigate the generalization of contrastive learning to existing deep learning approaches for vulnerability detection.
data availability the replication of this paper is publicly available .