growing a test corpus with bonsai fuzzing vasudev vikram university of california berkeley berkeley ca usa vasumv berkeley.edurohan padhye carnegie mellon university pittsburgh pa usa rohanpadhye cmu.edukoushik sen university of california berkeley berkeley ca usa ksen cs.berkeley.edu abstract this paper presents a coverage guided grammarbased fuzzing technique for automatically synthesizing a corpus of concise test inputs.
we walk through a case study of a compiler designed for education and the corresponding problem of generating meaningful test cases to provide to students.
the prior state of the art solution is a combination of fuzzing and test case reduction techniques such as variants of deltadebugging.
our key insight is that instead of attempting to minimize convoluted fuzzer generated test inputs we can instead grow concise test inputs by construction using a form of iterative deepening.
we call this approach bonsai fuzzing .
experimental results show that bonsai fuzzing can generate test corpora having inputs that are smaller in size on average as compared to a fuzz then reduce approach while achieving approximately the same code coverage and fault detection capability.
index terms test case generation grammar based testing fuzz testing small scope hypothesis test case reduction i. i ntroduction this paper describes a new technique for automatically generating a concise corpus of test inputs having a welldefined syntax and non trivial semantics e.g.
for a compiler .
this project originated when the authors were faced with the task of generating a test corpus for use in an undergraduate compilers course.
the course project targets the chocopy programming language .
chocopy is a statically typed subset of python designed specifically for education.
in a chocopybased course students are expected to build a compiler in java that statically checks and then translates chocopy programs to risc v assembly.
student projects can be autograded by comparing their compilers output at various stages parser type checker and code generator with the corresponding output produced by a reference implementation.
when starting their project students are provided with a suite of chocopy test programs and the autograder which together serve as a partial executable specification.
this workflow simulates test driven development while also enabling students to continuously get feedback about their progress.
for instructors writing test cases to validate every language feature is a tedious task we wanted to automatically synthesize such a test corpus.
this paper describes the technique we developed for this purpose.
in particular we focus on the problem of automatically generating test cases that exercise the typechecker since generating well typed programs is known to be a difficult problem .
this task presents two conflicting challenges the generated test suite must be comprehensive in covering variousf2 f2 1f2 2f1 f2 1f1 1f1 f1 fig.
.
an example bonsai fuzzing architecture a lattice of coverage guided size bounded grammar based fuzzers fm n d ordered by three size bounds on the syntax of the test cases they produce number of unique identifiers m maximum sequence length n and maximum nesting depth d. test cases flow along directed edges the inputs generated by each fuzzer are used as the seed inputs to its successors.
the result of bonsai fuzzing is the corpus produced by the top most element.
semantics of the language including corner cases the test suite must be concise and readable in particular each test case should be small in size so that test failures can guide students towards identifying which feature was incorrectly implemented.
the conflict is apparent from previous work which indicates that automated test generation for covering difficult program branches works better with larger test cases.
much work has been done on automatically generating concise and comprehensive unit test suites .
however this work mainly focuses on generating test code as sequences of method calls while minimizing the number of test cases or size of the entire test suite.
our goal is to generate non trivial testinputs e.g.
strings while minimizing the individual size of each test case on average.
this is because our conciseness goals are related to readability and debuggability rather than reducing the cost of test execution .
the state of the art in concise automatic test case generation for structured input domains such as compilers is as follows first perform some form of random fuzzing to automatically discover unexpected or coverage increasing inputs.
then perform test case reduction on every fuzzersaved input in order to find a corresponding locally minimal input that causes the test program to exhibit the same behavior.
for example csmith and c reduce complement each other by respectively generating and minimizing c programs for automated testing of c compilers.
by their very nature fuzzer generated inputs exercise program features chaotically.
this can make isolating the most ieee acm 43rd international conference on software engineering icse .
ieee significant features of a fuzzer saved test input challenging both for humans and for minimization algorithms.
further to make the test case minimization problem tractable algorithms such as delta debugging and its variants perform only local optimization.
in this paper we present bonsai fuzzing a technique for automatically generating a concise and comprehensive test corpus of structurally complex inputs.
our key insight is that instead of reducing large convoluted inputs that exercise many program features at once we can grow a concise test corpus bottom up .
bonsai fuzzing generates small inputs by construction in an iterative evolutionary algorithm the first round generates tiny trivial inputs and then each successive round generates inputs of slightly larger size by mutating inputs saved in a previous round.
in particular we first define a procedure to sample syntactically valid inputs from a grammar specification using bounds on the number of identifiers linear repetitions and nested expansions in the resulting derivation trees.
we then define a partial order over coverage guided bounded grammar fuzzers cbgfs .
for any given desired size bound this partial order results in a lattice of cbgfs.
a corpus produced by each cbgf in this lattice is used as a set of seed inputs for all successive cbgfs.
the bottom element of the lattice has minimum size bound a fuzzer with no good seed inputs and the top element has the maximum desirable size bound a fuzzer that produces the final test corpus.
fig.
visualizes bonsai fuzzing for a given size bound.
experimental results on the chocopy typechecker indicate that bonsai fuzzing produces inputs that are .
smaller than those produced by the fuzz then reduce approach while retaining .
of coverage and .
of the mutation score.
although we developed bonsai fuzzing to solve a specific problem related to the use of chocopy the technique is more generally applicable.
we report results of applying bonsai fuzzing to the google closure compiler which optimizes javascript programs bonsai fuzzing results in test corpora that are .
smaller on average than those produced by the conventional fuzz then reduce approach while achieving approximately the same code coverage.
we have made a replication package publicly available at .
ii.
b ackground and motivation a. chocopy chocopy is a statically typed subset of python .
.
it uses python s type annotation syntax but enforces static type checking.
figures and show examples of welltyped chocopy programs demonstrating a variety of language features borrowed from python.
chocopy is primarily used in undergraduate compilers courses.
for the programming assignments students implement a java based chocopy compiler whose output is compared against that produced by a publicly available reference compiler.
autograding is supported by the chocopy infrastructure out of the box.
in this paper we are interested in specifying and autograding the type checking component of1def is zero items idx int bool val int val items return val 5idx int 6print is zero idx fig.
.
chocopy program illustrating functions variables and static typing.
prints true when executed.
1class a object x int def setx self a y int self .x y def equals self a y int bool return self .x y 7a a none 8a a 9iftrue ifa.equals a.setx 12print a.x fig.
.
chocopy program illustrating classes methods objects and conditional statements.
student developed chocopy compilers on semantically valid programs their output is expected to match the type annotated asts in json format with those produced by the reference compiler on invalid programs error messages and corresponding line numbers are compared.
a comprehensive test suite therefore consists of both valid and invalid chocopy programs that exercise various aspects of the chocopy typing rules.
b. problem definition our high level goal in this paper is to automatically synthesize test cases for the chocopy typechecker that are not only comprehensive but also concise .
we expand on these primary goals as follows automatic manual test creation is cumbersome and error prone.
further we want to have the option of quickly adding and removing language features in chocopy to evolve its scope.
we therefore want a mechanism to automatically generate a test corpus given only a syntax definition i.e.
a grammar and a reference compiler implementation.
comprehensiveness we want the automatically generated test corpus to have high code coverage andfaultdetection ability .
we focus on optimizing for branch coverage in the reference compiler and also measure mutation scores where applicable.
conciseness we want to generate minimal test cases that exercise various features in the reference compiler.
we focus on optimizing for individual test case size though we also measure the size of the test corpus in number of test cases.
semantic validity we want a high fraction of semantically valid programs.
although invalid programs are necessary to cover specific aspects e.g.
error messages of the typechecker we prefer generally prefer test cases 724to be semantically valid as they are more representative examples of language features.
finally it only makes sense to invest in automation if our efforts can be applied to more than one testing target.
we therefore also add a secondary goal generalizable we would like the technique to generalize to at least one other testing target.
on the surface this seems like a standard automated testing problem.
why do we need a new technique?
we next briefly discuss prior work in the context of our application goals and why we felt the need to develop a novel solution.
iii.
c hallenges with prior solutions a. systematic testing since our goal is to generate concise test cases a natural approach to consider is simply enumerating a bounded space of inputs or program behaviors.
bounded exhaustive testing tools such as korat testera astgen and udita perform bounded exhaustive testing inputs of a bounded size are generated systematically while employing various optimizations.
these tools have been effective at generating test suites for data structure libraries for powering automatic refactoring tools etc.
unfortunately the input space of a chocopy compiler is too large to be enumerated exhaustively.
the number of unique syntactically valid programs with at most one userdefined identifier up to two statements per block and a maximum block expression nesting depth of two is more than the estimated number of atoms in the universe about .
input structure since we know the chocopy syntax we can consider systematically enumerating k paths within the chocopy grammar.
this approach yields minimal programs corresponding to each unique k length path from root to leaf in valid syntax trees.
this works really well for generating parser tests however it is not ideal for exercising the type checking and semantic analysis logic of a compiler.
for example a minimal well typed chocopy program that contains a valid method call invocation requires several syntax subtrees to ensure valid class definition valid method definition inside the class valid instantiation of an object of that class and a valid method call on this object.
this semantic feature cannot therefore be defined as a linear k path for any k. symbolic execution instead of enumerating the input space tools such as jpf se systematically explore the space of program paths using symbolic execution .
with the use of constraint solvers one could potentially generate a comprehensive test suite that covers a diverse set of program paths of bounded size assuming that execution path length correlates with input size .
however the number of program paths to explore grows exponentially with the number of branches encountered during execution .
even on the small chocopy program in fig.
the reference compiler executes conditional jumps and virtual method calls.
exhaustive symbolic execution is therefore not a practical solution even for bounded input sizes.b.
fuzz testing random test generation is an established technique for sampling complex input spaces with the hope of discovering unexpected corner cases.
the term fuzz testing or simply fuzzing is generally used for techniques that randomly generate test inputs as opposed to test code .
fuzzing is mainly used for discovering security vulnerabilities.
there are two main challenges in using fuzz testing tools for test corpus generation.
first generating a comprehensive test corpus for a compiler requires generating a diverse set of inputs satisfying complex constraints e.g.
programs should be well typed .
we therefore consider several variants of fuzzing that address effective state space exploration.
second fuzzergenerated inputs are often notoriously large and unreadable.
we thus consider some advances in making test inputs concise andsemantically valid .
coverage guided fuzzing one one extreme end coverage guided fuzzing cgf uses no knowledge of the input domain instead it instruments programs under test to analyze their run time behavior.
cgf evolves a corpus of test inputs with the goal of maximizing code coverage.
the process starts with developer provided or randomly generated seed inputs .
new inputs are created by performing random mutations on seed inputs e.g.
randomly inserting modifying or deleting bytes at randomly chosen locations .
inputs that cause the test program to cover previously uncovered code are added to the set of seeds.
the process repeats until a time budget expires.
afl and libfuzzer are popular cgf tools for finding bugs in programs that parse binary data e.g.
media players and network protocol implementations .
when applied to the chocopy compiler these tools are useful for generating tests for the frontend indeed afl helped discover some dormant bugs in the reference parser.
however these tools are ineffective at generating comprehensive tests for the type checker.
in a preliminary experiment we found that less than .
of afl generated inputs were valid chocopy programs.
this is unsurprising because random bytelevel mutations rarely lead to the generation of inputs that can satisfy syntactic and semantic constraints.
specialized compiler fuzzing on the other extreme end a highly precise compiler fuzzer can be developed by incorporating the syntax and semantics of the language in the input generation process itself.
for example csmith generates c programs while avoiding undefined behavior pa ka et al.
generate well typed lambda terms for testing the glasgow haskell compiler and dewey et al.
use constraint logic programming to test the rust type checker.
such specialized compiler fuzzers require quite a bit effort to develop and do not meet our secondary criteria of being generally applicable to multiple testing targets.
grammar based fuzzing between these extremes grammar based fuzzers offer an acceptable middle ground.
using only a declarative specification of a compiler s input grammar which is often readily available these fuzzers randomly sample syntax trees.
inputs generated in this way are guaranteed to be syntactically valid .
by enforcing bounds 725on the expansion of recursive production rules and other repeating elements the size of generated test inputs can also be controlled.
in section iv a we provide an algorithm for sampling size bounded test inputs from a context free grammar provided in an extended bnf notation.
although grammar fuzzing produces syntactically valid test inputs by construction generating inputs that are semantically valid is challenging.
for example we empirically found that the probability of a randomly sampled chocopy program of size precisely defined in section iv a being semantically valid is less than .
semantic fuzzing recently developed tools such as zest nautilus and superion combine structureaware e.g.
grammar based input generators with code coverage feedback.
the hope is that such feedback will help generate inputs that are not only syntactically valid but also exercise various code paths in the compiler corresponding to semantic checks.
in fact zest is specifically designed to generate semantically valid inputs for programs such as compilers.
we therefore found zest a very promising approach for generating a test corpus for chocopy.
while zest produced test suites were comprehensive achieving about line coverage on the chocopy typechecker the generated test corpora were not concise .
for example the size bounded zest generated program in fig.
simultaneously achieves novel coverage related to the handling ofwhile loops for loops and if else expressions.
however the program also contains certain redundant features those that exist in other inputs in the corpus such as pass statements assignments and list indexing.
this is sometimes referred to as collateral coverage in the literature .
we prefer not to provide such a compound input to undergraduate students developing a compiler as it does not immediately suggest an implementation goal and it is not ideal for debugging failures.
c. test case reduction a natural solution to the conciseness problem presented by zest generated inputs is to simply minimize them.
in general finding a minimal input that exhibits a given behavior e.g.
triggers a bug or exercises certain program features is an np hard problem.
starting with an initial input of size n there areo 2n possible subsets of the starting input itself not to mention other small inputs that contain elements not present in the initial input.
techniques such as delta debugging dd find locally minimal inputs that are subsets of the initial input in worstcaseo n2 steps.
one drawback of dd applied on the string representation of inputs is that deleting individual characters and contiguous substrings often results in inputs that have invalid syntax therefore most subsets do not exhibit the desired behavior.
hierarchical delta debugging hdd solves this problem by applying a dd like algorithm on a tree representation of parsed inputs.
hdd requires knowledge of the input syntax which is readily available in our application.
similarly perses utilizes a grammar to perform reductions1while not for aina band true .a c pass fig.
.
chocopy program generated using coverage guided bounded grammar based fuzzing with size bounds of .
1while a for ain a none ifaifnone else aelse a fig.
.
minimized chocopy program achieving the same novel coverage as achieved by the program in fig.
.
and guarantees that each reduction step also produces a syntactically valid program.
we used state of the art implementations of dd and hdd developed by hodovan et al.
on zest generated chocopy programs.
fig.
depicts a minimized version of the program listed in fig.
where the reduction criterion was that the reduced input achieves at least the unique same coverage as achieved by the original input.
the minimization takes about seconds to run and achieves a reduction in test case size the redundant pass assignment etc.
has been removed.
however fig.
still contains multiple loops branching statements etc.
in the next section we will describe a novel solution that produces inputs that are much more concise for free .
iv.
b onsai fuzzing our proposed technique leverages the scalability advantages of grammar based coverage guided fuzzing while avoiding the constraints of the fuzz then reduce approach.
the key idea in our approach is to grow a test corpus bottom up by using coverage guided bounded grammar fuzzing cbgf to generate small inputs by construction and iteratively increasing the input size inspired by iterative deepening based search algorithms .
we call our approach bonsai fuzzing .
figs.
and show a total of eleven chocopy programs saved during various rounds of bonsai fuzzing comments added manually .
these programs are concise and the language features they exercise can be easily discerned.
in our opinion they look almost like hand written test cases that are precisely designed for testing specific features of the chocopy language semantics.
however they were generated completely automatically and without knowledge of any typing rules.
we next build a series of concepts leading up to a description of the bonsai fuzzing algorithm.
a. bounded grammar fuzzers we start by considering an input generator that can randomly sample inputs of a bounded size where the bounds are based on the definition of an input language s grammar.
we can observe three properties of a chocopy program to get an idea of how we might bound the input space.
ex.
a single pass statement pass ex.
b simple assignment statement a object ex.
c function definition with return def a return fig.
.
three examples of chocopy programs saved during bonsai fuzzing in a corpus produced by f1 .
ex.
d class definition with attribute declaration class a object a int pass ex.
e indexing into a string a ex.
f less than comparison on two integers ex.
g equality comparison on two strings a ex.
h function definition with two arguments def a b str a int pass fig.
.
four examples of chocopy programs saved during bonsai fuzzing by f2 f1 andf1 .
idents the number of new unique identifiers variable names function names class names excluding predefined identifiers e.g.
int .
items the maximum number of elements in a linear group.
this can correspond to the maximum number of statements in a block arguments in a function definition arguments in a list expression etc.
depth the maximum number of times an expression statement or function definition is nested.
for the chocopy example in fig.
we have idents is zero items idx val items commaseparated list elements on line and depth triply nested expressions on line .
for the example in fig.
we have idents a setx equals self x y a items top level statements in the program and depth doubly nested ifstatements on lines .
we can bound the input space if we restrict the maximum value of idents items and depth for any generated chocopy program.
we will now generalize this to any language.
consider a specification for the syntax of an input language in the form of a context free grammar g. we consider definitions in an extended backus naur form where gconsists of a set of terminals t a set of non terminals n a start symbols2n and a set of production rules of the form a !
wherea2n and a1a2 ex.
i nested list expression ex.
j object construction and attribute assignment class a object a int a .a ex.
k nested functions def a def b pass return fig.
.
example chocopy programs saved in the bonsai fuzzing corpus of f3 .
the right hand side of production rules are a sequence of zero or more symbols which are defined recursively as follows a symbol is either a terminal in t a non terminal innor of the form wherebis a symbol.
the kleenestar in the final form has the usual meaning and enables nonrecursive definitions of linear repeating sequences e.g.
list of statements or arguments to a function call.
we also consider a special class of terminals t whose concrete values are user defined e.g.
identifiers instead of predefined e.g.
or while .
in the chocopy grammar included in our online repository ref.
section i we have fid idstringg.
now consider the set of programs p fp p gg .
each programphas a corresponding derivation tree tfromg.
we are interested in bounding the following properties idents p the maximum number of distinct values for any terminal in e.g.
number of distinct identifiers observed across the entire tree t. items p the maximum number of repetitions in any expansion of a kleene star e.g.
number of statements in a block when generating t. depth p the maximum number of expansions of the same non terminal e.g.
expr in any path from the root to any leaf node in t. we can then define a smaller input space pm n d where pm n d p p2p idents p m items p n depth p d9 for example the chocopy program in fig.
belongs to chocopy4 but the program in fig.
does not.
both of them belong to chocopy7 .
neither is in chocopy1 .
algorithm details the procedure we use for sampling programs inpm n d .
the parameters to function b ounded sample are a grammarg a symbola and bounds m n d the function returns a string which is an expansion of symbol a that obeys the provided bounds.
a top level call to b ound edsample witha s the start symbol of the grammar produces a random program in pm n d .
727algorithm bounded grammar sampling algorithm.
gis a grammar m n anddare positive integers.
function bounded sample g symbola m n d case typeof a terminalt return concretize t m .see text... repetition return concatenate bounded sample b m n d fori2f0 chooserandom g nonterminal a return sample nonterminal g a m n d function sample nonterminal g nonterminal a m n d ifjnt expansions g a j then p .expand to leaf node else ifjtexpansions g a j then p .expand to non leaf node else letc number of expansions of afrom root to here p c d .probability of leaf expansion with probabilityp leta!
chooserandom t expansions a otherwise leta!
chooserandom nt expansions a return concatenate function texpansions g nonterminal a return all expansions a!
ingwhere 8ai2 typeof ai terminal function nt expansions g nonterminal a return all expansions a!
ingwhere 9ai2 typeof ai nonterminal the sampling algorithm has a similar structure to the ptc1 grammar sampling procedure described by luke the following discussion clarifies specific algorithmic details.
in general since acan be any type of symbol terminal nonterminal or a group with kleene star b ounded sample performs different logic depending on the type of a. whenais a terminal symbol it is concretized as follows ifa2 then one of mpre populated expansions is uniformly chosen at random e.g.
if the terminal represents an identifier then one of say a 1 a 2 .
.
.
a m is returned uniformly at random .
otherwise ahas exactly one concrete value e.g.
or while which is returned directly.
ifais a repetition we choose a number of expansionsiuniformly at random in the range .
then we recursively call b ounded sample with symbol b foritimes and the results are concatenated.
ifais a nonterminal a then with a calculated probabilitypwe return the output of b ounded sample on a randomly chosen terminal expansion.
otherwise we use a randomly chosen nonterminal expansion.
the probabilitypis a function of the number of times a has been expanded from the root and the maximum depth parameter d. it ensures that the program cannot have a depth larger than d while favoring nonterminal expansions when the nesting depth is relatively smaller.
the calculation of pdiffers from that used by luke in ptc1 since we are interested in bounding themaximum nesting along any given path in a derivation tree instead of bounding the size of the tree itself.
preliminary results with chocopy there is a natural dichotomy between conciseness andcomprehensiveness .
tiny bounds such as produce very concise inputs but they do not exercise many language features.
additionally most randomly sampled inputs of size are well typed.
as we increase the bounds the likelihood of a randomly sampled program being semantically valid diminish.
for preliminary experiments we ran small hour fuzzing sessions using bounded grammar sampling for all configurations where m n anddwere between and each a total of configurations.
each experiment was repeated ten times to account for randomness.
we then measured branch coverage in the chocopy reference typechecker across all the inputs generated during each experiment and fraction of generated inputs that were semantically valid .
fig.
shows averages of the fraction validity and relative branch coverage for all configurations.
we noticed that bounds such as were able to achieve high coverage however the fraction of valid inputs generated for was concerning only .
we next consider a feedback directed variant of the bounded grammar sampling fuzzer that can produce inputs that are more likely to be semantically valid.
b. coverage guided bounded grammar fuzzing cbgf in order to incorporate a feedback from test execution we enhance our bounded grammar sampling technique to acoverage guided bounded grammar fuzzer cbgf .
algorithm describes cbgf.
it is almost a standard coverageguided fuzzing loop e.g.
as described by b ohme et al.
but focuses on generating a comprehensive test case corpus rather than discovering program crashes1.
the technique expects an instrumented version of the test program such as the chocopy reference compiler the instrumentation provides a way to receive feedback e.g.
code coverage from test execution.
test execution on a given input can also return additional feedback such as whether the input was semantically valid or not e.g.
based on whether type checking succeeded or if there were any errors .
the function cbgf is given an ordered set of initial seed inputs ins.
the main fuzzing loop continuously cycles through the set s picking each input in order sometimes with repetition to increase energy mutating it and executing the test program with the mutated input to receive feedback.
if the feedback is interesting e.g.
coverage includes a program location that is not exercised by any other input insso far then the mutated input is added to s. the loop ends after a fixed time budget and the resulting corpus of inputssis returned.
the two main unspecified components in this algorithm are how m utate works line and what the interestingness criteria is for saving new inputs line .
we use an off the shelf implementation of zest a structureaware coverage guided fuzzer that is well suited for our 1we assume that the reference program being analyzed is not buggy.
if we find any crashes we apply a patch and restart from the beginning.
d1 5nm m m m m .
.
.
.
.
.
coverage d1 5nm m m m m .
.
.
.
.
.
validityfig.
.
properties of chocopy programs randomly sampled using b ounded sample with various size bounds for hours each.
data shows normalized branch coverage and fraction of semantically valid programs in sampled population average over repetitions per config.
.
higher values are better.
application2.
in zest all inputs including the initial seed inputs are generated using some sampling procedure called agenerator in our case the generator is simply the bounded grammar sampler ref.
algorithm .
each input is associated with a sequence of pseudo random choices made during the sampling procedure which uniquely determine the input produced by that procedure.
in algorithm this includes the random choices made in expanding production rules and concretizing terminal values.
zest records these choices in a vector which is associated with the corresponding input .
the m utate function in algorithm works by performing random point mutations on these recorded pseudo random choices and then replaying b ounded sample with the specified choices and with the given bounds to produce input0.
essentially b ounded sample is implicitly parameterized by the source of pseudo randomness which zest controls in the implementation by simply overriding java.util.random .
we expect the returned value input0to be a syntactically valid input that is subtly different from that is a structural mutation of the original input input .
note that if input was a member of the initial set of seeds then the size bounds m n d provided to m utate may be larger than the bounds used to originally generate input we will exploit this fact in the section iv c. the criteria used by zest to determine whether to save input0 line in algorithm is the following the feedback from execution of poninput0is interesting if there is new code coverage regardless of the validity of input0 or 2we elide details of all other heuristics in algorithm since we inherit them from the original zest implementation .
the search heuristics are not important to our proposed technique which works at a higher level.
input0is semantically valid and it achieves new coverage when compared to all other semantically valid inputs in s. zest thus favors saving semantically valid inputs.
section iv d describes a tweak to this criterion we make in some scenarios.
thefnotation we now define some short hand notation that will be useful when describing our proposed bonsai fuzzing technique.
let fg p m n ddenote a coverageguided bounded grammar fuzzer cbgf parameterized by grammarg test program p size bounds m n andd.
as per algorithm fg p m n dis a function that accepts an ordered set of inputs and returns a corpus of the same type.
since the grammar and target program are usually fixed in a given application we will omit the superscripts hereon therefore fm n d is a cbgf of size bounds m n d .
preliminary results with chocopy as described in section iii c simply using zest followed by input minimization on the resulting corpus still lacks conciseness.
the program in fig.
was produced using f3 3in seedless mode .
the program in fig.
is its corresponding reduction after applying hierarchical delta debugging the invariant being that the reduced input still meets the same interestingness criteria from algorithm .
a full hdd reduced corpus of zest generated chocopy programs can be found in our online repository ref.
section i .
c. bonsai fuzzing our novel solution is to build a concise test corpus from the bottom up by using a set of cbgfs with gradually increasing size bounds.
the intuition is that the smaller cbgfs would initially build a corpus of tiny test corpus covering simple features and larger cbgfs can build on the smaller 729algorithm coverage guided bounded grammar fuzzing require instrumented program p grammarg boundsm n d function cbgf seed inputs s .returns corpus s repeat input next s .cycle throughs input mutate input g m n d .see text... feedback execute p input0 .validity coverage iffeedback is interesting then .new coverage?
s s input until time budget expires returns programs to generate more complex test cases that achieve better coverage.
by inceasing the size bounds gradually at each step we expect the complex test cases in later stages to be structural mutations of test cases discovered in earlier stages thus we hope to simultaneously achieve validity conciseness and comprehensiveness.
we now define a way to iteratively increment the size of a cbgf which allows us to create a formal procedure for this approach.
given upper bounds m n andd we can consider the set of cbgfs cm n d fm n d m m n n d d9 with upper bounds we would have 27different cbgfs in setc3 .
we define a partial order overcm n d as follows fm n d fm0 n0 d0 m m0 n n0 d d0 consequently fm n d fm0 n0 d0ifffm n d fm0 n0 d0and fm n d6 fm0 n0 d0.
this ordering suggests that cm n d is a lattice withf1 being the bottom element denoted f?
andfm n d being the top element denoted f .
fig.
visualizes the lattice for c2 where the partial order corresponds to graph reachability.
in this example f f2 .
additionally we define the terms successor andpredecessor with their usual meaning fsis a successor offiff fsand there exists no cbgff0 ssuch thatf f0 s fs.
fpis apredecessor offiffp fand there exists no cbgff0 psuch thatfp f0 p f. for example f2 1is a successor off1 whereasf2 is not.
conversely f1 1is a predecessor of f2 1but not a predecessor off2 .
in fig.
every node has incoming edges from its predecessors and outgoing edges to its successors.
naturally predecessors f?
successors f fg.
we now formally define bonsai fuzzing as a procedure that begins with the smallest configuration f?and iteratively increases the size until a given upper bound is reached.
algorithm describes the procedure for bonsai fuzzing.
variablefis initialized to the smallest cbgf f?.
recall from algorithm that a cbgf is a function that is given a set of seed inputs and returns a test corpus.
initially we havealgorithm bonsai fuzzing algorithm procedure bonsai fuzzing f f?
seeds .single random seed corpus f?
f seeds .run cbgf to generate corpus worklist successors f while worklist is not empty do foreachfinworklist do .parallelizable p predecessors f seeds sortbysize s fp2pcorpus fp corpus f f seeds .run cbgf worklist s fs2worklistsuccessors fs return corpus f no seeds.
we thus start by running the cbgf f?with one random seed input similar to slf to produce corpus f?
.
then a worklist is populated with the successors f .
for each unprocessed element in the worklist that is each unexecuted fuzzer we prepare its seeds by taking a union of all test cases in the corpus generated by each of its predecessors.
the seeds are also sorted by size in ascending order so that algorithm encounters smaller inputs to mutate first .
we then runf save its resulting corpus and repeat this process.
eventually we reach the point where f f and there are no more successors.
the final corpus is the result of f .
consider a sample run of bonsai fuzzing over the set c3 .
we start by running the cbgf f?
f1 1with one randomly generated seed input.
fig.
shows three sample test cases saved in the resulting corpus f1 .
we can see that the generated programs are small in size and test simple language features.
these inputs will then be used as seeds in successor cbgfs f2 f1 andf1 .
fig.
lists some programs saved in the corresponding corpora of these fuzzers.
we can now start to see programs with slightly complex features such as class attributes binary expressions and functions with multiple parameters.
we repeat the process until we reach f3 the top element of the lattice c3 .
fig.
shows some example programs saved in the its corpus.
more complex features such as nested list expressions and nested function definitions are demonstrated in these generated programs.
note that some of these inputs may have been copied verbatim from its seeds having been discovered by predecessors.
the final corpus necessarily incorporates the corpora generated by all cbgfs in the lattice.
the full corpus of chocopy programs generated using bonsai fuzzing can be found in our online repository ref.
section i .
d. bonsai fuzzing with extended lattice so far we have restricted test generation to only those programs that are semantically valid.
by and large we want semantic rules e.g.
well typed addition to be exercised in valid representative programs as opposed to larger invalid programs that contain these as subexpressions.
however in order to have a comprehensive test corpus we also need some invalid input programs for testing various error paths in the semantic analysis e.g.
duplicate variable definition non730boolean condition to while and so on .
ideally we want these invalid programs to be concise as well that is they are indicative of the particular error path that is being tested.
to achieve this goal we define two variants of cbgf by tweaking the interestingness criterion on line of algorithm .
first arestricted cbgf is a cbgf that only saves valid inputs that is the feedback is considered interesting on line if the input was valid andit achieved new code coverage.
second an unrestricted cbgf saves both valid and invalid inputs using zest s interestingness criterion as described in section iv b. we thus add a parameter v2 fr ugto cbgfs where rdenotes restricted and udenotes unrestricted.
we use the symbol fm n d v to denote a cbgf that is parameterized by size bounds as well as the validity restriction or lack thereof .
we can now define a new partial ordering as follows given two cbgfs fm n d v andfm0 n0 d0 v0 fm n d v fm0 n0 d0 v0 fm n d fm0 n0 d0and v v0orv0 u the definitions of successors andpredecessors remain the same as before.
so we now have successors f1 r ff2 r f1 r f1 r f1 ug.
similarly we now have predecessors f1 u ff1 u f1 rgthe key idea of this lattice is that restricted cbgfs are predecessors of unrestricted cbgfs with the same size bounds.
in other words unrestricted cbgfs with size bounds m n d will be able to use as seeds all the valid inputs produced by a fuzzer of the same size bounds as well as both valid and invalid inputs produced by unrestricted fuzzers with smaller size bounds.
the hope is that invalid inputs that are generated by mutating valid inputs are more likely to be concise as they would trigger fewer semantic errors in a single chocopy program.
setting f?
f1 randf fm n d u we can run bonsai fuzzing using algorithm as is.
v. e valuation we evaluate bonsai fuzzing by measuring its ability to generate a test corpus containing test cases that are concise comprehensive semantically valid and where applicable able to detect faults.
we compare bonsai fuzzing to a baseline of cbgf that is zest with a grammar based input generator post processed with minimization techniques.
the baseline is thus the conventional fuzz then reduce approach.
we run our evaluation on two test targets our primary application and a secondary target to ensure that our solution is not biased towards a particular implementation or input language.
chocopy reference compiler 6k loc the test driver reads in a chocopy program and runs the semantic analysis type checking stage of the chocopy reference compiler.
for the fault detection evaluation we additionally run a differential test on the typed asts returned by a reference and buggy compiler see section v d .
google closure compiler 250k loc the test driver borrowed from prior work expects a javascript program as input and performs source tosource optimizations.experimental setup bound overall we found the bounds of m n d to be a good trade off between conciseness and comprehensiveness.
we use these bounds for bonsai fuzzing as well as for the baseline cbgf.
duration we run each cbgf node in the bonsai fuzzing extended lattice for one hour which totals hours of cpu time.
we allocate the same hours of cpu time for the baseline cbgf to run3.
repetition we run each experiment times and report metrics across all repetitions due to the nature of randomness in fuzzing and its effect on results.
minimization techniques for the fuzz then reduce baseline we use picire and picireny which are state ofthe art implementations of character level and grammar based hierarchical delta debugging respectively.
an interestingness predicate script was required for each of these tools.
we provided a predicate that checked whether a candidate minimized input program met the same criterion as was used to save the original input during cbgf ref.
line in algorithm .
table i lists the average cpu time for each of these reduction tools to minimize an entire corpus.
a. conciseness test corpus size we evaluate conciseness by measuring the size of each test file excluding whitespace characters in the generated corpus.
fig.
displays the distribution of test input sizes for the baseline and bonsai fuzzing.
on both targets we observed that bonsai fuzzing produces test files that are statistically significantly lower in size than those of the baseline.
the chocopy files are on average .
smaller than the results of grammar based reduction and .
smaller than the results of character based reduction.
the closure files are on average .
smaller than the results of grammar based reduction and .
smaller than the results of character based reduction.
we also see that the variance of the size of files in the violin plot of bonsai fuzzing is much lower than that of the baseline.
one clear advantage is that bonsai fuzzing is able to produce these smaller inputs without requiring any additional postprocessing time .
in contrast the fuzz then reduce approach of the baseline can take up to hours for minimization to run.
as a sanity check we also report the number of files in the test corpora as shown in table ii.
the resulting corpus from bonsai fuzzing contains about fewer files in both targets.
this shows that bonsai fuzzing does not compensate for its smaller test inputs by having a large number of tests.
b. semantic validity one of our goals was to generate a high fraction of semantically valid inputs ref.
section ii b .
for each input 3we chose these durations because one hour is sufficient time for coverage to stagnate for each cbgf node and because it helps us make a fair comparison with the baseline by fixing total fuzzing duration to a constant.
bonsai fuzzing can be optimized by stopping each cbgf early by detecting saturation dynamically but this would make the total fuzzing duration variable.
our evaluation is conservative.
731chocopy closure target020406080100120140number of characters in individual test filestechnique baseline with grammar reductions baseline with character reductions bonsai fuzzingfig.
.
distribution of size of individual test files excluding whitespace characters in saved test corpora.
lower is better.
table i time to minimize zest saved test inputs minutes avg stdev .
chocopy closure picireny grammar reductions picire character reductions table ii number of files in test corpus avg stdev .
l ower is better .
chocopy closure baseline bonsai fuzzing program in the saved test corpora we re run the chocopy compiler to test whether the input is semantically valid or whether the compiler reports any errors.
the average percent of semantically valid programs in the generated corpora is shown in fig.
.
bonsai fuzzing has a statistically significant increase in both targets.
on average it is able to achieve a improvement in validity in chocopy and a improvement in closure.
why is this so?
in the initial round of bonsai fuzzing sampling smaller programs leads to a higher likelihood of semantically valid inputs as compared to sampling a larger program from scratch ref.
fig.
.
in subsequent rounds it is easier to mutate a small valid program into a slightly larger valid program as there are less opportunities to introduce errors.
we observed that the baseline s seed pool quickly fills up with invalid or large programs early on in the fuzzing campaign making it harder to recover in producing diverse valid inputs via random mutations.
we value this improvement in validity resulting from bonsai fuzzing since it means that more language features are being covered by test cases that are semantically valid which in our opinion results in more meaningful and readable test cases.
chocopy closure target01020304050607080percent of valid programstechnique baseline bonsai fuzzingfig.
.
fraction of semantically valid programs in test corpora averages with standard deviation .
higher is better.
c. comprehensiveness coverage a key concern when generating small inputs by construction is whether they comprehensively exercise various program behaviors as conventional coverage guided fuzzing.
we measure coverage using a third party tool the widely used jacoco library .
we report the branch coverage on the semantic analysis classes within each of the benchmarks similar to approach in .
since many of the branches are unreachable from our test drivers it is important to focus on the relative difference between the baseline and bonsai fuzzing rather than the raw coverage values.
fig.
shows the branch coverage achieved by the baseline and bonsai fuzzing on each of the targets.
we can see that both techniques achieve approximately the same branch coverage.
on closure the difference is statistically insignificant.
on chocopy the difference is significant but its effect is small bonsai fuzzing loses of branch coverage on average.
we are not dismayed with this small reduction.
in our application we can easily incorporate the few test cases from conventional fuzzing that cover logic that is not exercised by bonsai fuzzing in chocopy this is usually just one test case.
732chocopy closure target01020304050607080percent of branches coveredtechnique baseline bonsai fuzzingfig.
.
branch coverage in semantic analysis stages achieved by saved test corpora averages with standard deviation .
higher is better.
table iii mutation scores for choco py typechecker avg stdev baseline bonsai fuzzing d. fault detection mutation scores finally we want to ensure that the concise inputs generated by bonsai fuzzing for the chocopy target are still useful for catching faults that is they can be used for automated grading or providing student feedback.
this is essentially a validation of the small scope hypothesis .
in a classroom setting we would compare a candidate buggy student implementation with the reference implementation.
for our experimental evaluation we simulate such a buggy candidate by using a mutation testing tool on a copy of the reference compiler.
we run the chocopy autograder on the reference compiler and its mutation if the auto grader detects a failure then the mutation is killed .
the test corpus saved by bonsai fuzzing by itself achieves a mutation killing score of on average.
this is despite the fact that the fuzzing technique and input saving criteria is related to coverage improvements within the reference compiler only and is unaware of program mutations or bugs in student implementations.
as recently observed by chen et al.
a better technique for increasing fault detection while minimizing test sizes is to first optimize for coverage and then optimize for mutation scores when coverage saturates.
we thus use the corpus produced by bonsai fuzzing and the baseline for comparison as seed inputs for a simple grammarbased blackbox fuzzer with the maximum bounds for minutes.
we do this for each of the mutated compilers that is simulated buggy candidates.
if any blackbox fuzzer generated input kills the mutation we say that the corresponding technique kills that mutation.
table iii summarizes these results.
both the baseline and bonsai fuzzing achieve more than mutation killing score which we find to be acceptable.
we therefore conclude that size bounded fuzzing does not significantly sacrifice fault detection capability on chocopy.
unfortunately we cannot report meaningful mutation scores on closure since the project does not have a proper differential testing oracle.vi.
d iscussion and threats to validity although our original motivation for this work was to synthesize concise test inputs for chocopy programming assignments we also evaluated our technique on the google closure compiler.
the results of are promising.
bonsai fuzzing can synthesize test inputs that are concise by construction without sacrificing the quality of test inputs in terms of code coverage or mutation scores as compared to the fuzz thenreduce approach.
moreover the test inputs produced using bonsai fuzzing are smaller in size by .
however since the number of target programs we evaluated on is small we cannot claim that this technique will generalize more broadly.
further we restricted our evaluation only to compilers where the input can be represented by a context free grammar cfg .
we leave the generalization of this technique to other input formats and problem domains as future work.
further in our evaluation we fixed the final size bounds to and fuzzing duration to one hour per cbgf node.
bonsai fuzzing can be improved further by dynamically choosing ideal size bounds and fuzzing duration by monitoring the quality of test inputs saved by each cbgf node.
we were unfortunately unable to test fault detection capabilities of bonsai fuzzing on actual student implementations due to procedural issues with using student authored assignments for this research.
we used mutation scores to estimate the ability of bonsai fuzzing to catch student bugs.
prior empirical studies have shown this metric to be reasonable but we cannot make general claims about the impacts of this research in the classroom.
in this paper we used the notion of conciseness of test inputs as a proxy for readability based on what we feel are important features of readable test cases size and semantic validity .
since our evaluation did not comprise of a user study we cannot make any subjective claims about human perceived readability.
independently from our work roy et al.
have recently worked on improving the readability of automatically generated test code addressing issues such as variable names and code comments.
it has not escaped our notice that the bonsai fuzzing technique may also be useful in synthesizing regression tests for fast evolving software.
for validating code changes it is much more efficient to simply run a fixed suite of regression tests than to run a full fuzzing session after every code commit.
concise test inputs such as those produced using bonsai fuzzing are more likely to be maintainable.