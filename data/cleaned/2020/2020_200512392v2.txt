mtfuzz fuzzing with a multi task neural network dongdong she columbia university new york usa ds3619 columbia.edurahul krishna columbia university new york usa rk3080 columbia.edulu yan shanghai jiao tong university shanghai china jiaodayanlu sjtu.edu.cn suman jana columbia university new york usa suman cs.columbia.edubaishakhi ray columbia university new york usa rayb cs.columbia.edu abstract fuzzing is a widely used technique for detecting software bugs and vulnerabilities.
most popular fuzzers generate new inputs using an evolutionary search to maximize code coverage.
essentially these fuzzers start with a set of seed inputs mutate them to generate new inputs and identify the promising inputs using an evolutionary fitness function for further mutation.
despite their success evolutionary fuzzers tend to get stuck in long sequences of unproductive mutations.
in recent years machine learning ml based mutation strategies have reported promising results.
however the existing ml based fuzzers are limited by the lack of quality and diversity of the training data.
as the input space of the target programs is high dimensional and sparse it is prohibitively expensive to collect many diverse samples demonstrating successful and unsuccessful mutations to train the model.
in this paper we address these issues by using a multi task neural network that can learn a compact embedding of the input space based on diverse training samples for multiple related tasks i.e.
predicting for different types of coverage .
the compact embedding can guide the mutation process by focusing most of the mutations on the parts of the embedding where the gradient is high.
mtfuzz uncovers 11previously unseen bugs and achieves an average of more edge coverage compared with state of the art fuzzer on real world programs.
ccs concepts software and its engineering software testing and debugging .
keywords graybox fuzzing multi task neural networks gradient guided optimization transfer learning permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
copyrights for components of this work owned by others than acm must be honored.
abstracting with credit is permitted.
to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
request permissions from permissions acm.org.
esec fse november virtual event usa association for computing machinery.
acm isbn .
.
.
.
reference format dongdong she rahul krishna lu yan suman jana and baishakhi ray.
.
mtfuzz fuzzing with a multi task neural network.
in proceedings of the 28th acm joint european software engineering conference and symposium on the foundations of software engineering esec fse november virtual event usa.
acm new york ny usa pages.
https introduction coverage guided graybox fuzzing is a widely used technique for detecting bugs and security vulnerabilities in real world software .
the key idea behind a fuzzer is to execute the target program on a large number of automatically generated test inputs and monitor the corresponding executions for buggy behaviors.
however as the input spaces of real world programs are typically very large unguided test input generation is not effective at finding bugs.
therefore most popular graybox fuzzers use evolutionary search to generate new inputs they mutate a set of seed inputs and retain only the most promising inputs i.e.
inputs exercising new program behavior for further mutations .
however the effectiveness of traditional evolutionary fuzzers tends to decrease significantly over fuzzing time.
they often get stuck in long sequences of unfruitful mutations failing to generate inputs that explore new regions of the target program .
several researchers have worked on designing different mutation strategies based on various program behaviors e.g.
focusing on rare branches call context etc.
.
however program behavior changes drastically not only across different programs but also across different parts of the same program.
thus finding a generic robust mutation strategy still remains an important open problem.
recently machine learning ml techniques have shown initial promise to guide the mutations .
these fuzzers typically use existing test inputs to train ml models and learn to identify promising mutation regions that improve coverage .
like any other supervised learning technique the success of these models relies heavily on the number and diversity of training samples.
however collecting such training data for fuzzing that can demonstrate successful unsuccessful mutations is prohibitively expensive due to two main reasons.
first successful mutations that increase coverage are often limited to very few sparsely distributed input bytes commonly known as hot bytes in a high dimensional input space.
without knowing the distribution of hot bytes it is extremely hard to generate successful mutations over the sparse arxiv .12392v2 sep 2020esec fse november virtual event usa she d. krishna r. yan l. jana s. and ray b. high dimensional input space .
second the training data must be diverse enough to expose the model to various program behaviors that lead to successful unsuccessful mutations this is also challenging as one would require a large number of test cases exploring different program semantics.
thus the ml based fuzzers suffer from both sparsity andlack of diversity of the target domain.
in this paper we address these problems using multi task learning a popular learning paradigm used in domains like computer vision to effectively learn common features shared across related tasks from limited training data.
in this framework different participating tasks allow an ml model to effectively learn a compact and more generalized feature representation while ignoring taskspecific noises.
to jointly learn a compact embedding of the inputs in our setting we use different tasks for predicting the relationship between program inputs and different aspects of fuzzing related program behavior e.g.
different types of edge coverage .
such an architecture addresses both the data sparsity and lack of diversity problem.
the model can simultaneously learn from diverse program behaviors from different tasks as well as focus on learning the important features hot bytes in our case across all tasks.
each participating task will provide separate pieces of evidence for the relevance or irrelevance of the input features .
to this end we design implement and evaluate mtfuzz a multitask neural network mtnn based fuzzing framework.
given the same set of test inputs mtfuzz learns to predict three different code coverage measures showing various aspects of dynamic program behavior edge coverage which edges are explored by a test input ?
approach sensitive edge coverage if an edge is not explored how far off it is i.e.
approach level from getting triggered ?
context sensitive edge coverage from which call context an explored edge is called ?
note that our primary task like most popular fuzzers is to increase edge coverage.
however the use of call context and approach level provides additional information to boost edge coverage.
architecturally the underlying mtnn contains a group of hidden layers shared across the participating tasks while still maintaining task specific output layers.
the last shared layer learns a compact embedding of the input space as shown in figure .
such an embedding captures a generic compressed representation of the inputs while preserving the important features i.e.
hot byte distribution.
we compute a saliency score of each input byte by computing the gradients of the embedded representation w.r.t.
the input bytes.
saliency scores are often used in computer vision models to identify the important features by analyzing the importance of that feature w.r.t.
an embedded layer .
by contrast in this paper we use such saliency scores to guide the mutation process focus the mutations on bytes with high saliency scores.
our mtnn architecture also allows the compact embedding layer once trained to be transferred across different programs that operate on similar input formats.
for example compact embedding learned with mtfuzz for one xmlparser may be transferred to other xmlparsers.
our results in rq4 show that such transfer is quite effective and it reduces the cost to generate high quality data from scratch on new programs which can be quite expensive.
ourtool is available at and the artifacts available at we evaluate mtfuzz on real world programs against stateof the art fuzzers.
mtfuzz covers at least more edges on programs and several more on the rest.
mtfuzz also finds a total of real world bugs previously unseen see rq1 .
when compared to learning each task individually mtfuzz offers significantly more edge coverage see rq2 .
lastly our results from transfer learning show that the compact embedding of mtfuzz can be transferred across parsers for xml and elf binaries.
overall our paper makes the following key contributions we present a novel fuzzing framework based on multi task neural networks called mtfuzz that learns a compact embedding of otherwise sparse and high dimensional program input spaces.
once trained we use the salience score of the embedding layer outputs w.r.t.
the input bytes to guide the mutation process.
our empirical results demonstrate that mtfuzz is significantly more effective than current state of the art fuzzers.
on 10real world programs mtfuzz achieves an average of and up to edge coverage compared to neuzz the state of the art mlbased fuzzer.
mtfuzz also finds 11previously unknown bugs other fuzzers fail to find.
the bugs have been reported to the developers.
we demonstrate that transferring of the compact embedding across programs with similar input formats can significantly increase the fuzzing efficiency e.g.
transferred embeddings for different file formats like elf and xml can help mtfuzz to achieve up to edge coverage compared to state of the art fuzzers.
background multi task networks multi task neural networks mtnn are becoming increasingly popular in many different domains including optimization natural language processing and computer vision .
the key intuition behind mtnn is that it is useful for related tasks to be learned jointly so that each task can benefit from the relevant information available in other tasks .
for example if we learn to ride a unicycle a bicycle and a tricycle simultaneously experiences gathered from one usually help us to learn the other tasks better .
in this paper we use a popular mtnn architecture called hard parameter sharing which contain two groups of layers see fig.
a set of initial layers shared among all the tasks and several individual task specific output layers.
the shared layers enable a mtnn to find a common feature representation across all the tasks.
the task specific layers use the shared feature representation to generate predictions for the individual tasks .
mtnn training.
while mtnns can be used in many different ml paradigms in this paper we primarily focus on supervised learning.
we assume that the training process has access to a training dataset x x1 x2 ... xn .
the training data contains the ground truth output labels for each task.
we train the mtnn on the training data using standard back propagation to minimize a multi task loss.
multi task loss.
an mtnn is trained using a multi task loss function l. we assume that each individual task iin the set of tasks t 1 2 ... m has a corresponding loss function li.
the multi task loss is computed as a weighted sum of each individualmtfuzz fuzzing with a multi task neural network esec fse november virtual event usa decoder gid00052 gid00053 gid00034 gid00040 gid00038 gid00001 gid00018 gid00027 gid00001 gid00053 gid00081 gid00064 gid00072 gid00077 gid00001 gid00046 gid00084 gid00075 gid00083 gid00072 gid00083 gid00064 gid00082 gid00074 gid00001 gid00039 gid00068 gid00068 gid00067 gid00069 gid00078 gid00081 gid00086 gid00064 gid00081 gid00067 gid00001 gid00047 gid00047context sensitiveedge coverage approch sensitive input filecompact embedding guided mutation select inputsinstrumented programupdate seed corpus seed corpus gid00052 gid00053 gid00034 gid00040 gid00038 gid00001 gid00020 gid00027 gid00001 gid00052 gid00068 gid00068 gid00067 gid00001 gid00052 gid00068 gid00075 gid00068 gid00066 gid00083 gid00072 gid00078 gid00077 gid00001 gid00064 gid00077 gid00067 gid00001 gid00042 gid00077 gid00066 gid00081 gid00068 gid00076 gid00068 gid00077 gid00083 gid00064 gid00075 gid00001 gid00045 gid00068 gid00064 gid00081 gid00077 gid00072 gid00077 gid00070 gid00052 gid00053 gid00034 gid00040 gid00038 gid00001 gid00019 gid00027 gid00001 gid00040 gid00084 gid00072 gid00067 gid00068 gid00067 gid00001 gid00046 gid00084 gid00083 gid00064 gid00083 gid00072 gid00078 gid00077 identify hotbytesupdated seed corpusdecoder encoderdecoder figure overview of mtfuzz task loss.
more formally it is given by l m i 1 i li.
here i represents the weight assigned to task i. the goal of training is to reduce the overall loss.
in practice the actual values of the weights are decided based on the relative importance of each task.
most existing works assign equal weights to the tasks .
the multi task loss function forces the shared layer to learn a general input representation for all tasks offering two benefits increased generalizibility .
the overall risk of overfitting in multitask models is reduced by an order of m where mis the number of tasks compared to single task models .
intuitively the more tasks an mtnn learns from the more general the compact representation is in capturing features of all the tasks.
this prevents the representation from overfitting to the task specific features.
reduced sparsity .
the shared embedding layer in an mtnn can be designed to increase the compactness of the learned input representation.
compared with original input layer a shared embedding layer can achieve same expressiveness on a given set of tasks while requiring far fewer nodes.
in such compact embedding the important features across different tasks will be boosted with each task contributing its own set of relevant features .
methodology this section presents a brief overview of mtfuzz that aims to maximize edge coverage with the aid of two additional coverage measures context sensitive edge coverage and approach sensitive edge coverage using multi task learning.
figure illustrates an end to end workflow of the proposed approach.
the first stage trains an mtnn to produce a compact embedding of an otherwise sparse input space while preserving information about the hot bytes i.e.
the input bytes have the highest likelihood to impact code coverage section .
.
the second stage identifies these hot bytes and focuses on mutating them section .
.
finally in the third stage the seed corpus is updated with the mutated inputs and retains only the most interesting new inputs section .
.
.
modeling coverage as multiple tasks the goal of any ml based fuzzers including mtfuzz is to learn a mapping between input space and code coverage.
the most common coverage explored in the literature is edge coverage which is an effective measure and quite easy to instrument.
however it is coarse grained and misses many interesting program behavior e.g.
explored call context that are known to be important to fuzzing.
one workaround is to model path coverage by tracking the program execution path per input.
however keeping track of all the explored paths can be computationally intractable since it can quickly lead to a state space explosion on large programs .
as an alternative in this work we propose a middle ground we model the edge coverage as the primary task of the mtnn while choosing two other fine granular coverage metrics approach sensitive edge coverage and context sensitive edge coverage as auxiliary tasks to provide useful additional context to edge coverage.
.
.
edge coverage primary task.
edge coverage measures how many unique control flow edges are triggered by a test input as it interacts with the program.
it has become the de facto code coverage metric for fuzzing.
we model edge coverage prediction as the primary task of our multi task network which takes a binary test case as input and predicts the edges that could be covered by the test case.
for each input we represent the edge coverage as an edge bitmap where value per edge is set to 1or0 depending on whether the edge is exercised by the input or not.
in particular in the control flow graph of a program an edge connects two basic blocks denoted by prev block andcur block .
a unique ed e idis obtained as hash prev block cur block .
for each ed e id there is a bit allocated in the bitmap.
for every input the edge ids in the corresponding edge bitmap are set to or0 depending on whether or not those edges were triggered.
a a b b c c d dedge bitmap approac h bitmap figure approach bitmap vs. edge bitmap.
the edge d has a visited parent edge b and is thus marked .
in the approach bitmap.
.
.
approach sensitive edge coverage auxiliary task .
for an edge that is not exercised by an input we measure how far offesec fse november virtual event usa she d. krishna r. yan l. jana s. and ray b. the edge is from getting triggered.
such a measure provides additional contextual information of an edge.
for example if two test inputs failed to trigger an edge however one input reached closer to the unexplored edge than the other traditional edge coverage would treat both inputs the same.
however using a proximity measure we can discern between the two inputs and mutate the closer input so that it can reach the unexplored edge.
to achieve this approach sensitive edge coverage extends edge coverage by offering a distance measure that computes the distance between an unreached edge and the nearest edge triggered by an input.
this is a popular measure in the search based software engineering literature where instead of assigning a binary value or as in edge bitmap approach level assigns a numeric value between and to represent the edges if an edge is triggered it is assigned .
however if the edge is nottriggered but one of its parents are triggered then the non triggered edge is assigned a value of we use .
.
if neither the edge nor any of its parents are triggered it is assigned .
this is illustrated in fig.
.
note that for a given edge we refrain from using additional ancestors farther up the control flow graph to limit the computational burden.
the approach sensitive coverage is represented in an approach bitmap where for every unique ed e id we set an approach level value as shown in fig.
.
we model this metric in our multi task neural network as an auxiliary task where the task takes binary test cases as inputs and learn to predict the corresponding approach level bitmaps.
.
.
context sensitive edge coverage auxiliary task .
edge coverage cannot distinguish between two different test inputs triggering the same edge but via completely different internal states e.g.
through the same function called from different sites in the program .
this distinction is valuable since reaching an edge via a new internal state e.g.
through a new function call site may trigger a vulnerability hidden deep within the program logic.
augmenting edge coverage with context information regarding internal states of the program may help alleviate this problem .
1void foo char addr int a if a strncpy addr a return else return 8int main int argc char input char buf ... foo buf input ... foo buf input ... figure an example c code to demonstrate the usefulness of using context sensitive measures.
measures such as edge coverage will fail to detect a possible bug in strncpy consider the example in fig.
.
here for an input the first call to function foo appears at site line and it triggersthe if condition on line the second call to foo appears on siteline and it triggers the else condition on line .
as far as edge coverage is concerned both the edges of the function foo on lines and have been explored and any additional inputs will remain uninteresting.
however if we provide a new input say we would first trigger line offoowhen it is called from line .
then we trigger line offoofrom line and further cause a buffer overflow at line because a bytes string is written into a bytes destination buffer buf.
moveover the input will not be saved by edge coverage fuzzer since it triggers no new edges.
frequently called functions like strcmp may be quite susceptible such crashes .
input call ctx edge coverage l12 l2 l3 l14 l l6 l12 l l6 l14 l l3 l2 l3 l5 l6 l5 l6 l2 l3 figure the tuple in edge coverage does not differentiate between the clean input and the buggy input while of context sensitive edge coverage labeled call ctx does.
in order to overcome this challenge chen et al.
propose keeping track of the call stack in addition to the edge coverage by maintaining tuple call stack prev block cur block .
fig.
shows the additional information provided by context sensitive edge coverage over edge coverage.
here we see an example where a buggy input has the exact same edge coverage as the clean input .
however the call context information can differentiate these two inputs based on the call stacks at line and14.
we model context sensitive edge coverage in our framework as an auxiliary task.
we first assign a unique id to every call.
next at run time when we encounter a call at an edge ed e id we first compute a hash to record all the functions on current call stack as call stack call id1 ... call idn where call id i represents the i th function on current call stack and denotes xor operation.
next we compute the context sensitive edge id as call trace id call stack ed e id.
thus we obtain a unique call trace idfor every function called from different contexts i.e.
call sites .
we then create a bit map of all the call trace ids.
unlike existing implementations of contextsensitive edge coverage we assign an additional id to each call instruction while maintaining the original ed e idintact.
thus the total number of elements in our bit map reduces to sum of call trace ids and ed e ids rather than a product of call trace ids anded e ids.
an advantage of our design is that we minimize the bitmap size.
in practice existing methods requires around larger bitmap size than just edge coverage our implementation only requires around .
bitmap size of edge coverage.
the smaller bitmap size can avoid edge explosion and improve performance.
in our multi tasking framework the context sensitive edge coverage task is trained to predict the mapping between the inputs and the corresponding call trace ids bitmaps.
this can enable us to learn the difference between two inputs in a more granularmtfuzz fuzzing with a multi task neural network esec fse november virtual event usa fashion.
for example an ml model can learn that under certain circumstances the second input byte input in fig.
can cause crashes.
this information cannot be learned by training to predict for edge coverage alone since both inputs will have the same edge coverage as shown in fig.
.
.
stage i multi task training this phase builds a multi task neural network mtnn that can predict different types of edge coverage given a test input.
the trained model is designed to produce a more general and compact embedding of the input space focusing only on those input bytes that are most relevant to all the tasks.
this compact representation will be reused by the subsequent stages of the program to identify the most important bytes in the input i.e.
the hot bytes and guide mutations on those bytes.
.
.
architecture.
fig.
shows the architecture of the mtnn.
the model contains an encoder shared among all the tasks and three task specific decoders .
the model takes existing test input bytes as input and outputs task specific bitmap.
each input byte corresponds to one input node and each bitmap value corresponds to an ouput node.
encoder.
comprises of one input layer followed by three progressively narrower intermediate layers.
the total number of nodes in the input layer is equal to the total number of bytes in the largest input in the seed corpus.
all shorter inputs are padded with 0x00 for consistency.
the last layer of the encoder is a compact representation of the input to be used by all the tasks green in fig.
.
decoders.
there are three task specific decoders shown in lilac in fig.
.
each task specific decoder consists of three intermediate layers that grow progressively wider.
the last layer of each of the decoder is the output layer.
for edge coverage there is one node in the output layer for each unique ed e id likewise for context sensitive edge coverage there is one output node for each call trace id and for approach sensitive edge coverage there is one output node for each unique ed e idbut they take continuous values see fig.
.
.
.
loss functions.
the loss function of a mtnn is a weighted sum of the task specific loss functions.
among our three tasks edge coverage and context sensitive edge coverage are modeled as classification tasks and approach sensitive edge coverage is modeled as a regression task.
their loss functions are designed accordingly.
loss function for approach sensitive edge coverage.
approachlevel measures how close an input was from an edge that was not triggered.
this distance is measured using a continuous value between and .
therefore this is a regression problem and we use mean squared error loss given by l approach mse n i ...n yi yi .
where yiis the prediction and yiis the ground truth.
loss functions for edge coverage and context sensitive edge coverage .
the outputs of both these tasks are binary values where 1means an input triggered the ed e idor the call trace idand0 otherwise.
we find that while some ed e ids orcall trace ids are invoked very rarely resulting in imbalanced classes.
this usually happens when an input triggers a previously unseen rare edges.
xb one.superior xb two.superior xb three.superiorxb xbn z one.superior z two.superior z m.superior task specific decoding layers z f xb f .
shared encoding layers inputs xb embedding z call context approach leveledge coverage figure the mtnn architecture representing the n dimensional input layer xbi xb m dimensional compact embedding layer zj z s.t.
m n with a function f to map input xband the embedding layer xb three task specific layers .
due to this imbalance training with an off the shelf loss functions such as cross entropy is ill suited as it causes a lot of false negative errors often missing these rare edges.
to address this issue we introduce a parameter called penalty denoted by to penalize these false negatives.
the penalty is the ratio of the number of times an edge is notinvoked over the number of times it is invoked.
that is penalty times an edge id or call trace id is notinvoked times an edge id or call trace id is invoked here represents the penalty for every applicable task t and it is dynamically evaluated as fuzzing progresses.
using we define an adaptive loss for classification tasks in our mtnn as l ec ctx edge p lo p p lo p in eq.
l ec ctxresults in two separate loss functions for edge coverage and context sensitive edge coverage.
the penalty is used to penalize false positive and false negative errors.
penalizes p lo p representing false negatives 1penalizes both false positives and false negatives equally and 1penalizes p lo p representing false positives.
with this we compute the total loss for our multi task nn model with ktasks ltotal k i 1 ili this is the weighted sum of the adaptive loss lifor each individual task.
here ipresents the weight assigned to task i. .
stage ii guided mutation this phase uses the trained mtnn to generate new inputs that can maximize the code coverage.
this is achieved by focusing mutation on the byte locations in the input that can influence the branching behavior of the program hot bytes .
we use the the compact embedding layer of the mtnn shown ingreen in fig.
to infer the hot byte distribution.
the compact embedding layer is well suited for this because it a captures the most semantically meaningful features i.e.
bytes in the input in a compact manner and b learns to ignore task specific noiseesec fse november virtual event usa she d. krishna r. yan l. jana s. and ray b. patterns and pays more attention to the important bytes that apply to all tasks .
formally we represent the input shown in orange in fig.
as a byte vector xb xb1 xb2 ... xbn n where xbi is the ithbyte in xbandnrepresents the input dimensions i.e.
number of bytes .
then after the mtnn has been trained we obtain the compact embedding layer z z1 z2 ... zm consisting ofmnodes.
note that when input bytes in xbchanges zchanges accordingly.
the amount of the change is determined by how influential each byte in the input is to all the tasks in the mtnn model.
changes to the hot bytes which are more influential will result in larger changes to z. we use this property to discover the hot bytes .
to determine how influential each byte in xbis we compute the partial derivatives of the nodes in compact layer with respect to all the input bytes.
the partial derivative of the j th node in the embedding layer with respect to the i th input byte is xbz fj x xbi zj xbi i ...n j ...m in order to infer the importance of each byte xbi xb we define asaliency score for each byte denoted by s xbi .
we compute the saliency score as follows s xbi m j zj xbi i .
.
.n the saliency score s xbi is the sum of all the partial derivatives in xbzw.r.t.
to the byte xbi.
the numeric value of each of the n elements in s xb determines the hotness of each byte.
the larger the saliency score of an input byte xbiis the more likely it is to be ahot byte .
using the saliency score we can now mutate a test input to generate new ones.
to do this we identify the top kbytes with the largest saliency values these are the byte locations that will be mutated by our algorithm.
for each selected byte locations we create a new mutated input by changing the bytes to all permissible values between 0and255.
since this only happens to the top khot bytes the number of newly mutated seeds remains manageable.
we use these mutated inputs for fuzzing and monitor various coverage measures.
.
stage iii seed selection incremental learning in this step mtfuzz samples some of the mutated inputs from the previous stage to retrain the model.
sampling inputs is crucial as the choice of inputs can significantly affect the fuzzing performance.
also as fuzzing progresses the pool of available inputs keeps growing in size.
without some form of sampling strategy training the nn and computing gradients would take prohibitively long.
to this end we propose an importance sampling strategy where inputs are sampled such that they reach some important region of the control flow graph instead of randomly sampling from available input.
in particular our sampling strategy first retains all inputs that invoke previously unseen edges.
then we sort all the seen edges by their rarity.
the rarity of an edge is computed by counting how many inputs trigger that specified edge.
finally wetable test programs used in our study programs linesmtfuzz train s initial coverage class name binutils .
elf parserreadelf a nm c objdump d size strip ttf harfbuzz .
.
jpeg libjpeg 9c pdf mupdf .
.
xml libxml2 .
.
zip zlib .
.
table state of the art fuzzers used in our.
fuzzer technical description afl evolutionary search aflfast evolutionary markov model based search fairfuzz evolutionary byte masking angora evolutionary dynamic taint guided coordinate descent type inference neuzz neural smoothing guided fuzzing select the top t rarest edges and include at least one input triggering each of these rare edges.
we reason that by selecting the inputs that invoke the rare edges we may explore deeper regions of the program on subsequent mutations.
in order to limit the number of inputs sampled we introduce a sampling budget kthat determines how many inputs will be selected per iteration.
using these sampled inputs we retrained the model periodically to refine its behavior as more data is becoming available about new execution behavior retraining makes sure the model has knowledge about them and make more informed predictions.
evaluation implementation.
our mtnn model is implemented in keras2.
.
with tensorflow .
.
as a backend .
the mtnn is based on a feed forward model composed of one shared encoder and three independent decoders.
the encoder compresses an input file into a 512compact feature vector and feeds it into three following decoders to perform different task predictions.
for encoder we use three hidden layers with dimensions and .
for each decoder we use one final output layer to perform corresponding task prediction.
the dimension of final output layer is determined by different programs.
we use relu as activation function for all hidden layers.
we use sigmoid as the activation function for the output layer.
for task specific weights set each task to equal weight 1in eq.
.
the mtnn model is trained for epochs achieving a test accuracy of around on average.
we use adam optimizer with a learning rate of .
.
as for other hyperparameters we choose k for top khot bytes.
for seed selection budget tin stage iii .
we use t 750input samples where each input reaches atleast one rare edge.
we note that all these parameters can be tuned in our replication package.
to obtain the various coverage measures we implement a custom llvm pass.
specifically we instrument the first instruction of each basic block of tested programs to track edge transition betweenmtfuzz fuzzing with a multi task neural network esec fse november virtual event usa them.
we also instrument each call instructions to record the calling context of tested programs at runtime.
additionally we instrument each branch instructions to measure the distance from branching points to their corresponding descendants.
as for magic constraints we intercept operands of each cmpinstruction and use direct copy to satisfy these constraints.
study subjects.
we evaluate mtfuzz on real world programs as shown in table .
to demonstrate the performance of mtfuzz we compare the edge coverage and number of bugs detected by mtfuzz with 5state of the art fuzzers listed in table .
each stateof the art fuzzer was run for hours.
the training retraining and fuzzing times are included in the total runs for each fuzzer.
training time for mtfuzz is shown in table .
mtfuzz and neuzz both use the same initial seeds for the the approaches and the same fuzzing backend for consistency.
we ensure that all other experimental settings were also identical across all studied fuzzers.
experimental setup.
all our measurements are performed on a system running ubuntu .
with intel xeon e5 cpu and an nvidia gtx ti gpu.
for each program tested we run afl .52b on a single core machine for an hour to collect training data.
the average number of training inputs collected for 10programs is around 2k.
we use 10kb as the threshold file size for selecting our training data from the afl input corpus on average of the files generated by afl were under the threshold .
experimental results we evaluate mtfuzz with the following research questions rq1 performance.
how does mtfuzz perform in comparison with other state of the art fuzzers?
rq2 contributions of auxiliary tasks.
how much does each auxiliary task contribute to the overall performance of mtfuzz ?
rq3 impact of design choices.
how do various design choices affect the performance of mtfuzz ?
rq4 transferrability.
how transferable is mtfuzz ?
rq1 performance we compare mtfuzz wiht other fuzzers from table in terms of the number of real world and synthetic bugs detected rq1 a and rq1 b and edge coverage rq1 c .
rq1 a. how many real world bugs are discovered by mtfuzz compared to other fuzzers?
evaluation .to evaluate the number of bugs discovered by a fuzzer we first instrument the program binaries with addresssanitizer and underfinedbehaviorsanitizer .
such instrumentation is necessary to detect bugs beyond crashes.
next we run each of the fuzzers for hours all fuzzers use the same seed corpus and gather the test inputs generated by each of the fuzzers.
we run each of these test inputs on the instrumented binaries and count the number of bugs found in each setting.
finally we use the stack trace of bug reports generated by two sanitizers to categorize the found bugs.
note if multiple test inputs trigger the same bug we only consider it once.
table reports the results.
observations.
we find that mtfuzz finds a total of bugs the most among other five fuzzers in real world programs.
in the remaining three programs no bugs were detected by any fuzzer after hours.table real world bugs found after hours by various fuzzers.
mtfuzz finds the most number of bugs i.e.
unseen comprised of heap overflows memory leaks integer overflows and out of memory bugs.
program aflfast afl fairfuzz angora neuzz mtfuzz readelf nm objdump size strip libjpeg mupdf total table synthetic bugs in lava m dataset found after hours.
program bugs angora neuzz mtfuzz base64 md5sum uniq who among these bugs were previously unreported .
among the other fuzzers neuzz another ml based fuzzer is the second best fuzzer finding bugs.
angora finds .
we observe that the new bugs predominantly belonged to types memory leak heap overflow integer overflow and out of memory.
interestingly mtfuzz discovered a potentially serious heap overflow vulnerability in mupdf that was not found by any other fuzzer so far see figure .
a mupdf function ensure solid xref allocates memory line for each object of a pdf file and fills content to these memory chunks line .
prior to that at line it tries to obtain the total number of objects by reading a field value xref num objects which is controlled by program input a pdf file.mtfuzz leverages gradient to identify the hot bytes which control xref num objects and sets it to a negative value.
as a result nummaintains its initial value 1as line if check fails.
thus atline the function allocates memory space for a single object asnum .
however in line it tries to fill more than one object to new sub table and causes a heap overflow.
this bug results in a crash and potential dos ifmupdf is used in a web server.
mupdf .
.
source pdf pdf xref.c 2static void ensure solid xref ... ... int num xref num objects ismanipulated byattacker if num xref num objects num xref num objects ... allocate memory for num objects new sub table fz calloc ctx num sizeof object ... fill content tonum objects for i i sub len i new sub table sub table ... figure heap overflow bug in mupdf .
the red line shows the bug.esec fse november virtual event usa she d. krishna r. yan l. jana s. and ray b. table theaverage edge coverage of mtfuzz compared with other fuzzers after hours runs for repetitions.
parenthesized numbers represent the standard deviation.
a program binaries compiled with afl clang fast program mtfuzz neuzz angora fairfuzz afl aflfast readelf nm objdump size strip libjpeg libxml mupdf zlib harfbuzz indicates cases where angora failed to run due to the external library issue.
b program binaries compiled with alf gcc programs mtfuzz neuzz angora fairfuzz afl aflfast readelf nm objdump size strip libjpeg libxml mupdf zlib harfbuzz rq1 b. how many synthetic bugs in lava m dataset are discovered bymtfuzz compared to other fuzzers?
evaluation .lava m is a synthetic bug benchmark where bugs are injected into four gnu coreutil programs .
each bug in lava m dataset is guarded by a magic number condition.
when the magic verification is passed the corresponding bug will be triggered.
following conventional practice we run mtfuzz and other fuzzers from table on lava m dataset for a total of hours.
we measure the number of bugs triggered by each of the state of the art fuzzers.
the result is tabulated in table .
observations.
mtfuzz discovered the most number of bugs on all programs after hours run.
the better performance is attributed to the direct copy module.
to find a bug in lava m dataset fuzzers need to generate an input which satisfies the magic number condition.
mtfuzz s direct copy module is very effective to solve these magic number verification since it can intercept operands of each cmpinstruction at runtime and insert the magic number back into generated inputs.rq1 c. how much edge coverage does mtfuzz achieve compared to other fuzzers?
evaluation.
to measure edge coverage we run each of the fuzzers for hours all fuzzers use the same seed corpus .
we periodically collect the edge coverage information of all the test inputs for each fuzzer using afl s coverage report toolkit afl showmap .
afl provides coverage instrumentation scheme in two mainstream compilers gccandclang .
while some authors prefer to use afl gcc some others use afl clang fast .
the underlying compilers can have different program optimizations which affects how edge coverage is measured.
therefore in order to offer a fair comparison with previous studies we measure edge coverage on binaries compiled with with both afl gcc andafl clang fast .
in the rest of the paper we report results on programs compiled with afl clang fast .
we observed similar findings with afl gcc .
observations.
the results for edge coverage after hours of fuzzing are tabulated in table .
the edge coverage gained over time is shown in fig.
.
overall mtfuzz achieves noticeably more edge coverage than all other baseline fuzzers.
consider the performance gains obtained over the following families of fuzzers evolutionary fuzzers mtfuzz outperforms all the three evolutionary fuzzers studied here.
mtfuzz outperforms angora on the programs which angora supports and achieves up to more edges in objdump .
note angora can t run on some programs due to the external library issue on its taint analysis engine .
when compared to both fairfuzz and aflfast mtfuzz covers significantly more edges e.g.
more than fairfuzz in readelf and over .
edges compared to aflfast on objdump .
machine learning based fuzzers in comparison with the state ofthe art ml based fuzzer neuzz we observed that mtfuzz achieves much greater edge coverage in all programs studied here.
we notice improvements of more edges in readelf and more edges in nmandstrip .
mtfuzz found real world bugs were previously unknown and also reach on average 277and up to 867more edges compared to neuzz the second best fuzzer on 10programs.
rq2 contributions of auxiliary tasks mtfuzz is comprised of an underlying multi task neural network mtnn that contains one primary task edge coverage and two auxiliary tasks namely context sensitive edge coverage and approachsensitive edge coverage.
a natural question that arises is how much does each auxiliary task contributes to the overall performance?
evaluation .
to answer this question we study what would happen to the edge coverage when one of the auxiliary tasks is excluded from the mtfuzz .
for this we build four variants of mtfuzz ec a single task nn with only the primary task to predict edge coverage.
ec call ctx an mtnn with edge coverage as the primary task and context sensitive edge coverage as the auxiliary task.
ec approach an mtnn with edge coverage as the primary task and approach sensitive edge coverage as the auxiliary task.
mtfuzz our proposed model with edge coverage as the primary task and two auxiliary tasks context sensitive edge coverage and approach sensitive edge coverage.mtfuzz fuzzing with a multi task neural network esec fse november virtual event usa mtfuzz neuzz angora fairfuzz aflfast afl time01000200030004000coverageharfbuzz time0150030004500strip time0100020003000size time0200400600libjpeg time0150030004500objdump time0150030004500nm time060012001800libxml0 time0120240360zlib time04008001200mupdf time0300060009000coveragereadelf figure edge coverage over hours of fuzzing by mtfuzz and other state of the art fuzzers.
table edge coverage after hour.
the most improvement to edge coverage is observed when including both the auxiliary tasks are trained together as a multi task learner.
programs ec ec call stack ec approach mtfuzz readelf nm objdump size strip harfbuzz libjpeg mupdf libxml2 zlib to rule out other confounders we ensure that each setting shares the same hyper parameters and the same initial seed corpus.
also we ensure that all subsequent steps in fuzzing remain the same across each experiment.
with these settings we run each of the above multi task models on all our programs from table for hour to record the edge coverage for each of these mtnn models.
observations .
our results are tabulated in table .
we make the following noteworthy observations .
fuzzer that uses an mtnn trained on edge coverage as the primary task and context sensitive edge coverage as the only auxiliary task tends to perform only marginally better than a single task nn based on edge coverage.
in some cases e.g.
in table we notice about more edges.
however in some other cases for example libjpeg we noticed that the coverage reduces by almost .
.
the above trend is also observable for using edge coverage with approach sensitive edge coverage as the auxiliary.
for example in libjpeg the edge coverage is lower than the single task model that uses only edge coverage.
.
however mtfuzz which uses both context sensitive edge coverage and approach sensitive edge coverage as auxiliary tasks to edge coverage performs noticeably better than all other models with up to800 more edges covered in the case of readelf .the aforementioned behavior is expected because each auxiliary task provides very specific albeit somewhat partial context to edge coverage.
context sensitive edge coverage only provides context to triggered edges while approach sensitive edge coverage only reasons about non triggered edges see .
for details .
used in isolation a partial context does not have much to offer.
however while working together as auxiliary tasks along with the primary task it provides a better context to edge coverage resulting in overall increased edge coverage see the last column of table .
mtfuzz benefits from both the auxiliary tasks.
using contextsensitive edge coverage and edge coverage along with the primary task of predicting edge coverage is most beneficial.
we achieve up to more edge coverage.
rq3.
impact of design choices while building mtfuzz we made few key design choices such as using a task specific adaptive loss .
.
to improve the quality of the multi task neural network mtnn model and a novel seed selection strategy based on importance sampling see .
.
here we assess how helpful these design choices are.
rq3 a. what are the benefits of using adaptive loss?
mtnn model predicting for edge coverage and for context sensitive edge coverage tends to experience severely imbalanced class labels.
consider the instance when a certain input triggers an edge for the first time.
this is an input of much interest because it represents a new behaviour.
the mtnn model must learn what lead to this behaviour.
however in the training sample there exists only one positive sample for this new edge in the entire corpus.
an mtnn that is trained with an off the shelf loss functions is likely to misclassify these edges resulting in a false negative error.
such false negatives are particularly damaging because a large number of new edge discoveries go undetected affecting the overall model performance.
to counter this we defined an adaptive loss in .
.
here we measure how much it improves the mtnn s performance.
evaluation .
to evaluate the effect of class imbalance we measure recall which is high when the overall false negatives fn are low.
while attempting to minimize fns the model must not make tooesec fse november virtual event usa she d. krishna r. yan l. jana s. and ray b. table impact of design choices.
adaptive loss .
.
increases recall by while maintaining similar f1 scores.
seed selection based in importance sampling .
demonstrate notable gains in overall edge coverage.
adaptive default seed selectionprogramsrecall f1 recall f1 our approach random readelf nm objdump size strip harfbuzz libjpeg mupdf libxml2 zlib many false positive fp errors.
although false positives are not as damaging as false negatives we must attempt to keep them low.
we therefore also keep track of the f1 scores which quantify the trade off between false positives and false negatives.
we train mtfuzz with two different losses i.e.
with our adaptive loss and with the default cross entropy loss on 10programs for 100epochs and record the final recall and f scores.
observations .
the result are shown in table .
we observe that adaptive loss results in mtnns with an average of recall score on10programs while the default loss model only achieves on average75 recall score.
generally we notice improvements greater than over default loss functions.
the low recall for default loss function indicates that it is susceptible to making a lot of false negative predictions.
however our adaptive loss function is much better at reducing false negative predictions.
also the adaptive loss model achieves on average f score of while unweighted loss model achieves an average of .
this is encouraging because even after significantly reducing the number of false negatives we maintain the overall performance of the mtnn.
weighted loss improves mtfuzz s recall by more than .
rq3 b. how does seed selection help?
evaluation .
here we evaluate our seed selection strategy .
by comparing it to a random selection strategy.
specifically we run two variants of mtfuzz one with importance sampling for seed selection and the other with a random seed selection.
all other components of the tool such as mtnn model hyperparameters random seed etc.
are kept constant.
we measure the edge coverage obtained by both the strategies on programs after fuzzing for one hour.
table shows the results.
observations .
when compared to a random seed selection strategy.
importance sampling outperforms random seed selection in all 10programs offering average improvements of .
more edges covered than random seed selection for readelf it covers around more edges.
this makes intuitive sense because the goal of importance sampling was to retain the newly generated inputs that invoke certain rare edges.
by populating the corpus with such rare and novel inputs the number of newly explored edges would increase over time resulting in increase edge coverage see table .table generalizability of mtfuzz across different programs parsing the same file types elfand xml .
the numbers shown represent new edge coverage.
inputs embedding inputs only rq4 a file type source targetmtfuzz rq4 b mtfuzz neuzz afl nm nm size nm readelf nm size size readelf size nm size readelf readelf size readelf 327elf nm readelf xmlwf xmlwf libxml2 xmlwf libxml2 libxml2 73xml xmlwf libxml2 indicates baseline setting without transfer learning importance sampling helps mtfuzz achieve on average .
edge coverage compared with random seed selection.
rq4.
transferability in this section we explore the extent to which mtfuzz can be generalized across different programs operating on the same inputs e.g.
two elf fuzzers .
among such programs we study if we can transfer inputs generated by fuzzing from one program to trigger edge coverage in another program rq4 a and if it is possible to transfer the shared embedding layers between programs rq4 b .
rq4 a. can inputs generated for one program be transferred to other programs operating on the same domain?
mtfuzz mutates the hot bytes in the inputs to generate additional test inputs.
these hot bytes are specific to the underlying structure of the inputs.
therefore inputs that have been mutated on these hotbytes should be able to elicit new edge coverage for any program that parses the same input.
evaluation.
to answer this question we explore different programs that operate on file types readelf size and nmoperating on elf files and libxml andxmlwf operating on xml files.
for all the programs that operate on the same file format we pick a source program say s pi and use mtfuzz to fuzz the source program for hour to generate new test inputs.
next for every other target program t pj i we use the test inputs from the previous step to measure the coverage.
note that we do not deploy the fuzzer on the target program we merely measure the code coverage.
for comparison we use neuzz another ml based fuzzer and afl to fuzz the source program sto generate the test inputs for the target program.
observation.
we observe from table that inputs generated by mtfuzz produce much higher edge coverage on the target program compared to seeds generated by neuzz or afl.
in general we notice on average more edge coverage than afl and more edge coverage than neuzz.
here afl performs the worse since it generates seeds very specific to the source program.
neuzz a machine learning based fuzzer performs better than afl since itmtfuzz fuzzing with a multi task neural network esec fse november virtual event usa attempts to learn some representation of the input but it falls short ofmtfuzz which learns the most general input representation.
rq4 b. can the shared layer be transferred between programs?
we hypothesize that since mtfuzz can learn a general compact representation of the input it should in theory allow for these compact representations to be transferred across programs that share the same input e.g.
across programs that process elfbinaries.
evaluation to verify this we do the following we pick a source program say s pi and use mtfuzz to fuzz the source program for hour to generate new tests inputs.
for every target program t pj i we transfer the shared embedding layer along with the test inputs from the source program to fuzz the target program.
note that the key distinction here is unlike rq4 a here we fuzz the target program with mtfuzz using the shared layers and the seed from the source program to bootstrap fuzzing.
observation.
we achieve significantly more edge coverage by transferring both the seeds and the shared embedding layers from the source to target program .
on average we obtain more edge coverage on all 10programs.
specifically transferring the shared embedding layers and the seeds from nmtoreadelf results in covering more edges compared to neuzz and over more edges compared to afl.
transferring offers better edge coverage compared to fuzzing the target program with afl.
mtfuzz s compact embedding can be transferred across programs that operate on similar input formats.
we achieve up to 14times edge coverage for xml files with an average of 2times edge coverage across all programs compared to other fuzzers.
threats to validity a initialization for the fuzzers studied here it is required to provide initial set of seed inputs.
to ensure a fair comparison we use the same set of seed inputs for all the fuzzers.
b target programs we selected diverse target programs from a wide variety of software systems.
one still has to be careful when generalizing to other programs not studied here.
we ensure that all the target programs used in this study have been used previously we do not claim that our results generalize beyond these programs.
c other fuzzers when comparing mtfuzz with other state of theart fuzzers we use those fuzzers that are reported to work on the programs tested here.
our baseline fuzzer neuzz has reported to outperform many other fuzzers on the same studied programs.
since we are outperforming neuzz it is reasonable to expect that we will outperform the other fuzzers as well.
related work fuzzing has garnered significant attention recently.
there are three broad types of fuzzers a blackbox with no knowledge of the target program b whitebox with source binary level access the target program and c greybox fuzzers like afl with the ability to instrument and collect some target program specific information like code coverage.
this paper specifically focuses on greybox fuzzers.
most greybox fuzzers use evolutionary search to guide their input generation strategy .
since the release of afl the researchers have attempted toimplement a wide range of mutation strategies augmented with program analysis to optimize the evolutionary mutation process .
all of these projects focus on manually designing different mutation strategies and use either program analysis or aggregate statistics to customize their strategy for specific target programs.
by contrast mtfuzz uses multi task neural networks to automatically learn an compact representation of input to identify and mutate the hot bytes.
more recently machine learning techniques are being increasingly used to improve fuzzing.
one line of work focused on using neural networks to model the input format of the target programs based on a corpus of sample inputs .
another alternative approach like neuzz models the edge behaviour of a program using a neural network.
in this paper we demonstrate that neural networks can be further used to adaptively learn a number of mutation parameters that can significantly improve edge coverage.
transfer learning is beneficial when there is insufficient data for a target task but there exists sufficient data for other source task.
to ensure ideal transfer the target task and source task should have same or similar feature space and share similar data distribution.
raina et al .
and dai et al .
use transfer learning to perform cross domain text classification.
long et al .
and sun and saenko apply transfer learning to solve image classification problem.
we demonstrate that mtfuzz can transfer a nn learnt on one program to other similar programs.
conclusion this paper presents mtfuzz a multi task neural network fuzzing framework.
mtfuzz learns from multiple code coverage measures to reduce a sparse and high dimensional input space to a compact representation.
this compact representation is used to guide the fuzzer towards unexplored regions of the source code.
further this compact representation can be transferred across programs that operate on the same input format.
our findings suggest mtfuzz can improve edge coverage significantly while discovering several previously unseen bugs.