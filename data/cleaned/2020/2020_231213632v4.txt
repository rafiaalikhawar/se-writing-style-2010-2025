accepted at ieee acm 47th international conference on software engineering icse tracefl interpretability driven debugging in federated learning via neuron provenance waris gill computer science department virginia tech blacksburg usa waris vt.eduali anwar computer science and engineering department university of minnesota minneapolis usa aanwar umn.edumuhammad ali gulzar computer science department virginia tech blacksburg usa gulzar cs.vt.edu abstract in federated learning clients train models on local data and send updates to a central server which aggregates them into a global model using a fusion algorithm.
this collaborative yet privacy preserving training comes at a cost.
fl developers face significant challenges in attributing global model predictions to specific clients.
localizing responsible clients is a crucial step towards a excluding clients primarily responsible for incorrect predictions and b encouraging clients who contributed highquality models to continue participating in the future.
existing ml debugging approaches are inherently inapplicable as they are designed for single model centralized training.
we introduce tracefl a fine grained neuron provenance capturing mechanism that identifies clients responsible for a global model s prediction by tracking the flow of information from individual clients to the global model.
since inference on different inputs activates a different set of neurons of the global model tracefl dynamically quantifies the significance of the global model s neurons in a given prediction identifying the most crucial neurons in the global model.
it then maps them to the corresponding neurons in every participating client to determine each client s contribution ultimately localizing the responsible client.
we evaluate tracefl on six datasets including two real world medical imaging datasets and four neural networks including advanced models such as gpt.
tracefl achieves accuracy in localizing the responsible client in fl tasks spanning both image and text classification tasks.
at a time when stateof the art ml debugging approaches are mostly domain specific e.g.
image classification only tracefl is the first technique to enable highly accurate automated reasoning across a wide range of fl applications.
index terms interpretability explainability debugging machine learning federated learning transformer i. i ntroduction federated learning fl offers distributed training that enables multiple clients to collaboratively train a global model without sharing raw data .
in a typical fl setup individual clients such as healthcare institutions train models on their local data.
these local models are then aggregated on a central server to form a comprehensive global model all without transferring sensitive client data.
the resulting global model a fusion of all clients models is then used in production to make predictions on unseen data.
the complexity of fl systems however introduces unique debugging challenges.
when a global model makes a prediction whether correct or incorrect a key question arises which client s is primarily responsible for a global model soutput?
this question is akin to debugging software where understanding the impact of each input and the line of code on the software s output is crucial.
addressing this debugging question is vital for the effective deployment maintenance and accountability of fl applications.
for example fl developers face challenges in identifying and rewarding clients responsible for successful classifications.
this recognition is crucial to encourage their continued participation in future incentivized fl rounds .
there is mature evidence that such practice significantly improves the fl model s quality .
similar debugging is key in localizing faulty clients that may transfer an inaccurate model for aggregation which can result in a dangerously low quality global model .
problem.
in federated learning the client s most responsible for a global model s prediction are the ones trained on data that contains the predicted labels .
this is analogous to finding influential training samples in classical machine learning .
however the two domains single model based centralized ml and fl are fundamentally different.
existing influence based debugging approaches in ml and regular software require transparent access to data including all data manipulation operations applied on the input data.
when applied to fl these approaches will require endto end monitoring of clients training i.e.
require access to clients data which is prohibited in fl.
more broadly ml influence and interpretability based debugging approaches target a single model in which the debugging is restricted to identifying the training data.
in contrast debugging in fl entails isolating a client s model among many.
this paper addresses the following debugging problem in fl given the global model inference on an input in fl how can we identify the client s most responsible for the inference?
challenges.
determining a client s influence on the global model is challenging.
clients are randomly sampled in each round each possessing unique data and contributing differently to the global model.
thus the influence of a client on the global model is dynamic non uniform and changes across rounds making it difficult to link the global model s behavior to a specific client.
the fl protocol restricts access to clientside training turning fl configuration into a nearly blackbox setting.
additionally clients models are collections of neuron weights that are individually uninterpretable.
static 1arxiv .13632v4 jan 2025accepted at ieee acm 47th international conference on software engineering icse analysis of models weights to measure clients influence is ineffective because clients models are intrinsically different in terms of weights.
furthermore neural networks today comprise millions of neurons e.g.
gpt has billion parameters .
considering all neurons equally in such cases would lead to imprecise and incorrect debugging.
fl is increasingly used for domains other than vision using various neural networks such as transformer and convolutional neural networks cnns .
designing a generic fl debugging approach is a major challenge.
for instance transformers contain a self attention mechanism that allows the model to focus on different parts of the input sequence.
this mechanism is usually not seen in cnns instead it uses a convolutional layer to detect the special patterns in the input data.
additionally these architectures use different activation functions such as rectified linear unit relu and gaussian error linear unit gelu introducing another source of complications.
our contribution.
we present the concepts of neuron provenance a fine grained lineage capturing mechanism that formulates the flow of information in the fusion algorithm from multiple clients models into a global fl model ultimately influencing the predictions of the global model.
using neuron provenance we determine the precise magnitude of contributions of participating clients towards the global model s prediction.
we materialize the idea of neuron provenance in tracefl which runs at the aggregator i.e.
central server and requires no instrumentation on the client side.
tracefl is designed with the following insights.
since a global model consists of millions of neurons we observe that a dynamic subset of neurons activates in response to a given input and not all neurons contribute equally to a prediction .
using this insight tracefl quantifies the contribution of these neurons in the global model s prediction by computing the gradient of the neurons w.r.t.
to the prediction.
such neuron level gradients reveal the neuron s output impact on the global model s prediction and thus reduce the scope of important neurons.
tracefl then maps the global model s important neurons to the corresponding neurons in each client s model and computes the contribution of each client s neuron to the corresponding global model s neuron.
at this stage tracefl computes the end to end neuron provenance of the global model prediction with the magnitude of the contribution of each client s neurons.
finally tracefl aggregates the contributions of each client.
the client with the highest contribution is deemed the most responsible for the given prediction.
evaluations.
we demonstrate tracefl s effectiveness generalizability and robustness by evaluating its client localization accuracy on both image and language models under various commercial data distributions and differential privacy methods.
we evaluate tracefl on four state of the art neural networks resnet densenet bert and gpt and using six datasets including two real world medical imaging datasets .
tracefl achieves an average accuracy of in localizing the responsible client across unique flsettings spanning both correct and misprediction scenarios.
for fault localization in fl tracefl achieves an average accuracy of compared to by the existing technique demonstrating tracefl s effectiveness in realworld fl deployments.
additionally we test tracefl s robustness against varying data distributions and differential privacy settings and find that tracefl remains robust and effective.
we also vary the number of clients increasing it up to and find that tracefl is both scalable and efficient.
overall we evaluate tracefl on trained client models.
these experiments exceed prior research s evaluation complexity and fully represent commercial fl usage .
tracefl is implemented in flower fl and compatible with gpu for parallel processing of neuron provenance for computeintensive models e.g.
gpt .
tracefl advances the state of fl debugging with the following core contributions tracefl localizes the responsible clients for a given prediction without modifying the underlying fusion algorithm.
moreover it does not require access to clients training and can solely determine clients contributions at the central aggregator.
tracefl introduces a unique concept of neuron provenance for fl applications to capture the dynamic contribution of each client which helps rank clients based on the contribution to a given prediction.
tracefl efficiently tracks the contribution of clients in large models like gpt containing millions of parameters.
tracefl achieves localization accuracy in localizing the responsible client in fl.
tracefl s localization accuracy remains high during localizing a faulty client where existing baseline achieves .
tracefl is the first approach that is equally effective on transformers and cnns.
even the most sophisticated ml debugging approaches work on single model architecture and data domains i.e.
either cnns or transformers.
tracefl significantly advances the field of debugging and interpretability in fl addressing open challenges in fl and work with differential privacy and realworld data distributions among fl clients.
source code.
tracefl s artifact is available at com seed vt tracefl.
ii.
b ackground and motivation a. federated learning federated learning enables multiple clients e.g.
mobile devices organizations to train a shared model without sharing their data.
this allows the model to be trained using distributed data which can be useful in cases where data is distributed across multiple devices or organizations and cannot be easily collected and centralized.
one algorithm of fl is federated averaging fedavg which uses the following equation to update the global model at each round of the training process wt global kx k 1nk nw t k 2accepted at ieee acm 47th international conference on software engineering icse h0h1h2h3h4h5h6h7h8h9 training data pointshospital training data distribution across hospitals adiposebackgrounddebrislymphocytesmucussmooth musclenormal colon mucosacancer associated stroma .... global modelhospitals local modelsfl training round responsible client localization with traceflclassificationtest inputs mucuscancer associated stroma0.34h20.33h40.25h30.02h10.02h70.01h50.01h60h80.37h60.32h50.25h70.02h30.01h10.01h80.01h20h4 hospital h2 have data points with label mucus hospital h6 have data points with label cancer associate stromacancermucus fig.
illustration of training testing and localization phases of the real world motivating example.
the fl global model correctly classifies two colon pathology images original labels cacner associated stroma and mucus .
during responsible client localization tracefl accurately identifies the client most responsible for the prediction i.e.
clients trained on data points with labels mucus hospital h2 and cancer associated stroma hospital h6 .
where w t kandnkrepresent received weights and size of training data of client kin each round t respectively.
the variable nrepresents the total number of data points from all clients and it is calculated as n pk k 1nk.
the equation states that the global model wt 1at the next round is the average of the local models from all participating clients at the current round.
in each round the clients first train their local models using their own data then send the parameters e.g.
w t k nk to the central server.
the central server averages the model parameters to produce a global model which is then sent back to the participating devices.
this process is repeated for multiple rounds e.g.
tfrom to with each client updating its local model using the global model from the previous round.
the final global model is the result of the federated averaging process.
fl has variations such as vertical fl and personalized fl .
tracefl primarily focuses on horizontal fl similar to previous work on fault localization in fl .
a typical fl setup involves a few to thousands of clients such as mobile devices healthcare institutions or enterprises.
fl clients exhibit diversity in data distribution and computational resources.
data is often non independently and identically distributed non iid with varying sizes across clients such as hospitals specializing in different medical conditions figure .
all participating clients use the same neural network architecture ensuring compatibility during model aggregation.
additionally clients have heterogeneous hardware and network capabilities e.g.
smartphones to powerful servers impacting their participation and training consistency .
b. motivation suppose a developer deploys an fl system to diagnose colon diseases based on colon pathology images as shown in figure .
in this fl system ten hospitals identified as h0 to h9 collaborate to train a global fl model.
each hospital trains its local model which is then aggregated to form a global model.
the classification stage in figure shows a scenariowhere the global model makes a correct prediction on new test colon pathology images e.g.
cancer associated stroma and mucus .
since these are correct predictions the fl developer aims to determine which hospital is most responsible for these correct predictions so that it can be encouraged to participate in future rounds.
since the training data is protected under the privacy of medical records and inaccessible to the developer it is challenging to identify the responsible hospital by inspecting the raw model weights shared by the hospitals.
to address this issue the developer decides to use tracefl to identify the most responsible client behind the correct predictions.
when enabled during the global model s prediction tracefl localizes the hospital with h2 as the one responsible for the prediction of mucus and the hospital h6 as the one responsible for the prediction of cancerassociated stroma .
more specifically as shown on the right in figure tracefl ranks hospitals i.e.
clients based on their contributions to each prediction.
the score associated with each hospital quantifies how responsible a hospital is for that prediction.
the training data distribution on the left shows that h2 s training data include data points labeled mucus whereas h6 s training data include data points labeled cancer associated stroma .
conversely hospital h1 s contribution is .
and .
in the two predictions because it does not have any data points with the labels mucus or cancer associated stroma respectively.
detailed evaluations on two real world medical imaging datasets are presented in section v a. localizing the clients responsible for the prediction with tracefl serves as a basis for designing advanced incentivization approaches.
iii.
c hallenges in debugging fl federated learning poses several challenges in designing a debugging technique that reasons about a global model s prediction on an input.
unlike traditional ml training where training data can be easily analyzed the fl global model wt global is not directly trained on the data.
instead the global 3accepted at ieee acm 47th international conference on software engineering icse model is generated by fusing clients models together across many rounds using popular fusion algorithms.
with no insight into the training it is challenging to identify how different clients influence the global model s behavior.
state of the art neural networks such as transformers bert gpt and cnns resnet densenet have varying structures activation functions and numbers of parameters.
for example gpt is a layer block transformer architecture with gelu activation function and million parameters.
densenet has layers million parameters and uses the relu activation function.
the fusion algorithm or the global model does not inherently provide any information about individual clients contributions.
thus tracking a client s contribution among millions of parameters is a significantly challenging task.
moreover the data distribution across fl training rounds is non identical clients rarely have the same data point.
not all clients participate in every round and some clients may contain only a few data points to train their local model.
the class label distribution also varies across clients.
such variability causes more hurdles in precisely reasoning about a global model s behavior.
simply tracking the static weights of the global model is inadequate as different sets of neurons are activated on different inputs and not all neurons have equal importance.
inspecting individual clients models does not help understand the client s contribution to the global model prediction as it will not capture the cumulative behavior of the global model.
iv.
d esign of trace fl tracefl addresses the aforementioned challenges using neuron provenance .
at a high level tracefl dynamically tracks the lineage of the global model at the neuron level and identifies the most influential clients against a given prediction by the global model wt global on an input.
enabling provenance at the neuron level solves the complexities of different neural networks architectural design e.g.
number of layers and parameters different activation functions and enables tracefl to work in cross domains such as image and text classification tasks.
in essence tracefl first identifies the influential neurons by jointly analyzing neuron activations the layers the neurons are in and gradients with respect to individual neurons in the global model for a given test input.
next tracefl precisely quantifies the individual contribution of each corresponding neuron from every participating client to the neurons in the global model.
finally tracefl computes the total contribution of each client to the global model.
these steps collectively construct a comprehensive end to end provenance graph which is used to debug the contributions of clients in the given prediction of the global model.
algorithm outlines the design of tracefl.
a. determining influential neurons tracefl first aims to identify neurons that actively participate in an fl global model s prediction.
traditional dataalgorithm tracefl s approach input letclients be the list of clients models participating in the fl training round.
input letglobal model be the aggregated global model of clients models after the end of a training round input lettestinput be an input output client 2norm contribution contains the contribution of each client in the prediction of testinput 1activated neurons section iv a equation 2y global model test input 3foreach neuron inglobal model do activated neurons .append neuron 5neuron2grad y.backward section iv b 6neuron2prov 7forneuron inactivated neurons do neuron2prov forclient inclients do cont forfeature inneuron.input features do cont client.weight neuron feature feature.value neuron2prov cont neuron2grad section iv c 14client2contribution 15forclient inclients do equation contribution forneuron inneuron2prov do contribution neuron2prov client2contribution contribution equation 20client2norm contribution softmax client2contribution.values 21return client2norm contribution provenance approaches must trace the participation of all input data records in the operation for completeness eventually mapping them to individual outputs of the operation.
however tracking the provenance of all neurons with equal importance is wasteful because not all neurons participate equally in a model s prediction.
therefore tracking the behavior of neurons with the same importance in a model may lead to over approximation i.e.
more than expected clients are classified as contributors when provenance is used to identify the contributing clients.
the behavior of a neural network on a given input is determined by the set of activated neurons in the network and different sets of neurons are activated on different inputs.
we leverage this insight and apply tracefl s neuron provenance to dynamically quantify the influence of global model neurons on each prediction for the given input.
this reduces the likelihood of over approximation by minimizing the contribution of neurons that may distort the outcome when the lineage of a specific neuron is used to localize the influential client.
mathematically the output of a neuron is z w z where wis the set of weights of the neuron zis the input to a neuron and is the activation function.
one of the commonly used activation functions is relu .
the output of is called the activation or output of the neuron.
a neuron with relu function is considered active if z .
note that the 4accepted at ieee acm 47th international conference on software engineering icse output of a neuron z is part of the input to the neurons of the next layer.
next tracefl computes the activation of each neuron in the network.
suppose that njrepresents the j th neuron in a neural network and the set of all the outputs i.e.
activations of all the neurons in a neural network can be represented as zn1 zn2 ... z nj which captures the complete dynamic behavior of the network on a given test input x. note that for the first layer the input zto neurons will be the input xto the model i.e.
z xfor the first layer of the neural network.
after computing the global model neurons activations tracefl s goal is to find their measurable contribution towards the global model s prediction y on an input.
in the output y of the global model not all the neurons carry equal importance.
for instance neurons in the last layers learn better and more rigorous features than neurons in the initial layers of the network .
since tracefl aims to localize the client that contributed the most towards a prediction assigning equal importance to all neurons will again cause over approximation or even wrong client localization.
to enable precise and accurate provenance we must measure the individual influence of a neuron on the final prediction.
tracefl quantifies the impact of the output of a neuron on the global model s prediction by computing the gradient w.r.t.
every activated neuron on a given input to wt global.
similar to taint analysis in program analysis gradients are sophisticated taints that encapsulate the impact of a neuron output on the output y of the global model.
the intuition behind this is that the neurons with a higher gradient will likely cause a bigger change in prediction.
thus such neurons are likely to be more influential to a model prediction.
we use the aforementioned insight to find the influence of a neuron in the prediction y of the global model.
the influence denoted by cnj of a neuron njin the output y is the partial derivative of ywith respect to znj which measures how much ychanges when znjchanges slightly.
mathematically we write it as cnj y znj tracefl computes the gradients using the automatic differentiation engine of pytorch .
tracefl starts from the output layer and goes back to the input layer using the chain rule of differentiation at each step.
by the end of this phase tracefl determines the gradient influence of global model neurons on its output y .
for instance in the presence of a disease in a medical imaging input e.g.
predicting colorectal cancer crc from histological slides of tumor tissue the fused neurons of the global model that have learned the representation of that particular disease during fl training will significantly influence the model s output y .
these gradients are essential in mapping neurons of clients models to the most influential ones in the global model.
b. neuron provenance across fusion in this step tracefl accurately determines the individual contribution of each corresponding neuron from every participating client to the neurons of the global model.
in essence tracefl maps the outputs of the global model neurons to clients neurons during prediction.
finding such a mapping and its magnitude has two challenges.
first fl uses fusion algorithms to merge clients neurons statically.
instrumenting the fusion algorithms to trace the flow of weights across fusion is prohibitively expensive as numerous clients participate in a round where each model may have millions of neurons.
second the influence of clients neurons on the neurons of the global model wt global is directly impacted by the output of the preceding layer in the global model i.e.
the output of the neuron in the global model s previous layer is the combined output of the corresponding neurons of each client in that layer.
consequently attempting to determine clients neurons contributions by feeding input to the clients model in isolation will lead to incorrect neuron provenance as it cannot capture the overall impact of other clients.
tracefl leverages the insight that the set of weights of a single neuron in the global model is determined by the corresponding weights of the neurons in the clients models.
mathematically the weights of a single neuron in the global model represented as wg w1 g w2 g wi g are given by the following equation wi g kx k 1pk wi k p1 wi p2 wi pk wi k here wi kis the i th weight of the neuron in the k th client model.
the variable pkisnk n where nkrepresents the size of training data of client k and nrepresents the total number of data points from all clients and it is calculated as n pk k 1nk equation .
given an input zto the neuron wgof wt global a client s contribution can be calculated as follows zout wg z w1 g w2 g wi g w1 g z1 w2 g z2 wi g zi p1 w1 p2 w1 pk w1 k z1 p1 w2 p2 w2 pk w2 k z2 p1 wi k p2 wi pk wi k zi here ziis the i th input feature to the neuron and zoutis the output of the neuron.
thus the contribution of a client k denoted by in a neuron njof the global model wt global is given by the following equation nj pk w1 k z1 pk w2 k z2 pk wi k zi cnj pk w1 k z1 w2 k z2 wi k zi cnj cnj pk x i 1wi k zi in the above equation pk p i 1wi k ziis the exact contribution of a client kin a neuron njof the global model.
5accepted at ieee acm 47th international conference on software engineering icse the global gradient of neuron njiscnjwhich is multiplied with client contribution to find its actual contribution i.e.
influence towards the prediction of the global model.
for instance if the contribution of a client kis high in a neuron njbut globally the neuron njhas minimal influence on the global model prediction then cnjwill scale down the contribution of the client in the given neuron nj.
note that zi represents the i th output of the previous layer in the global model during prediction.
at the end of this stage tracefl constructs a neuron provenance graph that traces a global model s prediction to influential neurons in the global model wt global which are further traced back to individual neurons in the clients models.
c. measuring client s contribution to find the end to end contribution we must accumulate neuron level provenance cnj pk p i 1wi k zi of a given client s model to derive its complete contributions toward the global model s prediction.
a client s overall contribution to the global model prediction is determined by the sum of the client s contribution to the neurons of the global model.
specifically if the set of neurons of the global model is denoted by n1 n2 nj then the total contribution tk of the client kcan be calculated using equation as follows tk n1 n1 n2 n2 nj nj cn1 x i 1wi kn1 zi n1 n1 cn2 x i 1wi kn2 zi n2 n2 cnj x i 1wi knj zi nj nj pk is an importance factor that tracefl computes using an exponential decay method for each neuron based on its position in the neural network.
specifically tracefl assigns higher importance to the last layers and lower importance to the earlier layers to minimize the noisy contributions based on the evidence presented elsewhere .
njis the contribution of the client kin neuron nj zi njis the i th input feature to neuron nj and wi knjis the i th weight of neuron njin the client kmodel.
using equation we can compute for each client k the total contribution towards the global model prediction.
thus the client with max contribution is the client that has the most influence on the global model prediction.
to make the client contribution more interpretable we normalize the client contribution by using the softmax function as follows tk etk pk i 1eti tkis the normalized contribution of the k th client which is now a probability value between and representing the relative influence of client kon the global model output yfor a given input.
tracefl concludes its neuron provenance capturing technique by listing the total contribution of each participating client in an fl round towards a global model s prediction on a given input.
the magnitude of the contributions can beinterpreted as a confidence level of tracefl in identifying the source of the global model s prediction.
given that the total confidence scores of all clients cannot exceed if a client has a contribution score of .
it implies that no other client can surpass a score of .
.
this makes the client most influential in determining the global model prediction and most likely responsible for the prediction.
enable tracefl to use gpu.
by design tracefl is compatible with hardware accelerators and can fully harness their parallelizability.
the primary dependency of tracefl is capturing the output of previous layer neurons in the global model for input to the next layer neurons which inherently exists in inference as well.
additionally tracefl computes gradients using equation leveraging the chain rule of differentiation that the hardware accelerators can parallelize.
next equation dissects the global model neuron and computes the contribution based on the previous layer neurons outputs z of the global model which is the cumulative output of all clients neurons in that previous layer.
this is the only dependency in tracefl.
once tracefl has the cumulative output from the previous layer neurons it parallelizes the process to find the contribution of a client in each neuron of the global model in the current neuron layer and ultimately the total contribution using equations and .
these optimizations in tracefl enable neuron level provenance for neural networks primarily deployed on gpus such as gpt.
v. e xperimental evaluations we design experiments to evaluate tracefl s accuracy in localizing the client responsible for a global model s prediction on an input.
we ask the following research questions.
how accurate is tracefl in identifying the client s responsible for a global model s prediction?
is tracefl equally accurate on fl of different models and architectures such as cnns and transformers gpt ?
how accurate tracefl is in localizing clients responsible for mispredictions by global model?
does tracefl remain effective with varying data distributions and differential privacy?
can tracefl scale to a large number of clients?
what is the runtime performance of tracefl?
models and datasets.
we evaluate tracefl on state of the art and commercially used cnns including resnet and densenet as well as the two most popular transformer models bert and gpt to demonstrate the wide applicability of tracefl.
we train resnet and densenet on cifar and mnist .
these network dataset combinations are widely used and serve as standardized benchmarks in practice .
we also evaluate tracefl on real world medical imaging datasets including the colon pathology dataset and abdominal ct dataset to demonstrate its usability in complex real world fl systems.
the colon pathology dataset contains biomedical images representing nine classes of colon pathology while the abdominal ct dataset contains images of abdominal ct scans representing classes.
more details about these 6accepted at ieee acm 47th international conference on software engineering icse datasets can be found in .
for nlp tasks we evaluate tracefl on bert and gpt models trained on the dbpedia and yahoo answers datasets .
the dbpedia dataset contains training samples and testing samples while the yahoo answers dataset contains training samples and testing samples representing and classes respectively.
data distribution among clients .
we use dirichlet distribution in fl to distribute non overlapping data points among clients in each round.
this is the standard fl data distribution method proven to produce real world distribution .
the parameter in dirichlet ranges from determining the level of non iid in experiments.
for instance when equals it replicates uniform local data distributions while smaller values increase the probability that clients possess samples from a single class .
a value of .
is a common practice in prior work .
we use an even stricter parameter value of .
to stress test tracefl and demonstrate its usability in more challenging cases.
nevertheless section v c1 performs sensitivity analysis by varying from .
to .
these settings inherently simulate varying degrees of label overlap among clients.
to explicitly manage overlapping labels pathological data distributions can be employed as shown in figure .
the pathological data distribution is available in tracefl s artifact.
furthermore tracefl s artifact contains configurable data distributions among clients and allows evaluations on varying numbers of test inputs.
experimental environment.
to resemble real world fl we deploy our experiments in flower fl running on an enterprise level cluster of six nvidia dgx a100 nodes.
each node is equipped with gb of memory at least cores and an a100 gpu with gb of memory.
we vary training rounds between to with clients ranging from to thus testing tracefl on more configurations than any related work .
ten randomly selected clients participate in each round reflecting a realworld scenario where not all the clients participate in the given round .
we evaluate tracefl with fedavg .
localization accuracy.
to measure the performance of tracefl we evaluate the accuracy of tracefl in finding the responsible clients.
for brevity we refer to this as localization accuracy which is defined as follows given the znumber of test inputs to the global model wt global if tracefl accurately locates mtimes the clients responsible for the zpredictions then the localization accuracy ism z. a. tracefl s localization accuracy in correct predictions identifying the clients most responsible for correct prediction is a key debugging objective that helps encourage future participation of those clients to improve the overall fl accuracy.
note that tracefl directly does not improve the fl model accuracy.
instead it reasons about the behavior of the fl global model which an fl developer can use to improve the fl model accuracy e.g.
selecting clients which are contributing more in the fl global model predictions .
01020255075100a colon pathology resnet 01020b abdominal ct resnet 01020c colon pathology densenet 01020d abdominal ct densenet 01020255075100e dbpedia gpt 01020f yahoo answers gpt 01020g dbpedia bert 01020h yahoo answers bert 02040255075100i mnist resnet 02040j cifar10 resnet 02040k mnist densenet 02040l cifar10 densenet communication roundsaccuracy tracefl localization accuracy fl model accuracyfig.
tracefl performance on multiple datasets and models both on text and image classification tasks.
tracefl s neuron provenance traces predictions back to clients trained on those labels ranking clients by their contribution.
tracefl returns a ranked list of clients in descending order of responsibility towards a prediction where the client with the highest score is likely to be most responsible.
we evaluate tracefl s localization accuracy on two realworld medical imaging datasets two standardized image datasets and two nlp classification datasets using resnet densenet bert and gpt models resulting in over fl configurations spanning a total fl rounds and models.
we verify if the most responsible client returned by tracefl contains the data with the label that was correctly predicted by the global model.
we measure the accuracy on at least test inputs in each round.
figure shows tracefl s performance in localizing responsible clients.
the x axis represents training rounds while the y axis shows the fl global model s classification accuracy and tracefl s localization accuracy.
we include the fl global model s accuracy to demonstrate the training progression.
higher global model accuracy improves neuron provenance confidence aiding tracefl s effectiveness.
global model accuracy helps calibrate the provenance results because lower model accuracy leads to low confidence in prediction which transitively reduces the confidence of neuron provenance causing additional challenges for tracefl.
as training progresses and more clients with unique labels participate the global model s accuracy improves.
our results indicate that tracefl consistently localizes responsible clients regardless of the global model s performance neural network architecture number of training rounds or dataset.
it accurately identifies contributions even from clients participating for the first time.
across different fl 7accepted at ieee acm 47th international conference on software engineering icse domain dataset dirichlet distribution feddebug accuracy tracefl accuracy imageabdominal ct0.
.
.
.
.
.
colon pathology0.
.
.
.
.
.
cifar100.
.
.
.
.
.
mnist0.
.
.
.
.
.
textdbpedia0.
na .
.
na .
.
na .
yahoo answers0.
na .
na .
na table i comparison of tracefl with feddebug on localizing clients responsible for misprediction.
feddebug is compatible with image classification only and is effective under specific data distribution i.e.
.
settings tracefl s average localization accuracy on image classification tasks is .
and in text classification tasks it is .
demonstrating its broader effectiveness and applicability to domains other than image classification.
takeaway.
on average tracefl achieves localization accuracy of .
across all fl experiments settings.
b. tracefl s localization accuracy in mispredictions fl s global model can exhibit unwanted behavior e.g.
mispredictions due to intentional or unintentional faults in the training data of clients.
mislabelling in training data may occur due to faulty sensors human error in labeling data or in some cases adversarial attacks .
finding a client responsible for such behavior is a crucial debugging goal that helps fl developers exclude such clients from participating in future rounds to improve the global model s quality.
to evaluate tracefl s localization accuracy on mispredicted labels by a global model we design the following experiments with ten clients.
similarly to prior work on fault localization in fl feddebug we select one client in an fl round and flip a specific label in its training data to make it faulty.
the inclusion of such clients influences the global model to make mispredictions.
for instance in the medical dataset we flip the label cancer associated stroma to adipose in the colon pathology dataset to reflect a faulty hospital containing incorrect label data that may occur due to misdiagnosis.
table i shows the results.
tracefl outperforms feddebug significantly and can operate in cross domain tasks of image and text classification without any change in its approach.
this is expected since feddebug by construction applies to a different problem setting i.e.
debugging the model instead of the prediction and it primarily targets a specific set of non iid data distributions.
even on image classification tasks tracefl outperforms feddebug in terms of localization accuracy.
for .
.
.
.
.
.
avg.
tracefl localization accuracy1.
e yahoo answers0.
.
.
.
.
max fl model accuracyd cifar10a colon pathologyb abdominal ct c mnist f dbpediaaccuracy fig.
tracefl performance on different data distributions.
the x axis represents the values of dirichlet alpha.
instance in abdominal ct with feddebug s average accuracy is .
while tracefl s accuracy is .
takeaway.
tracefl achieves .
average localization accuracy across fl settings whereas feddebug s average localization accuracy is only on image classification.
c. tracefl s robustness varying the client s data distribution and applying differential privacy dp techniques in fl pose additional hurdles to fl in achieving high model accuracy which in turn may pose challenges to tracefl in keeping its high localization accuracy.
therefore to add rigor to our experiments we evaluate the impact of these two additional fl settings on tracefl localization accuracy.
in this section we only include results from the most challenging experiment setting due to space constraints.
varying data distribution different distributions of data among clients can impact the fl training process.
for instance in a highly challenging data distribution .
fl training suffers from low global model accuracy.
this is a known phenomenon in fl where the fl fusion algorithm struggles to aggregate clients models trained on severely heterogeneous training data.
to mitigate bias towards a specific dirichlet data distribution we evaluate tracefl on varying the value of from .
to .
showing the impact of different data distributions on tracefl s localization accuracy.
figure shows the results of this experiment on all six datasets.
the x axis represents the value of in the dirichlet distribution while the y axis represents the accuracy.
for a value of we report the maximum accuracy achieved by the global model across all the rounds as fl model accuracy and the average accuracy of tracefl across all the rounds as localization accuracy of tracefl.
as expected the fl training accuracy decreases as the value of decreases.
this is because the clients have varying data both in terms of quantity and labels.
for instance when .1in figure a the maximum fl global model accuracy observed across all rounds is .
and when .5the maximum accuracy is .
.
since gpt is an advanced neural network architecture that learns better in comparison to densenet the fl training accuracy is higher in gpt on lower values as well.
overall tracefl localization 8accepted at ieee acm 47th international conference on software engineering icse dp noise dp sensitivity fl model accuracy tracefl avg.
accuracy .
.
.
.
.
.
table ii results of tracefl with dp in fl.
.
.
.
.
.
.
.
differential privacy noise050100accuracy avg.
tracefl localization accuracy fl model accuracy fig.
impact of dp noise on fl training accuracy.
accuracy is .
on average across all values of .
the line plots show no significant change in tracefl localization accuracy demonstrating tracefl s robustness in challenging real world data distributions.
differential privacy enabled fl differential privacy dp is a privacy preserving mechanism that ensures that the output of a model does not reveal any information about the individual data points.
dp in fl adds noise to the weights of a model to protect against an adversary stealing or recovering the individual training data points.
however a delicate balance is needed in dp between the noise to be added and model accuracy as adding too much noise severely decreases the model s accuracy.
we evaluate tracefl s robustness when dp is enabled in fl using standard dp settings in fl that provide optimal privacy and model accuracy as mentioned in prior work .
table ii presents the results of this experiment and figure shows the impact of noise on the fl training accuracy.
as expected the fl model s accuracy decreases when the dp noise increases and vice versa.
however tracefl maintains its performance in dp enabled fl.
as dp adds noise to the model weights the global model s output is still based on its neurons activations on the given input.
thus tracefl s working principle remains intact and it successfully traces back to the source of the prediction based on the global model s neuron provenance .
we want to emphasize that tracefl does not recover the individual clients data points.
it only identifies the responsible clients in ranked order.
overall we find that tracefl is robust against the use of differential privacy in fl where it achieves an average localization accuracy of in gpt and dbpedia dataset figure and table ii .
takeaway.
tracefl is robust to challenging real world data distributions and the use of differential privacy achieving approximately localization accuracy.
d. tracefl s scalability we assess the scalability of tracefl across three different dimensions by increase the total clients by increasingtotal clients fl model accuracy tracefl avg.
accuracy .
.
.
.
.
.
.
.
table iii scalability results of tracefl with different number of clients with gpt.
tracefl localization accuracy fl model accuracy communication roundsaccuracy fig.
tracefl s scalability when of rounds increase the client participation and by increasing the number of rounds.
first we vary the number of clients from to and measure if tracefl can still accurately localize the responsible client.
we use the state of the art neural network gpt and the dbpedia dataset.
table iii presents the results of the scalability experiment.
we observe that tracefl s performance remains consistent with an average localization accuracy of across to clients over a total of fl training rounds.
this experiment significantly exceeds the scale of experiments performed by prior work .
when we vary the number of participating clients per round from to tracefl s performance remains stable achieving localization accuracy across fl training rounds.
prior work has shown that even at an enterprise scale only a few clients participate in a single fl round .
furthermore we evaluate the scalability of tracefl over up to rounds with clients in total.
figure demonstrates that tracefl maintains consistent performance with an average localization accuracy of .
these results indicate that tracefl is scalable and can handle numerous clients and rounds without compromising its performance.
takeaway.
overall tracefl is capable of handling the provenance of millions of neurons in the neural network to accurately identify the most responsible client.
in fl settings of up to fl training rounds and clients using large models such as gpt and bert and different datasets tracefl achieves an average localization accuracy of .
.
e. tracefl s localization time we evaluate the runtime performance of tracefl by measuring the time tracefl takes to accurately localize the responsible clients in fl.
as mentioned before there is no existing method that localizes the responsible clients for both correct and incorrect predictions.
the closed related work to tracefl is feddebug which only localizes faulty clients.
thus we compare tracefl s localization time with feddebug s faulty localization time.
9accepted at ieee acm 47th international conference on software engineering icse abdominal ctcolon pathologycifar10mnistdbpedia yahoo answers0510avg.
time s feddebug time s tracefl time s fig.
client localization of tracefl vs. feddebug.
figure presents the localization times per dataset for both tracefl and feddebug averaged across faulty client localization settings.
note that feddebug is not compatible with the text classification models therefore its localization times for the two text datasets are not available.
tracefl takes on average .
seconds to localize the responsible client whereas feddebug s faulty client s localization time is .
seconds on average.
this is expected as tracefl requires computing gradients of neuron outputs whereas feddebug compares raw neuron activations.
while tracefl s localization time is higher than feddebug it is almost negligible compared to the fl s per round training time in minutes if not hours .
takeaway.
tracefl compensates for the marginally slower localization time with much broader debugging support for model architecture text data domains and general purpose reasoning in fl.
f .
threat to validity and limitations there are two primary threats to the validity of the results.
first in our experiments we select a random subset of clients to participate in every round.
a different sequence of randomly selected participating clients may alter the tracefl s accuracy.
we mitigate this threat by performing responsible client localization on every round and then reporting the average localization accuracy across rounds.
second the same dirichlet distribution may provide a different distribution of the training data across clients.
even when the value is the same the localization accuracy of tracefl may vary slightly.
we mitigate this threat by averaging the localization accuracy across rounds and also measuring the localization accuracy on different datasets and models.
tracefl is designed for classification tasks in fl and may not be directly applicable to non classification tasks such as text generation and embeddings generation .
vi.
r elated work debugging and interpretability in machine learning.
as the complexity of neural network models continues to increase the need for interpretability techniques becomes more crucial and important.
interpretability techniques are used to understand the inner workings of a neural network.
these techniques try to explain the decisions made by the model and how the model makes these decisions.
this is important for manyreasons including the ability to explain which input features are important to a model s output to understand the model s behavior and to identify potential biases and errors in a trained model.
several approaches such as integrated gradients gradient shap deeplift saliency guided gradcam occlusion also called sliding window method and lime exist which evaluate the contribution of each input feature to model s output.
for instance integrated gradients evaluates the contribution of each input feature by calculating the integral of gradients w.r.t.
input.
this is done along the path from a selected baseline to the given input.
occlusion involves replacing each contiguous rectangular region with a predetermined baseline or reference point and measuring the difference in the model s output.
this approach is based on perturbations and provides a way to evaluate the importance of input features by measuring the change in the model s output.
existing debugging techniques are designed to identify issues and enhance the performance of a single neural network in centralized ml.
these methods typically require access to training data which is prohibited in fl.
for example npc constructs a decision graph using training data.
furthermore these approaches have not been evaluated on modern neural network architectures such as transformers.
almost all existing debugging and interpretability approaches are inapplicable in fl as by design they solve an orthogonal problem identifying the important feature in the input responsible for a prediction instead of clients.
this distinction is critical because the training data or the training process is completely inaccessible in fl.
existing approaches require access to the client s data.
furthermore they are only designed for a single neural network but the fl global model is a mixture of clients models participating in the given round.
operating these techniques on fl would require us to first identify a suspicious client s mode a problem that tracefl solves.
even if such techniques are applied to a client s model the resulting feedback is not immediately actionable and constructive.
tracefl is designed to address the limitations of the existing debugging approaches and added challenges of fl such as distributed training inaccessibility to clients and the mixture of models.
feddebug introduces differential testing in fl to identify faulty clients by capturing each client s activations for a given input and localizing the client s whose behavior deviates from others.
building on feddebug a backdoor detection technique in fl is presented in .
additionally fedgt aims to identify malicious clients in fl however it is limited to scaling up to clients and has not been tested on advanced architectures like gpt.
despite their contributions these existing methods target a narrower problem under a specialized setting.
feddebug is limited to image classification tasks using cnns restricting its applicability to transformer architectures.
additionally it is designed primarily for faulty clients and iid distributions as demonstrated in table i. in contrast tracefl targets a broader debugging problem using a domain agnostic and 10accepted at ieee acm 47th international conference on software engineering icse highly accurate client localization mechanism applicable to diverse neural network architectures data types and distributions through its novel fine grained neuron provenance .
there has been recent work on ensuring accountability in fl systems.
a vast majority of solutions leverage the blockchain to ensure accountability .
some of these works blockflow blockfla design an fl system that uses the ethereum blockchain to provide accountability and monetary rewards for good client behavior.
however all these systems require utilizing the blockchain and entail significant modifications to the existing fl system presenting a barrier to adoption.
tracefl in contrast can work with any existing system without modifications.
provenance approaches in ml.
provenance has been extensively studied for both ml and dataflow programs .
they address various issues such as reproducibility provide debugging and testing granularities explainability and mitigating data poisoning attacks .
in the context of machine learning provenance tracks the history of datasets models and experiments.
this information is used to select the interpretability of neural network predictions and reproducibility.
provenancebased approaches are important to create ml systems that generate reproducible results .
for instance ursprung captures provenance and lineage by integrating with the execution environment and records information from both system and application sources of an ml pipeline.
ursprung does not require changes to the code and only adds a small overhead of up to .
vii.
c onclusion we introduce the concept of neuron provenance and developed a debugging and interpretability tool tracefl for fl.
tracefl accurately identifies the primary contributors to a global model s behavior.
our evaluations show that tracefl achieves an impressive average localization accuracy of .
furthermore tracefl also outperforms the existing fault localization technique.
we provide a reusable functional artifact of tracefl in the flower framework to have an immediate practical impact in real world fl deployment addressing the open challenges of debugging and interpretability in fl.
acknowledgement we thank anonymous reviewers for providing valuable and constructive feedback to help improve the quality of this work.
this work was supported in part by amazon virginia tech initiative in efficient and robust machine learning 4v a and the national science foundation award .
we also thank the advanced research computing center at virginia tech and the flower fl framework for their support in building and evaluating this work.