green ai do deep learning frameworks have different costs?
stefanos georgiou queen s university stefanos.georgiou queensu.camaria kechagia university college london m.kechagia ucl.ac.uktushar sharma dalhousie uninversity tushar dal.ca federica sarro university college london f.sarro ucl.ac.ukying zou queen s university ying.zou queensu.ca abstract the use of artificial intelligence ai and more specifically of deep learning dl in modern software systems is nowadays widespread and continues to grow.
at the same time its usage is energy demanding and contributes to the increased co2emissions and has a great financial cost as well.
even though there are many studies that examine the capabilities of dl only a few focus on its green aspects such as energy consumption.
this paper aims at raising awareness of the costs incurred when using different dl frameworks.
to this end we perform a thorough empirical study to measure and compare the energy con sumption and run time performance of six different dl models written in the two most popular dl frameworks namely pytorch and tensorflow.
we use a well known benchmark of dl models deeplearningexamples created by nvidia to compare both the training and inference costs of dl.
finally we manually investigate the functions of these frameworks that took most of the time to execute in our experiments.
the results of our empirical study reveal that there is a statistically significant difference between the cost incurred by the twodl frameworks in of the cases studied.
while tensorflow achieves significantly better energy and run time performance than pytorch and with large effect sizes in of the cases for thetraining phase pytorch instead exhibits significantly better energy and run time performance than tensorflow in the inference phase for of the cases always with large effect sizes.
such a large difference in performance costs does not however seem to affect the accuracy of the models produced as both frameworks achieve comparable scores under the same configurations.
our man ual analysis of the documentation and source code of the functions examined reveals that such a difference in performance costs is under documented in these frameworks.
this suggests that developers need to improve the documentation of their dl frameworks the source code of the functions used in these frameworks as well as to enhance existing dl algorithms.
the first two authors contributed equally to this work.
permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
copyrights for components of this work owned by others than acmmust be honored.
abstracting with credit is permitted.
to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
request permissions from permissions acm.org.
icse may pittsburgh pa usa association for computing machinery.
acm isbn ... .
concepts hardware power and energy software and its engineering softwarelibrariesandrepositories computing methodologies machine learning keywords energy consumption run time performance deep learning apis acm reference format stefanos georgiou maria kechagia tushar sharma federica sarro and ying zou.
.
green ai do deep learning frameworks have different costs?.
in44th international conference on software engineering icse may pittsburgh pa usa.
acm new york ny usa pages.
https introduction deep learning dl is a field of machine learning ml that has recently gained significant attention from researchers and prac titioners.
along with the increase of computational power and availability of data the use of deep learning has contributed to the improvement of several applications e.g.
in the medical financial transportation sectors that for instance use speec h and image recognition machine translation and natural language processing nlp .
the advancement in these areas would have not been possible without the great advancement in dl.
while the research community has spent a significant effort towards improving the accuracy of dl approaches it has often overlooked their costs.
as recently reported by schwartz et al.
dl has been assisting in an increase in the computational costs of the state of the art ai research as big as 000x between and .
such a dramatically increasing trend in resource consumption dubbed as red ai is not just often prohibitively expensive for researchers and practitioners but also environmentally unfriendly.
this has motivated the field of green software engineering se research which aims to decrease software environmental footprints and supports inter alia green ai .
optimizing resource utilization used by expensive dl models without compromisingtheir accuracy is important to combat such an environmentally unfriendly and prohibitively expensive trend .
this paper presents an in depth empirical analysis to investigate and compare the energy consumption and run time performance of dl frameworks in particular pytorch and tensorflow.
tothe best of our knowledge this is the first such empirical study.
we select six large models for dl from different ai domains recommender systems nlp and computer vision extracted from a popular benchmark i.e.
deeplearningexamples .
we use the ieee acm 44th international conference on software engineering icse authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
icse may pittsburgh pa usa s. georgiou et al.
benchmark to perform training and inference experiments involving dl algorithms e.g.
transformer cnn gnmt and measure the consumed energy and run time performance.
furthermore to investigate issues that may affect the energy consumption and runtime performance of dl models we examine whether particular functions provided within the pytorch and tensorflow apis can affect the efficiency of dl models.
finally we discuss potential suggestions for improving the energy consumption and run time performance of dl models without compromising accuracy.
our findings show that tensorflow outperforms pytorch regarding energy consumption by .
xand run time performance by .1xwhen training models belonging to the recommender systems and computer vision categories of our benchmark.
by contrast pytorch is .
xmore energy efficient and .
xfaster than tensorflow when training models of the nlp category.
in the inference of the models tensorflow is .
xfaster and .
xmore energyefficient than pytorch only for the recommender systems and resnet models.
regarding accuracy both frameworks achieve a similar score under the same configurations.
therefore under our configurations tensorflow is overall more energy and run time efficient compared to pytorch in the training phase but less efficient in the inference phase.
finally we manually investigated the functions of the frameworks examined that took most of the time toexecute in our experiments.
we argue that the energy consumption and run time performance of such functions could be improved in the future by both improving the documentation and source code of the dl frameworks and optimizing existing core dl algorithms.
the paper makes the following contributions.
a publicly available framework prengdl it stands for performance and energy of deep learning .
an empirical study to compare dl frameworks pytorch and tensorflow regarding energy and run time efficiency using six large models for dl.
an analysis of the issues that hinder the energy consumption and run time performance of dl models for pytorch and tensorflow as well as a discussion on potential recommendations to mitigate the identified issues in the future without sacrificing accuracy.
background deep learning.
dl a subfield of ml allows computational models to compose and arrange in multiple processing layers to learn representations of data with multiple levels of abstraction .
dl techniques are extensively used to solve a variety of detection prediction and classification problems belonging to various domains.
these domains include image recognition speech recognition and nlp .
as in traditional supervised ml dl models consist of two processes training andinference.
training refers to the process of learning weights of the internal nodes ofa dl model using training data to learn patterns from the data.
inference refers to the process of using a trained dl model to make a prediction on unseen data.
each layer in a dl model transforms the sequence of data coming from the previous layer or learns the representation of the input data in the form of weights of the nodes.
a well designed dl model is capable of inferring features during training and can learn toclassify samples based on these inferred features.
for example a convolution neural network cnn mimics the alternating layers of simple and complex cells of the visual cortex in animals .
cnnbased dl models have been proven effective for image classification and detection and face recognition .
similarly a recurrent neural network rnn and a fully connected neural network are among the various layers that are used to compose a dl model their arrangement within a dl model is often influenced by the problem at hand .
the wealth of available software specific artifacts coming from abundant open source repositories and the advancements in the ml applications beyond audio and images have paved the way for a rapid growth of ml techniques for software engineering applications.
to this end the repetitive and predictable nature of the sourcecode revealed by the statistical characteristics of the source code hasbeen compared with the properties of the natural text .
also researchers have extensively applied ml techniques for clone detection de obfuscation language migration code summarization auto correction auto completion code generation and program comprehension .
energy and run time efficiency.
a programming task s dl model here energy consumption is the amount of energy measured injoules required by a computer system to accomplish the task the energy consumption is calculated by the formula e p t wherepdenotes the power consumption in watts and t the total amount of time run timeperformance in seconds required to execute a task.
although in the physical sense energy cannot be consumed we will use the term energy consumption to refer to the conversion of electrical energy by it equipment into thermal energydissipated to the environment.
for example we say that a program a consumes joules and needs ten seconds to accomplish a task andprogram bconsumes joules and needs seconds to accomplish the same task as program a. then program ais more run time efficient while program bis more energy efficient.
additionally as computer systems change and become more complex with anevolving memory hierarchy having processors of multiple cores and distinct power states power requirements begin to vary.
even though there are several studies related to computer systems and energy efficiency it is still unclear how certain design decisionscan alter the energy consumption of computer programs or what trade offs exist .
experimental setup .
research questions rq1 which is the most energy and run time efficient dl framework for the models examined?
with rq1 we examine the energy consumption and run time performance of pytorch and tensorflow for the models used in our study.
knowing this information we can inform the dl community about the most efficient frameworks for the models under evaluation.
rq2 how accurate are the dlframeworks for the models under examination?
with rq2 we examine the accuracy in the results produced by the dl frameworks for the models ofour study i.e.
we wish to see whether the selected frameworks sacrifice accuracy over energy or run time efficiency under ourconfigurations.
knowing this information we can inform the dl authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
green ai do different deep learning frameworks... icse may pittsburgh pa usa community about the most accurate as well as energy and run time efficient frameworks for a given model.
rq3 whataretheleastenergyandrun timeefficient apis of dlframeworksforthemodelsunderexamination?
with rq3 we investigate the reasons that make dl frameworks less energy and run time efficient.
in particular we identify apis in dl frameworks that are energy hungry and run time inefficient.
locating these apis we will be able to make suggestions for improving those apis in the future and thereby the dl frameworks.
.
benchmark benchmark.
to achieve high accuracy dl algorithms must learn differentiating patterns with the help of large data sets.
we considered the following criteria to select an appropriate benchmark for our study.
the benchmark should be public popular having a significant number of stars which is a proxy of popularity we consider benchmarks with more than stars on github andmaintained having recent commits on github i.e.
a t most one year old .
we opt for data sets that are interesting to the community and active.
the benchmark should have been used in previously publishedresearch.
its successful use in other empirical studies proves that such a benchmark can be used for evaluating dl.
the benchmark should consist of models from different categories e.g.
recommender systems nlp and computer vision .
we want to measure the energy consumption and run time performance of various models.
the benchmark should contain models already available for bothpytorch and tensorflow.
ensuring the availability of the same models in both frameworks is necessary to compare the frameworks energy and run time performance.
after searching the related work articles published in icse and fse 1and github for benchmarks that can be used in the evaluation of dl we found that deeplearingexamples satisfies our criteria listed above.
deeplearingexamples is developed by nvidia a leading hardware manufacturing company.
in particular we chose deeplearingexamples commit dfed8d4 because it is publicly available on github popular with more than 6k stars on github and continuously maintained by nvidia.
we preferred to rely on algorithm implementations made publicly available by practitioners to avoid introducing our own implementation biases.
furthermore deeplearingexamples has been used in previous research and the implementations of the dl algorithms used were developed and tested based on the original research papers proposing them.
additionally we opted for deeplearingexamples since this benchmark offers different models and dl algorithms for instance models for recommendersystems naturallanguage processing nlp and computer vision.
finally deeplearingexamples provides models written in both pytorch and tensorflow.
to the best of our knowledge deeplearningexamples is the only repository that offers the implementations of a same dl algorithm in three different frameworks 1we chose icse and fse since these two conferences are the most prestigious in software engineering.
we checked the publications from the last two years since the dl field is emerging and evolves rapidly.
i.e.
tensorflow pytorch and mxnet for various tasks.
however we only focused on tensorflow and pytorch because only one algorithm i.e.
resnet was implemented in mxnet.
models.
deeplearingexamples provides state of the art models that one can to train and deploy on gpus via docker images.
from these models we selected and successfully configured six models listed in table .
we selected the six models using the following criteria.
these models are implemented both in pytorch and tensorflow while other models are not.
we ensured through manual analysis that the models found in deeplearningexamples for pytorch and tensorflow are identical to each other in terms of functionalities and configurations.
the models can be successfully executed on our execution environment.
for this we tested each model to make sure that they can run on our available hardware.
the models are unique.
for instance for computer vision we removed different versions of the resnet leaving only resnet in our data set.
we performed this check as we wanted to compare the energy consumption and run time performance of different models.
table lists the models obtained according to our criteria.
we have one model that belongs to the category of the recommender systems and three models that belong to the nlp category.
additionally from the computer vision category we kept three unique models out of five because the other three models shared a considerable overlap.
we needed to configure the deeplearingexamples benchmark to the requirements of our study so that we can perform fair comparisons between pytorch and tensorflow .
we present the steps we followed.
first we checked whether all the configurations of each model are alike for the two dl frameworks.
second we exe cuted each model with its default configurations.
third we changed some of the default configuration e.g.
number of gpus epochs batches seeds because many times our gpu was running out of memory or running for days without giving us a result.
however insome cases even after reducing all the available configurations andrunning a model for days we did not get any result e.g.
bert .
therefore we excluded such models from our data set.
algorithms.
in the data set we used in our study we include six dl algorithms implemented both in pytorch and tensorflow.
in particular the examined models use ncf tranformer xl gnmt resnet mask r cnn and ssd.
we briefly describe these algorithms in the forth column of table .
.
evaluation measures forrq1 we wish to measure the energy consumption and run time performance for different models written in the two dl frameworks considered in this study.
we measured both energy consumption and run time performance for the training and inference phasesof dl.
to calculate the run time performance we used the time unix tool .
we considered the realtime produced by the time tool.
to fetch the energy consumption measurements we used the perf and nvidia smi tools.
at its heart perf uses the running average power limit rapl framework to report the energy consumption of a running model.
rapl uses hardware authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
icse may pittsburgh pa usa s. georgiou et al.
table selected models from deeplearningexamples.
categor y model data set description recommender systems rs ncf ml 20mit filters and provides feedback based on the ncf specifications according to he et al.
.
natural language processing nlp transformer xl wikitext 103it enables capturing longer term dependency and resolves the context fragmentation problem built based on the study of dai et al.
.
gnmt wmt16 en deit uses google s neural machine translation system gnmt to translate english to german built based on the study of wu et al.
.
computer vision cv resnet coco 2014it is an image classification algorithm with low complexity developed according to the study of he et al.
.
mask r cnn coco 2017it is a convolution based neural network for the model of object instance segmentation built according to the study of he et al.
.
ssd coco 2017it detects objects in images using a single deep neural network following the study of liu et al.
.
performance counters to estimate the energy consumption of the cpu cores package pkg i.e.
core and uncore components of the processor and main memory ram .
we used rapl since it is a wellestablished utility that has been used in related work .
furthermore rapl s accuracy has been validated by various studies and it offers a high sample interval a single reading per one millisecond .
to collect the energy measurements from the gpu we used the nvidia smi a command line tool developed and maintained by nvidia.
to our knowledge nvidia smi is the only available tool to fetch energy measurements from a gpu.
forrq2 we argue about the accuracy of models that are efficient regarding energy consumption and run time performance.
therefore we measured the accuracy of the different models used in our study including hit rate perplexity bleu top error rate average precision and precision.
the evaluation measures are modeldependent.
the selected measures are used by the authors who introduced the models used in our study .hitrate aims to show the success rate of recommender systems in suggesting the top items from a top n list it is desired to have a high hit rate.perplexity is an exponentiation of the entropy lower values of this measure suggest more accurate models .
bleu bilingual evaluation understudy measures the difference between human and machine translation output a high bleu score indicates a better model .top error rate shows the fraction of test images for which the correct label is not among the five labels low values of this measure are desired .
the last two measures are precision and average precision.
both measures are desired to be high.
forrq3 we wish to investigate whether there exist functions called from the pytorch or tensorflow frameworks into the models under examination that consume considerable energy and impact run time performance.
to achieve this we used a profiling tool called cprofile .
the tool produces run time execution measurements of an application s function and library calls.
specifically cprofile offers information such as the number of times each function is invoked by an application under test the total time taken by each function and the total time taken per call.
along with cprofile we utilized gprof2dot a command line tool to plot dotgraphs from cprofile .
by using gprof2dot we were able to point out the exact path of the functions invoked by a model.
thistool also helped us to analyze the source code of those functions that were energy hungry or run time inefficient.
.
execution framework to automate the evaluation of the energy consumption and run time performance of the selected models we implemented a framework called prengdl to support the reproducibility of our study.
prengdl offers the following capabilities installs all necessary packages and modules of our experiments through an ansible script sets up the test bed configurations with the parameters used in our experiments to reproduce our results for each model checks whether the corresponding gpu is compatible with the experiments setup and ensures all the necessary dependencies are installed to get all the measurements sets the power governor to the performance mode to avoid reducing the performance of our experiments can execute all experiments multiple times and report the progress of the experiments compiles a report on the executed models with mean values.
.
experimental settings all experiments run on a server equipped with two 6th generation intel r xeon r gold cpu running on .
ghz as basic fre quency totaling into logical cores and gb of main memory.
we used python .
and shell scripts for our experiments and the latest available docker containers pytorch and tensorflow release .
py3 available from the nvidia gpu cloud repository it is updated on monthly basis and includes all the required dependencies needed for one to run the models.
before running our experiments we stopped all the unnecessary background processes as suggested in other similar studies to let our system reach a stable condition i.e.
where the energy consumption is stable .
then we started executing models to obtain their energy consumption and run time performance.
after the end of each model s execution we let the computer remain idle for one minute using the sleep command .
in this manner we were able to avoid tail power states and allow the system to reach a stable condition again idle energy consumption before authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
green ai do different deep learning frameworks... icse may pittsburgh pa usa executing the next model .
finally to reduce any noise in our measurements we executed the above steps ten times for each model.
it took us hours to collect the energy consumption and run time performance measurements for all experiments.
results .
answer to rq1 our goal is to find which framework is more energy and run time efficient for the models under examination.
table and table present the energy consumption in joules and run time perfor mance in seconds measured during the training and inference phases of our experiments respectively.
we use the abbreviations pkg for the core and non core components of the processor ram for the main memory and gpu for the graphic card.
to compare our results we use the following equation p pmin wherepis the measurement and pminis the minimum value of energy consumption or run time performance for each model.
if x p pmin the model giving pminisxtimes more energy or runtime efficient than p s implementation.
moreover we report the mean values of the energy consumption of pkg core and uncored components of a processor ram and gpu for a particular model.
the median values are also available in our replication package and online repository .
the highlighted cells of the tables show which framework has the most energy or run time efficient results for the corresponding model.
additionally to assess for statistically significant differences and their magnitude we report the results of the wilcoxon signed rank test with a confidence level of .
and a bonferroni correction for multiple hypothesis testing and the non parametric vargha and delaney s a12statistic respectively.
table summarizes the results from the training phase of the models.
we observe that tensorflow outperforms pytorch for training an ncf model by being .
xfaster and .
xmore energy efficient.
by contrast pytorch scored better for the transformer xl and gnmt models compared to tensorflow.
in particular pytorchtrained a transformer xl and gnmt model .
xand .1xfaster compared to its counterpart.
pytorch consumed .
xfewer energy to train a transformer xl model viz a viz tensorflow.
moreover to train a gnmt model pytorch needed .
xless energy compared to tensorflow.
for training computer vision models tensorflow was much more energy and run time efficient than pytorch.
specifically tensorflow s run time performance is .
x .2x and .7x more efficient for resnet mask r cnn and ssd respectively.
similarly for resnet tensorflow was .
xmore energy efficient than pytorch s implementation.
likewise for mask r cnn tensorflow was .
xless energy demanding than pytorch s implementation.
for training an ssd model tensorflow was again .1xmore energy efficient than pytorch s implementation.
the 2given a performance measure m the a12statistic measures the probability where implementing a model with a framework ayields better results than implementing it with a framework b. if the two implementations are equivalent we will get a12 .
.
if the first implementation performs better than the second one we can have the following cases a12is considered small for .
a12 .
medium for .
a12 .
and large for a12 .
.statistical tests see table confirm that the results in the training phase are statistically different with a large effect size in out cases with tensorflow significantly outperforming pytorch in out of cases .
table shows the results for the inference phase.
from the collected results we observe that tensorflow achieves the best results for an ncf model.
particularly tensorflow needed .
x less time and .
xless energy for inference compared to pytorch.
again similarly to the training process pytorch took less time and consumed less energy to train models under the category ofnlp.
specifically pytorch took .
xand 3xless time to train a transformer xl and gnmt model while it also used .
xand .7x less energy to train a transformer xl and gnmt model respectively.
for the computer vision category tensorflow only performedbetter than pytorch for a resnet model.
in particular tensorflow s implementation was .
xand .7xmore run time and energy efficient than pytorch s respectively.
to infer a mask rcnn and ssd model pytorch was .
xand .7xfaster while also being .1xand .5xmore energy efficient than tensorflow s implementations correspondingly.
the statistical tests confirm that the results achieved by the two frameworks in the inference phase statistically differ with a large effect size for out of cases and are in favor of pytorch in out of these cases .
answertorq1 we find that tensorflow is the least costly framework for training recommender systems and computer vision models while pytorch is the cheapest for training nlp models.
when it comes to model inference tensorflow isbetter for the recommender systems and for the resnet computer vision model while pytorch outperforms tensorflow for the remaining models.
overall we observe that the cheapest framework for the training phase is tensorflow while pytorch achieves the least costly inference.
.
answer to rq2 our goal is to find the energy and run time performance trade offs against the selected models accuracy.
figure depicts the accuracy of each model selected in our study along with the corresponding run time performance and energy consumption.
to identify therun time energy combined energy of pkg ram and gpu andaccuracy trade offs we utilize the combined results of training and inference summarized in table and table along with the accuracy results illustrated in figure .
we use the combined results of training and inference because obtaining the final accuracy involves both the training and inference steps.
additionally we compare and discuss our results by using the equation as we did for rq1.
we use the basic configurations for executing the experiments since we are interested in measuring energy and run time performance and we do not tune the configurations such that to achieve the best accuracy.
to gather accuracy results we run only once our techniques since according to the related work using the same and basic configurations the models will be deterministic and accuracy will remain the same.
figure presents the trade offs among the three aspects i.e.
energy consumption y axis run time performance size of circle and accuracy color of the circle .
for example tensorflow s authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
icse may pittsburgh pa usa s. georgiou et al.
table rq1.
mean values for the energy consumption in joules and run time performance in seconds of training.
the wilcoxon statistical significance test results p value and effect size a12 are also reported.
model pkg energy ram energy gpu energy run time pytorch tensorflow p value a12 pytorch tensorflow p value a12 pytorch tensorflow p value a12 pytorch tensorflow p value a12 ncf .
.
.
.
.
transformer xl .
.
.
.
gnmt .
.
.
.
resnet .
.
.
.
mask r cnn .
.
.
.
ssd .
.
.
.
table rq1.
mean values for the energy consumption in joules and run time performance in seconds of inference.
the wilcoxon statistical significance test results p value and effect size a12 are also reported.
model pkg energy ram energy gpu energy run time pytorch tensorflow p value a12 pytorch tensorflow p value a12 pytorch tensorflow p value a12 pytorch tensorflow p value a12 ncf .
.
.
.
.
.
.
transformer xl .
.
.
.
gnmt .
.
.
.
resnet .
.
.
.
mask r cnn .
.
.
.
.
ssd .
.
.
.
implementation of gnmt not only consumes higher energy than pytorch s implementation but also takes longer to execute and thus it has a larger circle compared to pytorch .
however tensorflow s gnmt shows slightly better accuracy than the pytorch s implementation.
therefore the circles have the same color.
for the ncf model tensorflow not only outperforms pytorch in terms of energy consumption and run time performance but also in terms of accuracy having .
xbetter hit rate.
for the transformer xl model we observe that pytorch is .
xmore accurate.
however for the gnmt model pytorch is xmore inaccurate than tensorflow.
for the computer vision models we find that tensorflow has better accuracy for the resnet model since the top error rate of pytorch is xhigher than tensorflow s. we also observe for the ssd model that tensorflow has xbetter precision compared to pytorch.
for mask r cnn we obtainzero results for both frameworks as the used configurations and hyper parameters did not contribute to a visible accuracy.
answer to rq2 the collected results suggest that better energy consumption and run time performance in most cases yield better accuracy results as well.
overall we find that tensorflow has similar accuracy to pytorch under the configurations and parameters used in our study.
table rq3.
energy and run time performance tests.
tuples pytorch tensorflow pkg energy run time .
.
ram energy run time .
.
gpu energy run time .
.
.
answer to rq3 our goal is to identify apis of the frameworks under examination that consume a significant amount of energy and are run timeinefficient.
we analyze such functions which the models invoke that contribute more than to the total execution time of thetraining and inference of a model see tables and .
weselect such a low threshold since any function call with lowerthan of execution time might have a negligible impact on the energy and run time performance of the training and inference of a model.
the complete profiling of our experiments is availablein our replication package and online repository .
table table table and table present the collected results for each model the corresponding function name number of calls the total execution time run time and the portion in terms of percentage of the total execution time.
to the best of our knowledge there are no available tools to measure the energy consumption of a model in terms of milliseconds thus it is challenging for one to collect energy measurements with a high sampling rate and map them to the energy consumption of the selected models.
additionally since the total energy consumption is a function of the power usage multiplied by the total time spent on a model see section we consider that greater total time taken by a function of pytorch or tensorflow also increasesenergy consumption.
therefore in table table table and table we report only the run time.
furthermore we perform the spearman s correlation test since our data does not follow a normal distribution and find that pytorch and tensorflow s energy consumption and run time performance have on average a positive moderate and very strong monotonic correlation respectively see table .
table presents the results for the correlation test of each framework and the resources tested.
the detailed call graphs used along with the performance measures in figures can be accessed in our replication package and online repository .
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
green ai do different deep learning frameworks... icse may pittsburgh pa usa table rq3.
pytorch training.
function name number of calls ncalls run time cost against the total run time and typewhere squaresolidstandsforcomplexcalculations squarecompleximplementation largedata diamonddevicedependency and unknown.
the same symbols apply to tables .
.model function name ncalls run time cost type torch.autograd.backward torch.addmm .
squaresolid torch.cat .
square torch.nn.functional.embedding .
torch.nn.functional.dropout .
torch.nn.functional.relu .
squaresolidncf torch.tensor.t transformer xltorch.autograd.backward .
torch.tensor.item .
torch.tensor.nonzero .
torch.autograd.backward .
torch.tensor.sum .
squaresolid torch.tensor.mul .
squaresolidgnmt torch.tensor.add .
squaresolid resnet50torch.cuda.synchronize .
diamond torch.autograd.backward .
torch.nn.conv2d .
squaresolid torch.tensor.item .
torch.tensor.item .
torch.tensor .
diamond mask r cnn torch.autograd.backward .
ssdtorch.tensor.zero .
square torch.cuda.synchronize .
diamond torch.tensor.add squaresolid torch.autograd.backward .
torch.tensor.mul .
squaresolid pytorch training.
the obtained results for pytorch indicate that the functions of apis such as torch.autograd.backward and torch.cuda.synchronize contribute to the most time taken in training a model see table .
specifically we find that all of our models spend on average .
of their to tal execution time on the function run backward which is invoked by the torch.autograd.backward api responsible for computing a tensor s gradients.
we also observe that the torch.cuda.synchronize api can take up to .
on average for training an resnet or ssd model.
the corresponding function waits for all kernels of all streams for the gpu card to complete.
apart from the aforementioned functions we find that a function called by the torch.tensor object such as t item nonzero sum zero add andmul takes up on average to .
of the total execution time.
functions to the object torch.tensor such as add mul andsum are responsible for performing arithmetic calculations on tensors while itemreturns the value of a tensor tis responsible to transpose dimensions and so on.
finally for training a recommender system we observe that functions suchas torch.addmm matrices multiplication torch.cat tensors concatenation torch.nn.functional.embedding retrieval of word embeddings using indices and torch.nn.functional.relu applies a rectified linear function to given elements contribute to .
.
.
and .
of the total execution time respectively.pytorchinference.
in contrast with pytorch s training process for inference there is not a single api for all our models that isresponsible for taking the most of the execution time.
however as inthe training process in resnet torch.cuda.synchronize and torch.nn.conv2d functions take up to the most of the inference time.
for ncf transformer xl resnet and mask r cnn we observe that similar functions are invoked in the training process except for the torch.autograd.backward being invoked in the training only and contribute to the most of the execution time.
tensorflow training.
when it comes to tensorflow s training process we find that all the models apart form mask r cnn use the tensorflow.session.run api at .
on average of their total training time.
the corresponding api is responsible forrunning computations and evaluating the tensors.
the specific func tion that is eventually invoked by tensorflow.session.run is the pywrap tensorflow internal.tf sessionrun wrapper .
for mask r cnn we observe that tensorflow.keras.model.fit takes .
of the total execution time to train the model.
tensorflow inference.
tensorflow.session.run is found to take the most of the execution time for model inference which is .
on average.
in comparison with the whole model implementation we observe that ncf s inference process is not affected to a great extend by the tensorflow framework.
this possibly happens because many other libraries are used by the developers in authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
icse may pittsburgh pa usa s. georgiou et al.
table rq3.
pytorch inference.
functions number of calls ncalls run time cost against the total run time and type.
model function name ncalls run time cost type torch.addmm .
squaresolid torch.cat .
square torch.nn.functional.embedding .
torch.nn.functional.relu .
squaresolid torch.tensor.t .
ncf torch.sigmoid .
transformer xltorch.tensor.item .
torch.tensor.nonzero torch.einsum .
squaresolid torch.cat .
square torch.tensor.matmul .
squaresolid torch.tensor.to .
square torch.nn.lstm .
squaresolid gnmt torch.tensor.matmul .
square resnet50torch.cuda.synchronize .
diamond torch.nn.conv2d .
squaresolid torch.tensor .
diamond torch.nn.conv2d .
squaresolid torch.tensor.nonzero .
torch.tensor.float .
torch.tensor.to .
squaremask r cnn torch.tensor.type .
ssdtorch.max .
torch.nn.conv2d .
squaresolid torch.tensor.item .
table7 rq3.tensorflowtraining.functions numberofcalls ncalls run time costagainstthetotalrun time andtype.
model function name ncalls run time cost type ncf tensorflow.session.run .
square transformer xl tensorflow.session.run .
square gnmt tensorflow.session.run .
square resnet50 tensorflow.session.run .
square mask r cnn tensorflow.keras.model.fit .
ssd tensorflow.session.run .
square table rq3.
tensorflow inference.
functions call number ncalls run time cost against the total run time and type.
model function name ncalls run time cost type ncf tensorflow.session.run .
square transformer xl tensorflow.session.run .
square tensorflow.session.run .
squaregnmttensorflow.io.gfile.gfile .
square resnet50 tensorflow.session.run .
square mask r cnn tensorflow.keras.model.predict .
ssdtensorflow.session.run .
square tensorflow.io.gfile.glob .
square the inference phase apart from tensorflow taking up to the most of the total execution time.
moreover for mask r cnn we observe that tensorflow.keras.model.predict consumes .
of thetotal execution time in inference.
we also observe two classes from tensroflow.io.gfile namely gfile an asynchronous file i o wrapper and glob returns a list of files by using pattern matching .
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
green ai do different deep learning frameworks... icse may pittsburgh pa usa figure rq2.
comparison of energy consumption runtime performance rt and accuracy acc between tensorflowandpytorch .
the size of a circle represents the runtime performance i.e.
the bigger the circle the lower therun time and color represents the value of accuracy met ric i.e.
the darker the circle the higher the accuracy theinterpretation depends on the metric of the model.
accu racy has been computed with hit rate nfc perplexity transformer xl bleu gnmt top error rate resnet50 avg.
precision mask r cnn and precision ssd .
although globis invoked only a single time it takes a huge toll on the inference process of ssd i.e.
.
of the total execution time .
likewise gfile calls take .
of the total execution time in the inference of the gnmt model.
answer to rq3 most of the times specific apis are most demanding and take the majority of the training and in ference time of the models examined.
overall pytorch s autograd.backward and tensorflow s session.run are the most performance intensive api calls.
.
discussion analysisofdocumentationandsourcecode.
our results show that there are functions in the apis of pytorch and tensorflow that may slow the execution of dl applications and consume more energy.
therefore the first two authors of this paper manually investigated the functions documentation and source code functionbody in the pytorch and tensorflow frameworks for all thefunctions listed in tables and .
in case of a disagreement between the two authors there was a discussion between them to reach a consensus .
our manual analysis revealed that in the documentation of these functions there is not any particular information regarding energy consumption or run time performance.
we also read the source code of the functions identified and found four types of issues that could be improved in the future.
as it is shown in tables and we identified nine unique functions performing complex calculations six unique functions having complex implemen tation e.g.
with many control flows seven unique functions that can handle large data and which performance depends on the data magnitude and two unique functions which performance depends on the device characteristics used.
we also found six methods in pytorch that we were unable to categorize because these methods were either written in another language than python or because we lack the knowledge to understand their source code.
suggestions.
based on our manual analysis we suggest that since there is a need for greener dl frameworks extra information on energy consumption run time performance and minimum required configurations should be systematically included in the documentation of such frameworks in the future.
dl frameworks could for instance include in their documentation new energy and performance related text fields for each method and special symbols for each method type e.g.
a sw ed o in the last column of table to indicate the requirements.
for example the pytorch documentation is currently limited and in the future it would be good to include the minimum hardware requirements at least.
developers could also list constraints regarding energy and performance requirements possible errors or energy and performance issues that can happen at run time as well as provide default values to avoid run time issues.
furthermore annotations e.g.
as nonnull in java could be added to the documentation to warn developers about potential energy performance inefficiencies which could be encountered at run time.
these observations could be drawn from the testing and evaluation of the energy and perfor mance of dl frameworks.
using prengdl we hope that energy and performance metrics of dl frameworks could be gathered systematically.
we however acknowledge that these suggestions should be further validated in future work possibly involving researchers and practitioners.
for functions that are complex or handle large data dl researchers may consider to optimize the performance of existing algorithms themselves and then dl frameworks can be updated accordingly.
for functions with a complex implementation the developers of dl frameworks may consider directly optimize their existing code by leveraging for example the genetic improvement of software which studies how to automatically modify the source code to improve software s non functional properties .
in the following paragraphs we summarize the key take aways of our study for researchers and practitioners that develop dl frameworks.
furthermore we suggest stepsthat a user of a dl framework could follow according to the insights of our study to write moreefficient programs when using pytorch and or tensorflow.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
icse may pittsburgh pa usa s. georgiou et al.
keytake aways.
to summarize our study offers the following take aways to researchers and practitioners that use dl frameworks the study raises awareness on the fact that different dl frameworks incur different energy and performance costs for both the training and inference phases.
our results showthat no framework is best for all tasks investigated and thus call for actions to allow users to consider and understand energy and performance requirements when selecting a dl framework.
the proposed approach prengdl can help future studies inthis domain by offering a comprehensive and sound method to automatically measure and compare energy and run time performance.
the deficiencies we found in the current documentation of dl frameworks reveal the need for new green awaredocumentation of dl frameworks.
steps.
to improve efficiency a user of a dl framework may consider the following steps run small experiments first and test configurations before running large scale experiments use profiling approaches on small experiments to estimate resources to be used for large experiments afterwards analyze the energyaccuracy trade offs to decide whether energy and performance should be sacrificed over accuracy.
to conclude we hope that the methodology presented in this paper together with its publicly available implementation prengdl can aid users to assess dl frameworks energy and run time performance.
threats to validity internalvalidity.
due to hardware constraints we used basic configurations and parameters of the models to facilitate the training process on our test bed.
the reader should consider that some of the obtained results may vary significantly based on the used gpus or cpu architectures.
using different configurations can impact the accuracy score reported in figure .
however our current aimis to investigate the energy and run time performance of two dl frameworks while performing the same models.
therefore we planto examine the impact of different configurations on accuracy in the future.
also in section .
we found that two functions under the gfile module of pytorch have a heavy toll on the performance of the framework.
this fact could have been caused by our server system s slow hard disk drive.
however for the fair comparisons of our findings we calculated correlation scores in table .
we acknowledge that hardware is notalways a limitation for example for large companies accessing large computing resources.
thus we wish to run our experiments in an industrial setting in the future to show the implications of hardware on our results.
the energy and the run time performance of an application under test can be affected by many different factors such as running background processes daemons and so on.
we tried to limit as much as possible such interference.
having full control over the os workload and background operations is hard because at any time different daemons for instance may operate.
this could affectour calculations too and the results may vary among different executions.
however this issue is common in such studies.
we also set one minute of idle time between each execution of our tasks because we found that this time budget is sufficient for our system to reach a stable condition.
using another time budget may give different results.
finally our manual analysis for the functions found in section .
many suffer from human errors.
to eliminated this issue two validators cross checked the results and we made our results publicly available .
external validity.
regarding the generalizability of our findings section we admit that our results regard the models and frameworks selected in our study .
however we argue that the benchmarks used are developed from well known research studies as mentioned in section .
in the future we wish to execute our study using other benchmarks to strengthen the generalizability of our findings and balance the categories of the models used in our experiments .
we note that we kept the same version of the packages and modules used originally in the deeplearningexamples repository since these tasks are extensively tested and developed on monthly basis according to nvidia s developers .
therefore under different versions the results may differ slightly.
reliability.
for the reproducibility of our study we developed an execution framework prengdl and we made it publicly available as well as the inputs and outputs of our experiments .
we also provide a configuration management script to enable the installation of modules and tools needed to run our tasks.
related work many studies examine the accuracy of dl.
however a few studies focus on dl s energy consumption and run time performance .
researchers have pointed out though that the field of dl is energy demanding.
thus dl also contributes to the increased co2emissions and has a great financial cost as well .
several research studies introduced practices on how to use traditional ml efficiently to reduce energy consumption.
for instance mcintosh et al .
performed an empirical study to examine which algorithms are less energy demanding to train ml models for android devices.
their results suggest that j48 smo and mlp contribute to more energy efficiency better accuracy and show a correlation to algorithms complexity.
moreover the authors pointed out a number of factors that can significantly affect the energy consumption of ml for android devices such as the data set size and the number of fields.
to suggest changes in java based source code for ml kumar et al .
introduced jepo an eclipse plugin that can help in optimizing ml source code regarding data types operators strings exceptions objects and arrays.
in addition to the previ ously mentioned studies kan et al .
proposed the eclass that makes use of the dynamic voltage frequency scaling mechanisms to reduce the energy consumption of a computer while training a ml model.
the suggested approach increased the average energy savings by .
.
furthermore researchers performed studies to investigate and suggest changes for popular dl models to make them more efficient.
for instance zhang et al .
conducted a preliminary study to find the latency memory footprint and energy usage of alexnet and sqeezenet implemented using tensorflow tensorflow lite pytorch mxnet and caffe2.
as a result the authors found that there is not a single framework that outperforms the others.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
green ai do different deep learning frameworks... icse may pittsburgh pa usa wang et al .
proposed an approach of dropping unnecessary computations from cnn models running on fpgas to reduce energy consumption.
the authors achieved energy savings ranging from to with an accuracy loss of .
to for resnet74 resnet110 and mobilenetv2 respectively.
other researchers proposed guidelines on how to fetch energy measurements for studies with respect to ml .
specifically the study of garc a mart n et al .
states the limitations of various approaches used by researchers to estimate the energy consumption of model training and proposes ways to build models that can estimate the energy consumption on different hardware systems.
likewise in the study of fu et al.
the authors developed models to estimate the energy consumption of machine learning applications.
similarly pathak et al .
used system calls to generate power models for estimating smart phones energy consumption.
furthermore bornholt et al .
argued that using only a ml model is not enough to estimate the energy consumption of applications.
thisstudy.
we examined how two of the most popular dl frameworks pytorch and tensorflow perform for dl models from different categories.
closer to our study is the preliminary work by zhang et al .
.
zhang et al .
assessed the performance of running a trained model i.e.
not during the training phase with the purpose of assessing the use of different hardware for two pre trained models namely alexnet and sqeezenet from one category i.e.
image classification .
by contrast we measured the performance during both the training and inference phases of six different models from three different categories i.e.
recommender system nlp and computer vision .3besides our empirical methodology is more robust including for instance statistical tests effect size and mitigations for stochastic behavior.
additionally we found which dl framework is more energy and run time efficient for certain models and investigated the trade offs of the frameworks accuracy.
finally we investigated the reasons behind the obtained results concerning which functions or libraries arehurting the performance of the frameworks examined and weprovided some initial suggestions for dl frameworks users and makers developers.
conclusions high accuracy of dl comes at the cost of high computational cost and resource utilization.
in this study we studied and compared the energy consumption and run time performance of two commonly used dl frameworks pytorch and tensorflow .
we found that tensorflow performs better for training models of the recommender systems and computer vision categories and pytorch of the nlp category.
regarding inference tensorflow performs better than pytorch only for the recommender systems and resnet50 categories.
furthermore we found that better energy consumption and run time performance in most cases yield better accuracy results.
overall tensorflow is more energy and run time 3our choice of models is guided by maximizing the number of different categories and algorithms studied while using publicly available actively maintained and tested implementations in two dl frameworks.
the models alexnet and sqeezenet used by zhang et al .
cannot be used in our study because sqeezenet is not implemented for tensorflow and alexnet provides only a pre trained model.
for our study we need access to the source code to train the models and take measurementduring this phase.
ho wever we could not locate the training source code for alexnet and sqeezenet.efficient compared to pytorch in the training phase but less efficient for the inference phase.
we also identified specific apis and functions from pytorch and tensorflow that are most resourcehungry and take the majority of the training and inference time.
our results can have several implications for researchers and practitioners dl frameworks show a significant model sensitive difference in their run time performance and energy consumption.
therefore dl developers may choose the most appropriate framework for the model at hand while keeping accuracy run time performance and energy consumption optimal.
the training phase of dl frameworks is more expensive than the inference one thus resulting in a higher footprint impact.
consequently dl users should consider appropriate steps when using dl models with large data.
our manual analysis of the source code and documentation of dl frameworks reveals that the current documentation needs improvement since it lacks for example information about the minimum hardware requirements regarding energy consumption and run time performance.
therefore users are left with no indication on how to choose a dl framework with regards to these aspects.
these results raise the awareness of the need for greener software for users dl library makers developers and researchers.
our manual code analysis and profiling identifies the most expensive apis.
these findings can guide both researchers and dl library makers developers into the optimization of the energy and performance of dl source code which could be attempted both manually or automatically by using for instance the genetic improvement of software .