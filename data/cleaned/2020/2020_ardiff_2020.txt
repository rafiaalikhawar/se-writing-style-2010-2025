ardiff scaling program equivalence checking via iterative abstraction and refinement of common code sahar badihi university of british columbia canada shrbadihi ece.ubc.cafaridah akinotcho university of british columbia canada fari100 ece.ubc.ca yi li nanyang technological university singapore yi li ntu.edu.sgjulia rubin university of british columbia canada mjulia ece.ubc.ca abstract equivalence checking techniques help establish whether two versions of a program exhibit the same behavior.
the majority of popular techniques for formally proving refuting equivalence relies on symbolic execution a static analysis approach that reasons about program behaviors in terms of symbolic input variables.
yet symbolic execution is difficult to scale in practice due to complex programming constructs such as loops and non linear arithmetic.
this paper proposes an approach named ardiff for improving the scalability of symbolic execution based equivalence checking techniques when comparing syntactically similar versions of a program e.g.
for verifying the correctness of code upgrades and refactoring.
our approach relies on a set of novel heuristics to determine which parts of the versions common code can be effectively pruned during the analysis reducing the analysis complexity without sacrificing its effectiveness.
furthermore we devise a new equivalence checking benchmark extending existing benchmarks with a set of real life methods containing complex math functions and loops.
we evaluate the effectiveness and efficiency of ardiff on this benchmark and show that it outperforms existing method level equivalence checking techniques by solving of all equivalent and of non equivalent cases compared with to for equivalent and to for non equivalent cases in related work.
ccs concepts software and its engineering software evolution .
keywords equivalence checking program analysis symbolic execution.
acm reference format sahar badihi faridah akinotcho yi li and julia rubin.
.
ardiff scaling program equivalence checking via iterative abstraction and refinement of common code.
in proceedings of the 28th acm joint european software permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
copyrights for components of this work owned by others than the author s must be honored.
abstracting with credit is permitted.
to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
request permissions from permissions acm.org.
esec fse november virtual event usa copyright held by the owner author s .
publication rights licensed to acm.
acm isbn .
.
.
.
12345678910111112131415161717181920bessel norm arg acc res bess math.pow norm norm twoarg arg if norm res arg math.pow norm returnres if arg res twoarg bess res twoarg else for j j norm j bess j acc twoarg res res math.pow bess res res bess res res acc bess returnres figure program versions mandm .
engineering conference and symposium on the foundations of software engineering esec fse november virtual event usa.
acm new york ny usa pages.
introduction equivalence checking establishes whether two versions of a program have identical behavior and is used in a variety of tasks such as verifying the correctness of software upgrades refactoring and optimization .
the most common form of equivalence used in practice is functional equivalence which establishes whether two terminating versions of a program produce the same output for any identical input .
for example figure shows the simplified code of two consecutive versions of a method mandm that calculates bessel s differential equation which is often used in scientific computing and signal processing .
we adopt a git style representation of versions where lines prefixed by are insertions of statements in version m that were not present in mand lines prefixed by are deletions of statements that were present in version m. despite syntactical differences these two versions are functionallyesec fse november virtual event usa sahar badihi faridah akinotcho yi li and julia rubin equivalent and the goal of our work is to prove equivalence or non equivalence of such cases.
symbolic execution a static program analysis technique that uses symbolic rather than concrete values to represent program inputs is one popular approach for establishing functional equivalence.
with symbolic execution a program is represented by a first order logic formula over symbolic variables which captures each program execution path as a conjunction between path conditionandpath effect the first is the formula constraining values that enable the executing of the path and the second describes values computed along the path.
this representation is referred to as a program symbolic summary .
establishing functional equivalence between two versions of a program then translates into the problem of establishing equivalence between their summaries usually using solvers for boolean satisfiability sat or satisfiability modulo theories smt .
the limitations of symbolic execution are well known unbounded loops and recursions lead to a large number of paths and the exact number of iterations is difficult impossible to determine statically.
for the example in figure the number of iterations of the forloop in lines depends on the exact value of the input parameter norm which is unknown during static analysis.
thus most techniques rely on a user specified bound for the number of iterations e.g.
two or five.
bounded symbolic execution is not as complete as the unbounded one and might miss feasible behaviors e.g.
in the sixth execution of the loop.
furthermore complex expressions in symbolic summaries such as non linear integer arithmetic might lead to expressions in summaries that are intractable for modern decision procedures which produce an unknown result in these cases .
an example of such non linear arithmetic is the power operation in lines and of figure .
in the context of functional equivalence checking two main approaches for dealing with these limitations of symbolic execution have been proposed differential symbolic execution dse uses uninterpreted functions function symbols that abstract internal code representation and only guarantee returning the same value given the same input parameters to abstract syntactically identical segments of the code in the compared versions e.g.
the code in lines as well as in lines in figure .
the main idea behind this approach is to hide the complexity of this common code and skip executing it symbolically.
that is while the na ve approach for constructing symbolic summaries of the methods m andm in figure would unwind the loop in lines up to a user specified bound the execution of this loop can be skipped altogether as it does not affect the equivalence of these methods the values computed in the loop are used in the same manner in both symbolic summaries of versions mandm .
even in the presence of uninterpreted functions the equivalence of these summaries can be established by an smt solver using the theory of equality and uninterpreted functions .
however abstracting all syntactically identical code is not effective first it can abstract away important information needed to establish equivalence.
for example the code acc in line albeit common to both methods is essential for establishing equivalence of statements res res bess and res res acc bess in line .
that is an over approximation introduced by abstraction may lead to spurious false negative results characterizingprograms as not equivalent when they are in fact equivalent.
that happens because values assumed for uninterpreted functions may not correspond to real code behavior.
second introducing numerous uninterpreted functions with complex relationships between them may result in unnecessary complexity in symbolic summaries producing unknown results that could be eliminated when the abstracted away code is relatively simple and is used as is .
the regression verification using impacted summaries imp s approach proposes an alternative way to abstract complex code.
instead of identifying common code blocks it uses static analysis to identify all statements impacted by the changed code.
the tool then prunes all parts of symbolic summaries that do not contain any impacted statements.
the authors of imp s formally prove that the results produced by such an approach are correct for a given loop bound i.e.
if the approach determines the compared programs equivalent non equivalent they indeed are equivalent non equivalent for that bound.
however this approach assumes that all impacted statements including common statements with complex logic can affect the decision about the equivalence of two programs.
this assumption results in inclusion of unnecessary statements and constraints in the symbolic summaries leading to unknown results that could otherwise be eliminated.
another weakness of this approach is that the conservative nature of static analysis may mark certain unimpacted statements as impacted further inflating the produced summaries.
moddiff and clever focus on extending equivalence analysis to work in an inter procedural manner.
while these techniques also perform some pruning of common code they only do that at a path level eliminating full path summaries only if the entire path contains no changed statement.
at a method level these techniques thus suffer from the same and even more severe limitation than imp s. to summarize the techniques proposed by existing work suffer from false negatives and are unable to eliminate a large portion of undecidable cases i.e.
cases when an sat smt solver returns unknown as the result.
that is because they are either too conservative and abstract larger portions of the program than actually needed to establish equivalence dse or leave unnecessary parts of the program in the summaries and prevent the solver from successfully resolving these cases imp s moddiff clever .
in this paper we propose a method level analysis for abstracting a portion of code statements aiming to arrive at an optimal abstraction which hides complex statements not necessary for establishing equivalence while keeping statements needed to prove equivalence.
the goal of our work is to decrease the number of unknown results and increase the number of provable results without loop bounding compared with earlier work.
inspired by the counterexample guided abstraction refinement cegar paradigm our approach implemented in a tool named ardiff conservatively abstracts all unchanged blocks as done by dse and then iteratively refines these abstracted blocks guided by a set of heuristics for identifying the most prominent refinement candidates.
unlike prior work that mostly focuses on reducing the size of symbolic summaries treating their complexity as a side effect our approach balances the size the complexity and the expressiveness of the summaries aiming at producing concise yet solvable expressions.ardiff scaling program equivalence checking via iterative abstraction and refinement of common code esec fse november virtual event usa to evaluate the efficiency and effectiveness of ardiff we extend the set of benchmarks collected by li et al.
which were inspired by classical numerical computation functions and were used for evaluating symbolic execution methods in the presence of complex path conditions and non linear functions .
for example the bessbenchmark used as the baseline for our motivating example in figure contains methods used to compute bessel s differential equation.
another benchmark tsafe contains three methods borrowed from an aviation safety program that predicts and resolves the loss of separation between airplanes.
we adapted these benchmarks for the equivalence checking context by systematically injecting realistic changes into each of the benchmark s methods producing one equivalent and one nonequivalent version of each method.
we opted for using benchmarks by li et al.
in addition to those introduced by trostanetski et al.
for our evaluation because the latter benchmarks are relatively small and contain no complex constraints.
we compare the efficiency and effectiveness of ardiff for establishing method level equivalence with that of existing work dse and imp s. our evaluation results show that ardiff is able to establish equivalence in out of cases and non equivalence in out of cases .
for equivalent cases this is substantially higher than the results produced by imp s and dse and cases respectively.
for non equivalent cases ardiff performs comparably and even slightly better than other tools it is able to solve out of non equivalent cases while imp s solves and dse cases.
contributions.
this paper makes the following contributions it introduces a cegar like abstraction refinement approach that uses uninterpreted functions to abstract a large portion of common code and employs a number of heuristics helping to refine only abstractions that are needed to determine equivalence.
it provides the first publicly available implementation of dse and imp s as well as our novel approach named ardiff all in a generic framework for determining method level functional equivalence.
it introduces a non trivial benchmark for method level functional equivalence checking with samples of equivalent and non equivalent method pairs.
the samples of the benchmark include loop and complex non linear arithmetic.
it empirically demonstrates the effectiveness and efficiency of ardiff compared with dse and imp s. our implementation of ardiff dse and imp s as well as our experimental data are available online .
organization.
the remainder of the paper is structured as follows.
section provides the necessary background and definitions used for the rest of the paper.
we discuss existing techniques and outline their limitations that motivated our work in section .
we describe the main idea behind ardiff in section and its implementation in section .
.
section describes our evaluation methodology including benchmark construction and the evaluation results.
we discuss the related work in section and conclude the paper in section with a summary and suggestions for future research.
background in this section we provide the necessary background on program analysis and equivalence checking that will be used in the remainder of the paper.
programs.
we formalize the ideas in the paper in the context of a simple imperative programming language where all operations are either assignments or method calls and all variables range over integers and doubles.
we assume that each program method m performs a transformation on the values of the input parameters and returns a set of values.
without loss of generality we represent m s printing statements as return values and also assume that global variables can be passed as input parameters and return values along each path of the method.
we assume that methods have no additional side effects.
we also assume that all executions of m terminate but this assumption does not prevent mfrom possibly having an infinite number of paths such as in the case where there is a loop whose number of iterations depends on an input variable.
control and data dependencies.
for two statements s1ands2 we say that s2iscontrol dependent ons1if during execution s1 can directly affect whether s2is executed .
for the example in figure statements in lines and are control dependent on the method definition in line .
statements inside the forloop in lines and are control dependent on the loop declaration in line which in turn is control dependent on the ifstatement in line .
we say that statement s2isdata dependent on statement s1ifs1 sets a value for a variable and s2uses that value.
for the example in figure the statement in line is data dependent on the statement in line because it uses the value of the variable resset in line .
symbolic summaries.
symbolic execution is a program analysis technique for evaluating the behavior of a program on all possible inputs.
it starts by assigning symbolic values to all input parameters.
for the example in figure we denote the two symbolic inputs corresponding to input parameters norm andarg line by nanda.
it then executes a program with symbolic rather than concrete inputs.
asymbolic summary for a method mis a first order formula mover a set of input parameters and output variables.
to build a symbolic summary the symbolic execution technique systematically explores all execution paths of a method maintaining a symbolic state for each possible path.
the symbolic state consists of two parts path condition a first order formula that describes the conditions satisfied by the branches taken along that path and effect a mapping of program variables to expressions calculating their values in terms of symbolic inputs.
to collect all paths when a conditional statement such as ifor for is reached during the symbolic execution the symbolic state of the explored path is cloned and two paths are created in one the path condition is conjuncted with the predicate of the condition and in the other with its negation symbolic execution then continues to explore both paths independently.
for non conditional statements such as assignments it extends the symbolic state with a new expression that associates the variable on the left hand side of the assignment with the symbolic expression for calculating its value.
for example the condition on the path spanning the linesesec fse november virtual event usa sahar badihi faridah akinotcho yi li and julia rubin in both versions of the method in figure is n 0and the effect of the path is ret a math.pow n where retrepresents the output variable and math.pow represents the power operation from non linear arithmetic.
the effect is calculated as a multiplication of argandmath.pow n line .
the exact number of loop iterations can depend on values of input variables which are unknown statically e.g.
in the forloop in lines of figure .
to compute the symbolic summary the loops are thus bounded to a particular user defined value.
with a bound of the loop in our example induces two paths with one and with two iterations over the loop.
skipping the loop altogether zero iterations is impossible in this program because the loop is reachable only if the value of norm is greater than see lines .
with loop bounding symbolic execution has the potential to underapproximate the program s behaviors e.g.
those that happen in subsequent iterations of the loop.
a symbolic summary of a path is a conjunction of its path condition and symbolic state e.g.
n ret a math .pow n .
the symbolic summary of a method is a disjunction of symbolic summaries of all its paths.
e.g.
the symbolic summary of the method min figure with the loop bound of is n ret a math .pow n n a ret a math .pow n n n a n ret math .pow a a n a n ret math .pow a math .pow a a versions.
we denote by mandm two successive versions of a method.
we assume that mandm have the same method name and input parameters otherwise they are not equivalent .
we consider common all statements that are syntactically identical in mandm .
statements added in m are referred to as insertions and statements removed for mare referred to as deletions we represent statement updates as a deletion of an old statement and an insertion of a new one.
for the example in figure statements in lines and are updates represented by deletion and insertion of the corresponding statements in mandm .
symbolic execution based equivalence checking.
two input methods mandm with symbolic summaries mandm respectively are functionally equivalent ifmis logically equivalent to m .
anequivalence assertion is a first order logic formula that helps determine such equivalence m m .
this formula is typically given to a sat or smt solver which either proves that no satisfying assignment to this formula exists meaning that mandm are equivalent or finds a counterexample to demonstrate non equivalence.
that is the satisfiability of indicates that mandm produce different outputs for at least one input.
if a solver cannot find any satisfying assignment for i.e.
the result is unsat the methods are equivalent.
symbolic summaries can contain uninterpreted functions i.e.
functions that are free to take any value .
the equality logic with uninterpreted functions relies on functional consistency a conservative approach to judging functional equivalence which assumes that instances of the same function return the same value if given equal arguments.
we leverage this quality of uninterpreted functions to abstract portions of common code and also to model method calls.symbolic execution based equivalence checking approaches rely on sat or smt solvers such as z3 to find satisfying assignments for equivalence assertions.
yet as the satisfiability problem with non linear constraints is generally undecidable and practically difficult our goal is to simplify these formulas and eliminate a large portion of unknown results.
motivating example in this section we use the example in figure to describe two existing solutions for method level functional equivalence dse and imp s and outline their limitations.
we introduce our solution that addresses these limitations in the following section.
differential symbolic execution dse .
person et al.
are among the first to use symbolic execution for program equivalence checking.
dse uses uninterpreted functions to abstract common parts of the compared code thus skipping portions of the program that are identical in two versions and reducing the scope of the analysis.
for the example in figure there are three common code blocks in lines line and lines .
the return statements lines and in both versions even if common are not abstracted as they capture the effect of the entire path and are required by the symbolic execution engine for producing the summary.
for each common block the tool collects all variables that are defined in the block and represents each variable as an uninterpreted function which accepts as inputs all variables that are used in the block.
for example for the block in line resis the output which is represented by an uninterpreted function uf7res a n .
the benefits of using uninterpreted functions can be realized when two symbolic summaries are compared with each other in this example the equivalence assertion for establishing equivalence of these two paths reduces to uf7res a n uf7res a n which can be determined unsatisfiable using the theory of uninterpreted functions .
as in evolving software common code blocks are expected to appear more frequently than changed code such an approach has a potential to hide loops and complex expressions leading to more solved equivalence cases and more complete solutions than that of a na ve checker with loop bounding.
however as discussed in section abstracting all syntactically identical code is not effective for two reasons.
first even if a solver determines that an equivalence assertion is satisfied i.e.
the method summaries are non equivalent this can be a false negative result if the satisfying assignment allocates to an uninterpreted function a value that it cannot take in practice.
for example the uninterpreted function uf2acc representing the code in line of figure cannot take any value other than .
moreover introducing numerous uninterpreted functions may result in unnecessary complexity in symbolic summaries producing unknown results that could be eliminated if the abstracted code is simple like in lines and of figure .
thus there is a need for a decision process establishing which parts of the common code need to be abstracted away and which are not.
we address this need in our work.
impacted summaries imp s .
instead of identifying common code blocks bakes et al.
propose a technique that uses static analysis namely forward and backward control and data flow analysis to identify all statements impacted by the changed code.
the tool then prunes all clauses of symbolic summaries that do notardiff scaling program equivalence checking via iterative abstraction and refinement of common code esec fse november virtual event usa eq neq unk statement s no neq unk eq neq unk methods m m abstraction refinement refinable?
yes equivalent?
4symexecution figure ardiff architecture.
contain any impacted statements.
for the example in figure statements in lines and are impacted by the change in line .
since only the statements in lines and are used in the summary of the path in lines n ret a math.pow n and none of these statements are impacted by the change the summary of this path can be pruned from the method s symbolic summary altogether.
the main limitation of this approach lies in the assumption that all impacted statements are required for deciding equivalence of two programs.
this assumption results in inclusion of unnecessary statements and constraints in the symbolic summary.
for example the path in lines contains the impacted statement in line .
as such imp s keeps the complex formula introduced by this statement math.pow in the symbolic summary and as a result also has to bound the forloop that controls this statement lines .
due to the complexity introduced by the statement the output of the tool for this case is unknown .
yet the statement in line is common between the two versions of the program and can in fact be abstracted away without hindering the decision about the equivalence of the methods.
that is the approach a leads to unnecessary unknowns and also b often requires bounding loops even when the execution of the loop can be abstracted away altogether.
like in the case of dse establishing which parts of the statements are required for determining equivalence without inflating symbolic summaries is a challenging task.
our approach in this section we provide a high level overview of ardiff and demonstrate its operation on the methods mandm in figure .
we then describe its main process selecting refinement candidates in detail.
finally we formally prove the correctness of the output produced by the tool.
.1ardiff overview ardiff obtains as input two versions of a method mandm and reports whether these versions are equivalent denoted by eq or non equivalent denoted by neq .
if equivalence cannot be established it returns unknown denoted by unk .
a high level overview of ardiff is given in figure .
it is inspired by the cegar abstraction refinement loop aiming to arrive at the optimal abstraction which hides complex statements while refining statements needed to prove equivalence.
as the first step ardiff abstracts all syntactically equivalent statements in mandm using uninterpreted functions as done in dse and discussed in section .
it then produces symbolic summaries forthe abstracted methods denoted by mandm and generates the equivalence checking assertion m m step in figure .
for the example in figure ardiff abstracts three common blocks in lines and .
that produces seven uninterpreted functions uf2acc uf3res uf4 bess norm uf5 twoar ar uf7res ar norm uf14 bess ar norm uf14 bess acc twoar norm and uf15res res bess norm .
the input parameters of these uninterpreted functions will be replaced by their corresponding symbolic values during the symbolic execution the produced assertion with three symbolic paths in both mandm is shown in figure 3a.
next is passed to an smt solver step in figure .
if the solver determines that it does not have a satisfying assignment i.e.
the functional summaries of the input methods with uninterpreted functions are equivalent ardiff outputs eq and the process terminates.
in this case the soundness of the abstraction guarantees that the concrete methods are also equivalent see section .
.
otherwise the result is either neq or unk.
if contains uninterpreted functions the unk result might be an artifact of abstraction and using a subset of original statements with concrete values might result in simpler summaries.
for the neq case a satisfying assignment making the summaries non equivalent might assign values to uninterpreted functions even though code abstracted by these functions can never produce such values .
for the example in figure 3a is satisfiable neq result even though methods mand m are in fact equivalent.
such results occurs because assigning a value other than to uf2acc will make the formulas mandm different.
in most cases refining abstractions that lead to neq or unk results can help eliminate false negatives and unresolved instances.
ardiff then checks whether refining is effective step in figure .
for the unk case this simply translates into checking whether still contains uninterpreted functions.
for the neq case the tool checks whether is satisfiable that is whether there exists at least one assignment that makes mandm equivalent.
if so ardiff proceeds to the refinement step.
otherwise further refinement is either impossible or ineffective the tool then returns the corresponding result to the user and the process terminates.
this refinement step step in figure is at the core of our approach it accepts as input the formula and by applying a set of heuristics outputs a statement sin methods mandm that is skipped from being abstracted away.
ardiff then proceeds to creating a finer grained abstraction next iteration of step in figure aiming at producing symbolic summaries where only the code that is required to establish equivalence appears in the summaries in its refined form.
.
the refinement process to identify the best refinement candidate in each iteration we utilize a set of heuristics described in algorithm .
the main goal of these heuristics is to find the most critical yet simple code statements that can help establishing equivalence non equivalence without introducing unnecessary complexity into the equivalence assertion.
our heuristics work on two levels symbolic summaries heuristic and and the code itself heuristic .
the goal of summary level heuristics and is to narrow down the selectionesec fse november virtual event usa sahar badihi faridah akinotcho yi li and julia rubin n ret u f7 res n a n a ret u f5 twoar a u f4 bess n n a ret u f15 res u f3 res u f14 bess u f2 acc u f5 twoar a n n u f14 bess u f2 acc u f5 twoar a n n ret u f7 res n a n a ret u f5 twoar a n a ret u f15 res u f3 res u f14 bess u f2 acc u f5 twoar a n n u f2 acc u f14 bess u f2 acc u f5 twoar a n a refinement iteration .
n ret u f7 res n a n a ret u f5 twoar a u f4 bess n n a ret u f15 res u f3 res u f14 bess u f5 twoar a n n u f14 bess u f5 twoar a n n ret u f7 res n a n a ret u f5 twoar a n a ret u f15 res u f3 res u f14 bess u f5 twoar a n n u f14 bess u f5 twoar a n b refinement iteration .
figure the equivalence assertions m m for methods mandm in figure .
algorithm the refine procedure 1input equivalence assertion m m output statement sto skip 2begin u u n consider all uninterpreted functions in uc refinement candidates foreach u udo heuristic is there a value of uthat make the summaries equivalent for any values of the remaining functions?
ifsmt sat then uc uc u adduto the set of candidates heuristic is uused differently by mandm ?
ifcount u m count u m then uc uc u adduto the set of candidates ifuc then uc u cannot narrow down selection consider all functions heuristic rank all statements lower is better s u ucstatements u all statements from all functions in uc r ranked statements foreach s sdo heuristic .
the depth of sin loop nesting r1 loopnestingindex s heuristic .
the total number of non linear arithmetic operators in s r2 nonlinearoperators s r r1 r2 total rank r r addswith rank rto candidate set return smallestrank r return a statement with the smallest rank only to statements truly necessary to prove disprove equivalence these heuristics do not directly reason about the structure of the code.
then code aware heuristic selects the next refinement candidate based on code simplicity.
we start the description from the summary level heuristics which consider all uninterpreted functions in as potential refinement candidates line and further rank them to identify the best refinement candidates uc lines heuristic first for each uninterpreted function u u we check whether there exists a value of uthat would make the formula hold regardless of the values of other functions.
the rationale behind this heuristic is that if such value exists and refinementwill prove that it can hold no other functions need to be refined eliminating the need to introduce unnecessary complexity.
for example given three uninterpreted functions u1 u2 and u3 and u1 u2 u3 u1 u2 u3 setting u3to can make these two summaries equivalent.
refining this function can help to prove the equivalence of the summaries without further refining u1andu2.
to check if such a value exists for each u u we build the formula and check if it is satisfiable by passing it to an smt solver.
if the answer is yes we add the function to the list of candidates uc lines .
heuristic our second summary level heuristic is based on the intuition that functions that are used differently in mandm are better candidates for refinement because they are more likely to lead to nonequivalent summaries.
in that case again non equivalence can be established without refining the remaining functions.
for example given uninterpreted functions u1andu2 and u1 u2 u2 satisfaction of the formula can be established by refining u1.
ifu1is equal to the summaries are equivalent regardless of the value of u2.
to follow on this intuition for each u u we count the number of occurrences in mandm .
if the number differs we add the function to the list of candidates uc lines .
for the example in figure 3a this heuristic will identify functions uf2acc and uf4 bess norm .
the first is selected because accis used in line of m in figure but not in m. the second is selected because bessis used in line of min figure but not in m .
when no heuristics identifies promising refinement candidates to add to uc we set ucto all uninterpreted functions in u lines in algorithm .
we then proceed to the next step analyzing codelevel information for identifying the most promising statement candidate to skip lines .
heuristic to perform code level analysis we extract all statements abstracted by the uninterpreted functions in uc line .
in our example these are statements in lines and in figure .
then for each statement we calculate two metrics.
the first heuristic .
returns the depth of the statement in the nested loop structure line .
the rationale behind this metric is that statements that are not nested in any loops are better candidates for refinement.ardiff scaling program equivalence checking via iterative abstraction and refinement of common code esec fse november virtual event usa for the example in figure both statements in lines and have a nesting index of they are not nested inside any loop.
in fact in this example only statements in lines and have a nesting index of .
next heuristic .
we calculate the number of non linear arithmetic operators such as multiplication division power and square root in a statement line .
the rationale is again that simpler statements which do not introduce additional complexity for an smt solver are better candidates for refinement .
for our example in figure the statement in line has no such operators and the statement in line has pow and .
we sum the loop nesting index and the statement complexity index and consider that to be the score of a statement lines in algorithm .
after all statements are scored this process returns a statement with the smallest score line choosing one at random if multiple statements with the same score exist.
in our example the statement in line of figure has a score of and is returned by the procedure it will not be abstracted in the next iteration.
the equivalence checking assertion produced after this refinement is shown in figure 3b.
when given to an smt solver ardiff s step in figure the result is still neq.
as the formula still contains uninterpreted functions ardiff proceeds to the second refinement iteration.
in this case contains uninterpreted functions all listed above besides uf2acc .
ifuf5 twoar ar is assigned a value of is unsatisfiable regardless of the value of other functions.
thus it is picked by heuristic and added to uc.
for heuristics uf4 bess norm is selected again like in the previous iteration.
the statements abstracted by these uninterpreted functions are the statements in lines and of figure .
the rank of the first one is and of the second is .
thus heuristic will pick the statement in line as the next candidate.
to prove equivalence we need to show that the value of resin line is the same in both methods.
as predicted by heuristic that is indeed the case because the skipped statement in line shows that twoarg a and thus under the path condition of n a resis in both cases.
after this refinement the process terminates as the equivalence of the methods is established without refining the remaining uninterpreted functions.
the order of refinement plays a key role here as refining the function uf4 bess norm first would lead to an unknown result.
thus our heuristics were effective in choosing the right refinement candidates.
we evaluate each of the proposed heuristics separately as well as their combination comparing our results to that of existing tools in section .
next we show that the results produced by ardiff are provably correct.
.
validity of the results we denote by mfandm fthe symbolic summaries of methods m andm respectively that contain no uninterpreted functions.
we denote by muandm usymbolic summaries of these methods that might contain uninterpreted functions.
when ardiff terminates with an eq result and the equivalence assertion still contains an uninterpreted function mu m u is unsat.
this means thatmu m uisvalid i.e.
satisfied by every assignment.
according to kroening and strichman uninterpreted functions only weaken the formula thus mf m fis also valid and the methods are equivalent.
ardiff terminates with a neq result and uninterpreted functions in the equivalence assertion only if mu m u is unsat.
in that case mu m u is valid which implies that mf m f is valid.
that is there exists no assignment making mfandm fequivalent i.e.
the original methods are not equivalent.
.
implementation to identify common vs. changed code blocks we use gumtree a state of the art code differencing tool for languages such as java c and python.
gumtree identifies inserted deleted changed and moved code statements using an abstract syntax tree ast structure rather than a text structure.
we consider all the remaining statements common and in each refinement iteration exclude from this set statements that our algorithm chose to refine.
we group the remaining statements into consecutive blocks and for each block identify subsets of statements that can be abstracted by uninterpreted functions.
as discussed in section some common statements cannot be abstracted away e.g.
return statements or conditionals that control return statements and changed blocks.
for example common statements in lines in figure corresponds to two abstractable common blocks in lines and line .
we then use asm defuse an extension to the asm analysis framework to identify inputs and outputs of common blocks and abstract each variable defined in the block with an uninterpreted function.
we use the java pathfinder symbolic execution framework jpfse and the z3 smt solver for producing and reasoning about symbolic summaries.
we configure z3 to use simplify and aigtactics for compressing boolean formulas and qfnra nlsat and smttactics for handling non linear arithmetic.
an up to date fullyfunctional implementation of ardiff is available in our online appendix the latest citable release can also be found online .
evaluation in this section we discuss our experimental setup and evaluation results.
our goal is to answer the following research questions rq1.
how effective are the heuristics applied by ardiff ?
rq2.
how does the effectiveness of ardiff compare with that of existing solutions?
in what follows we describe our experimental subjects methodology and findings.
we then discuss threats to the validity of our results.
to facilitate reproducibility our experimental package is available online .
.
subjects we started by using benchmarks proposed by recent work on symbolic execution based equivalence checking which we refer to as the moddiff benchmarks.
as these benchmarks are relatively small cases .
statements per case on average and contain no complex constraints we also adapted for our evaluation benchmarks collected by li et al.
from the literature on evaluating symbolic and concolic execution methods in the presence of complex path conditions and non linear functions .
the methods of those benchmarks are classical numerical computationesec fse november virtual event usa sahar badihi faridah akinotcho yi li and julia rubin table evaluation benchmarks.
bench.
m loc non linear loops changed min.
max.
mean exp.
stms moddiff .
.
airy bess .
.
.
caldat .
.
.
dart .
ell .
.
.
gam .
.
.
pow .
ran .
.
.
sine .
.
tcas .
tsafe .
.
total .
.
.
functions used in real world distributions.
we excluded from this suite methods with less than lines of code as we cannot effectively inject changes in these methods.
we further excluded methods that contain string and array manipulations even though the relevant decision procedures abc and z3str are integrated with jpf se its support for strings and arrays is still incomplete.
we thus cannot provide full support for these constructs at the moment.
yet supporting strings arrays and other language constructs is orthogonal to the abstraction refinement idea proposed in this work.
in fact heuristics and .
loops are code agnostic and will work with any code constructs.
heuristic .
currently only considers arithmetic operations but can easily be extended e.g.
to count access to strings arrays with a symbolic index as another source of complexity.
the remaining moddiff benchmarks and benchmarks from the work of li et al.
are listed in table .
the first three columns of the table show the name of each benchmark the number of methods it includes and the number of lines of code loc in benchmark s methods minimum maximum and mean.
the fourth and fifth columns of the table show the fraction of statements with complex non linear arithmetic and the number of loops in each method averaged across all methods of a particular benchmark.
for example the bessbenchmark used as the baseline for our motivating example in figure contains methods ranging from to loc with .
of complex statements on average.
overall considering methods from all benchmarks together of the methods out of contain at least one loop and there are .
loops per method on average.
.
of the methods out of contain at least one statement with complex non linear arithmetic and there is .
of statements with non linear arithmetic per method on average.
as these benchmarks were not designed for the equivalence checking problem we had to create an equivalent and non equivalent version of each method.
to this end we systematically injected changes to each method using the following protocol first we used a random number generator software to automatically pick the number of changes to inject in each method between one and three.
then we used the software to select the location for the change.
to produce non equivalent cases we relied on a catalog of changes proposed by ma and offutt and picked a type of change insertion deletion update and the essence of a change arithmetic operation modification or condition modification .forequivalent cases we first attempted to use one of the existing code refactoring techniques split loops extract variable inline variable consolidate conditional fragments decompose conditionals or replace nested conditional with guard clauses .
if none of these modifications were applicable we inserted dead code such as redundant assignments or unreachable code guarded by conditions that cannot hold in practice.
we balanced the number of complex and simple non linear logic expressions in all statements we generated.
the last column of table shows the fraction of changed statements in each of the benchmarks averaged across all methods of a benchmark.
the benchmarks contributed in this work are substantially larger and more comprehensive than those used in prior studies on equivalence checking techniques.
our benchmarks together with a detailed description of the injected changes for each benchmark are available online .
.
methods and metrics to answer rq1 we created three versions of our tool which differ by the heuristics they apply in the refinement step step in figure ardiff rselects a statement to preserve at random skipping all the heuristics described in section .
.
ardiff h3applies only the statement level heuristic heuristic picking the simplest statement to preserve while considering all uninterpreted functions as refinement candidates.
ardiff applies summary level heuristics heuristic and to narrow down the set of candidate uninterpreted functions to refine and then applies the statement level heuristic for picking the statement to refine heuristic .
for each of the tool versions we counted the number of cases where the tool could correctly prove or disprove equivalence for equivalent and non equivalent cases separately.
we also counted the number of iterations it took the tool for producing the right answer.
finally we recorded the execution time for each of the benchmarks.
to answer rq2 we compared the version of the tool that performed the best in rq1 to two state of the art method level equivalence checking techniques dse and imp s. we excluded from our evaluation regression verification based tools such as symdiff and rvt as these tools can only prove equivalence but cannot disprove it.
we could not compare our technique with r ve as this tool cannot handle programs containing doubles which is the majority of our benchmarks.
like for rq1 we counted the number of correctly solved cases and the execution time of each tool.
we reached out to the authors of dse and imp s but the implementations of the techniques were not available at the time of writing.
we thus re implemented the techniques and included them in our generic equivalence checking framework .
we ran the re implemented techniques on all examples given in the corresponding papers to ensure correctness.
furthermore two authors manually cross validated the results of all experiments on all tools.
we used the same setup to configure all tools setting a timeout of seconds for each tool which included a timeout of seconds for the z3 assertion checking step.
we ran all our experiments on an ubuntu .
.
virtual machine vm with cores and gb ofardiff scaling program equivalence checking via iterative abstraction and refinement of common code esec fse november virtual event usa table correctly resolved cases with and without bounding.
bench mequivalent not equivalent dse imp s ardiff r ardiff h3ardiff dse imp s ardiff r ardiff h3ardiff moddiff16 airy bess caldat dart ell gam pow ran sine tcas tsafe total73 table mean runtime in seconds.
bench mequivalent not equivalent dse imp s ardiff r ardiff h3ardiff dse imp s ardiff r ardiff h3ardiff moddiff16 .
.
.
.
.
.
.
.
.
.
airy .
.
.
.
.
.
.
.
.
.
bess .
.
.
.
.
.
.
.
.
.
caldat .
.
.
.
.
.
.
.
.
.
dart .
.
.
.
.
.
.
.
.
.
ell .
.
.
.
.
.
.
.
.
.
gam .
.
.
.
.
.
.
.
.
.
pow .
.
.
.
.
.
.
.
.
.
ran .
.
.
.
.
.
.
.
.
.
sine tcas .
.
.
.
.
.
.
.
.
.
tsafe .
.
.
.
.
.
.
.
.
.
mean .
.
.
.
.
.
.
.
.
.
ram which was hosted on an ubuntu .
server with cores and 512gb of memory.
we enforced the timeout of seconds on each process by using the linux timeout command and used user time as reported by the linux time command to measure time for terminating processes.
we used the java xms option to control memory allocation.
.
results table shows the number of correctly resolved cases for equivalent and non equivalent methods of each benchmark separately.
for equivalent cases we also distinguish between cases that were resolved without loop bounding and the cases where loop bounding was required.
we report our result per benchmark and also in total for all benchmarks.
for example for the bess benchmark in line of table dse is able to correctly resolve six out of equivalent cases imp s is able to correctly resolve cases without loop bounding and three more cases with loop bounding.
ardiff r ardiff h3 and ardiff resolve and cases respectively without loop bounding and one more case each with loop bounding.
for non equivalent cases dse and imp s are able to disprove equivalence in four and six out of cases respectively the three variants of our tool are able to resolve six seven and seven cases.table shows the mean execution time in seconds averaged over all cases of each benchmark for equivalent and non equivalent cases separately.
rq1.
comparing the performance of the three versions of our tool with each other shows that the combination of all heuristics that ardiff applies is the most beneficial for resolving both equivalent and non equivalent cases ardiff is able to resolve equivalent cases compared with for ardiff h3and only for ardiff r. this includes three bounded cases for each tool.
interestingly for the gam benchmark while ardiff h3had to bound one case ardiff could avoid selecting the statement sleading to the loop bounding.
that is because it applied heuristic first to select an uninterpreted function that only appeared in the summary of the changed method m .
even though statements of this function had a higher individual complexity score than s skipping them in the abstraction helped prove equivalence without any need to refine loops as predicted by the heuristics.
ardiff was able to resolve two additional cases for this benchmark both without loop bounding.
table shows the total number of cases where performing additional refinement iterations helped each of the tool version arrive atesec fse november virtual event usa sahar badihi faridah akinotcho yi li and julia rubin table correct cases with iterations.
mardiff r ardiff h3ardiff cases iter.
cases iter.
cases iter.
eq .
.
.
neq .
.
.
the correct result cases as well as the mean number of iterations per case iter .
the number of uninterpreted functions in the final summary for each case and the time spent in the refinement step are also available in our online appendix .
while ardiff rhas the highest mean number of iterations for both equivalent and non equivalent cases it is able to solve the smallest number of cases.
that is because by making a wrong pick it arrives at a solution that leads to an unknown result and keeps refining the summary until it times out.
ardiff h3makes smarter choices and is thus able to solve more cases with a lower number of iterations.
the combination of heuristics applied by ardiff allows it to reach the best result with the smallest number of iterations.
as a result ardiff also outperforms other variants in the mean execution time as shown in table .
answer to rq1 to summarize our experiments show that the refinement heuristics implemented by ardiff increase its effectiveness in terms of the total number of equivalent and non equivalent cases the tool can resolve and its efficiency in terms of both the execution time and the number of iterations per benchmark.
rq2.
we now compare the performance of ardiff to that of dse and imp s. naturally ardiff outperforms dse because it extends dse with the abstraction refinement loop and the refinement heuristics.
as a result ardiff solves more equivalent and more non equivalent cases compared with dse.
however it is also slower than dse because it has to perform more abstractionrefinement iterations to achieve these results.
when comparing with imp s ardiff can solve out of equivalent cases vs. cases for imp s. it also had to bound loop iteration in only vs. cases.
all equivalent cases solved by imp s are solved by ardiff as well.
in addition there are cases solved by ardiff and not by imp s. that is because imp s relies on static analysis which over approximates the set of statements really required to prove disprove equivalence.
as such it deems a complex statement impacted and includes it in the summary even though the statement is unnecessary for proving equivalence as we showed in section for our motivating example.
non equivalent cases are a harder challenge for any equivalence checking tool ardiff performs comparably and even slightly better than imp s solving vs. non equivalent cases.
in five cases from bess caldat gam and ellbenchmarks ardiff could produce the correct proof when imp s resulted in unknowns due to the overapproximations described above.
however there are three non equivalent cases solved by imp s which result in unknown forardiff intcas bess and ranbenchmarks.
in all three cases imp s was more successful because the change only impacted a very small portion of each method.
as such imp s could quickly prove non equivalence while ardiff continued refining numerous uninterpreted functions in these methods until it ran out oftime.
interestingly increasing the execution time allowed ardiff to solve the previously unresolved case in the tcasbenchmark as well.
for the other two cases even though the solver made a correct non equivalence decision in one of the iterations ardiff conservatively refined uninterpreted functions see figure until it obtained an equivalence assertion which is no longer solvable.
for the runtime ardiff outperforms imp s in terms of the execution time for equivalent cases .
vs. .
seconds per case on average.
that is because it is able to successfully solve more cases eliminating many timeouts.
for non equivalent cases imps s performance is higher.
the main portion of performance loss in our tool occurs in unknown cases while imp s makes one attempt and terminate if the smt solver produces unknown ardiff will attempt to refine the assertion and try multiple times.
yet this design choice allows ardiff to solve more cases.
interestingly for cases solved by both ardiff and imp s the performance of the tools is comparable .77s and .56s on average respectively.
answer to rq2 to summarize ardiff substantially outperforms existing techniques for equivalent cases and performs comparably and even slightly better for non equivalent cases.
the increased accuracy comes at the cost of a decrease in execution time when compared with dse and with imp s for non equivalent cases only.
ardiff outperforms imp s in terms of execution time for equivalent cases.
.
threats to validity forexternal validity our results may be affected by the selection of subject methods that we used and may not necessarily generalize beyond our subjects.
we attempted to mitigate this threat by using a set of benchmark methods available from related work on symbolic execution based equivalence checking and by extending this set to include additional benchmarks for evaluating symbolic execution methods in the presence of complex conditions such as loops and non linear arithmetic functions.
as we used a set of different benchmarks of considerable size and complexity we believe our results are reliable.
as we had to inject changes when generating equivalent and nonequivalent versions for each of these new benchmarks the changes may not reflect real cases of software evolution.
we mitigated this threat by basing our changes on existing refactoring techniques.
we mitigated possible investigator bias of creating these cases by applying the changes in a systematic way that considered a broad range of change types and a random number generator software to pick the change type and location.
finally we had to re implement the baseline tools dse and imps.
to ensure the correctness of our implementation we run the reimplemented techniques on all examples given in the corresponding papers.
furthermore as the implementation of ardiff relies on the same underlying framework and setup we do not believe that hinders the validity of our findings.
forinternal validity deficiencies of the underlying tools our approach uses such as the symbolic execution engine and smt solver might affect the accuracy of the results.
we controlled for this threat by manually analyzing the cases that we considered and confirming their correctness.ardiff scaling program equivalence checking via iterative abstraction and refinement of common code esec fse november virtual event usa discussion and related work our discussion of related work focuses on techniques that use symbolic execution for equivalence checking and software equivalence checking techniques that are based on other related approaches.
symbolic execution.
dse and imp s are the closest to our work.
they are extensively discussed in section and compared with our tool.
in a nutshell our work extends dse with an abstraction refinement loop and a set of heuristics for selecting preferred refinement candidates.
our work is orthogonal to imp s as our proposed heuristics focus on selecting the best refinement candidate based on the structure of the symbolic summaries and structure of the code.
in fact a fruitful direction of possible future work could be applying our proposed heuristics over imp s which could result in a solution that better handles the non equivalent cases.
we also intend to explore broader solutions for non equivalent cases as a part of the future work.
moddiff is a modular and demand driven analysis which performs a bottom up summarization of methods common between versions and only refines the paths of the methods that are needed to prove equivalence.
clever formulates the notion of clientspecific equivalence checking and develops an automated technique optimized for checking the equivalence of downstream components by leveraging the fact that their calling context is unchanged.
as such clever only explores paths that are relevant within the client context.
both these techniques scale the analysis to work on the inter method level and only consider full path pruning at the individual method level.
our work is thus orthogonal and complementary to these approaches combining the approaches could be explored in future work.
model checking and theorem proving.
symdiff checks the equivalence of two methods given their behavioral specification provided by the user.
rvt proves partial equivalence of two related programs showing that they produce the same outputs for all inputs on which they terminate according to a set of proof rules.
recursive calls are first abstracted as uninterpreted functions and then the proof rules for non recursive functions are applied in a bottom up fashion.
our technique does not rely on any user defined rule.
also while these approaches can only prove the equivalence our technique can formally prove non equivalence.
relational verification approaches e.g.
focus on verifying properties about two programs or two runs of the same program including program equivalence.
these approaches mostly focus on loopy and or recursive programs they aim to align programs and or their execution traces to a so called product program and then identify invariants at the alignment points effectively transforming a verification problem into an invariant synthesis task.
our work is orthogonal to these approach as it does not need to discover invariants but rather assumes that the two compared versions are closely related allowing for better scalability of our tool.
yet combining and comparing our technique with these approaches could be an interesting topic of possible future work.
incremental verification.
this line of work aims to reuse results from prior verification as programs evolve assuming that properties of a client to be verified are given.
for example sery et al.
usesa lazy approach implemented in a tool named evolcheck which extracts the property directed summaries of all function calls i.e.
that capture only the relevant information needed to verify the assertion and then locally validates the old summaries w.r.t.
the updated version of the program thus effectively avoiding the need to reverify the updated code whenever possible.
chaki et al.
use state machine abstractions to analyze whether every behavior that should be preserved is still available and whether added behaviors conform to their respectful properties.
fedyukovich et al.
offer an incremental verification technique for checking equivalence w.r.t.
program properties designed specifically for loopy programs.
our work does not rely on verification results from previous versions and does not require any user generated specifications.
concolic execution.
shadow symbolic execution uses a combination of concrete and symbolic runs to identify path divergence between subsequent program versions.
the goal of this technique is to generate an input that will make two versions of the program take a different path.
however it cannot prove or disprove functional equivalence.
uc klee is an equivalence checking tool for c programs built on top of the symbolic engine klee .
it automatically synthesizes inputs and verifies that they produce equivalent outputs on a finite number of paths.
yet this tool cannot prove or disprove equivalence in full.
while all these techniques mostly aim at identifying examples to demonstrate differences the main focus of our work is on formally proving equivalence.
conclusion in this paper we proposed an iterative symbolic execution based approach for checking equivalence of two versions of a method.
it leverages the idea that versions share a large portion of common code which is not necessarily required to prove equivalence and can be abstracted away using uninterpreted functions.
such abstraction helps hide complex parts of the code such as non linear arithmetic and unbounded loops that lead to unknown or imprecise results.
the key contribution of our approach lies in identifying the set of common code statements that can be abstracted away vs. common code statements that are needed for establishing equivalence.
we developed a set of heuristics that help to distinguish between such cases and evaluated both the contributions of individual heuristics and of their composition comparing our tool with two state of theart method level equivalence checking techniques dse and imp s .
for the evaluation we used the existing equivalence checking benchmarks proposed by earlier work and also devised a more complete set of benchmarks that contains realistic methods with complex non linear arithmetic operations borrowed from the field of scientific computing.
the results of our evaluation show that our tool substantially outperforms existing approaches for proving equivalence and performs comparably when applied to nonequivalent cases.
the implementation of our approach the benchmarks we developed and our experimental evaluation results are available online .