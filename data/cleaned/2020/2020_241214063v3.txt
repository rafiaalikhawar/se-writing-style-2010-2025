rango adaptive retrieval augmented proving for automated software verification kyle thompson university of california san diego ca usa r7thompson ucsd.edununo saavedra inesc id ist university of lisbon lisbon portugal nuno.saavedra tecnico.ulisboa.ptpedro carrott imperial college london london uk pedro.carrott imperial.ac.uk kevin fisher university of california san diego ca usa kfisher ucsd.edualex sanchez stern university of massachusetts amherst ma usa sanchezstern cs.umass.eduyuriy brun university of massachusetts amherst ma usa brun cs.umass.edu jo ao f. ferreira inesc id ist university of lisbon lisbon portugal joao joaoff.comsorin lerner university of california san diego ca usa lerner cs.ucsd.eduemily first university of california san diego ca usa emfirst ucsd.edu abstract formal verification using proof assistants such as coq enables the creation of high quality software.
however the verification process requires significant expertise and manual effort to write proofs.
recent work has explored automating proof synthesis using machine learning and large language models llms .
this work has shown that identifying relevant premises such as lemmas and definitions can aid synthesis.
we present rango a fully automated proof synthesis tool for coq that automatically identifies relevant premises and also similar proofs from the current project and uses them during synthesis.
rango uses retrieval augmentation at every step of the proof to automatically determine which proofs and premises to include in the context of its fine tuned llm.
in this way rango adapts to the project and to the evolving state of the proof.
we create a new dataset coqstoq of open source coq projects and theorems from github which includes both training data and a curated evaluation benchmark of well maintained projects.
on this benchmark rango synthesizes proofs for .
of the theorems which is more theorems than the prior state ofthe art tool tactician.
our evaluation also shows that rango adding relevant proofs to its context leads to a increase in the number of theorems proven.
index terms formal verification theorem proving large language models retrieval augmentation software reliability i. i ntroduction the cost of poor software quality is alarmingly high with estimates suggesting that it incurs trillions of dollars in losses annually in the united states alone .
formal verification which enables developers to mathematically prove that software kyle thompson nuno saavedra pedro carrott kevin fisher alex sanchezstern yuriy brun jo ao f. ferreira sorin lerner and emily first.
rango adaptive retrieval augmented proving for automated software verification.
inproceedings of the 47th international conference on software engineering icse ottowa on canada april .adheres to its intended behaviors and specifications has been shown to help improve software quality.
notably a study investigating c compilers among them compcert llvm and gcc observed that the only compiler for which no bugs were found was compcert which is formally verified using the coq proof assistant.
while formal verification can lead to high quality software it is expensive.
for example the code required to verify compcert is times as large as the code implementing its functionality .
a promising line of work towards automating formal verification is to automatically generate the proofs using machine learning techniques .
within this research space there has been a recent and exciting line of work on exploring large language models llms for proof generation .
prior llm based approaches for proof automation have shown that premises such as lemmas and definitions are important to add to the context .
this builds off of retrieval augmented generation rag approaches which use a separate search step to add context to an llm.
for the task of proof synthesis we call this technique retrieval augmented proving rap where a separate search step retrieves relevant information for proving a given theorem.
one limitation of prior approaches using rap is that they do not fully exploit the local information that is available when synthesizing proofs.
in this paper we show that an essential component of rap is to also include similar proofs in the context not only at the beginning of the proof but to continue to give the llm sources of inspiration and knowledge adapting to the evolving proof state.
the intuition is that having similar proofs in the context of the llm as determined at each step in the proof can help guide the llm in the right direction.
our 1arxiv .14063v3 jan 2025work also distinguishes itself within the broader scope of all machine learning based proof generation approaches by using both premises and proofs in an online setting.
we reify this idea of adding relevant proofs not just premises to the context of an llm in an approach and tool called rango.
at each proof step rango first determines which proofs and premises from the current project are most relevant for generating the next step.
by retrieving in project information rango is able to learn local proof strategies adapting itself to the current project.
then the next step is generated using a language model where the most relevant proofs and premises are given as context in addition to the current proof script the steps taken so far and the proof state a set of logical formulas describing the goals that remain to be proven .
furthermore the assessment of which proofs are relevant is done at each step in the proof thus being able to adapt to the evolving nature of the proof.
to train rango effectively we collected a new large corpus of coq data which we call coqstoq.
we mine this corpus from github using the coqpyt python client for coqlsp .
we split coqstoq into training data and a benchmark on which we evaluate rango.
the benchmark contains all of the projects from a previous benchmark coqgym that compile in coq .
.
additionally it contains compcert and four projects from the coq community repository that are committed to long term maintenance .
in summary this paper s main contributions are an approach rango to synthesizing proofs that adds to the context of the llm not just premises but also relevant proofs.
in this way rango adapts to the project and to the proof state at each step.
a new dataset coqstoq for proof synthesis in coq comprising theorems and proof steps from different github repositories.
the dataset is split into training data and an evaluation benchmark.
an evaluation on coqstoq comparing rango to three stateof the art systems proverbot9001 tactician and graph2tac .
our evaluation shows that rango does better than these tools by proving more theorems than tactician more than proverbot9001 and more than graph2tac.
our evaluation also shows that adding relevant proofs to the context in rango is important leading to a increase in the number of theorems proven.
we release rango coqstoq all trained models appearing in this paper and all of the code required to reproduce the experiments in this paper at this link rkthomps coq modeling.
ii.
m otivating example in coq to motivate our approach we explain how formal verification works in coq and then demonstrate through a real example how rango helps automate the proof writing process.
in coq a proof engineer can state a theorem about their code and then write a proof that the theorem holds true.
theorems in coq are types and so proving them true amountsto constructing a proof term of the same type in coq s gallina language.
however since writing that term directly is challenging proof engineers typically write proof scripts in coq s ltac language which consist of tactics such as induction .
when executed these tactics guide coq in the construction of a complete proof term.
coq provides feedback after each tactic application and displays the current proof state which includes the goals left to prove and the local context of assumptions.
the proof engineer knows that they have proven the theorem when there are no more goals.
aproof development in coq consists of theorems and their associated proof scripts potentially across multiple files.
a proof engineer may even prove a series of lemmas with the sole intention of using them to prove a main theorem.
across a proof development proof engineers often reuse bits and pieces from their proofs.
however different proofs have meaningful differences in say which lemmas are used.
when building tools to help automate a proof engineer s proving process it is important to fully utilize the expertise provided by the proof engineer.
we accomplish this by directly leveraging information from existing proofs.
let s take a closer look at the compcert proof development which is in coqstoq s benchmark.
the file memdata.v has the following theorem.
lemma memval inject compose forall f g v1 v2 v3 memval inject f v1 v2 memval inject g v2 v3 memval inject compose meminj f g v1 v3.
to prove such a theorem one can attempt to apply tactics step by step considering the current proof state and context of assumptions.
alternatively one can instead at each step also take inspiration from existing proofs in the project.
this is the rango approach.
at each step the rango tactic prediction model draws inspiration from the following proof from the file values.v in the compcert proof development just one of the many that it retrieves.
lemma val inject compose forall f g v1 v2 v3 val.
inject f v1 v2 val.inject g v2 v3 val.inject compose meminj f g v1 v3.
proof.
intros.
inv h auto inv h0 auto.
econstructor.
unfold compose meminj rewrite h1 rewrite h3 eauto.
rewrite ptrofs.add assoc.
deceq.
unfold ptrofs.add.
apply ptrofs.eqm samerepr.
auto with ints.
qed.
rango updates its sources of inspiration and knowledge at each step as rango also adapts to the current proof state.
the proof script for val inject compose would not work outright for the theorem in question but a part of it is useful and so rango begins to write the proof of memval inject compose as follows.
proof.
intros.
inv h inv h0 econstructor.
as rango generates the next tactic it relies both on learned knowledge from fine tuning and on retrieved knowledge in the form of lemmas and proofs in the project.
later in the proof rango retrieves the following proof from earlier in memdata.v .
2lemma memval inject incr forall f g v1 v2 memval inject f v1 v2 inject incr f g memval inject g v1 v2.
proof.
intros.
inv h econstructor.
eapply val inject incr eauto.
qed.
rango also identifies val inject compose as a relevant helper lemma.
it determines that it may be able to useval inject compose likeval inject incr and closes the proof as follows.
proof.
intros.
inv h inv h0 econstructor.
auto.
eapply val inject compose eauto.
qed.
without retrieval a tool could get lucky and hallucinate that certain lemmas like val inject compose exist.
however rango does not have to rely on luck because it can retrieve relevant lemmas and proofs.
thus through retrieving both proofs and lemmas from the project at each step rango is able to prove the theorem in question while other state of the art tools like tactician and proverbot are not.
iii.
t herango approach rango synthesizes coq proofs using relevant proofs and lemmas from the current project at every step of the proof adapting to the project and to the state of the proof.
to do this rango uses two subsystems.
the first subsystem the tactic generator generates individual proof steps or tactics .
the second subsystem the searcher section iii d uses the tactic generator to search for a complete proof by composing generated tactics.
figure illustrates the interaction between the tactic generator and the searcher.
rango s tactic generator can be further broken down into three components.
the first two components the proof retriever section iii a and the lemma retriever section iii b determine which proofs and lemmas respectively are relevant for generating the next tactic.
the third component the language model section iii c takes as input relevant proofs relevant lemmas a proof script and a proof state and then generates the next tactic in the proof.
in the remainder of this section we describe each of the three components in the tactic generator and we describe the searcher.
a. proof retriever the proof retriever selects relevant previously completed proofs in the current project to provide as context to the language model as it generates the next tactic.
at a given proof step the proof retriever selects from a set of proofs called the proof bank .
the proof bank consists of proofs from earlier in the file or from one of the file s dependencies.
only proofs from the current project are in the proof bank.
at every proof step the proof retriever selects the kmost relevant proofs from the proof bank for generating the next tactic.
to find the kmost relevant proofs at a given point in the proof the proof retriever compares the current proof state s with proof states from proofs in the proof bank.
the proof retriever defines the relevance of a proof pfrom the proof bank to be the maximum similarity between sand a proof statesifrom p. specifically given a function similarity that determines the similarity between two proof states the proof retriever defines the relevance of a proof in the proof bank as relevance p max si states p similarity s si where states p is the set of proof states in p. to determine the similarity between two proof states the proof retriever uses the bm information retrieval technique .
given a set of documents and a query bm assigns each document a score based on its relevance to the given query.
bm determines the relevance of a document by comparing the word frequencies from the document to the word frequencies from the query.
if the document and the query have similar word frequencies then bm considers the document to be relevant.
in its calculation bm downweighs words that appear across many documents as these words are often not helpful for determining relevance.
note that bm is a sparse retrieval technique because it retrieves based on word frequencies.
when the proof retriever uses bm documents correspond to proof states from proofs in the proof bank and the query corresponds to the current proof state.
the words in a proof state are the identifiers used in the proof state.
we then define similarity in terms of bm as follows the similarity between the current proof state sand a proof state from a proof in the proof bank siis defined to be the relevance assigned to siby bm .
note that information retrieval techniques other than bm can be substituted into rango s proof retriever.
in section v d we explore the use of retrieval techniques that rely on neural networks known as dense retrieval techniques.
b. lemma retriever the lemma retriever retrieves the statements of the lemmas previously defined in the current project that could be directly used in the current proof.
note that the lemma retriever does not retrieve the proofs of these lemmas just the statements.
the structure of the lemma retriever is similar to the structure of the proof retriever.
the lemma retriever has access to the lemma bank which is defined as the set of lemmas appearing earlier in the current file or in one of the file s dependencies.
the lemma bank only considers lemmas from the current project.
like the proof retriever the goal of the lemma retriever is to select the jmost relevant lemmas.
the lemma retriever uses the sparse retrieval algorithm tf idf to assign a relevance score to each lemma in the lemma bank with respect to the current proof state.
note that in this case the query given to tf idf is the current proof state the set of documents are the lemmas in the lemma bank and the words in a lemma correspond to the identifiers in the lemma.
again like in 3rango tactic generator tg proof retriever lemma retrieverllmrelevant proofs relevant lemmas theorem current proof state andproof script sofarprevious proofs in current project previous lemmas incurrent projectnext tactictactic tgrango searcher tactic coq checks proof complete and error free tactic tacticattempt n tg coq finds error attempt tgfig.
.
overview of rango s architecture.
rango s tactic generator uses retrieved relevant proofs and lemmas from the current project as input to an llm along with the theorem current proof state and proof script so far to predict the next tactic.
rango s searcher uses the tactic predictions to attempt to synthesize a complete proof.
a proof attempt is correct if coq determines that it has no errors and there are no more goals left to solve.
the proof retriever the lemma retriever can use information retrieval techniques besides tf idf.
c. language model at a given proof step the language model generates the next tactic using the following inputs relevant proofs retrieved from the proof retriever relevant lemmas retrieved from the lemma retriever thetheorem statement and the proof script thus far the current proof state to obtain a language model that can effectively use this information we fine tune a pretrained decoder only llm.
we construct fine tuning examples from a set of training projects see section iv .
each fine tuning example consists of a prompt containing the four inputs mentioned above and a target containing the next tactic.
since the language model is a decoder only llm the inputs and targets are concatenated during fine tuning.
following prior work the loss is only computed over the target so that the model learns to conditionally generate the target given the input and not the input itself.
we create each training example exactly as we would during inference.
that is we run the proof retriever and lemma retriever at every proof step in our dataset and then construct the prompt using the retrieved proofs and lemmas.
note that language models can only process a limited number of tokens.
to account for this constraint we allocate a maximum number of tokens to each of the four inputs in each training example.
furthermore we allocate a maximum number of tokens that can be generated by the language model.
we truncate each input as follows.
we keep the largest whole number of relevant proofs that does not exceed the token limit.
we do the same for relevant lemmas.
we keep the longest suffix of the theorem statement and proof script that does not exceed the token limit.
we keep the longest suffix of the proof state that does not exceed the token limit.
we truncate the output at training time by keeping the longest prefix that doesnot exceed the token limit.
at inference time we limit the number of tokens that the model can generate.
d. searcher given a tactic generator the searcher attempts to find a sequence of tactics that completes the proof.
to find a sequence of tactics the searcher uses a procedure that we call rollout search .
rollout search consists of a sequence of rollouts where in each rollout the searcher samples a tactic from the tactic generator using temperature sampling.
the searcher then appends the tactic to the current proof and uses coq to check the resulting proof attempt.
the proof attempt will be in one of three states complete invalid or incomplete.
if the proof attempt is complete meaning that coq shows no more goals to be proven then the search is successful.
if the proof attempt is invalid then the tactic sampled from the language model resulted in an error and the searcher begins a new rollout.
if the proof attempt is incomplete the searcher continues the current rollout by sampling yet another tactic from the tactic generator.
the searcher executes rollouts until it finds a complete proof or until a timeout.
iv.
t hecoqstoq dataset as part of our work we created coqstoq a new dataset of coq proofs mined from open source github projects.
we collect theorems and their respective proofs from all opensource repositories that listed coq as its primary language as of november 5th .
we applied no other filters to our data collection e.g.
stars or number of contributors since coq itself ensures that successfully compiled files provide sound proof data.
we first attempted to automatically compile each repository by executing any existing makefile or by compiling each individual file in the order specified by a coqproject file present in the repository.
then we used coqpyt to validate each coq file.
we considered a file to be valid if it reports no errors during compilation.
we only included repositories in our training dataset with at least valid file.
we note that both the compilation and validation steps are 4table i attributes of the training set benchmark and validation set .
attributecount training benchmark validation total repositories theorems proofs proof states steps executed using coq .
so files not compatible with this version are excluded.
for each valid coq file obtained we used coqpyt to extract information from each proof step in the file.
for each proof step we extracted its textual representation corresponding proof state and its context.
the context of a proof step includes the premises used in the proof step.
we also use coqpyt to collect the set of premises that are available at every point in the file.
after collecting coqstoq we split it into a training set a validation set and a benchmark test set .
we use the training set to train the language model.
we use the benchmark to evaluate rango against other tools and to evaluate the individual components of rango.
we use the validation set to tune model hyper parameters and to experiment with different configurations of our tool.
coqstoq s benchmark consists of all coqgym projects that compiled in coq .
.
coqgym is a benchmark that was used to evaluate previous tools for which the projects were compiled in coq .
.
we also added compcert to our set of test projects to evaluate how rango could help formally verify real world software.
finally we add projects from the coq community that are committed to long term maintenance to our benchmark and validation set.
we put any project not in our benchmark or validation set in the training set.
finally to prevent against copy andpasted theorems we omit files from our training set where a theorem statement exactly matched a theorem statement from the validation set or the benchmark.
table i shows how the relevant proof data is numerically distributed across all splits.
the training set contains a substantial portion of the repositories proofs and proof steps in comparison to the benchmark and validation set.
these results showcase the abundance of proof data used for training which is guaranteed to pertain to valid coq proofs due to the use of coqpyt during the mining process.
figures and plot the distribution of proofs and projects respectively according to their size.
in terms of proof size the number of steps per proof follows a similar distribution for all splits.
in terms of project size the training set contains mostly smaller projects with fewer proofs while the reverse is true for the benchmark and validation set.
this asymmetry is justified as we intend to evaluate how the training generalizes to other possibly larger projects.
v. e valuation to understand rango s performance we propose the following research questions sizeproofsdensity training 359714611benchmark validationfig.
.
violin chart over the size of proofs in the training set benchmark and validation set.
proof size is the number of steps in the proof.
the quartiles are indicated near the corresponding dashed lines.
sizeprojectsdensity training 53benchmark validation fig.
.
violin chart over the size of projects contained in the training set benchmark and validation set.
project size is the number of proofs in the project.
the quartiles are indicated near the corresponding dashed lines.
rq1 how does rango compare against other proof synthesis tools in coq?
rq2 how do the proof retriever and the lemma retriever contribute to rango s ability to synthesize proofs?
rq3 how do alternative retrieval techniques perform in rango s proof retriever?
rq4 how does rango perform when it is instantiated with a na ve retrieval algorithm?
rq5 how does rango s rollout search compare to best first search?
rq6 what kinds of theorems can rango prove and how do the proofs generated by rango compare to the proofs generated by other tools?
a. experimental setup rango s language model is a fine tuned version of the .
billion parameter model deepseek coder .
we fine tune the llm on a set of examples gathered from the training projects in our dataset coqstoq.
we fine tune for training steps with a batch size of on nvidia a100 gpus.
we use gradient accumulation steps so that our effective batch size is .
we choose the checkpoint with the best loss on our validation set.
we fine tune using lora and fsdp .
we use the adam optimizer with a learning rate of .
we allocate tokens to retrieved 5table ii comparison of theorems proven between rango and state of the art proof synthesis tools projectcoqstoq evaluation graph2tac evaluation rango tactician proverbot theorems rango graph2tac theorems compcert .
.
.
fourcolor .
.
.
mathclasses .
.
.
buchberger .
.
.
reglang .
.
.
poltac .
.
.
.
.
huffman .
.
.
zfc .
.
.
.
.
zornslemma .
.
.
extlib .
.
.
dblib .
.
.
.
.
hoaretut .
.
.
total .
.
.
.
.
rango tool .
.
.
table iii post training cutoff comparison of theorems proven between rango and state of the art proof synthesis tools rango tactician proverbot theorems bb5 .
.
.
pnv .
.
.
total .
.
.
proofs tokens to retrieved lemmas tokens to the theorem and proof script tokens to the proof state and tokens to the output.
during proof synthesis rango is allocated a single nvidia rtx for inference and a single cpu with 16gb of ram for proof checking.
we use a minute timeout for all of our proof attempts.
our timeout does not include the initialization costs of loading and compiling the file.
we use a temperature of .
for sampling.
b.rq1 rango versus other tools we evaluate rango against three state of the art proof synthesis tools for coq proverbot9001 tactician and graph2tac .
proverbot9001 which we refer to as proverbot uses a custom architecture involving several gated recurrent units and feed forward neural networks .
graph2tac also uses a custom architecture based on graph neural networks.
it uses this architecture both to predict which tactic to use next and which definitions in the environment including helper lemmas should be given as an argument to the tactic.
therefore graph2tac can retrieve helper lemmas and definitions from the environment just like rango.
lastly tactician maintains a database of proof states which is defined similarly to rango s proof bank.
at every proof step tactician finds the most similar proof states in its database by comparing sets of identifiers using k nn .
then tactician performs a search by directly applying tactics that were used at similar proof states.we evaluate rango tactician and proverbot on all projects from coqstoq s benchmark using coq .
.
note that neither tactician nor proverbot are built to utilize a gpu during their respective proof search procedures.
therefore we run each tool using a single cpu.
we run tactician using a minute timeout.
proverbot is configured to run with depth limits instead of timeouts so for most of the reported proofs proverbot fails before minutes.
in table ii we report the results for rango tactician and proverbot on the theorems in the coqstoq benchmark.
rango finds more proofs than tactician and more proofs than proverbot.
in table ii we also report results for graph2tac.
note that since graph2tac is only compatible with coq .
we evaluate graph2tac on different project versions than rango.
furthermore there are only of the projects in coqstoq s benchmark that graph2tac was not directly trained on.
therefore we can only fairly evaluate on these three projects.
we only compare theorems whose statements match exactly between project versions.
note that this does not guarantee that a proof in one project version will translate to a proof in the other project version since other definitions in the project may have changed between versions.
for each theorem we ran graph2tac on a single nvidia rtx and a single cpu with a timeout of mins.
keeping differences between project versions in mind rango proves more theorems than graph2tac.
in the last row of table ii we show the combined number of theorems proven between rango and each other tool.
we can see that each tool finds proofs for a significant subset of theorems where rango could not find a proof.
running rango alongside tactician proverbot and graph2tac leads to and respective increases in the number of theorems proven over running rango alone.
one limitation of the coqstoq benchmark is that its projects were created before the pretraining cutoff of rango s underlying llm.
so although we do not fine tune on the projects in the coqstoq benchmark there is a risk that rango s underlying 6table iv proof l emma retriever ablation system theorems proven rango .
rango w o lemmas .
rango w o proofs .
rango w o retrieval .
time s theorems proven theorems proven over time rango rango w o lemmas rango w o proofs rango w o retrieval fig.
.
number of theorems proven by rango variants over time in seconds.
llm saw them during pre training.
therefore we evaluate rango on two projects whose first commit on github occurred after the pretraining cutoff of rango s underlying llm .
the results of this evaluation are shown in table iii.
on these two projects rango proves more theorems than tactician and62 more theorems than proverbot.
unfortunately we cannot compare rango to graph2tac on these projects because they do not compile with coq .
.
takeaway rango synthesizes more proofs than tactician and more proofs than proverbot9001 on coqstoq s benchmark.
rango also synthesizes more proofs than graph2tac on its subset of coqstoq s benchmark.
c.rq2 contribution of proof and lemma retrievers to determine the contribution of the proof retriever and the lemma retriever to rango s performance we train one version of rango without the proof retriever one version without the lemma retriever and one version with neither the proof retriever nor the lemma retriever.
we evaluate each of these variants on a randomly selected subset of theorems from coqstoq s benchmark.
we call this subset of theorems our ablation set .
we report the percentage of theorems that each of these variants prove in table iv.
table iv shows that retrieval augmentation is essential to rango s success.
rango proves more theorems than the variant without retrieval.
table iv also shows that the prooftable v proof l emma retriever ablation on a random file wisesplit systemtheorems proven coqstoq split file wise split rango .
.
rango w o lemmas .
.
rango w o proofs .
.
rango w o retrieval .
.
retriever contributes to rango s success more than the lemma retriever.
indeed rango proves more theorems than the variant without a proof retriever whereas rango only proves more theorems than the variant without a lemma retriever.
this is indeed one of our main contributions we show that adding relevant proofs not just lemmas as prior work had done is important to making retrieval augmented proving perform better.
we show the number of proofs found by rango and its variants over time in fig which visualizes the large effect of rango s proof retriever.
we also investigate the contribution of rango s proof and lemma retrievers to its ability to adapt to held out projects.
we show that rango s proof and lemma retrievers capture information about a project that would otherwise need to be stored in the weights of the underlying llm.
we show this by first training a separate version of each variant on an inter file split as opposed to coqstoq s inter project split.
that is we randomly split the files in the coqstoq dataset into a training validation and testing set.
then we train each variant on the training set of the inter file split.
this way the inter file versions of the variants have information about all coqstoq projects in their weights.
then we compare inter file variants to inter project variants on a subset of theorems that are in the testing sets of both the inter file split and the inter project split.
we show the results in table v. from these results we see that all variants benefited from having project specific information in the weights of their underlying llms.
however the variants that did not have proof retrieval benefited more than variants that did have proof retrieval.
specifically rango without proofs and rango without proofs and lemmas obtained increases of and43 in the number of theorems proven when they were trained on an inter file split.
in contrast rango and rango without lemmas obtained more modest increases of15 and11 .
this indicates that rango s proof retriever captures a significant amount of the information that would be gained by training directly on files from the current project.
takeaway rango s proof retriever and lemma retriever are imperative to its success.
together they contribute to a increase in the number of theorems proven and rango s proof retriever alone contributes to a increase in the number of theorems proven.
this demonstrates the importance of adding relevant proofs not just lemmas as prior work had done.
7table vi proof retrieval variants proof retrieval theorems proven bm .
tf idf .
codebert .
d.rq3 comparing retrieval algorithms for proof retrieval we compare sparse retrieval techniques to dense retrieval techniques for retrieving proofs.
sparse retrieval techniques such as bm are those that retrieve information based on word counts.
in contrast dense retrieval techniques retrieve information based on vector embeddings derived from a neural network.
note that a comparison has been made between sparse retrieval techniques and dense retrieval techniques for the selection of premises .
however the techniques for training models to select premises do not transfer to training models to retrieve proofs due to a difference in objectives.
in premise selection the objective is to predict whether or not a premise will be used in the next proof step.
for proof retrieval the objective is to retrieve the proofs that are most helpful for generating the next proof step.
however at training time there is no way to know which proofs satisfy this objective.
therefore standard supervised learning techniques are not applicable.
recall that a main requirement of the proof retriever is the ability to compare proof states.
rango uses the bm algorithm to determine the similarity between proof states.
alternatively to compare two proof states rango could use a neural network to compute a vector embedding that contains semantic information about each proof state.
then the similarity between two proof states could be defined as the cosine similarity between the vector embeddings.
we implemented this kind of proof retriever using the codebert 125m parameter model .
we compare the proof retriever used in rango to a version that uses dense embeddings in table vi.
we also include another popular sparse retrieval algorithm tf idf in table vi.
because the difference in performance between bm and tf idf is small we ran this ablation on the entire coqstoq benchmark instead of our ablation set to ensure the precision of our comparison.
rango proves more theorems than a variant that uses codebert embeddings to retrieve proofs.
thus embeddings from codebert do not capture similarities between proof states that are relevant for proof retrieval.
we also see that rango proves more theorems than a variant that uses tf idf for proof retrieval.
takeaway using the bm sparse retrieval technique for proof retrieval led to more proven theorems than using codebert dense embeddings and more proven theorems than using another sparse retrieval technique tf idf.table vii comparing rango rango pre and a hybrid approach rango variant coqstoq cutoff rango .
.
rango pre .
.
rango hybrid .
.
table viii searcher variants searcher theorems proven rollout .
best first search beam .
best first search temp .
e.rq4 rango with na ve retrieval variant rango uses a proof retriever and a lemma retriever to gather relevant context for a fine tuned llm to use when generating the next tactic in a proof.
a na ve form of retrieving proofs and lemmas could use the lines directly preceding the theorem being proven as context to the llm.
we call this retrieval technique prefix retrieval .
in this section we explore rangopre a variant of rango whose only retrieval mechanism is prefix retrieval.
table vii shows rango pre s performance on the coqstoq benchmark and on our two post cutoff projects.
note that while rango proves more theorems than rango pre the margin is small.
we know that rango pre cannot retrieve context outside of the current file.
however we observed that it still performed well compared to rango which can retrieve proofs and lemmas throughout a project.
this led us to the following hypothesis when the required context is in close proximity to the current theorem rango pre is preferable since it presents this context to the llm as it was originally written.
however when the required context is not in close proximity to the current theorem rango is preferable since it is able to retrieve proofs and lemmas across the project.
following this hypothesis we created rango hybrid to capitalize on advantages from both rango and rango pre.
rango hybrid simply alternates between rollouts using rango and rangopre.
we can see that rango hybrid leads to a increase in the number of theorems proven by rango and a increase in the number of theorems proven by rango pre.
takeaway rango proves more theorems than rangopre.
rango and rango pre can be combined into a hybrid search procedure that proves more theorems than rango and more theorems than rango pre.
f .rq5 searcher variants we also explore proof search alternatives in rango s searcher.
recall from section iii d that rango uses rollout search to search for a complete proof using its tactic generator.
one weakness of the rollout search is that it does not use previous proof attempts to inform subsequent proof attempts.
in this section we compare rollout search to a best first search which length of human written proof tactics of theorems proven of theorems proven by length rango tactician proverbotfig.
.
percentage of theorems proven by rango tactician and proverbot by the length of the human written proof.
is standard in llm proof search implementations .
in our best first search we maintain a set of candidate proofs.
in each search step we select the candidate with the highest score given by rango s language model.
then we use the tactic generator to generate bdistinct possible next tactics.
each tactic corresponds to a new candidate proof.
we continue the search in this way until we either find a complete proof or the search times out.
note that this search algorithm guarantees that each explored proof is distinct.
finally we do not include invalid proofs or redundant proofs as candidates.
we compare the searcher used in rango based on rollout search to two best first search configurations.
in one configuration the searcher samples tactics at each search step using beam decoding.
in the other configuration the searcher samples tactics using temperature sampling.
in each configuration the searcher samples b tactics at each search step.
note that temperature sampling does not guarantee that the sampled tactics will be distinct.
if the sample tactics are not distinct we remove the duplicates.
we compare rango s rollout search with these two bestfirst search configurations on our ablation set.
we show the results of this comparison in table viii.
we can see from table viii that rango proves more theorems than the configuration using beam decoding and more theorems than the configuration using temperature sampling.
takeaway rollout search is a simple yet effective technique for synthesizing proofs.
when used in rango it synthesizes more theorems than best first search.
g.rq6 understanding rango s proofs in this section we investigate which kinds of theorems rango can prove and we compare the proofs generated by rango to the proofs generated by other proof synthesis tools.
of dependencies01020304050 of theorems proven of theorems proven by of dependencies rango tactician proverbotfig.
.
percentage of theorems proven by rango tactician and proverbot by the number of dependencies of the current file to other files in the project.
kinds of theorems rango can prove the strongest indicator that we have found for whether or not rango can prove a theorem is the length of its corresponding humanwritten proof.
we show the success rate of rango tactician and proverbot by human written proof length in figure .
for all proof synthesis tools figure shows a sharp decrease in the percentage of theorems proven as the length of human written proofs increases.
a weaker indicator for whether or not rango can prove a theorem is the number of dependencies of the file containing the theorem.
we show the success rates for rango tactician and proverbot in fig for files with varying numbers of dependencies where a dependency is a coq file that is imported either directly or transitively.
we notice that the success rates for all three proof synthesis tools drop for files that have a hundred or more dependencies.
despite rango s decreased success rate on files with many dependencies it is still able to find more proofs than other tools.
we speculate that rango s retrieval mechanisms allow it to remain competitive in files with many dependencies.
for example consider the following theorem from the file values.v in the compcert proof development which has 300dependencies.
theorem swap cmpu bool forall valid ptr c x y cmpu bool valid ptr swap comparison c x y cmpu bool valid ptr c y x. rango finds the following proof for this theorem using the lemma int.swap cmpu which is defined in a different file and is not used anywhere in values.v prior to this theorem.
proof.
destruct x destruct y simpl auto.
rewrite int.swap cmpu.
auto.
qed.
in this case rango s lemma retriever identified int.swap cmpu as a relevant lemma for this proof and its proof retriever found proofs that inspired this proof s structure.
9table ix proof length and editdistance between machine generated and human written proofs systemproof length edit distance in tactics to human proof mean median mean median rango .
.
tactician .
.
proverbot .
.
human .
takeaway .
like other proof synthesis tools rango s success rate has a strong relationship with the length of the human written proof.
we also found that the performance of rango and other proof synthesis tools decreased for files with many dependencies.
qualities of proofs generated by rango to understand the qualities of proofs generated by rango we measure two attributes proof length and edit distance to the human written proof.
we measure these attributes for rango tactician and proverbot.
to calculate proof length we first collected the 252theorems for which all three proof synthesis tools found proofs.
then we calculated the number of tactics in each proof.
we report the mean and median of these proof lengths in table ix.
we also report the corresponding statistics for human written proofs.
human written proofs are shorter on average than proofs generated by all proof synthesis tools.
proofs generated by rango and tactician are of similar length and are shorter on average than proofs generated by proverbot.
we use string edit distance to the human written proof as a measure of how human like the proofs generated by rango are.
for each proof of the theorems where rango tactician and proverbot all found proofs we computed the string edit distance between the proofs found by the proof synthesis tools and their corresponding human written proofs.
we report these edit distances in table ix.
on average rango produces proofs that are edit operations closer to humanwritten proofs than tactician and edit operations closer to human written proofs than proverbot.
a prior study on proof engineers found that they are constantly making repetitive repairs across their proofs due to changes to specifications or dependencies .
it is likely that automatically generated proofs that are in a similar style to the proof engineer s handwritten proofs would be easier for them to repair and maintain though future work should explore this.
takeaway .
on average the proofs synthesized by rango have similar or shorter lengths and smaller edit distances to human written proofs than the proofs generated by other proof synthesis tools.h.
threats to validity a threat to internal validity is that while the pretraining data for llms often consist of data from public repositories such as github it is not publicly known what is in the pretraining data for the llm we fine tune for rango deepseek coder .3b.
since coqstoq s benchmark was taken from github it is possible that it intersects with the llm s pretraining data.
most evaluations involving llms suffer from this test set contamination problem.
we mitigate this issue by evaluating on two projects coq bb5 and pnvrocqlib that were created after the pretraining cutoff for deepseek coder .3b.
another threat to internal validity is that in our comparison of rango to other tools there are some differences in the coq versions and machines used cpu vs gpu .
the evaluations of rango tactician and proverbot all use coq .
and are all run on coqstoq s benchmark.
however graph2tac only runs in coq .
.
we evaluated rango and graph2tac on gpus while tactician and proverbot were run on cpus since they are not intended to use gpus.
a threat to external validity is that while the rango approach could be implemented for other proof assistants such as isabelle and lean it is not known whether our results generalize across proof assistants.
this is an interesting and important direction to be explored in future work.
vi.
r elated work formal verification aims to improve software quality a problem that takes up of the total software development budgets .
other methods of improving software quality include debugging and testing but only formal verification can guarantee code correctness.
automated techniques can similarly improve program quality and can also help developers debug manually but still do not guarantee correctness and in fact often introduce new bugs .
recent work in automating theorem proving in proof assistants such as coq lean isabelle and metamath has focused on machine learning based approaches.
typically with a machine learning approach neural theorem prover uses a model to predict the next tactic to apply which guides a search through the space of possible proofs.
early work explored the use of lstm rnn and gnn based models .
recent work has focused on the use of llms in neural theorem proving either fine tuning models or prompting pretrained ones .
large foundation models have demonstrated incredible capabilities on a wide range of tasks .
to adapt to knowledge intensive tasks and new domains researchers have explored the use of retrieval augmented generation rag to boost performance including sparse and dense retrieval techniques.
recent work has explored retrieval augmentation for theorem proving where they train models to retrieve premises such as lemmas and definitions that are relevant to the current proof goal and then condition the next tactic generation on 10those premises .
leandojo trains a model to select which premises should be included as input to its llm tactic generation model.
magnushammer for isabelle takes this approach one step further and additionally trains a reranker model to prioritize which premises are its llm tactic prediction model s input though this extra step is costly.
prior work explored the use of tf idf for retrieving portions of premises with the aim of training a reinforcement learning approach to theorem proving without access to human written proofs which our approach uses.
most similar to our work are graph2tac and tactician which explore online representation learning for coq.
graph2tac uses gnns to incorporate information from new definitions and theorems.
tactician uses online k nn to select tactics from other in project proofs to apply in the current proof.
rango goes beyond these approaches by being able to retrieve both new lemmas and proofs to serve as input to an llm tactic prediction model.
baldur uses in project information using the lines preceding a theorem as context to its whole proof generation llm.
section v e showed that rango can be instantiated with this retrieval mechanism and that a hybrid search procedure between rango and rango pre leads to the best results on the coqstoq benchmark.
lego prover builds a skill library of lemmas and theorems while proving so that it may retrieve new skills learned instead of relying on a fixed library.
neural theorem provers have also been shown to make use of other sources of information.
deepseek prover learns from synthetic data.
trialmaster learns from trial and error paths.
baldur learns from proof assistant error messages.
passport explores the use of rich identifier information.
qedcartographer uses reinforcement learning to estimate progress toward a complete proof to improve search during proof synthesis.
autoformalization techniques are guided by informal proofs in their construction of formal proofs.
tactictoe employs an a search.
evariste uses a monte carlo tree search to outperform a best first search approach in lean.
tacticzero learns proof search strategies not just tactics through deep reinforcement learning for hol4.
hammers such as coqhammer and sledgehammer are automation techniques used in proof assistants that also perform premise retrieval.
they employ smt solvers like z3 and perform efficient automated reasoning to iteratively apply the set of available facts.
in languages like f that allow for smt assisted proof oriented programming new work has shown promise in using rag when synthesizing whole programs .
other work uses rag to generate and summarize java and python code .
rag has also been shown to be useful for program repair .
our work has focused on proving properties which is complementary to specifying them e.g.
by generating formal specification from natural language .
formal languages can be extended to be more expressive to capture privacy properties data based properties fairness properties among others.
someof these kinds of properties can be automatically verified probabilistically .
vii.
c ontributions we developed an adaptive retrieval augmented proving approach and tool rango to synthesize proofs for formal software verification.
rango improves on prior retrievalaugmented proving approaches by retrieving proofs in addition to lemmas.
rango employs its retrieval mechanisms at every step in the proof to obtain the most relevant proofs and lemmas for the current proof state.
to train rango we collected coqstoq a new dataset of coq proofs which includes both our training data and a curated benchmark of well maintained projects.
coqstoq mined from open source github projects contains theorems their respective proofs and proof steps.
rango proves .
of theorems on coqstoq s benchmark which is more than tactician a prior state of the art tool.
rango s proof retrieval is important to its success leading to a increase in the number of theorems proven.
overall our research shows that retrieval augmentation using in project proofs in addition to premises is a powerful technique that can increase the proving power of automated proof synthesis tools reducing the costs of formal verification.