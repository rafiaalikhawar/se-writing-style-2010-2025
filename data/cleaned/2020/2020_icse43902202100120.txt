enhancing genetic improvement of software with regression test selection giovani guizzo justyna petke federica sarro and mark harman y department of computer science university college london ucl london united kingdom yfacebook london united kingdom fg.guizzo j.petke f.sarro mark.harmang ucl.ac.uk abstract genetic improvement uses artificial intelligence to automatically improve software with respect to non functional properties ai for se .
in this paper we propose the use of existing software engineering best practice to enhance genetic improvement se for ai .
we conjecture that existing regression test selection rts techniques which have been proven to be efficient and effective can and should be used as a core component of the gi search process for maximising its effectiveness.
to assess our idea we have carried out a thorough empirical study assessing the use of both dynamic and static rts techniques with gi to improve seven real world software programs.
the results of our empirical evaluation show that incorporation of rts within gi significantly speeds up the whole gi process making it up to faster on our benchmark set being still able to produce valid software improvements.
our findings are significant in that they can save hours to days of computational time and can facilitate the uptake of gi in an industrial setting by significantly reducing the time for the developer to receive feedback from such an automated technique.
therefore we recommend the use of rts in future test based automated software improvement work.
finally we hope this successful application of se for ai will encourage other researchers to investigate further applications in this area.
index terms genetic improvement regression test selection search based software engineering genetic programming i. i ntroduction genetic improvement gi is an artificial intelligence technique used to improve a given property of an existing software in an automated way .
the software property can be either functional e.g.
bug fixing or non functional e.g.
runtime memory usage energy consumption provided such a property can be formulated as a fitness function.
the fitness function guides the iterative search process by quantitatively measuring the level of improvement of the software.
at each iteration multiple variants of the software are produced and tested in order to assess whether the transformations preserve the overall software functionality and then their level of improvement is measured.
as one can infer this process of constantly testing different versions of the software is timeconsuming especially when the software is accompanied by a costly test suite.
even for toy programs with relatively small test suites gi executions can take several hours or even days .
one possible way of solving this problem is to select only a subset of test cases to execute instead of using the whole test suite.regression test selection rts has been extensively studied in the software engineering literature with the main purpose of selecting subsets of test cases for newer versions of the software.
rts has been successfully used to following a set of code modifications select only the subset of test cases that can test the changed code.
differently from regression test minimisation and regression test prioritisation that aim at permanently removing redundant useless test cases and ordering test cases for execution respectively rts temporarily selects subsets of test cases for the imminent testing task.
the underlying objective is to reduce the overall cost of software testing by simply executing fewer test cases at each iteration.
we hypothesise that existing rts techniques which have been proven to be efficient and effective can and should be used as a core component of the gi search process for maximising its effectiveness.
prior work showed the effectiveness of rts in various contexts but never for non functional gi.
in this context different unseen challenges can arise when rts is applied because not only it concerns whether the software variants pass all test cases which automated program repair apr is solely concerned with but also whether the non functional properties will be affected.
in other words speeding up the gi process impacts the search itself because the software speed up is one of the fitness functions that guides the search.
therefore a thorough investigation is needed to discover and report the magnitude of such effects.
specifically we present results to show how rts can imbue gi fitness computation with a faster procedure whilst also maintaining the correctness of the generated improved software.
the main objective of this paper is to investigate i how effective are the rts techniques in the context of gi ii what is the efficiency gain provided by such techniques and iii what is the overall trade off between efficacy and efficiency gain in various scenarios.
in order to answer these questions and evaluate the effectiveness of rts in the context of gi we carry out an extensive empirical evaluation with two state of the art rts techniques based on dynamic and static analysis over seven realworld programs.
the main contributions of this work are assessment of the effectiveness of rts in the context of gi with extensive experimentation ieee acm 43rd international conference on software engineering icse .
ieee report of results that can shape how gi is designed and applied in the future integration of state of the art rts techniques into an open source genetic improvement tool.
the results of our empirical evaluation show that incorporation of rts within a gi framework can significantly speed up the whole gi process making it up to faster on our benchmark set with minimal loss to generality to the whole test set.
in fact the combination of both dynamic and static rts with gi led to improved program variants that passed all the tests for the given program.
the results are significant in that they can save hours to days of computational time yet still be able to find valid software improvements.
this should provide a faster uptake of the techniques in an industrial setting by significantly reducing the time for the developer to receive feedback from such an automated technique.
therefore we recommend the use of rts in future test based automated software improvement work.
finally we hope this successful application of se for ai will encourage other researchers to investigate further applications in this area.
ii.
b ackground this section presents the background on the two main topics of this paper rts and gi.
a. regression test selection regression testing is a task performed to assess whether changes to a given software harm any of its pre existing functionalities .
the default strategy is retest all which basically re runs all the available test cases against the modified program.
however the cost of this strategy becomes prohibitive as the software and its test suite grow in size and complexity.
in order to speed up the process and avoid the execution of the whole test suite a set of regression test strategies have been proposed .
the most common ones are test case prioritisation test suite minimisation and test case selection.
test case prioritisation aims at rearranging the test cases execution order to maximise fault detection or to reveal faults earlier.
test suite minimisation focuses on permanently removing obsolete or irrelevant test cases from the test suite.
finally test case selection also known as regression test selection rts techniques select test cases based on current changes between one software version to another.
its main objective is to avoid the execution of test cases that do not exercise the modified code.
note that rts mostly depends on the differences between versions of the software whereas test suite minimisation and test case prioritisation do not necessarily rely on such information.
this work focuses on rts hence we present it in more detail.
according to yoo and harman a subset of test cases t0from the test suite tshould contain all available test cases that can reveal the fault in the modified version p0of the original program p. a test case tis fault revealing in relation topandp0if the result of the execution of tis different in both versions.
in order to check whether tis fault revealing tmust be executed against pandp0.
the underlying and reasonable assumption is that p t halted and produced the correct output.
hence for a new version p0 one should select all test cases that traverse the modified code in p0 or that used to traverse a deleted piece of code in p0 and then compare the results.
if an rts technique selects all modification traversing test cases in relation to pandp0 this technique is called safe.
in this work we use two rts techniques a modificationbased approach dynamic analysis and a firewall approach static analysis .
the modification based approach implementation is based on the ekstazi tool.
ekstazi performs dynamic analysis over a given program in order to find dependency between java files.
it applies hashing functions over the content of the files and when a mismatch between old hashes and new ones occur all test cases that depend on such a file are selected.
on the other hand the firewall approach implementation is based on the starts tool.
starts collects dependency information between classes with static analysis before executing the tests.
this technique then analyses the modifications and selects all test cases with dependencies to entities inside the firewall .
both tools have been evaluated in the literature and have been shown to be relatively inexpensive and safe.
however as shown by chen and zhang.
rts can also be used in other testing contexts.
the authors compared both tools for speeding up mutation testing showing that both are able to select the adequate test cases to test a given mutant.
we believe that rts can also be used in the gi context with significant benefits.
b. genetic improvement and efficiency genetic improvement gi consists of the improvement of existing software through search based algorithms .
search based algorithms try to find an approximately optimum solution for a given problem for which the true optimum solution cannot be found in feasible time .
gi can be seen as part of the search based software engineering sbse field in which search based algorithms are used to solve hard software engineering problems.
during gi optimisation software undergoes transformations in order to improve a set of properties either functional or non functional .
the most common type of functional improvement is apr in which a faulty program is modified until the failing test suite passes.
in non functional gi however the goal is to improve the software s memory usage execution time energy consumption and other non functional properties whilst maintaining the functional properties of the software measured with the use of the program s test suite i.e.
test cases should pass after the program transformation.
either way the gi process is guided by a fitness function that measures the level of functional or non functional improvement.
at each gi iteration usually a new version of the software is generated its fitness computed by executing the test suite against it and then the best versions found are stored for further use during the optimisation process.
this process may 1324go on for hundreds or thousands of iterations each of which imposing the cost of executing the test suite against the candidate solution.
the efficiency of gi becomes a problem when the software is accompanied by costly test suites which has been pointed out in apr work .
gi tools already implement some efficiency improvement mechanisms.
for example gin an all purpose gi tool for java programs performs in memory compilation which removes the overhead of writing transformed classes to disk before compiling.
gin also applies a profiling phase before starting the optimisation in order to identify target classes and methods thus avoiding the transformation of uncovered code.
however the execution can still take several hours even for relatively small programs .
we hypothesise that rts can provide a significant efficiency improvement for gi.
as far as we are aware there is only one related work in the literature.
mehne et al.
used an ad hoc rts called test case pruning and a localisation technique with genprog an apr tool for c programs.
their technique only applies patches in specific places selects test cases that cover the patched functions and then executes only these test cases when the patch needs to be validated.
the results show that test case pruning provides a speed up of .
with no additional overhead whilst mostly maintaining the correctness of the patches.
differently from the work of mehne et al.
we propose a more in depth evaluation of the impact of rts on multiple gi properties such as safety efficiency improvement capability and the trade off between these properties.
furthermore we investigate rts in the context of non functional improvement as opposed to apr though the techniques can also be applied in the apr context.
we chose to target runtime improvement as fitness evaluation is even more costly than in the case of apr as it requires multiple runs of each of the software variants to get reliable fitness measures.
therefore efficiency of improvements of the whole gi process would be most beneficial.
the next section presents the research questions and the experimental set up used to answer them.
iii.
r esearch questions in this work we aim to answer the following research questions rqs rq1.
effectiveness how effective is regression test selection in the context of genetic improvement of software?
rq2.
efficiency what is the efficiency gain when using regression test selection with genetic improvement?
rq3.
trade off what is the trade off between efficiency and efficacy of the genetic improvement process with various regression test selection strategies in different application scenarios?
in the following subsections we discuss in detail the motivation for each of the rqs and the measures we defined to gather the answers.
in section iv we describe the techniques tools and program subjects we used in our empirical study.a.
rq1 effectiveness how effective is regression test selection in the context of genetic improvement of software?
this question is asked to evaluate whether rts harms the general functionality of gi.
we define herein effectiveness as a combination of functional validity and improvement levels of the software produced by the gi optimisation process.
specifically we are concerned that rts techniques may discard important test cases and consequently the improved software resulting from the gi optimisation may fail when tested against the whole test suite.
moreover depending on the selected test cases the non functional improvement capability of gi can be affected.
if this is the case then the use of rts with gi may impose serious disadvantages that can affect the overall results of gi rendering its application infeasible in practice.
we define the relative safety rs measure as follows rs si p jptsi pj jtj wherejtjis the number of test cases in the test suite t of program p andjptsi pjis the number of passing test cases in twhen executed against the best improved version ofpobtained by the strategy sin the i th independent run.
effectively this measure computes the percentage of test cases in the whole test suite tthat pass when executed against the improved software version.
the greater the rs the safer the rts technique.
we further analyse the results of the experiments in order to investigate whether the rts techniques have any impact on the final outcome of gi in terms of improvement.
for this end we define the relative improvement change ric measure as follows ric si p improvement si p originalimprovement p improvement si p is the level of improvement fitness value of a valid version of the improved program pobtained by the strategy siin the i th independent run and originalimprovement p is the average level of improvement for the program pwhen using gi without rts.
in summary ric computes the magnitude of the improvement obtained by a given strategy when compared to the results of gi with no rts strategy.
thus if ric then it means that the respective rts strategy improves the capability of gi to improve software otherwise there is a negative impact.
the results of rs andric are compared using the kruskal wallis statistical test and vargha delaney a12 effect size .
the former is used to assess if the difference between the techniques is statistically significant across the independent runs whereas the latter measures the magnitude of the difference.
both tests are non parametric thus they do not assume normal distribution of the data.
b. rq2 efficiency what is the efficiency gain when using regression test selection with genetic improvement?
this question focuses 1325on the main benefit of using rts with gi efficiency gain.
we want to unveil what is the magnitude of the savings in terms of gi execution time during the optimisation process.1whilst our implementation of gi works on improving the execution time of a program the rts techniques aim at improving the execution time of gi itself.
the overhead of rts techniques comes mainly from the data collection on test cases and class dependencies during such a phase and from the filtering of test cases for subsequent use section ii a .
as one can infer these tasks can become quite costly when a program is accompanied by thousands of methods and test cases.
certainly it is undesirable to use an rts technique that introduces more overhead than the efficiency gain it provides.
therefore the cost of the strategies is also included in the efficiency evaluation.
we define the relative cost rc of a strategy as follows rc si p cost si p originalcost p where cost si p is the sum of overhead time and optimisation time of the strategy sat the i th independent run for program p and originalcost p is the average cost of the default implementation of gi without any rts for program p. the lower the rc the better.
if the result of rc is greater or equal than then we can state that the rts technique does not reduce the overall cost of gi in that specific context.
on the other hand if the result is lower than then we can quantify how much execution time can be saved by the strategy and compare to others e.g.
a rc of 4means that the strategy saved in execution time.
similarly to rq1 we apply the kruskal wallis and varghadelaney a12tests over rc to identify statistical differences between the different test case selection strategies.
c. rq3 trade off what is the trade off between efficiency and efficacy of the genetic improvement process with various regression test selection strategies in different application scenarios?
finally rq3 takes into account the two measured properties and weighs them on a multi objective space to identify if the trade off is positive in different scenarios.
for example we want to identify whether the strategies provide greater cost savings than safety loss.
in order to answer this question we first weigh the relative cost of each strategy versus its safety.
if the strategies yield rs andric i.e.
the improved programs do not fail when tested with the whole test suite and do not harm the improvement capabilities of gi then the comparison is straightforward the cheapest strategy provides the best tradeoff between the measures.
however in case of obtaining results that are conflicting i.e.
failing test cases or negative changes in improvement we have to perform a more careful investigation on the real trade off.
1not to be confused with the savings in execution cost of the improved version of the program.with that in mind we define a few gi application use cases and evaluate the trade offs of each rts strategy in such scenarios.
the first use case is when the engineer wants to find the perfect improvement i.e.
they let the gi optimisation process execute until the end and then select the best improved software.
the second use case takes place when the engineer needs a fast improvement regardless of how good this improvement is.
in other words the engineer stops the optimisation process after the first positive improvement found by gi in which the software does not fail.
the last scenario concerns diversity.
in this case the engineer wants to find a plethora of improved software versions and then choose one or many from the set of non failing ones.
in all of the posed use cases we evaluate the efficiency of each strategy against a different property of interest.
for the perfect improvement use case herein abbreviated aspimprov the property is the level of improvement of the best and valid found improved version.
if a strategy is both faster to execute and provides better improvement then it is naturally preferred for this scenario.
in the fast improvement use case fimprov the property of interest is the validity of the first improved version found.
the improved version must pass all test cases in the test suite not only the ones selected by the rts technique otherwise the engineer stopped the optimisation and was left with no valid software.
the level of improvement for fimprov is not important as long as it is a positive one.
finally in the diverse improvement use case dimprov the engineer will choose an improved software of their liking thus the property of interest is the number of valid and positive improvement versions.
the more options the engineer has the better suited the rts strategy is for this use case.
the underlying question posed here is how fast the rts techniques can successfully fulfil each of these use cases?
this question is answered in a qualitative manner using the concept of pareto optimality .
iv.
e xperimental design in this section we describe in detail the techniques the program subjects and the tools we use in our empirical study.
in order to allow reproducibility we provide a replication package at a. techniques in order to answer our research questions we use two stateof the art rts techniques based on the ekstazi and starts tools section ii a in combination with gin .
namely we compare the following strategies in our experiment gi gi with no rts gi random randomly selects a subset of test cases without guidance gi ekstazi gi using ekstazi as a dynamic analysis rts technique gi starts gi using starts as a static analysis rts technique.
1326we did not use the default test case selection mechanism implemented in gin since it showed to be infeasible.
for instance whilst ekstazi and starts both took less than minutes to execute on commons codec gin s selection took hours.
the gi random strategy is used as a matter of sanity check.
we compare these implementations using seven subject programs over independent runs more details in section iv c .
multiple independent runs are needed to cater for the stochastic nature of search based algorithms .
the result of each independent run best improved version p0of the program p is collected and then evaluated in terms of number of passing test cases.
conveniently gin applies a profiling mechanism before the actual optimisation process to gather information about hot spots in the code which are later focused on by the gi optimisation.
the output of this preprocessing is a csv file containing which methods and how many times they were executed along with the set of test cases to test each method during the optimisation process.
if no rts technique is selected then the whole test suite is assigned to test all methods equally.
on the other hand if an rts technique is selected then it collects dependency data and assigns the test cases to each hot spot based on its own selection mechanism.
in order to answer questions about efficiency of the gi process with and without rts we sum the profiling overhead and the execution time of the gi process.
because all runs share the same stopping condition as a constant number of fitness evaluations configuration parameters are presented in section iv c we can determine which strategy can finish the optimisation process the fastest and how much time can be saved in relation to the default gi implementation without rts whilst also considering the overhead incurred by each technique.
b. experimental procedure for each program under improvement each of the independent runs is preceded by a profiling task.
hence first we perform the profiling task without any rts each of which generating a profiling csv file containing the hot spots and all test cases are assigned to all hot spots.
the execution time of this phase original overhead is then stored and serves as a baseline for further comparisons.
then we compute the overhead of the other strategies over the independent runs.
after performing the experiments without rts we collect and compute the average execution time.
the execution time of a single run is simply the execution time taken to complete the optimisation process.
then we compute the execution time of the other strategies over the independent runs.
finally we sum the execution time of both the profiling task and the optimisation process for each strategy program and independent run.
this is the total computational cost of gi with the respective strategy which can tell us whether the total cost of such a strategy is lower than the total cost of the default gi implementation.table i subject programs .lloc number of logical lines of code executable lines t number of test cases in the program s test suite t. lloc number of logical lines of test code cov statement and branch coverage percentages obtained by the test suite testtime execution time of the test suite mm ss .
program lloc t t. lloc cov test time codec .
compress .
csv .
fileupload .
imaging .
text .
validator .
at the end for each program strategy and independent run we obtain a a testing cost and a set of improved software variants.
then the software variants are tested against the whole test suites in order to check for validity.
c. subject programs we focus on the non functional gi optimisation of execution time i.e.
the improvement goal of the gi implementation is to reduce the overall execution time of the program under improvement.2the seven subject programs are presented in table i. these programs are part of the apache commons project3 a set of well known and widely used libraries.
we selected such programs because they are different in size build with no errors comply with all the requirements needed to run with gin have relatively large and passing test suites and have different testing times.
furthermore differently from related work the use of non trivial programs provides another investigation angle on the cost and results of non functional gi.
in other words with such extensive experimentation we can evaluate the rts tools in a wider range of scenarios.
d. genetic improvement framework we chose gin for our experiments.
it has been designed specifically for the improvement of java programs.
gin provides several optimisations for running gi on java software including in memory compilation which removes the overhead of writing transformed classes to disk before compiling.
it also applies a profiling phase that helps identify which parts of code are covered by a given test suite and thus preventing uncovered parts from being modified.
the search algorithm used in the experiments is genetic programming gp which has recently been updated in gin.
it uses tournament selection uniform crossover and a mutation strategy that picks between a delete replace copy and swap mutation operators uniformly at random before applying the selected operator to program statements at the abstract syntax tree level.
the parameters were set based on previous work we found that uses this algorithm .
we 2not to be confused with the execution time of gi itself.
1327table ii algorithm parameters .
parameter value population size generations test repetitions independent runs tournament percentage mutation probability table iii percentage of selected test cases .median across all independent runs .
program ekstazi starts random codec .
.
.
compress .
.
.
csv .
.
.
fileupload .
.
.
imaging .
.
.
text .
.
.
validator .
.
.
median .
.
.
use the default runtime fitness evaluation as implemented in gin and set the number of test evaluations for each program to for more reliable runtime measurements.
table ii presents the parameters used by the algorithm.
v. r esults this section presents the results of the experiments and provides answers to the rqs formulated in the previous section.
table iii presents the number of test cases selected by each strategy for each program.
this selection was performed in the profiling phase and the time taken to do such a task is computed as overhead.
a. answer to rq1 effectiveness the first part of the effectiveness analysis concerns the relative safety rs equation of the best patches generated by the gi algorithm in each independent run when re executed against all test cases as opposed to tested only by the test cases selected by the rts techniques.
our first finding is that almost all resulting patches are valid.
the only exceptions are gin random results for commons csv andcommons text and gin starts for commons text .
gin random generated five invalid patches in five independent runs for which test cases failed in total i.e.
the resulting patches were deemed invalid by the whole test suite.
gin starts only generated one invalid patch out of for which two test cases failed.
hence the rs of gin random and gin starts is always higher than and for gin ekstazi rsis always .
the statistical tests showed no difference between the results thus we can state that the rts techniques can safely be used with gi.
the second part of this rq concerns the relative improvement change ric equation of gi when using the rtstable iv rq1.
m edian relative improvement change ric of strategies .greater values are better .
bestric values or values statistically equivalent to the best ones are highlighted in bold p values .
program gi ekstazi starts random p value codec .
.
.
.10e compress .
.
.
.07e csv .
.
.
.10e fileupload .
.
.
.50e imaging .
.
.
.
text .
.
.
.70e validator .
.
.
.90e median .
.
.
table v rq1.
e ffect sizes for the relative improvement change ric .
effect sizes greater than 5mean positive improvement for the left strategy .
differences n negligible s small m medium and l large .
large effect sizes are highlighted in bold .
program gi ekstazi gi starts ekstazi starts codec .
l .
l .
s compress .
l .
l .
m csv .
l .
l .
n fileupload .
l .
s .
s imaging .
s .
n .
n text .
l .
s .
l validator .
l .
l .
m strategies.
unlike rs we observed significant changes in the results.
table iv presents the median ric of each strategy alongside the kruskal wallis p value results whereas table v presents the effect size results for the ric comparisons.
for all programs gi ekstazi presented significant positive or statistically equivalent ric to the best one i.e.
by using ekstazi with gi the quality of the resulting patches was at least equal or better in terms of obtained improvement.
similarly starts also presented favourable results for six out of seven programs.
for six out of seven the differences between gi and gi ekstazi or gi starts are statistically large.
one possible explanation for this positive impact on improvement is that during the optimisation process with rts considerably fewer tests are executed.
in such a case the execution time differences between an improved version of the software and the original one are more significant to the search process.
in other words even with a small improvement of a few hundred milliseconds the improvement is deemed more important by the gi algorithm because the cost of testing the program is also relatively small.
without rts the same execution time improvement would be diluted by thousands of test cases that do not test the changed code.
hence the gi algorithm puts more emphasis on such small improvements and better explores the search space around those modifications.
answer to rq1 state of th art rts strategies are feasible 1328table vi rq2.
m edian relative cost rc of strategies .lower values are better .
bestrc values or values statistically equivalent to the best ones are highlighted in bold p values .
program gi ekstazi starts random p value codec .
.
.
.
.11e compress .
.
.
.
.12e csv .
.
.
.
.97e fileupload .
.
.
.
.81e imaging .
.
.
.
.48e text .
.
.
.
.60e validator .
.
.
.
.50e median .
.
.
.
table vii rq2.
e ffect sizes for the relative cost rc .
effect sizes greater than 5mean greater cost for the left strategy .
differences n negligible s small m medium and l large .
large effect sizes are highlighted in bold .
program gi ekstazi gi starts ekstazi starts codec .
l .
l .
n compress .
l .
l .
m csv .
n .
m .
m fileupload .
s .
s .
l imaging .
l .
n .
l text .
l .
l .
s validator .
s .
l .
m when used with gi.
in our experiments they showed almost safety with only one improved software version failing when tested against all test cases.
moreover such techniques presented positive changes in the improvements obtained by the gi algorithm.
b. answer to rq2 efficiency this section presents the results for the efficiency rq.
figure depicts the relative cost rc equation of the strategies in relation to gi without rts e.g.
a rc of means that using gi with a given rts strategy costs less in terms of execution time when compared to the cost of using gi with no rts.
similarly table vi presents the median rc for each strategy and the respective results of the kruskal wallis p value test in the last column.
finally table vii presents the vargha delaney a12effect size results for the pairwise comparisons.
it is worth restating that the cost includes both overhead and speed up of the optimisation process.
for six out of seven programs using either ekstazi or starts as rts strategy showed a significant improvement in execution time p value .
overall gi ekstazi and gi starts can save up to in relative execution time on average .
moreover for five out of seven programs this difference is considered statistically large according to the effect size analysis.
the results do not always show a relationship between the number of test cases table iii and the relative cost i.e.
the fewer the test cases the lower the cost .
this happens becausesome test cases might be more expensive than others to run.
for example ekstazi selects considerably fewer test cases for fileupload imaging and validator yet the relative cost to run them is greater than the cost paid by other strategies which select more but cheaper test cases for these projects.
we investigated the projects more closely and we found that projects characteristics play a role.
the cost reduction does not seem high when there is a common dependency in the source code e.g.
csv or few methods are tested by multiple test cases e.g.
text .
in such cases the rts strategies end up selecting almost all test cases because they test the improved and highly dependent method or the improved method is thoroughly tested with expensive test cases.
on the other hand the cost reduction is high when multiple computationally expensive test cases test different parts of the code e.g.
compress .
in other words the test cases are more isolated i.e.
test only the unit and the targeted method only requires a few inexpensive tests.
figure presents the cumulative cost of the profiling and optimisation phases of each strategy over the independent runs.
for programs with expensive test suites e.g.
commonscompress andcommons imaging the rts techniques saved in total from a couple of hours to more than a day of computational time.
it is worth noting that random test case selection during profiling does not add any overhead.
however the selected test cases still incur an execution cost and the random selection sometimes selects fewer test cases sometimes selects almost all test cases hence the differences in results with respect to no test selection.
in our specific case the total amount of time required to run the experiments without rts was over cpu hours whereas with ekstazi and starts this time was reduced to and hours respectively.
in other words using rts saved us approximately hours of execution time on average more than a third of the cost .
shorter execution times will allow gi adoption for larger programs for which the running cost might still be prohibitive and environmentally unfriendly without rts.
considering both patch validity and changes in improvement section v a and the overall efficiency of the strategies gi starts and gi ekstazi are preferred.
gi random fails more often and does not provide much benefit in improvement and cost savings.
henceforth we will not discuss the results of gi random and will focus our attention on the other two rts strategies.
answer to rq2 using rts in combination with gi can significantly reduce the overall relative cost of the optimisation process up to depending on the program .
the reduction is statistically significant in of the cases and large in of the cases.
furthermore when considering the cumulative total cost of experimentation using rts can save more than a third of the execution time.
c. answer to rq3 trade off this section presents the results for the three considered use case scenarios of gi perfect improvement pimprov fast 1329fig.
.
rq2.
relative cost rc of strategies.
lower values are better.
the dashed line represents the median cost of gi without rts.
fig.
.
rq2.
cumulative execution times results are for four gi strategies i without rts ii and iii with rts and iv gi with random test selection.
table viii rq3.
pimprov use case .median improvement found in seconds .
greater values are better .
program gi ekstazi starts codec .
.
.
compress .
.
.
csv .
.
.
fileupload .
.
.
imaging .
.
.
text .
.
.
validator .
.
.
median .
.
.
improvement fimprov and diverse improvement dimprov .
forpimprov the best strategy in this scenario is the one that is able to find the best valid improvement.
table viii shows the median best improvement in seconds found for each program.
gi ekstazi obtained the best improved software in most of the cases four out of seven whilst also obtaining the highest median improvement across projects.
since the rts strategies are safe when used in combination with gi with the exception of gi starts for commonscsvas shown in section v a then the comparison for the fimprov use case is straightforward the strategy that can find a positive improvement the quickest is preferred.
consideringtable ix rq3.
fimprov use case .median time in seconds each strategy took to find a positive and valid improvement .
lower values are better .
program gi ekstazi starts codec .
.
.
compress .
.
.
csv .
.
.
fileupload .
.
.
imaging .
.
.
text .
.
.
validator .
.
.
median .
.
.
this scenario table ix shows how long each strategy took in seconds to find the first positive and valid improvement.
on average gi starts finds an improvement in the first seconds of the search process and for three out of seven programs it is also the quickest strategy.
finally for the last use case dimprov we are concerned with the diversity of improved software found by the strategies.
table x presents the median number of different valid and positive improvements found by each strategy.
for five out of seven programs gi ekstazi finds a wider variety of improvements.
1330table x rq3.
dimprov use case .median number of positive and valid improvements found .
greater values are better .
program gi ekstazi starts codec compress .
.
.
csv fileupload imaging .
text .
.
validator median .
.
answer to rq3 if the engineer is concerned with either finding the perfect improvement or a wider variety of positive and valid improved software then using gi ekstazi is the best option.
however if the main objective is to find a positive and valid improvement as fast as possible then gi starts is recommended.
in most of the cases considered i.e.
out of comparisons using gi rts provides better results than traditional gi without rts.
therefore we recommend the use of rts in future gi work.
vi.
r elated work the work most related to ours is the one that applies regression testing selection techniques to a genetic improvement process.
to the best of our knowledge only the work of mehne et al.
has investigated any kind of rts in this context and only for apr.
the authors defined their own rts technique and evaluated the results in terms of speed up.
their results show a speed up of up to .
the original cost of automated program repair of c programs using genprog .
other works use other kinds of regression techniques such as test case prioritisation and sampling.
venugopal et al.
proposed and evaluated a history based test case prioritisation for apr.
the approach consisted in prioritising test cases that are most likely to fail whilst also sampling test cases in order to make the software variant to fail faster.
the authors achieved up to .
in execution time savings during patch validation.
similarly qi et al.
proposed trpautorepair an on line prioritisation technique for apr.
the idea behind the approach is to avoid the overhead of pre gathering information about test cases executions and use information already obtained during the execution of candidate patches.
trpautorepair was able to perform at least as well as genprog for out of programs while significantly improving the repair efficiency as measured in the number of test case executions.
fast et al.
incorporated random sampling of test cases in the fitness function computation for apr.
their approach first samples a subset of passing test cases and all failing test cases.
the software variant is only tested against the remaining test cases if all test cases in the subset pass.
the authors also compared their approach to a regression technique for test suite minimisation based on a genetic algorithm ga .
the results showed that their approach is able to reduce the computational effort needed to test patches in .apr is concerned exclusively with one functional property i.e.
bug fixing while gi concerns with any functional e.g.
addition of a new feature bug fixing and non functional improvement e.g.
runtime energy consumption .
only one previous work uses rts for gi functional improvement by applying a single ad hoc rts dynamic technique.
other works investigate other types of regression techniques such as test suite minimisation and prioritisation which are inherently different to rts.
our work differentiates from the ones presented in this section since we focus solely on rts and we consider nonfunctional improvement as opposed to apr .
state of the art rts techniques have not been extensively evaluated in the context of gi specially in regards to non functional improvement.
we are the first to investigate the impact of any test selection strategy in the context of non functional automated software improvement using gi and with both dynamic and static rts techniques.
furthermore all related work focuses on program repair and uses the same tool namely genprog.
we note that the gp implementation in gin also follows the genprog search strategy.
however unlike previous work our focus is on java software.
in this work through extensive experimentation with realworld java programs we evaluate the benefits of rts along multiple angles efficiency effectiveness and the underlying trade off between those properties i.e.
we evaluate the safety efficiency and improvement impact of rts.
especially the last angle to the best of our knowledge has not been considered before.
vii.
t hreats to validity a threats to external validity as it happens to most software engineering papers with empirical evaluations the set of programs used in the experiments might not be representative of the whole population.
in order to mitigate this threat we have selected well know non trivial software projects of different sizes test times and coverages.
another threat regards to the fact that we only compared the results of two rts techniques one based on dynamic and one based on static analysis.
although there are other techniques in the literature it would be infeasible to compare all of them thus we decided to compare only state of the art .
b threats to internal validity to reduce internal threats we used the same configuration for all experiments.
this configuration was used in previous work thus allowing for further experimental comparisons.
moreover we executed all experiments on the same machine with the same resources.
with these precautions we intended to prevent other factors to impact the results of our experiments.
c threats to construct validity the execution times of optimisation algorithms such as gi may fluctuate due to their stochastic nature.
in order to cater for these fluctuations we performed multiple independent runs and analysed the results with statistical significance tests and effect size analysis as suggested by arcuri and briand .
to further mitigate 1331noise in the execution time measurements we repeated each test case execution times and considered the median as a more accurate data source.
finally we took extra care when selecting statistical tests to avoid making assumptions that would jeopardise the validity of our results e.g.
we used non parametrised tests because we could not assume normal distribution of the data .
viii.
c onclusions genetic improvement gi an artificial intelligence technique has been successfully used to improve various software properties ranging from reduction of software s runtime optimisation of energy and memory consumption through to bug fixing and addition of new software features .
however it has yet to see wider uptake.
a major obstacle is its high demand on runtime of the gi process to find the desired improvements.
the biggest bottleneck for runtime of a gi process comes from the fitness evaluation which requires running the whole test suite for each and every evolved program version in order to ensure that regression bugs are not introduced during the gi process.
regression test selection rts a traditional software engineering approach aims to reduce testing effort by selecting only the most relevant tests for a given task.
however it has not yet been tried in the context of genetic improvement of software.
we investigated the use of two state of the art rts techniques in an open source gi framework and conducted an extensive study on seven large real world software to show that these can indeed speed up the gi process without impacting the validity and improvement gain of the evolved software.
in particular we show that integration of rts does not hinder the validity of the improved patches.
in fact all evolved software but one out of when tested against the test cases selected using either rts approach always passed the whole test suite thus showing safety.
we observed efficiency gains of the whole genetic improvement process of up to .
given that the gi process might run for hours days or even weeks such an efficiency gain is non trivial impacting not only the execution times of scientific experiments but also the carbon footprint of the servers used to run gi in the industry .
therefore we recommend the integration of rts techniques in test based automated improvement software.
we also recommend the static starts rts technique for finding quick improvements while we conjecture the dynamic ekstazi might be best when the improvement gain or software validity is of most concern.
our proposed software engineering approach will thus reduce the feedback time from the automated software improvement system to the developer.
therefore we hope it will contribute to wider and faster uptake of gi techniques.
there are still several questions to be answered that could help speed up the process even further.
other test case selection strategies could be investigated.
moreover it would beuseful to know what characteristics a given test suite should have in order to be effective with the gi processes.
initial work has been done in this direction investigating standard test suite measures yet no strong correlation between test suite metrics and their effectiveness in the improvement process has been found.
if known test case selection for gi could be further improved by applying such metrics by providing further guidance to rts.
this is a direction we would like to investigate in future work.