bilo cpdp bi level programming for automated model discovery in cross project defect prediction ke li natural zilin xiang sharp tao chen kay chen tan sharpcollege of computer science and engineering uestc chengdu china naturaldepartment of computer science university of exeter exeter ex4 4qf uk department of computer science loughborough university loughborough le11 3tu uk department of computer science city university of hong kong tat chee avenue hong kong sar k.li exeter.ac.uk ziling.xiang hotmail.com t.t.chen lboro.ac.uk kaytan cityu.edu.hk abstract cross project defect prediction cpdp which borrows data from similar projects by combining a transfer learner with a classifier haveemergedasapromisingwaytopredictsoftwaredefectswhen the available data about the target project is insufficient.
however developing such a model is challenge because it is difficultto determine the right combination of transfer learner and clas sifier along with their optimal hyper parameter settings.
in this paper weproposeatool dubbed bilo cpdp whichisthefirstof itskindtoformulatetheautomatedcpdpmodeldiscoveryfrom the perspective of bi level programming.
in particular the bi levelprogramming proceeds the optimization with two nested levels in a hierarchical manner.
specifically the upper level optimization routine isdesigned tosearch forthe rightcombination oftransfer learnerandclassifierwhilethenestedlower leveloptimizationroutine aims to optimize the corresponding hyper parameter settings.
to evaluate bilo cpdp we conduct experiments on projects to compare it with a total of existing cpdp techniques along with its single level optimization variant and auto sklearn a state ofthe artautomatedmachinelearningtool.empiricalresultsshow thatbilo cpdp champions better prediction performance than all other21existingcpdptechniqueson70 oftheprojects whilebeing overwhelmingly superior to auto sklearn and its single level optimization variant on all cases.
furthermore the unique bi level formalizationin bilo cpdp alsopermitstoallocatemorebudget to the upper level which significantly boosts the performance.
ccs concepts softwareanditsengineering softwarecreationandmanagement software defect analysis.
k. li z. xiang and t. chen contributed equally to this research.
permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation on the first page.
copyrights for components of this work owned by others than acmmustbehonored.abstractingwithcreditispermitted.tocopyotherwise orrepublish topostonserversortoredistributetolists requirespriorspecificpermissionand ora fee.
request permissions from permissions acm.org.
ase september virtual event australia association for computing machinery.
acm isbn ... .
cross project defect prediction transfer learning classification techniques automatedparameteroptimization configurablesoftware and tool acm reference format keli zilinxiang taochen andkaychentan.
.bilo cpdp bi level programming for automated model discovery in cross project defect prediction.in 35thieee acminternationalconferenceonautomatedsoftware engineering ase september virtual event australia.
acm new york ny usa pages.
introduction softwaredefectsareerrorsincodeanditslogicthatcauseasoftware product to malfunction or to produce incorrect unexpected results.
given that software systems become increasingly ubiquitous in ourmodernsociety softwaredefectsarehighlylikelytoresultin disastrous consequences to businesses and daily lives.
for example the latest annual software fail watch report from tricentis1shows that globally software defects failures affected over .
billion people and caused .
trillion in lost revenue.
one of the key reasons behind the prevalent defects in modern software systems is their increasingly soaring size and complexity.
due to the limited resource for software quality assurance and the intrinsicdependencyamongalargenumberofsoftwaremodules it is expensive if not impossible to rely on human efforts e.g.
code review to thoroughly inspect software defects.
instead itis more pragmatic to predict the defect prone software modulesto which software engineers are suggested to focus their limited software quality assurance resource.
to this end machine learning algorithmshavebeenwidelyusedtoautomatetheprocessofdefect prediction.
as discussed in one of the keys to the success of defect predictionmodelsistheamountofdataavailableformodeltraining.
inpractice however itisunfortunatelynotuncommonthatsuch dataisscarceorevenunavailable.thiscanbeattributedtothesmallsizeofthecompanyand orthetargetedsoftwareprojectisthefirst ofits kind.cross projectdefectprediction cpdp which aims topredictdefectsintheasoftwareprojectbyleveragingexperience e.g.
trainingdataorhyper parametersoftraineddefectprediction models from other existing ones has therefore become extremely appealing .
unfortunately partially due to the difference of the data distribution between the source and the target projects the 35th ieee acm international conference on automated software engineering ase performanceofvanillacpdpisnotaspromisingasitwassupposed tobe .transferlearning whichisabletotransferknowledge across different domains has shown to be able to overcome the aforementioned challenges e.g.
data scarcity and data distribution discrepancy and has gradually become the main driving force for cpdp .generallyspeaking thebasicideaistoequipamachine learning classifier with a transfer learner that enables its ability to learn from other projects in model building.
thereisnofreelunch indefectpredictiongiventhatmachine learning enabled defect prediction models often come with configurableandadaptableparameters prevalentclassifiersare withatleastoneparameter .thepredictionaccuracyon various software projects largely depends on the parameter settings of those defect prediction models .
furthermore it becomesmorecomplicatedincpdpbecause theconfigurable parameters is augmented by the transfer learner widely used cpdp techniques require at least one parameter to setup in thetransfer learner thus lead to an enlarged search space thereexist complex yet unknown interactions among the parametersof the classifier and those of the transfer learner that is to sayparameter optimization over either the classifier or the transferlearner alone may not lead to the overall optimal performance and the optimal selection of the combination of classifier and transferlearnerisasimportantasparameteroptimizationbutisunfortunately ignored in the current literature most if not all cpdp modelsaredesignedwithan ad hoccombinationoftransferlearner andclassifier theperformance ofwhich isreportedto befar from optimal .although thereexistsome priorworks considering the hyper parameter optimization for cpdp models they onlyconsiderthehyper parametersassociatedwiththeclassifier.
asinvestigatedinalatestempiricalstudy thispracticeisfar from truly optimizing the performance of the underlying cpdp modelwhilethesettingsofhyper parametersofthetransferlearner are more decisive.
bearing the above considerations in mind we propose a new tool dubbed bilo cpdp toautomatethemodeldiscoveryforcpdp tasks.itprovidesanunifiedperspectiveforthecombinatorialselection of classifier and transfer learner as well as their hyper parameter optimization within the mathematical framework ofbi level programming where two levels of nested optimizationproblems are formulated the upper level optimization problemis solved subject to the optimality of a lower level optimization problem.specifically theupper leveloptimizationproblemaims to identify the optimal combination of transfer learner and clas sifier from a given portfolio while the lower level optimization problemisdedicatedtosearchingfortheoptimalparametersetting associated with the corresponding transfer learner and classifier.note that a combination of transfer learner and classifier is not considered to be feasible for comparison unless the corresponding parameters have been optimized.
in bilo cpdp the upper level optimizationisformulatedasacombinatorialoptimizationproblemwhich issolved bythe tabusearch whilethelower level optimizationismodeledasanexpensiveoptimizationproblemwith a limited budget to be solved by tree structured parzen estimator tpe a state of the art bayesian optimization algorithm.
to evaluate the the effectiveness of bilo cpdp for automated model discovery in cpdp we conduct experiments to compareit with existing cpdp techniques its single level variant and auto sklearn astate of the artautomatedmachinelearning automl tool over distinct projects.
theresults fully demonstrate the overwhelming superiority of bilo cpdp over the others with statistical significance and a large effect size on all projects.
in summary the key contributions of this paper are as follows to the best of our knowledge bilo cpdp is the first of its kind for automating cpdp from the perspective of bilevelprogramming.giventhat bilo cpdp isnotonlyable to automatically search the optimal combination of transferlearnerandclassifier butalsocansettheirappropriate hyper parameter settings it paves a new avenue for automated model discovery in cpdp.
through extensive experiments with existing cpdp techniques we show that bilo cpdp is the best on out of projects and second to only one existing technique for anotherfive.thisfullydemonstratestheeffectivenessand importance brought by automatically choosing the appro priate transfer learner and classifier associated with their optimal hyper parameter settings for cpdp.
intermsofoptimizationproblemformulation onallprojects we show that the bi level programming formulated in bilocpdpis statistically better than hybridizing both combinatorial selection and parameter optimization as a single level globaloptimizationproblem whichisperhapsamoreconservative solution as used in e.g.
auto sklearn .
interestingly from our experimental results we disclose that choosing the best combination of classifier and transfer learner upperlevel ismoreimportantthanfullyoptimizingtheirparameters lowerlevel .henceforth giventhelimited resource for software quality assurance it is beneficial to allocate more search budget to the upper level optimization.
intherestofthispaper section2givesthebackgroundabout bi level programming.section delineatesthe algorithmic implementation of bilo cpdp step by step.
the experimental setup is introduced in section and the results are analyzed in section .
thereafter section6and7reviewstherelatedworksanddiscusses thethreatstovalidity respectively.finally section8concludesthis paper and threads some lights on future directions.
bi level programming bi levelprogrammingisamathematicalprogramwithinwhichone optimization problem is nested within another in a hierarchical manner .
it is ubiquitous in many real world optimization and public private sector decision making problems where the realized outcome of any solution or decision taken by the upper level authority a.k.a.leader tooptimizetheirobjectivesisaffectedby the response of lower level entities a.k.a.
follower who seek tooptimize their own outcomes.
this is in principle similar to the stackelberg games in which a leader first makes its move and afollowermaximizesthecorrespondinggainbytakingtheleader s move into account.
it is interesting to note that the two levels ofoptimization problems are asymmetric in bi level programming.
that is to say the upper level leader has the entire picture of optimization problemsat both levels whereasthe lower level follower 574usuallytakesthedecisionsfromtheleaderandthenoptimizesits own strategies.
thebi levelprogrammingformulatedin bilo cpdp canbemathematically defined as maximize xu d rn xl rnf xu xl subject to xl argmax fxu xl where xu d rnandxl rndenotetheupper andlower level variables2whilef d rn randfxu rn raretheupperleveland lower levelobjective functions respectively detailscan befoundinsection3 .abi levelprogrammingthatinvolvesnested optimization decision makingtasksatbothlevels.foranygiven combination xu thereexistsa xu xl pairwhere xl isanoptimal ornear optimal responseto xurepresentsafeasiblesolutionto theupper leveloptimizationproblemgiventhatitalsosatisfiesthe constraints therein.
bi level programming for automated cpdp model discovery thecpdpmodelbuildingprocessconsistsoftwointertwinedparts transfer learning that augments data from different domains by selectingrelevantinstancesorassigningappropriateweightstodifferent instances and defect prediction model building based on adapteddata.asreportedinalatestresearch theperformance of a cpdp model largely depend on the combination of transfer learner and classifier along with their hyper parameter settings.
in light of this the bilo cpdp proposed in this work was specifically designed to address such a problem.
through automatically discovering the best combination of transfer learner and classifier as well as their optimal hyper parameter settings bilo cpdp serves as an automatictoolthatprovidesa denovacpdpmodeldiscovery.in thissection wewilldelineatethearchitectureof bilo cpdp and the algorithmic details of its optimization routines at both levels.
.
overview of bilo cpdp the overall architecture of bilo cpdp is illustrated in fig.
which consistsofthreekeyphases i.e.
datapre processing optimization andperformance validation.
data pre processing given a raw dataset with n projects software engineers are asked to specify which one is the target domain that serves as the target domain data while the remaining n projects are then used as the sourcedomaindata.inparticular allsourcedomaindataare used in the model training while a part of the target domain dataisusedasthehold outsetforthetestingpurpose.as thedefaultin bilo cpdp weuse10 ofthetargetdomain datafortestingwhiletheremaining90 isfortraining.thisisbecausesometransferlearnersconsideredinthisworkdoneeddatafromthetargetdomainintraining e.g.
mcws .
forothertransferlearnersthatcanbetrainedindependently to the target domain we use all data for testing.
optimization bilo cpdp models cpdp as a bi level programmingthatnotonlyidentifiesthemostcompetitivecombinationoftransfer leanerandclassifierfor theunderlying 2 d rnmeans that the problem is a discrete combinatorial problem.
bar.c bar.h foo.c foo.h source domain training data bar.c bar.h foo.c foo.h target domaintraining data target domain testing dataraw datasetcalculate testing performance transfer learning algorithmsdefect prediction modelupper level optimiztion .
transfer learner classifierauctabu search data pre processinglow level optimiztion calculate training performance t optimizationperformance validationtpe t figure the overall architecture of bilo cpdp.
cpdp task tackled by the upper level routine but also equips the chosen cpdp model with the appropriate hyperparametersettings carriedoutbythelower levelroutine .
since the resources for software quality assurance are often limited the entire optimization process would inevitably be constrained under a computational budget of running time.
in this regard the unique bi level programming formulated inbilo cpdp can in fact provide a fine grained and flexible allocation of the budget between upper and lower level whoseeffectswillbeinvestigatedaspartoftheexperimental evaluationinsection5.
.thecpdpmodel whichhasthe best combination with its optimal hyper parameter settings intermsofthetrainingaccuracy isreturnedintheend.notethat due to the lack of data samples using training accuracy intheparameteroptimizationoftransferlearnerisnotuncommon and has shown promising results for cpdp .
performance validation aftertheoptimizationphase as an optional module in bilo cpdp the generalization of the builtcpdpmodelcanbevalidatedandtestedbyusingthe hold outsetfromthetargetdomaindata whichisunknownduringtrainingstage.inpractice thiswillbethenewprojectthatonewishestopredictdefectsfor.in bilo cpdp thearea under the receiver operating characteristic roc curve i.e.
auc isappliedastheperformancemetrictomeasure the effectiveness of a model.
formally auc is defined as auc summationtext.
t d summationtext.
t d bracketleftbig pred t pred parenleftbigt parenrightbig bracketrightbig d d wherepred t is the probability that sample tis predicted to be a positive sample and bracketleftbig f t f parenleftbigt parenrightbig bracketrightbig is an indicator function which returns if f t f t otherwise it returns .
d is theset of negative samples and d is the set of positive samples.
apart from the fact that auc has beenwidelyforsoftwaredefectprediction ithastwo distinctive characteristics different from other prevalent metricslikeprecisionandrecall aucdoesnotdependon a particular threshold which is difficult to tweak in order to carry out an unbiased assessment and it is not 575sensitivetoimbalanceddatawhichisnotuncommoninsoftwaredefectprediction .thelargertheaucvalueis the better prediction accuracy the model achieves.
in particular the auc value ranges between and where indicates the worst performance .
corresponds a randomly guessed performance and represents the best performance.
note that auc is also the metric used in optimization phase to evaluate and compare training accuracy.
.
upper level optimization tables 1and respectivelylist the transferlearners and theclassifiers considered in our work which form the portfolios.
note that all transfer learners considered in bilo cpdp have been used in either the defect prediction or cpdp literature while the classifiers comefrom scikit learn3 thestate of the artmachinelearning pythonlibrary.inaddition thecorrespondinghyper parametersas sociatedwiththosetransferlearnersandclassifiersalongwiththeir value ranges are also provided in the corresponding tables.
any combinationofatransferlearnerandaclassifiercomesupwitha cpdpmodel.theultimategoaloftheupper leveloptimizationistosearch for the best combination out of all possible alternatives in this work for the underlying cpdp task.
in particular for each candidatecombinationoftransferlearnerandclassifier theircorresponding hyper parameter settings are optimized via a lower level optimization routine which will be explained in section .
.
attheupper levelin bilo cpdp thesearchofthebestcombinationoftransferlearnerandclassifierissolvedasacombinatorial optimization problem as specified below.
search space fortheupperlevel thesearchspaceconsists ofallthevalidcombinationsoftransferlearnersandclassifierpickedupfromthegivenportfolios i.e.
thoselistedin tables1and2.inpractice suchportfolioscanbeamended and specified by the software engineers based on their preferences requirements.
objective function recall from the equation the objective function for the upper level f xu xl takes a combination from the portfolio xu and the optimized hyperparameterofsuchcombination xl asinputs.itthenoutputsthecorrespondingtrainingaucobtainedbytraining the cpdp model for comparison.
note that xl is initially unknownforagiven xuattheupper levelbeforerunning a lower level optimization routine.
therefore the objective functionatupper leveloptimizationisconstrainedanddetermined by the lower level optimization.
optimization algorithm fortheupper leveloptimization inbilo cpdp weuse tabusearch toserve asthe optimizer whichisalsotheentrypointoftheoptimizationphase.
in particular we use tabu search in this work because our problem is expensive and thus it is unrealistic for an exact search to reach the optimal solution.
metaheuristicsuch as tabu search which does not guarantee optimum but can often produce near optimal result is more practical and acceptable.
runtabusearch upper leveloptimization thattunesthecombinationoftransferlearnerandclassifier.
input portfolio of transfer learners tand classifiers c output optimal cpdp model xu optand its optimal parameter settings xl opt 1randomly initialize a valid combination of transfer learner and classifier xu t c t t andc c are a candidate transfer learner and classifier lscriptt lscripttis the tabu list 3whilethe overall time budget is not exhausted do searchcandidate xu lscriptt 5ifxu nelement lscripttthen lscriptt lscriptt uniontext.
xu 7return xu opt xl opt argmaxxu lscriptt f xu xl algorithm searchcandidate xu lscriptt searchthenext combination candidate from the neighborhood of xu input candidate cpdp model xuand newest tabu list lscriptt output the best cpdp model within xu s neighbor and its optimal parameter settings xopt the performance of this cpdp model fopt i.e.
the value of f xu xl 1 get the neighbors of xu 2 xu get the configuration space of the transfer learner and the classifier specified by xu runtpe xu xu 4xopt xu xl prime fopt fxu xl prime 5foreach xc xc nelement lscripttdo 6 xc get the configuration space of the transfer learner and the classifier specified by xc runtpe xc xc 8iffxc xl prime foptthen xopt xc xl prime fopt fxc xl prime 10return xopt fopt unlike other metaheuristics tabu search employs local searchtospeed up its convergence .
tabu search permits a better chance to escape from localoptima than other local search methods .
asshownininalgorithm1andalgorithm2 tabusearch carries out a neighborhood search where the neighborhood of the current solution is restricted by the search historyofpreviouslyvisitedsolutionsandisstoredintheformofatabu list lines and in algorithm and lines to inalgorithm2 .ifallneighborsare tabu itisacceptableto take a move that worsen the value of the objective function lines and in algorithm .
this is what enables tabu search to escape from local optima which is highly likelyto cause issues with a traditional gradient decent method.
according to a provided selection criteria tabu search only keep a record of some previously visited states.
576table overview of selected transfer learners and denote integer real and categorical value respectively .
algorithm parameter range algorithm parameter range algorithm parameter range nnfilter k metric euc man che min mahcde smote k metric euc man che min mahfss bagging topn threshold ratio tca kernel dime lamb primal rbf linear sam max n s n t gis prob chrm size pop size num parts num gens clife morph n alpha beta per gama mcount hisnn minham mcws k sigma lambda fesch nt strategy sfd ldf fcrum p qua t cli cohen td strategy k nn em vcb m lambda pcamining dime max n s n t for full specification of all the parameters please visit our repository table overview of selected classifiers and denote integer real and categorical value respectively .
algorithm parameter range algorithm parameter range algorithm parameter range extra trees classifier exs max e criterion min s l splitter min a p gini entropy random best extra tree classifier extree max e criterion min s l splitter min a p gini entropy random best decision tree dt max e criterion min s l splitter min a p gini entropy auto sqrt log2 random forest rf m stim criterion splitter min s l min a p gini entropy auto sqrt log2 support vector machine svm c kernel degree coef0 gamma rbf lin poly sig multilayerperceptron mlp active hid l s solver iter iden log tanh relu lbfgs sgd adam passive aggressiveclassifier pac c fit int tol loss true false hinge s hingeperceptronpenalty alpha fit int tol l1 l2 true false naive bayes nb nbtype alpha norm gauss multi comp ture false ridgealpha fit int tol ture false baggingn est max s max f logistic regression lr penalty fit int tol l1 l2 ture false knearest neighbor knn n neigh p radius neighborsradius weight uni distnearest centroidmetric euc man che min mah adaboostn est rate classifier rnc classifier ncc shrink t for full specification of all the parameters please visit our repository .
lower level optimization asintroducedinsection3.
themainpurposeofthelower leveloptimization is to optimize the hyper parameters associated with the chosencombinationoftransferlearner andclassifier.specifically this level in bilo cpdp is modeled and tackled as below.
search space at this level the search space is the configurationspaceofthecorrespondingparametersforthetransfer learnerandclassifierpickedupfromtheupper levelroutine.
indeed as can be seen from tables and such a config uration space might be different depending on the chosen combination of transfer learner and classifier.
objective function recall from the equation when a combination of transfer learner and classifier is picked upfrom the upper level routine the objective function for the lower level f xl takes the configuration of the correspondinghyper parametersastheinputs xl andoutputsthetrainingaucforthecpdpmodel.theauccollectedfromthe resultofthelow levelroutineisfinallyusedastheobjective value at the upper level routine to steer the optimization.
optimization algorithm itisnotuncommonthatthetraining andevaluation of a cpdpmodel is computationallydemanding and time consuming.
to this end in bilo cpdp weapplythetree structuredparzenestimator tpe a state of the artbayesianoptimizationalgorithmforhyperparameteroptimizationofmachinelearningalgorithms astheoptimizerforthelower leveloptimization dueprimarily to the following reasons 577algorithm3 runtpe xu xu lower leveloptimization for identifying the optimal hyper parameters.
input combination of transfer learner and classifier xu configuration space c output optimized hyper parameters xl and its objective function fxu xl 1d use space filling to sample a set of hyper parameters from cand evaluate their objective functions 2whilethe lower level time budget is not exhausted do 3use tree parzen to build a surrogate model based on d xlc best configuration based on the auc predicted by the acquisition function over the surrogate model 5fxu xlc evaluate the objective function of xlcby physically training the cpdp model 6d d uniontext.
xlc fxu xlc 7return xl fxu xl argmax xlc fxu xlc d fxu xlc tpecopes witha widerange ofvariables well including integer real and categorical ones which fits precisely with our need .
recentworkoncpdp andfromthemachinelearning community have reported the outstanding performance of tpe for expensive configuration problems.
as the pseudo code shown in algorithm the tpealgorithmfirstusesaspace fillingtechniquetosampleasetof hyper parameters valuesfromthegivenconfigurationspace cof transfer learner and classifier which would then be trained for collecting the training auc performance line .
alltheseconstitutetheinitialdataset d.duringthemain while loop a relatively cheap surrogate model of the expensivephysicalmodeltrainingandtheaucevaluationisbuilt basedonallsampleddatain d line3 .thereafter apromisinghyper parameter configurationtrial xlcisidentified by optimizingtheacquisitionfunction i.e.
expectedimprovement following a classic bayesian optimization rigour.
the aucof xlcisthereafterevaluatedandusedtoaugment d lines4to6 .attheend thebesthyper parametersetting xl indalong with its auc performance fxu xl are returned to the upper level optimization routine line .
experimental setup this section introduces our experiment setups4.
.
dataset in our experiments the dataset of software projects is collected according to the following three inclusion criteria topromotethereproducibilityandpracticalityofourexperiments we only consider projects hosted in public repositories and are related to non academic software.
to mitigate potential conclusion bias projects are required to cover different corpora and domains.
4all source code and data of this work can be publicly accessed via our repository that have already been used in the cpdp literature.
notethataprojectistemporarilyselectedifitmeetsallabovethree criteria.
to further refine our dataset composition we apply the following two exclusion criteria to rule out inappropriate projects.
it is not uncommon that the projects are evolved with more than one version during their lifetime.
since different ver sions of the same project are highly likely to share many similarities they may simplify the transfer learning.
in this case only the latest version of the project is kept.
to promote the robustness of experiments projects with repeated or missing data are ruled out from our consideration.
based on the above inclusion criteria we select five publicly available datasets i.e.
jureczko nasa softlab aeeem relink.
note that all these datasets have been reviewed and discussed in many recent survey in the cpdp literature .
thereafter softlabisfurtherruledoutfromourconsiderationaccordingto the above exclusion criteria.
in addition nasais also not consideredinourexperimentssinceitsdataqualityisrelativelypooras reportedin .attheend thedatasetconsideredinourexperiments consist of open source projects with instances.
its characteristics are summarized as follows aeeem thisdatasetcontains5opensourceprojectswith 371instances.inparticular eachinstancehas61metrics withtwodifferenttypes includingstaticandprocessmetrics like the entropy of code changes and source code chorn.
relink this dataset consists of open source projects with649instances.inparticular eachinstancecomeswith 26staticmetrics.notethatthedefectlabelsarefurthermanuallyverifiedafterbeinggeneratedfromsourcecodemanagement system commit comments.
jureczko thisdatasetoriginallyconsistsof92released softwarecollected froma mixof opensourced proprietary and academic projects.
with respect to the first inclusioncriterion those proprietary and academic projects are not considered.moreover sincetheprojectsin jureczko have beenupdatedmorethanonce accordingtothefirstexclusion criterion only the latest version of a project is consideredin our experiments.
ultimately we choose open source projects with instances from jureczko.
.
experimental procedure our experimental procedure follows the three phases workflow of bilo cpdp introduced in section .
.
here we explain the corresponding settings for each phase.
inthedatapre processing phaseforallpeercpdptechniques allprojectsinthisworkwillbeusedastargetdomaindata inaround robinmanner forming20differentcpdptasks.
this aims to mitigate the potential bias in conclusion.
in theoptimization phase each cpdp task is allocated with an overall time budget of one hour i.e.
seconds as suggestedbyfeureretal.
whilesettingeachlower level exploitationas20secondsin bilo cpdp .whenapplicable thesamebudgetisgiventootherstate of the artpeercpdp techniques that permit hyper parameter optimization in the 578table scott knott test on bilo cpdp and existing cpdp techniques over runs.
the larger rank the better gray the best cpdp technique apache eq jdt lc ml pde safe tomcatzxing ant camel ivy jedit log4j lucene poi synapse velocity xalan xerces nnfilter nb um nb um lr clife nb clife knn fesch rf gis nb fesch lr clife svm td rf td lr td mlp td dt fesch dt vcb svm cde smote rf cde smote knn fss bagging rf fss bagging nb fss bagging lr hisnn nb bilo cpdp the raw auc values can be found in our repository comparison e.g.
auto sklearn .weapplythetpealgorithm implementation integrated in hyperopt5 a popular pythonlibraryforhyper parametertuninginmachinelearning for the lower level routine of bilo cpdp.
in theperformance validation phase auc is used as the performancemetric.duetothestochasticnatureof bilo cpdp andsome peer cpdptechniques considered each technique is independently repeated times for a given cpdp task and the mean auc values are recorded for comparison.
.
ranking statistical test and effect size in our experiments we use the following three statistical measures to interpret the statistical significance of our comparative results.
scott knotttest insteadofmerelycomparingtherawauc values weapplythescott knotttesttoranktheperformance of different peer techniques over runs on each project as recommended by mittas and angelis .
in a nutshell the scott knotttestusesastatisticaltestandeffectsizetodivide the performance of peer techniques into several clusters.
in particular the performance of peer techniques within the sameclusterarestatisticallyinsignificant i.e.
theiroverall aucvaluesarestatisticallyequivalent.notethattheclustering process terminates until no split can be made.
finally eachclustercanbeassignedarankaccordingtothemean aucvaluesachievedbythepeertechniqueswithinthecluster.inparticular sinceagreateraucispreferred thelarger therankis thebetterperformanceofthetechniqueachieves.
weapplythewilcoxonsignedranktest withasignificantlevel p .
toinvestigatethestatisticalsignificanceofthecomparisons.itisa non parametricstatisticaltestthatmakeslittleassumption abouttheunderlyingdistributionofthedataandhasbeen recommended in software engineering research .
a12effect size to ensure the resulted differences are not generatedfromatrivialeffect weapply a12 astheeffect sizemeasuretoevaluatetheprobabilitythatonetechniqueis better than another.
according to vargha and delaney when comparing bilo cdpd with another peer technique in our experiments a12 .
means they are equivalent.
a12 .
denotes that bilo cdpd is better for more than ofthetimes.inparticular .
a12 .64indicates a small effect size while .
a12 .
anda12 .
mean a medium and a large effect size respectively.
note that both wilcoxon signed rank test and a12are also used in the scott knott test for generating the clusters.
.
research questions we seek to answer the following four research questions rqs through our experimental evaluation rq1 isbilo cpdp able to automatically configure a cpdp model having better performance than the existing cpdp techniques under their reported settings?
rq2 howistheperformanceof bilo cpdp comparingwith auto sklearn a state of the art automl tool?
rq3 is the bi level programming in bilo cpdp beneficial?
579figure total ranks achieved by bilo cpdp the right most one andthe21peertechniques thelargerrank thebetter the dashed line and dotted line denote the best and averageresult over the peer techniques respectively .
rq4 given a limited computational budget which level in bilo cpdp is more important and deserves more budget?
results and discussions in this section we present and discuss the results of our empirical experiments and address the rqs posed in section .
.
.
comparison with existing cpdp work .
.
method.
inordertoanswerrq1 weusethetransferlearners andclassifierscollectedintables1and2toconstitute21peercpdp techniques in comparison with bilo cpdp .
note that although thereareonly13transferlearnerslistedintable1 someofthemarecombinedwithmorethanoneclassifiertoconstitutedifferentcpdpmodelsusedintheliterature e.g.
tdiscombinedwithclassifiers rf lr mlpanddtthat constitute four different cpdp models in .
for the parameter settings we use the tuned values as reported in the corresponding work.
.
.
results and analysis.
fromtheexperimentalresultsonthe scott knott test shown in table it is clear to see that bilo cpdp is the best on out of projects second only to one other on five cases.
in contrast most of the other peer cpdp techniques albeit hand crafted by domain experts are not as competitive as bilo cpdp .
in particular nnfilter nb is the most outstanding peertechniquethatisthebestononly7out20 projectswhile the other peer techniques rarely take the best rank across all projects.
noteworthily the performance of nnfilter nb ties with bilo cpdp in two of its best results.
in terms of the total ranks achievedoverallprojects asshowninfig.
wecanobservethe clearsuperiorityof bilo cpdp whichisatleast50 betterthanthe other peer techniques.
furthermore we notice that the superior performance of bilo cpdp is consistent across all projects in view of its top three ranked positions achieved in all projects.
in contrast theperformanceofexistingcpdptechniquesexhibitclear variations depending on the underlying target projects.
response to rq1 bilo cpdp isgenerallybetterthantheother existing cpdp techniques over all projects.
unlike others that werehand craftedbydomainexpertstocertainextents bilo cpdp builds an effective cpdp model in a completely automated manner leading to highly competitive performance over different projects.table mean auc standard deviation for bilo cpdp and auto sklearn over runs gray better bold p .
.
project bilo cpdp auto sklearn p value poi8.1703e .38e .5262e .98e .71e synapse .1999e .72e .0183e .68e .65e zxing .3949e .37e .2615e .45e .91e ant8.0006e .26e .4530e .63e .71e log4j .4196e .52e .0965e .19e .57e safe7.9923e .09e .7513e .15e .64e ivy8.0657e .51e .2407e .64e .19e pde6.8539e .57e .9781e .22e .62e camel .2228e .01e .9006e .11e .62e lucene .1065e .13e .4408e .87e .37e jdt7.3705e .09e .7517e .11e .66e jedit .5207e .77e .1589e .70e .68e eq7.1714e .34e .0201e .33e .73e velocity .0220e .40e .0896e .50e .61e tomcat .7295e .40e .3892e .32e .45e apache .4808e .27e .4787e .33e .58e ml6.4966e .58e .1708e .22e .73e xerces .1552e .03e .9892e .03e .71e lc7.0859e .89e .2476e .11e .73e xalan .6250e .67e .7732e .31e .71e figure a12result between bilo cpdp and auto sklearn over runs a12 .5means bilo cpdp is better .
.
comparison with auto sklearn .
.
method.
in principle bilo cpdp is an automl tool that automaticallysearchesfortherightcombinationoftransferlearner andclassifierandtheiroptimizedhyper parametersettingsfora given cpdp task.
to validate its competitiveness from the perspectiveofautoml we comparetheperformanceof bilo cpdp with auto sklearn6 astate of the artandreadilyavailableautoml tool that can also optimize the combination and its parameters.
.
.
results and analysis.
fromthecomparisonresultsofauc values shown in table we clearlysee the overwhelmingly superior performance of bilo cpdp versus auto sklearn where the auc values obtained by bilo cpdp are all better than those of auto sklearn .
in particular all those better results except on apache arestatisticallysignificant accordingtothe pvaluesshown inthelastcolumnoftable4.furthermore asshowninfig.
all a12 valuessuggestalargeeffectsize.inparticular weseeanoverwhelminga12 except only on zxingandapache.
these indicate that the improvements on the auc results brought by bilo cpdp over that of the auto sklearn are significantly large in general.
580theresultsarecausedbythefactthat auto sklearn doesnot haveabi levelstructure henceitencodesalltransferlearnerand classifier combinations along with their corresponding hyper parametersettingsintoanintegratedsolutionatasingle level which is solved by the smac algorithm .
during its optimization process acombinationoftransferlearnerandclassifierisselectedfirst.
thereafter the variables corresponding to the hyper parameters of thechosen transferlearner andtheclassifier becomeactivewhile the remaining variables are set to be dummy.
by this means the total number of variables considered in auto sklean goes up to resultingaunnecessarilymuchlargersearchspacecomparing with bilo cpdp .giventhelimitedbudget auto sklearn therefore ends up with a less effective exploration of both useful combinations of transfer learners and classifiers and their hyper parameter settings.
response to rq2 comparingwiththestate of the artautoml toolauto sklearn bilo cpdp achievessignificantlybetterresults given a limited computational budget.
.
comparison with single level variant .
.
method.
itisconservativetocuriousabouttheusefulness broughtbythisbi levelprogrammingformulationandwhynotsimply formulating a single level problem that consists of both combinationandparameters.thecomparisonwith auto sklearn which isatasingle level partiallyvalidatesthisconcern buttheresults canbebiasedbythe factthatitusesadifferentoptimizationalgorithm.tofully evaluatetheeffectiveness ofbi levelprogramming we develop a single level variant of bilo cpdp dubbed slo cpdp which differs from bilo cpdp only on the solution representation.
specifically slo cpdp issimilarto auto sklearn inthesense that they both work on single level optimization the transfer learnerand classifier togetherwiththeir hyper parameters areen codedasasinglesolutionrepresentation.however thedifferenceisthat slo cpdp exploitsthe tpealgorithmasthebayesianoptimizer whichisidenticalto bilo cpdp .auto sklearn incontrast uses the classic smac algorithm that leverages random forest to build the surrogate model.
.
.
results and analysis.
fromtheaucvaluesshownintable5 we observe a rather superior performance achieved by bilo cpdp over slo cpdp .specifically bilo cpdp againobtainsabetterauc value on all projects.
in particular all better results are with statistical significance p .
as shown in the last column of table .
furthermore from fig.
we find that the differences between the aucvaluesachievedby bilo cpdp andslo cpdp arewithalarge effect size.
given such a result we can infer that the ineffective ness of slo cpdp can be attributed to the enlarged search space caused by the unwise coupling of transfer learner and classifier combination along with their parameters at a single level.
response to rq3 the bi level programming in bilo cpdp considerably contributes to its effectiveness.
in contrast to the single level where the combination and parameters are formulated in a flat way bi level programming significantly reduces the search spaceandsteerthesearchinahierarchicalmanner leadingtobetter performance under a limited budget.table mean auc standard deviation for bilo cpdp and slo cpdp over runs gray better bold p .
.
project bilo cpdp slo cpdp p value poi8.1703e .38e .7493e .71e .92e synapse .1999e .72e .0601e .33e .73e zxing .3949e .37e .4209e .46e .92e ant8.0006e .26e .3099e .76e .73e log4j .4196e .52e .2807e .49e .60e safe7.9923e .09e .4254e .96e .74e ivy8.0657e .51e .3528e .77e .73e pde6.8539e .57e .0874e .52e .73e camel .2228e .01e .7330e .15e .22e lucene .1065e .13e .8568e .05e .15e jdt7.3705e .09e .2603e .81e .36e jedit .5207e .77e .5203e .50e .73e eq7.1714e .34e .4016e .21e .88e velocity .0220e .40e .3123e .11e .73e tomcat .7295e .40e .6400e .40e .92e apache .4808e .27e .2924e .23e .01e ml6.4966e .58e .8287e .53e .16e xerces .1552e .03e .3384e .29e .87e lc7.0859e .89e .3199e .38e .02e xalan .6250e .67e .9866e .21e .79e figure4 a12resultbetween bilo cpdp and slo cpdp over30 runs a12 .5means bilo cpdp is better .
.
impact of budget for the two levels .
.
method.
inpractice itisnotuncommonthattheresourcefor defectprediction particularthetimebudget islimited.inourexper iments thetotalbudgetallocatedto bilo cpdp isonehourintotal followingthebestpracticeintheautomlcommunity .however the unique bi level programming formulated in bilo cpdp allows us a flexible control over the budget allocated to the two levels hence it is interested to know how their budget allocations may impacttheperformance.tothisend withintheonehourtotalbudget we set two budget allocation strategies one with high budget totheupper level dubbed bilo cpdp h thatallows20seconds for each low level optimization leaving more resources for exploringthecombinationsattheupper level.notethat20secondsare very shortfor some model trainingthus is counter intuitive.
this isalsothedefaultsettingin bilo cpdp weusedforotherexperiments.anotheronepreserveshighbudgettothelow level dubbed bilo cpdp l inwhichthelower leveloptimizationisallocated with training and auc evaluations.
this allows a low level routinetoconsumeatleast80seconds thesmallestamountoftime required tocomplete evaluationsamong all combinations formore sufficient exploration of the hyper parameters.
581table mean auc standard deviation for bilo cpdp h and bilo cpdp l over runs gray better bold p .
.
project bilo cpdp h bilo cpdp l p value poi8.1703e .38e .9447e .74e .85e synapse .1999e .72e .1897e .26e .73e zxing .3949e .37e .1108e .10e .46e ant8.0006e .26e .6150e .31e .91e log4j .4196e .52e .1593e .91e .46e safe7.9923e .09e .1771e .38e .87e ivy8.0657e .51e .9659e .04e .23e pde6.8539e .57e .3027e .05e .71e camel .2228e .01e .9054e .79e .90e lucene .1065e .13e .3341e .69e .12e jdt7.3705e .09e .7420e .51e .85e jedit .5207e .77e .0339e .30e .72e eq7.1714e .34e .2035e .22e .37e velocity .0220e .40e .0660e .55e .92e tomcat .7295e .40e .6762e .87e .50e apache .4808e .27e .1257e .62e .22e ml6.4966e .58e .7510e .07e .70e xerces .1552e .03e .8507e .72e .87e lc7.0859e .89e .9327e .00e .23e xalan .6250e .67e .9144e .05e .91e figure5 a12resultbetween bilo cpdp h and bilo cpdp l over runs a12 .5means bilo cpdp h is better .
.
.
results and analysis.
asshownintable6 wecanseethat bilo cpdp h isoverwhelminglysuperiorto bilo cpdp l where it obtains better auc values on all projects.
in addition from the comparison results of a12shown in fig.
we can see that the differences between auc values achieved by the two budget allocation strategies are categorized to have a large effect size.
theperformancedifferencesareduetothefactthatthecpdp model training can be rather time consuming and unfavorable especially given a limited budget.
therefore for bilo cpdp l oncea combinationoftransfer learnerandclassifier isselectedat the upper level routine its initiative to favor better exploration of thehyper parametersatthelower levelroutinecaneasilyconsumeasignificantamountofthebudget themediancomputationaltime isaround300secondsaccordingtoourofflinestatistics .thishas causedthecombinatorialspaceoftransferlearnersandclassifiersto become severely under explored.
in contrast by strictly restricting the budget at the lower level optimization routine bilo cpdp h suffers from a limited exploration of the hyper parameter space butpermittingasufficientchancetoexploremanycombinations of transfer learners and classifiers.
from the results it evidencesthatexploringthecombinationspaceismoreimportantthanusing the hyper parameter space under a limited budget.
response to rq4 givenalimitedbudget itisrecommendedto allocatemoreexpendituretotheupper leveloptimizationroutinein bilo cpdp .bythismeans morecombinationsoftransferlearner and classifier can be investigated even without fully optimized hyper parameters which is more beneficial to performance.
related work in the past decades machine learning classifiers have becomethe core techniques for defect prediction in which the successcan be greatly affected by the setting of the classifiers hyper parameters .
this is a challenging issue as jiang et al .
pointed out that simply using the default values are dreadful causing severely bad performance of the prediction.
the automatedparameter optimization for defect predictors is therefore crucial.
indeed alargescaleempiricalstudybytantithamthavornetal .
foundthatwell tunedhyper parameterscansignificantlyboost the performance of the classifiers in defect prediction.
fu et al .
even suggest that such optimization should become a standard practice in every single software engineering task.
in light of this agrawal and menzies have applied differential evolution to tune smote apre processorforhandlingdataimbalance forpredictingsoftwaredefects.theirworkfocusonwithin projectdefect prediction though.
similarly dodge is a recent tool that optimizestheparametersofdatapre processorandclassifier.although they aim for within project case the combination of pre processor andclassifiercanberesembletoourcpdptask.however theirop timizationassumesconservativehybridizationofalltheparameters and the combinations as a single level optimization problem.
theimportanceofautomatedparameteroptimizationremains stand in the context of cpdp where the problem become evenmore complex as the parameters of transfer learners also come into play.
qu et al .
have shown that the parameter settings of classifiersforcpdpareevenmoreimportant.afewautomatedop timizersexistforcpdp forexample zt rk andquetal .
examinevariousdifferentoptimizationalgorithmstotunecpdp models.
nevertheless they focus only on the parameter tuning whilstignorethecombinationoftransferlearnerandclassifierduring optimization.
indeed li et al .
further demonstrate that the parameterinteractionsbetweentransferlearnerandclassifier as wellastheircombination alsoplayanintegralroletotheprediction performance.
auto sklearn which is a widely used generic tooltotunearbitrarymachinelearningalgorithms isalsohighly potentialforcpdptuning.however again itsdesignhasrestricted thatthecombinationoftransferlearnerandclassifieralongwith theirparametersneedtobetunedasasingleoptimizationproblem which worsen its performance compared with bilo cpdp a sw e have shown in section .
although the potentials of bi level programming have been explored for other software engineering problems e.g.
code smell detection andtestcasegeneration tothebestofourknowledge its adoption has never been reported in the context of cpdp.
ourworkisthereforeuniquetoallaforementionedtechniquesin the sense that bilo cpdp is the first of its kind to formulate bi level programming for the parameter optimization of cpdp.
bilo cpdp automaticallyoptimizesnotonlytheparameters butalsodiscoverthepossiblecombinationoftransferlearner and classifier from a given portfolio.
we show that exploring the combination of transfer learner andclassifierismoreimportantthanthetheirparameters tuning the former should thus deserve more computational budget.
in this regard the bi level programming formulated inbilo cpdp provides better flexibility to achieve such a requirement of fine grained budget allocation.
threats to validity similar to many empirical studies in software engineering our work is subject to threats to validity.
constructthreatscanberaisedfromtheexperimentuncertainty caused by the learning and optimization.
to mitigate this we have repeated 30runs for each techniquesand compare the techniques using scott knott test supported by wilcoxon signed rank test anda12effect size metric .
therefore whenever we report a is better than b we imply that a is indeed statistically betterwithlargeeffectsize.thesinglemetricaucmayalsosubject to such a threat.
however auc was chosen mainly due toits parameter free nature and high reliability as reported in the machine learning community .
internalthreatscanberelatedtotheparametersetting whichin our case the key parameter is the time budget for optimization.
indeed adifferentbudgetmayaffecttheresult andthereforewehave setatotalbudgetfollowingthestate of the practicesuggestedin theautomlcommunity whichisreasonablegiventherequired runs.
wehave also investigatedthe relativeimportance of budget allocation between the upper and lower level in bilo cpdp.
external threats are concerned with whether the findings are generailzabletootherprojects.tomitigatesuch asdiscussedinsec tion4 our20projectscoverawidespectrumofthereal worldcases withdiversecharacteristics eachofwhichwasusedasthetarget domain data to be predicted using the other ones as sources.
conclusion thechoiceofcombinationoftransferlearnerandclassifieralong withtheirhyper parametersettingshaveasignificantimpacttothe performanceofcpdpmodel.inthispaper wepropose bilo cpdp a tool that is able to automatically develop a high performance cpdp model for the given cpdp task.
specifically bilo cpdp for the first time formulates the automated cpdp model discovery problemfromabi levelprogrammingperspective.inparticular theupper leveloptimizationroutinesearchesfortherightcombinationof transfer learner and classifier while the lower level optimization routine optimizes the corresponding hyper parameters associated withthechosencombination.furthermore thehierarchicaloptimization paradigm allows a more flexible control of the computationalbudgetatbothlevels.fromourempiricalstudy wehave shown that bilo cpdp automaticallydevelopsabetter cpdpmodelcomparingto state of the art cpdp techniques with hand crafted combination and reported parameter settings.
overwhelmingly outperforms auto sklearn a state of theartautomltool andthesingle leveloptimizationvariant ofbilo cpdp.
allows software engineers to set more search budget for the upper level which significantly boosts the performance.
bilo cpdp showcases the importance of automatically optimizing the combination of transfer learners and classifiers together with their parameters.
this paves a new way to enable more intelligentparameteroptimizationandadaptationforcpdpmodel building.
in future we seek to consider multiple objectives within thebi levelprogrammingandtoinvestigatemorepreciseeffectsof allocating budget between the two levels.
we also plan to fur therdistinguishbetweentheparametersfortransferlearnerand classifier at the low level as it has been shown that the parameter tuning of the former is more important than the latter .
acknowledgement k. li was supported by ukri future leaders fellowship grant no.
mr s017062 .