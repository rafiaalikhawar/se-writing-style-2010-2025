on learning meaningful assert statements for unit test cases cody watson washington and lee university lexington virginia cwatson wlu.edumichele tufano microsoft redmond washington michele.tufano microsoft.comkevin moran william mary williamsburg virginia kpmoran cs.wm.edu gabriele bavota universit della svizzera italiana usi lugano switzerland gabriele.bavota usi.chdenys poshyvanyk william mary williamsburg virginia denys cs.wm.edu abstract software testing is an essential part of the software lifecycle and requires a substantial amount of time and e ort.
it has been estimated that software developers spend close to of their time on testing the code they write.
for these reasons a long standing goal within the research community is to partially automate software testing.
while several techniques and tools have been proposed to automatically generate test methods recent work has criticized the quality and usefulness of the assert statements they generate.
therefore we employ a neural machine translation nmt based approach called a automatic learning of assert statements to automatically generate meaningful assert statements for testmethods.
given a test method and a focal method i.e.
the main method under test a can predict a meaningful assert statement to assess the correctness of the focal method.
we applied a to thousands of test methods from github projects and it was able to predict the exact assert statement manually written by developers in of the cases when only considering the top1 predicted assert.
when considering the top predicted assert statements a is able to predict exact matches in of the cases.
these promising results hint to the potential usefulness of our approach as i a complement to automatic test case generation techniques and ii a code completion support for developers who can bene t from the recommended assert statements while writing test code.
ccs concepts software testing unit tests arti cial intelligence machine translation .
acm reference format cody watson michele tufano kevin moran gabriele bavota and denys poshyvanyk.
.
on learning meaningful assert statements for unit test cases.
in 42nd international conference on software engineering icse may seoul republic of korea.
acm new york ny usa 12pages.
permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for pro t or commercial advantage and that copies bear this notice and the full citation on the rst page.
copyrights for components of this work owned by others than acm must be honored.
abstracting with credit is permitted.
to copy otherwise or republish to post on servers or to redistribute to lists requires prior speci c permission and or a fee.
request permissions from permissions acm.org.
icse may seoul republic of korea association for computing machinery.
acm isbn .
.
.
.
introduction writing high quality software tests is a di cult and time consuming task.
to help tame the complexity of testing ideally development teams should follow the prescriptions of the test automation pyramid which suggests rst writing unit tests that evaluate small functionally discrete portions of code to spot speci c implementation issues and quickly identify regressions during software evolution.
despite their usefulness prior work has illustrated that once a project reaches a certain complexity incorporating unit tests requires a substantial e ort in traceability decreasing the likelihood of unit test additions .
further challenges exist for updating existing unit tests during software evolution and maintenance .
to help address these issues the software testing research community has responded with a wealth of research that aims to help developers by automatically generating tests .
however recent work has pointed to several limitations of these automation tools and questioned their ability to adequately meet the software testing needs of industrial developers .
for example it has been found that the assert statements generated by state of the art approaches are often incomplete or lacking the necessary complexity to capture a designated fault.
the generation of meaningful assert statements is one of the key challenges in au tomatic test case generation .
assert statements provide crucial logic checks in a test case to ensure that the program is functioning properly and producing expected results.
however writing or generating e ective assert statements is a complex problem that requires knowledge pertaining to the purpose of a particular unit test and the functionality of the related production code.
thus an e ective technique for the generation of assert statements requires predicting both the type and logical nature of the required check using source and test code as contextual clues for prediction.
to help advance techniques that aid developers in writing or generating unit tests we designed a an approach for automatically generating syntactically and semantically correct unittest assert statements using neural machine translation nmt .
a generates models trained on large scale datasets of source code to accurately predict assert statements within test methods.
we take advantage of the deep learning strategy of nmt which has become an important tool for supporting software related taskssuch as bug xing code changes code migration code summarization pseudo code generation code deobfuscation and mutation analysis .
to the best of our knowledge this is the rst empirical step toward ieee acm 42nd international conference on software engineering icse icse may seoul republic of korea cody watson michele tufano kevin moran gabriele bavota and denys poshyvanyk evaluating an nmt based approach for the automatic generation of assert statements.
speci cally we embed a test method along with the context of its focal method i.e.
a declared method within the production code whose functionality is tested by a particular assert statement and we translate this input into an appropriate assert statement.
since our model only requires the test method and the focal method we are able to aid developers in automaticassert generation even if the project su ers from a lack of initial testing infrastructure.
note that our approach is not an alternative to automatic test case generation techniques but rather a complementary technique that can be combined with them to improve their e ectiveness.
in other words the automatic test case generation tools can be used to create the test method and our approach can help in de ning a meaningful assert statement for it.
to train a we mined github for every java project making use of the junit assert class.
in total we analyzed over 9k projects to extract examples of developer written assert statements being used within test methods.
this data was used to give the nmt model the ability to generate assert statements that closely resemble those created by developers.
therefore not only do we enable e ciency within the software testing phase but we also facilitate accuracy and naturalness by learning from manually written assert statements.
after we extracted the pertinent test methods containing assert statements from the java projects we automatically identi ed the focal method for each assert statement based on the intuition from qusef et al.
.
we hypothesize that combining the test method and the focal method should provide the model with enough context to automatically generate meaningful asserts.
we then quantitatively and qualitatively evaluated our nmt model to validate its usefulness for developers.
for our quantitative analysis we compared the models generated assert statements with the oracle assert statements manually written by developers.
we considered the model successful if it was able to predict an assert statement which is identical to the developer written one.
our results indicate that a is able to automatically generate asserts that are identical to the ones manually written by developers in .
of cases perfectly predicted assert statements when only considering the top predicted assert.
when looking at the top recommendations this percentage rises to .
.
for our qualitative analysis we analyzed imperfect predictions i.e.
predictions which can di er semantically or syntactically as compared to the assert manually written by developers to understand whether they could be considered an acceptable alternative to the original assert.
we found this to be true in the of cases we analyzed.
finally we computed the edit distance between the imperfect predictions and original asserts in order to assess the e ort required for a developer to adapt a recommended assert statement into one she would use.
we show that slight changes to the imperfect asserts can easily convert them into a useful recommendation.
to summarize this paper provides the following contributions we introduce a a nmt based approach for automatically generating assert statements.
we provide details pertaining to the mining synthesizing and pre processing techniques to extract test methods from the wild and to train and test a an empirical analysis of a and its ability to use nmt to accurately generate a semantically and syntactically correct assert statement for a given test method a quantitative evaluation of the model and a detailed comparison between modeling raw and abstracted test methods a publicly available replication package containing the source code model tools and datasets discussed in this paper.
related work motivation while several automated tools such as evosuite randoop and agitar have been proposed to automatically generate test methods these tools embed their own methods for synthesizingassert statements.
evosuite one of the most popular automated test generation tools uses a mutation based system to generate appropriate assert statements.
in particular it introduces mutants into the software and attempts to generate assert statements able to kill these mutants.
evosuite also tries to minimize the number of asserts while still maximizing the the number of killed mutants .
randoop is another automated test generation tool that creates assertions with intelligent guessing.
this technique applies feedback directed random testing by analyzing execution traces of the statement it creates.
essentially a list of contracts or pieces of logic that the code must follow are used to guide the generationof assert statements.
these contracts are very similar to user de ned assert statements.
however the contracts only provide the logic.
the randoop program creates a syntactically correct assert statement that tests the user s provided logic pertaining to the test method.
di erently from evosuite and randoop a applies a deep learning based approach with the goal of mimicking the behavior of expert developers when writing assert statements.
recent research has evaluated the ability of state of the art automated techniques for test generation to capture real faults .
the recent study conducted by shamshiri et al.
highlights the importance of high quality complex assert statements when detect ing real faults.
the authors compare the abilities of both exceptions and asserts as fault nding mechanisms.
they note that three automated approaches evosuite randoop agitar detect more faults through the use of an assert statement however insu ciencies in the automatically generated asserts led to many bugs going undetected .
thus this work makes two important conclusions i assert statements are an important component of automated test case generation techniques as they are the main vehicle through which faults are detected ii the current quality of assert statements generated by automated testing techniques are often not of high enough quality to detect real faults.
a complimentary study performed by almasi et al.
tested evosuite and randoop s ability to detect real faults in an industrial software system.
the study found that evosuite was able todetect .
and randoop was able to detect .
of the faults within that system.
of particular note was the author s qualitative evaluation which showed that nearly half of the undetected faults could have been detected with a more appropriate assert statement.
additionally the authors solicited feedback from developers asking how can the generated tests be improved?
.
the general consensus among the respondents was that automated testing strategies failed to generate meaningful assert statements.
the authors also 1399on learning meaningful assert statements for unit test cases icse may seoul republic of korea github test methods datasetsmine junit test methods 21spoon framework focal methods create test method context3 filtering abstraction raw source code abstractcode rnns encoder decoder copy aht xtaht xt a!n.
aht xtaht xt6 figure overview of a tlas work ow presented hand written test methods to developers for comparison and they commented that the assertions are meaningful and useful unlike the generated ones .
these ndings demonstrate a clear need for automated techniques that generate meaningful assert statements to complement existing test generation approaches.
one of the limitations that tools such as evosuite randoop and agitar have is that they rely on heuristics or intelligent randomness in order to generate assert statements.
this type of generation does not take into account the learn able components of test and focal methods and thus leads to more simplistic asserts.
therefore we leverage a nmt based dl technique to generate asserts that can test the complexities contained within the context of the test and focal method.
this strategy results in an assert which possesses the ability to accurately evaluate the logic of the focal method leading to more useful unit tests and a higher quality test suite.
a tlas learning asserts via nmt we provide an overview of the a work ow for learning assert statements via nmt in fig.
.
our approach begins with the mining and extraction of test methods from java projects.
to do this we mine github projects that use the junit testing framework sec.
.
.
from those projects we mine all test methods denoted with the test annotation as well as every declared method within the project sec.
.
.
we then lter this data identify the appropriate focal method context and generate pairs containing the contextualtest method i.e.
the test method augmented with information about the focal method it tests and the relevant assert statement sec.
.
sec.
.
.
we refer to these pairs as test assert pairs taps .
next we generate two datasets of taps i raw source code where taps are simply tokenized ii abstract code where we abstract the taps through our abstraction process sec.
.
.
finally we train two rnn encoder decoder models one using the copy mechanism trained on the raw source code taps and another using only the attention mechanism trained on the abstract code taps sec.
.
.
.
github mining our main motivation toward studying java projects that use the junit framework is applicability.
as of august the tiobe programming community index indicated java as the most popularprogramming language .
in addition a study done by oracle in found that junit was the most popular java library .
hence curating a dataset of projects that use java and junit lends to the potential for impact on real world software development.
we identi ed github projects using the junit testing framework.
since client projects can use junit by declaring a dependency through apache maven we started by using the github search api to identify all java projects in github having at least one pom le needed to declare dependencies toward maven libraries.
this resulted in the identi cation of client projects using pom les and declaring .1m dependencies in total.
we downloaded all the identi ed pom les and mined them to identify all client projects declaring a dependency toward junit version and all its minor releases.
these dependencies can be easily identi ed by looking in the pom le for artifacts having the junit groupid junit artifactid and a version starting with .
.
using this process we collected a total of projects.
note that we decided to focus on junit v. since in the mined dataset of pom les we found that the majority of them had a dependency towards this version.
.
method extraction after mining these projects from github we downloaded the source code and extracted the relevant test methods using spoon .
this framework allows for source code analysis through the creation of a meta model where the user can access program elements.
to access relevant methods we extract methods beginning with the test annotation which is inherent to the junit framework.
after extracting the test methods we extract every method declared within the project excluding methods from third party libraries.
the extracted methods comprise a pool from which we can determine the focal method of interest for a particular test method.
the reason we only consider methods declared within the project is two fold.
first most assert statements are evaluating the internal information of the project itself rather than information taken from third party libraries or external packages.
second it would require a substantial e ort to retrieve the method bodies and signatures from all the third party libraries and external packages.
since our goal is to learnappropriate assert statements for a given test method and its context any test method without an assert statement has been discarded.
also since this is the rst work in the literature applying nmt to automatically generate assert statements we decided to focus on test methods having a single assert statement and thus we exclude those implementing multiple asserts.
while we acknowledge that this is a simpli cation of the problem we tackle we preferred to rst investigate the potential usefulness of nmt in a well de ned scenario in which for example it is safe to assume that the whole test method provides contextual information for the unique assert statement it contains.
this assumption is not valid in the case of multiple asserts and instead requires the development of techniques which are able to link parts of the test method body to the di erent asserts in order to understand the relevant context for each of them.
this is part of our future work.
overall we collected test methods with a single assert statement.
.
identifying focal methods our next task is to identify the focal method that the assert statement within the test method is testing.
to accomplish this we 1400icse may seoul republic of korea cody watson michele tufano kevin moran gabriele bavota and denys poshyvanyk implement a heuristic inspired by qusef et al.
.
we begin by extracting every method called within the test method.
the list of invoked methods is then queried against the previously extracted list of methods de ned inside the project considering the complete method signature.
we then assume that the last method call before the assert is the focal method of the assert statement .
in some instances the assert statement contains the method call within its parameters.
in these cases we consider the method call within the assertion parameters as the focal method.
it may appear problematic that we use the line we attempt to predict in order to extract the focal method since in theory the line to generate should not exist .however in a real usage scenario we assume that the developer can provide the focal method to our model i.e.
she knows the method she wants to test .
since identifying the focal method manually for a large number of assert statements is unreasonable we used the heuristic previously described in place of manual identi cation of the focal method.
we note this as a limitation but nd it reasonable that either a developer or an automated test generation strategy would provide this information to our approach.
.
filtering in this work we are attempting to generate semantically and syntactically correct assert statements from the test method and focal method context.
thus we are creating a model which must learn relationships from source code.
modeling this type of data presents certain challenges such as the open vocabulary problem and the length of the input problem .
usually these problems are tackled by limiting the vocabulary and the input length so that the model can adequately learn .
we employ similar solutions when training our model.
we lter the data in three distinct ways i excluding test methods longer than tokens ii ltering test methods that contain an assert statement which requires the synthesis of unknown tokens and iii removing duplicate examples within the dataset.
every ltering step helps to address nmt related challenges and have been used in previous approaches that take advantage of this deep learning based strategy .
our rst ltering step is fairly straightforward we remove all test methods that exceed tokens.
the second ltering step removes test methods in which the appropriate assert statement requires the synthesis of one or more unknown tokens.
this means that the syntactically and semantically correct assert statement requires a token that cannot be found in the vocabulary or in the contextual method i.e.
test method focal method .
indeed there is no way to synthesize these tokens when the model attempts to generate a prediction.
we further explain this problem as well as our developed solution in section .
.
.
lastly our third ltering step aims at removing duplicated instances ensuring that every contextual method and assert statement pair in our dataset is unique.
.
.
vocabulary we have alluded to the open vocabulary problem which is an inherent limitation of nmt.
this issue arises because developers are not limited in the number of unique tokens they can use.
they are not limited to for example english vocabulary but also create new tokens by combining existing words e.g.
by using the camelcase notation or inventing new words to com prise identi ers e.g.
v0 new .
for this reason the source code vocabulary frequently needs to be arti cially truncated.
to dealwith this problem we studied the tokens distribution in our dataset observing that it follows zipf s law as also found by previous work analyzing open source software lexicons .
this means that the dataset s tokens follow a power law like distribution with a long tail and that many of the taps in our dataset can be successfully represented by only considering a small subset of its uniquetokens.
based on analyzing the data and on previous ndings in the literature we decided to limit our vocabulary to the most frequent tokens.
this allows us to successfully represent all tokens for .
of the taps in our dataset i.e.
out of .
this ltering step aimed at removing instances for which the model would need to generate an unknown token.
this can be formally de ned as follows given a contextual method i.e.
the test method tmand the corresponding focal method fm we remove taps for which the anticipated assert to generate contains a token tsuch that t v lobal vtm vfm where vrepresents the vocabulary.
we refer to vtm vfmas the contextual method.
each ltering step was due to concrete limitations of state of the art nmt models.
in numbers starting from 750thousand test methods having a single assert .5thousand tests are removed due to their excessive length and 280thousand due to unknown tokens.
thus of the single assert test methods are removed.
.
test assert pairs and abstraction the next step of our approach consists of preparing the data in such a manner that it can be provided as input to a s nmt model.
this process involves i the concatenation of the focal method to the test method in order to create the test assert pair tap ii the tokenization of the tap and iii the abstraction of the tap.
starting from the rst point it is important to note that not every test method will inherently contain a focal method being tested.however for the test methods that do posses a focal method we append its signature and body to the end of the test method.
while comments and whitespaces are ignored we do not remove any other token from either the test or focal method.
we then proceed to remove the entire assert statement from the test method replacing it with the unique token assertplaceholder .
therefore the rst part of a tap consists of the concatenated test and focal method and the second part consists of the assert statement to generate.
we generate two separate datasets of taps.
the rst uses the raw source code to represent the test and the focal method.
the second dataset consists of abstracted taps in which the source code tokens are abstracted to limit the vocabulary and to increase the possibility of observing recurring patterns in the data.
as previous studies have shown this can lead to an increase in performance without losing the ability to automatically map back the abstracted tokens to the raw source code.
our abstraction process tokenizes the input determines the type for each individual token replaces the raw token with its abstractionand nally creates a map from the abstracted tokens back to the raw ones.
each tap is abstracted in isolation and has no a ect on the way other taps are abstracted.
we start by using the javalang tool to tokenize the input which allows us to analyze the type of token.
this tool transforms the java method into a stream of tokens which is then parsed by the same tool to determine their type e.g.
whether a token represents an identi er a method declaration etc.
.
we use these types in order to create an expressive representation that 1401on learning meaningful assert statements for unit test cases icse may seoul republic of korea test method focal method abstracted test method focal method abstracted assert statement abstracted test method focal method with idiomsabstracted assert statement with idiomsshouldcreateredmana mage.mana mana mage.mana.redmana assertplaceholder getred return red org.junit.assert.assertequals mana.getred method 0 ident 0.ident 1 ident 2 op 0 ident 0.ident 1.method 1 int 0 string 0 method 3 return ident 3 method 0 ident 0.ident 1 ident 2 op 0 ident 0.ident 1.method 1 string 0 method 3 return ident 3 ident 4.ident 5.ident 6.method 2 int 1 ident 2.method 3 org.junit.assert.assertequals ident 2.method 3 assert statement learning process figure overview of the abstraction process maintains the structure of the code.
in total there are di erent types of tokens that we use as part of our abstraction process complete list in our replication package .
when we encounter one of these types we replace the raw source code token with an abstraction term that indicates the type and number of occurrences of that type of token up to that moment.
in other words we use a numerical value to di erentiate tokens of the same type.
for example suppose we encounter a token that is determined to be a method call.
this token is replaced with the term method 0 since this is the rst type of that token we have encountered.
the next time we encounter a new method call in the same stream of tokens it would be assigned the term method 1. in the event where the same token appears multiple times within the tap it is given the same abstraction term and numerical value.
this means that if the same method is invoked twice in the test or in the focal method and it is represented with the term method 0 the abstraction will contain method 0 twice.
since all taps are abstracted in isolation we can reuse these terms when abstracting a new tap thus limiting the vocabulary size for our nmt model.
in addition to the abstraction terms that replace the raw source code tokens we take advantage of idioms in order to create an abstraction that captures more semantic information.
the inclusion of idioms can also help contextualize surrounding tokens since some abstracted tokens may be more likely to appear around a particular idiom.
in addition idioms help to prevent the exclusion of a tap due to the synthesis of an unknown token.
for instance consider the example of abstraction shown in figure .
in the middle of the gure it is possible to see that int 1 ident 4 ident 5 and ident 6 only appear in the abstracted assert statement but donot appear in the abstracted test and focal method.
if we only reliedon the abstraction we would be unable to resolve these tokens that are unique to the predicted assert statement.
therefore we keep the raw value of common idioms i.e.
the top tokens in our dataset in terms of frequency in our abstracted representation as shown in the bottom part of figure .
overall the vocabulary of the abstract taps comprises idioms plus typi ed ids while the vocabulary of the raw source code taps contains tokens.
.
sequence to sequence learning our approach applies sequence to sequence learning through a recurrent neural network rnn encoder decoder model to automatically learn assert statements within test methods.
this modelh1 h2 hn rnn cell lstm x1 x2 end start y1 ymci s1 s2 sm rnn cell lstm so!max test focal method assert statementencoder rnn a ention decoder rnn .. .... ...... copy mechanism figure the rnn bidirectional encoder decoder model is inspired by chen et al.
which attempts to predict a single line of code that has a predetermined place holder within the method.
the goal of this deep learning strategy is to learn a conditional distribution of a variable length sequence conditioned on a completely separate variable length sequence p ... m x1 x2 ... xn .
where nandmmay di er.
during training the model s encoder is fed the tokenized input sequence of the test method plus the context of the focal method as a single stream of tokens x1 ... xn .
the assert statement which is our target output sequence has been removed and replaced with a specialized token.
the decoder attempts to accurately predict the assert ... m by minimizing the error between the decoder s generated assert and the oracle assert statement.
this is accomplished by using the negative log likeli hood of the target tokens using stochastic gradient descent .
an overview of an rnn encoder decoder can be seen in figure .
.
encoder the encoder is a single layer bi directional rnn which is comprised of two distinct lstm rnns.
this bidirectionality allows the encoder to consider both the tokens that come before and the tokens that come after as context for the token of interest.
theencoder takes a variable length sequence of source code tokens x x1 x2 ... xn as input.
from these tokens the encoder produces a sequence of hidden states h1 h2 ... hn generated from lstm rnn cells.
these cells perform a series of operations to prop agate relevant information including previous hidden states to the next cell.
due to the bidirectionality of the encoder there exists a sequence of hidden states when considering the token sequence from left to right !hi f xi hi and right to left hi f xi0 hi0 .
for our model each hidden state can be formally described as the non linear activation of the current sequence token and the previously synthesized hidden state.
once the hidden state for each directional pass is found they are concatenated to derive the nalized hidden state hi.
the sequence of resulting hidden states is propagated through the model as the context vector.
the encoder also applies the regularization technique of dropout at a rate of .
.
.
attention mechanism the context vector c commonly referred to as an attention mechanism is computed as a weighted average of the hidden states from the encoder c n i ihi.
in this equation represents a vector of weights used to denote the in uence of di erent parts of the input sequence.
in this manner the model can pay greater attention 1402icse may seoul republic of korea cody watson michele tufano kevin moran gabriele bavota and denys poshyvanyk test method focal method shouldparseversion subject.parse version assertplaceholder isprintversionmode return printversionmode org.junit.assert.asserttrue subject.
isprintversionmode assert statement vocabulary v1 v3 v5 v11 subject asserttrue assert org assert version junit parse assertequals assert assert junit assert unk .
.
.. ........ copied from test method copied from vocabulary figure copy mechanism example to particular tokens of the input sequence when attempting to predict the output token i. the weights which in uence the attention mechanism are trained over time to help identify the patterns of contribution from di erent input tokens.
.
decoder and copy mechanism the decoder is a double layer lstm rnn that learns to take a xed length context vector and translates it into a variable length sequence of output tokens.
given a previous hidden state h i the previous predicted token i 1and the context vector cthe decoder generates a new hidden state that can be used to predict the next output token.
as done for the encoder we apply regularization to the decoder by using dropout at a rate of .
and the adam optimizer for learning with a starting learning rate of .
h i f h i i c the decoder generates a new hidden state each time it predicts the next token in the sequence until a special stop token is reached.
the hidden states are generated using the equation above.
however these hidden states are also used by the copy mechanism to help predict the appropriate output token.
in particular the copy mechanism works to calculate two separate probabilities.
the rst is the probability that the next predicted token in the output sequence should be taken from the vocabulary.
the second is the probability that the next predicted token in the output sequence should becopied from the input sequence.
with the ability to consider copying tokens from the input sequence to the output sequence we can arti cially extend the vocabulary of the encoder decorder rnn model for the raw dataset.
each sequence inferred from the model now has the ability to consider any predetermined vocabulary token in addition to any token from the input sequence.
the downside is that the copy mechanism is a trainable extension ofthe model that learns which input tokens should be copied over.
the bene t is that the model can better deal with rare tokens that would otherwise not appear in the vocabulary.
to further demonstrate how the copy mechanism works consider figure .
in this example we see the vocabulary tokens predicted for each time step t. for the purpose of this example we do not consider the translation of the separator tokens.
however in a real scenario our model would predict these tokens in identical fashion.
the rst predicted token for the output sequence is the org token which is copied from the vocabulary.
this process is repeated for the junit token the assert token and would continue for all further tokens but the last one i.e.
isprintversionmode .
the last token is not found anywhere in the vocabulary.
at time step the model recommends the unktoken to indicate that the highestprobability token does not exist within the de ned vocabulary.
in this case the copy mechanism is used to determine which input token has the highest probability to be the predicted token.
in the case shown in the example the context appended from the focal method contains this token and it is copied to the output sequence.
without the copy mechanism there would have been no way to resolve this example and it would have been discarded.
it is important to note that the copy mechanism is trained along with the network and requires no e ort on the end users.
also note that the copy mechanism is only applied to the raw dataset of source code tokens.
the reasoning is that after abstracting the source code all tokens are available within the vocabulary.
therefore the probability that a predicted token would be outside of the vocabulary and within the input sequence is rendering the copy mechanism useless.
rather our abstraction process servesas a pseudo copy mechanism of typi ed ids.
consider the previous example in figure 2where isprintversionmode was not found anywhere in the vocabulary.
in our abstraction process this token is abstracted into method 1 and since method 1 is a termcontained within our vocabulary the model has no problem inpredicting this token in the output assert statement.
then when we map the abstracted assert statement back to raw source code we replace method 1 with the token isprintversionmode without relying on the copy mechanism.
experimental design the goal of our study is to determine if a can generate meaningful syntactically and semantically correct assert statements for a given test method and focal method context.
additionally it isimportant for our approach to be lightweight in order to require as little overhead as possible if for example it is combined with approaches for the automatic generation of test cases.
the context of our study is represented by a dataset of taps for the abstracted dataset and taps for the raw dataset.
these datasets are further broken down into taps for training taps for validation and taps for testing in the abstract dataset.
likewise we had taps for training taps for validation and taps for testing in our raw dataset.
the di erences in number of examples between the two datasets is due exclusively to the removal of duplicates.
since the abstracted model reuses typi ed ids there is a greater chance for the duplication of taps within the abstracted dataset.
our evaluation aims at answering the research questions described in the following paragraphs.
rq is a tlas able to generate assert statements resembling those manually written be developers?
we assess whether a is a viable solution for generating semantically and syntactically correct assert statements.
therefore we perform experiments on real world test methods and determine if our model can pre dict the appropriate assert statement.
we use both datasets i.e.
raw source code and abstracted code to train the encoder decoder recurrent neural network model.
during training we use our validation set to determine the optimal parameterization of the nmt model complete list of used parameters available in .
we then evaluate the trained model on the test set which contains examples previously unseen in both the training set and the validation set.
1403on learning meaningful assert statements for unit test cases icse may seoul republic of korea we begin training our model on taps feeding the model the test method and associated focal method context.
we train our model until the evaluation on the validation set shows that the models parameterization has reached a near optimal state i.e.
the model is no longer improving the calculated loss for data points outside the training set .
this is a common practice to prevent the e ects of over tting to the training data.
our training phase results in two separate models one for predicting raw source code assert statements and the other for predicting abstracted asserts.
remember that when working with raw source code we also implement the copy mechanism which is not used for abstracted code.
in total the abstract model trained for hours while the raw model trained for hours.
the di erence in training time can be attributed tothe use and training of the copy mechanism in conjunction with the lack of abstraction.
once the model is trained inference is performed using beam search .
the main intuition behind beam search decoding is that rather than predicting at each time step the token with the best probability the decoding process keeps track of khypotheses with kbeing the beam size .
thus for a given input i.e.
test method focal method the model will produce kexamples of assert statements.
we experiment with beam sizes going from k tok 50at steps of .
given the assert statements predicted by our approach we consider a prediction as correct if it is identical to the one manually written by developers for the test method provided as input.
we refer to these asserts as perfect predictions .
when experimenting with di erent beam sizes we check whether a perfect prediction exists within the kgenerated solutions.
we report the raw counts and percentages associated with the number of perfect predictions.
note that while the perfect predictions certainly represent cases of success for our approach this does not imply that the imperfectpredictions all represent failure cases i.e.
the generated asserts are not meaningful .
indeed for the same test focal method di erent assert statements could represent a valid solution.
therefore we sample imperfect predictions and manually analyze them tounderstand whether while di erent from the original assert statements written by the developer they still represent a meaningful prediction for the given test method.
in particular we split the imperfect predictions into four sets based on their bleu score value.
the bleu score is a well known metric for assessing the quality of text automatically translated from one language to another .
in our case the two languages are represented by i the test method and the focal method and ii the generated assert statement.
we use the bleu variant meaning that the bleu score is computed by considering the grams in the generated text as previously done in other software related tasks in the literature .
the bleu score ranges between and with indicating in our case that the generated assert is identical to the reference one i.e.
the one manually written by developers .
we use the bleu score ranges and to split the imperfect predictions.
then we randomly selected instancesfrom each set and the rst author manually evaluated them to determine if the generated assert statement is meaningful in the context of the related test focal methods.
to avoid subjectiveness issues the instances were also randomly assigned to four other authors each who acted as second evaluator for each instance.con icts i.e.
cases in which one of the two evaluators classi ed the assert statement as meaningful while the other did not arose in a single case that was solved through an open discussion.
wereport the number of meaningful assert statements we found in the manually analyzed sample as empirical evidence that imperfect assert statements could still be useful in certain cases.
note that while there might be authors bias in assessing the meaningfulness of the imperfect assert statements i.e.
authors may tend to be too positive in evaluating the meaningfulness of the asserts we make our evaluation publicly available in the replication package to allow the reader to analyze the performed classi cation.
rq which types of assert statements is a tlas capable of generating?
after obtaining the perfect predictions from rq w e analyze the types of assert statements our model can generate.
in particular we analyze the taxonomy of assert statements generated by our approach in the context of perfect predictions to determine the types of assert statements the model is able to correctly predict.
we then report the raw counts and the percentages for each type of assert statement the model can perfectly predict.
note for this evaluation we only report results for k since we found that already with this beam size the model was able to generate all types of assert statements in the used dataset.
rq does the abstraction process aid in the prediction of meaningful assert statements?
remember that while our abstraction model generates abstracted asserts we can map them back to the raw source code at no cost to the developer.
thus we can check whether the generated assert is a perfect prediction as we dofor the raw source code.
besides comparing the performance of thetwo models we also analyze whether they produce complementary results by computing the following overlap metrics ppr a ppr ppa ppr ppa ppr a ppr ppa ppr ppa ppa r ppa ppr ppr ppa the formulas above use the following metrics ppr ppa represents the set of perfect predictions generated using the raw abstracted source code dataset ppr ameasures the overlap between the set of perfect predictions generated by using the two datasets ppr ameasures the perfect predictions generated on the raw source code but not when using abstraction vice versa forppa r .
rq what is the e ect of using the copy mechanism in our model?
with the addition of the copy mechanism we can perfectly predict assert statements which contain tokens only found in the input sequence and not in the vocabulary.
here we wantto quantify the e ect of the copy mechanism and see how manyassert predictions we would be capable of producing without its usage.
therefore we analyze the perfect prediction set from the raw source code model.
if the perfect prediction contains a token not found in the vocabulary then we know that its generation was possible due to the usage of the copy mechanism.
we report the raw counts and percentages of the number of assert statements that were resolved thanks to the use of the copy mechanism.
rq does a tlas outperform a baseline frequency based approach?
as output of rq 2we de ned a taxonomy of assert statements that our approach is able to correctly generate in theperfect predictions.
we noted that there are eight types of assert 1404icse may seoul republic of korea cody watson michele tufano kevin moran gabriele bavota and denys poshyvanyk table prediction classi cation beam sizeraw model abstract model peferct prediction percentageperfect prediction countsperfect prediction percentageperfect prediction counts .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
statements that the model is capable of generating.
however the model also predicts the variables and method calls contained within the assert statement.
therefore we want to determine if the most frequently used assert statements found within our dataset e.g.
assert true could be used to create a frequency based approach that outperforms our learning based approach.
we analyze the duplicated assert statements generated in our perfect prediction set.
this means that the model generated the same correct assert statement for di erent test methods provided as input.
it is important to highlight here that while the same assert statement can be used in di erent test methods this does not imply that we have duplications in our datasets.
indeed while the same assert statement can be used in di erent taps the test focal methods are guaranteed to be unique.
the developed frequency based approach takes the most commonly found assert statements and applies them as a solution for a given test method.
in particular we take the top kmost frequent assert statements and test if any of them represents a viable so lution for each test method in the test set.
in this evaluation we set the same kfor both approaches i.e.
the frequency based and the learning based ones .
for example assuming k this means that for the frequency based approach we use the ve most frequent assert statements as predictions while for the learning based approach we set beam size to ve.
we report the raw counts of the frequency based approach as compared to our nmt based approach.
we compare the two approaches at k .
rq what is the inference time of the model?
our last research question speaks to the applicability and ease of use of our model.
when developing test cases within a software project itis unreasonable to expect the developer to spend a considerable amount of time to set up and run an inference of the model.
therefore we performed a timing analysis to assess the time needed to generate assert statements for a variety of beam sizes.
in particular we used k 1tok 50with an increment of to test the trade o between the timing of the model s inference and the increased prediction results of the model.
we record the results in number of seconds and map the increased performance against the increased time.
we do not con sider the time it may take for a developer to look at all resulting predictions of assert statements for di erent beam sizes.
note that we do not consider the training time since this is a one time cost that does not a ect the usability of the approach.
02550edit operations raw code 02550edit operations raw code abstracted code figure edit distance between imperfect predictions and ground truth truncated tail of higher edit distances experimental results rq rq rq ability to generate meaningful assert statements comparison between raw and abstracted dataset and usefulness of copy mechanism.
table 1shows the perfect prediction rate for both the raw model and the abstract model for beam sizes and at increments of rq rq .
as expected the perfect prediction rate increases using larger beam sizes with a plateau reached at beam size i.e.
only minor increases in performance are observed for larger beam sizes .
when using beam size equal to for the model trained tested with the raw dataset our approach generates .
perfect predictions resulting in over .3k correctly generated assert statements.
the average bleu score for the asserts predicted when only considering the top recommendation i.e.
beam size is .
.
we also found that the copy mechanism helps the raw model in generating perfect predictions rq .
indeed we determined how many perfect predictions require the use of the copy mechanism nding that when using beam size equals our approach is able to perfectly predict examples by using the copy mechanism and when only relying on the vocabulary.
this means that the copy mech anism is responsible for resolving perfect predictions which constitutes .
of the perfect prediction rate.
for the abstract model the percentage of perfect predictions goes up to .
5k correctly generated asserts .
here the average bleu score is .
.
note that we mention the bleu scores for completeness but do not perform a full evaluation using this metric.
of particular note is the substantial bump in perfect predictions that we obtain as result of increasing the beam size to ve for both models especially for the abstracted one.
for the latter in .
oftest focal methods provided as input one of the generated asserts isidentical to the one manually written by the developer for a total of .9k perfectly predicted asserts .
this indicates the potential of our approach in an automatic code completion scenario in which the developer could easily pick one of the ve recommended asserts.
as mentioned in section we also analyze the complementarity of the perfect predictions generated by the raw and the abstracted models when using beam size equals .
in terms of overlap i.e.
ppr a we found that only examples were captured and perfectly predicted by both models.
also .
of the perfect predictions are only generated by the raw model ppr a while .
can only be obtained by using the abstracted model ppa r .
this shows a surprising complementarity of the two models that are able to learn di erent patterns in the data.
the combination of 1405on learning meaningful assert statements for unit test cases icse may seoul republic of korea perfect prediction generated by the abstract model .
method 0 org .
ident 0 .
ident 1 .
conf .
ident 2 ident 3 new org .
ident 0 .
ident 1 .
conf .
method 1 ident 3 .
setname org .
ident 0 .
ident 1 .
conf .
ident 4 .
ident 5 assertplaceholder getname return name .
org .
junit .
assert .
assertequals org .
ident 0 .
ident 1 .
conf .
iden t 4 .
ident 5 ident 3 .
getname perfect prediction unabstracted .
testname org .
kefirsf .
bb .
conf .
namedvalue namedvalue new org .
kefirsf .
bb .
conf .
namedvalue namedvalue .
setname org .
kefirsf .
bb .
conf .
namedvaluetest .
name assertplaceholder getname return name .
org .
junit .
assert .
assertequals org .
kefirsf .
bb .
conf .
namedvaluete st .
name namedvalue .
getname figure example of a perfect prediction made by the abstract model and its unabstructed mapping to actual code these two di erent representations for example by using a model with two encoders one per representation and a single decoder may be an interesting direction for future work.
however the overall higher performance in both bleu score and perfect prediction rate of the abstract model shows that it is better able to translate a meaningful assert statement from the test and focal method context.
this is likely due to the di erent way in which the two models see the out of vocabulary tokens.
in the raw dataset they are all represented as unknown tokens while in the abstracted dataset they are represented with the associated type e.g.
method var int etc.
.
when dealing with out ofvocabulary tokens this helps the abstracted model in learning patterns such as a method token is likely to follow a var and a .
token.
for the raw model this only results in observing unk .
unk hindering its ability to learn meaningful patterns in these cases.
due to the better performance ensured by the abstract model the subsequent analyses are performed using this model.
here we discuss an interesting example generated by our abstracted model.
figure 6presents the abstracted contextual method in line and the abstracted assert statement in line .
lines and 4are the result of the unabstraction process where we map back the abstracted tokens into raw source code.
in this example the test method is creating a new object namedvalue and setting the name attribute of this object.
the test method contains the method call getname which our heuristic identi es as the focal method and is appended to the end of the test method.
the model then generates an assert statement that compares the name attribute of the new object with the results from the getname method call.
indeed the model learns the relationship between the test and focal method in order to generate a meaningful assert statement which appropri ate tests the method s logic.
this assert statement is a nontrivial example of the model determining what type of assert statement togenerate as well as the appropriate parameters the assert statement should contain.
concerning the manual inspection of the imperfect predictions we found that of them can represent a valuable assert statement for the provided contextual method despite them being di erent from the asserts manually written by developers.
notethat while a might look like a negative result it is important to understand that these results are in addition to the already perfectly predicted assert statements.
the full evaluation of the cases is available in our replication package .
here we discuss a representative example for a provided test focal method where our approach generated the assert statement assertsame input result while the assert manually written by the developer was assertequals blablabla result .
the input object is present in the test method and contains indeed the value blablabla .
basically our model generated an easier to maintain assert since changes to the value assigned to the input objectstable types of predicted assert statements assert type count total in dataset assertequals asserttrue assertnotnull assertthat assertnull assertfalse assertarrayequals assertsame table learning based vs. frequency based beam sizenumber of perfect predictions frequency model abstract model do not require changes to the assert statement.
concerning thedi erence between assertsame and assertequals the former compares two objects using the operator while the latter uses theequals method that if not overridden does also perform the comparison using the operator.
although we have shown that our model can produce meaningful results outside of the perfect predictions we wanted to understand how far are the imperfect predictions from the manually written assert statements.
therefore for each imperfect prediction generated by the abstract model with k we computed the number of tokens one needs to change add or delete to convert it into the manually written assert.
we found that by only changing one token it is possible to convert .
of the imperfect assert statements i.e.
instances into perfect predictions.
also the median of indicates that in half of the cases changing only three tokens would be su cient.
note that the average number of tokens in the generated assert statements is .
.
figure 5shows the distribution of edit changes needed for the imperfect predictions to become perfect predictions.
summary for rq rq rq .a s abstracted model is able to perfectly predict assert statements according to a developer written ground truth .
and .
of the time for top and top predictions respectively.
conversely the model operating on raw source code with the copy mechanism achieveda perfect prediction rate of .
and .
for top and top predictions respectively.
this indicates the abstracted model performs better overall.
however we also found that models had a relatively high degree of orthogonality with .
of all perfect predictions generated by the raw model and .
generatedby the abstracted model illustrating that the copy mechanism allowed for the prediction of a unique set of assert statements.
1406icse may seoul republic of korea cody watson michele tufano kevin moran gabriele bavota and denys poshyvanyk rq which types of assert statements is atlas capable of generating?
we also analyzed the types of junit4 assert statements that were perfectly predicted.
here we use the perfect predictions generated using the abstract model and beam size equals one.
table 2shows that our approach was able to correctly predict eight di erent types of assert statements with assertequals and asserttrue being the most commonly predicted type of assert statement.
note that some junit4 assert types e.g.
assertnotsame andassertfail are not generated by our model because they were not present in our dataset.
as it can be seen in table the distribution of assert statements we are able to predict is similar to the one of the assert statements in the entire dataset.
this result mitigates the possible threat that our approach is only successful in generating a speci c type of assert statement.
indeed as shown in table the lack of a uniform distribution of data points in the dataset from which a is learning seems to be the main reason for the skewed distribution of correctly predicted asserts.
the main exception to this trend is represented by the assertthat statements.
we hypothesize that assertthat statements are more di cult to predict due to the nature of the assert itself.
these types of asserts compare a value with a matcher statement which can be quite complex since matcher statements can be negated combined or customized.
despite the complexities ofassertthat statements the model is still able to perfectly predict .
of the ones seen in the testing set.
summary for rq .we found that assertequals was the most common type of assert generated matching the distribution we were learning from.
our analysis showed that a is capable of learning every type of assert statement found in developer written test cases.
rq does atlas outperform a baseline frequency based approach?
in this research question we explore whether our abstract model outperforms a baseline frequency based approach see section .
table 3shows the results of this comparison.
we note that our dl based approach outperforms the frequency based approach at each experimented beam size.
the di erence in terms of performance is substantial resulting in .
beam size to .
beam size times more perfect predictions generated by our approach.
for example when only considering the top candidate assert statement for both techniques a correctly predicts assert statements as compared to the of the frequency based model.
the achieved results indicate that a is in fact learning relationships based on hierarchical features and not being overwhelmed by repetitive assert statements.
we also want to note that a encompassed a majority of the assert statements found by the frequency based baseline.
therefore we do not combine a frequency based approach with a and believe our implementation to be superior on its own.
summary for rq .a is able to signi cantly outperform a frequency based baseline prediction technique by a factor of .
rq what is the inference time of the model?
our last research question assesses the time required by our approach to generate meaningful assert statements.
given the previously discussed performance of the experimented models we computed .
.
.
.
beam size0510 50time in seconds figure seconds per assert generation the generation time on the abstract model.
it is important to note the reported time does not include the code abstraction nor the mapping of the prediction back to source code although these operations are typically more e cient than inference.
figure 7shows the increase in time based on the number of solutions the model generates.
these timings concern the generation of assert statements for test focal methods provided as input.
the reported time is in seconds per provided input and includes the generation of all assert statements in the given beam size.
for example assuming a beam size of it would take around .
seconds to generate all predictions for a particular test focal method.
these results were computed using a single consumer grade nvidia rtx gpu.
summary for rq .we found that with a beam size of we can generate all predictions in .
seconds per test method focal method pairing.
when increasing beam size we nd that the time needed to generate assert statements appears to scale linearly.
threats to validity construct validity threats concern the relationship between theory and observation and are mainly related to sources of impre cision in our analyses.
we automatically mined and parsed the taps used in our study.
in this process the main source of noise is represented by the heuristic we used to identify the focal method for a given assert statement.
as said in a real usage scenario this information could be provided by the developer who wrote the test or by the automatic test case generation tool.
despite the presence of introduced noise our approach was still able to generate meaningful asserts con rming the robustness of our nmt model.
internal validity threats concern factors internal to our study that could in uence our results.
the performance of our approach depends on the hyperparameter con guration that we report in ouronline replication package .
however given how computationallyexpensive the hyperparameter search was we did not investigate the impact of the copy mechanism across all con gurations.
external validity threats concern the generalizability of our ndings.
we did not compare atlas with state of the art test casegeneration techniques using the heuristics described in section 2to de ne appropriate asserts.
this comparison would require a manualevaluation of the correctness of the asserts generated by atlas and by the competitive techniques for automatically generated tests likely on software of which we have little knowledge assuming open source projects .
furthermore we would have to make the subject systems executable e.g.
as required by evosuite which is 1407on learning meaningful assert statements for unit test cases icse may seoul republic of korea known to be di cult.
hence this would not allow us to scale such an experiment to the size of our current evaluation.
indeed our main goal was to empirically investigate the feasibility of a learning based approach for assert statement generation.
comparing combining the two families of approaches is part of our future work.
finally we only focused on java programs and the junit framework.
however atlas s learning process is language independent and its nmt infrastructure can easily be ported to other programming languages.
conclusion and future work in this work we mined over 9k github projects to identify test methods with their related assert statements.
we then used a heuristic to identify the focal method associated with an assert statement and generated a dataset of test assert pairs taps composed by i an input sequence of the test and focal method and ii a target sequence reporting the appropriate assert statement for the input sequence.
we used these taps to create a nmt based approach called atlas capable of learning semantically and syntactically correct asserts given the context of the test and focal methods.
we found that the model was capable of successfully predicting over of the assert statements developers wrote by only using the top ranked prediction.
when looking at the top predictions the percentage of correctly generated assert statements grew up to .
we also showed that among the imperfect predictions meaning the scenario in which atlas generates assert statements di erent from the ones manually written by developers there are assert statements that either represent a plausible alternative the the one written by the developer or can be converted into the latter by just modifying a few tokens 3in of cases .
finally some of the limitations of our approach as well as the extensive empirical study we conducted provide us with a number of lessons learned that can drive future research in the eld raw code vs. abstracted code our results show that through the abstraction mechanism applications of nmt on code can ensure better performance as already observed in previous studies .
more interestingly we found that the two code representations arequite complementary and allow our approach to generate di erentsets of perfect predictions .
this points to the possibility of combining the two representations into a single model that could bene t from an architecture having two encoders one per representation and a single decoder.on the possibility of generating multiple assert statements we investigated this research direction while working on atlas.
the main problem we faced was the automatic identi cation of the part of test method body that it is relevant for a given assert.
indeed while with a single assert we can assume that the whole method body is relevant this is not the case when dealing withmultiple asserts.
here a possible heuristic could be to consider the statements preceding the assert statement a1 but coming after the previous assert a0 as relevant for a1.
however it is unlikely that the statements coming before a0are totally irrelevant for a1.
another possibility we considered was to apply backward slicing on each assert statement but unfortunately this resulted in scalability issues and in well known problems related to the automaticcompilation of open source projects .
approaching this problem is a compelling direction for future work.integrating a learning based approach in tools for automatictest case generation as discussed earlier we foresee two possible usages for atlas.
first it can be used as a code completion mechanism when manually writing unit tests in the ide.
second it could be combined with existing tools for automatic test case generation .
we currently lack empirical evidence to substantiate any claim on the e ectiveness of atlas in improving automatically generated tests which would be an important rst step prior to integration.
additionally before combining atlas with existing tools it is necessary to deeply understand the cases in which the two families of approaches i.e.
the ones integrated in the test case generation tool and the learning based one succeed and fail.
in this way learning based approaches could be used only when needed i.e.
when the standard approach implemented in the test case generation tools is likely to fail thus increasing the e ectiveness of the generated tests.
studying and comparing the strengths and weakness of the two families of techniques is part of our future research agenda.
the automatic generation of meaningful assert statements is a compelling problem within the software engineering community.
we showed that a learning based approach could help aid in this problem and opened a complementary research direction to the one already adopted in automatic test case generation tools .