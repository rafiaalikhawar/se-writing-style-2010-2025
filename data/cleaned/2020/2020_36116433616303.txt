oom guard towards improving the ergonomics of rust oom handling via a reservation based approach chengjun chen fudan university shanghai china ant group hangzhou china cjchen20 fudan.edu.cnzhicong zhang fudan university shanghai china zhicongzhang21 m.fudan.edu.cnhongliang tian ant group hangzhou china tate.thl antgroup.com shoumeng yan ant group hangzhou china shoumeng.ysm antgroup.comhui xu fudan university shanghai china xuh fudan.edu.cn abstract out of memory oom is an exceptional system state where any further memory allocation requests may fail.
such allocation failures would crash the process or system if not handled properly and they may also lead to an inconsistent program state that cannot be recovered easily.
current mechanisms for preventing such hazards highly rely on the manual effort of the programmers themselves.
this paper studies the oom issues of rust which is an emerging system programming language that stresses the importance of memory safety but still lacks handy mechanisms to handle oom well.
even worse rust employs an infallible mode of memory allocations by default.
as a result the program written by rust would simply abort itself when oom occurs.
such crashes would lead to critical robustness issues for services or modules of operating systems.
we propose oom guard a handy approach for rust programmers to handle oom.
oom guard is by nature a reservation based approach that aims to convert the handlings for many possible failed memory allocations into handlings for a smaller number of reservations.
in order to achieve efficient reservation oom guard incorporates a subtle cost analysis algorithm based on static analysis and a proxy allocator.
we then apply oomguard to two well known rust projects bento and rcore.
results show that oom guard can largely reduce developers efforts for handling oom and incurs trivial overhead in both memory space and execution time.
ccs concepts software and its engineering software reliability .
corresponding author.
permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
copyrights for components of this work owned by others than the author s must be honored.
abstracting with credit is permitted.
to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
request permissions from permissions acm.org.
esec fse december san francisco ca usa copyright held by the owner author s .
publication rights licensed to acm.
acm isbn .
.
.
.
out of memory static analysis reservation software reliability acm reference format chengjun chen zhicong zhang hongliang tian shoumeng yan and hui xu.
.
oom guard towards improving the ergonomics of rust oom handling via a reservation based approach.
in proceedings of the 31st acm joint european software engineering conference and symposium on the foundations of software engineering esec fse december san francisco ca usa.
acm new york ny usa pages.
.
introduction out of memory oom is a hazardous state where the system cannot allocate new memory.
programs suffering oom may result in aborting data corruption and even catastrophic system crashes .
nevertheless handling allocation failures remains a challenging issue for software developers .
on one hand the code snippets with oom risks may widely exist in a project but they are often insufficiently tested because oom is rarely triggered in practice .
on the other hand the oom handling code itself may require additional memory space and suffer a second oom .
this work studies the oom issue of an emerging programming language rust.
rust has attracted many system developers due to its advantages in memory safety and efficiency.
different from c c apis that either return null or throw exceptions when oom occurs the stable version of rust does not expose any interfaces of oom handling to developers.
one major reason is that it is not easy for developers to handle oom well.
therefore rust apis employ an infallible mode for memory allocation by default that simply aborts the program if suffering oom.
however the drawback is obvious i.e.
developers lose their flexibility to design programs that can handle or survive oom.
the flaw is unacceptable for critical servers or operating systems that have little tolerance for crashes .
an intuitive way to help rust escape this predicament is to expose fallible apis for memory allocation.
actually the idea has already been proposed recently and is under development in nightly rust .
nevertheless it suffers from critical limitations because developers should at least face similar challenges as traditional c c developers.
even worse any inappropriate implementation of the oom handling code may lead to undefined behaviors and esec fse december san francisco ca usa chengjun chen zhicong zhang hongliang tian shoumeng yan and hui xu undermine the memory safety of rust.
another idea is to reserve sufficient memory space in the program entry or the beginning of some critical code regions e.g.
based on banker s algorithm .
such a mechanism can prevent the program from suffering oom when executing a snippet of critical code.
however there is still a critical problem to be addressed i.e.
how to estimate the least required memory space for executing the code?
the problem is generally undecidable .
our paper proposes a novel reservation based approach for handling oom namely oom guard.
via oom guard developers can selectively annotate any function that should be spared from crashes caused by oom and our approach then automatically infers and reserves the amount of memory required by the function.
the core components of oom guard include a memory cost analyzer and a proxy allocator.
the cost analyzer can extract the parameterized memory cost expression of a function based on static analysis.
while encountering code snippets that cannot be analyzed e.g.
implicit bounded loops or dynamic trait function calls we employ a multi level reservation mechanism.
oom guard can identify these situations and inform developers to make further annotations to reserve memory spaces for them separately e.g.
making an extra reservation for each iteration or recursion during execution.
oom guard automatically inserts memory reservation code based on the cost expression at the beginning of the function through macro expansion.
all subsequent memory allocation and deallocation operations of the function will be handled by the proxy allocator during runtime.
in this way oom guard can guarantee that the oom is only possible to occur in reservation instructions and release developers from handling the oom risk of all allocation sites.
in the experiment study we evaluate the effectiveness of oomguard with two real world rust systems with infallible allocations bento and rcore.
we first modify these systems to the oom guard version and study the usability of our approach.
results show that compared to the fallible mode promoted by nightly rust developers only need to modify less than lines of code.
our further pressure test shows that the oom guard version is resilient to oom.
besides we also study the cost analysis accuracy and overall performance of our approach.
results show that the average peak memory usage overheads are both less than for bento and rcore and the average overhead of execution time is for bento and for rcore.
we summarize the contribution of this paper as follows.
this paper serves as the first attempt to study the oom problem of rust caused by its infallible mode.
in comparison with the fallible model promoted by nightly rust our proposed approach should be more convenient to developers and less error prone.
our approach incorporates a set of subtle designs especially an accurate memory cost analyzer and a proxy allocator.
for cost expression depending on conditional branches we mainly retain the cost expression by detecting ordinal relationships.
if we overestimate the cost due to the absence of an ordinal relationship our proxy allocator can still avoid memory waste by reusing the overestimated memory blocks.
figure sample method of rust slice with implicit memory allocation from official rustdoc1 experimental results with real world systems show our approach is efficient in both peak memory usage and execution time.
we implement oom guard as an semi automated toolchain.
our implementation consists of over lines of rust and c code.
we believe it would be useful to facilitate the community toward solving oom related problems.
background this section presents the challenges of oom handling and techniques adopted by rust in handling oom.
.
challenges of oom handling oom is a situation where the newly requested memory cannot be allocated by the system.
in general processes suffering oom would lead to an exceptional process state that should be carefully handled.
however since triggering oom requires an extreme system state of low memory such allocation failures are sometimes ignored or mishandled in practice .
for example cve2021 and are all oom bugs missing allocation failure handling which may lead to null pointer dereference cve and are another type of oom bugs with mishandled allocation failures which may result in unexpected abort during recovery.
handling oom is challenging for developers because there could be many allocation sites in a program.
besides obvious memory allocations e.g.
malloc in c or new in c there are also other implicit allocation sites.
for example the push method of vector may dynamically adjust the reserved memory space for the container.
furthermore some allocation sites can hardly be noticed unless developers read the code carefully.
for example the sort figure and sort by methods of rust slice all require temporary storage half the size of a slice.
such allocation failures are often ignored by developers.
to release developers from tedious oom handling work and mitigate oom risks too small to fail is a promising solution adopted by linux.
such a mechanism aims at no failure for small memory allocation requests.
linux approaches the objective via an over commit and oom killer mechanism.
the over commit mechanism does not actually allocate the physical memory until 734oom guard towards improving the ergonomics of rust oom handling via a reservation based approach esec fse december san francisco ca usa the program accesses the newly allocated memory space.
therefore the allocation request is always successful as long as there are available memory address spaces e.g.
up to 248or 128t for x86 .
if the physical memory is not enough the oom killer will select one process to kill based on a fitness evaluation mechanism to free memory.
however the side effect is also obvious.
for example the oom killer sometimes kills innocent processes and attackers may leverage the mechanism to attack other processes running on the same computer.
besides this mechanism is subject to deadlocks in a low memory situation which may lead to a full system lockup .
therefore too small to fail is not a silver bullet for oom and gets complained about a lot in history .
.
techniques of oom handling in rust .
.
infallible allocation.
rust by default employs infallible allocation i.e.
the allocation error is not exposed or observable to developers.
for example the push method of vecinvolves memory allocations.
if there s no enough capacity in the vec push will allocate new space twice the original capacity.
but users of push cannot know if the allocation fails.
instead push directly aborts the program within its implementation.
since the low level memory allocation method rust alloc is an unsafe method mishandling oom may cause memory safety bugs.
therefore such an infallible mode is beneficial to the memory safety purpose of rust.
informally an infallible heap allocation function is one of the following three types.
it is a function defined by rust s alloc crate2that involves heap memory allocations and causes panics when the allocation fails such as vec push box new and arc new .
it is a user specified function that involves heap memory allocations and causes panic when the allocations fail.
it is a function that may invoke infallible heap allocation functions.
.
.
fallible allocation.
recently nightly rust adds new fallible allocation apis to its standard libraries e.g.
try push that returns a result object for handling.
nevertheless manually transferring existing infallible code to fallible code with these apis is labor intensive and error prone.
for example figure 2a 2b demonstrates the usage of fallible allocation apis for the bread function from bento.
the original version employs three infallible allocation functions arc new arrwrapper new andhashmap insert .
to transfer bread to fallible mode developers need to rewrite these called functions into fallible mode functions try new and try insert .
as shown in figure 2a this also requires developers to modify all functions recursively in the call chains of bread including the function signature and corresponding callsites.
the developer then needs to make sure allocation failures in any allocation site in the call chain be handled carefully hence they can propagate to the upper level bread recursively.
finally they get a fallible bread which will return a bentoerror generated based on another newly added from method when encountering oom.
as shown in this example even translating a single function from infallible mode to fallible may involve dozens of lines of code furthermore it is challenging to implement a correct and safe failure handling routine .
in this example generating an error message with string from still needs additional heap memory and may result in a second oom.
overview of oom guard .
objective of oom guard although rust defaults memory allocations to the infallible mode some software applications may still prefer the fallible mode.
for example rust rfc mentions infallible mode as an inappropriate approach for embedded systems and garbage collectors and other applications like gecko browser engine also prefer fallible mode when implementing some features due to user experience considerations.
in order to meet the need of memory allocation failure handling while mitigating the risk of oom handling errors we propose oom guard.
oom guard is a semi automated mechanism that can help rust programmers transfer infallible code snippets to fallible mode handily and safely.
in this way it can improve the ergonomics of oom handling in rust programs.
.
approach overview oom guard approaches the goal via reserving sufficient memory for infallible allocations to guarantee their success.
in this way when developers employ fallible mode to a target function they only need to enable oom guard and handle reservations for it instead of transferring all infallible allocations in the call chain into fallible mode.
figure overviews the major process of oom guard.
developers or oom guard users may select candidate functions to protect based on their needs and annotate the function with oom guard macro.
subsequently the program can achieve the anticipated functionality through two rounds of compilation with the assistance of oom guard.
first oom guard performs automated memory cost analysis on the target functions based on the results generated from the first round of compilation obtaining their memory cost expressions.
during the second round of compilation the annotated procedural macros will be expanded and generate the corresponding reserved statements by parsing these expressions.
for example figure 2c shows how developers can use oomguard to fix the previous oom issue of figure 2b.
developers mainly need to add a procedure macro before thebread function which can parse the source code and be automatically expanded to insert code snippets for memory reservation during compilation.
if the reservation succeeds all subsequent allocations will be based on the reserved memory.
this can be achieved via another macro that specifies a new proxy allocator as the global allocator for the program.
if the reservation fails the allocation failures can be captured and handled by the function s caller through the returned result also need an implementation of the from method like figure 2b for the used error type .
thus oom guard turns bread into the fallible mode with a simple annotation and only requires the developer to handle the reservation failures.
as shown in figure 2a it is obvious that the revision requires fewer changes of code than the manual modification.
735esec fse december san francisco ca usa chengjun chen zhicong zhang hongliang tian shoumeng yan and hui xu bread arc arrwrapper new arrwrapper new hashmap insert hashbrown insertalloc aligned vecbox new rust alloc ...... ...... ...... ......caller functions that need to modify signature if modifying manually functions that need to modify signature if with oom guard callsites that need to be handled if modifying manually callsites that need to be handled if with oom guardfninsert self k k v v self .base.insert k v fntry insert self k k v v result allocerror self .base.try insert k v ?
callsite should be modified accordingly modify signatureexample a the usability comparison between oom guard and existing fallible mode.
implfrom tryreserveerror forbentoerror fnfrom err tryreserveerror bentoerror bentoerror alloc fail string from ..error message need allocation second oom may occur fnbread self bno u64 result bufferhead bentoerror ... allocation free instructions letbh buf arrwrapper new ... ?
allocation letnew arc arc new bh buf allocation cache lock.insert bno arc downgrade new arc cache lock is a hashmap and need allocation when expending letbh buf arrwrapper try new ... ?
letnew arc arc try new bh buf ?
cache lock.try insert bno arc downgrade new arc ?
returnok bufferhead new new arc bno b manual modification with fallible apis.
pubstaticallocator oomguardallocator new defaultallocator fnbread self bno u64 result bufferhead bentoerror ...calculative statements letreserve array letguard life ti me allocator.reserve reserve array ?
automatically generated during macro expansion ... allocation free instructions letbh buf arrwrapper new ... ?
letnew arc arc new bh buf cache lock.insert bno arc downgrade new arc returnok bufferhead new new arc bno c modification with oom guard.
figure example from bento fs that demonstrates how to modify a function from infallible mode to fallible mode.
source code with oom guard macro developer macro expansionnew code with mem reservation mem cost analysisexecutable with mem reservationcompilationdefault allocatorproxy allocatorannotate extra annotation notification figure overview of oom guard.
the two core components of oom guard include a memory cost analyzer and a proxy allocator .
the cost analyzer extracts the memory cost of the target function as a tuple of multiple different sized blocks e.g.
x which means the function requires memory block of xbytes and memory blocks of 8bytes where x is a parameter or symbolic value that can be concretized when the function is called.
note that each function may involve multiple allocation sites with different sized memory blocks.
rather than extracting a simple maximum cost we prefer employing such detailed memory layout information for the reservation because it is useful for achieving efficient memory block management and reuse during execution.
our cost analyzer is based on static analysis instead of dynamic analysis because static analysis is sound and more reliable for our problem.
to date there are still many situationsthat static cost analysis cannot handle like unbounded loops or dynamic dispatches.
in order to deal with such problems and make the results of cost analysis sound oom guard adopts a multi level reservation mechanism i.e.
perform deeper reservations through extra annotations when encountering unsolvable situations.
oomguard will give developers the information about extra annotations all at once to handle these situations quickly.
section will provide a more detailed design of our cost analysis approach.
another important part to achieve oom guard is to implement the reservation mechanism for the allocator used in the programs.
in this paper we design a proxy allocator to achieve the reservation mechanism which can handle subsequent allocation and deallocation operations for oom guard functions annotated with and is ineffective for other functions.
we design the proxy allocator to hold a reference to the program s default allocator and leverage it to request memory from the system thus the users can employ it to any rust programs directly even though they have their own allocator.
there are three essential phases for proxy allocation a reservation phase that the allocator reserves the required memory blocks of each size an execution phase that the allocator performs allocations and deallocations based on the reserved blocks and an exit phase which updates the remaining information.
section presents more details of our proxy allocator design.
736oom guard towards improving the ergonomics of rust oom handling via a reservation based approach esec fse december san francisco ca usa .
merits over current solution the current solution of nightly rust requires developers to manually make tedious modifications and handle abundant allocation failures returned by fallible apis.
oom guard is better than the approach of nightly rust in several aspects.
most importantly it releases developers from handling such widely existing but rarely occurred oom situations.
users of oom guard only need to annotate some top level functions and oom guard will automatically take over all memory allocations of the call chains.
therefore it can avoid aggravating code complexity.
particularly it avoids leaking implementation details from function interfaces such as changing thesort method of figure to fallible mode.
it can also avoid breaking some standard rust interfaces e.g.
drop trait that may also involve small memory allocations or suffer oom.
cost analysis approach .
cost expression and tuple in our approach a cost expression follows the following grammar in backus naur form .
costexpr phiexpr arithexpr leafexpr leafexpr const var field arithexpr costexpr binop costexpr phiexpr phi costexpr costexpr field var .
const field .
const binop ... const number var identifier the grammar defines the format of cost expressions recursively.
in general a cost expression can either be a phi expression of multiple cost expressions the arithmetic of multiple cost expressions or a simple leaf expression.
the leaf expression can be a constant number a variable or a field of a variable.
for example phi x 4is a cost expression for the function a of figure 4c.
we finally convert the cost expression into a tuple of different sized memory blocks by grouping the sub expressions with the same block size.
to this end we should remove the phi operator from the expression by retaining the operand expression that is always larger.
if such an ordinary relationship does not exist we simply sum all operand expressions of the phi node.
for example for an expression phi x we can remove phi and convert it to x because there is no ordinary relationship between xand .
note that the phi expression must be maintained in the intermediate results during analysis to enable its capacity to perform a set function.
thereby it can effectively prevent repetitive superposition of identical constants for the situation without an ordinary relationship.
further we can convert it to a tuple x by grouping the two sub expressions with block size .
.
cost expression extraction algorithm demonstrates our cost analysis algorithm for a target function.
there are two main steps extracting the cost expressions of all allocation sites of the function lines analyzing the cost of the target function by traversing its control flow graph lines .
we choose to carry out this analysis on the llvm ir of rust programs considering that it has completed polymorphism and is in the single static assignment ssa form.
we first clarify several main terms related to our cost expression extraction approach and then elaborate the details of these two steps.
.
.
terms and definition.
in general the heap allocation statements may not explicitly appear in the function but are nested in the call chains.
therefore we should clarify several concepts related to the phenomenon.
primitive allocation functions there are two inherent functions in standard rust to call the global allocator rust alloc and rust realloc .
they are the primitive points of all heap allocations.
primitive allocation site the call site of primitive allocation functions.
allocation site the call site of a function that contains either primitive allocation sites or other allocation sites.
allocation function a function with allocation sites.
allocation chain a path on the call graph from the root function to a primitive allocation function.
take figure 4a as an example function e is an allocation function with a primitive allocation site functions a and c are also allocation sites because they call other allocation functions.
the call chain a c e is an allocation chain.
.
.
cost expression of allocation sites.
we first get the cost expression of the function for each allocation site in the target function through performing algorithm recursively lines .
this can be terminated with primitive allocation sites or cached results line .
in other words we guarantee all functions in the allocation chains of the target function have been analyzed before the analysis.
hence the cost expression of every related allocation function is available and the main task of cost analysis for the allocation site is to replace the arguments of callee s cost expression lines .
taking figure 4c as an example we can recursively infer the cost expression of the function e isz 4because it only contains one primitive allocation site.
e z is an allocation site of the function c .
we should replace the argument of e z with the value of z which is phi y and get the cost expression of function call e z asphi y .
to find the parameter value line we leverage the technique of sparse value flow analysis .
in particular the value flow of a parameter can be traced backward based on the define use chain which is directly available in the ssa form of llvm ir.
besides we also leverage the pointer analysis and memory ssa construction to refine the value flow graph by resolving the usedefine chain involved with alloca variable.
the backward tracing would be terminated when meeting a node of a constant value or a parameter of the current function.
otherwise we continue to search for the definition node.
if a value node is defined based on two or multiple values e.g.
binary operation or phi node we continue to search the definition of each value separately.
during the value flow analysis our analyzer may encounter some unsolvable situations discussed in section .
.
and break off the traversing in the use define chain.
taking figure as an example the unsolvable is such a function e.g.
a dynamic virtual function and the analyzer can not fetch the value of a.
737esec fse december san francisco ca usa chengjun chen zhicong zhang hongliang tian shoumeng yan and hui xu a sample call graph.
b code involving memory allocation.
c cost expression.
figure demonstration of cost analysis.
algorithm cost analysis algorithm.
input cur the current function to analyze output result cost expression of the current function 1function extractexpr cur allocsites getallocsites cur foreach allocsite allocsites do calleeexpr getcalleeexpr allocsite if calleeexpr then extractexpr allocsite .callee parvalue getparamvalue allocsite allocsite .cost replacepar calleeexpr parvalue sccs getscc cur foreach scc sccsdo scc.cost handleloop scc cfgworklist cfgworklist .push cfg.entry while curblock cfgworklist .pop do nextblocks getnextblocks curblock foreach block nextblocks do ifblock sccsthen block movetosccexits ifblock .indegree 1then block .cost mergecost block curblock else block .cost addcost block curblock ifhavevisitedprev block then cfgworklist .push block result cfg.exit.cost hence it is unable to get the expression of function call f a .
to make the reservation mechanism sound i.e.
every infallible allocation can be satisfied by the reserved space oom guard introduces a multi level reservation mechanism.
when detecting such unsolvable situations our analyzer will give the developer a notification that includes the location of the current analyzed function and therelated functions and inform them to annotate the related functions fin this example .
after that the function calls influenced by the unsolvable value flow can be ignored and will do reservations for themselves.
in this example fcan reserve for itself so that the reservation in adoes not need to take the memory cost of f into consideration.
thus we can finally get the cost expression of function casphi y andaasphi x .
our approach also achieves field sensitivity to enhance the accuracy of results.
we maintain a vector as the field information during the value flow analysis to indicate the located field of our target value in the current value node.
for example when reaching a parameter node that represents a struct with two i64fields in the current function the field information can help to infer which field represents our target value and generate a field expression as the result.
furthermore we can also leverage the field information to prune the branches for the value flow analysis.
specifically for the alloca variable with multiple fields each of its fields is defined by a distinct store instruction hence such node will have several incoming edges.
in this case we can leverage the field information to locate the exclusive store node as the definition node.
we will update the field information once encounter the field related instructions like getelementptr orinsertvalue by pushing the corresponding index to or popping an element from the vector.
.
.
cost expression of allocation functions.
supposing we have obtained the cost expressions of all allocation sites of a function we can traverse the control flow graph cfg of the function to obtain its cost expression.
to this end we first use tarjan algorithm to extract all strongly connected components scc of the cfg and analyze the cost of each scc separately lines .
since scc is more complicated for cost analysis we defer our discussion of loop handling to .
.
we then shrink each scc into a node as its exit node.
thus we can treat the cost of the scc as the cost of the exit node lines .
we employ a worklist approach to traverse the cfg in topological order and combine the cost of each allocation site into a final expression lines .
for two sequential allocation sites or blocks in the control flow graph we can directly add the cost of the previous block to the subsequent one line .
for two parallel blocks we should merge their cost expressions line .
ideally we only need to retain the expression that is always larger.
however 738oom guard towards improving the ergonomics of rust oom handling via a reservation based approach esec fse december san francisco ca usa such an ordinary relationship may not exist between two expressions.
for cost expressions that cannot be compared we simply accumulate their costs.
note that if the function of an allocation site is also annotated as oom guard the analyzer will ignore its cost because the function will perform reservation for itself.
thus we can leverage this design to break the recursion by annotating one of the functions in the recursion cycle.
such a mechanism justifies how our cost analysis approach supports multi level or recursive oom guard functions.
.
handling loops .
.
general loop handling.
scc is special because we should infer the max iteration time of each loop.
for each loop the cost expression can be represented as the cost expression of each iteration multiplied by the iteration time.
when meeting nested loops we first compute the cost of inner loops and then compute the expression of the outer loop in turn.
in general for explicitly bounded loops like the foriterator we can obtain the iteration time expression via a value flow analysis approach on the iterator which is similar to the parameter solving of section .
.
.
however there are two exceptions that cannot be solved with the approach implicit bounded loops and loop variant allocation sites.
next we discuss how oom guard handles such cases.
.
.
implicit bounded loops.
forwhile andloop loops either the step size after each iteration or the termination conditions cannot be easily determined.
therefore we cannot simply employ the previous value flow approach to calculate their iteration times.
these loops as implicit bounded loops.
oom guard can detect implicitly bounded loops and give the notification to users.
such information can guide developers to play corresponding treatments.
it provides two options for developers to handle implicit bounded loops.
firstly it allows developers to specify the iteration number either a constant value or an expression with valid variables manually for the loop which will be used directly for cost analysis.
secondly developers may also annotate the loop as oom guard to achieve multi level reservation.
in this way the call sites within the loop will perform reservations for themselves and the caller function can ignore the cost of the loop.
.
.
loop variant allocation sites.
for some allocation sites within a loop the parameter value could be updated during each iteration.
therefore we cannot assume a uniform cost for each iteration and multiply the iteration number as the cost of the loop.
for such cases oom guard also informs developers automatically and suggests they to annotate the loop as oom guard.
.
handling dynamic dispatch besides loops dynamic dispatch can also cause problems for cost analysis because the callee function of an allocation site cannot be easily determined via static analysis.
in rust dynamic traits can be used for dynamic dispatch e.g.
by declaring a function with the parameter of dynamic traits or calling a function that returns a boxed dynamic trait.
if the program further invokes a member function of the dynamic trait it would be difficult to determine which actual function would be called until runtime.
for such cases we generally cannot obtain a max cost expression of all candidate figure pages management in oom guard allocator.
functions because such an ordinal relationship rarely exists among functions.
also we cannot sum all the cost expressions of each candidate function because it would waste memory when there are many candidate functions.
therefore oom guard chooses to inform developers about the allocation site involving dynamic traits and inform them to annotate the allocation site separately.
5implementation of proxy allocator in this section we describe how to implement our proxy allocator to achieve memory reservation management.
.
objective to avoid users having to manually modify their allocator to adapt to the reservation mechanism we implement a proxy allocator that can directly leverage the default allocator to achieve the reservation mechanism.
as shown in figure 2c users of oom guard can specify a new proxy allocator as the global allocator.
in this way the proxy allocator will receive all allocation and deallocation requests.
it then bypasses the requests of regular functions to the original allocator and only processes the requests from oom guard functions.
since such an allocator cannot manage memory directly it may introduce some overhead.
hence another objective of the allocator design is to reduce the overhead to achieve efficient memory management.
next we discuss the detailed design of the proxy allocator.
.
data structure for memory management our proxy allocator adopts a classic design for memory management i.e.
it reserves memory pages bytes with size classes varied from bytes to bytes ascending by an exponential of .
pages with the same size class are linked into a double linked list.
figure demonstrates the detailed structure of each page.
in particular each page has a free stack to record the indexes of empty blocks of the page and a free index to record the top index of the free stack.
for other memory blocks greater than bytes we simply store each of them in a seperate page and organize them into a list which is dedicated to big memory allocations.
the design described above ensures each request for memory in reservation is larger than the page size which avoids a large abundant memory request.
meanwhile the size class design eliminates the external memory fragmentation making every block reusable as well as accelerating the page searching when allocating.
in most instances the allocator can also fetch a free block from a page in a short time count on the free index and free stack.
739esec fse december san francisco ca usa chengjun chen zhicong zhang hongliang tian shoumeng yan and hui xu .
allocator apis there are three core apis for the proxy allocator reservation allocation and deallocation.
.
.
reservation.
the reservation api is called in the entry of each oom guard function.
the proxy allocator maintains the remaining information for each size class to help reserve memory blocks for a given memory cost tuple.
it mainly calculates a reserved number for each size class and uses it to subtract from the corresponding remaining number during reservation.
if there are not enough blocks it will request more pages from the system for reservation.
when the oom guard function exits the reserved number should be added back to the remaining number since the objective of the reservation has been achieved.
however we can not directly use the reserved number calculated in the reservation because there could be some reserved memory blocks still in use after the function exits.
to tackle the problem we also record the actual allocation number and deallocation number for each oom guard function.
when the function exits the reserved number of blocks to be given back should be calculated as reserved num alloc num dealloc num .
.
allocation.
our proxy allocator will employ the reserved memory for the allocations in oom guard functions.
for small allocations bytes the allocator searches for empty blocks from pages of the corresponding size.
firstly it gets the page list with the target size class and starts searching from the first page.
if there are empty blocks within the page our allocator can get theindex of an empty block through the free index and the free stack then compute the address of the empty block by multiplying itsindex with the block size and then adding to the address of the page.
these calculations are under o time complexity.
if the page has no empty blocks our allocator will continue to search for the next page until an empty block is found.
for large allocations bytes the allocator will return the reserved big page directly and remove it from the page list.
note that our scheme can ensure there are always available empty blocks if the reservation succeeds.
in particular because the reserved number and remaining number for each size class are globally maintained across all oom guard functions we do not need to care which block is reserved by which oom guard function.
such a design largely simplifies the complexity of our allocation mechanism.
.
.
deallocation.
when performing deallocation the proxy allocator first checks if the target memory is managed by it.
if not the proxy allocator will directly use the default allocator to release the memory.
otherwise if the deallocation memory is a small block bytes the allocator only needs to push the index of the corresponding block to the free stack of the page it belongs to.
for large sized memory bytes the allocator can directly release it since it occupies a whole page.
evaluation this section demonstrates our case study of applying oom guard to two representative rust system level programs bento fs and rcore os.table the annotated top level functions.
system top level function analysis time rcore open read write dup pipe exit sleep yield exec thread create condvar wait condvar signal condvar create semaphore down semaphore up semaphore create mutex create fork42s bento fs init lookup open read write statfs fsync opendir fsyncdir create getattr setattr readdir31s .
experimental setting we implement oom guard based on rust version .
.
and clang version .
.
.
it consists of over lines of rust codes and lines of c codes.
we implement our cost analysis algorithm based on llvm ir with c .
the proxy allocator and proc macro crate are developed with rust.
we choose bento fs and rcore os for evaluation because they are well known and recent research work in the rust community and employ infallible mode by default.
bento fs3is a file system that emphasizes memory safety and velocity.
rcore4is a simple unix like kernel based on risc v architecture written in rust language.
however aborting on oom will significantly impacts the availability and is not suitable for such low level system softwares.
we modify the original bento fs and rcore os with oom guard and evaluate oom guard in the following aspects.
usability is oom guard a more handy approach to avoiding aborting on oom compared with alternative approaches?
.
resilience can oom guard programs survive under oom circumstances?
.
cost analysis accuracy how accurate is oom guard in estimating memory usage?
.
overall efficiency how much overhead does oom guard introduce compared to the original programs?
we conduct experiments on a .
ghz intel processor with the .
.
ubuntu operating system linux kernel version .
.
we run rcore benchmark with the qemu platform.
.
usability to implement the oom guard version of bento fs we annotate its top level apis with the macro.
for rcore we annotate all syscall functions involving memory allocations.
the annotated top level functions in these benchmarks are shown in table .
we measure the coding efforts saved by oom guard compared to the baseline of the existing fallible mode with try version apis.
to this end we manually implement a functionally equivalent version with corresponding fallible apis.
table shows the result.
the baseline version requires to modify function signatures and callsites for bento fs and function signatures and callsites for rcore.
in comparison using oom guard only needs to modify about one hundred places which is five times less than that of the baseline.
to elaborate the oom guard version should annotate and top level functions for bento fs and rcore.
during cost 740oom guard towards improving the ergonomics of rust oom handling via a reservation based approach esec fse december san francisco ca usa table changes needed by oom guard versus the try version apis to modify the benchmarks.
func sign the number of functions that should be manually changed from infallible mode to fallible mode.
callsite lines of code of the callsite for handling allocation failures.
extra extra lines of code needed.
system annotation func sign callsite extra bento.try baseline bento.oom guard rcore.try baseline rcore.oom guard table resilience experiment under oom.
there are ten rounds for each system and each round has cases.
oomguard systems have survived all rounds.
systemsettingcrash successful cases round cases before oom after oom bento.origin baseline bento.oom guard rcore.origin baseline rcore.oom guard analysis there are respectively and notifications generated.
discussed in section .
and .
.
for such code we place extra annotations for dynamic reservation.
note that this would not undermine the effectiveness of memory reservation.
if the dynamic reservation fails the failure can also be propagated to and returned by the top level function.
in practice the extra annotations can be automated to facilitate user experience.
since oom guard does not modify the function signatures of call chains there are relatively fewer callsites to be modified.
besides oom guard requires extra lines of code to import related libraries and specify the global allocator.
our cost analyzer is also efficient.
as shown in table the static analysis time for both systems is less than one minute.
in general users only need to conduct cost analysis after the development is completed.
meanwhile the notification for extra annotations will be reported at once hence it does not need to repeat the process several times.
therefore performing a cost analysis does not have much impact on the usability of oom guard.
.
resilience in this experiment we test whether oom guard can help rust programs survive from oom situations.
to this end we execute test cases in simulated low memory situations.
for bento fs we set the memory size to mb and inject memory load with several threads that randomly allocate or deallocate memory.
the test cases of bento fs are general file system operations including reading files writing files and reading directories.
for rcore we set the kernel heap size of rcore to 2mb to simulate a low memory situation and also fork several processes to execute random allocations and deallocations to keep pressurizing the memory.
the test cases of rcore are directly from the project repository which covers all allocation related system calls.for each benchmark we run test cases with the original system and oom guard system separately.
we do tests for each system.
in each test we execute randomly selected test cases.
besides we also randomize the parameter values such as writing size in each test case to trigger different allocation behaviors.
if the system encounters an allocation failure when executing a test case this test case will fail.
at this point an ideal oom sound system can recover from the oom state and is able to execute some subsequent tests successfully when memory is sufficient again.
to reveal this ability we also record the number of tests executed successfully before and after the first encounter with the oom state respectively for each benchmark.
table shows our experimental results.
oom guard does improve the stability of system softwares under low memory circumstances.
oom guard versions can recover from oom state successfully and execute more test cases after recovering.
however the original versions crash and become immediately unavailable once oom happens for all rounds.
in the results oom guard version executes fewer tests before first encountering oom state due to the overestimation and the design of our proxy allocator which performs reservation on a per page basis.
nevertheless this design serves for the safer recovery since more available space is left in the system when the oom happens.
.
cost analysis accuracy in this experiment we evaluate the accuracy of cost analysis.
we record the ratio of the predicted memory cost to the actual memory cost for each callsite of oom guard functions in the test cases used in .
.
we execute each test case several times with diverse parameter values to trigger richer execution branches and allocation sizes.
since some allocation sites will be executed bunches of times with exactly the same arguments we only record once for the same callsites with the same actual memory cost and predicted memory cost.
we record the results as the scatter chart and indicate the number of callsites with completely accurate predictions for each test case.
figure demonstrates our results.
in general over of analysis results are accurate.
none of these estimation results is lower than the actually allocated memory ratio .
among all allocation sites there are overestimated allocations ratio .
among all overestimated cases the overestimation ratio is below .
.
such overestimations are generally caused by our estimation strategy that remains the max value as the memory cost for allocations on branches.
the result implies our approach will not bring much overestimation in most cases.
note that these overestimated memory does not necessarily indicate memory waste when incorporating our allocator design section .
.
on one hand if there are enough unreserved memory blocks held by the proxy allocator our preservation api simply decreases the number of remaining blocks instead of actually requesting memory from the default allocator.
secondly even if the overestimation may lead to over reservation the reserved memory can be used by other oom guard functions after the function returns.
741esec fse december san francisco ca usa chengjun chen zhicong zhang hongliang tian shoumeng yan and hui xu figure the proportions of predicted allocation size to actual allocation size.
we count the result for each test case separately in which the breaddir breadfile and bwritefile are test cases in bento and others are test cases in rcore rcore init counts the allocation sites during initialization of rcore .
a the proportion of executing time of syscall tests in rcore benchmark.
for the syscall tests with more frequent memory allocations fork read write thread we modified the executing parameters to trigger richer allocations and conduct experiments separately.
b throughput experiment in bento fs.
c peak memory usage experiment in bento fs.
d peak memory usage experiment in rcore.
e peak memory usage of thread test in rcore.
f peak memory usage of fork test in rcore.
figure performance experiment results.
for bento fs benchmark we perform the throughput experiment with 256mb large scale writing operations under different cache size and peak memory usage experiment with different total writing size under 64kb cache size.
for rcore benchmark we evaluate the overhead through its default syscall tests.
.
overall performance this section evaluates the performance overhead introduced by oom guard.
since these two systems are very different we discuss their performance separately.
for bento fs we measure the throughput and peak memory usage when performing large scale serial writing operations under varied operating sizes.
we run each experiment three times and calculate the average value.
figure 7b demonstrates our results of throughput study.
the original bento fs is .
faster than oom guard version on average and .
faster in the worst case.
figure 7c shows the overhead of memory space which is on average and in the worst case.
for rcore we first evaluate the speed overhead of oom guard by measuring the executing time of the default syscall tests of rcore used in .
.
we repeat each syscall test times.
figure 7a demonstrates the result in box chart.
the overhead of executiontime is on average and in the worst case.
when evaluating the memory overhead we sequentially execute these test cases several times and measure the peak memory usage during the execution.
figure 7d shows the overhead of peak memory usage which is on average and in the worst case.
we also choose two syscall tests which involve high memory usage thread and fork .
we execute these two tests by creating diverse numbers of processes or threads.
the overhead of peak memory usage is shown in figure 7e and figure 7f which is on average and in the worst case.
in summary oom guard only introduces a small overhead even in the worst cases.
we further analyze which part contributes most to overhead.
both the executing time and peak memory usage overhead are mainly caused by the proxy allocator.
since it cannot manage memory directly the additional overhead is unavoidable.
the proxy allocator needs extra time to call the default allocator for 742oom guard towards improving the ergonomics of rust oom handling via a reservation based approach esec fse december san francisco ca usa reservations and to manage its owned pages.
when using oomguard to handle oom situations for general programs such overheads are acceptable.
for those programs with high performance requirements implementing the reservation mechanism for their own allocators can further reduce these overheads.
related work this section reviews some related work that focus on oom situations and cost analysis.
.
existing work on oom situations large parts of work focused on oom situations try to detect memory leakage vulnerabilities that aggravate the memory usage and trigger oom situations more easily in the programs.
mitchell et al.
construct a automated tool to detect memory leakages of java programs in the server.
ma et al.
propose a framework that can discover memory leakage bugs in smart pointer systems.
xie et al.
and sun et al.
focus on the efficiency and accurate static memory leakage detection in the programs with complicated control flows.
these work can help programmers build a program with less oom related vulnerabilities.
however oom is a general program event especially for embedding systems or other memoryconstrained venues where every allocation may lead to an oom.
compared to the memory leakage detection work our research tries to help users solve these more general oom situations.
there are also some system level work trying to handle the oom situation robustly.
biscuit is a kernel written in go and can deal with the oom situation.
biscuit ensures the allocations in syscalls always succeed by reservation enough memory at the syscall entry.
anticipatory memory allocation ama also adopts the reservation mechanism to build robust allocation code in linux kernel.
ama requires developers to manually analyze the memory usage of allocation functions and modify the kernel code to achieve redirection for allocations.
compared to oom guard these two work cannot perform their mechanism in other programs handily as well as their approaches for prediction require more manual participation.
besides some research on oom handling enhances the performance of oom killer .
however these work only serves the linux based systems with oom killer and cannot completely avoid the hazards caused by oom.
.
existing work on cost analysis several research work aims to predict the memory cost of programs.
hofmann and jost are dedicated to studying the heap cost prediction for first order programs.
based on this research hoffmann j et al.
carried out further research by using amortized analysis and validated the automatic analysis on a wide range of first order programs.
however rust is an imperative language that is more complicated than functional programming languages.
their approaches are not directly applicable to rust.
chin et al.
work on the memory cost prediction of low level languages.
they calculated the parameter expression by means of symbol execution and constraint solution.
braberman et al.
s work computes symbolic polynomial approximations of the amount of dynamic memory for java like imperative programs using region based gc.
similarly albert et al.
proposed a heapcost prediction framework that can be instantiated with different gc strategies.
such work can solve some simple loop and recursion cases through fix pointed analysis but they have limitations in handling complex programs and cannot achieve field sensitive.
conclusion in this paper we propose a novel automated mechanism oomguard to help rust programs to evade the potential hazards of oom status.
this work contains a static analysis tool for accurate memory cost prediction and a platform independent proxy allocator to fit the reservation mechanism.
we perform experiments on two well known rust system softwares.
experimental results show that oom guard can successfully predict the memory cost of the target functions and help programs survive from allocation failure with acceptable overhead.
we believe our approach can provide a new idea for gracefully handling oom situations not only in rust programs but also in other important scenarios.
data availability we release oom guard and supported data as open source at https github.com cchanging oom.
acknowledgement this work was supported by the research grant of ant group no.
.
it was done during chengjun chen s internship at ant group.