layout and image recognition driving cross platform automated mobile testing shengcheng yu chunrong fang yexiao yun yang feng state key laboratory for novel software technology nanjing university china corresponding author fangchunrong nju.edu.cn abstract the fragmentation problem has extended from android to different platforms such as ios mobile web and even mini programs within some applications app like wechat1.
in such a situation recording and replaying test scripts is one of the most popular automated mobile app testing approaches.
however such approach encounters severe problems when crossing platforms.
different versions of the same app need to be developed to support different platforms relying on different platform supports.
therefore mobile app developers need to develop and maintain test scripts for multiple platforms aimed at completely the same test requirements greatly increasing testing costs.
however we discover that developers adopt highly similar user interface layouts for versions of the same app on different platforms.
such a phenomenon inspires us to replay test scripts from the perspective of similar ui layouts.
in this paper we propose an image driven mobile app testing framework utilizing widget feature matching and layout characterization matching to analyze app uis.
we use computer vision cv technologies to perform ui feature comparison and layout hierarchy extraction on mobile app screenshots to obtain ui structures containing rich contextual information of app widgets including coordinates relative relationship etc.
based on acquired ui structures we can form a platform independent test script and then locate the target widgets under test.
thus the proposed framework non intrusively replays test scripts according to a novel platform independent test script model.
we also design and implement a tool named lirat to devote the proposed framework into practice based on which we conduct an empirical study to evaluate the effectiveness and usability of the proposed testing framework.
the results show that the overall replay accuracy reaches around .
on android .
improvement over state of the art approaches and .
on ios improvement over state of the art approaches .
index terms cross platform testing mobile testing image analysis record and replay i. i ntroduction fragmentation problem is proposed in .
in the situation of android fragmentation problems recording and replaying test scripts on a large scale device cluster is one of the key quality assurance technologies for mobile apps.
it can automatically execute preset test cases and detect various bugs .
test scenarios recorded on one device can be replayed on other devices of different hardware or software e.g.
operating system versions .
moreover the fragmentation problem has extended to multiple platforms including android ios mobile web and even mini programs within some apps like wechat.
here we define the platform much more than operating system 1a popular chatting app in china providing a platform for other manufacturers to deploy mobile apps.but refer to a set of complete frameworks that independently provide an environment to support the apps to run.
the feature of rapid iteration and frequent requirement change of mobile apps on different platforms triggers even increasing demands on app quality assurance.
for a specific app the expanded fragmentation problem on all mobile platforms means multiple clients for different platforms sharing the same services provided by a unified server.
more importantly they also share similar ui layouts for better human computer interaction.
the expanded fragmentation problem raises a higher demand for developers when they test their mobile apps.
in other words they have to write different test scripts based on different framework supports for completely the same test requirements leading to tedious and repetitive work.
moreover different customized operating system versions can even have different supports for test script execution.
this phenomenon causes a great burden on developers because they need to get familiar with platform specific features.
besides the test scripts are impossible to execute generally for different platforms.
in lack of platform free testing technologies it is impossible for cross platform test script record and replay.
fig.
.
an example multiple clients for jingdong most mobile developers design the app user interface ui with a high similarity when supporting various platforms to improve the user experience.
here we take one of the most popular online shopping apps in china like amazon in the us jingdong as an example to illustrate such a phenomenon see fig.
.
it is evident from fig.
that the general layouts are with high similarity on different platforms as are the ui elements and their relative positions despite some slight differences on contents.
however faced with these highly similar ui layouts developers are still required to ieee acm 43rd international conference on software engineering icse .
ieee develop test scripts respectively for different platforms based on platform specific features to test the same functions and to meet completely the same test requirements.
they also need to adopt complete different testing frameworks on various platforms which significantly increases both economic and human resource costs.
the similar ui layouts enlighten us to research from the ui perspective instead of the respective underlying implementation.
to reduce the costs of adapting scripts among a wide range of platforms some existing researches start with different points of views like exploring the runtime statements matching source code of the apps on various platforms taking advantage of ui images etc.
however such techniques tend to be intrusive and have much overhead .
also they can hardly identify dynamic or similar widgets which are common in current mobile apps.
different platform features and different testing framework supports always make it a failure to relocate the target widgets and replay test scripts even on the same platform let alone cross platform replays.
some researchers have done primary studies based on image understanding techniques.
sikuli is an image based testing tool focused on desktop apps and it can identify and manipulate gui widgets without source code.
however sikuli has a poor support for the mobile environment.
sikuli relies on simple image feature matching which can lead to failures when images are too simple to extract enough features to match.
airtest is another testing tool based on image driven technologies and it is developed on the basis of sikuli.
however airtest adopts different matching solutions for various mobile platforms thus making it still hardly possible to record and replay test scripts among different platforms.
tools mentioned above merely make simple image feature extraction and matching making it tough to deal with dynamic elements which is common in such a data explosion era.
for example in a news app each piece of news has a different content constructing a distinct image feature set.
when the content is refreshed traditional technologies will have trouble locating the recorded widgets via image features.
such tools take images as images only instead of widget sets .
in other words they ignore the contents and mutual relationships and some important information is left out.
in this paper we propose an image driven mobile app testing framework to solve the cross platform record and replay problem of test scripts for the first time.
we combine image context understanding and layout extraction to solve the problem.
during the recording phase the proposed testing framework automatically characterize the layout and extracts widget screenshots layout coordinates and other attributes from the testing devices.
with the obtained information we form a test script according to the platform independent test script model introduced in section iii a including all the extracted screenshots and well organized hierarchy xml files.
in the replaying phase the proposed testing framework adopts both traditional computer vision and deep learning technologies.
the image driven mobile app testing framework is composed of widget feature matching and layout characterizationmatching.
layout characterization matching can compensate for the drawbacks of widget feature matching when a mobile app activity has dynamic or several similar widgets.
after a comprehensive analysis of the intermediate results of widget feature matching and layout characterization matching lirat can reach a high accuracy when positioning widgets on different devices.
therefore the corresponding operations can be successfully replayed.
the proposed image driven mobile app testing framework realizes one script record multiple script replays on devices of different platforms.
the framework utilizes the combination of image understanding and layout extraction for the first time and the framework significantly reduces the complexity of test script developing.
based on the image driven mobile app testing framework we design and implement a tool named lirat.
lirat simulates real app manipulation and simplifies the test script developing process into operation sequence record.
users operate on webpages where a projection of real mobile devices are shown.
also we conduct an empirical experiment to evaluate our image driven mobile app testing framework on lirat.
main contributions of this paper are as follows we propose an image driven mobile app testing framework for cross platform test script record and replay solving the problem of reusing test scripts cross platforms.
we introduce a platform independent test script model containing rich information recorded from mobile apps including screenshots widget information etc.
we declare a comprehensive cross platform widget matching approach including widget feature matching and layout characterization matching and based on which we design and implement a novel tool which can record and replay test scripts on multiple platforms.
we conduct an empirical experiment on how our approach with real world apps and devices and the tool can effectively improve testing efficiency.
the rest of this paper is organized as follows.
section ii introduces the problems and existing solutions together with their drawbacks.
section iii illustrates the methodology in detail including the pivotal technologies in the record phase and replay phase.
the specific tool design and implementation are presented in section iv.
in section v an empirical experiment is conducted to evaluate the effectiveness of the proposed approach.
section vi introduces the related work.
finally this research is concluded in section vii.
more details of the framework design and the experiment data can be found on ii.
b ackground m otivation many researches have been done to deal with the record and replay of test scripts.
they start from different perspectives including runtime statements source codes ui images etc.
however such solutions still have drawbacks and limitations.
1562fig.
.
image driven mobile app testing framework a. script replay dilemma the fragmentation problem originates from the android platform which is open for all manufacturers to make modifications to satisfy their own demands.
the openness of android has led to hundreds of thousands of different types of mobile models with different brands operating system versions screen shapes resolutions etc.
currently the fragmentation problem has extended to many other platforms such as ios where devices have different screen shapes different resolutions mini programs within some apps where mobile apps need to show the same appearances but base on different operating system kernels and mobile web where mobile apps need to make special modifications to user interfaces for mobile web browsers.
developers have to develop different versions of an app to adapt to different platforms.
we also conduct an analysis on the fragmentation problem.
we find that apps in the top free apps and apps in the top paid apps in the google play have their ios versions and most of them have mobile web versions2.
this result proves the fragmentation problem actually exists and has a deep impact on the mobile app developing.
such extended fragmentation problem leads to a great burden for developers on app testing.
developing test scripts for each platform and each version respectively can be indeed painful and time consumption and makes it easy for developers to make mistakes.
each platform will require a group of developers to work on app testing.
moreover as for developers testing work is much more substantial.
in traditional testing developers must acquire the underlying information such as the widget id or xpath.
this phenomenon makes it hard for cross platform replay because the implementations for multiple platforms of the same mobile app are quite different and based on the features of each platform.
b. limitations of current solutions sikuli is an automated testing tool presented by yeh et al.
.
sikuli uses activity screenshots to generate test cases and execute automated testing for desktop apps.
it can be 2some applications have no mobile web version due to their categories such as tools video games etc.used for various web based apps and desktop applications .
however sikuli has a poor support for mobile devices.
though it can be used to operate mobile device projections on desktop emulators being unable able to operate on real devices is a significant drawback.
moreover sikuli adopt simple image feature extraction and matching which is unsuitable for the constantly refreshing apps.
therefore the problem of recording and replaying test scripts for mobile apps is still unresolved.
however the ideas of sikuli inspired us to make use of mobile app ui elements.
airtest is an automated testing tool for gui testing.
airtest has a better support for mobile platforms.
airtest technology can acquire the whole ui tree structures from the .apk files and identify the target widgets.
then related simulative operations to replay scripts will be executed.
airtest mainly focuses on video game testing where widgets have different image features.
therefore airtest still has problems when facing mobile apps of a wider range of categories such as tools news apps etc.
especially when the widgets have similar image features.
moreover airtest cannot execute cross platform replays of the same script such as ios and mobile web client because it adopts different script developing implementations on different platforms.
iii.
m ethodology our proposed image driven mobile app testing framework consists of two processes script record and script replay see fig.
.
besides the proposed framework also adopts a novel platform independent test script model.
in the script record process the proposed framework records the screenshots and layout information of the widgets operated by the users required in the test requirements and translates obtained information into test scripts according to the proposed platform independent test script model lits .
in the script replay process we extracted the lits script and combine widget feature matching and layout characterization matching to match the corresponding widgets on the replaying devices according to the screenshots and layout information recorded in the lits instances.
1563a.
platform independent test script model we propose a novel test script model named lits which means layout image test script .lits is platformindependent because we extract and record all the information from ui screenshots without relying on platform specific features or functions.
moreover we make further processing to make the obtained information free of device attributes.
therefore lits gets rid of both software and hardware dependence and can be used uniformly without adaptation.
during the script record we extract the rich but necessary information after each operation.
during the script replay we also extract the same information from the replaying device and match with the information stored in lits scripts.
the information for each operation includes the screenshot of the app activity under test denoted as ssa the screenshot of the operated widget denoted as ssw the coordinate of the widget denoted as cw which is composed of the top left and the bottom right coordinates of the operated widget the operated point coordinate denoted as co the recording device serial number denoted as dsn the recording device resolution denoted asdr texts on the widget denoted as t and the operation type denoted as o. all the above information are critical to the cross platform record and replay.
ssais used to analyze the whole context of the activity we can extract all the widgets including cwfromssa.sswis extracted from ssa representing the target widget.
sswplays an important role in widget feature matching replay.
cwis representing with the distance from the top left vertex of the screenshot and it is used for the layout characterization.
cois the operated point and it can help judge the operated point falls in which extracted widget screenshot range.dsn is combined with the recording timestamp as the script id for store.
dr is also an important element.
it is used to calculate the relative proportional position of the widget and the operation point.
tis the texts on the widget which can assist identify the widgets.
orefers to the operation type like click slide etc.
which is also an indispensable part.
when the above information is obtained further processing is required for making the script platform independent.
first we combine the dsn and recording timestamp as the script id.
second we calculate the relative proportional position of the widget and the operation point specifically which are calculated as the proportion of the absolute coordinate and the resolution of the device and the results are denoted ascwr cor.
therefore lits is a list of tuples which is id ss a ssw o c wr cor t and each tuple represent for a user operation.
b. script record script record is implemented by a series of single step operations record.
the screenshots and layout information of the operated widgets are extracted and recorded for each operation as a lits instance attached with some attribute information of the widgets such as texts widget types etc.
when received by the recording device the user s operations are converted into executable instructions on different plat forms through the adb for android or wda for ios .
the extracted widget information including coordinates texts etc.
is recorded and based on the information xml files representing the activity layout in tree structures will be generated automatically through the proposed framework.
together with the activity screenshots and the widget screenshots cropped from activity screenshots the xml files are stored in the form of a nested directory the root directory represents for the test script and each subdirectory represents for the widget information file for each operation and the operation sequence is stored in the root directory.
algorithm shows the formal expression.
the input is a sequence of operations denoted asos and the output is a platform independent test script defined in section iii a denoted as lits .
script record based onlits model each operation on a widget is recorded.
then necessary information mentioned in section iii a is automatically extracted and primary processing like relative coordinate calculation are done.
algorithm script record input operation sequence os output test scriptlits initiatelits foreach operation o2osdo initiate dimension tuple tso tso dsn tso o tso ssa crop the screenshot of operated widget ssw tso ssw extract the top left and the bottom right coordinate of the operated widget cw tso cwr cw dr extract the coordinate of the operated point co tso cor co dr extract the text on the widget t tso t lits tso end for returnlits c. script replay for script replay the proposed framework retrieves the script file from the database and then orderly executes widget matching and single step replay.
according to the formal expression in algorithm first in the order of the operation sequences that obey the testing requirements each step is replayed on the replaying devices.
for each step we extract the screenshot of the activity under test and the operated widget and perform matching using both widget feature matching and layout characterization matching separately.
widget feature matching will output a set of possible widgets with runimagematching line in algorithm and layout characterization matching will output only one candidate 1564widget with runlayoutmatching line in algorithm .
the nearest one in the possible widget set from widget feature matching to the candidate widget from layout characterization matching is considered as the candidate widget of widget feature matching line to line in algorithm .
the candidate widgets will be merged with parameter to obtain a target widget.
then the coordinates of the target widget will be matched and the operation information will be converted into executable commands on the replaying devices.
a successful replay refers to the success of the operation on the right widgets and makes the app redirect to the preconceived activity.
the proposed image driven mobile app testing framework adopts two algorithms to match the operated widgets in the scripts and on the replaying devices widget feature matching andlayout characterization matching .
script replay for each step the activity screenshot and widget information on the replaying device are extracted and compared with the information in the recorded lits script.
then the coordinate is acquired and the corresponding operation is therefore done.
algorithm script replay input test scriptlits replaying device dreplay output test result tr initiate target widget wtarget image runimagematching wtarget layout runlayoutmatching if image .size 1then wtarget image image .get else dmin foreach widget wimage2 image do dwidget distance wimage wtarget layout ifdwidget dmin then dmin dwidget wtarget image wimage else continue end if end for end if set tr operate wtarget image wtarget layout returntr widget feature matching.
widget feature matching algorithm is used to match the screenshots of app widgets recorded in the scripts and the corresponding widgets on the replaying devices.
it takes the target image and the image to match as input and outputs the coordinate value of the widgets.
the algorithm includes five main processes preprocessing feature extraction feature matching mismatch elimination and distortion calculation.
each process is described below preprocessing.
the input image of the widget is performed with grayscale processing since the color informa tion of the image is not treated as a processing attribute.
this process make a projection from a channel image to an channel greatly improving the efficiency of subsequent processing and keeping the relative features of color changing and object contours .
the preprocessing enables a better effect in subsequent processing.
feature extraction.
this process includes detection of image features and construction of image feature descriptor set and feature point set.
the target widget image and the activity image to match are processed separately and two feature point sets represented as ktarget and ksource and two descriptor sets represented as dtarget anddsource are obtained.
feature matching.
we perform the feature matching and then estimate nearest neighbors.
in the processing of two feature point sets the nearest points found in dtarget anddsource are considered as matching points.
then the preliminary matching of the feature points is completed.
mismatch elimination.
matching points may have mismatches so it is necessary to eliminate such mismatches.
we employ a ratio testing to address this problem.
if the calculated value is smaller than a preset threshold the match is considered good.
otherwise the match is considered as a mismatch and will be removed.
distortion calculation.
since the target images may have distortions such as rotation and zoom in order to obtain the position of the matching region more accurately the homography matrix between the target widget image and the activity image to match is calculated.
finally the perspective transformation of the target image is performed to obtain the coordinate position information.
widget feature matching can complete the area matching of the widget screenshot to the image of the replaying device activity page.
it can almost complete the processing from image input to coordinate output in a few milliseconds which largely ensures the soundness in the replay process.
however the limitation is that when the widget screenshots in the replaying devices change frequently or when there are many dynamic or similar widgets in the activity the target widget can hardly be correctly positioned.
therefore we will record all the suspected widget information and compare them with the result acquired from layout characterization matching and finally calculate the probability for the suspect widgets to be operated.
layout characterization matching.
because of the rapid refreshing of app contents widget feature matching would be out of effect because it relies heavily on the image features of app contents.
in the ui testing tasks the smoothness of app functionality instead of the app contents is the main concern.
therefore a supplement of widget feature matching positioning is necessary.
due to the similarity of app ui layouts among different platforms we are considering further employing layout characterization matching to improve the replay accuracy.
here we define the layout as the widget localization and the hierarchy relation among the widgets.
in the layout characterization matching we first extract 1565fig.
.
widget feature matching fig.
.
layout characterization matching the widget contours based on the recorded activity screenshot stored in the scripts and then divide the activity screenshot according to the widget contours and acquire the relative position of the widgets on the activity.
after obtaining all the widget contours we will characterize the layout of the activity.
first we execute group operation which means a rough horizontal characterization to the activity.
in this process widgets wrapped in other widgets are omitted in this step and we will get several groups of widgets.
then we will divide each group into several lines by line operation.
in the line operation some widgets that wrapping other widgets will be segmented according to the contours of the wrapped widgets.
finally in each line we execute the column operation to segment each line into several columns vertically.
therefore each widget can be represented as a tuple g l c which means the group number the line number and the column number.
also the relative relationship among the widgets and the activity structure are also acquired according to the 3tuple.
the tuple is platform independent and for replaying the tuples will be translated into dimension coordinates according to the corresponding position in the layout characterization matching results.
our approach might generate some noise data.
we also make efforts to eliminate such noise data.
according to our survey on an open sourced dataset we observe that the size of most widgets is more than of the screenshot size.
therefore we discard the data whose size is smaller than the of the screenshot size.
in order to further improve the accuracy we also extract text information on the widgets.
on many occasions some highly similar widgets with different texts are close to each other making the matching hard to handle so that the texts can assist the matching.
after the necessary information is collected then starts the script replay process.
during the replay first the same process is performed on the replaying devices then we load the recorded information from the record device to match theinformation from the replaying devices.
with the layout characterization matching we can easily solve the problem of dynamic widgets that the contents are rapidly refreshing.
take the news app as an example.
while replaying the test script the piece of news in the recorded script may have changed and in the place of the news there is a new piece of news.
it is equivalent to click on the new piece of news.
for widget feature matching the different pieces of new are definitely different so the matching would fail.
however with the layout characterization matching the framework will ignore the detailed content and pay attention to the widget position and the activity layout.
iv.
t ool implementation in order to devote the proposed image driven mobile app testing framework into practice we design and implement a tool namely lirat which is short for layout and image recognition driving cross platform automated mobile testing.
in this section we illustrate the specific design and detailed algorithms and parameters.
based on lirat we also conduct an empirical experiment to evaluate the effectiveness of our proposed image driven mobile app testing framework which will be discussed in the next section.
lirat is user friendly.
for script record developers can select one specific device and operate on the webpage of the lirat and the operation will be automatically recorded and analyzed.
for script replay developers only need to invoke a recorded script and then select the devices they want to execute the script replay.
the following process is automatic.
a. widget feature matching replay to replay with widget feature matching we extract image features of activity screenshots and widget screenshots with sift algorithm .
the process can be seen in fig.
.
the sift algorithm can effectively detect and describe local features in images it is also a key technique adopted in state of the art image based record and replay tools.
after 1566extracting the image features and forming the feature point sets and descriptor sets represented as ktarget ksource dtarget anddsource we employ flann library proposed by muja et al.
.
flann performs fast approximate nearest neighbor searches in high dimensional spaces.
we perform flann algorithm on the extracted feature point sets from both the recorded activity screenshot under test and real time activity on the replaying device.
in the processing of two feature point sets the kd tree index is used and the knn algorithm helps find the nearest points in dtarget anddsource as matching points.
therefore the preliminary matching of the feature points is executed.
to eliminate mismatches of the matching points we utilize a ratio testing method given by lowe which is calculated according to the formula ratio dmin dsecond min.
according to the practical experience the threshold is set as .
in our tool .
.
b. layout characterization matching replay to solve the problems triggered by the drawbacks of the widget feature matching we introduce the layout characterization matching.
layout characterization matching divides the activity screenshot into small areas according to the widget contours and then uses the canny algorithm to perform layout characterization.
then we obtain the coordinate position information of the widgets on the recorded activity page of the recording device.
meanwhile the same layout characterization matchingwith the canny algorithm is performed on the activity screenshots of the replaying devices and the target widget is positioned according to the extracted tuple coordinate information.
the main process can be seen in fig.
.
since most apps have a similar layout for different versions on multiple platforms and the test script model we propose is platform independent the cross platform replay can be successfully realized.
we also refer to some other research work like remaui which is designed to generate code based on ui images.
remaui uses canny and ocr to characterize the image layout and combines the two algorithms to generate the page layout data structure.
lirat encapsulates and improves the layout characterization approach remaui uses.
the canny algorithm is elaborate on extracting edges but if the detection for the contours is performed without extra processing many tiny and redundant edge contours will be produced which often have no significance in layout characterization matching.
instead they can negatively affect the processing of contour data and layout characterization.
therefore we expand the widget edges and connect the redundant contours to retain large meaningful widgets texts etc.
contour detection is implemented by the findcontours function in the canny algorithm and the complete layout hierarchy is stored in the form of four vertex coordinates of the rectangular contour.
finally we calculate the size of the extracted widgets the ones which are smaller than of the activity size are discarded.
we also introduce the ocr technology into lirat to assist the matching.table i experiment mobile application open sourced apps commercial apps app name category app name category adguard system keep sports jamendo music booking shopping kiwix internet nba app sports linphone phone sms bing search tool matomo mobile development evernote tool monkey development mcdonald shopping openhab internet investing finance osmand map taobao shopping vlc music qq music music wikipedia internet kfc shopping kindle tool however the obtained widget set still has a lot of redundancy.
through the multiple empirical trials on different app activities we conclude the following rules to basically filter out redundancy and to improve the effect.
clear the contour with the length and width less than the pre defined threshold in the contour.
practice from the analysis on large amount real world apps shows that when the threshold is of the current device screen width the contour element is not a functional widget.
clear the inner contour of the contour.
this rule is ignored when the contour is longer or wider than of the width of the corresponding device .
when widgets occupy a small part of the device screens the function of the inner widget is generally equivalent to the outer widget.
therefore under such circumstances such inner contour is meaningless.
after the layout characterization of the activity each widget is assigned with a tuple g l c to represent its position.
results both from widget feature matching and layout characterization matching are considered for final widget positioning.
and we use a parameter to calculate the final result which can be seen in line of algorithm .
v. e mpirical evaluation based on lirat we conduct an empirical experiment to evaluate the effectiveness of the proposed image driven mobile app testing framework.
in this experiment we investigate to answer the following research questions rq1 how effective can lirat replay test scripts?
rq2 how much can lirat outperform the state of theart image based record and replay tools?
rq3 why does lirat fail to replay in some cases?
a. experiment setup to evaluate the effectiveness of the proposed image driven mobile app testing framework and the tool lirat we define a matrix replay accuracy to evaluate the effectiveness.
replay accuracy the percentage of the successful replays account for total replays.
during the selection of the experimental subjects we consider the compatibility on multiple platforms.
with this 1567table ii android device in the experiment device id serial no.
usage brand market name model sdkandroid versionresolution d0 wbubb18923510113 record huawei honor honor 8x max are al10 .
.
d1 2003161a replay oppo oppo pbet00 .
.
d2 63fa9ed5 replay xiaomi xiaomi mi d3 7swk89so4hy5njt8 replay vivo vivo v1901a d4 clb0218724002507 replay huawei huawei p20 eml al00 d5 ce0717179034e124027e replay samsung samsung sm n9508 table iii ios d evice in the experiment device id udid usage market name model os version resolution uikit size d6a81e386cf822ce0edeba741d 64b04a8ca7d272e4replay iphone mg482ll a ios .
.
d7ba149a8863cee87c7dec7ec2 c6e4620e3f0568bereplay iphone mngx3ch a ios .
16a366 concern we totally select mobile apps which can be referred to in table i. the selected apps include commercial ones and open sourced ones and cover different categories including system music internet phone sms development finance tool sports shopping and map which can show the generalization capability.
the selection is according to the ranking of google play and apps are filtered by the criteria of multiple platform supporting.
we also select multiple experimental devices for this experiment including android platform and ios platform.
the device list can be referred to in table ii and table iii.
our experiment covers most mainstream mobile brands and models including samsung huawei apple oppo vivo and xiaomi.
and the devices are of different operating system versions and different screen resolutions.
b. rq1 script replay success .
failure34.
android success .
failure64.
ios fig.
.
replay accuracy to answer rq1 we recruit senior software engineering majored students to organize test scenarios on the experimental mobile apps and record the test scenarios on an android device labeled as d0.
we require each test scenario includes test operations and each operation contains an app widget.
then we simultaneously replay the recorded scripts on android devices and ios devices.
as is shown in fig.
the average replay accuracy of android and ios devices arearound .
and .
3respectively.
the results show that the mobile app testing framework is promising.
the replay accuracy of android device is around .
and the replay accuracy of ios device is around .
.
results show that the framework and lirat to be promising.
c. rq2 baseline comparison we further research on the comparison between lirat and the state of the art approaches.
the final results are denoted as final results results from widget feature matching are denoted as image results and results from layout characterization matching are denoted as layout results .
images results can be considered as the results of the state of the art approaches because we obtain them with the same algorithms and such tools are not available.
fig.
a and fig.
c show the accuracy comparison among the final results image results and layout results.
fig.
b and fig.
d show the analysis of the influence among the final results image results and layout results.
there are bars in subfigure b and d .
labels containing i mean the image results are right labels containing l mean the layout results are right and labels containing f mean the final results are right4.
in the subfigure a and c widget feature matching bar represents the results from the same algorithms adopted by state of the art image based record and replay approaches such as sikuli and airtest.
we can find that our framework has an improvement with layout characterization matching over the state of the art approaches by .
and on android and ios platform respectively.
the improvements are especially obvious on cross platform test script replay from android to ios .
from the subfigure b and d we can find that with the combination of widget feature matching and layout 3kiwix and jamendo are unusable on ios devices due to the apps themselves.
4we omit the situation when final results and results from algorithms are all wrong 1568fig.
.
approach comparison algorithm influence labels containing i mean the widget feature matching results are right labels containing l mean the layout characterization matching results are right and labels containing f mean the final results are right characterization matching the replay accuracy is much higher than the two respective results.
especially for ios the increase is especially apparent.
moreover compared with widget feature matching the layout characterization matching also achieves a higher replay accuracy.
among the results where the final results are right .
and .
of successful replays on android and ios are due to the success from both algorithms .
and .
of successful replays are due to the success from widget feature matching .
and .
of successful replays are due to the success from layout characterization matching.
however even if algorithms fail there are .
and .
of final results to be successful.
among the data we can find that layout characterization matching can lead to much more final success than widget feature matching which is .
on android and .
on ios.
this phenomenon also proves that the introduction of layout characterization matching to compromise the drawbacks of widget feature matching alone achieves success which is especially apparent in cross platform replay.
the introduction of layout characterization matching greatly improves the replay accuracy compared with the same algorithms of the state of the art imagebased record and replay approaches.
the improvements on android and ios platforms reach .
and .
the improvement is especially apparent in crossplatform replay.
moreover layout characterization matching shows a more positive influence on the final replay accuracy.
d. rq3 failure analysis we review and analyze the failure cases one by one and summarize some failure reasons.
in the widget feature matching failures due to repeated highly similar widgets account for almost one third of all failure cases which is the most important reason for failure secondly the parsing failures in the recording phase result in the wrong screenshot of the target widgets.
such failures account for approximately of all failure cases.
some minor reasons have also led to individual failure cases such as the missing of corresponding widgets on the replay device too few feature points extracted by the algorithm making the algorithm output result set empty.
in the layout characterization matching failure cases are caused by layout characterization errors.
subtle layout changes caused by changes in activity contents caused approximately .
of failures.
in addition about .
of the failures are due to changes in the device status bar.
therefore there is much space for improvement in layout characterization and our approach will perform much better if the layout characterization algorithms has improvement.
several factors lead to replay failures including repeat of highly similar widgets wrong widget screenshots missing widgets on the replaying device layout characterization error layout changes led by activity changes or differences on status bar.
e. threats to validity the devices we use are limited we totally use android devices and ios device to complete the experiments.
however the mobile brand model and android version have thousands of different types thus the limitation of the device cluster can lead to a threat.
however the mobile devices we select are all the most popular ones on the current market which accounts for a large percentage of the mainstream mobile device market.
the representativeness of apps in our experiment is also a potential threat .
we select the popular apps that support both android and ios platforms.
even if we consider the diversity of the app category we cannot cover all the categories.
also some widely used apps that support only one single platform are also not considered.
however we think our proposed image driven mobile app testing framework focuses on the ui of the mobile app therefore the different kinds of apps will not affect much.
one important thing we have to claim that game apps that have no obvious layout are not applicable to the proposed framework.
we recruit senior software engineering majored students to design the test scenarios and record test scripts in the experiment .
this may be a threat.
however salman et al.
propose that senior students are sufficient developer proxies in well controlled experiments .
1569vi.
r elated work a. code based mobile test record and replay traditional android test script record tools such as instrumentation robotium uiautomator espresso are some of the mainstream automated testing framework for android platform.
they encapsulate most operations and are easy to use.
in ios platform kif and uiautomation are the most widely used automated testing tools.
however the above tools have poor capabilities for cross platform replay and the quality of test scripts depends largely on developers capabilities.
monkeyrunner is another automated testing tool on the android platform.
monkeyrunner can replay test scripts on different devices simultaneously greatly improving the test efficiency.
however users have to get familiar with the shell programming or python programming to write the test scripts which is a demanding requirement and is unfriendly to users.
appium encapsulates different frameworks to support different platforms.
appium does not compile or adjust the app under test and can complete the automated test non intrusively .
however the test scripts for different platforms cannot be generally used so cross platform replay is still hard to realize.
reran is a very early tool supporting android test script record and replay.
it captures events of low level with adb by reading logs in dev input event files.
some similar tools like appetizer and mosaic utilize similar techniques.
sara presented by guo et al.
in further improves the android application test script replay accuracy.
however such tools still cannot support cross platform replay.
barista proposed by fazzini et al.
is an approach that can help generate platform independent test cases while it start from the runtime state analysis.
the above tools are of high record and replay efficiency.
however they heavily rely on the platform frameworks and features.
even if some of them can support different platforms like android and ios developers still need to develop complete different test scripts for different platforms and the developers need to know the different knowledge well which is quite a high bar.
b. gui based mobile test record and replay behrang and orso propose apptestmigrator which allows for migrating test cases between apps with similar features using the similarity among gui widgets.
sikuli a tool presented by yeh et al.
allows developers to use gui element screenshots as a parameter.
in the replay phase sikuli applies image retrieval algorithms to match widgets according to the screenshots in the scripts.
such ideas make sikuli able to cross devices .
however the traditional computer vision algorithms it applies significantly limit the usability when used for cross platform replay.
ui elements become more dynamic and tend to have different scaling ratio which is the drawback of pixel comparison method in the computer vision algorithm sikuli uses.
based on sikuli airtest presented by netease is a crossplatform ui automated testing framework based on imagerecognition technology and poco widget recognition technology.
airtest improves the image recognition technology and adds a poco widget recognition technology in order to position the widgets by the xpath oridvalues of the widgets.
airtest has higher accuracy in the replay phase.
however airtest mainly focuses on the video games and has a relatively weaker support for a wider range of mobile apps.
moreover some state of the art approaches analyze the video information to record and replay test scripts within android platform.
qian et al.
propose a tool leveraging visual test scripts to express gui actions and using a physical robot to drive automated test execution.
bernal cardenas et al.
introduce v2s to translate video recordings of android app usages into replayable scenarios.
the gui based tools can alleviate the severity of the crossplatform problem.
however the problem is still not well solved.
the depended image feature extraction and matching algorithms will meet quite much obstacles under the circumstances that app contents are constantly refreshed leading to the constantly changing of image features.
c. widget recognition technology chang et al.
present a new approach using computer vision technology for developers to automate their gui testing tasks and execute all kinds of gui behaviors.
nguyen et al.
firstly introduce an approach namely remaui to use input images to identify ui elements such as texts images and containers using computer vision and optical character recognition ocr techniques.
moreover moran et al.
implement a tool on the basis of remaui namely redraw which can generate codes from ui images using the deep learning technology.
additionally qin et al.
present a tool namely testmig for migrating test scripts from ios to android platform using widget hierarchy information and screenshots.
chen et al.
also present a neural network machine translator which combines recent advances in computer vision and machine translation and translates ui images into gui skeletons.
chen et al.
present an approach to automatically add labels to ui components using deep learning models.
lowe present an object recognition system sift scale invariant feature transform which uses a kind of news local image features.
these features are invariant to image translation scaling and rotation and partially invariant to illumination changes affine or 3d projection.
their work greatly enlightens us and we absorb their ideas into widget recognition and test script record and replay in the image driven mobile app testing framework.
vii.
c onclusion mobile apps often run on multiple platforms so the limited capability of test scripts to work on multiple platforms can lead to repetitive developing work.
the proposed imagedriven mobile app testing framework solves such problems by the proposed platform independent test script model and the widget feature matching and layout characterization 1570matching algorithms realizing the accurate positioning of the target widgets on different platforms.
our approach greatly simplifies the scripting work and makes it possible of one script record multiple script replays on multiple platforms.
the experiment we conduct shows that the proposed imagedriven mobile app testing framework achieves promising success in replaying mobile app test scripts on different platforms and outperforms the state of the art approaches much for cross platform replay.
acknowledgement this work is supported partially by national natural science foundation of china fundamental research funds for the central universities and national undergraduate training program for innovation and entrepreneurship 202010284073z .