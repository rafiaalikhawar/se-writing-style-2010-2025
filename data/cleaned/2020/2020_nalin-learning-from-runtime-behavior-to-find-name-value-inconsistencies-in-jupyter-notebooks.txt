nalin learning from runtime behavior to find name value inconsistencies in jupyter notebooks jibesh patra university of stuttgart germany jibesh.patra gmail.commichael pradel university of stuttgart germany michael binaervarianz.de abstract variable names are important to understand and maintain code.
if a variable name and the value stored in the variable do not match thentheprogramsuffersfroma name valueinconsistency whichis duetooneoftwosituationsthatdevelopersmaywanttofix either a correct value is referred to through a misleading name which negatively affects code understandability and maintainability orthe correct name is bound to a wrong value which may cause unexpected runtime behavior.
finding name value inconsistencies is hard because it requires an understanding of the meaning ofnames and knowledge about the values assigned to a variable atruntime.thispaperpresentsnalin atechniquetoautomaticallydetect name value inconsistencies.
the approach combines ady namic analysis that tracks assignments of values to names witha neural machine learning model that predicts whether a nameand a value fit together.
to the best of our knowledge this is thefirst work to formulate the problem of finding coding issues as aclassification problem over names and runtime values.
we apply nalinto106 652real worldpythonprograms wheremeaningful namesareparticularlyimportantduetotheabsenceofstaticallyde claredtypes.ourresultsshowthattheclassifierdetectsname value inconsistencies with high accuracy that the warnings reported by nalin have a precision of and a recall of w.r.t.
a ground truth created in a user study and that our approach complements existing techniques for finding coding issues.
ccs concepts softwareanditsengineering softwaremaintenancetools software post development issues keywords neural software analysis identifier names learning based bug detection acm reference format jibesh patra and michael pradel.
.
nalin learning from runtime behavior to find name value inconsistencies in jupyter notebooks .
in permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation on the first page.
copyrights for components of this work owned by others than acmmustbehonored.abstractingwithcreditispermitted.tocopyotherwise orrepublish topostonserversortoredistributetolists requirespriorspecificpermissionand ora fee.
request permissions from permissions acm.org.
icse may pittsburgh pa usa association for computing machinery.
acm isbn ... .
pittsburgh pa usa.
acm new york ny usa pages.
https introduction variable names are a means to convey the intended semantics of code.
because meaningful names are crucial for the understandability and maintainability of code developers generally try to name a variable according to the value s it refers to.
names are particularly relevant in dynamically typed languages e.g.
python andjavascript wherethelackoftypesforcesdeveloperstorelyon names e.g.
to understand what types of values a variable stores.
unfortunately the name and the value of a variables sometimes donotmatch whichwerefertoasa name valueinconsistency.a common reason is a misleading name that is bound to a correct value.
because such names make code unnecessarily hard to understand and maintain developers may want to replace them with moremeaningfulnames.anotherpossiblereasonisthatameaningfulnamereferstoan incorrectvalue.becausesuchvaluesmay propagate through the program and cause unexpected behavior developers should fix the corresponding code.
the following illustrates the problem with two motivating examples both found during our evaluation on real world python code .asanexampleofamisleadingnameconsiderthefollowing code log file glob.glob var www some file.csv the right hand side of the assignment yields a list of file names whichisinconsistentwiththenameofthevariableitgetsassigned to because log file suggestsasinglefilename.thecodeiseven more confusing since this specific call to globwill return a list with at most one file name.
that is a cursory reader of the code mayincorrectlyassumethisfilenametobestoredinthe log file variable whereas it is actually wrapped into a list.
to clarify the meaning of the variable it could be named e.g.
log files or log file list or the developer could adapt the right hand side oftheassignmentbyretrievingthefirst andonly elementfrom the list.
we find misleading names to be the most common reason for name value inconsistencies.
lesscommon butperhapsevenworse arename valueinconsistenciescausedbyanincorrectvalue asinthefollowingexample train size .
iris.data.shape test size iris.data.shape train size train data data the code tries to divide a dataset into training and test sets.
names liketrain size areusuallyboundtonon negativeintegervalues.
however theabovecodeassignsthevalue135.0tothe train size ieee acm 44th international conference on software engineering icse authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
icse may pittsburgh pa usa jibesh patra and michael pradel variable i.e.
afloatingpointvalue.unfortunately thisvaluecauses thecodetocrashatthethirdline where train size isusedasan indextoslicethedataset butindicesforslicingmustbeintegers.
whiletherootcauseandthemanifestationofthecrashareclose toeachotherinthissimpleexample ingeneral incorrectvalues maypropagatethroughaprogramandcausehardtounderstand misbehavior.
findingname valueinconsistenciesisdifficultbecauseitrequires both understanding the meaning of names and realizing that a value that occurs at runtime does not match the usual meaning of a name.
as a result name value inconsistencies so far are found mostly during some manual activity.
for example a developer may point out a misleading name during code review or a developer may stumble across an incorrect value during debugging.
because developer time is precious tool support for finding name value inconsistencies is highly desirable.
thispaperpresents nalin anapproachfordetecting name value inconsistencies automatically.
the approach combines dynamic programanalysiswithdeeplearning.atfirst adynamicanalysis keeps track of assignments during an execution and gathers pairs of names and values the names are bound to.
then a neural model predictswhetheranameandavaluefittogether.whenthedynamic analysis observes a name value pair that the neural model predicts to not fit together then the approach reports a warning about a likely name value inconsistency.
whilesimpleatitscore realizingthenalinideainvolvesfour key challenges c1understandingthesemanticsofnamesandhowdeveloperstyp icallyusethem.theapproachaddressesthischallengethrough alearnedtokenembeddingthatrepresentssemanticsimilarities of names in a vector space.
for example the embedding mapsthenames train size size andlentosimilarvectors as they refer to similar concepts.
c2understanding the meaning of values and how developers typicallyusethem.theapproachaddressesthischallengeby recording runtimevalues andby encodingthem intoa vector representation based on several properties of values.
the properties include a string representation of the value its type and type specific features such as the shape of multi dimensional numeric values.
c3pinpointingunusualname valuepairs.weformulatethisproblem as a binary classification task and train a neural modelthatpredictswhetheranameandavaluematch.tothebest of our knowledge this work is the first to detect coding issues through neural classification over names and runtime values.
c4obtaining a dataset for training an effective model.
the approachaddressesthischallengebyconsideringobservednamevaluepairsascorrectexamples andbycreatingincorrectexamplesbycombiningnamesandvaluesthroughastatistical type guided sampling that is likely to yield an incorrect pair.
our work relates to learning based bug detectors which share the idea to classify code as correct or incorrect.
however we are the first to focus on name value incon sistencies whereas prior work targets other kinds of problems.
nalin alsorelates to learnedmodels that predictmissing identifier names .
our work differs by analyzing code with namessupposed to be meaningful instead of targeting obfuscated or compiledcode.finally therearestaticanalysis basedapproachesfor findinginconsistentmethodnames andothernaming issues .akeydifferencetoalltheaboveworkisthatnalinis based on dynamic instead of static analysis allowing it to learn fromruntimevalues whichstaticanalysiscanonlyapproximate.
one of the few existing approaches that learn from runtime behavior aims at finding vector representations for larger pieces of code but cannot pinpoint name value inconsistencies.
we train nalin on 780k name value pairs and evaluate it on 10k previously unseen pairs from real world python code extracted fromjupyternotebooks.themodeleffectivelydistinguishesconsistentfrom inconsistentexamples with anf1scoreof .
.comparing the classifications by nalin to a ground truth gathered in astudywithelevendevelopersshowsthatthereportedinconsistencies have a precision of and a recall of .
most of the inconsistenciesdetectedinreal worldcodeareduetomisleading names but there also are some inconsistencies caused by incorrect values.finally weshowthattheapproachcomplementsstate ofthe artstaticanalysis basedtoolsthatwarnaboutfrequentlymade mistakes type related issues and name related bugs.
in summary this paper contributes the following an automatic technique to detect name value inconsistencies.
the first approach to find coding issues through neural machine learning on names and runtime behavior.
a type guided generation of negative examples that improves upon a purely random approach.
empirical evidence that the approach effectively identifies namevalue pairs that developers perceive as detrimental to the understandability and maintainability of the code.
overview thissectiondescribestheproblemweaddressandgivesanoverview ofourapproach.nalinreasonsabout name valuepairs i.e.
pairs of a variable name and a value that gets assigned to the variable.
the problem we address is to identify name value pairs where the name is not a good fit for the value which we call inconsistent name value pairs.
identifying such pairs is an inherently fuzzy problem whether a name fits a value depends on the conventions that programmers follow when naming variables.
the fuzzinessof the problem motivates a data driven approach where we usethevastamountsofavailableprogramsasguidanceforwhat name value pairs are common and what name value pairs stand out as inconsistent.
broadly speaking nalin consists of six components and two phases illustrated in figure .
during the training phase the approachlearnsfromacorpusofexecutableprogramsaneuralclassificationmodel whichthenservesduringthepredictionphasefor identifyingname valueinconsistenciesinpreviouslyunseenprograms.thefollowingillustratesthesixcomponentsoftheapproach with some examples.
a detailed description follows in section .
given a corpus of executable programs the first component is a dynamic analysis of assignments of values to variables.
for each assignment during the execution of the program the analysis extracts the variable name the value assigned to the variable and several properties of the value e.g.
the type length and shape.
as authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
learning from runtime behavior to find name value inconsistencies icse may pittsburgh pa usa name value pairstraining predictiontrain neuralmodel4 representationas vectors3generation ofnegative examples2 query neuralmodel5previously unseenexecutable programs ...name .
file name compute ... name valueinconsistencies name .
!executable programs ...age arr probability get prob data xs train load data ... name value type length shape age int null null probability .
oat null null xs train n .. ndarray name .
oat null null file name example.txt str nulldynamic analysisof assignments1 heuristic ltering of meaningless names6 figure overview of the approach.
illustratedinfigure1 propertiesthatdonotexistforaparticular value are represented by null.
for example the analysis extracts thelengthoftheassignedvaluefor xs train butnotfor ageand probability asthecorrespondingvaluesareprimitivesthatdo not have a length.
whilethename valuepairsobtainedbythedynamicanalysis serve as positive examples the second component generates negative examples that combine names and values in an unusual and likelyinconsistentway.themotivationbehindgeneratingnegative examples is that nalin trains a classification model in a supervised manner i.e.
theapproachrequiresexamplesofbothconsistentand inconsistent name value pairs.
using the example pairs in figure one negative example would be the name xs train paired with the floating point value .
which indeed is an unusual namevalue pair.
our approach for generating negative examples is a probabilistic algorithmthat biasesthe selectionof unusualvalues toward unusual types based on the types of values that are usually observed with a name.
the first and second component together addresschallengec4fromtheintroduction i.e.
obtainingadataset for training an effective model.
thethirdcomponentofnalinaddresseschallengesc1andc2 i.e.
understanding thesemanticsofnamesandvalues.tothisend the approach represents names and values as vectors that preserve theirmeaning.torepresentidentifiernames webuildonlearned token embeddings which map each name into a vector while preserving the semantic similarities of names .
for example the vector of probability will be close to the vectors of names probabandlikelihood becausethesenamesrefertosimilarconcepts.
to represent values we present a neural encoding of values based on their string representation type and other properties.
giventhevectorrepresentationsofname valuepairs thefourth component trains a neural model to distinguish positive from negative examples.
the result is a classifier that once trained with sufficiently many examples addresses challenge c3.
the fifth component of the approach queries the classifier with vector representationsofname valuepairsextractedfrompreviouslyunseen programs producing a set of pairs predicted to be inconsistent.
thefinalcomponentheuristicallyfilterspairsthatarelikelyfalse positives and then reports the remaining pairs as warnings to the developer.
for the two new assignments shown in figure thetrained classifier will correctly identify the assignment name .5as unusual and raises a warning.
approach the following presents the components of nalin outlined in the previous section in more detail.
.
dynamic analysis of assignments the goal of thiscomponent is to gather name valuepairs from a corpus of programs.
our analysis focuses on assignments because theyassociateavaluewiththenameofavariable.oneoptionwould betostaticallyanalyzeallassignmentsinaprogram.however a static analysis could capture only those values where the righthand side of an assignment is a literal but would miss many other assignments e.g.
whentheright handsideisacomplexexpression or function call.
in the code corpus used in our evaluation we find that of all assignments have a value other than a primitive literal on the right hand side i.e.
a static analysis could not gather name valuepairsfromthem.instead nalinusesadynamicanalysis thatobservesallassignmentsduringtheexecutionofaprogram.
besidesthebenefitofcapturingassignmentsthatarehardtoreason about statically a dynamic analysis can easily extract additional properties of values such as the length or shape which we find to be useful for training an effective model.
.
.
instrumentation and data gathering.
todynamicallyanalyze assignments nalin instruments and then executes the programs in the corpus.
for instrumentation the analysis traverses the abstract syntaxtreeofaprogramandaugmentsallassignmentstoavariable withacalltoafunctionthatrecordsthenameofthevariableand the assigned value.
asruntimevaluescanbearbitrarilycomplex theanalysiscan extract only limited information about a value.
we extract four properties of eachvalue which wefound to be usefulfor training aneffectivemodel butextendingtheapproachtogatheradditional propertiesofvaluesisstraightforward.slightlyabusingtheterm pair toincludethepropertiesextractedforeachvalue theanalysis extracts the following information definition name value pair .
a name value pair is a tuple n v l s wherendenotes the variable name on the left hand authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
icse may pittsburgh pa usa jibesh patra and michael pradel side vis a string representation of the value represents the type ofthevalue and landsrepresentthelengthandshapeofthevalue respectively.
thestringrepresentationbuildsuponpython sbuilt instring conversion whichoftenyieldsameaningfulrepresentationbecause developerscommonlyusethisrepresentation e.g.
fordebugging.
the type of values is relevant because it allows nalin to find typerelated mistakes which otherwise remain easily unnoticed in a dynamicallytypedlanguage.lengthherereferstothenumberof itemspresentinacollectionorsequencetypevalue whichisuseful e.g.
to enable the model to distinguish empty from non empty collections.sincesomecommondatatypesaremultidimensional theshaperefers to the number of items present in each dimension.
thetableinfigure1showsexamplesofname valuepairsgathered bytheanalysis.weshowintheevaluationhowmuchtheextracted properties contribute to the overall effectiveness of the model.
.
.
filtering and processing of name value pairs.
merge types.
we observe that the gathered data forms a longtaileddistributionoftypes.oneofthereasonsisthepresenceof manysimilartypes suchaspython sdictionarytype dictandits subclassdefaultdict.
to help the model generalize across similar types we reduce the overall number of types by merging some of the less frequent types.
to this end we first choose the ten most frequent types present in the dataset.
for the remaining types we replace any types that are in a subclass relationship with one of the frequent types by the frequent type.
for example consider aname value pair stopwords frozenset all afterwards eleven ... frozenset null .
because type frozenset is not among the ten most frequent types but type setis we change the name value pairinto stopwords frozenset all afterwards eleven ... set null .
filtermeaninglessnames.
anunderlyingassumptionofnalin isthatdevelopersusemeaningfulvariablenames.unfortunately some names are rather cryptic such as variables called aorts pd.
such names help neither our model nor developers in deciding whetheranamefitsthevalueitrefersto andhence wefilterlikely meaningless names.
the first type of filtering considers the length ofthevariablenamesanddiscardsanyname valuepairswherethenameislessthanthreecharacterslong.thesecondtypeoffiltering is similar to the first one except that it targets names composed of multiplesubtokens suchas ts pd.wesplitnamesatunderscores1 and remove any name value pairs where each subtoken has less than three characters.
.
generation of negative examples the gathered name value pairs provide numerous examples of names and values that developers typically combine.
nalin uses supervised learning to train a classification model that distinguishes consistent or positive name value pairs from inconsistent or negative pairs.
based on the common assumption that most code iscorrect we consider the name value pairs extracted from executions as positive examples.
the following presents two techniques create a negative example input name value pair n v l s datasetdof all pairs output negative example n v l s fglobal computefrom damapfromtypestotheirfrequency fname compute from dandna map from types observed withnto their frequency tname types seen with n tname infreq types infrequently seen with n for each f fnamedo tname iff threshold then tname infreq tall dom fglobal all types ever seen tcand tall tname tname infreq types never or infrequently seen with n weightedrandomchoice tcand fglobal v l s randomchoice d return n v l s for generating negative examples.
first we explain a purely randomtechnique followedbyatype guidedtechniquethatwefind to yield a more effective training dataset.
.
.
purely random generation.
ourpurelyrandomalgorithm forgeneratingnegativeexamplesisstraightforward.foreachnamevaluepair n v l s thealgorithmrandomlyselectsanothernamevalue pair n v l s from the dataset.
then the algorithm creates a new negative example by combining the name of theoriginal pair and the value of the randomly selected pair which yields n v l s .
whilesimple thepurelyrandomgenerationofnegativeexamplessuffersfromtheproblemofcreatingmanyname valuepairs that dofit welltogether.
theunderlying rootcause isthat thedistributionofvaluesandtypesislong tailed i.e.
thedatasetcontains manyexamplesofsimilarvaluesamongthemostcommontypes.
forexample considera name valuepairgatheredfromanassignmentn u m .
when creating a negative example the purely randomalgorithmmaychooseavaluegatheredfromanotherassignment a g e .
as both values are positive integers they both fitthename num i.e.
thesupposedlynegativeexampleactuallyisa legitimate name value pair.
having many such legitimate negative examples in the training data makes it difficult for a classifier to discriminatebetweenconsistentandinconsistentname valuepairs.
.
.
type guided generation.
tomitigatetheproblemoflegitimate negativeexamplesthatthepurelyrandomgenerationalgorithmsuffersfrom wepresentatype guidedalgorithmforcreating negative examples.
the basic idea is to first select a type that anameisinfrequentlyobservedwith andtothenselectarandom value among those observed with the selected type.
algorithm showsthetype guidedtechniqueforcreatinganegativeexample for a given name value pair.
the inputs to the algorithm are a name valuepair n v l s andthe completedataset dof positive name value pairs.
thefirsttwolinesofalgorithm1createtwohelpermaps which map types to their frequency.
the fglobalmap assigns each type to authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
learning from runtime behavior to find name value inconsistencies icse may pittsburgh pa usa years n v l s years list null fname list ndarray int float dict tuple set tname infreq float dict tuple set fglobal str bool float dict weighted random selection of a target type random selection of a float value from the dataset n v l s years .
oat null null infrequent types for years global frequencies of types infrequently or never seen with years given name value pair all types years has been in the dataset and their frequencies float figure steps for creating a negative example.
itsfrequencyacrosstheentiredataset d whereasthe fnamemap assigns each type to how often it occurs with the name nof the positive example.
next lines to populate two sets of types.
the firstset tname ispopulatedwithalltypeseverobservedwithname n. the second set tname infreq is populated with all types that are infrequentlyobservedwithname n. infrequent heremeansthat the frequency of the type among all name value tuples with name nis below some threshold which is in the evaluation.
the goal of selecting types that are infrequent for a particular name is to createnegativeexamplesthat areunusual andhence likelyto be inconsistent.
the remainder of the algorithm lines to picks a type to be usedforthe negativeexample andthencreates anegativenamevalue pair by combining the name nwith a value of that type.
to this end the algorithm computes all candidates types tcand that are either never observed with name nor among the types tname infreqthat infrequently occur with n. the algorithm then randomly selects among the candidate types using the global type frequencyasweights fortherandomselection.the rationaleisto chooseatypethatisunlikelyforthename n whilefollowingthe overall distribution of types.
the latter is necessary to prevent the modelfromsimplylearningtospotunlikelytypes buttoinstead learn to find unlikely combinations of names and values.
once the targettype forthenegativeexampleisselected thealgorithm randomly picks a value among all values line observed with type andeventuallyreturnsanegativeexamplethatcombines namenwith the selected value.
figure illustrates the algorithm with an example from our evaluation.
the goal is to create a negative example for a namevalue pair where the name is years.
in the dataset of positive examples thename yearsoccurswithvaluesoftypes list ndarray int etc.
with the frequencies shown in the figure.
for example yearsoccurs235timeswitha listvalue butonlyseventimeswith afloatvalue.amongalltypesthatoccurinthedataset manynever occurtogetherwiththename years e.g.
strandbool.basedonthe global frequencies of types that yearsnever or only infrequently occurs with the algorithm picks floatas the target type.
finally avari abl e name val ue typelength of valueshape of value n v l s concat classi er probability of being inconsistentfasttext gru convol uti on one hot one hot one hot figure architecture of the neural model.
corresponding floatvalue is selected from the dataset which is .
for the example and the negative example shown at the bottom of the figure is returned.
by default nalin uses the type guided generation of negative examples and our evaluation compares it with the purely random technique.
the generated negative examples are combined with the positive examples in the dataset and the joint dataset serves as trainingdatafortheneuralclassifier.duetotheautomatedgenera tion ageneratednegativeexamplesmaycoincidentallybeidentical toanexistingpositiveexample.inpractice thedatasetusedduringtheevaluationcontains38instancesofidenticalpositiveand negative examples out of negative examples.
.
representation as vectors givenadatasetofname valuepairs eachlabeledeitherasapositive or a negative example nalin trains a neural classification model to distinguishthetwokindsofexamples.acrucialstepistorepresent the information in a name value pair as vectors which we explain inthefollowing.theapproachfirstrepresentseachofthefivecom ponents n v l s ofaname valuepairasavector andthenfeeds theconcatenationofthesevectorsintotheclassifier.figure3showsanoverviewoftheneuralarchitecture.thefollowingdescribesthe vectorrepresentationinmoredetail followedbyadescriptionof the classifier in section .
.
representing variable names.
to enable nalin to reason about the meaning of variable names it maps each name into a vector representationthatencodesthesemanticsofthename.forexample the representation should map the names list of numbers and integers to similar vectors as both represent similar concepts but the vector representations of the names ageandfile name shoulddifferfromtheprevious vectors.
tothisend ourapproach builds on pre trained word embeddings i.e.
a learned functionthat maps each name into a vector.
originally proposed in natu ral language processing as a means to represents words wordembeddingsarebecomingincreasinglypopularalsoonsource authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
icse may pittsburgh pa usa jibesh patra and michael pradel code wheretheyrepresentindividualtokens e.g.
variable names.
webuilduponfasttext aneuralwordembeddingknown torepresentthesemanticsofidentifiersmoreaccuratelythanother popularembeddings .anadditionalkeybenefitoffasttextis toavoidtheout of vocabularyproblemthatotherembeddings e.g.
word2vec sufferfrom bysplittingeachtokeninton gramsand by computing a separate vector representation for each n gram.
to obtainmeaningfulembeddingsforthepythondomain wepre train a fasttext model on token sequences extracted from the corpuspython programs used in our evaluation.
formally the trainedfasttext model m assigns to each name na real valued vector m n rd whered in our evaluation.
representing values.
the key challenge for representing the string representations of values as vectors is that there is a widerange of different values including sequential structures e.g.
in values of types string ndarray list and values without an obvious sequential structure e.g.
primitives and custom objects.
the string representations of values may capture many interesting properties includingandbeyondtheinformationconveyedbythetypeofa value.forexample thestringrepresentationofan intimplicitlyencodes whether the value is a positive or negative number.
our goal whenrepresentingvaluesasvectoristopickupsuchintricacies without manually defining type specific vector encoders.
to this end nalin represents value as a combination of two vectorrepresentations eachcomputedbyaneuralmodelthatwe jointlylearnalongwiththeoverallclassificationmodel.ontheone hand we use a recurrent neural network rnn suitable for capturing sequential structures.
specifically we apply gated recurrent units gru over the sequence of characters where each character is used as an input at every timestep.
the vector obtained from the hidden state of the last timestep then serves as the representation of the complete sequence.
on the other hand we use a convolutional neural network cnn suitable for capturing non sequential information about the value.
specifically the approach applies a one dimensional cnn over the sequence of characters where the number of channels for the cnn is equal to the number of characters in the string representation of the value the number of output channels is set to relu is the activation function and a onedimensional maxpool layer serves as the final layer.
finally nalin concatenates the vectors obtained from the rnn and the cnn into the overall vector representation of the value.
representing types.
to represent the type of a value as a vector the approach computes a one hot vector for each type.
each vectorhasadimensionequaltothenumberoftypespresentinthedataset.
atypeisrepresentedbysettinganelementtoonewhilekeeping theremaining elementssetto zero.for example ifwehaveonlythree types namely int float andlistin our dataset then using one hotencoding eachofthemcanberepresentedas and respectively.fortheevaluation wesetthemaximum numberoftypestoten.moresophisticatedrepresentationsoftypes e.g.
learned jointly with the overall model could be integrated into nalin as part of future work.
representing length and shape.
length and shape are similar concepts andhence werepresenttheminasimilarfashion.becausethelengthofavalueistheoreticallyunbounded weconsiderten rangesoflengthsandrepresenteachofthemwithaone hotvector.
specifically nalinconsidersrangesoflength100 startingfrom0 until1 .thatis anylengthbetween0and100willberepresented bythesameone hotvector andlikewiseanylengthgreaterthan 000willberepresentedbytheanothervector.theshapeofavalue is a tuple of discrete numbers which we represent similarly to the length exceptthatwefirstmultiplytheelementsoftheshapetuple.
for example for a value of shape x y z we encode x y zusing the same approach as for the length.
for values that do not have a length or shape we use a special one hot vector.
.
training and prediction oncenalinhasobtainedavectorrepresentationforeachcomponent of a name value pair the individual vectors are concatenated into the combined representation of the pair.
we then feed this combinedrepresentationintoaneuralclassifierthatpredictsthe probability pofthename valuepairtobeinconsistent.theclassificationmodelconsistsoftwolinearlayerswithasigmoidactivation functionattheend.wealsoaddadropoutwithprobabilityof0.
before each linear layer.
we train the model with a batch size of using the adam optimizer for epochs after which the validationaccuracysaturates.duringtraining themodelistrained toward predicting p .
for all positive examples and p .
for all negative examples.
once trained we interpret the predicted probability pas the confidence nalin has in flagging a name value pairasinconsistent andtheapproachreportstotheuseronlypairs withpabove some threshold section .
.
.
heuristic filtering of likely false positives before reporting name value pairs that the model predicts as inconsistent to the user nalin applies two simple heuristics to prune likelyfalsepositives.theheuristicsaimatremovinggenericand meaningless names that have passed the filtering described in section .
.
such as dataandval 0. the rationale is that judging whetherthosenamesmatchaspecificvalueisdifficult butthegoal of nalin is to identify name value pairs that clearly mismatch.
the first heuristic removes pairs with names that contain one of thefollowing terms which are often found in generic names data value result temp tmp str andsample.
the second heuristic removes pairs with short and cryptic names.
to this end we tokenize names at underscores and then remove pairs with names where at least one subtoken has less than three characters.
evaluation our evaluation focuses on the following research questions rq1 how effective is the neural model of nalin in detecting name value inconsistencies?
rq2 aretheinconsistenciesthatnalinreportsperceivedashard to understand by software developers?
rq3 what kinds of inconsistencies does the approach find in real world code?
rq4 how does our approach compare to popular static code analysis tools?
rq5 how does nalin compare to simpler variants of the approach?
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
learning from runtime behavior to find name value inconsistencies icse may pittsburgh pa usa .
experimental setup weimplementourapproachforpythonasitisoneofthemostpopular dynamically typed programming languages .
all experiments arerunonamachinewithintelxeone5 2650cpuhaving48cores 64gb of memory and an nvidia tesla p100 gpu.
the machine runs ubuntu .
and we use python .
forthe implementation.
theevaluationrequiresalarge scale diverse andrealisticdataset of closed i.e.
include all inputs programs.
we choose one million computational notebooks in an existing dataset of jupyter notebooks scrapped from github .
the dataset is i large scale because there are many notebooks available ii diverse becausethey are written by various developers and cover various appli cation domains iii realistic because jupyter notebooks are one ofthemostpopularwaysofwrittenpythoncodethesedays and iv closedbecausenotebooksdonotrelyonuserinput.another option would be to apply nalin to executions of test suites which oftenfocusonunusualinputsthoughand bydefinition exercise well tested and hence likely correct behavior.
excluding some malformed notebooks we convert notebooksintopythonscriptsusing nbconvert.someofthesenotebooks containonlytextandnocode whileforothers thecodehassyntax errors orthecodeisveryshortanddoesnotperformanyassignments.all ofthis decreasesthe numberof pythonfilesthat nalin can instrument and we finally obtain instrumented files.
the instrumentation takes approximately two hours.
whengatheringname valuepairs wefacegeneralchallenges related to reproducing jupyter notebooks .
first even with the installationofthe100mostpopularpythonpackages unresolved dependencies result in crashes during some executions.
second some python scripts read inputs from files e.g.
a dataset for training a machine learning model which may not be locally available.
considering all notebooks that we can successfully execute despitetheseobstacles nalingathersatotalof947 702name value pairs ofwhich500 332remainafterthefilteringdescribedinsection .
.
.
the extracted pairs come from python files with a total of lines of non comment non blank python code.
runningtheinstrumentedfilestoextractname valuepairstakes approximately hours.
before running any experiments with the model we sample name value pairs as a held out test dataset.
unless mentionedotherwise allreportedresultsareonthistestdataset.ontheremaining490 332name valuepairs weperforman80 20splitinto trainingandvalidation data.foreachname valuepairpresentin thetraining validation andtestdatasets wecreateacorresponding negative example which takes two hours in total.
the total numberofdatapointsusedtotrainthenalinmodelhenceisabout 780k.
training takes an average of seconds per epoch and once trained predictionontheentiretestdatasettakesabout15seconds.
wefindthename valuepairstoconsistofadiversesetofvalues andtypes.thereare99.8kuniquenames i.e.
eachnameappears on average about times.
the top frequent types are list ndarray str int float.
the presence of a large number of collection types suchaslistandndarray whichusuallyarenotfullyinitializedas literals shows that extracting values at run time is worthwhile.figure4 precision recall andf1scorewithdifferentthresholds for reporting warnings.
.
rq1 effectiveness of the trained model we measure the effectiveness of nalin s model by applying the trained model to the held out test dataset.
the output of the model canbeinterpretedasaconfidencescorethatindicateshowlikely the model believes a given name value pair to be inconsistent.
we consider all name value pairs pwarningwith a score above some thresholdasawarning andthenmeasureprecisionandrecallof themodelw.r.t.theinconsistencylabelsinthedataset pinconsistent are pairs labeled as inconsistent precision pwarning pinconsistent pwarning recall pwarning pinconsistent pinconsistent we also compute the f1 score which is the harmonic mean of precision and recall.
figure shows the results for different thresholds for reporting apredictionasawarning.theresultsillustratetheusualprecisionrecall tradeoff where a user can reduce the risk of false positive warningsatthecostoffindingfewerinconsistencies.themodel achieves the highest f1 score of at a threshold of .
with a precisionof andarecall of91 .unless otherwise mentioned weuseathresholdof0.5asthedefault whichgives87 f1score.
out of files in the held out test set .
have at least one warning reported by nalin.
finding1 themodeleffectivelyidentifiesinconsistentnamevalue pairs with a maximum f1 score of .
.
rq2 study with developers to answer the question how well nalin s warnings match namevalue pairs that developers perceive as hard to understand we perform a study with eleven software developers.
the participants arefourphdstudentsandsevenmaster levelstudents allofwhich regularlydevelopsoftware andnoneofwhichoverlapswiththe authors of thispaper.during the study each participant isshown name value pairs and asked to assess each pair regarding its understandability.theparticipantsprovidetheirassessmentona five point likert scale ranging from hard to easy where authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
icse may pittsburgh pa usa jibesh patra and michael pradel nalin s prediction developer consistent inconsistent assessment pnowarning pwarning easy to understand peasy hard to understand phard a nalinpredictions of inconsistenciesvs.
developer perceived understandability.
b understandabilityratingsforname valuepairswithandwithout warnings by nalin.
figure results from user study.
hard meansthatthenameandthevalueareinconsistent makingit hardtounderstandandmaintainthecode.the40name valuepairs consist of pairs that are randomly selected from all warnings nalinreportsasinconsistentwithaconfidenceabove80 andof20 randomlyselectedpairsthattheapproachdoesnotwarnabout.for each pair the participants are shown the name of the variable the valuethatnalindeemsinconsistentwiththisname andthetypeof the value.
in total the study hence involves developer ratings.
because what is a meaningful variable names is to some extent subjective we expect some variance in the ratings provided by the participants.
to quantify this variance we compute the inter rater agreement using krippendorff s alpha which yields an agreement of .
that is developers agree with a medium to high degree on whether a name value pair is easy to understand.
before providing quantitative results we discuss a few representativeexamples.amongthename valuepairswithoutawarning isavariablecalled data url thatstoresastringcontainingaurl.
thispairis consistentlyratedaseasyto understand withamean rankingof5.
.amongthepairsthatnalinreportsasinconsistent are a variable password text storing an integer value which most participants consider as hard to understand mean rating .
.
another pair that the approach warns about is a variable calledpaththat stores an empty list.
the study participants are rather undecided about this example with a mean rating of .
.
the main question of the user study is to what extent nalin pinpoints name value pairs that developers also consider to be hard to understand.
we address this question in two ways first bycomputingprecisionandrecallofnalinw.r.t.thedeveloperratings andthenbycomparingtheratingsforwarningsandnon warnings.
precisionandrecallw.r.t.developerratings.
weassigneachof the name value pairs into two sets on the one hand a pair is inphardifthemeanratingassignedbythedevelopersislessthan threeandin peasyotherwise.ontheotherhand apairisin pwarning if nalin flags it as an inconsistency and in pnowarning otherwise.
table5ashowstheintersectionsbetweenthesesets.forexample weseethat16ofthepairsthatnalinwarnsabout butonly5ofthe pairswithoutawarning areconsideredtobehardtounderstand.
we compute precision and recall as follows precision pwarning phard pwarning recall pwarning phard phard ratingsforwarningsvs.non warnings.
inadditiontothepairbased metrics above we also globally compare the ratings for pairs with and without warnings.
the goal is to understand whether nalin is effective at distinguishing between name value pairs that developers perceive as easy and hard to understand.
to this end consider two sets of ratings ratings rwarningfor name value pairs that nalin reports as inconsistent and ratings rnowarning for other name value pairs.
figure 5b compares the two sets of ratings with each other showing how many ratings there are for each point on the point likert scale.
the results show a clear difference betweenthetwosets easy isthemostcommonratingin rnowarning whereasthemajorityofratingsin rwarningiseither relativelyhard or hard .
we also statistically compare rwarningandrnowarning using a mann whitney u test which shows the two sets of rankings to be extremely likely to be sampled from different populations with a p value of less than .
.
finding developers mostly agree with the in consistency predictionsbynalin.inparticular theyassess80 ofthenamevalue pairs that the approach warns about as hard to maintain and understand.
.4rq3 kinds of inconsistencies in real world code tobetterunderstandthekindsofname valueinconsistenciesdetectedinreal worldcode weinspectname valuepairsinthetest datasetsthatappearassuchinthecode butthatareclassifiedas inconsistentbythemodel.whenusingnalintosearchforpreviouslyunknownissues thesename valuepairswillbereportedas warnings.weinspectthetop 30predictions sortedbytheprobability score provided by the model and classify each warning into one of three categories misleading name.
name value pairs where the name clearly fails to match the value it refers to.
these cases do not lead to wrong program behavior but should be fixed to increase the readability and maintainability of the code.
incorrectvalue.name value pairswherethemismatchbetween anameandavalueisduetoanincorrectvaluebeingassigned.
these cases cause unexpected program behavior e.g.
a program crash or incorrect output.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
learning from runtime behavior to find name value inconsistencies icse may pittsburgh pa usa table examples of warnings produced by nalin.
code example category run time value comment name philip k. dick ... name .
iftype name str print yes misleading name2.
avariablecalled nameistypicallyholdingastring but here stores a float value.
file os.path.exists reference.csv iffile false print warning ... misleading namefalse the namefilesuggests that the variable stores either a file handle or a file name but it here stores a boolean.
defcustom information prob get betraying probability information if prob returnd elif prob returnchoice else returncincorrect value cooperate assigning a string to a variable called probis unusual becauseprobusually refers to a probability.
the value isincorrectandleadstoacrashinthenextlinebecause comparing a string and a float causes a type error.
dwarf users iayork downloads dwar 2013 2015.txt dwar pd.read csv dwarf sep header none false positive users .. thevalueisastringthatdescribesfilepath whichfitsthe name where the fsupposedly means file .
the model reports this false positive because it fails to understand the abbreviation.
false positive.
name value pairs that are consistent with each other and which ideally would not be reported as a warning.
the inspection shows that of the warnings correspond to misleadingnames 2areincorrectvalues and7arefalsepositives.
that is the majority of the reported inconsistencies are due to the name whereasonlyafewarecausedbyanincorrectvaluebeing assigned to a meaningful name.
this result is expected because incorrectbehavioriseasiertodetect e.g.viatesting thanmisleading names for which currently few tools exist.
the fact that out of30warnings aretruepositivesisalsoconsistentwiththe developer study in rq2.
table1showsrepresentativeexamplesofwarningsproducedby nalin.thefirsttwoexamplesshowmisleadingnames.forexample it is highly unusual to assign a number to a variable called name or to assign boolean to a variable called file.
to the best of our knowledge thesemisleadingnamesdonotcauseunexpectedbehavior but developers may still want to fix them to increase thereadability and maintainability of the code.
in the third example nalinproducesawarningabouttheassignmentonline2.thevalueassignedduringtheexecutionisastring cooperate .duetothe stringassignment thecodeonline3crashessincetheoperator does not support a comparison between a string and float.
nalinis correct in predicting this warning because the variable name probistypicallyusedtorefertoaprobability nottoastringlike cooperate .
the final example is a false positive which illustratesoneofthemostcommoncausesoffalsepositivesseenduring our inspection namely short and somewhat cryptic names for which the model fails to understand the meaning.finding3 themajorityofinconsistenciesdetectedinrealworld code are due to the name in a name value pair being misleading and occasionally also due to incorrect values.
.
rq4 comparison with previous bug detection approaches we compare nalin to three state of the art static analysis tools aimed at finding bugs and other kinds of noteworthy issues i pyre a static type checker for python that infers types and uses availabletypeannotations.wecomparewithpyrebecausemanyof theinconsistenciesthatnalinreportsaretype related andhence might also be spotted by a type checker.
ii flake8 a python linter that warns about commonly made mistakes.
we compare with flake8becauseitiswidelyusedandbecauselinterssharethegoalof improving the quality of code.
iii deepbugs a learning based bug detection technique.
we compare with deepbugs because it alsoaimstofindname relatedbugsusingmachinelearning butus ingstaticinsteadofdynamicanalysis.werunpyreandflake8using theirdefaultconfigurations.fordeepbugs weinstallthe deepbugsforpython pluginfromthemarketplaceofthepycharmide.
we apply each of the three approaches to the files where nalin has produced a warning and which have been manually inspected rq3 .namer arecenttechniqueforfindingname relatedcoding issues through a combination of static analysis pattern mining andsupervisedlearningwouldbeanothercandidateforcomparing with but neither the implementation nor the experimental results are publicly available.
table shows the number of warnings reported by the existing toolsandhowmanyofthesewarningsoverlapwiththosereported by nalin.
we find that except one warning reported by pyre none authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
icse may pittsburgh pa usa jibesh patra and michael pradel table comparison with existing static bug detectors.
approach warnings warnings common with nalin pyre flake8 deepbugs figure result of ablation study.
matches with the manually inspected warnings from nalin.
the matching warning is a misleading name shown on the first row of table .
the pyre type checker reports this as an incompatible variable type because in the same file the variable nameis first assignedastring philip k. dick andlaterassignedafloatvalue .
.
the warnings produced by flake8 are mostly about coding style e.g.
missing white space and whitespace after .
the warnings reported by deepbugs include possibly wrong operatorusagesandincorrectlyorderedfunctionarguments butnone matches the warnings reported by nalin.
finding nalin is complementary to both traditional static analysis basedtoolsandtoastate of the artlearning based bug detector aimed at name related bugs.
.
rq5 comparison with variants of the approach .
.
type guided vs. purely random negative examples.
the following compares the two algorithms for generating negative examples described in section .
.
following the setup from rq1 we find that the purely random generation reduces both precision and recall leading to a maximum f1 score of .
compared to .
with the type guided approach.
manually inspecting the top reportedwarningsasinrq2 wefind21falsepositives ninemisleading names and zero incorrect values which clearly reduces the precision compared to the type guided generation approach.
these results confirm motivation for the type guided algorithm section .
.
and show that it outperforms a simpler baseline.
.
.
ablation study.
we perform an ablation study to measure theimportanceofthedifferentcomponentsofaname valuepairfed into the model.
to this end we set the vector representation of individual components to zero during training and prediction and thenmeasuretheeffectonthef1scoreofthemodel.figure6shows the results where the vertical axis shows the f1 score obtained onthevalidationdatasetateachepochduringtraining.eachline infigure6showsthef1scoreobtainedwhiletrainingthemodel keeping that particular feature set to zero.
for example the green line no shape is for a model that does not use the shape of a value andtheblueline all isforamodelthatusesallcomponents of a name value pair.
we find that the most important inputs tothemodelarethevariablenameandthestringrepresentationofthe value.
removing the length or the type of a value does not significantly decrease the model s effectiveness.
the reason is that thesepropertiescanoftenbeinferredfromotherinputsgivento the model e.g.
by deriving the type from the string representation of a value.
we confirm this explanation by removing both the type andthestringrepresentationofavalue whichyieldsanf1score similar to the model trained by removing only values.
finding5 eachcomponentoftheapproachcontributesto the overall effectiveness but there is some redundancy in the properties of values given to the model.
threats to validity internal validity.
several factors may influence our results.
first the filtering of name value pairs based on the length of namesmay accidentally remove short but meaningful names such as abbreviationsthatarecommoninaspecificdomain.preliminary experimentswithoutsuchfilteringresultedinmanyfalsepositives and we prefer false negatives over false positives to increase developer acceptance.
second our manual classification into different kinds of inconsistencies is subject to our limited knowledge of the analyzed python files.
to mitigate this threat the classificationis done by two of the authors discussing any unclear cases until reaching consensus.
externalvalidity.
severalfactorsmayinfluencethegeneralizabilityofourresults.first ourapproachisdesignedwithadynamically typedprogramminglanguageinmind becausemeaningfulidentifier names are particularly important in such languages.
thisfocus and the setup of our experiments implies that we cannotdraw conclusions beyond python or beyond the kind of pythoncode foundin jupyter notebooks.
second ourdeveloper study is limited to eleven participants and other developers may assess the understandability of the name value pairs differently.
we mitigate thisthreat bygetting elevenopinions abouteach name valuepair and by statistically analyzing the relevance of the results.
related work detectingpoornames.
theimportanceofmeaningfulnamesduring programming has been studied and established .
there areseveraltechniquesforfindingpoorlynamedprogramelements e.g.
basedonpre definedrules bycomparingmethodnames againstmethodbodies andthroughatypeinference likeanalysisofnamesandtheiroccurrences .toimproveidentifiernames authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
learning from runtime behavior to find name value inconsistencies icse may pittsburgh pa usa rule basedexpansion n grammodelsofcode andlearningbasedtechniquesthatcomparemethodbodiesandmethodnames have been proposed .
namer combines static analysis patternmining andsupervisedlearningtofindname related coding issues.
many of the above approaches focus on method names whereaswetargetvariables.moreover noneoftheexisting approaches exploits dynamically observed values.
predicting names.
when namesare completely missing e.g.
in minified compiled or obfuscated code learned models can predict them .
another line of work predicts method names giventhebodyofamethod whichbeyondbeingpotentially useful for developers serves as a pseudo task to force a model to summarize code in a semantics preserving way.
nalin differs by considering values observed at runtime and not only static source code andbycheckingnamesforinconsistencieswiththevalues they refer to instead of predicting names from scratch.
name basedprogramanalysis.
deepbugsintroducedlearningbasedandname basedbugdetection whichdiffersfromnalin by being purely static and by focusing on different kinds of er rors.
the perhaps most popular kind of name based analysis is probabilistictypeinference oftenusingdeepneuralnetwork models that reason about the to be typed code.
refinumusesnamestoidentifyconceptualtypes whichfurtherrefine the usual programming language types .
semseed exploits semantic relations between names to inject realistic bugs .
all of the above work is based on the observation that the implicit information embedded in identifiers is useful for program analyses.
our work is the first to exploit this observation to find name value inconsistencies.
naturallanguagevs.code.
beyondnaturallanguageintheform ofidentifiers commentsanddocumentationassociatedwithcode are another valuable source of information.
icomment and tcomment usethisinformationtodetectinconsistenciesbetweencommentsandcode.ourworkdiffersbyfocusingonvariable names instead of comments by comparing the natural languageartifact against runtime values instead of static code and by usingalearning basedapproach.anotherlineofworkusesnatural language documentation to infer specifications of code which is complementary to our work.
learningoncode.
inadditiontotheworkdiscussedabove machinelearningoncodeisreceivingsignificantinterestrecently .
embeddingsofcodeareoneimportanttopic e.g.
usingastpaths controlflowgraphs asts oracombinationoftokensequencesandagraphrepresentationofcode .ourencoderof variable names could benefit from being combined with an encodingofthecodesurroundingtheassignmentusingthoseideas.
otherworkmodelscodechangesandthenmakespredictionsabout them or trains models for program repair code completion and code search .
learningfromexecutions.
despitetherecentsurgeofworkon learning on code learning on data gathered during executions is a relativelyunexploredarea.onemodelembedsstudentprograms based on dynamically observed input output relations .
wang et al.
s blended code embedding learning combines runtimetraces whichincludevaluesofmultiplevariables andstaticcodeel ementstolearnadistributedvectorrepresentationofcode.beyondcodeembedding blankit usesadecisiontreemodeltrainedon runtimedatatopredictthelibraryfunctionsthatacodelocation mayuse.incontrasttothesepapers ourworkaddressesadifferent problem and feeds one value at a time into the model.
conclusion using meaningful identifier names is important for code understandability and maintainability.
this paper presents nalin which addressestheproblemoffindinginconsistenciesthatarisedueto theuseofamisleadingnameorduetoassigninganincorrectvalue.
thekeynoveltyofnalinistolearnfromnamesandtheirvalues assigned at runtime.
to reason about the meaning of names and values the approach embeds them into vector representations that assign similar vectors to similar names and values.
our evalua tionwithabout500kname valuepairsgatheredfromreal world python programs shows that the model is highly accurate leading to warnings reported with a precision of and recall of .
our implementation and experimental results are available