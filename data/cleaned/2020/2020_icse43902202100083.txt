centris a precise and scalable approach for identifying modified open source software reuse seunghoon woo sunghan park seulbae kim heejo lee hakjoo oh korea university seunghoonwoo sunghan park heejo hakjoo oh korea.ac.kr georgia institute of technology seulbae gatech.edu abstract open source software oss is widely reused as it provides convenience and efficiency in software development.
despite evident benefits unmanaged oss components can introducethreats such as vulnerability propagation and license violation.
unfortunately however identifying reused oss components is a challenge as the reused oss is predominantly modified and nested.
in this paper we propose c entris a precise and scalable approach for identifying modified oss reuse.
by segmenting an oss code base and detecting the reuse of a unique part of the oss only c entris is capable of precisely identifying modified oss reuse in the presence of nested oss components.
for scalability centris eliminates redundant code comparisons and accelerates the search using hash functions.
when we applied c entris on widely employed github projects comprising versions and billion lines of code we observed that modified oss reuse is a norm in software development occurring times more frequently than exact reuse.
nonetheless c entris identified reused oss components with precision and recall in less than a minute per application on average whereas arecent clone detection technique which does not take into account modified and nested oss reuse hardly reached precisionand recall.
index terms open source software software composition analysis software security i. i ntroduction recent years have seen a dramatic surge in the number and use of open source software oss .
not to mention the immediate benefit of reusing the functionalities of existing oss projects using oss in software development generally leads to improved reliability because oss is publicly scrutinized by multiple parties.
at the same time however reusing oss without proper management can impair the maintainability and security of software especially when a piece of code is reused over various projects.
one effective solution to prevent this undesirable situation is to undertake software composition analysis sca .
the aim of sca process is to identify the osscomponents contained in a target program.
with an sca tool developers can systematically keep track of what and how oss components are reused in their software and can therefore mitigate security threats by patching known vulnerabilities and avoid potential license violations.
unfortunately precisely identifying oss components in the target software is becoming increasingly challenging mainlyowing to the following recent trends in software developmentpractice regarding oss.
heejo lee is the corresponding author.
modified oss reuse instead of reusing existing oss in its entirety developers commonly utilize only a portion of it or modify the source code or structure.
nested oss components the reused oss may contain multiple sub oss components and even the sub oss components may include other oss components.
growth of oss projects and their code size the number of oss projects is rapidly increasing along with the growing code size .
these three factors collectively affect the accuracy and scala bility of sca tools.
to our knowledge no existing techniques are capable of precise and scalable detection of modified ossreuse in the presence of nested oss components.
limitations of existing techniques.
existing sca techniques assume that the reused oss is essentially unmodified or modified to a limited fashion thereby producing false negativeswhen it comes to identifying modified reuse.
for example osspolice a recent sca technique that aims to identifypartially reused components cannot identify oss components when their directory structures are modified.
on the other hand existing code clone detection techniques e.g.
can in principle be used for identifying modified reuse of oss components but they easily produce false positivesif an oss project is nested.
when only a nested third party software component of an oss is used in the target software clone detection techniques falsely report them as reuse of theoriginal oss.
also as we demonstrate in this paper existing sca and clone detection techniques are hardly scalable forlarge oss code bases details are explained in section vii .
our approach.
in this paper we present c entris a new sca technique that aims to overcome the above limitations.
centris can effectively detect modified oss reuse in a precise and scalable manner even when oss components are arbitrarily nested.
for scalability c entris uses a technique called redundancy elimination.
instead of generating signatures from all functions in all versions of the entireoss code base c entris first collects all functions in all versions of an oss project and then removes all redundanciesin functions across versions.
this approach is effective inreducing space complexity most of the time the delta acrossversions is significantly smaller than the size of the unchanged code base.
for precision we employ a technique called code segmentation.
to identify modified components we basically use loose matching that checks whether the code similarity ieee acm 43rd international conference on software engineering icse .
ieee between the target software and the oss is greater than a predefined threshold.
however simply applying this method suffers from false alarms especially when an oss is nested.therefore we segment an oss into the application code i.e.
a unique part of the oss and the borrowed code e.g.
a part of the nested third party software we analyze whether each function in the oss belongs to the application code or theborrowed code.
we then remove the borrowed code of an ossand only analyze the reuse patterns of the application code ofthe oss for component identification.
this code segmentationenables c entris to drastically filter out false alarms while still identifying desired oss components even when they are heavily modified or nested.
evaluation.
for the experiment we collected a large oss dataset from public c c repositories on github comprising versions and billion lines of code loc in total.
from a cross comparison experiment we dis covered that of the detected components were reused withmodifications.
nevertheless c entris successfully identified the reused components with precision and recall whereas a recent clone detection technique d ej avu yielded less than precision and at most recall because d ej avu neither identifies heavily modified components nor filters out false alarms caused by nested components see section v b .
furthermore c entris reduced the matching time to tens of seconds when comparing a software with one million loc to the dataset while d ej avu requires more than three weeks because they perform matching against all lines of code from every oss in the dataset see section v c .
contributions.
this paper makes the following contributions we propose c entris the first approach capable of precisely and scalably identifying modified oss reuse in the presence of nested oss components.
the key enabling technical contributions include redundancy elimination and code segmentation.
we applied c entris in an industrial setting with a large oss dataset.
as a result we confirmed that most of the oss components are reused with modification.
centris can identify reused oss components from 10k widely utilized software projects on github with precision and recall even though modified ossreuse is prominent.
c entris takes less than a minute on average to identify components in a software project.
ii.
t erminology and motiv a tion a. terminology basic terms.
we first define a few terms upfront.
target software denotes the software from which we want to identify reused oss components.
an oss component refers to an entire oss package or sometimes the functions contained in the oss called component for short.
lastly oss reuse refers to utilizing all or some of the oss functionalities .table i examples of identified components in arangodb using c entris .
name v ersion reused functions unused functionsstructure changereuse patterns identical modified curl v7.
.
x p c c googletest v1.
.
o p s c c c asio v1.
.
x e v elocypack old x p tz v2014b x p e exact reuse p partial reuse sc structure changed reuse cc code changed reuse old version v elocypack code committed in .
a software project.
we define a software project as the combined set of application and borrowed codes.
the borrowed code denotes the part comprised of reused oss i.e.
a set of third party software which we aim to identify within the target software.
the application code refers to the original part of the software project excluding the code from another oss.
oss reuse patterns.
we classify oss reuse patterns into four categories according to the code and structural changes exact reuse e the case where the entire oss is reused in the target software without any modification.
partial reuse p the case where only some parts of an oss are reused in the target software.
structure changed reuse sc the case where an oss is reused in the target software with structural changes i.e.
the name or location of an original file or directory is changed such as code amalgamation.
code changed reuse cc the case where an oss is reused with source code changes.
when an oss is reused with modification i.e.
partial structure changed and code changed reuse we refer to thisasmodified oss reuse.
in the modified reuse p sc and cc can occur simultaneously.
b. motivating example suppose we want to identify oss components reused in arangodb v3.
.
.
million loc a native multi model database software .
given a large oss dataset billion loc c entris took less than a minute and identified a total of c c oss components in arangodb.
table i elaborates on five of the identified oss components.
the modified reuse pattern is very prominent in arangodb.
among the identified oss components were modified wherein the reused functions were located in directories different from those in the original oss e.g.
googletest or the code base was partially updated e.g.
curl.
also in most cases arangodb reused a fraction of the oss code base e.g.
.
of v elocypack with unnecessary features such as testing infrastructure removed.
moreover components were reused in the form of nested components for example tz was reusedby the v8 engine and v8 was in turn reused in arangodb.
existing sca techniques are not designed for handling such code bases with modified components.
for example sixcomponents were reused in arangodb with structural changes as osspolice relies on the original oss structure for 861arango db...detection coverage a sca approach b code clone detection approach c centrisboost v8 many false negatives many false positives an oss component an oss not a component of arangodb ... components arango db...boost v8arango db...boost v8 fig.
illustration of the component detection coverage of the sca approach code clone detection approach and c entris .
compared to c entris which identified components existing sca approaches could not detect components where structural modification occurs e.g.
osspolice or when only a small portion of an oss code base is reused whereas code clone detection approaches e.g.
d ej avu reported numerous false positives.
component detection it fails to identify such structure changed components.
in contrast code clone detection techniques re port numerous false alarms in identifying modified and nestedcomponents.
for instance d ej avu reported that oss were reused in arangodb among which were confirmed as false alarms as we investigated see section v b .
this is because d ej avu reports any oss as a reused component if the oss contains the same third party software reused in arangodb.
one example is ripple a cryptocurrency relatedoss that contains rocksdb as a sub component.
arangodbalso reuses multiple functions from rocksdb thereby having shared functions with ripple and d ej avu misinterprets this relation as arangodb reusing ripple.
iii.
d esign of centris in this section we describe the design of c entris .
a. overview figure depicts the workflow of c entris .c entris comprises two phases p1for constructing the oss component database db and p2for identifying oss components reused in the target software.
in p1 we use a technique called redundancy elimination which enables scalable component identification c entris reduces the space complexity in component identification by eliminating redundancies acrossthe versions of each oss project.
all functions of an oss project are converted into the oss signature which is a set of functions without redundancies and subsequently storedin the component db.
in p2 we use a technique code segmentation for precise component detection.
specifically c entris minimizes false alarms in component detection by only analyzing the patterns wherein the application code of an oss is reused in the target software.
design assumptions.
centris is designed to identify oss components at the source code level that is our goal is to identify components regardless of whether all or only partsof the oss code base are reused in the target software.
in addition although the concept of c entris is applicable to any granularity of component units we focus on the function oss dataset redundancy elimination component dbp1.
component db construction phasep2.
component identification phase target softwareinput code segmentation component identification oss componentsoutput for all stored osscompare result application code of oss version reuse patterns fig.
high level overview of the workflow of c entris .
units for the approach design and evaluation.
as the term oss reuse refers to utilizing all or some oss functionalities we determined that function units are moreappropriate for detecting various oss reuse patterns compared to other units.
with less granularity e.g.
a file c entris can identify components faster than when using function units however c entris may miss partial reuses especially when only some functions in a file were reused in the target software the benefits of function units have been discussed in previous studies .
in light of this c entris extracts functions from all versions of the oss in our dataset usinga function parser see section iv and performs lightweight text preprocessing to normalize the function by removingcomments tabs linefeed and whitespaces which are easy tochange but do not affect program semantics.
b. component db construction phase p1 in this phase we process the oss projects to generate the component db.
however we observed that simply storing all functions from all versions of every oss makes the componentidentification phase extremely inefficient.
redundancy elimination.
we thus focus on the characteristics of oss the entire source code of an oss is not newly developed each time the oss is updated and thus some parts common to different versions are redundantly compared with the target software when identifying oss components.
thischaracteristic gives the following intuition if the functionscommon to multiple versions are only once compared with the target software space and time complexity can be reduced.
let us define an oss signature as a set of functions of the oss which will be stored in the component db.
the process for generating an oss signature is as follows first we extract all functions in all versions of an oss.
next we create as many bins as the total number of versions in the oss denoted as n .
when a particular function appears in idifferent versions of the oss the function is stored in the i th bin along with the version information to which this function belongs and the path information within each version.
note that all the functions have undergone text preprocessing in accordance with our design assumptions.
in addition we apply a locality sensitive hash lsh to the functions when storing them which has native support for measuringthe similarity between two hashes.
the generated nbins of an oss become the signature of the oss see figure 3b .
862oss version ... function i function j function k function l version function k... function l version ... ... a a naively generated oss signature.
oss bin bin bin n...... function i function j ... function k function l path i the path of function iin version b a redundancy eliminated signature for an oss.
fig.
illustration of oss signatures.
we generate signatures for each oss in the manner shown in b thereby reducing space complexity.
if we naively generate a signature by mapping the function to the version it belongs to see figure 3a a function that exists inidifferent versions would be compared itimes with the target software.
however our method of storing redundant functions only once in the corresponding bin reducessuch unnecessary comparisons the quantitative efficiency ofredundancy elimination is described in section v c. another advantage is that even if an oss is constantly updated thenumber of functions newly added to the component db is not large enough to impair scalability.
lastly because there are no functions excluded from indexing if we designed an appropriate identification algorithm the accuracy and specifically recall would not be impaired.
by generating signatures for alloss and storing them the component db is constructed.
c. component identification phase p2 in this phase c entris identifies the reused oss components in the target software.
common functions.
we first define the notion of common functions between two software projects.
each lsh algorithm provides its own comparison method and cutoff value .
using the comparison method we can measure the distance for each function pair between the two software projects which indicates the syntactic difference between the two inputfunctions.
hence we define the relation between two functions f f2 based on the distance and cutoff as follows lsh based function relation decision if parenleftbig distance f f2 parenrightbig f1andf2are identical if parenleftbig distance f f2 cutoff parenrightbig f1andf2are similar if parenleftbig distance f f2 cutoff parenrightbig f1andf2are different.
the similar and identical function pairs between the two software projects are determined as the common functions the lsh algorithm is specified in section iv .
key concepts for precise identification.
to identify modified components we employ similarity threshold based loose matching i.e.
to check whether the code similarity between the target software and the oss is greater than the predefined threshold.
however as previously mentioned a simplethreshold based identification method suffers from a large number of false alarms.
false alarms may occur when i an oss is nested or ii only the borrowed code of the oss is included in the target software.
consequently we present two concepts to reduce false alarms and precisely identify oss components.
prime oss.
this refers to an oss not containing any third party software.
if there is a number of common functions between a prime oss and the target software the prime oss can be considered the correct component because it violates condition i for false alarms.
code segmentation.
if we only consider the application code of an oss in component identification no false alarms occur owing to the third party software because this does not satisfy the false alarm condition ii .
accordingly our component identification process comprises the following three steps s1 to s3 s1 detecting the prime oss in the component db s2 extracting application code from all oss projects s3 identifying components within the target software.
the above steps are conducted after extracting all functions of the target software and then applying the text preprocessingand lsh algorithm to the extracted functions.
detecting the prime oss in the component db lets be the oss to be checked as to whether it contains any third party software.
to determine whether sis the prime oss we first detect common functions between sand each oss denoted as x in the component db.
if there is an oss project having one or more common functions with s the relation between sandxcan be determined as belonging to one of the following four categories r 1to r see table ii .
table ii possible relations between sandx type description r1.sandxshare widely utilized codes e.g.
hash function .
r2.sandxsimultaneously reuse some other oss projects.
r3.sreusesx.
r4.xreusess among these relations we are interested in r 2and r which imply that scontains at least one third party software conversely when sand every xare related by r 1or r w e can determine that sis the prime oss.
in fact r 1contrasts with the other three relations because there are few common functions between sandx.
therefore the main challenge in determining whether sis the prime oss is to differentiate r 4from r 2and r .
subsequently we focus on when a common function betweensandxfirst appeared in each oss we refer to this as the birth time of the function.
suppose that xreusess i.e.
r4 then the birth time of a particular reused function fin swould be earlier than that in x.
863based on the above idea we calculate the similarity score between sandxas follows let birth f s be the birth time offins s x g x whereg f parenleftbig f s x parenrightbig parenleftbig birth f x birth f s parenrightbig as shown in the above equation we measure the similarity score by considering only the common functions that appeared earlier in xthansfor identifying that xexhibits the r and r 3relations with s. as there are several ways to obtain the birth time of a function in an oss e.g.
code generation time we utilize the information we already have.
within abin of an oss signature the function hash values and version information to which the functions belong to are recorded.therefore we assign the release date of the earliest version among all recorded versions of a function as the birth timeof the function in the oss.
in addition widely used generic code e.g.
hash functions or error handling routines can exist in bothsandx r and thus we use as a threshold.
finally we determine that xbelongs to the r 2or r relation if xsatisfies the following condition s x one might consider that xcould reuse a third party software denoted as r at a time later than s. in this case because the functions in rhave earlier birth times in sthan those in x the functions would not affect the measurement of s x .
therefore even though sandxcontain common third party software equation may not be satisfied.
however this case has no effect on determining whether sis the prime oss.
obviously scontains the rcode base and even if s x does not satisfy equation s r will be greater than and thus sis not the prime oss which is the correct answer.
consequently if there is no xthat satisfies equation we determine that sis the prime oss.
s braceleftbigg prime oss if x. parenleftbig s x parenrightbig non prime oss if x. parenleftbig s x parenrightbig otherwise we consider every xthat satisfies equation as possible members of s and store them this information will be utilized for the code segmentation.
extracting application code in this step we extract the application code through code segmentation for every oss in the component db.
as a prime oss does not have anyborrowed code we only focus on non prime oss projects.
letsbe the oss of interest i.e.
the signature .
one way to locate the application code of s s a is to remove the borrowed code s b froms i.e.
sa s sb .
however detecting the oss that belongs to sbleads to a paradox the c entris methodology for identifying oss components from the target software requires the same methodology for identifying the components of an oss.
fortunately we do not need to exactly identify the subcomponents of s. instead we use the possible members of s denoted as p which were obtained from the previous step.algorithm the high level algorithm for the code segmentation input s the oss that will be segmented input db the component db output sa the application code of the s 1procedure code segmentation parenleftbig s db parenrightbig 2sa 3isprime members check prime s db if isprime shas borrowed code parts then forp members do s s p set minus operation 8sa s returnsa 10procedure check prime parenleftbig s db parenrightbig 11isprime true 12members forx db do g forf s x do ifbirth f x birth f s then g.add f s x g x similarity measurement if s x then isprime false members.add x returnisprime members aspis a possible member of s it would be reused in s i.e.
r or it reuses a common third party software with s i.e.
r .phas no code that might belong to the application code ofs this is because only the code of an oss that exhibits the r 4relation with scan belong to the application code of s. in other words the common functions between sandp are exactly included in the borrowed code of s as mentioned in our definition see section ii a .
therefore we can obtain the application code of sby removing all functions of the possible members of sfrom the function set of s. the high level algorithm for code segmentation is shown in algorithm .
consequently every oss project in the component db remains in a state wherein it is i detected as the prime or ii the application code isextracted only for the non prime oss projects .
identifying components the next step is identifying the oss components of the target software.
let tbe the target software and sbe the oss in the component db.
to identify whether sis the correct component of t we measure the code similarity score between tand the application code of s.i fs is the prime oss the application code s a is the same as the entire s. the similarity score is calculated as follows t s t sa sa there may be a possibility that widely used or generic code exists in both tands as in the case of r thus we again 864employ the threshold as a filter.
finally we determine that sis the correct component when t s .
once this process has been applied to all oss in the component db we can get a set of oss components of the target software.
why c entris is accurate.
first as c entris does not rely on structural information in the identification phase we can identify components regardless of structural change.next irrespective of whether oss is nested if the ratio ofapplication code of each oss is reused greater than i t can be identified as a correct component.
lastly the codesegmentation of c entris not only reduces false positives but also helps to identify heavily modified components.
letconsider the v elocypack component of arangodb introduced insection ii b only .
of v elocypack code base were reused in arangodb.
in fact v elocypack included another oss googletest and the ratio of the reused applicationcode of v elocypack was measured as .
highlighting the reuse patterns of only the application code of an oss makesthe similarity score between the target software and the oss higher if the oss is the correct component and lower when theoss is a false positive i.e.
close to .
using this distinct similarity score difference c entris can precisely identify modified components with low false positives.
v ersion identification.
to identify the reused version of each component we focus on the reused functions of the oss component.
in the modified reuse the functions of multipleversions could be simultaneously reused in the target soft ware.
therefore we assign a weight to each reused function.
specifically we utilize a weighting algorithm that satisfiesthe condition that a larger weight is assigned to functionsbelonging to fewer versions.
tf idf suffices where term frequency tf refers to the frequency of a function appearingin a particular version and inverse document frequency idf refers to the inverse of the number of versions containing this function.
the idf that satisfies the condition we set is utilized as the main weight function and we use the boolean frequency as the tf i.e.
we assign to the tf of all functions.
letnbe the total number of versions of an oss and v f be the versions to which a particular function fbelongs.
the weight function w is defined as w f l o g parenleftbig n v f parenrightbig .
note that the v f value offthat belongs to the i th bin is i by the definition of our signature generation.
accordingly we loop through all the reused functions of the oss componentand add the weight of each function to the score of the versions to which it belongs.
after scoring all functions we identify the utilized version with the highest score.
reuse pattern analysis.
we then analyze the reuse pattern of the detected components.
first to identify code changes occurring during oss reuse we utilize the distance measured using the comparison method of the lsh algorithm as explained at the beginning of p2 for each function pairbetween the oss component and the target software.
we determine whether the function is reused distance notreused distance cutoff or reused with code changes distance cutoff .
next to measure the structural changes we analyze the path differences between the reused functionsand original functions.
we split each function path using slash traverse each path backward starting from the filename and compare each path level.
the criterion for comparison is the path of the original function.
if any directory or file nameis different we determine that the structure has been modified.
finally according to the definition in section ii a if all functions of the oss are reused without any modification werefer to it as exact reuse.
if there are unused functions we refer to it as partial reuse.
if the structure is changed while reusing structure changed reuse occurs.
if any code is modified while reusing the oss we refer to it as code c hanged reuse.
iv .
i mplementa tion of centris centris comprises three modules an oss collector a preprocessor and a component detector.
the oss collector gathers the source code of popular oss projects.
the preprocessor stores the oss signatures generated through redundancy elimination and then extracts the application codeof the oss through code segmentation.
the oss collector and preprocessor need to be executed only once.
thereafter the component detector performs the actual component identification on the target software.
c entris is implemented in approximately lines of python code excluding externallibraries.
initial dataset.
many programming languages provide dependency information e.g.
gemfile in ruby .
however c and c which are two of the most popular languages combined rank in github do not provide dependency information despite the need.
although c entris is not restricted to a particular language we demonstrate c entris targeting c c software to prove its efficiency without any prior knowledge of dependency.
we targeted github which has the largest number of repositories among version control systems .
finally we collected all repositories having more than100 stars.
the oss collector of c entris collected repositories including linux kernel openssl tensorflow among others as of april.
.
when we extracted all versions e.g.
tags from the repositories we obtained versions the total lines were .
this dataset issignificantly larger than those used in previous approaches e.g.
.
billion c c loc database .
parser and lsh algorithm.
to extract functions from software we employed universal ctags an accurate and fast open source regular expression based parser.
next among thevarious lsh algorithms we selected the tlsh as it is known to incur fewer false positives and have a reasonable hashing and comparison speed as well as low influence of theinput size .
its comparison algorithm diffxlen returns the quantified distance between the two tlsh hashes provided as inputs.
in the context of c entris functions that undergo modification after reuse fall into this category.
we setthe cutoff value to referring to .
865v.
e v alua tion and findings in this section we evaluate c entris .section v a investigates how accurately c entris can identify oss reuse in practice.
section v b compares c entris with d ej avu motivating the need for code segmentation.
in section v c we evaluate the scalability of c entris and the efficacy of redundancy elimination.
finally we introduce our findings on oss reuse patterns in section v d. we evaluated c entris on a machine with ubuntu .
intel xeon processor .
ghz 32gb ram and 6tb hdd.
a. accuracy of centris methodology.
we conducted a cross comparison experiment on our dataset of repositories.
to do so we first selected representative versions i.e.
the version with the most functions of each oss.
as the reused components are mostly similar across different versions in one oss we decided to identify the components only for the representative version for each oss and measure the detection accuracy.
to evaluate the accuracy of c entris we used five metrics true positives tp false positives fp false negatives fn precision parenleftbig tp tp fp parenrightbig and recall parenleftbig tp tp fn parenrightbig.
ground truth establishment.
since c c software does not carry standardized information about its components we have to set the criteria for determining whether a detected component is actually reused in the target software.
therefore we decided to utilize the following three factors to verify thedetection results paths the file paths of the reused functions for stricter validation we only consider the case when the name of the detected component is included in the reused function path header files the header file configured with the oss name metadata files one of the readme license and copying files in the top level directory of the oss .
if one of the above factors of the detected oss is contained in the target software we determine that the detected oss isthe correct component of the target software.
as an exampleof the paths inflate.c of zlib is reused in the path of src .. zlib .
.
inflate.c in mongodb.
asexamples of other factors redis reuses lua while containing lua.h and libjpeg is reused in reactos where thereadme file of libjpeg is contained in reactos with the path of dll 3rdparty libjpeg readme.
when a false alarm occurs neither the name of the falsely detected component is included in the reused function path nor the main header file and metadata files of the detected component are reused in the target software.
moreover these factors are only used to verify the results detected by c entris .
obviously finding the correct answers is a more complexproblem than verifying the obtained answers and an issue arises when identifying components by relying sorely on these measured by only using the three automated validation methods.
x .
.
.
.
x x threshold components log scaled detected components correct components fig.
experimental results for measuring efficiency of .
factors the target software can implicitly reuse an oss without utilizing both the header files and the metadata files of theoss.
thus the validation methods using these factors do notnegate the need for c entris .
multi level verification.
using the aforementioned three factors i.e.
paths header files and metadata files we run multilevel verification on the results of c entris automated verification.
we first check that at least one of the three factors of the detected oss are intact in the target software this task is done in an automated way.
manual verification.
for the remaining results that are not verified using the automated way we manually analyzed the results because the three factors could be reused with modification for example openssl could bereused in the path of open ssl .
for more accurate verification we further check whether the name of the identified oss is specified in any comments of the reusedsource files in the target software.
any identified components that are not verified by the multilevel verification are counted towards fps.
parameter setup.
we then selected a suitable value to mitigate false alarms due to widely utilized code see section iii c .
to select we evaluated each cross comparison result using the predefined automated verification while setting to .
.
.
and .
.
the results are depicted in figure .
notably the proportion of correct components in the detected components drops significantly when is less than .
.
on the contrary if is greater than .
the proportion of correct components in the detected components increases slightly however the number of correct components decreases.
the overall result implies that a widely utilized code is often sharedamong different oss projects and accounts for only a small portion of each oss project generally less than .
for our experiment we set as .
to balance recall and precision.
accuracy measurement.
from the cross comparison result we observed that out of oss projects were reusing at least one other oss a total of componentswere detected.
as it is challenging to identify literally everycomponent in the target software we cannot easily measurefalse negatives.
hence we only considered false negatives thatoccurred when the application code of an oss is reused lessthan the ratio and thus c entris fails to identify it which can be measured by subtracting the number of correct componentswhen is .
from that when is zero see figure .
866table iii accuracy of c entris component identification results.
for cases validation result t p f p f n precision recall automated verification results paths v p n a n a n a n a header files v h n a n a n a n a metadata files v m n a n a n a n a combined all automated verification methods v p vh vm n a n a n a n a manual verification .
.
total .
.
according to our definition all the results verified by the validation methods are tp thus the remaining columns are filled with n a. among the cross comparison results we successfully validated results using the automated verification and the remaining detection results were analyzed by the manual verification.
the manual verification was performed by two people and took two weeks.
we manually viewed the paths header files and metadata files as well as the reused source code and comments within the source code to determinewhether the identified oss is the correct component.
the accuracy measurement results are presented in table iii.
although most of the detected oss components were reused with modification c entris achieved precision and recall.
although c entris precisely identified reused components in most cases it reported severalfalse results.
we observed that false positives were mainlycaused when the target software and the detected component only shared the third party software that was not includedin our component db.
hence the application code of oss projects was not properly obtained resulting in false alarms.in addition if the reuse ratio of the application code of the oss was less than or the reused component was not included in the component db c entris failed to detect the correct oss components i.e.
false negatives occurred.
however simply decreasing for reducing false negatives can impair precision.
expanding current component db such as collecting more oss projects from various sources wouldbe an efficient solution to reduce false results even so webelieve that the method of minimizing false alarms throughthe proposed code segmentation works efficiently and the selected simultaneously maintains a good balance in terms of precision and recall.
v ersion identification accuracy.
some components are not managed by the versioning system and further the target software often does not reuse files or codes containing versioninformation of a reused component.
subsequently we decided to measure version identification accuracy for the three mostwidely reused oss projects in our results googletest lua and zlib.
their version information is relatively well definedcompared to that of other oss while still providing a suffi cient pool to measure the accuracy.
in our cross comparisonexperiment these three oss projects were reused a total of682 times.
approximately half of the reuses provided the utilized version using related files zlib.h in zlib readme in lua and changes in googletest.
when these files weretable iv v ersion identification accuracy of c entris .
reuse patterns t p f p precision exact reuse e modified reuse p sc p cc p sc cc total .
e exact reuse p partial reuse sc structure changed reuse cc code changed reuse not reused in the target software the version information wasmanually analyzed e.g.
using the commit log .
the version identification result is presented in table iv.
partial reuse mainly occurred in lua code changes mostly appeared in zlib and structural changes primarily arose in googletest.
c entris succeeded in identifying the utilized version information with .
precision.
we failed to identify the accurate version in some modified reuse cases especially when the functions from different versions in extreme cases more than versions of an oss were mixed in the target software i.e.
code changed reuse.
in such cases we determined that notonly is identifying the correct version a challenge but alsothat the version identification is meaningless.
therefore weconcluded that identifying the oss reuse and the most similarversion would be sufficient for the code changed reuses.
b. in depth comparison with d ej avu tool selection.
we reviewed several related approaches published since however most sca approaches are only applicable to identifying components in android applicationsor software binaries .
for example osspolice is open to the public but its targets are android applica tions.
moreover as the parser for the c c library is not open source it would be difficult to apply their algorithm to our experiment.
therefore we decided to compare c entris with d ej avu a similar approach in terms of technology and purpose .
d ej avu is based on the code clone detection technique i.e.
sourcerercc and it aims to analyze the software dependencies among github repositories by detecting project level clones.
thus we concluded that the detection results ofd ej avu can be compared with those of c entris .
methodology.
currently the d ej avu software is not publicly available only the detection results previously obtained using the dataset i.e.
github c c repositories in are provided2.
we thus attempted to examine the component identification results of the common datasets between c entris and d ej avu and compare them.
in particular d ej avu determined the existence of a dependency based on the code similarity score between the two software projects.
we set thesimilarity threshold to and in d ej avu refer to and analyzed the number of correct target software and oss component pairs from their results where the similarity score exceeded the selected threshold.
c entris employs as .
to demonstrate the efficiency of code segmentation we provide both component identification results when code segmentation is turned on and off.
867table v component identification results of d ej avu and c entris .
centris with cs centris without cs d ej avu classified by the threshold software t f p f n t f p f n t f p f n t f p f n t f p f n arangodb crown cocos2dx splayer total precision .
.
.
.
.
recall .
.
.
.
.
cs code segmentation t the number of true positives fp the number of false positives f n the number of false negatives.
table vi oss reuse patterns in the four software projects.
softwarereuse patterns exact partial structure changed code changed arangodb crown cocos2dx splayer total p sc and cc can occur simultaneously in the modified component.
comparison results.
among our cross comparison results four of the top software projects i.e.
arangodb crown cocos2dx classical and splayer with the maximum oss reuse were observed to be part of the d ej avu datasets as well.
we decided to compare the oss component detection results between c entris and d ej avu for these four software projects the results are listed in table v. d ej avu failed to identify many modified components.
in fact most identified components for the selected softwarewere reused with modifications see table vi .
as d ej avu could not identify components when the reused code ratio was less than the selected threshold the results showed low recallvalues i.e.
at most .
moreover although d ej avu aimed to detect project level clones its mechanism did not includea handling routine for false positives caused by nested oss.subsequently d ej avu reported many false positives i.e.
it showed and precision when the threshold was selected as and respectively.
even though d ej avu showed precision when the threshold was selected as itcould not detect any partially reused components as indicated by the fact that the recall was .
in contrast c entris yielded substantially better accuracy than d ej avu i.e.
precision and recall when the code segmentation is applied.
in the absence of code seg mentation c entris reported numerous false positives i.e.
precision with the same cause as d ej avu this implies that the method of using only the application code of oss formatching through code segmentation can successfully filter outcountless false positives.
lastly oss components that wereidentified only in d ej avu and not identified in c entris did not appear in the four software projects.
c. speed and scalability of centris efficacy of redundancy elimination.
we can reduce space complexity by eliminating redundancies across oss versions.
the total number of functions in all versions of every osscentris first exp.
sourcerercctime in hours 200a minute nthexp.
1m 10m 100m 1b 5b98 hours first exp.
dataset loc centris nthexp.
the limitation of sourcerercc due to memory error fig.
total time consumed on varying dataset sizes.
c entris exhibited tremendous time efficiency because of recycling of the preprocessed oss projects in the dataset whereas sourcerercc required approximately three weeks to process the matching using the billion loc dataset.
project that we collected is .
after eliminating redundancies we confirm that the number of non redundantfunctions only accounts for .
functions ofthe total functions indicating that the size of the comparison space can be reduced by times compared to all functions.
speed.
when we measured the preprocessing extracting functions from the oss storing hashed functions and generating the component db time of c entris on average it took min to preprocess million loc.
note that the oss doesnot need to be preprocessed again after it undergoes initialpreprocessing.
in contrast component identification occursfrequently.
hence it is necessary to achieve fast speeds for practical use.
when we compared representative versions with the component db c entris took less than hours in total.
this implies that c entris takes less than a minute per target application on average which is sufficientlyfast for practical use.
scalability.
to evaluate the scalability of c entris we measured the time taken to compare the target software of million loc with different datasets ranging from million to billion loc.
we compared the performance of c entris with that of the core algorithm of d ej avu sourcerercc .
figure depicts the results.
in the first experiment c entris required hours for preprocessing and matching.
after thefirst experiment because c entris could recycle the preprocessed component db the required time was significantly reduced to less than a minute.
sourcerercc needed threeweeks for billion loc dataset and when the dataset was increased in size we could not measure the time consumed owing to memory errors in our evaluation environment even ifthe experiment is performed with a larger memory we expectthe processing time to be significantly high.
d. findings on oss reuse patterns from the cross comparison result we found that oss projects were reusing at least one other oss.
surprisingly the modified reuses accounted for of the detected components.
the distribution of detected reuse patterns and the average degree of modification are depicted infigure .
we summarize two key observations as follows.
partial reuse accounts for of all modified reuses.
we observed that developers were mostly reusing only part of the oss code base they needed.
mainly functions deemed 868e p p cc p cc sc others sc cc p sc sc cc summary of all reuse patterns average degree of modification target softwareoss unused reused with code changes fig.
depiction of detected reuse patterns and averaged modification degree obtained from our experiment.
partial reuse appeared the most and we found that developers reused only half of the oss code base with code changeson average.
unnecessary for the target software to perform the desired operation testing purposed functions such as located in test directory and cross platform support functions were excludedduring an oss reuse.
code and structural changes also frequently occur .
among all modified reuses changed at least one original function and changed the original structure.
we found that code changes occurred primarily due to developers attempts to adapt the reused functions to their software e.g.
change variable names and to fix software vulnerabilities propagatedfrom reused oss.
moreover we observed that the reused functions of an oss are often merged in a single file ratherthan scattered in different structures.
for example rebol software reused only of libjpeg while integrating all ofthe reused functions into src core u jpg.c.
our observation results suggest the need to detect heavily modified components i.e.
only of the oss code base were reused on average but the existing approaches did notconsider this trend e.g.
both d ej avu and osspolice selected the lowest threshold as hence failed to identify manycorrect components.
from this point of view c entris would be a better solution for the efficient sca process as it canprecisely identify modified components.
vi.
d iscussion a. function level granularity although the design of c entris is applicable to any granularity the benefits we can obtain by using each granularityare certainly different in terms of both the accuracy and thescalability in component identification.
we confirmed that the function level granularity works best for balancing scalability and accuracy in component identification thus the function units were used for our experiments as the basis.
if c entris uses a coarse grained unit e.g.
a file c entris is able to identify components with higher scalability however centris misses many partial and code changed reuses.
to demonstrate this we analyzed the components detected by c entris insection v. specifically when we detectedcases where more than i.e.
of all files in the component were reused exactly only cases of them belonged to these cases.
this is because developers often reuse only necessary functions in a file while excluding unnecessary functions e.g.
functions used for testing .
conversely if c entris uses a finer grained unit e.g.
a line or a token c entris can analyze more detailed reuse patterns yet the disadvantages are clear the poor scalability and more false alarms due to a short generic code.
our componentdb contains a total of billion lines of source code and itis not trivial to compare them with all the lines of sourcecode of the target software.
in addition as simple and generic codes e.g.
a variable declaration code line such as int i are widely spread among software that does not have a reuse relation this yields more false alarms.
thus we determined that the function level granularity was most balanced reasonable scalability see section v c fewer false positives and false negatives than the line level and filelevel granularity respectively the benefits of the function level granularity have been discussed in previous studies specifically vuddy introduced the scalabilityand accuracy comparisons between function units and otherunits in detail .
b. generalizability of c entris the generalizability of a tool is an important issue from a practical point of view .
in section v we evaluated c entris over extensively reused popular github projects considering them as a representative body of oss and observed promising results.
this gives us confidence that centris will work well in all contexts of oss projects that fit in the ecosystem.
for one thing the code segmentation of c entris is affected by the number of oss contained in the dataset i.e.
the component db .
if the approach of c entris performed with fewer oss than used in this paper the identification accuracy may slightly decrease meanwhile if c entris identifies components with a larger and more refined dataset the higher component identification accuracy can be obtained.
we leavethe task of finding the most optimal number of oss that willbe contained in the component db to future work.
c. implications for practice to the best of our knowledge none of the existing approaches are applicable to precisely identify modified oss components.
yet our experimental results affirmed that themodified reuses are prevalent in the real world popular ossecosystem.
c entris is a design science research with a clear goal to design and improve an algorithm i.e.
artifact in the context of identifying modified oss reuse from the software based on two techniques code segmentation and redundancyelimination.
from this point of view c entris can be the first step towards addressing problems arising from unmanagedoss components in practice.
in particular with the help of 869centris developers can precisely identify the reused modified components and further address potential threats arising from unmanaged components e.g.
by updating components .
d. use case software vulnerability management one potential use case of c entris is software vulnerability management which reduces security issues by identifyingnewly found but unpatched vulnerabilities.
below we discuss our experience of using c entris in this regard.
by referring to the national vulnerability database nvd we can obtain the affected software and version informa tion i.e.
common platform enumeration cpe for each reported vulnerability.
we have extensively examined whether the names and versions of detected oss components areincluded in the obtained cpe .
consequently c entris discovered that oss projects contain at least one othervulnerable oss component.
among them oss projects are still reusing the vulnerable oss in their latest version.
for the cases of successfully reproducing the vulnerability we have reported to the corresponding vendors.
of these the most notable example related to modified reuse is godot 32k github stars .
we found that the latest version of godot was reusing vulnerable jpeg compressor contains cve cvss .
.
godot was reusing only one file from jpeg compressor jpgd.cpp which contains the exactvulnerable code.
more seriously this vulnerability could be reproduced by simply uploading a malicious image file to thegodot project.
we reported this information on their reposi tory s issues developers immediately patched the vulnerability jul.
.
likewise we could successfully reproduce a vulnerability in stepmania audacity so far reusing vulnerable libvorbis libgdx reusing vulnerable jpeg compressor and redis reusing vulnerable lua for all cases we reported to the corresponding development and security teams and confirmed that proper actions were taken such as vulnerability patches.even though developers reuse only a small part of an oss the vulnerability in that part opens up the attack surface.
to address this we can apply c entris for more attentive vulnerability management as shown here.
e. threats to validity first although our dataset is more expansive compared to those in previous approaches the benchmark oss projects utilized herein might not be representative.
second to the best of our knowledge there are no approaches that directly attempt to identify modified components.
although we conducted an in depth comparison with d ej avu our intention is not to deny the accuracy and performance of d ej avu but to demonstrate that our approach is much more efficient for the purpose of identifying modified components.
finally there may behidden components in a target software that both c entris and d ej avu failed to identify as all oss reuse statuses are not known we cannot exactly measure the missed components and these are the false negatives of c entris .vii.
r ela ted work code clone detection.
over the past decades numerous techniques have been proposed to detect code clones and c entris adopts a signature based clone detection method .
however as we demonstrated in this paper using an existing clone detection technique as it issuffers from false alarms when identifying modified reuse of nested oss.
software composition analysis.
existing sca techniques are not accurate enough to identify modified oss reuse.
duan et al.
proposed osspolice to find third party libraries of an android application.
they utilized constant features of obfuscation to extract the version information and determine if vulnerable versions were utilized.
they minimized false alarms through hierarchical indexing and matching.
since their concern is more on accurately identifying third party libraries at the binary level thus it differs from our concern to detecting modified components.
backes et al.
and bhoraskar et al.
also do not consider detection of modified oss reuse.
copilot analyzes security risks that arise from unmanaged oss components.
however as it is based on dependency files it can be applied only for languagesin which dependencies are managed.
to our knowledge andexperience commercial sca tools such as black duck hub by synopsys and antepedia do not consider modified reuse and hence miss many reused components.
viii.
c onclusion identifying oss reuse is a pressing issue in modern software development practice because unmanaged oss components pose threats by increasing critical security and legal issues.
in response we presented c entris which departs significantly from existing techniques by enabling precise and scalableidentification of reused oss components even when they areheavily modified and nested.
with the information providedby c entris developers can mitigate threats that arise from unmanaged oss components which not only increases themaintainability of the software but also renders a safer devel opment environment.
d ata av ailability we service c entris as a form of open web service at iotcube the source code and dataset i.e.
the component db used in section v is available at acknowledgment we appreciate the anonymous reviewers for their valuable comments to improve the quality of the paper.
this workwas supported by institute of information communica tions technology planning evaluation iitp grant funded by the korea government msit no.
development of automated vulnerability discovery technologiesfor blockchain platform security and no.
ictcreative consilience program .
870references open source security and risk analysis ossra synopsys audits show open source risks .
the github blog thank you for million repositories github h. li h. kwon j. kwon and h. lee clorifi software vulnerability discovery using code clone verification in concurrency and computation practice and experience vol.
no.
.
wiley online library pp.
.
s. kim s. woo h. lee and h. oh vuddy a scalable approach for vulnerable code clone discovery in proceedings of the 38th ieee symposium on security and privacy sp .
ieee pp.
.
r. duan a. bijlani m. xu t. kim and w. lee identifying opensource license violation and day security risk at large scale inproceedings of the acm sigsac conference on computer andcommunications security ccs .
acm pp.
.
s. kim and h. lee software systems at risk an empirical study of cloned vulnerabilities in practice computers security vol.
pp.
.
software composition analysis explained whitesource software composition security analysis .
technology insight for software composition analysis gartner inc. .
a. s. barb c. j. neill r. s. sangwan and m. j. piovoso a statistical study of the relevance of lines of code measures in software projects ininnovations in systems and software engineering vol.
no.
.
springer pp.
.
h. sajnani v .
saini j. svajlenko c. k. roy and c. v .
lopes sourcerercc scaling code clone detection to big code in ieee acm 38th international conference on software engineering icse .
ieee pp.
.
c. v .
lopes p .
maj p .
martins v .
saini d. yang j. zitny h. sajnani and j. vitek d ej avu a map of code duplicates on github in proceedings of the acm on programming languages vol.
no.
oopsla .
acm p. .
p .
wang j. svajlenko y .
wu y .
xu and c. k. roy ccaligner a token based large gap clone detector in proceedings of the 40th international conference on software engineering icse .
acm pp.
.
c. w. krueger software reuse in acm computing surveys csur vol.
no.
.
acm pp.
.
m. l. griss software reuse architecture process and organization for business success in proceedings of the eighth israeli conference on computer systems and software engineering.
ieee pp.
.
r. duan a. bijlani y .
ji o. alrawi y .
xiong m. ike b. saltaformaggio and w. lee automating patching of vulnerable open source software v ersions in application binaries in in proceedings of the annual network and distributed system security symposium ndss .
a. lee and t. atkison a comparison of fuzzy hashes evaluation guidelines and future suggestions in proceedings of the southeast conference.
acm pp.
.
g. salton and m. j. mcgill introduction to modern information retrieval.
new y ork mcgraw hill book company .
v ersion control systems popularity in rhodecode https rhodecode.com insights version control systems .
universal ctags ctags j. kornblum identifying almost identical files using context triggered piecewise hashing in digital investigation vol.
.
elsevier pp.
.
v .
roussev hashing and data fingerprinting in digital forensics in ieee security privacy vol.
no.
.
ieee pp.
.
j. oliver c. cheng and y .
chen tlsh a locality sensitive hash in f ourth cybercrime and trustworthy computing workshop.
ieee pp.
.
g. m. kapitsaki n. d. tselikas and i. e. foukarakis an insight into license tools for open source software systems journal of systems and software vol.
pp.
.
s. ikeda a. ihara r. g. kula and k. matsumoto an empirical study of readme contents for javascript packages ieice transactions on information and systems vol.
no.
pp.
.
z. ma h. wang y .
guo and x. chen libradar fast and accurate detection of third party libraries in android apps in proceedings of the 38th international conference on software engineering companion pp.
.
m. backes s. bugiel and e. derr reliable third party library detection in android and its security applications in proceedings of the acm sigsac conference on computer and communications security ccs pp.
.
m. li w. wang p .
wang s. wang d. wu j. liu r. xue and w. huo libd scalable and precise third party library detection in android markets in proceedings of the 39th international conference on software engineering icse .
ieee pp.
.
w. tang d. chen and p .
luo bcfinder a lightweight and platformindependent tool to find third party components in binaries in 25th asia pacific software engineering conference apsec .
ieee pp.
.
an open source management solution copilot blackducksoftware.com .
s. ghaisas p .
rose m. daneva k. sikkel and r. j. wieringa generalizing by similarity lessons learnt from industrial case studies in2013 1st international workshop on conducting empirical studies in industry cesi .
ieee pp.
.
r. wieringa and m. daneva six strategies for generalizing software engineering theories science of computer programming vol.
pp.
.
r. j. wieringa design science methodology for information systems and software engineering.
springer .
b. s. baker on finding duplication and near duplication in large software systems in reverse engineering proceedings of 2nd working conference on.
ieee pp.
.
i. d. baxter a. yahin l. moura m. sant anna and l. bier clone detection using abstract syntax trees in proceedings.
international conference on software maintenance.
ieee pp.
.
r. komondoor and s. horwitz using slicing to identify duplication in source code in international static analysis symposium.
springer pp.
.
t. kamiya s. kusumoto and k. inoue ccfinder a multilinguistic token based code clone detection system for large scale source code inieee transactions on software engineering vol.
no.
.
ieee pp.
.
g. myles and c. collberg detecting software theft via whole program path birthmarks in international conference on information security.
springer pp.
.
z. li s. lu s. myagmar and y .
zhou cp miner a tool for finding copy paste and related bugs in operating system code in osdi vol.
no.
pp.
.
g. myles and c. collberg k gram based software birthmarks in proceedings of the acm symposium on applied computing.
acm pp.
.
l. jiang g. misherghi z. su and s. glondu deckard scalable and accurate tree based detection of code clones in proceedings of the 29th international conference on software engineering icse .
ieee computer society pp.
.
s. schleimer d. s. wilkerson and a. aiken winnowing local algorithms for document fingerprinting in proceedings of the acm sigmod international conference on management of data.
acm pp.
.
c. k. roy and j. r. cordy a survey on software clone detection research in queen s school of computing tr vol.
no.
pp.
.
nicad accurate detection of near miss intentional clones using flexible pretty printing and code normalization in 16th ieee international conference on program comprehension.
ieee pp.
.
y .
semura n. y oshida e. choi and k. inoue ccfindersw clone detection tool with flexible multilingual tokenization in asia pacific software engineering conference apsec 24th.
ieee pp.
.
m. a. nishi and k. damevski scalable code clone detection and search based on adaptive prefix filtering in journal of systems and software vol.
.
elsevier pp.
.
a source code search engine searchcode d. luciv d. koznov g. chernishev h. a. basit k. romanovsky and a. terekhov duplicate finder toolkit in proceedings of the 40th international conference on software engineering companion proceedings.
acm pp.
.
m. gharehyazie b. ray m. keshani m. s. zavosht a. heydarnoori and v .
filkov cross project code clones in github in empirical software engineering.
springer pp.
.
t. vislavski g. rakic n. cardozo and z. budimac licca a tool for cross language clone detection in ieee 25th international conference on software analysis evolution and reengineering saner .
ieee pp.
.
r. bhoraskar s. han j. jeon t. azim s. chen j. jung s. nath r. wang and d. wetherall brahmastra driving apps to test the se curity of third party components in proceedings of the 23rd usenix security symposium security pp.
.
a complete open source management solution by synopsys black duckhub a comprehensive software analysis solution synopsys .
a software artifacts knowledge base the service is currently hold antepedia s. kim s. woo h. lee and h. oh poster iotcube an automated analysis platform for finding security vulnerabilities in proceedings of the 38th ieee symposium on poster presented at security and privacy .