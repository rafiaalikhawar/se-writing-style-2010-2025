fairness testing through extreme value theory verya monjezi vmonj uic.edu university of illinois chicago vladik kreinovich vladik utep.edu university of texas at el pasoashutosh trivedi ashutosh.trivedi colorado.edu university of colorado boulder saeid tizpaz niari saeid uic.edu university of illinois chicago abstract data driven software is increasingly being used as a critical component of automated decision support systems.
since this class of software learns its logic from historical data it can encode or amplify discriminatory practices.
previous research on algorithmic fairness has focused on improving average case fairness.
on the other hand fairness at the extreme ends of the spectrum which often signifies lasting and impactful shifts in societal attitudes has received significantly less emphasis.
leveraging the statistics of extreme value theory evt we propose a novel fairness criterion called extreme counterfactual discrimination ecd .
this criterion estimates the worst case amounts of disadvantage in outcomes for individuals solely based on their memberships in a protected group.
utilizing tools from search based software engineering and generative ai we present a randomized algorithm that samples a statistically significant set of points from the tail of ml outcome distributions even if the input dataset lacks a sufficient number of relevant samples.
we conducted several experiments on four ml models deep neural networks logistic regression and random forests over socially relevant tasks from the literature on algorithmic fairness.
first we evaluate the generative ai methods and find that they generate sufficient samples to infer valid evt distribution in of cases.
remarkably we found that the prevalent bias mitigators reduce the average case discrimination but increase the worst case discrimination significantly in of cases.
we also observed that even the tail aware mitigation algorithm minimax fairness increased the worst case discrimination in of cases.
we propose a novel ecd based mitigator that improves fairness in the tail in of cases with no degradation of the average case discrimination.
we hope that the evt framework serves as a robust tool for evaluating fairness in both average case and worst case discrimination.
i. i ntroduction recent technological advancements in training large machine learning ml models such as deep neural networks deep reinforcement learning and large language models have led to a proliferation of data driven software in almost every aspect of modern socioeconomic infrastructure.
these data driven systems such as those that decide on recidivism predict benefit eligibility or decide whether to audit a given taxpayer learn their decision logic as ml models by mining simple patterns from historical data.
however these systems often codify and amplify the biases present in the historical data due to various systemic factors.
to address this challenge the software engineering community has developed solutions to characterize quantify and mitigate bias in the ml models.
we discuss their inadequacies and propose new tools and techniques for the tail of outcome distributions of data driven software.
inadequacies of average case fairness.
although there is an increased participation of minorities e.g.
women in the labor market parity in average they are considerably underrepresented in high paying occupations and leadership positions disparity in the extreme .
additionally the wage gap between privileged and unprivileged individuals continues to be more pronounced in high paying jobs .
considering these factors it is indeed surprising that a notable gap exists in the literature regarding the evaluation of algorithmic fairness in the context of extreme outcomes.
one broad class of fairness definitions is individual fairness which requires treating individuals similarly if they are deemed similar based on their non protected attributes regardless of their protected attributes.
one popular individual fairness notion is counterfactual discrimination which necessitates that algorithmic outcomes should be similar for an individual and any related counterfactual individual who differs only in protected attributes.
however these fairness notions primarily focus on the average behavior expected value or variance of the model which can create a false sense of fairness by ignoring the discrimination in socially influential edge cases.
this paper presents a framework rooted in evt to quantify ai fairness within the tail of ml outcomes.
statistics of the extreme extreme value theory.
while statistics and machine learning typically focus on usual behavior extreme value theory evt is a branch of statistics that deals with unusual or extreme behaviors.
evt can be applied to model rare events such as the maximum temperature in the summer.
under appropriate assumptions the statistics of extreme values follow the generalized extreme value gev distribution which is analogous to the central limit theorem for the statistics of averages or expected values.
fairness through extreme value theory.
the primary focus of this paper centers on a narrow view of equality of opportunity which necessitates similar individuals to be treated similarly at the time of decision making as defined by dwork et al.
.
we consider the distribution of counterfactual discrimination which refers to the distribution ofarxiv .11597v1 jan 2025differences in the ml outcomes when a protected attribute like race or gender is altered from observed value a to a counterfactual b. while previous studies have focused on the expected values from this distribution known as average causal discrimination acd representing the average change in the outcome when a protected attribute is flipped this work quantifies the maximum change in the ml outcome when a protected attribute is flipped.
we call this quantity extreme counterfactual discrimination ecd and use gev distributions to model and quantify it.
by comparing the gev distributions of different sub groups we quantify the fairness of ml models in the extreme tail of outcome distributions as well as the effectiveness of mitigation algorithms in reducing discrimination in the tail.
the ecd metric proposed in this paper has a normative implication.
it tells us in the worst case how much dis advantages are experienced by individuals solely due to their memberships in un privileged groups at the time of ml decision making.
our proposal complements t hemis that shows the amounts of such discrimination on average.
for example an acd of .
vs. an ecd of .
for an unprivileged group show that flipping their protected attributes to a privileged group increased their likelihood of receiving favorable ml outcomes by on average but up to in the worst case.
the statistics of evt allow us to directly model gev distributions that bring significant advantages.
it directly models the tail distribution which allows us to investigate the validity of the tail or provide statistical guarantees on the returns likelihood of extreme discrimination.
other metrics like the conditional value at risk cvar model the tail of a usual distribution e.g.
normal distributions .
hence they fail to reason about the validity of the tail and provide any statistical guarantees on extrapolations.
statistical ecd testing framework.
in this paper we have developed a randomized test case generation algorithm that explores the tail of ml models and applies the exponentiality test to convince statistical significance.
the primary challenge stems from the statistical test s requirements for a certain size of tail samples and the scarcity of samples in the extreme tail which is precisely why they are considered extreme .
if only a subset of these tail samples is included in the analysis it can result in low confidence in the model due to high variance.
on the other hand selecting a larger number of data points will lead to the erroneous inclusion of non tail samples and the inference of mixture distributions that violate the asymptotic basis of extreme value theory.
rather than randomly generating the test cases from the domain of variables we leverage and evaluate various generative methods such as gans and v aes to synthesize samples with realistic combinations of features.
experiments.
we conducted experiments on nine fairnesssensitive datasets with four popular classifiers an overall training scenarios .
our findings indicate that evt fits well to the tail of counterfactual bias distributions in of cases that enable us to derive worst case guarantees.
in of scenarios the worst case and average case cd differ significantly across different groups.
we also evaluated the characteristics of fairness in the tail over four mitigation algorithms exponentiated gradient eg fair smote maat and stealth .
our results over the mitigated model show that the worst case and average case cd differ significantly across different groups in of cases.
in addition the average based mitigated models significantly increase worstcase discrimination in of the cases while preserving or improving average fairness in of cases.
with tail based methods we implement an in process mitigation strategy that outperforms minimax fairness and reduces the discrimination in the tail for of cases while improving average fairness in of cases.
contributions.
in this paper we introduce a metric to measure unfairness in the tail of ml outcome distributions present a fairness testing method that generates realistic test cases and provides statistical guarantees in the tail evaluate the worst case discrimination for a large set of well established algorithms and bias mitigators and propose and evaluate a novel tail aware mitigator.
ii.
o verview we first give a background overview for extreme value theory.
we then go through our approach step by step using an example of adult census income dataset trained using a dnn algorithm.
extreme value theory.
given a set of independent and identically distributed random variables z1 .
.
.
z n the extreme value theory is concerned with the max statistics of a random process i.e.
mn max z1 .
.
.
z n .
under some mild assumptions it has been proved e.g.
see leadbetter et al.
that mnbelongs to a family of distributions called thegeneralized extreme value gev .
there are two basic approaches to infer the parameters of gev distributions block maximum and threshold approach .
in this paper we use the threshold approach where extreme events that exceed some high threshold u i.e.
zi zi u are extreme values.
the gev distribution has three parameters a location parameter a scale parameter and a shape parameter.
when the shape is close to zero or negative the statistical guarantees on the worst case discrimination may be feasible.
threshold selection.
a proper choice of threshold value u is critical to analyze the behavior of gev .
low values of threshold umight include non tail samples and lead to mixture distributions that violate the asymptotic basis of the model.
on the other hand high values of threshold umight include only a few tail samples and lead to low confidence in the model due to high variance.
in this work we use coefficient of variation cv and provide statistical guarantees in picking thresholds.
return level.
areturn level describes by the set of points m m where mis the time period e.g.
the number of queries to the ml software and the level mis expected to observed during the mperiod e.g.
maximum discrimination afterminteractions .fig.
counterfactual discrimination of dnn left the observed cd for white with the threshold red line at .
mid left the observed cd for black with the threshold line at .
.
cd of mitigated dnn mid right the observed cd for white with the threshold line sets at .
and right the observed cd for black with the threshold line sets at .
.
dataset.
the adult census income dataset is a binary classification dataset used to predict whether an individual has an annual income over 50k.
it consists of instances and14attributes.
in our study we consider race as the protected attribute and compare the outcomes between white and black individuals.
ml model and typical fairness.
we used the same neural network architecture as previous literature on fairness testing which is a six layered fully connected neural network with neurons that produces probabilities from the raw logit scores.
the model was trained on the adult census income dataset using the adam optimizer with a learning rate of .
.
the accuracy of the model on the test data is .
the true positive rates for white and black individuals are .
and .
respectively.
this yields an average odd difference aod of .
.
test case generations.
the search algorithm samples and test cases for white and black groups respectively.
for each sub group we compute the likelihood of a favorable outcome for the original sample and its counterfactual i.e.
counterfactual discrimination cd .
figure left part shows the cd of these samples for the white and black sub groups.
the mean and standard deviation of cd are .
.
and .
.
for the white and black groups.
inferring extreme value distributions.
figure left part shows cd of samples with the threshold red lines for white and black groups where red points are extreme values.
to infer the parameters of gev distribution we set the threshold to .
and .
for white and black groups allowing only samples to exceed the threshold .
given this criterion the estimated location scale and shape are .
.
.
.
and .
.
for white and .
.
.
.
and .
.
for black respectively.
fairness measures through extreme value distributions.
we use the characteristics of gev distributions to measure the amounts of discrimination between two groups in the tail of the dnn outcomes.
figure shows the gev density plot for white left and black mid left sub groups.
while the average of cds for these two groups differ by .
favoring white the expected extreme cds differ by .
.
crucially gev distributions allow us to compute the expected return levels rl for a given number of interactions.
table i original dnn shows the rls.
for instance the table indicates that thetable i return levels of ecd for original vs. mitigated.
num.
original dnn mitigated dnn interactions rl white rl black rl white rl black .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
worst case cds of .
and .
are expected in the next interactions for white black sub groups respectively.
validating prevalent fairness mitigators.
we validate the behaviors of popular in process and pre process bias mitigators exponentiated gradient eg and fairsmote in the tail.
when using eg the average odd difference is .
which shows improvements in the averagecase fairness with only accuracy loss.
figure right parts shows cd values for the mitigated dnn with a threshold red line set at .
and .
for white and black respectively.
the estimated location scale and shape of gev are .
.
.
.
and .
.
for white and .
.
.
.
and .
.
for black respectively a significant increase in the tail discrimination see figure right parts .
the rls of the mitigated models have also significantly increased as shown in table i. within the white sub group in the next interactions we expect an extreme bias of .
in the dnn whereas an rl of .
is expected for the mitigated dnn.
for the black sub group the expected rl has increased from .
to .
.
tail aware bias reduction algorithms.
we first validate the minimax fainess a tail aware bias reduction algorithm.
compared to the eg the minimax fairness reduces the ecd to .
and degrades the average based fairness by .
.
we guide an in process bias mitigator that reduces the ecd to .
while degrading average based fairness only by .
.
iii.
e xtreme counterfactual discrimination we consider machine learning classifiers with a set of input variables a which are divided into a protected set of variables z e.g.
race sex and age and non protected variables x e.g.
profession income and education .
a learning problem can be defined as identifying a mapping from the inputs to a probabilistic score of the favorable outcome inferred from a fixed training dataset dt xi zi yi n i such that the ml model generalizes well to previously unseen situations based on a test dataset d x i z i y i m i .
we abstractly express a machine learning classifier as a function ml x z .
the accuracy of model isfig.
the density of gev for dnn left the density for white with the location of .
and scale of .
mid left the density for black with the location of .
and the scale of .
.
the density of gev for mitigated dnn mid right the density of gev distributions for white with the location of .
and scale of .
right the density of gev distributions for black with the location of .
and the scale of .
.
measured for the fraction of points in d that satisfy the predicate ml x i z i .
y i. as a convention we letzi indicate membership in a privileged group and zi in the unprivileged group.
definition iii.
cd .given an individual with non protected value x xand protected attribute z z the amount of discrimination over the protected attribute ibased on the causal fairness notion defines as the difference between ml outcomes over the individual and its counterfactual i.e.
cd x z ml x z ml x z where z i ziwithz j zjfor all protected attributes j i rand cd .
the positive values indicate that the ml model disadvantages the individual xin the group z whereas the negative values show unfair advantages for the membership in z z. considering individuals with zi the average causal discrimination for sub groups privileged and unprivileged is acd p ezi 1cd x z andacd u ezi 0cd x z .
previously t hemis used z score testing with an assumption about the normal distribution of counterfactual outcomes to deem discrimination between two groups.
from a practical standpoint it is crucial to ensure fairness on average outcomes e.g.
t hemis as well as in the tail.
definition iii.
ecd .given an ml model and a protected attribute zi our goal is to model the statistics of extreme counterfactual discrimination for each group i.e.
mp max zi 1cd x z andmu max zi 0cd x z compute whether the difference between two groups mpand mu is statistically significant to detect a discrimination in the tail provide worst case guarantees on the amounts of discrimination and mitigate biases in the tail.
iv.
a pproach we are interested in determining the maximum values of counterfactual discrimination denoted as mpfor privileged groups and mufor unprivileged groups.
since these values for different individuals are independent of each other we can consider the estimation over a large number of independent and identically distributed random variables.
extreme value theory is the field of study that examines the limit distributions of such extreme values and the convergence towards these distributions.
our objective therefore is to estimate the worst case counterfactual discrimination by comparing the statistical characteristics of gev distributions between privileged and unprivileged sub groups.
however analyzing extreme values necessitates having an adequate number of samples from the tail behavior of ml models for any given group to have confidence in the results.
our approach comprises three key steps learning the underlying distributions of the target population to generate valid samples for any sub group collecting tail samples with statistical guarantees through a randomized test case generation algorithm and inferring the tail distributions of counterfactual discrimination by fitting gev distributions to each group and comparing the results to determine statistically significant discrimination in worst case scenarios.
learning the underlying distributions.
the scarcity of samples for some protected groups in datasets can result in statistical uncertainties in extreme value distributions.
for instance in the heart dataset the number of samples for male individuals is notably limited.
the conventional approach of sampling data points uniformly at random from the domain of each variable without considering the relationships between variables has the risk of producing samples that do not represent the target group .
for example random generation could result in an income level that is out of line with the general age distribution.
generative adversarial networks gans and variational autoencoders v ae have been shown to effectively learn and reproduce actual data distributions making them suitable for generating synthetic data that closely resembles the realworld distributions of sensitive groups .
in the gan paradigm during the training phase the generator s primary function is to produce synthetic data samples while the discriminator is tasked with distinguishing between real and synthetic samples.
after multiple rounds of training the generator learns to generate data so indistinguishable from the original samples.
v aes on the other hand are trained by encoding input data into a latent representation and recovering it afterward.
the decoder then reconstructs the input using the sampled latent points.
training involves optimizing two essential components the reconstruction loss and the kullback leibler kl divergence.
however in addition to making sure to learn the target distribution of each demographic to alleviate the risk ofalgorithm tail sample generations.
input decision support ml software ml generative adversarial network gan training dataset d test samples d target group g counterfactual group g low bounds on exp.
test kmin upper bounds on exp.
test kmax num.
of gan samples m and timeout t. 1done false 2while t t orpassed do y ml d g y ml d g y y hq samples true fork kmin tokmax do ifsize kmax then hq samples false break select top k k average std cvk ifcvk .
k then hq samples false break else passed hq samples true true ifnot hq samples then d d data generator d g m 21return d unrealistic data generation we also need to ensure that they generate samples proportional to the representation of groups in the original dataset.
in so we explore conditional tabular gan ctgan and triplet based variational autoencoder tv ae .
ctgan and tv ae are specialized for tabular data capable of handling mixed variable types and complex relationships unlike traditional gans and v aes which focus more on image data.
previosly xiao et al.
used ctgan to generate natural test cases in fairness testing as well.
ctgan allowed them to improve the naturalness of test cases by on average compared to the baseline .
in our application the generator learns to produce samples for a given protected group as a target that closely reflects the underlying distribution of the group.
collecting tail samples with statistical guarantees.
algorithm shows our approach to assess the fairness of ml models in the tail.
given a dataset its protected attribute the target group and a ml model we first initialize the testcase samples d to all samples from the target group e.g all samples with race white and compute the likelihood of favorable outcomes of the ml model for this target group line .
we do the same for the counterfactual group byflipping the value of the protected attribute e.g.
white to black line .
we set the counterfactual discrimination for the target group as the differences in the ml outcomes between the counterfactual and original group line .
then we start our search algorithm to collect enough samples to fit the evt distributions on the tail.
in so we perform the exponential test adopted from on the current samples d line .
this test utilized the coefficient of variation cv to determine the type of extreme value distribution.
specifically the test goes over khighest values of the counterfactual discrimination and calculates the cv value where kranges from kmin tokmax line .
if for all values of k the cv is less than .
k then we are statistically confident that we have enough samples from the tail to infer valid extreme value distribution with exponential or light tails noting that the extra term k is to correct the bias in the estimation of cv due to small sample size in the tail line .
otherwise if any values of cv are greater than .
k we may not be able to fit an evt distribution in the tail under the current samples d line .
only in this case we use synthetic data generation methods ctgan and tv ae to generate m data samples similar to the training data samples of the target group lines .
we repeat the search until we pass the cv or a timeout occurs.
inferring the tail distributions of counterfactual discrimination.
given the generated tail samples d and the counterfactual discrimination measurements our final goal is to infer the parameters of gev distributions to estimate counterfactual discrimination on the tail for each group.
following we initially set the threshold of extreme values to mkmax i.e.
onlykmax measurements exceed the threshold.
then we fit the gev distribution and analyze the shape of the distributions to decide the validity.
if we are statistically confident that the shape is zero or negative then the gev belongs to the type i exponential or type iii light and we compare the expected worst case values and the scale .
given valid gevs for privileged and unprivileged groups we measure the amounts of discrimination between them with u p that is the expected worst case discrimination for a unprivileged group uminus the privileged group p. tail aware bias mitigation.
our approach to mitigating bias in the tail employs in process bias reduction algorithm via hyperparameter optimization.
our approach extends p arfait ml where we change the objective of optimization from the aod to ecd while keeping the accuracy constraints the same.
v. e xperiments in this section we first formulate the research questions rqs .
then we overview datasets ml models bias mitigation algorithms and our implementations.
finally we carefully analyze and answer the research questions.
rq1 generating realistic test cases can the previously proposed algorithm generate realistic data from the underlying distribution of the real dataset?rq2 feasibility usefulness guarantee can extreme value theory evt model and quantify the counterfactual discrimination in the tail of ml outcome distributions with statistical guarantees?
rq3 average based bias mitigators can we validate the efficacy of the prevalent bias mitigation algorithm via evt?
rq4 tail based bias mitigators what are the performance of existing tail aware bias reductions?
how does an evt based mitigator compare to them?
dataset.
we consider 9socially critical datasets from the literature of algorithmic fairness.
these datasets and their properties are described in table ii.
we assume that group is privileged and group is unprivileged.
training algorithms and ml models.
we consider popular ml models from the literature.
we use a six layer dnn following .
we trained dnn in tensorflow and used the same hyperparameters for all tasks with num epochs batch size and learning rate are set to and0.
respectively.
we use the lr svm and random forest algorithms from scikit learn library with the default hyperparameter configuration similar to .
average based bias mitigation algorithm.
we consider four commonly used average based bias mitigation algorithms exponentiated gradient eg implemented in both ai fairness and fairlearn fair smote maat and stealth .
eg algorithm adapts lagrange methods to find the multipliers that balance accuracy and fairness.
fair smote looks for bias in the training data and aims to balance the statistics of sensitive features by generating synthetic samples.
maat employs a fairness model alongside a performance model to infer the final decision.
stealth employs a surrogate model to use in predictions and explanations.
for evaluating fairness in average based scenarios in addition to aod and eod metrics we also included statistical parity difference spd and disparate impact di which compare the probabilities of favorable outcomes among protected groups .
tail aware bias reduction.
we utilize minimaxfairness that takes an iterative game theoretical approach to reduce the maximum error for protected groups.
to investigate the usefulness of the ecd based mitigator we adopt a hyperparameter optimization technique p arfait ml that finds the configurations of ml algorithms to minimize the bias of resultant ml models in the tail.
we set ecd as the objective search criteria and run the tool for hour on each benchmark.
implementation and technical details.
we run all the experiments on an ubuntu .
.
lts server equipped with an amd ryzen threadripper pro 3955wx cpu and two nvidia geforce rtx gpus.
we split the dataset into training validating and test data where accuracy f1 and fairness measures are reported over the test data.
we use fairlearn to quantify the fairness.
to measurecounterfactual bias we sample data instances independently and at random for each sub group.
we use the implementation of eg in fairlearn to study the common bias mitigation algorithm.
we repeated each query times and took the average to control the stochastic behavior of the eg with high precision.
we obtained the implementation of minimaxfairness from their github repository.
we also modify the implementation to support training on gpu.
we set the error type numsteps and epochs to0 1loss and respectively.
we implemented the evt algorithms in r using evd andextremes libraries .
in algorithm we setkmin kmax m tto10 and s respectively.
this choice of kminandkmax provides confidence on the feasibility of worst case guarantees via evt .
we obtained the implementation of fair smote maat and stealth from their github repository and used the recommended configuration to achieve their best results.
we repeated each experiment times and conducted runs in total.
for the statistical tests we follow prior work and perform a nonparametric test using the scott knott procedure.
this involved applying cliff s delta and a bootstrap test to assess the results.
in our scottknott ranking we classify results as wins ties or losses based on statistically significant improvements indistinguishable performance or significant degradations respectively compared to the original baseline vanilla model.
we compare different methods to each other based on number of wins ties and losses.
the replication package is available at a. evaluating synthetic data generation rq1 we assess the performance of conditional tabular gan ctgan and triplet based variational autoencoder tv ae by comparing their synthetic data against the original dataset focusing on statistical similarities and distribution characteristics.
we aim to determine which model better generates representative test cases for target demographic groups.
we also included datasets generated independently at randomly from the domain of variables.
for quality assessment we considered two criteria similarity to the dataset in several statistical properties and the performance of a downstream ml model trained on generated data versus the actual dataset .
table iii shows the results of experiments and the evaluation of metrics for each benchmark.
column fid reports the fr echet inception distance fid is an inception scorebased metric to measure the resemblance between generated and actual datasets.
the normalized kl divergence shown in thekl d column measures the disparity in the informational content between two distributions with a value of .
indicating minimal divergence.
column lg d indicates the logistic regression detection score that calculates how difficult it is to distinguish real from synthetic data based on the average roc auc scores across cross validation splits.
column f1 loss highlights the performance disparities between models trained on actual and synthetic datasets with values near zerotable ii datasets used in our experiments.
dataset instances features protected groups outcome label group group label label adult census 14sex male sex femalehigh income low incomeincome race white race black german credit sex male sex female good credit bad credit bank marketing age young age old subscriber non subscriber compas race caucasian race non caucasian did not reoffend reoffend default sex male sex female default not default heart sex male sex female disease not disease meps15 sex male sex female utilized benefits not utilized benefits meps16 sex male sex female utilized benefits not utilized benefits student performance sex male sex female pass not pass table iii data generation techniques.
legend algorithm generating method fid fr echet inception distance kld kullback leibler divergence lg d logistic regression detection acc accuracy difference f1 downstream f1 loss.
similarity ml perf dataset algorithm fid kl d lg d f1 loss adultctgan .
.
.
.
tv ae .
.
.
.
rnd .
.
.
.
compasctgan .
.
.
.
tv ae .
.
.
.
rnd .
.
.
.
creditctgan .
.
.
.
tv ae .
.
.
.
rnd .
.
.
.
bankctgan .
.
.
.
tv ae .
.
.
.
rnd .
.
.
.
defaultctgan .
.
.
.
tv ae .
.
.
.
rnd .
.
.
.
heartctgan .
.
.
.
tv ae .
.
.
.
rnd .
.
.
.
meps15ctgan .
.
.
.
tv ae .
.
.
.
rnd .
.
.
.
meps16ctgan .
.
.
.
tv ae .
.
.
.
rnd .
.
.
.
studentsctgan .
.
.
.
tv ae .
.
.
.
rnd .
.
.
.
indicating comparable ml performance across both datasets.
in this downstream evaluation we trained two logistic regression models on the actual dataset and the generated data and then assess their f1 score against the identical test set from the dataset.
fig.
mds plotour results indicate that both ctgan and tv ae are effective in learning and replicating the actual data distribution.
however their ability to capture complex feature relationships varies across datasets.
for instance with the compas dataset ctgan s performance stands out it achieves a kl divergence of .
.
conversely tv ae shows its strength with the adult dataset as supported by all four evaluation metrics.
as table iii reveals data generated randomly tend to deviate significantly from the actual data distribution.
we also employ multidimensional scaling mds to visualize these methods.
by reducing data to two principal dimensions mds provides a visual and analytical means toassess the accuracy with which different generation techniques replicate the characteristics of real dataset.
figure displays this comparison for the compas dataset particularly highlighting the alignment of tv ae generated data with the actual dataset s distribution.
answer rq1 ctgan and ta ve demonstrate their ability to accurately replicate the distribution of actual datasets.
in our experiments they generated data with a kl divergence as high as .
and an inception distance as low as .
.
but we found that their effectiveness is dataset dependent.
b. feasibility usefulness and guarantee of evt rq2 one important investigation of this paper is to find out whether extreme value theory evt can effectively model the tail of ml outcome distributions.
in table iv we present 80experiments with their corresponding evt characteristics and the feasibility of evt to provide fairness guarantees.
the number of test cases generated for each group is shown in column n determined by the exponential testing in algorithm .
the numbers reported in this column include both the original sample size from the dataset and the additional synthetic samples required to pass the test.
for instance a value of .
.
indicates that there are original samples with additional synthetic samples.
columns acd cvar and ecd show average conditional value at risk and extreme counterfactual discrimination.
in the columns type of table iv we detail the characteristics of the gev distribution for each benchmark that informs ecd.
here represents the mean of the extreme value distribution at a specific threshold for each combination of algorithm dataset and subgroup.
for instance in the dnn application to the census dataset with sex as protected attribute we observe an acd of .
cvar of .
and ecd of .
where mand fis .
and .
respectively implying a significant counterfactual discrimination toward female in the tail of dnn s outcome.
the shape indicates the tail behavior of the gev .
a shape around zero or negative suggests that gev can extrapolate for a long finite based on q q plot or infinite interactions with statistical guarantees shown with b. in out of scenarios evt results in a type iii distribution with a negative shape indicating a finite tail and enabling extrapolation for an unlimited number of queries.
for cases evt produces a type i distribution with a near zerotable iv characteristics of extreme value distributions.
legend dataset p protected attribute n number of test cases acd acd u acd p average causal discrimination difference ecd u p the amounts of ecd tail discrimination evt characteristics type for parameters of distributions threshold.
feasibility evt based extrapolation based on the type of evt q q plot and its horizon for extrapolations b .
.
.
name fairness evt characteristics feasibility alg dataset p n k acd cvar ecd type q q plot b dnncensuswhite .
.
.
.
.
.
.
.
.
iii finite linear black .
.
.
.
.
.
.
.
.
.
iii finite linear censusmale .
.
.
.
.
.
i log skewed right female .
.
.
.
.
.
.
.
.
.
.
iii finite linear creditmale .
.
.
.
.
.
.
iii finite linear female .
.
.
.
.
.
.
iii finite linear bankyoung .
.
.
.
.
.
.
.
ii infinite heavy tail old .
.
.
.
.
.
.
.
i log skewed left compascaucasian .
.
.
.
.
.
.
i log skewed left other .
.
.
.
.
.
.
.
.
i log skewed left defaultmale .
.
.
.
.
.
.
ii infinite heavy tail female .
.
.
.
.
.
iii finite linear heartmale .
.
.
.
.
.
.
.
.
iii finite linear female .
.
.
.
.
.
iii finite linear meps15male .
.
.
.
.
.
.
.
.
iii finite linear female .
.
.
.
.
.
.
.
.
.
iii finite linear meps16male .
.
.
.
.
.
.
.
.
i log skewed left female .
.
.
.
.
.
.
.
.
.
iii finite linear studentsmale .
.
.
.
.
.
.
iii finite linear female .
.
.
.
.
.
.
.
.
iii finite linear lrcensuswhite .
.
.
.
.
.
i log skewed left black .
.
.
.
.
.
.
iii finite linear censusmale .
.
.
.
.
iii finite linear female .
.
.
.
.
.
.
.
iii finite linear creditmale .
.
.
.
.
.
.
iii finite linear female .
.
.
.
.
.
.
iii finite linear bankyoung .
.
.
.
.
.
.
.
iii finite linear old .
.
.
.
.
iii finite linear compascaucasian .
.
.
.
.
.
.
.
iii finite linear other .
.
.
.
.
iii finite linear defaultmale .
.
.
.
.
.
.
.
iii finite linear female .
.
.
.
.
iii finite linear heartmale .
.
.
.
.
.
.
.
.
iii finite linear female .
.
.
.
.
.
iii finite linear meps15male .
.
.
.
.
.
iii finite linear female .
.
.
.
.
.
.
iii finite linear meps16male .
.
.
.
.
.
iii finite linear female .
.
.
.
.
.
.
iii finite linear studentsmale .
.
.
.
.
.
.
iii finite linear female .
.
.
.
.
.
iii finite linear svmcensuswhite .
.
.
.
.
.
.
.
.
.
.
iii finite linear black .
.
.
.
.
.
.
.
iii finite linear censusmale .
.
.
.
.
.
iii finite linear female .
.
.
.
.
.
.
.
.
.
iii finite linear creditfemale .
.
.
.
.
.
.
.
.
iii finite linear male .
.
.
.
.
iii finite linear bankyoung .
.
.
.
.
.
.
.
.
.
i log skewed left old .
.
.
.
.
.
.
.
.
i log skewed left compascaucasian .
.
.
.
.
.
.
.
ii infinite heavy tail other .
.
.
.
.
i log skewed left defaultmale .
.
.
.
.
.
.
.
i log skewed left female .
.
.
.
.
iii finite linear heartmale .
.
.
.
.
.
.
.
.
iii finite linear female .
.
.
.
.
.
i log skewed left meps15male .
.
.
.
.
.
.
iii finite linear female .
.
.
.
.
.
.
.
.
iii finite linear meps16male .
.
.
.
.
.
.
iii finite linear female .
.
.
.
.
.
iii finite linear studentsmale .
.
.
.
.
.
.
.
ii infinite heavy tail female .
.
.
.
.
i log skewed left rfcensuswhite .
.
.
.
.
.
.
.
.
.
.
iii finite linear black .
.
.
.
.
.
.
.
iii finite linear censusmale .
.
.
.
.
.
.
.
.
.
i log skewed left female .
.
.
.
.
.
.
.
.
iii finite linear creditmale .
.
.
.
.
.
.
.
.
.
.
.
iii finite linear female .
.
.
.
.
.
.
.
i log skewed right bankyoung .
.
.
.
.
.
.
.
.
.
.
iii finite linear old .
.
.
.
.
.
.
.
iii finite linear compascaucasian .
.
.
.
.
.
.
.
.
.
iii finite linear other .
.
.
.
.
.
.
.
.
iii finite linear defaultmale .
.
.
.
.
.
.
.
.
.
.
iii finite linear female .
.
.
.
.
.
.
.
iii finite linear heartmale .
.
.
.
.
.
.
.
.
.
.
.
iii finite linear female .
.
.
.
.
.
.
.
.
iii finite linear meps15male .
.
.
.
.
.
.
.
iii finite linear female .
.
.
.
.
.
.
.
iii finite linear meps16male .
.
.
.
.
.
.
.
.
.
.
iii finite linear female .
.
.
.
.
.
.
.
iii finite linear studentsmale .
.
.
.
.
.
.
.
.
.
.
iii finite linear female .
.
.
.
.
.
.
.
iii finite linear shape implying an infinite but exponentially decaying tail suitable for extrapolation within bounded queries b. overall the worst case guarantees are achievable in cases .
we examine the relevance of extreme counterfactual discrimination in ml model fairness by employing evt to measure tail biases comparing them to established fairness metrics like acd and cvar.
for instance in the dnn model trained on the compas dataset an acd of .
and a cvar of .
indicate fairness in both average and tail cases yet an ecd of .
suggests a tail bias toward caucasians.
we classify any ecd difference exceeding .
as discrimination with its significance indicated by the grayscale in the ecd column.
out of cases ecd based discrimination occurs in .
in contrast average case discrimination acd is observed in out of cases .
notably in cases ecd is significantly greater than acd.
in out of experiments ecd found significant discrimination against the unprivileged group in the tail that missed by the cvar metric.
answer rq2 evt effectively models extreme counterfactual discrimination ecd in of cases allowing for valid extrapolation of worst case discrimination.
in of cases ecd shows significantly higher discrimination than the average case one acd .
in out of experiments ecd found significant discrimination against the unprivileged group in the tail that missed by prevalent tail based metric cvar .
c. validation of prevalent bias mitigation algorithms rq3 in this analysis we leverage evt to assess the effectiveness of prevalent mitigation algorithms like exponentiated gradient eg and fair smote in the tail.
we also include two recent mitigation techniques maat and stealth in our experiments to evaluate our approach against more advanced methods.
the results are reported in table v and vi.
the column accuracy loss shows the accuracy difference between the original and mitigated models with positive values indicating improved accuracy in the mitigated model columns aod eod spd and di report the absolute values of average based fairness measures and the column ecd shows the amount of discrimination in the tail.
darker gray shades indicate lower rankings while lighter shades represent higher rankings no shading indicates the topranked method .
we use the scott knott ranking outcomes to compare the four mitigation methods where we consider a statistically significant improvement over the original baseline model the vanilla model as a win.
while the tables include all metrics we explain the results for one average based metric and one tail based metric.
consider the aod metric we find that eg outperforms other methods where it wins in cases out of .
stealth maat and fairsmote win in and cases in reducing aod biases.
in terms of average aod over all benchmarks eg stealth maat and smote achieve an average of .
.
.
and .
respectively.
in terms of number of cases with an aod bias below or equal to .
we observe that eg stealth maat and smote have and cases out of respectively.
when considering ecd metric stealth demonstrates superior performance among the average based mitigation methods in reducing tail discrimination.
specifically we find that stealth wins in cases out of whereas eg maat and fair smote win in and cases respectively.
in terms of average ecd over all benchmarks stealth eg maat and fair smote achieve an average of .
.
.
and .
respectively.
in terms of number of cases with an ecd bias below or equal to .
stealth eg maat and fair smote have and cases out of respectively.
answer rq3 while the average based mitigation methods preserved or improved fairness based on metrics like aod in they increase unfairness in tail based on ecd metric in of cases.
stealth outperformed other mitigation methods significantly based on the ecd metric failing only in of cases while preserving reducing the aod bias in .
d. tail aware mitigation algorithms rq4 we first evaluate the effectiveness of minimaxfairness which serves as our baseline alongside our proposed in process mitigator ecd fair .
results in table vii follow a similar format to table v where we only include the dnn and logistic regression models since the minimax fairness only supports these models among our base models.
considering ecd metric our approach significantly outperforms minimax fairness.
specifically ecd fair wins in cases out of while minimax fairness wins in cases out of .
when considering eod and aod metrics ecd fair outperforms minimax fairness with and win cases vs. and win cases out of .
in terms of absolute values over all benchmarks ecd fair achieves a average aod and ecd of .
and .
respectively.
the number of cases with aod and ecd below .
are and out of respectively.
we also compare ecd fair to stealth method over the dnn and lr benchmarks as stealth outperformed other baseline methods.
based on the eod and aod metrics we find that ecd fair wins in and cases out of vs. stealth wins in and cases out of respectively.
when considering the ecd metric ecd fair and stealth win in and cases out of respectively.
stealth degrades unfairness in tail for benchmarks while ecd fair does not increase the unfairness in the tail for any benchmark.
overall while stealth demonstrates a competitive result ecd fair slightly outperforms it for both tail and average metrics.table v average based bias mitigation.
legend p protected attribute acc loss accuracy loss in mitigation aod eod spd di average based fairness measures ecd u p the amounts of ecd tail discrimination nv not valid.
name exponentiated gradient eg fair smote algorithm dataset p acc loss aod eod spd di ecd acc loss aod eod spd di ecd avg basedcensusrace .
.
.
.
.
.
.
.
.
.
.
.
sex .
.
.
.
.
.
.
.
.
.
.
.
credit sex .
.
.
.
.
.
.
.
.
.
.
.
dnn bank age .
.
.
.
.
.
.
.
.
.
.
.
compas race .
.
.
.
.
.
.
.
.
.
.
.
default sex .
.
.
.
.
.
.
.
.
.
.
.
heart sex .
.
.
.
.
.
.
.
.
.
.
.
meps15 sex .
.
.
.
.
.
.
.
.
.
.
.
meps16 sex .
.
.
.
.
.
.
.
.
.
.
.
students sex .
.
.
.
.
.
.
.
.
.
.
.
avg basedcensusrace .
.
.
.
.
.
.
.
.
.
.
.
sex .
.
.
.
.
.
.
.
.
.
.
.
credit sex .
.
.
.
.
.
.
.
.
.
.
.
lr bank age .
.
.
.
.
.
.
.
.
.
.
.
compas race .
.
.
.
.
.
.
.
.
.
.
.
default sex .
.
.
.
.
.
.
.
.
.
.
.
heart sex .
.
.
.
.
.
.
.
.
.
.
.
meps15 sex .
.
.
.
.
.
.
.
.
.
.
.
meps16 sex .
.
.
.
.
.
.
.
.
.
.
.
students sex .
.
.
.
.
.
.
.
.
.
.
nv avg basedcensusrace .
.
.
.
.
.
.
.
.
.
.
.
sex .
.
.
.
.
.
.
.
.
.
.
.
credit sex .
.
.
.
.
.
.
.
.
.
.
.
svm bank age .
.
.
.
.
.
.
.
.
.
.
.
compas race .
.
.
.
.
.
.
.
.
.
.
.
default sex .
.
.
.
.
.
.
.
.
.
.
.
heart sex .
.
.
.
.
.
.
.
.
.
.
.
meps15 sex .
.
.
.
.
.
.
.
.
.
.
.
meps16 sex .
.
.
.
.
.
.
.
.
.
.
.
students sex .
.
.
.
.
.
.
.
.
.
.
.
avg basedcensusrace .
.
.
.
.
.
.
.
.
.
.
.
sex .
.
.
.
.
.
.
.
.
.
.
.
credit sex .
.
.
.
.
nv .
.
.
.
.
.
rf bank age .
.
.
.
.
.
.
.
.
.
.
.
compas race .
.
.
.
.
.
.
.
.
.
.
.
default sex .
.
.
.
.
.
.
.
.
.
.
.
heart sex .
.
.
.
.
.
.
.
.
.
.
.
meps15 sex .
.
.
.
.
.
.
.
.
.
.
.
meps16 sex .
.
.
.
.
.
.
.
.
.
.
.
students sex .
.
.
.
.
nv .
.
.
.
.
.
table vi average based bias mitigation stealth and maat .
legend is similar to table v name stealth maat algorithm dataset p acc loss aod eod spd di ecd acc loss aod eod spd di ecd avg basedcensusrace .
.
.
.
.
.
.
.
.
.
.
.
sex .
.
.
.
.
.
.
.
.
.
.
.
credit sex .
.
.
.
.
.
.
.
.
.
.
.
dnn bank age .
.
.
.
.
.
.
.
.
.
.
.
compas race .
.
.
.
.
.
.
.
.
.
.
.
default sex .
.
.
.
.
.
.
.
.
.
.
.
heart sex .
.
.
.
.
.
.
.
.
.
.
.
meps15 sex .
.
.
.
.
.
.
.
.
.
.
.
meps16 sex .
.
.
.
.
.
.
.
.
.
.
.
students sex .
.
.
.
.
.
.
.
.
.
.
.
avg basedcensusrace .
.
.
.
.
.
.
.
.
.
.
.
sex .
.
.
.
.
.
.
.
.
.
.
.
credit sex .
.
.
.
.
.
.
.
.
.
.
.
lr bank age .
.
.
.
.
.
.
.
.
.
.
.
compas race .
.
.
.
.
.
.
.
.
.
.
.
default sex .
.
.
.
.
.
.
.
.
.
.
.
heart sex .
.
.
.
.
.
.
.
.
.
.
.
meps15 sex .
.
.
.
.
.
.
.
.
.
.
.
meps16 sex .
.
.
.
.
.
.
.
.
.
.
.
students sex .
.
.
.
.
.
.
.
.
.
.
.
avg basedcensusrace .
.
.
.
.
.
.
.
.
.
.
.
sex .
.
.
.
.
.
.
.
.
.
.
.
credit sex .
.
.
.
.
.
.
.
.
.
.
.
svm bank age .
.
.
.
.
.
.
.
.
.
.
.
compas race .
.
.
.
.
.
.
.
.
.
.
.
default sex .
.
.
.
.
.
.
.
.
.
.
.
heart sex .
.
.
.
.
.
.
.
.
.
.
.
meps15 sex .
.
.
.
.
.
.
.
.
.
.
.
meps16 sex .
.
.
.
.
.
.
.
.
.
.
.
students sex .
.
.
.
.
.
.
.
.
.
.
.
avg basedcensusrace .
.
.
.
.
.
.
.
.
.
.
.
sex .
.
.
.
.
.
.
.
.
.
.
.
credit sex .
.
.
.
.
.
.
.
.
.
.
.
rf bank age .
.
.
.
.
.
.
.
.
.
.
.
compas race .
.
.
.
.
.
.
.
.
.
.
.
default sex .
.
.
.
.
.
.
.
.
.
.
.
heart sex .
.
.
.
.
.
.
.
.
.
.
.
meps15 sex .
.
.
.
.
.
.
.
.
.
.
.
meps16 sex .
.
.
.
.
.
.
.
.
.
.
.
students sex .
.
.
.
.
.
.
.
.
.
.
.
answer rq4 ecd fair significantly outperformed minimax fairness a state of the art tail aware mitigator.
when compared to stealth a competitive baseline we found that ecd fair and stealth improved fairness in the tail for and of cases respectively.
ecd fair and stealth reduced the aod bias in and of cases respectively.vi.
d iscussions limitations.
one limitation is the lack of ground truth regarding the tail of ml outcome distributions.
we can use the maximum individual discrimination in the validation dataset as it gives a lower bound on the ground truth.
our approach requires the presence of protected attributes during inference.
therefore it cannot be used to study worst case fairness for notions such as fairness through unawareness which requires the removal of protected attributes .
our approach alsotable vii tail aware bias mitigation.
legend is similar to table v name minimax fairness ecd fair algorithm dataset p acc loss aod eod spd di ecd acc loss aod eod spd di ecd tail basedcensusrace .
.
.
.
.
.
.
.
.
.
.
.
sex .
.
.
.
.
.
.
.
.
.
.
.
credit sex .
.
.
.
.
.
.
.
.
.
.
.
dnn bank age .
.
.
.
.
.
.
.
.
.
.
.
compas race .
.
.
.
.
.
.
.
.
.
.
.
default sex .
.
.
.
.
.
.
.
.
.
.
.
heart sex .
.
.
.
.
.
.
.
.
.
.
.
meps15 sex .
.
.
.
.
.
.
.
.
.
.
.
meps16 sex .
.
.
.
.
.
.
.
.
.
.
.
students sex .
.
.
.
.
.
.
.
.
.
.
.
tail basedcensusrace .
.
.
.
.
.
.
.
.
.
.
.
sex .
.
.
.
.
.
.
.
.
.
.
.
credit sex .
.
.
.
.
.
.
.
.
.
.
.
lr bank age .
.
.
.
.
.
.
.
.
.
.
.
compas race .
.
.
.
.
.
.
.
.
.
.
.
default sex .
.
.
.
.
.
.
.
.
.
.
.
heart sex .
.
.
.
.
.
.
.
.
.
.
.
meps15 sex .
.
.
.
.
.
.
.
.
.
.
.
meps16 sex .
.
.
.
.
.
.
.
.
.
.
.
students sex .
.
.
.
.
.
.
.
.
.
.
.
depends on the representative individuals sampled from the same training distribution and may not be valid for outof distribution queries.
finally our approach assumes that flipping the sensitive values leads to valid representations to measure the sensitivity of ml models to the protected attributes.
threat to validity.
to address the internal validity and ensure our finding does not lead to invalid conclusions we follow established guidelines and report the statistical significance of measures with the exponential and scott knott statistical testing.
to ensure that our results are generalizable we perform our experiments on three well established training algorithms from scikit learn andtensorflow libraries with a popular mitigation algorithm from the fairlearn library over fairness sensitive tasks that have been widely used in the fairness research.
it is an open problem whether the algorithms hyperparameters and datasets are sufficiently representative to cover challenging fairness scenarios.
vii.
r elated work fairness testing of data driven software.
individual discrimination is a major fairness debugging method .
t hemis is the closest approach.
while t hemis focuses on the average causal discrimination between two subgroups via counterfactual queries with prevalent statistical guarantees of normal distributions we introduce the notion of extreme causal discrimination between two subgroups with exponentially statistical guarantees of extreme value distributions.
rather than randomly sampling data from the domain of variables we leveraged generative ai models to produce realistic test cases from the tail.
fairness in the tail.
multiple works consider the worst case group fairness .
williamson and menon leveraged conditional value at risk cvar to minimize the expected loss and the worst case loss of any group in the upper quantile.
we found that cvar might miss discrimination in the tail and cannot reason about the shape of tail.
diana et al.
proposed a constrained optimization objective where the goal is to minimize the expected overall loss for all data instances subject to the hard constraints wherein no group loss can be more than a threshold.
we propose an in process bias mitigator that significantly outperforms this technique as shown in rq4.intersectional fairness.
the keyword worst case fairness has been also used in the relevant fairness literature .
however their notion of fairness still relies on regular average fairness metrics like the rate of favorable outcomes per each subgroup.
in particular intersectional fairness concerns about the summary of fairness statistics when there are fairness measures for n subgroups.
for example ghosh et al.
suggests a min max ratio that takes the maximum for average favorable outcomes of all subgroups and divides it by the min for average favorable outcomes of all subgroups.
on the other hand our fairness measure looks at the tail of ml outcome distributions per each subgroup via evt and compares the tail distributions between groups to quantify the amounts of discrimination.
other application of evt for fairness.
in addition to its technical applications extreme value theory has been significantly used to study income and wealth inequalities around the world .
piketty and saez used the generalized pareto distribution to study the distribution of income in the us between and .
wang studied the concept of degree of matthew effect in recommendation systems via extreme value theory whereas we consider social bias discrimination against protected groups in decisionmaking systems based on classifications .
viii.
c onclusion and future work we studied fairness through the lens of extreme value theory.
our proposed approach fitted well to model the worst cases counterfactual bias with statistical guarantees and revealed the limitations of a state of the art bias reduction algorithm in the worst case.
there are multiple exciting future directions.
one direction is to leverage evt to provide a notion of ai harms to understand if automated decision support software systematically harms a vulnerable community.
acknowledgement.
the authors thank the anonymous icse reviewers for their time and invaluable feedback to improve this paper.
monjezi and tizpaz niari were also affiliated with ut el paso in the completion of this work.
tizpaz niari and trivedi have been partially supported by nsf under grants ccf and ccf .