glib towards automated test oracle for graphically rich applications ke chen fuxi ai lab in netease hangzhou china chenke3 corp.netease.comyufei li university of texas at dallas dallas usa yxl190090 utdallas.eduyingfeng chen fuxi ai lab in netease hangzhou china chenyingfeng1 corp.netease.com changjie fan fuxi ai lab in netease hangzhou china fanchangjie corp.netease.comzhipeng hu fuxi ai lab in netease hangzhou china zphu corp.netease.comwei yang university of texas at dallas dallas usa wei.yang utdallas.edu abstract graphically rich applications such as games are ubiquitous with attractive visual effects of graphical user interface gui that offers a bridge between software applications and end users.
however various types of graphical glitches may arise from such gui complexity and have become one of the main component of software compatibility issues.
our study on bug reports from game development teams in netease inc. indicates that graphical glitches frequently occur during the gui rendering and severely degrade the quality of graphically rich applications such as video games.
existing automated testing techniques for such applications focus mainly on generating various gui test sequences and check whether the test sequences can cause crashes.
these techniques require constant human attention to captures non crashing bugs such as bugs causing graphical glitches.
in this paper we present the first step in automating the test oracle for detecting non crashing bugs in graphically rich applications.
specifically we propose glib based on a code based data augmentation technique to detect game gui glitches.
we perform an evaluation of glib on real world game apps with bug reports available and the result shows that glib can achieve precision and .
recall in detecting non crashing bugs such as game gui glitches.
practical application of glib on another real world games without bug reports further demonstrates that glib can effectively uncover gui glitches with of bugs reported by glib having been confirmed and fixed so far.
ccs concepts software and its engineering software testing and debugging computing methodologies neural networks .
the first two authors contributed equally to this research.
permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
copyrights for components of this work owned by others than acm must be honored.
abstracting with credit is permitted.
to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
request permissions from permissions acm.org.
esec fse august athens greece association for computing machinery.
acm isbn .
.
.
.
automated test oracle game testing gui testing deep learning acm reference format ke chen yufei li yingfeng chen changjie fan zhipeng hu and wei yang.
.
glib towards automated test oracle for graphically rich applications.
in proceedings of the 29th acm joint european software engineering conference and symposium on the foundations of software engineering esec fse august athens greece.
acm new york ny usa pages.
introduction graphically rich applications also short for apps have been popular on mobile and personal computer pc platforms.
with a growing number of complex visual effects such as advanced rendering light and shadows animation and intensive media embedding being used to enhance the quality of gui also short for ui various graphical glitches may occur in the apps and severely impact user experience.
existing automatic ui testing techniques detect bugs by generating test sequences and check whether some crashes are caused.
therefore these techniques require constant human attention to capture the ui glitch inducing bugs.
however there are quantities of ui glitches that can severely degrade graphically rich apps usability but not induce crashes in practical scenarios.
hence in this paper we make a first step in addressing the lack of oracle problem for graphically rich apps.
specifically we propose an automated test oracle for detecting ui glitches in game apps.
figure examples of game ui glitches.
recent image based ui testing techniques demonstrate that adding images with versatile ui display issues to the training datasets can help improve the performance of convolutional neural network cnn based detection models in non game mobilearxiv .10507v3 jul 2021esec fse august athens greece ke chen yufei li yingfeng chen changjie fan zhipeng hu and wei yang apps.
for example owl eyes designs a heuristic based data augmentation approach for generating abnormal screenshots on rico dataset by mimicking the symptom of real world ui display issues.
its main methodology is to classify ui display issues into five classes and design each issue generation rule according to its features.
with a large amount of generated ui screenshots owl eyes improves the effectiveness of detecting ui glitches in non game apps significantly.
however we observe that the existing heuristic based data augmentation approach applied in owl eyes cannot accurately reflect the ui glitch issues in graphically rich applications especially in game scenarios due to three main reasons.
first their manuallydefined rules require human inspection on screenshots of ui glitches and humans may miss certain unnoticeable but important patterns.
moreover their generation process is to mimic the screenshots of ui glitches thus the generated images may be infeasible to be generated by the real bugs in the program code.
this approximation may cause false positives in the detection process.
last owl eyes mainly focuses on text related ui display issues whereas in game scenario the ui display issues are typically text irrelevant graphical glitches which may not be generalized by the heuristic rules defined by owl eyes .
to address these issues we propose glib an automated test oracle to detect ui glitch related bugs.
to enable better performance ofglib we develop a code based data augmentation approach to augment the training data for glib by injecting the buggy code snippets to the game apps and record the manifestation of the bugs i.e.
ui glitches .
in this way our generated screenshots contain real ui glitches so that the dl model can be trained with more precise datasets and potentially learn subtle patterns that humans may not observe.
moreover our study of bugs root causes can guide developers to debug with some empirical knowledge after detecting the ui glitches.
because some ui glitch issues occur in only parts of the ui screen area and human inspectors may miss the issues we develop a technique based on the saliency map to localize the glitch regions with different bug categories so that the developers can easily determine whether and where our detected images have ui glitches.
to better evaluate the effectiveness of glib we create a testing dataset consisting app screenshots with and without ui glitches from real world game bug reports.
evaluation on the testing dataset demonstrates that glib can achieve .
and .
boost in precision and recall compared to the prediction results of the model trained without data augmentation leading to precision .
recall and .
f .
moreover we evaluate the practical usefulness of glib by detecting ui glitches in real world games with different platforms and engines the practical application result shows that our model can successfully spot previously undetected ui glitch issues and help developers to fix the bug.
the contributions of this article are as follows our work1 is the first to systematically investigate ui glitch issues in real world graphically rich apps.
we create a large scale dataset of screenshots with ui glitches and release the data for follow up studies.
1code to reproduce our experiments is available at glib.git based on our characteristic study on the root causes of graphical ui glitches we propose a code based training data augmentation approach that can be applied in real world game apps to generate ui glitches.
our study can also guide developers to find and fix the bug after detecting game ui glitches.
we propose a cnn based model for detecting images with ui display issues and leverage saliency map to localize the glitch region in the ui.
background game testing company testbird collected and tested mobile game apps in and reported relevant compatibility issues.
according to the statistics of terminals tested for each game the average number of game compatibility issues is and the average pass rate is .
.
testbird analyzed all these compatibility issues and classified them into categories namely ui glitch install failed start failed crash app freeze ui lags black screen network error andother problems .
among them ui glitch and game crash are the two largest categories with ui glitch accounting for .
and game crash occupying .
of compatibility issues.
the detailed compatibility issue distribution is shown in figure 2a.
particularly ui glitch occurs and has been the most severe compatibility issue in nearly every tested mobile game.
testbird also investigated the proportion of game engines on mobile game applications as shown in figure 2b among which unity3d also short for unity is the most prevalent one and hence our following study is based on the unity game engine.
another game company wetest tested all tencent mobile games and summarized the compatibility issues into eight categories among which ui glitch is also the largest issue and accounts for .
of all the problems.
specifically the percentage of ui glitches increased by compared to last year and among them the proportion of problems such asabnormal color block andrandom noise has increased.
a game issue proportion b game engine proportion figure test report from testbird.
characteristic study before we build a model to detect game ui glitches we collected quantities of ui glitch issues that appeared in the real world game apps.
our study aims to answer the following two questions rq1 what is the general manifestation of ui graphical glitches in mobile game apps?
rq2 what are the bug causes of these game ui glitches?
.
data collection to better understand the ui glitch issues in real world mobile game apps we collect the bug reports of netease androidglib towards automated test oracle for graphically rich applications esec fse august athens greece a abnormal color block b random noise c partial repetition d frame overlay e object missing f abnormal text g overexposed h black border figure examples of eight categories of game ui glitches.
games belonging to different categories such as adventure game action game first person shooter game role playing game etc.
with ui glitch images.
the main reason we focus on mobile game ui display issues is that compatibility issues between software and hardware frequently appear on mobile devices.
take android as an example nowadays more than major versions of the android operating system os run on distinct device models with different screen resolutions .
because most of the abnormal images are photos captured from the external camera with some annotation rather than the screenshots we preprocess these images by remaining the screenshots and excluding photos and images with system related bugs.
finally we obtain filtered graphical glitch screenshots and use them for our characteristic study.
.
manifestation of game ui glitches rq1 given those collected screenshots we found that ui glitches are actually versatile in terms of their manifestation and that different types of ui glitches may appear with different frequencies thus has a different level of impact on the game usability.
therefore categorization of these issues would facilitate our study design and evaluation of the related approach.
following the card sorting and adapt the technique to the game scenario we categorize these bugs into categories namely abnormal color block random pixel noise partial repetition frame overlay model missing abnormal text overexposed andblack border and statistic their proportion of occurrence with details as follows abnormal color block .
as shown in figure 3a abnormal color blocks stretch and cover the ui graph.
the main cause is that some material is missing or the camera responsible for rendering pixel rgb values is incorrectly turned off.
random noise .
as shown in figure 3b quantities of color pixels randomly distribute over the whole screen or specific area.
the main cause is that the camera is incorrectly turned off.
partial repetition .
as shown in figure 3c part of the ui area is repeated or mirrored.
disabling camera or post processing error gpu does not support the rendering effect or incorrect render logic may result in this glitch issue.frame overlay .
as shown in figure 3d the frame in the previous time step overlaps the current frame.
the wrong value of the camera s clearflag might be the main reason.
object missing .
as shown in figure 3e the ui model lacks part of its component.
this may be caused by the incorrect values of the alpha channel in the model texture.
abnormal text .
as shown in figure 3f multiple pieces of texts are located in the wrong area and may cover the characters or other objects.
the main reason for this glitch issue is that the ui is not adapted to the screen resolution.
overexposed .
as shown in figure 3g the whole or part of ui scene is too bright or overexposed.
the main reason is that the intermediate result is stored in a low precision variable and the result is clipped or overflows.
black border .
as shown in figure 3h the ui image is not flattened to cover the whole screen and leaves the black borders on both sides because the display resolution e.g.
and aspect ratio of some special devices are not considered by the developer.
to ensure the completeness of our study we asked several game testing experts from the company s development teams to confirm that our summarized ui glitches cover all the common ui issues in their games including not only mobile apps but also other platforms such as pc and ps4.
we also demonstrate that our glib can be applied to various types of games on distinct platforms and precisely detect ui bug issues in rq4.
.
bug causes of game ui glitches rq2 after we collect quantities of game ui glitch samples and have a common sense of ui display issues and their threat to the user s game experience a more important thing is to understand the bug causes of these glitch issues.
to common sense the reason for game ui display issues might be the defects of hardware e.g.
gpu related issues or the wrong setting of rendering special effects.
to facilitate the visual understanding in detecting ui display issues we focus on explaining the root causes in terms of source code level bugs .
by so we collect the historical commit diff of various game apps and categorize the bug issues into major types.
for each bug fix example the code marked with green color is the missing part of the original bug code.esec fse august athens greece ke chen yufei li yingfeng chen changjie fan zhipeng hu and wei yang figure effect of incorrect camera turned off.
a rendering components b rendering effect figure frame overlay generation process.
rendering cameras are turned off incorrectly.
cameras in the unity engine are the devices that capture the color and depth information of the game world and display the whole scene to the players.
a game scene can hold an unlimited number of cameras with different objects probably rendered by different cameras.
if one camera is turned off unexpectedly the render results may be substituted by any memory block which has not been initialized thus the rgb values of the corresponding objects in the image can be randomized and the manifestation of these random pixel values in game ui display issues will most likely be abnormal color block random noise orobject missing .
the bug fix procedure of camera enabled error is shown in listing .
targetcamera .
targettexture originrt targetcamera .
enabled true if uimanager .
inst !
null uimanager .
inst .
uicamera !
null uimanager .
inst .
uicamera .
enabled true listing bug fix procedure of camera enable error.
wrong settings of camera s clearflag.
cameras in the unity engine typically clear the color and depth information on the screen before rendering image frames and the clearflag function of a camera determines how the color buffer and depth buffer are cleared.
if the clearflag instruction is modified incorrectly the depth and color settings of the scene may get chaotic e.g.
if there is a cube moving randomly in the scene with the blue and gray parts as the background i.e.
the depth is infinite and the camera s clearflag is incorrectly set as don t clear the color and depth buffers of the previous frame will remain and cause frame repeatedly appear at each time step.
the white and red objects in figure 5a are camera and cube to be rendered respectively and the rendering result is in figure 5b.
this bug is regarded as the main cause of frame overlay .
we fix this bug by setting the camera s clearflag according to the depth buffer.
the bug fix procedure of camera clearflag error is shown in listing .
figure effect of wrong settings of camera clearflag.
var originrt targetcamera .
targettexture targetcamera .
targettexture rt targetcamera .
render cameraposteffect .
instance .
doposteffects rt postrt if uimanager .
inst !
null uimanager .
inst .
uicamera !
null if uicameraon uimanager .
inst .
uicamera .
render var originuirt uimanager .
inst .
uicamera .
targettexture uimanager .
inst .
uicamera .
targettexture postrt uimanager .
inst .
uicamera .
render uimanager .
inst .
uicamera .
clearflags cameraclearflags .
depth uimanager .
inst .
uicamera .
targettexture originuirt listing bug fix procedure of camera clearflag error.
post processing special effects of the previous scene are not cleared in time.
adding post processing can apply various kinds of filters or effects to the camera s image buffer before an image is displayed on the screen and this post processing technique drastically improves the visual expression of the scene.
but if the post processing effect is added incorrectly or if the effect is not cleared in time when the scene changes the image content will become scrambled even mess up the whole scene.
for example when one enters a scene without any post process effects as in figure 7a it looks like a man is standing on the ground.
however if a game developer adds a mirror effect to the previous scene e.g.
a lake scene in figure 7b and steps into the scene without clearing the post process effect in time the image then becomes symmetric as shown in figure 9c as if there is a lake in the scene.
this postprocessing special effect bug is likely to cause partial repetition issue and the bug fix code is shown in listing .
private static luafunction m hookondisable null private void ondisable if m hookondisable !
null if gamebaseobject .
inst .
invokenewhook m hookondisable this return if cameraposteffect .
instance null image .
texture null return cameraposteffect .
instance .
releaseuibloomtarget cameraposteffect .
instance .
clearpostrenderrt listing bug fix procedure of incorrect camera postprocessing effect error.glib towards automated test oracle for graphically rich applications esec fse august athens greece a raw scene b mirror effect c synthetic scene figure effect of post processing error.
gpu related rendering bugs.
some ui glitches are caused by gpu driver bugs or gpu related rendering bugs.
for instance the version of the operating system e.g.
android ios on the mobile device might be too old and its handling palettes on the gpu cause ui display issues or the wrong gpu rendering settings like skipping some buffering effect for faster program running might cause object missing issue.
wrong gpu rendering settings may also lead to resolution adaption problem and text out of position issue.
main approach our main approach glib consists of three parts first we propose a source code based augmentation approach for generating quantities of abnormal game ui display images then we design a cnn based image recognition model to learn the pattern of various categories of game ui glitch issues and detect those screenshots with ui display issues finally we come up with a saliency map for automatic problem localization.
our glib frame is shown in figure .
.
code based data augmentation training a powerful cnn model for visual recognition and ui issue detection requires quantities of data samples.
for example densenet uses samples from cifar images from svhn and .
million images from imagenet for training.
similarly our proposed cnn model for ui glitch detection requires a large number of screenshots with versatile ui glitches.
nevertheless our collected real world game ui screenshots contain a small proportion of glitch images which also do not fully cover diverse categories of game ui glitches as we mentioned in section .
.
therefore we propose a code based data augmentation approach based on the root causes we study in section .
for generating ui glitch problems by modifying the source code of various mobile game apps and making screenshots for typical scenes.
particularly when we inject the corresponding bug code into mobile game execution programs to force ui glitches to occur so that we can collect quantities of screenshots with ui display issues we must ensure that only ui related issues happen and other functions of the game apps are not affected e.g.
do not crash after their programs get updated.
we wrap the bug code with execution parameter settings which we also refer to as patch code so that the execution program could get updated to the bug injected version and this patching technique is called hotfix .
our code based ui glitch generation approach is automated and can be well generalized to other games.
with hotfix we only need to download the patch code that is pushed to the execution server and the execution programs will get updated automatically rather than reinstalling and recompiling the game apps.
therefore most mobile apps support hotfix for fixing code related bugs.
particularly for unity games we can insert bug code with the help of hotfix without authority and knowledge of the source programs.
we inject bug code by changing certain global variables or executing global functions from the unity native interface.
in this way our code injection approach can be generalized to all unity engine based apps and even be easily adapted to graphics engines other than unity by modifying the global variables and functions in the corresponding engines.
figure illustrate examples of augmented screenshots with ui glitch issues in which the first row shows the normal ui scenes and the second row displays the generated ui glitch scenes.
to be mentioned that gpu related rendering bugs are typically bottom layer issues or hardware setting problems and may vary differently from each game also the manifestation of ui glitches caused by gpu related rendering bugs is versatile depending on the device itself.
hence we put this root cause in the future work and our approach focuses on generating ui glitch scenes with the following three categories.
turn off cameras in the scene.
as we discussed before the camera is used to capture the objects in the scene we hence disable some cameras to force the ui glitches to appear in the game apps we save the screenshots in different scenes as the abnormal samples.
the patch code is shown in listing .
1local cameraobjs cs.unityengine.object.findobjectsoftype typeof cs.unityengine.camera 2for i cameraobjs.length 3do cameraobjs .enabled false 5end listing lua patch for turning off all cameras.
modify camera s clearflag.
camera clearflag an enum type determines how to clear the depth buffer and color buffer before rendering the scene.
there are four pre defined values for clearflag skybox solidcolor depthonly and nothing.
a skybox clear the color buffer and depth buffer with skybox b solidcolor clear the color buffer and depth buffer with solidcolor c depthonly only clear the depth buffer d nothing don t clear either color buffer or depth buffer.
when we enter a scene we traverse the camera set the clearflag as one of the enum values we list above and check the ui display state if ui glitches occur we save the screenshot as an abnormal example.
the patch code is shown in listing .
1local cameraobjs cs.unityengine.object.findobjectsoftype typeof cs.unityengine.camera 2for i cameraobjs.length 3do cameraobjs .clearflags unityengine.cameraclearflags.depthonly 5end listing lua patch for changing clearflag as depthonly for all existing camera in the scene.
add incorrect post processing effect.
adding post processing effects is the last step in the unity render pipeline and the effects can modify the scene style easily.
hdr and background blurring are two common post processing effects.
the ui image frame could become scrambled if we add incorrect post processing effects to the scene e.g.
adding the mirror effect to the button can lead toesec fse august athens greece ke chen yufei li yingfeng chen changjie fan zhipeng hu and wei yang ui sampling data augmentation sec .
game apps bug injection generated screenshots normal screenshots train input cnn detection model backprop to input pixel normal screenshots ui glitch screenshots detect cnn based ui glitch detection sec .
saliency map ui issue localization sec .
figure overview of glib.
a camera enabled b camera clearflag c post processing figure examples of code based data augmentation.
partial repetition .
we randomly choose some post processing effects and add them to different scenes and save the screenshot as the abnormal sample if the ui scene is messed up.
the patch code is shown in listing .
1local detectcamera gameobject.find uicamera 2if detectcamera nil 3then detectcamera.gameobject addcomponent typeof camerafilterpack 3d mirror 5end listing lua patch example for adding mirror postprocessing effect to current scene.
note that there are two main reasons why we do not directly apply our summarized code patches to find bugs in game source code.
first injecting a type of bug requires to know only one code pattern of such bug type but detecting bugs requires knowing all patterns of this type of bug.
in our patch we only need to change some global variables or functions to generate ui glitches.
however for each bug type there may be thousands of relevant statements and the correctness of each statement depends on other context codes.
second even if one can figure out a code analysis dl model for detecting bugs the source code of the application under test is not always available noted that our bug injection needs access to the source code of the training applications only .
thus our glib is a more general and effective approach for real world testing cases.
.
cnn based ui glitch detection model deep learning has achieved remarkable success in computer vision tasks such as image classification object detection object tracking etc.
and we hence choose the cnn architecture for detecting abnormal ui display images which can be regarded as one kind of image classification tasks.
given the screenshot as input to our cnn model we firstly resize the input to a fixed size whose width and height is w h then we use convolutional kernels to extract feature maps of the input followed by pooling layer which can progressively reduce the spatial size of feature representation meanwhile control overfitting.
to improve the stability of cnn the batch normalization bn is added after each convolutional layer.
we obtain feature maps from the last convolutional layer and send them to the multiple full connection fc layers to train a classifier with the k dimensional vector as the output.
finally the probability distribution of each class c is computed by softmax function p y c x efc x k k 1efk x the classification result is given by the argmax function label arg max cp y c x .
to increase the nonlinearity of the cnn model an activation function is added after the bn layer and fc layer.
.
saliency map the cnn model only determines whether the image is abnormal however we are more concerned about which part of an image is abnormal thus can help the developer to fix the bug.
moreover the saliency map can help to understand whether the model is accurate and how the model works.
we simply compute the derivative of the label to the input by f i i wherefrepresents the cnn model and iis the input image.
the bigger gradient value indicates a larger contribution to the classification result.
if the output shows that the image is abnormal the pixel with a large gradient value indicates the abnormal area.glib towards automated test oracle for graphically rich applications esec fse august athens greece max pooling fc layeroutputconv bn relu screenshotnormal ui glitch figure the architecture of cnn.
.
implementation we resize the input to a fixed size if the image is vertical we will rotate it to horizontal then resize it to the fixed size.
our cnn model consists of convolutional layers whose kernel size is followed by batch normalization layers maxpooling layers and fully connected fc layers with the output size of the last layerk the activation function we adopt is relu.
we set the number of kernel as for convolutional layer for layer for layer 8and for layer .
the model updates its parameter by minimizing the crossentropy loss for the two label classification task.
the network is trained by adam optimizer over batches of input images with an initial learning rate as .
.
the detail of our convnet configurations is shown in figure .
we implement our model based on the pytorch framework.
experiment design our experiment is designed to answer the following questions rq3 how effective is glib in terms of detecting game ui glitches?
rq4 how well does glib perform in real world game applications?
.
experimental setup the game ui screenshots in our experiment are composed of parts screenshots without ui glitches normal images and screenshots generated by code based augmentation approach glitch images .
we combine the two parts of data samples to train our glib .
to balance the distribution of our training data we roughly set the number of normal images and that of glitch images as particularly we randomly select screenshots from all the code based generated glitch images for training among which of them are generated by setting the wrong clearflag of the scene camera of them are generated by turning the camera off and of them are generated by adding incorrect post processing effect.
there are normal screenshots and glitch screenshots in the training dataset normal screenshots and glitch images in the validation dataset where of them are generated by setting the incorrect camera clearflag are generated by turning the camera off and are generated by adding incorrect post processing effect.
the screenshots are collected from two games we manually traverse the scene in the mobile game app by clicking randomly on the mobile screen capture the screenshots until ui components are stable and save the screenshots as bug free data.
then we apply three patches in section .
to the game if the screen is blurred we capture the screen as the code augmentation result.table data distribution data type augmentation approach s game1 game2 normal glitch partial repetition solid color block rule mosaic effect random noise camera turned off code incorrect camera clearflag incorrect post processing note that game scenes are typically dynamic rather than static.
in each scene there may be multiple moving ui objects which produce a different screenshot in the next frame thus there are quantities of different screenshots in each scene.
given that each game contains abundant different scenes we can produce sufficient diverse abnormal screenshots for well fitting the model.
the rulebased data augmentation is an offline approach thus is processed after all the bug free screenshots are collected.
table shows the distribution of screenshots we collected.
the test dataset that we use to evaluate the model is collected from historical bug reports.
we exclude the screenshots of game1 and game2 as well as some low quality images and finally get glitch images.
table experiment setup approach glitch image normal image total base rule code code rule .
baselines to further demonstrate the advantage of our proposed data augmentation approach we compare glib with five baselines utilizing deep learning techniques to examine the ui glitch detection effect.
because our goal is to detect ui glitches via bug understanding for all the baseline we use the same cnn model and only with different data handling techniques.
the dataset size of each baseline is listed in table .
base.
we search the historical test reports of game1 as well as game2 and collect screenshots which are truly bug images confirmed by the development teams.
we select of the glitch screenshots and combine them with normal images that we collect from game1 and game2 to build the training dataset without any augmentation approach and our evaluation dataset consists of left glitches screenshots and normal images.
we exclude the game1 and game2 screenshots from the filtered graphical glitch screenshots which are collected from game apps and remain glitch screenshots for the test procedure.esec fse august athens greece ke chen yufei li yingfeng chen changjie fan zhipeng hu and wei yang figure examples of rule based data augmentation the four rows from top to bottom correspond to image partial repetition adding solid color block adding mosaic effect and adding random noise respectively.
rule r .
the heuristic based data augmentation approach proposed by owl eyes contains several rules to approximate the ui display issues in non game apps.
because most of their rules are based on text relevant ui bugs e.g.
null value text overlap which rarely appear in a game scenario we adapt their rules to our studied manifestation of game ui glitches for each of the ui display issues we generate screenshots by randomly choosing one of the following four rules.
image partial repetition we randomly choose a rectangle area in an image then repeat sampling in a horizontal or vertical direction adding solid color block we generate 5blocks where all pixels share the same color in one block and put them on an image randomly one by one thus the former color block may be partial covered by the latter one.
color of each block can be arbitrary rgb value adding mosaic effect we randomly choose a rectangle area in an image dividing the area into several small patches where every pixel has the same rgb value as the center pixel in one patch adding random noise we randomly choose a rectangle area in an image and set rgb value randomly for every pixel in the rectangle.
the four pairs of rule based generated screenshots are shown in figure .
we generate abnormal samples based on the normal data with four simple heuristic approaches we discuss above note that each normal screenshot is used only once.
the final training data contains normal screenshots and generated glitch screenshots where of them are generated by image partial repetition of them are generated by adding solid color block of them are generated by adding random noise and the left of them are generated by adding mosaic effect to the screenshots.
the1 evaluation samples are composed of partial repetition glitch images abnormal color block screenshots random noise screenshots mosaic effect screenshots and normal screenshots.
rule f .
for the second rule adding solid color block we choose the rgb value of generated color blocks from the pre defined four color values red black pink and cyan rather than arbitrary value due to the prior knowledge that these color appears mostly when the material of game objects is missing or settled during the loading process.
the other setting in this baseline is the same as rule r approach.
code rule r .
we combine both code based and rule r based generated screenshots as the training dataset for modeling the ui glitches.
code rule f .
we combine both code based and rule f based generated screenshots as the training dataset for modeling the ui glitches.
.
evaluation metrics to evaluate the overall effectiveness of our proposed game ui display issue detection approach we apply four commonly used evaluation metrics in image classification tasks i.e.
accuracy precision recall f1 score .
for all the metrics a higher value indicates better model performance.
accuracy.
accuracy reflects the trained model s ability to make correct decisions on the test set.
the more correct samples the model predicts the higher accuracy it will output.
precision.
precision presents the proportion of correctly classified screenshots as ui glitch among all screenshots predicted as ui glitch.
recall.
recall indicates the proportion of correctly classified screenshots as ui glitches among all screenshots that have ui display issues.
f1 score f measure .
f1 score is calculated from the precision and recall of the test and it reflects the harmonic mean of precision and recall.
the highest possible value of an f1 score is which indicates perfect precision and recall and the lowest possible value is if either precision or recall is zero.
results and analysis .
ui glitch detection performance rq3 we evaluate the effectiveness of our glib and the baseline approaches on the testing dataset composed of the collected abnormal screenshots with ui glitches and normal screenshots the experiment results are listed in table .
we can see that our code based data augmentation approach achieves the overall best performance i.e.
highest precision recall f1 score accuracy .
the .
increment of recall compared to the base approach indicate the effectiveness of our code based data augmentation approach.
we search for only one false negative sample and find that the error area in this screenshot is too tiny to be recognized even for humans.
particularly the five baseline approaches all achieve high precision indicating that most screenshots predicted by the model as abnormal have ui glitches.
the base approach trained without any augmentation approach by only using the original glitch screenshots has the lowest recall .
indicating that almost half ofglib towards automated test oracle for graphically rich applications esec fse august athens greece the ui glitch images are incorrectly classified by the model if not sufficient ui glitch samples are learned.
we search the classification result and find that the model cannot detect the screenshots with ui glitches such as partial repetition abnormal text and abnormal color block.
though these categories occupy a large proportion of ui glitch issues the number of glitch images is too small to cover the different patterns of these categories and hence the model cannot learn the ui glitch manifestation sufficiently.
table experiment results approach precision recall f1 score accuracy base .
.
.
.
rule r .
.
.
.
rule f .
.
.
.
code rule r .
.
.
.
code rule f .
.
.
.
glib .
.
.
.
rule f incorrectly classifies glitch screenshots as normal.
we check these images and find that the glitch issues of them are mainly abnormal color block and text overlap.
as we mentioned before we only adopt four colors black red pink cyan to generate the solid color block in rule f approach which may cause the detection failure when a new color block appears.
we check the bug reports and find that color blocks other than the pre defined four types appear due to material missing.
however this unexpected error only occurs on a special gpu that has a special order of rgb values which indicates that the manifestation of ui glitches on different devices caused by the same bug can still be different.
the performance of rule f is degraded by text overlap glitch issues because we do not consider the rules of abnormal text as we cannot localize the text area in ui screenshots without labeled json files that are typically not supplied by game engines.
moreover in game apps some texts are displayed as word arts or images but not the order of standard characters thus the localization technique that uses ocr tools cannot work.
we study the false negative samples from rule r and find that the main ui glitch categories of them are text overlap and abnormal color block particularly these color blocks are transparent and can be easily recognized as part of the background object.
this transparent color block is similar to the dialog box in games and is misclassified also because we didn t generate the text relevant glitch images in our training dataset.
because the transparent color blocks do not appear in the training dataset of the rule approach it is straightforward that the model cannot this type of ui glitches.
moreover we find that the glitch images with blue color blocks are detected as ui glitch images whereas rule f regards them as normal images the reason may be that the rule r approach can generate blue color blocks that can t be produced by rule f .
for code rule r and code rule f their recalls are largely improved compared to the single rule r and rule f approach which demonstrates that the glitch images generated by our codebased approach can facilitate the model to learn more effectively.
however the reason that the combined approaches are not as effective as the single code based augmentation approach may be thatthe distribution of code based generated samples and rule based generated samples are not identically consistent which may affect the training result.
.
practical evaluation rq4 to examine the practical value of our glib we collect two pc games from the official website three ios games from app store and nine android games from taptap development teams.
these games are developed by different game engines and none of these apps appear in the training dataset.
airtest is a cross platform ui automatic game testing framework and testers can write test scripts in airtest ide to execute specific test cases in the mobile device.
airtest ide also provides a screen capture api for testers to take screenshots when necessary.
we use the screen capture api to collect screenshots of various kinds of ui events e.g.
click swipe long press etc.
from the games by running different test cases.
we generate in total screenshots from the games an average of screenshots are obtained for each app.
we then feed those screenshots to our glib for detecting abnormal ui issues.
once a ui glitch is spotted we record the bug and report the issue to the app development team.
table detected game issues game name game category source daily active users download justice role playing official web 300k 50m a chinese ghost story role playing official web 300k 50m ghost role playing taptap 700k 100m revelation mobile role playing taptap 500k 10m love is justice love taptap 50k 5m uno card app store 50k 5m fever basketball moba app store 5k 5m marvel duel card taptap 5k 500k oracle civilization simulation app store 1k 100k ghost world chronicle card develop team n a n a elysium of legends card develop team n a n a phase10 card develop team n a n a fpus shooting develop team n a n a the absolute acting simulation develop team n a n a table practical evaluation results platform glib rule r rule f pc android ios total confirmed confirmed confirmed table lists all bug issues detected by our glib and table shows the number of detected ui glitch issues on different platforms by the three approaches.
in sum glib detects glitch issues and of them are confirmed and fixed by the game development team rule r spots glitch issues and of them are confirmed and fixed rule f detects glitch issues and of them are confirmed and fixed.
these confirmed and fixed bugs further demonstrate the effectiveness of the practical value of our proposed approach in detecting game ui glitches.esec fse august athens greece ke chen yufei li yingfeng chen changjie fan zhipeng hu and wei yang case study to demonstrate that glib can accurately localize the glitch area of detected abnormal screenshots we apply the saliency map introduced in section .
to show developers more detail about our model s prediction.
we randomly select some images that are classified by glib as glitch images and calculate the derivative of the output concerning each pixel in the input image the results are shown in figure where the original screenshots are placed in the left and the generated saliency maps which are converted to heat maps are listed in the right.
a brighter area in the heat maps indicates a larger gradient of corresponding pixels i.e these pixels contribute more during the classify progress and are more likely to be the ui glitch issues.
the ui glitch of the first image in figure is partial repetition and the corresponding saliency map shows that glib concentrates much on these repetition areas which is consistent with the manifestation.
the saliency maps of the second and the third images indicate that the abnormal color blocks rather than the other background elements are the buggy area of the screenshots which also agrees with the manifestation.
from the saliency map of the glitch screenshots we can see that the model can not only accurately detect the image with ui glitch issues but can also localize which part of the screenshot is abnormal.
figure the images in the left column are the glitch images and images in the right column are the corresponding saliency map the red pixel contribute most to the final label.
discussion in this section we discuss the generality of our approach.
generality across games.
our training data are collected and augmented from acting games which may limit the model s applicability in real world practice.
however our testing data used in rq3 consists of games including categories such as roleplaying games card games shooting games moba multiplayer online battle arena love games simulation games etc.
which nearly cover all popular daily used game apps.
the evaluation result shows that our proposed glib can accurately detect .
recall all screenshots with ui glitches.
this further demonstratesthe generality of glib across different types of games.
moreover our glib is a black box image augmentation approach that requires source code only in the training phase and the well trained model can be directly used to detect ui glitches on other games.
generality across languages.
another advantage of our glib is that it can be applied for detecting ui glitches on game applications with different languages.
although the testing data of our experiment for rq3 and case study only contains the screenshots of chinese games our study in section .
shows that most of the game ui glitches are text irrelevant i.e.
abnormal text only account for of all the ui display issues plus our code based data augmentation approach mainly focuses on ui glitches that are language invariant such as abnormal color block random noise partial repetition and frame overlay caused by rendering effect or post processing effect error.
hence our proposed glib can be generalized for ui glitch detection in games with other languages.
generality across platforms.
even though different games may run on different platforms the game ui content is mostly decided by novel images which consist of 3d models as well as ui components.
to prove that our model can precisely detect glitch images in terms of different game platforms we collect ui screenshots from android games ios games and pc games and use them as our testing dataset.
the experiment results in rq3 show that our approach can accurately detect all ui glitch images from games with different platforms which further demonstrates the feasibility of our proposed glib .
generality across engines.
the game engine is a software development environment that provides developers with a series of tools to facilitate easy program writing.
games based on different engines may have different program structures but the game ui rendering effect mainly depends on the low level cpu gpu system calls.
for the same root cause bug error the manifestation of glitch images is typically similar regardless of which game engine the game is based on.
to prove that our glib can well recognize glitch images across different engines we select games developed by a self defined engine unreal engine based game and unity games to compose our test dataset in rq3.
the experiment results show that our model can be generated well across different game engines.
related work our work inspired by the automatic gui testing combined with deep learning technique proposes a game gui bug detection approach.
gui a visual interface connecting users and software programs has been studied by many researchers on different topics.
automatic gui testing dynamically explores guis of an application and several approaches use computer vision techniques to detect gui components to make predictions and compare different tools for gui testing on android applications.
recent deep learning based techniques have also been applied for automatic gui testing.
more work on gui with computer vision techniques such as gui search and gui code generation facilitates the effective completion of computing tasks based on image features.glib towards automated test oracle for graphically rich applications esec fse august athens greece on the other hand many software linting tools aiming to flag bugs stylistic errors programming errors and suspicious constructs have been proposed to ensure the normal operation of gui.
for example stylelint helps developers avoid errors and enforce conventions in styles android lint reports over different types of android bugs including correctness performance security usability and accessibility.
different from static linting our glib dynamically explores guis of an app as what automatic gui testing does but note that these gui testing techniques concentrate on functional testing whereas our work focuses on non functional testing i.e.
gui glitches typically do not cause app crash but negatively affect the app usability .
we analyze the gui display issue in terms of software rendering bugs such as rendering camera settings and post processing effects error which cause the app compatibility problems.
it is extremely difficult and expensive for the developers to cover all the popular contexts when conducting testing.
moreover our work only requires the screenshots as the input rather than these works based on static or dynamic code analysis.
this crucial characteristic makes it easier for our lightweight cnn based model to learn the pattern of ui glitch images and localize the ui glitches on the screenshot by a saliency map and also makes our approach more generalized to a different platform.
threats to validity in our glib framework the only manual part is to traverse and identify multiple diverse game scenes in each game for building our original training dataset.
also our defined three categories of code injection approaches are based on study and empiricism.
the code injection data augmentation based on hotfix patching technique cnn based ui glitch detection as well as ui issue localization are all automated and can be easily adapted to other games on different platforms.
inappropriate selection of game screenshots in the manual part may weaken the external validity of experimental conclusions.
we try to mitigate this threat by traversing and selecting as many as distinct game scenes to make the dataset diverse and abundant.
our internal threat mainly arises from the completeness of manifestation of game ui glitches and our defined three types of code patching approaches.
we ask several game developing experts from netease to confirm that our summarized eight categories of ui glitches do cover all the common issues in their game apps.
we also show that our code injection can generate all the most common five types of ui glitches.
conclusion and future work detecting and improving the quality of mobile game applications is of great value for nowadays game developers and testers.
this paper proposes an automated ui glitch detection approach based on deep learning and bug analysis.
our empirical study on the root causes of game ui glitches facilitates a code based data augmentation approach.
experimental results show that our glib is effective and shows great advantage in a real world game testing scenario i.e.
achieving nearly precision recall and f score for classifying screenshots collected from popular games way better than the existing rule based approach.
also as the first work on game ui testing we contribute to a systematical investigation ofui glitches in real world mobile game apps as well as a large scale dataset of game app uis with display issues for follow up studies.
our proposed test oracle for automated ui glitch detection could facilitate further study on game ui testing.
in the future we will focus more on the gpu related rendering issues that cause game ui glitches and also keep improving the functionality of our model.
specifically glib is one part of the game testing framework that we plan to research in the future.
the whole framework contains an io module ascene traverse module glib and a log module .
first io module captures screenshots from a mobile device and feeds them to both glib and the scene traverse module second glib classifies the given screenshot as normal or glitch log module loggings the corresponding information and the scene traverse module recognizes ui and click to yield the next scene then it chooses a ui and returns the ui back to io module last we repeat the two steps to realize the whole automated game testing.
moreover we hope to find a tight connection between bugs and the characteristic of ui glitches so that we can predict the bug code given a screenshot with ui display issues.
and this bug inference technique can be more valuable when guiding developers to fix app compatibility issues.