data driven accessibility repair revisited on the effectiveness of generating labels for icons in android apps forough mehralian school of information and computer sciences university of california irvine usa fmehrali uci.edunavid salehnamadi school of information and computer sciences university of california irvine usa nsalehna uci.edusam malek school of information and computer sciences university of california irvine usa malek uci.edu abstract mobile apps are playing an increasingly important role in our daily lives including the lives of approximately million users worldwide that are either completely blind or suffer from some form of visual impairment.
these users rely on screen readers to interact with apps.
screen readers however cannot describe the image icons that appear on the screen unless those icons are accompanied with developer provided textual labels.
a prior study of over android apps found that in around of the apps less than of the icons are labeled.
to address this problem a recent award winning approach called labeldroid employed deep learning techniques to train a model on a dataset of existing icons with labels to automatically generate labels for visually similar unlabeled icons.
in this work we empirically study the nature of icon labels in terms of distribution and their dependency on different sources of information.
we then assess the effectiveness of labeldroid in predicting labels for unlabeled icons.
we find that icon images are insufficient in representing icon labels while other sources of information from the icon usage context can enrich images in determining proper tokens for labels.
we propose the first context aware label generation approach called coala that incorporates several sources of information from the icon in generating accurate labels.
our experiments show that although coala significantly outperforms labeldroid in both user study and automatic evaluation further research is needed.
we suggest that future studies should be more cautious when basing their approach on automatically extracted labeled data.
ccs concepts human centered computing empirical studies in accessibility software and its engineering software usability .
keywords accessibility deep learning android alternative text screen reader acm reference format forough mehralian navid salehnamadi and sam malek.
.
data driven accessibility repair revisited on the effectiveness of generating labels for icons in android apps.
in proceedings of the 29th acm joint european esec fse august athens greece copyright held by the owner author s .
acm isbn .
engineering conference and symposium on the foundations of software engineering esec fse august athens greece.
acm new york ny usa 12pages.
introduction there is an increased onus on app developers to make their products accessible for users with a wide range of disabilities including the approximately million users worldwide that are blind or visually impaired .
blind users rely on screen readers to interact with apps.
built in screen readers in mobile devices facilitate interactions with mobile apps by reading the screens out loud for the users.
similar to alt text for web images the embedded textual labels for gui images are essential for enabling usage of these apps by the blind.
these labels are even more critical for functional icons images that developers utilize to convey the availability of an action not to convey information.
without a proper description of the functionality initiated by icons screen reader users are unable to interact with an app.
app accessibility is thus directly affected by the lack of informative icon labels.
recently several projects have studied the extent of accessibility issues in mobile apps among others demonstrating widespread violation of label based accessibility guidelines in android apps.
missing labels duplicate labels and non informative labels are different types of label based accessibility concerns among which missing labels is the most prominent one.
missing label occurs when an icon is not accompanied with a textual label a.k.a.
content description in android describing its functionality.
ross et al.
report that in of their assessed apps less than of icons were labeled.
the increasing awareness of this accessibility issue has instigated some recent efforts towards alleviating it .
notably chen et al.
developed a promising method called labeldroid which employs deep learning techniques to train a model on a dataset of existing icons with labels to automatically generate labels for visually similar unlabeled icons.
for data driven approaches such as labeldroid data exploration is a prerequisite.
perfect model architectures may deliver misleading or unexpected results if the dataset is not carefully examined.
although prior works have empirically studied the severity of the missing labels none have studied the characteristics of natural language labels for the labeled icons extracted from thousands of automatically explored apps in terms of their categories uniqueness distribution and dependency to other icon properties which can be relevant to the problem of automatic label generation effectiveness of existing repair approaches in predicting different categories of labels and impact of incorporating different sources of information in generating icon labels.
1labeldroid received the acm sigsoft distinguished paper award at icse .
107this work is licensed under a creative commons attribution international .
license.
esec fse august athens greece forough mehralian navid salehnamadi and sam malek to fill this gap we conducted a large empirical study on icons extracted from android apps to understand the characteristics of icons and labels in android apps.
we then assessed the effectiveness of learning and generating natural language labels using this dataset.
our empirical study reveals that the dataset of automatically extracted icon labels is highly imbalanced resulting in a severe data driven bias in the labeldroid model.
it is striking that the introduced bias in labeldroid is toward predicting predefined labels that are shipped with icons in the widgets and templates of android s standard development kit.
since in practice it is extremely unlikely for these icons to be unlabeled generating labels for them is pointless.
we found that excluding these predefined labels drops the labeldroid s accuracy by .
besides our empirical study shows the necessity but insufficiency of images in representing icon labels.
we found that incorporating different information sources for icons can enrich their representation by providing their usage context substantially improving the identification of correct tokens in labels.
these findings subsequently informed the development of coala adeep learning dl approach to generate context aware labels for icons in android apps.
coala automatically extracts high quality labels for icons from the raw dataset of app screens and layouts from which it learns how to incorporate different sources of information and translate the image to a textual label.
it then utilizes the learned model to generate informative labels for unlabeled icons.
our experiments show that coala outperforms labeldroid by in generating labels for unlabeled icons that exactly match the ground truth.
this paper makes the following contributions an empirical study of the nature of labels and how different sources of information contribute to predicting a correct label an analysis of data imbalanceness and how it invalidates the results reported in the evaluation of labeldroid coala the first context aware label generation approach to generate textual labels for android icons and its implementation which is publicly available experimental results corroborating the superiority of coala in comparison to labeldroid in generating high quality labels for icons.
the remainder of this paper is organized as follows.
section provides the background of this study using an illustrative example.
section explains the empirical study of natural language labels and other sources of information of icons.
then section describes coala in detail which will be evaluated in section along with the existing deep learning model labeldroid.
section explains the threats to the validity of the research.
the paper concludes with a discussion of the related research and avenues of future work.
background an android app s user interface ui is implemented in terms of one or more activity components where each activity represents a screen.
figure shows an activity for a messenger app along with snippets of its xml layout and source code.
a layout file specifies the placement and design of ui elements in an activity.
ui elements such as imageview are objects in the xml tree structure of layout.
package phone.callclass contactshandler extends activity audiocall contact addcontact search... audiocall phonenumber apk com.app.voipcontacts list.xml imageview... android id id contactadd android contentdescription create new contact ... imageview... android id id phoneicon android contentdescription audio call ... imageview... android id id navigateup android contentdescription navigate up ... imageview... android id id dial android contentdescription dial new number ... natasha contacts 4figure icons and their content descriptions in a messenger app visually impaired users rely on screen readers like google s talkback service to interact with apps.
screen readers describe images for blind users by announcing the developer provided textual label in android contentdescription field of ui elements such asimageview andimagebutton .
figure illustrates four icons in a messenger app along with their content descriptions in the layout.
note that the icons comprising android standard development kit s ui widgets and templates such as action bars come with predefined labels.
the textual description of icon number in figure navigate up is an example of such predefined labels.
prior studies show that missing label i.e.
content description is a prevalent accessibility issue in android apps rendering screen readers inoperable.
the plus icon in figure suffers from this issue.
talkback screen reader describes this button as unlabeled button seriously hindering a blind user s ability to use the app.
to tackle this issue chen et al.
proposed labeldroid which predicts natural language labels for icons given their images using deep learning techniques.
in their work the authors extracted thousands of labeled icons from android apps.
they then trained an image captioning deep learning model to transform icon images to natural language labels.
however images cannot fully represent icon labels.
for example while the plus icon in figure and figure are visually similar a proper label for the former e.g.
create new contact is different from the label for the latter i.e.
add a playlist .
the distinction between two labels comes from the usage context of icons.
the former is used in the contacts page of a messaging app while the latter is used in a music player app.
our objective is to understand the nature of natural language labels for icons study the effectiveness of the prior work and propose an automated label generation model to alleviate the shortcomings of the prior work and motivate the need for further studies.
data exploration to develop a better understanding of icon labels and whether different sources of information have predictive impact on them we conducted an empirical study to answer the following research questions 108data driven accessibility repair revisited on the effectiveness of generating labels for icons in android apps esec fse august athens greece apk media.music.musicplayeractivity main.xml viewgroup... android id id fab create playlist imageview... android id id mybutton android contentdescription null ... ... figure plus icon in a music player app rq1.
what are the characteristics of labels regarding their uniqueness and distribution?
rq2.
how similar are the labels of icons with similar images?
rq3.
to what extent different sources of information from icon context can reveal the label?
.
experimental setup we conduct our study on a set of icons extracted from android apps included in the labeldroid dataset .
this dataset was collected through dynamic gui exploration of apps.
we extracted visible clickable android imageview andimagebutton icons from xml layouts and screenshots to form our primary dataset for this study.
each icon in our dataset corresponds to a triple of image label usage context .
for image we crop the screenshot based on the coordinates of an icon s boundary box as specified in the bounds property of the icon considering the orientation of the device.
for label we use the value of contentdescription property associated with the icon.
for contextual information we extract several parameters in three levels i.e.
app level app category activity level activity name screen title icon level android id screen region ancestor id siblings id text .
the majority of contextual parameters directly map to a property in the xml layout e.g.
idandtext .
to find the parent and siblings of an icon we refer to the hierarchical structure of xml layouts.
icons that share a parent node in the xml tree are considered to be siblings.
for the screen title we refer to the text property of the top leftmost textview element in the layout.
for the screen region we refer to the bounds property of an icon to determine in which of the screen regions as specified with dashed lines in figure it belongs.
activity names and package names are available in gui exploration artifacts.
we then use package names to extract app categories from google play using beautifulsoup crawler.
to improve data integrity we performed text normalization steps on textual information of icons.
labels and textual parameters extracted using the above mentioned techniques are not restricted to follow a standard or commonly accepted structure.
developers may use camelcase or snake case conventions or even other types of characters as delimiters.
we transformed the textual information to lower case replaced all the special characters with figure imbalanced distribution of labels for icons.
to the left are the few dominant classes and to the right is the long tail.
the cutoff separates the labels with more than samples.
a space and applied spell correction and lemmatization to their tokens.
we also filtered meaningless labels as introduced in the prior work .
in our dataset icons with the same label in the same app would be counted once.
thus our dataset consists of icons extracted from different screens of apps.
.
rq1.
characteristics of labels for this research question we first study the distribution of icon labels.
in our dataset we found different labels with high class imbalance.
by considering each of these labels as a class for icons we observed a long tailed dataset as shown in figure in which .
of the data comes only from most frequent classes while .
of the classes have less than samples in the whole dataset and out of occurred only once.
the average number of samples per class is .
and the median is .
the gap between mean and median also indicates a left skewed data distribution.
by further exploration of dominant classes of labels we found that some android icons come with a predefined label.
for example if a developer uses an up button in the action bar similar to icon in figure it comes with navigate up label.
we manually extracted predefined labels for all icons in android studio the most widely used ide for android development.
this analysis produced the following labels navigate up more options next month previous month open navigation drawer close navigation drawer search clear query interstitial close button .
if we exclude these labels the average number of samples per class drops by .
and changes to .
.
this observation alerts us to the erroneous conclusions we may draw from the evaluation of a label prediction approach.
to facilitate the explanation of the issue imagine of the data has label x. in that case a model that just predicts x is already accurate and its effectiveness may not be interpreted realistically.
this issue would be exacerbated if our goal was to label unlabeled icons but the model is only good at predicting dominant labels that happen to be the aforementioned predefined labels.
in addition to dominant classes it is also important to pay attention to low frequency labels.
the long tail of label distribution demonstrates the labels for which the dataset may not be representative enough.
when we exclude predefined labels .
of 109esec fse august athens greece forough mehralian navid salehnamadi and sam malek the remaining labels have only one sample in the dataset.
that means a proper label for them cannot be simply retrieved from the previously seen data challenging a deep learning model for prediction of labels.
observation the data is highly skewed towards a limited set of labels threatening the validity of the evaluation of a label prediction model.
furthermore low frequency and unique labels in the long tail challenge the construction of an effective learning based prediction model.
when we studied the distribution of tokens in the whole dataset we observed the same long tailed distribution.
that is the tokens of predefined labels are the dominant classes.
we further studied the tokens for unique labels to determine to what extent the tokens of unique labels can be derived from previously seen tokens.
we found that for .
of unique labels allof the tokens were observed in the previously seen tokens and for .
of the unique labels at least one non trivial token was previously seen.
by trivial tokens we mean stop words such as for the to etc.
thus a token based label prediction model may hold promise in correctly generating low frequency and unique labels.
observation substantial portion of tokens comprising the unique labels can be found in the existing vocabulary of tokens suggesting a token based prediction model may be effective in correctly generating low frequency and unique labels.
.
rq2.
labels of visually similar icons in order to study labels of icons with similar images we trained an image classifier and annotated the icons with their image class.
liu et al.
identified common image classes shared across apps through manual open coding of android icons.
they then trained a convolutional neural network cnn to classify icon images.
their model is accurate on average in predicting class of icon images.
rico dataset provides the output of this image classifier for icons existing in their dataset of android screens.
we augmented our dataset with the class of icons to study the diversity of labels of visually similar icons.
on average each class contains .
icons with .
different labels.
for example among icons in class add the plus icon different labels exist.
in terms of tokens the average number of unique tokens for labels in each class of icons is .
with the median of .
for instance there are unique tokens comprising the labels of icons in class add .
observation while image similarity restricts the set of probable labels and tokens for icons there is still substantial level of diversity among labels and tokens for visually similar icons.
.
rq3.
labels and icon information we study the relationship between tokens of icon labels and other contextual information from the icon.
we extract the contextual information in three levels app level that contains the categoriestable correlation and mutual information mi between icon information c and tokens in labels t. information sources mi t c t c app level category .
.
activity levelscreen title .
.
activity name .
.
icon levelandroid id .
.
screen region .
.
siblings id .
.
siblings text .
.
parent id .
.
of apps activity level including screen title and activity name and icon level that contains the identifier name of the icon itself its parents and its siblings along with the region that the icon is located and the texts of its siblings.
to measure the dependency between two random variables we calculate their mutual information mi .
it quantifies the amount of information obtained about one random variable through observing another random variable.
in the context of our problem mi determines which parameter c has the highest likelihood of predicting correct tokens in the label t.mi c t is defined as h t h t c wherehis the entropy representing the uncertainty in a random variable.
although mi tells us how important the parameters are in predicting tokens it does not tell us whether the contextual information is a predictor of presence or absence of tokens in icon labels.
for that we calculate the pearson correlation coefficient t c to see how changes in the icon information result in predictable changes in the tokens.
table summarizes the result of this experiment.
as shown in table we observe different degrees of correlation between the various sources of information and the tokens.
the identifier name of the icon and its parent have the highest correlation with tokens in the labels.
while app category does not appear to associate with tokens.
apart from app category activity level parameters have least correlations.
observation different information sources exhibit different degrees of effectiveness in empowering a probabilistic model in predicting tokens for icon labels.
.
summary our findings in data exploration motivated us to conduct further studies on the models and develop coala the first context aware label generation approach.
first the empirical study showed that the dataset of icons and labels in android is highly imbalanced towards predefined labels.
thus we will study the impact of learning on such data on the model fairness.
second the empirical study showed that while a significant subset of labels in the dataset are unique substantial portion of tokens comprising these unique labels can be found in the existing vocabulary of tokens.
to overcome the challenge posed by unique and low frequency labels for a dl approach we devise a learning model to generates labels in terms of their constituent tokens.
third the empirical study showed that while there exists a wide variety of labels for visually similar icons there are other sources 110data driven accessibility repair revisited on the effectiveness of generating labels for icons in android apps esec fse august athens greece of information available for improving the representation power of a probabilistic model.
our approach in turn leverages additional sources of information of an icon in addition to its graphical representation to determine the probable tokens in its label.
this is akin to the intuition that sighted users can easily distinguish the functionality of similar icons by virtue of their knowledge of each icon s usage context.
in the following section we describe the architecture of coala .
we then study further research questions related to the fairness and effectiveness of dl models in generating textual labels for icons in section .
4coala in the following section we introduce coala adeep learning dl approach to generate context aware labels for icons in android apps.
figure provides an overview of coala which consists of two main modules data pre processing anddl architecture .
data pre processing module in coala is responsible for extracting a dataset of labeled icons along with their information in their usage context.
after finding icon specifications from thousands of xml layouts it filters improper and duplicate icons similar to the prior work and creates a dataset of icons for the dl module.
the dl architecture is responsible for encoding the icons to be later decoded to textual labels.
the encoding step has two phases image encoder and context encoder each of which is tailored to compute the embedding of a specific type of data.
these representations are then fused in a fully connected layer to prepare a vector from which label decoder generates the corresponding textual label.
in the remainder of this section we describe the details of each module in our dl architecture as illustrated in figure .
.
image encoder module embedding visual data into low dimensional space has been extensively studied using the convolutional neural networks cnn .
this type of network receives input images as a matrix of their pixel values and extracts a feature vector of the input image through various convolutional and pooling layers.
coala encodes images in the same fashion.
however instead of training a cnn model from scratch it utilizes the transfer learning technique.
transfer learning allows us to leverage pre trained cnn models such as resnet without the need for dealing with technical challenges of training a model from scratch on a big lstmglovelstmone hotlstmglovetoken0tokennh0hnh1reg cat imagelabeldatacontext encoderresnetfeature vectorlinearfully connected layerlstmlstmlstmsoft maxsoft maxsoft maxw0w1 eos sos w0wnlabel decoderimage encoder icon extractor data pre processing filter in gdeep learning architecture figure overview of coala frameworkenough set of training data for sufficient amount of time.
that means we leverage the knowledge of a pre trained resnet model and re purpose it for icon image classification a.k.a.
fine tuning.
to that end we prepared a dataset of icon images with their annotated classes from rico dataset .
using a tool in prior work rico augmented more than screenshots with semantic annotations which consist of icon classes.
we extracted annotated icons in rico dataset and manually checked the consistency of images with their annotated class.
we also downsampled dominant classes of icon images to have a balanced dataset.
we trained and fine tuned a pre trained resnet18 classifier using this data and used it in coala for encoding icon images.
.
context encoder module the input of context encoder is the sources of information from usage context of the icon as shown in table .
the purpose of this module is to embed these parameters into a feature vector.
in choosing a proper model for context encoder we should consider three main characteristics of parameters.
first these parameters have two different types categorical and textual.
second textual parameters have a variable length.
third often only a subset of parameters are available for a given icon.
to support both categorical and textual parameters context encoder utilizes two different input embedding components namely one hot encoder and a word embedding model specifically glove .
one hot encoder maps the categorical parameters i.e.
category andscreen region to a binary vector.
category can take either one of the categories that exist in google play or none if it was removed from google play by the time we checked.
screen region is one of the zones as shown in figure that an icon can belong to.
thus the encoded vector should be at least bits in length.
however it is zero padded to have the same length as the vector representation of other parameters.
for textual parameters similar to context encoder first summarizes all the parameters into one sentence by joining the textual phrases with a dot .
as a delimiter.
for example for the plus icon in figure joining the page title i.e.
playlist and its cleaned android id i.e.
create playlist results in the summary of playlist.create playlist.
for textual parameters of the icon we filtered fab token since it specifies the icon type i.e.
floating action button and is not informative .
then a pre trained glove model is responsible for mapping each token in the summarized sentence to its vector representation.
glove is an unsupervised pre trained model that has proven its ability in capturing syntax and semantic regularities using vector arithmetic .
this is mainly because it is not needed for the model to learn the exact vocabulary of these tokens and using a semantic preserving word embedding enables the model to better generalize to unseen tokens whose synonyms exist in the dataset.
given the vector representation of icon information context encoder utilizes a recurrent neural network rnn .
rnns are known for their chain like structure which makes them capable of learning from variable length sequences of data.
specifically we use a type of rnns long short term memory lstm networks shown to be superior to the standard rnns by avoiding the long term dependency problem caused by vanishing gradients .
lstms consist of a chain of repeating modules a.k.a.
lstm cells .
the vector representation of icon information passes through the 111esec fse august athens greece forough mehralian navid salehnamadi and sam malek lstm cells in which four neural network layers interact in a special way.
several adjustable weights control the information each cell remembers forgets or passes to the next cell a.k.a.
hidden state .
during training the model tunes these internal weights towards decreasing the overall training loss.
the output of the last lstm cell is fused in a fully connected layer with the image embedding to provide the input for the label decoder module.
.
label decoder module given the image and other information of an icon the label decoder is responsible for generating natural language labels.
icon labels are variable length sequences of tokens.
thus a proper model should be able to generate accurate tokens of labels sequentially.
to that end coala employs an lstm network with an internal loop that lets it iteratively generate icon labels token by token.
at each time step the label decoder chooses the most probable token from a vocabulary of tokens.
coala builds this vocabulary based on frequent tokens in the labels of the training set.
this vocabulary also includes sos start of sequence eos end of sequence and unk unknown .
then each label will be represented by a sequence of ids of its comprising tokens surrounded by sos andeostokens.
unk stands for tokens of labels that are not in the vocabulary.
label decoder initializes the hidden state of the first lstm cell with the encoder output.
similar to the lstm network of context encoder module four internal neural network layers with adjustable weights regulate the information flow through the network.
label decoder also sends an sostoken to the first lstm cell to signal the start of the label generation process.
next the lstm cells get the previously generated token as input and calculate the score of choosing each token in the vocabulary.
a softmax layer gets the lstm cell output to transform the scores to a probability function.
the most probable token is the final output at each step.
label decoder terminates this procedure when eostoken is the output of current time step.
to train dl model label decoder calculates cross entropy loss function to measure the extent to which the predicted probability diverges from the actual token.
coala trains the whole dl architecture end to end.
thereby this loss function back propagates through the whole network i.e.
encoder and decoder to adjust the internal weights.
during training the aforementioned process of passing the last generated token to the next lstm cell can be followed.
however this process results in model instability and slow convergence .
to alleviate these issues coala uses teacher forcing strategy.
teacher forcing is a training time procedure in which the model receives the ground truth output ytas input at time step t .
this means label decoder passes the tthtoken of the target label as the input to the t 1thlstm cell during training.
however in the testing phase we pass the previously generated tokens to the next lstm cell and we only use the ground truth labels to calculate the performance of the model.
dl model assessment to study the impact of imbalanced training data on the state of theart model labeldroid and also the effectiveness of our contextaware approach we study the following research questions rq4.
how effective is labeldroid in practice?table details of coala dataset app activity icon train test validation total rq5.
to what extent is the dl architecture of labeldroid capable of coping with imbalanced data?
rq6.
how effective is the context aware model of coala in label prediction?
to what extent coala outperforms the contextagnostic model of labeldroid?
rq7.
to what extent the labels provide an informative explanation of the icon functionality?
rq8.
how long does it take for coala to train and predict labels?
.
experimental setup .
.
datasets.
we split the dataset of icons introduced in section .
into three separate sets with respect to apps.
in this way train validation and test set are respectively and of apps selected randomly.
table shows the details of our dataset.
note that we run our experiments times using different random partitioning of the data to minimize evaluation bias.
this means in a different random partitioning the number of icons and screens may be slightly different in each partition since we split based on apps.
moreover as we aim to study the effects of imbalanced data on labeldroid inspired by prior work we created balanced datasets by downsampling dominant classes of data.
a parametric sigmoid function on the inverse label frequency manages the balanceness of the dataset.
sigmoid parameter adjusts the number of frequent labels included in the sampled data by controlling the steepness of its curve.
we experimented with different parameters of sigmoid resulting in balanced datasets of size .
the smallest dataset is completely balanced with one instance for each label.
.
.
dl implementation and configurations.
our dl model is implemented in pytorch a popular open source machine learning library for python.
we utilized adam optimizer to update the internal weights iteratively based on the cross entropy loss function.
to prevent the predefined labels from overwhelming the network during training and producing a biased model we adapted weighted cross entropy to enforce the model learn from the labels in minority.
each dl model has several configurable parameters a.k.a.
hyperparameters that can impact the performance of the model.
to tune these hyperparameters of the model we also performed a guided grid search strategy to choose the values that had the best performance on the validation data.
the details of our configurations are available on coala s website .
.
.
evaluation metrics.
we evaluate the effectiveness of dl models using evaluation metrics that are commonly used for image captioning problems namely bleu meteor rough cider .
we also report exact match i.e.
the percentage of data for which the generated label is an exact match of the ground truth.
that means it only awards the model if allthe tokens of the ground truth appear in the generated label with the same order.
bleu score however focuses on n gram overlaps to measure the quality of the 112data driven accessibility repair revisited on the effectiveness of generating labels for icons in android apps esec fse august athens greece table labeldroid s effectiveness in generating predefined non predefined labels in their test set.
exact match bleu bleu bleu meteor rouge l cider predefined .
.
.
.
.
.
.
non predefined .
.
.
.
.
.
.
all .
.
.
.
.
.
.
generated label.
it calculates precision for n grams denoted by bleu bleu and bleu for n in .
bleu score has some drawbacks for example in not considering sentence structure or word meanings which has led to the advent of other evaluation metrics.
meteor metric for evaluation of translation with explicit ordering is based on the harmonic mean of unigram precision and recall .
rough is a set of recalloriented measures from which we use rough l that is based on the longest common subsequence in the ground truth and the generated label .
cider consensus based image description evaluation leverages term frequency inverse document frequency tf idf to measure the similarity of the ground truth and the generated label .
the implementation of these metrics is available in a python library called nlgeval library which we have used to evaluate coala .
.
rq4.
labeldroid s effectiveness our empirical study section revealed a severely imbalanced label distribution for icons.
we conducted an experiment to study whether overlooking this data driven bias leads to misinterpretation of prior work s effectiveness.
for that purpose we trained labeldroid on their dataset using their default configurations and evaluated the model on generating predefined labels which as introduced in section .
correspond to the default catalog of icons in widgets that come with android studio and non predefined labels i.e.
all the icons in the test set except the ones with predefined labels.
among icons in their test set of them have predefined labels and the remaining icons have non predefined labels.
note that for this research question we use the original dataset of labeldroid to only study the impact of data balanceness and keep their approach as close as possible to their original version.
for next questions we use the dataset introduced in section .
.
which is the extended version of labeldroid s dataset since the dataset they used in their work lacks additional sources of information from icons.
table summarizes the results of this experiment.
as shown in table the effectiveness of labeldroid in all metrics is significantly higher in generating predefined labels than the nonpredefined labels.
the unfortunate outcome is that this variation impacts the overall result resulting in an incorrect interpretation of the model s effectiveness in predicting proper labels for unlabeled icons.
for a better illustration of the impact of imbalanced data on the overall effectiveness of labeldroid consider the stacked bar chart of figure .
here each bar indicates the ratio of correctly predicted labels according to a different metric.
within each bar the solid blue fill indicates the ratio of correctly predicted non predefined labels while the dashed fill indicates the ratio of correctly predicted predefined labels.
figure clearly shows the overall evaluation is highly impacted by the model s effectiveness on predefined labels.this observation indicates that the imbalanced data produced a biased model for predicting predefined labels.
but the issue is substantially more severe than it may appear at first blush since there is no point in predicting icons with predefined labels.
after all these are the labels of icons that are shipped with the popular android studio.
in practice it is a rare occurrence for android studio icons to appear in apps with no labels.
this would only occur if the developer intentionally removes the label automatically associated with the icon by the ide.
the ultimate goal of label prediction is to generate labels for unlabeled icons which often have non predefined labels.
.
.
.
.
.
.
bleu 1bleu 2rouge l0.1ciderexact matchnon predefined labelspredefined labels figure biased effectiveness of labeldroid towards predefined labels .
rq5.
impact of balanced data on labeldroid s effectiveness to further evaluate labeldroid we also studied its performance if it were to be trained on balanced data in predicting non predefined labels.
to that end we performed balance sampling with regard to distinct labels of the training data to downsample dominant labels.
then we trained a new model on the newly sampled training set and evaluated the model on the test set.
figure depicts the results of training labeldroid on balanced data using cider metric.
the orange dashed line corresponds to the effectiveness of the model trained on balanced data.
we should note that in balanced sampling as well as changing the data distribution we are reducing the amount of training data which affects the model s ability to learn.
to monitor this variable we also performed random downsampling on the training data to make the dataset have the same number of training data as in our balanced datasets.
in figure the blue solid line depicts the performance of the model trained on randomly sampled data.
figure shows that having balanced training data does not improve labeldroid s effectiveness.
the general trend in the blue solid line shows that reducing the training data slightly degrades the model s effectiveness.
however increasing the data balanceness drastically drops 113esec fse august athens greece forough mehralian navid salehnamadi and sam malek table comparison of coala and labeldroid effectiveness in generating non predefined labels model exact match bleu bleu bleu meteor rough l cider coala .
.
.
.
.
.
.
labeldroid .
.
.
.
.
.
.
the model s effectiveness.
the same behavior was observed in the model s effectiveness in generating non predefined labels and when we used other evaluation metrics.
however to comply with the page limits those results are available on coala s website .
this concludes that learning from balanced data did not provide any remarkable improvement in the effectiveness of labeldroid in generating non predefined labels.
.
rq6.
effectiveness of coala the ultimate goal of coala is to generate labels for unlabeled icons.
thus our main objective is to evaluate coala s effectiveness in generating non predefined labels and compare it with the prior work .
table summarizes the effectiveness of coala and labeldroid in generating non predefined labels and shows the superiority of coala over labeldroid in all metrics.
figure illustrates two icons in a painting app in our test set for which coala was able to generate correct labels but labeldroid failed.
in this app there are different icons for different painting tools such as a marker in a vertical left toolbar as well as other essential icons in the horizontal top toolbar.
it is clear that without considering the context of these icons generating the correct label may be impossible.
for example the marker icon in the vertical toolbar has been widely used to denote the edit icon.
however by considering the adjacent icons coala was able to detect the icon as a painting tool.
for the undo icon in addition to commonly co occurred icons existing hints in their textual information such as android id enabled the model to generate accurate labels.
more examples of labeldroid s failures for which coala was able to generate correct labels are available on our website .
we also examined common failure scenarios for coala .
as shown in figure coala has generated incorrect labels particularly for icons and .
due to the black box nature of dl models pinpointing the exact reason for these failures is not possible.
however examining the icons gives us an overview of probable culprits.
in the first snapshot the contextual information for minus icon is not figure overall evaluation of labeldroid model trained on re sampled data labeldroidpreviouscoalaundoground truthundo 1labeldroideditcoalamarkerground truthmarker figure examples of inability of the context agnostic model labeldroid in generating correct labels.
informative.
thereby coala was unable to recognize its functionality.
furthermore the existence of the token wheel in the identifier name of its sibling may have confused the model to generate a wrong label.
there are also some failures in generating labels for infrequent icons e.g.
icon .
not having sufficient training data to help the model learn the icon is a probable cause of this failure.
besides these model failures there are certain cases that are not mistakes yet penalize the effectiveness of our model in the manner evaluated here.
case in point consider icon in figure where coala has generated more valid tokens possibly conveying more useful information to a blind user than the ground truth.
additionally the generated labels may be semantically valid alternatives as in icons and in figure .
there are also some cases such as icon in which the ground truth is invalid not the generated label.
these examples indicate that in practice coala is more effective than the nlp metrics suggest since they are simply comparing the generated labels against the ground truth.
these metrics do not account for situations in which coala either generates a semantically equivalent label as the ground truth label or the ground truth itself is wrong.
this observation motivated us to conduct a user study to better evaluate coala .
.
rq7.
informative explanation for users in addition to the automated evaluation of models using metrics described in section .
.
we conducted a user study to understand the quality of automatically generated labels by labeldroid and coala .
since manual investigation of all icons in our test set was not practical we randomly selected a sample from the test data 114data driven accessibility repair revisited on the effectiveness of generating labels for icons in android apps esec fse august athens greece 456labeldroidopennavigate uppausecoalaopen menuhide sidebarpauseground truthopen navigation drawercollapsecongratulations 123labeldroidremove unk refreshcoalago unk menurefresh resultground truthdecrease valuefilter callrefresh figure examples of failures in label generation using coala and labeldroid based on the image classes of icons.
this ensures having a representative and balanced dataset of icons with different images e.g.
plus backward arrow etc.
.
we used our icon image classifier introduced in section .
to get image classes and randomly selected up to10icons from each class resulting in icons from distinct image classes.
next we highlighted the icon under investigation on the screenshot of the app as shown in figure .
for each icon we show four types of labels ground truth which is the content description extracted from the xml layout the generated label by labeldroid the generated label by coala and a random label different from the ground truth selected from all labels in the dataset.
we then used google form to display the icons on the screenshots as well as four different labels to the users and get their responses.
we shared the survey on social media and asked volunteers to rate the quality of the labels from to after reading an instruction the instruction is available at .
to avoid bias we collected and aggregated responses of at least three different users for each icon resulting in answers in total.
prior to analysis we filtered out the unreliable data as follows incomprehensible icons.
the highlighted area on a screenshot may not specify a proper icon due to capturing the screenshot of an app at a transition point during app exploration.
alternatively the user may not be able to determine the functionality of a designated icon from the screenshot.
we remove such images from our analysis by asking users if the icon on the screenshot is valid and understandable.
inconsistent scores.
we expect users to assign the same score to the same labels of an icon otherwise there is inconsistency in scores.
for example the ground truth and coala s candidates for an icon can both be collapse and users should assign the same score to both of them.
we remove all scores of users who have inconsistent scores since such users are not reliable.
insufficient rating.
we have a threshold of three responses for each icon.
thus if applying the prior filtering steps drops the number of responses for an icon below three we remove the icon entirely.
our filtering criteria removed responses resulting in responses for icons.
we then aggregated the users responsestable statistical analysis of scores.
given the significance level of .
the scores of coala s labels are significantly better than the scores of labeldroid s labels.
diff is the average of difference between score lists.
h0 null hypothesis diff p value ground truth coala .
.14e ground truth labeldroid .
.68e coala labeldroid .
.7e ground truth random .
.94e coala random .
.49e labeldroid random .
.43e by calculating the average of all the scores for each icon.
therefore for each type of labels in ground truth coala labeldroid and random there is a list of scores corresponding to each icon which we call score list .
the average of all score lists of ground truth coala labeldroid and random are .
.
.
and .
respectively.
to determine if the differences observed between the means of score lists are statistically significant we performed hypothesis testing.
since the scores failed the shapiro wilk normality test we performed non parametric testing using wilcoxon signed rank test with significance level of .
.
table shows the result of this analysis.
as seen on the upper half of the table the quality of ground truth labels is better than the quality of labels generated by coala and labeldroid since the mean of ground truth s score list is significantly better than the mean of coala s and labeldroid s score list p value equal to .14e and .68e respectively .
similarly it shows that the quality of labels generated by coala is significantly higher than the quality of labels generated by labeldroid p value .7e .
moreover the lower half of the table shows that labels of ground truth coala and labeldroid have higher quality than random labels.
an outcome of this analysis is that although coala significantly improves the state of the art technique in generating natural language labels for icons it is still not as good as the labels provided by actual developers.
this observation suggests that there is still room for improvement and further research in this area.
.
rq8.
performance to answer this research question we evaluated the time required to train a new model and used the resulting model to generate a label for an icon.
we ran the experiments on a ubuntu computing cluster using an nvidia gp102 gpu and 128g memory.
it took minutes on average for coala to train a new model on our dataset.
this time includes evaluating the model at each time step on the validation set for model selection purposes.
however it took only 17milliseconds on average for the trained model to generate the label of an icon given its specification.
this indicates that coala is efficient for use in a variety of settings including automated repair of inaccessible apps and inclusion in screen readers to dynamically resolve unlabeled icons.
threats to validity sampling bias the selection of android apps in this study may introduce bias.
we mitigated this threat by exploring another dataset rico .
we obtained similar results as that reported here.
the results of our study on rico dataset are available online .
moreover both labeldroid and rico datasets consist of more than 115esec fse august athens greece forough mehralian navid salehnamadi and sam malek figure a sample question from the user study.
thousands apps selected from various categories of google play store.
learner bias for the empirical study on dl models we use two architectures coala and labeldroid.
one possible threat to the validity of our results is the choice of the neural network modules and hyper parameters of our models.
for coala our focus was studying the impact of incorporating different sources of information using a well known architecture.
also for training labeldroid we used their original implementation and hyper parameters.
evaluation bias we evaluated labeldroid and coala under the same evaluation metrics used in labeldroid s publication and consistent with natural language processing literature.
we report the effectiveness of models on a test set left out from the whole dataset of labeled icons.
however the generalizability of models on unlabeled icons needs to be studied further.
this signifies the need for creating high quality benchmarks of icons in android apps in future.
we further reduce the evaluation bias by running our experiments times and averaging the results.
related work accessibility issues have been extensively studied for websites and more recently for mobile apps either in specific categories such as e government smart cities and health or in general .
the increased awareness of the prominence of accessibility issues has motivated the development of several accessibility guidelines and accessibility assessment and repair tools.
accessibility guidelines the world wide web consortium w3c is the main organization in determining protocols and standards for websites whose primary initiative is to develop accessibility standards.
they have provided detailed tutorials for constructing inclusive web pages .
for mobile apps google and apple the primary organizations facilitating the app marketplace have published accessibility guidelines for android and ios developers .
despite the existence of these guidelines accordingto developers are still not aware of the issues or find it costly to address them.
android accessibility evaluation and repair tools accessibility evaluation tools leverage static analysis and or dynamic analysis techniques to report various accessibility issues.
lint is a static tool that checks project files and warns the developers about missing labels.
espresso robolectric and accessibility scanner are based on accessibility testing framework of android with the capability to dynamically scan the app for accessibility issues .
puma mate and ibm mobile accessibility checker mac are other dynamic testing frameworks that check accessibility issues at runtime.
despite several tools for accessibility assessment only a few repair tools are available to fix accessibility issues for blind users.
to enable runtime accessibility repair and enhancement for android zhang et al.
proposed interaction proxies to layer on top of the original implementation of app.
in their subsequent work they utilize this platform for social annotation of gui elements for missing labels.
different from their work coala is capable of automatically generating labels for icons by learning from the previously labeled ones.
furthermore liu et al.
utilize a deep learning classifier to semantically annotate icon images based on around categories they defined for the icons.
although their initiative was not fixing accessibility issues screen readers can take advantage of their proposed textual annotations for unlabeled icons.
unlike their work coala generates textual labels not only from icon images but also from their usage context.
in this work we leverage from their annotated icons to fine tune an image classifier which is capable of embedding icon images.
the most relevant work to our study is labeldroid which is a context agnostic model for generating labels for icons.
as discussed heavily throughout the paper labeldroid s insufficient representation of android icons only by their images as well as its biased model negatively affect its effectiveness.
116data driven accessibility repair revisited on the effectiveness of generating labels for icons in android apps esec fse august athens greece conclusion and future work missing labels seriously hinder blind users ability to interact with mobile apps.
in this work we studied the characteristics of icon labels and demonstrated how overlooking the imbalanced nature of labels result in a biased deep learning model.
we also presented coala a context aware label generation approach for icons in android.
our experimental results show that by incorporating additional sources of information coala could outperform the prior work in automatically generating labels for unlabeled icons.
in future we will explore incorporating additional sources of information from source code to enrich icon representation and improve the accuracy of our model by studying different dl models.
we also aim to integrate our model with ide analysis tools such as lint to not only detect missing labels but to also recommend fixes and screen readers to facilitate blind users interactions with apps.
our research artifacts are available to the public .