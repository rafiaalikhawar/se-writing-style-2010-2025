hierarchicalbayesian multi kernellearningforintegrated classification and summarization ofappreviews moayad alshangiti universityof jeddah saudi arabia rochester institute of tech.
usa mshangiti uj.edu.saweishi shi rochester institute of technology rochester usa ws7586 rit.edueduardo lima rochester institute of technology rochester usa eduardo.lima rit.edu xumin liu rochester institute of technology rochester usa xumin.liu rit.eduqiyu rochester institute of technology rochester usa qi.yu rit.edu abstract app stores enable users to share their experiences directly with the developers in the form of app reviews.
recent studies have shownthatthefeedbackreceivedfromusersisavaluablesource of information for requirements extraction which encourages app developerstoleveragethereviewsforappupdateandmaintenance purposes.follow upstudiesproposedautomatedtechniquestohelp developersilterthelargevolumeofdailyandnoisyreviewsand or summarizetheircontent.however allpreviousstudiesapproached the app reviews classiication and summarization as separate tasks whichcomplicatedtheprocessandintroducedunnecessaryoverhead.moreover noneofthoseapproachesexploredthepotentialof utilizingthehierarchicalrelationshipsthatexistbetweenthelabels ofappreviewsforthepurposeofbuildingamoreaccuratemodel.
in this work we propose hierarchical multi kernel relevance vector machines hmk rvm a bayesian multi kernel technique that integrates app review classiication and summarization using a uniiedmodel.moreover itcanprovideinsightsintothelearned patternsandunderlyingdataforeasiermodelinterpretation.we evaluatedourproposedapproachontworeal worlddatasetsand showed that in addition to the gained insights the model produces equal orbetterresults thanthe state ofthe art.
ccs concepts software andits engineering requirementsanalysis keywords bayesian modeling multi kernel learning relevant vector machines app reviews userrequirements acmreference format moayad alshangiti weishi shi eduardo lima xumin liu and qi yu.
.
hierarchical bayesian multi kernel learning for integrated classiication and summarization of app reviews.
in proceedings of the 30th permissionto make digitalor hard copies of allorpart ofthis work for personalor classroom use is granted without fee provided that copies are not made or distributed forproitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation ontheirstpage.copyrights forcomponentsofthisworkownedbyothersthanthe author s mustbehonored.abstractingwithcreditispermitted.tocopyotherwise or republish topostonserversortoredistributetolists requirespriorspeciicpermission and or a fee.
request permissions from permissions acm.org.
esec fse november 14 18 singapore singapore copyright heldby the owner author s .
publicationrightslicensed to acm.
acm isbn ... .
joint european software engineering conference and symposium on the foundations of software engineering esec fse november 14 18 singapore singapore.
acm new york ny usa 12pages.https introduction user opinions on mobile apps are highly valued by app developers due to thecompetitive natureofthemarket where developers attempt to attract the highest possible user base and maintain their satisfactionlevel.
thus developers would like to analyze thefeedback received from users in the form of app reviews to understand theusers requirements preferences andcomplaints .however the large volume of app reviews received on a daily basis has madeamanualanalysisofreviewstootime consuming.assuch it became favorable to have automated approaches that can facilitate quicker andeasier access to the feedbackfoundinapp reviews.
existingefortsonthistaskfallintotwodirections.intheirst one aclassiicationmodelisconstructedtoassignreviewsintoa predeined list of labels considered to be useful for app developers e.g.
bug reports and feature requests as a way to automate the process .
however assigning such generallabelsisinadequatetoextractusefulrequirementsasone can easily ind thousands of reviews that fall under one of those labels and signiicant manual work is still needed to ind the actual requirements.
thus the second direction aims to summarize or group together user reviews with similar topics for easier requirementextraction .visualizationtechniqueshavebeenused tohighlightthemostfrequenttermsusedinthosereviewsandit is leftto thedevelopers to infer therequested feature s .similarly clusteringhasbeenleveragedtogroupreviewsthatcoverthesame set of topics but the developers still have to analyze each cluster to identifythe requirements embeddedin the reviewcontent.
in a moreend to endresearch boththeclassiicationandsummarization tasks were attempted .
we align our work with this direction.
however unlike previous work where the classiicationandsummarizationtaskswerehandledseparately wepropose to merge the twotaskstogetherinasinglelearningprocess.
in this work we present a novel approach to facilitate the extraction of user requirements from app reviews in which both the classiicationand summarizationare achieved simultaneously usingauniiedmodel.inparticular weproposehierarchicalmultikernelrelevantvectormachines hmk rvm inwhichthreemain esec fse november14 singapore singapore moayad alshangiti weishishi eduardo lima xumin liu andqi yu goalsare accomplished.first weexploitthe hierarchicalrelationships between the labels during the learning process to build a more accurate classiier.
second we adopt a bayesian multi kernel learning approach that encapsulates a rich feature space into separate kernels which achieved improved model interpretability and understandingofpredictions.third inadditiontoacompetitive classiication accuracy the proposed approach can identify a small set of most representative reviews as part of its learning process that can efectively summarize the content of all available reviews.
weextensivelyevaluateourapproachontworeal worlddatasets andshowthatitcanproduceequalorbetterclassiicationaccuracy thanthe stateof theart while identifying the most informative reviewstogreatlyfacilitaterequirementsextraction.wesummarize our contributionsas follows weleveragethehierarchicalrelationshipsthat existinthe app reviewlabelsaspartofthelearningprocess whichisanewperspectiveontheclassiicationtaskthatwasnotconsideredbefore.
wefurtherdemonstratethatusingthehierarchicalrelationships between the labels can leadto amore accuratemodel.
we propose a multi kernel bayesian approach that integrates classiication and summarization under a uniied framework.
weshowthatourproposedapproachcanofertwoadditional beneitsbeyondaccuracy i aninsightintothelearnedtaskand the underlying data for better model interpretability and ii an insightintothemostrepresentativereviewsthatbestsummarize the usersfeedback for easier requirements extraction.
weevaluateourproposedapproach hmk rvm ontworealworld datasets and show that it can provide better classiication results while providing signiicantly better summarization resultsthanthe state ofthe art.
theremainderofthispaperisorganizedasfollows.wepresenta summary of related work in section .
we discuss our proposed approachinsection .weevaluateourapproachandpresentour results in section .
we then discuss the signiicance of the results and the potential threats to validity in section 5and section .
finally we conclude the paper insection .
related work inthissection wesummarizeexistingstudiesrelatedtoappreviews classiication and or summarization.
we divide existing works into two major categories i classiication only and ii classiication followed by summarization.
for the former a key limitation is thattheydonotaddressrequirementextraction.hence developers need to manually analyze all informative reviews which is usually around of all reviews that leads to signiicant overhead.
as for the latter they usually rely on a complex pipeline that requires the implementation tuning and maintenance of two diferentmlmodels oneforclassiicationandoneforextraction throughclustering visualization orotherrelevantstrategies.
.
summarizing user reviews thereareseveralexistingworkswithafocusonsummarizingor visualizingtheoveralltopicsfoundinuserreviews.in anapproachtosummarizethemostdiscussedaspectsofaproductand thecorrespondinguseropinions i.e.
positiveornegative ispresented.
in topic modeling is exploited to discover the topicsfoundinthereviewsalongwithrepresentativesentences.in dbscanclusteringisusedtogrouptogethersimilarreviews.in theauthorsproposedaninformationretrievalframeworkthat processes thereviews andputthem ina knowledgedatabase.
the framework returns the most relevantreviews thatdiscussthe provided topics given the developer selected keywords.
in diferent visualization tools techniques are presented.
for example in an html tool was presented that visualizes the content of reviews by showing terms formatted in a word cloud.
in they focused on providing an interface that summarizes and tracks thechangeinreviewsunderspeciictopicsbetweendiferentversionstohighlightabnormalchanges e.g.
version2hassigniicantly higher bugreports thanallotherversions .
.
classifying user reviews as for app review classiication is among the irst attempts to classify app reviews to be either informative ornon informative .
the authors used a bag of words bow representation similar to otherstudies .in theauthorsleveragedn gramsin the bow representation to account for context that requires two or three words e.g.
not laggy .ifwe processthose words separately wewillnotunderstandtheactualintention.in thetenseofthe verbwasincorporatedinto thefeature space.theauthorsargued thatverbsinthepastareusuallyassociatedwithusersreporting bugs whereas verbs in the future are usually correlated with hope andrequestsforadditions i.e.
featurerequests .in theauthors claimed that most reviews follow a speciic linguistic patterns and identifying those patterns can help to improve classiication performance.thus theycreated246linguisticpatternsthatdescribe the general form in which a review would be in to fall under a speciiclabel e.g.
shouldadd .in the bow representation is replaced with a representation generated from parsing sentences as parsing trees and then traversing the treetoconstructtherepresentation.theauthorsclaimedthisapproach can take word semantics into consideration.
in the authorssuggestedtoclassifyonthesentencelevelinsteadofthe reviewleveltoallowformulti labelclassiication.itisalsoworth mentioning that some studies investigated connections beyond the classiicationofappreviews.forexample in theauthorsinvestigatedthepossibilityoflinkinguserfeedbacktothesourcecode components.
diferent from the studies above we argue that there is still room to improve the automation of requirements extraction from app reviews.
therefore we extend this line of work by integratingsummarizationandclassiicationtaskswhileexploring unique characteristics of the problem such as the hierarchical relationshipsbetweenthelabels.by to further improve the automation of such tasks.
.
otherrelatedstudies on app reviews thereisanumberofstudiesthatfocusonanalyzingappstores typesoffeedbackinuserreviews andtheinteraction betweenthesetwo .wediferfromthosestudiesinthatweare not analyzing the feedback itself.instead we focus on app review classiicationandsummarizationtolargelyautomatetheextraction ofuserrequirements.
559bayesianlearning forintegratedclassification andsummarizationof app revs.
esec fse november14 singapore singapore classifying into predefined labelsidentifying most representative subsetseparating informative from non informativedataset app reviewspreprocessing data as many before asked we need support for .vlc add dark theme allow us to ...... review presenting example based summaryclassificationsummarization figure overview of the proposed approach for requirements extractionfromapp reviews methodology overview.
in this section we present the proposed hmk rvm model as seen in figure .
given a set of app reviews the proposed approachirstclassiieseachreviewintothepredeinedlabels.this would help developers separate informative reviews from noninformativeones.additionally thepredeinedlabels e.g.
feature request bugreport etc.
canfurtherguidethedeveloperstoextract therelevantrequirements.alongwiththeclassiicationprocess the modelalsoidentiiesasetofthemostrepresentativereviewsthat summarizetheentirecollection.asaresult developerscanonly focus on these representative reviews for requirements extraction astheyareexpectedtocapturemostofthediscussedrequirements.
fortherestofthissection weirstdiscussthediferencebetween a lat and a hierarchical approach and justify how the latter its betterwithappreviewclassiication.wethenpresentourproposed multi kernelrvm whichleveragesbayesiansparselearningand multiple kernels to integrate classiication andsummarization.
.
hierarchical user reviewclassiication forcommonclassiicationtaskswithasetofbalancedclasses standardmulti classmodelscanbestraightforwardlyapplied.however for problems with highly imbalanced classes e.g.
those that involve rare classes standard techniques may sufer from a poor performance due to lack of attention given to the minority class.
meanwhile ithasbeenshownthatleveragingexistinghierarchical relationshipbetweenclassescanimprovetheperformanceofthe classiier .intraditionallatclassiication thehierarchical relationshipbetweenclassesisignored.forexample abinarylat classiier would attempt to distinguish app reviews with feature requestsfrom all other classes.
this ignores the fact that reviewswithfeature requests and orbug reports are all considered as informative reviews i.e.
theyshareacommonparentclass.taking thisinformationintoconsiderationwhentrainingtheclassiiercan help us build a better classiier that attempts to irst distinguish theinformative reviewsfromthe non informative reviewsand then further classify those informative reviews into their appropriate class.
in this way classesat both levels tendto be more balanced.
root feature requestusabilitybug reportfunctionalnonfunctional security performance energynoninformativeinformative information seekingsentimental spam figure the hierarchical structure inapp review classes weobservethatallthepreviousworkshaveapproachedtheproblemas alatclassiication problem.in a binaryclassiierthat determineswhetheranappreviewis informative ornon informative was used introducing the irst two types of classes.
a follow up work further studied the app reviews and introduced a new set of labels rating bug reports feature requests anduser experience .
a more recent study used feedback from the industry to further break down user experience into reviews reporting securityconcerns energyconcerns andsoon.however noexisting work has attempted toleveragethehierarchicalrelationship betweenthose classes as part of the learning process.
based on the analysis of previous work it is clear that the classes of app reviews can be organized into a fairly complex hierarchy as shown in figure .
it has been reported in multiple studies that the informative subset of app reviews represent at most of the whole corpus.
if we further break down the informative subset into multiple classes we can observe that some classes can be as rare as .
as such using traditional lat classiication will create classiiers dominatedbythenegative i.e.
non informative class leadingtoa poorclassiicationperformance.thislimitationcanbeaddressed when ahierarchical classiication approach isused.
.
multi kernelrelevancevectormachines notations.
letx x1 x2 ..xn denote a set of ntraining instances where xi rd.
we limit the introduction to relevance vector machines rvm to binary classiication problem for simplicity where each data instance xiis assigned with a label ti .later thebinaryclassiicationsolutioncanbedirectly generalized to multi class problem with the one vs the rest formulation.thervmisabayesianmodelinwhichthelabelfollowsthe 560esec fse november14 singapore singapore moayad alshangiti weishishi eduardo lima xumin liu andqi yu bernoullidistribution ti bernoulli p ti yi parenleftbiggm summationdisplay.
m 1 m xi wm parenrightbigg w xi where xi isavectorofmbasisfunctionsthatprojectsthefeature space fromrdtorm xi .
typical basis functions include polynomial gaussian and sigmoidal .
in rvm thebasisfunctionsarespeciiedwithakernelfunction k i x k x xi .wedenote k rn nasthegrammatrixwhose i th row is given by .
the kernel viewof isgiven by p ti yi parenleftbiggn summationdisplay.
n 1wnk x xn parenrightbigg whereware model parameters that follow a gaussian distributionp w n a withabeing a diagonal matrix a diag 1 ... n .
the goal of rvm is to learn the posterior distributionp w t aswellastoestimatethehyper parameter .here we omit the dependency on x whichisimplied.
the posteriordistributioncan be derivedviathe bayes rule lnp w t lnp t w lnp w by applying laplace approximation the posterior distribution also follows a gaussian distribution n w whose mean and covariance are given by w a 1k t y and k bk a respectively where b diag y y .
the hyper parameter canbe derived using type ii maximization.todothat we irstcompute the modelevidence p t p t w p w dw p t w p w dw where we used taylor expansion on the integrant at w to remove the integral.
then the optimal value of is obtained by solving p t i i ii w i training of rvm is achieved through an iterative process of updatingw and iuntilconvergence.inthepredictionphase thepredictive distribution of a test data point x is given by p t x w bernoulli w x .
the prior distribution adopted by rvm is commonly referred as auto relevance detection ard .
it makes themodelprefersimplerexplanationsthancomplexexplanations so that over itting can be automatically addressed.
speciically duringthetrainingprocess acertainnumberof scomponents will be driven to ininity making their corresponding training data instances independent fromtheprediction and theremainingfew importanttraining data instancesare called relevancevectors .
wemakeageneralextensiontorvmtohandletheinputwith multiple modalities e.g.
diferent representations .
suppose the inputxis now given in three diferent representations xi xii andxiii.
then we construct a overall gram matrix as the linear combination ofthe gram matrixfor eachrepresentation.
k 1k xi xi 2k xii xii 3k xiii xiii replacing the gram matrix in standard rvm with we have the rvm for multi modality data input.
the hyper parameters 1 2 3 can be solved by type ii maximization similartosolving .however theobjectivefunctionisnotconvexwith respect to and may cause the optimization either to trap into the localoptimaorcommittoslowconvergence.toaddressthis we adopt a gradient free method simplex to directly search the optimal inthe hyper parameter space.
.
why extend rvm?
afundamentalreasonforusingandextendingrvmforourproblem is its ability to identify the most representative points that can summarizetheunderlyingdataset.thisalignswellwiththetaskof inding the best subset of reviews that can be used for requirement extraction.
during model training it ensures both the sparsityand thequalityof the selected data points.
the former i.e.
sparsity allows us to identify a small subset of reviews to summarize the entiredatasetinacompactway.asaresult thedevelopercansafely ignore a large portion of the reviews to signiicantly reduce the manual analysis efort when performing requirement extraction.
thelatter i.e.
quality furtherhelpstoidentifythemostinformative reviewsthatcanensuretheaccuracyandqualityoftheextracted requirements.
at the end of this training process a set of points are selected which the model uses for classiication.
we propose to use those points forsummarization aswell.
consequently we wouldachieve both aspectsusing asinglelearningmodel.
.
constructing thekernels the number of kernels used with the approach and their types can be selected based on the available data and given task.
for the purpose of app reviews classiication we constructed four kernels to buildacomprehensive kernel space.
the irst isa metakernel whichcaptures simple metainformation about the review e.g.
the rating and the number of words.
the second is a kernel that utilizes the textual content of the reviewbycapturingtheimportantrecurringterms e.g.
add crash etc.to construct this kernel we applied a standard natural languageprocessingmethods suchasstop wordremovalandword stemming on the textual content of the title and body of an app review to generate such a representation using the term frequencyinverse document frequency tf idf approach .
however one potential disadvantage withthis kernel isthatthe textualnature of app reviews isquite noisy whichcan leadto a largeand sparse dictionary.forthatpurpose weconstructedathirdakernelthat wouldprovideuswithalesssparserepresentationbyattemptingto capture the broad topics within the reviews in contrast to relying on the exact terms.
to construct this kernel we used the topic modeling technique latent dirichlet allocation lda .
lda been widely used in many previous studies to summarize the topicsof a largedocument corpus.
the intuition behind lda is that it leverages the textual content of a set of documents to group together the frequently co occurring words into an approximation ofareal world concept i.e.
atopic.
eventhoughthosekernelswouldprovideacomprehensiverepresentation theylackoneimportantaspect andthatisthesemantics of the used words.
in they foundthat classifying the reviews comingfromtheiosappstorewassigniicantlymoreaccuratethan those coming from the android store.
they attribute this diferencetothelanguageandvocabularydiferencefromthosetwoapp 561bayesianlearning forintegratedclassification andsummarizationof app revs.
esec fse november14 singapore singapore stores.theyclaimthattheiosstorereviewswerelessnoisy e.g.
havinglesstypos andusedamuchmorehomogeneousvocabulary ofterms.
this observationhighlightstheefectofthenoisefound inuserreviewsontheclassiicationtaskandtheimpactithason thelearningprocess.in thisobservationwasstudiedfurther as the authors also highlighted and described the observation that app reviews sufer from a high percentage of typos acronyms and abbreviations.
they performed a preliminary analysis of reviews and compared their textual content against an english dictionaryof150 000commonwords andfoundthatalargeportion of the used words in app reviews do not match any words in the english dictionary mainly due to abbreviations and typos.having such high noise and unique language e.g.
wait is written as w8 createsanissuefortraditionaldataminingtechniquesthatrelies on stemming and dictionary creation as both waitandw8will still exist as two unique diferent words.
they hypothesized that this observation might be due to the fact that reviews are written using mobile devices which lack a physical keyboard hence it is more likely to have typos acronyms and abbreviations.
to overcome thisissue theauthorsin manuallycreatedacustomdictionary that attempts to replace the most frequent out of dictionary words with their dictionary equivalent e.g.
replacing exelentwithexcellent .
moreover in a similar observation was made and the authorsmanuallyconstructedacollectionof60diferenttyposand contractions andreplacedthemusing regularexpressions.
wehaveobservedasimilarpatternofnoisewithappreviews wherealargeportionofwordsinthepost processingandstemming dictionary seem to represent the same word but written diferently duetomisspelledwords e.g.
fantastic vsfantastick oralternatively spelledwordseitherforabbreviationspurposes e.g.
thanks vsthx or to represent a stronger emotion e.g.
loved vsloooved .
in table we showafewadditionalexamples.
table examples ofmis oralternativelyspelled words word observed noise amazing amaazing amaaazing amassing amazeng thanks thx thanx tx tnx 10x thnx ty awesome awasome awesomeeee awsome owesome asssome love lov luv lovve looove loveee because bc b c cuz coz bcz caus while merging misspelled or alternatively spelled words would improvethetextualrepresentationandthemodel sperformance wearguethatusingamanuallycreatedcustomdictionarywould betoodiicultto createandmaintainoverthetime.to overcome this issue we constructeda fourthkernel that leverageswordembedding techniques to create a representation that captures the semanticsofwords.forexample theword2vec theglove orthe fasttext modelarealltechniquesthattakeinto consideration word semantics and meanings.
these techniques are built on thenotionthatwordswithsimilarsemanticmeaningswillhavethe samesetofwordsaroundthem.forexample thewords loveandlikeareusedinsimilarmanners i.e.
ilovethatapp andilikethatapp .
asaresult theywouldbecloselyplacedintheembeddingspace as they share a similar semantic meaning.
to construct this kernel space weneedtoeitheruseapre trainedmodelfromadiferent domain e.g.
tweets ortrainourownproblem speciicmodelto generatethewordembeddingsfortheappreviews.accordingto whichstudiedthisspeciicconcernamongotherchoices withwordembeddingmodels itisrecommendedtouseamodel that is speciic to your domain as it can better capture the relevant vocabulary and their unique usage.
we believe this is especially trueforapp reviewsandanimportantfactortoovercomethe issue of misspelled and alternatively spelled words.
to the best of our knowledge there sno publicly availableword embedding model that was trained on app reviews.
for that reason we decided to create such a model and make it publicly available as part of our replicationpackage.
we trainedafasttext model on1 app reviews collected from and .
we chose fasttext because it is most efective in settings where out of dictionary words arecommon likeours.formoredetailsonthetrainingprocessand the selectedparameters kindlyrefer to the replication package1.
finally itisworthnotingthatourapproachhasthelexibilityto useanynumberofkernels.webelievethesuggestedfourkernels representappreviewsquitewellandcancapturebothhigh level concepts e.g.
lda and low level characteristics e.g.
meta .
as a result thefourkernelsofersuicientexpressivepowertoconstruct a comprehensive feature space that can help the machine learning modelachieve agoodlevel of robustnessandgeneralization.
evaluation and results inthissection weplantoevaluatetheproposedmodel speciically byinvestigating the following research questions rq1 dowe gainany app reviews predictionaccuracy fromhierarchical classiication versuslatclassiication?
rq2 howaccurateisthe classiication oftheproposedhmk rvm approach comparedto the state of the art?
rq3 howaccurateisthe summarization oftheproposedhmkrvm approach comparedto the state of the art?
rq4 beyond accuracy what insights can we gain from using the proposedhierarchical multi kernelrvm approach?
the source code and data used in the experiment section are available onlinefor easyreplication validation purposes1.
table statistics ofthe used datasets maalej panichella feature request bug report userexperience total info total non info totalreviews 562esec fse november14 singapore singapore moayad alshangiti weishishi eduardo lima xumin liu andqi yu .
datasets to address our questions we will report results on two real world datasetsthatwereprovidedbypreviousresearch.theirstisthe maalejdataset wherereviewswererandomlyselectedfrom bothappleandgoogleplaystores.theauthorscrawledoveramillion app reviews and followed a sampling strategy with the goal of picking a stratiied and a representative sample e.g.
equal number offreeandpaidapps equalnumber ofiosandandroidapp etc.
.
the second is the panichella dataset where the authors favoredanappspeciicsamplingapproach.thedatasetcontains reviews of apps coming from google play microsoft and apple appstores.unfortunately thegroundtruthwasnotprovidedfor thisdatasetsoweaskedtwoteamsofgraduatestudentstolabelthe dataset separately according to a labelling guide that can be found withthereplicationpackage1.theguidefollowscloselytheguidance of the original paper.
once the teams completed the labelling task we compared thelabels andaddressed all disagreements.we foundagoodinter rateragreement kappa .
betweentheannotators.
the statisticsofboth datasets can be foundintable .
.
experiment andresults rq1 dowegain any app reviewsprediction accuracy from hierarchical classiication versus lat classiication?
experimental setup to evaluate the model s accuracy gained from leveraging the hierarchical relationship embedded within the labels we will use a simple feature space consisting of a bag ofwords representation using tf idf .
for this evaluation we willnotattempttoaddanyadditionalfeaturessuchasmeta data features e.g.
rating reviewlength etc.
aswewanttofocusonthe added beneit of hierarchical versus lat app reviews classiication.
moreover to make sure the results are not due to a speciic classiierortoaspeciicdataset wewillevaluateonboththe maalej andpanichella datasets andonfourdiferentclassiiers logistic regression l1regularization randomforest trees support vector machines linear kernel relevant vector machines linear kernel and naive bayes multinomial .
as we are limited to the three mutual labels bug report feature request and user experience providedwiththosedatasets wewillbuildtheexperiment around them.
finally to make sure both the lat and hierarchical classiiers were exposed to the same set of reviews during training andtesting we usedasingletrain test split of80 20for both.
for lat classiication as shown in figure a we are training three one vs the rest binary classiiers one classiier per label e.g.
bugreportornot .weprefertousebinaryclassiiersinsteadofa multi classclassiierasthissetupallowsformulti labelclassiication.thismeansanappreviewcanbegivenasingleormultiple labels.
for example an app review with multiple labels from the panichella dataset is this is a great app for keeping track of weight ...thereshouldbeawaytoturnofdailyreminder...alsoinoticeit keeps changing the year i was born... .
however using this setup it isalsopossibleforanappreviewnottobeassignedanyofthethree classes.
for that purpose in figure a we show a non informative node that captures allsuch cases.forhierarchicalclassiication asshowninfigure b weuse a top down approach for training and classiication purpose.
at the irst level we are using a binary classiier that classiies all app reviews as either informative ornon informative and on the second level we use three one vs the rest binary classiiers that attempt to further classify what passes as informative under one ornoneofthethreeclasses bugreport featurerequest anduser experience.
thus in hierarchical classiication we are training one more classiier than lat classiication.
this may seem as added complexity however thetopdownapproachactuallyhasabetter overallcomputationalcostbecauseonlythe informative classiieris trainedonallthetrainingexamples theremainingthreeclassiiers train only on the informative subset.
for example if we had a training data set of 10k app reviews 3k of those are informative thentheirstlevelclassiierwilltrainonall10kappreviews butthe secondlevelwillonlyhavetotrainonthe3kappreviews.whereas inlatclassiication eachoftheclassiierswouldneedtobetrained onthe complete 10kdataset.
root feature requestuser experiencebug report a flat classiicationroot feature requestuser experiencebug reportinformative b hierarchicalclassiication figure3 evaluationoflatandhierarchicalappreviewclassiication where eachnodeis apotentiallabel experimentresults wereporttheaverageauccomputedfrom precision and recall aucpr macro f1 m f1 and macro recall mr intable .wecanmakeacoupleofobservations.first naive bayes seems to outperform the other classiiers when a simple bag of words model is used which was also observed in a previous study because a term count representation aligns perfectly withhownaivebayesworks.second overall formulatingtheproblemusinghierarchicalclassiicationincreasesthemodel saccuracy especiallywithrecall i.e.
increasingthechancethatwedonotmiss any informative app reviews .
on the maalej dataset we observed onaveragea8.
better aucpr .
betterf1measure and108 betterrecall.similarlyonthepanichelladatasetweobserved13 betteraucpr betterf1 and33 betterrecall.tobetterunderstand theresults weanalyzed theperformanceof randomforest on the panichella dataset where the recall had an improvement of61 .it simportanttomentionthatinappreviewclassiication the ability to label all existing informative reviews correctly i.e.
recall ismoreimportantthanmis classifyingafew non informative reviews as informative i.e.
precision because all reviews labelled asnon informative are usually disregarded i.e.
feedback would be lost with low recall .
thus this signiicant improvement on the recallwhen using ahierarchical approach is aperfect matchwith the app reviewclassiication problem.
563bayesianlearning forintegratedclassification andsummarizationof app revs.
esec fse november14 singapore singapore table classiication results oflatandhierarchical app review classiiers classiiermaalejdataset panichella dataset flat hierarchical flat hierarchical aucprmf1mraucprmf1mraucprmf1mraucprmf1mr logistic reg.
.
.
.
.
.
.
.
.
.
.
.
.
random forest0.
.
.
.
.
.
.
.
.
.
.
.
svm .
.
.
.
.
.
.
.
.
.
.
.
naive bayes0.
.
.
.
.
.
.
.
.
.
.
.
rvm .
.
.
.
.
.
.
.
.
.
.
.
root feature requestbug reportuser experienceclassifier 1given reviews with bug reports classified as bug reports discarded as non informative a flat classiicationroot feature requestbug reportuser experienceclassifier 1given reviews with bug reports classified as informative discarded as non informativeinformative classifier classified as bug reports remained labeled as informative w o a subclass b hierarchicalclassiication figure given 52app reviewswith bugreports how were they classiied inlatvs hierarchical?
wereportintable 4therecallofeachclassiier.inlatclassiication we can observe that the classiier s abilityto correctly classify all thebug report anduser experience instances is quite poor.
as we believe the bugreport is a more criticalcategory we further investigated the instances and how they were labelled in both classiiers as shown in figure .
in our experiment the testing sample had app reviews with bug reports.
in the case of lat classiication we clearly observed that the classiier missed of the bug reports .however thehierarchicalclassiiermislabelled8bugreports out of the as non informative and mislabeled bug reports outofthe informative reviews as othertype of informative reviews.
overall theclassiiermislabelled42 ofthebugreports amuch better recall than the lat classiier.
upon further checking we can observethattheirstlevelperformanceinthehierarchicalclassiier is excellent as we were able to capture of the bug reports as informativereviews.however thesecondlevelperformancewas less ideal i.e.
missing out of but we can argue that it is still betterthan the lat classiier as we were still able to label thoseapp reviewsas informative i.e.
theywerenotcompletelymissed but were incorrectlyclassiiedas othertypes of informative reviews.
564esec fse november14 singapore singapore moayad alshangiti weishishi eduardo lima xumin liu andqi yu table analyzing random forest the lat vs. the hierarchicalclassiiers on thepanichella dataset type info.feature requestbug reportuser experience recallmeasure flat .
.
.
.
hierarchical .
.
.
.
we credit the better performance of the hierarchical classiier to two main factors.
first it is not afected as much by the class imbalance as the lat classiier.
in the case of lat classiication the frequency of each class is dominated by the negative class e.g.
the bug report classiier had instances of the negative class so it needstodistinguishfromthe non informative andother informativeclasses which is quite challenging.
however in hierarchical classiication the irst level uses the combined knowledge from all threeclassestoirstilterout informative fromnon informative app reviews whichisaneasiertask i.e.
duetothediferentnatureof non informative reviewsfrom informative alongwithamuchhigher positiveclassfrequency.second weobservedthatthe bugreport classiier can distinguish itself better from other feature request anduser experience reviews i.e.
informative reviews when noninformative reviews are removed which is what the hierarchical top downclassiication isinherently rq2 howaccurate istheclassiication ofthe proposedhmk rvmapproach compared to the stateoftheart?
baselines toevaluateourproposedapproach wecomparedagainst ive baselines and using two diferent datasets.
the proposed approach and all the baselines presented are trained using the textual contentofthe reviewsandthe meta data information.
first the ar miner baseline used a naive bayes model where the hidden topics of the reviews were discovered using latentdirichletallocation lda andusedalongsidetherating of the app review to construct the feature space.
to implement theirapproach weselectedthenumberoftopics kforldausing cross validation.
speciically we chose85 topics for both datasets.
second the maalej baseline also adopted a naive bayes modelduetoitspreviouslyreportedhighperformancewithtext classiication.
however used a bag of words approach and extracted the ratio of past present and future tenses in the review to represent the textual content claiming that reviews with bug reportstendtousepasttenses whereasreviewswithfeaturerequests tendtousefuturetenses.additionally theyusedthereview srating length andsentiment score as part oftheirfeatures.
third the ardoc baselineleveragedadecisiontree j48 model.theauthorsmanuallyconstructed246linguisticpatterns each mapping to a speciic app review label e.g.
reviews with pattern should add are mapped to feature requests.moreover theygeneratedatf idfrepresentationfromthe textualcontentofthereviewsandusedthereview ssentimentscore intheirfeaturespace.duetothediicultiesinrecreatingthe246linguisticpatterns we didnotimplement thisapproach ourselves but rather used the tool provided by the authors to generate labels.
as such we do not have the auc and roc scores for this baseline sincecomputingthemrequiresaccesstothemodelitselftoevaluate performance underdiferentdecision thresholds.
finally we include the proposed approach with two variant baselines.
the rvmbaseline where the relevance vector machines rvm with fast marginal likelihood maximization is usedasabaselineusingourcompletefeaturespace featuresare concatenated into a single large feature space and presented as an alternative to using the multi kernel learning approach.
the mk rvm baselinewhere the multi kernelapproach isaddedto the previous baseline and the problem is approached using a lat classiication approach as an alternative to using a hierarchical approach.finally hmk rvm whichisourproposedmodel the hierarchical multi kernel rvm which combines the power of rvm with multi kernel learning and follows a hierarchical classiication approach that leveragesthe existing hierarchical structure.
experiment setup we formulated the learning task as a binary one vs the rest problem by following earlier work.
we chose this formulation due to two reasons the irst is that it supports multi labelclassiication e.g.
areviewcancontainbothabugreport and a feature request and the second is due to its higher reported performance than multi class classiication.
for example reportedthatusingmultiplebinaryclassiiersforappreview classiication performed signiicantly better than a single multiclass classiierinall cases.tomeasure theaccuracyofthemodels weusedatrain testsplitof80 .tomeasuretherobustness i.e.
performanceondiferentdatasets weconductedtheexperiment onbothmaalejandpanichella datasets.
experiment results in table5 we show a summary of the results.
we can observe that the traditional rvm that uses our proposedfeaturespaceperformsonparwiththeotherbaselines introducedinpriorwork.thishighlightstheusefulnessofleveragingtheinformationfrommultipleaspectsandshowsthatrvm is on equal footing to other models such as naive bayes and decision trees in terms of accuracy.
moreover it shows that using alargerfeaturespaceonitsownisnotenoughtogainacompetitive advantage as the diference between it and other baselines isnotthatsigniicant.onceweutilizethemulti kernelapproach we can observe a improvement in the overall model s performance aucpr over traditional rvm on both datasets and a improvement with the proposed hierarchical version of themulti kernelrvmclassiier.wecanalsoobservethatmostof this improvement is due to a boost in the recall increase on maalejand40 onpanichella .aswe discussedearlier thisisthe main advantage of leveraging the existing hierarchical relationship between labels.
breaking the prediction task into multiple levels wherebyintheirst we predict informativevs.non informative and use the collective knowledge between the diferent children of eachbranchcansigniicantlyboostthemodel srecall i.e.
increases our chance ofidentifying informative reviewscorrectly.
overall we can observe that the proposed hierarchical multikernel rvm is outperforming all the baselines as it can ofer a boost through the combination of two aspects.
first the multikernel learning technique allows it to choose the best kernel s for the current learning task through the assigned weights e.g.
565bayesianlearning forintegratedclassification andsummarizationof app revs.
esec fse november14 singapore singapore table summary oftheresults comparing proposed approachto the start ofthe art approachmaalejdataset panichella dataset aucpraucrocmf1mf1mpmraucpraucrocmf1mf1mpmr ar miner .
.
.
.
.
.
.
.
.
.
.
.
maalej .
.
.
.
.
.
.
.
.
.
.
.
ardoc .
.
.
.
.
.
.
.
rvm .
.
.
.
.
.
.
.
.
.
.
.
mk rvm .
.
.
.
.
.
.
.
.
.
.
.
hmk rvm .
.
.
.
.
.
.
.
.
.
.
.
meta informationmightbemoreusefultobugreportsthanfeature requests leadingtoahigherweightforthecorrespondingkernel thanotherkernels or lda topicsmay introducemore noise than true signals for bug reports hence setting the lda kernel s weight to very small can improve the model s accuracy .
second the hierarchical approach ofers a boost in the model s recall through leveraging existing hierarchical relationships between the diferentlabels.moreover throughthelearningprocess theproposed approach has identiied on average relevant vectors variesby classiier dataset .thoserelevantvectorsshouldbethemostrepresentative reviews i.e.
reviews that best summarize the content which provides us with two additional advantages beyond accuracy.
the irst is a computational advantage as we can limit future training and prediction to those relevant vectors since other points arealreadyrepresentedbythem whichsigniicantlycutsdownthe original dataset size.
the second is a summarization advantage as those reviews should highlight the reviews that best summarize the dataset whichdevelopers can use for requirement extraction.
rq3 howaccurate isthesummarizationofthe proposedhmk rvmapproach compared to the stateoftheart?
building on the classiication step which helped us identify the set of informative reviews and ilter out the non informative ones the next goal is to summarize the feedback in the set of informative reviews for thepurpose ofrequirement extraction.
we proposeto leverage the set of relevant vectors which hmk rvm learns as part of the classiication task as a way to potentially summarize the users feedback.as a result we achieve both the classiication and summarization tasks simultaneously using the same model.
in this section we will evaluate the set of reviews identiied as the mostinformativebyhmk rvmforrequirementextractionagainst multiple baselines that were used in the literature for this purpose orfor summarizationingeneral.
baselines we willuse thesetof relevantvectors identiiedby thehmk rvm modelpresentedinrq2asourproposedapproach andcompare itto the following baselines first wewillcompareagainstapproachesthatwereproposed by prior work.
we will build upon the classiication experiment tofurther summarize the content of the reviews basedonthe recommendationoftheoriginalauthors.for ar miner andardoc latent dirichlet allocation lda will be used to group the setofreviewspredictedas informative andthenthereviewwith the highest probability for each topic will be picked as the most informativeone.thesizeoftheinallistofselectedreviewswill be equal to the number of topics.
as for maalej where the original authors did not propose any summarization approach we will apply k meansto the set of reviews classiied as informative to cluster them andthen usethe reviewat the centerof eachcluster as the most informative review.
we will also compare against star clustering whichcreatesagraphwhereeachnodeisareview and an edge is created if the cosine similarity between two reviews is larger than a given alpha and then use the set of nodes with the highest degree to be the set of center stars i.e.
most informative reviewsfor requirement extraction.
second for the purpose of completeness we will use random samplingasa baselinewherewerandomly picked npointsasthe set of most informative reviews.
additionally we will compare against widely used summarization techniques such as k means andlatentdirichletallocation lda inthesamewaydescribed earlierbut appliedto the complete dataset.
tokeepthiscomparisonfair wemadetheselectionofthehyperparameters e.g.
numberoftopicsforlda inamannerthatprovided us with a inal set of informative reviews that is equal in size for allbaselines.
experimentalsetup toevaluatethisaspectoftheproposed hmk rvm approach we asked two graduate ph.d. students in computing toreadthereviewsinthepanichelladatasetandgenerate a list of the requirements discussed and then label each review with a requirement id s a level of informativeness ranging fromonetothree where oneisareviewwithnorequirements two isareviewthatisrelevanttoarequirementbutwithoutenoughinformationtoextractit e.g.
duetomissinginfo poorreadability or notbeingexplicitenough i.e.
requiringthedevelopertoguess infer the meaning and threeis a review with an explicit requirement and enough information to extract it.
we show examples of this labelingintable .thetwostudentsannotatedthedatasetseparately and then compared their labels.
disagreements were resolved in 566esec fse november14 singapore singapore moayad alshangiti weishishi eduardo lima xumin liu andqi yu table6 examplesofreal worldreviewsfromthepanichella datasetandhowtheywerelabeledforrq3.requirementid refersto users request foradditional loginoptions.
review req.
id informative level blinq okay na low login facebook?
nope.app medium immediately deleted fbandwithoutfbcan blinq high not work??
there mustalso be an alternative logonoptions!
ratio of most informative reviews lvl ratio of most informative reviews lvl ratio of most informative reviews lvl ratio of most informative reviews lvl ratio of most informative reviews lvl ratio of most informative reviews lvl ratio of most informative reviews lvl ratio of most informative reviews lvl ratio of most informative reviews lvl ratio of most informative reviews lvl ratio of most informative reviews lvl ratio of most informative reviews lvl ratio of most informative reviews lvl ratio of most informative reviews lvl ratio of most informative reviews lvl ratio of most informative reviews lvl ratio of most informative reviews lvl ratio of most informative reviews lvl ratio of most informative reviews lvl ratio of most informative reviews lvl ratio of most informative reviews lvl ratio of least informative reviews lvl ratio of least informative reviews lvl ratio of least informative reviews lvl ratio of least informative reviews lvl ratio of least informative reviews lvl ratio of least informative reviews lvl ratio of least informative reviews lvl ratio of least informative reviews lvl ratio of least informative reviews lvl ratio of least informative reviews lvl ratio of least informative reviews lvl ratio of least informative reviews lvl ratio of least informative reviews lvl ratio of least informative reviews lvl ratio of least informative reviews lvl ratio of least informative reviews lvl ratio of least informative reviews lvl ratio of least informative reviews lvl ratio of least informative reviews lvl ratio of least informative reviews lvl ratio of least informative reviews lvl ar miner hmk rvm k meanslda maalej w kmeans random samplingstar clusteringcoveragelevel low level medium level high informativeness figure the results of the summarization evaluation.
the y axis represents the coverage i.e.
percentage of requirementsthatwerecapturedbytheselectedsetofinformative reviews.
the higher the score the better.
the color provides a visual representation of how informative are the reviews selectedbyeachapproach.themoregreenandthelessred thebetter theapproach.
group discussions.
more details on this process can be found in the replication package1.
we found a substantial inter rater agreement kappa .
between the annotators.
it is important to know that the reviews are sharing the same context same app same version to assume that they are discussing the same requirement which is why we only used the panichella dataset for this evaluation as it provides the app information in addition to the review whereas this information ismissinginthe maalej dataset.
we use two metrics to evaluate each approach.
first how informative aretheselectedreviewsforrequirementextraction i.e.
were the selected reviews mostly of level two and three of informativeness medium and high or were they mostly level one noise .
second as part of the labeling process we compiled a list of requirementsthatarediscussedinthereviews andusingthisground truth we want to evaluate the coverageof each approach i.e.
how many of the existing discussed requirements were mentioned in theselectedset.however wearguethatnotallrequirementsareequal.themorementioned discussedarequirementis themore valuable andviceversa.assuch wemeasuredcoverageonlyfor requirements mentioned in three or more reviews.
as most machine learning models require a certain level of statistical presence to learn patterns two maynot be suicient to show the statistical signiicance.
meanwhile setting a higher threshold e.g.
four or more maymiss somemeaningfulrequirements.
experimentalresults we show the evaluation results in figure5.wecanobservethattheproposedhmk rvmsigniicantly outperformsallthebaselines.first lookingat coveragewherethe higher the score the better the model at capturing all the discussed requirements wecanseethatitis11 betterthanlda thesecond bestmodel androughly50 betterthanallotherbaselines.this means it is able to select at least one review for each discussed requirement with a much higher success rate than the state of theart.second lookingatinformativeness whichisakeyaspect of requirement extraction we can see that the reviews selected byhmk rvmhavethehighestlevelofinformativeness andthe least level ofnoise.
hmk rvm had more informative reviews thanthesecond bestbaseline.additionally itpicked50 lessnoisy reviews than the second best baseline.
this means that it is far superior at picking the most informative reviews and avoiding the least informative noisy reviews for requirements extraction than the state ofthe art.
table analyzing the model s insight what and the learned weights tell usaboutthe underlying data?
maalej dataset we x meta x tfidf x lda x informative .
.
.
.
feature request .
.
.
.
bug report .
.
.
.
user experience .
.
.
.
rq4 beyondaccuracy whatinsightscanwegain from usingtheproposedhmk rvmapproach?
experimentalsetup to addressthisquestion weevaluatedthe weightsassignedto eachof the kernels.
experimental results for the irst aspect we report the assignedweightsperkernel intable 7forthemaleejdataset.wecan observe that the learned weights per kernel vary between roughly onaverage whichindicatesadiferentprioritybasedonthe learnedtask.forexample forthe informative classiier kernelswith higher representation i.e.
meta and lda were assigned higher weights whichcan be due to the fact that the majority of reviews at the irst level of classiication are non informative reviews mostlyratingreviews i.e.
astrongpositiveornegativeratingwith a short sentimental text .
as such they can be easily identiied with a more broad view of the reviews.
also for the feature request andbug report classiiers we can observe a higher assigned weight to the tf idf kernel which may be due to the fact that such reviewscanbeidentiiedthroughafewfrequentlyusedwordsthat arecapturedbytf idf e.g.
add feature bug crash etc.
.finally theuser experience classiier shows a signiicant weight diference 567bayesianlearning forintegratedclassification andsummarizationof app revs.
esec fse november14 singapore singapore between kernels.
the lda kernel and word embedding kernel are highly utilized whereas the tf idf kernel is essentially ignored.
webelievethatthisisduetotherichandlengthynatureofsuch reviews reviewswithuserexperienceareverydescriptive .having thatnaturein mindwiththefact thatappreviewsareusually full oftyposandalternativelyspelledwordswouldputarepresentation thatreliesonexacttermssuchastf idfatadisadvantage whereas a semantic capturing representation such as word embedding or a topic capturing representation such as lda is at a clear advantage.as such wecanconclude thatthe userexperience classiier s predictionsrelyheavilyontheldaandwordembeddingrepresentation i.e.
inorderto maintain a healthy user experience classiier weneedtomaintainthoserepresentations.suchinsightintothe classiier slearningpatterns isvaluable tothe understanding and interpretationofthe classiier s behavior.
discussion how is the proposed approach diferent from the current state of the art sota ?
the existing sota approaches use a pipeline of two dedicated models one for classiication and anotherforsummarization.thisallowsthemtoine tuneeachmodel for its speciic task.
however this also complicates the process ofimplementationandmaintainability.incontrast ourproposed approach is designed to achieve both the classiication and summarization tasks using a single model.
although we do not have the option to ine tune the results for each task we still demonstrated that we were able to provide equal or better results on one task i.e.
classiication andoutperformallbaselinesontheother i.e.
summarization which shows that we did not compromise on the accuracy when we attempted to merge the two tasks.
in fact the summarization aspect is the most important aspect for requirements extraction in which our approach outperforms all baselinesinbyalarge margin.
howdoestheproposedapproachimprovetheextractionof requirements?howisthistested ?thekeyimprovementliesin theamountofefortthattheproposedapproachcanreduceinterms ofthehumanefortforrequirementsextraction.tomeasurethis aspect we introduced two metrics coverage and informative level.
fortheformer ahighcoverageimpliesthatanalyzingthemodelidentiiedsubsetofreviewswouldallowthedevelopertoextract mostrequirements.thesavingofefortisachievedastherestof the reviews can be safely ignored.
as for the latter reviews with ahigherlevelofinformativenesscanhelpdevelopersmoreeasily and accurately extract the requirements without cross checking other reviews.
in our experiment the set of informative reviews constitutesaround35 oftheentiredatasetwhereastheset ofrepresentativereviewsthathmk rvmidentiiedincludesonly around of the dataset.
this implies that by using hmk rvm we can efectively reduce the human efort needed to extract the requirementsfrommanuallyanalyzing35 ofthedatasetto only .
inaddition the reviewsidentiiedbyhmk rvmareofa high level of informativeness which can improve the easiness and accuracyofrequirement extractionfrom thesereviews.
what are the limitations of the approach?
one limitation is that rvm tends to pick from highly representative regions as aresultofmaximizingthemodelevidenceineq.
.whileitishighly desirable to choose a small number of reviews to represent the whole set it may also miss some requirements from less representative regions.
our results show that hmk rvm achieved a coveragebyjustusingasmallnumberofrepresentativereviews which clearly demonstrates its efectiveness.
an interesting future direction is to augment rvm s learning process to include a few reviewsfromlessrepresentativeregionstoenhancethecoverage further.anotherlimitationisthataswegodownthehierarchy we areexpectedtohavelessdatawhichmayafecttheperformance.
thus anotherinterestingdirection isto studytheefect ofadding more hierarchical levels onthe performance of the model.
threats to validity intermsof internal validity themainthreatisthatweusedtwo datasetsinourexperimentcomingfrompreviouswork.wedidnot participate in the collection or preparation of those datasets.
thus any issues with the reviews content or the labels are a potential riskfactor.the maalejdataset providedboththereviewsandthe labels whereas the panichelladataset providedonlythereviews.
as such we had to manually label the reviews ourselves for the panichella dataset .
in both cases whether the ground truth was handedtous orwhetherwemanuallylabeledthereviews there istheriskofhumancodersmistakes.toreducethisthreattoour labels we created a coding guide that precisely deines the app reviewtypeswithanexampleofeach andweemployedtwoteams each with two members to label the dataset separately.
once both teamscompletedtheir task we satdown and extensivelydiscussed anydisagreements.intermsof external validity webelieveour results should have high generalizability for app reviews as we evaluateditontwodiferentreal worlddatasetsthatwerecarefully constructed i.e.
sampled randomly from diferent apps and app stores.
as such they shouldprovide a reasonable approximation of the generalpopulation.
conclusion in this paper we proposedhierarchical multi kernel rvm hmkrvm where we extended and customized the use of rvm in a novel way to facilitate requirement extraction from app reviews by ofering an integrated process that is easier to implement interpret andmaintain.theproposedapproachclassiies reviewsina hierarchical fashion leading to a more accurate model.
in addition we showed that the assigned weights to each kernel can provide an insight into what the classiier has learned from the underlying data.
moreover we leveraged rvm s inner working mechanism toaccomplishthesummarizationtaskaspartoftheclassiication learningprocess andwehavedemonstrateditsabilitytooutperform the state of the art in terms of summarization accuracy while achievingacompetitive classiication accuracy.