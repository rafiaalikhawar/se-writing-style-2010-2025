arxiv .12309v1 mar 2025how scientists use jupyter notebooks goals quality attributes and opportunities ruanqianqian lisa huang savitha ravi michael he boyu tian sorin lerner michael coblenz university of california san diego la jolla ca united states r6huang s2ravi mih024 btian lerner mcoblenz ucsd.edu abstract computational notebooks are intended to prioritize the needs of scientists but little is known about how scient ists interact with notebooks what requirements drive scientis ts software development processes or what tactics scientist s use to meet their requirements.
we conducted an observational stu dy of scientists using jupyter notebooks for their day to d ay tasks finding that scientists prioritize different qualit y attributes depending on their goals.
a qualitative analysis of their us age shows a collection of goals scientists pursue with jupyt er notebooks a set of quality attributes that scientists v alue when they write software and tactics that scientists le verage to promote quality.
in addition we identify ways scientists i ncorporated ai tools into their notebook work.
from our observatio ns we derive design recommendations for improving computatio nal notebooks and future programming systems for scientists.
k ey opportunities pertain to helping scientists create and man age state dependencies and abstractions in their software e nabling more effective reuse of clearly defined components.
index terms scientific computing computational notebooks end user software engineering i. i ntroduction unlike traditional development environments computational notebooks interleave program text with program output in a linear flow of content.
notebooks divide programs into cells enabling users to execute cells and see output in any order they choose.
computational notebooks such as jupyter have enabled thousands of users to create milli ons of notebooks to explore and communicate ideas in a form interleaving code output prose and sometimes multimedi a. these tools facilitate end user software engineering creation of critical software systems by people whose main focus is completing tasks not authoring software.
despite the broad adoption of computational notebooks they only provide a thin layer over existing runtime environ ments.
code in cells can side effect the environment imped ing reproducibility when users execute cells out of order.
cell s provide no abstractions they are not invokable for exampl e and their code shares a scope with surrounding code.
version control is rarely used even by notebook users who use version control in their other work.
previous research a nd commercial implementation exploring alternative desi gns have not yet produced popular competitors.
why do computational notebooks still serve the needs of their users better than existing alternatives?
we hypothes ize co first authors.that this is not merely a problem of challenges transitionin g from popular well documented tools instead we do not yet understand enough about how computational notebooks meet their users needs.
to lay a foundation for a new generation o f tools we seek to understand notebook users non functional requirements properties that notebook users value andhow they promote the properties they value and design opportunities that could lead to more effective notebook systems.
this paper focuses on scientific users of computational notebooks i.e.
those who write scientific programming code in notebooks.
prior work suggests that scientists struggle with keeping effective work in notebooks and transitioning from notebooks to other general purpose programming tools nonetheless notebooks are widely popular among scientists .
to understand how and why computational notebooks benefit scientists and identify opportunities f or improvement we focus on three research questions rq1 what goals do scientists pursue in notebooks?
rq2 what non functional requirements do scientific users of computational notebooks prioritize?
rq3 what tactics do scientists use to create notebooks that meet their quality requirements while also facilitating their scientific discovery process?
past investigations have studied users of jupyter notebook s focusing broadly on general data workers .
howeve r like ko et al.
in their study of java programming we wanted to understand the interaction level techniques tha t scientists use to create software that meets their requirem ents.
therefore we conducted an observational study of how individual scientists use jupyter notebooks to accomplish real istic day to day tasks.
in our irb approved study we recruited participants to let us watch them do their work.
to understan d how software related training affects use we recruited bo th computer scientists and non computer scientists.
we first observed how each participant worked with jupyter notebooks using their own setup and workflow for up to minutes.
then because any limited observation period coul d have resulted in unfinished work we asked them to wrap up the work for future continuation.
finally we interviewed t hem about their experience with jupyter notebooks during the st udy as well as overall perceptions.
leveraging techniques from constructivist grounded theory we noted memos of each observation and coded every notebook related action as well as every notebook related comment made by participants.
in sec.
iii we presen t eight quality attributes that our participants valued cla rity explorability reusability reproducibility correctne ss performance debuggability and collaboration.
we describe tact ics such as implementing each task in one cell that participant s used to promote quality.
additionally we show how participants incorporated ai tools into notebook work in scientific settings.
finally we discuss design opportunities that ar e revealed by this framing of computational notebook use.
cell structure and out of order execution distinguish not ebooks from other programming environments and promote explorability particularly for code that can be slow to run .
unfortunately they simultaneously inhibit aspects of cor rectness and reproducibility which scientists also value.
how ever future notebook systems could empower users to choose their tradeoffs more precisely by controlling scope dependenci es and in what cases cells are evaluated automatically.
while our work may not render a complete description of how people use jupyter notebooks in every possible way our findings are contextualized in realistic tasks and can inspi re future improvements to jupyter notebooks and similar enduser programming environments.
in summary this paper s key contributions are eight quality attributes that scientists value when creati ng and maintaining notebooks from an an observational study of participants performing their own tasks tactics that scientists use to promote software quality in jupyter notebooks opportunities for improvement in notebook tools that could promote quality in software written by scientists.
ii.
m ethods a. participants we recruited participants from various disciplines via institutional mailing lists messaging platforms and snowb all sampling.
since we aimed to study users with different domai n expertise programming experience and software engineer ing experience we did not impose screening constraints other t han requiring prior experience with jupyter notebooks and the ability to demonstrate a realistic task to be done in jupyter notebooks during the study.
we explicitly hoped to recruit people with varying experience in software enginee ring so we recruited half of the participants from the computer science discipline and the other half from other scientific disciplines.
we stopped recruiting participants after we h ad achieved saturation following standard practice af ter each study we compared field notes to existing observations to construct theoretical categories and their properties the last four participants did not lead to new categories or properti es.
b. procedure each study session included two parts a minute observation and a minute interview.
we conducted the studies in person and over zoom recording participants screens fo r analysis.
two authors ran the studies and took turns to lead.
participants received a gift card after the study.during the observational portion participants worked on tasks of their choosing more in sec.
ii d using jupyter notebooks.
we prepared a backup task in case participants did not have a task ready but we never used it.
we asked participants to explain their tasks as they worked in the st yle of think aloud.
however past observations of programmers have shown that additional depth is needed so while working on the task the experimenter asked questions as needed about the subject s workflow when using notebooks and various aspects of the task.
after about minutes of observation we asked the participant to start wrapping up t heir work to continue later.
most tasks can take many work session s to complete and sessions can be hours long.
to observe how users initiated the cleanup process in the limited time span of a study we asked participants to spend up to minutes wrapping up their work so they could easily pick up from where they left off the minute threshold was determined via pilot studies and no study participants needed all minutes.
in the cases where we observed no wrap up activitie s we asked about participants usual practices.
we conducted a semi structured interview afterward.
our questions pertained to five topics notebook reproducibili ty notebook understandability the ability of the participan t or collaborators to continue working on the notebook the expecte d longevity of the current notebook and changes in workflow when using computational notebooks compared to scripts.
c. protocol development process we started the study with one very open ended question how do people use jupyter notebooks for their day to day tasks?
prior work on notebook use and pain points motivated our initial interview topics.
we used a qualitative analysis method with key techniques from constructivist ground ed theory including open coding theoretical coding an d memo writing.
following the theoretical sampling approach we recruited participants in areas in which we lacked data a nd we refined the questions we asked participants per charmaz s guidelines based on emerging patterns to enable a deepe r understanding of topics for which we had not yet gathered sufficient data while this led to new questions asked in late r studies our irb advised us that new questions within the subject matter of the study did not need further review.
after ten sessions we analyzed the memos that we had written and found that participants had varying attitudes t owards using jupyter notebooks some used ad hoc organizational techniques caring little about readability and or reproducibility others attended to organizing the content insi de a notebook ensuring attributes such as modularity readabi lity and reproducibility.
for example p1 mentioned notebooks have no longevity do all notebook users hold the same low expectations for the longevity of notebooks?
expectati ons about longevity could have implications on how users prioritize readability and reproducibility.
with these questio ns in mind starting the 11th session we added additional questi ons to our protocol asking participants about their expectatio ns for the notebook s longevity.
we also observed that most par ticipants conducted cleanup tasks such as adding markdown headings leaving notes on to dos both inside and outside th e notebook and deleting empty cells in their last minutes.
for participants who performed little notebook cleaning wo rk at the end of the study we asked why they chose not to do the cleaning work.
we also asked about any cleaning work they would do if they were to share the notebook with others.
after the 15th interview interested in what users valued in notebook work we added questions about what they would teach to a novice notebook user.
d. task each participant worked on their own ongoing tasks during the study.
prior to each study we asked participants to brin g their own tasks that could be completed within the time fram e of the study.
although the tasks required domain knowledge each participant chose tasks in their own field of expertise.
as a result all of the challenges we observed were computation al rather than domain specific.
most participants worked on a single task during the observational session but three sub jects p8 p15 p20 completed their first task and started a second one.
we coded each of the task descriptions to categorize them into seven different task types based on our observatio ns analysis visualization refactoring reproduction dev elopment data cleaning and notetaking.
reproduction tasks involve d taking existing data and an expected output and recreating that output from the data in a new notebook.
we saw tasks across participants.
all except p20 did the tasks in one notebook.
to derive the approximate size of work in each notebook we counted the scrolling activities that occurred during the study to approximate task size defined as scroll size in table i using the low level action codes the derivation of which we describe in sec.
ii e. table i show s the complete task descriptions their respective task type s and the scroll sizes of their corresponding notebooks.
e. data analysis we open coded the study recordings which resulted in two subsets of low level codes those pertaining to actions conducted by the participant and comments and preferences they indicated during the observational portion and th ose relating to the interview responses.
the first two authors who also ran the studies coded the observational component s of each study and the third and fourth authors coded the interviews after reviewing the coded observations and field notes.
while coding the observational components the first two authors also coded meta observations i.e.
high level observations they made about each participant s behavior imp lied by their actions or quotes.
the four author coders met weekl y to review the low level codes until achieving agreement.
finally to further seek patterns among the low level codes the first two authors conducted a second round of coding upon codes of participant comments preferences and metaobservations from the observational portion and codes fro m the interview portion.
this round of coding is top down as th e coders derive high level codes implied by the low level codesunder three categories quality attributes of notebook con tent native notebook attributes related to the quality attribut es and user tactics.
we then created memos to relate the user tactic s to the quality attributes and the native notebook attribute s following the grounded theory practice.
we categorized the tactics as either a direct use of notebook attributes or a workaround for notebook limitations.
we report the identifi ed quality attributes and their associated notebook attribu tes and user tactics in sec.
iii c. we also include the full list of co des and a replication package in the paper supplement .
f .
limitations while our starting question how do people use jupyter notebooks?
is broad our participants primarily work in academia either as graduate students or as scientists.
as a result of the tasks were part of ongoing research projects limitin g generalizability to non research settings.
also the proj ects we saw were of limited size different techniques could be used by those who work on very large codebases.
participants brought in their own tasks which might result in varying tas k difficulties albeit improving external validity.
a confirma tory survey and member checking could help further validate the findings but the methods we used reveal the lived experience s of our participants .
we met with each participant once so we were not able to see the notebooks they worked on evolve over time.
furthermore our participants were all pa rt of the same institution as the authors limiting external va lidity.
representativeness may also be limited given that of the participants are graduate students although many scien tists who write code are graduate students .
finally five stud ies were done in person instead of on zoom and the modality differences could have affected participants performanc e. although the authors are computer scientists researchers with other perspectives particularly with more domain knowledge could have had different understandings of the work we observed and our software engineering perspective could have biased our interpretations of the efficacy of the tactics used by our participants.
in addition our study cou ld be biased towards the fact that the participants prioritized j upyter notebooks over other tools e.g.
matlab command line tools for computing in the observed contexts.
iii.
r esults we identified three categories of goals that participants ha d in their work ranging from disposable exploration toartifact construction rq1 sec.
iii b .
participants valued eight nonfunctional requirements which we describe using quality attributes rq2 sec.
iii c .
they promoted those quality attributes using tactics rq3 summarized in table ii .
in addition to our research questions we report how participa nts used ai based tools in their notebook work sec.
iii d .
a. participants we recruited participants identifying as male as female .
seven had prior work experience in software engineering one had formal training in software engineeri ng six self reported some familiarity with software engineer ing and six reported none.
half of the participants were from computing relevant domains in computer science one in data science and nine from non computing relevant domains across biology three social sciences three a nd earth sciences four where p6 had experience in both socia l sciences and earth sciences.
table i displays the participa nts backgrounds along with the tasks they worked on.
b. goals for using jupyter notebooks codes pertained to the kinds of goals that participants had in their work.
for example some participants described focusing on scientific findings whereas others focused on presenting their work to others.
we also identified codes relevant to ensuring the clarity of a notebook.
these codes include five categories removing redundant code and cells taking notes as comments or markdown refactoring code e.g.
renaming variables inserting empty cells to separate sections and reformatting or editing code for code and or output readability.
we also noticed varying expectations f or notebook longevity i.e.
whether to revisit the notebook after the task demonstrated in the study is done within the first te n participants and we started asking about the expectations for notebook longevity explicitly since p11.
combining these observations we found that each task fit into one of three categories disposable exploration findings and artifact .disposable exploration refers to exploratory work that will be discarded immediately after the outcome is achieved.
we consider a notebook used for disposable exploration if it does not have any expected longevity.
an artifact details the process and outcome of problem solving and or scientific discovery in a clear descriptive and pot entially reproducible way.
we consider a notebook to be an artifact if the task where it is used is a cleanup task or it has expected longevity and its author showed three or more kinds of the clarity related actions i.e.
more than half of the five available kinds to demonstrate sufficient effort in ens uring clarity from multiple aspects .
finally a findings notebook documents the process and outcome of problem solving and or scientific discovery but not necessarily in a structured way its main purpose is to expose information to the notebook author for them to decide on next steps of work.
although a findings notebook has some expected longevity its author used less than half of the possible kinds of clarity related actions.
out of participants we have notebooks p20 worked on two notebooks during the study which we denote as p20a and p20b as necessary.
we found four notebooks for disposable exploration nine for findings and eight for art ifact.
the first two authors compared the results with each individu al study and field notes and agreed upon the categorization.
while only p20 worked on more than one notebook during the observations several participants p3 p5 p11 share d the context of their notebook work via multiple notebooks prior to the observation or during the post observation intervie w.c. software quality attributes participants valued eight quality attributes clarity re producibility explorability debuggability reusability correctness performance and collaboration.
we detail each quality attribute how notebooks promoted inhibited quality and use r tactics that promoted quality results summarized in table ii .
clarity.
participants described tactics that they used to improve the clarity and presentability of their notebooks.
ten of our participants planned to present their work to their colleagues using their notebooks so they took extra care to ensure that the notebook was readable and could even be edite d and recomputed on the fly.
others including p17 p18 p19 and p20 reported that they often refer back to code written in previous notebooks and needed to be able to understand and potentially reuse code from them.
p17 described reusing code from notebooks dating back to and said he would continue writing new code in the notebook in the future.
seven of our participants highlighted that they appreciate d the ability to interleave markdown notes with their code.
p10 said that these notetaking abilities in notebooks make i t easier for others to understand the code in notebooks and p2 stressed that the markdown function is extremely important to when writing exploratory code.
for some users like p1 too many notes can have the opposite effect and hinder clarity.
instead he wrote high level to dos elsewhere.
p7 had a similar strategy and explained that she writes notes in a separate notetaking software because it was better at track ing history compared to notes inside the notebook.
the markdown capabilities of notebooks also allow users to create sectio ns in their notebooks by creating headings for certain groups o f cells which both p1 p2 and p20 used.
alternatively p9 p1 and p19 split up their notebooks using multiple empty cells t o segregate tested code from exploratory code and to separate different paths of exploration.
over half of the participants used the flexibility of the cell structure to organize content for clarity.
they adopted the heuristic of one task per cell to keep relevant lines of cod e together while maintaining the ability to see the outputs of intermediate computations however p1 noted that there wa s a tension between wanting to group related code and wanting to break apart and inspect inside a cell on one hand i want the flexibility to be able to look inside a cell and really get into its pieces.
but on the other hand i also want to be able to flip it over and be like okay i ve iterated on some kind of structure and i have this modular building block.
this form of content organization aids the reuse of code across notebooks since notebook code cannot be exported and must be reused via copy paste.
however copy pasting code can impede readability when unnecessary or redundant code is added to a notebook.
p18 found some vestigial code copied from another notebook and noted sometimes i ll copy and paste old code into here and then i ll just forget to delete it .
the flat cell based structure increased the participants cognitive load as inspection code and outputs interleaved.
p16 remarked that once there are too many things happeningtable i participant backgrounds and tasks .
in field c omp c omputing b io b iology s oc s ocial sciences and earth e arth sciences .
intask type denotes more than one task done in the study .
each participant worked on one notebook except p20 as denotes data for separate notebooks in goals and scroll size.
ingoals a represents artifact f represents findings and de represents disposable exploration .
id gender occupation field se experience task description t ask type goals scroll size p1 m phd student cs work refactoring a data analysis notebookrefactoring a p2 f phd student cs work algorithm data comparison an alysis f p3 m phd student cs training data visualization visua lization a p4 m phd student cs knowledge exploratory data analys is analysis f p5 m phd student bioinformatics knowledge explorator y algorithm analysis analysis f p6 f data analyst researcher economics oceanographyknowledge refactoring a data analysis notebookrefactoring a p7 f phd student neuroscience knowledge reproducing a n existing notebookreproduction de p8 m ms student cs work data cleaning developing a machine learning modeldata cleaning developmentf p9 m scientist geoscience none reproducing data vis ualizationsreproduction f p10 m scientist microbiology none migrating a script t o a notebook for documentationrefactoring a p11 f phd student oceanography none data visualizat ion homework assignmentvisualization a p12 m phd student cs work code cleanup refactoring f p13 f lab assistant psychology none data visualizatio n visualization de p14 f phd student cs none algorithm implementation de velopment f p15 f phd student geoscience knowledge data analysi s visualization analysis visualizationf p16 m phd student cs work analysis of machine learning modelsanalysis a p17 m phd student cs work data analysis analysis a p18 f phd student cs work testing different machine learning modelsanalysis f p19 m undergraduate ds knowledge drafting a programm ing assignmentdevelopment de p20 f phd student bioinformatics none annotating a not ebook reproducing visualizations two notebooks notetaking reproductionde a in a notebook it becomes hard to follow.
to manage information load p14 would reuse cells for multiple inspections and both p13 and p16 would delete inspection code to reduce visual clutter.
p16 also preserved inspection code in comme nts for later use to avoid retaining the inspection output.
five of our participants p12 p16 p17 p18 p20 reported that they create new notebooks to explore new ideas debug and clean up code which required copy and pasting code from notebooks.
p17 explained that he sometimes creates a new notebook and copies over his code cell by cell to debug p2 completed the study using a notebook she created exclusivel y for debugging.
p5 inspected a dataset in an existing cleane dup notebook instead of in his current notebook.
two participants wrote code in functions to explicitly promote clarity in their notebook.
p18 explained that she abstr acts code into functions to help her focus on relevant informatio n while reading through her notebook.
p14 explained in her interview that at the end it s nice to have a bunch of functions when the code is cleaned but like p1 she preferred to lose the clarity of functions when developing to ease debugging.takeaway users put effort into ensuring notebook clarity and often use markdown cells in jupyter.
whereas typical software engineers rely on abstraction and structu re to make code understandable notebooks flat structure does not provide these capabilities and often hinders clarity.
reusability.
traditionally software engineers leverage modularity and abstraction to promote reusability since abstractions can be reused across contexts without understan ding modules implementation details.
in contrast jupyter s fl at namespace and single scope for all cells both facilitated reuse by avoiding the need to pass parameters or change representations and inhibited reuse by enabling bugs cau sed by variables having meanings that pertain to irrelevant par ts of the program .
participants reported writing functions w hen code would otherwise be duplicated but p3 and p11 preferred to duplicate code unless it would result in more than several copies p11 explained that repetitive code can be easier to r ead than non repetitive code that invokes functions.
jupyter s single scope caused problems for p12 who copiedtable ii summary of how notebooks affect quality attributes and tacti cs participants used to improve quality attribute ways notebooks inhibit ways notebooks promote ta ctics used to promote clarity flat cell based structure of notebooks makes it difficult to organize informationmarkdown notetaking abstraction sectioning maintainin g one task per cell creating new notebooks reusability single scope results in accidental variable re use single scope avoids need for parameter passingai based explanations of unfamiliar code reproducibility out of order cell execution no built in pa ckage managementbroad usage of jupyter enables viewing and running others notebooksvirtual environments re running from the top readability and cleanliness storing notebooks alongside data explorability lack of support for output comparison across runs information overload manual cell execution and state management inability to inspect in the middle of a cell or in the middle of a loopcell structure based interactions and code ouptut correspondenceswriting intermediate outputs to disk exploring new ideas in fresh short notebooks merging cells with state dependencies correctness error prone manual state management cell by cell execution allows users to check the validity of each linecell based risk management restart and run all enforcing linear execution performance error prone manual state management caching d ata saving outputs cell bycell executionreusing data sectioning debuggability out of order cell execution single scope whe n debugging inside a function difficulty with navigating to relevant buggy cells inability to inspect in the middle of a cell enforced kernel restart with changes in dependenciescell based structure promotes small inspection code output correspondence and rapid edit run cyclesrestart and run all avoid debugging within function definitions notetaking collaboration limited compatibility with file diffing utili ties broad usage of one notebook tool jupyter makes collaboration easiersectioning and pasted code within a notebook but forgot to update a variable which was still bound due to its previous use.
fortunately after seeing plot emitted by a cell p12 debugg ed and fixed the problem.
later p12 encountered another instan ce of the same problem but did not notice the bug.
because of mutation code reuse within a notebook even for the same purpose is unsafe.
participants often invoked pand as functions that for example renamed columns so code that is correct before the renaming operation would be incorrect afterward.
p1 became unsure which lines of code would change the structure of a dataframe restarting evaluation to be sure okay let s start from the top.
some participants wanted to reuse code between notebooks and python scripts.
for example p10 adapted code from a standalone script for use in jupyter.
however jupyter coul dn t invoke the script s main function.
p10 refactored the code to use variables instead of command line arguments.
p7 worked with example code that reflected this same pattern it includ ed a function called mainfunction .
some participants wanted to reuse unfamiliar code from other contexts which required understanding the code to be reused at least to some extent.
p7 relied on chatgpt to explain unfamiliar code from an example that she wanted to reuse even though the code included various comments.
but these tools were not integrated into jupyter so p7 had to copy and paste the code into another window leaving chatgpt without the code s surrounding context.
p7 s query to chatgpt was only the source code followed by explain missing a possible opportunity to ask a more specific questio n. p16 described converting notebook code to scripts which execute outside jupyter this process is facilitated by the fact that jupyter provides only a thin interface on top of python.takeaway jupyter s lack of abstraction promotes frequent copy paste.
the flat namespace and single global scope makes copy paste convenient but error prone.
reproducibility.
reproducibility concerns the ability for the developer or others to reproduce the same notebook output in the future.
reproducibility is important in replicating sc ientific analyses and extending prior work with new analytic techniques.
unfortunately reproducibility can be a real probl em for notebook users.
p17 recounted a situation in dealing with a non reproducible notebook i simply created a blank notebook and copied section by section because i think this section would run if it does run then i move on to the next section and that does identify the problem.
because notebooks permit out of order cell execution reexecuting notebooks in order can produce different results than users first observe.
at the end of each session we asked participants to re run their notebooks in order.
p2 and p9 we re unable to reproduce their earlier work this way suggesting that out of order execution is a real threat to validity.
so me participants e.g.
p3 were careful to write code in order o f dependencies but this process was manual.
p6 and p8 used restart and run all to make sure their notebooks would run in order p17 complained about how out of order execution threatens reproducibility.
p16 cited mutation and order of execution when explaining why he kept imports at the top.
p1 who had a computing background used a package manager poetry to create virtual environments for notebooks enabling specification of dependencies.
in contrast most participants did not appear to be concerned with librar y versioning which could threaten reproducibility.
nine participants considered reproducibility to include r ead ability and cleanliness since readers might need to unders tand the code to reproduce the analyses.
matters of readability a re discussed under the clarity heading in this section.
takeaway scientists value reproducibility but out oforder execution and lack of package management hinder it.
explorability.
exploratory programming is about prototyping ideas and iterating on implementations through code withou t pre defined specifications or goals .
regardless of thei r goals our participants valued explorability indeed exp lorations are prevalent in programming and even the process of creating an artifact involves exploration.
jupyter includes features that promote exploration cell based interactio ns facilitating exploration through small inspection p8 p11 p17 nonlinear execution p20b and interleaving code and outp ut for correspondence and quick comparison p12 p17 .
participants often needed to compare outputs between different versions of their code but jupyter did not facilitat e this every time they re ran a cell the old output was overwritten .
to work around this problem p1 saved output outside of the notebook for comparison i have code blocks output their result to a file or save it somewhere and then i ll copy paste that result into like a constant in the code bl ock .
p8 chose another approach leveraging outof order cell execution putting various implementations of an algorithm in different cells enabled comparing the outputs .
notebooks truncate cell output if it is too long even though the output could include important information that is easi ly missed.
p9 for example missed a message indicating an installation failure because it was buried in a long output instead believing that installation had succeeded.
this ca used persistent failures when he ran other cells that used functi ons in that package.
long outputs can also cause difficulties when testing out multiple new ideas by reducing clarity.
as a workaround p12 and p16 started fresh notebooks for exploring new ideas to avoid a notebook getting long due to too many inspection cells and outputs just a new notebook if something gets messy p12 .
jupyter requires users to manually rerun a cell after it has been edited but users sometimes forgot to do so leading to unexpected output and changes to the global state.
these changes made it difficult to assess the validity of explorato ry code.
for example p2 changed the input file she was using to a truncated version in order to do more explorations.
however she forgot to rerun this edited cell and operated under the impression that she was working with the truncated files.
thi s caused her to both waste extra time waiting for the runs to finish and created an extra bug for her to solve distracting her from her original task.
p8 tried to avoid such hiccups by packaging exploratory code into a function with explorator y parameters as the arguments and putting a call to that functi on in the same cell so that he could repeatedly call the functio n with different parameter values to explore outputs.
finally similar to how they used markdown notes and annotations to keep notebook content clear participants u sednotetaking to facilitate explorations so that they could fr eely explore without getting lost.
this way p20 said i know that is the the newest exploration and the se are all the file paths that i wanted to use .
jupyter s limitation of only showing values of expressions that are at the ends of cells frustrated p13 who expected to inspect an expression in the middle of a cell without using th e print function.
likewise the promise of expression based interactivity enabled by the cell structure breaks with loo ps p4 could not inspect expressions within a loop unless printi ng them out and was forced to rerun the whole loop as opposed to individual iterations to gain any feedback on code chang e. takeaway cell by cell execution can help users iterate in straight line code but the cell model has difficulty scaling to more complex workflows.
correctness.
in traditional software engineering systematic testing is used to evaluate the correctness of code.
in contrast our participants found it difficult to concisely desc ribe expected results.
p17 notes that it s not like you can write unit tests to see if things are correct sometimes you can tell by t he data.
if the data distribution doesn t look right then r ealize maybe i should have done it differently.
lack of functional decomposition makes it difficult to write unit tests only fiv e out of participants wrote new functions.
in addition to inspecting output manually participants adopted noteboo krelated strategies to leverage the notebook environment an d mitigate its risks including cell based risk management described below enforcing linear execution and restarting and rerunning notebooks for ensuring the correctness of their code.
incell based risk management used by four participants p1 p2 p8 p17 users manage the risks presented by new code by writing in separate cells which they later combine.
for example p8 created a new cell to remap a categorical column of a dataframe to numerical values.
he checked that his code worked as expected by inspecting the datatype of the column.
as he needed to do the same for three other columns he created a new cell and wrote similar code for all three remappings in the same cell and ran the cell without addition al inspection.
when asked why he chose not to inspect he said i did my proof of concept for the first thing... i know it s going to work because it worked for one of them.
because jupyter requires users to manually manage state some participants took time to ensure that they had the corre ct mental model of their notebook s execution.
when trying to understand a collaborator s notebook which involved a lot of variable mutation p1 said i get nervous about this stuff because i don t know if i ve reset the state.
so my way of handling that is just restart and run it from the top.
p6 a newcomer to notebooks and programming runs each of her cells again whenever she makes a major change in her code to ensure that there are no new errors.
others p2 p3 p8 p12 p17 enforced linear execution in their notebooks.
restarting and running all notebook cells is not always desirable especially when working with large data.
p4 said the nice thing about jupyter is like just loading the d ata and not having to load it every single time when i run a script.
restarting and running all the cells to ensure correctness i n this case would counteract the performance benefits of notebooks .
takeaway traditional software testing methods are difficult to incorporate in notebooks so users mitigate ris k through inspection and cell by cell execution.
performance.
some participants praised notebooks for facilitating working with large datasets.
p4 talked about how his dataset takes minutes to load but using jupyter allows h im to just load it once and run his computations as many times as he needs.
p2 explained the point of the jupyter notebook is that i have saved so i can use them later.
participants promoted performance in their notebook work by limiting the number of times they loaded data and ran unnecessary computations.
out of order execution and split ting up cells allow both reusing loaded data and running the code efficiently.
p11 preferred to complete multiple tasks in the same notebook and created sections to separate them.
to run the code for a single task she would run the first notebook cell containing all the import statements she needed and sk ip to only the cells in the relevant section.
initially p2 wrote code following the one task per cell principle.
however when debugging code that took a long time to run she split up her cells based on how often she needed to recompute certain lines and how long they took to run.
cycles of editing and rerunning the split up cells caused som e confusion about the current state of the notebook and whethe r certain cells had been ran after changes.
ultimately p2 had to rerun each of the expensive computations again in order to confirm that she was working with the most up to date outputs .
this tactic that was intended to aid performance ended up hindering it when used in the context of debugging.
takeaway notebooks benefit data heavy tasks by enabling partial execution of programs but users must carefully manage state to leverage this feature.
debuggability.
debuggability refers to the ability to determine the cause of a bug.
all tasks but cleanup tasks p6 and p20a involved some debugging.
the cell based model enabled user s to see output of small portions of the program making the edit run cycle much faster than in traditional ides.
cells enabled participants to compare and connect code to output p12 run cells out of order p2 p8 p13 and isolate code for debugging errors p9 p19 .
however out of order execution single global scope difficulty in finding releva nt cells requiring reloading when dependencies are changed and expression based inspection having to be at the end of a cell all interfered with participants ability to debug efficien tly.
out of order execution in notebooks required the user to manually rerun cells that had been edited and all other cell s that depended on them .
for example p15 had written a for loop that was supposed to update values in rows of apandas data frame.
unfortunately p15 neglected to index into the frame accidentally rewriting the entire column in ever y iteration.
the first iteration ran with some output but the second iteration failed due to the unexpected change in the entire column.
confused p15 decided to rerun the cell to replicate the error only to see the for loop fail immediately during the first iteration it was now operating on data that had been mutated in the previous failed run.
minutes int o the situation the participant sought help from the intervi ewer who explained that p15 had to reload the data frame resolve the bug in the loop then rerun the cell with the loop to finally see the expected output.
neglecting an index may be common in dynamically typed languages but a scripting setting wo uld not have produced the output that misled the participant acr oss runs as every run executes the entire script not just snippe ts of code.
like p1 pointed out one must resolve some debugging scenarios in jupyter notebooks by restarting the kernel and rerunning all cells to enforce the script like execution li nearity.
the single global scope in notebooks also makes debugging and inspecting local variables in a function hard p3 p10 .
for example p10 considered returning local variables he wante d to inspect from a function to use the expression based inspect ion in a cell.
instead p14 simply avoids debugging inside a function.
when processing large files inside a function the edit run inspect cycles can take a long time.
by moving code out of a function she could see intermediate output without having to stop add print statements and rerun the code.
compared to an ide for scripts where one could easily go to the definition of a function or simply a specific line of code to localize the bug notebooks provided no easy way to navigate to relevant cells p3 p9 p12 .
in particular p could not locate the cell he just ran after he scrolled throug h the notebook to read other cells while waiting for the execut ion to complete.
as such participants spent a lot of time scroll ing through the notebook in fact scrolling was the most preval ent action across all studies with coded instances out of total action instances .
.
to complement the lack of navigation aid in notebooks participants p14 p16 took m ore notes in the notebook to facilitate cell navigation in debug ging if you leave notes then if something doesn t work at l east i can go back and look at my notes start with the things that looked weird intermediately and go from there p14 .
notebooks required restarting the kernel for changes in the dependencies to take effect which severely slowed down the edit run debugging cycles for p7 when some of the debuggingrelated code changes occurred in an imported module.
jupyter shows the value of the last expression in each cell.
p13 wanted to inspect arbitrary expressions in cells withou t insertingprint statements.
enabling easy inspection of all values could further promote debuggability.
takeaway cell structure helps isolate errors but out oforder execution and single scope impedes debugging because debugging work can mutate state needed elsewhere.
collaboration.
collaboration is an important part of the sci entific process.
as students and researchers our participa nts needed to ensure that their work could be understood by others and when needed could be collaboratively written.
two of the twenty participants planned to co author their notebooks with their colleagues p6 p14 but many planned to share and iterate on their notebook work with the input of others p1 p3 p5 p10 p11 p12 p16 p17 .
however jupyter does not natively provide many tools for facilitati ng collaboration on the same notebook so users rely on ad hoc methods such as splitting a notebook into separate sections and storing the notebook on a shared drive.
version control systems have limited benefit because they do not integrate nicely with notebook cells.
this also affected our particip ants willingness to collaborate with others on notebooks.
p8 sai d that he collaborates with others when working with python scripts but chooses not to collaborate with others because of the difficulty of resolving editing conflicts in notebooks.
t o avoid messy conflicts p20 elaborated in interview that she had once split a notebook into two sections by adding empty cells in the middle and she and her collaborator worked on the cells on opposite sides of the divide.
takeaway scientists often work together but a lack of version control integration or other collaboration tools f or notebooks makes collaboration difficult.
d. use of ai tools participants used ai generated code during their respec tive studies.
three p1 p2 p5 used github copilot which was integrated into their notebook environment i.e.
vs code .
nine participants p5 p7 p9 p10 p13 p15 p17 p19 p20 used chatgpt for help when writing notebook code and two p12 p16 mentioned using it in the past.
the participants using copilot largely used it as an autocomplete tool to accelerate their productivity sinc e it was a good time saver p2 .
in of the instances of copilot usage copilot would complete their line of code and instances were accepted without changes.
two were considered unhelpful after reading and were deleted and th ree were accepted and edited.
p1 also used copilot to explore solutions by prompting it in the comments to create a plot in a new cell.
once he ran the cell he saw that the axes labels were unreadable.
he tried to fix this issue by prompting copilot to fix the code but when unsuccessful moved on.
table iii shows instances chatgpt usage of which had a participant successfully integrate chatgpt generat ed code into their notebook.
to validate the ai generated code each of these participants first read over the code and all but one p5 copied and ran the code inside their notebook to determine if it met their needs.
however this strategy di d not always succeed p9 could not download the dependencies needed to run the generated code.
in addition p7 relied on chatgpt twice to explain code from the notebook but noted i don t know this code well enough to tell if chatgpt is giving me something wrong.
all but one chatgpt usertable iii usage of chatgpt chatgpt usage scenario participants success rate explaining code p7 fixing errors p13 p17 generating visualization code p9 p13 using unfamiliar libraries p5 p9 p15 p19 other programming tasks p10 p13 p20 worked in a non computer science field which highlights the important role of ai tools for scientists in programming.
the exploratory nature of notebooks eases validating aigenerated code because as p12 puts it if it gives me code that might be wrong i can just try it.
still for those with less coding expertise it may take them more effort to integrate t he code into notebook before validation by execution is possib le.
takeaway scientists rely on ai based tools even though they are not integrated into their environments but sometimes lack the programming knowledge to understand or incorporate ai based suggestions successfully.
iv.
d iscussion and future work identifying quality attributes that scientists value exposes opportunities to build theory and deepen our understanding of prior work which focused on data workers more generally.
first our study provides a framework for understandi ng notebook use and challenges in scientific settings through t he lens of quality attributes and identifies tactics scientist s use to promote the reported quality attributes.
this could enab le theory building opportunities data collection could foc us on the root causes of priorities and motivations which would e nable a stronger theoretical perspective.
for example our s tudy identified conflicting quality attributes for certain goals and contexts e.g.
clarity could conflict with debuggability when a notebook aims to show more intermediate computations and in depth data collection could better explain how scien tists navigated quality attributes in conflict.
second with a spe cific focus on scientific users while our study reveals notebook usage goals and pain points similar to prior results of data workers we found that priorities for notebo ok quality attributes depended on context and goals rather th an a general prioritization of exploration over explanation .
we noted highlights in the current design of notebooks that supported scientific work and its associated quality attrib utes.
support for dividing code into cells that can be executed in any order and share an execution environment is the hallmark of the computational notebook paradigm.
as we observed this promotes explorability which our participants prize d. combined with the support for markdown based headings and explanations which promotes clarity computational note books focus on exactly the quality attributes most valued by our participants.
support for easily seeing output also promot escorrectness and debuggability and out of order executio n facilitates work with very expensive analyses performance .
our participants were less concerned with reproducibility and reusability which are weaknesses of computational notebo oks.
how then could future tools for scientists do better?
key design opportunities pertain to reusability and reproduci bility which are inhibited by out of order execution the global s cope for all cells and lack of built in package management.
here we believe an opportunity lies in enabling more separation between the cells.
cells could have their own scopes with explicit control over which variables are imported from and exported to global scope.
this could enable a kind of reactiv ity similar to spreadsheets or observable in which cells ar e automatically re evaluated when their inputs change.
similar to that shown in other work we observed a spectrum from exploratory work to explanatory work.
system s need to support work that spans this spectrum over time but these are sometimes in conflict out of order execution which promotes explorability inhibits reproducibility also single scope promotes explorability but inhibits some aspe cts of reusability.
also some tactics promote some quality attributes at the expense of others leading to refactoring ne eds when goals change.
for example a very exploratory notebook might include a large number of short cells to enable quick edit debug cycles as the notebook becomes more explanatio noriented we found that participants were more likely to com bine related code into larger cells.
future notebook tools c ould provide refactoring tools that make transitioning between goals more convenient when users are ready and even enable backward transitions.
existing tools enable splitting cells which helps but documentation can increase viscosity tools that track a tighter relationship between code and doc umentation and between different regions of code could make it easier to revise mature code.
in our study we repeatedly observed participants starting over with fresh notebooks w hen they needed to make these kinds of transitions creating a me ss of different files with unclear histories and necessitating rework to construct each new version.
modular notebooks.
notebooks have a linear structure a sequence of code cells interspersed with markdown cells.
t he result is that notebooks hide dependencies inhibiting modularity code cells can rely on variables that were bound or whose values were mutated in other cells in the notebook.
then reusing a cell requires first identifying its dependen cies.
tools could help find required code but it could be more effective to promote modularity.
dependencies between cel ls could be restricted lexical and semantic dependencies cou ld be made explicit adding annotations of preconditions and postconditions on cells .
gradual approaches could pr omote formal abstraction mechanisms refactoring tools cou ld make it easy to extract cells as functions and notebooks cou ld adapt tools like projection boxes to enable live exploratio n of function behavior which engraft has attempted .
another axis of modularity concerns data code that reads fr om files or internet data sources can be buried in notebooks aga inhiding dependencies.
notebook environments and languages could improve modularity by making these dependencies including requirements regarding file formats explicit.
when executing a notebook users can choose to run all cells a single cell or all cells up to a point.
but this inhib its explorability because executing all of these cells can be ve ry expensive.
alternatively running just one cell is risky be cause the environment does not track which cells need to be re run after recent changes.
modularity could enable analyses tha t let users explore more safely and efficiently.
organizing large notebooks.
cells in notebooks are in a fixed scrollable view making it difficult to see portions of the notebook that pertain to specific tasks.
other tools that facilitate data analysis are more flexible.
spreadsheets in clude multiple sheets enabling users to divide analyses into sec tions.
labview a graphical programming environment that tar gets scientists and engineers breaks projects into separa te files and libraries.
although jupyter notebooks can call functio ns in other notebooks via the run command so pollutes the namespace with all of the referenced functions.
future computational notebooks could be more flexible allowing users to organize their cells according to their content.
parallel evaluation.
some cells can take a long time to run.
when those cells are executing no other cells can be evaluated.
this restriction relates to notebooks inabili ty to analyze dependencies from the environment s perspective any cell can produce state that is needed for any other cell.
but in general this is not the case and restricting progress in an unrelated part of the notebook inhibits exploration.
a fe w notebook improvements have adopted dataflow analysis to report or indicate dependencies across cells .
base d on these works we could identify non dependent cells to parallelize their evaluation to address this problem.
caching partial results.
cells can include some very expensive lines of code whereas other lines of code are very cheap .
better analysis of dependencies in notebooks could enable caching partial results promoting exploration.
packaging dependencies.
notebooks often depend on installed packages and data files.
current notebooks do not support specifying dependencies and their versions in metadata.
al though users can work around this via virtual environments notebooks could make this easier with explicit support.
lik ewise users must manually bundle input data with notebooks something that automated support could help with.
better ai integration.
our study shows how scientists used ai assistants in notebook work.
our findings align with prior evidence of ai use in ides and further unveil the need for built in ai support in notebook environments which pri or work has proposed for general notebook use .
specific to scientists future ai integrations in notebooks should emp hasize supporting the validation of ai generated code i.e.
checking if the generated code matches one s intent while taking into account their programming and domain expertise .v.
r elated work since knuth s proposal numerous literate programming environments have enabled end users to incorporate more storytelling into their code .
jupyt er notebooks allow quickly prototyping ideas through cells an d interleaving narratives with code helping document scien tific discoveries and analyses .
indeed among the long line of computing environments scientists use jupyter notebooks have become very popular .
corpus studies.
with millions of public jupyter notebooks on github multiple corpus studies gai ned insights into the usage patterns in jupyter notebooks via su ch data.
these studies identified the tension between explorat ion and explanation in constructing and sharing notebooks their lack of reproducibility and the lack of good codin g practices in notebooks .
building upon prior results r ecent work proposed a linear regression model to predict the level of exploration vs. explanation in a notebook develope d a taxonomy of bugs in notebooks and analyzed refactorin g behavior across the evolution of notebooks .
these studies show that while notebooks can evolve from exploration focused to explanation oriented by introduc ing more clarity and notebook users do attempt debugging and refactoring notebook code may be of low quality according to traditional metrics such as presence of unused module imports .
these quality metrics howev er may be less relevant for scientists than the higher level qu ality attributes that we identified.
in addition these studies an alyze notebooks on github which might miss some insights since scientists often choose not to publish notebooks on github except for sharing .
our study revealed notebook specifi c quality attributes that scientists valued tactics they pe rformed to promote quality and the difficulty in achieving quality g oals without support for modularity scoping and refactoring a cost they had to bear to optimize exploration.
studies with humans.
while corpus studies derive notebook usage patterns through notebook artifacts interviews ob servational studies and surveys seek the answer directly from notebook users mainly data scientists .
wang et al.
conducted the first observational study where pairs of data scientists collaborated in a notebook task focusing on col laboration patterns but not the low level notebook related ac tions.
four prior works although targeting general data workers as opposed to scientsts are particularly relevant to ours.
through interviews and surveys kery et al.
found that data scientists prioritized exploration over explanation and this prioritization often backfired when revisiting work la ter in contrast we found that scientists priorities depend on context and goals.
for example p17 carefully documented exploratory code with markdown notes expecting to revisit his code years later even though documentation could inhib it exploration later by increasing modification costs.
as subr amanian et al.
found from screen recordings of nine data workers performing their own tasks our study showed that scientists used notebooks for both experimentation and res ultssharing additionally while this work showed that noteboo ks could easily become disorganized most scientists in our st udy valued clarity in notebooks.
our participants adopted tact ics to promote clarity in their notebooks but these same tactic s often inhibited other quality attributes they valued e.g.
avoiding debugging within function definitions which maintaine d clarity but limited debuggability .
chattopadhyay et al.
conducted observations interviews and surveys with indu strial data scientists and engineers revealing nine pain points w hen using notebooks.
although their study population differs f rom ours our participants encountered similar issues includ ing a lack of built in ai code assistance tools and difficulty refactoring code hitting all pain points except data secur ity in addition our work surfaced tactics scientists adopted to w ork around the pain points e.g.
p20 split a notebook into two sections to address limitations in collaborative work .
fi nally in addition to conducting two corpus studies rule et al.
interviewed academic data analysts who felt that althoug h messes built up easily notebook clarity was unnecessary unless for sharing in contrast we found clarity to be a top quality attribute that scientists cared about even wit hout sharing or collaboration with four participants explicit ly using tactics to promote notebook clarity in non collaborative w ork such as adding documentation and writing modular code.
notebook improvements and novel systems.
driven by the existing challenges with jupyter notebooks researche rs have reviewed the design of computational notebooks and proposed analysis techniques novel notebook systems and jupyter extensions to improve the notebook quality and user experience.
some systems incorporate informal version control into noteboo ks to help users explore and compare code alternatives .
some tackle the error prone manual state management issue in jupyter by reporting unsafe notebook executions that lea d to out of sync data dependencies or allowing dataflow execution across cells .
other systems aim to redu ce the potential clutter created during the exploration proce ss by providing more live feedback and cleaning up redundant code with program slicing .
our study complements these systems by proposing design opportunities for future impro vements to jupyter notebooks grounded in observational data.
vi.
c onclusion scientists value eight different quality attributes in the ir work and use tactics to promote those quality attributes.
the cell model in computational notebooks promotes key quality attributes such as explorability that scientists value partly explaining their dominance among scientists.
although the model also inhibits other valued quality attributes such a s reproducibility future changes to the notebook model coul d enable scientists to meet their quality goals and navigate t he spectrum from exploration toexplanation more effectively.