representing and reasoning about dynamic code jesse bartels department of computer science the university of arizona tucson az usa jessebartels cs.arizona.edujon stephens department of computer science university of texas austin tx usa jon cs.utexas.edusaumya debray department of computer science the university of arizona tucson az usa debray cs.arizona.edu abstract dynamiccode i.e.
codethatiscreatedormodifiedatruntime is ubiquitous in today s world.
the behavior of dynamic code can dependonthelogicofthedynamiccodegeneratorinsubtleandnonobvious ways e.g.
jit compiler bugs can lead to exploitable vulnerabilitiesintheresultingjit compiledcode.existingapproaches to program analysis do not provide adequate support for reasoning about such behavioral relationships.
this paper takes a first step in addressing this problem by describing a program representation and a new notion of dependency that allows us to reason about dependency and information flow relationships between the dynamiccodegeneratorandthegenerateddynamiccode.experimental results show that analyses based on these concepts are able to capture properties of dynamic code that cannot be identified using traditional program analyses.
keywords program analysis program representations dynamic code selfmodifying code slicing introduction dynamiccode i.e.
codethatiscreatedormodifiedatruntime is ubiquitous in today s world.
such code arises in many contexts including jit compilation obfuscation and dynamic code unpacking in malware.
dynamic code raises a host of new program analy sis challenges arising partly from the fact that the behavior ofan application containing dynamic code may depend in part onlogic that is not part of the application itself but rather is in thedynamic code generator.
as a concrete example rabet describesajitcompilerbuginchrome sv8javascriptenginethatcausessome initialization code in the application program to be incor rectly optimized away resulting in an exploitable vulnerability cve .
as another example frassetto et al.describe how a memory corruption vulnerability can be used to modify the byte code of an interpreted program such that subsequent jit compilation results in the creation of the malicious payload .
to reason about such situations it would be helpful to be able to start from some appropriate point in the dynamically generated code permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation on the first page.
copyrights for components of this work owned by others than acmmustbehonored.abstractingwithcreditispermitted.tocopyotherwise orrepublish topostonserversortoredistributetolists requirespriorspecificpermissionand ora fee.
request permissions from permissions acm.org.
ase september virtual event australia association for computing machinery.
acm isbn ... .
code to understand the data and control flows that influenced the jitcompiler sactionsandcausedthegenerationoftheproblematic code.
e.g.
for the cve bug mentioned above we might want to perform automated analyses to identify which analyses transformations within the jit compiler led to removal of the program s initialization code and which data flows and controlflow logic influenced those transformations.
such analyses which we refer to as end to end analyses can significantly speed up the process of identifying and fixing such problems.
unfortunately existing approaches to static or dynamic program analysis do not adequately support such reasoning about dynamiccodemodification.traditionalprogramrepresentations such ascontrolflowgraphs cannothandletheeffectsofruntimechanges to the code which require accommodating the possibility of some memorylocationshavingdifferentinstructionsatdifferenttimes during execution.
jit compilers and dynamic binary translators maintain representations of the code being dynamically modified butnottogetherwiththatofthecodethatperformscode modification.
whole system analyses perform dynamic taint propagation taking into account explicit information flows via data dependencies but not implicit flows via control dependencies.
as we discuss later they also do not take into account dependencies that can arise through the act of dynamic code modification.
thus existing approaches to automated reasoning about program behaviors suffer from the following shortcomings a they do not provide program representations that let us answerquestionssuchas whichcodeinthedynamiccodegeneratoraffected thegenerationof thefaulty applicationcode?
or whatdataflowsinfluencedthebehaviorofthosecomponents of the dynamic code generator and in what ways?
.
b theydonotsupportnotionsofdependencethatcanallow us to reason about the computation in ways that can help answer such questions.
thispapershowshowthisproblemcanbeaddressedviaaprogram representationthatisabletocapturethestructureandevolution of code that can change dynamically together with a notion ofdependency that arises from the process of dynamic code gener ation and which is not captured by conventional notions of data andcontroldependencies.wealsodiscussanoptimizedrepresentationthatyields significantimprovementsinspacerequirements.
experimentalresultsshowthatourideasmakeitpossibletoreason about dynamic code in novel ways e.g.
we can construct backward dynamic program slices starting from incorrect dynamically generatedjit compiledcode toincludethejit compilerlogicresponsiblefortheproblem anddetectsituationswhereadynamic 35th ieee acm international conference on automated software engineering ase code generator embeds environmental triggers in dynamically generatedcode.suchend to endanalysesarenotpossibleusingcurrent approaches to program analysis.
background this section briefly discusses some key concepts relevant to our ideas.
it may be skipped by readers familiar with this material.
.
interpreters and jit compilers aninterpreterisasoftwareimplementationofavirtualmachine vm .
programs are expressed in the vm s instruction set with eachinstructionencodedasadatastructurethatrecordsrelevant informationsuchastheoperation sourceanddestinationoperands etc.
the computation for each operation xin the vm s instruction set is performed by a piece of code called the handler for x. the interpreterusesavirtualinstructionpointertoaccessthevminstructions encoding the input program and a dispatch routine to transfer control to appropriate handler code.
whileinterpretationoffersanumberofbenefitssuchasportability it incurs a performance overhead due to the cost of instruction decoding and dispatch as well as the limited scope for code optimizationresultingfromthefactthattheuserprogramsexecutedby theinterpreterarenot availableforanalysiswhentheinterpreter is compiled to machine code.
additionally modern dynamic languagesareoftenimplementedusinginterpreters andtheseincur additional overheads due to runtime type checking.
to address this problem just in time jit compilers are widely used alongside interpreters to improve performance by compilingselectedportionsoftheinterpretedprograminto optimized code at runtime.
the general idea is to take frequently executedportions of the program identified via runtime profiling apply optimizing transformations and generate optimized machine code.
theseoptimizationsareperformedatruntime astheprogramis beingexecuted andresults incode thatisdynamically createdor modified.
some jit compilers support multiple levels of runtime optimization wherethedynamicallycreatedcodemaybesubjected to additional rounds of optimization as execution progresses .
.
control flow graphs program analyses are based on representations of the program s structure forconcreteness wefocusoncontrolflowgraphs cfgs .cfgconstructionforstaticcodeviastaticanalysisiswell understood .however thisapproachisinadequatefordynamiccodebecause codecreatedatruntimeisnotavailableforstaticinspection instead we use dynamic analysis.
this has the benefit of being able to handledynamiccode itsdrawbackisthattheconstructedcfgmaynot contain all of the program s code due to incomplete code coverage.
we sketch herehow cfgs for static codecan be constructed from an instruction trace obtained via dynamic analysis.
the extension of this approach to dynamic code is discussed in section .
.
letgdenotethecfgunderconstruction.weprocessinstructionsintheexecutiontraceastheyareencountered.foreachinstruction i itsproperties e.g.
whetherornotitisacontroltransfer anditsstatuswithin g e.g.
whetherornotitisalreadyin g determinehowitisprocessed werefertothisas processingiinthecontextofg.
if ihasnotbeenencounteredpreviously itisadded as a new instruction.
if ifollows a conditional or unconditional jump itshouldbeginabasicblock thus if iiscurrentlyin gand is not the first instruction of its block the block has to be split and control flow edges added appropriately.
multi threading introduces additional complexity because adjacent instructions in the execution trace may be from differentthreads and thus may not represent adjacent instructions in the code.tohandlethis werequirethateachinstructioninthetrace beflaggedwithavalueindicatingthethreadthatexecutedit we refer tothis asthe thread id of theinstruction.
thecfg constructionprocessseparatelymaintainsasummaryofthestateofeach thread thissummarycontainsinformationsuchasthecallstack previous instruction seen current function being reconstructed etc.whenconstructingthecfg g eachinstruction iinthetrace isnowprocessedinthecontextofthestatesummaryforitsthread whichisobtainedfromthethread idfor i.thus thelastinstruction from one thread may be appending an instruction to a basic block whereas a different thread could be splitting a different block.
reasoning about dynamic code this section discusses the concepts underlying our approach to representing and reasoning about dynamic code.
.
design goals in devising program representations that support end to end analysis of dynamic code we have the following design goals it should be a natural and scalable generalization of existing program representations.
it should provide a basis for extending existing program analyses to handle dynamic code in a natural way.
it should be precise enough to distinguish between conceptually distinct dynamic code changes.
the first two goals aim to avoid reinventing the wheel as much aspossible.thethirdismotivatedbythefactthatdynamiccodechanges can be quite complex.
for example jit compilers typicallyusesharedcodebuffersthatmayberepeatedlyreusedtohold different andpossiblyunrelated piecesofdynamicallygenerated code different dynamically optimized code fragments may involve differentruntimeoptimizations piecesofdynamicallyoptimized codemaysometimesbe deoptimized tofreeupspaceintheshared code buffer and such deoptimized code and may later get dynamicallyoptimizedagain possiblywithadifferentsetofoptimizations that involve different parts of the jit compiler.
the third goal aims to obtain program representations that are able to separate out the effects of such complex runtime code changes and allow analyses to reason about them.
.
dynamic code modification dynamic code modification can give rise to different versions of the program with different instructions and behaviors at different points in its execution.
a representation suitable for end to endanalysis of dynamic code should keep track of the different versionsofthecoderesultingfromdynamicmodification.thereare two issues to consider here what constitutes dynamic code 313trace 0 1 2...phases...first instruction modified in 0first instruction modified in 1 figure phases modification ?
and how should such modifications be captured in the program representation?
we address these questions as follows.first wenotethatingeneral heuristicapproaches suchas categorizingamemorywriteascodemodificationifittargetsanexecutable section of the program s memory may not be sufficiently precise e.g.
becausepermissionsonmemorypagescanbechanged during execution making a non executable memory region executable.wethereforeconsiderawritetoamemorylocation lscriptas codemodification onlyif lscriptispartofsomeinstructionthatissubsequently executed.
second even small dynamic code modifications canresultinarbitrarilylargechangestotheprogram srepresen tation and behavior.
in the x86 isa for example the arithmeticinstruction bitwise exclusive or opcode xor encoding 0x32 can by flipping a single bit be changed to the control transfer instruction jumpshortifbelow opcode jb encoding 0x72 with potentially large effect on the control flow graph.
based on these observations we build our program s cfg using dynamicanalysis asdescribedinsection2.
untilweencounter an instruction whose memory locations have been modified.
atthis point we are confronted with a potentially arbitrary change to the program sbehavior and representation.
to capturethis we begin construction of a new cfg which we link to the previously constructed cfg using a special type of edge that we call a dynamic edge.
each such linked cfg corresponds to a phase of the program s execution.
we make this notion more precise below.
terminology.
in some situations it may make sense to distinguish between code created at runtime prior to being executed dynamic code generation and code modified at runtime after it hasalreadybeenexecuted dynamiccodemodification .theideasdescribedhereapplytoboththesesituations andweusetheterms generation and modification of dynamic code interchangeably.
.
concepts and definitions .
.
phases.
the idea behind phases is topartition an execution ofaprogramintoa sequence offragments 0 1 ... i ...such thatforeach i noneofthelocationswrittenbytheinstructionsin iispart ofany instructionexecuted by i.each iisreferred to as aphase.
execution begins in phase 0with the program s initial code.whenthefirstdynamicinstructionisencountered weswitch to 1. execution continues in 1 including other instructions that may have been created or modified in 0 until an instruction is encountered that was modifiedin 1 at which point we switch to 2 and so on.
this is illustrated in figure .
an execution with no dynamic code consists of a single phase.
more formally given a dynamic instance iof an instruction in a program let instr locs i denote the set of locations occupied by iandwrite locs i theset oflocations writtenby i.these notions extend in a straightforward way to a sequence of instructions s i0 i5i1 j1 x ydynamic modification of x to yi1 i2 i3 i4 a static cfgi0 dynamic edge g0 cfg 0 g1 cfg 1 i1 i2 i4 i5j1 i3 i4 b dynamic cfg figure dcfg an example instr locs s uniontext i sinstr locs i write locs s uniontext i swrite locs i given an execution trace tfor a program let t denote the ithinstruction in t andt denote the sequence subtrace t ... t .
we define the phases of tas follows definition3.
.
givenanexecutiontrace t thephasesof t denoted t is a sequence 0 1 ... i ...of subtraces of tsuch that the following hold 0 t wherek max j j and write locs t intersectiontextinstr locs t fori let i t then i t wheren max j j mand write locs t intersectiontextinstr locs t .
.
.
dynamic control flow graphs.
we use the notion of phases to construct control flow graphs for dynamic code we construct a cfgforeachphaseoftheexecution asdiscussedinsection2.
and linkthemtogetherusingspecialedges called dynamicedges that represent the control flow from the last instruction of one phase to the first instruction of the next phase.
we refer to such a cfg as a dynamic control flow graph dcfg .
more formally definition .
.
given an execution trace tfor a program let t 0 ... ndenote the phases of t and letgi vi ei denotethecfgconstructedfromthesubtrace i.thenthedynamic control flow graph for tis given by g v e where v unionmultitextn i 0viis the disjoint union of the sets of vertices viof the individual phase cfgs gi and e unionmultitextni 0ei edynisthedisjointunionofthesetsofedges ei together with a set of dynamic edges edyndefined as follows edyn last i first i wherelast i andfirst i denote respectively the basic blocks corresponding to the last instruction of iand the first instruction of i .
example .
.
figure gives a simple example of a dcfg.
the static cfg of the programunder consideration is shown in figure a .wheninstruction i2isexecuted itchangesinstruction i1toj1 indicatedbythedashedredarrow where j1isaconditionalbranch with possible successors i3andi5.
the following is an execution trace for this program along with its phases 314trace i0i1i2i4 bracehtipupleft bracehext bracehext bracehext bracehext bracehext bracehext bracehext bracehext bracehext bracehtipdownright bracehtipdownleft bracehext bracehext bracehext bracehext bracehext bracehext bracehext bracehext bracehext bracehtipuprightj1i3i4j1i5 bracehtipupleft bracehext bracehext bracehext bracehext bracehext bracehext bracehext bracehext bracehext bracehext bracehext bracehext bracehext bracehtipdownright bracehtipdownleft bracehext bracehext bracehext bracehext bracehext bracehext bracehext bracehext bracehext bracehext bracehext bracehext bracehext bracehtipupright phases 0 1 the first phase 0 consists of the instruction sequence i0 i1 i2 i4.
when control returns to the top of the loop at the end of this sequence instruction i1is found to have been changed to j1.
this ends 0and begins 1 which comprises the rest of the trace j1 i3 i4 j1 i5.
the cfgs corresponding to phases 0and 1in figure b areg0andg1respectively.
finally the control transfer from 0to 1is indicated via a dynamic edge from the basic block ofthelastinstructionof 0tothebasicblockofthefirstinstruction in 1 i.e.
from the block for i4ing0to the block for j1ing1.
the reader may notice in example .
that the basic block containing i4occurs in both g0andg1.
this illustrates a potential drawback of a naive implementation of dcfgs namely that cfg componentsmaybereplicatedacrossdifferentphases.itispossible to implement dcfgs to avoid such replication but in this case it is importanttoensurethatalgorithmsthattraversethedcfg e.g.
forslicing donotfollowunrealizablepaths.thedetailsformerging phases are discussed in section section .
.
briefly sketches the performance improvements we see from implementing sharing of dcfg components across phases.
.
.
codegen dependencies.
dynamic code modification can induce a dependency between the code performing the modification and the resulting modified code.
consider the following example addi r0 immloc mov loc r1a bdynamic code modification code modifier modified code inthisexample bisaninstructionthataddsanimmediatevalue immtotheregister r0 thebytesof bcontaining immareataddress loc.thus if loccontainsthevalue5 then b addi r0 .instruction awrites the contents of register r1to address loc thereby modifyingb.
when bis executed the value added to r0depends on the value written toaddress locbya.
thus theexecution of aaffects the behavior of bthrough the act of dynamic code modification independent of any data or control dependencies that may exist in theprogram.werefertodependenciesarisinginthiswaydueto dynamiccodemodificationas codegendependencies.moreformally definition3.
.
givenanexecutiontrace t adynamicinstance of an instruction i t is codegen dependent on a dynamic instanceofaninstruction j t j i ifandonlyif forsome loc instr locs i the following hold loc write locs j i.e.
jmodifies the location loc and ks.t.j k i loc nelementwrite locs t i.e.
jmostrecently modifieslocbeforeiis executed.
while codegen dependencies resemble data dependencies in some ways they differ in one fundamental way.
if an instruction i isdatadependentonaninstruction j thenjcanchangethevalues used byi but not the nature of the computation performed by i. by contrast if iis codegen dependent on j thenjcan change the nature of the computation performed by i e.g.
from an xor instruction to a jump if below instruction as discussed earlier.algorithm dcfg construction unoptimized input an execution trace t result a dcfggfort 1function instr starts new phase instr writtenlocs 2return instr locs instr writtenlocs nequal 3begin 4g 5 6w 7g addg tog 8fori 0tolen t 1do ifinstr starts new phase t w then w g addg tog processt in the context of g see sec.
.
ifinstr starts new phase t w then add a dynamic edge from last block of g to first block of g w w write locs t .
dcfg construction algorithm1showshowweconstructadcfgfromanexecution trace.
the algorithm is based directly on definition .
and con structs an unoptimized dcfg.
the dcfg consists of a sequenceof cfgs g ... one per phase linked together by dynamic edges we refer to the index for these cfgs as their phaseindex.thealgorithmproceedsasfollows.weinitializethe phase index to and the dcfg gto .
the set wof memory locationswritteninthecurrentphaseisinitializedto .thecfg g is initialized to the empty graph and added to g line .
we theniteratethroughthetrace tprocessingeachinstruction t in turn.ift beginsanewphase weincrementthephaseindex line reset wto since no memory locations have been written in the new phase that has just begun initialize the cfg v for the newphasetotheemptygraph andaddthisnew v tothedcfg g lines10 .wethenprocesstheinstruction t inthecontext ofthecfg g asdiscussedinsection2.
line13 .atthispoint if t is the first instruction of a phase line it has been added to g which means g has a basic block for it so we add a dynamic edge from the basic block of the last instruction of the previous phasetothebasicblockofthefirstinstructionofthecurrentphase line .
finally we update the set of written memory locations by adding in the set of locations written by t line .
we then continue the process with the next instruction of t. space optimization of dcfgs dcfgsconstructedusingthestraightforwardapproachdescribed in algorithm may contain redundancies.
this is illustrated in figure3 whichshowstheexecutionofaprogramwhereafunction fis jit compiled and the resulting code is executed after which a different function is jit compiled and executed.
suppose that the program sexecutionbeginsinphase 0.thememorywritesthat 315interp f jit f the resulting code is fjitexec fjit interp g jit g the resulting code is g jitexec gjit execution tracephases 0 1 2 figure potential redundancies in dcfgs create the jit compiled code for fare thus in 0. the execution of the jit compiled code for ftherefore causes a transition to a newphase 1.subsequentlyexecutedinstructions includingthe jit compiled code for fand the jit compilation of are then a part of 1. when the jit compiled code for is executed there is a transition to a new phase 2. thus the jit compiler code executed when compiling fis part of 0 while the jit compiler code executed when compiling is part of 1. the control flow graphs constructed from these two invocations of the jit compiler arethereforereplicated oncein 0andoncein 1 meansthatthere is potential for a significant amount of redundancy in a naively constructed dcfg.
in general the situation described arises if the same code is invoked multiple times from different phases.
anaturalapproachtoaddressingtheredundancyproblemwould be to merge the repeated components of the dcfg.
for example if thejitcompilerisinvokedmultipletimesinthecourseofexecution as in figure we can coalesce the various replicatedcontrol flow graphs for the jit compiler into a single copy and redirect all control flow edges accordingly.
however a naive approach to such coalescingcanleadtoalossinprecisionofanalysisbypropagatinginformationalongunrealizablepaths similartotheissueofcontextsensitivity in interprocedural program analysis .
animportantdifferencebetweenthegeneralproblemofcontextsenstiveinterproceduralanalysis i.e.
k cfa andtheissueofmergingreplicatedcodein dcfgs isthatofthenatureandcomplexity of the context relationships that arise.
programs can have arbitrarilycomplexcallgraphs andincreasing theamountofcontext information maintained during interprocedural analyses can therefore increase the precision of analysis albeit at increased cost .
phasesinadcfg ontheotherhand haveapredictablelinearpro gression withphase ntransitioningtophase n 1onencountering dynamic code.
this predictable structure of inter phase relation ships means that given the phase number of a function or basic blockinadcfg identifyingthephasenumberofthepreviousor next phase is straightforward.
this allows us to implement this optimizationefficientlyatalllevelsofgranularity namely instructions basic blocks edges and functions without incurring the complexity and cost of general k cfa.
our implementation of merged dcfgs associates a set of phase identifiers with each dcfg component instruction basic block and edge .
in the simple case there are nidentical blocks each containing the same sequence of instructions that appear in n phases a1 ... an.
we merge these into a single block which is then associated with a set of phase identifiers a1 ... an .
the resulting merged block must also account for merging the edges into out of it.
an edge that occurs in a single phase gets the phase identifierforthatphase.sharededges ontheotherhand areedges that connect the same blocks in multiple phases.
these are merged0x123 add rdx rcx 0x126 nop0x127 nop 0x128 nop 0x129 jmp .
0x160x123 add rdx rcx0x126 sub rdx 0x20x129 jmp .
0x16 0x123 add rdx rcx 0x126 sub rdx 0x20x126 nop 0x127 nop0x128 nop 0x129 jmp .
0x16 phase phase ghost edges ... phase identifier setsmerge figure merging sub parts of a basic block.
the dashed edges internal to the block are ghost edges .
into a single edge whose set of phase identifiers is the union of the phase identifiers for the phases in which that edge appears.
merging basic blocks becomes more complex when sharing similar but non identical blocks.
we take advantage of the similarportions of the blocks using a notion of splitting a block across aphase.
tosplitablockacrossaphaseweintroduceanewtype of edge which we call a ghost edge.
conceptually a ghost edge e is an intra block connector and indicates that for the given phase identifiers associated with e the two sub blocks connected by e should be treated as a single block.
using ghost edges we can split a block merging the shared components across multiple phases whilestillkeepinguniqueportionsoftheblockthatcouldnotbe shared.
figure shows an example of merging sub parts of a block.
whentraversingamergeddcfg atraversalalongtheedgesand basic blocks of one phase should not take an edge leading out of a shared basic block associated with a different phase if the outgoing edge is not shared between the two phases.
we use the sets of phaseidentifiersassociatedwithbsicblocksandedgestoenforce thisrequirementandonlyallowtraversalsacrosscomponentswith matching phase identifiers.
applications this section discusses a few applications of dcfgs and codegen dependencies to reasoning about dynamic code.
.
program slicing for bug localization and exploit analysis in jit compilers program slicing refers to identifying instructions that may affect orbeaffectedby thevaluecomputedbyaninstructioninaprogram .
slicing can be static or dynamic and orthogonally forwardorbackward.byeliminatinginstructionsthatareprovablyirrelevanttothecomputationofinterest slicingreducestheamount ofcodethathas tobeexaminedinordertoreason aboutit.inthe contextofdynamiccodemodification dcfgsplayacrucialrolein providingcontrolflowinformationneededtoconstructbackward slices.
analyses that reason about dynamic code solely through datadependencies e.g.usingtaintpropagation ar e unable to capture the effects of control dependencies and therefore are unsound with respect to slicing.
weimplementedbackwarddynamicslicingasanapplicationfor evaluating theefficacy ofdcfgs and codegendependencies with thegoalofbuglocalizationandexploitanalysisinjitcompilers.
316backwarddynamicslicingaimstoidentifythesetofinstructions thatmayhaveaffectedthevalueofavariableorlocationatsome particularpointinaparticularexecutionoftheprogram.ourimplementation is based on korel s algorithm for dynamic slicing of unstructured programs however any slicing algorithm for unstructured programs would have been adequate.
inkorel sslicingalgorithm aninstruction iatposition pin atracet i.e.
i t dependson aninstruction j t written i squiggleright korel j if and only if for some source operand aofi jis the last definition ofaat position p. more formally i squiggleright korel jiff a source operand aofi a write locs j and n q n p a nelementwrite locs t when processing an instruction i korel s algorithm lines and of fig.
marks all instructions jsuch that i squiggleright korel j. to work with dynamic code we modify this notion to also take codegendependenciesintoaccount writingtheresultingnotionof dependency as i squigglerightj i squigglerightjiffi squiggleright korel joriis codegen dependent on j. our slicing algorithm is identical to korel s except for two generalizations codegendependenciesaretakenintoaccountinpropagating dependencies.
in the marking step of the algorithm lines and16offig.
weusethe squigglerightrelationratherthanthe squiggleright korel relation used by korel .
the structure of the dcfg is taken into account by treating dynamic edges similarly to jumps in the terminology used by korel this corresponds to the notions of j entryand j exit .
.
detecting environmental triggers in malware malware sometimes use environmental triggers to evade detection by performing malicious actions only if the right environmental conditionsaremet e.g.
ifthedatehassomespecificvalue.current work on detecting such behaviors is geared towards static code e.g.
identifyingconditionalbrancheswithinput taintedoperands .theideaistousedynamictaintanalysistoidentifyconditional branchesoftheform ifexprthenbehavior 1elsebehavior where expris tainted from i.e.
influenced by some input values.
once suchconditionalshavebeenidentified othertechniques e.g.
using smt solvers to generate alternate inputs can be used to further explore the program s behavior.
dynamiccodeopensupotherwaystoimplementenvironmental triggers e.g.
by using the environmental input to directly affect whatinstructionbytesaregenerated.thisideacanbeillustrated by adapting an example of evasive behavior described by brumley et al.
to use dynamic code instead of a conditional.
the code shown in figure uses bit manipulation instead of conditionals toevaluatethetriggerexpression therebyrenderinginapplicable techniquesthatrelyontaintedconditionals.thevariable day bits is set to or depending on whether or not the most significant bit of the value of the expression day 9is i.e.
whether or notthe predicate day 9is true.
similarly mth bits is or dependingonwhetherornot month 7istrue.thus thevariable triggeris1or0dependingonwhethertheenvironmentaltrigger in this example the predicate day month is true or not.
the assignment to addinstrptr writes this value into the source byte of an assignment to a variable that is usedin a conditional to determine whether the malicious behavior is manifested.1note thatthe conditionalthat controlsthe execution ofthe payload functionisneitherdata dependentnorcontroldependent on the input instead there is a codegen dependency betweenthisconditionalandthe patchinginstructions whichare data dependent on the input.
ourcurrentimplementationgeneralizestheapproachofbrumley et al.
to incorporate codegen dependencies we taint the values obtainedfromanyenvironmentalinputsofinterest thenpropagate taint in a forward direction.
we determine that an environnmental trigger is present if either of the following hold a conditional jump instruction with one or more tainted operands is executed or thereisacodegendependencywherethevaluewrittenis tainted equivalently one or more memory locations containing an executed instruction are tainted .
the first condition is that originally used by brumley et al.
while the second condition incorporates the effects of dynamic codemodification.analysisofthecodeshowninfigure5proceeds as follows.
the values obtained from the call localtime are tainted.
this causes the variables day bits and mth bits and thence the variable trigger to become tainted this tainted value is then written to memory via the assignment addinstrptr trigger whenthefunction hide issubsequentlyexecuted thelocation written by the above assignment is found to be a code location thereby indicating a codegen dependency where the value written is tainted.
this indicates the presence of an environmental trigger.
evaluation .
overview we built a prototype implementation to evaluate the efficacy of our ideas and ran our experiments on a machine with cores .
ghz and tb of ram running ubuntu .
.
we used intel s pin software version .
for program instrumentation and collecting instruction level execution traces and xed version .
.
forinstructiondecoding.weiterateovertheinstruction tracetoconstruct adcfgfortheexecution.
weidentifydynamic code and determine codegen dependencies using taint analysis we taint writes to memory with each memory write getting a distinct taint label.
for each instruction in the trace we check whether any ofitsinstructionbytesistainted inwhichcasetheinstructionis flagged as dynamic.
our evaluations focused on the following questions 1thiscodereliesontheappropriatebyteofthemodifiedinstructionbeingataspecific offset inthiscase 11bytes fromthebeginningofthatfunction scode andtherefore isoviouslyhighlycompiler andsystem dependent.thisisnotatypicalofmalware which are usually launched as system specific binary executables.
317void hide volatile int environmental trigger if environmental trigger payload ... perform malicious action void patch int pg sz sysconf sc page size mprotect void long hide pg sz pg sz pg sz prot read prot write prot exec time t rawtime struct tm systime time rawtime systime localtime rawtime int day systime tm mday int day test day int day bits day test day bits iff day int month systime tm mon int mth test month int mth bits mth test mth bits iff month trigger iff day month int trigger day bits mth bits unsigned char addinstrptr unsigned char hide addinstrptr trigger int main hide patch hide return figure environmental trigger based on dynamic code how capable are existing state of the art dynamic analysis tools at end to end reasoning of dynamic code?
to answer this question we used two small synthetic benchmarks to evaluate three widely used modern dynamic analysis tools pinplay angr and triton .
howeffectiveareourideasinreasoningaboutdynamiccode in scenarios involving problems in real world software?
toevaluatethisquestion weconsidertwokindsofexperiments dynamicslicingforbugreportsandexploitsfor the jit compiler in v8 the javascript engine in google s chrome browser and two benchmarks that use dynamic code for environmental triggers in malware.
what is the performance impact of the merging optimizations discussed in section ?
the bug exploit proof of concept code used in the slicing experimentsmentionedaredeliberatelyconstructedtocrash the software quickly and thus do not reflect typical application behavior.
we use the jetstream benchmarks sec.
.
to more accurately evaluate the impact of our memory optimizations on typical application code.
thecodeforourprototypeimplementationisavailableat https github.com skdebray ase and projects lynx project samples ase .
our data samples are available at samples ase data .
.
assessing the capabilities of existing tools weevaluatedthecapabilitiesofexistingstate of the arttoolsusing threewidely used moderndynamicanalysis toolsthatimplement backwarddynamicslicing namely pinplay revision1.
angr commitbd3c6d8ongithub andtriton buildno.
.our approachpinplay angr triton syntheticbenchmark y n n n benchmark y n n nexploitanalysisv8 oob to jit y x x x code pages v8 escapeanalysis bug y x x x luajit exploit y n n nbug local izationoob read y x x x jit typeconfusion y x x x scoping issue y x x x key y picks up dynamic code generator from backwards slice of dynamic code.
n does not pick up dynamic code generator from backwards slice of dynamic code.
x crashes or fails to load.
table assessing existing dynamic analysis tools weinvokedthesetoolstoincorporatesupportforself modifying codeasfollows wesettheflags smc support andsmc strict flags totrueforpinplay andloadedourprojectwith auto load libs andsupport selfmodifying code set to true for angr.
to avoid potentially confounding factors such as code size or complexity weconsideredtwosmallsyntheticbenchmarksof15 and x86 instructions respectively.
both programs are simple instructure oneaddsaconstanttothetargetoperandofajump instruction the other adds a constant to the immediate operand of anaddinstruction.thefixedandunconditionalnatureofthesecode modifications means that there is nothing tricky e.g.
no data or control dependencies between the instructions being dynamically modified and the instructions performing dynamic modification.
this allows us to focus entirely on questions of representation and analysisofdynamiccode anyproblemsinanalyzingsuchsimple programsrelatedirectlytoshortcomingsintheunderlyingprogram representationsand analysisalgorithms whenappliedto dynamic code.
we used the three tools mentioned above along with our prototype implementation of slicing section .
to carry out backward dynamic slicing on our synthetic benchmarks.
in each case we computed a backward dynamic slice with the slice criterion being thevaluecomputedbythefunctionwhosecodewasdynamically modified.theresultsoftheseexperimentsaresummarizedintable .itcanbeseenthatwhileallthreetoolssuccessfullyincludedallof the relevant non codegen dependent instructions in the slices they computed none of them are able to pick up the code that performs dynamic modification.
given that soundness for slicing algorithms is defined as not excluding any statement that can influence theslicing criterion this indicates that the resulting slices were unsound.
onfurther investigation wefound thatthe reason forthis is a fundamental limitation of the underlying cfgs constructedby these tools which do not represent the different versions ofcode resulting from dynamic code modification.
by contrast we found that our implementation using dcfgs and codegen dependencies computedslicesthatcorrectlycontainedtheinstructions that performed dynamic code modification.
318tracing dcfg construction slicing test program ntrace treadninstrsnblocksnedgesnphasestdcfg nslice tslice sliceexploit analysisv8 oob to jit code pages .
.
.
v8 escape analysis bug .
.
.
luajit exploit .
.
.
buglocalizationoob read .
.
.
jit type confusion .
.
.
scoping issue .
.
.
key ntrace no.
of instructions in execution trace tread time to read trace seconds ninstrs no.
of instructions in dcfg nblocks no.
of basic blocks in dcfg nedges no.
of basic blocks in dcfgnphases no.
of phases tdcfg dcfg construction time seconds nslice no.
of instructions in slice tslice slice construction time seconds slice fraction of dcfg removed from slice ninstrs nslice ninstrs.
table slicing performance additionally to assess the applicability of these tools to realworldsoftwarethatmakesuseofdynamiccode weevaluatedthem onsixbugandexploitreportsforthev8jitcompiler.asshown in table none of them were able to successfully analyze these examples they all crashed with internal errors when loading v8.
all three tools were able to process the luajit example without crashing butnoneoftheslicestheycomputedcontainedthejitcompiler or exploit code that created the dynamic code.
.
analysis efficacy on real world examples toevaluateourapproachonrealworldsoftwarethatusesdynamic code weconsiderthreeapplications analysisofexploitsinvolv ingjitcode buglocalizationinjitcompilers and detectionoftrigger basedevasivebehaviorsthatusedynamiccode.ourgoal wastoperformend to endanalysesontheseexamples i.e.
start fromtheproblematicdynamiccodeandcomputeabackwarddynamic slice that includes the culprit portions of the dynamic code generator where the bug security exploit originates.
the results are shown in table .
.
.
exploit analysis.
weconsiderthreeexamplesofexploits two of them involving dynamic code in google s v8 javascript engine maliciousshellcodeoriginatingfromanout of bounds oob write to the jit code pages in v8 escape analysis bug in v8 s jit compiler cve and malicious bytecode used to escape a luajit sandbox .
for each of these exploits we used the proof of concept code to computeadcfg backwarddynamicslicestartingfromthedynamically generated exploit code.
separately we used the write up for eachexploittodeterminethebugsresponsibleforeachexploit identifyingthebuggy code generatorportionsintheexecution traces recordedforeachexploit.wethencheckedtheslicetodetermine whether the buggy generator code is present in the slice.
the first security exploit we consider entails an oob write to thejitcodepageswithingoogle sv8javascriptengine .the exploitisaresultofarraytypeambiguitythatallowstheattackerto writeandexecutearbitraryshellcode.weconstructedadcfgfromanexecutiontraceofthebuggyv8codeandcomputedabackward dynamic slice from the first nop shellcode instruction in the nop sled in the attack code.
our backward slice correctly included both thebuggycodewithinv8thatledtothearraytypeambiguityalong with the exploit code that generated the shellcode at runtime.
the second exploit we examined is discussed in detail by rabet .
it arises out of a bug in v8 s escape analysis and causes some variableinitializationsinthejit optimizedcodetobeincorrectly optimized away when performing load reduction.
the proof of concept code provided causes v8 to crash while executing the optimizeddynamiccodeduetoanoobread.thewriteupprovidedbyrabetproceedstousethisoobreadasasteppingstonetowards demonstrating arbitrary code execution.
for our analysis of thisexample we built our dcfg from the execution trace recorded by pinandthen wecomputed abackward dynamicslice fromthe dynamic instruction prior to the exception that is thrown due to the oob read.
we found that the resulting slice correctly included thebuggyportionsoftheloadreducerintheescapeanalysisphase of v8 s jit compiler whose optimizations cause the oob read.
our final example in this category was with malicious lua bytecode being used to escape a sandbox in luajit .
the proof of conceptmaliciousprogramcorruptsbytecodewiththegoalofwriting shellcode which prints a message.
we followed an approach similar tothe one we usedto slice thev8 oob write startingour slice at the beginning of the nop sled used in the attack.
we found that the backward slice computed by our tool correctly picks up the lua code that generates the shellcode.
theroleofcodegendependencies.
foreachexploitexamplediscussed wecomputedslicesstartingata nopinstructioninthenop sledgeneratedaspartoftheshellcode.toassesstheroleofcodegendependencies werecomputedtheseslicesignoringcodegendepen dencies.wefoundthat ineachcase theresultingsliceconsistedof justthe nopinstructionandnothingelse.by contrast whencodegen dependencies were considered the relevant jit compiler code wasincludedintheslice.thisdemonstratesthatcodegendependenciesare fundamentaltoreasoning abouttherelationship betweendynamically generated code and the dynamic code generator that created that code.
319original dicing improvement test program dcfgorigsliceorigdcfgmkslicemk dcfg slice mkexploit analysisv8 oob to jit code pages .
.
.
v8 escape analysis bug .
.
.
luajit exploit .
.
.5buglocalizationoob read .
.
.
jit type confusion .
.
.
scoping issue .
.
.
key dcfgorig no.
of instructions in original dcfg dcfg improvement in dcfg size due to dicing sliceorig no.
of dcfg instructions in original slice dcfgorig dcfgmk dcfgorig dcfgmk no.
of instructions in dcfg with marker slice improvement in slice size due to dicing slicemk no.
of dcfg instructions in slice with marker sliceorig slicemk sliceorig mk fraction of dcfgmkremoved due to dicing dcfgmk slicemk dcfgmk table dicing performance .
.
bug localization.
we consider three jit compiler bugs from google sv8javascriptenginethatwerepostedto bugs.chromium.org and classified as type bug security.
empty jump tables generated by the bytecode generator leadingtoout of boundreadsthatcrashthegeneratedjitcompiled code .
atypeconfusionbugthatleadstoacrashafterthedynamic code has been generated .
arrowfunctionscopefixingbug wherecertainconstructs involving a single line arrow function cause a crash .
for each of these bugs we proceeded as follows.
to identify the problematic code in the jit compiler we examined the correspondinggithubcommits togetherwithanyrelevantinformationinthe bug report to determine the code that was changed to fix the bug.
wedelineatedtheproblemcodesoidentifiedusingsmall marker code snippets i.e.
small easily identifiable code snippets that do not affect the operation of the jit compiler and confirmed thatthe behavior of the buggy jit compiler was unaffected.
we thenused the example code submitted with the bug report to obtain anexecution tracedemonstratingthe bug and usedthistrace together with the dcfg constructed from it to compute a backward dynamicslicestartingfromtheinstructionthatcrashed.finally we analyzed the resulting slice to determine whether the problematic code as identified above was included in the slice.
the results of ourexperiments are summarized in table .
our end to endanalysiswasabletosuccessfullypickupthebuggycode foreach ofthebugs mentionedabovein theslice allowing oneto narrow down the functions involved in v8 that lead to the crash.
.
.
performance.
table2showstheperformanceofourprototype dcfg based slicing implementation on our real world testinputs the environmental trigger example is omitted because it doesnotusebackwardslicing .theseinputprogramsallinvolve computationsofsubstantialsize thesmallest luajitexploit has atraceof464kinstructions whiletheremainingexecutiontraces rangefromalmost7.9minstructions v8scopingissuebug to135minstructions v8escapeanalysisbug .thetimetakentoreadthe traces and do nothing else is roughly 1m instructions sec.
thedcfgsconstructedtypicallyrangeinsizefromabout22k basic blocks and 62k edges v8 scoping issue bug to about 41k blocks and 117k edges v8 oob exploit with a low of .6k blocks and12kedgesfortheluajitexploitandahighofabout53kblocks and 154k edges for the v8 escape analysis bug.
most of our test programshave2 4phases withthev8jittypeconfusionexample an outlier with phases.
dcfg construction incurs an overhead of roughly15 oversimplyreadingatrace mostofthetestinputstake roughly2 3minutes withthelowesttimebeing7.5secondsforthe luajitexploitandthehighestbeingabout30minutesforthev8 escape analysis bug.
since dcfg construction involves processing each instruction in the execution trace the time taken depends on the sizes of both the instruction trace and the dcfg.
theoverheadincurredbyslicingrelativetothetimetakenfor dcfg construction ranges from .
for the luajit exploit to .
forthev8scopingissuebug withmostofthetestprograms ranging from to .
in absolute terms most of the programs takeabout2 10minutesforslicing withalowofabout8secsfor the luajit example and a high of about about .
hours for the v8 escapeanalysisbug.slicingisabletoremoveabout50 ofthe instructions in the dcfg with a high of of the instructions removed for the luajit exploit.
these results indicate that our approachisbothpractical intermsoftime anduseful intermsof the amount of code removed from the dcfg .
since our approach does not fundamentally alter the slicing algorithm but rather augmentsittoworkoverdcfgsandusecodegendependencies itis not difficult to adapt our approach to other slicing algorithms with different cost precision characteristics.
.
.
focusing the analysis markers and dicing.
givenourobjectiveoflocalizingproblemsinthejit compilercode itisusefulto examine the extent to which our approach is able to reduce the amountofactualjit compilercodethathastobeconsidered.to 2ourimplementationusespintocollectaninstructiontracethatiswrittentoafileon disk.thenumbersreportedhererefertothetimerequiredtoreadsuchinstruction trace files the time taken to record the traces and write the trace files which depends onthetracingtoolusedandisindependentoftheideasdescribedhere isnotincluded.
320no.
of instructions no.
of basic blocks no.
of edges test program orig opt orig opt orig opt performance benchmarksbase64 .
.
.
crypto sha1 .
.
.
date format .
.
.
nbody .
.
.
poker .
.
.
str unpack .
.
.5securitybenchmarksv8 oob to jit code pages .
.
.
v8 escape analysis bug .
.
.
luajit exploit .
.
.
oob read .
.
.
jit type confusion .
.
.
scoping issue .
.
.
key orig value in original representation dcfg opt value in optimized representation dcfg improvement orig opt orig table impact of representation optimization on dcfg size do this we placed markers i.e.
small code snippets that are unambiguously identifiable and semantically neutral in the code as close as we were able to the invocation of the jit compiler.
during analysis we excluded the portion of the execution trace before the marker.
this effectively computed a program dice that excluded the front end parser byte code generator and interpreter.
table gives the results of these experiments.
the two columns labeled original refer to the size of the dcfg and the backwardslicecomputedwithoutmarkers i.e.
asshownintable2 the columns labeled dicing refer to the size of the dcfg and slice when markers are used the columns labeled improvement show the percentage improvement due to dicing.
the columns labeled dcfgand sliceshow respectively the reductions in the size of thedcfgandtheslicewhenirrelevantcodeisexcluded.theseare intherange35 fordcfgsizeand26 forslicesize.the jit type confusion bug sample is an outlier with almost all of the original dcfg and slice eliminated.
the final column labeled mk shows the effects of slicing focusing only on the dcfg resultingfrom dicing these range from about to about .
overall these results show that our approach is effective in focusing on the relevant portions of the jit compiler and the use of codemarkers to identify entry into the jit compiler can be helpful in zeroing in on the relevant portions of the code being analyzed.
.
detecting environmental triggers we use two test programs to evaluate the detection of environmentaltriggersbasedondynamiccode oneisshowninfigure5 the otherisavariantofthisprogramthatusesimplicitflowstofurther disguise the influence of environmental values on the trigger code.
we built two detectors to demonstrate the utility of dcfgs and codegendependenciesforthispurpose.inthefirstcase wetaint theinput sourceand propagatethe taintforwardin theexecution trace.
if there is a codegen dependency from an instruction with tainted operands to an instruction that is later executed an inputdependent value may be influencing the instruction bytes of somedynamic instruction and we report that there is dynamic input dependent program behavior.
in the second case we compute a backwarddynamicslicewiththeslicingcriterionbeingthedynamically modified code location at the point where it is executed.
ourimplementationscorrectlydetectthatenvironmentalvalues influencedynamicprogrambehaviorforourbenchmarks.toassessthestateoftheart wetestedtheseprogramsusingtwowidelyused analysis tools s2e a widely used symbolic execution engine andangr.ineachcase wefoundthattheinputvaluesusedtopatchthefunction hide infigure5aresilentlyconcretizedandonlythe false path is explored.
as a result these tools are unable to identify the environment dependent aspect of the program s behavior.
.
space optimization the impact of merging toevaluatetheeffectofthespaceoptimizationdiscussedinsection we used a collection of benchmarks from the jetstream suite of javascript workloads base64 crypto sha1 dateformat nbody poker andstr unpack .
theresults are shownin table .these benchmarks havesignificantly larger dcfgs than the security benchmarks described earlier.
this is not surprising since the security benchmarks were submitted as demo codeforbugreportsandthusaimedtoquicklymanifestthebugand crashorexittheprogram.theperformancebenchmarksyielded significantly higher performance improvements than the security benchmarks with improvements ranging from to .
wealso found thattheamountofimprovementincreaseswith the size of the unoptimized dcfg.this is shown in figure .
this indicatesthatthereisasignificantamountofoverlapinthecode executed by different phases e.g.
library code the interpreter and jit compiler and also that our merged dcfg representation is effective in optimizing away the resulting redundancies.
we did not see a significant difference in execution speed between the dcfg implementations with and without this optimization.theversionusingspace optimizationwasslightlyfasteron average possibly due to fewer calls to allocate free routines and improved memory locality.
dcfg size no.
of instructions x 020406080improvemen t key basic blocks x instructions 250dcfg size no.
o f basic blocks x1000 figure space optimization improvements vs. dcfg size summary and discussion our design goals in section .
were to devise a program representation that naturally and scalably generalizes existing representations allowsexistinganalysestobeextendedtodynamic codeinasimpleandnaturalway andispreciseenoughtodistinguishbetweenconceptuallydistinctdynamiccodemodifications.
dcfgs providea natural generalization ofthe well known notion of control flow graphs to dynamic code and thus satisfy the firstgoal.
section .
shows how we extend slicing to dynamic code inastraightforwardway therebysatisfyingthesecondgoal.for the third goal dcfgs allow us to distinguish the code structure of individualjit compiledfunctionsbyseparatingoutthedifferent codemodificationsindifferentdcfgphases withthespaceoptimizationsofsection4ensuringscalability codegendependencies then make it possible to identify and reason about the code components and value flows in the dynamic code generator relevant to thecodemodificationsineachsuchphase.asfarasweknow no other existing system can do this.
related work anckaert etal.describeaprogramrepresentationfordynamiccode that is capable of representing multiple versions of the code as it is modified during execution .
however this w ork does not have a notion of codegen dependencies and as a result is of limited utility for applications that involve reasoning aboutcausal relationships between the dynamic code generator and the dynamic code.
debray and yadegari discuss reasoning about control dependenciesininterpretedandjit compiledcode .whilethegoalsof thisworkaresimilartoours itstechnicaldetailsarequitedifferent.inparticular itdoesnotaimtoprovideaprogramrepresentationca pableofsupportingarbitrarydynamiccode butinsteadisnarrowly focused on control dependency analysis in interpretive systems.
it also makes assumptions such as the ability to map each dynam ically generated instruction to a unique byte code instruction it originatedfrom thatrender itinapplicable tocontexts notinvolving interpreters such as the dynamic code based environmental triggers discussed in sections .
and .
.
korczynski and yin discuss identifying code reuse injections usingwhole systemdynamictaintanalysis .whilethisworkcaptures codegen dependencies it does not propose a program representation that can capture the code structure for the different phases that arise during execution.
as a result this approach isnot suitable for analyses such as program slicing that require informationaboutthecontrolflowstructureofthecode.dallapredaetal.describeanotionofphasestocharacterizethesemanticsofselfmodifyingcode howeverthisworkwasneverimplemented and the technical details are very different from ours.
thereisalargebodyofliteratureonprogramslicing e.g.
see butallofthisworkfocusesonstaticcode.there is a lot of work on dependence and information flow analyses e.g.
see but these typically do not consider end toend analysis of dynamic code.
several authors have discussed taint propagationinjit compiledcode butfocusingontaintpropagationin just the application code rather than on end to end analyses .whole systemanalyses focusonissues relating to dynamic taint propagation through the entire computer system.
such systems provide end to end analyses but typically consideronlyexplicitinformationflows similarequaldatadependencies not implicitflows similarequalcontroldependencies theyarethusoflimiteduse forreasoningaboutbehaviors suchasconditionaldynamiccode modification i.e.
where the dynamic code generated may depend conditionally on input and or environmental values which are common in applications such as jit compilers.
thereareanumberofsystemsthatreasonaboutprogrambehavior using dynamic analysis and therefore are able to perform somekindsofanalysisondynamiccode .ourexperiments indicatethatthesesystemsdonotkeeptrackofmultipleversions ofcoderesultingfromdynamiccodemodification andsocannot fully capture the dependencies arising from runtime code changes.
caiet al.
and myreen discuss reasoning about dynamic code for the purposes of program verification using hoare logic.
wehavenotseenanyimplementationstoapplytheirworktowards modernsoftwarethatutilizesdynamiccode i.e.ajavascriptengine .
furthermore our work is more specific in that we seek to provide a program representation capable of representing dynamic code.
conclusions dynamiccodeisubiquitousintoday sworld.unfortuntely existing approaches to program analysis are not adequate for reasoning about the behavior of dynamic code.
this paper discusses how this problem can be addressed via a program representation suitablefor dynamic code as well as a new notion of dependencies that can capture dependencies between the dynamic code and the code that generated it.
experiments with a prototype implementation of backwardsdynamicslicingbasedontheseideasshow onanumber ofreal worldexamples thattheseideasmakeitpossibletowork backfromthefaultycodetothejitcompilerlogicthatledtothe generation of the faulty code.