buglistener identifying and synthesizing bug reports from collaborative live chats lin shi1 fangwen mu1 yumin zhang1 y ey a n g5 junjie chen6 xiao chen1 hanzhi jiang1 ziyou jiang1 qing wang1 1laboratory for internet software technologies institute of software chinese academy of sciences beijing china 2university of chinese academy of sciences beijing china 3state key laboratory of computer science institute of software chinese academy of sciences beijing china 4science technology on integrated information system laboratory institute of software chinese academy of sciences beijing china 5school of systems and enterprises stevens institute of technology hoboken nj usa 6tianjin university college of intelligence and computing tianjin china shilin fangwen2020 yumin2020 chenxiao2021 hanzhi2021 ziyou2019 wq iscas.ac.cn yyang4 stevens.edu junjiechen tju.edu.cn abstract in community based software development developers frequently relyonlive chattingtodiscussemergentbugs errorstheyencounter in daily development tasks.
however it remains a challenging task to accurately record such knowledge due to the noisy nature of interleaveddialogsinlivechatdata.inthispaper wefirstformulate thetaskofidentifyingandsynthesizingbugreportsfromcommunity live chats and propose a novel approach named buglistener toaddressthechallenges.specifically buglistenerautomatesthree sub tasks disentangle the dialogs from massive chat logs by usingafeed forwardneuralnetwork identifythebug report dialogs from separated dialogs by leveraging the graph neural network to learn the contextual information synthesize the bug reports by utilizing transfer learning techniques to classify the sentences into observed behaviors ob expected behaviors eb andstepstoreproducethebug sr .buglistenerisevaluatedonsix open source projects.
the results show that for bug report identification buglistenerachievestheaveragef1of77.
im provingthebestbaselineby12.
andforbugreportsynthesis task buglistener could classify the ob eb and sr sentences with thef1of84.
.
and73.
improvingthebestbaselinesby .
.
.
respectively.
a human evaluation study also confirmstheeffectivenessofbuglisteneringeneratingrelevantandaccuratebugreports.thesedemonstratethesignificantpotentialof applying buglistener in community based software development for promoting bug discovery and quality improvement.
corresponding author.
permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation on the first page.
copyrights for components of this work owned by others than acmmustbehonored.abstractingwithcreditispermitted.tocopyotherwise orrepublish topostonserversortoredistributetolists requirespriorspecificpermissionand ora fee.
request permissions from permissions acm.org.
icse may pittsburgh pa usa association for computing machinery.
acm isbn ... .
bug report generation live chats mining open source acm reference format linshi1 fangwenmu1 yuminzhang1 yeyang5 junjiechen6 xiao chen1 hanzhijiang1 ziyoujiang1 qingwang1 .
.
buglistener identifyingandsynthesizingbugreportsfromcollaborativelivechats .in44thinternationalconferenceonsoftwareengineering icse may pittsburgh pa usa.
acm new york ny usa pages.
https introduction collaborative communication via live chats allows developers to seek information and technicalsupport share opinions and ideas discuss issues and form community development in a moreefficientwaycomparedwithasynchronouscommunication suchasemailsorforums .consequently collaborative livechattinghasbecomeanintegralpartofmostsoftwaredevelopmentprocesses notonlyforopensourcecommunitiesconstituting globally distributed developers but also for software companies to facilitatein houseteamcommunicationandcoordination esp.in accommodating remote work due to the covid pandemic .
existingliteraturereportsthatdevelopersarelikelytojoincollaborative live chats to discuss problems they encountered during development .
shi et al.
analyzed live chat dialogs from eight oss communities and found of the dialogs are reporting unexpected behaviors such as something does not work reliabilityissues performanceissues anderrors.infact these reportingproblemsusuallyimplypotentialbugsthathavenotbeen found.
fig.
illustrates an example slice of collaborative live chats from the docker community.
in this conversation developer davidreportedaperformancebugthatdockertookalotofdisk space and lena indeed confirmed david s feedback.
then jack provided a suggestion to help resolve this problem but failed in the end.
althoughdevelopers haverevealed this bugvia collaborative livechats thehighlydynamicandmulti threadingnatureoflive chattingmakesthisbug reportconversationgetquicklyfloodedby new incoming messages.
after several months docker developers calltoremembrancethisbugwiththefrustratedcommentssuch as lost all my system backups and it s a shame when thereare several formal bug reports i.e.
and ieee acm 44th international conference on software engineering icse icse may pittsburgh pa usa lin shi et al.
dylg hf wklqn kdyh vrphwklqj lpsruwdqw wr vd w v wkh vhfrqg wlph wkdw wklv kdsshqv zlwk ph lqvwdoo grfnhu rq lqx 0lqw iwhu vrph krxuv wkh glvn lv ixoo orvw doo p v vwhp edfnxsv wklqn kdyh wr uhsruw wklv ehfdxvh lw v d vkdph khq ghohwh doo grfnhu lpdjhv dqg xqlqvwdoo grfnhu kdyh iuhh 6rphrqh whoov ph rz wklv lv hyhq srvvleoh wkdw grfnhu xvhv dq grfnhu dyrlg xvlqj vxfk kxjh glvn 3ohdvh il wkdw 8qwlo wkhuh zloo eh xvlqj grfnhu rq d yluwxdo pdfklqh ehfdx vh fdq w wuxvw wklv vriwzduh dq pruh hf juhdw ihhgedfn hqd dfn hf dfn rhvq w pdnh dq vhqvh iwhu uhvwduw p frpsxwhu wkh glvn iuhh vsdfh nhhsv ghfuhdvlqj hf dylg lw vrxqgv olnh rx shuiruphg d lqvwhdg ri d dqg hqghg xs iloolqj rxu glvn grfnhu sxoo vrphkxjhuhsrvlwru grfnhu sxoo vrphkxjhuhsrvlwru vshflilfwdj dylg hvfulswlrq kdyh vrphwklqj lpsruwdqw wr vd w v wkh vhfrqg wlph wkdw wklv kdsshqv zlwk ph orvw doo p v vwhp edfnxsv wklqn kdyh wr uhsruw wklv ehfdxvh lw v d vkdph khq ghohw h doo grfnhu lpdjhv dqg xqlqvwdoo grfnhu kdyh iuhh rz wklv lv hyhq srvvleoh wkdw grf nhu xvhv 8qwlo wkhuh zloo eh xvlqj grfnhu rq d yluwxdo pdfklqh ehfdxvh fdq w wuxvw wklv vriwzduh dq pruh 2evhuyhg hkdylru iwhu vrph krxuv wkh glvn lv ixoo shfwhg hkdylru dq grfnhu dyrlg xvlqj vxfk kxjh glvn 6whsv wr uhsurgxfh lqvwdoo grfnhu rq lqx 0lqw fig.
an example of identifying and synthesizing a bug report from the docker collaborative live chats.
reflecting the similar problem that was submitted to the github bug repository.
we can observe that if the bug discussed in live chatscouldbeidentifiedanddocumentedinatimelymanner the bugmayhavebeenresolvedearlierbythedockercommunity.consequently the docker community may have the opportunity to prevent many failure incidents associated with this bug .
althoughthelivechatscouldbeatremendousdatasourceembedded withbug reportsover time it is quitechallenging tomine massivechatmessagesduetothefollowingbarriers.
entangled andnoisydata.livechatstypicallycontainentangled informal conversationscoveringawiderangeoftopics .moreover there exist noisy utterances such as duplicate and off topic messagesin chat messages that do not provide any valuable information.such entangled and noisy nature of live chat data poses a difficultyinanalyzingandinterpretingthecommunicativedialogues.
understanding complex dialog structure .
in complex dialogs developersusuallyeitherconfirmorrejectabugreportby replying to previous utterances.
since the reply to relationship is not linear to the dialog structure it is necessary to employ moresophisticated techniques to handle nonlinear dialog structure in orderto learnprecise feedback andreduce thelikelihoodof introducing false positive.for example the utterance when iuse the automationname key i get an error that it is not a recognized w3c capability.
is very likely to be classified as a bug proposal.
however when examining the dialog we found that the followingup utterances pointed out the error was not a valid bug.
instead it was caused by the user s action of importing incorrect packages.
extremelyexpensiveannotation.thelivechatsaretypically largeinsize.itisextremelyexpensivetoannotatebugreportsfrom chat messages due to the high volume corpus and a low propor tion of ground truth data.
only a few labeled chat messages are categorizedintobugreporttypes.thus thelabeledresourcesforsynthesizingbugreportsarealsolimited.howtomakemaximaluse ofthelimitedlabeleddatatoclassifytheunlabeledchatmessages accurately becomes a critical problem.
in this work we propose a novel approach named buglistener whichcanidentifybug reportdialogsfrommassivechatlogsand synthesize complete bug reports from predicted bug report dialogs.
buglisteneremploysadeepgraph basednetworktocapturethe complexdialog structure and atransfer learning networkto synthesize bug reports.
specifically buglistener addresses the challengeswiththree elaboratedsub tasks disentanglethe dialogs frommassivechatlogsbyusingafeed forwardneuralnetwork.
identify bug report dialogs from separated dialogs by modeling theoriginaldialogtothegraph structureddialogandleveraging the graph neural network gnn to learn the complex context representation.
synthesizethebugreportsfrompredictedbugreport dialogs using transfer learning techniques.
specifically we use the pre trained bert model provided by devlin et al.
and fine tune it twice using the external bee dataset and our owndataset respectively.toevaluatetheproposedapproach we collect and annotate dialogs from six popular open source projects.
the experimental results show that our approach significantlyoutperformsallotherbaselinesinbothtwotasks.forbug report identification task buglistener achieves an average f1 of .
improving the best baseline by .
.
for bug report synthesistask buglistenercouldclassifysentencesdepictingobserved behavior ob expected behavior eb and steps to reproduce sr with the f1 of .
.
and .
respectively improving thebestbaselineby9.
.
and10.
respectively.wealsoconductahumanevaluationtoassessthecorrectnessandqualityof the generated bug reports showing that buglistener can generate relevant and accurate bug reports.
the main contributions and their significance are as follows.
we propose an automated approach named buglistener based on a deep graph based network to effectively identify the bug report dialogs and a transfer learning network to extensively synthesizebugreports.webelievethatbuglistenercan facilitatecommunity basedsoftwaredevelopmentbypromoting bug discovery and quality improvement.
we evaluate the buglistener by comparing with state of the art baselines with superior performance.
dataavailability publiclyaccessibledatasetandsourcecode to facilitate the replication of our study and its application in other contexts.
in the remaining of this paper sec.
defines the problem.
sec.
elaboratestheapproach.sec.4presentstheexperimentalsetup.sec.5demonstratestheresultsandanalysis.sec.6describesthehuman evaluation.
sec.
discusses indications and threats to validity.
sec.
introduces the related work.
sec.
concludes our work.
problem definition to facilitate the problem definition and further discussion we first provide some basic concepts and notations used in this study a chat log l corresponds to a sequence of utterances uiin chronological order denoted by l u1 u2 ... un .
anutterance ui consistsofthetimestamp developerrole and textual message denoted by ui time role text .
adeveloperrole role inadialogisdefinedaseithera reporter oradiscussant.a reporterreferstoadeveloperlaunchingadialog whileadiscussant referstoadeveloperparticipatinginthedialog.
denoted by role reporter discussant .
a dialog di is a sequence of kutterances ui retaining the reply to relationshipamongutterances denotedby di ur1 ur2 ... urk k .
arelationalcontextforutterance ui ri isasetofundirected reply to relationshipidentifiers eachidentifiercorresponding to a message replying to or replied by ui.
if two utterances share the same superscript then it implies one replies to the other.
for example d ur1 r2 ur1 ur2 represents that both u2andu3 reply to u1.
our work then targets at automatically identifying and synthesizing bug reports from community live chats.
we formulate the task of automatic bug report generation from live chats with three elaborated sub tasks dialogdisentanglement giventhehistoricalchatlog l disentangle it into separate dialogs d1 d2 ... dn .
bug reportdialogidentification bri givenaseparatedialog di findabinaryfunction fsothat f di candeterminewhether the dialog involves bug reporting messages.
bug report synthesis brs assuming that the content of bugreportsismadeupofsentencesextractedfromthereporters utterances givenallthereporter sutterances urinthepredictedbugreportdialog di findafunction gsothatg ur des ob eb sr wheredes ob eb andsrrepresentthecollectionsofsentences inurthat depict description observed behavior expected behavior andstep to reproduce.
approach therearefivemainstepstoconstructbuglistener asshowninfig.
.
these include dialog disentanglement and data augmentation to prepare the data utterance embedding to convert utterances intosemanticvectors graph basedcontextembeddingtoconstruct dialog graph and learn the contextual representation by employing a two layer graph neural network dialog embedding andclassificationtolearnwhetheradialogisabug reportdialog and bugreportsynthesistoformacompletebugreport.next we present details of each step.
.
data disentanglement and augmentation in this step we first separate dialogs from the interleaved chat logsusingafeed forwardnetwork.then weaugmenttheoriginal dialog dataset utilizing a heuristic data augmentation method to overcome the insufficient labeled resource challenge.
.
.
dialog disentanglement.
utterances from a single conversation thread are usually interleaved with other ongoing conver sations and therefore need to be divided into individual dialogsaccordingly.
to find a reliable disentanglement model we exper iment with four state of the art dialog disentanglement models i.e.
bilstm model bert model e2e model and ff model using our manual disentanglement dataset as detailed insection4.1later.thecomparisonresultsfromourexperiments show that the ff model significantly outperforms the others on disentanglingdeveloperlivechatbyachievingthehighestscoresonnmi shen f f1 andarimetrics.theaveragescoresofthese four metrics are .
.
.
and .
respectively1.
specifically the ff model is a feed forward neural network with layers dimensional hidden vectors and softsign nonlinearities.
it employs a two stage strategy to resolve dialog disentanglement.
first the ff model predicts the reply to relationship between every two utterances in the chat log based on averaged pre trained word embedding and many hand engineered features.
second it clusters the utterances that can reach each other via the reply to predictions as one dialog.
thus the ff model can output not only the utterances in one dialog but also their reply to relationship whichisessentialforconstructingtheinternalnetwork structure of dialogs.
.
.
data augmentation.
toaddressthelimitedannotationand data imbalance issue a heuristic data augmentation mechanism is employed to enlarge the dataset through dialog mutation.
the key todialogmutationistoaltertheutteranceformsandretaintheir semantics.toachievethat wemutatealongutterancebyreplacing a few words with their synonyms or mutate a short utteranceby replacing it with another short utterance.
specifically givena dialog d u1 u2 ... un we generate ndifferent mutants by iterating the following steps ntimes.
for each utterance uiin a dialogd we perform either an utterance level replacement or a word level replacement based on its length and generate a new utterance ui prime ui ui d ui braceleftbigg uk ui sr ui ui where ui denotes the length of ui and is a predefined threshold we empiricallyset 5inthisstudy .
ukistheutterancethatis randomly selected from the entire dialog corpus with a length less than .sr ui denotes the synonym replacement operation that hasbeenwidelyusedbynlptextaugmentationtask .afterall utterances in dialog dare processed we then obtain a new dialog daug u1 prime u2 prime ... un prime .
toachievedatabalancing foreachproject wefirstaugmentthe nbrdialogstoacertainnumber thenweaugmentbrdialogsto matchthesamenumber.takingtheangularprojectasanexample wefirstaugmentthenbrdialogsfrom179to358 2times then augment the br dialogs from to for balancing purposes.
.
utterance embedding the utterance embedding aims to encode semantic information of words as well as to learn the representation of utterances.
word encoding.
we encode each word in utterances into a semantic vector by utilizing the deep pre trained bert model whichhasachievedimpressivesuccessinmanynaturallanguage processingtasks .thelastlayerofthebertmodeloutputs a dimensional contextualized word embedding for each word.
utteranceencoding.
withallthewordvectors weusetextcnn tolearntheutterancerepresentation.textcnnisaclassical method for sentence encoding by using a shallow convolutionneural network cnn to learn sentence representation.
it hasanadvantageoverlearningoninsufficientlabeleddata since 1duetospace experimentaldetailsonevaluationexistingdisentanglementmodels are provided on our website .
301icse may pittsburgh pa usa lin shi et al.
x x x3.
.
utterance embedding .
dialog di sentanglement and augmentation dialog d .
graph based co ntext embedding dialog d construct dialog graph g ... ... berttextcnn ...... ... ... embed graph context ... ... ... label nbr3.
dialog embeddin g and classification .
bug reports synthesisdialog d chat log data augmentation augmented dialog datasetdialog datasetdialog disentanglement... dialog embedding fc layersum pooling softmax label brmax pooling des xxxx ob xxxxeb xxxxsr xxxx bug reportoblarge annotated bug reports externel eb sr desbug report dialogs internel genglish wikipedia and bookscorpus externel prune reporter s utterances fc layerfine tuned bert fc layertwice fine tuned bertpre trained bert fig.
overview of buglistener.
itemploysaconcisenetworkstructureandasmallnumberofparameters.weusefourdifferentsizeconvolutionkernelswith100 featuremapsineachkernel.theconvolutedfeaturesarefedtoa max pooling layer followed by the reluactivation .
then we concatenate these features and input them into a dimensional full connectedlayertoobtainthe100 dimensionalutteranceembedding vecui.
after encoding all the utterances of a dialog d we can get utterance embedded dialog d prime vecu1 vecu2 .. vecun .
.
graph based context embedding thisstepaimstocapturethegraphicalcontextofutterancesinone dialog.
given the utterance embedded dialog d prime vecu1 vecu2 .. vecun with the set of reply to relationship r we first construct a dialog graphg d prime .
then we learn the contextual information of g d prime via a two layer graph neural network and output gc d prime where each vertex in gc d prime restores the contextual information of the correspondingvertexin g d prime .finally weconcatenateeachvertex ing d prime withitscorrespondingvertexin gc d prime andoutputthe sequence of combination as the dialog vector c vecc1 vecc2 ... veccn .
.
.
construct dialog graph.
giventheutterance embeddeddialogd primeconsisting of nutterances and the set of reply to relationshipr weconstructadirectedgraph g d prime v e w t wherevisthevertexset eistheedgeset wistheweightsetof edges and tis the set of edge types.
more specifically vertex.eachutteranceisrepresentedasavertex vi v.w euse theutteranceembedding vecuitoinitializethecorrespondingvertex vi.
theviwill be updated during the graph learning process.
edge.we construct the edge set ebased on the reply to relationship.
the edge eij edenotes that there is a reply to relationship between uianduj.
edge weight.
the edge weight wijis the weight of the edge eij with wij where wij wandi j .
wijis determined by the similarity of vecuiand vecuj.
specifically we employ pair wise dot product to compute the similarity score of pair vertices.
then we normalize the similarity score and calculate the edge weight wij wij vecuit we vecuj summationtext.
k n i vecuit we vecuk whereweisatrainablematrixusedtoperformlinearfeaturetransformationonvertex n i denotesthesetofverticesthatvertex vipoints to.
edgetype.
wedefinethetypeoftheedge eijastij t accordingtothe developer roledependency ofeij.specifically weconsider four types of edges in this study i.e.
r r r d d r and d d where rdenotesthereporter ddenotesthediscussant as we defined in the previous section.
.
.
embed dialog graph context.
givenadialoggraph g d prime weemployatwo layergraphneuralnetwork gnn toembed the graph context of dialog structure and developer role dependency respectively.
we output gc d prime where each vertex restores graph context information.
structure levelgnn.
inthefirstlayer abasicgnn isused tolearnthestructure levelcontextforeachvertexinagivengraph including embedding its neighbor vertices via the reply to edges as well as the features contained in the neighbor vertices.
a basic gnn layer can be implemented as follows vi l parenleftbigg w l 1vi l w l summationdisplay.
j n i vj l parenrightbigg where n i denotes the set of neighboring vertices that point to vertex vi.vi l represents the updated vertex at layer l and vi l represents the updated vertex at layer l .
denotes a non linearfunction suchassigmoidorrelu w l 1andw l 2are trainable parameter matrices.
we introduce the edge weights to betteraggregatethelocalinformation.hence theupdatedvertex vi of the structure level gnn layer is calculated as vi parenleftbigg w vecui w summationdisplay.
j n i wji vecuj parenrightbigg wherewjidenotes the edge weight from vertex vjto vertex vi.
role levelrgcn.
inthesecondlayer wefurthercapturethe high levelcontextualinformationbyleveragingrelationalgraph convolutional networks rgcn .
rgcn is a generalization ofgraphconvolutionalnetworks gcn whichextendsthe hierarchical propagation rules and takes the edge types between 302vertices into account.
since rgcn explicitly models the neighborhood structures it can better handle multi relational graph data likeourdialoggraph whichcontainsfouredgetypes.thevertex vi is updated by applying the rgcn over the output of the first layer.
vi parenleftbigg w 1vi summationdisplay.
t t summationdisplay.
j nt i ci tw tvj parenrightbigg wherent i denotesthesetofverticesthatpointtovertex viunder edge type t t.ci tis a normalization constant that can either be learnedorsetinadvance suchas ci t nt i .
denotesanonlinear function w l 2andw l tare trainable parameter matrices the latter matrix changes under different edge types.
the output of role level rgcn is the gc d prime where each vertex virestores the embedded graph context vechifor utterance ui.
.
.
combined representation.
to enrich the utterance representation weconcatenateeachvertexin g d prime withitscorresponding vertexin gc d prime andoutputthesequenceofcombinationasthe dialog vector c vecc1 vecc2 ... veccn where vecci and is the concatenation operator.
.
dialog embedding and classification this step aims to obtain the representation of an entire dialog and classify it as either a positive or a negative bug report dialog.
dialogembedding.
weinputthedialogvector c vecc1 vecc2 ... veccn tothesum pooling andthemax pooling layerrespectively.then we concatenate the output vectors to get the dialog embedding vecg vecg v summationdisplay.
i vecci maxpooling vecc1 ... veccn where is the concatenation operator v is the number of the graph s vertices.
dialog classification.
the label is predicted by feeding the dialogembedding vecgintotwofull connected fc layersfollowed by thesoftmaxfunction p softmax fc2 relu fc1 vecge wherepisthe2 lengthvector thep nbr d is the predicted probability of non bug report dialog the p br d is the predicted probability of bug report dialog.
finally weminimizethelossthroughthefocalloss function.
the focal loss improves the standard cross entropy loss by addinga focusingparameter .itfocuseson trainingon hard examples while down weight the easy examples.
fl summationdisplay.
i i pi yilog pi whereyiis thei th element of the one hot ground truth label br or nbr iand are tunable parameters.
.
bug report synthesis due to the high volume of live chat data and the low proportion of ground truthbug reportdialogs itisdifficulttogetenoughtraining data for bug report synthesis task.
to address this challenge we utilizeatwicefine tunedbertmodel whichprovestobeeffective toimproveperformancethroughmoresophisticatedtransferringknowledge from the pre trained model .
specifically we use apre trainedbertandfine tuneittwiceusingtheexternalbee dataset and our brs dataset as shown in the dashed box of .
in fig.
.
initial fine tuning bert model.
the bert model is a bidirectional transformer using a combination of masked languagemodel andnextsentenceprediction.itistrainedfromenglish wikipedia 500m words and bookscropus 800m words .
theentirebertmodelisastackof12bertlayerswithmorethan million parameters.
based on an assumption that the contents of bug reports are likely from the reporters utterances we perform the initial finetune on the task of classifying bug report contents into ob eb sr andothers.first weselecttheexternalbeedatasetproposedby songetal.
thatincludes5 067bugreports 776obsentences 568ebsentences and24 655srsentencesasthesourcedataset.
second followingthepreviousstudy wepreprocesssentences inthe5 076bugreportswithlowercase tokenization excludingnonenglishandoverlong over200words ones.third wefreezethe firstninelayersofthepre trainedbertandupdatetheparameters ofthelastthreelayersviathesentencesinthe5 076bugreports.we take the output of the first token the token as the sentence embedding.
finally we input the sentence embedding into a fc layertoproducetheprobabilitiesofob pb eb pe sr ps and others po .
we apply cross entropy loss when measuring the difference between truth and prediction loss yblog pb yelog pe yslog ps yolog po whereyb ye ys andyoindicate the ground truth labels of sentences.
twice fine tuning bert model.
given the above finetuned bert model we perform the second round of fine tuningon our brs dataset as follows.
we first collect all the reporter sutterances urin dialog das our inputs.
since urmay contain trivial contents that are less meaningful for reporting bugs we prunethe urintou primeriftheysatisfythefollowingheuristicrules remove the sentence sif length s and sdoes not contain or removethe stringstrfromitssentenceif str hi hiall heythere hi everybody hey guys hi guys guys hi there thank you thanks thanks anyway thanks for replaying ok thanks etc.
.second wetransferthebertmodelpreviouslyfine tunedon the external bug report dataset for initialization and replace theoriginal fc layer with a new one.
third the bert model is finetunedthesecondtimevialabeledsentencesin u primerusingasmaller learning rate.
bug reports assembling.
when generating bug reports weassemblesentencesthatarepredictedtothesamecategoryin chronological order.
to fully retain the useful information in u primer we assemble all the sentences that belong to the others category asthedescriptionparagraph.intheend wecouldgenerateabug reportwithitsdescription observedbehavior expectedbehavior and step to reproduce according to best practices for bug reporting .
303icse may pittsburgh pa usa lin shi et al.
experimental design to evaluate the proposed buglistener approach our evaluation specifically addresses three research questions rq1 how effective is buglistener in identifying bug report dialogs from live chat data?
rq2 how effective is buglistener in synthesizing bug reports?
rq3 how does each individual component in buglistener contribute to the overall performance?
.
data preparation .
.
studied communities.
many oss communities utilize gitter or slack as their live communication means.
considering the popular open and free access nature we select studied communities from gitter2.
following previouswork weselect popularandactivecommunitiesasourstudiedsubjects.specifically we select the top most participated communities from six active domains coveringfrontendframework mobile datascience devops collaboration andprogramming language.then we collect the live chat utterances from these communities.
gitter provides restapi togetdataaboutchattingroomsandpostutterances.
inthisstudy weusetherestapitoacquirethechatutterances of the six selected communities and the retrieved dataset contains all utterances as of .
.
.
preprocessing and disentanglement.
fordatapreprocessing we first convert all the words in utterances into lowercase and removethestopwords.wealsonormalizethecontractionsinutterances with contractions library and use spacy for lemmatization.followingpreviouswork wereplacetheemojiswith specific strings to standard ascii strings.
besides we detect low frequencytokenssuchasurl emailaddress code htmltag and version number with regular expressions and substitute them into and respectively.
then we usetheffmodel todivide theprocesseddatainto individual dialogs as introduced in sec.
.
.
.
the detailed statistic is shown in the entire population column of table .
.
.
sampling and filtering.
after dialog disentanglement the numberof individualchatdialogs remainsquite large.limitedby thehumanresourceoflabeling werandomlysample100dialogs from each community.
the samplepopulation accounts for about .
of the entire population.
although the ratio is not large we considertheselecteddialogsarerepresentativebecausetheyarerandomly selected from six diverse communities.
the details of sampling results are shown in the sample population column of table .
sincebuglistenerreliesonnaturallanguageprocessingtounderstand the dialog dialogs that have too much noise or do not contain enough information are almost incomprehensible and thus cannotdecideabugreport.followingthedatacleaningprocedures of previous studies we excluded noisy dialogs by applyingthefollowingexclusioncriteria dialogsthatarewrittenin non englishlanguages dialogswherethecodeorstacktracesac countsformorethan90 oftheentirechatcontent low quality dialogssuchasdialogswithmanytyposandgrammaticalerrors.
2inslack communitiesarecontrolledbytheteamadministrators whereasingitter access to the chat data is public4 dialogsthatinvolvechannelrobotswhichmainhandlesimple greeting or general information messages.
.
.
ground truth labeling.
for each sampled dialog obtained in thepreviousstep welabelground truthdatafromthreeaspects correct disentanglement results.
for each sampled dialog we manually correct the prediction of the reply to relationships between utterances as well as the disentanglement results.
label dialogs with br and nbr see the sample population column in table .
for each dialog that has been manually corrected we manually labelitwitha br oran nbr tag accordingtowhetheritdiscusses a certain bug that should be reported.
label sentences with ob eb and sr see the brs dataset column in table .
for each dialoglabeledwithbr wefirstpruneallreporter sutterances ur toobtain u primerasdescribedinsec.
.
.thenwelabeleachsentence inu primerwith observed behavior ob expected behavior eb and step to reproduce sr according to their contents.
to ensure the labeling validity we built an inspection team whichconsistedoffourphdstudents.allofthemarefluentenglishspeakers andhavedoneeitherintensiveresearchworkwith software development or have been actively contributing to opensourceprojects.wedividedthemintotwogroups.theresultsfrom both groups were cross checked and reviewed.
when a labeled resultreceiveddifferentopinions wehostedadiscussionwithall team members to decide through voting.
based on our observation thecorrectnessofautomateddialogdisentanglementis79 .the average cohen s kappa about bug report identification is .
and the average cohen s kappa about bug report synthesis is .
.
.
.
dataset augmentation and balancing.
forbritask weaugment the dataset as introduced in sec.
.
.
for each project we first augment the nbr data eight times and then augment the br data until br and nbr data are balanced.
the details are shownin the bri dataset column in table .
for brs task we apply eda techniquestoaugmentob eb srsentencesuntiltheir numbers are balanced.we further incorporatean external dataset fortransferlearning.theexternaldatasetisprovidedbysongetal.
including5 067bugreportswith11 776obsentences eb sentences and sr sentences.
.
baselines the first two rqs require comparison with state of the art baselines.weemployfourcommonmachine learning basedbaselines applicableto bothrq1andrq2 including naivebayesian nb random forest rf gradient boosting decision tree gbdt andfasttext .
in addition we employ several baselines applicable to rq1 and rq2 respectively.
additionalbaselinesforidentifyingbug reportdialogs rq1 .furthermore we also consider some existing approaches that can identify sentences or mini stories which are discussing problems.
cnc isthestate of the artlearningtechniqueto classify sentences in comments taken from online issue reports.
they proposed a cnn based approach to classify sentences intosevencategoriesofintentions featurerequest solutionproposal problemdiscovery etc.toachievebetterperformanceofthecncbaseline weretrainthecncmodelonourbridataset.weas semblealltheutterancesinadialogasanentry andpredictwhether 304buglistener identifying and synthesizing bug reports from collaborative live chats icse may pittsburgh pa usa table1 ourexperimentdataset.
part dial uttr senareshortforparticipatingdevelopers dialog utterance andsentence respectively.
br and nbr denote bug report and non bug report dialogs.
urdenotes sentences in reporter s utterances and u primer denotes the pruned ur.
samplepopulation bridataset brsdatasetentire populationnbr br augmented nbr augmented br brdialog reporter sen. brcontent project part.
dial.
uttr dial.uttr.dial.uttrdial.
uttr.dial.
uttrdial.sen.urur obebsrdes angular appium docker dl4j gitter typescript total table baseline comparison across the six communities for bug report dialog identification .
angular appium docker dl4j gitter typescript averagemethodsprf1prf1prf1prf1prf1prf1prf1 buglistener .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
nb .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
gbdt72.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
rf .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
fasttext77.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
cnc .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
deca .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
casper67.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
the entry belongs to problem discovery.
deca is the state ofthe art rule basedtechnique foranalyzing development emails.it isusedtoclassifythesentencesofemailsintoproblemdiscovery solutionproposal informationgiving etc.
byusinglinguisticrules.
we use the twenty eight linguistic rules for identifying the problem discovery utterances in a dialog and regard the dialog containing the problem discovery utterances as the bug report dialog.casper is a method for extracting and synthesizing user reportedmini storiesregardingappproblemsfromreviews.
similartothecncbaseline wealsoretrainthecaspermodelon the bri dataset and apply it to determine bug report dialogs by assembling all the utterances in a dialog as one entry.
additionalbaselineforsynthesizingbugreports rq2 .
we investigatedsevenstate of the artapproachesforthebugreport synthesistask includingcuezilla demlbud itape s2rminer infozilla euler and bee .
among theaboveapproaches onlythereplicationpackagesfromitape s2rminer andbee areavailable.since itapeand s2rminer classify sr sentences and only bee share the same target with us thatistoclassify ob eb sr andothersentencesforbugreports.
therefore wechoosebeeasouradditionalbaselinesforbugreport synthesis.beecomprisesthreebinaryclassificationsvm which can tag sentences with ob eb or sr labels.
thisleadstoatotalofsevenbaselinesforrq1 andfivebaselines for rq2.
.
evaluation metrics we use three commonly used metrics to evaluate the performance ofbothtwotasks i.e.
precision recall andf1.
precisionrefersto theratioofthenumberofcorrectpredictionstothetotalnumber ofpredictions recallreferstotheratioofthenumberofcorrect predictions to the total number of samples in the golden test set and f1is the harmonic mean of precision and recall.
whencomparing the performances we care more about f1 since it is balanced for evaluation.
.
experiment settings the experimental environment is a desktop computer equipped with an nvidia geforce rtx gpu intel core i5 cpu 12gb ram running on ubuntu os.
forrq1 weapply cross projectevaluation onourbridatasetto perform the training process.
we iteratively select one project as a test dataset and the remaining five projects for training.
we train buglistener with batch size.
we choose adamas the optimizer withlearning rate 1e .
to avoid over fitting we set dropout .
andadoptthe l2 regularization with 1e .the and offocal lossfunctionare0and2 respectively.whentraininggbdt we set thelearning rate .
and the n estimators for rf we set themin samples leaf 10andthe n estimators wetrain100 epochs for fasttext and set the learning rate .
the window sizeofinputn gramas2 casperchooses svm.svc asthedefault function with rbfas the kernel as the degree and as the cache size cnc selects as the batch size dimensional word embedding fourdifferentfiltersizesof with128filters 30trainingepochs and dropout .
.forthesehyper parameters we use greedy search as the parameter selection method to obtain the best performance.
forrq2 inthefirstfine tuneround wetrainbuglisteneronthe external bee dataset see sec.
.
.
with batch size.
we set the warmupproportionofbertmodelto0.
andthevalueofgradient clipto1.
.wechoose adamastheoptimizerwith learning rate 1e4andweightdecayrate .
.wetrainbuglistenerfor13epochs and save the best model.
in the second fine tune round we usethe same parameters while changing the batch size from to theepochfrom to and the learning rate from 1e to 1e .
we apply a fold partition on the brs dataset to perform the secondaryfine tuning i.e.
weuseninefoldsforfine tuning and 305icse may pittsburgh pa usa lin shi et al.
theremainingonefortesting.fornb gdbt rf fasttextbaselines we usethe greedy strategyto tune parametersto achieve the best performance.
for the additional baseline bee we directly utilize its open api to predict ob eb and sr sentences.
forrq3 wecomparebuglistenerwithitstwovariantsinbugreport identification task buglistener w o cnn which removes thetextcnn.
buglistenerw ognn whichremovesthegraph neural network.
buglistener with its two variants use the same parameters when training.
we compare buglistener with its variant without transferring knowledge from the external bee dataset i.e.
buglistener w o tl in bug report synthesis task.
buglistener w o tl has the same network structure with buglistener but it doesnotusetheexternalbeedatasetandisonlyfine tunedonour brs dataset.
results and analysis .
performance in identifying bug reports table shows the comparison results between the performance ofbuglistenerandthoseofthesevenbaselinesacrossdatafrom six oss communities for britasks.
the columns correspond to precision recall and f1.
the highlighted cells indicate the best performancefromeachcolumn.then weconductthenormality testandt testbetweeneverytwomethods.overall thedatafollows anormaldistribution andbuglistenersignificantly p value .
outperforms the seven baselines on f1.
specifically when comparing with the best precision performer among the seven baselines i.e.
cnc buglistener can improve its average precision by6.
.similarly buglistenerimprovesthebestrecall performer i.e.
casper by .
for average recall and improves the best f1performer i.e.
cnc by .
for average f1.
at the individualproject level buglistener can achieve the best f1 score in all six communities.
forbri tasks we believe that the performance advantage of buglistenerismainlyattributedtotherichrepresentativenessof its internal construction from two perspectives buglistenermodels the textual dialog as the dialog graph thereby can effectively exploit the graph structured knowledge.
while the structure informationismissinginthebaselinemethodsthattreatadialog as a linear structure.
buglistener leverages a novel two layer gnnmodelwithconsideringtheedgetypesbetweenutterancesto learn a high level contextual representation.
thus it can capture the latent semantic relations between utterances more accurately.
answering rq1 on average buglistener has the best precision recall and f1 i.e.
.
.
and .
improving the best f1 baseline cnc by .
.
on individual projects it also outperformstheotherbaselineswithachievingthebestf1 score in all six communities.
.
performance in synthesizing bug reports fig.
summarizes the comparison results between the averageperformance of buglistener and the five baselines for brstask.
we can see that buglistener can achieve the highest performance in predicting ob eb and sr sentences.
it outperforms the six baselinesintermsoff1.forpredictingobsentences itreachesthe highest f1 .
improving the best baseline fasttext by .
.
for predicting eb sentences it reaches the highest f1 .
g1 g2 g1 g3 g1 g4 g1 g5 g1 g6 g1 g7 g1 g8 g1 g9 g1 g10 g1 g2 g1 g1 g11 g28 g22 g16 g23 g26 g27 g21 g24 g21 g25 g14 g20 g26 g27 g19 g21 g29 g27 g18 g14 g15 g11 g12 g19 g17 g11 g11 g13 g13 g14 g12 g13 g12 g16 g15 g9 g5 g1 g10 g7 g1 g9 g3 g1 g9 g7 g1 g7 g11 g1 g8 g4 g1 g9 g2 g1 g7 g8 g1 g7 g6 g1 g9 g4 g1 g7 g6 g1 g6 g11 g1 g9 g4 g1 g7 g5 g1 g7 g4 g1 g8 g11 g1 g9 g1 g3 g6 g1 fig.
baseline comparison for bug report synthesis.
improvingthe bestbaseline fasttextby12.
.
forpredicting sr sentences it reaches the highest f1 .
improving the best baseline fasttext by .
.
ourapproachismoreeffectivetoclassifyob eb andsrsentences in live chats than others mainly due to two reasons by leveraging the transfer learning technique buglistener can obtain generalknowledgefromexistingbugreports thuswouldfurther boosttheclassificationperformancesonthelimitedresource.
by employing the state of the art bert model which has a strong abilitytolearnsemanticsviathetransformerstructure buglistener can capture richer semantic features in word and sentence vectors.
wenoticethatfasttextachievethesecondperformances.these resultsaremainlyduetothat fasttextcanbetterunderstandthe contextbycapturingtheneighborwordsusingafixed sizewindow whenembeddingwords.wealsonoticethatbeeperformstheworst on predictingeb average f1is only7 .
these resultsare mainly due to that bee is trained from the external normal bug reports dataset and the expression style for eb sentences is quite different betweenthoseinnormalbugreportsandthoseinliveconversations.
theebsentencesinbugreportsarelikelyexpressedinadeclarative tonethatstatethereporter sexpectationasanobjectivefact e.g.
i wishdockercansavediskusage .whileinlivechats ebsentences aremorelikelyexpressedinaninterrogativetonethatthereporters inquiry or ask for a reply e.g.
can docker avoid using such huge disk?
.
therefore it is difficult for bee to predict eb sentences correctly on live chat data.
answering rq2 buglistener outperforms the six baselines in predicting ob eb and sr sentences in terms of f1.
the three categories averageprecision recall andf1are75.
.
and .
respectively.
.
effects of main components fig.
a presentstheperformancesofbuglisteneranditstwovariantsforbritask.wecanseethat thef1 performanceofbuglistener is higher than all two variants across all the six communities.
whencomparedwithbuglistenerandbuglistenerw ognn removingthegnncomponentwillleadtoadramaticdecreaseofthe averagef1 by17.
acrossallthecommunities.thisindicates that the gnn is an essential component to contribute to buglistener s high performances.
when compared with buglistener and buglistener w o cnn removing the textcnn component will lead to the average f1 declines by .
.
it is mainly because the textcnn model can capture the intra utterance semantic features which improves the classification performance.
306buglistener identifying and synthesizing bug reports from collaborative live chats icse may pittsburgh pa usa qjxodu sslxp rfnhu lwwhu shvfulsw xj lvwhqhu xj lvwhqhu z r xj lvwhqhu z r a the bri performance xj lvwhqhu z r xj lvwhqhu b the brs performance fig.
the component analysis.
fig.
b shows theperformance ofbuglistener anditsvariant without transferring knowledge from the external bee dataset for brstask.
we can see that without the knowledge transferred from the external bee dataset the f1 will averagely decrease by .
.
.
forob eb andsrprediction respectively.this indicatesthatincorporatingthetransferredexternalknowledgecan largelyincreasetheperformanceonebprediction whileslightly increase the performance on ob and sr prediction.
answeringrq3 thegnn textcnn andtransferlearning techniqueadoptedbybuglistenerarehelpfulforbugreportidentification and synthesis.
human evaluation to further demonstrate the generalization and usefulness of our approach we apply buglistener on recent live chats from five new communities webdriverio scala materialize webpack andpandas note that these are different from our studied communitiesso that all data of these communities do not appear in our training testing data .
then we invite nine human annotators to assess thecorrectness quality andusefulnessofthebugreportsgenerated by buglistener.
human annotators.
we recruit nine participants including twophdstudents twomasterstudents threeprofessionaldevelopers and two senior researchers all familiar with the five open source communities.
they all have at least three years of software developmentexperience andfourofthemhavemorethantenyears of development experience.
procedure.first wecrawltherecentone month july2021to august live chats of the five new communities from gitter whichcontain3 443utterances.second weapplybuglistenerto disentangleandconstructthelivechatsintoabout562separated dialogs.
among them buglistener identifies potential bug reportsin total3.
for each participant we assign bug reports 3limited by the space we list the details about the bug reports on our website .of the communities that they are familiar with.
each bug reportis evaluated by three participants.
for each bug report each participant has the following information available the associated opensourcecommunity theoriginaltextualdialogsfromgitter the bug report generated by buglistener.
the survey contains three questions correctness whether thedialogisdiscussingabugthatshouldbereportedatthatmoment yes or no ?
quality how would you rate the quality of description observed behavior expected behavior and step to reproduceinthebugreport usingafive levellikertscale ?
usefulness howwouldyouratetheusefulnessofbuglistener using a level likert scale ?
results.
to validate the correctness of bug reports identified by buglistener we ask each participant to determine whether it is a real bug report and aggregate group decision based on the majority vote from the three participants.
to validate the quality and usefulness of each identified bug report we ask each participant torateusingaschemefrom1 10andusetheaveragescoreofthe three evaluations as the final score.
fig.
a shows the bar and piechartdepictingthecorrectnessofbuglistener.amongthe31 bug reports identified by buglistener of them are correct while of them are incorrect.
the correctness is in line with our experiment results precision of bug report identification .
the bar chart shows the correctness distributed among the five communities.thecorrectnessrangesfrom63 to100 .theperceived correctness indicates that buglistener is likely generalized tootheropensourcecommunitieswitharelativelygoodandstable performance.
fig.
b shows an asymmetric stacked bar chart depicting the perceived quality and usefulness of buglistener s bugreports intermsofdescription observedbehavior expected hegulyhulr 0dwhuldol h 3dqgdv6fdoh hesdfn ruuhfw qfruuhfw a correctness 3hufhqwdjh hv 8vhixoqhvv 4xdolw lvvdwlvilhg 6rphzkdw glvvwlvilhg 1rw glvvdwlvilhg 6rphzkdw vdwlvilhg 6dwlvilhg b quality and usefulness fig.
results of human evaluation 307icse may pittsburgh pa usa lin shi et al.
behavior andsteptoreproduce.wecanseethat thehighquality of bug report description is highly admitted of the responses agreethatthebugreportdescriptionissatisfactory i.e.
somewhat satisfied or satisfied .
the high quality of ob eb and s2r are also moderately admitted and on aggregated cases respectively .
in addition the usefulness bar chart shows that of participants agree that buglistener is useful.
we will further discuss where does buglistener perform unsatisfactorily in sec.
.
.
discussion encouraged by the significant advantages of buglistener as shown insec.
webelievethatourapproachcouldfacilitatethebugdiscoveringprocess andsoftwarequalityimprov ement.inthissection weproposepotentialusagescenariosaswellasimprovementopportunities for future work.
.
potential usage scenario software engineering bots are widely known asconvenient ways forworkflowstreamliningandproductivityimprovement .
buglistener can be easily incorporated into a collaborative bot on gitter following the basic implementation ideas first the oss repository owner or core team members who care about the po tential bugs could subscribe to their interesting chat rooms viabuglistener then buglistener will monitor the corresponding chat rooms and send potential bug reports periodically and finally for the bug reports that are confirmed by subscribers buglistener couldautomaticallypullthemtocoderepositoriessuchasgithubor gitlab that are well integrated with gitter.
we believe that buglistener could enhance individual and team productivity as well as improving software quality.
.
improvement opportunities asreportedinsec.
7outof31bugreportsareincorrectlylabeled by buglistener.
to identify further improvement opportunities forfollow upstudies wesummarizedthefollowingspecialcases based on examining the human evaluation results that necessitates further studies to improve the performance of buglistener.
dialogswithafewornofeedback.
wefoundthat5outof the incorrect cases are related to insufficient feedback i.e.
three monologues and the other two with less than five utterances in total.whendecidingwhetheradialogcontainsabugornot the feedbackprovidedbyotherdevelopersisimportant.
forexample feedback such as it is still not working and could you please file an issue likely indicate the discussing bug should be reported.
therefore it is difficult for buglistener to predict dialogs with insufficient feedback.
in the future follow up research can enrich the bug report classification by adding different confidence levels highandnormal.
high referstothebugreportsthatthereporter or the discussants have confirmed and normal refers to the bug reports that have the potential.
dialogsreflectingusermisuse mistake.
weobservedthat 7incorrectbugreportsareactuallyassociatedwithinstallation and version update due to the users mistake or negligence.
the differencebetween bugs and usermisuse mistake issubtle.both of them might contain negative complaints error stack traces and similarkeywordssuchas igeterrors notaddressedatall etc.in the future follow up studies are needed to incorporate priori knowledge e.g.
dialogs discussing installation updating or buildingissuesarelikelynotreportingbugs.
tobetterdistinguishthe two categories.
.
threats to validity the first threat is generalizability.
buglistener is only evaluated on six open source projects which might not be representative of closed sourceprojectsorotheropen sourceprojects.theresults may be different if the model is applied to other projects.
however ourdataset comesfrom sixdifferentfields.
thevarietyof projects relatively reduce this threat.
the second threat may come from the results of automated dialogdisentanglement.inthisstudy wemanuallyinspectandcorrectthedisentanglementresultstoensurehigh qualityinputsforevalu atingbuglistener.theaveragecorrectnessis79 inourinspection.however forthefullyautomaticusageofbuglistener thetrade off option would be directly adopting the automated disentanglement results.thus inreal worldapplicationscenarioswithoutmanual correction a slight drop in performance might be observed.
to alleviatethethreat fourstate of the artdisentanglementmodels are selected and experimented on live chat data.
we adopt the best performing modelamong thefour models the ffmodel todisentanglethelivechat.theresultsofhumanevaluationstudyshow thatbuglistener canachieve precisionwithout manualcorrection andtheperformanceonlyslightlydeclinedby3 compared with buglistener taking the corrected dialogue as input.
therefore we believe this can serve as a good foundation for buglistener s fully automatic usage.
thethirdthreatrelatestotheconstructofourapproach.first we hypothesize that the contents of bug reports likely consist of reporters utterances whichoccasionallyresultsinmissingcontextinformation.toalleviatethethreat wethoroughlyanalyzedwhere our approach performs unsatisfactorily in sec.
.
and planned future work for improvement.second we enlarge our bri dataset by using a heuristic data augmentation which may alter the se manticsoftheoriginaldialog.toalleviatethethreat weemploy the utterance mutation fromtwo dimensions utterance level and word level which has been commonly used in augmenting the datasetsfornlptasks .itcouldreducesemanticchangesof the overall dialogs to a minimum.
the fourth threat relates to the suitability of evaluation metrics.
we utilize precision recall and f1 to evaluate the performance.we use the dialog labels and utterance labels manually labeled as ground truth when calculating the performance metrics.
thethreats can be largely relieved as all the instances are reviewed withaconcludingdiscussionsessiontoresolvethedisagreementin labelsbasedonmajorityvoting.thereisalsoathreatrelatedtoour humanevaluation.wecannotguaranteethateachscoreassigned to every bug report is fair.
to mitigate this threat each bug report isevaluated by3 humanevaluators and weuse theaveragescore of the evaluators as the final score.
related work identifying bug reports.
identifying bug reports from user feedback timely and precisely is vital for developers to update their 308buglistener identifying and synthesizing bug reports from collaborative live chats icse may pittsburgh pa usa applications.
many approaches have been proposed to identify bugs or problems from app reviews mailing lists and issue requests .
for example vu et al.
detected emerging mobile bugs and trends by counting negative keywords based on google play.
maalej etal.
leveraged natural language processing and sentiment analysis techniques to classify app reviews into bug reports featurerequests userexperiences andratings.scalabrinoetal.
developedclaptoclassifyuserreviewsintobugreports feature requests andnon functionalissuesbasedonarandomforestclassi fier.disorboetal.
classifiedsentencesindevelopermailing listsintosixcategories featurerequest opinionasking problem discovery solution proposal information seeking and information giving.huangetal.
addressedthedeficienciesofdisorboet al.
s taxonomy by proposing a convolution neural network cnn basedapproach.ourworkdiffersfromexistingresearchesinthat wefocusonidentifyingbugreportsfromcollaborativelivechats whichposedifferentchallengesaschatmessagesareinterleaved unstructured informal and typically have insufficient labeled data than the previously analyzed documents.
synthesizing bug reports.
several efforts have been made to synthesize bug reports by utilizing heuristic rules automatically .asheuristicapproachesoftenfailtocapturethediverse discourseinbugreports learning basedapproacheshavebeenpro posed .songetal.
proposedatoolthatintegrates threesvmmodelstoidentifytheobservedbehavior expectedbehavior ands2ratthesentencelevelinbugreports.zhaoetal.
proposedansvm basedapproachthatautomaticallyextractsthe textual description of steps to reproduce s2r from bug reports.
chaparro et al.
proposed a sequence labeling based approach that automatically assesses the quality of s2r in bug reports.
chen etal.
proposedaseq2seq basedapproachthatautomatically generates titles regarding the textual bodies written in bug reports.
most of these methods focus on structuring or synthesizing bug re portsfromtextualdescriptionsthatdepictingbugsinasingle partystyle whileourapproachtargetstoautomaticallystructureandsyn thesizebugreportsfrommulti partyconversations complementing the existing studies on a novel resource.
knowledge extraction from collaborative live chats.
recently moreandmoreworkhasrealizedthatcollaborativelivechats play an increasingly significant role in software development andare a rich and untapped source for valuable information about the softwaresystem .severalstudiesarefocusingonextractingknowledgefromcollaborativelivechats.chatterjeeetal.
automatically collected opinion based q a from online developer chats.shietal.
proposedanapproachtodetectfeature request dialoguesfromdeveloperchatmessagesviathedeepsiamesenetwork.
qu et al.
utilized classic machine learning methods to predictuserintentwithanaveragef1of0.
.rodegheroetal.
presented a technique for automatically extracting information relevant to user stories from recorded conversations.
chowdhury and hindle filtered out off topic discussions in programming irc channels by engaging stack overflow discussions.
the findings of previousworkmotivatetheworkpresentedinthispaper.ourstudy is different from the previous work as we focus on identifying and synthesizingbugreportsfrommassivechatmessagesthatwould beimportantandvaluableinformationforsoftwareevolution.inaddition ourworkcomplementstheexistingstudiesonknowledge extraction from developer conversations.
conclusion inthispaper weproposedanovelapproach namedbuglistener whichcanautomaticallyidentifyandsynthesizebugreportsfrom livechatmessages.buglistenerleveragesanovelgraphneuralnetwork to model the graph structured information of dialog thereby effectively predicts the bug report dialogs.
buglistener also adopts atwicefine tunedbertmodelbyincorporatingthetransferlearningtechniquetosynthesizecompletebugreports.theevaluation results show that our approach significantly outperforms all other baselines in both bri and brs tasks.
we also conduct a human evaluation to assess the correctness and quality of the bug reports generated by buglistener.
we apply buglistener on recent livechats from five new communitiesand obtain potentialbug reportsintotal.amongthe31bugreports ofthemarecorrect.
of human evaluators agree that buglistener is useful.
these results demonstrate the significant potential of applying buglis tenerincommunity basedsoftwaredevelopment forpromoting bug discovery and quality improvement.