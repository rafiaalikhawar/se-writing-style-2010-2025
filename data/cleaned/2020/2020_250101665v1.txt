fairsense long term fairness analysis of ml enabled systems yining she carnegie mellon university yiningsh andrew.cmu.edusumon biswas case western reserve university sumon case.educhristian k astner carnegie mellon universityeunsuk kang carnegie mellon university eunsukk andrew.cmu.edu abstract algorithmic fairness of machine learning ml models has raised significant concern in the recent years.
many testing verification and bias mitigation techniques have been proposed to identify and reduce fairness issues in ml models.
the existing methods are model centric and designed to detect fairness issues under static settings .
however many ml enabled systems operate in a dynamic environment where the predictive decisions made by the system impact the environment which in turn affects future decision making.
such a self reinforcing feedback loop can cause fairness violations in the long term even if the immediate outcomes are fair.
in this paper we propose a simulation based framework called fairsense to detect and analyze long term unfairness in ml enabled systems.
given a fairness requirement fairsense performs montecarlo simulation to enumerate evolution traces for each system configuration.
then fairsense performs sensitivity analysis on the space of possible configurations to understand the impact of design options and environmental factors on the long term fairness of the system.
we demonstrate fairsense s potential utility through three real world case studies loan lending opioids risk scoring and predictive policing.
i. i ntroduction socio technical systems are increasingly using machine learning ml models to automate high stakes decisions such as loan lending drug risk scoring predictive policing college admission and vaccine allocation .
as unfair decisions made by such systems can cause harm to users and our society approaches to developing fair systems have gathered significant interest in recent years.
for example researchers have developed various methods for fairness measures and identification verification and testing and bias mitigation .
most of the existing work on fairness is model centric under static settings that is it evaluates and improves fairness of a given model at a particular point in time.
however even if a system appears to be fair initially fairness issues may arise after it has been deployed for a period of time we call these long term fairness issues.
a long term fairness issue arises as a result of a feedback loop between a system and itsenvironment decisions made by an ml enabled system induce certain changes or shifts in the environment which in turn can influence the ensuing system behavior.
for example when an ml enabled lending application declines a request for a bank loan this decision may reduce the credit score of an individual which further damages their chance of a future loan approval.
if left unattended over a long periodof time such a self reinforcing feedback loop can result in discrimination against certain groups of individuals .
unintended consequences from feedback loops are being recognized as an emerging problem in ml enabled systems .
identifying long term fairness issues poses new challenges beyond static fairness analysis as it requires looking beyond the boundary of an ml model and analyzing possible interactions between the system and its environment .
the behavior of a system is influenced not only by ml system design decisions e.g.
data collection agent policies hyperparameters optimization metrics and retraining criteria but also depends strongly on the dynamics of the surrounding environment e.g.
how people react to and adapt to the system and its decisions .
depending on the combination of these decisions and possible environmental dynamics the system can evolve in numerous ways some of which may result in an undesirable feedback loop.
thus explicit consideration of the environment and its interactions with the system is crucial for identifying long term fairness issues.
in this paper we propose fairsense a tool assisted approach for proactive analysis of long term fairness issues that specifically considers a model of the environment and uncertainty about the environment .
a key distinction of our approach is that fairsense is designed to aid developers early in the requirements and design stages so that they can focus on the design decisions and environmental factors that most impact long term fairness and avoid deliberating on others.
that is fairsense helps to proactively analyze requirements and consequences of different designs before the system is implemented and deployed which helps not only to create better initial designs but also to plan for mitigations and monitoring to maintain fairness when the system is deployed in the real world.
we show an overview of the proposed framework in figure .
a developer using fairsense specifies three types of inputs system parameters which describe the space of configuration options e.g.
type of ml model and agent policies to be explored desired fairness criteria and anenvironmental model where the environmental parameters control the dynamics of environmental changes that are induced by the system s decisions.
the latter model itself consists of i a target dataset that represents the target population and ii a distribution shift model which describes how the system outcome may cause changes in the dataset.
the distribution1arxiv .01665v1 jan 2025distribution shift shift function projectiontarget datasetsimulation framework...system parameters values configuration with traces... ... ...sensitivity analysis average fairnesssociotechnical system fairness criteria metric tolerance frequency of violating traces ......system parameters ml model policy decisionenvironmental model system designer...fig.
an overview of the f airsense approach shift model is stochastic explicitly encoding uncertainty about how the environment may evolve in response to system output.
given these inputs fairsense performs monte carlo simulation to systematically generate traces that show how the system and the environment may evolve together over time for a given configuration i.e.
an assignment of values to the system and environmental parameters .
the desired fairness criteria are then evaluated over these traces assigning each configuration a fairness metric that represents the level of unfairness that might arise over time.
system designers are often overwhelmed with many design choices and can spend a lot of time negotiating a choice that ultimately matters little for fairness.
fairsense adopts sensitivity analysis to identify which system parameters and environmental parameters are the most influential to shape long term fairness.
this helps developers to focus their time effectively on reasoning about options that provide the highest leverage e.g.
monitor critical environmental parameters closely to reduce uncertainty and react in a timely fashion or invest in system design options that have the largest potential impact.
in addition fairsense enables a trade off analysis between system utility and longterm fairness metrics to aid developers in selecting decisions that achieve desired levels of utility and long term fairness.
to demonstrate its potential utility we have applied fairsense on three real world case studies built on models and data from prior research loan lending opioids risk scoring and predictive policing .
our case studies show that fairsense can be used to systematically analyze and understand the impact of design options on long term fairness.
the main contributions of the paper are a conceptual model of feedback loops and their impact on long term fairness of ml enabled systems section iv .
a simulation based framework that systematically explores possible evolution traces section v and performs sensitivity analysis to rank system parameters in terms of their impact on long term fairness section vi .
a prototype implementation of fairsense and its demonstration on three real world case studies section viii .
ii.
b ackground in this paper we focused on the long term fairness of mlenabled sociotechnical systems.
these systems are software solutions that closely interact with humans and society in different domains such as education finance and the judiciary.
the system consists of several components such as the collected data one or more ml models and the decision making entity.the system operates in a certain social context which we refer to as the environment .
the system and the environment interact continuously during its operation.
the environment dynamics can usually be decomposed further such as the population distribution and human behaviors.
the involvement of many agents such as system users and policymakers affects various dynamics which leads to uncertain evolution of the system and the environment over time.
afeedback loop occurs when the system induces certain changes to the environment which impacts the decision making of the system through its input .
a balancing feedback ornegative feedback loop is created by system structures that are sources of both stability and resistance.
on the other hand a reinforcing feedback or positive feedback loop causes divergence and continuously shifts the environment toward a risky outcome commonly seen in various domains such as biology electronics economics and sociology .
an example of such a feedback loop is described in detail in section iii in the context of sociotechnical systems.
identifying the cause of the feedback loop before deployment can help design interventions such as creating artificial feedback to mitigate existing one or choosing the best system parameter .
we proposed modeling the system environment and their interactions which we call a feedback loop model to understand the system design space.
various fairness criteria exist with common metrics including including demographic parity andequal opportunity .
for example in a loan lending system serving two groups aandb demographic parity measures the difference in the approval rates between individuals in aandb.
formally given the predictive outcome y and group membership feature a the demographic parity requirement is given by p y a a p for some threshold .
in contrast equal opportunity measures the difference of true positive rates between the groups formally with yrepresenting the actual outcome p p y a b y .
iii.
m otivating example unfairness in bank loan approvals and credit scoring has been investigated extensively in prior work .
for example city national bank was recently fined over million for discriminatory lending against black and latinos and the apple card joint venture of apple and goldman sachs has been accused of discriminating against female applicants for credit approval .
in the us equal credit opportunity act of ecoa requires non discrimination in lending.
2ml softwarerepayment decision makerapproved applicants default group with lower credit scorecredit score increase credit score decrease further avg.
credit score difference between and loan applicants group with higher credit score fairness measurefig.
a feedback loop created by ml enabled loan lending system a developer of a loan lending application can leverage existing fairness metrics or testing methods to analyze whether the system statically satisfies a fairness requirement at the model level.
however a seemingly fair loan lending system e.g.
satisfying demographic parity at the time of deployment may begin to exhibit unfair behaviors over time.
figure depicts a possible feedback driven interaction between the ml enabled system and the environment.
the ml model here uses the applicants credit score to predict the likelihood of on time loan repayment only if this predicted value is above a certain threshold the applicant is granted the loan.
suppose that group ahistorically has a higher average credit score than group b. to reduce this gap a policy may deliberately approve a higher number of applications from group b. if however individuals in group bare more inclined to a loan default their average score may decrease at a higher rate than those in group a. furthermore an individual whose application gets rejected may begin to apply for other loans incurring multiple hard inquiries that further decrease their credit score .
thus a feedback loop will influence the credit scores of members of bto decrease over time.
even if the ml model satisfies demographic parity in the short term the system could begin to show unfair behavior over time due to the shifting distribution of credit scores.
the intensity of the feedback loop also depends on many factors such as the magnitude of credit score decrease for a default and the loan approval threshold.
some of these are configurable system parameters e.g.
the loan approval threshold and some are uncontrollable environmental parameters e.g.
credit score update model .
at design time it may be challenging to understand how these different parameters might give rise to a feedback loop and negatively impact the long term fairness of a system.
in the following sections we describe our approach for explicitly modeling feedback interactions between the ml based system and the environment and a simulationbased analysis to understand the impact of both system and environmental parameters on long term fairness.
iv.
m odeling feedback loops we propose a conceptual framework to specify the structure and key elements of feedback loops in an ml enabled system.
then we describe how this conceptual framework can be used to develop a design time analysis for long term unfairness.
a. feedback loop model we illustrate the conceptual model of a feedback loop in an ml enabled system in figure the system encompasses the ml model and any other components needed to produce the ml modeldecision maker policysystem environment population subset projection function fairness check shift function input populationtraining datafig.
feedback loop model of ml enabled system decisions here we modeled the system with the two components the ml model and the decision maker .
feedback loops are system level phenomena and hence modeling the entire system the environment and their interactions is necessary to analyze these phenomena.
mgiven input data population sample xin the ml model mgenerates predictions o. for example in a loan lending system mtakes the applicants data as input and outputs the probability of repayment.
the decision maker entity d e.g.
the bank then makes decision d e.g.
loan approval or rejection based on the predictions o. the environment is modeled as the stateful entity q where each state q qcaptures the relevant properties of the population at a certain point in time.
we model xqas the population characteristic of the state qsuch that each individual x xqhas the attributes x1 x2 ... .
for the loan lending application xican be the protected attribute e.g.
age gender race or non protected attribute e.g.
credit score income education of the applicants.
a system decision can affect the environment and change certain attributes such as credit scores.
the change is modeled by a distribution shift function s q d q where s is a stochastic function and q represents the probability distributions over the possible states q.the stochastic nature of this function captures uncertainty about the way in which the environment evolves given a system decision.
for some decision d the environment shifts from qtoq where q s q d represents the resulting probability distribution over the environmental states.
over time one possible evolution of states is q0 q1 q2 ... which are impacted by the series of system decisions d0 d1 d2 ... and where qnis sampled from the distribution s qn dn .
the environmental state might not be fully observable by the system.
in the feedback loop model a projection function p q idetermines the observable parts where iserves as the input to the system.
in practice the developer may choose input data xinfrom iin the next step.
the training data xtr is optionally set aside from ifor updating the ml model periodically i.e.
mcan be left static or retrained over time.
infairsense we model pas a stochastic sampling function since it can depend on various uncertain factors such as human 3behavior economic condition and geographic location.
while the system is in deployment the environment evolves through a series of distribution shifts and may reach a state that can cause mto exhibit a certain level of unfairness.
example in the loan lending example the shift function s can be modeled using a stochastic function that changes the credit score of the individuals based on the decision following a normal distribution n 2 .fairsense employs separate distributions n1andn2for approval and rejection decisions.
in addition fairsense allows developers to conduct analysis for multiple environmental models by enumerating various options for the and to reflect aggressive or conservative updates in the credit score.
similarly psamples the input population by using a normal distribution n 2 .
b. feedback loop analysis given an instantiation of the above feedback loop model for a particular system fairsense provides an analysis for understanding how different ml system design options and the dynamics of the environment may impact the long term fairness of a system.
the output of this analysis could be used by developers to identify and select design options that improve long term fairness while considering trade offs against other quality attributes such as system utility and monitor the environment for the actual dynamics and apply interventions when necessary e.g.
modifying the decisionmaking policy .
note that the analyst does not need to provide a perfectly accurate model of the environment for the analysis to be useful.
the main objective is to identify what design decisions and environmental factors are important not what exactly will happen in a particular environment.
where uncertainty exists for instance if it is unclear how strongly credit scores are impacted by declined loans the analyst can model uncertain factors explicitly as parameters to be explored by fairsense .
for its analysis fairsense conducts a type of simulationbased configuration analysis .
each component of a feedback loop model i.e.
m d q s p contains one or more of system orenvironmental parameters .
system parameters such as the choice of ml models and the approval threshold in loan lending are decisions that are configurable by the developer while environmental parameters such as the credit score change mechanism for a loan default are assumed to be uncontrollable but observable by the ml system.
each parameter is associated with a set of parameter values for example the approval threshold for the loan lending policy may take on a value from a given range of parameter values e.g.
a credit score of .
then as an input to this analysis the developer identifies a set of relevant system parameters denoted ps ps ps .
.
.
ps m and environmental parameters pe pe pe .
.
.
pe n .
the latter set of parameters and their values are typically elicited through a discussion with stakeholders e.g.
policy makers or estimated based on prior data e.g.
a historical analysis of lending decisions and their impact on credit scores .
the combinations of different parameter values lead to a large number of configurations c1 c2 ... for the feedbackloop model where each configuration ci p1 p2 .
.
.
p m n is a member of the space c ps pe.
the idea behind fairsense then is to simulate the feedback loop model under all possible configurations and extract relationships between the parameters and a desired long term fairness measure.
more precisely we state the goal of the feedback loop analysis as given a feedback loop model of a system m d q s p and its possible configurations c which of the system and environmental parameters have the most impact on its longterm fairness negatively or positively?
v. s imulation framework in this section we describe how the feedback loop model is simulated for long term fairness analysis.
a. monte carlo simulation first we obtain a target dataset that represents the environment.
taking the loan lending system as an example the environment state can be represented by a snapshot of the dataset containing the credit scores of all loan applicants.
the effect of the system decisions would be reflected in the changes in the dataset.
for each configuration we simulate the feedback loop model for ktime steps and record one trace.
in every timestept the system takes the inputs from the current state of the environment.
the decisions of the system bring certain changes to the environment in the subsequent time step t t .
then the system makes a new set of decisions based on the new inputs from the updated environment in step t .
we record the inputs xin outputs o d and the environmental state q in each step together constituting a snapshot s. thus after ksimulation steps we generate a trace t s1 s2 ...sk .
however the feedback model may evolve in numerous ways for the same configuration due to the uncertainty of the environmental parameters and the interactions between the system and the environment.
to systematically account for the uncertainty we conduct a monte carlo simulation for each configuration.
the monte carlo simulation is a computational technique that uses random sampling to model complex systems and assess the impact of uncertainty.
by generating a wide range of possible scenarios it allows for the analysis of outcomes under varied conditions.
here for each configuration ci we repeatedly conduct random simulation and collect a set of traces ti t1 t2 .. t mi .
the number of times the simulation needs to be conducted depends on the variance of the generated traces.
the goal is to get a stable distribution of traces with respect to long term fairness and stop early for efficiency purposes.
specifically we want to ensure that the estimated mean falls within the confidence interval of the true value with a probability of over .
therefore the simulation for one configuration will be run repeatedly until the recorded set of traces t t1 t2 .. t m satisfies z0.95std lf t mean lf t m .
where z0.95is the coefficient for confidence level which is equal to .
and lfis the selected long term fairness metric.
.27long term unfairness time threshold .3demographic parity .33probability of approvalfig.
an evolution trace of loan lending system showing long term unfairness.
b. long term fairness evaluation given a fairness criteria we perform long term fairness evaluation on all the traces.
for example one possible simulation trace for a configuration of the loan lending system is shown in figure here the feedback loop causes a divergence of fairness between two population groups and eventually results in a violation of the demographic parity requirements.
we propose two different types of long term fairness criteria that can be used to evaluate a trace for the presence of unfairness that arises over time average increase in unfairness this long term fairness of a trace t s1 s2 ...sk is computed by measuring the average fairness of a trace using fairness criteria f e.g.
demographic parity and then subtracting the unfairness of the initial state.
when the goal is to analyze the trend of longterm fairness e.g.
equilibrium oscillation this criterion would be a suitable choice avginc f t ki kx i 1f si f s1 maximum increase in unfairness this is measured by subtracting the unfairness of the initial state from the maximum unfairness exhibited by a trace for the given configuration.
when the goal is to avoid any severe unfairness in the future analyzing this criterion would be useful maxinc f t max x tf x f s1 while we focus mainly on the above two criteria the developer may plug in other criteria into fairsense such as bias promptness i.e.
how quickly the system reaches a biased state or violation frequency i.e.
how many violations occur in a given time period .
vi.
s ensitivity analysis global sensitivity analysis technique has been successfully applied to investigate how uncertainty in the output of a model is attributed to different sources of model input .
this technique has also been applied to interpret the fairness in ml models .
however prior work focused on studying stationary ml models and evaluating the sensitivity of the training features on static fairness.
our approach on the other hand focuses on identifying parameters that are more likely to influence long term fairness.
the sensitivity analysis onsimulation results could be used by the developer to understand the long term fairness impact of the entire design space of system configurations.
for example if it is not clear how the environment behaves different alternatives can be encoded as parameters and a sensitivity analysis would identify whether that uncertainty in the environment is actually an important factor in influencing the long term fairness of the model.
exhaustively simulating the large space of configurations can become computationally prohibitive as the number of parameters and their possible values increases.
hence we propose a sampling heuristic to reduce the number of configurations to explore while preserving the accuracy required for effective sensitivity analysis.
in this section we first describe the sensitivity analysis method and then the sampling heuristic.
a. sensitivity analysis with regression modeling regression analysis has been shown to be a good match for investigating parametric importance and sensitivity .
compared with other sensitivity analysis methods like elementary effects methods and variance based methods the coefficient for each input variable in a regression model can be directly interpreted as the exact effect that the input variable brings to the output variable.
the idea is to learn a regression model that explains how the response is influenced by different options.
in our case the response is the long term fairness measured in simulation and the options are possible values for the system and environment parameters.
the model a standardized multiple linear regression model is trained based on the measured fairness results of simulations with different configurations.
the model s coefficients then indicate the influence of each parameter on the fairness result of the simulation.
the regression model has the structure shown below in equation where yis the output variable i.e.
the longterm unfairness score.
as introduced in previous section pi is the option for the ith parameter in a configuration c p1 p2 p3 ... p n .
iand i jare the coefficients for the terms.
we include both individual terms which assess the impact of each parameter pi in isolation and pair wise interaction terms which explore the combined effects of any two parameters e.g.
the interaction of piandpj .
this dual approach also allows us to understand the independent contribution of every single parameter as well as the interplay between different parameters that influence long term fairness.
while interactions might be possible among more than two parameters at the same time in some case studies our current focus is on the most salient pair wise interactions balancing the depth of analysis with model interpretability.
y nx i 1 i pi nx i 1nx j i 1 i j pi pj we use analysis of variance anov a for the model which allows us to identify which parameters contribute in a statistically significant way using the common significance threshold of p .
.
then we quantify the effect sizes of the statistically significant coefficients using the sums of squares 5and the eta squared 2 derived from anov a. we evaluate whether an individual parameter or its interaction with another parameter is impactful based on cohen s well established guidelines 2 .
.
and .14indicate a small medium and large effect respectively and further rank them according to their effect sizes.
we additionally report the model s r2value as a measure of fit that indicates how much variance in the long term fairness the model can explain in terms of the parameters and their interactions.
b. sampling heuristic the presence of numerous parameters and their potential values lead to an exponentially large configuration space.
given the time intensive nature of monte carlo simulations and the typical constraints of real world development simulation of all configurations can be challenging.
to address this we propose covering array sampling on the configuration space to reduce the number of configurations to be explored while ensuring a diverse and comprehensive coverage of the parameter values.
covering array sampling technique is widely used in software testing to achieve an adequate coverage of program behavior with a small number of carefully selected inputs.
a covering array characterized by a coverage number g is a structured method to select combinations of a set of n parameters values.
the key feature of a covering array is that it guarantees the inclusion of every possible combination of any set of gfactors values from these nparameters at least once i.e.
all possible g factor interactions are covered within the array.
for example in a coverage array i.e.
g an array of combinations is created such that every possible pair of parameter values is included.
this approach effectively minimizes the number of configurations fairsense needs to simulate.
for example a coverage array for ten binary parameters can cover all pairwise interactions with only configurations a significant reduction compared to the configurations needed when enumerating all.
vii.
e xperimental setup to demonstrate the utility and applicability of fairsense we conducted three case studies and answered the following research questions rq1.
what are system and environmental parameters that significantly impact the long term fairness of a system?
rq2.
what trade offs among the parameters does fairsense identify?
rq3.
how effective is the sampling heuristics in reducing the number of configurations explored while retaining the accuracy?
rq1 is intended to demonstrate that fairsense can potentially reduce the system developer s effort by identifying parameters that have significant influence on long term fairness.
rq2 shows that fairsense can be used by the developer to navigate the trade off space between fairness and utility to identify a design solution that acceptably meets both qualities.
rq3 evaluates the efficiency of fairsense when the sampling heuristics is used.the remainder of this section describes the case study systems and the experimental settings.1the space of possible configurations for each system is shown in table i in total loan lending has possible configurations opioid risk scoring has and predictive policing has .
the code offairsense and the results of the case studies are available in our replication package.
a. loan lending ml enabled systems are used to predict the creditworthiness of people and approve or reject loan applications.
an ml model is trained on personal data e.g.
education income sex race credit score of individuals and then predicts the probability of an individual to repay or default.
the decision making system adopts a policy e.g.
a threshold that approves or rejects loans based on the predictions.
potential feedback loop section iii presented how a possible feedback loop might exhibit longterm unfairness against a group.
ml enabled system we leverage the predictive models defined by which determine credit score thresholds dynamically for different groups and then employ the thresholds for loan approval and refusal.
environment we use the fico dataset to present all the potential loan applicants.
detailed dynamics are described in section iv.a.
experimental settings following liu et al.
and d amour et al.
we evaluated fairness between two racial groups white and black.
the fairness metric is given by the demographic parity and the mean credit score difference between the groups.
for long term fairness metric we leveraged the average increase eq.
and the maximum increase eq.
.
the developer may choose to apply fairsense using any of the defined long term fairness metric we used the maximum increase of demographic parity for the sensitivity analysis.
to further explore the trade off between long term fairness and utility we defined the profit of the bank as the utility metric.
b. opioid risk scoring opioids are a class of medicine that are frequently used for pain management.
common opioids such as oxycodone morphine fentanyl and methadone are used to reduce pain but can cause overreliance and addiction which is called opioid use disorder oud .
recent data shows a worsening situation with over annual deaths from oud for the first time in .
to reduce oud a prescription drug monitoring program pdmp is mandated in each state which measures the opioid risk score of individuals.
many pdmps use an mlbased application called narxcare which produces a numeric risk score for individuals .
the risk score is shown to the doctors and pharmacists based on which they can modify the prescription.
potential feedback loop the narxcare ml model is trained using patients medical records such as past opioid 1further details of the case studies i.e.
ml model decision maker environmental dynamics and configuration parameters are presented in our supplemental material shared in the artifact fairsense tree main supplementalmaterial 6table i the parameters and their possible values.
the middle and right column contain the configuration parameters taking part in the systems decision making and the interactions between systems and environments respectively.
case study system parameter environmental parameters loan lendingagent max util eq op bank utility func param ... 3score update repay ... score update default ... shift function mode expected normal aggressive opioid risk scoringmodel type xgboost mlp doctor threshold .
.
.
.
.
.
.7shift function mode hospital visits expected equal normal aggressive shift function mode prescription expected normal aggressive predictive policingmodel type sepp hotspot number 50discovery rate hotspot cell .
.
... .
discovery rate other cell .
.
... .
hot spot effect area range usage number of pharmacies visited number of prescribers overlap from different prescribers etc.
.
the narxcare software uses these attributes to predict a risk score .
underrepresented patients including women and racial groups with complex medical conditions can have artificially inflated scores.
consequently they can be denied a legitimate amount of opioids suffer physical or mental debilitation and be coerced into illegal activities which may further increase their risk score in the long term .ml enabled system the ml model adopted from uses patients medical records to predict opioid risk scores and then doctors make prescriptions based on scores.
environment we use the publicly available mimic iv v2.
dataset to represent the potential patients.
patients will visit hospitals to get prescriptions when a patient get an insufficient prescription their further doctor visits may be affected.
the shift function is defined to update the number of hospital visits by patients based on their risk scores higher the risk score a patient has more visits they likely need .
experimental settings we computed the fairness between two gender groups male and female.
the long term fairness metrics are the maximum increase eq.
in the gap between the mean opioid disorder risk scores of two groups and the average increase eq.
of the gap between ml model s performance metrics for two groups prediction accuracy and f1 score.
the first one is used for sensitivity analysis of the case study and others are used in the trade off analysis.
the utility metrics are defined by the daily average of ml model s performance metrics prediction accuracy and f1 score.
c. predictive policing police departments are widely using ml algorithms to predict crime hotspots and deploy police based on the prediction.
in a survey by the national institute of justice over of agencies have reported to use predictive crime maps .
lum and isaac experimented on the self exciting point process sepp model and data collected from oakland ca to demonstrate over policing in minority neighborhoods .
potential feedback loop the model predicts crime hotspots based on the crime incident records from the past .
because of the crime increase for a short period or inaccurate prediction more police may be sent to a certain location.
this causes more crime discovery in that region which in turn may influence the ml model to predict those regions as hotspots in the future.
ml enabled system the crime prediction model is adopted from which predicts crime intensity of each location for the next day.
based on the intensities the decision makerallocates more police force to the top cells i.e.
locations with the highest intensities.
environment adopted from we synthesized all the crime incidents that will take place.
the shift function is used to derive the incidents occurring each day.
the projection function is defined as a stochastic function that determines which incidents would be discovered based on hotspot allocation the incidents in the neighborhoods of hotspots are more likely to be discovered.
experimental settings we measured the fairness of police allocation across districts by calculating the average pairwise relative percentage difference rpd between districts overpolicing scores.
following akpinar et al.
a district s overpolicing score is determined by the relative number of predicted hotspots.
for the long term fairness metrics we computed the maximum and average increase of the districtwise allocation unfairness.
the former metric is used for sensitivity analysis in our evaluation.
for system utility we considered three metrics the total number of discovered incidents the mean of daily percentages of discovered incidents and the number of correct predicted hotspots.
viii.
e valuation results a. rq1 sensitivity analysis to identify impactful parameters we answer rq1 through the sensitivity analysis results on the three case studies.
we identify the most impactful parameters and their interactions and show that only a small subset of the parameters are influential on long term fairness.
a loan lending fairsense collected traces in total for possible configurations.
on average every trace has .
increase in the unfairness demographic parity at the final time step compared to the initial step.
around of the configurations have more than increase on average and table ii top impactful regression terms for loan lending.
a parameter can be numerical or categorical.
categorical parameters are transformed into binary variables using one hot encoding.
the specific values of the categorical parameter are listed in the second column.
the pair of parameters represent interaction terms.
terms dummies coefficient sum sq.
2 agent max util .51e .19e .
bank utility param .45e .35e .
agent bank utility p. max util .38e .35e .
score update d. agent max util .35e .16e .
score update d. .38e .16e .
p values p .
p .
p .
7table iii top impactful terms for opioid risk scoring.
terms dummies coefficient sum sq.
2 ml model xgboost .12e .35e .
ml model shift function prscrptn.
xgboost normal .53e .28e .
xgboost aggressive .65e 3shift function hospitalnormal .00e .92e .
aggressive .70e equal .03e 4shift function prescriptionnormal .37e .82e .59aggressive .38e ml model shift function hospital xgboost normal .15e .92e .
xgboost aggressive .21e xgboost equal .77e p values p .
p .
p .
around of configurations have increase on average demonstrating long term fairness issues in loan lending.
the fitted regression model explains the variance well r2 .
.
table ii shows the terms i.e.
individual parameters and their interactions with the top effect sizes sum of squares in the regression model all statistically significant.
regarding rq1 there are only out of terms that can be considered as impactful 2 .
.
among them the choice ofagent is the most dominant factor 2 .
influencing long term fairness max utility agent can greatly improve longterm fairness.
the bank utility parameter and its interaction with the agent together explain of the variance in the total sum of squares both have a moderate influence on long term fairness.
one standard deviation increase in bank utility parameter can decrease long term fairness by .
indicating that it is fairer if a bank makes loan decisions conservatively i.e.
smaller bank utility parameter .
however with the existence of max utility agent the individual effects ofbank utility parameter score update parameters and shift function mode will be offset.
this illustrates how sensitivity analysis can highlight the small number of decisions or sources of uncertainty of environment parameters that require careful attention where one factor dominates four more have moderate influences and more are largely negligible.
b opioid risk scoring we collected traces in total for possible configurations.
the average initial unfairness score average risk gap between groups for all configurations is .
.
however in the final step of the simulation the average unfairness score increases to .
.
more than of configurations have an increase of more than .
.
the fitted regression model again explains the variance very well r2 .
.
we show the ranking of the terms for this case study in table iii.
regarding rq1 only out of parameters is impactful 2 .
the choice of ml model explaining around of all variance.
choosing xgboost model would significantly amplify longterm unfairness.
although the other terms have much smaller effects 2 .
we noticed that two environmental parameters in the configuration shift function hospital and shift function prescription and their interaction terms with ml model also have small but statistically significant influences table iv top impactful terms for predictive policing.
terms coefficient sum sq.
2 discovery rate other .46e .26e .
discovery rate hotspot .99e .48e .
discovery rt hotspot discovery rt o.
.75e .21e .
discovery rt o. hotspot area range .40e .30e .
hotspot area range .18e .40e .
p values p .
p .
p .
that developers might want to consider when tuning the model.
c predictive policing we explored traces in total for possible configurations.
the average initial unfairness score is .
.
in the last step of the simulation the average score for all configurations increases to .
.
around of all configurations see an increase of more than .
the fitted regression model again explains most of the variance r2 .
considered high in sensitivity analysis .
table iv summarizes the ranking of the terms effect sizes for predictive policing.
regarding rq1 of terms 2 .
are considered impactful.
the incident discovery rate for areas except the hotspots discovery rate other has the greatest impact on long term fairness explaining of the variance.
the increase in discovery rate other can greatly enhance long term fairness.
the second impactful parameter is the incident discovery rate for hotspot areas discovery rate hotspot explaining about of the variance.
compared to discovery rate other the increase in the discovery rate for hotspot areas has the opposite effect it reduces long term fairness.
this suggests long term fairness might be improved if the police force is not only concentrated in hotspot areas predicted by the sepp model but also partially distributed to other regions.
summary.
we observe that only a small subset of the parameters impact 2 .
long term fairness.
these results demonstrate that fairsense can be used to identify the most impactful parameters and allow the developer to allocate their design effort on them.
b. rq2 trade off between long term fairness and utility the fairness requirement of the system can be defined using multiple metrics.
in addition the developer would typically care about the utility of the system e.g.
financial profit of the bank.
optimizing exclusively for one long term fairness metric may overlook this aspect as the configuration yielding the lowest unfairness scores does not necessarily guarantee optimal utility.
therefore it is essential to identify the trade off between multiple fairness criteria and the utility of the system.
to this end given the long term fairness metric and utility metric fairsense finds a set of pareto optimal configurations.
these configurations represent scenarios where any improvement in utility would result in a decrease in long term fairness and vice versa.
in this section we demonstrate the trade offs that exist in the case studies.
a loan lending.
figure 5a shows the trade off among long term fairness metrics and utility metric defined in 8max inc demoavg inc demo max inc credit avg inc credit util profit0.
.
.
config a1 config a2 config a3 a loan lending case study.
max inc riskavg inc acc avg inc f1 util acc util f10.
.
.
config b1 config b2 config b3 b opioid risk prediction case study.
max inc rlnavg inc rln util discover rate util total discover util correct hotspot0.
.
.
config c1 config c2 config c3 c predictive policing case study.
fig.
the radar plots visualizing trade offs in three pareto optimal configurations for each case study.
all values were scaled to .
a higher value implies better performance.
section vii for pareto optimal configurations.3configuration a1optimizes maximum increase of demographic parity max inc demo and financial profit of the bank util profit while configuration a2anda3optimize average increase of credit score gap avg inc credit and util profit .
a detailed examination of a2anda3reveals a discernible conflict between avg inc credit andutil profit highlighting the inherent tradeoffs in optimizing these two metrics simultaneously.
interestingly configuration a1excels in both max inc demo and util profit suggesting that there might be no evident conflict between them.
if the developer places a higher emphasis on utility while optimizing all fairness metrics a3could be chosen as it has nearly optimal utility and good fairness.
b opioid risk scoring.
figure 5b shows the trade offs for pareto optimal configurations.
configuration b1optimizes maximum increase in risk gap max inc risk and utility of accuracy util acc .b2is pareto optimal in both i optimizing average increase in accuracy gap avg inc acc and util acc ii optimizing average increase in f1 gap avg inc f1 and util acc.
notably b3optimizes two long term fairness metrics max inc riskandavg inc acc.
looking at b1andb2 we find that achieving the highest util accis possible while addressing any of the fairness metrics involved.
furthermore b3demonstrates that all three fairness metrics can attain favorable scores concurrently.
beyond these three pareto optimal configurations it is surprising to find that there always exists a nearly optimal configuration for any pair of metrics.
this observation suggests an absence of significant pairwise conflicts in this case study.
c predictive policing.
figure 5c illustrates the trade offs for pareto optimal configurations that optimize maximum increase of relative number of hotspots max inc rln and total number of discovered incidents util total discover .
the comparison of these configurations reveals a conflict between the fairness metric max inc rln and utility metrics util total discover andutil discover rate .
notably as we move from c1toc2and then to c3 there is a monotonic increase in max inc rln accompanied by a corresponding 3for visualization we omitted showing all the pareto optimal configurations for the case studies in the plot.
the assignments of all the configurations used in this section are presented in supplemental material.decrease in both utility metrics.
furthermore the magnitude of changes observed in these metrics appears to align with the principle of diminishing marginal utility.
while c3shows only a slight improvement in max inc rlnover c2 it experiences a substantial reduction in the utility metrics.
conversely c1 marginally outperforms c2in utility but at the cost of a significant reduction in max inc rln.
summary.
overall regarding rq2 these observations highlight the complex and often delicate balance between maximizing long term fairness and utility in system design demonstrating the need for careful investigation of the trade off between specific metrics during the design stage.
c. rq3 performance evaluation in this section we evaluate the efficiency of fairsense in exploring a potentially large space of configurations for simulation through sampling.
our hypothesis is that by applying covering array sampling fairsense can avoid simulating every configuration while maintaining a high accuracy of regression analysis and the identification of the most significant variables or interaction terms.
to test this we consider the baseline as the ranking of the statistically significant i.e.
p .
terms which is computed by analyzing every possible configuration from the given configuration space.
then we compute the ranking of the same terms after applying both coverage and 3coverage sampling.
we measure the time consumption of each sampling strategy and computed their effectiveness using ranking similarity between the baseline ranks and the ranks found using sampling.
the ranking similarity metrics we used are rank biased overlap rbo with persistence .
and kendall tau tau .
results for the three case studies shown in table v demonstrate that both coverage and coverage sampling require only a significantly smaller number of configuration simulations to obtain a regression model with little loss of model fit r2 .
the models trained on samples also identify impactful terms with a ranking very similar to the baseline derived from analyzing all configurations.
specifically the analysis results of coverage sampling for loan lending and opioid risk scoring benchmarks are almost as good as the baseline while saving and simulation effort the 9table v comparison of efficiency of f airsense with baseline method.
case study coverage coverage baseline no sampling r2rbo tau configs time r2rbo tau configs time r2 configs time loan lending .
.
.
6min .
.
.
24min .
.3hr opioid risk scoring .
.
.
39min .
.
.
2hr .
.9hr predictive policing .
.
.
.5hr .
.6hr predictive policing case study only has three parameters so way coverage samples all possible configurations .
with coverage sampling simulation effort is reduced to compared to analyzing all configurations while the resulting models still explain the variance similarly well.
in summary to answer rq3 the results show that the impactful parameters are still identifiable in the sensitivity analysis with carefully sampled configurations.
the results in table v demonstrate that this heuristics can eliminate a significant number of configurations and traces associated with them while retaining the performance of fitted models.
ix.
t hreats to validity fidelity of the environment models.
the validity of simulation results depends on the fidelity of the environment model used for simulation.
instead of coming up with environmental parameters and dynamics on our own we inferred these from the existing studies and analyses of these systems loan lending opioid risk scoring predictive policing .
although a process for developing environmental models is beyond the scope of this paper we provide a discussion of existing methodologies that could be adopted for this purpose in section xi.
validity of simulation results with respect to the real world.
simulation in fairsense is a type of what if analysis estimating the potential impact of options for various systems and environmental parameters on fairness over time.
in this paper we do not validate the accuracy of the simulation with regard to the real world.
such validation would be very difficult and is orthogonal to the contributions of this paper.
in theory one way to validate the accuracy of our analysis results would be to deploy and execute a system under all possible configurations and collect the resulting traces as the ground truth data.
so however would be extremely challenging and ethically questionable especially for socio technical systems where the system directly interacts with and influences users in the real world sometimes negatively.
to the best of our knowledge no such ground truth data is available for the kind of systems we study in this paper.
instead we provide a comparison against other prior analyses of long term fairness for these systems.
the comparison shows that the conclusions drawn from the simulation about the real world are consistent with those from the other analyses.
although this does not offer the same level of validation of the simulator s ability to correctly model real world behaviors against real world observations we believe that it provides evidence that the simulation is able to produce meaningful predictions about the potential impact of the parameters.
loan lending liu et al.
propose an analytical model that estimates the impact of different ml policies e.g.
equalopportunity vs. maximizing utility on long term fairness studying a loan lending system based on the same dataset as the one used in this paper.
their model shows that the eq op agent which optimizes for equality among different groups in the short term may actually result in long term unfairness in a somewhat counter intuitive and surprising result theorem .
.
consistent with their conclusion our sensitivity analysis results table ii also show that max util agent is the most effective in reducing long term unfairness and hence fairer than the eq op agent.
moreover our analysis presents additional information such as how the choice of agent together with other parameters e.g.
utility of the bank table ii term affect long term fairness.
predictive policing ensign et al.
propose an analytical model that estimates the occurrence of a feedback loop in the same predictive policing system that we studied.
in particular their model shows that over time the system converges to a biased allocation scheme that assigns police only to the neighborhoods with the highest number of observed incidents and ignores those that are historically not hotspots.
their model also indicates that this bias can be mitigated by deliberately allocating resources to those non hotspots to increase the number of observations in those neighborhoods.
these findings are consistent with our analysis results the positive coefficient of discovery rate hot spot table iv term confirms that the dominant observation of incidents in hotspots would exacerbate unfairness on the other hand the large negative coefficient of discovery rate other table iv term marks the importance of improving discovery rates of non hot spot area for long term fairness .
opioid scoring although fairness in ml based opioid risk scoring has been studied to the best of our knowledge no prior work studies long term fairness issues.
adam et al.
conducted a simulation study on the same dataset that we used specifically they created artificial data drift and investigated the impact of different ml model retaining methods on performance.
however their work did not consider the impact of the system decision on the environment and thus is not comparable to ours.
x. r elated work development of fair ml enabled systems.
understanding and improving algorithmic fairness in ml models has received significant attention in the recent past .
many bias mitigation techniques have been proposed for ml algorithms .
the mitigation techniques can be categorized into preprocessing in processing and post processing methods depending on where the mitigation is applied.
however several challenges remain for the development of fair ml enabled systems .
10prior works showed that fairness enhancing interventions can fail due to fluctuations in dataset characteristics preprocessing methods etc.
.
holstein et al.
outlined the challenges industry product teams face in developing fair systems .
thus several software engineering techniques have been proposed for testing verifying and achieving the accuracy fairness trade offs .
however these works focus on fairness under static settings and do not consider long term fairness.
long term fairness.
gohar et al.
conducted a survey on different notions of long term fairness and created a taxonomy.
d amour et al.
conducted simulations to show that static analysis is not sufficient to capture longterm fairness issues.
researchers focused on the predictive policing model to investigate the divergence of fairness over time .
algorithmic solutions have also been proposed by considering the temporal factor of fairness in the sequential selection process .
albarghouthi and vinitsky proposed a runtime specification language to monitor fairness statistics and provide warnings for violations.
henzinger et al.
built retrospective analysis and proposed a runtime statistical estimator to avoid long term unfairness.
several ml algorithms have been proposed for optimizing a longterm fairness objective under certain assumptions or fixed environmental dynamics .
however no prior work has focused on analyzing the influence of system parameters on long term fairness.
understanding the dynamics of fairness requires modeling the system and its context and difficult to achieve through static analysis .
feedback loops.
an emerging problem for ml systems is to ensure robustness in presence of feedback loops .
o neil explained several harmful feedback loops in sociotechnical systems at length.
pagan et al.
classified the different types of feedback loops in ml enabled systems.
with an emphasis on accuracy most of the ml research in the area focuses on data bias and distribution shifts induced from feedback .
however designing an ml system for long term fairness would need adaptive design and mitigation strategies .
recently reader et al.
proposed a system theory based approach to quantify feedback in sociotechnical systems.
martin jr et al.
also recommend system level analysis and in depth understanding of the societal context to identify feedback loops.
to that end we have built a simulationbased framework to analyze long term fairness issues.
xi.
d iscussions the simulation based analysis in fairsense relies on an environmental model that describes how the environment evolves in response to the system output.
fairsense is specifically designed to enable reasoning about interactions between the system and the environment when certain details about the environment are unknown at the design time these details can be encoded as environmental parameters which are then explored by the tool to provide insights into their impact.
this allows the system designer to identify which uncertainty in the environment is most important to focus their efforts on rather than wasting efforts on aspects of the environment that matter little for fairness.
that is the challenge of creating an accurate environment model is not a limiting factor but a key motivation for sensitivity analysis in f airsense .
although our environmental models were derived from prior work as described in section vii in practice creating environment models would involve a requirements engineering process understanding relevant environment behaviors from stakeholders and domain experts.
beyond requirements engineering techniques the system dynamics community has long studied a rich set of methods for building simulating and analyzing environmental models in socio technical systems .
one promising method is a type of modeling notation called causal loop diagram cld which is used to model the environment as a set of variables parameters in our terminology relationships between those variables i.e.
shift dynamics and possible feedback loops that arise from them .
clds have been used to model and simulate the environment in a wide range of domains such as economics social sciences ecology and public policy methodologies for developing clds are also well studied .
clds have also been adopted in requirements engineering to model the impact of software on sustainability for example although not yet in the context of fairness as far as we know.
a complementary approach to improving the quality of the models used in fairsense isruntime monitoring .
once a system is deployed observations collected from the environment i.e.
new data samples could be used to evaluate whether the environment model is consistent with the actual environmental behavior.
if there are discrepancies possibly due to inaccurate modeling or data drift this information could be used to update the model and improve its fidelity.
recent work in runtime monitoring for fairness could be adopted for this purpose as part of a framework like f airsense .
xii.
c onclusions understanding the impact of design decisions for mlenabled systems has received much attention recently.
many ml interventions have been proposed to improve algorithmic fairness in static settings however the long term impact of such interventions is still unclear as the system interacts with the environment over time possibly forming unexpected feedback loops.
precisely understanding the environment to accurately predict long term fairness is challenging.
to this end we have proposed fairsense to aid developers in identifying and understanding design decisions and environmental factors that impact long term fairness.