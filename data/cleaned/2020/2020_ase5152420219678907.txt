can neural clone detection generalize to unseen functionalities?
chenyao liu school of software tsinghua university liucy19 mails.tsinghua.edu.cnzeqi lin microsoft research asia zeqi.lin microsoft.comjian guang lou microsoft research asia jlou microsoft.com lijie wen school of software tsinghua university wenlj tsinghua.edu.cndongmei zhang microsoft research asia dongmeiz microsoft.com abstract many recently proposed code clone detectors exploit neural networks to capture latent semantics of source code thus achieving impressive results for detecting semantic clones.
theseneural clone detectors rely on the availability of large amountsof labeled training data.
we identify a key oversight in thecurrent evaluation methodology for neural clone detection cross functionality generalization i.e.
detecting semantic clones ofwhich the functionalities are unseen in training .
specifically wefocus on this question do neural clone detectors truly learn theability to detect semantic clones or they just learn how to modelspecific functionalities in training data while cannot generalizeto realistic unseen functionalities?
this paper investigates howthe generalizability can be evaluated and improved.
our contributions are folds we propose an evaluation methodology that can systematically measure the cross functionality generalizability of neural clone detection.
based onthis evaluation methodology an empirical study is conducted andthe results indicate that current neural clone detectors cannotgeneralize well as expected.
we conduct empirical analysisto understand key factors that can impact the generalizability.we investigate factors training data diversity vocabulary and locality.
results show that the performance loss on unseenfunctionalities can be reduced through addressing the out of vocabulary problem and increasing training data diversity.
wepropose a human in the loop mechanism that help adapt neuralclone detectors to new code repositories containing lots of unseenfunctionalities.
it improves annotation efficiency with the com bination of transfer learning and active learning.
experimentalresults show that it reduces the amount of annotations by about88 .
our code and data are publicly available .
index t erms code clone detection generalization neural network evaluation methodology human in the loop i. i ntroduction code clone detection is the task of finding similar code fragment pairs i.e.
clones within or between software systems.
it has become an important part in many software engineeringtasks such as software refactoring quality manage ment defect prediction plagiarism detection and program comprehension .
work done during an internship at microsoft research corresponding author recent years many neural network based methods are proposed for detecting semantic clones and they have achieved impressive results .
semantic clones areclones in which code fragments implement the same func tionality but may have low syntactic similarity.
for example a quick sort code and a heap sort code should be con sidered semantically equivalent.
traditional matching basedcode clone detectors e.g.
token matching based methods treematching based methods and graph matching based methodswork well in detecting syntactic clones while previous studies found that they had limited success with semanticclones.
to address this problem a recent research trend isto leverage deep neural networks to effectively capture com plex semantic information in code fragments.
for example some studies e.g.
cdlh astnn and tbccd focus on learning from abstract syntax trees asts and some other studies focus on learning fromcontrol flow graphs cfgs or program dependency graphs pdgs .
these studies have achieved impressive results inwidely used code benchmarks for code clone detection e.g.
bigclonebench gcj and ojclone state of the art neural clone detectors achieve more than precisionand recall.
existing neural clone detectors are supervised relying on a large number of annotated true false code fragment pairs fortraining.
this paper identifies a key oversight in the currentevaluation methodology for neural clone detection cross functionality generalizability the ability to detect semantic clones of which the functionalities have never beenpreviously observed in the training dataset.
for example a good neural clone detector should be able to find clones of sort algorithms even if the training datacontain no code fragments of sorting.
this generalizability isa critical aspect to measure whether neural clone detectioncan be applied in practice at scale because there area potentially infinite number of functionalities in real worldsoftware systems especially for domain specific softwaresystems making it almost impossible to construct a large6172021 36th ieee acm international conference on automated software engineering ase 36th ieee acm international conference on automated software engineering ase .
ieee .
ase51524.
.
.
ieee scale training dataset that covers most functionalities it is expensive and not scalable to annotate specific training datasetfor each domain.
the current evaluation methodology for neural clone detection does not systematically test the cross functionality gener alizability.
due to annotation difficulties the benchmarks withmany semantic clones usually have a limited number of func tionalities.
for example bigclonebench gcj and ojclonehave functionalities respectively.
training test setsare randomly sampled from all annotated code fragment pairs with the restriction that a code fragment should not appear inboth training set and test set.
in this setting whether a clonedetector can generalize to unseen code fragments or not iswell tested but the cross functionality generalizability is not.a reasonable concern is do neural clone detectors really learnto model semantic equivalence of code fragment pairs or theyjust simply remember fixed patterns of fixed functionalities?
in this paper we aim to answer three questions how does neural clone detection generalize to unseen functionalities?
if the cross functionality generalizability of neural clone detection is limited what are the key factors that impact it?
in a new domain how to learn an accurate neural clone detector with minimal cost?
our first contribution is a simple yet realistic evaluation methodology for the generalizability of neural clone detec tion and an empirical study based on it.
currently annotated code fragment pairs are divided into training test sets basedon code fragments.
this setting tests whether the detector cangeneralize to unseen code fragments but not a complete testof the generalizability for unseen functionalities.
to addressthis problem we improve the evaluation methodology throughfunctionality based re partition of training test sets.
we thenuse this methodology to test the generalizability of neuralclone detection on ojclone dataset which contains func tionalities .
in particular we divide these functionalitiesinto groups and run experiments on different training testsettings.
our empirical observation is neural clone detectionsuffers from significant performance degradation on average f1 score decreases from .
to .
in cross functionalitysettings.
this result motivates our second contribution a series of experiments are conducted to understand the factors that impact the cross functionality generalizability.
specifically we examine potential improvement directions training data diversity.
we define training data di versity as the total number of functionalities in trainingset.
we hyphothesize that the cross functionality gen eralizability can benefit from increasing training datadiversity.
our empirical results confirm this hypothesiswhile significant marginal effects are observed.
vocabulary.
neural networks in software engineeringtasks usually suffer from the out of vocabulary oov problem tokens in test set may rarelyor even never occur in training set thus these tokensare not effectively modeled in neural networks.
thevocabulary of different functionalities is likely to bevery different.
therefore we hypothesize that adress ing the oov problem can alleviate the lack of cross functionality generalizability.
our empirical results con firm this hypothesis.
locality.
common wisdom in machine learning com munity suggests that we should use attention mechanismto better model local structures of data especially fortheir latent alignments .
we apply this ideato neural clone detection and study whether it canhelp improve cross functionality generalizability.
ourempirical results show that this mechanism brings littleimprovement for generalizability.
finally our third contribution is a human in the loop mechanism that efficiently bootstraps neural clone detec tors for unseen functionalities with only a small amountof human efforts.
the scenario is we have a training dataset a but we want to learn a good neural clone detector thatcan find semantic clones in a new lower resourced domainb containing many functionalities that have never been previously observed in a .
the key point of this human inthe loop mechanism is the combination of transfer learningand active learning we learn a preliminary neural clonedetector on domain a then use it to actively select informative code fragment pairs in domain bfor human annotation thus transferring the neural clone detector from domain ato domainb.
experimental results show that this human in theloop mechanism reduces the amount of annotations by thus alleviating the difficulty that neural clone detectors cannotwell extend to various real world code repositories.
more broadly these contributions may impact research on neural source code representation i.e.
encoding codefragments to continuous vectors based on neural networks which has attracted much attention in recent years .neural source code representation has been widely used andachieved impressive results not only in code clone detection but also in various software engineering tasks e.g.
codecompletion code search code summarization code translation and defect prediction .
in this paper we use codeclone detection as a case study to show the importance of studying the dependence of supervised neural methods ontraining data probing whether these methods can gener alize beyond training data.
we suggest that a generalization aware evaluation methodology should be used to better eval uate neural methods in software engineering community andmore future efforts should be made to improve generalizability.
ii.
b ackground a. semantic clones and neural clone detection existing research work divides code clones into four major types type identical code fragments except for differencesin white space layout and comments.
type identical code fragments except for differences in identifier names and literal values as well as type 1differences.
type syntactically similar code fragments that differ atthe statement level.
the fragments have statements added modified and or removed with respect to each other inaddition to type and type clone differences.
type syntactically dissimilar code fragments that im plement the same functionality.
as there is no clear boundary between type clones and type clones we vaguely define semantic clones as the union of type clones and type clones that cannot easily bedetected by pre defined rules.
figure shows an examlple of semantic clone type .
even through the functionality of these two code fragmentsis very simple calculates xraised to the power n different programmers may implement it in totally different ways.
in recent years many neural network based methods are proposed for detecting such semantic clones and they haveachieved impressive results both precision and recall arehigher than .
most of these neural clone detectors sharethe same model paradigm match c c prime f c c prime wherecandc primeare two code fragments is a learnable neural network that encodes each code fragment as a vector andfis a function that measures the semantic similarity between two vectors.
the code fragment pair c c prime will be regarded as a clone if and only if match c c prime is larger than a threshold .
researchers usually define fbased on cosine similarity euclidean distance or linear classification.
the key in theseneural clone detectors is the source code representation method .
in cdlh is an ast based lstm network.
in astnn is an ast based rnn network in which each large ast is split into a sequence of small statementtrees thus alleviating the long term dependency problem.
intbccd is an ast based convolution network.
in deepsim is based on a matrix based representation which encodes code control flow and data flow.
b. rethinking semantic clone benchmarks to evaluate the effectiveness of neural clone detectors some benchmarks that contain a large number of semantic clones have been proposed and widely used.
as it is challenging for annotators to find in the wild semantic clones from large scale code repositories these benchmarkswere usually created based on specific functionalities.
big clonebench is a clone detection benchmark containing7 ground truth clones .
of them are semanticclones while all of them are clones of specific func tionalities.
to create this benchmark the researchers beganby selecting commonly needed functionalities in open source java projects as target functionalities e.g.
bubble sort web download and decompress zip .
code fragments i.e.
1doublepower double x intn 2doubletemp 3if n return1.
4temp power x n 5if n returntemp temp 7else if n returnx temp temp else return temp temp x 13doubleexponent double x intn 14if n n!
int min n 15doubleans .
16for int i i sizeof int char bit i if n n n!
int min ans x x x x n n 22if n int min ans x 23returnn ?
.
ans ans fig.
an example of semantic clone type .
functions that might implement a target functionality were identified using keywords and source code pattern heuristics then these identified code fragments were manually tagged astrue or false positive of the target functionality by judges.
alltrue positive code fragments of a functionality form a largeclone group.
ojclone is a dataset that contains func tionalities.
specifically each functionality is a programmingquestion on openjudge and there are corresponding solutions submitted by students written in c passing alltest cases for each functionality.
originally this dataset wascreated for program classification but researchers also widelyused it as a clone detection benchmark two code fragments i.e.
solutions are regarded as a ground truth clone if andonly if they are solutions of the same functionality.
gcj is a benchmark similar to ojclone.
it contains 669solutions written in java for different functionalities i.e.
programming questions from google code jam contests .
we carefully rethink the impact of specific functionalities on the evaluation of neural clone detection.
our main concern isthat neural networks may just learn how to classify these spe cific functionalities rather than how to detect semantic clones.this concern origins from the fact that neural clone detectorsrely on a large number of true false clones for training.
thestandard evaluation methodology is to divide data into disjointtraining and test sets.
however the diversity of functionalitiesis limited in these benchmarks leading to the result that foreach code fragment in test set there are always many codefragments in training set that have the same functionality asit.
therefore though neural clone detectors achieved goodperformance in this experimental setup a possible reason forthe good performance is that neural networks learn to representthese specific functionalities well.
619this is not a true evaluation of neural clone detection as it is an essential need that clone detectors should find clones of various functionalities rather than just specific functional ities that have been previously observed in training set.
thecurrent evaluation methodology cannot tell us about a neuralclone detector s generalizability to handle code fragments ofunseen functionalities.
therefore it is necessary to improvethe evaluation methodology and revisit existing neural clonedetectors based on it.
iii.
e v alua ting generalizability a. an improved evaluation methodology to evaluate the cross functionality generalizability of neural clone detection we propose an improved evaluation method ology.
the intuition is simple yet effective training test setsin current benchmarks should be re partitioned with therestriction that no functionality is allowed to appear in bothof them.
here we give the formalism description.
dis a dataset that contains many code fragments c c c2 ... c c .fis the set of functionalities f f1 f2 ... f f .
take ojclone as an example we have f and c .
l c fis a function that indicates the functionality of each code fragment.
for each dataset lis a known function that is determined from the collection procedure of the dataset.
to obtain training test sets for evaluating neural clone detectors we propose the following steps creating functionality groups.
we divide functionali ties f intokdisjoint groups as evenly as possible k is a hyper parameter .
we denote these groups as g g2 ... gk.
creating training test grid.
for each i j k w e set an experiment ei jin which neural clone detectors are trained on functionalities in giand tested on functionalities in gj.
therefore we have k kexperiments with different training test functionality groups and weform them as a grid.
we define that an experiment isanunseen functionality experiment i f g i negationslash gj otherwise we define this experiment as a seen functionality experiment.
sampling code fragment pairs.
for each function ality group g i i k we randomly sample disjoint sets of code fragment pairs from c x cy i c c prime c c prime c l c l c prime gi c negationslash c prime whereiis an indicator function i c c prime braceleftbigg 0l c negationslash l c prime 1l c l c prime we denote these sets as ptrain i pdev i andptest i respectively.
for each experiment ei j i j k neural clone detectors will be trained on ptrain i validated on pdev j and then tested on ptest j .
neural clone detectors formulate semantic clone detection as a binary classification task and use precision recall f1 scoreas evaluation metrics.
previous studies proved that existingtable i performance of two neural clone detectors whengeneralizing to unseen functionalities average f1 score g1g2g3g4g5g6g7 av g astnn seen .
.
.
.
.
.
.
.
unseen .
.
.
.
.
.
.
.
tbccd seen .
.
.
.
.
.
.
.96unseen .
.
.
.
.
.
.
.
afr rate astnn .
afr rate tbccd .
xgotb kyz fig.
f1 results of astnn trained on different functionality groups y axis and tested on different functionality groups x axis .
each cell is colored according to f1 score the deepera cell is colored the better the neural clone detector performsin the corresponding experiment setting e i j .
neural clone detectors can achieve very high performanceone i jifi j. however we cannot conclude that these neural code detectors well learn how to find semantic clones or they just learn how to classify specific functionalities ing i. therefore we need to report p r f1 results for each ei j i negationslash j .
as this may involve many result numbers we further introduce average f1 remaining rate afr rate a new metric to summarily evaluate the cross functionalitygeneralizability of neural clone detection afr rate summationtext i negationslash j i jf1 ei j k summationtext if1 ei i the more afr rate is higher than the more it indicates that the neural clone detector has cross functionality generalizability.
b. experimental setup we conduct empirical experiments to evaluate the crossfunctionality generalizability of neural clone detection.
we choose two state of the art neural clone detectors astnn andtbccd as our evaluation objects.
we build our benchmark based on ojclone dataset.
this dataset has functionalities which is much more thanbigclonebench functionalities and gcj functionali ties .
all these ojclone functionalities are divided into7 groups g g2 g3 ...g7 g1contains functionality 620table ii how does training data diversity impact generalizability average f1 score afr rate g1g2g3g4g5g6g7 average w.r.t.
baseline astnn training data diversity .
.
.
.
.
.
.
.
training data diversity .
.
.
.
.
.
.
.
.
training data diversity .
.
.
.
.
.
.
.
.
training data diversity .
.
.
.
.
.
.
.
.
training data diversity .
.
.
.
.
.
.
.
.
training data diversity .
.
.
.
.
.
.
.
.
tbccd training data diversity .
.
.
.
.
.
.
.
training data diversity .
.
.
.
.
.
.
.
.
training data diversity .
.
.
.
.
.
.
.
.
training data diversity .
.
.
.
.
.
.
.
.
training data diversity .
.
.
.
.
.
.
.
.
training data diversity .
.
.
.
.
.
.
.
.
ids g2contains functionality ids and so on.
g7only contains functionalities ids .
for each groupgi i we sample code fragment pairs as ptrain i pdev i ptest i .
c. results and observations table i shows the performance of two neural clone detectors when generalizing to unseen functionalities.
columns g1 g2 ... g 7represents different functionality groups for test.
we use seen to denote that training data are collected from the same functionality group as the test set and weuse unseen to denote that the training set share no common functionality with the test set.
for example for astnn wehave summationtext i 2f1 ei .
.
figure shows detailed f1 results of astnn trained on different functionality groups y axis and tested on different functionality groups x axis .
our observations are as follows good ability for modeling seen functionalities.f o reach experiment in which all test functionalities havebeen previously observed in training set i.e.
exper iments on the diagonal from top left to bottom right infigure astnn achieves very high performance.
allthe experiments have f1 score higher than .
and theaverage f1 score is .
.
these results are consistent withthe results reported in the original astnn paper.
how ever as discussed in section ii b we argue that resultson such experiment settings can only indicate that theneural clone detector s ability to represent code fragmentsof seen functionalities but not the true ability to detectsemantic clones that may involve unseen functionalities.
cannot well generalize to unseen functionalities.
fromexperiments outside the aforementioned diagonal i.e.
e i jfor each i j 7andi negationslash j we can observe that astnn cannot generalize to unseen functionalitiesas expected.
f1 scores of these experiments range from0.
e to .
e4 .
the average f1 score is .
.
these results indicate that the essence of thelearned models is likely to be program classification rather than clone detection.
therefore it is difficult to useastnn in real world code clone detection scenarios.in tbccd our observations are the same as those in astnn.
finding to evaluate neural clone detectors we need tominimize the functionality overlap between trainingset and test set thus truly indicating the generalizabilityfor detecting real world semantic clones.
the ideal way to minimize functionality overlap is to collect semantic clones in the wild rather than specifying severaltarget functionalities in advance just as bigclonebench ojclone and gcj do .
however this would be too costlyfor human annotation.
therefore to evaluate neural clonedetectors more efficiently we make a trade off we still needto specify several target functionalities in advance but thetotal number of target functionalities should be as manyas possible e.g.
and the training test set should be split based on functionalities.
previous researches usingrandom training test splits suffer from serious functionalityleak problem resulting in models achieving almost perfectevaluation results exhibit poor real world performance.
ourproposed evaluation methodology addresses this problem thuscan better indicating the real performance of neural clonedetectors though it is still not as solid as evaluating in thewild .
iv .
k eyfactors of generalizability in this section we explore to understand key factors that impact the cross functionality generalizability of neural clonedetection.
specifically we mainly investigate potential di rections training data diversity vocabulary and locality.
a. training data diversity to investigate key factors of cross functionality generalizability one hypothesis is that h1.
the cross functionality generalizability of neural clone detection can be improved through increasing training data diversity.
here we define training data diversity as the total number of functionalities in training set.
621this hypothesis is proposed based on the fact that each of our experiments in section iii b uses only one functionality group for training i.e.
training data diversity is g o r1 g1 g6 .
a possible reason for the lack of cross functionality generalizability is that neural clone detectors are likely todegenerate to program classifiers for specific functionalitieswhen they are trained on a dataset with small functionalitydiversity this problem may be alleviated or addressed throughincreasing training data diversity.
it is essential to study this hypothesis if cross functionality generalizability can be significantly improved through in creasing training data diversity an important direction forfuture work is to improve the data collection methodology forbetter functionality diversity otherwise it indicates that wecannot equip existing neural clone detectors with true cross functionality generalizability through collecting much moretraining data thus future work should focus on improvingthese neural model architectures.
we conduct a series of experiments to study this hypothesis.
these experiments are set up based on the following steps select a functionality group for test.
here we use g 1as an example.
useg2for training that is train a neural clone detector astnn tbccd on p2 train and test it on p1 test.
in this experiment the training data diversity is .
useg2 g3for training.
training data are sampled from pairs of which code fragments are of functionalities ing g3 i.e.
the training data diversity is .
we use the same sampling amount as p2 train i.e.
.
we also keep the same positive rate in training data i.e.
t o prevent suffer from the class imbalance problem causedby the growth of training data diversity.
useg g3 g4for training.
the training data diversity is .
useg2 g3 g4 g5for training.
the training data diversity is .... draw results of the above experiments as a line chart of the influence of training data diversity on clone detectionperformance f1 score .
we useg g2 ... g 7for test respectively thus we draw lines in the line chart.
figure shows the results of astnn.our observations are as follows increasing training data diversity can significantly im prove the cross functionality generalizability of neuralclone detection.
for example consider astnn g the f1 score is .
when the training data diversity is the f1 score will increase to .
when the training datadiversity is .
an increase of .
is observed.
forg g2 ... g the increase ranges from .
to .
and the average increase is .
.
there are significant marginal effects to improve neuralclone detection through increasing training data diversity.for example consider astnn g the f1 score increases from .
to .
when the training data diversityfig.
influence of training data diversity on performanceof neural clone detection astnn .
we can observe that increasing training data diversity can significantly improve theperformance of neural clone detection but there are significantmarginal effects.
increases from to while the increase is only .
from .
to .
when the training data diversityincreases from to .
for g g2 ... g the average f1 increase for training data diversity 45is .
accounting for .
of the increase for .
we regard these results as significant marginal effects which indicates that it is not likely to be sustainable thatimproving neural clone detection through continuouslyincreasing training data diversity.
table ii lists detailed results of both astnn and tbccd.
in tbccd our observations are the same as those in astnn.
finding to train neural clone detectors training set with diverse functionalities can alleviate the problem of lacking cross functionality generalizability.
however due to the marginal effect this is not a silver bullet tocompletely address this problem.
b. v ocabulary common wisdom suggests that vocabulary is a key factor that may impact the effectiveness of neural networks espe cially for source code modeling .
neural clonedetectors need to represent tokens as numerical representationsso that the lexical information can be fed into the neural net works.
these tokens include reserved words in programminglanguages e.g.
if int and break built in functions and data structures e.g.
abs and vector programmerdefined identifiers e.g.
x y and max distance etc.
in general methods a static vocabulary is extracted from trainingset mainly based on token frequency then all tokens whichare not in this vocabulary will be converted to a specifictoken unknown .
this works well in natural language processing but may be problematic for source code.
this ismainly because that programmers are free to create various 622table iii how does vocabulary impact generalizability average f1 score afr rate g1g2g3g4g5g6g7 average w.r.t.
baseline astnn test data average unk rate .
.
.
.
.
.
.
.
.
test data average unk rate .
.
.
.
.
.
.
.
.
.
test data average unk rate .
.
.
.
.
.
.
.
.
.
test data average unk rate .
.
.
.
.
.
.
.
.
.
tbccd with pace .
.
.
.
.
.
.
.
w o pace .
.
.
.
.
.
.
.
.
tokens especially variable names and function names thus aggravating the out of vocabulary oov problem.
that is in test set a large amount of tokens will be converted to unknown thus the lexical information they carry will be lost.
therefore an intuitive hypothesis is that h2.
the cross functionality generalizability of neural clone detection can be improved through addressing the oov prob lem caused by vocabulary.
in tbccd position aware character embedding pace a simple yet effective method for alleviating the oov problemin source code is proposed.
therefore tbccd does notsuffers from the oov problem.
the key point of paceis to not treat each token as an individual building block but a position weighted combination of characters one hotembeddings.
that means for a token that has kcharacters denoted as c c2 ... ck its embeddings can be obtained with equation summationtextk i 1k i k emb whereemb is the onehot embedding of ci.
to summarize pace learns character embeddings then generates the embedding of each word by assembling embeddings of every characters in this word.therefore pace addresses the oov problem at the cost oflower capability of word level semantics.
the tbccd paperreported that though the effectiveness of pace is marginalin random training test splits it can bring significant gain incross functionality splits.
we conduct an ablation experiment in which pace is replaced by a regular token embedding layer i.e.
tbccd w o pace in table iii and the result shows that the crossfunctionality generalizability is significantly reduced withoutpace.
this indicates that the oov problem brought byvocabulary is likely to be a key factor of generalizability.astnn uses a regular token embedding layer the vocabularyis defined as top frequent tokens in training set andtoken embeddings are pre trained using word2vec thus it may suffer from the oov problem.
when we apply paceto astnn we observe no improvement.
this indicates thatpace is not a universal solution to the oov problem in allmodel architectures.
we speculate that the reason is astnn requires a larger capability of word level semantics than tbccd.
tbccd isa tree based cnn model which mainly captures programsemantics from ast structures words are also important yet secondary .
therefore for tbccd addressing the oovproblem at the cost of lower capability of word level semanticswill do more good than harm.
unlike tbccd astnn isan rnn based model in which each code fragment are pre processed as a sequence rather than a tree.
therefore word level semantics plays a more important role in astnn thanin tbccd.
though pace can address the oov problem thisbenefit is offset by its lower capability of word level semantics.
we investigate the impact of vocabulary in astnn through breaking down test sets according to the percentage of unknown tokens.
specifically we create test sets that contain less unknown tokens than p test i i .
our assumption is if astnn performs better in test sets with less unknown tokens it means that astnn can benefit from reducing unknown tokens thereby indicating that the oov problem is a key factor that can impact cross functionalitygeneralizability.
for each experiment e i j we re sample the test set ptest j as follows.
for each functionality f gj we sort all code fragments of fby the percentage of unknown tokens in ascending order.
we keep the top of these codefragments.
then test sets are created from these code frag ments.
in p test i i the average unk rate is .
in test sets created from code fragments theaverage unk rate is .
.
.
.
therefore we denotethese test settings as astnn tested data average unk rate .
.
.
.
in table iii.
we observe thatastnn has better performance in test cases which less sufferfrom the oov problem on average the f1 score of astnn tested data average unk rate .
is .
which is muchbetter than the baseline .
.
this indicates that the problemof lacking cross functionality generalizability is likely to bepartly alleviated by addressing the oov problem.
finding the out of vocabulary problem is an important factor that limits the cross functionality gener alizability of neural clone detection.
character level orsubword level token embeddings e.g.
pace can helpalleviate this problem but are not universal enough forvarious neural clone detectors.
c. locality we consider a consensus in machine learning community local structure inference between two objects is essential fordetermining the overall inference between these two objects .
for example in natural language processing if we 623table iv how does locality impact generalizability average f1 score g1g2g3g4g5g6g7 av g astnn .
.
.
.
.
.
.
.
with locality .
.
.
.
.
.
.
.
want to learn a neural network model to determine whether two natural language sentences are semantically equivalent this model needs to employ some forms of alignment toassociate the relevant local structures e.g.
words phrases and clauses between two sentences.
in code clone detection task the objects are code fragments and the local structures can be statements code blocks sub asts etc.
figure shows an example of local structurealignment between code fragments.
intuitively suppose thatcode fragment ais semantically equivalent to code fragment b it is likely that some local structures in acan be aligned with some local structures in b. local structure alignment is more in line with human perception of code clone detection thus preventing neural clone detectors degenerate to programclassifiers.
based on this intuition we hypothesize that h3.
incorporating locality into model architecture can help improve the cross functionality generalizability of neural clone detection.
some recent research works of neural clone detection have incorporate locality into their model architectures but it is not easy to adapt their codes to ojclone.
therefore toinvestigate this hypothesis we use astnn as the base modelarchitecture and add a locality component on top of it basedon common practices in machine learning community.
we briefly summarize the workflow of astnn as follows a code fragment will be parsed into an ast then the ast will be split into a sequence of statement trees sttrees which are trees consisting of statement nodes asroots and corresponding ast nodes of the statements .
for each code fragment all st trees in it are encoded into individual vectors denoted as e ... et.
then astnn uses a bidirectional gated recurrent unit bi gru network to obtain their contextual vectors de noted as h ... ht.
code fragment representation is computed by max pooling of h1 ... ht then whether a pair of code fragments is a clone is determined by euclidean distance betweentheir representations.
we incorporate locality into astnn through introducing attention based alignment between contextual vectors of st trees h .
notice that we do not propose a novel localitycomponent for improving neural clone detection instead thegoal of this part is to leverage a state of the art localitycomponent of which the effectiveness has been wellproved in machine learning community to study whetherlocality is a key factor for cross functionality generalizability.
suppose that we have two code fragments c h ... ht andc prime h prime1 ... h primet prime we add a soft alignment layer to fig.
an example of local structure alignment betweencode fragments.
intuitively suppose that code fragment ais semantically equivalent to code fragment b it is likely that some local structures e.g.
statements or blocks in acan be aligned with some local structures in b. astnn tildewideh i t prime summationdisplay j 1exp hi h primej summationtextt prime k 1exp hi h primek h prime j i intuitively in equation the content in h prime j t prime j 1that is relevant to hiwill be selected and represented as tildewidehi.
the same is performed for each st tree in c prime.
then we use a bi gru network to convert local alignment information tildewideh to local alignment aware contextual representations h mi h1 ... ht bi gru m1 ... mt representation of code fragment cwill be computed by max pooling of h1 ... ht and the remaining steps remain exactly the same as astnn.
table iv shows the experimental results.
we disappointedly find that the cross functionality generalizability of neural clone detection cannot benefit from incorporating with the localitycomponent.
we speculate that the reasons may be three folds code fragments that are semantically equivalent mayhave totally different syntactic structures as figure shows making neural networks difficult to leverage local structurealignment information.
the oov problem discussed insection iii also lead to lots of noisy alignments.
thelocality component we use is more suitable for sequence data i.e.
natural language sentences rather than tree data i.e.
asts of code fragments thus tree based locality componentmay be a potential direction for improvement.
finding in neural clone detection local structure align624annotator neural clone detectoractively provide informative code fragment pairs human annotation for model transferringsource domain dataset labeled preliminary trainingtarget domain dataset unlabeled candidate pool fig.
human in the loop mechanism for domain adaptation of neural clone detection.
ment has not yet been well leveraged to improve cross functionality generalization.
v. h uman in the loop for domain adapta tion a. task domain adaptation from section iii and iv we can conclude that neural clone detectors cannot well generalize to unseen functionalities asexpected.
though we find that this problem can be alleviatedthrough addressing the oov problem caused by vocabularyand increasing training data diversity there is still a largeperformance gap afr rate is about for astnn t bccd .
therefore it is not a good idea to train existing neuralclone detectors on a common dataset and directly use them tofind semantic clones in various code repositories that containlots of functionalities that have never been previously observedin the training set.
instead for each individual code repository if we want to find semantic clones effectively with highprecision and recall we have to annotate a specific trainingset for this code repository.
this is expensive thus limiting thescalability of neural clone detection in real world scenarios.
we formulate this as a domain adaptation problem that is how to adapt a model i.e.
neural clone detector learned fromone domain i.e.
the training set to a new domain i.e.
anew code repository containing lots of unseen functionalities .here we define that two domains are different if they containdifferent functionalities.
b. solution human in the loop we propose a human in the loop mechanism see figure to address this domain adaptation problem.
the key point is a little annotation does a lot of good based on the combination of transfer learning and active learning.
givena neural clone detector learned from a high resource domain our goal is to adapt it to a unlabeled target domain.
to achievethis our human in the loop mechanism automatically exploresthe target domain and actively select most informative ratherthan random code fragment pairs that can help transfer theneural clone detector learned from source domain to the targetdomain.
human annotate these actively selected code fragmentpairs whether this pair is a clone or not then these annotateddata are leveraged as new training samples to update thealgorithm human in the loop mechanism input dsrc annotated dataset of source domain ctrg code fragments of target domain oracle human annotators m active query batch size v informative degree measurement function output model a neural clone detector for target domain 1model trainmodel dsrc 2pool candidate code fragment pairs from ctrg 3dtrg 4while budget not exhausted do 5queries topmpairs inpool byv model pair 6dtrg dtrg oracle queries 7model trainmodel dsrc dtrg 8end neural clone detector.
this mechanism helps domain adap tation of neural clone detection through improving annotationefficiency human just need to annotate a small collection ofsamples which is much smaller than regular annotation toachieve an accurate neural clone detector for the low resourcetarget domain.
algorithm is an overall procedure of this human in theloop mechanism.
it exploits both transfer learning and activelearning to improve annotation efficiency.
in the following weexplain this algorithm from these two aspects.
transfer learning the goal of transfer learning is to leverage knowledge learned from source domain and apply itto target domain.
in algorithm we train an neural clonedetector on source domain as our preliminary model line1 .
once the oracle i.e.
human annotators provides someannotated code fragment pairs in target domain these data willbe used to update the model line .
therefore the neuralclone detector will be transferred from source domain to targetdomain iteratively.
there are two optional strategies for modelupdate one is to iteratively fine tune the model with newlyannotated data and the other is to learn from scratch i.e.
re train the model on d src dtrg in each iteration.
in the fine tuning strategy there are some hyper parameters such aslearning rate and the number of fine tuning epochs and it isnot easy to find the best setting of these hyper parameters foreach scenario in different scenarios the best hypher parametersettings are usually different .
our preliminary experimentsshow that results of these two model update strategies arecomparable thus we finally choose the learning from scratchstrategy line as it is much simpler than fine tuning.
active learning after training a preliminary model from source domain we start the active learning process basedon this model s outputs.
the first step of active learning is to create a pool consisting of many candidate unlabeled code fragment pairs from targetdomain line .
there are optional strategies for creatingthis pool it can be all possible code fragment pairs in the target a performance when the source domain is g1and the target domain isg3 b performance when the target domain is g3 and the source domain isg1 g2 g4 g5 g6 g7 fig.
human in the loop mechanism performance.
the horizontal dashed line is the performance of the model trainedon annotated samples from target domain.
reachingthe horizontal dashed line means that our human in the loopmechanism successfully transfer the neural clone detector astnn to the target domain.
domain if the total number of code fragments in this domain is not large or we can just use a part of it through simplerandom sampling in real world scenarios considering thatclones are sparse in randomly sampled code fragment pairs wecan also use some heuristics to filter out code fragment pairsthat are unlikely to be clones before sampling e.g.
whethertwo code fragments have the same input output data types .
after that we actively select mcode fragment pairs from the pool line .
human annotators label whether each ofthesempairs is a clone or not line then these newly annotated data are used for transfer learning line .
thisprocedure iterates until the budget for data annotation usuallyvery limited is exhausted.
the key in active learning is the informative degree measurement function v. the actively selected pairs should behighly informative thus they can help the model be trans ferred to target domain efficiently.
in this paper we computev model pair based on model uncertainty v model pair max l p l model pair p model pair is the model s estimated probability that this pair is a clone and we have p model pair p model pair .
intuitively v model pair can be regarded as the uncertainty of the model given the pair.
thehigher the uncertainty is the more it means that this pair islikely to help improve the model.
therefore in each activelearning iteration we select candidate code fragment pairs withtopmuncertainty for human annotation.
besides these uncertainty based methods many methods have been proposed in the literature to better find informativesamples for active learning.
for example some methods arebased on representative and some others are based ondiversity .
in this paper we think our uncertainty basedmethod is simple and effective enough thus we leave theexploration of other sample selecting methods to future work.
c. simulation experiments we conduct simulation experiments to evaluate the effectiveness of our human in the loop mechanism.
setup we use astnn as the model architecture.
evaluation benchmark is created based on ojclone.
as discussed in section iii a we have divided all the functionalitiesin ojclone into groups and denote them as g g2 ... g .
for each group gi i we have created trainning development test sets ptrain i pdev i ptest i for it.
we select one functionality group gsrc as source domain and another functionality group gtrg as target domain for simulation experiment.
following algorithm the astnn model will beinitially trained on p train src then iteratively updated by samples actively selected from ptrain trg each iteration has msamples and finally validated tested on pdev trg ptest trg .
to investigate the impact of the hyper parameter m i.e.
active query batch size we evaluate the human in the loop mechanism withdifferent mvalues .
results and analysis figure shows the performance of our human in the loop mechanism in one simulation ex periment.
in figure 6a we randomly select g 1as the source domain and g3as the target domain.
the random curve means that the samples for annotation i.e.
queries in algorithm are randomly sampled from pool rather than actively selected by model .
it is used as an ablation study for proving the effectiveness of active learning.
the horizontaldashed line is the performance of the model trained on 000annotated samples from target domain.
if a curve reaches thishorizontal line when the x axis value is x it indicates that our human in the loop mechanism successfully transfer the neuralclone detector from source domain to target domain with x annotated samples for target domain.
from figure 6a we can observe that our human in the loop mechanism can significantly reduce data annotation efforts.
when m i t requires about annotations to transfer the astnn model to the target domain.
comparing to ptrain trg which has annotated samples in total we reduce theamount of annotations by about .
selecting informative candidate samples actively is important in this human in the loop mechanism.
whensamples for annotation are randomly sampled the random curve rather than actively selected curves m the performance significantly drops.
we also conduct another simulation experiment to examine how this human in the loop mechanism performs on trainingdata with higher diversity.
in this experiment the targetdomain is g and the source domain is g1 g2 g4 g5 g6 g7 training data diversity .
figure 6b shows the results.
in figure 6b we have the same observations as infigure 6a.
finding to adapt neural clone detection to real worldlow resourced domains our human in the loop mechanism can effectively reduce annotation efforts.
note that this experiment is simulated which means that we already have these annotations but only use some of them tosimulate the human annotation process.
this approach allevi ates the problem of lacking cross functionality generalizability but it is not a cure for the problem it can just reduce theannotation cost but still require users to label data in the targetdomains.
vi.
t hrea ts to validity we have identified the following main threats to validity programming languages.
our experiments are conducted based on ojclone dataset in which code fragmentsare written in c. there are some other clone detec tion datasets e.g.
bigclonebench and gcj which aremainly in java language.
the reasons why we onlyconduct experiments on ojclone is to prevent issues thatmay caused by the lack of functionality diversity e.g.
gcj dataset only has functionalities and data im balance e.g.
in bigclonebench the functionality copyfile accounts for .
of clone pairs and the top 10functionalities accounts for .
.
in principle neuralclone detectors are designed based on generalized pro gram structures e.g.
ast and pdg rather than specificprogramming languages.
therefore we can speculate thatour findings in this paper can generalize to other program ming languages.
in the future we will work to improveclone detection benchmarks in terms of functionalitydiversity and programming language diversity.
model evaluated.
in this paper we choose two state ofthe art neural clone detectors astnn and tbccd asour evaluation objects.
astnn is the representative ofrnn based models and tbccd is the representativeof cnn based models.
therefore we think findingsin this paper can generalize to other rnn cnn basedmodels which accounts for a large part of previous work.however we still need to further explore whether recentmethods based on gnns graph neural networks orplms pretrained language models have better cross functionality generalizability or not.
though currently wedo not know whether our findings got from rnn cnn based models can apply to gnn plm based models wesuggest that newly proposed neural clone detectors shouldbe evaluated based on a cross functionality methodologyto alleviate threats to validity.
vii.
c onclusion in this work we identify a key oversight in the current evaluation methodology for neural clone detection cross functionality generalizability i.e.
the ability to detect se mantic clones of which the functionalities have never beenpreviously observed in the training dataset .
our contributionsare folds by proposing an evaluation methodology forcross functionality generalizability we conduct experimentson two state of the art neural clone detectors and find thatthey cannot well generalize to unseen functionalities as ex pected.
to understand key factors that impact the cross functionality generalizability we conduct empirical analysison factors training data diversity vocabulary and locality and find that the performance loss on unseen functionalitiescan be reduced through increasing training data diversityand addressing the out of vocabulary problem.
to adaptneural clone detectors to new code repositories containinglots of unseen functionalities we propose a human in the loopmechanism that helps reduce the amount of annotations byabout .
our analysis has clear implications for future work new neural code clone detectors should be evaluated onfunctionality based data splits to ensure that they can general ize to real world scenarios.
based on findings in this paper future research directions for improving cross functionalitygeneralizability include addressing the oov problem ex ploring better model architectures that have the capability tobenefit from more diverse training data exploring unsuper vised or semi supervised methods that can exploit large scaleunlabeled code fragments to improve neural clone detection.
human in the loop is an efficient way to adapt neural clonedetection to low resource real world code repositories and apotential research direction is to explore better algorithms forselecting informative code fragment pairs.
more broadly these implications are not limited to neural clone detection but also various neural source code representation methods.
a cknowledgments the work was supported by the national key research and development program of china no.
2019yfb1704003 thenational nature science foundation of china no.
71690231and no.
tsinghua bnrist and beijing key labo ratory of industrial bigdata system and application.
627references p .
weissgerber and s. diehl identifying refactorings from source code changes in 21st ieee acm international conference on automated software engineering ase .
ieee pp.
.
s. kawaguchi t. yamashina h. uwano k. fushida y .
kamei m. nagura and h. iida shinobi a tool for automatic code clone detection in the ide in 16th working conference on reverse engineering.
ieee pp.
.
y .
dang d. zhang s. ge c. chu y .
qiu and t. xie xiao tuning code clones at hands of engineers in practice in proceedings of the 28th annual computer security applications conference pp.
.
n. a. milea l. jiang and s. c. khoo v ector abstraction and concretization for scalable detection of refactorings in proceedings of the 22nd acm sigsoft international symposium on foundations ofsoftware engineering pp.
.
e. juergens f. deissenboeck b. hummel and s. wagner do code clones matter?
in ieee 31st international conference on software engineering.
ieee pp.
.
e. juergens f. deissenboeck and b. hummel clonedetective a workbench for clone detection research in ieee 31st international conference on software engineering.
ieee pp.
.
e. juergens f. deissenboeck m. feilkas b. hummel b. schaetz s. wagner c. domann and j. streit can clone detection supportquality assessments of requirements specifications?
in proceedings of the 32nd acm ieee international conference on software engineering v olume pp.
.
j. doe recommended practice for software requirements specifications ieee ieee new york .
c. k. roy j. r. cordy and r. koschke comparison and evaluation of code clone detection techniques and tools a qualitative approach science of computer programming vol.
no.
pp.
.
b. hummel e. juergens l. heinemann and m. conradt index based code clone detection incremental distributed scalable in ieee international conference on software maintenance.
ieee pp.
.
m. rieger effective clone detection without language barriers ph.d. dissertation v erlag nicht ermittelbar .
h. wei and m. li supervised deep features for software functional clone detection by exploiting lexical and syntactical information insource code.
in ijcai pp.
.
g. zhao and j. huang deepsim deep learning code functional similarity in proceedings of the 26th acm joint meeting on european software engineering conference and symposium on the foundationsof software engineering pp.
.
h. wei and m. li positive and unlabeled learning for detecting software functional clones with adversarial training.
in ijcai pp.
.
j. zhang x. wang h. zhang h. sun k. wang and x. liu a novel neural source code representation based on abstract syntax tree in2019 ieee acm 41st international conference on software engineering icse .
ieee pp.
.
h. y u w. lam l. chen g. li t. xie and q. wang neural detection of semantic code clones via tree based convolution in ieee acm 27th international conference on program comprehension icpc .ieee pp.
.
y .
y .
zhang and m. li find me if you can deep software clone detection by exploiting the contest between the plagiarist and the detector inproceedings of the aaai conference on artificial intelligence vol.
pp.
.
y .
li c. gu t. dullien o. vinyals and p .
kohli graph matching networks for learning the similarity of graph structured objects inproceedings of the 36th international conference on machine learning icml june long beach california usa ser.
proceedings of machine learning research k. chaudhuriand r. salakhutdinov eds.
vol.
.
pmlr pp.
.
.
available w. wang g. li b. ma x. xia and z. jin detecting code clones with graph neural network and flow augmented abstract syntax tree in ieee 27th international conference on software analysis evolutionand reengineering saner pp.
.
j. svajlenko and c. k. roy evaluating clone detection tools with bigclonebench in ieee international conference on software maintenance and evolution icsme .
ieee pp.
.
h. sajnani v .
saini j. svajlenko c. k. roy and c. v .
lopes sourcerercc scaling code clone detection to big code in proceedings of the 38th international conference on software engineering pp.
.
j. svajlenko j. f. islam i. keivanloo c. k. roy and m. m. mia towards a big data curated benchmark of inter project code clones in2014 ieee international conference on software maintenance and evolution.
ieee pp.
.
l. mou g. li l. zhang t. wang and z. jin convolutional neural networks over tree structures for programming language processing inproceedings of the thirtieth aaai conference on artificial intelligence ser.
aaai .
aaai press p. .
v .
j. hellendoorn and p .
devanbu are deep neural networks the best choice for modeling source code?
in proceedings of the 11th joint meeting on foundations of software engineering pp.
.
r. m. karampatsis h. babii r. robbes c. sutton and a. janes big code !
big v ocabulary open v ocabulary models for sourcecode in proceedings of the 42nd international conference on software engineering ser.
icse .
acm .
.
available a. parikh o. t ackstr om d. das and j. uszkoreit a decomposable attention model for natural language inference inproceedings of the conference on empirical methods innatural language processing .
austin texas association for computational linguistics nov. pp.
.
.available q. chen x. zhu z. ling s. wei h. jiang and d. inkpen enhanced lstm for natural language inference in proceedings of the 55th annual meeting of the association for computational linguistics acl .v ancouver acl july .
c. ciliberto f. bach and a. rudi localized structured prediction in advances in neural information processing systems pp.
.
t. sylvain l. petrini and d. hjelm locality and compositionality in zero shot learning in international conference on learning representations .
m. allamanis e. t. barr p .
devanbu and c. sutton a survey of machine learning for big code and naturalness acm computing surveys csur vol.
no.
pp.
.
v .
raychev m. v echev and e. yahav code completion with statistical language models in proceedings of the 35th acm sigplan conference on programming language design and implementation pp.
.
m. white c. v endome m. linares v asquez and d. poshyvanyk toward deep learning software repositories in ieee acm 12th working conference on mining software repositories.
ieee pp.
.
v .
raychev p .
bielik m. v echev and a. krause learning programs from noisy data acm sigplan notices vol.
no.
pp.
.
a. bhoopchand t. rockt aschel e. barr and s. riedel learning python code suggestion with a sparse pointer network .
.available j. li y .
wang m. r. lyu and i. king code completion with neural attention and pointer networks in proceedings of the 27th international joint conference on artificial intelligence pp.
.
x. gu h. zhang and s. kim deep code search in proceedings of the 40th international conference on software engineering icse2018 .
acm .
q. chen and m. zhou a neural framework for retrieval and summarization of source code in 33rd ieee acm international conference on automated software engineering ase .
ieee pp.
.
z. feng d. guo d. tang n. duan x. feng m. gong l. shou b. qin t. liu d. jiang et al.
codebert a pre trained model for programming and natural languages arxiv preprint arxiv .
.
j. cambronero h. li s. kim k. sen and s. chandra when deep learning met code search in proceedings of the 27th acm joint meeting on european software engineering conference and symposiumon the foundations of software engineering pp.
.
m. allamanis h. peng and c. sutton a convolutional attention network for extreme summarization of source code in international conference on machine learning pp.
.
s. iyer i. konstas a. cheung and l. zettlemoyer summarizing source code using a neural attention model in proceedings of the 54th annual 628meeting of the association for computational linguistics v olume long papers pp.
.
y .
wan z. zhao m. yang g. xu h. ying j. wu and p .
s. y u improving automatic source code summarization via deep reinforce ment learning in proceedings of the 33rd acm ieee international conference on automated software engineering pp.
.
u. alon m. zilberstein o. levy and e. yahav a general pathbased representation for predicting program properties acm sigplan notices vol.
no.
pp.
.
u. alon s. brody o. levy and e. yahav code2seq generating sequences from structured representations of code in international conference on learning representations .
x. hu g. li x. xia d. lo and z. jin deep code comment generation with hybrid lexical and syntactical information empirical software engineering vol.
no.
pp.
.
u. alon m. zilberstein o. levy and e. yahav code2vec learning distributed representations of code proceedings of the acm on programming languages vol.
no.
popl pp.
.
a. leclair s. jiang and c. mcmillan a neural model for generating natural language summaries of program subroutines in ieee acm 41st international conference on software engineering icse .
ieee pp.
.
y .
wang l. du e. shi y .
hu s. han and d. zhang cocogum contextual code summarization with multi relational gnn on umls microsoft tech.
rep. msr tr may .
.
avail able x. chen c. liu and d. song tree to tree neural networks for program translation in advances in neural information processing systems pp.
.
m. a. lachaux b. roziere l. chanussot and g. lample unsupervised translation of programming languages arxiv preprint arxiv .
.
s. wang t. liu and l. tan automatically learning semantic features for defect prediction in ieee acm 38th international conference on software engineering icse .
ieee pp.
.
m. pradel and k. sen deepbugs a learning approach to name based bug detection proceedings of the acm on programming languages vol.
no.
oopsla pp.
.
m. allamanis m. brockschmidt and m. khademi learning to represent programs with graphs in international conference on learning representations .
s. bellon r. koschke g. antoniol j. krinke and e. merlo comparison and evaluation of clone detection tools ieee transactions on software engineering vol.
no.
pp.
.
c. k. roy and j. r. cordy a survey on software clone detection research queen s school of computing tr vol.
no.
pp.
.
a. culotta and a. mccallum reducing labeling effort for structured prediction tasks in aaai vol.
pp.
.
s. dasgupta and d. hsu hierarchical sampling for active learning in proceedings of the 25th international conference on machine learning pp.
.
a. kirsch j. van amersfoort and y .
gal batchbald efficient and diverse batch acquisition for deep bayesian active learning .