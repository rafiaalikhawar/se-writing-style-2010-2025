fault localization with code coverage representation learning yi li department of informatics new jersey institute of technology new jersey usa email yl622 njit.edushaohua wang department of informatics new jersey institute of technology new jersey usa email davidsw njit.edutien n. nguyen computer science department the university of texas at dallas texas usa email tien.n.nguyen utdallas.edu abstract in this paper we propose d eeprl4fl a deep learning fault localization fl approach that locates the buggy code at the statement and method levels by treating fl as an image pattern recognition problem.
d eeprl4fl does so via novel code coverage representation learning rl and data dependencies rl for program statements.
those two types of rl on the dynamic information in a code coverage matrix are also combined with the code representation learning on the static information of the usual suspicious source code.
this combination is inspired by crime scene investigation in which investigators analyze the crime scene failed test cases and statements and related persons statements with dependencies and at the same time examine the usual suspects who have committed a similar crime in the past similar buggy code in the training data .
for the code coverage information d eeprl4fl first orders the test cases and marks error exhibiting code statements expecting that a model can recognize the patterns discriminating between faulty and non faulty statements methods.
for dependencies among statements the suspiciousness of a statement is seen taking into account the data dependencies to other statements in execution and data flows in addition to the statement by itself.
finally the vector representations for code coverage matrix data dependencies among statements and source code are combined and used as the input of a classifier built from a convolution neural network to detect buggy statements methods.
our empirical evaluation shows that d eeprl4fl improves the top results over the state of the art statement level fl baselines from .
to .
.
it also improves the top results over the existing method level fl baselines from .
to .
.
index terms fault localization code coverage representation learning machine learning deep learning i. i ntroduction finding and fixing software defects is an important process to ensure a high quality software product.
to reduce developers effort several fault localization fl approaches have been proposed to help localize the source of a defect also called a bugorfault .
in the fl problem given the execution of test cases an fl tool identifies the set of suspicious lines of code with their associated suspiciousness scores .
the key input of an fl tool is the code coverage matrix in which the rows and columns correspond to the source code statements and test cases respectively.
each cell is assigned with the value of if the respective statement is executed in the respective test case and with the value of otherwise.
in recent fl several corresponding authorresearchers also advocate for fault localization at method level .
fl at both levels are useful for developers.
spectrum based fault localization sbfl approaches take the recorded lines of code that were covered by each of the given test cases and assigned each line of code a suspiciousness score based on the code coverage matrix.
despite using different formulas to compute that score the idea is that a line covered more in the failing test cases than in the passing ones is more suspicious than a line executed more in the passing ones.
a key drawback of those approaches is that the same score is given to the lines that have been executed in both failing and passing test cases.
an example is the statements that are part of a block statement and executed at the same nested level.
another example is the conditions of the condition statements e.g.
if while do and switch .
to improve sbfl mutation based fault localization mbfl approaches enhance the code coverage information by modifying a statement with mutation operators and then collecting code coverages when executing the mutated programs with the test cases.
they apply suspiciousness score formulas in the same manner as the spectrum based fl approaches on the code coverage matrix for each original statement and its mutated ones.
despite the improvement mbfl are not effective for the bugs that require the fixes that are more complex than a mutation section ii .
machine learning ml anddeep learning dl have been used in fault localization.
deepfl computes for each faulty method a vector with scores in which each score is computed via a specific feature e.g.
a spectrum based or mutation based formula or a code complexity metric.
despite its success the accuracy of deepfl is still limited.
a reason could be that it uses various calculated scores from different formulas as a proxy to learn the suspiciousness of a faulty element instead of fully exploiting the code coverage.
some formulas such as the spectrum and mutation based formulas inherently suffer from the issues as explained earlier with the statements covered by both failing and passing test cases.
we propose d eeprl4fl a fault localization approach for buggy statements methods that exploits the image classification and pattern recognition capability of the convolution neural network cnn to apply on the code coverage cc matrix.
instead of summarizing each row in that matrix ieee acm 43rd international conference on software engineering icse .
ieee with a suspiciousness score we use its full details.
importantly we enhance the matrix to facilitate the application of the cnn model in recognizing the key characteristics in the matrix to discriminate more easily between faulty and non faulty statements methods.
toward that end we order the columns test cases of the cc matrix so that the test cases with the non zero values on nearby statements are close together .
specifically the first test case covers the most statements.
the next test case shares with the previous one as many executed statements as possible.
we expect that the cnn model with its capability to learn the relationships among nearby cells via a small filter can recognize the visual characteristic features to discriminate faulty and non faulty statements methods.
inspired by the method in crime scene investigation we use three sources of information for fl code coverage matrix with failed test cases the crime scene and victims similar buggy code in the history usual suspects who have committed a similar crime in the past and the statements with data dependencies related persons .
first the evidences at the crime scene are always examined.
for an analogy the cc matrix for the occurrence of the fault is analyzed.
second an investigator also makes a connection from the crime scene to the usual suspects .
this is analogous to the modeling of the code of the faults that have been encountered in the training dataset.
the idea is that if the persons analogous to the code who have committed the crimes with similar modus operandi m.o.
in the past are likely the suspects code with high suspiciousness in the current investigation.
third in addition to the crime scene the investigator also looks at the relationships between the victim or the things happening at the scene and other related persons.
thus in addition to the statement itself its suspiciousness is viewed taking into account the data dependencies to other statements in execution flows and data flows.
the idea is that some statements even far away from the buggy line could have impacts or exhibit the consequences of the buggy line when they are data dependent.
thus for a test we first identify the error exhibiting ee line defined as the line where the program crashed or exhibited an incorrect value s behavior s .
that is if the program crashes the error exhibiting line is listed.
if there is no crash and an assertion fails assertion statement is ee line.
ee line is usually specified in a test execution.
to identify the related statements from the ee line we consider the execution order.
however if the statements are in the same block of code i.e.
being executed sequentially we also consider the data dependencies among them and with the ee line.
finally all three sources of information are encoded into vector matrix representations which are used as input to the cnn model to act as a classifier to decide whether a statement method as a faulty or not.
we conducted several experiments to evaluate d eeprl4fl on defects4j benchmark .
our empirical results show that deeprl4fl locates faults and faults at the method level and the statement level respectively using only top1 candidate i.e.
the first ranked element is faulty .
it can improve the top results of the state of the art statementlevel fl baselines by .
.
.
.
1public static string join object array char separator int startindex int endindex 3if array null return null 6int noofitems endindex startindex 7if noofitems return empty stringbuilder buf new stringbuilder array null?
array .tostring .length stringbuilder buf new stringbuilder noofitems for int i startindex i endindex i if i startindex buf.append separator if array !
null buf.append array return buf.tostring fig.
an example of a buggy statement and .
when comparing with ochiai dstar muse metallaxis and rbf neural network based fl rbf respectively.
d eeprl4fl also improves the top results of the existing method level fl baselines multric fluccs trapt and deepfl by .
.
.
and .
respectively.
our results show that three sources of information in d eeprl4fl positively contribute to its high accuracy.
we also evaluated d eeprl4fl on manybugs a benchmark of c code with projects.
the results are consistent with the ones on java code.
d eeprl4fl localizes faulty statements and faulty methods using only top results.
the contributions of this paper are listed as follows .
novel code coverage representation.
our representation enables fully exploiting test coverage matrix and taking advantage of the cnn model in image recognition to localize faults.
.
d eeprl4fl novel dl based fault localization approach.
test case ordering and three sources of information allow treating fl as a pattern recognition.
without ordering and statement dependencies the cnn model will not work well.
.
extensive empirical evaluation.
we evaluated our model against the most recent fl models at the statement and method levels in both within project and cross project settings and for both c and java.
our replication package is available at .
ii.
m otivating examples fig.
shows a real world example of a bug in defects4j .
the bug occurs at line in which the length of the string to be built via stringbuilder was not set correctly.
a developer fixed the bug by modifying lines into line .
to localize the buggy line there exist three categories of approaches.
the first one is spectrum based fault localization sbfl .
the key idea in sbfl is that in a test dataset a line executed more in the failing test cases than in the passing ones is considered as more suspicious than a line executed more in the passing ones .
a summary of the cc matrix for this bug is shown in fig.
2a.
the lines and in fig.
are 662t1t2 ... line ... ... ... ... ... line ... ... ... ... ... line ... ... ... ... ... line ... ... ... ... ... line ... ... ... ... ... line ... ... ... ... ... line ... ... ... ... ... line ... ... ... ... ... line ... ... ... ... ... line ... ... ... ... ... line ... ... ... ... ... line ... ... ... ... ... a t9t33 ... line ... line ... line ... line ... line ... line ?
... line ?
... line ... line ... line ... line ... line ... b fig.
code coverage for fig.
note ?for executed in both passing and failing test cases and as a result given the same suspiciousness scores .
thus sbfl is ineffective to detect the buggy line and this buggy method.
the second category is mutation based fault localization mbfl .
a mbfl approach e.g.
metallaxis modifies a statement using mutation operators.
after collecting code coverage information for each statement regarding to multiple mutations it computes the suspiciousness score for each statement using a spectrum based formula e.g.
ochiai on the cc matrix for each original statement and for its mutated ones.
however the fix for the buggy line requires more complex code transformations than a mutation.
thus an mbfl approach cannot detect this buggy line and buggy method.
the third category is deep learning and machine learningbased fl approaches .
specifically wong el al.
use a backpropagation neural network on code coverage for each statement.
since the lines and are executed in both passing and failing test cases the model cannot learn to distinguish them to detect the buggy line .
deepfl uses multilayer perceptron mlp on a matrix in which each row corresponds to a statement while each column is a suspiciousness score computed by a spectrum based formula or a code complexity metric.
in our experiment section ix c1 deepfl could not detect the buggy line .
despite combining several scores the aforementioned lines are given the same suspiciousness scores by each spectrum based formula.
observation .
the state of the art spectrum based mutation based and deep learning based fl approaches do not consider the full details of the cc matrix.
instead they summarize each statement row with a suspiciousness score thus limiting their capabilities.
to address that we aim to exploit the full details of the cc matrix via the use of the cnn model which has been shown to be effective in image pattern recognition.
however there is a challenge if we do not enforce an order on the test cases columns we might end up with a cc matrix with the dark cells the values of that are far apart .
note that the cnn model is effective to learn the relationships among the nearby cells in a matrix with its small sliding window called filter .
thus we need to enforce an order on the test cases i.e.
the columns of the cc matrix so that the values of on the same or nearby rows get to be close to one another .
for example if we enforce an order with the mentioned strategy we will explain the detailed algorithm later for the running example we will have the matrix in fig.
2b.
that is the results1public int compute int x int y int z int i x int j x y int m if i y if i y if j z j m m z else m m j else m m i i m return m fig.
a buggy statement and interdependent statements for the test cases etc.
in the test dataset of defects4j for this example are shown in the leftmost columns.
we expect thatthe cnn model with its sliding window is more effective in the resulting matrix after the ordering due to the nearby dark cells on the left side .
the empirical study on the impact of such ordering will be explained in section ix.
let us consider another example in fig.
.
the bug occurs at line and is fixed in line .
the program fails in two test cases x y z and x y z .
in this example the lines and are all executed in both passing and failing test cases.
thus the spectrum based mutation based approaches and deepfl give them the same suspiciousness scores and do not detect the buggy line and this buggy method.
the line returns the unexpected results for the two failing test cases.
in fact the spectrum based and mutationbased approaches locate line as the buggy line.
however the actual error occurs at line steering the execution to the incorrect branch of the ifstatement.
this implies that while the source of the bug is at line the error exhibits at line which is far apart from line yet has a dependency with it.
however the line immediate preceding of line does not contribute to the incorrect result at line .
observation .
we observe that the line that exhibits erroneous behavior e.g.
line might not be the buggy line line .
however the buggy line has a dependency with the line .
thus identifying the key line exhibiting the erroneous behavior is crucial for fl .
we also observe that the lines with program dependencies with one another are in fact more valuable in helping localize the buggy line than the lines without such dependencies.
thus while considering the execution order of statements an fl approach should consider the statements with program dependencies as well .
iii.
e xploratory study inspiring by the above observations to further study the impact of ordering of the columns i.e the test cases of the code coverage matrix we conduct an exploratory experiment with the convolution neural network cnn model.
specifically we choose a simple cnn model having 2d convolutional layer and convolutional cores with the size of .
in 663fig.
a feature map after ordering of test cases this experiment we use all the bugs in the defects4j dataset will be explained in table i .
as for training and testing we use the leave one out strategy on the entire defects4j dataset.
that is when we perform testing on a fault we use all other faults in the dataset as the training data to train the model.
as for the ordering in the code coverage matrix the first test case is the one covering as many statements as possible and the subsequent test case is the one that runs through as many same statements as the previously selected test cases will be detailed in section v c .
to encode the pass fail information we detected the error exhibiting lines ee see section v b and marked them with values.
we conduct two executions with two different inputs for the cnn model.
in the first one for training we use the original spectrum based cc matrix as the input.
the output is a matrix with the same size as the input cc matrix however the row corresponding to the buggy statements lines are marked with all the values and all other rows are marked with the zeros.
for the second execution we use the cc matrix after ordering.
the output is the same as in the first execution.
for testing we use the trained cnn model to run on the buggy methods under test.
we examine the output of that execution.
the cnn model generates feature maps as the output from the different convolutional cores.
the feature maps of a cnn capture the result of applying the cnn filters to an input matrix.
that is at each layer the feature map is the output of that layer.
by visualizing a feature map for a specific input image i.e.
an cc matrix we aim to gain some understanding of what features the cnn model can detect.
we randomly select faults as the testing data.
in two of them the result of the cnn model indicates the correct buggy statement for the fault.
fig.
shows the result for one of the faults.
we visualized the code coverage matrices and feature maps as gray scale images.
in the code coverage matrices on the left rows represent statements from the top to the bottom and columns represent test cases.
the buggy statement line is marked with a red rectangle.
as seen after ordering the left side of the cc matrix becomes darker.
the white part which represents the zero values corresponds to the test cases that do not go through the statements in this buggy method.
fig.
d eeprl4fl s architecture for the feature maps corresponding to before and after ordering the rows also correspond to the statements and the columns represent the test cases.
we examine all feature maps when running the cnn model on an input.
among the feature maps for the case of ordering we found one feature map feature map the bottom right image contains the darker spot at the buggy statement line compared to the lighter spots for the non buggy statements lines.
we examine all feature maps for the case of the original cc matrix and visualize the corresponding feature map feature map the upper right image .
as seen in the red rectangle there is no dark line spot around the buggy statement.
in brief with the ordering of the columns in the cc matrix we make the cnn model recognize visual characteristics corresponding to the buggy statement and distinguish it from the non buggy ones.
this motivates us to integrate the ordering of the columns in the cc matrix for code coverage representation learning.
iv.
a pproach overview inspired by the crime scene investigation method we explore three aforementioned sources of information.
correspondingly d eeprl4fl has three representation learning processes code coverage representation learning crime scene statements dependency representation learning relations and source code representation learning usual suspects .
code coverage representation learning this learning is dedicated to the crime scene analysis of the bug.
this process has two parts.
first to help the cnn model recognize the patterns we take the given un ordered set of test cases andperform an ordering algorithm to arrange the columns of the cc matrix.
the strategy of ordering is to enable the values of to be closer to form darker spots in the left side of the matrix expecting that the cnn model can work effectively to recognize nearby cells to distinguish the buggy and non buggy statements see exploratory study and empirical evaluation .
second we also perform the analysis on the output of test cases to locate the error exhibiting ee lines observation .
if the execution of a test crashes the line information is always available.
even if there is no crash the test fails the program often explicitly lists the lines of code that exhibit the incorrect results behaviors.
we use such information to locate the ee line in the buggy source code corresponding to each test 664case.
finally the results of individual test cases are encoded as follows.
the cells in the matrix corresponding to the ee lines of test cases will be marked with values see the stars in fig.
2b .
thus if a column has a value of at a row the corresponding test case is a failing one.
the values of and represent the coverage or non coverage of the test case to a statement.
thus a column has no value of all the values are or the corresponding test case is passing .
the resulting matrix is called the enhanced cc matrix ecc .
dependency representation learning the suspiciousness of a statement is seen taking into account the data dependencies to other statements in the execution flows and data flows in addition to the statement itself observation .
specifically we consider both the execution orders and data dependencies among the statements.
for example if the statements are executed sequentially in the same nested level as part of a block statement data dependencies will help the model in fl as shown in section ii.
additionally encoding the statements with such dependencies has the same effect as putting together the rows corresponding to the dependent statements in the cc matrix.
in our example in addition to the entire matrix in fig.
we also encode the data dependencies among statements i.e.
in the same spirit with the case of putting closer the rows and and feed them into the cnn model.
in our tool we collect execution paths and data flow graph for each test case.
source code representation learning for each buggy code in the training data we choose to represent the code structure by the long paths that are adapted from a prior work .
a long path is a path that starts from a leaf node ends at another leaf node and passes through the root node of the ast.
the ast structure can be captured and represented via the paths with certain lengths across the ast nodes .
after this we have the vectors for the buggy code.
finally all the representation vectors are used as the inputs of the cnn model which is part of the fl module in fig.
.
v. c ode coverage representation learning a. generating code coverage matrices as in prior fl studies we obtain a code coverage matrix for each method of a given project and error messages of the failing test cases using gzoltar a tool for code coverage analysis.
we further modify gzoltar to record the actual execution path of statements within a method during the execution of a test case.
for example for the method in fig.
the execution path of running the first selected test case is line line line line line line line line line z statements repeated in the for loop line .
we also use mutation to generate more coverage information.
first we apply the same mutators as in deepfl to mutate each statement within a method using the mutation tool pit .
.
.
to generate a mutation based matrix we apply one mutator to mutate a statement and use gzoltar to record the execution.
thus given nmutators that can be applicable to a statement we generate nnew versions of the given method.
fig.
error message example if it has mstatements we generate n mmatrices for the method.
we refer the mutation generated n mmatrices as mutation based matrices and for clarification we refer the non mutator generated matrix as the spectrum based matrix .
b. identifying error exhibiting lines a cell in the cc matrix can have three values f1 1g.
while the values of and indicate passing the values of indicate failing.
we obtain for an error exhibiting statement or crashed statement from the error messages of failing test cases.
an error message shows the names of classes methods and line numbers exhibiting an error.
we directly use the line numbers method and class names to assign 1s to the statements in the matrix.
fig.
shows an example of the error message containing a stack trace produced by running a test case on the project chart with the bug chart .
because the current method under investigation is getpaint our algorithm searches for that method in the stack trace to derive the ee statement at the line of the file graypaintscale.java which contains the method getpaint .
each failing test case has only one ee statement for the current method under study.
c. test case ordering algorithm algorithm takes the set of test cases sand enforces an order on s. the strategy is to move the values of and closer to one another in the left side.
first if there exist failing test cases i.e.
test cases with 1s we select the test case with the value of at the statement appearing latest in the code.
we then find the test case that shares the same statement having with the last selected test case line .
that is we group together the test cases that go through the same statement and also fail.
if we do not have such test case then we repeat the process of looking for another failing test case i.e.
with .
in fig.
2b the test case is selected as the first one with only one marked with a star at the line latest statement .
we search for the next test case that has a at the latest.
the test case is chosen at the second column.
if we do not have any failing test case left we select the test case that has the most 1s line .
next we select the next test case that shares the most number of the same statements having the values of 1s with the last selected test case.
this helps move the values of closer.
we repeat this step to select a new test case compared with the previously selected one until all the test cases were ordered.
we stop this step if no test case has the same statements with 1s as the last selected test case column .
if two test cases are tie we select the one with the 665algorithm test case ordering algorithm function ordering testcases s testset list while s do ifhavetestcases withminus one s then selt findtestcasewithminus onewithhighest index s s remove selt list append selt while havetestcasesame stmtwithminus one selt s do selt findtestcasesame stmtwithminus one selt s s remove selt list append selt else selt findtestcasewithmostone s s remove selt list append selt while havetestcasewithsame stmts withone selt s do selt findtestwithmostsame stmts withone selt s s remove selt list append selt return list last value of at a statement appearing latter.
the rationale is that such a test case covers more statements than the other.
if they are still tie the selection of either of them will result in similar visual effects locally at that row.
in brief in any cases of ties the visual effects around the statements are similar.
in addition to the spectrum based matrices we also apply the same enhancements identifying error exhibiting lines and ordering text cases to mutation based code coverage matrices.
vi.
s tatement dependency representation we aim to model the execution orders anddata dependencies among the statements of the method under study.
execution order representation we obtain the execution path e path as each test case was executed.
we only consider the relations among statements within a method.
since an e path is a sequence of statements we apply word2vec on all execution paths of test cases to learn the vectors that encode the relations among statements.
thus each statement has a word2vec generated vector .
data dependency representation using execution paths is not sufficient due to the following.
first the statements in a loop may repeat multiple times in an e path thus they may dominate vector learning using word2vec and weaken the relations between the statements inside and outside of a loop which is also crucial in fl.
second interdependent statements might not be nearby in an e path yet are useful in detecting the buggy line observation .
to address those we also use the data flow graph dfg for the statements in a method.
we use wala to generate dfgs in which a node represents a statement and an edge represents a data flow between two nodes.
if aconnects to b we assign the weight of .
if there is no edge from btoa we create that edge but assign the weight of .
this makes node2vec a network embedding technique applicable to our graph.
the value of helps distinguish between the artificial edges and the real ones.
after this step some statements nodes with data dependencies have node2vec generated vectors.
vectors for statements with dependencies the word2vec vector for a statement sin the execution order andthenode2vec vector for sin program dependencies among the statements are combined via hadamard product to represent s. finally the output vector is a statement dependency vector for a statement modeling the statement with the dependencies and or execution orders among statements.
combining statement dependencies and ecc matrices to further enrich the ecc matrix a spectrum mutationbased matrix we incorporate the dependencies among the statements in a method under study into that matrix.
in the enhanced matrix we have the i th statement si of a method under test with the test cases t ft1 tj tng where jindicates the j th test case j n and nis the number of test cases.
the statement siunder a test case tjhas a cell value vijthat can be eitherf1 or 1g.
thus the statement sican be represented as a vector si fvi1 v ij v ing.
each statement si has a statement dependency vector ssd i .
we multiply each vijwith ssd i to obtain vij ssd i for each cell of siandtjin the enhanced matrix.
thus the statement sican be represented as a new dimensional vector s2d i vi1 ssd i v ij ssd i v in ssd i .
any vector ssd i multiplied by a vij results in a vector with all 0s.
a method often has multiple statements fs1 si smg where iindicates the i th statement i m and m is the number of statements.
thus a method is presented as a d matrix i.e.
a list of d statement vectors .
the same steps are used to enhance and combine statement dependencies into a mutation based matrix.
a statement si in a mutation based matrix is represented as a set of mutated statements and each mutated statement is represented as a d vector.
thus in this case the statement siis represented as a d matrix.
after enhancing the ecc matrix and combining statement dependencies as explained we obtain the following in a spectrum based matrix sbm a statement is represented as a d vector and a method as a d matrix in mutation based matrices mbm a statement is represented as a d matrix and a method as a d matrix.
encoding code coverage matrices with a cnn model after obtaining those representations for statements and methods we apply the convolution neural network cnn to learn features.
we use a typical cnn with the following layers a convolutional layer a pooling layer and a fully connected layer.
we feed the followings into the cnn model separately to detect a buggy statement method i for spectrum based matrices sbm we fed a d vector representing for a statement and a d matrix for a method ii for mutation based matrices mbm we fed a d matrix representing for a statement and a d matrix for a method.
we apply a fully connected layer before cnn on the method in a mutation based matrix i.e.
represented as a d matrix to reduce an d matrix into an d matrix.
the outputs of the cnn include the vectors for a statement or a method in spectrum based or mutation based matrices i vss d vector for a statement in sbm ii vsm d vector for a method in sbm iii vms d vector for a statement in mbm and iv vmm d vector for a method in mbm.
666vii.
s ource code representation learning let us explain how we capture the usual suspicious source code via code representation learning.
for a statement we tokenize it and treat each token in the statement as a word and the entire statement as a sentence.
we useword2vec on all the statements of a project to compute a token vector for each token.
after having the vectors for all the tokens for a statement we have a matrix tokenvector token vector token vector m .
to obtain a unified vector to represent a statement instead of a matrix we apply a fully connected layer to reduce the matrix into d vector.
thus we have one vector for each statement.
at the method level we used two existing code representation learning techniques code2vec and astnn for a method.
in code2vec we use long paths over the ast.
a long path is a path that starts from a leaf node ends at another leaf node and passes through the root node of the ast.
the ast structure can be represented via the paths with certain lengths across the ast nodes.
specifically we regard a long path as a sequence and apply word2vec on all the long paths of a method to generate a vector representation for each ast node.
now each path is represented as an ordered list of node vectors the order is based on the appearance order of the nodes in a path and each method is represented as a bag of paths i.e.
ordered lists of node vectors.
essentially a method is represented by a matrix.
we use a fully connected layer to transform the matrix into d vector for a method.
at the method level we also used tree based representation astnn .
astnn splits the ast of a method into small subtrees at the statement level and applies a recursive neural network rnn to learn vector representations for statements.
the astnn exploits the bidirectional gated recurrent unit gru to model the statements using the sequences of sub tree vectors.
after obtaining the long pathbased vector and the tree based vector for a method we apply a fully connected layer as the one in cnn to combine these two vectors into one unified vector for a method.
viii.
f ault localization with cnn m odel a. statement level fault localization after all the previous steps each statement has vectors vss a sbm based statement vector section vi vms a mbm based statement vector section vi and vcs a source code based statement vector section vii .
the vectors are combined via hadamard product ms mm mc mcombined broadcast ms broadcast mm broadcast mc mis the matrix which is expanded from vby keeping one dimension as vand adding two more dimensions with the size of1.broadcast is the operation to copy a dimension into multiple times to expand the matrix to the suitable size for hadamard product.
the rationale is that all three vectors from three different aspects should be fully integrated.
the resulting matrix is of the size .
next weuse the trained cnn model with a softmax on the matrix to classify a statement into faulty or non faulty.
the output of the softmax is standardized to be between 0to1.
to train the model the same combined matrix for a statement is used at the input layer and the corresponding classification faulty or not is used at the output layer of the cnn model.
b. method level fault localization similar to statement level fl each method has vectors vsm a sbm based method vector section vi vmm a mbm based method vector section vi and vcm a source code based method vector section vii .
moreover we also consider the similarity between the source code and the error messages of the failing test cases as in deepfl .
we first collect types of information from failed tests including the name of the failed tests the source code of the failed tests and the complete failure messages including exception type message and stacktrace .
second we collect types of information from source code including the full qualified name of the method accessed classes method invocations used variables and comments.
for each combination we calculate the similarity score between each information from the failed tests and each from the source code using the popular tf idf method .
we generate similarity scores as features for a method.
thus a method also has the fourth vector vsim m with features.
for fault localization we combine the above method vectors into a matrix by using the hadamard product as in section viii a then use the trained cnn model with a softmax to classify a method into faulty or non faulty.
we train the model in the same manner as fl at the statement level.
ix.
e mpirical evaluation a. research questions we seek to answer the following research questions rq1.
statement level fl comparison.
how well does our tool perform compared with the state of the art statement level fl models?
rq2.
method level fl comparison.
how well does our tool perform compared with the existing method level fl models?
rq3.
impact analysis of different matrix enhancing techniques.
how do those techniques including test case ordering and statements dependency affect the accuracy?
rq4.
impact analysis of different representations learning.how do different types of information affect the accuracy?
rq5.
cross project analysis.
how does d eeprl4fl perform in the cross project setting?
rq6.
performance on c code.
how does d eeprl4fl perform in c projects for fl?
b. experimental methodology data set we use the benchmark defects4j v1.
.
with ground truth table i .
for a bug in project p defects4j has a separate copy of pbut with only the corresponding test suite revealing the bug.
for example p1 a version of p passes a test suite t1.
later a bug b1inp1is identified.
after 667table i defects4j dataset identifier project name of bugs chart jfreechart closure closure compiler lang apache commons lang math apache commons math mockito mockito time joda time debugging p1has an evolved test suite t2detecting the bug.
in this case defects4j has a separate copy of the buggy p1 with a single bug together with the test suite t2.
similarly for bugb2 defects4j has a copy of p2together with t3 evolving from t2 and so on.
for within project setting we test one bugbiwith test suite t i by training on all other bugs inp.
to reduce the influence of the overfitting problem we applied l2 regularization and added dropout layers.
experiment metrics following prior studies we use the following metrics to evaluate an fl model recall at top k is the number of faults with at least one faulty statement that is correctly predicted in the ranked list ofkstatements.
we report top top and top .
mean average rank mar we compute the average rank of all faulty elements for each fault.
mar of each project is the mean of the average rank of all of its faults.
mean first rank mfr for a fault with multiple faulty elements methods statements locating the first one is critical since the others may be located after that.
mfr of each project is the mean of the first faulty element s rank for each fault.
experiment setup and procedure rq1 statement level fault localization comparison.
baselines.
we compare d eeprl4fl with the following statement level fl approaches two spectrum based fault localization sbfl techniques ochiai and dstar two recent mutation based fault localization mbfl techniques muse and metallaxis two deep learning based fl approaches rbf neural network rbf and deepfl .
deepfl works at the method level with several features.
for comparison in this rq1 for the statement level we can only use deepfl s spectrum and mutation based features applicable to detect faulty statements.
as in fl work using defects4j we used the setting of leave one out cross validation on the faults for each individual project i.e.
within project setting .
specifically we use one bug i.e.
with one buggy statement or method as testing and the remaining bugs in a project for training.
tuning deeprl4fl and the baselines.
we tuned our model with the following key hyper parameters to obtain the best performance epoch size i.e.
batch size i.e.
learning rate i.e.
.
.
.
.
vector length of word representation and its output i.e.
convolutional core size i.e.
and11 the number of convolutional core and .as for word2vec for a method we consider all tokens in the source code order as a sentence.
we tune the following hyperparameters for deepfl using only the features relevant to statements epoch number ... loss functions softmax pairwise and learning rate .
.
.
.
rq2 method level fault localization comparison.
baselines we also compare our approach with the following state of the art approaches that localize faulty methods.
multric is a learning based approach to combine different spectrum based ranking techniques using learning torank for effective fault localization.
fluccs is a learn to rank based technique using spectrum based scores and change metrics e.g.
code churn and complexity metrics to rank program elements.
trapt is a learn to rank technique to combine spectrum based and mutation based fault localization.
deepfl is a dl based model to learn the existing latent features from multiple aspects of test cases and a program.
we used all the features of deepfl in this method level study.
tuning deeprl4fl and the baselines.
similar to rq1 we perform our experiments using leave one out cross validation on the faults for each project.
we use the same settings in rq1 to train our model.
note that in deepfl paper deepfl multric fluccs and trapt have been evaluated using leave one out cross validation and other settings on the same data set of defects4j v1.
.
.
d eeprl4fl is also evaluated on defects4j v1.
.
using the same settings and procedure as deepfl.
thus we used the result on the numbers of detected bugs reported in deepfl for those models.
rq3 impact analysis of different matrix enhancing techniques.
we evaluate the impact of the following techniques on accuracy test case ordering algorithm utilizing the ee lines order statements dependencies statdep .
we first build a base model by using only the spectrum and mutation based matrices in d eeprl4fl without using the above techniques then apply the above techniques on the matrices to build two variants of d eeprl4fl fbase orderg andfbase order statedep deeprl4fl g. we train each variant using the same settings as in rq1.
due to space limit we show only the analysis results obtained in the withinproject setting for method level fl.
rq4 impact analysis of learning representations.
we have the following representation learning schemes the enhanced spectrum based cc matrix newspecmatrix and the enhanced mutation based cc matrix newmutmatrix .
we also have source code representation coderep and textual similarity between source code and error messages in failing tests textsim .
to test the impact of those representation learning schemes on accuracy we built a base model using only newspecmatrix and three other variants fnewspecmatrix newmutmatrix g fnewspecmatrix newmutmatrix coderep g andfnewspecmatrix newmutmatrix coderep textsim g. we trained each variant using the same settings as in rq1.
due to space limit we show only the results for the within project setting for method level fl.
668table ii rq1.
results of comparative study for statementlevel fault localization.
p jtop 1j f395 bugsg approach top top top p mfr mar ochiai .
.
.
dstar .
.
.
muse .
.
.
metallaxis .
.
.
rbf .
.
.
deepfl .
.
.
deeprl4fl .
.
.
rq5 cross project analysis.
we also setup the cross project scenario testing one bug in a project but training a model on all of the bugs of other projects.
for a project we test every bug and sum up the total number of bugs in the project that can be localized in the cross project scenario.
rq6 d eeprl4fl s fault localization performance on c code.
we also evaluated d eeprl4fl on c projects from the benchmark dataset manybugs with bugs from projects.
we used the same model in rq1 for statement level fl and the model in rq2 for method level fl.
c. experimental results rq1 results statement level fault localization comparison as seen in table ii d eeprl4fl improves over the state of the art statement level fl baselines.
specifically deeprl4fl improves recall at top by .
.
.
.
.
and .
in comparison with ochiai dstar muse metallaxis rbf and deepfl.
we examined the results and report the following.
the key reason for the spectrum based fl approaches fail to localize the buggy statements is that they give the same suspiciousness score to the statements at the same nested level.
for the mutation based fl approaches the key reason for not being able to localize the buggy statements methods is that the fix requires a more sophisticated change than a mutation.
let us take an example.
in fig.
the fault is caused by an incorrect variable.
to fix it the variable was changed from postopt at line .
the state of art spectrum based approaches cannot localize this fault because lines and have the same score they were executed in both passing and failing test cases .
for the mutation based fl approaches there is none of mutation operators that changes the variable posinto ptin a method call at the buggy line .
thus they cannot observe the impact of mutations on the code coverage.
as a consequence they cannot locate the buggy line .
to gain insights we performed a visualization of a feature map for this case.
during training cnn learns the values for small windows called filters .
the feature maps of a cnn capture the result of applying the filters to an input matrix.
that is at each layer the feature map is the output of that layer.
in image processing visualizing a feature map for an input helps gain understanding on whether the model detects some part of our desired object and what features the cnn observes.
fig.
shows a feature map for the example in fig.
.
we can see that around the lines and the feature1public void translate charsequence input writer out ... ... 3int pos 4int len input.length 5while pos len 6int consumed translate input pos out 7if consumed char c character.tochars char...codepointat ... out.write c pos c.length 11continue for int pt pt consumed pt pos char.charcount char.codepointat input pos pos char.charcount char.codepointat input pt fig.
an example from defects4j fig.
a feature map produced by cnn for fig.
map is visually dark.
without ordering i.e.
a random order of test cases the feature map does not exhibit such visualization.
to further study the impacts of the ordering and data dependencies we modified d eeprl4fl in the following settings no ordering no dependencies the buggy line is ranked at 43th no ordering dependencies it is ranked at 29th ordering no dependencies it is ranked at 7th and ordering dependencies it is ranked at the top.
rq2 results method level fault localization comparison as seen in table iii d eeprl4fl improves recall at top by .
.
.
and .
over multric fluccs trapt and deepfl respectively.
deeprl4fl s mar is slightly higher than deepfl s .
higher .
on average d eeprl4fl ranks the correct elements higher than deepfl as its mfr is lower .
lower .
the spectrum based and mutation based fl approaches fall short of deepfl and d eeprl4fl.
a key reason is that they consider only dynamic information in test cases while deepfl and our model use both static and dynamic information.
in comparison with deepfl we further analyzed the bugs that our tool can locate but deepfl missed.
we found that the mean first rank of a buggy method in the ranking lists of potential buggy methods returned by deepfl is .
.
without the ordering and statement dependency in our model the mean first rank is .
.
with only ordering in our model the mean first rank is .
.
with only dependency in our model the mean first rank is .
.
with both ordering and dependency our model can locate the bugs that deepfl missed.
let us use an example in defects4j that our model detected but deepfl missed.
the buggy method 669table iii rq2.
results of comparative study for methodlevel fault localization.
p jtop 1j f395 bugsg approach top top top p mfr mar multric .
.
.
fluccs .
.
.
trapt .
.
.
deepfl .
.
.
deeprl4fl .
.
.
fig.
ordering and statement dependencies affect ranking flipifwarranted together with the other methods in the project were fed into four variants of our model.
as seen with the setting in which both ordering and statement dependencies are removed flipifwarranted is ranked 5th in the list of all methods.
for the setting with only ordering it is ranked at 2nd place.
for the setting with only statement dependencies it is ranked 3rd.
with both our model ranks the buggy method flipifwarranted at the 1st position.
this analysis shows that ordering test cases and statement dependencies are the key drivers that help our model locate more bugs than deepfl.
rq3 results impact analysis of different matrix enhancing techniques table iv shows that our matrix enhancing techniques positively contribute to d eeprl4fl.
specifically comparing fbasegwithfbase orderg ordering the test cases can improve every metric.
order helps localize more bugs .
using top .
it helps improve mfr and mar by .
and .
respectively showing that ordering can help d eeprl4fl push the faulty methods higher in the ranked list.
comparingfbase ordergwithfbase order statedep g we see that modeling dependencies into matrices is useful to improve the performance of d eeprl4fl.
statedep can improve .
.
and .
in top mfr and mar.
to further study the impact of the ordering we visualize the feature maps for the bugs that order can detect and base did not.
those are the cases where ordering helps.
visualizing the feature maps for those inputs allows us to understand what features the cnn detects in both cases of ordering and noordering.
moreover that also allows us to see if ordering can help the cnn model learns better the discriminative features in locating the buggy statements.
to do so for each of those bugs we used the cnn model as part of base andorder to produce two feature maps one corresponds to base no ordering and one to order .
we then visualized and compared those feature maps as gray scale images.
the cnn model generates feature maps as the output from convolutional cores.table iv rq3.
ordering order and adding dependencies statedep in method level fl.
p jtop 1j f395 bugsg variants top1 p mfr mar base d eeprl4fl w o order statedep .
.
.
base order .
.
.
base order statedep deeprl4fl .
.
.
fig.
visually darker lines around buggy statement in all the bugs we observe the same phenomenon.
let us take an example.
fig.
shows two feature maps for one of those bugs.
the left image is for base without ordering and the right one is for order with ordering .
we zoom out the leftmost columns in the right feature map.
the row corresponding to the buggy line is in the red rectangle.
with ordering one of those feature maps has visually darker lines around the buggy statement.
in contrast without ordering all the feature maps are similar to the one on the left i.e.
do not show any clear visual lines.
in brief with ordering the cnn model which focuses on the relations of neighboring cells can detect the features along the buggy statement.
rq4 results impact analysis of learning representations table v shows that our representation learning has positive contributions.
comparing fbasegwithfbase newmutmatrixg we can see that mutation based matrices can help locate more bugs using top and improve mfr and mar by .
and .
.
by adding code representation learning we improve d eeprl4fl to localize more bugs and gain an increase on mfr and mar by .
and .
respectively.
furthermore textsim also positively contributes to our model.
for statement level fl code representation is also useful improving top from to bugs i.e.
.
not shown .
rq5 results cross project analysis as seen in table vi d eeprl4fl achieves better results in the withinproject setting than in the cross project one.
this is expected as the training and testing data is from the same project in the within project setting thus a model may see similar faults.
in the cross project setting d eeprl4fl correctly detects bugs at top in comparison with the best result bugs from the baselines.
in the within project setting deeprl4fl correctly detects bugs at top in comparison with bugs not shown from the baseline models multric fluccs trapt deepfl respectively.
time complexity.
on average training time is minutes per project in the cross project setting and minutes per project in the within project setting.
once the model is trained the prediction time per fault is seconds in both the cross and within project settings.
670table v rq4.
results of learning representations in method level fl.
p jtop 1j f395 bugsg variants top p mfr mar base newspecmatrix .
.
.
base newmutmatrix .
.
.
base newmutmatrix coderep .
.
.
base newmutmatrix coderep textsim deeprl4fl .
.
.
table vi rq5.
cross project versus within project results projectscross project within project top p mfr mar top p mfr mar chart .
.
.
.
.
.
time .
.
.
.
.
.
math .
.
.
.
.
.
closure .
.
.
.
.
.
mockito .
.
.
.
.
.
lang .
.
.
.
.
.
rq6 results performance on c code as seen in table vii d eeprl4fl can localize faulty statements and faulty methods with only top statements and methods.
the empirical results show that the performance of d eeprl4fl on the c projects is consistent with the one on the java projects.
specifically at the statement level the percentages of the total c and java bugs that can be localized are similar i.e.
.
vs. .
respectively.
at the method level the percentages of the total c and java bugs that can be localized are also consistent i.e.
.
vs. .
respectively.
threats to validity i baseline implementation.
for comparative study we implemented ochiai dstar muse metallaxis and rbf neural network for statement level fl.
we followed the paper to implement muse and metallaxis using pit .
.
.
rbf neural network approach is built for artificial faults and our real bug dataset cannot match the requirements.
ii result generalization.
our comparisons with the baselines were only carried out on the defects4j dataset.
further evaluation on other datasets should be done.
limitations the quality of test cases is important for our approach.
if there are only a couple of passing test cases or the crash occurs far apart from the faulty method d eeprl4fl does not learn a useful representation matrix to localize the faults.
it does not work well on locating the faults that require statement additions to fix all of the baselines in this paper do not either .
moreover it does not work well for short methods as they provide less statement dependencies.
it is also hard for our model to localize the uncommon faults.
because it is dlbased if there is a very uncommon fault that may not be seen in the training dataset it will not work correctly.
x. r elated work fault localization fl .
the spectrum based fault localization sbfl e.g.
has been intensively studied in the literature.
tarantula sbi ochiai and jaccard they share the same basic insight i.e.
code elements mainly executed by failed tests are more suspicious.
the mutation based fault localization mbfl e.g.
aims to additionally consider mutated code in fault localization.
the examples of mbfl are metallaxis and musetable vii rq6.
manybugs c projects versus defects4j java projects .
p jtop 1j ftotal bugs in datasets g levelmanybugs c projects defects4j java projects top p mfr mar top p mfr mar statement .
.
.
.
.
.
method .
.
.
.
.
.
.
learning to rank ltr has been used to improve fault localization .
multric combines different suspiciousness values from sbfl.
some work combines sbfl suspiciousness values with other information e.g.
program invariant and source code complexity information for more effective ltr in fl.
trapt combines suspiciousness values from both sbfl and mbfl.
neural networks have been applied to fault localization .
however they mainly work on the test coverage summarization scores which has clear limitations e.g.
it cannot distinguish elements covered by both failing and passing test cases and are usually studied on artificial faults or small programs.
deepfl was shown to improve the method level fl approach trapt .
d eeprl4fl is also related to cnn fl which feeds the original coverage matrix with passing failing information into a cnn model.
cnn fl is theoretically equivalent to base model in table iv without any matrix enhancements test cases ordering statement dependencies and code representations.
code representation learning crl .
the recent success in machine learning has lead to much interest in applying machine learning especially deep learning to program analysis and software engineering tasks such as automated correction for syntax errors spreadsheet errors detection fuzz testing program synthesis code clones program summarization code similarity probabilistic model for code and path based code representation e.g.
code2vec and code2seq .
all the approaches learn code representations using different program properties.
however none of the existing fault localization techniques has performed direct code modeling and learning on code coverage information of the test cases for the fl purpose as in d eeprl4fl.
xi.
c onclusion we propose a deep learning based fault localization fl approach d eeprl4fl to improve existing fl approaches.
the key ideas include treating the fl problem as the image recognition enhancing code coverage matrix by modeling the relations among statements and failing test cases combining code coverage representation learning with statement dependencies and the code representation learning for usual suspicious code.
our empirical evaluation shows that our model advances the state of the art baseline approaches.
acknowledgment this work was supported in part by the us national science foundation nsf grants ccf ccf twc1723198 ccf and cns .
671references the defects4j data set.
.
available rjust defects4j gzoltar.
.
available the manybugs data set.
.
available https repairbenchmarks.cs.umass.edu pit.
.
available the github repository for this study.
.
available r. abreu p. zoeteweij and a. j. van gemund an evaluation of similarity coefficients for software fault localization in 12th pacific rim international symposium on dependable computing prdc .
ieee pp.
.
on the accuracy of spectrum based fault localization in testing academic and industrial conference practice and research techniquesmutation taicpart mutation .
ieee pp.
.
m. allamanis h. peng and c. a. sutton a convolutional attention network for extreme summarization of source code corr vol.
abs .
.
.
available u. alon s. brody o. levy and e. yahav code2seq generating sequences from structured representations of code arxiv preprint arxiv .
.
u. alon m. zilberstein o. levy and e. yahav code2vec learning distributed representations of code corr vol.
abs .
.
.
available m. amodio s. chaudhuri and t. w. reps neural attribute machines for program generation corr vol.
abs .
.
.
available t. d. b le d. lo c. le goues and l. grunske a learning to rank based fault localization approach using likely invariants in proceedings of the 25th international symposium on software testing and analysis issta .
acm pp.
.
d. w. barowy e. d. berger and b. zorn excelint automatically finding spreadsheet formula errors proc.
acm program.
lang.
vol.
no.
oopsla oct. .
.
available s. bhatia and r. singh automated correction for syntax errors in programming assignments using recurrent neural networks corr vol.
abs .
.
.
available p. bielik v .
raychev and m. vechev phog probabilistic model for code in proceedings of the 33rd international conference on machine learning ser.
proceedings of machine learning research m. f. balcan and k. q. weinberger eds.
vol.
.
new york new york usa pmlr jun pp.
.
.
available l. c. briand y .
labiche and x. liu using machine learning to support debugging with tarantula in the 18th ieee international symposium on software reliability issre .
ieee pp.
.
t. a. budd mutation analysis of program test data.
.
a. grover and j. leskovec node2vec scalable feature learning for networks corr vol.
abs .
.
.
available hadamard hadamard product hadamard product matrices last accessed july .
j. a. jones m. j. harrold and j. stasko visualization of test information to assist fault localization in proceedings of the 24th international conference on software engineering icse pp.
.
j. a. jones and m. j. harrold empirical evaluation of the tarantula automatic fault localization technique in proceedings of the 20th ieee acm international conference on automated software engineering ase .
acm pp.
.
f. keller l. grunske s. heiden a. filieri a. van hoorn and d. lo a critical evaluation of spectrum based fault localization techniques on a large scale software system in ieee international conference on software quality reliability and security qrs .
ieee pp.
.
y .
kim convolutional neural networks for sentence classification arxiv preprint arxiv .
.
a. krizhevsky i. sutskever and g. e. hinton imagenet classification with deep convolutional neural networks in advances in neural information processing systems pp.
.
c. le goues n. holtschulte e. k. smith y .
brun p. devanbu s. forrest and w. weimer the manybugs and introclass benchmarks for automated repair of c programs ieee transactions on software engineering tse vol.
no.
pp.
december .
l. li h. feng w. zhuang n. meng and b. ryder cclearner a deep learning based clone detection approach in ieee international conference on software maintenance and evolution icsme sep. pp.
.
x. li w. li y .
zhang and l. zhang deepfl integrating multiple fault diagnosis dimensions for deep fault localization in proceedings of the 28th acm sigsoft international symposium on software testing and analysis .
acm pp.
.
x. li and l. zhang transforming programs and tests in tandem for fault localization proc.
acm program.
lang.
vol.
no.
oopsla oct. .
.
available y .
li s. wang t. n. nguyen and s. v .
nguyen improving bug detection via context based code representation learning and attentionbased neural networks proc.
acm program.
lang.
oopsla article october .
b. liblit m. naik a. x. zheng a. aiken and m. i. jordan scalable statistical bug isolation in proceedings of the acm sigplan conference on programming language design and implementation ser.
pldi .
new york ny usa association for computing machinery p. .
.
available l. lucia d. lo l. jiang f. thung and a. budi extended comprehensive study of association measures for fault localization journal of software evolution and process vol.
no.
pp.
.
t. mikolov i. sutskever k. chen g. s. corrado and j. dean distributed representations of words and phrases and their compositionality in 27th annual conference on neural information processing systems nips pp.
.
s. moon y .
kim m. kim and s. yoo ask the mutants mutating faulty programs for fault localization in ieee international conference on software testing verification and validation pp.
.
l. mou g. li z. jin l. zhang and t. wang tbcnn a tree based convolutional neural network for programming language processing corr vol.
abs .
.
.
available v .
musco m. monperrus and p. preux a large scale study of call graph based impact prediction using mutation testing software quality journal vol.
no.
pp.
.
l. naish h. j. lee and k. ramamohanarao a model for spectrabased software diagnosis acm transactions on software engineering and methodology tosem vol.
no.
p. .
m. papadakis and y .
le traon using mutants to locate unknown faults in ieee international conference on software testing verification and validation .
ieee pp.
.
metallaxis fl mutation based fault localization software testing verification and reliability vol.
no.
pp.
.
j. patra and m. pradel learning to fuzz application independent fuzz testing with probabilistic generative models of input data tud cs2016 tu darmstadt tech.
rep. .
r. singh b. livshits and b. zorn melford using neural networks to find spreadsheet errors microsoft research microsoft tech report number msr tr tech.
rep. .
r. smith and s. horwitz detecting and measuring similarity in code clones .
r. socher c. c. lin c. manning and a. y .
ng parsing natural scenes and natural language with recursive neural networks in proceedings of the 28th international conference on machine learning icml pp.
.
j. sohn and s. yoo fluccs using code and change metrics to improve fault localization in proceedings of the 26th acm sigsoft international symposium on software testing and analysis issta .
acm pp.
.
d. tang b. qin and t. liu document modeling with gated recurrent neural network for sentiment classification in proceedings of the conference on empirical methods in natural language processing .
association for computational linguistics sep. pp.
.
.
available wala wala documentation.
php main page last accessed july .
m. white m. tufano c. vendome and d. poshyvanyk deep learning code fragments for code clone detection in proceedings of the 31st ieee acm international conference on automated software engineering ser.
ase .
new york ny usa acm pp.
.
.
available w. e. wong v .
debroy r. golden x. xu and b. thuraisingham effective software fault localization using an rbf neural network ieee transactions on reliability vol.
no.
pp.
.
w. e. wong v .
debroy y .
li and r. gao software fault localization using dstar d in 6th ieee international conference on software security and reliability .
ieee pp.
.
w. e. wong r. gao y .
li r. abreu and f. wotawa a survey on software fault localization ieee trans.
softw.
eng.
vol.
no.
pp.
aug. .
.
available w. e. wong and y .
qi bp neural network based effective fault localization international journal of software engineering and knowledge engineering vol.
no.
pp.
.
w. e. wong y .
qi l. zhao and k. y .
cai effective fault localization using code coverage in 31st annual international computer software and applications conference compsac vol.
.
ieee pp.
.
j. xuan and m. monperrus learning to combine multiple ranking metrics for fault localization in ieee international conference on software maintenance and evolution icsme .
ieee pp.
.
j. zhang x. wang h. zhang h. sun k. wang and x. liu a novel neural source code representation based on abstract syntax tree in proceedings of the 41st international conference on software engineering icse .
ieee press pp.
.
l. zhang m. kim and s. khurshid localizing failure inducing pro gram edits based on spectrum information in proceedings of the 27th ieee international conference on software maintenance icsm .
ieee pp.
.
l. zhang t. xie l. zhang n. tillmann j. de halleux and h. mei test generation via dynamic symbolic execution for mutation testing inieee international conference on software maintenance icsm .
ieee pp.
.
l. zhang l. zhang and s. khurshid injecting mechanical faults to localize developer faults for evolving software in proceedings of the acm sigplan international conference on object oriented programming systems languages and applications ser.
oopsla .
new york ny usa association for computing machinery p. .
.
available z. zhang y .
lei x. mao and p. li cnn fl an effective approach for localizing faults using convolutional neural networks in ieee 26th international conference on software analysis evolution and reengineering saner pp.
.
z. zhang y .
lei q. tan x. mao p. zeng and x. chang deep learning based fault localization with contextual information ieice transactions on information and systems vol.
no.
pp.
.
g. zhao and j. huang deepsim deep learning code functional similarity in proceedings of the 26th acm joint meeting on european software engineering conference and symposium on the foundations of software engineering ser.
esec fse .
new york ny usa acm pp.
.
.
available w. zheng d. hu and j. wang fault localization analysis based on deep neural network mathematical problems in engineering vol.
.