wikidominer wikipedia domain specific miner saad ezzini university ofluxembourg luxembourg saad.ezzini uni.lusallam abualhaija university ofluxembourg luxembourg sallam.abualhaija uni.lumehrdad sabetzadeh university ofottawa canada m.sabetzadeh uottawa.ca abstract we introduce wikidominer a tool for automatically generating domain specific corpora by crawling wikipedia.
wikidominer helps requirements engineers create an external knowledge resource that is specific to the underlying domain of a given requirements specification rs .
being able to build such a resource is important since domain specific datasets are scarce.
wikidominer generates a corpusby first extracting aset of domain specific keywords from a given rs and then querying wikipedia for these keywords.
the output of wikidominer is a set of wikipedia articles relevant to the domain of the input rs.
mining wikipedia for domain specific knowledge can be beneficial for multiple requirements engineering tasks e.g.
ambiguity handling requirements classification and question answering.
wikidominer is publicly available on zenodo under an open source license https ccsconcepts software and its engineering requirements analysis computing methodologies language resources .
keywords requirementsengineering natural languagerequirements natural language processing domain specific corpus generation wikipedia acm referenceformat saadezzini sallamabualhaija andmehrdadsabetzadeh.
.wikidominer wikipedia domain specific miner.
in proceedings of the 30th acm joint european software engineering conference and symposium on the foundations ofsoftwareengineering esec fse november14 18 singapore singapore.acm new york ny usa 5pages.
introduction requirementsspecifications rss varyconsiderablyacrossdomains inlargepartduetothespecificterminologyassociatedwitheach domain .
several requirementsengineering re taskscanbe performed more accurately when scoped toa specific domain.for example winkler and vogelsang propose an automated solutionforclassifyingrequirementsandnon requirementsfortheautomotivedomain.ferrarietal.
investigatedefectsinrequirements esec fse november 14 18 singapore singapore copyright held bytheowner author s .
acm isbn978 .
proposeadomain specific methodforhandlingambiguityinrequirements.addressingreautomationinadomain specificmannerusuallynecessitatesdomainspecificknowledgeresources.suchresourcesarenonethelessoften unavailable since domain specific datasets in re are scarce.
intherecentreliterature thereisanincreasingrelianceonnaturallanguageprocessing nlp technologiesforautomation leading to the rapidly emerging research area of nlp4re .
meanwhile nlp is shifting towards the application of large scale language models e.g.
bert forsolvingdownstreamnlptaskssuchas question answering natural language inference and paraphrasing .
language models are often pre trained on large bodies of generictext.forinstance theoriginalbertmodelispre trainedon the entire english wikipedia and the bookcorpus.
this way pretrainedlanguagemodelswouldlearnaboutwordco occurrencesas well as syntactic and semantic regularities in passages.
pre trained language modelscanthenbe fine tunedfor solvingdownstream tasks.fine tuningistheprocessofexposingapre trainedmodel toanotherdataset that is task specific and orin domain .
due to this evolutionary development in nlp many nlp4re solutions even some of the most recent ones need to be reexamined and revamped to fit the new technological trend.
the reason is not only to improve the accuracy of the existing nlp4re solutions butalsotoavoidrelyingonnlplibrariesthatwillsoonbe outdated in turn leadingtomaintenance headaches andupgrading difficulties.anotheressentialaspectthatislikelytoimpactthecurrentnlp4reliteratureisreusability.thecurrentimplementation tendency in view of the available large scale language models is towards python basedlibraries.
toenable better reusabilityof the existingnlp4resolutions itisadvantageoustohaveamorehomogeneous implementation in python even when similar libraries are available in otherlanguages e.g.
java.
in this paper we present wikidominer wikipediadomainspecificminer .
given an rs as input wikidominer automatically generatesadomain specificcorpusfromwikepedia withoutanyaprioriassumptionsaboutthedomainoftheinputrs.wikidominer is a re implementation of the corpus generator in an earlier researchprototype maana .maanaisanautomatedambiguity handlingtoolwhichusesfrequency basedheuristicstodetectcoordinationandprepositional attachmentambiguity.inthatcontext a largedomain specificcorpusisneededforestimatingwordfrequencies.
in our ongoing research since maana we have increasingly neededdomain specificcorpusgeneration notforfrequency based statistics but rather for fine tuning pre trained language models.
this prompted us to build and release wikidominer as a standalonetoolandamorerobustandusablealternativetothecorpus generatorinmaana.maana scorpusgeneratorisjava based.
furthermore it requires a local dump of wikipedia installed as an sqldatabase.thisconsumessignificantresourcesandmakesboth this work is licensed under a creative commons attributionnoncommercial .
internationallicense.
esec fse november14 18 singapore singapore ezzini abualhaija andsabetzadeh theinstallationand re useofmaanacomplex.wikidominerlifts this major limitation and further by virtue of being python based ismucheasier to use alongside languagemodels.
intherestofthispaper weoutlinetheworkingsofwikidominer anddemonstratethe tool s applicationintwodifferentdomains.
tool architecture wikidominer is a usable prototype tool for generating domainspecificcorpora.figure 1showsanoverviewofwikidominerarchitecture.
the tool is implemented in python .
.
using google colab1.
below we discuss the different steps of the tool markeda c infigure .
.
preprocesstext inthefirststep weparsethetextualcontentoftheinputrsand preprocess the text.
to do so we apply an nlp pipeline composed ofsixmodules fourofwhicharerelatedtoparsingandnormalizingthetext andtwoareforperformingsyntacticparsing.these modules include a tokenizer splits the text into different tokens e.g.
commas and words sentence spitter identifies the boundaries of sentences in the running text e.g.
a sentence in english can end with a period lemmatizer findsthe canonicalformofa word e.g.
thesingularword communication isthecanonicalformof its plural variant communications and the infinitive transmit isthecanonicalformfor itspast tense variant transmitted and finally a stopwords removal module removes the stopwords such as articles the and prepositions e.g.
in .
to perform syntactic analysis wefurtherapply postagger thatassignsapart of speech tag for each token e.g.
the tag vbd is assigned to transmitted indicatingapast tenseverb anda syntacticparser thatidentifies the syntactic units in the text e.g.
the notification service is a noun phrase np .
tooperationalizethenlppipeline weusethetokenizer porter stemmerandwordnetlemmatizeravailableinnltk3.
.
.we furtherapplypythonre2.
.1regexlibrary2 inadditiontoavailable modulesinspacy3.
.
includingtheenglishstopwordslist tokenizer np chunker dependency parser and entity recognizer.
.
extract keywords inthisstep weextractasetofkeywordsthatarerepresentativefor the underlying domain.
to do that we adapt a glossary extraction methodfromthereliterature .thebasicideainthisstepisto collectthenounphrasesintheinputrs andsortthemaccordingto their frequency of use.
to ensure that these keywords are domainspecific wikidominerappliestwomeasures.first weremovefrom the list any keyword that is available in wordnet which isagenericlexicaldatabaseforenglish.theintuitionofthisstep is to remove very common words that are not representative of the underlying domain.
for instance the word rover exists in wordnet3as a noun referring to someone who leads a wandering unsettled life or an adultmemberofthe boy scouts movement .
these two meanings do not fit the rover in the lunar rover o2 o0 o8 o1 o7 o5 o9 o6 o3 o4 h context and the np lunar rover .
this way we filter out the word rover whenitoccursalone i.e.
therover andkeepitaspartof thenp lunarrover .wenotethatthethenp lunarrover isnot available inwordnet but isinwikipedia4.
asasecondmeasure wikidominercomputestermfrequency inverse document frequency tf idf instead of mere frequency.
tf idfisatraditionalmethodthatisoftenappliedinthecontext of information retrieval ir to assign a score reflecting the importance of words to a specific document in a document collection.
in wikidominer the importance of the words nps in our case indicates that the words are significant for the underlying domain.
wenotethatidfiscomputedonlywhentherearemultipledocuments from other domains available.
otherwise the tf idf scores are similar to term frequencies.
once the tf idf scores are computed we sort the keywords in descending order of these scores and select the top kkeywords.
while the default value applied by wikidominer is k we showin the demoof the toolthatthis parameter can be configured by the user according to the intended application.
weimplementthedifferentmodulesusingwordnetfromnltk .
.
andtf idf transformation from scikit learn1.
.
.
.
querywikipedia in this step we use the keywords from the previous set to query wikipedia andcollecttherelevantarticleswhich willthenconstituteour final domain specific corpus.
to better understand this step we first explain the structure of a category in wikipedia illustrated in figure .
each article in wikipedia belongs to one or more categories.
each category containsasetofarticlesandsub categories.toillustrate assume that we are querying wikipedia for the keyword rail transport within the railway domain.
our first hit will be a page titled rail transport 5. note that we refer to a page in wikipedia as anarticle.
if we view the category structure for this article6 we find out that it belongs to a category under the same name rail transport i.e.
category ainfigure .inside this category there are31sub categoriessuchas locomotives railinfrastructure and electric rail transport .
category a contains22 other pages alongside the above mentioned pages such as bi directional vehicle and pocket wagon .viewing thestructure ofasub category e.g.
rail infrastructure will show us again the available pages andsub categories.
in wikidominer the result of querying wikipedia for a given keyword is a wikipedia article whose title partially matches the keyword.weconsiderthetitleofawikipediaarticleaspartially matchingthekeywordiftheyhavesomeoverlap.forexample if we query wikipedia for the keyword efficiency of rail transport then we will retrieve the same article mentioned above whose title rail transport partiallymatches the keyword.
foreachkeyword weretrievefromwikipediaamatchingarticle if applicable.
some applications might require that the domainspecific corpus be sufficiently large.
for example to accurately estimate the frequencies of words co occurrences one needs a 1707wikidominer wikipediadomain specificminer esec fse november14 18 singapore singapore requirements specification wikipediaa c b txt wikipedia articlespreprocess text extract keywords query wikipedia tokenizer sentence splitter pos tagger lemmatizer syntactic parser np extractor frequency computer articles retriever corpus expander preprocessed texttop k domainspecific keywords stopwords removal figure toolarchitecture.
rail transport keyword 2keyword k... ... categories... articles ... sub categories articles ...rsdepth depth depth 2articles extract keywords a figure illustration of traversing wikipedia categories examplekeyword railtransport .
largecorpus .similarly topre trainadomain specificlanguage model a large text body should be available.
therefore we expand ourcorpusbydefiningaconfigurableparameter depthtocontrol the level of expansion thus allowing the user to adjust the size and relevance of the corpus based on their needs.
the minimal depthdepth 0can be used to extract directly matching articles only leading most often to a few hundred articles .
wikidominer further retrieves for each matching article all articles in the same categoriesfor depth e.g.
thetwootherpagesintheexample above subcategories of depth sub subcategories of depth andsoon.
specific details of our implementation are as follows.
we use the wikipedia .
.07and wikipedia api .
.48libraries to query wikipedia.otherlibrarieswhichweusebutwhicharenotnecessary to run the tool include pypdf2 .
.09to read requirements documentsinpdfformat theword2vecsimilarityfeatureinspacy .
.0library andthewordcloud1.
.010librarytovisualizethe mostprevalentwordsinthe extractedcorpora.
application inthissubsubsection weapplywikidominertoautomaticallygenerate domain specific corpora for two distinct domains namely railway andtransportation.
we further assess how representative the corpus generated for each of these domains is.
we do so by computingthesemanticrelatednessofeachdomain specificcorpusagainstrssfromthesamedomainotherthanthoseusedfor generatingthe corpus.
generating adomain specific corpus is not a frequent activity.
in practice requirements engineers would typically have a small set of rss from a given domain at the time of generating a domain specific corpus and would utilize this corpus toperformactivitiesonotherrssnotinvolvedinthegeneration process.
.
data collection forthetwodomainsconsideredinthissection wecollectedatotal of six rss from the pure dataset with three rss from each domain.onersisusedforgeneratingthecorpusandtheothers are used for evaluatingsemanticrelatedness against theresulting corpus.
in the following we listthe six rss from the railway domain we used rs1 ertms abouttrain control rs2 eirenesys15 andrs3 eirenefun both aboutdigital radio standard for railway .
from the transportation domain we used rs4 ctc network abouttraffic managementinfrastructure rs5 pontis abouthighwaybridgeinformationmanagement andrs6 mdot abouttransportation info management .
.
domain specific corpora for illustration we centre our discussion around the railway domain.wegeneratethecorpusfromrs1 andevaluatetherelatednessonrs2andrs3.thefirststepinwikidomineristopreprocess rs1.wikidominerthenextractsasetofkeywordsbasedontheir tf idfscores.examplesofsuchkeywordsinclude trainborneequipmentandemergencybrake .weselectthetop kkeywords where k .
thenextstepistoquerythekeywordsonwikipedia.forourset ofkeywordsinthisdomain weretrieve15matchingarticles.we then set the configuration parameter depthto .
following this we collectforeacharticlethatmatchesakeywordthearticlesinthe respective categories see figure .
finally we collected a total of 686articles whichareconsideredasourdomain specificcorpus.
weapplywikidomineronrs4 fromthetransportationdomain in a similar manner.
the two resulting corpora are depicted in 1708esec fse november14 18 singapore singapore ezzini abualhaija andsabetzadeh figure word cloud visualization of domain specific corpora left hand side railway domain and right hand side transportation domain .
figure3as word clouds.
we show for each domain the main terms that frequently occur in the corpus.
we see that the keywords rail track train railway andrailroadcharacterizetherailwaycorpus whilethetransportationcorpusischaracterizedbythekeywords traffic road street andlane.wenotethatthe railwaydomaincan be regarded as a sub domain of the transportation domain.
this observation is highlighted through the frequent terms that the two corporahaveincommoninfigure suchassignal system vehicle anddriver.
.
domain representativeness to examinehow representative the resulting domain specificcorpora are we compute semantic relatedness as follows.
we first transform each article in the corpus into a vector representation usingword2vec.wedothesameforthetestrs.then wecompute the cosine similaritybetween the vector representingthe test rs andthevectorrepresentingeacharticle.inthefollowing wereport theminimum average andmaximumcosinesimilarityscoresfor eachdomain railway domain cosine similarity between the railway corpusandtest rss min .
average .
andmax .
transportation domain cosine similarity between the transportationcorpusandtestrss min .
average .
and max .
.
our results show that the domain specific corpora are on average highly similar to the test unseen rss not used for generating thecorpora.inparticular theaveragesemanticsimilarityis .
indicating thatmanyarticlesinthecorpusare relevanttothetest rss.theminimumscoreof0.27intherailwaydomainimpliesthat there are articlesinthecorpuswhich aremore document specific i.e.
morerelevanttothersthatinducedthecorpusbuthavinglittle incommonwiththetestrss.notethat despitesomedocumentspecificarticlesbeingpresentinthegeneratedcorpus theveryhigh average semantic similarity .
indicates that such articles are asmallminorityandthusdonothaveasignificantnegativeimpact onthe in domainusabilityofthe generatedcorpus.
the gap seen between the minimum scores reported for the two domain specific corpora can be explained by the following as mentionedinsection .
allrssfromthetransportationdomainin our collection are on the topic of traffic and transportation informationmanagement.thisleadstoextractingmanykeywords related to information management.
in contrast the rss in our collection from the railway domain are tailored to more specific topics namely train control and digital radio standard for railway.
this in turn leads to extracting document specific terms which are related to train control i.e.
the topic of the rs used for corpus generation butnotsomuchtodigitalradiostandardforrailway i.e.
the topic of the test rss .
to summarize our experiments show that wikidominer has successfully generated representative corporafor twodistinct domains.
conclusion we presented wikidominer a tool for automatically generating domain specific corpora from wikipedia.
our current implementation is a significantly enhanced and usable adaptation of the corpus generation component briefly outlined in our earlier work .
wikidominerextracts keywordsfrom agiven requirementsspecification rs andthenqueriesthesekeywordsinwikipedia.for each keyword wikidominer looks for a matching article whose titlehassomeoverlapwiththekeyword.toexpandthecorpus we providetheuserwiththepossibilitytoconfigureaparameter depth thatcontrols how deeplythe wikipedia categorystructure should be traversed.
we assess the relatedness of the resulting corpora to rss different from those used for corpus generation.
our empirical resultsshowthat acrosstwodistinctdomains wikidomineryields an averagesemantic relatedness of .94for in domainanalysis.
inthefuture weplantoutilizewikidominerforaddressingnew analyticalproblemsbeyondambiguityanalysis.notabletargetproblems include question answering andrequirements classification.