generalizable and interpretable learning for configuration extrapolation yi ding mit csail cambridge ma usa ding1 csail.mit.eduahsan pervaiz university of chicago chicago il usa ahsanp uchicago.edu michael carbin mit csail cambridge ma usa mcarbin csail.mit.eduhenry hoffmann university of chicago chicago il usa hankhoffmann cs.uchicago.edu abstract modern software applications are increasingly configurable which puts a burden on users to tune these configurations for their target hardware and workloads.
to help users machine learning techniques can model the complex relationships between software configuration parameters and performance.
while powerful these learners have two major drawbacks they rarely incorporate prior knowledge and they produce outputs that are not interpretable by users.
these limitations make it difficult to leverage information a user has already collected e.g.
tuning for new hardware using the best configurations from old hardware and gain insights into the learner s behavior e.g.
understanding why the learner chose different configurations on different hardware or for different workloads .
to address these issues this paper presents two configuration optimization tools gilandgil using the proposed generalizable and interpretable learning approaches.
to incorporate prior knowledge the proposed tools start from known configurations iteratively construct a new linear model extrapolate better performance configurations from that model and repeat.
since the base learners are linear models these tools are inherently interpretable.
we enhance this property with a graphical representation of how they arrived at the highest performance configuration.
we evaluate gilandgil by using them to configure apache spark workloads on different hardware platforms and find that compared to prior work gilandgil produce comparable and sometimes even better performance configurations but with interpretable results.
ccs concepts software and its engineering software configuration management and version control systems computing methodologies machine learning approaches .
esec fse august athens greece copyright held by the owner author s .
acm isbn .
configuration machine learning generalizability interpretability acm reference format yi ding ahsan pervaiz michael carbin and henry hoffmann.
.
generalizable and interpretable learning for configuration extrapolation.
in proceedings of the 29th acm joint european software engineering conference and symposium on the foundations of software engineering esec fse august athens greece.
acm new york ny usa 13pages.
introduction the increasing configurability of modern software makes it challenging for users to tune performance due to high complexity tremendous configuration spaces and complicated interactions between these configuration parameters .
configurations have a large influence on application performance such as latency throughput and energy consumption .
as a result tools to help tune application configurations for high performance have become a crucial yet challenging research area.
to configure software applications efficiently machine learning ml approaches have been applied to model the complex relationships between configuration parameters and performance.
most prior work on incorporating ml approaches in software performance modeling is to first randomly sample assignments of configuration parameters for the application measure the application s performance with the sampled parameters train a learner on these samples predict the performance for unsampled configurations and then deploy the software in the configuration with the best predicted performance .
the most sophisticated of these learners e.g.
neural networks random forests and gaussian process regression are black box meaning that users have no visibility into their internal workings .
although black box ml approaches are effective at software performance modeling there are two practical limitations to be addressed for efficient optimal configuration search difficulty incorporating prior knowledge.
prior ml based tools have little ability to leverage information a user has previously collected.
such tools require significant data collection they must start from scratch by generating numerous random configurations and collecting their performance.
two specific scenarios are considered as follows 728this work is licensed under a creative commons attribution international .
license.
esec fse august athens greece yi ding ahsan pervaiz michael carbin and henry hoffmann scenario workload x runs slowly due to some faulty configuration settings .
to find a better configuration a user can randomly sample new configurations from scratch run x for each to collect performance data and build a new ml model.
to avoid this tedious process a user can instead leverage the known configurations even though they are slow to build a model that can extrapolate to find a better configuration.
this strategy saves time as it does not need new initial training data collection.
scenario workload y has been tuned to work at the optimal configuration on hardware a. due to some hardware upgrade or scheduling issues a is no longer available and y has to be deployed on hardware b. using prior approaches users would randomly sample configurations on b collect performance data and build a ml model for configuration search .
an alternative is to incorporate prior knowledge by using configurations known to run fast on a and developing a model to extrapolate the configuration space from a to b. in .
we show that incorporating prior knowledge achieves better performance than starting from scratch with random sampling.
lack of interpretability.
prior work evaluates their black box models only for their performance prediction accuracy it is difficult for users to interpret the prediction results .
considering again the above two scenarios scenario users hope to understand the underlying factors from software applications to hardware resources that cause the low performance and thus avoid the similar issues in the future .
scenario users hope to interact with the learners and gain insights into why prior configurations are slow and how faster configurations are achieved.
they also hope such knowledge to generalize across different hardware and workloads .
to address these limitations we present gilandgil configuration extrapolation tools that incorporate prior knowledge to achieve high performance and provide interpretability to advance human knowledge.
to incorporate prior knowledge gilandgil use existing information about configurations as initial training samples and then extrapolate to even higher performance configurations.
to achieve interpretability the key insight is to iteratively construct linear models that approximate the true nonlinear function such that the most important configuration parameters can be interpreted as a combination of both their weights in the linear model and the changes in those weights as the model is iteratively updated.
to help understand the relationships between the application and the computer system on which it runs gil augments gil with a hierarchical model that connects application level configurations low level system metrics e.g.
context switches and cache misses and the final application performance see detailed definitions in .
.
additionally we develop graphical tools to visualize these relationships to help users interpret learning results.
we implement gilandgil and evaluate them on apache spark workloads of hibench which is a widely used benchmark suite to evaluate data processing frameworks .
we run ten workloads covering a wide range of categories on three different hardware platforms.
we consider two experimental settings corresponding to scenarios 1and respectively.
our results show the following figure gil hierarchical model relating application configurations low level system metrics and performance.
gilandgil achieve better extrapolation performance than random sampling neural networks and genetic algorithms with results comparable to bayesian optimization .
?
?
.
for all learners incorporating prior knowledge achieves performance improvements compared to starting from scratch with random sampling for initial training .
.
gil enables the users to interact with the learners and interpret relationships between application level configurations low level system metrics and performance via visualization tools .
.
in summary this work makes the following contributions proposing gilandgil two configuration extrapolation tools that incorporate prior knowledge to avoid starting from scratch.
demonstrating the benefits of incorporating prior knowledge into learning systems for configuration extrapolation.
developing visualization tools for gilandgil to help users interpret learning results.
releasing code and data for gilandgil in motivational example as an example of the value our tools we study apache spark workloads from hibench on three different hardware from a public heterogeneous cloud system the chameleon cloud research platform .
we use the names that chameleon1uses for different hardware with details shown in table which includes three hardware microarchitectures skylake haswell and storage the first two are compute servers the last is optimized for disk bandwidth.
we determine the best configuration for each workload and specific hardware by exhaustive search among our measurements.
gil develops a hierarchical model connecting application level configurations low level system metrics and performance shown in figure see detailed definitions in .
.
in particular gil builds a linear model between low level system metrics and performance and for each low level system metric gil builds a linear model between application level configuration parameters and it.
with the extra low level system layer in between gil makes it easier 729generalizable and interpretable learning for configuration extrapolation esec fse august athens greece bmr cmr ipc csrpfr .
.
.
.
.0before after a nweight bmr cmr ipc csrpfr .
.
.
.
.2before after b lr figure visualizing learned relationships between lowlevel systems metrics and performance.
the value on each axis shows how the corresponding low level system metric influences performance when moving from haswell before to storage after .
for users to reason about the hardware and software cross stack interactions as well as tune application level configurations.
to illustrate gil s behavior we use the nweight workload from hibench.
consider the case where haswell is available first for deployment and the high performance configurations have been tuned for haswell either by human users or learners.
later a new class of storage machines with a small processor downgrade slightly reduced clockspeed and last level cache and huge storage system upgrade see details in table becomes available.
a reasonable hypothesis would be that for the nweight workload the upgraded storage system will outweigh the small downgrade in computing power.
thus when we deploy nweight on storage it is natural to start the high performance haswell configurations and run them directly on storage.
unfortunately we find that the performance throughput can be more than worse on storage than haswell for the same configuration.
even if black box learners from prior work are used to tune configurations using these available configurations the best possible performance we find on storage is still worse than the best haswell performance.
even worse these black box learners provide no interpretation of their results.
thus at this point the user might be wondering if storage is fundamentally slower for nweight or if the black box learners simply need more time to search for a better configuration.
with a black box learner there is no way for a user to gain insight into these questions.
gil on the other hand produces an interpretable model that a user can inspect.
figure 2a shows the nweight interpretation results between application performance and low level system metrics before and after applying gil to tune application level configurations on storage.
in other words the before configurations are those that perform well on haswell and the after configurations are those that perform well on storage.
the label for each axis in the radar chart represents a specific low level system metric see details in table and the value on each axis is the learned linear coefficient mapping from the low level system metric to application level performance.
see .
to know more about how we visualize the results.
this chart shows that ipc instructions per cycle changes most a sharp spike towards ipc after applying gil which indicates that higher ipc is associated with better performance on storage .
.
.
.
.
linear coefficient differencesbmrcmripccsrpfrspark.broadcast.blocksize spark.shuffle.file.buffer spark.executor.memory spark.broadcast.compress spark.kryoserializer.buffer spark.memory.fraction spark.reducer.maxsizeinflight spark.io.compression.snappy.blocksize spark.speculation.interval spark.shuffle.spill.compress spark.driver.memory spark.task.maxfailures spark.shuffle.compress spark.speculation.quantile spark.network.timeoutfigure visualizing learned relationships between lowlevel system metrics and application level configurations fornweight workload.
the magnitude of each bar shows how much the corresponding application level configuration parameter changes each low level system metric when moving from haswell to storage with larger bars indicating larger effects .
this enables users to relate the large effects from application level configurations to the effects each low level system metric has on performance in figure .
and thus application level configurations should be tuned to increase ipc.
these results immediately provide insights into why haswell performs better than storage haswell s faster clock and larger last level cache are likely beneficial for an application that wants increased computational power.
being able to interpret the model gives us certain confirmation that haswell is really faster than storage for this workload.
furthermore gil can be used to discover workloads that behave similarly and infer the possible optimal deployment for new workloads.
figure 2b shows the radar chart for lr it behaves similarly to nweight both having sharp spikes towards ipc which indicates that they would likely benefit from the same hardware.
in other words it may not be worthwhile running lron storage because nweight is faster on haswell than on storage and it is likely that lrwill be faster on haswell as well.
in contrast black box learners cannot report back this type of information to human users.
nevertheless no configuration optimizer can directly affect ipc instead they must tune the application level configurations to increase nweight s ipc and then its performance.
therefore gil builds interpretable models that map application level configurations and low level system metrics to tune configuration parameters.
figure shows the absolute linear coefficient differences between after and before applying gil starting from configurations that perform well on haswell and arriving at configurations that perform well on storage .
this figure shows that although storage has only a small difference in processor the application level configurations that help achieve this throughput change greatly i.e.
spark.broadcast.blocksize .
in contrast black box learners are not able to provide such insights to help users understand why they get different optimal configurations for different hardware.
since gil starts from prior knowledge configurations that work well on haswell and then finds high performance configurations on storage this provides users insights into the differences between 730esec fse august athens greece yi ding ahsan pervaiz michael carbin and henry hoffmann figure workflow for gilandgil tools.
the configurations they know well and those that gil finds.
additionally our empirical results see .
show that extrapolating from known configurations can achieve better performance than starting from scratch with randomly sampling from the tremendous configuration space.
proposed tools in this section we will first define related terminologies and then introduce two proposed tools gilandgil and then describe the visualization tools for model interpretation and finally discuss the limitations of the proposed tools.
.
definitions figure illustrates gilandgil .
the input includes a workload to optimize a list of application level configurations and the low level system metrics and performance data to be collected.
workload.
a workload is a configurable software application.
we evaluate apache spark workloads shown in table but in principle this could be any configurable software system whose quantitative behavior we want to understand and optimize.
configuration.
a configuration for a software application represented by a p dimensional vector where pis the number of configuration parameters xi where xiis the i th configuration xi jis the value of the j th configuration parameter in the i th configuration.
for instance pis corresponding to the apache spark configuration parameters in our evaluation shown in table .
low level system metric llsm .
llsm is the quantifiable behavior of the underlying os e.g.
context switches and hardware e.g.
cache misses that helps understand the application level performance.
these are represented as a d dimensional vector assuming there are dmetrics to measure and understand ui where uiis the i th low level system metric vector ui jis the value of the j th metric in the i th low level system metric vector.
for example in this work dis as five low level system metrics are studied as shown in table .
performance.
performance is the measured behavior for a workload on certain hardware.
this work focuses on throughput which is the rate of the total data delivered in the network .
each configuration and its corresponding measurement including low level system metrics and performance is a sample .giland gil use these samples to build performance models to search the optimal configuration as an output.
specifically gilandgil buildalgorithm gilperformance model.
require xtr training configuration set require xte test configuration set require ytr training performance set require k sample budget at each round require t number of rounds foreach round t .
.
.
t do train model that maps configurations xtrto performance ytr.
use above trained model to predict performance on xte.
select kconfiguration set xtwith best predicted performance.
run workload to get true performance ytforxt.
update training configuration set xtr xtr xt.
update training performance set ytr ytr yt.
update test configuration set xte xte xt.
train model that maps configurations xtrtoytr.
use the trained model to predict performance for test configuration set xte.
interpret results using tools in .
.
output configuration x with the best predicted performance and interpretation results visualized by radar and bar charts.
a series of models relating application level configurations to performance a series of models relating the low level system metrics to performance and a series of models relating application level configurations to each low level system metric.
then the coefficients learned from these models are passed to model interpretation to visualize the results as another output.
next we will elaborate the performance models and interpretation visualization.
.
gilperformance model to improve performance accuracy and promote search space exploration giliteratively interacts with the workload by sequentially learning an unknown function f modeling the relationships between application configuration and performance with a sample budget.
at each iteration limited configurations are selected to update f. after all iterations are completed giluses the learned f to evaluate the remaining untested configurations to find the one with the best predicted performance.
in this process two challenges chs need to be addressed ch1 designing a model to learn the unknown function f. ch2 formulating a query strategy to select the samples.
we will address these two chs as follows.
.
.
learning linear functions.
to learn the unknown function f giluses a linear regression model .gilchooses linear model over other nonlinear models such as neural networks and gaussian process regression due to several advantages better extrapolation ability.
although nonlinear models usually achieve higher overall prediction accuracy than linear models they are more likely to overfit the training set which leads to poor extrapolation performance when facing unseen data points .
in contrast linear models are less likely to overfit and thus generalize better on unseen data.
interpretability.
linear models are naturally interpretable the linear coefficients quantify the relationships between independent metrics and performance a positive coefficient indicates positive correlation between a metric and performance while a negative coefficient indicates negative correlation.
the coefficients magnitudes represent the strength of these relationships.
731generalizable and interpretable learning for configuration extrapolation esec fse august athens greece for the i th configuration xi assuming its measured performance isyi the linear regression model will be yi 1xi1 2xi2 .
.
.
pxip i where 1 .
.
.
pare coefficients corresponding to pconfiguration parameters and iis the noise usually assumed to be a gaussian .
the linear model is solved via ridge regression which is a regularized method to avoid overfitting .thus giladdresses ch1 by iteratively estimating the unknown function with linear models.
.
.
active learning.
gilapplies active learning to iteratively query samples over successive rounds.
at each round gilcollects samples that are intended to improve the model predictions for the best configurations.
after evaluating the new samples the model is updated using these samples and then the next round begins.
as such the key is to come up with a query function that converges quickly so that gilcan find the optimal configuration across spaces with limited samples.
this is not trivial because the model needs to balance the tradeoff between exploration avoiding local optima in training space and exploitation improving the predictions for the highest performance configurations in new space.
given the base learner is linear giloptimizes locally by querying samples with the best predicted performance at each step for each step t assume the predictive function is ft then the optimizer searches for a subset swith kconfigurations such that s arg max s s s k sft s .
this query strategy selects a subset of configurations with the best predicted performance at each round.
intuitively picking configurations with the best performance is more likely to improve the prediction accuracy for the best performance configurations in the next round.
with this query strategy giladdresses ch2 by searching the optimal configuration as rapidly as possible.
algorithm summarizes the procedures for gilperformance model.
.
gil performance model gilinterprets the relationships between the application level configuration parameters and ultimate performance by quantifying the learned coefficient for each application level configuration parameter.
to further benefit from interpretation we propose a hierarchical performance model that relates application level configuration parameters to performance through low level system metrics.
in particular we hope to understand not just how each application parameter influences performance but also how that influence manifests through low level system metrics like cache misses or context switches.
to accomplish this goal we present gil illustrated in figure .
we consider five low level system metrics in this paper see details in table .
in principle gil could be applied to any set of low level system metrics.
we incorporate this extra layer as follows.
algorithm summarizes the procedures for gil .
instead of directly building models mapping from application configurations to performance gil first builds an model that maps from low level system metrics to performance.
then gil obtains the low level system metric vector with the best predicted performance from test low level system metric set ute as in line .
next fori th low level system metric ui i .
.
.
gil builds a modelalgorithm gil hierarchical performance model.
require xtr training configuration set require xte test configuration set require utr training low level system metric set require ute test low level system metric set require ytr training performance set require d number of low level system metrics llsms require k sample budget for each low level system metric at each round require t number of rounds foreach round t .
.
.
t do train model that maps llsms utrto performance ytr.
get llsm vector with best predicted performance from ute.
foreach llsm ui i .
.
.
d do train model that maps xtrtoui tr.
use trained model to predict on ui te.
select kconfigurations xi twith closest predicted i th llsm values to ui.
run workload to get true llsm value ui tand performance yi tforxi t. update training configuration set xtr xtr xi t. update training llsm set utr utr ui t. update training performance set ytr ytr yi t. update test configuration set xte xte xi t. train model that maps configurations xtrtoytr.
use the trained model to predict performance for test configuration set xte.
interpret results using tools in .
.
output configuration x with the best predicted performance and interpretation results visualized by radar and bar charts.
that maps from application configurations to ui.
then gil selects topkapplication configurations that have the closest predicted i th low level system metric values to ui and these kconfigurations and corresponding measurements will be queried for the next round as in line .
after all training and test sets are updated gil trains the model on the final training configuration and performance sets and uses it to evaluate the remaining test configurations picking the one with the best predicted performance as the output as in line .
the intuition of this hierarchical model is to select application configurations that induce the nearest low level system metric values producing the best predicted performance.
.
interpretation by visualization we interpret results from performance models via visualization.
we focus on gil because of its extra low level system metric layer which makes it possible to investigate the cross stack interactions between system and application levels.
we visualize the learned relationships between performance and low level system metrics and low level system metrics and configuration parameters.
we use radar charts to depict the relationships between performance and low level system metrics and how they change before and after applying gil .
these charts visualize the differences between the initial user provided configurations and the final relationships that gil learns.
if users provide configurations that are known to work well on different hardware then these charts will visualize the differences in the influence of these initial configurations and those gil learned.
we choose radar charts because they can show multiple metrics simultaneously and quickly compare different values in each axis.
the label for each axis represents a specific low level system metric and the value on each axis is the learned linear coefficient mapping from low level system metric to performance.
the changes are visualized with different colors.
we use bar charts to illustrate the relationships between lowlevel system metrics and application configuration parameters.
we 732esec fse august athens greece yi ding ahsan pervaiz michael carbin and henry hoffmann choose bar charts because there are multiple low level system metrics and we need to compare each with their relationships with configuration parameters.
take nweight workload in figure as an example.
the y axis represents each low level system metric and the x axis represents the learned absolute linear coefficient differences before and after applying gil .
each bar represents different configuration parameters and their direction and length correspond to the x axis.
with bar charts we can interpret the learned relationship between low level system metrics and configuration parameters and how their influences to each low level system metric change.
.
discussion and limitations gilandgil use linear models as base learners to achieve interpretability which would lose a slight amount of overall prediction accuracy compared to using more sophisticated black box learners such as neural networks gradient boosting trees and gaussian process regression .
moreover these black box learners are more likely to overfit the training data and make conservative judgment in exploring new space.
to compensate for the lose of prediction accuracy gilandgil employ an iterative learning paradigm to allow the model to correct itself every time there is an error .
meanwhile bayesian optimization updates the model iteratively using a black box learner gaussian process regression and usually achieves high prediction accuracy which is also demonstrated in our evaluation in section .
while powerful it is uninterpretable and thus does not provide insights into how the highest performance configuration is reached.
to sum up giland gil are practical trade offs between accuracy and interpretability.
experimental methodology this section describes our experimental setup and evaluation methodologies to demonstrate the effectiveness of gilandgil at configuration extrapolation in multiple workloads hardware and settings.
.
systems .
.
software.
we use apache spark .
.
2as our software distributed computing framework.
each experiment has a server node and four worker nodes.
we choose a wide range of configuration parameters that reflect significant spark properties categorized by shuffle behavior data compression and serialization memory management execution behavior networking and scheduling.
table shows the total parameters in detail.
we use similar parameters to prior work but not the same set because spark has actually reduced the number of user visible configuration parameters precisely because configuring them is challenging.
.
.
hardware.
we run experiments on a public cloud computing system the chameleon cloud research platform .
we use the names that chameleon3uses for three intel x86 processors shown in table .
we collect five low level system metrics that have been shown to influence application performance .
table shows the five low level system metrics in detail.
workloads we select ten apache spark workloads from the hibench4big data benchmark suite with details shown in table .
these workloads cover various domains including microbenchmarks micro machine learning ml websearch and graph analysis and they exhibit a wide range of resource usage.
for ten workloads with configurations per workload on three hardware platforms it took four weeks of computing time to collect all these data for experimental evaluation in this paper.
.
points of comparisons we compare the following approaches default the default application level configuration provided by the apache spark developers.
rs randomly sample configurations and select the best with a linear regression performance model.
nn a design space exploration method with neural network and intelligent sampling proposed in .
dac a configuration parameter tuning approach with the ensemble tree model and genetic algorithm proposed in .
bo bayesian optimization for configuration tuning .
gil generalizable and interpretable learning relating application configurations and performance.
gil generalizable and interpretable learning relating application configurations low level system metrics and performance.
opt exhaustive search for the true optimal configuration over the entire measurements.
rs nn and dac are non iterative learning methods that train only once while bo gil and gil are iterative methods that train multiple rounds until the sample budget is met.
nn dac and bo use black box models while rs gil and gil are interpretable.
all parameters for these algorithms used in our experiments are selected via cross validations.
.
evaluation metric for each workload we compare the relative performance rp between the best performance throughput found from the learningbased configuration search methods and the true optimal performance found through exhaustive search over our measurements rp ypred yopt yopt where ypredis the best performance from the above methods and yoptis the optimal performance.
lower rp is better.
.
evaluation methodology we randomly generate application level configurations for each workload which is a commonly used size in prior work .
for each workload we run it at each configuration on different hardware to record their performances.
we divide the total configurations into three levels low modest and high performance with corresponding ratios e.g.
the high performance configurations are the top of the measured configurations.
the optimal configuration for each workload on each hardware is obtained via exhaustive search over our measurements.
we then use 733generalizable and interpretable learning for configuration extrapolation esec fse august athens greece table details of the apache spark .
.
configuration parameters.
configuration parameter range description spark.reducer.maxsizeinflight maximum size of map outputs to fetch simultaneously from each reduce task in mb.
spark.shuffle.file.buffer size of the in memory buffer for each shuffle file output stream in kb.
spark.shuffle.sort.bypassmergethreshold avoid merge sorting data if there is no map side aggregation.
spark.speculation.interval how often spark will check for tasks to speculate in millisecond.
spark.speculation.multiplier how many times slower a task is than the median to be considered for speculation.
spark.speculation.quantile percentage of tasks which must be complete before speculation is enabled.
spark.broadcast.blocksize size of each piece of a block for torrentbroadcastfactory in mb.
spark.io.compression.snappy.blocksize block size used in snappy in kb.
spark.kryoserializer.buffer.max maximum allowable size of kryo serialization buffer in mb.
spark.kryoserializer.buffer initial size of kryo s serialization buffer in kb.
spark.driver.memory amount of memory to use for the driver process in gb.
spark.executor.memory amount of memory to use per executor process in gb.
spark.network.timeout default timeout for all network interactions in second.
spark.locality.wait how long to launch a data local task before giving up in second.
spark.task.maxfailures number of task failures before giving up on the job.
spark.shuffle.compress false true whether to compress map output files.
spark.memory.fraction fraction of heap space mb used for execution and storage.
spark.shuffle.spill.compress false true whether to compress data spilled during shuffles.
spark.broadcast.compress false true whether to compress broadcast variables before sending them.
spark.memory.storagefraction .
amount of storage memory immune to eviction.
table details of the hardware platforms.
skylake haswell storage processor gold e5 e5 ram size gb gb gb of threads clockspeed .
ghz .
ghz .
ghz l3 cache .
mb mb mb memory speed .
ghz .
ghz .
ghz mem channels network speed gbe .
gbe gbe disk vendor samsung seagate seagate disks disk bandwidth gb s gb s gb s table details of the five low level system metrics.
abbr.
low level metrics description bmr branch misses rate branch misses total branch misses cmr cache misses rate cache misses total cache misses csr context switch rate context switch cpu cycles pfr page faults rate page faults cpu cycles ipc instruc.
per cycle instruction cpu cycles the methods mentioned above to search for the best configuration for each workload on different hardware.
since our goal is to examine the extrapolation ability of each algorithm we consider the following two experimental settings low2high training set only has configurations of low performance and test set has configurations with a wide range of performance.
this setting corresponds to scenario 1in i.e.
table details of the ten hibench workloads.
workload data size workload data size wordcount gb lr gb terasort .
gb linear gb als .
gb rf .
gb bayes gb pagerank .
gb kmeans gb nweight .
gb this represents the case where users start from configurations of low performance and aim to extrapolate to high performance .
mod2high training set only has configurations of modest performance that run fast from a different hardware and test set has configurations with a wide range of performance.
for instance if the training set has configurations that run fast on haswell but run modestly on skylake the search phase will evaluate all configurations in test set to pick the one predicted to run fastest on skylake.
since we have hardware we have training test pairs.
this setting corresponds to scenario 2in i.e.
this represents the case where users have found configurations of high performance for one hardware and attempt to use those as a starting point to optimize for a different hardware.
in algorithm and tandkare set as small numbers to demonstrate that gilandgil can produce comparable and better results on a small sample budget than those methods without intelligent sampling e.g.
rs .
since the collected dataset size for each hardware is we choose and for low2high andmod2high i.e.
and which are much smaller than thousands used in prior work .
low2high requires more labeled data for training because it extrapolates larger space than mod2high does.
kis set as .
we report results averaged over runs with different seeds.
734esec fse august athens greece yi ding ahsan pervaiz michael carbin and henry hoffmann experimental evaluation we examine the following research questions rqs rq1 how good are gilandgil at extrapolating from configurations of low performance to high performance low2high ?
rq2 how good are gilandgil at extrapolating from configurations of modest performance to high performance mod2high ?
rq3 does incorporating prior knowledge improve extrapolation performance compared to starting from scratch?
rq4 what can we interpret from visualization in case studies?
.
rq1 how good are gilandgil at extrapolation from configurations of low performance to high performance?
we examine the extrapolation results from configurations of low performance to high performance in low2high setting.
figure shows the relative performance rp results for each method.
the strip label on the right for each row of bar charts represents the hardware platform for the experiments.
the x axis represents each workload and the y axis represents rp.
lower is better closer to optimal .
the last column harmean shows the harmonic mean results over all workloads which are also quantified in table .
table harmonic mean results over all workloads of each hardware for low2high .
the last column harmean is the harmonic mean over three hardware.
skylake haswell storage harmean default rs nn dac bo gil gil for non iterative learning methods rs is generally better than nn and dac which is a bit counter intuitive as we would think that linear models are not as powerful as black box models.
however as discussed in .
.
despite perhaps overall lower prediction accuracy linear models are less likely to overfit and thus promote extrapolation.
in contrast black box models such as neural networks and ensemble trees are more likely to overfit and make less accurate predictions for unseen data.
for iterative learning methods bo is slightly percentage points better than gilandgil because black box models generally have higher prediction accuracy than linear models.
overall iterative learning methods are better than non iterative ones because they encourage extrapolation in the iterative process.
these results demonstrate that gil andgil s iterative learning can provide performance comparable to the best black box methods and overcome faulty or extremely low performance configurations.
.
rq2 how good are gilandgil at extrapolating from configurations of modest performance to high performance?
we examine the extrapolation results from configurations of modest performance to high performance in mod2high setting.
figure and show the relative performance rp for each method on three target hardware platforms respectively.
in each figure the strip label on the right for each row of bar charts represents the hardware platform where the starting configurations are from.
the x axis represents each workload and the y axis represents rp for the target hardware.
lower is better closer to optimal .
the last column harmean shows the harmonic mean results over all workloads which are also quantified in table .
table harmonic mean results over all workloads of each hardware for mod2high .
the last column harmean is the harmonic mean over three hardware.
skylake haswell storage harmean default rs nn dac bo gil gil the results analyzed in the low2high setting almost hold for the mod2high setting.
rs is better than nn and dac and bo is almost comparable to gilandgil .
overall bo gilandgil are better than rs nn and dac due to their iterative learning paradigm.
these results demonstrate that gilandgil are comparable to the best black box learners.
different from prior methods gilandgil can benefit from starting from user suggested configurations which is evidence that incorporating human knowledge is beneficial it gets gilandgil on par with the best black box learner.
.
rq3 does incorporating prior knowledge improve extrapolation performance compared to starting from scratch?
as further evidence of the benefits of extrapolating from prior knowledge we compare starting from scratch with random sampling to incorporating prior knowledge for initial training.
figure shows the aggregated improvements from incorporating prior knowledge over starting with random sampling across all workloads in the mod2high setting higher is better .
overall all learners benefit from incorporating prior knowledge with improvements from to in harmonic mean where gilandgil both have improvement.
starting from scratch achieves lower performance because random sampling over the whole space loses initial direction for extrapolation while a tighter cluster of samples provides a clearer direction to pursue next and reduces the chance of getting stuck in local optima.
these results demonstrate the efficacy of gil andgil by incorporating prior knowledge for initial training.
735generalizable and interpretable learning for configuration extrapolation esec fse august athens greece skylakehaswellstorageals bayes kmeans linear lr nweight pagerank rf terasort wordcount harmean0255075 workloadsrp default rs nn dac bo gil gil figure relative performance rp of each method in low2high setting for different hardware lower is better .
haswellstorageals bayes kmeans linear lr nweight pagerank rf terasort wordcount harmean020406080 workloadsskylake rp default rs nn dac bo gil gil figure relative performance rp of each method in mod2high setting when skylake is the target hardware lower is better .
skylakestorageals bayes kmeans linear lr nweight pagerank rf terasort wordcount harmean020406080 workloadshaswell rp default rs nn dac bo gil gil figure relative performance rp of each method in mod2high setting when haswell is the target hardware lower is better .
skylakehaswellals bayes kmeans linear lr nweight pagerank rf terasort wordcount harmean0204060 workloadsstorage rp default rs nn dac bo gil gil figure relative performance rp of each method in mod2high setting when storage is the target hardware lower is better .
.
rq4 what can we interpret from visualization in case studies?
to demonstrate the scope of our visualization tools for interpretation we use two case studies in different applications cause interpretation and deployment prediction.
.
.
cause interpretation.
we examine the gil s ability to interpret the causes for low performance by visualizing the coefficients of the learned relationships mapping from low level system metrics to performance and mapping from application configurations to low level system metrics.
figure shows two workloads running on skylake and how their coefficients change from low performance 736esec fse august athens greece yi ding ahsan pervaiz michael carbin and henry hoffmann haswell skylake storage harmean workloadsimprovement rs nn dac bo gil gil figure improvements from incorporating prior knowledge over starting with random sampling higher is better .
to high performance.
the common thing observed in two radar charts is that both workloads need higher bmr and cmr for higher performance.
this is counter intuitive because higher bmr and cmr conventionally lead to lower performance.
to interpret the radar charts correctly we need to read every axis together.
it is not that increasing bmr and cmr increases performance rather increasing bmr and cmr together while reducing csr is key to achieving better performance.
figure shows the corresponding bar charts for the absolute learned coefficient differences from application configuration parameters on each low level system metric.
we can see that the ways to get similar system level metrics changes are different for different workloads via different application level configuration parameter changes.
for linear the influence magnitudes of bmr and cmr from configuration parameters do not change much.
forlr the largest influence changes of bmr and cmr are from spark.memory.fraction .these results demonstrate gil s ability to interpret causes for low performance by discovering the relationships between application configurations low level system metrics and performance.
bmr cmr ipc csrpfr .
.
.
.
.0before after a linear bmr cmr ipc csrpfr .
.
.
.
.
.0before after b lr figure visualizing learned relationships between lowlevel systems metrics and performance.
the value on each axis shows how the corresponding low level system metric influences performance when moving from low performance before to high performance after on skylake.
.
.
deployment prediction.
we show that the learned coefficients of the model mapping from low level system metrics to performance can predict the deployment benefits across hardware.
figure shows two radar charts where for each workload configurations running fast on haswell and their performance on storage are used for initial training to obtain the before coefficients.
these coefficients represent how fast configurations found on haswell behave when they are on storage.
then we apply gil to iteratively .
.
.
.
.
linear coefficient differencesbmrcmripccsrpfrspark.speculation.quantile spark.executor.memory spark.broadcast.blocksize spark.shuffle.spill.compress spark.driver.memory spark.broadcast.compress spark.shuffle.file.buffer spark.speculation.interval spark.task.maxfailures spark.kryoserializer.buffer.max spark.kryoserializer.buffer spark.locality.wait spark.network.timeout spark.memory.fraction spark.speculation.multiplier spark.memory.storagefraction spark.reducer.maxsizeinflight spark.shuffle.compress spark.shuffle.sort.bypassmergethreshold spark.io.compression.snappy.blocksize a linear linear coefficient differencesbmrcmripccsrpfrspark.memory.storagefraction spark.executor.memory spark.broadcast.compress spark.kryoserializer.buffer.max spark.driver.memory spark.shuffle.sort.bypassmergethreshold spark.io.compression.snappy.blocksize spark.shuffle.file.buffer spark.broadcast.blocksize spark.shuffle.compress spark.speculation.quantile spark.shuffle.spill.compress spark.task.maxfailures spark.kryoserializer.buffer spark.speculation.multiplier spark.network.timeout spark.locality.wait spark.speculation.interval spark.memory.fraction b lr figure visualizing learned relationships between lowlevel system metrics and application level configurations.
the magnitude of each bar shows how much the corresponding application level configuration parameter changes each low level system metric when moving from low performance to high performance with larger bars indicating larger effects .
this enable users to relate the large effects from application level configurations to the effects each low level system metric has on performance in figure .
extrapolate the configurations that can run fast on storage until the sample budget is met.
the after coefficients represent how the best configurations found on storage behave.
figure 12a and 12b show that the two workloads alsandkmeans both have sharp spikes away from csr meaning that they both benefit from decreased influence from csr.
thus we predict that both workloads have same best hardware deployment.
this prediction is validated by the true data that the hardware choice for the best performance of both workloads is storage over haswell.
this also tells users that there is no need to tune both workloads separately on both hardware to find which hardware will be a better deployment because it is likely that they will have the same best hardware deployment due to their similar low level system 737generalizable and interpretable learning for configuration extrapolation esec fse august athens greece bmr cmr ipc csrpfr .
.
.
.
.0before after a als bmr cmr ipc csrpfr .
.
.
.
.0before after b kmeans figure visualizing learned relationships between lowlevel systems metrics and performance.
the value on each axis shows how the corresponding low level system metric influences performance when moving from haswell before to storage after .
behavior.
these results show that our interpretation tool enables the users to interact with the learners and acquire the knowledge that generalizes across different hardware workloads.
related work ml for configuration management.
ml techniques confront the complexity of software configuration management .
ml is generally incorporated into configuration tuning via performance modeling i.e.
the process of learning a function mapping application level configuration parameters to quantifiable behavior e.g.
latency throughput energy consumption .
for instance conex uses evolutionary markov chain monte carlo sampling to find high performance configurations for big data systems .
ottertune uses gaussian processes to tune database configurations .
opentuner uses an ensemble of genetic algorithms to tune configuration parameters for computer programs .
more recently there has been a growing interest in tuning ml systems themselves using other black box optimization techniques .
transfer learning.
transfer learning is a common approach to incorporate prior knowledge which gains knowledge from one problem and applies it to a different but related problem .
for configurable software systems the knowledge can be transferred across different workloads and hardware environments to reduce data collection efforts .
for instance a cost aware transfer learning method uses gaussian process to transfer knowledge from simulators to real systems .
l2s uses active learning to select samples for knowledge transfer to a new domain .
beetle uses a discovery step to identify the most relevant source from multiple sources of data .
however these works are fundamentally different from our proposal in that they use black box models in which the knowledge transferred is not interpretable by users .
in contrast gilandgil not only incorporate prior knowledge to improve application performance but produce interpretable results to help expand that knowledge.
interpretability.
there has been an emerging line of work on interpreting software systems.
comprex proposes a white box performance model based on a data flow analysis which does notincorporate prior knowledge or use learning.
valov et al use linear models to transfer knowledge across different hardware environments but they directly use the model learned from the source on the target software applications and thus do not extrapolate to improve results.
our proposed methods use linear models to provide users an interpretation of the interactions between application level configurations low level system metrics and performance .
our proposed tools gilandgil combine the advantages of transfer learning and interpretability to improve configuration extrapolation results and give feedback to users.
conclusion this paper introduces two configuration extrapolation tools gil andgil that incorporate prior knowledge and produce interpretable results.
these tools also produce a graphical interpretation of how they arrived at the highest performance application configuration.
our results show that gilandgil achieve application performance comparable to the best black box learner and outperform those starting from scratch with random sampling for initial training which demonstrates the benefits of incorporating prior knowledge into the learning process.
additionally the graphical visualization tools enable users to interact with the learners and interpret relationships between application level configurations low level system metrics and performance.
we hope this work can inspire software engineering researchers to consider prior knowledge and model interpretability when applying machine learning techniques to performance modeling.