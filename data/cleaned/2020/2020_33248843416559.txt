hybrid deep neural networks to infer state models of black box systems mohammad jafar mashhadi university of calgary calgary canada mohammadjafar.mashha ucalgary.cahadi hemmati university of calgary calgary canada hadi.hemmati ucalgary.ca abstract inferring behavior model of a running software system is quite usefulforseveralautomatedsoftwareengineeringtasks suchasprogram comprehension anomaly detection and testing.
mostexisting dynamic model inference techniques are white box i.e.
they require source code to be instrumented to get run time traces.
however inmanysystems instrumentingtheentiresourcecode is not possible e.g.
when using black box third party libraries or mightbeverycostly.unfortunately mostblack boxtechniquesthat detect states over time are either univariate or make assumptions on the data distribution or have limited power for learning overa long period of past behavior.
to overcome the above issues in thispaper weproposeahybriddeepneuralnetworkthataccepts as input a set of time series one per input output signal of the system andappliesasetofconvolutionalandrecurrentlayersto learn the non linear correlations between signals and the patterns over time.
we have applied our approach on a real uav auto pilot solution from our industry partner with half a million lines of c code.weran888randomrecentsystem leveltestcasesandinferred states over time.
our comparison with several traditional time serieschangepointdetectiontechniquesshowedthatourapproachimprovestheirperformancebyupto102 intermsoffindingstatechangepoints measuredbyf1score.wealsoshowedthatourstateclassificationalgorithmprovidesonaverage90.
f1score which improves traditional classification algorithms by up to .
ccs concepts computingmethodologies neuralnetworks software anditsengineering softwarereverseengineering requirements analysis.
keywords recurrent neural network convolutional neural network deep learning specificationmining black boxmodelinference time series acm reference format mohammad jafar mashhadi and hadi hemmati.
.
hybrid deep neural networks to infer state models of black box systems.
in 35th ieee acm permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation onthe firstpage.copyrights forcomponentsof thisworkowned byothersthan the author s mustbehonored.abstractingwithcreditispermitted.tocopyotherwise or republish topostonserversortoredistributetolists requirespriorspecificpermission and or a fee.
request permissions from permissions acm.org.
ase september21 virtual event australia copyright held by the owner author s .
publication rights licensed to acm.
acm isbn ... .
conference on automated software engineering ase september virtual event australia.
acm new york ny usa pages.
introduction automated specification mining or model inference is the process of automatically reverse engineering a model of an existing software system.
behavioral models e.g.
state machines are typically inferred from a running system by abstracting the execution traces.theinferredmodelsareusefulartifactsinmanyusecases where the actual behavior abstracted as the inferred model of the system is needed for analysis such as debugging testing anomalous behavior detection and requirements engineering .
inferring a behavior model of a system in a black box manner is particularly interesting.
in many real world applications the largescalesystemisbuiltbyintegratingmanyoff the shelflibrariesthat are only available as binaries no source code access .
thus from a system s pointof view knowing the exactbehavior of thesystem including all the interactions between black box units are needed for most run time analysis.
mostcurrentbehavioralmodelinferencetechniquesaredynamic analysismethods usuallyaremoreaccuratethanstaticanalysisfor run timebehaviorinference thatrequiresourcecodeinstrumentationtocollectexecutiontraces .thesemethodsareusually helpfulinunit levelanalysiswheretheinstrumentationisnotexpensive and access to the code is allowedfor the unit under study.
however in the system level thorough instrumentation is more expensive not limited to one unit and might not be even possi ble for some units black box libraries .
therefore for use cases such assystem level anomaly detection testing anddebugging a black boxbehaviormodelinferencethatworksonreadilyavailable input outputs of the system is crucial.
inthispaper weproposeadynamicanalysismethodtodetect the internal state and the state changes in a black box software system usingdeeplearning.
wecollectedthe numericalvalues of theinputsandoutputsofthesystem inregulartimeintervalsto create a multivariate time series.
a hybrid deep learning model includingconvolutionandrecurrentlayers wasthentrainedon these time series to predict the state of the system at each point intime.thedeeplearningmodelautomaticallyperformsfeature extractionmakingitwaymoreeffectiveandflexiblecomparedto traditional methods.in addition wedo not makeany assumption about statistical properties of the data which makes it applicable to a wide range of subjects.
we applied and evaluated this method on an auto pilot software autopilot used in an unmanned aerial vehicle uav system 35th ieee acm international conference on automated software engineering ase developed by our industry partner winnipeg based micropilot inc. micropilotistheworld leaderinprofessionaluavauto pilotwhich developsbothhardware andsoftwarefor1000 clients including nasa raytheon andnorthropgrumman in85 countriesduring thepast20 years.weevaluatedthemethodfromtwoperspectives howwellthemodelcandetectthepointintimewhenastatechangehappens?
rq1 changepointdetection cpd andhowaccurately itcanpredictwhichstatethesystemisin duringtheexecution?
rq2 stateclassification .inaddition inrq3 weexploredsome simplervariationsofourmethod non hybridvariations toroughly see how each part contributes to the overall model performance.
comparing our approach with state of the art alternatives the resultsshowthatourapproachperformsbetterinbothchangepointandstatedetection.weobserved88.
to102.
improvementinthef1scoreofourcpd comparedtotraditionalcpdtechniques.in addition we saw a .
to .
improvement in the f1 score of ourstatedetection comparedtotraditionalclassificationalgorithms on a sliding window over the data.
the contributions of this paper can be summarised as introducing the first to the best of our knowledge deeplearningarchitecturetoinferbehaviormodelsfromblackbox software systems.
empiricallyevaluatingthemodelandachievingveryhigh accuracycomparedtobaselinesusingareal worldandlargescale case study on a uav auto pilot system developed by our industry partner.
note that we have made all our source code models and executionscriptsavailableonline1 however due toconfidentiality we can not make our dataset public.
the rest of this paper is organized as follows in section we explain further how and in which contexts this research can be beneficial.theninsection3webrieflyexplainsomebackground material this work is based on.
in section we explain how ourproposed model is designed.
the way it was evaluated and the results are explained in section .
finally related work reviewed in section and some final remarks about the future work are made in section .
motivation black box components are ubiquitous in software development.
reusing high quality black box units generally offers a better overall system quality and a higher productivity .
the black box units can be as small as a reusable library or as large as a framework such as .net before going open source or a complete piece ofsoftwaresuchasaremotelyhostedwebservice.therearealso scenarios where the unit s source code is not black box in general but not accessible to a specific team that wishes to perform the dynamic analysis.
one particular interesting use case of system level black box analysis is inferring run time state model of a control software systems where inputs outputs are signals to from the system.
these inputs outputs are typically multivariate time series which are already logged in such systems no overhead for instrumentation .
the goal is automatically detecting the high level system state and its changes over time.
discussed in section we partnered with an auto pilot manufacturer and performed this study on their auto pilot software calledautopilotinthispaper .thegoalwastodeterminethestate of autopilot from its input output signals over time.
in this scenario theinputsarethesensorreadingsgoingintoautopilotand theoutputsarecommandsignalssenttocontrollermotorsofthe aircraft showingautopilot sreactiontoeachinputateachstate.a stateinthisexampleisthehigh levelstageofaflightandastate change happens when the current input values in the current state trigger a constraint in the implementation that changes the way the output signals are generated.
in this example the training set will consist of input and output values recorded during one execution of the system as a multivariate time series along with state ids as labels per time stamp.
one executionoftheautopilotwillbethewholeflightprocessthatmay go through a take off until a successful landing .
depending on theflightplan autopilotgoesthroughstatessuchas acceleration take off climbing turning descending etc.
during a flight the autopilot monitors changes in the input values and makes adjustments to its outputs in order to hold some invariants predefined rules .
for example if autopilot is in the holdaltitude mode itmonitorsthealtimeter sreadingsandwhen itgoesoutoftheacceptablerange proportionateadjustmentstothe throttle or the nose pitch will be made to get it back to the desired altitude.
this is basically how a typical feedback loop controller such as pid or its variations work .
when autopilot s state changes from hold altitude to descend to x ft state the set of invariantsthatautopilotistryingtoholdarechanged.itmeansits reactionstovariationsininputswillbedifferent.inthisexample a decreasing altimeter reading will not trigger an increase in the throttle anymore.
lookingatthetimeseries adomainexpertcanidentifywhatthe stateofautopilotis ateachpointintime thelabelingprocess.now the goal is to automate this task on a test set in practice future flights assuming a training set is labeled by the experts they only need to identify the state change time stamps during a flight .
thisproblemcan betackledintwoways.
thefirstsolution isto identify the time stamp that the state change happens i.e.
change point detection rq1 the more advanced solution is to predict the exactstate pertime stamp i.e.
stateclassification rq2 .the classic cpd techniques on time series are mainly applicable onunivariatedataorputassumptionsontheinput outputdistributions thus not applicable inour case with multivariate inputs and no assumptionsor knowledgeabout the states distribution.
the classicstateclassificationtechniquesintimeseriesarealsoweakin thattheyfailtobalancebetweenconsideringlong termrelations oracting locally.theonesthat useasliding window forexample donothavealong termmemory.theonesthatactonthewhole dataontheotherhandaretoocoarse grainedandinaccuratefor this task.
therefore themotivationforthisstudyistoprovideablack box techniquethat canbeapplicable onboth cpdandstate classificationproblems andovercomethelimitationsoftheexistingtech niques intermsofcapturingthenon linearcorrelationbetween multivariate inputs and outputs as well as learning patterns over a longperiodoftime.ourproposal whichwillbeexplainedindetail in section4 leveragesthe power ofa deep neuralnetwork dnn 300withtwotypesoflayersthatareparticularlyusefulforthisproblem a convolutionallayerswhichdiscoverlatentfeaturesfromthedata effectively through parameter sharing and b recurrent layers that play a significant role in problems dealing with time series as they can learn long term dependencies and seasonalities in the data.
though our motivational example as well as our case study are from the uav auto pilot domain our proposed method can be adapted to be applied to similar black box control software systems in domains such as iot intelligent video surveillance and self driving cars.
background unlikethenumeroustechniquesintheliteratureforbehaviormodel inference which abstract a set of execution traces intostates ourapproachrequiresconsumingamultivariatetimeseriesanddetectthestatechangesacrosstimeandpredicttheexact statelabels.thus inthissection webrieflyexplainthetwomain setsofrelevantexistingtechniquesfor changepointdetection and state prediction in time series that can serve as background for our approach.
.
change point detection a fundamental tool in time series data analysis is change point detection cpd .
it refers to the task of finding points of abruptchange in the underlying statistical model or its parameters that could be a result ofa state transition .
there are plenty ofcpd algorithms many of which perform effectively on a subset of cpd problems with some assumptions.
the assumptions can be of varioustypes.forexample onemayassumethetimeserieshasonly one input variable univariate there is only one changing point or the number of change points is known beforehand or they might assume some statistical properties on the data .thesearelimitingfactors sincemanyoftheseassumptions donotnecessarilyholdinourcase.cpdtechniquesarecategorized intotwomaingroups a onlinemethodsthatprocessthedatain real time and b offline methods that start processing the data after receiving all the values .
since our model inference use case of cpd can afford waiting to collect all historical training data we only considered offline techniques.
in general cpd algorithms consist of two major components a thesearchmethodandb thecostfunction .searchmethodsare either exact or approximate.
for instance pelt is the most efficient exact search method in the cpd literature which uses pruning .
approximate methods include window based bottom up binary segmentation and more.
in the window based segmentation a sliding window is rolled over the data and then sumofcostsofleftandrighthalf windowsissubtractedfromthe costofthewholewindow.whenthedifferencegetssignificantly highit meansthat thediscrepancy betweenleftand righthalf of thewindowishighandthereforeachangepointprobablyliesright inthemiddleofthewindow.inthebottom upmethod theinput signal is split into multiple smaller parts then using a similarity measureadjacentsegmentsaremergeduntilnomoremergesare feasible.thebinarysegmentationmethodfindsonechangepoint and splits the input into two parts around that point and then recursively applies the same method on each part.thecostfunctionsarealsoquitevarious fromsimplysubtracting each point from the mean to much more complex metrics such as auto regressive cost functions and kernel based cost functions.
kernel basedcostscanhaveawidevariety sincethekernelfunction canbealmost arbitrary howeverahandful ofthemsuchas linear and gaussian kernels are among the most popular ones .
in the context of our paper we need a cpd method with no assumptionondatadistribution numberofchangepoints etc.in addition ourcpdmethodshouldworkonmultivariatedata andbe abletocapturenon linearrelationsbetweensignals.italsoneeds to be resilient to time lags between an input signal change andits effect on the output signal and the systems state .
there is notraditionalcpdalgorithmsthatcoversalltheserequirements.
therefore we propose a novel cpd techniques that is based on hybriddnnsandcompareitwithseveralexistingcpdtechniques as our baselines which are explained in details in section .
.
convolutional and recurrent neural networks inbothourproblems cpdandstateclassification wecanseethatthechangesinsignalsaremoreinformativethantheirabsolutevalues.
therefore applying a derivation operation or more generally agradient seemslikenecessary atsomepointintheprocessing.
faridandsimoncellilistedsomediscretederivationkernelsintheirstudy buttohaveamoregeneralizedandmoreflexiblenotion ofdiscretederivatives convolutionsseemslikeabetterchoiceto apply.nowadays applyingconvolutionalfiltersonsignalsispretty much a standard process in signal processing studies that leverage deeplearning .convolutionalneuralnetworks cnns can learn to find features in a multidimensional input while being lesssensitivetotheexactlocationofthefeatureintheinput .
in the forward pass of a convolutional layer multiple filters are applied to the input.
it means that in a trained neural net multiple features can be leaned in one single convolutional layer.
recurrentneuralnetworks rnn haveshowngreatperformance in analysing sequential data such as machine translation timeseriesprediction andtime seriesclassification .
rnnscancapturelong termtemporaldependencieswhichisquite useful for solving our problem.
for example they might learn that climb state in a uav auto pilot usually follows take off .
therefore whileitisoutputting takeoff itanticipateswhatthe next state will probably be and as soon as its input features start shifting itdetectstheonsetofastatechange.itwillhelpthemodel to better predict the system s behavior and be quicker to detect statechangesinawaythatcouldhardlybeachievedwithclassic methods.therefore inthispaper wecombinethecnnsandrnns to create what is known as a hybrid deep neural network t o use forboth cpdand state classificationproblems in ourcontext.
hybrid neural network for state inference inthissection wedescribeourproposeddeeplearningapproach for the black box state inference task in details.
301softmaxconvolutional layers all signals fully connected layersseq2seq recurrent layers states over time black box system inputs outputs figure1 theinputandoutputsignalsoftheblack boxsystemarecapturedasamultivariatetimeseries theyareprocessedin adeepneuralnetworkthatconsistsof3sections convolutional recurrent anddense fullyconnected topredictthesystem sinternal state and its changes over time.
.
the model architecture the goal of this study is to infer the states of a running software system over time.
given that our assumption is we don t have accesstothesourcecode orpartofit weonlyleveragethevalues ofinputsandoutputsofthesystem overtime.ascanbeseenin figure we capture all the inputs and outputs of the system asa time series and then process it in a dnn.
the architecture of our proposed modelis a hybrid dnnwhich is inspired bymodels proposed inthe fieldof humanactivity recognition har .
this taskisquitesimilartothesubjectofourpaperinthesensethatthey both take in a multivariate time series data from sensor readings andoutputthestateofthesystemthatgeneratedthosereadings see section .
for more details on har papers .
this dnn is made of threepartsinsequence convolutional recurrent and3 fully connectedlayers.thisarchitectureaddressestheaforementioned traditionalmethods challenges eachpartservesadifferentpurpose in this process as follows.
convolutions beingmore generalizedthan simplesliding windows can discover patterns and features in the signals both in temporal and in spatial how signals affect each other dimensions .theconvolutionallayers flexibilityallowsthemtolearnsome typicalpreprocessingoperations.forexampleamovingaverageor a discrete derivative can be learned as simple convolutional filters.
theyalsohelpthemodeltobemoreresilienttovaryingtimedelays between noticing a deviation in input signals and the reaction that will appear in the output signals.
applying convolutional layers in sequence has been shown to result in each layer learning more complex features than the previous layers .
the number of layers filters and the kernel size are hyper parameters that should beselected based on the size of data and the complexity of the system beingmodeled.usingasequenceofconvolutionswitha increasing number of filters and the same kernel size b same number offiltersandincreasingkernelsize andc decreasingfilterswith increasing kernel sizesare all different approachesthat have been used in the literature by well known architectures such as vgg and u net .
we will discuss more details of our cnn layers in section .
.
convolutionsarequitepowerfulindiscoveringlocalfeatures.to capturelong termfeatures recurrentlayerswhichlearnsequences of data are leveraged.
for example in our case they can learn that accelerate and take off states only happen in the start of the statessequence andeach takeoff stateisusuallyfollowedbya climb state.
the type of recurrent cell to use lstm gru etc.
howmanycellstounravelinthelayer andthenumberoflayers are also hyper parameters that need to be tuned depending on the size and complexity of system under study.
finally one or more dense fully connected layers in the end areacommon wayofreducingthedimensions tomatchexpected outputdimensions.ifthereareonlytwostates thelastlayercan have a sigmoid activation function and be of shape l the length of theinput otherwise tomatchtheone hotencodingoflabels an outputofshape l nswithsoftmaxactivationalongthesecond axis ns is required nsbeing the number of possible states .
in termsof loss functionto optimize inthe training process a good choice is a dice overlap loss function which is used in image semanticsegmentationtasksaswell.animportantpropertyofthis loss function is not getting negatively affected by class imbalances .
.
data encoding theinput outputvaluesoftheblack boxsystemcreateamultivariatetime series tk whichcanbedefinedasasetof nunivariate timeseries vi ofthesamelength lk.eachvicorrespondstothe recorded values for one of the inputs or outputs of the system tk v1k v2k ... vnk v1k v2k ... vnk lk note that as figure shows we take both inputs and outputs as partofthetime seriesdatatobefedasinputintoourdeeplearning models.
this is to make sure we can model state based behavior of thesystem wherethecurrentstatedependsnotonlyontheinputs but also on the last state s captured as previous outputs of the system.
as an example from our case study if the outputs are not taken into account a mid flight descend state and the approach state right before landing are indistinguishable using the sensor readings inputs alone.
having such a time series the only remaining pieces from a training set arethe labels.
unlike the input output values the features in the data set the labels are not usually given.
our method to infer the labels is a supervised approach.
thus we need the domainexpert tomanually labeleachindividual timestamp witha state name id.
in practice what they would do is to identify the approximate time that a state change happens and assign the new statetooneofthepreviousstateslabelsordefineanewlabelfor this new state.
thus we encode the states information over time as 302a setof tuplesin theform of ts s wheretsdenotes thetimestamp wherethesystementeredstate s.weshowthesetofallpossible states with s s s and define nsas the cardinality of this set.
cpk braceleftbig ts1 s1 ts2 s2 ... tsl sl bracerightbig si s ns s so in summary the dataset consists of npairs of the i o values as features and their state information as labels braceleftbig x tk y cpk k n bracerightbig .
.
.
data preprocessing.
beforebeingfedintothemodel f as defined below the inputs and labels need some preprocessing.
f t m rl n rl sl.
torunmoreefficiently tensorflowexpectsallthe inputstohave the same length.
to do that the shorter tks should be zero padded tolengthl max lk .thepaddingfunction doesthat.therefore eventually theinputtothemodelwillbe tksthatarerearranged toformatensorofshape n lalongwithapaddingmask denoted withm .themasktellsthemodelwherethetailstartssothemodel can ignore all the zeros from there on.
o angbracketleft oi s angbracketrightl i f parenleftbig bracketleftbig v1 intercal v2 intercal... vn intercal bracketrightbig m parenrightbig m vec1l i.e.
angbracketleftmj angbracketrightl j angbracketleftmj angbracketrightl j l hereldenotes the length of the input before padding.
it is equal to lkfor thekth training data tk .
as defined in cpks are tuples of t s which indicate the system have gone into state sat timet.
to train the model cpk needstobeexpandedintoavectoroflength ldenotedby owhere each element otholds the state at time t. to define it formally the elements can be derived from cpkusing the following formula o angbracketleft t nl si tsi si cpk tsi max tsj tsj sj cpk tsj t angbracketright for example suppose l andcp a b c a theno angbracketleftaaabbcccaa angbracketright.
if there are more than two possible states ns oneeds to be one hot encoded at this stage.
.
the model implementation the first few layers of the model are convolutional layers.
we have used convolutional layers with filters each and a growing kernelsize.the intuitionbehindthis designis thatstarting witha small kernel guides the training in a way that the first layers learnsimplermorelocalfeaturesthatfitsintheirwindow kernel size .
kernel sizes started with since it is a common number inthe literature for kernel sizes then we used multiples of from5 to .
the rationale behind choosing is because the samplingfrequency is so each layer with a kernel size of nprocesses a wholensecondsworthofsimulationdata ineachstep.stoppingat kernelsizeof20wasacompromisebetweengeneralizabilityand modelsize.generally alargermodelhasmorelearningcapacity butitisalsomorepronetoover fitting.thecurrentmodelsarethe smallest we could make the models to avoid over fitting without compromising the performance.
same compromise was made in the second section of the model recurrentlayers thesweetspotforhyper parametersherewas to use two gru layers with cells each.
their output was fedintoafullyconnectedlayerwith128neuronswithaleakyrelu .
activationfunction andfinally toa denselayer with ns units with softmax activation.
we used adam optimizer thatcouldconvergein60 80epochs i.e.validationaccuracy plateaued.
the full architecture can be seen in figure .
empirical evaluation inthissection weexplainourempiricalevaluationoftheproposed approach through a case study.
.
the study objectives the goals of this study is to evaluate our proposed method in terms of change point detection and state inference in comparison to traditional techniques in this domain.
therefore our research questions are as follows .
.
rq how does our proposed technique perform in detect ing the state changes?
thegoalofthisrqistoseehowclosethe predicted state change times are to the real state change times.in other words in rq1 we do not predict the exact state labelsand are only interested in predicting the change.
to answer this question we comparethe performance of our proposedapproach withseveraltraditionalbaselines see5.
.
intermsofmodified precision recall and f1 scores that are introduced in section .
.
.
.
.
rq how well does our proposed technique predict the internal state of the system?
in rq1 we are only interested in detecting the time a state change happens binary classification but here in rq2 we extend that and are also interested in predicting the label ofthenewstatethatthesystemisgoinginto multi classclassification .
therefore to answer this rq we change the labels from a boolean changed not changed to the actual collected labels.
notethatforbothrqs inourempiricalstudy toevaluateour approach weusethesourcecodetocollecttheexacttimeastatechangehappensandtheactualstatelabels groundtruth .however in practice labeling the training set is supposed to be done by the domain expert in a black box manner.
this is not an infeasible task or extra overhead.
monitoring the logs and identifying the current systemstateisinfactpartofthedevelopers testersregularpracticeduringinspectionanddebugging.allweprovidehereisatoolthat given a partial labeling only on the training set automatically predictthestatelabelsandthestate changetimes forfutureflights.
also note that even though we use the source code to label the training set we still look at the test set as a black box and don t leak any information.
.
.
rq how much does the proposed model owe its performance to being a hybrid model?
theproposedmodelarchitecture inspired by the related work combines the power of convolutional andrecurrentlayers.ithasbeenshowninthosecontextsthatusing this combination is beneficial over using a fully convolutional architecture or a recurrent architecture without any help from convolutions.
to answer this question we trained two other models onewithouttheconvolutionalpartandonewithoutthegrulayers.
we compare these two with the proposed model.
303gru gru leaky relu softmaxconv1d conv1d conv1d conv1d conv1d seq2seq gru units fully connected layers figure2 modelarchitectureinanutshell.tandemconvolutionallayerswithincreasingkernelsizefedintotwosequence tosequencerecurrentlayerswith128grucellseach whichisthenfedintodenselayerstooutputthepredictedsystemstate as alistofone hotencodedstates.
owillbetheresultofapplyingargmaxoperationonthelastlayer soutput.
l ns .
evaluation metrics .
.
rq1 cpd performance metrics.
given that in rq1 there isaninherentclassimbalance therearefarmorepointswherea change has nothappened compared to points with a state change positive label we avoid using accuracy and report both precision andrecall.however theoriginalprecision recallmetricsrequire some modifications due to the difficulty of predicting the exact timestampthatastate changehappened.tohandlethis similarto related work we use a tolerancemargin .
if a detected statechange cpk is within of a true change cpk we call the predictionatruepositive otherwiseitisafalsepositive.similar adjustment to definition is applied for true negative and false negative.formallyspeaking wedefinepredictedchangepointsfor k th sample as cpk braceleftbig t ot ot nequal ot bracerightbig please note that in otrefers tot th element of output vector o as previously defined in .
based on that the confusion matrix elements are calculated as tp barex barex barex braceleftbig t s t cpk barex barex t s t cpks.t.
t t bracerightbig barex barex barex fp barex barex barex braceleftbig t s t cpk barex barex t s t cpks.t.
t t bracerightbig barex barex barex fn barex barex barex braceleftbig t s t cpk barex barex t s t cpks.t.
t t bracerightbig barex barex barex with these in mind we measure precision recall and their harmonicmeanf1scorewiththreevaluesfor and5seconds.
the smaller the tolerance is the stricter the definitions become and the lower the numbers are.
.
.
rq2 state detection metrics.
in rq2 we have a multi class classification problemand thusmultiple precisions recallswill be calculated one per class state label .
we then report the mean value across all classes.
ps braceleftbig st ok barex barex s t s bracerightbig ts braceleftbig st ok barex barexs t s bracerightbig tps braceleftbig st ps barex barex s t st ok bracerightbig precision nsns summationdisplay.
s tps ps recall nsns summationdisplay.
s tps ts .
.
rq3.
we used the same metrics as rq1 and rq2.
.
comparison baselines .
.
rq1 cpd baselines.
weused ruptures librarydeveloped byauthorsofarecentcpdsurveystudy .itprovidesamodular framework forapplying several cpd algorithmsto univariate and multivariate data.
as mentioned earlier two main elements of a cpd algorithm in their survey are the search method and the cost function.
we used pelt as the most efficient exact search method.
as examplesofapproximatesearchmethods weappliedbottom up segmentation and window based methods using a default window size of .
however after trying to run pelt algorithm we realizedthatittakesprohibitivelylongertoruncomparedtothe approximate methods without providing much better results so we only use the bottom up and the window based segmentation methods as our cpd baselines.
forthecostfunction wetried leastabsolutedeviation least squared deviation gaussian process change kernelized mean change linear model change rank based cost function and auto regressive model change as defined in the library.
their parameters were left as default.
to optimize the number of change points a penalty value linearly proportionate to the number of detected change points is added to the cost function which limits thenumberofdetectedchangepoints thehigherthepenaltythe fewerreportedchangepoints.wetriedthreedifferentratios and for the penalty.
.
.
rq2 multi class classification baselines.
weusedasliding windowofwidth woverthe10time seriesvaluesandthenflattened it to make a vector of size was the features.
for the labels we used one hot encoded state of the system.
the window sizes were chosen as same as the sizes of convolutional layers kernel sizes to make the baselines better comparable with our method.weusedscikit learn simplementationoftheclassification algorithms aridgeclassifier logisticregressionwithl2regularization andthreedecisiontrees.theridgeclassifierwasconfigured tousethebuilt incrossvalidation toautomaticallychosethebest regularization hyper parameter in the range of 6to .
each decision tree was regularized by setting maximum number of features and maximumdepth .for maximumnumberoffeatures we tried no limits 10w andlog210w.
to find best maximum depth we first tried having no upper bound and observed how deep the tree grows then we tried multiple numbers less than the maximum until a drop in performance was observed.
304table the n 10collected i os of autopilot.
the inputs are sensor readings and the outputs are the servo position update commands.
all these i os over time are used as theinputs of the state prediction model.
inputs pitch theanglethataircraft snosemakeswiththehorizon around lateral axis roll theangleofaircraft swingsmakewiththehorizon around longitudinal axis yaw the rotation angle of aircraft around the vertical axis altitude agl3altitude airspeed speedoftheair craft relative to the air outputs elevator control surfaces that control the pitchaileron control surfaces that control the rollrudder control surface that controls the yawthrottle controller of engine s power ranges from to 1flaps surfaces of back of the wings that provide extra lift at low speeds usually used during the landing .
.
rq3 hybrid vs. homogeneous baselines.
wecomparedtwo versions of the model one fully convolutional and one fully recurrent withthefullhybridmodeltoseeifcombiningrnnsand cnns has an added value or the same results could be achieved using only one type of layers.
.
dataset and the data collection process we ran existing test cases from micropilot s test repository using a software simulator2and collected the logged flight data over time.
the test cases are system level tests.
each test caseincludes a flight scenario for various supported aircraft.
a flight scenariogoesthroughdifferentphasesinaflightsuchas takeoff climb cruise hittingwaypoints and landing .wesampled input and output values listed in table at hz rate which isthe rate that autopilot reads the sensor values and performs the calculations required to update its output values at.
out of the flight logs we omitted that were either too short or too long shorter than samples or longer than 20k samples .
figure showsthedistributionoftheremainingloglengths.themaximum length l was samples.
the dataset was randomly split into three chunks of and for training validation and testing where each sample corresponds to one test execution.
note that separate test and validationsetsareneededtofacilitateproperhyper parameterstuning without leaking information.
2it isdeveloped bymicropilot incand providesan accuratesimulation ofthe aerodynamic forces on the aircraft the physical environment irregularities e.g.
unexpected wind gusts and noises in sensor readings 3above ground level figure distribution of flight log lengths for the n logs outoftheoriginal948availablelogs whichwerekeptin the dataset l k .
experiment execution environment trainingandevaluationofthedeeplearningmodelwasdoneon a single node running ubuntu .
lts linux .
.
equipped withintelcore i7 9700cpu 32gigabytesof mainmemory and8 gigabytesofgpumemoryonanvidiageforcertx2080graphics card.
the code was implemented using keras on tensorflow .
.
thebaselinemodelscouldnotfitonthatmachine sotwonodes on compute canada s beluga cluster one with cpus and 75gib ofmemoryandonewith16cpusand64gibofmemory wereused to train and evaluate them.
.
results inthissection wepresenttheresultsoftheexperimentsandanswer the two research questions.
.
.
rq1 results cpd performance.
table shows the results of runningcpdalgorithmsforvariousconfigurations asdescribed in5.
.
.foreachsearchmethodandcostfunctionpaironlyone of the penalty values which resulted in the highest f1 scores for all values is reported.
the first observation from the results is that as values of increasesthescoresgetbetter.thiswasexpected sincelargervalues relax the constraints onwhich detected change pointsareconsidered asa true positive.
anotherobservation is thatthe bottom up segmentation consistently outperforms the window based segmentationmethod.wecanalsoseethatthelinearcostfunctionbeats all the other ones in terms of precision.
the gaussian cost func tion achieves much higher recall values costing it a huge loss in precision.itmeansthiscostfunctionresultsindetectingnumerouschangepointsspreadacrossthetimeaxis sothereisagoodchance of having at least one change point predicted close to each true changepoint hencethehighrecall butalsotherearealotoffalse positives which leads to a low precision.
measuring the same metrics on how our model performs on the test data shows better scores almost twice the f1 score of the bestperforming baseline see table .
please note that unlike machine learningalgorithms suchasours cpdalgorithmsdonothavea separate training and testing phases.
this fact works in their favor by using the entire dataset for prediction and not just the training set but still our model outperforms them.
305table2 changepointdetectionprecision recall andf1 scorecalculatedforthebaselinemethodsusingthreevaluesoftolerance for multiple configurations.
cost function search method penalty prec.
recall f1 prec.
recall f1 prec.
recall f1 1s 3s 5s autoregressive modelbottom up .
.
.
.
.
.
.
.
.
window based .
.
.
.
.
.
.
.
.
least absolute deviationbottom up .
.
.
.
.
.
.
.
.
window based .
.
.
.
.
.
.
.
.
least squared deviationbottom up .
.
.
.
.
.
.
.
.
window based .
.
.
.
.
.
.
.
.
linear model changebottom up .
.
.
.
.
.
.
.
.
window based .
.
.
.
.
.
.
.
.
gaussian process changebottom up .
.
.
.
.
.
.
.
.
window based .
.
.
.
.
.
.
.
.
rank based cost functionbottom up .
.
.
.
.
.
.
.
.
window based .
.
.
.
.
.
.
.
.
kernelized mean changebottom up .
.
.
.
.
.
.
.
.
window based .
.
.
.
.
.
.
.
.
table change point detection precision recall and f1score calculated on the test data for our proposed model usingthreevaluesoftolerance comparedwiththerespective s best f1 score among baseline methods prec.
recall f1 score baselinef1 1s .
.
.
.
3s .
.
.
.
5s .
.
.
.
in terms of execution cost running all different settings of cpdalgorithmsonthewholedatasettookabitover12hoursinthecloudusing16cpusand64gbofmainmemory.thedeeplearning model on the other hand takes about an hour to train which only needstobe doneonce on asmallermachine seesection5.
.
it made predictions on the whole dataset in less than a minute.
so to answerrq1 ourmethodhasshown .
.
.
improvementinf1scorewith 1s .
.
.
with 3s and .
.
.
with 5s almost doubling the score compared to the baselines.
our model which requires less memory compared to traditionalcpdalgorithms improvedtheirbestperformance by up to measured by f1 score in less execution time.
.
.
rq2 results multi class classification performance.
toanswer rq2 we first compare different configurations of the baselinemethodsusingthef1score harmonicmeanofprecisionandrecall on the test data.
the results are presented in table .
comparing the baseline methods with our proposed method the last row in table shows that our model outperforms all baselines.
comparing it with the model with the best f1 scoretable precision recall and f1 score of ridge classifiers linear classifiers with l2 regularization and decision tree classifiers dt withdifferentslidingwindowwidths w .for eachalgorithmoneach wseveralhyper parameterswereapplied producing different models.
in this table we onlyshowtheresultsofthebestperformingmodelineachgroup.
wclassifiermax depthmax featuresprec.
recall f1 3ridge .
.
.
dt .
.
.
5ridge .
.
.
dt .
.
.
10ridge .
.
.
dt .
.
.
15ridge .
.
.
dt 10w69.
.
.
20ridge .
.
.
dt 10w73.
.
.
ourproposed method .
.
.
shows a .
.
.
improvement in precision as well as a .
.
.
improvement in recall that means .
.
.
overallimprovementinf1 score.
to have a feeling of how good our predictions are in practice figure4showstheoutputofourmodelsidebysidewiththegroundtruth.thehorizontalaxisshowssampleid time andthestatesare color coded.
as it is seen our algorithm performs better when the state changes are farther apart.
also there are some state changes that happen quite briefly which are not detected.
that is not toa great surprise since it takes some time for state changes to be reflected in the outputs and those might not have got any chance.
306the classical models only see one window of the data at a time convolutionallayersontheotherhandaremoregeneralizedand flexible since each filter in each layer is comparable to a sliding window.aswesawintable4 alargerwindowsizemeansahigher performance.however itgetssignificantlymoredifficulttotrain a model with large window sizes.
in addition convolutions can automatically learn preprocessing steps that could be beneficialsuch as a moving average.
each convolutional filter can learn a linear combination of its inputs.
so when the convolutional layers are stacked oneach other withnon linearactivation functionsin between the hypothesis space they can learn becomes quite large probablymuchlargerthanmostoftheclassicalmlalgorithmshere.
also theyarestillquiteefficient moreefficientthanbaselines due to parameter sharing and their high parallelizability.
thefactthattheperformanceimprovesasthewindowsizeincreasesindicatesthepositiveeffectofbeingabletoseelonger term relations in detecting the system s state.
recurrent cells such as gru can capture long term dependencies that do not necessarily fallintoonewindow andlearnsequences.thisisoneofthemajor differences between an rnn model and others such as decision trees whichdonothavesuchanotionofa long termmemory as lstm gru neural networks do.
all a decision tree could see is the values in a sliding window.
in terms of the training complexity time and memory our methodissuperioraswell.thatcanlargelybeattributedtotheuse ofdeeplearning.inbaselinemodels asthewindowsize wgrows the training and evaluation complexity grows up to a point that theyranoutofmemory consumingallthe47gbofmainmemoryandswaparea.thisforcedustotraintheminthecloud.meanwhile as mentionedearlier the deep learningmodel could betrained on a8gbgpuinroughlyanhour.
seesection5.5forthemachines specs .also thedecisiontreetrainingwasnotparallelizedusing only one core of the cpu while virtually all deep learning models can be heavily parallelized on a gpu tpu.
our model which requires less than half as many cpus and70 asmuchmemorycomparedtothebestperforming classicalmlmodel improvedtheirbestperformanceby up to measured by f1 score in less execution time.
.
.
rq3 results hybrid vs. homogeneous model.
astheresultsin table5suggest usingahybridarchitectureinthisproblemdelivers more thansum of its parts outperforming the fullyconvolutional andfullyrecurrentbaselines.wecanalsoseehowthernnbaselinegotcloserresultstothefullmodel suggestingtheimportantroleitplays in capturing long term relations in the data and inferring the system s internal state.
you might also notice that the results in the last column differ a little around1 inabsolutevalue fromtheircorrespondingresultsintables4and3.thatisduetorandomizationsinsplittingthedata into training testing and validation sets.table5 comparingthehybridmodel sperformanceinboth regards with the the its homogeneous sub models.
rnn only cnn only full model precision 1s .
.
.
recall 1s .
.
.
f1 1s .
.
.
precision 3s .
.
.
recall 3s .
.
.
f1 3s .
.
.
precision 5s .
.
.
recall 5s .
.
.
f1 5s .
.
.
classification prec.
.
.
.
classification recall .
.
.
classification f1 .
.
.
thehybridarchitectureperformsbetterthanacomparable rnn model or fully convolutional model however the recurrentsectionplaysamoreimportantroleinthemodel s performance.
.
limitations and threats to validity one of the limitations of our approach is that it might miss an input outputinvariantcorrelation.itcanhappenwhentheinput remainsconstant oritchanges toolittletoreveal itsrelationwith certainoutputs thereforeremainingunobserved.howeverthisisa sharedshortcomingofdynamicanalysisapproaches.weassume that during the data collection sampling happens in regular intervals ourapproachprobablywillhaveahardtimeachievinghigh performances working on unevenly spaced time series data.
interms ofconstructvalidity weareusing standardmetricsto evaluatetheresults.however theuseoftolerancemarginshould be taken with caution since it is a domain dependant variable and can change the final results.
to alleviate this threats we have used multiplemarginsandreportedallresults.intermsofinternalvalidity threats we reduced the threat by not implementing the cpd baselinesbyourselvesandratherreusingexistinglibraries.interms of conclusion validity threats we have used many real test casesfrommicropilot stestrepositoryandprovidedapropertrainvalidation test split for training tuning and evaluation.
finally intermsofexternalvaliditythreats ourstudysuffersfrombeing limited to only one case study.
however the study is a large scale real worldstudywithmanytestcases.weplantoextendthiswork with more case studies from other domains to increase its generalizability.
307figure evaluation of the model on random test data.
each graph shows the states in one run of the system.
the colors show the states.
the top half of each plot depicts model s prediction of the system states o and the bottom half shows the true labels o .
since the output is one hot encoded the item with the most probability is used as the predicted label at each point in time.
x axis is the time axis.
only the first samples minute of simulation are shown to improve legibility.
related work .
time series change point detection change point detection is a well studied subject due to its wide rangeof applications .several statisticalandalgorithmic methods have been tried to tackle several variations of this problem .
the models vary based on whether the whole data is available at once offline or itisbeinggeneratedonthego online whethertherearestatisticalassumptionsaboutthedatadistribution whetherthe number of change points is known or whether we are dealing with a univariate or a multivariate time series etc.
ives and dakos utilized locally linear models and used statistical significance test to determine at which point the changes in model parameters are large enough to signal a change in the state .
blythe et al.
used subspace analysis to reduce data dimensionality to keep the most non stationary dimensions.
this process helps detectingchangepointsmoreeffectively .severaltechniques haveusedpenaltyfunctionstofindmodelsthatbestfiteachsegmentofthesignal .desobryetal.
andhidoetal.
proposedmethodstoindirectlyuseclassifierssuchassvmtodetect changepoints .weappliedtheirapproachonourdata in early stages of the research but it could not perform as others.lee et al.
trained deep auto encoder networks that learns latent features in the data to detect change points .
ebrahimzadeh et al.
proposed what they call a pyramid recurrent neural networkarchitecture which is resilient to missing to detect patterns that are warped in time .
therearealsoafamilyofmethodsbasedonbayesianmodelsthat focus on finding changes in parameters of underlying distributions of the data .
makingassumptionsaboutthedatasuchasitsdistributionorthe distributionofchangepointsacrossthetimeandrelyingonbasic statisticalpropertiesarethetwomajorshortcomingsoftraditional cpd methods which our proposed approach has overcome.
.
state model inference roughly speaking dynamic efsm4inference algorithms generally takeatraceof events alongwithperhapssomevariablevalues astheirinput toinferageneralizedfinitestatemachine.theyuse the events to find the state transitions and the values for detecting invariantsandgeneratingtheguardconditionsonthetransitions.
ktails gktail edsm andmintareexamplesofthesealgorithms each improving upon the previous one .
walkinshawet al.
proposed analgorithmand developeda tool for state model inference .
their work is based on previous endeavorsonstatemergingalgorithmssuchasgk tailandk tails .
these methods require an execution trace of the program 4extendedfinitestatemachines arespecialkindofstatemachinesthathaveconditionalexpressionscalled transitionguards ontheirtransitions .astatetransition can only happen if the transition guard evaluates as true.
308consistingofalistof events thatoccurredduringprogramexecution such as function calls system calls transmitted network data etc.krkaetal.
performedanempiricalstudyon4different categories of model inference algorithms to figure out what makes each group of methods more effective .
beschastnikh et al.
proposeda methodto mineinvariantsfrom partiallyorderedlogs fromconcurrent distributedsystems .invariantscanbeused to augment state models .
groz et al.
use machine learningtoheuristicallyinferstatemachinemodelsofaun resettableblack box system however a significant difference between ourmethodandtheirsisthattheirmethodstillreliesondiscrete events such as http request and responses while our methoddoes not assume that the input and outputs contain any kind of events happeningatcertain times.ourmethod aimstosearch for sucheventsaschangepointsinacontinuousstreamofdataastime series.
.
using deep learning on time series data human activity recognition har is a well researched task which is quite relevant to the problem of black box model inference.
inhar just like in our context a multivariate time series data is createdfromvarioussensorsonahumanbody.thegoalistofigure our what was the activity that human was performing in different time intervals.
the sensors can be body worn accelerometers or more generic sensors such as the ones found in a smart watch or a smartphone.
murad et al.
have shown deep rnns outperform fullyconvolutionalnetworksanddeepbeliefnetworksinhartask.hybridmodelsarethecombinationofsomedeeparchitectures suchasacnn rnnoracnn afullyconnectednet.morales et al.
have shown the former preforms better than the latter inhar .
yao et al.
introduced a cnn rnn architecture that outperforms the state of the art both in classification and in regressiontasks.similarresultshavebeenshowninotherworks such as as well.
another related topic here is the time series classification.
however time series classification techniques often output only onelabel classifying entire data thus not applicable in our context.
whatismorerelatedtoourproblemiscalled segmentation using the computer vision terminology not be confused with timeseries segmentation such as .
u net is one of the promising auto encoder architectures for image segmentation .
perslev et al.
developed a similar idea for time series to capture long term dependenciesandcalleditu time .itisfullyconvolutionaland doesnotusememorycells recurrentcells .afullyconvolutional model can perform very well since convolutions operate locally and image segments are large chunks of pixels in the 2d space and capturinglocalfeaturesusingneighbouringpixelsisquiteuseful.
however it cannot necessarily be as powerful on a more limited 1d data of time series with different characteristics from an image.
thisstudy sdesignisoptimizedforthetaskofsleepphasedetection whichdoesnothaveveryclearboundariesbetweenstatesand alsothestatechangesarenotveryfrequent.therefore thesame methoddoesnotnecessarilygeneralizetotaskssuchasours where we cannot make assumptions about frequency of state changes.
summary and future work in this paper we introduced a hybrid cnn rnn model that can be usedfor bothcpdandstate classificationproblemsinmultivariatetimeseries.theproposedapproachcanbeusedasablack boxstatemodel inference for variety of use cases such as testing debugging andanomalydetectionincontrolsoftwaresystems wherethereare several input signals that control output states.
we have evaluated our approach on a case study of a uav auto pilot software fromour industry partner with test cases and showed significant improvementinbothchangepointdetectionandstateclassification.
in the future we are planning to extend this research with more casestudiesfromopensourceauto pilots.inaddition bettertuning of hyper parameters will be explored.
finally we plan to examine the use of transfer learning to reduce the labeling overhead.