jigsaw large language models meet program synthesis naman jain t namanjain microsoft.com microsoft research bangalore indiaskanda vaidyanath svaidyan stanford.edu stanford university stanford usaarun iyer ariy microsoft.com microsoft research bangalore indianagarajan natarajan nagarajn microsoft.com microsoft research bangalore india suresh parthasarathy supartha microsoft.com microsoft research bangalore indiasriram rajamani sriram microsoft.com microsoft research bangalore indiarahul sharma rahsha microsoft.com microsoft research bangalore india abstract large pre trained language models such as gpt codex and google s language model are now capable of generating code from natural language specifications of programmer intent.
we view these developments with a mixture of optimism and caution.ontheoptimisticside suchlargelanguagemodelshavethe potential to improve productivity by providing an automated ai pair programmer forevery programmer in the world.on the cautionary side since these large language models do not understand programsemantics theyoffernoguaranteesaboutqualityofthe suggested code.
in this paper we present an approach to augment theselargelanguagemodelswithpost processingstepsbasedon program analysis and synthesis techniques that understand the syntaxandsemanticsofprograms.further weshowthatsuchtechniques can make use of user feedback and improve with usage.
we presentourexperiencesfrombuildingandevaluatingsuchatool jigsaw targeted at synthesizing code for using python pandas api using multi modal inputs.
our experience suggests that as these large language models evolve for synthesizing code from intent jigsawhas an important role to play in improving the accuracy of the systems.
acm reference format namanjain skandavaidyanath aruniyer nagarajannatarajan suresh parthasarathy sriram rajamani and rahul sharma.
.
jigsaw large language models meet program synthesis.
in 44th international conference on software engineering icse may pittsburgh pa usa.
acm newyork ny usa 13pages.
introduction pre trained large language models ptlm such as gpt a r e finding pervasive applications in natural language processing nlp as a general purpose platform to solve many nlp tasks.
recent efforts show that ptlms can generate code from natural work done by author during internship at microsoft research india permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation on the first page.
copyrights for components of this work owned by others than acmmustbehonored.abstractingwithcreditispermitted.tocopyotherwise orrepublish topostonserversortoredistributetolists requirespriorspecificpermissionand ora fee.
request permissions from permissions acm.org.
icse may pittsburgh pa usa association for computing machinery.
acm isbn ... .
figure multi modal problem specification in jigsaw language prompts by associating documentation text with code from alarge training set .
thispresents a newavenue for program synthesis.
however ptlms do not understand either thesyntaxorsemanticsofthecode andtreatcodeastext .consequently the code produced by such models has no guarantees of correctness or quality.
hence any system that uses such ptlmst o generatecodewillneedtoaugmentitwithprogramanalysisand program synthesis modules to ensure correctness.
in this paper we present the design and empirical evaluation of such a multimodalprogram synthesissystem called jigsaw which istargeted specifically at synthesizing code for using large and complex apis.
jigsawis multi modal as depicted in figure in the sense that itcaningestinputas anaturallanguagestringexpressingintent and a set of test cases or input output examples and produces acodesnippetasoutput.futureincarnationsmaybedesignedto acceptothermodesofinputaswell.thearchitectureof jigsawis showninfigure2.thepre processingmoduleconvertsthenatural language intent into a customized query to send to the ptlm.
the post processingmoduleperformssyntacticandsemanticchecks and performs transformations on the code produced by the ptlm ensuring that the code passes the supplied test cases and otherquality checks.
the transformations are specifically designed tocorrect common and recurring errors made by ptlms such as referencingerrors wherethecodereferencesvariablenamesincorrectly argumenterrors wherethecodeinvokesthecorrectapi butwithincorrectarguments andaclassofsemanticerrors which ieee acm 44th international conference on software engineering icse authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
icse may pittsburgh pa usa naman jain skanda vaidyanath arun iyer nagarajan natarajan suresh parthasarathy sriram rajamani and rahul sharma can be corrected by learning ast to ast transformations .
section2showsconcreteexamplesofsucherrors andsection3shows how the transformations correct such errors.
jigsawlearns from usage by incorporating user feedback into both pre processing and post processing modules and learns from user engagements to improveitsoverallquality.ourexperimentsshowhowjigsawis able to learn from past usage to improve future performance.
the current version of jigsawis designed and evaluated to synthesizecodeforthepythonpandasapi .however theprinciples behind the design of jigsaware general and the design can be extended to other libraries and programming languages as well.
we create a user interface for jigsawusing a jupyter notebook extension.theextension canbeinvokedusing amagiccommand andinvocationofthecommandcreatesasidebarwindowwitha jigsawcard for each invocation.
the jigsawcard allows users to supply andedit inputsto thesystem inspectthe resultsand copy the desired output back into the main notebook window.
weevaluate jigsawintermsoftheoverallaccuracy aswellasaccuracyofthecomponentsofthepre processingandpost processing modules on two datasets we created pandaseval1 created by the authorsofthispaper and pandaseval2 createdby25usersduringa hackathon whereparticipantsweregivenpointsforsolvingpython pandas tasks using jigsaw.
the hackathon was conducted across two sessions details in section .
we used user feedback from the first session to improve the pre pro cessing and post processing modules of jigsaw and found users were about to solve about more tasks in the second session due to learning improvements from the first session.
in section we instantiate jigsawwith two state of the art ptlms gpt andcodex and present comprehensive evaluations.
we show the ov erall improved p erformance of jigsaw compared to baselines and state of the art code synthesis frameworks on the two datasets as well as gains due to learning from user feedback over time.
in summary this paper makes the following contributions we present an architecture to perform code synthesis by augmenting black box ptlms with program analysis and synthesis basedtechniquesandmulti modalspecifications.
wehaveimplementedthearchitectureinatoolcalled jigsaw.
wehavedevelopedajupyternotebookextensionthatallows users to interact with the system seamlessly.
we characterize common classes of errors made by ptlms namely reference errors argumenterrors andsemantic errors.
motivated by these errors we have designed program analysis and synthesis techniques in jigsawto fix such errors in code produced by ptlms.
we have also designed techniques to learn from user feedback and improve with usage.
wehavecreatedtwopandasdatasetswithmulti modalspecifications released for community use .
using two stateof the art ptlms weshowthat jigsawyieldssignificantly higheraccuracy comparedto baselineson thetwo datasets.
ourhypothesisisthatevenas ptlmsforcodeimprove systems such asjigsawthat perform pre processing and post processing moduleswillbecrucialtoimproveuserexperience andenhancethequalityoftheoutputproduced.thisisbecause ptlmsinherentlydonotunderstandthesyntaxorsemanticsofcodetheygenerate sowe expect gaps to remain between ptlmoutput and user expectation.
tools based on program analysis and synthesis techniques that understand the code and api syntax and semantics can addressthesegapsbetterthangeneric ptlms.wediscusshowtodesign pre processing and post processing modules in a general manner so thatjigsawcan work for any language and any api.
jigsaw overview jigsawis amulti modal interactive code synthesis system where a theuserspecifiesintentviaacombinationofnaturallanguage descriptionandtestcases i.e.
input output i o examples and b theuserinteractswiththesystemviaafriendlyandseamless interfaceintegratedwiththeprogrammingenvironment.theinteractiveaspectof jigsawiscrucialfor thedevelopertorefinethe possiblyambiguousintentspecificationaswellasforthesystemto gather useful feedback for improving the components.
in this section we highlight some of the challenges in using general purpose ptlmsforspecificdomainswithexamplequeries whichdirectly motivates the design of our jigsawcode synthesis pipeline.
.1jigsawdesign principles wetreatlargelanguagemodelsasblack box i.e.
wecanonlyquery them.thisisareasonableassumptionsincethepremisethatthe expertiseandmeanstofine tunethemodelsisoutofreachformost users.
this design choice is motivated by three reasons a there is a natural barrier to access these large models and we can get only theoutputofthemodelforagiveninputviasomeinterface e.g.
rest apis b these large language models constantly evolve and get better with each generation treating them as blackboxes enables plug and play with minimal effort and c finally domain specificimprovementstolargelanguagemodels e.g.for pythonprogramming generalprogramming arerendered complementary to our efforts rather than competitive.
we configure jigsawwith aptlm gpt and codex in this work of choice to be used as a black box.
we focus on appropriatelysettinguporprimingthesemodelsforagiventaskathand characterizingcommonfailuremodesof ptlmsforcodesynthesis and building components that can overcome such recurring failures.
we rely on both program synthesis based techniques and multi modal specification to design these components.
our goal is toenablesynthesisofsyntacticallyandsemanticallycorrectcode snippets for a given domain and using feedback from usage to improve the system over time.
thepre processingmoduleof jigsawcontextualizestheinputto theblack boxlanguagemodelusingheuristictechniques akinto recentefforts .akeycontributionofoursystemisinits post processingmodule a s peedingupthecombinatorialsearch spaceofapifunctionsandtheirarguments and b learningand updatingasetoftransformationorre writerulestobeappliedtothe erroneous snippets output by ptlms.
the post processing module uses i o examples to choose the appropriate transformation.
in the rest of the paper we instantiate jigsawfor solving data transformationtaskswithpythonpandasapi whichiswidelyused by data scientists to process tabular data .
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
jigsaw large language models meet program synthesis icse may pittsburgh pa usa pre process inputsnatural language input output examples other specificationse.g.
assertions pre trained language model ptlmpost process outputscorrect program edited by users learning from user feedback figure architecture of jigsaw .2ptlms as black box consider a typical scenario where the user wants to load and ex amine the data in a csvfile.
pandas uses dataframe objects twodimensional tabular representation to store and process heterogeneousdata commonlynamedwith dfprefixesinthecode like df df1 df2 dfin .
the user invokes jigsawwith a simple natural language description of the intent in a cell of jupyter notebook jigsaw q load .
data.csv file the magiccommand jigsawinvokesthesynthesispipeline withthegivenquery.
jigsaw configuredwith gpt returnsthe following snippets for the above query df pd.read csv .
data.csv csv pd.read csv .
data.csv header none the user then issues the following query in the session jigsaw q remove substring name from column country of df jigsawproduces the following snippets.
df df .str.replace name akeyknobin ptlmsissettingtherightcontextforagivenuser query.thiscontextispassedasaninputtothe ptlminaddition to the user query.
to this end jigsawfirst prepares the input in thepre processing stage details in section .
.
the preparation involves assembling a set of relevant question answer pairs to informthe ptlmofthenatureoftheinputtask whichisconverting natural language text to python code specifically pandas code.
with the context selection in the pre processing stage jigsawproducesthedesiredcodesnippetsshownabove.incontrast thegpt modelwithout contextselection producesthe followingincorrect snippet for the above query df df.country.str.remove name recent studies both in the context of natural language understanding as well as in the programming domains have shown the influence and importance of context selection in the output of ptlms.
our work provides further evidence that context selection can significantly impact the quality of the code gener ated for pandas programming tasks with two different ptlms demonstrated in section .
.
.
learning to fix recurring failure modes ofptlms the core aspect of jigsawsystem design is incorporating a postprocessing phase that involves a characterizing b transforming the syntactically and or semantically erroneous code snippets and moreimportantly c endowingthesystemwiththecapabilitytoimprove intermsofaccuracy fromfeedbackasmoreusersinteractwithitovertime.below wehighlightcommonclassesoferrors weobserveovertwodifferentpandasprogrammingdatasets created by us and described in section using two different ptlms namely gpt and codex.
.
referencing errors we observe that even with suitable context ptlmscanproduceincorrectreferencingofvariablenames in otherwise accurate code snippets.
.incorrectarguments insomecases ptlmsproducecodewith the right composition of api functions but with incorrect arguments.
for instance consider the following invocation jigsaw q remove all duplicate entries of column inputb dfout df.drop duplicates subset ptlm dfout df.drop duplicates subset keep false correct .
semantic errors a recurring failure mode for the ptlmsw e have experimented with is that they produce code snippets that arealmostcorrect but the semantics are wrong because of a minor error.wecanquantifythisviasuitableeditdistancebetweenthe asts of the produced and the correct i.e.
intended code snippets.
for instance consider the following invocation jigsaw q get fourth value from column c in dfin and assign to dfout dfout dfin.ix ptlm dfout dfin.loc correct jigsawemploys a post processing phase that critically relies on the multi modal specification i o examples in particular toovercome the aforementioned recurring failures.
to this end we passtheincorrectoutputcodesnippetfrom ptlm whichcanbe ascertained with the help of i o examples in the specification through a series of components driven by pl based techniques details in section .
.
the two key ideas are outlined below.
usingtheapifunctionsintheincorrectcodesnippetsproducedbyptlm weseedtheenumerativesearchfortheright arguments.
we perform this search efficiently adapting the authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
icse may pittsburgh pa usa naman jain skanda vaidyanath arun iyer nagarajan natarajan suresh parthasarathy sriram rajamani and rahul sharma gpt3 gpt engine davinci temperature .
max tokens examples to train a english to french translator gpt3.add ex example what is your name?
quel est votre nom?
gpt3.add ex example what are you faites vois?
gpt3.add ex example how are you?
comment allex vous?
input to the model prompt3 where are you?
output3 gpt3.submit request prompt3 model output output3.choices.text output o tes vous?
figure english to french translation using gpt autopandas framework which is an enumerative search basedprogrammingbyexamplesframeworkbuiltforpandas api.
the user interface of jigsawenables getting feedback which is then used by our system to learn a set of ast to ast transformations using the prosesynthesis framework .thechallengehereliesinclusteringerrorsthatare alike so that a small set of general transformations can be learnt.
jigsaw architecture the architecture of jigsawis depicted in figure .
in this section we describe each module in detail.
.
pre trained language models we describe pre trained language models ptlms usinggpt as an example.
gpt 3stands for generative pre trained transformer which is the third version of a large transformer model developed by openai.
gpt 3is a neural model with billion parameters trainedonaverylargecorpusconsistingofpublicly availabledatasetssuchascommoncrawl1 webrtextdataset two internet basedbookscorpora andenglishwikipedia.
gpt 3isa general purposemodelthatcanbecustomizedtoperformavarietyofnlptasks.suchcustomizationsdonotinvolvefine tuning the ml model for the specific task at hand.
instead the user of gpt 3can describe the task using a few examples on the order of examples works usually and gpt 3is then able to produce answersforthespecifictask.asessionwith gpt 3hastheform q1 a1 q2 a2 ... qk ak q wherekisasmallnumber typically4or5 thepairs qi ai arequestion answerpairstodescribe thetaskwewant gpt 3toperform and qisthequestionforwhich we seek an answer.
for example if qi ai are such that qiare english statements andaiarecorrespondingfrenchtranslations then gpt 3becomes an english french language translator.
see session in figure .
otherrecent ptlmsincludecodex whichisopenai srecentlanguagemodeltrainedspecificallyoncode andgoogle slargelanguagemodel thesemodelstranslatenaturallanguagetoprogram.jigsawusesptlms to produce pandas code given a natural languagedescriptionofintent andtestcases.specifically jigsaw sessionwith gpt 3hastheform n1 p1 n2 p2 ... nk pk n whereniisenglishdescriptionofintent and piisthecodesnippet crawling of documentation pages context bank mean standard deviation normalization of dataframe dfcontext selectorn1 find the mean of datap1 data.mean n2 perform column wise oroperation in dfp2 df df.any mean standard deviation normalization of dataframe df ptlm figure illustration of pre processing step of jigsaw we want the ptlmto produce.
we currently do not pass inputoutputexamplestothe ptlm.instead weusethesetestcasesto check and filter the candidate codes produced by the ptlmduring post processing ortransformthecodeproducedbythe ptlmsuch that it passes the test cases.
.
pre processing thegoalof jigsaw spre processingmoduleistoconverttheuser intent into a suitable query for the ptlm.
as mentioned above ptlmstakeasequenceofquestion answerpairs n1 p1 n2 p2 ... nk pk asapreamblebeforewesupplythecurrentquery.we use the term contextto denote this preamble.
previous works in natural language processing nlp have shown that the performance of these ptlms is heavily influenced by this context and the performance improves if the question answer pairs in contextaresimilartothecurrentquery n.hence wemaintaina contextbank ofpossiblequestion answerpairs andthenchoose elements of the context bank that are similar to the current query and add these to the context.
jigsawcreates a context bank offline by scraping and annotating examples from api documentation forpandas aswellasotherresourcesofexamples fromtutorials etc.
that are used to teach the api.
when the user asks a question thequestionisfedtoacontextselectorthatusesatextsimilarity metric to pick the most relevant prompts from the context bank seefigure4 .westudytwokindsofsimilaritymetricsforthecontext selector a tf idf similarity tfidf andb transformer similarity transformer .
the context thus produced is appended with the current query and fed as input to the ptlm.
incaseswhere jigsawisunabletoproducethecorrectanswer we let users make changes to the incorrect jigsawcode and use suchafeedbacktoenhancethecontextbank detailsinsection3.
.
ptlms also take an input parameter called temperature.l o w e r values of temperature result in fewer accurate answers.
higher values result in a less accurate but more diverse set of answers.
we report on how we pick temperature values in section .
.
post processing the code snippets produced by the ptlmvary in accuracy and quality dependingonthenaturallanguagesentencesusedtoask toencodethequestion thecontextbanksupplied thecontextselection as wellas the temperature parameter.
the goalof jigsaw s post processing step is to filter and transform the output produced authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
jigsaw large language models meet program synthesis icse may pittsburgh pa usa by theptlmto produce a correct answer.
our measure of correctness is that the code produced should pass the i o examples specified by the user.
in many cases the code does not parse orfails with an exception.
we consider such cases as test failures.if a non empty set of candidate solutions produced by the ptlm satisfiesthetestcases thenwemerelyshowthosecodesnippetsto the user.
our experience is that for about of the cases dependingonthe ptlmandthedataset the ptlmproducescorrect outputs.intheremainingcases jigsawusesthecandidatesolutions produced by ptlmas starting points and performs transformations on candidate code snippets using simple program analysis and synthesis techniques to produce correct solutions.
we describe the correctness checks and transformations below correctness checks in cases where we have i o examples we run the candidate codesnippet starting with each of thespecified inputs and check if the output produced agrees with the corresponding specified output.
this check can be expanded to include staticanalysestocheckforsecurityvulnerabilitiesandothererrors as motivated by recent work .
variablenametransformations insomecases ptlmsproduce accuratecodesnippets butwithincorrectvariablenames.thisisof tenduetothemodel sbiastowardscommonvariablenameslike df forpandasdataframesandalsobecauseusersassumevariablereferencing to be implicit.
as an example we find that gpt 3produces the code snippet df1.merge df2 when the correct answer is df2.
merge df1 .
since users specify inputs and output variables in the naturallanguagedescriptionorintestcases thispost processing step uses such information from multi modal inputs as well as namesofvariablesinscope bysystematicallysearchingoverpotentialvariables andtryingpossiblepermutationsandcombinations of variable names so as to pass the test cases.
argument transformations in some cases the ptlms produce codesnippetswithcorrectmethodnamesandmethodsequences incasemultiplemethodsneedtobeinvokedinanestedmanneror oneafteranother butwithincorrectarguments.asanexample inresponsetothequery replace united states in location by us and in zip by codexproduces dfout df.replace united states us thissnippetinvokesthecorrectmethod replace butmissesthe detail in the question that united states and3434must be replacedwith us and4343onlywhenthesevaluesarepresentin the columns location and zip respectively.
the correct code synthesized by jigsawfor this query is as shown below dfout dfin.replace location united states us zip motivatedbysuchcases thispost processingstepsystematically searchesthroughargumentsfromaninferredargumentspacefora given sequence of method function names.
in order to implement the systematic search over the space of arguments we adapt the approachusedbyautopandastool withthefollowingmodifications.autopandasusesagraphneuralnetwork thattakesi o examples as input to choose method names.
however we needa lot of domain specific data to train such neural networks.
in ourcase wesimplyextractthemethodnamesfromtheoutputof ptlmgiven the natural language query which readily scales toprogramming domains beyond pandas .
the argument space to performthesearchisinferredusingthenaturallanguagetextinput theargumentspresentinthe ptlmoutput thecolumnnamesfrom the dataframe schema as well as variables in scope.
we extend the generatorsinautopandastoconsidercomplexdatatypessuchas lists and dictionaries and we extend the set of apis considered to include apis that return pandas series types one dimensional labeledarrayscapableofholdingdataofanytype inadditionto the ones that return pandas dataframe types.
with these modifications wefindthat jigsawisabletotransformseveralincorrect codesnippetsproducedbythe ptlmtocorrectcodesnippets as shown in section .
ast to ast transformations in some cases we find that the ptlmproducescodethatisalmostcorrectbuthasaminorerror.
we also find that such errors are repeatedly made by the ptlms.
as aspecific example we find gpt 3oftenmisses the bitwise not operator and produces the code train data instead of the following correct code with the bitwise not operator train data asanother example we findthat gpt 3missesparanthesizations whichresultsinthegeneratedcoderaisinganexception.specifically the generated code is dfout dfin dfin insteadofthefollowingcodesynthesizedby jigsawwhichisparenthesized correctly dfout dfin dfin such errors cannot be fixed via variable name transformation or argument transformations.
however code has well defined structure usuallyrepresentedasabstractsyntaxtree ast .jigsawtakes advantage of this structure and corrects such errors by learning re writing rules as ast to ast transformations learned from user interactionswith jigsaw.thesetransformationsareapplicationsof productionrulesfromgrammarusedinbluepencil whichis usedforsuggestingcodere factorings.however itisnotpossibletolearntheserulesattheappropriatelevelofgeneralityfromasingle example.
this generality is necessary so that the missing negation or parenthesizing can be corrected by the learnt transformation evenifthesamepatternisrepeatedwithadifferentsetofvariablesorconstants.toachievethis wecollectdatafromuserinteractions where the user edits the answer produced by jigsawto produce the correct code.
we cluster the data points i.e.
code snippets so that similar data points are grouped together and we learn a singleast to asttransformationthatisabletohandleallthedata points in a cluster.
unlikethe case of refactoring where users will implicitlyhintatclusteringofsimilaredits byattemptingthemone aftertheother weresorttoagreedyheuristics basedclustering algorithm.
this clustering is performed in an online fashion as we get more data points for learning ast to ast transformations.
for each data point we decide if the data point is grouped inside an existing cluster or instantiate a new cluster.
in the former case we check if the ast to ast transformations from the existing cluster authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
icse may pittsburgh pa usa naman jain skanda vaidyanath arun iyer nagarajan natarajan suresh parthasarathy sriram rajamani and rahul sharma can be re learnt to be more general and if so re learn the transformations.inaddition weperturbthedatapointsineachclusterto change variable names and constants in order to prevent learning transformations that over fit.
together with the above mentioned clustering and perturbationheuristics we find thatwe are able to learn transformations at the appropriate level of generality section5.
.
.weusetheproseprogramsynthesissystem to learnthetransformationsfromaclusterofincorrect correctcode snippets.while jigsawcurrentlyworksonlyonpythoncode the post processingstepworksatthelevelofasts andcanbemade to work across programming languages as well.
werefertoargumenttransformationsandast to asttransformations together as semantic repair in experiments section .
.
learning from user feedback the user interface of jigsaw integrated into the jupyter notebook isdesignedtoletuserssubmitcorrectcodein caseswherejigsaw is incorrect.
jigsawcan be improved by assimilating user feedback.
specifically we design techniques for updating context bank in the pre processing module and ast to ast transformations in the post processing steps as more users interact with jigsaw.
updatingcontextbank theprocedureforupdatingcontextbank withuserqueriesisgiveninalgorithm1.wefirstcheckwhether jigsawalreadyfoundacorrectsolutionforthegiven new query n thusgivingussomeconfidenceaboutitscorrectness.otherwise wecheckifanyofthesolutionsgeneratedby jigsawis close to some correct code determined by the standard edit distance on strings deditand a chosen threshold code .
if either of the two conditionsissatisfied weaddthenewquerytoourcontextbank whileadditionallyensuringthatasimilarqueryalreadydoesnot exist viatfidfbaseddistance dtfidfandathreshold bank .with algorithm updating context bank inputs context bank c n1 p1 n2 p2 ... n c p c new query and feedback code snippet n p output updated context bank c let output jigsaw n c if min idedit outputi p code return c if max idtfidf n n i bankreturn c return c n p moreusage wegrowthecontextbank andtrytocover different stylesofuserqueries whichinturnhelpsrelevantcontextselection.
updating transformations for every query paired with correct code snippet s weselect all incorrect codessuggested by ptlm within some small edit distance of a correct code.
the ast to ast transformations learning sub module performs clustering withperturbations on the selected code snippets as discussed in the above subsection and updates the set of transformations.
.
generality of approach webelievethattheideaspresentedabovesuchascontextselection correctnesschecking andtransformationsaregeneralandthatit is possible to design pre processing and post processing steps in abeginner intermediate advanced python pandas table1 proficiencyofparticipantsfrom pandaseval2 dataset generic manner that can work across languages apis and ptlms.
we give some evidence to this argument below a though we did our initial analysis on pandas code generated by gpt we found that codex also fails in similar modes.
jigsaw trained on gpt failures is able to fix similar failures generated by codex as well in thissetting.
b argumenttransformationscanbeinstantiatedfor different libraries in a manner similar to autopandas .c ast transformationsandlearningfromuserfeedbackextendtoother languagesreadily in suchanapproachisusedtolearnnontrivial code refactoring in c sql markdown and spreadsheets .
for each new api specific transformation rules can be learnt from usage data generated by users of that api.
datasets we perform our experiments on two different datasets2.
.
pandaseval dataset pandaseval1 thisdatasetconsistsof68pythonpandastasks.eachtaskcanbe solved using a single line of code by composing at most pandas functions sometimes followed by assigning variables.
this dataset was created by authors of this paper by going through queries in online forums like stackoverflow.
an example task from this dataset is for every row in df1 update common column to true if value in column a of df1 also lies in column b of df2 .
.
hackathon dataset pandaseval2 this dataset consists of pandas tasks each task can be solved bycomposingatmost2 3pandasfunctions possiblyfollowedby assigning variables as in the pandaseval1 dataset.
we posed these tasksasillustrations inahackathonweconductedwith25users over2differentsessions.theparticipantsofthishackathonweremicrosoft research fellows and interns.
table presents self reported proficiencyoftheusersinpythonandpandas.anexampleillustra tion that shows the intent of a task is given in figure .
users were asked to read such pictorial illustrations and come up with their ownnaturallanguage english queryconstructionsforeachtask to solve the problem.
we then collected the queries written by the users clustered andannotatedthemtoproducethe pandaseval2 dataset comprising of a total unique queries constructions.
the task corresponding to the illustration in figure from the datasetpandaseval2 is shown below.
here dfinanddfoutrefer to the dataframes in figure .
we note that while users provided precise and clear natural language queries in many cases they also came up with imprecise and incorrect formulations in some cases.
for instance in the specshown above the query provided by user1is correct whereas the one provided by user2is incorrect because the word france i s presentinthe iata columnaswell figure5conveysthatonly the country column needs to change and not the iata column.
2the datasets can be found at authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
jigsaw large language models meet program synthesis icse may pittsburgh pa usa figure example task part of the dataset pandaseval2 a s presented to the user during the hackathon session.
since such queries were created by users interacting with the system andusers tendto make mistakes it is usefulto havesuch variationsinthedataset.whilecuratingthedataset weremoved naturallanguagequeriesthatwereclearlyincorrect andretained queries that were imprecise and partially correct.
task 8 queries replace france with fr in country column and paris with par in city column user1 in dataframe dfin replace cells having france to fr and cells having paris to pr user2 io inputs dfin output dfout listing example json for a task in pandaseval2 as mentioned earlier we conducted the hackathon over two sessions.weuse pandaseval2 s1 todenotethedatasetgenerated from user queries from the first session and pandaseval2 s2 to denote the dataset generated from user queries from the second session.
for each of the tasks we created semantic variations e.g.changingconstants apiarguments ofthesametask.consequently usersinthesecondsession pandaseval2 s2 sawdifferent variants of the tasks when compared to users in the first session pandaseval2 s1 .
specifically tasks were exactly the same haddifferencesinconstantsand9hadchangesinarguments.we introducedthesevariantsinordertostudyif jigsawcanlearnfrom usage in the first session to improve user experience in the second session see section5.
.
we use pandaseval2 todenote theunion ofpandaseval2 s1 andpandaseval2 s2.
experiments we evaluate jigsaw on the two datasets introduced in section with emphasis on the following questions a how accurate is thejigsawsystem compared to the black box ptlms and other code synthesis methods?
b what is the utility and applicability of the individual jigsawcomponents in the pre processing and post processing modules ?
c can these components benefit from feedback over time as more users interact with the system?for the first and second questions we evaluate jigsawin an offline setting i.e.
without learning from any feedback in sec tions .
and present comparisons against the state of the art autopandas framework which generates pandas snippets using only i o example in section .
.
for the third question we perform a temporal study on the pandaseval2 dataset in section .
where we leverage user feedback from the first hackathon session toupdatethesystemandmeasuretheperformanceimprovement in the second session.
we also perform ablation studies in sec tion5.
pertainingtoourcontextselectionsub module.weend with a preliminary evaluation of jigsaw on tasks pertaining to the tensforflow api in section .
.
we consider accuracy as our primary evaluation metric i.e.
fractionofspecificationsinthedatasetforwhicha correctprogram wassynthesized.wedefineaprogramascorrectifitsatisfiesthe giveni oexamples andadditionallypassesamanualinspectionof whetherthesynthesizedcodemeetstheintentofthenaturallanguage description.the manualinspectionhelps us rejectprograms that satisfy the i o examples by overfitting on them and violate thegeneralintentofthenaturallanguagedescriptions.notethat thereisinherentrandomnessintheoutputofthe ptlms sowerun every evaluation three times and report the mean accuracy and standard deviation over the runs .
in some cases we also present taskcompletion metricwhichisthepercentageoftaskscorrectly solved by a user regardless of the number of queries used to solve a task interacting with the system.
furthermore in every case we present the best accuracy obtained by varying the temperature parameter of ptlm .
.
.
.
.
offline evaluation intable2 wepresenttheperformanceof jigsawonpandaseval1 andpandaseval2 datasets with gpt 3andcodexptlm s.thesecond column of the table indicates the context selection strategyfor the ptlm.
for this study we consider no context no tailored context provided for the user query we use a default context import pandas as pd andtransformer transformersimilarity based context selection discussed in section with number of context prompts fixed as .
each cell in the table gives the accuracy metric with mean and standard deviation as defined above.
forjigsaw thecolumntitledvariablenameindicatestheperformance of the system using only this part of the post processing module andthecolumntitledsemanticrepairindicatestheperformance of the system in its entirety i.e.
running variable name transformations followed by semantic repair argument transformations and ast to ast transformations .
comparing ptlmand semantic repair columns it is evident thatjigsawimproves upon the black box ptlms in terms of accuracy by15 irrespectiveofthecontextselectionstrategy onboththedatasetsaswellasonboththe ptlms.theseresults underscore theutility ofprogram analysis based augmentationoflarge language models.
next from table we find that providing useful context for the language model along with the query significantly improves upon not providing any context comparing rows vs and rows 3vs4 acrossthedatasetsand ptlms.itisclearthat ptlmwith transformer contextisbetterthan no context byamargin authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
icse may pittsburgh pa usa naman jain skanda vaidyanath arun iyer nagarajan natarajan suresh parthasarathy sriram rajamani and rahul sharma pandaseval1 pandaseval2 ptlm variable name semantic repair ptlm variable name semantic repair gpt 3no context .
.
.
.
.
.
.
.
.
.
.
.
transformer .
.
.
.
.
.
.
.
.
.
.
.
codexno context .
.
.
.
.
.
.
.
.
.
.
.
transformer .
.
.
.
.
.
.
.
.
.
.
.
table performance mean accuracy std.
deviation after different stages of the jigsawpipeline on pandaseval1 and pandaseval2 datasets.
jigsawpost processingstepssignificantlyimprovesupon ptlmsirrespectiveofcontextselectionstrategy.
pre processing clearly benefits comparing rows vs and vs .
withoutpost processing andupto15 withpost processing forcodexon the two datasets.
for gpt transformer contextissignificantlybetterthan no context onthepandaseval2 dataset and on pandaseval1 the numbers are statistically insignificant.ptlmsrequiresomeinitialcontextintheformofexamples tocharacterizethetasktobesolved andtheseresultsunderscore the importance of having a pre processing module in jigsaw.
finally from table we also observe the effectiveness of the individualpost processingmodulesof jigsaw asdiscussedbelow.
notethat fortheseresults weseedourast to asttransformations using a small dataset collected from stackoverflow questions.
later in section .
we show that these numbers can be significantlyimprovedby learningtransformationsfromusageovertime.
variable name transformations ptlms make variable referencing errors as noted in section because of its implicit bias towardscommondataframenamessuchas df df1 df2 dfout and also because users tend to not specify variables explicitly in theirqueries.wefindthatthissimplepost processingmodulegives an improvement of for codexand for gpt .
semanticrepair weseethatthesemanticrepairpost processing moduleimprovesabsoluteperformanceof codexby andof gpt 3by6 .thisunderscoresthesignificanceofusingprogram analysis techniques to augment language models that do not haveinherentunderstandingofcodesemantics.recall fromsection that semantic repair consists of argument transformations and ast to ast transformations sub modules.
we find that using just the argument transformations without ast to ast transformations improvesabsoluteperformanceofthesystemby5 and3 for gpt 3andcodexrespectively notshownintable2 .
similarly using ast to ast transformations alone without argumenttransformations weobtainimprovementofupto3 .
for gpt 3and .
forcodex not shown in table .
we find that our post processing steps are reasonably fast time takenby jigsawisprimarilybottle neckedbytheinferencetimes ofptlmapis.
specifically on average getting output from codex takes seconds while our post processing module takes 3s ec onds.similarly onaverage gpt 3takes30 40secondsfordifferent context sizes while post processing finishes in seconds.
.
temporal evaluation inthissection weevaluate jigsawonitsabilitytolearnandimprove withuserfeedback.weperformthisevaluationonthe pandaseval2 dataset.recallthatthehackathonwasorganizedovertwoseparate sessions so we use the submissions andfeedback for tasks in the first session corresponding to the pandaseval2 s1 dataset to a update our context bank b learn ast to ast transformations and c evaluate jigsawonthepandaseval2 s2 datasetconsistingofvariantsofthetasksin pandaseval2 s1 asdescribedinsection4.
.
updatingpre processingmodule wefollowalgorithm1 with code bank .
andfilteroutbadlywrittenqueriesfrom thefirstsessionusers.notethat forthe3tasksthatareidentical in the two sessions we do not make any updates to the context bank.wedenoteourseededcontextbankthatwasusedinthefirst session containing243question answerpairs with cs1andthe updated context bank updated resulting from algorithm with cs2containing seeded new question answer pairs.
updatingpost processingmodule wefollowtheproceduredescribed in section .
to learn ast to ast transformations from session one data along with seeded data.
we use ts1to denote transformationsseededduringsessiononeand ts2todenotethe new updated transformations learned from session one data.
wecomparetheperformanceof jigsawonpandaseval2 s1 with cs1andts1 againstpandaseval2 s2 with baseline cs1andts1 as well as with the updated context bank cs2and transformationsts2 intable3.eachcellinthetableisthemeanaccuracyand standarddeviationonthecorrespondingdataset.twoobservations are in order.
learning helps improve jigsaw.itisevidentthattheperformance of jigsawon thepandaseval2 s2 dataset with the default cs1 ts1setting column3 issignificantlylowerthanthatofthe updatedcs2 ts2setting column for both the ptlms.
accuracy ofthesystemwith gpt 3improvesbyover30 duetotheupdated modules even with codex which already performed quite well on all datasets we still improve by with updates.
second session was in general more challenging.
we also observe that the performance on pandaseval2 s2 with the default cs1 ts1setting column is significantly lower than that on pandaseval2 s1 with the same setting column .
this is because in general the second session was more challenging partly dueto the higher percentage of queries on difficult tasks and the semanticdifferencesintasksacrossthetwosessions.butwhenwe use the updated the context and transformations banks we find a drastic improvement in the performance on pandaseval2 s2 a s highlighted in above.
this illustrates that jigsawhas the ability to improve from user feedback regardless of the ptlmused.
finally we also look at the task completion metric described in thebeginningofsection5 toassesshowtheperformancegains of learning from feedback translated to user experience during the hackathon.insessionone usersweabletosolveonly71 ofthe tasks on average however in session two users were able to solve of the tasks on average thus making the experience of the jigsawsystem more productive with the updates.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
jigsaw large language models meet program synthesis icse may pittsburgh pa usa pandaseval2 s1 pandaseval2 s2 cs1 ts1 cs1 ts1 cs2 ts2 gpt .
.
.
.
.
.
codex75.
.
.
.
.
.
table performance mean accuracy std.
deviation ofjigsawwithout cs1 ts1 andwith cs2 ts2 learningcontext bank and transformations from user feedback on the pandaseval2 dataset.learninghelpsimproveaccuracysignificantly comparing columns and .
.
.
analyzing learned ast to ast transformations.
wepresent someofthelearnedast to asttransformationsappliedtocode snippets produced by gpt in table .
the transformations were learned using the clustering and perturbing technique outlinedin section .
.
we see that the code fixes are interpretable andthey solve common semantic problems in the outputs of ptlms.
please refer to supplementary material for details of the precise ast to asttransformationslearntcorrespondingtofirsttworows of table .
forinstance considertheruleimpliedinthefirstrowoftable4 which is of inserting bitwise not operator inside subscript.
this transformation learnedusingtheclusterof diversecodesnippets in listing is fairly general this is one of the clusters obtained by running our clustering technique on seeded and session one data .
on the other hand consider the last row of table which waslearned using the cluster of code snippets in listing .
since the clusteredsnippets followasimilarstructure thelearnedtransformationworksonlywhenanewsnippethasexactlythesamelogical conditional operators in the specific order.
thus the quality of the learnedtransformationsdependsonthequalityoftheclustering andofthecodesnippetsthemselves andweexpectthatmoreusage data positively influences the overall quality.
task dfout df.loc incorrect dfout df.loc correct task df p df p.loc .str.contains ch incorrect df p df p.loc .str.contains ch correct listing cluster of code snippets from two different tasksthat yields the bitwise not transformation in table .
.
comparison to autopandas autopandas ap isapandasprogramsynthesisenginecapable ofgenerating programs withtwoor threepandasfunctions.
ituses generators for enumerating over the pandas api and guides the search with the help of graph neural networks gnns which operateontheinput output i o dataframe s andreturnsthemost likely function sequences and arguments.
in contrast we make use of multi modal specification both natural language query and i o examples .
programming by examples is known to have ambiguous under specifications .
from our experience this issue is exacerbated for large apis that provide multiple ways for achieving similar functionalities.
for instance considerthespecificationinfigure1.ifweonlyconsiderthei o example for the given task we can find many trivial solutions that just drop or select certain rows of dataframe.weevaluate aponourpandaseval1 andpandaseval2 datasets.
as discussed in section apdoes not support series operations column assignments and dictionary or list generators many of whicharenecessaryinpandasworkflows.so outof68tasksinthe pandaseval1 dataset and tasks in the pandaseval2 dataset only and are covered by the autopandas framework respectively.
hence we compare jigsaw instantiated with the codex ptlm againstaponlyonthese27tasksanduseatimeoutof3minutes.
inthefirstrowoftable5 weseethat jigsawclearlyoutperforms autopandas even in the restricted subset solvable by ap.
this is because of the tasks are under specified if only i o examples are used and apreturns over fitting solution on many of these tasks this highlights the necessity of multi modality.
we also run jigsawon theapdataset where all tasks are supported by autopandas and i o examples are sufficient.
this datasethasbeensourcedfromstackoverflowposts.since jigsaw usestextastheprimaryinput weaddnaturallanguagedescriptions in these posts for querying codex.
the results are in the second row of table while codexalone is inferior to ap jigsaw with codex performs better than ap.
.
ablation study in both the offline and temporal evaluations presented in the previoussubsections wefixedthe numberof contextpromptsto 4and transformer asthecontextselectorinthepre processingmodule.
in this ablation study we ask if the performance of jigsawis sensitive to these choices and provide justification for the same.
allexperimentsinthissectionarecarriedoutwiththesamesetting as that of section .
.
table compares the performance of jigsawwith two different context selection strategies namely tfidfandtransformer .
we find that the transformer context selector is slightly better but moreimportantly thattheperformanceof jigsawisnotsensitiveto the selection strategy.
table compares the performance of jigsaw with different number of context prompt examples i.e.
and .
ourexperimentsshowthatwhilethereisn tasignificantdifferencebetweentheperformancesof4promptsvs.8prompts bothperform betterthanusingjust 1prompt.again jigsawisrelativelyrobust to these choices.
finally note that all variations of these choices for the number of prompts as well as the selection strategy outperform the no context setting see table this further underscores the utility of the pre processing module.
.
beyond pandas to test the generality of jigsaw we did a preliminary evaluation with25tensorflow taskssourcedfromtf coder andonline forums like stackoverflow.
we setup the pre processing module of jigsawsimilar to the offline evaluation by creating a context bank of prompts from documentation pages.
we reuse the variablename module and do a what ifanalysis for argument and tree transformationsmanually.table8showstheperformanceofjigsaw on the tensorflow dataset.
as seen from the table codex aloneis able to solve only of the tasks variable transformation 3interestingly this missing parenthesis mistake is quite common and frequented even by humans!
see blog post and stackoverflow question .
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
icse may pittsburgh pa usa naman jain skanda vaidyanath arun iyer nagarajan natarajan suresh parthasarathy sriram rajamani and rahul sharma code before code after semantic explanation out data out data adding bitwise not inside subscript df df df df df df parenthesizing mistake3 out df.
iloc out df.
loc changing iloctoloc dfout df1.
append df2 ignore index true dfout df1.
append df2 dropping the last keyword argument dfout dfin.
duplicated dfout dfin.
duplicated .sum computing sum of series using .sum train data.
drop test train data.
drop test.index adding .indexin first argument of drop dfin dfin .rolling window .
mean dfin dfin .rolling .mean reassign back to the column dfout dfin dfout dfin giving precedence to bitwise or table applications code after of learned transformations on code snippets produced by ptlm code before .
task dfout dfin dfin dfin incorrect dfout dfin dfin dfin correct task dfout per dfin per.loc dfin per dfin per incorrect dfout per dfin per.loc dfin per dfin per correct listing cluster of code snippets from two different tasks that yields the precedence transformation in table .
autopandas ptlm jigsaw subset of jigsawdatasets autopandas dataset table5 numberoftaskssolvedby jigsawandaponasubset of our dataset supported by apand their dataset.
context pandaseval1 pandaseval2 gpt 3tfidf .
.
.
.
transformer .
.
.
.
codextfidf .
.
.
.
transformer .
.
.
.
table6 ablationstudy performanceof jigsawwithtwocontext selection strategies.
prompts pandaseval1 pandaseval2 gpt .
.
.
.
.
.
.
.
.
.
.
.
codex16 .
.
.
.
.
.
.
.
.
.
.
.
table7 ablationstudy performanceof jigsawwithdifferent number of context prompts.
ptlmvariable name semantic repair table8 preliminaryresultsof jigsawwithtensforflowapi.
improvestheperformanceto15tasks.wemanuallycomparethe code outputs to the expected output to check if argument and tree transformations can be learnt.
based on this analysis we find that semantic repair can potentially improve the performance to tasks.weshowsomeexamplesbelow.forthequery givenatensor in1 replace all instances of with ptlmoutputs the following tf.where x x thecorrectcodeforthisquery synthesizedbyjigsawusingvariable transformation is shown below tf.where in1 in1 forthequery givenatensorin1andatensorofindicesind get thesumofelementspresentatindicesinindfromtensorin1.
the ptlmoutputs the following incorrect code tf.gather in1 ind the correct code shown below can be synthesized by jigsaw with a learnt ast to ast transformation if sufficient data points are collected from usage tf.reduce sum tf.gather in1 ind in summary this shows that the proposed pre processing and postprocessing modules are useful and can be generalized to other libraries and programming languages as well.
threats to validity ourdatasetshavebeencreatedbymanuallyinspectinginternet forumslikestackoverflow.wetriedtocoverthecommonprogrammingpatternsinpandas.however theyarenotrepresentativeof all pandas programs in the wild.
we designed the pandaseval2 s1 andpandaseval2 s2 datasets by collecting data from two sessions of a hackathon as a proxy for the real world setting where large software teams are working on thesameprojectwithsimilartasks allowing jigsawtolearnand improveovertime.wevariedthetasksbetweenthetwosessions so as to simulate variants of tasks.
however the variations we introduced may not representative of variations of tasks in the real world.
our study had only participants evaluating whether the productivity of developers is enhanced in a statistically significant manner ina largescale deploymentof jigsaw isbeyond thescope of this paper.
whencomparingjigsawto autopandas jigsawtakesasinput both the natural language description and the i o examples while autopandas onlytakesthei oexamplesasinputs.hence jigsaw authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
jigsaw large language models meet program synthesis icse may pittsburgh pa usa has more information about the tasks than autopandas .
jigsaw takeslessthanaminutepertaskandweuseatimeoutofthreeminutesforautopandas .althoughhighertimeoutsmightimprovethe performance of autopandas minutes they are not compatible with the interactive user experience that we are aiming for.
whether autopandas solvedataskcorrectlyornotisdetermined by manual inspection and is susceptible to human errors.
related work the literature on using machine learning for program synthesis is vast and we restrict to works which are closest to jigsaw synthesizing code for large apis using large models and multi modal specifications .
these works can be classifiedintothefollowingcategories designedforlargeapis but do not use large models based purely on large models with no multimodal specification and multimodal synthesis for small apis.
details follow thetde systemforjavareliesonrichtypeinformation which is absent in pandas and fails to generate argument combinationsthat areabsentfromitscorpus.
autopandas generates pandas code exclusively from input output i o examples usinga combination of gnns which predict function sequences and enumerativesearch.tf coder usesbothnaturallanguagedescriptions and i o examples to generate tensorflow code.
both of themusesmallspecificmodels asopposedtolargegenericmodels like gpt and lack mechanisms to incorporate user feedback.
gpt whiletrainedonwebhasshowninspiringcapability on synthesizing code.
models have also been explicitly trained on code with documentation .
in particular codex that is part of github copilot generates python code from natural languagedescriptions.syncromesh usesbuildcontextpromptsfor ptlms similar to how jigsawdoes in pre processing.
additionally they propose constrained semantic decoding for generating code while respecting syntactic and semantic constraints.
however the expressiveness of the constraints is restricted and more work is needed to model constraints that occur in practice.
spider i s a text to sql competition where many tools compete .
rahmani et al .
use the outputs of gpt to guide a component based search.
their approach is evaluated only on small dsls suchasregularexpressionsandcssselectorsandtheydonotlearn from user feedback.
manshadi et al .
and raza et al .
synthesize string transformations.
webqa synthesizes programs toextractinformationfromwebpages.regel andyeetal .
synthesizes regular expressions.
mars synthesizes data wrangling operations.
these techniques have not been demonstrated at the scale of pandas that has hundreds of operations.
jigsaw fixes the output of ptlmand is hence related to work on programrepairlikerefazerthatlearnscodetransformationsfrom editsused tofixprograms .jigsaw s interfaceisinspired from b2 s interface that augments visualizations to notebooks.
conclusion and future work jigsaw is the first tool for synthesizing code for large apis like pandas that leverages the advancements in ptlms.
the key contribution of jigsaw lies in the post processing steps that drastically improvethequalityofthecodegeneratedby ptlmslikegpt .inparticular themultimodalsynthesisofjigsawoutperformsboththebaselinesthatexclusivelyuse ptlmsandthosethatexclusivelyuse i oexamplesforprogramsynthesis.however severalchallenges remain before we can have a true pair programmer experience withptlms and we discuss a couple of them.
first in this paper the quality of the synthesized code is largely determinedbythei oexamples.however inpractice codequality is more nuanced than correctness on unit tests.
ideally the synthesizedcodeshouldhavehighperformance shouldnothavesecurity vulnerabilities and respect licensing attribution4.
second jigsaw focuses on multi modal specifications with natural language intent and i o examples.
however even multi modal specifications can be weak or ambiguous and would need to be refined using richer specifications like preconditions postconditions invariants boundsonresourceusageliketimeandmemory etc.
to obtain the intended code.
acknowledgement.
we thank dhvanil sanghvi for helping us perform a preliminary evaluation of jigsawwith tensorflow reported in section .
and arjun radhakrishna for helping us with prose and refazer related queries.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
icse may pittsburgh pa usa naman jain skanda vaidyanath arun iyer nagarajan natarajan suresh parthasarathy sriram rajamani and rahul sharma