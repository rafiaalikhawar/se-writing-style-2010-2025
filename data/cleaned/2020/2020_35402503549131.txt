towardinteractivebugreporting for android app end users yang song collegeof william mary usajunayed mahmud georgemason university usayingzhou universityof texasat dallas usa oscarchaparro collegeof william mary usakevinmoran georgemason university usaandrianmarcus universityof texasat dallas usa denysposhyvanyk collegeof william mary usa abstract many software bugsare reported manually particularly bugsthat manifestthemselvesvisually intheuserinterface.end userstypicallyreportthesebugsviaappreviewingwebsites issuetrackers or in app built in bug reporting tools if available.
while these systemshavevariousfeaturesthatfacilitatebugreporting e.g.
textual templates or forms they often provide limitedguidance concrete feedback orqualityverificationtoend users whoareofteninexperienced at reporting bugs and submit low qualitybug reports that lead to excessive developer effort in bug report management tasks.
weproposeaninteractivebugreportingsystemforend users burt implementedasatask orientedchatbot.unlikeexistingbug reportingsystems burtprovidesguidedreportingofessentialbug reportelements i.e.
theobservedbehavior expectedbehavior and steps to reproduce the bug instant quality verification and graphicalsuggestionsfor theseelements.weimplementedaversionof burtfor android and conducted an empirical evaluation study with end users who reported bugs from six android apps studiedinpriorwork.thereportersfoundthat burt sguidanceand automatedsuggestions clarificationsareusefuland burtiseasyto use.wefoundthat burtreportscontainhigher qualityinformation thanreportscollectedviaatemplate basedbugreportingsystem.
improvements to burt informed by the reporters include support forvariouswordingstodescribebugreportelementsandimproved qualityverification.ourworkmarksanimportantparadigmshift from staticto interactive bugreportingfor end users.
ccs concepts softwareanditsengineering softwaremaintenancetools .
keywords bug reporting task orientedchatbots android apps permissionto make digitalor hard copies of allorpart ofthis work for personalor classroom use is granted without fee provided that copies are not made or distributed forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation on the first page.
copyrights for components of this work owned by others than acm mustbehonored.abstractingwithcreditispermitted.tocopyotherwise orrepublish topostonserversortoredistributetolists requirespriorspecificpermissionand ora fee.
request permissions from permissions acm.org.
esec fse november 14 18 singapore singapore associationfor computing machinery.
acm isbn .
format yangsong junayedmahmud yingzhou oscarchaparro kevinmoran andrian marcus and denys poshyvanyk.
.
toward interactive bug reporting for android app end users.
in proceedings of the 30th acm jointeuropeansoftwareengineeringconferenceandsymposiumonthefoundationsofsoftwareengineering esec fse november14 18 singapore singapore.
acm newyork ny usa 13pages.
.
introduction bug report management is an important and costly software engineering activity.
while certain types of bugs can be reported automatically via a known oracle e.g.
crashes recent studies haveillustratedthatmorethanhalfofthebugsreportedinopen source software relate to functional problems with no automaticallyidentifiableoracle and hence mustbereportedmanually.
high qualitybugreportsareessentialforbugtriageandresolution and they are expected to describe at minimum the observed incorrect behavior ob the steps to reproduce the bug s2rs and the expected correct software behavior eb .
one of the main difficulties that contributes to quality issues in end user bug reporting is the knowledge gap between end users and developers .
that is there is often a gap between what end users knowandwhatdevelopers need generallyduetothe factthatusersarebothunfamiliarwiththeinternalsofthesoftware and with the explicit types of information that are important for developers e.g.
the ob eb ands2rs .
most current reporting systems are not designed to address the above mentionedknowledgegapbetweenend usersanddevelopers.inparticular currentsystemsaretypicallylackingalongtwo important dimensions they offer limited guidance related to whatneeds to be reported and howit needs to be reported and nofeedbackisofferedtoreportersonwhethertheinformationthey provided is correct or complete.
in consequence given the static natureofthesebugreportinginterfaces theburdenofproviding high qualityinformation restsonthe reporters.
wepositthatan interactive reportingsolutioncanhelptobridge the developer end user knowledge gap.
inspired by prior work on question answering systems for debugging we argue that a conversational agent i.e.
a chatbot can successfully guide endusers through the reporting process while offering interactive suggestions andinstantquality verification.
esec fse november14 18 singapore singapore yang song junayedmahmud ying zhou oscar chaparro kevin moran andrian marcus denysposhyvanyk inthispaper weintroduceandevaluateatask orienteddialogue system for bug reporting orburt that is capable of providing instant feedback for each element of a bug description i.e.
ob eb and s2rs while actively guiding corrections where needed.
burt combinesnovelandstate of the arttechniquesfordynamicsoftware analysis naturallanguage processing and automated report qualityassessment.wedesignedanddevelopedthecurrentversion ofburtto work for android apps but its architecture is platformagnosticanditcanbeinstantiated withsomeengineeringeffort for other types of gui based applications e.g.
web based desktop or ios based .inparticular burtconstructsagraphofprogramstates usingbothcrowdsourcedappusagedataandautomatedgui based exploration techniques.
the chatbot then parses and interprets end user descriptions of various bug report elements by matching them to states and transitions in the constructed graph and produces graphical suggestions regarding information that is likely tobereported e.g.
thenexts2rs .additionally burtrecognizes when end users provide incomplete or ambiguous information and suggests improvements or clarifications to the users.
traditional task orientedchatbotstypicallyhavedirect accesstoastructured andeasilyparseableknowledge base .incontrast burtismore complex asitreconcileshigh leveldescriptionsprovidedbyend usersandmatchesthesetotechnicalprograminformation bridging the end userto developer knowledge gap.
we evaluated burtempirically asking end users with variouslevelsofpriorbugreportingexperience toreport12bugsfrom sixandroidappsusingaprototypeimplementationof burt.we foundthattheguidanceandautomatedsuggestions clarifications made by the chatbot were accurate useful and easy to use and the collectedbug reportsare high quality.
weasked additional end users to report the same bugs with a template based bug reportingsystem itrac andcomparedthequalityofthesereportsto thosereportedwith burt.burtreportshavefewerincorrectand missings2rsthanthe itracreports.wealsofoundthat burthelps novicebugreportersprovidemorecorrectsteps andexperienced reporters avoid missingsteps.
in summary the contributionsofthis paper are as follows burt thefirsttask oriented conversationalagentthatsupports end users in reporting bugs currently for android apps with features such as automated suggestions real time feedback prompts for information clarification andgraphicalcues.
theresultsofanempiricalevaluationinvolving36end users thatinvestigates user experiences preferences and attributes ofinteractivebugreportingwith burt aswellasthequality ofthe resultingbugreports.
ourworkopensthedoortoanewwayofthinkingaboutenduserbugreporting usingconversationalagents shiftingthestate of the art from statictointeractive bug reporting.
while burtis a prototype we expect that it will serve as the foundation fora new classofinteractivebug reportingsystems combiningelementsof existingstaticsystemswithfeaturesofconversationalagents .
burt a chatbotforbug reporting we propose a task oriented chatbot for bug reporting burt .
burtoffers a variety of features for interactive bug reporting such as the ability to i guide the user in reporting essential bug report the chat box reported steps panel4 quick action panel screen capture panel5 tips panel figure b urt sgraphicaluserinterface elements ii check the quality of these elements iii offer instant feedbackaboutissues and iv providegraphicalsuggestions.
burtis designed to collect three key elements for developers during bug triage and resolution theobserved behavior ob theexpected behavior eb and the steps to reproduce the bug s2rs .burtcollectsthesefromtheuserthroughadialogueand generatesa web basedbug reportcontaining textualdescriptions for theseelements withattachedscreen captures of the system.
burt sdesignconsistsofthreemaincomponents inspiredbythe typicalarchitectureoftask orienteddialoguesystems which adapttechniquesfromautomatedprogramanalysisandnaturallanguage processing to facilitate bug reporting.
burt snatural language parser nl parses the relevant information from end user responsestothechatbot.the dialoguemanager dm dictates the structured conversation flow for burt s reporting process and handles the presentation of multi modal e.g.
screenshots and text informationtotheuser.finally the reportprocessingengine rp mapsinformationparsedfromuserresponsestovariousstates in a program execution model for a given app in order to assess bugelementquality.thecurrentversionof burtisdesignedfor androidappsandbuildsitsexecutionmodelusingacombination ofautomatedappexplorationandcrowdsourcedusertraces.inthis section we present burt scomponentsindetail.
.
graphicaluser interface gui we designed burtas a web based application that includes both a standardchatbotinterfacealongwithadditionalvisualcomponents as illustrated in fig.
.
thechat box allows the end user to provide textual descriptions of the ob eb and s2rs as well as interact with the graphical information that burtdisplays e.g.
recommendationsofthenexts2rsviascreenshots .the reported steps panel enumerates and displays the s2rs that the user has reported.thetextualdescriptionofthereportedstepscanbeedited andthelastreportedstepcanbedeleted iftheusermakesamistake andwishestocorrectit.the screencapturepanel displaysscreen capturesofthelastthrees2rs.the quickactionpanel provides buttonstofinishreportingthebug restartthebugreportingsession and pre viewthebugreportbeingcreated thesecanbeactivated 345towardinteractive bugreporting for android app end users esec fse november14 18 singapore singapore anytime.the tipspanel displaysrecommendationstoend users onhowtouse burtandhowtobetterexpresstheob eb ands2rs.
thetipschangedependingonthecurrentstageoftheconversation.
.
naturallanguage parser nl burtparsestheob eb ands2rdescriptionsprovidedbyend users usingdependencyparsingviathestanfordcorenlptoolkit .
this process obtains the tree of grammatical dependencies between words in a sentence and extracts the relevant words from thetree.thisparsingtechniqueisneededbythereportprocessing enginetoassessthequalityofparsedbugreportelementsandto helpdirectthe flowofconversation see sec.
.
.
.
burtfirstutilizestheheuristic basedapproachintroducedby chaparro et al.
to identify the type of a sentence e.g.
conditional imperative or passive voice for each message received fromtheuser.thisapproachimplementsheuristics basedondependency parsing and part of speech tagging to identify discourse patterns in ob eb and s2r descriptions .
once the sentence type is identified burtexecutes a series of algorithms to extract the relevant words from the sentence based on prior work on quality assessment of s2rs .
in essence we implemented 16parsingalgorithmsthattraversethegrammaticaltrees of end user sentences which have a different structure depending on the sentence type e.g.
conditional or imperative .
each algorithm parsessentencesofonetype.allthe16algorithmsimplemented for the different types of ob eb s2r sentences can be found in our onlinereplication package .
burtparses asinglesentence using the following format where the subjectis the actor e.g.
the user or an app component performingthe action whichisanoperationortask e.g.
tap create crash the objectisan entity directlyaffectedbythe action and object2isanother entity relatedtotheobjectbythe preposition .
an entity isanounphrasethatmayrepresentnumeric textual appinput domainconcepts guicomponents etc.dependingon thesentence itstype andwhetheritdescribesanob eb ors2r thewords e.g.
thesubject preposition orobject2 extractedfrom the entity are requiredoroptional.
for example for the mileage android app the ob sentence theaveragefueleconomyshowsananvalue writteninpresent tense is parsed as .
the eb sentence fuel economy statistics should be calculated correctly which uses the modal should isparsed as average fuel economy .thes2rsentence savethecarfillup written imperatively isparsedas .
somesentencesdescribeacombinationofob ebands2rsin asinglephrase.forexample thesentence theappstoppedwhen i added a new time range describes both an ob and a s2r.
this sentenceisparsedby burtas astheob and as the s2r.
in this example burtextracts the s2rfromthesentenceasfollows.first itlocatestheadverb when in the parsed grammatical tree then it follows the relationship that leads to the verb add for which when is the adverbial modifier.
next burtlocatestheverb snominalsubject i and its direct object time range .
if these relationships donot exist in the tree the sentence is not conditional as expected.
otherwise burt prompt user for ob eb s2r descrip6onuser writes ob eb s2r screen match?check ob eb s2r quality show screens to userselect one screen ask for next bug report element ask user to rephrase user re phrases ob eb s2r figure burt sdialogueflow forqualitychecking extracts the verb add as theactionand the noun phrase time range as theobject.
in the end this sentence is parsed as the s2r .
when multiple sentences compose a single user message burt only parses the initial sentence.
when burtis unable to parse a usermessage e.g.
becauseitcannotidentifythe subject itasks theusertorephrasethesentence.
burt stipspanel anduser guide suggests patterns to the user to phrase the ob eb and s2rs.
.
dialogue manager dm burt s dialogue flow consists of three main phases ob eb and s2r collection.
burt s dialogue is multi modal in nature and is capableofsuggestingbothnaturallanguageandgraphicalelements suchasscreenshots tohelpguidetheuserthroughthereporting process.
the dm relies upon the rp engine to assess the quality of bug elementsreportedbyendusers see sec.
.
.
.whileburt s dialogueflowproceedslinearlytocaptureeachbugelement the ob eb and s2rs in that order the dialogue flow is similar for all elements.therearetwomaindialogueflowsthat burtnavigates i performing quality checks on written bug report elements applies toallbugelements and ii automatedsuggestionofs2rs fors2rs only .
nextwe describe thesetwomain dialogueflows.
.
.
dialogue flow for bug element quality checks ob eb s2r .
before the dialogue begins a user must select the target app by clickingonitsicon.then burt sdialogueflowforqualitychecking illustrated in a modified swimlane diagram in figure is initiated startingwith the ob.
to begin the qualitychecking process burt promptstheusertoprovidethebugelement ob eb s2r .
burt automatically parses the description of the element and the rp engine verifiesits quality see sec.
.
.
.
if the ob eb s2r is matched to an app screen from burt s executionmodel seesec.
.
.
burtaskstheuserforconfirmation ofthematchedscreen.iftheuserconfirms burtproceedstothe nextphaseoftheconversation e.g.
askingfortheebornexts2rs otherwise burtasks the userto rephrase the bugelement.
iftherearenoappscreenmatches burtinformstheuserabout theissueandaskshertorephrasetheob eb s2r.oncetheuser provides a new description the quality verification procedure is re executed.ifthereare multiplematches burtprovidesalistofup tofiveappscreenshots derivedfromtheappexecutionmodel that matchthedescription.theusercantheninspecttheappscreens 346esec fse november14 18 singapore singapore yang song junayedmahmud ying zhou oscar chaparro kevin moran andrian marcus denysposhyvanyk suggest likely screens from current posi6onuser selects one mul6ple or no screens screen selected?
suggest addi6onal screens user selects one mul6ple or no screens ask user if they would like addi6onal screen sugges6ons if any user responds yes or no response prompt user for s2r descrip6onuser writes s2r figure dialogueflow fors2r predictions andselecttheonethatshebelievesbestmatchesherdescription ofthe bugelement.
ifnone are selected burtsuggestsadditional appscreensifany.iftheuserselectsoneappscreen burtsaves the bug element description and screen and proceeds to collecting the next bug element.
after three unsuccessful attempts to provide a high quality ob description burtrecords the last provided ob description for bug report generation.
this process proceeds for each bug element starting with the ob.
s2rs are treated slightly differently since burtcan alsopredicts2rs as we describe next.
.
.
dialogueflowforsuggestings2rs.
burtsuggestspotential nexts2rsthattheusermayhaveperformedduringactualappusage depending on the last reported step and the user selected screen thatishavingtheproblem i.e.
theobscreen.figure 3illustrates this process.
this dialogue flow uses a predictive algorithm that usesburt sexecutionmodel seesec.
.
.
.thesuggestionsare displayedasalistofappscreens eachscreenrepresentingas2r.
each s2r in the list displays the screen capture with a textual description placed below the image.
the screen capture is visually annotated with a yellow oval highlighting the gui component e.g.
a button executedby the step.
the usercan select none one or multiple of the suggested s2rs.
when a s2r is selected burt suggests additional s2rs if any.
when none are selected and burt has more suggestions burtasks the user if she wants to get more suggestions.ifso burtdisplaysthem.otherwise burtprompts the userto describe the nexts2r.
.
.
collecting input values.
user input from type like steps e.g.
i entered gallons are extracted by burtfrom the objector object2oftheparseds2rs byidentifyingliteralvaluesorquoted text.
if the input value is missing or generic i.e.
not a literal or text burtprompts the user to provide the input.
this is only activatedifthematcheds2risconfirmedbytheuserasacorrects2r.
.
report processing engine rp burt s rp engine is composed of three sub components i the appexecutionmodel ii thedialoguequalityprocessor whichmaps parsedbugreportelementstoappstatesfromthemodel and iii thes2rresponsepredictor whichinferslikelynexts2rs givenan existing setofs2rs already mappedto the executionmodel.
.
.
appexecutionmodel.
theappexecutionmodelisagraph thatstoressequentialgui levelappinteractions e.g.
taps types or swipesperformedonscreenguicomponents andtheappresponse to those interactions i.e.
app screens .
these interactions and app responsesareproducedusingtwostrategies byexecutingan automatedsystematicappexplorationadaptedfrom crashscope s gui ripping engine and by recording crowdsourced app usage information from app end users or developers.
both the systematic app exploration and app usage data are collected before burtisdeployedfor use.
appexecutionmodeldatacollection.
thisisburt splatform specific part and would be constructed differently for nonandroidapplications.
burtusesaversionof crashscope sguirippingengine togenerateappexecutiondataintheform of sequential interactions.
crashscope enables dynamic analysis of android apps that utilizes a set of systematic exploration strategies e.g.
top down and bottom up and has been shown to exhibit comparable coverage to other automated mobile testing techniques .
for a detailed description of the engine we refer the readers to moran et al.
s previous work .
as in prior work we instantiate data collection by recordinglow levelappeventtracesusingthe getevent sendevent uiautomator utilities includedinthe android os andsdk.
collectingcrowdsourceduserappusagedataservestwomain purposes increase the coverage of app states and screens in burt sexecutionmodel and augmentthemodelwithscenarios thatarecommonduringnormalappusage.section .5describes the procedure that we implemented to collect the crowdsourced data.
crowdsourceddata collection leadsto the same types of app eventsas the automaticapp explorationdoes.
app execution model structure.
the execution model is a directedweightedgraph g v e wherevisthesetofunique app screens with complete gui hierarchies andeis a set of app interactions performed on the screens gui components.
in this model two screens with the same number type size and hierarchicalstructureofguicomponentsareconsideredasingle vertex.eis a set of unique tuples of the form vx vy e c where eis an application event tap type swipe etc.
performed on a gui component cfrom screen vx andvyis the resulting screen right after the interaction execution.
each edge stores additional information about the interaction such as the textual data input onlyfortypeevents andtheinteractionexecutionorderdictatedby theappusage manualorautomatic .thegraph sstartingnodehas onlyoneoutgoinginteraction whichcorrespondstotheapplication launch.aguicomponentisuniquelyrepresentedbyatype e.g.
a button or a text field an identifier a label ok or cancel and its size position in the screen.
additional information about a component is stored in the graph for example the component descriptiongivenbythedeveloper theparent childrencomponents andanannotatedscreencaptureoftheapphighlightingthegui component being interacted with.
the screen captures are used in the screen suggestionsmadeby burt see sec.
.
.
.
thegraphedgeshaveaweightwhichindicatesthelikelihood of a given app interaction represented as a state transition.
the weights are utilized by the s2r response predictor see sec.
.
.
which aims to suggest s2rs that end users would perform when normally using given app features.
to enable accurate predictions 347towardinteractive bugreporting for android app end users esec fse november14 18 singapore singapore burtassignshigherweightsto interactionsexecutedbyhumans than those executed automatically by crashscope .
to accomplish this burtsets the weight of an edge to the number of timesit was executedinthecollectedusagedata.ifanedgeisnotexecutedbya human butwasexecutedby crashscope ssystematicexploration then edge weight is set to one even if crashscope executes the same interaction multiple times.
while this weight assignment scheme isstraightforward itprovedto be effective see sec.
.
.
.
dialoguequalityprocessor.
basedonpriorwork burt s quality definition is based on the ability to match a textual bug description ob eb ors2r tothescreens states andinteractions edges of the execution model.
a textual description is considered to be high quality if it can be precisely matched to the executionmodel otherwiseitisdeemedlow quality.thisdefinition andburt s dialogue features that prompt users to improve lowquality descriptions aim to reduce the knowledge gap between the reporters whoareunfamiliarwithappinternalsandmaynotknow howtoexpressabug anddevelopers whodefineandimplement the vocabulary capturedin burt sexecutionmodel.
assessing ob quality.
burtfirst builds a query to the app execution model by concatenating the non empty elements from the parseddescription namelythe subject action object andobject2.
then it preprocesses the query using lemmatization and attempts to retrieve all matching gui components via an adapted version of the matching procedure proposed by prior work .
thisprocedurecomputes thesimilarityscorebetweenthe query andtheelementsfromaguicomponent namelythecomponent label thedescription andtheidspecifiedbytheoriginaldeveloper.
the similarity is computed based on a normalized length of the longest common substring between query and the component elements.
if such similarity is greaterthan orequal to .
then there is a match otherwise there is a mismatch.
if the initial query does notmatchanappscreen burtrunsadifferentquerybyusingonly thesubject since basedonourexperience itmayindicateakey gui componentthat isdirectlyrelatedwithabug.
burtkeepsa listof theapp screens with atleast one matching gui component.
such a list is sorted in increasing order by the distance between the starting state in the execution model and the matchedstate.ifthislistisempty itmeanstheobdescriptiondoes notusevocabularyfromtheappscreensandneedstoberephrased.
ifthislistcontainsonlyoneelement itisusedtoshowtheuserthe potentialbuggyappscreen whichtheuserhastoconfirmascorrect or incorrect.
otherwise if the list contains multiple elements it isusedtodisplaythepossiblebuggyappscreenssothattheuser decides the appropriate screen.
the selected ob screen by the user is tracked in the execution model and is used for eb description matching the prediction of the next s2rs and asking the userif the last provideds2r isthe last step to replicate the bug.
assessing eb quality.
burtperforms the matching approach described above using the parsed eb description against the ob screenconfirmedbytheuser.
burtassumestheobscreenisthe one that should work correctly therefore it attempts to match the eb description to it.
if the user did not select an ob screen the eb matchingisbypassedandtheebdescriptionissavedforgenerating the bug report.
if the eb description does not match the ob screen it means the vocabulary used in the eb description is differentfrom the ob screen and the eb description should be rephrased.
however rather than prompting the user to rephrase it burtasks the userif the obscreen isthe one that should work correctly.
assessings2rquality.
burtadaptsthestepresolution matching algorithm proposed by chaparro et al.
and performs exploration of the execution model driven by the matching of the reporteds2rs.bydefault burtassumesthefirsts2rperformed by a user is launching the app and the current graph state is set to be the firstapp screen that results from this operation.
foraprovideds2rdescription startingfromthecurrentstate burttraverses the graph in a depth first manner and performs stepresolutiononeachstate.stepresolutionistheprocessofdetermining the most likely app interactions that the s2r refers to ina particular state i.e.
app screen .theresult isa set of resolved interactions for the s2r on the selected states.
if the s2r resolution failsforthesestates eitherwithamismatchoramultiple match result thenitmeansthateither thereareappstatesnotpresent in the execution model or the s2r description is of low quality.
theresolved interactions are matched against the interactions i.e.
theedges fromthegraph bymatchingtheirsourcestate vx the event e and the component c. if a pair of interactions match then they are considered to be the same interaction.
the matching returnsasetofinteractionsfromthegraphthatmatchtheresolved ones.
if this set is empty it means that the resolved interactions werenotcoveredbytheappexplorationandthequalityassessment returns a low quality result with a mismatch.
if the reason for the mismatchisbecauseofmultiple componentor eventmatch i.e.
thes2rdescriptionmatchesmultipleguicomponentsormapto multiple events burtconsiders thes2r as ambiguous and burt indicatesthatthes2r s actioncorrespondstomultipleevents or theobjectorobject2matchmultipleguicomponents.ifthereisa no match burtspecifies the problematic vocabulary from the s2r elements action object object2 orany combination of these.
otherwise ifthe setof resolvedinteractions isnotempty burt proceeds with selecting the most relevant interaction that correspondstothes2rdescription byselectingtheonewhosesource state isthe nearestto the currentexecutionstate inthe graph.
.
.
s2rresponsepredictor.
burtpredictsthenexts2rsthata user may have performed in practice.
the prediction is executed duringthefollowingdialoguescenarios seefig.
whenanob screenfromtheexecutionmodelhasbeenselected confirmedby theuser whenthes2rcollectionphasestarts rightafterthe userconfirmsamatcheds2rforhers2rdescription or when the userhas already selectedone ormore s2rs suggestions.
burtimplementsashortest pathapproachtopredictthenext s2rs.
first burtdetermines the paths between the current graph state and the corresponding ob state.
then burtcomputes the likelihoodscore basedonthe executionmodeledge weights.
burtuses the equation below to compute the score spof an n edge path p w1 w2 ... wn withwkbeing edge k sweight sp n summationtext.
kwk n the first term in the sum is the average weight among all path edges andthe secondterm isafactor that favorsshorterpaths.
once the paths are ranked by their scores in descending order these are modified to include loops i.e.
steps that lead to the same appscreen e.g.
typesforprovidinginputvalues .then onlythe 348esec fse november14 18 singapore singapore yang song junayedmahmud ying zhou oscar chaparro kevin moran andrian marcus denysposhyvanyk first five steps for each path are selected.
with only the first five steps all unique paths are kept and only the top paths are saved forbeingpresentedtotheuser.thefirstoneisalwayspresented andiftheuserdoesnotselectanyofthestepsasbeingthenexts2rs and wants more suggestions the second path is presented next.
every time the user selects a suggested step as being the next step the prediction suggestion processrestarts withnewpredictions.
.
burtimplementation burtis currently implemented as a webapplication with two majorcomponents thefront end developedwiththereact chatbot kit andtheback end developedwithspringboot .burt s implementationistailoredforandroidapplications however its underlyingtechniquesaregenericenoughtobeeasilyimplemented forothertypesofsoftware theappexecutionmodeldatacollection isthe only platform specific part.
tocollectthecrowdsourcedappusagetracesfor burt twocomputer science students who did not have knowledge of our studied bugs were instructed to use the apps features as they typically would do and recorded traces that exercise key app features.
additionally twoofthepaperauthorsrecordedsequencessimulating appdeveloperswhotesttheapps.thesetraceswereconvertedand mergedintoappexecutionmodelsforeachofthestudiedappsas described in sec.
.
.
.
in practice developers can utilize recorded tests crowdsourced data or automated app exploration techniques witha one time costfor buildingthe app executionmodel.
empiricalevaluation design we conducted two user studies to evaluate burt s perceived usefulnessandusability burt sintrinsicaccuracyinperforming bugreportelementqualityverificationand prediction and the quality of the bug reports collected with burt compared with reports collected by a template based bug reporting system.
we aim to answer the following researchquestions rqs rq1 whatburtfeatures doreportersperceiveas not useful?
rq2 whatburtfeaturesdoreportersperceiveas not easytouse?
rq3 what is the accuracy of burtin performing bug element quality verification and prediction during the bug reporting process?
rq4 what is the quality of the bug reports collected by burtcompared to reports collected by a template based bug reporting system?
to answer the rqs we selected a set ofandroidapp bugsused in prior research sec.
.
and asked bug reporters to report these bugsusing burtandtoevaluatetheirexperience sec.
.
.weanalyzedtheconversationsthereportershadwith burtandmeasured how accurate burtwas during the reporting process sec.
.
.
then we asked additional participants to report the same bugs with a template based bug reporting system secs.
.
.1and3.
.
and analyzed the collected bug reports to measure their quality basedonbugelementcorrectness sec.
.
.
.wepresentanddiscuss the results in sec.
.
our user studies were approved by an institutional review board irb and conducted remotely due to restrictionsrelatedto covid .
.
appsandbug dataset we selected android app bugs from the bug dataset provided by cooper et al.
.
the apps in the dataset support different apptable appsand bugdataset appbug id ofs2rs bug type apodcc3 11incorrect coloringuicomponent rb error message onscreen droidcc5 crash cc6 crash gnucc9 duplicated guicomponent rc crash growcc5 crash rc crash timecc1 guicomponentdisappears cc4 crash tokcc2 crash cc7 6guicomponentdoes not appear domains and have been studied in prior research .
the apps are antennapod apod a podcast manager time tracker time atime trackingapp androidtoken tok a one time password generation app gnucash gnu a personal finances manager growtracker grow a plant monitoringapp anddroidweight droid apersonalweight tracking app.
this dataset provides for each bug the apk installer thatcontainsthebug thedescriptionoftheincorrect observed app behavior ob theexpectedappbehavior eb andthe minimal listofthe steps to reproduce the bug s2rs .
fromthe60bugs 35crashesand25non crashes incooper et al.
s dataset we selected bugs crashes handled error and4non crashes usingastratifiedrandomapproach seetable .
werandomlyselectedtwobugsfor eachofthesixapps ensuring thatthebugsrepresentavarietyofbugtypesthatmanifestvisually onthedevice crashes guiissues functionalbugs etc.
andhave a diverse number and type of s2rs taps types swipes etc.
.
six bugs contain minimal s2rs and six bugs contain minimal s2rs see table .
the bugs are reproducible on a specificweb based android emulatorconfiguration virtual nexus 5x withandroid .
configuredviathe appetize.io service .
.
rq rq2 burt suser experience we asked participants to report a selected subset of bugs using burt andevaluate theirexperience viaan onlinequestionnaire.
.
.
burtbugreporterrecruitment.
wereachedoutto36potentialparticipantswithmixedexperienceinbugreportingfrom our personal network who were not involved in or aware of the purpose of this work.
they were offered a usd gift card for participation.fromthese 24userscompletedthestudyanddata fromsixparticipantswasdiscardedduetolow effortanswers thus resulting in valid responses from participants.
four of the six participantsdidnottreatthestudyseriously thatis theysubmitted incompletereports e.g.
onlytheobwasreported andanswered allsurveyquestionswiththesameresponse.theremainingtwo participantsreportedcompletelydifferentbugstotheonesassigned.
five participants had not reported a software bug before nine had reportedfiveorfewerbugs andtheremainingfourhadreported morethanfivebugs.theparticipantswereunfamiliarwith burt andthe selectedapps bugs.
349towardinteractive bugreporting for android app end users esec fse november14 18 singapore singapore table2 questionnaireforevaluatingb urt suserexperience id question q1howoften were burt sscreen suggestions useful?
q2howoften was burtable to understandyour ob eb s2rs?
q3how often were you able to understand burt s messages questions?
q4wasburt spanelofreported steps useful?
q5howeasy to use was burtoverall?
q6which of burt sfeatures didyoufind easy difficult to use?
q7what additional functionality if any would you like to see in burt?
.
.
bugassignmentandreporting.
eachofthe18participants was randomly assigned to report three bugs from the selected withburt eachbugcorrespondingtoadistinctapp.thereporters were instructed to report the bugs in a given random order to account for potential learning biases.
the bug reporting procedure consisted of five tasks which included the users i watching a short instructional video that explained how to use burtvia an example ii familiarizing themselves with the apps on the webbased emulator iii watching a video demonstrating the observed and expected behavior for each assigned bug with annotations toensure properunderstanding iv reproducingthe bugson the web based emulator and v reporting each bug with burt.
we aimed to control for participantunderstanding ofthebugs so that the effectofpotentialmisunderstandingswasminimized.
.
.
burt suserexperienceassessment.
aftertheparticipants reported the three assigned bugs they answered an online questionnairethatwasmeanttoassess burt susefulnessandeaseof use and to obtain feedback for potential improvements to burt.
table2shows the questions asked to the participants which are inspiredbythe paradise evaluation framework.
to address rq1 we focused on evaluating burt s four main features burt s app screen suggestions for the ob eb and s2rs burt s ability to parse and match the ob eb and s2r descriptions provided by the user burt s messages and questions given to the user and burt s panel of reported s2rs which allowsthe userto visualizeandedit thereporteds2rs.
questions q1 q5 in table 2aim to address rq1and used a level likert scale .weaskedtheparticipantsto optionally provideajustification rationalefortheiranswers.eachbuginvolvedmultiple screensuggestions ob eb s2ruserdescriptions and burtmessages questions.questionsq1 q3refertothefrequencyofthese userinteractionswith burt.
to address rq2 the reporters assessed burt s overall ease of use q5 andindicated burt sspecificfeaturesthatwereeasyor difficult to usefor them q6 .
q5used aused a5 level likert scale and q6 requested an open ended response.
the reporters were also asked to indicate additional features they would like to see inburt q7 .
additional open ended questions were asked not shownintable to obtain feedbackonhowto improve burt.
.
rq burt sintrinsicaccuracy toanswer rq3 weanalyzedtheconversationsthatthereporters hadwith burttodetermine howoften burtwasabletocorrectlymatchob eb s2rdescriptionstotheappexecutionmodel asconfirmedbythereporters and howoftentheuserselected oneormoreofthesuggestedappscreensasbeingcorrect i.e.
theymatchthereporters ob eb s2rdescriptions .wecomputedstatistics onthe meta datathat burtcollected fromthe conversations such as the type of messages that burtasked and the type of user responses as definedby burt sdialoguemanager see sec.
.
.
.
rq burt sbug report quality we describe the methodology to answer rq4inthis section.
.
.1itrac a web form for bug reporting.
we implemented a web template based bug reporting interface called itrac using qualtrics .itracoffers the same features of professional issue trackers e.g.
github issues or jira for reporting the ob eb ands2rs.specfically itracprovidestextboxeswithexplicit prompts that ask for the bug summary title and the ob eb and s2rs.inaddition itracpromptsthereportertoprovidethes2rs usinganumberedlist viaagiventemplate .thereporterscanwrite freely their own bugdescriptions in thetext boxes and also attach images files.
we use itracrather than an existing professional issue tracker to simplify the reporting process for the reporters because they can use itracwithouthavingto logintoaservice.
.
.
bugreportingwith itrac.followingthemethodologydescribed in sect.
.
.
we recruited more end users who did not participate in the burtstudy and asked them to report a subset of bugs using itrac.
these reporters did not know about burt itrac and the selected apps bugs and had a similar bug reporting experiencetothatofthegroupwhoreportedthebugswith burt.
fiveofthenewreportershadnotpreviouslyreportedasoftware bug eight had reported one to five bugs and the remaining five hadreportedmore thanfive bugs.
we assigned the same sets of three bugs used in the burtstudy to the new users trying to match the bug reporting experience and instructed them to report the bugs using itracin the same orderfrombefore.priortoreportingthebugs theparticipantswere instructedto i familiarizethemselveswiththeappsbyusingthem ontheweb basedemulator ii watchavideodemonstratingthe bugs withannotationstoensureproperunderstanding and iii reproducing the bugsonthe web basedemulator.
.
.
measuring bug report quality.
we estimate the quality of the collected bug reports via burtanditrac by assessing the correctness of the ob eb and s2rs described in the reports based onthequalitymodelproposedbychaparro etal.
.threeauthors manually compared each collected report with the ground truth scenarios fromcooper etal.
sdataset whichincludedcorrect descriptionsoftheobandebandaminimumviablesetofs2rs.
usingthismethodology wecomputedthefollowing i thenumber ofincorrectob eb s2rdescriptions and ii thenumberofmissing s2rs.
to limit the effect of subjective assessments two authors performedthebugreportanalysisindependentlyandathirdauthor reviewedtheresults reachingconsensusamongallthreeincaseof discrepancies.inordertodeterminehowhelpful burtanditrac are for novices or more experienced reporters we analyzed bug report qualityacrossdifferentlevels of bugreportingexperience.
results and analysis we present anddiscuss the results of our evaluation for eachrq.
350esec fse november14 18 singapore singapore yang song junayedmahmud ying zhou oscar chaparro kevin moran andrian marcus denysposhyvanyk never rarely sometimes o!en alwaysscreens ob eb s2rs messages panel useless somewhat useless neutral somewhat useful useful difficult somewhat di fficult neutral somewhat easy easyease of use figure user experienceresults forb urt q1 q5 .1rq1 burt sperceivedusefulness fig.4summarizes the users answers on i their perceived usefulness ofburt s screen suggestions row labeled screens ii burt s abilitytounderstandtheuser sob eb ands2rdescriptions rows ob eb ands2rs iii how often they were able to understand burt smessagesandquestions row messages iv theirperceived usefulness of burt s panel of reported s2rs row panel and v burt soveralleaseofuse row easeofuse .
app screen suggestions .
half of the participants agreed thatburt sappscreensuggestionswere oftenuseful andtheother half agreed theywere sometimes useful.
asfor their rationales one participant mentioned that the next s2r screen suggestions were useful because they shortened the time it took me to explain howtoreproducethebug .otherparticipantshighlightedthatthe suggestions werehelpfulinmakingsureiwasprovidingtheexact steps i wanted to describe or thatburt gave very good suggestions whenitcouldfigureoutwhichscreenhadthebugbasedontheinitial report .someoftheparticipantsevenhopedthat burtcanprovide suggestions more frequently.
these results illustrate the usefulness ofburt sapp screen suggestions.
some participants noted though that the suggestions were a little inaccurate .
we found that the inaccuracies stemmed from burtnot being able to recognize match the user sob description becauseofgenericwording withoutdetails e.g.
theappcrashed .
notethatthe burt ss2rsuggestionsarenotactivatediftheob description is not matched to an app screen which affected the reportersexperience.also theparticipantsrecommendedthatit would be useful to have suggestions of bug triggering screenshots as currently burt s screen captures may not show the bug that the user wants to report.
the participants also found some suggestions confusing because the screen captures for the s2rshighlight non existentbuttons .thisstemsfrom burt ssystematicguiexplorationtechnique whichcan executeeventsongui components such as layoutsorviews whichare often not visibleto the user.
ob eb ands2runderstanding.
thereportershaveapositive overall impression on how often burtunderstood their ob eb and s2r descriptions.
specifically burtwas able to oftenoralways sometimes understandtheob eb s2rdescriptionsof9 participants outof18 .onlytwo oneparticipant s feltthat burtrarelyrecognizedtheireb s2rs.
our analysis of the open ended answers also reveals that some participants were generally satisfied with burtin terms of bug descriptionunderstanding.this canbe seenincommentssuch as i mquitesatisfiedwiththerecognitionrate evenbetterthantalkingtoarealagent italwaysunderstandsmydescriptionof theob ebwhenitriedtousekeywordsfromapps itwaskindofeasy forburttounderstandmy eb description and itcanunderstand metodescribetheerrorbehavior .however severalparticipantshad a less positive perception of burt s bug description understanding stating thatit is difficult tomatch burt s language they need to follow specific pattern so thatburtis able to understand and they usually had to paraphrase their descriptions.
these comments stem from our design decision to limit the language that users could use to describe the ob eb and s2rs and inaccuracies in bug description matching.
however we observed based on the reporters commentsandtheirconversationswith burt thatthe participants learned how to describe the ob eb s2rs using burt s preferredformatsafterreportingthefirstbug.still thereporters main recommendation was to improve burt s ability to recognize additionalvocabulary andwaysof phrasingthe ob eb s2rs.
burt smessagesandquestions.
eleven of18 participants oftenunderstood burt s messages and questions while six participantsunderstoodthem sometimes .onlyinonecase thereporter rarelyunderstoodthe messages questions.
the analysis of their rationales reveals that generally burt s messages questionswere veryeasytounderstand .oneparticipant wrote that burt s wording was always clear and i could always tell whatburtwas asking for also echoed by multiple participants.
someparticipantsrecommendedtoimprovethemessagesandquestions assometimestheywereunclearandtoosimilartoeachother.
for example for burt s question was this the last s2r that you performed?
the participants suggested to clarify which last s2r burtwasreferringto.
thepanelofreporteds2rs.
burt spanelofreporteds2rs was deemed to be useful somewhat useful by participants.
only one participant found that the panel was somewhat useless .
the participants commented that the panel was very useful for visualizingabugreport that itwasgoodtoseewhatwasgetting logged andthatitwasuseful asawayformetoreviewthatthe reproduction steps i entered are complete .
summaryoffindingsfor rq1 overall reportersfound burt s screensuggestionsands2rpanel useful.they alsohada positive impression of burt s ob eb s2rs understanding and messages.
improvementsarerequiredfor burttosupportadditionalwording ofbugreport elements andmore accuratesuggestions.
.2rq2 burt sperceivedeaseofuse twelve reporters indicated burtwas either easyorsomewhat easy to use.
four reporters were neutral while two reporters expressed itwassomewhatdifficult to use see easeofuse infig.
.
we analyzed thereporterresponses regarding whichof burt s featurestheyfoundeasy difficulttouse.ingeneral theparticipants expressedthat burt sgui isreallyhelpful concise and easy to use and understand .
multiple reporters indicated that selecting burt sappscreensuggestionswaseasytouseandsomeofthem were very enthusiastic about them.
one reporter mentioned that i likedthescreenshotsalot veryeasytoreporttheprocesstoreproduce a bug .
other reporters expressed that the suggestions confirmations were very easy to use.
when it had the right idea confirming it was just amatter of clickinga button and that burt guides the 351towardinteractive bugreporting for android app end users esec fse november14 18 singapore singapore table qualityassessmentresults forbugreports brs collected by burtanditrac app bug id ofbrs avg.
ofs2rsavg.
of avg.
of ofbrs with ofbrs with incorrects2rs missings2rs incorrectob incorrecteb itrac burt itrac burt itrac burt itrac burt itrac burt itrac burt apod cc3 .
.
.
.
.
.
.
.
.
.
apod rb .
.
.
.
.
.
.
.
.
.
droid cc5 .
.
.
.
.
.
.
.
.
droid cc6 .
.
.
.
.
.
.
.
.
.
gnu cc9 .
.
.
.
.
.
.
.
.
.
gnu rc .
.
.
.
.
.
.
.
.
.
grow cc5 .
.
.
.
.
.
.
.
.
.
grow rc .
.
.
.
.
.
.
.
.
.
time cc1 .
.
.
.
.
.
.
.
.
.
time cc4 .
.
.
.
.
.
.
.
.
tok cc2 .
.
.
.
.
.
.
.
.
.
tok cc7 .
.
.
.
.
.
.
.
.
overall .
.
.
.
.
.
.
.
.
usertoprovidea step by step view .thepanelofreportedsteps waseasy to explore anditwaseasyto removeevents from it.
themainreasonbehindusagedifficultieswasthelimitedvocabulary that burtunderstands also observed before for rq1.
the reporters recommended to let the users upload their own screen captureswhen burtisunabletoattachscreenstotheuser sbug descriptions andthe abilityto delete modify anystep.
finally forboth rq1 rq2 wefoundnonotabledifferences inburt sperceivedusefulnessandeaseofusebetweendifferent levels ofuser sbugreportingexperience.
.3rq3 burt sintrinsicaccuracy we analyzed the conversations that reporters had with burtto determinehowoften burtwasabletocorrectly matchob eb s2rdescriptionstotheexecutionmodel and suggestrelevant ob s2r app screensto the reporters.
obreporting.
wefoundthatin3of54conversations .
burtwasabletomatchthereporter sobdescriptiontothecorrectscreenthatshowedortriggeredthebug asconfirmedbythe reporter during the conversation.
in of conversations .
burtmatched the ob descriptionto multipleapp screens.
in those cases burtsuggested the top matched screens so that the reporter selected the one s he was referring to.
in of these reports the reporter selected one of the suggested screens while in the remaining the suggested screens were irrelevant.
for the remaining of the conversations .
burtwas not able to match the ob description with any app screen because of incorrect ob wordingfrom the user and inaccuracies in burt s messageparserandprocessing.overall burtwasabletocorrectly matchtheirobdescriptionsin32of54oftheconversations .
.
ebreporting.
asdescribedinsect.
.
.
burtcanonlymatch the reporter s eb description when there is a matched selected obscreen.otherwise burtcollectstheebdescriptionfromthe userasis.inthe32caseswhen burtcanverifyebquality burt was able to match the eb against the ob screen in cases .
without having to ask the reporter for confirmation.
in of the cases .
the users confirmed the matched ob screen when burtaskedthemaboutthat.intheremaining9cases .
burt wasnot ableto parse the providedeb description.s2r reporting.
burtmatched a writtens2r with a stepfrom the execution model times in total across the conversations .8timesperconversationonavg.
.in157ofthesecases .
burtwas able to match s2rs correctly.
burtpredicted and suggestedthenexts2rsin146cases .6timesperconversationonavg.
forthe32conversationswheretherewasamatched selectedob screen.wefoundthatthereportersselected1.6ofthe3.9suggested s2rs on avg.
in cases .
.
in of the conversations the reporter always selected s2rs from the suggested list meaning at least one suggestion was correct.
in all the conversations burtaskedtheusertorephrasetheirs2rs176times .9timesper conversationonavg.
.wefoundthatinatleast59ofthesecases .
theusermadeamistakeordescribedthestepincorrectly e.g.
incorrectresult or no more steps .
summary of findings for rq3 the results support the users ratings rq1 onhowoften burt sob s2rscreensuggestionwere usefulandhowoften burtwasabletounderstandtheuser sob eb s2r descriptions.
the accuracy assessment revealed cases where burt s strugglesto parse andmatchtheusers descriptions however burtisabletocontinuewithrephrasingprompts.theoverall accuracy indicates that the techniques we used in building burt s components are adequate.
improvements are planned for future work to improve burt saccuracy.
.4rq4 bug report quality table3summarizesthequalitymeasuresofthe 108bug reports collected with itracandburt for the bugs in our dataset eachbugisreportedin3to 6reports .
s2rquality.
overall asshownintable burtreportscontain fewer incorrect s2rs than itracreports on avg.
.
vs. .
andfewermissings2rs .
vs. comparedtothegroundtruth scenarios of the bugs.
we performed an analysis to verify whether there there statistically significant differences between burtanditraconthepercentageofincorrectandmissings2rs.
we applied the wilcoxon signed rank test and cliff s delta cd on the results across the bugs at confidence level sincewehavepairedordinalmeasurements foreachbug that do not necessarily follow normal distributions.
we found that burt s bug reports have fewer incorrect p .
and fewer 352esec fse november14 18 singapore singapore yang song junayedmahmud ying zhou oscar chaparro kevin moran andrian marcus denysposhyvanyk table s2r qualityby bugreporting experience reporting ofbrsavg.
of avg.
of avg.
of s2rs incorrect s2rs missing s2rs experience itrac burt itrac burt itrac burt itrac burt novice .
.
.
.
.
.
intermediate .
.
.
.
.
.
experienced .
.
.
.
.
.
overall .
.
.
.
.
missing steps p .
thanitrac s reports with a large effect size cd .5and0.
respectively .
the main reasons for incorrect s2rs are generic unclear step wording 4in burtand36itracreports duplicates2rs 13in burt reports zero in itracreports and extra s2rs in burtand one initracreports .
examples of steps with unclear generic wording include add comment or i searched for tech where the user eitherreferstohigh levelappfeatures whichmaptomultiplesteps that are not explicit or does not specify which gui components should be used and or which action should be applied on them.
extras2rsareirrelevantreportedsteps e.g.
ididnothingelse .
weidentifiedtwomainreasonsforduplicates2rs usermistakes and duplicateappscreenssuggestedby burtandselectedby the users.
the latter stems from the design of burt s execution model that considers structural variations of the same screen as different screens see sec.
.
.
.
an example is when the users employ different keyboard layouts e.g.
numeric vs. alphanumeric to enter inputvaluesonthe same screen.
ob eb quality.
moreburtreports have an incorrect ob description compared to itracreports vs. out of reports while a comparable number of burtanditracreports have an incorrect eb description vs. .
we found that there is no statistically significant difference between the number of burtand itracbug reportswith incorrectexpectedbehavior p .
with a small effect size cd .
in favor of burt.
feweritrac reports than burtreports have an incorrect observed behavior p .
withamedium effectsize cd .
.
the incorrect ob eb descriptions in burtreports and itracreports total occurred either because the participants did notprovideenoughdetailsaboutthebug e.g.
theappcrashed ortheydescribedtheirinabilitytoperformanactionratherthan describing the bug itself e.g.
i can t add delete a comment vs. crash when trying to add delete acomment .
for the burtreports we found that in cases the users describedthe ob eb incorrectly to begin with and burtcorrectly prompted them to rephrase them.
nonetheless they still reported an incorrect ob eb.
in four cases burtaccepted the incorrect ob eb and in only three of the cases burtprompted incorrect ob eb reporting after the user correctly described them.
this is mainly dueto burt scurrentlimitationonthe ob eb wording.
summary of findings for rq4 overall burtbug reports containhigher qualitys2rsthan itracbugreports andcomparable ebdescriptions.theresultsindicatethatimprovementsto burt are neededto bettercollectobdescriptionsfrom the reporters.
novice vs. experienced bug reporters.
our original expectationwasthat burtwouldhelpnovicereportersmorethan itrac astheexperiencedreporterslikelyusedtemplate basedreporting systemsbefore.we compared the quality of the bug reports across different levels of user s bug reporting experience.
while we did not observe notabledifferencesintermsofob ebquality wefounddifferences in s2r quality which we discuss.
table 4shows the s2r quality results for three groups novice bug reporters with noprior reporting intermediate reporters who had reported bugs and experiencedreporters whohadreported6 bugs .
regardingincorrects2rs experiencedandintermediatereporters producedabouttwiceasmanyincorrects2rswith itrac compared toburt .
vs. .
and20.
vs. .
onavg.
respectively .
at the same time novices produced about five times more incorrect steps with itracthan with burt .
vs. .
on avg.
.
this indicates that burthelpsnovices mostto avoid incorrects2rs.
table4tells a different story for missing s2rs.
novices and intermediate reporters missed .
times fewer s2rs with burt compared to itrac while experienced reporters missed four times fewer s2rs with burt.
surprisingly this indicates that burthelps experiencedreporters mostto avoid missingsteps.
wedonotspeculateonthereasonsbehindtheseobservations as more in depthstudiesare neededfor proper explanations.
limitationsand threats to validity beforeburtis deployed for use either systematic app exploration data orcrowdsourced appusagedataneeds tobe collected toconstructtheappexecutionmodel.theevaluationresultsindicatethat burtperformsreasonablywellwiththedatacollectedby crashscopeand only four people.
however we expect that additional data more covered states and scenarios would improve burt s quality verification of reported elements and screen step suggestions enabling the reportingof different bug types under a variety of reproduction scenarios.
to confirm our expectations additional studiesare neededfor future work.
burtis evaluated in a lab setting where reporters were exposed to the bugsthrough videos rather than letting them findthe bugs while using the apps as users would do in real life.
as in prior studies weadoptedthissettingmainlytoreduceparticipant effort and fatigue.
to address the lack of knowledge about the apps bugs we instructed the users to get familiar with the apps by using them and with the bugs by reproducing them on the emulatorbeforetheyreportedthebugs.weaddressedpotentialbug misunderstandingsvia2 wordannotations addedto the videos.
a diverse group of reporters participated in the studies who have different levels of bug reporting experience.
since we offered thereportersamonetaryincentivefortheirparticipationandsome ofthemarestudentsfromourinstitution s theymayhavebeen motivated to diligently provide high quality bug reports which maynotnecessarilybethecaseinareal lifescenario.however we expect this factor to have a minimal impact on the results since we used the same procedure to recruit both burtanditracusers and the bug reporting experience in both reporter groups are almostthesame onlytwo itracusershaveadifferentexperience .
our evaluation did not consider how easy or difficult it is for developers to understand and reproduce the itracandburtbug reports.
instead we focused on assessing bug report quality as doneby priorwork .
assessing bugreport understanding and reproductionisinourplansforfuturework.additionally wedid 353towardinteractive bugreporting for android app end users esec fse november14 18 singapore singapore notaccountforthecomplexityofthebugsinourdataset.however weselectedbugsofdiversetypesanddistributionsofthes2rs.our future work willinvestigate howbugcomplexityaffects burt.
finally giventhe relatively expensive nature of our evaluation we limited it to bugs from six apps reported by participants which affects the external validity of our conclusions.
a larger evaluation possibly performed on a larger sample of apps bugs andparticipants isinour plans for future work.
related work we discuss burt sadvancements inrelation to prior work.
issue bug reporting systems .
a variety of systems currently enable end users and developers to manually report software bugs namely issue bug trackers e.g.
github issues or jira built in bug reporting interfaces in desktop and web apps e.g.
googlechrome in appbugreportingframeworks e.g.
bugsee app stores and q a platforms .
these systems typicallyconsistofweb guiforms withtext basedtemplates that allow reportersto providebug descriptions indicate bug system metadata andattachrelevantfiles.someofthesesystemscollect technical information e.g.
configuration parameters and offer screen recording that enable graphicalbugreporting.
while existing systems provide features that facilitate bug reporting theyofferlimitedguidancetobugreporters lackquality verification of bug report information and do not provide concretefeedbackonwhetherthisinformationiscorrectandcomplete.
these are some of the main reasons for having low quality bug reports whichhaveimportantrepercussionsfordevelopers .
researchershaveexploredimprovingbugreportinginterfaces as we do in this work.
moran et al.
proposed fusion a webbased system that allows the user to report the s2rs graphically by selecting via dropdown lists images of the gui components andactions taps swipes etc.
thatcanbeappliedonthem.more recently fazzini etal.proposed ebug amobileappbugreporting system similar to fusionthat suggests potential future s2rs to the reporter while they are writing them.
record and replay tools offertheabilitytorecorduseractionsduring app usage e.g.
when abugisfound andreplaythemlater.
burtofferstwomainadvancementsoverpriortechniqueslike fusion.first burtwasdesignedtosupportend userswithlittleor no bug reporting experience.
for example fusionwas not created to specifically cater to end users as inexperienced users found itmore difficult to use as compared to alternatives .
second whereas past systems helped to provide structured mechanisms to facilitate the reporting process e.g.
through drop down selectors theydonotoffer interactive assistancewhenreportingabug.
burt offers such interactivity through its automated suggestions realtime quality assessment and prompts for information clarification.
bug report quality analysis.
surveys and interviews with developersand end users have identifiedthe observed softwarebehavior ob theexpectedbehavior eb andthesteps toreproduce s2rs thebugsasessentialbugreportelementsfor developersduringbugtriageandresolution.unfortunately such elements are often missing unclear or ambiguous as indicated bynumerousstudiesanddevelopers whichhave anegative impact onbugreport managementtasks.in consequence researchers have proposed techniques to better capture and manage high quality information in bug reports.
prior work proposedwaystoautomaticallyidentify different essential elements in bug reports e.g.
s2rs analyzetheirquality andgivefeedbacktoreportersaboutpotential issuesinthem.in particular zimmermann etal.
proposedan approachtopredictthequalitylevelofabugreportbasedonfactors such as readability or presence of keywords.
hooimeijer et al.
measured quality properties of bug reports e.g.
readability to predict when a report would be triaged.
zanetti et al.
proposed an approach based on collaborative information to identify invalid duplicate or incomplete bug reports.
imran et al.
proposed an approach to suggest follow up questions for incomplete reports.
songetal.
proposedatechniquetodetectwhentheob eb and s2rs are absentin submitted bug reports.chaparro et al.
evaluated the quality of the s2rs in bug reports through the eulertool which integrates dynamic app analysis natural language processing andgraph basedapproaches.
ourworkbuildsuponpriorresearch fortheautomatedquality verification of bug descriptions by developing quality checks for new types of bug elements i.e.
ob eb and by designing dialogue flows capable of guiding the user during the bug reporting process.
conclusions burtis a task oriented chatbot for interactive android app bug reporting.unlike existingbugreportingsystems burtcan guide end usersinreportingessentialbugreportelements i.e.
ob eb ands2rs provideinstantfeedbackaboutproblemswiththisinformation andproducegraphicalsuggestionsoftheelementsthatare likely to be reported.
eighteen end users reported bugs from six android apps and reported that overall burt s guidance and automated suggestions clarifications are accurate useful and easy to use.
the resulting bug reports are higher quality than reports created via itrac atemplate basedbugreportingsystem byother18reporters.
specifically burtreportscontainfewerincorrectandmissingreproduction steps compared to itracreports.
we observed that burtis most helpful to novice reporters for avoiding incorrect s2rs.
surprisingly burtseems to be most useful to experienced reporters for avoidingmissingreproduction steps.
the reporters provided feedbackfor refining thesupported dialog byincludingsupportadditionalwordingstodescribetheob eb ands2rs.thestudiesalsorevealedareasofimprovementfor burtwithrespectto the verification of the reportedelements.
data availabilitystatement we provide an online replication package that contains a complete implementation of burt burt s app execution data code and data about burt s evaluation and documentation that enables the verification and validation of our work and future research on bugreportingsystems.