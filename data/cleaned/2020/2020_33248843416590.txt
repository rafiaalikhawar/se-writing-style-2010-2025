automated patch correctness assessment how far are we?
shangwen wang wangshangwen13 nudt.edu.cn college of computer science national university of defense technology changsha chinaming wen mwenaa hust.edu.cn school of cyber science and engineering huazhonguniversityof science and technology wuhan china letterbo lin linbo19 nudt.edu.cn college of computer science national university of defense technology changsha china hongjun wu wuhongjun15 nudt.edu.cn college of computer science national university of defense technology changsha chinayihao qin qinyihao15 nudt.edu.cn college of computer science national university of defense technology changsha chinadeqing zou deqingzou hust.edu.cn school of cyber science and engineering huazhonguniversityof science and technology wuhan china xiaoguang mao xgmao nudt.edu.cn college of computer science national university of defense technology changsha chinahai jin hjin hust.edu.cn school of computer science and technology huazhong university of science and technology wuhan china abstract test based automated program repair apr has attracted huge attention from both industry and academia.
despite the significant progressmadeinrecentstudies theoverfittingproblem i.e.
the generated patch is plausible but overfitting is still a major and long standingchallenge.therefore plentyoftechniqueshavebeen proposed to assess the correctness of patches either in the patch generation phase or in the evaluation of apr techniques.
however theeffectivenessofexistingtechniqueshasnotbeensystematicallycomparedandlittleisknowntotheiradvantagesanddisadvantages.
to fill this gap we performed a large scale empirical study in this paper.
specifically we systematically investigated the effectiveness of existing automated patch correctness assessment techniques includingbothstaticanddynamicones basedon902patchesautomaticallygeneratedby21aprtoolsfrom4differentcategories.
thefirsttwoauthorscontributedequallytothiswork andmingwenisthecorresponding author.
nationalengineeringresearchcenterforbigdatatechnologyandsystem services computing technology and system lab hubei engineering research center on big data security hust wuhan china shenzhen hust research institute shenzhen china cluster and grid computing lab hust wuhan china permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation on the first page.
copyrights for components of this work owned by others than acmmustbehonored.abstractingwithcreditispermitted.tocopyotherwise orrepublish topostonserversortoredistributetolists requirespriorspecificpermissionand ora fee.
request permissions from permissions acm.org.
ase september virtual event australia association for computing machinery.
acm isbn ... .
codefeatureswithrespecttopatchsyntaxandsemanticsaregener allyeffectiveindifferentiatingoverfittingpatchesovercorrectones dynamic techniques can generally achieve high precision while heuristics based on static code features are more effective towards recall existing techniques are more effective towards certain projectsandtypesofaprtechniqueswhilelesseffectivetotheoth ers existingtechniquesarehighlycomplementarytoeachother.forinstance asingletechniquecanonlydetectatmost53 .
ofthe overfitting patches while .
of them can be detected by at least onetechniquewhentheoracleinformationisavailable.basedon our findings we designed an integration strategy to first integrate static code features via learning and then combine with othersby themajority voting strategy.
our experiments show that the strategycanenhancetheperformanceofexistingpatchcorrectness assessment techniques significantly.
ccs concepts software and its engineering software verification and validation software testing and debugging.
keywords patch correctness program repair empirical assessment.
acm reference format shangwen wang ming wen bo lin hongjun wu yihao qin deqing zou xiaoguang mao and hai jin.
.
automated patch correctness assessment howfar arewe?.in 35th ieee acminternational conference onautomatedsoftwareengineering ase september21 virtual event australia.
acm new york ny usa 13pages.
.
35th ieee acm international conference on automated software engineering ase introduction automated program repair apr has gained huge attention from both industry and academia recently.
over the years substantial aprtoolshavebeenproposed with theaimtoreducetheexcessivelyhighcostinbugfixing.aprtools have shown to be promising towards both practical significance andresearchvalue.forinstance sapfix whichwasproposedby facebook to automatically generate and suggest fixes has already been deployed inreal products that collectively consist of millionsoflinesofcodeandareusedbymillionsofusersworldwide.
despite the tremendous effectiveness achieved existing apr toolsstillfaceasignificantandlong standingchallenge theoverfitting problem .
the overfitting problem arises when themeasurementsusedtoassessthecorrectnessofanautomated generatedpatchisimperfect.duetotheabsenceofformalspecifications of the desired behavior most of the apr tools leverage the developer provided test suite as partial specifications to assess whether a patch is correct currently.
such a measurement assumes a patch that passes all the test cases to be correct and incorrect otherwise.
however test suites in real world projects are often weak and inadequate and thus a patched program passing all the tests might be simply overfitting to the test suite and still be faulty.
later on people denote a patch that passes the test suite as aplausible patch .aplausiblepatchthatindeedfixesthetarget bug is deemed correct otherwise is regarded as an overfitting patch.
as revealed by recent studies existing apr techniques are widely suffering from the overfitting problem that is they generate more overfitting patches than correct ones on real bugs thus leading to a low precision of their generated patches.
thelowprecisionofthegeneratedpatchessignificantlyaffected the practical usefulness of existing apr techniques.
therefore growingresearcheffortshavebeenmadetoidentifycorrectpatchesamongplausibleonesautomatically .
forinstance difftgen wasinitiallyproposedtoidentifyoverfitting patchesthroughautomatedtestgenerationbasedonthedeveloperprovidedpatch whichisdenotedasthe oracle patch inthis study.
it first tries to enhance the adequacy of the provided testsuite via generating an extra set of test cases and then assumes ageneratedpatchwhosetestoutcomebasedonsuchtestsdiffers fromthatoftheoraclepatchtobeanoverfittingpatch.toeaseour presentation we denote those techniques designed for automated patch correctness assessment as apcatechniques in this study.
existingapcatechniquesdifferentiatethemselvesindiversedesignspaces.first theycanbeeither staticordynamicdependingon whethertheyexecutetestcases.statictechniquesprioritizeorfilter out incorrect plausible patches via analyzing the characteristics of patchesstatically e.g.
anti patterns .onthecontrary dynamictechniquesgenerallyleverage automatedtestgeneration tools suchasrandoopandevosuite toidentifycorrectpatchesamong plausible ones e.g.
difftgen patch sim .
second they canbedifferentiatedinwhethertheoraclepatchisrequired.thosetechniquesrequiretheoraclepatch suchas difftgen runautomatedtestgenerationtoolsbasedonthe oracleprogram i.e.
the programafterapplyingtheoraclepatch andthenleveragethose automated generated tests to identify overfitting patches.
thosetechniques do not require the oracle patch e.g.
patch sim andopad generateextratestsbasedonthebuggyversion and then leverage other information or certain heuristics as the oracle to identify overfitting patches.
techniques designed without theoracle patch can be applied to the process of patch generation with the aim to prioritize and filter out overfitting patches and thustoenhancetheprecisionofaprtechniques .onthe contrary techniquesrequiringtheoraclepatchareoftenusedfor patch evaluation thatistoassesstheeffectivenessofaprtechniques .bothofthesetwodirectionsofapcatechniquesare reportedtobesignificanttotheaprcommunity .
forinstance manuallyannotatingthecorrectnessofpatchesissub jectiveandratherexpensiveasreportedbyexistingstudies and thus apca techniques with the oracle information are useful to facilitate the evaluation of apr techniques.
althoughhugeeffortshavebeenmadetowardsautomatedpatch correctness assessment the effectiveness of existing techniques hasnotbeensystematicallystudiedandcompared.besides little is known to their advantages and disadvantages.
a recent study reported that difftgen andrandoop can only identify fewer than a fifth of the overfitting patches through an empirical study based on patches .
however the behind reasons and the effectiveness of other advanced apca techniques remain unknown.
therefore there is an urge need for a comprehensive empirical study comparing and analyzing the effectiveness of all the stateof the artapcatechniquesbasedonalargernumberofpatches.
such a study is necessary and essential which can help us find the answers to important questions when designing apca techniques.
forinstance whetherexistingapcatechniquesaremoreeffective towardscertaintypesofpatchesoraprtechniques?besides are existing techniques complementary to each other and whether the integrationofthemcanenhancetheperformance?answeringsuchquestionscanguideresearcherstodesignmoreeffectivetechniques.
this study aims to bridge this gap which performs a systematic empirical study for automated patch correctness assessment including9differenttechniquesand3heuristicsbasedon8static code features on the most comprehensive patch benchmark so far i.e.
902patchesintotal .viainvestigatinghowmanyoverfitting patches can be identified by each apca technique we understood theeffectivenessofexistingtechniques includingtheadvantages and disadvantages and pointed out how they can be improved.
for instance patch sim can be enhanced by test case purification whiledaikoncanbeimprovedbyconsideringthecharacteristicsof invariants.
our study also makes the following important findings f1 heuristicsbasedonstaticfeaturesgaugingpatchsyntaxandsemanticsaregenerallyeffectiveindifferentiatingoverfitting patches over correct ones which can achieve high recalls.
f2 dynamicapcatechniquescanachievehighprecisionwhilemostofthemwilllabelcorrectpatchesasoverfitting.besides those techniques with the oracle information are generating a fewer number of false positives i.e.
fewer than .
.
f3 existingtechniquesaremoreeffectivetowardscertainprojectsandtypesofaprtechniqueswhilelesseffectivetotheothers e.g.
project langandconstraint based aprtechniquesfor staticcodefeatures andproject closureandlearning based apr techniques for dynamic ones .
969f4 existingtechniquesarehighlycomplementarytoeachother.
a single technique can only detect at most .
of the overfittingpatcheswhile93 .
ofthemcanbedetectedbyat leastonetechniquewhentheoracleinformationisavailable.
based on our findings we designed an integration strategy to first integrate different static code features via leveraging machinelearningmodels andthencombinethelearnedmodelwithother apca techniques by the majority voting strategy.
our experiments show that the strategy can enhance the performance of existing apca techniquessignificantly.
specifically our strategy canidentify66.
oftheoverfittingpatcheswhilepreserveahighprecision of99.
withtheoracleinformation.suchahighrecalloutperforms the current most effective technique by .
.
background and related works this section presents the background and related works.
.
automated program repair techniques generally aprtechniquescanbedividedintotwocategorieswhich aresearch based techniques andsemantic based techniques respectively .
search based techniques aim to search for candidate patches within a predefined space with or without templates as the guidance for code transformation .
when without templates the applied techniques also known as heuristic basedapproach leveragegeneticprogramming randomsearch or multi objectivegenetic programming toguide thesearch of correctpatches.researchersalsominefixtemplates alsoknown astemplate based approach from history of large scale opensource projects or from static analysis tools .
these templates are applied to generate patches aiming at producing morecorrectpatches .semantic basedtechniques also known as constraint based approach synthesize a patch directly using semantic information via symbolic execution and constraint solving .
these approaches usually focusonsingleconditionalstatementsorassignmentstatements .
recently approaches have been proposed to generate patches directly via using deep learning models e.g.
sequencer which is denoted as learning based approach .
.
the overfitting problem traditionally apatchisconsideredascorrectifitcanpassallthe test cases .
qi et al.
first investigated the quality ofautomatedgeneratedpatches.longetal.
firstpointedout thatconventionalcriteriontoexaminepatchcorrectnessisquestionable since test suites in practice are usually inadequate to guaranteethecorrectnessofthegeneratedpatches.asaresult those generatedpatchesthatpassallthetests alsoknownas plausible patches may fix the bug incorrectly not fix the bug completely or breaksomeintendedfunctionalities andthusbecome overfitting patches .
after that researchers begin to adopt plausibility i.e.
how many plausible patches an apr tool can generate and correctness i.e.
how many generated plausible patches arereally correct as metrics for assessing the repairability of aprtools .
meanwhile an increasing numberofstudiesaimedatdetectingoverfittingpatcheshavebeen proposed including difftgen patch simtable selected techniques in this study.
oraclerequired nooracle required dynamicevosuite randoop difftgen daikon patch sim e patch sim r opad e opad static circlemultiplytext.
ssfix capgen anti patterns s3 weusessfix capgen and s3todenotetheheuristicsbasedonthecorrespondingstaticfeatures.
andsoon.recently yuetal.
introducedamethodtoclassify overfittingpatches intotwocategorizations i.e.
incompletefixing andregression introduction .
however their method can only be appliedtothoseoverfittingpatchesthatcanbedetectedbythegeneratedtestcases.consequently itcannotbeappliedtothewhole set of patches included in this study.
as a result we do not analyze the performance i.e.
precision andrecallas we will introduce in section3.
of different apca techniques from this perspective.
.
empirical studies in apr in recent years plenty of empirical studies have been conductedconcerning different aspects of apr .
for instance liuetal.foundthatfaultlocalization fl strategies utilized by different apr techniques are diverse and the fl results can significantly influence the repair results .
long et al.
investigated the search space of repair tools and revealed that correctpatches are sparse while the overfitting patches are much moreabundant which is further confirmed by .
durieux et al.
andwangetal.
focusedonbenchmarkoverfittingproblem andreachedtheconclusionthatmorebugsshouldbeconsidered when evaluating apr techniques performance.
recently lou et al.
exploredtheideaof unifieddebugging tocombinefaultlocalization andprogramrepairintheotherdirectiontoboosttheperformance of both areas .
study design this section presents the design details of this empirical study.
.
apca techniques selection our study selects all the state of the art techniques targeting assessingpatchcorrectnessofjavaprogram.thisstudyfocuseson java since it is the most targeted language in the community of program repair.
furthermore there is a wide range of apr toolsthathavebeenevaluatedinreal worldjavaprograms providing on hand patches for our study.
specifically we consider the living review of apr by monperrus to identify these techniques.
.
.
inclusion.
overall ourstudytakestotally9apcatechniques and heuristics based on static code features into consideration which can be classified from two aspects as mentioned in introduction.first itcanbecategorizedbywhetheritrequirestheoracle patch.thiscorrespondstotwodifferentapplicationscenarios those do not require oracles can be integrated into patch generation process and thus help to increase the precision of apr tools while thoserequireoraclesareusuallyusedfor patch evaluation that istohelpassesstheeffectivenessofaprtechniques.second itcan beeitherdynamicorstatic whichisdifferentiatedbywhetheritneeds to execute test cases.
table 1lists the categorized selected techniques and the following presents the detail of each of them.
970simple test case generation theintuitionofthismethodis straightforward sincemostoverfittingpatchesaregenerateddueto theinadequacyoftestsuitesprovidedbyreal worldprograms researchers proposed to utilize automated test generation tools to generate independent test suites based on the oracle program to examine whether patches are overfitting .
if a plausible patch fails in any of these test cases it is detected as overfitting.
followingthepreviousstudies inourexperiment weselect randoop andevosuite as the test generation tools since they are widely used in software testing tasks .
difftgen difftgen is a tool that identifies overfitting patches throughtestcasegeneration .thetoolemploysanexternaltest generator i.e.
evosuite togeneratetestinputwhichisdesigned touncoverthesyntacticdifferencesbetweenthepatchedandthe originalbuggyprogram notethatthisisthedifferencebetweenthis toolandsimpletestcasegeneration wherethetestsaregenerated randomly .
to achieve so difftgen creates an extended version of the patched program with dummy statements inserted as thecoverage goals to advocate test generator.
when executing thegenerated test inputs on the buggy and the patched programs if the output of the patch is not the same with that of the oracle it is regarded as overfitting.
daikon some recent studies concentrate on applying program invariant to apr tasks .
specially yang et al.
focus on the impacts on program runtime behaviors from different patches .
they found that a large amount of overfitting patches willexposedifferentruntimebehaviors capturedbydaikon aninvariantgenerationtool comparedwiththeircorresponding correct versions.
based on their findings in this study we adopt a simpleheuristicthatistoseeiftheinferredinvariantofageneratedpatchisdifferentfromthatoftheoracleprogram.ifdifferenceexists wethenconsideritasoverfitting.intherestofthispaper weuse daikonto represent this method.
opad opadusesfuzzingtestingtogeneratenewtestcasesbased on the buggy program it then uses two predetermined oracles thatpatchesshouldnotintroducenewcrashormemory safetyproblems to detect overfitting patches .
to apply it on java we adopt the method provided by a recent study that is to uniformly detect whether a patch introduces any new runtime exception on test runs.note thattheoriginal fuzztechnique doesnotwork onjava programs.
as a result in this study we use randoop and evosuite to generatetest caseson thebuggy programsand denotethem as r opadande opadrespectively.
patch sim patch sim isasimilarity basedpatchvalidation technique which does not require the oracle information.
it firstutilizesatest generationtool randoopintheoriginalstudy to generate new test inputs.
it then automatically approximates without the oracle under the hypothesis that tests with similar executionsarelikelytohavethesameresults.finally itusesthe enhancedtestsuitetoassesspatchcorrectnessconsideringthata correct patch may behave similarly on passing tests while differ ently on failing tests compared with the buggy program.
in our study to better explore the performance of this technique we also implemented another version of this tool by replacing the adopted randoopwithevosuitefortestgeneration.weuse e patch sim to represent our evosuite based patch sim .anti patterns anti patterns isoriginallydesignedforclanguage .
the authors defined seven categories of program transformation fordetails cf.table1in .toapplyitonjava we followthestrategyadoptedbyarecentstudy thatisifthecode transformation in the patch falls into any category it is considered as overfitting.
static codefeatures many studies have proposed to leverage static code features to prioritize correct patches over overfitting ones and a recent study demonstrates the effectiveness of these features.
for instance ssfix proposed to utilize thetoken based syntax representation of code to identify syntaxrelated code fragments with the aim to generate correct patches.
s3proposed six features to measure the syntactic and semantic distance between a candidate solution and the original buggy code andthenleveragedsuchfeaturestoprioritizeandidentifycorrectpatches.thesefeaturesarenamedas astdifferencing cosine similarity localityofvariablesandconstants modelcounting output coverageandanti patterns.
capgenproposedthreecontext aware models to prioritize correct patches over overfitting ones which arethegenealogymodel variablemodel anddependencymodelrespectively .
although such features are often used to prioritize overfittingpatchesduringpatchgeneration westillincludetheminthisstudywiththeaimtoinvestigatepatchcorrectnessassessment from the view of static features.
note that for s3 the proposed model counting can only be applied to boolean expressions and output coverage can only be applied to program by examples based apr.therefore theycannotbegeneralizedtoallthepatchesgenerated by a wide range of apr techniques.
besides anti patterns is used as a stand alone technique in this study.
as a result we exclude those features for s3in this study and table 2displays the detailsoftheselectedeightfeaturesintotal.wefollowtheoriginal studies to compute the values for each feature and we do not list the formulas in detail due to page limit.
.
.
exclusion.
inour study wealsodiscard somemethodsthat have been exploited by previous studies.
wenotethatresearchersalsoutilize agitarone anothertest generation tool which is reported to be able to achieve code coverage togeneratetests .wedonottakeitintoconsiderationsinceitisacommercialproduct.
katch andklee ar e both test generators which leverage symbolic execution and can achieve high coverage.
we discard them since they only supportc language currently while we focus on java.
unsatguided is a method that utilizes test case generation to alleviate overfittingin test suite based program repair .
we discard this method since that it only works for synthesis based repair techniques such asnopol andthuscannotbegeneralizedtoawiderangeofapr techniques selected inthis study.
arecent studyalso utilizes code embedding technique toidentify correct patches .
however it requirestremendouseffortstotraintheembeddingmodelandthusisdiscardedinthisstudy.besides wenotethatyeetal.proposedtouse4 199staticcodefeaturestoidentifyoverfittingpatchesrecently .
however their tool and data is not publicly available.
besides theirproposedfeaturesareatomiconeswhichareencodedatthe levelofastwhilethoseselectedinthisstudyarehigh levelfeatures used to encode code syntax and semantics.
therefore we exclude this method in our empirical study.
we also note there are many 971table static code features used to prioritize correct patches over overfitting ones shortname metric source description tokenstrct structural token similarity ssfix the similarity between the two vectors representing the structural tokens obtained from the buggy code chunk and the generated patch.
tokenconpt conceptualtokensimilarity ssfix thesimilaritybetweenthetwovectorsrepresentingtheconceptualtokensobtainedfromthebuggycodechunkandthegeneratedpatch.
astdist ast difference s3 the number of the ast node changes introduced by the patch.
astcosdist cosine similarity distance s3 one minus the cosine similarity between the vectors representing the occurrences of distinct ast node types before and after the patch.
variabledist localityofthevariablesand constantss3 the distance is measured by the hamming distance between the vectors representing the locations of variables and constants.
variablesimi variable similarity capgen the similarity between the variables involved in the original buggy code element and the applied patch.
syntaxsimi genealogy similarity capgen the similarity between the syntactic structures the ancestor and sibling nodes of the corresponding ast of the original buggy codeelements and the applied patch.
semanticsimi dependency similarity capgen thesimilaritybetweenthecontextualnodesaffectedbythebuggycodeelementsandtheappliedpatchwithrespecttotheirdependencies.
other test generation tools in the literature such as jcrasher andtestful .wediscardthemsincetheyarenotthestate ofthe artandmanyofthemarenolongermaintained e.g.
testful .
our selected subjects i.e.
randoop andevosuite are the most widely used open source tools to generate tests .
.
patch selection this section presents the large scale patches selected in our study.
.
.
patch benchmark.
in this study we focus on the patches generatedforawidelyusedbenchmarkbyexistingaprtechniques which is defects4j .
specifically we select all the patches prepared by a recent large scale study where apr systems are evaluated under the same configuration.
to better explore the overfitting problem we also include patches collected by ye et al.
that were not included in including the ones of jaid sketchfix capgen sofix andsequencer .
the following two steps are performed based on the selected patches.
first we removed those patches generated for mockito assimilarlyadoptedby sincesomeofourstudiedsubject e.g.
randoop cannotgenerateanyvalidtestforthisproject.second we performed a plausibility check to see whether the selected patches are indeed plausible i.e.
can be compiled and pass all the original test suite .
to achieve so we ran each patch on the original testsuites again.
in total we discarded patches after the two steps 2generatedfor mockitoand6failedintheplausibilitycheck we haveconfirmedthiswiththeauthorsof .ourpatchbenchmark is large scale this benchmark contains in total patches for correctness assessment and such a number is around more thantherecordingnumber i.e.
contains713examinedpatches for correctness in the literature.
of high coverage w.r.t apr tools this benchmark contains the patches generated by distinct apr tools which can be mainly divided into four categories namely heuristic based constraint based template based and learning based assummarizedbyarecentstudy .table3showsthedetailed informationoftheseaprtools.
ofhighcoveragew.r.tdistinctbugs this benchmark contains the patches generated for different bugsindefects4j accountingforoverhalfofthebugsinthedataset .suchahighcoverageprovidesgreatpatchdiversityfor evaluation.
although the learning based category contains only sequencer it contains patches in total which is almost the largest number for a single apr tool.
.
.
patch sanity check.
the precise oracle information of the selectedpatches i.e.
whetherapatchisoverfittingorcorrect is criticalinfairlycomparingtheeffectivenessofapcatechniques.
thelabelinformationoftheaforementionedcollectedpatchesis annotated by the associated researchers manually.
however astable covered apr tools in our benchmark.
category apr tools for java programs heuristic basedjgenprog jkali jmutrepair simfix arja genprog a kali a rsrepair a capgen .
constraint baseddynamoth nopol acs cardumen jaid sketchfix .
template based kpar fixminer avatar tbar sofix .
learning based sequencer .
previous studies have pointed out author annotation may produce wrong labels due to subjectivity i.e.
assessing an over fitting patch as a correct one .
to reduce such bias in our study we further performed a sanity check to examine the correctness of the collected patches.
to achieve such a goal we followed the strategies adopted by a recent study .
specifically we adopted randoop and evosuite to generate extra test cases automatically basedontheoracleprogramofthebug theprogramafterapplying the developer provided patch and then executed such extra tests againstthepatchedversioncollectedinourdatasetthataremarkedascorrectbytheauthors.wethenexaminediftherewereanygener atedtestthatpassedontheoracleprogrambutfailedonthepatched version.suchcasesindicatedthatthepatchannotatedascorrect by the authors might be actually overfitting.
therefore we further manuallycheckedeachofthem toseewhethertheyareoverfitting via understanding the programs.
three authors were involved and the process ended when they reached consensus.
a patch is still consideredascorrectifthreeauthorsadmititiscorrect.otherwise we sendthe patchwith thegenerated teststo theoriginal authors tosee iftheyagreewith ourjudgement.wedeema correctpatch in our dataset is actually overfitting if the original authors also confirm with our judgment.
in total our sanity check identified patches that are mistakenly labeled as correct.
due to page limit wedonotanalyzethe12cases inthispaper.detailscanbefound in our project page at aftertheprocessofthesanitycheck thepatchescanbeprecisely classified to correct patches which are denoted as pcorrect and overfittingpatches whicharedenotedas poverfitting .intotal there are 654poverfitting patches and pcorrectones.
.
research questions basedontheselectedapcatechniquesandthepreciselylabeled patches i.e.
poverfitting andpcorrect weseektoanswerthefollowing research questions rqs with the aim to investigate and enhance the effectiveness of existing assessment techniques rq1 how effective are existing static code features in prioritizing correct patches?
we first systematically investigate the effectiveness of each individual static code featureas summarized in table 2in prioritizing correct patches over overfittingones.to answerthisquestion wecomputethe valueswithrespecttoeachofthemforallthepatches andthen 972compare whether the values obtained over the correct patches aresignificantdifferentfromthoseobtainedovertheoverfitting ones.ifsignificanceobserved thedesignedfeatureispromisingindifferentiatingcorrectpatchesfromoverfittingones.besides we also investigate whether the effectiveness of existing featuresareaffectedbydifferentprojectsordifferenttypesofapr tools.
answering such a question can guide us better apply existingtechniquestodifferentdomains andunderstandtowards which direction should existing techniques be improved.
rq2 how effective are existing techniques in identify ing overfitting patches?
we systematically investigate the performanceofthestate of the artapcatechniquesondetect ingoverfittingpatches andwhethertheyarecomplementarytoeach other.
this question is rather essential to provide valuableguidanceforthedesignoffuturemethods.specifically wemea sure theprecision and recallto answer thisquestion which aredefinedbythefollowingmetrics truepositive tp anoverfitting patch in poverfitting is identified as overfitting.
false positive fp acorrectpatchin pcorrectisidentifiedasoverfitting.falsenegative fn anoverfittingpatchin poverfitting is identified as correct.
true negative tn a correct patch inpcorrectis identified as correct.
precision tp tp fp recall tp tp fn ithasbeenemphasizedbyrecentstudies thatapca techniques need to avoid dismissing correct patches.
therefore we conjecture an apca technique effective if it can generate few false positives while preserve a high recall.
as mentioned insection .
existingapcatechniquescanbecharacterized in different aspects such as dynamic orstatic with oracle or without oracle.
in this rq we will also investigate the effects of such design spaces on the effectiveness of existing techniques.
rq3.
can we enhance the effectiveness of existing tech niques via integrating static features and dynamic tech niquestogether?
basedontheexperimentaloutputsobtained from the previous rqs we further seek to investigate whether combining static and dynamic techniques can achieve better performance in identifying overfitting patches.
.
experiment settings alltheexperimentswereperformedonthesameconfiguredservers withubuntu18.04x64osand16gbmemory.thefollowingpresents the experimental details for each research question.
.
.
rq1 rq2.
static techniques the four static tools are described in section .
.
.
specifically to apply anti patterns on java we follow the heuristic adopted by a recent study that is to manually check whether the patches generated by existing aprtoolsfallintothesepatterns.ifageneratedpatchbreaksany predefined anti pattern rule it is considered as overfitting.
for the otherthreeapproaches wecalculatethevalueofeachindividual featureasdescribedintable .then for ssfixands3 thesumof the features is used as the final result while the multiplication is used forcapgen as adopted by the original paper .
evosuite randoop werunthesetoolsontheoracleprogram to generate tests with different seeds with a time limit of 300seconds by following previous studies .
after collecting those test cases we run them over the oracle program to eliminate the impact of flaky tests .
any test that fails on the oracle programwillberemovedfromourtestsuite.followingtheprevious studies westopthisprocessifalltheoraclepatchespass thewholetestsuiteforfivetimesconsecutively notethatthesanity check introduced in section .
.2also went through such a check .
afterthisprocess weobtainatestsuitewithmostflakytestsbeing removedandthenexecutetheautomatedgeneratedpatchesagainst it.
a patch is considered as overfitting if it fails any of the test case.
notethatfor125bugsinourstudy wedirectlyreusethe evosuite tests generatedby ye etal.
sincethey have alreadygenerated tests for the bugs and removed the flaky tests.
details of these bugs can be found in our replication package.
r opad e opad theexperimentalsettingofthesetwotools issimilartothatofrandoopandevosuite.thedifferenceisthatthe test cases are generated based on the buggy programs since opad doesnotrequiretheoracleinformation.instead whenexecuting the generated tests on the patched programs a patch is considered as overfitting if it introduces any runtime exception.
difftgen difftgen leverages evosuite togeneratetestcases.
inourexperiment weexecute evosuite for30timesandthesearchingtimeissetto60secondsforeachround.weusesuchsettings since it is reported that such a combination is the optimum .
patch sim e patch sim we note that the performance of our server is lower than that used in the original study.
we thus follow the instruction in the project page of that is to increase thetimeoutlimit 3minutesinoriginalstudy to5minutes.both patch sim ande patch sim requiretwothresholdstoclassifythe generated tests into passing or failing tests k t and the generated patchesintocorrectoroverfittingones k p .weadoptthepredefineddefaultvaluesasusedin .inthisstudy wedonotexplore the setting of different thresholds since it has been illustrated in that the impact from different thresholds is limited.
daikon runningdaikonisextremelytime consuming .to speedupthepro cess and reduce unnecessary computation in our experiment we only infer invariants by executing test classes that containthefailingtestcases asadoptedbythepreviousstudy .
.
.
rq3.
to answer rq3 we first integrate the eight static featuresasdisplayedintable 2usinglearning to rank strategies.learningtoranktechniquestrainamachinelearningmodelforarankingtask whichhasbeenwidelyusedininformationretrievaltasks.
we then integrate the learned model with dynamic techniques via themajority voting strategy .
to integrate static features we select six widely used classification models in our study including random forest decision table j48 naive bayes logistic regression and smo .
these are popular classificationmodelsthatarewildlyusedbyexistingstudies .
werandomlyseparatethepatchbenchmarkinto10foldswith identicalnumberofcorrectandoverfittingpatchesineachfold.we then use fold cross validation to evaluate the performance of each model.
the final performance of each model is summedup over the rounds of each training and testing process.
note thatourpatchbenchmarkisimbalanced thenumberofoverfitting patches is around three times as much as that of correct ones we thusadoptthestrategyof cost sensitivelearning toincreasethe lossofgeneratinganfpto3timesofthatofgeneratinganfn.since a tokenstrct b tokenconpt c astdist d astcosdist e variabledist f variablesimi g syntaxsimi h semanticsimi figure1 measurementsonoverfittingpatchesandcorrectpatches for different static code features cross different projects the bar denotes the correct patches while the white bar denotes the overfitting patches.
c t chart time cl closure l lang m math the fold cross validation involves randomness we repeated this process for times and results suggest that the impact caused by therandomnessislimited.forinstance themedianoftpgenerated byrandom forest is with a standard deviation of .
while the median of fp is .
with a standard deviation of .
.
we thus report the result of the first experiment in this paper.
to combine with dynamic techniques we select the model with the optimum performance and integrate it with dynamic ones usingthestrategyofmajorityvoting.asclassifiedintable there are two types of dynamic techniques the one with the oracle information and the other without.
however static code features aredesignedwithouttheinformationoforacle.tointegratewith thosetechniquesrequiretheoracleinformation wealsoconduct another experiment to leverage the oracle information for staticfeatures.
specifically we re compute all the feature values based on the generated patch and the oracle patch in the original experiment thefeaturevaluesarecomputedbasedonthebuggyprogramandthegeneratedpatch andthenadoptthesamemethodologyasdescribedabovetointegrateallthestaticcodefeatures.finally the model learned with the oracle information is combined with the dynamic techniques that require the oracle information.
study results wenowprovidetheexperimentaldataaswellasthekeyinsights distilled from our research questions.
.
rq1 effectiveness of static code features figure1shows the measurements over overfitting patches and correct patches with respect to each individual code feature aggregatedbydifferentprojects.sincethenumberofpatchescollected forprojecttimeisnotsufficientforstatisticaldifferencetesting i.e.
onlysixpatchesintotal wecombinedthepatchesinprojecttime andchart anddenotedthemas c t inthefigures.wecansee thatforfeatures tokenstrct tokenconpt variablesimi syntaxsimi andsemanticsimi the values obtained over correct patches are generallyhigherthanthoseobservedoveroverfittingones.such a tokenstrct b tokenconpt c astdist d astcosdist e variabledist f variablesimi g syntaxsimi h semanticsimi figure2 measurementsonoverfittingpatchesandcorrectpatches for different static code features cross different apr techniques the bar denotes the correct patches while the white bar denotes the overfitting patches.
c constraint based apr h heuristic based apr le learning based apr t template based apr resultsindicatethatcorrectpatchesaremorelikelytopreservehigh similaritieswithrespecttotheirsyntaxandsemanticscompared with the buggy program.
for features astdist astcosdist and variabledist thevaluesobtainedovercorrectpatchesaregenerally lowerthanthoseobservedoveroverfittingones.suchresultsreveal thatcorrectpatchesoftenmakeasmallnumberofmodifications i.e.
as measured by astdist and do not often change the locationsofvariables constants i.e.
asmeasuredbyvariabledist as compared to overfitting patches.
toinvestigatewhethersuchdifferencesobservedbetweencorrect and overfitting patches are significant we further performed a one sided mann whitney u test on the results collected from each project and table 4displays thep values.
aswe canseefrom thetable formostofthe cases thedifferencesaresignificant i.e.
p value .
whichindicatesthatexistingstaticcodefeatures areeffectiveindifferentiatingoverfittingpatchesfromcorrectones.however the measurements over the lang projects with respect tosixoutoftheeightfeaturesareinsignificant.sucharesultindicates that existing features are less effective to prioritize patches generatedforprojectlang.wefurtherinvestigatedthebehindreasonandfoundthatthebuggylocationsofthisprojectaremostlyconcerned withconditionexpressions andtheoverfittingpatchesareoften generatedviamodifyingoperatorsinsuchexpressions.listing showssomeexamplesofsuchoverfittingpatches.unfortunately existingcodefeaturesareunabletocapturethecharacteristicsof suchdifferencesembeddedinoperators.asaresult thedifferences measuredovertheoverfittingpatchesandthoseoverthecorrect patches are insignificant.
an overfitting patch generated for lang by jmutrepair if math.abs u math.abs v if math.abs u math.abs v an overfitting patch generated for lang by tbar if ch y if ch y listing overfitting patches generated for the lang project 974table p values over all the static code features feature nameprojects types of apr technique c t cl l m c h le t tokenstrct .
.
.
.
.
.
.
.
tokenconpt .
.
.
.
.
.
.
.
astdist .
.
.
.
.
.
.
.
astcosdist .
.
.
.
.
.
.
.
variabledist .
.
.
.
.
.
.
.
variablesimi .
.
.
.
.
.
.
.
syntaxsimi .
.
.
.
.
.
.
.
semanticsimi .
.
.
.
.
.
.
.
.
denotes the p value is less than .
table effectiveness of each apca technique.
apca tp fp tn fn precison recall evosuite .
.
randoop .
.
difftgen .
.
daikon .
.
r opad .
.
e opad .
.
patch sim .
.
e patch sim .
.
anti patterns .
.
s3 .
.
ssfix .
.
capgen .
.
the green cell denotes the technique requires the oracle information.
the bold name means the technique is dynamic.
for these tools results might not be generated for certain patches.
the reasons for non result generation are explained in detail in this section.
we performed similar analysis with respect to different types ofaprtechniques.figure 2showstheresultsandtable 4shows thecorrespondingp values.aswecanseefromthefigures similar resultscanbeobservedcomparedwiththoseobtainedwithrespect todifferentprojects.specifically existingstaticcodefeaturesare generallyeffectiveinprioritizingoverfittingpatchesovercorrect ones with respect to different types of apr techniques and thedifferences are mostly significant as shown in table .
however insignificanceisfrequentlyobservedforthosepatchesgeneratedbyconstraint based aprtechniques.weinvestigatedthebehindreason andfoundthatpatchesinthistypeoftenextendtheconditionof anifstatementwithrarenewvariablesinvolvedasshowninthe exampledisplayedinlisting .notethatthetokenlistinthispatch changes significantly compared with that of the buggy program.
therefore token based features are more effectivefor this type of patches as shown in table compared with other features that encode variables or the related semantics.
an overfitting patch generated for math by acs else if minratiopositions.size else if minratiopositions.size !
minratiopositions.size listing an overfitting patch generated by acs the systematic study on static code features reveals that existing staticcode featuresaregenerally effectivein differentiatingoverfittingpatchesovercorrectones thesefeaturesarelesseffectivetowardsprojectlangandconstraint basedaprtechniques while more effective with respect to other types of patches.
.
rq2 effectiveness of apca techniques .
.
evaluation results.
table5shows the detection results of each apca technique on our patch benchmark.
as indicated by the results among all the overfitting patches existing dynamicapca techniquescan identify adiversenumber of them ranging from to for different techniques.
for instance evosuite identified overfitting patches .
of the poverfitting while italsolabeled3correctpatchesasoverfitting daikonidentified337 overfittingpatcheswhileitproduced38falsepositives.besides our twoimplementationsof opad i.e.
r opadande opad generated no false positives but they detected the least number of overfitting patches.otherdynamictechniquesthatdonotrequiretheoracle information e.g.
e patch sim andpatch sim generated more numberoffalsepositives.thebehindreasonsofsuchfalsepositives for each technique will be discussed in detail subsequently.
figure overfitting patches dist.we also investigated the distributions of the overfittingpatches identified by different apca techniques and the results are shown in figure .
due to the space limit of the venn figure we do not include r opadande opadin thiscomparisonsincetheydetect the least number of overfittingpatches.actually these twotoolscanonlyuniquelydetect9and0overfittingpatches respectively.aswecanseefrom this figure only overfitting patches were detected by all thedisplayed techniques while substantial overfitting patches were detectedexclusivelybyspecifictechniques.forinstance 48overfitting patches can be detected by evosuite orrandoop that cannot bedetected byother techniques.in total bycombining allthe dynamic apca techniques plus anti patterns we can detect unique overfitting patches accounting for .
of the overfitting patchesinourbenchmark.suchresultsindicatethatconsidering multiple factors when designing apca techniques can achieve better performance.
heuristicsbasedonstaticcodefeaturesarenotdesignedasastandalone technique to identify overfitting patches directly.
however wealsolisttheresultsintable 5tocomparewithothertechniques.
specifically wecalculatedthevalueforeachpatch generatedby ssfix capgen ands3respectively asintroducedinsection .
.
andthenprioritizedallthepatchesbasedontheobtainedvalues andtheirrankingstrategies.thetop248patchesareclassifiedas correct patches and the remaining ones are regarded as overfitting ones thenumberof248isselectedsinceourpreparedpatchbenchmarkisunbalancedwhichonlycontains248correctpatches .as observed in table heuristics based on static code features identified more number of overfitting patches in general compared with dynamic ones.
however they are less precise as well since they generatedmorenumberoffalsepositives.forinstance although capgenclassified506patchesasoverfittingcorrectly italsolabeled 140correctpatchesasoverfittingones.applyingsuchtechniques willcausesignificantdestructiveeffects i.e.
dismissinganumberof correctpatches inwhichcase theeffectivenessof aprtechniques will be significantly under estimated.
.
.
analysis of the results.
we further performed a deeper analysis for the above results and the following presents our findings.
we carefully analyzed the false positivesgeneratedbyapcatechniquesandidentifiedthefollowing reasons.for evosuite itproduced3falsepositives i.e.
thepatches forlang 7generatedbyacs kpar andtbar whicharecausedby thefactthatthegeneratedtestshavebrokenthetargetprogram s preconditions.theoraclepatchforlang 7addsaconditionalstatement to deal with unexpected input in function createbigdecimal .
these three patches performed the correct modification as the oraclepatchbutinadifferentlocation inthefunction createnumber .
there exists a precondition of this program that createbigdecimal willonlybecalledby createnumber andthatiswhythesepatches arecorrect.
evosuite generatedteststhatviolatethisprecondition bycallingthefunction createbigdecimal directly.consequently the tests failed on the patched program and these patches are considered as overfitting.
for randoop it generated tests that check the version for bug closure as shown in listing .
these tests only pass on the oracle program and thus six generated correct patches failed on them.
a test case generated by randoop 2string str0 compiler.getreleaseversion 3asserttrue str0 !
d4j closure 115 fixed version str0.equals d4j closure 115 fixed version listing a test case generated by randoop fordifftgen besides generating the same three false positives asevosuite italso misclassified anothertwo correct patches.an example is shown in listing .acsgenerated a patch which is semanticequivalenttotheoraclepatchbythrowingthesameexception.
however it did not synthesis the thrown message i.e.
object must implement comparable .difftgen generateda test that checks whether the thrown messages of these two programs are identical.
as a result this correct patch is mislabeled.
fordaikon itintotalgenerated38falsepositivessincetherules adopted by daikonto affirm identical invariant is extremely strict.
note that daikoninfers invariant at every entry and exit points of the functions and if any differences is observed daikonwill label itas anoverfitting patch.specifically amongthe 38falsepositive cases 30ofthemconcerndifferentexitpointsoffunctionsand7 ofthemusedifferentprogramelementstofinishthesametarget.
note that if a function have multiple exit points daikonwill print the line number of each exit point in its output.
considering the example in listing line 6andline 12are the exit points of the oracleandpatchedprograms.theirlinenumberswithrespectto the whole program are different the former is while the latter is111 .thisleadstothedifferencesbetweentheoutputsof daikon andthusthiscorrectpatchismislabeledasoverfitting.anotheruncommon case is patch for lang generated by jaid.
the program callssystem.currenttimemillis during execution which generates differenttimestamps thuscausingdifferentinvariants.suchresults indicate that future work leveraging invariants to identify overfitting patches can consider to weaken the rules to compare identical invariants and also consider the characteristics of the inferred invariants and treat them differently when classifying patches.
oracle patch for math 2public void addvalue object v if v instanceof comparable ?
addvalue comparable ?
v else throw new illegalargumentexception object must implement comparable a correct patch for math by acs 10public void addvalue object v if !
v instanceof comparable ?
throw new illegalargumentexception addvalue comparable ?
v test case generated by difftgen 15assertequals e c org.apache.commons.math.stat.frequency addvalue object i java.lang.illegalargumentexception object must implement comparable throwable target obj 7au3e .tostring listing an example of false positive of difftgen and daikon forpatch sim ande patch sim they generated87false positivesintotal.weobservedthatthesecasesaremajorlycausedby themisclassificationofthegeneratedtestsduetothecomplexity of the original developer provided test suite.
listing 5shows a concreteexample.thecorrectpatchaddsaconditionalstatementto dealwiththeunexpectedinput null.however theoriginalfailing testiscomplex whichfeedsthefunction getrangeaxisindex with diverseinputsthatcoverbothnormalandunexpectedinputs.such a complex test leads to a complex path spectrum of getrangeaxisindexduringexecution.
patch sim generatedatestcasewhich calls this function only with the input null leading to an extremely limitedpathspectrumonthismethod.asaresult thisgenerated test is misclassified as a passing test since the execution trace is divergent to that of the original failing test.
when determining the correctness of this correct patch the execution trace of this test on the buggy program in this function is lines and a return statement completelydifferentfromthatofthepatchedprogram whichislines3and4.consequently thistestleadstoanextremely high value of a p the distance of a passing test which is .
thus misclassifyingthepatchasoverfitting cf.section4.
.2in .similarpatternshavebeenobservedformostoftheotherfpcases thatisthedistancebetweenthepathspectrumobtainedviaexecutinga passingtestagainstacorrectpatchandthatobtainedagainstthe buggyprogramissignificantdifferent.thebehindreasonisthat thelogicofthedeveloper providedtestsuiteiscomplex.therefore utilizingtest case purification technique i.e.
separating thosenormalinputsfromabnormalonesintheexample ispromising to enhance the accuracy to classify the generated tests thus to enhance the effectiveness of patch sim.
a correct patch for chart by avatar 2public int getrangeaxisindex valueaxis axis if axis null throw new illegalargumentexception int result this.rangeaxes.indexof axis if result a test case classified as passing test 9int int18 categoryplot7.getrangeaxisindex null asserttrue int18 listing an example of false positive of patch sim foranti patterns we further dissected the effectiveness of eachruleadoptedbyit includingthedetectednumberofoverfitting patchesandthenumberoffalsepositivecases.wefindthatonly fiverulesareeffectiveindetectingexistingoverfittingpatchesin thejavalanguageandallthesefiverulesalsoproducefalsepositive cases which proves that applying these patterns will inevitably causecertaindestructiveeffects i.e.
dismissinganumberofcorrect patches as revealed by another study .
976table performances of existing apca techniques with respect to different projects and different apr techniques apca techniqueprecision recall c t cl l m htcl e c t cl l m htcl e evosuite .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
randoop .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
difftgen .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
daikon .
na .
.
.
.
.
.
.
na .
.
.
.
.
.
r opad .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
e opad .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
anti patterns .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
patch sim .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
e patch sim .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
the darker blue of the cell the higher value the darker orange of the cell the lower value we did not compare with static code features since they have been studied in rq1.
different project c t chart time cl closure l lang m math.different techniques c constraint based apr h heuristic based apr le learning based apr t template based apr wenotethat our experiment reports much more false positives of patch sim than the original study .
we carefully checked our results and confirmed that for the set of correct patches that are selected in boththetwostudies onlytheclassificationresultofonepatchis different.consideringtherandomizationof randoop weconjecture itisreasonable.therefore ourstudyexposesthethreatstoexternal validityofthepreviousstudy usingalarge scalebenchmark as mentioned in .
we also note that our experiment reports much more true positives of two implementations of opad and respectively than thenumber reported in .
thereason is that the test suite used in our experiment contains hundreds of tests for a patch rather than at most as adopted in .
certaindynamicapca tools did not generate results for certain patches for daikon i t cannotgenerateinvariantsfor closureprograms alsoreportedin 241casesintotal for patch sim ande patch sim theyrun outofheapspacewhenalargeamountoftestscoverthepatched method also reported in cases for patch sim and cases fore patch sim fordifftgen it does not work if the oracle patchdeletesamethod sinceitneedsanoraclemethodtocheck thecorrectnessofthepatch orifthetypesandvaluesoftheinputs and outputs of the patched method cannot be obtained since it needs these information to perform the check cf.
section .
.1in .
there are cases in total and we have confirmed these limitations with the authors of difftgen.
table6shows the results of existing apca techniques in terms ofprecisionandrecall inparticular separatedbydifferenttypesof apr techniques and different projects.
in terms of precision existingapcatechniquesaregenerallyachievinghighperformances crossdifferentprojectsandaprtools.specifically anti patterns patch sim ande patch sim achieverelativelylowerprecisionvalues which mostly vary from to .
other techniques achieve better performances which are mostly greater than and for .
of the cases the precision achieved is .
.
in terms of recall the performance of existing apca techniques divergesalotcrossdifferentprojectsandaprtechniques.specifically the recalls achieved over projects chartandtimeare generallyhigherthanthatovertheotherprojectswhiletherecallof projectclosureisthelowest.itiscausedbythefactthatthetest suites on closure often achieve low coverage while dynamic techniquesrelyheavilyonthequalityofthegeneratedtests.therecalls achieved over the learning based apr technique i.e.
sequencer aregenerallylowerthanthatovertheothertypesofapr techniques.
especially we found three apca techniques achieved ratherlowrecallsonthistypeofpatches i.e.
randoop daikon and anti patterns .
we observed the following reasons for randoop the test suite generated for the bugs of this type of patches gen erally achieve low coverage for anti patterns learning based aprseldom generatepatches viacode transformationthat canbe captured by the patterns for daikon the variables modified by the patches are generally not the return values in which case their changesarerarelycapturedbytheinferredinvariants.suchresults indicatesthatexistingtechniquesare comparativelylesseffective inidentifyingoverfittingpatchestowardslearning basedaprtech niques.overalloursystematicstudyoftheeffectivenessofexisting apca techniques reveals that most of the dynamic apca techniques will label correct patches asoverfittingwhilethosewiththeoracleinformationaregeneratingafewernumberoffalsepositives i.e.
fewerthan10.
existing apcatechniquesarehighlycomplementarytoeachothersincea singletechniquecanonlydetectatmost53.
overfittingpatches while93.
oftheoverfittingonescanbedetectedbyatleastone techniquewiththeoracle heuristicsbasedonstaticcodefeatures canachievehigherrecallsbutarelessprecisebygeneratingmore number of false positives existing apca techniques are less effectivetowardsprojectclosureandlearning basedaprtechniques while more effective with respect to other types of patches.
.
rq3 learning integration previous findings reveal that static features can achieve high recall whiledynamictechniquesaremoreeffectivetowardsprecision and existingtechniquesarehighlycomplementarytoeachother.therefore it motivates us to integrate existing techniques together to take the advantage of each side s merits.
.
.
integrating static code features.
table7showstheresultsof our method to integrate all the static features via learning through sixmachinelearningmodels.fromtheresults randomforest isthe most effective model since it achieves the highest recall while still maintaining a relatively high precision for the two experimental settings.inparticular forthesettingwithouttheoracleinformation itachievesahighrecallof89 .
whilepreservingahighprecision of .
.
we find that our model achieves better performance than a single tool e.g.
random forest generates more tp with 977table effectiveness of each training model based on the eight static features with and without the oracle information decision table j48 logisticregression naivebayes randomforest smo without with without with without with without with without with without with tp fp precision .
.
.
.
.
.
.
.
.
.
.
.
recall .
.
.
.
.
.
.
.
.
.
.
.
theoptimum performance is displayed in bold.
without means the oracle patch is not available.
with means the oracle is available.
the same as table .
table integration results with and without the oracle strategy tpfp precision recallwithoutpatch sim .
.
anti patterns .
.
integration with the learned model .
.
patch sim e patch sim anti patterns .
.
withevosuite .
.
randoop .
.
integration with the learned model .
.
evosuite randoop daikon .
.
fewer fp than ssfix capgen ands3as shown in table .
for instance comparedwith s3 themosteffectiveoneamongthethree the precision and recall have been improved by .
and .
respectively.thissuggeststhatintegratingdiversestaticfeatures via learning to identify overfitting patches is a promising future direction.
we also find that the oracle information can boost the effectivenessofallthemodelsviaachievingbothahigher precision andrecall.forinstance forthemodelof randomforest thenumber of tp has been increased by while the number of fp has been reducedby23.sucharesultindicatesusingsuchmodelstofacilitate the evaluation of apr techniques is promising.
.
.
integrating with existing techniques.
we choose the most effectivemodel randomforest tointegratewithdynamictechniques andanti patterns .ourintuitionisthattheycanguaranteethe precisionwhilethetrainedmodelcanhelpenhancetherecall.asis wellknown dynamicmethodscanbeextremelytime consuming and thus we only consider the top two most effective techniques among dynamic ones and anti patterns for integration currently.
specifically for the scenario with the oracle information we integrate our trained model with the oracle information withevosuite andrandoop.
for the scenario without the oracle information we integrate our trained model without the oracle information with patch sim andanti patterns .
we adopt the majority voting strategy that is a patch is considered as overfitting ifithasbeenlabeledasoverfittingbyatleasttwooutofourconsidered techniques.
table 8shows the results which indicates that the effectiveness of existing apca techniques can be significantly enhanced via integration.
specifically for the scenario without the oracle information while preserving a low fp of the tp can be improved from 249to thus achievinga higher recall .
vs. .
.
for the scenario with the oracle information while preservingahighprecisionof99 .
therecallcanbeimproved from .
to .
.
to show the contributions of the learned modelintheintegrationstrategy wealsocomparedwiththeresultsobtainedbyintegratingthethreemosteffectiveexistingtechniques via the majority voting.
the results are shown in the last row of each experimental setting which indicate that without the learningmodelbasedonstaticcodefeatures theeffectivenessofidentifyingoverfittingpatchesisgreatlycompromised.forinstance ifweinte grate evosuite randoop anddaikon wecanonlyachievearecallof .
even lower than a single method like evosuite .
such resultsreflecttheusefulnessofstaticcodefeatures.ourintegration strategy reveals that combining static features via learning significantly outperforms existingheuristicsbasedonstaticcodefeaturesandthusisapromising direction for both patch generation and patch evaluation integrating static features with existing techniques can take the advantageofeachside thusachievingahigherrecallwhilepreserving a high precision.
therefore it is a future direction worth exploring.
threats to validity externalvalidity.
ourstudyonlyconsidersthepatchesgenerated by java apca techniques on the defects4j benchmark.
thus allfindingsmightbeonlyvalidforthisconfiguration.nevertheless this threat is mitigated by the fact that we use a wide range of state of the art apcatechniquesand a most comprehensive patch benchmark so far.
internalvalidity.
itiserror pronetoperformsuchalargescale study and some of our findings may face the threats from the way weperformedtheexperiments.wemitigatethisbyre checkingthe processofourexperimentformanytimesandidentifyingthebehindexplanationforeachresult.besides wehavereportedsomeofourresultstoauthorsof andobtainedpositivefeedback.
construct validity.
the parameters involved in this study may casteffectsfortheresults.wemitigatethisbystrictlyfollowingthe previous studies.
for instance we run simple test case generation toolsfor30seedsbyfollowing andadoptthedefaultvalues of k tand k pfrom for patch sim ande patch sim.
conclusion this paper performed a large scale study on the effectiveness of state of the art apca techniques and heuristics based on staticcodefeatures basedonthelargestpatchbenchmarksofar.
effectivenessisevaluatedandcomparedwithrespectto precision andrecall.
our study dissects the pros and cons of existing approachesaswellaspointsoutapotentialdirectionbyintegrating static features with existing methods.
artefacts all data in this study are publicly available at