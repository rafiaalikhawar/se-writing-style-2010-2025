harp holistic analysis for refactoring python based analytics programs weijie zhou wzhou9 ncsu.edu north carolina state university raleigh ncyue zhao yzhao30 fb.com facebook menlo park ca guoqiang zhang gzhang9 ncsu.edu north carolina state university raleigh ncxipeng shen xshen5 ncsu.edu north carolina state university raleigh nc abstract modern machine learning programs are often written in python with the main computations specified through calls to some highly optimized libraries e.g.
tensorflow pytorch .
how to maximize the computing efficiency of such programs is essential for many application domains which has drawn lots of recent attention.
this work points out a common limitation in existing efforts they focus their views only on the static computation graphs specified by library apis but leave the influence from the hosting python code largely unconsidered.
the limitation often causes them to miss the big picture and hence many important optimization opportunities.
this work proposes a new approach named harp to address the problem.
harp enables holistic analysis that spans across computation graphs and their hosting python code.
harp achieves it through a set of novel techniques analytics conscious speculative analysis to circumvent python complexities a unified representation augmented computation graphs to capture all dimensions of knowledge related with the holistic analysis and conditioned feedback mechanism to allow risk controlled aggressive analysis.
refactoring based on harp gives .
3x and .07x average speedups on a set of tensorflow and pytorch programs.
ccs concepts software and its engineering automated static analysis data flow architectures computing methodologies machine learning .
keywords machine learning program computation graph dynamic language program analysis acm reference format weijie zhou yue zhao guoqiang zhang and xipeng shen.
.
harp holistic analysis for refactoring python based analytics programs.
in permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
copyrights for components of this work owned by others than acm must be honored.
abstracting with credit is permitted.
to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
request permissions from permissions acm.org.
icse may seoul republic of korea association for computing machinery.
acm isbn .
.
.
.
international conference on software engineering icse may seoul republic of korea.
acm new york ny usa pages.
introduction for machine learning applications computing efficiency is essential for the growing scale of datasets and the needs for timely responses in various applications.
a pattern common in today s analyticsapplications ispython x where main computations are written with apis of some libraries x e.g.
tensorflow pytorch while the host code is written in python which connects all pieces together.
we call them python based analytics programs.
such programs have some common features.
we draw on tensorflow as an example for explanation.
like some other packages tensorflow was initially introduced for a specific scope deep learning but then evolved for a broader scope analytics and scientific computing .
at its core tensorflow builds on the dataflow programming model.
in developing a tensorflow program a devel oper writes code by calling tensorflow apis to specify the intendedcomputations and makes a call to the tensorflow runtime.
the call triggers the execution of those apis which constructs a computation graph the tensorflow runtime optimizes the graph and then executes it.
this approach represents one of the popular programming paradigms used by modern machine learning and analytics frameworks.
the recent years have seen a number of efforts for enhancing the performance of python based analytics programs.
for example the xla project and the r stream tf project try to improve the runtime performance of tensorflow by utilizing compiler techniques to transform dataflow graphs e.g.
fusing multiple operations .
however despite the many efforts a large room for performance improvement is left elusive for current optimizers to harvest.
we be lieve that one of the fundamental reasons is that current efforts have all focused on the dataflow graphs embodied by the invocationsof library apis in a program.
although dataflow graphs usually capture the core computations of an analytics program limiting the view on them may lose the big picture that the host code provides and hence many large scoped optimization opportunities.
listing offers an example.
this codelet is part of the core computations in deep dictionary learning .
the firstfive lines of the code specify the core computations and hence the structure of ieee acm 42nd international conference on software engineering icse icse may seoul republic of korea weijie zhou yue zhao guoqiang zhang and xipeng shen the dataflow graph.
line defines aas a variable as its value needs to be updated through the execution lines and define dandx as place holders for they will hold the input values line specifies the formula for calculating the new value of athrough a series of calls to the high level tensorflow mathematics functions line specifies an update to awith the new value.
line is a python loop statement and line calls tensorflow api sess.run a blocking api to invoke tensorflow runtime to actually construct the dataflow graph and execute it it passes the actual parameters d andx to the two place holders.
the following pseudo code shows what the codelet implements f or i iter a d x dta where each of the capitalized letters represents a multidimensional array called a tensor and dandxare input tensors and remain constant across the loop iterations.
the implementation by the codelet in listing contains some redundant computations which can be seen if we expand the mathematical formula in the pseudo code to dx ddta.
because terms dxandddtare invariant across the loop iterations they can be hoisted outside the loop computed once and reused for all iterations as shown as follows t1 dx t2 ddt f or i iter a t1 t2a even though the redundant computations are not hard to see at the pseudo code level it cannot be recognized or optimized by either tensorflow or any of the previously proposed optimizers designed for tensorflow programs.
moreover even if we rewrite the code to better expose the redundancy as in listing prior optimizers still cannot detect the redundant computations.
the reason is that all these tools focus only on the dataflow graph composed through the tensorflow apis while the redundancy comes from the interplay between those tensorflow api calls and the other python code that hosts those calls.
take listing for instance without analyzing the host python code it is impossible to tell that d and x are invariant across the forloop and hence dxandddtare also loop invariants as the computation graph does not capture the loop in the host code and its relation with the data in the graph.
on the other hand general python codeoptimizers cannot find out the redundancy either as they do not understand the necessary semantics of the tensorflow apis.
other examples include partially repeated computations involved two separate api calls the mis use of computation graph construction apis as computation apis in a loop and causing millions of graph nodes to be generated unnecessarily see section .
.
this work proposes a new approach named harp holistic analysis for refactoring python based analytics programs to address the problem.
we next gives an overview of harp the main challenges and our contributions.
overview of harp to overcome the aforementioned limitation of existing tools an initial option we considered was to create an automatic static code optimizer with a holistic view.
it is however impractical python is alisting example from deep dictionary learning tf forthe namespace of tensorflow a t f .
v a r i a b l e t f .
z e r o s shape dtype t f .
f l o a t d t f .
p l a c e h o l d e r shape dtype t f .
f l o a t x t f .
p l a c e h o l d e r shape dtype t f .
f l o a t r t f .
matmul d t f .
s u b t r a c t x t f .
matmul t f .
t r a n s p o s e d a l t f .
a s s i g n a r 6for iin range i t e r r e s u l t s e s s .
run l f e e d d i c t d d x x listing listing in a different form .
.
.
t t f .
matmul d x t t f .
matmul d t f .
t r a n s p o s e d r t f .
s u b s t r a c t t1 t f .
matmul t2 a l t f .
a s s i g n a r for iin range i t e r r e s u l t s e s s .
run l f e e d d i c t d d x x dynamically typed language the complexities of which listed later form some major barriers for static optimizers to work effectively.
a pure dynamic optimizer on the other hand is complicated to develop and causes runtime overhead and delays.
the strategy we finally took is to create a refactoring assistant which provides suggestions for developers to use in refactoring the code.
this strategy allows aggressive analysis on incomplete information.
even though the suggestions may not be always correct as the tool provides enough feedback on the assumptions it uses the developers can avoid the risks while taking advantage of the often correct suggestions.
harp is the first tool that enables holistic analysis that spans across dataflow graphs and their hosting python code.
harp achieves it through several novel features speculative analysis.
harp relies heavily on static analysis.
as a dynamically typed scripting language python poses many difficulties to static analysis such as unknown types operator overloading dynamic dispatch of higher order functions and so on.
harp circumvents the complexities with two key insights many python complexities rarely appear in analytics programs or can be ignored for those that do matter they can often be treated successfully through speculations on common patterns in analytics applications.
harp materializes the insights throughspeculative analysis.
uniform representation.
holistic analysis requires a coherent way with a uniform structure to represent the computations and relations attained from both the host and the computation graph.
the representation must be inclusive in the sense that it must contain necessary info from both the host and the library including necessary high level semantics e.g.
side effects expected tensor type of apis.
it at the same time must be amenable for automatic inferences for optimization opportunities.
harp introduces augmented computation graphs a uniform representation that augmentscomputation graphs with relations attained from the host code andsome light annotations of library apis.
it uses datalog as the media to create the coherent representation for holistic analysis.
informative and extensible interface.
harp employs a datalogbased interface such that code analysis modules can be simply 507harp holistic analysis for refactoring python based analytics programs icse may seoul republic of korea expressed in datalog rules in a declarative manner.
through the interface we equip harp with a set of predefined rules for detecting common inefficiencies on the augmented computation graphs.
the interface also allows users to easily extend harp with extra rules.
meanwhile we equip harp with a conditioned feedback mechanism through which harp gives users not only suggestions for coderefactoring but also the assumptions it holds in its speculations.
this feature helps control the risks of the speculative analysis and allows harp to offer likely useful suggestions despite language complexities.
to evaluate the efficacy of harp we implement it as a plugin of pycharm based on intellij1and develop the support for tensorflow and pytorch.
harp is effective in finding optimization opportunities that are elusive to prior techniques.
code refactoring based on the findings yield .
3x performance improvement on a gpu machine.
we further conduct a user study which helps confirm the productivity benefits of this refactoring tool.
we do not claim using datalog for program analysis as our contribution.
many previous papers have applied datalog for program analysis and shown promising productivity .
the key contributions of this work are four fold it points out the limited view of existing tools as a fundamen tal barrier to harvest important opportunities for refactoring modern machine learning applications for performance.
it provides several insights important for circumventing language complexities in machine learning applications andproposes ways to leverage common patterns in machine learning to enable effective speculative analysis.
it develops augmented computation graphs as unified way to host all dimensions of knowledge related with the holistic analysis.
it creates harp the first holistic analysis based tool for machine learning code refactoring and demonstrates its effectiveness in a range of applications.
the current implementation of harp focuses on supporting tensorflow and pytorch programs for their increasing popularity and also for their representatives of two paradigms in computation graph construction tensorflow builds static computation graphs while pytorch defines dynamic graph.
we next provide some background knowledge and then describe each part of harp in detail.
background this section presents background knowledge on tensorflow pytorch and datalog.
.
tensorflow a tensorflow program works in a define and execute way .
its execution first creates a computation graph which then gets optimized and executed by the runtime.
high level languages such as python are often used as the host language in defining the computations and low level languages such as c family languages are often used to implement the runtime system for the purpose ofperformance efficiency.
a tensorflow program can be regardedas a mix of two program components thefirst part called host codeapi tf systemexecute sessioncomputation graph figure high level relations among host code tf system and computation graphs.
program contains the computation that is directly executed by thefront end language.
the second part is the computation represented by the computation graph .
computation graphs.
in tensorflow the computation graph is a directed graph composed of a set of nodes and edges nodes instantiates operations e.g.
matrix multiply or sigmoid .
each operation can have zero or more inputs and zero or more outputs.
these operations get dispatched to devices cpu gpu by the runtime.
edges represent the values communicated between operations.
the most common types of values in tensorflow are tensors which are n dimensional arrays.
their elements can have one of the primitive types e.g.
int32 float32 or string .
tensors on edges are stateless and immutable.
there are some special nodes and edges.
for example a tf.variable creates a variable which represents stateful value and is mutable.
it is represented as a node in the graph carrying the variable name as its label.
in addition there are control dependency edges which indicate controls of the execution order of operations.
host program and graph execution.
in a typical tensorflow program the responsibilities of the host program include preparingdata for the computation hosting the api calls that define the computation graph and controlling its executions.
the host program interacts with computation graphs and the underlying tensorflow tf system through the session api.
it calls session.run which prompts the tf system to execute the computation graph.
the call may specify a set of output nodes whose values are to be fetched and a set of input tensors to be fed into the graph.
figure illustrates the relations.
a computation graph can be executed multiple times.
it is important to note that tensors do not survive across one execution of the graph e.g.
one session.run the memory holding them is allocated and reclaimed automatically.
in contrast values of variable nodes persist across executions.
.
pytorch pytorch is another popular machine learning framework.
similar to the tensorflow the pytorch program can also be regarded as a mix of the python host program and the underlying computation graph of operations which will be dispatched to runtime kernels in the execution.
however unlike tensorflow the pytorch builds the computation graph dynamically.
in other words the pytorch 508icse may seoul republic of korea weijie zhou yue zhao guoqiang zhang and xipeng shen analytics programhost program computation graphharp compiler graph generatoraugmented graph inference engineoptimization opportunities and conditionsanalysis ruleanalysis rule library apiproperties offline figure the overall system diagram.
constructs the computation graph on the fly so the computation graph can change every time it is executed.
.
datalog datalog is a popular logic programming language based on the first order logic.
in datalog program logic is expressed in terms of relations represented as facts and rules and computations are in queries over these relations.
two basic constructs are term and atom.
a term is either an entity constant or a variable2.
an atom is a predicate with a list of terms as arguments.
it is in form of p x1 x2 .
.
.
xn where pis a predicate and xiare terms.
a ground atom orfact is a predicate with only constant arguments.
many facts together form a datalog database.
datalog rules express logical inferences in the following form a b1 b2 .
.
.
bn.
which reads b1andb2and ... and bntogether imply a where each symbol is an atom.
a datalog program is a collection of rules.
when it runs on a fact database it infers a new set of facts by applying the rules to the known facts.
datalog can define recursive relations and recursive queries naturally and is declarative.
the harp solution this section presents harp in detail.
figure outlines the overall structure of harp.
harp code analysis extracts the relevant information from the host code and the computation graphs and represents them in a unified format augmented computation graph written in datalog atoms.
meanwhile through some light annotations we equip harp with the knowledge on the high level properties of the library apis including the side effects of apis argument types and returning types.
with all the relevant information captured and represented in an analyzable manner for a rule predefined in harp or given by users describing code inefficiency patterns the datalog inference engine can identify optimization opportunities that span across boundaries between host code and api calls.
harp is equipped with a list of predefined rules on code inefficiency which are derived through our analysis of realworld analytics applications listed in table and elaborated in section .
.
we next explain harp and how it addresses the main challenges in enabling holistic analysis.
2by conversion lowercase for constants and uppercase for variables.listing an example machine learning codelet 1def dfdx x param f z f x param z .
backward dfdx v x .
grad return dfdx v .
overcoming language complexities thefirst challenge this work encounters is python complexities.
as an important step outlined in figure the harp analyzer must capture the important interactions between the host python code and the computation graphs.
as a dynamically typed scripting language python poses many difficulties to the static analysis which are summarized in table .
these complexities cause unknown types and undecidable operations or function calls.
listing shows such an example.
the function dfdx calculates the partial derivative of a function with regard to the input x. due to the dynamic feature of python it is hard for static analysis to precisely determine the types of its input parameters.
harp circumvents the difficulties by leveraging insights obtained specially on analytics applications.
the first insight is that many python complexities rarely appear in analytics programs or can be ignored.
table reports the number of appearances of each type of complexity in real world analytics applications that we have surveyed in two github collections3.
these two collections contain some tensorflow and pytorch programs representing a variety of tasks in machine learning ranging from natural language processing to image processing object detection and so on.
in the survey we ran our static python code analyzer sec .
.
on each of the programs which reports places that give static analysis a hard time.
we then manually examined those cases.
among the applications the most frequent complexity is dynamic type changes but the frequency is still only .
the second insight is that for those complexities that do matter they can often be treated successfully through speculations.
the speculations are based on some common patterns observed in analytics applications.
analytics applications due to the common features of the domain exhibit some patterns.
for instance in pytorch code the type of a variable that has a member function grad or backward is usually a tensor with all floating point values.
that pattern can then help speculate on the types of variables xandzin listing .
although using names for speculation is in general not fully reliable we observed that that for some common functions in machine learning domain gives correct speculations in most of times.
table lists some of the patterns we attained through our studies on our collection of machine learning applications.
listing belongs to the second pattern in table .
when encountering a complexity in its static analysis of a given python program harp resorts to the common patterns.
if the conditions match harp resolves the complexity speculatively.
such speculations allow harp to carry on its code analysis even in the presence of the complexities.
that makes it possible to provide refactoring suggestions that are likely not guaranteed to be valid and beneficial.
speculations could be wrong the developer 509harp holistic analysis for refactoring python based analytics programs icse may seoul republic of korea table some inefficiency patterns predefined in harp no.
inefficiency code patterns potential optimization s mistake the computation construction for computation execution tensorflow use computation graph construction apis inside loop.
the apis are primitive operators such as tf.add tf.mul etc.do the computation in thesession.
loop redundancy loop invariant computation inside loop hoist the loop invariant out of the loop common subgraph computation two consecutive executed computation graphs have common intermediate nodes.
the value of the common nodes are invariant across the executions.cache the last common nodes and reuse the value.
plain forloop for computation tensorflow use the plain python loop for building computation graph.
the code inside the loop only reference nodes in the computation graph but not other data on the host side.replace the plainpython loop with tf.while loop miss performance tuning for static graph pytorch the dynamically constructed computation graph remains the same across loops no conditional branch or dynamic dispatch.
size of the input data is not changed.
iteration number is non trivial .turn on the cudaspecific optimiza tion tuning such as torch.backends.cudnn scalar computation that can be vectorized simple forloop contains straight line code with neither function calls nor branches.
computation on vector data type list of number array etc .
no vector dependence.use array or tensor type and their vectorized operations.
table python language complexities for static analysis and appearing frequencies in machine learning applications.
python language complexities programs with the complexity data dependent conditional branch static unknown function dispatch higher order function customized operator overload dynamic attribute setting dynamic type changes dynamic typed container table some of the machine learning patterns leveraged for speculative analysis.
no.
class of patterns access to an object through its attribute such as foo.bar or an index such as foo is speculated as side effect free.
the type of an object can be speculated based on the names of itsfields and methods visited locally if the names are common machine learning names e.g.
those in figure .
if a python list is speculatively converted to a tensor it is speculated that the elements in the list share the same type.
if all branches of a condition statement return variables with the same type they speculatively share the same type.
i o operations are normally used for loading data and logging thus they are speculated as having no unexpected side effects.
torch.utils.data.dataset transforms.centercrop transforms.normalize torch.from numpy t transforms.functional.adjust brightness img... torch.ones like a torch.add a b tensor tensor.abs tensor.add b tensor.min tensor.copy tensor.dim tensor.size tensor.permute tensor.reshape tensor.type as tensor.float tensor.detach tensor.cuda tensor.unsqueeze ... figure some common function names used in harp ashints for speculative analysis.
needs to make the final judgment.
to assist the developers in the process harp records all speculations and reports them when itprovides the corresponding refactoring suggestions as section .
details.
.
unified representation through augmented computation graphs for holistic analysis it is preferred that all the needed information of the program is represented in an analyzable form.
it implies threequestions what information to get how to get it and how to represent it.
harp answers these questions by following several design principles first the representation should be amenable for software inference but also easy to understand for humans.
the representation can then be used for not only program analysis but also as a kind of documentation.
second the set of information to collect from the program are intended to be used in a variety of analysis hence their definitions should be general rather than tailored to some particular analysis.
third the representation should also be extensible.
thus specification for new properties and other sources of information can be added easily.
we next explain the solutions from harp in detail.
.
.
info to attain semantic definitions.
the relevant information for holistic analysis comes from both the host python code and the computation graphs.
for simplicity of explanation we use semantics to refer to all4.
both host code and the computation graph carry many fold semantics defining the set that is most relevant to large scoped inefficiencies is the key.
semantics from computation graph.
as mentioned in section a computation graph consists of two types of objects nodes and edges.
each node represents an operation that consumes or produces values.
each edge represents the values that are output from or input to a node namely the values that flow along the edge.
we use tensorflow as the example to explain the set of semantics harp captures from nodes and edges.
4the meaning goes beyond traditional language semantics referring to any properties or knowledge about a programming language construct.
510icse may seoul republic of korea weijie zhou yue zhao guoqiang zhang and xipeng shen for a node tf operation harp captures four fold semantics control inputs referring to the set of operations on which this operation has a control dependency inputs which are the list of tensor inputs of the operation outputs which are the list of output tensors of the operation and type of computation such as add matmul .
harp contains the set of common computation types including those supported in onnx a standard for representing deep learning models more can be easily added.
for an edge tf value harp captures some important properties kind dtype shape constant or variable.
the first kind is about which kind of edge it is.
we distinguish two different kinds of edges based on their different purposes tensor edges convey the immutable tensors of the data.
in tensorflow all data are modeled as tensors and there is no need to distinguish tensors or scalars.
control edges do not carry values.
they are special edges used to constrain the order of execution.
the second property dtype is the type of data carried on the edge which can be any of the supported data types in tensorflow.
the third property shape records the shape of the tensor which is a list storing the size of each dimension of the tensor.
the final property indicates whether the tensor on the edge isconstant or mutable.
semantics from host code.
for tensorflow harp captures the following semantics that closely relate with the core computation the operations that invoke tensorflow apis to define the computation graph.
for example the statement c tf.add a b in the host program defines an add operation in the computation graph.
these apis are high order functions that return operations.
we convert them into operation creation nodes whose outputs are special edges representing operations .
the invocation of the session api which prompts graph executions.
this is also the interface for the host computation graph interaction.
the control flow of the host program.
the processing of data that is to be consumed by the computation graph which includes calls to other library apis e.g.
numpy .
.
.
collecting semantics through harp compiler.
deriving the semantics is done through our harp compiler and computation graph dumping.
the compiler is developed based on jedi a static analyzer of python programs.
computation graph.
the step to get the semantics of the computation graph is as follows.
for tensorflow programs the compiler inserts a graph dumping call and a follow up exit at the place in the program where the computation graph is built e.g.
invocation of run of a tf.session object and then runs the program on a provided sample input.
the computation graph is then dumped in a format easy to parse.
for most programs the automatic method can succeed.
in rare cases when the code does not follow the common patterns harp provides feedback and users can insert the dumping call as part of harp interface .
the exported graph is in a format called graphdef which can be easily parsed to get the structure relations and properties of nodes and edges.
for pytorch programs we use an approach similar to existing tools autograph and janus to create the computation graphs.
host program.
to get the semantics from the host program both dataflow analysis and control flow analysis are necessary.
two properties of machine learning applications ease the process.
first the set of data that requires attention is limited.
since the datais fed into the graph through the session api we only need to focus on data in the feed list.
thus the domain of the dataflowanalysis is largely narrowed down.
second in most of the deeplearning or machine learning programs the data has a straightforward workflow.
for example a typical flow of the input data is that it starts from being read from the external storage or beinggenerated from other components of the program and then it is converted to some tensor variables.
the variable is then provided to the computation graph as the input data.
so the data of interest often exhibits a linear control flow.
harp lowers the representation of some control flow structures by following existing practice e.g lowering ifstatement to switch andmerge primitives .
harp compiler circumvents python language complexities through the speculative analysis described in the earlier section.
it records the assumptions it uses when applying a speculation which will be used later as part of the feedback to users.
.
.
representing semantics augmented computation graph.
we design augmented computation graph for harp to use to seamlessly integrate the host code semantics with those of the computationgraph.
to make the representation amenable for existing logicinference engines to use we represent all semantics as datalog atoms using a single vocabulary.
augmented computation graph.
extensions are added to the default computation graph to accommodate each category of semantics from the host code.
harp uses inter procedural graph to model the interplay between host code and the computation graph.
the inputsto a computation graph are treated as function parameters and the outputs as function returns.
the analysis can hence take advantage of standard inter procedural analysis.
for the control flow structure in the host program the most important one is the loop structure which creates a local scope containing a set of computations.
to encode its se mantics a loop is modeled as a special operation node in the augmented graph.
for any computation inside the loop there is a control edge from the loop node to the node representing the computation.
if a data is loop variant there is an extra tensor edge from the loop operation to it.
edges go from a loop node only to operations in the host program which then may connect to the operations in the computation graph.
it is worth noting that the relations between the loop operation and the other nodes reflect dependencies rather than traditional structures in the abstract syntax tree ast of the host program.
for the influence to host data dependencies and control flows from calls to other library functions e.g.
numpy harp gets the semantics through library annotations.
particularly we annotation library apis such as type signature side effect.
511harp holistic analysis for refactoring python based analytics programs icse may seoul republic of korea listing specifications for edges edge edge id kind kind .
edge edge id dtype d a t a t y p e .
edge edge id shape t e n s o r s h a p e .
listing api misusage example from stackoverflow x t f .
v a r i a b l e .
.
.
.
.
.3for in range e6 x x .
.
.
s e s s .
run .
.
.
datalog atoms.
the augmented graph is represented in harp in the form of datalog atoms.
in our design each atom only describes one attribute of the object.
this is for the flexibility and extensibility.
for example if new attributes for the tensor is needed for new analysis they can be added to the semantic schema without breaking the existing specifications and rules.
listing shows the main kinds of atoms for edges tf values corresponding to the three kinds of semantics defined for edges.
the atoms of nodes are in similar forms but with different keywords for different semantics.
.
inefficiency detection rules and engines with the augmented computation graph written in datalog atoms program analysis algorithms can be written in datalog rules.
this design has several benefits.
first the declarative interface provided by the logic programming lowers the bar for writing complicated algorithms than the imperative interface of traditional compilers does.
second the semantics of machine learning programs often center around the graph structure.
the relational and recursivenature of logic programming languages makes it a goodfit for the graph based analysis.
for example in datalog the template of recursive algorithms are as simple as follows r e c u r s i v e r e l a t i o n edgefrom edgeto d i r e c t r e l a t i o n edgefrom edgeto .
r e c u r s i v e r e l a t i o n edgefrom edgeto d i r e c t r e l a t i o n edgefrom edgemid r e c u r s i v e r e l a t i o n edgemid edgeto .
the template queries the relation between every pair of edges.
the template simulates the process of computing the transitive closure of the graph.
it starts from the existing facts the direct relation and inference other facts through recursive propagation.
rules for nodes can be defined similarly.
through analysis of real world analytics programs5 we summarized a list of code inefficiency patterns in table .
we next illustrate the simplicity in defining corresponding rules for detecting inefficiency on the augmented graphs.
example api sanitizing.
thefirst inefficiency in table is misuse of the library apis on constructing computation graphs.
thecode pattern is that those apis are used inside a loop causing many nodes to be created unnecessarily as listing shows.
harp has rbm codelet a l p h a .
a t f .
p l a c e h o l d e r f l o a t b t f .
p l a c e h o l d e r f l o a t w t f .
v a r i a b l e t f .
random x t f .
p l a c e h o l d e r f l o a t h0 t f .
nn .
sigmoid t f .
matmul x w h1 t f .
nn .
sigmoid t f .
matmul h0 t f .
t r a n s p o s e w b v1 t f .
nn .
sigmoid t f .
matmul h1 w a y1 t f .
reduce mean x v1 y2 t f .
reduce mean h1 v1 with t f .
s e s s i o n as s e s s s e s s .
run t f .
i n i t i a l i z e a l l v a r i a b l e s for in range for s t a r t end in i n d i c e s x a b data gen s t a r t end y1 s e s s .
run y1 f e e d d i c t x x a a b b a a l p h a a y2 s e s s .
run y2 f e e d d i c t x x a a b b ax bh0 v1y2y1 h1 w figure the simplified dataflow graph for listing .
the square nodes represent data variables and circle nodes rep resent operations.
the labels inside the operation nodes in dicate their output names.
rules called api sanitizing rules to detect such api misuses.
the rules are simple thanks to the augmentation graph representation and the declarative interface harp uses.
the code below expresses the pattern of including operation creating apis inside a loop op o type opcreation op o i n s i d e l o o p loopid ?
where control edge indicates the operation is inside a loop.
another use case of the sanitizing rule is to help shape inference.
in tensorflow the shapes of some tensors can be unspecified whicharedynamic shapes.
at runtime the tensorflow system would need to infer the shape based on the input data and then propagate theinfo to other tensors that depend on these input tensors.
dynamic shapes are hurdles for tensorflow to simplify computation graphs or enable efficient memory allocations.
in many of the cases with dynamic shapes however the input data can actually be determined from the host code e.g.
deeplearning with a fixed batch size .
but as tensorflow compilers focus on computation graphs only it cannot do the shape inference in advance.
the holistic analysis by harp addresses the limitation and detects unnecessary dynamic shapes.
example detecting computation redundancy.
a more interesting use of the harp framework is to hunt for the computationredundancies patterns two and three in table that are elusive to the existing tools and subtle to see by programmers.
we demonstrate it on the example in listing of section .
figure shows the augmented computation graph including the relevant operations 512icse may seoul republic of korea weijie zhou yue zhao guoqiang zhang and xipeng shen listing dependency checking rules d i r e c t d e p e1 e2 i n p u t e d g e node e1 o u t p u t e d g e node e2 .
dep e1 e2 d i r e c t d e p e1 e2 .
dep e1 e2 d i r e c t d e p e1 x dep x e2 .
listing shape consistency checking rules shape e s f e e d i n e s shape check e .
shape e s out edge node e f i n d a l l ie i n p u t e d g e node ie i e s shape check node ies s .
from the host program.
it captures all the constant information and the scope of the loop.
through constant propagation harp infers that t1andt2are invariant across the loop and thus they can be hoisted.
the suggested code refactoring is to change the data type oft1andt2totf.variable making their values survive across the loop iterations and get reused.
another example is to detect common sub computation redundancy as the one shown in listing .
figure shows a simplified dataflow graph corresponding to the rbm codelet.
the outputs y1 and y2both need the intermediate value h0 h1andv1.
node a affects v1 but h0 h1 have the same values in the computations of y1and y2according to the python code in listing .
therefore potentially the values of h0andh1produced during the session.run for y1could be reused for the session.run that produces y2.
to detect such common sub computation redundancy rules are written to find intermediate values common to multiple fetched values such that they can be potentially cached and reused.
the core of the detection algorithm is to analyze the dependencies of the values.
the data dependency atoms are shown in listing .
one can query for finding common dependencies.
for example if we have two fetched values o1 and o2 we can use the following query to find operations that both o1 and o2 depend on common dep x o1 o2 dep x o1 dep x o2 .
by adding an extra check whether o1 and o2 belong to two different sessions one can then find cases worth caching the value ofxin one session and reusing it in the other session.
there are some other rules in harp including constant propagation which finds all constant variables finding for loop for victimization s which finds for loops in python code that operate on container objects likely containing elements of the same type and unlikely having loop carried dependency static graph identification which identifies graphs that remain unchanged across iterations useless tensor detection which finds tensors that are not used.
these analyses all lead to some potential optimizations.
for static graph identification for instance the knowledge would allow the inclusion of some special flags torch.backends.cudnn.benchmark which would allow pytorch engine to apply some aggressive optimizations to such graphs to improve the performance.
inference engine.
the inference engine of harp is the datalog inference engine with an extension to allow the invocations of external side effect free imperative functions.
the shape check function in listing is such an example.
it checks the shape consistency which means if an operator node has an outgoing edget t2mul mul submuld t1d x a a figure constant propagation on augmented computationgraph identifies loop invariants the shadowed nodes .
output its shape should comply with the expected shape of the operation and the inputs.
for example for matrix multiplication of a and b the output should have a shape of rows a x columns b .as the check requires shape calculations it is simple to write in imperative programming language but cumbersome in pure datalog predicates.
by extending datalog predicates with imperative functions harp creates conveniences for the development of inference rules.
caution must be taken to make sure that the extension does not break the safety of the datalog deduction.
in the shape check example since the function has no side effect on the datalog atoms it is regarded as a safe extension.
.
informative feedback when the analysis by harp involves speculations the results could be wrong.
harp provides conditioned feedback to keep the risks controlled.
the principle is to report also the assumptions harp uses in its speculations when it offers refactoring suggestions.
figure provides an example output from harp after it is integrated into the ide pycharm through intellij.
in this example harp identifies tensorflow computation redundancies among the lines that invoke sess.run .
then the ide plugin highlights involved code lines.
when the mouse hovers over the highlighted lines a tooltip prompts the suggestion for the optimization as well as the assumptions that harp takes in providing the suggestion.
the feedback needs correlate graph nodes and edges with source code of the program.
to facilitate it harp compiler conducts a preprocessing of the given program by rewriting it to add unique name to each computation graph construction statement.
for example c tf.add a b becomes c tf.add a b name id where id is a unique name managed by harp.
then the default tensorflow backend automatically assigns that unique name to the corresponding node in the computation graph.
evaluation in this section we report the evaluations of the efficacy of the proposed harp approach.
we demonstrate how it can help diagnose tensorflow and pytorch programs to find subtle pitfalls and optimization opportunities that are elusive to existing tools.
we report the significant performance improvement of the corresponding refactored code as well as the effectiveness and benefits of the speculative analysis.
we further report a user study on the usability of harp as a refactoring tool for programmers.
513harp holistic analysis for refactoring python based analytics programs icse may seoul republic of korea figure example feedback from harp on a restricted boltzmann machine rbm implementation.
table hardware platforms used in the experiments.
intel cpu nvidia gpu cpu xeon e5 1607geforce gtx titan x freq.
.
ghz .
ghz cores memory 16gb ddr3 .
ghz12gb gddr5 .
ghz memory bandwidth34.
gb s gb s os driver ubuntu .
cuda .
compiler gcc .
nvcc .
table benchmarks and datasets.
benchmark application dataset dict learn dictionary learning random generated size 1000x1000 rbm restricted boltzmann machine mnist char rnn recurrent neural networks shakespeare work styletransfer neural style transfer vgg model input size of 224x224 deep q net deep q network openai gym seq2seq variable length rnn blog authorship corpus cyclegan image to image translationcityscapes dataset cholesky cholesky decomposition random generated size .
experimental setup the hardware specifications for the evaluation platform are detailed in table .
the benchmarks are tested with gpu acceleration.
the implementation of harp is based on the python static analysis tool jedi and the inference engine is written based on flix .
harp is integrated into the ide pycharm through intellij to servetable potential efficiency problems reported by harp.
benchmark inefficiency reported by harp true pattern numbers defined in table positive dict learn .
loop redundancy y .
plain forloop for computation n rbm .
common subgraph computation y char rnn .
plain forloop for computation y .
scalar computation that can be vectorized case in .
scalar computation that can be vectorized case iiy styletransfer3.
common subgraph computation y .
plain forloop for computation y deep q net .common subgraph computation y seq2seq .
plain forloop for computation y cyclegan .
miss performance tuning for static graph y cholesky .
scalar computation that can be vectorized y table speedups by harp guided code refactoring.
benchmark no.
of ops edgeslibrary default exec.
time s speedup line of source codes dict learn tensorflow .
.
rbm tensorflow .
char rnn tensorflow .
.
styletransfer129 tensorflow .
.
deep qnet887 tensorflow .
.
seq2seq tensorflow .
.
cyclegan pytorch .
cholesky n a pytorch .
.
for code refactoring.
table lists all the benchmarks.
these benchmarks are outside the surveyed benchmarks for identifying the speculation and optimization patterns.
we collect these benchmarks from published work or real world tensorflow and pytorch programs.
they implement a range of machine learning algorithmsfor machine learning.
table also shows the input dataset for each benchmark.
these benchmarks are based on python .
tensor flow .
and pytorch .
.
.
in our experiment each benchmark was executed multiple times we saw only marginal fluctuations in the execution time and hence reported the mean value.
.
performance analysis we focus on the inefficiency patterns listed in the table in the experiments.
more rules can be inserted to detect more patterns.
table reports the inefficiency patterns that the harp finds in those benchmarks.
it reports potential inefficiencies in each of the benchmarks.
two out of the inefficiencies are false alarms.
one of the false alarms happens on dict learn .
harp suggests that the python forloop can be replaced with the tf.while loop .
although the suggestion is valid due to the existence of the loop redundancy the other suggestion is more efficient.
the majority of suggestions show useful insights and optimization hints.
with the help of more rules false alarms could be further reduced.
it is worth noting that as these optimizations all span across both the python host code and library apis none of the prior methods canfind these opportunities for their limited scopes of analysis.
514icse may seoul republic of korea weijie zhou yue zhao guoqiang zhang and xipeng shen table reports the speedups brought by refactoring that follows the suggestions from harp.
the baseline is the performance of the default programs running on the default tensorflow and pytorch systems these systems conduct the state of the art optimizations but limit their views and optimizations to the computation graphs only.
the results show .
.0x speedups confirming that the suggestions from harp are effective in fixing the efficiency problems that are elusive to existing optimizing systems.
in the evaluation we use the dataset included in the original application whenever it is available.
we have also experimented with 10x larger datasets and observed similar speedups.
all these benchmarks except the cholesky implement some kind of machine learning algorithms as table shows.
the cholesky measured the computations of cholesky decomposition which is useful for efficient numerical solutions.
harp constructs an augmented computation graph for it to represent its operations and host side controls.
thedict learn problem has already been discussed in listing .
after the enabled loop invariant elimination its performance on gpu improves by .02x.
for the rmbandstyle transfer benchmarks the intermediate results of multiple sub graphs depending on the common inputs are cached and reused.
the speedups are respectively .0x and .6x.
for char rnn harp suggests transforming to the tf.while loop instead of the plain python loop to implement the repeated rnn cells.
due to the dynamic feature of the pytorch framework computation graphs are constructed in each iteration.
this dynamic property prevents optimizations that apply to static graphs.
however for cycgan the inference by harp leads to the conclusion that the graph is invariant across iterations.
harp hence suggests autotuning and specialization for the underlying cuda implementation by turning on torch.backends.cudnn option.
the seq2seq andcholesky contain loops that cannot be vectorized by existing methods for the unknown data types of their container objects.
the analysis by harp leads to the speculation on the uniform type of their elements and the lack of loop carried dependencies.
it suggests vectorization to the corresponding loops.
to assess the benefits brought from the speculative analysis we disable the speculations for the several benchmarks on which speculations are used by harp.
due to the static time unknowntypes the analyzer is unable to infer the potential vectorization opportunities for seq2seq andcholesky .
for another benchmark dict learn without speculative analysis and the api knowledge the analyzer cannot tell the loop invariant calculations.
wrong speculations happen once in the experiments due to an unconventional usage of decorator property of python.
codelet illustrates it.
based on the first pattern in table the analyzer speculates that batches.next is side effect free and returns the same value in each iteration of the loop.
however the implementation ofbatches.next actually exploits the decorator property and returns different values at each access.
the informative feedback from harp help programmers easily find the wrong speculations.
table also reports the numbers of nodes and edges in the computation graphs.
they reflect on the complexities of the graphs but do not necessarily indicate the complexities of the problems.
for example complex computations such as an entire cnn layer can be wrapped into a single operation in a graph.listing codelet causing speculation errors 1c l a s s b a t c h e s .
.
.
property def next .
.
.
.
.
.
7def t r a i n s e l f s e s s i o n ops b a t c h e s n epochs for iin range n epochs s e s s i o n .
run ops f e e d d i c t s e l f .
i n p u t s b a t c h e s .
next the analysis by harp takes 973ms on these benchmarks.
the refactoring based on the suggestions from harp varies from several minutes to two hours including debugging time depending on the complexity of the benchmark.
the benchmark char rnn takes the longest time to refactor since it requires embedding dynamic control flows into static graphs.
it is worth noting that as these optimizations all span across both the python host code and library apis none of the prior methods can find these opportunities for their limited scopes of analysis.
.
usability evaluation by user study to evaluate usability of harp as a refactoring tool we conduct a controlled experiment with participants.
the hypothesis to test is as follows given a sub optimal program of interest harp can help users more easily find optimization opportunities and optimize the code to a more performant version.
all of the participants are graduate students in computer science.
ten of them were familiar with python programming among the ten three had written some beginner level tensorflow code before and two had written beginner level pytorch code before the otherfive haven t written either tensorflow or pytorch code before.
before the study the participants were given a minute lecture on the basics of python tensorflow and pytorch.
to eliminate the variance on experiment environments we set up all the required software on our gpu server for the students to run performance measurements.
the benchmarks include dict learn char rnn rbm and cyclegan.
we conduct a two stage user study to examine the usability of harp.
all of the students were asked to find the inefficiencies of these programs and to optimize them if possible.
in the first stage they were not using the harp but were allowed to use any other resources they could find.
they were asked to turn in their analysis results and the optimization results in a week.
only a few students successfully optimized some of the programs for dict learn for rbm for char rnn andcyclegan .
the speedups they got were .85x on dict learn and .05x on rbmon the gpu server.
in the second stage the students were asked to optimize those programs with the help of harp and submit the results in another week.
the students were asked to use only the feedback provided by the harp to optimize the programs.
each of the programs was successfully optimized by of the students and received .
.85x speedups.
program char rnn is an exception.
harp suggest to use tf.while loop to integrate itsforloop into the computation graph.
students unfamiliar with tensorflow failed making the code changes as that would need a 515harp holistic analysis for refactoring python based analytics programs icse may seoul republic of korea major rewriting of the code to embed dynamic control flows into static graphs.
in stage it took the students on average mins trying to find inefficiencies in each of the four programs and at least mins to refactor a program.
in stage the time in finding inefficiencies is reduced to mins and refactoring a program took no more than mins.
as stage happened after stage the familiarity to the code that the students had attained in stage could have contributed to the reduction of the analysis and refactoring times.
but the significant increase of success rates in refactoring offers evidences on the usefulness of harp.
the questionnairesaccompanied with the study provided further confirmations all students said that harp was useful in helping them find valid optimizations.
one suggestion is to make harp offer some examples on the suggested optimizations.
.
threats to validity besides the possible bias in the user study mentioned earlier this part discusses two extra threats to validity.
our framework is evalu ated based on python .
tensorflow .
and pytorch .
.
.
as new versions are released the apis and the underlying implementation may change and invalidate the refactoring patterns or optimization opportunities which are effective in the experiment.
however the goal of our work is to provide a framework to ease the analysis rather than to focus on particular patterns mentioned in this paper.
new patterns are easy to be included in the future.
although the programs in the evaluation represent real world programs on github they cannot reflect the version in the process of the development.
analyzing these programs cannot simulatehow our tool helps in the real programming process.
harp has the potential to give suggestions during development of a program through the integration in ide a detailed study is left for future.
related work there are some other work on suggesting optimizations to developers on other programs and many frameworks e.g.
xla tvm tensor comprehension caffe for deep learning optimizations.
this current study distinctively focuses on the special barrier for optimizations of python programs that use modern machine learning libraries and emphasizes holistic treatment.
autograph and janus create deep learning computation graphs from imperative python code.
harp leverages a similar idea in creating computation graphs for pytorch code but has a different focus identifying inefficiencies spanning across the boundaries of host code and libraries the inefficiencies in the evaluation section can be identified by neither autograph nor janus.
a recent work proposes a kind of intermediate representation called weld ir to support optimizations across multiple libraries and reported promising results.
it focuses on the main computations represented in the libraries rather than the api misuses or the interplay between the library calls and the host code.
it requires some manual changes to the library apis such that their calls can generate weld ir at runtime.
harp on the other hand requires no modifications to the library apis.there is a body of work on declarative program analysis .
speculative analysis has been explored in some prior studies on program optimizations.
lin and others demonstrate that the result of speculative alias analysis can enable speculative register promotion.
a recent work uses several speculation techniques in the implementation of a just in time compiler for r. harp receives inspirations from the prior work.
it is distinctive in being the first tool that enables holistic analysis of python based analytics applications and detects large scoped inefficiency thatare elusive to existing solutions.
it features novel insights on circumventing python complexities analytics conscious speculative analysis the design of augmented computation graphs and the informative feedback scheme for risk controls.
conclusion the diverse programming paradigms and the reliance on high level abstraction are common features of modern computing.
they bring challenges to the program analysis and optimizations.
current optimizers are limited in their views of the libraries and lack the abilities to analyze across the mixed program models or to utilize high level domain knowledge.
we believe that an efficient system to overcome these shortcomings needs to be able to synthesize knowledge from difference aspects of the applications of the target libraries.
and a friendly interface for encoding high level semanticsof abstractions is essential.
harp is a step towards a more effective approach to advanced analysis for modern applications.
it proves effective in analyzing machine learning programs helping identify the subtle optimization opportunities for the applications.
further development directions include extending this method to a broader range of libraries and programming frameworks and combining the approach with runtime analysis and optimization techniques.
acknowledgment this material is based upon work supported by the national science foundation nsf under grant no.
ccf and ccf .
any opinions findings and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of nsf.