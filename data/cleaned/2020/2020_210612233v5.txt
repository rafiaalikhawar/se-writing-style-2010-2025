testing of autonomous driving systems where are we and where should we go?
guannan lou macquarie university sydney nsw australia guannan.lou mq.edu.auyao deng macquarie university sydney nsw australia yao.deng hdr.mq.edu.auxi zheng macquarie university sydney nsw australia james.zheng mq.edu.au mengshi zhang meta menlo park ca usa mengshizhang fb.comtianyi zhang purdue university west lafayette in usa tianyi purdue.edu abstract autonomous driving has shown great potential to reform modern transportation.
yet its reliability and safety have drawn a lot of attention and concerns.
compared with traditional software systems autonomous driving systems adss often use deep neural networks in tandem with logic based modules.
this new paradigm poses unique challenges for software testing.
despite the recent development of new ads testing techniques it is not clear to what extent those techniques have addressed the needs of ads practitioners.
to fill this gap we present the first comprehensive study to identify the current practices and needs of ads testing.
we conducted semi structured interviews with developers from autonomous driving companies and surveyed developers who have worked on autonomous driving systems.
a systematic analysis of the interview and survey data revealed common practices and emerging needs of autonomous driving testing.
through a comprehensive literature review we developed a taxonomy of existing ads testing techniques and analyzed the gap between ads research and practitioners needs.
finally we proposed several future directions for se researchers such as developing test reduction techniques to accelerate simulation based ads testing.
ccs concepts software and its engineering software testing and debugging .
keywords autonomous driving software testing empirical study acm reference format guannan lou yao deng xi zheng mengshi zhang and tianyi zhang.
.
testing of autonomous driving systems where are we and where corresponding authors xi zheng mengshi zhang.
permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
copyrights for components of this work owned by others than acm must be honored.
abstracting with credit is permitted.
to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
request permissions from permissions acm.org.
esec fse november singapore singapore association for computing machinery.
acm isbn .
.
.
.
we go?.
in proceedings of the 30th acm joint european software engineering conference and symposium on the foundations of software engineering esec fse november singapore singapore.
acm new york ny usa pages.
introduction autonomous driving has been making great strides towards reality in recent years.
in waymo launched the trail of fully autonomous ride hailing services in california .
more recently tesla released the beta version of its full self driving fsd software which has been installed on at least 60k tesla vehicles .
however given the traffic accidents caused by autonomous vehicles there is still a long way to ensure the robustness and reliability of autonomous driving systems adss .
similar to traditional software systems autonomous driving companies also adopt testing as the main quality assurance mechanism for adss.
several leading companies such as waymo and tesla have their own fleets to perform extensive on road testing.
furthermore simulation testing environments such as carla are widely adopted to test various driving scenarios or extreme conditions that cannot be easily replicated in reality.
in recent years the software engineering se community has also proposed many testing techniques to improve the safety and reliability of adss .
for example deeproad and deeptest leverage metamorphic testing to test adss under extreme weather conditions.
ac3r generates critical driving scenarios e.g.
collisions in a simulation environment based on crash reports.
these methods have shown promising results for end to end driving models.
however with the rapid evolution of autonomous driving technologies industrial adss have become much more sophisticated these days using multiple perception models in tandem with logic based control and planning modules.
currently there is a lack of comprehensive understanding of the emerging needs of ads testing and to what extent existing ads testing techniques meet the needs of ads practitioners.
to bridge this gap we adopted a mixed methods research design with a combination of qualitative interview study large scale survey and literature review to investigate the following three research questions rq1 .what are the industrial practices of ads testing?
rq2.
what are the emerging needs of ads testing?arxiv .12233v5 sep 2022esec fse november singapore singapore guannan lou yao deng xi zheng mengshi zhang and tianyi zhang rq3.
to what extent existing ads testing techniques address the industrial needs?
we first interviewed developers from autonomous driving companies to collect qualitative responses on ads testing practices and needs.
based on the insights from the interview study we developed a survey and solicited quantitative responses from a boarder audience.
specifically we sent out surveys to ads developers and received complete and valid responses.
through comprehensive data analysis and triangulation we summarized seven common practices in ads development and testing some of which have not been accounted by existing testing techniques.
for example ads practitioners adopt more system level testing metrics such as consistency and latency when testing an ads rather than just using model accuracy.
furthermore we identified four common needs of ads testing identifying possible corner cases and unexpected driving scenarios speeding up ads testing tool support for constructing complex driving scenarios and tool support for data labeling .
we further conducted literature review on ads testing methods proposed by the se community.
we manually went through papers that mentions autonomous driving or related keywords in se conferences and identified papers specifically about ads testing.
we categorized them and developed a taxonomy of different kinds of research on ads testing.
we identified four gaps between existing research and industrial needs.
for instance existing ads testing methods only consider simple image transformations.
there is a lack of support for identifying richer and more complex traffic scenarios that ads developers really need in practice.
based on these gaps we proposed several future directions.
for example se researchers can leverage test selection and prioritization techniques to speed up ads testing need .
specifically to account for the multi module architecture of adss test selection methods can be formulated as a multi objective optimization problem to maximize multiple coverage metrics for different modules e.g.
neural coverage for a perception model and statement coverage for a logic based control module rather than a single model.
paper organization.
section discusses related work in ads testing.
section illustrates how we conduct interviews and surveys.
section provides current practice of ads testing in industry.
section summarizes needs of industry in ads testing.
section discusses the existing se solutions to these needs and future research directions.
section discusses the threats to validity in this study.
section concludes this work.
related work there are several literature reviews on testing and verification of machine learning ml models .
the most comprehensive literature review is by zhang et al.
.
they analyzed papers related to machine learning testing and provided an overview of various testing properties components and workflows of ml models.
in addition zhang et al.
identified several challenges of testing ml models such as how to generate natural test inputs.
compared with these studies our study focuses on ads testing.
in addition to a literature review we also interviewed and surveyed ads practitioners to understand the common practices and needs of ads testing.
we found that the unique characteristics of adss e.g.
the multi module architecture along with the special testing needs pose new challenges and opportunities compared with ordinary ml models e.g.
leveraging multi objective search in test selection for multi module adss.
two recent studies analyzed the codebase and bugs in autonomous driving systems .
peng et al.
conducted a case study of baidu apollo and summarized the architecture and individual modules in the apollo system.
they found that apollo lacked adequate testing at the system level.
garcia et al.
analyzed commits and issues in apollo and autoware .
they classified these issues and summarized their symptoms and root causes.
there are also several empirical studies on bugs in ml applications .
for example zhang et al.
analyzed software bugs in ml applications built by tensorflow.
the most related work to our study includes several literature reviews on autonomous driving testing .
huang et al.
reviewed testing and verification methods from the intelligent vehicle iv community.
they summarized not only testing methods for individual modules in the software stack but also hardware inthe loop testing methods for hardware components and integrated testing for the entire vehicle.
compared with huang et al.
we focus on testing methods from the software perspective.
our literature review summarized recent advances in ads testing from the se community.
please refer to section for a detailed summary and discussion of these software testing techniques.
koopman and wagner proposed five challenges of testing autonomous vehicles based on the v model for autonomous vehicles .
masuda described the software architecture of autonomous vehicle simulations and discussed several software testing challenges of such simulations .
compared with them our discussion is anchored upon common practices and needs of ads testing from interviews and online surveys with ads practitioners.
methodology following our empirical study contains steps as shown in figure .
first we conducted semi structured interviews with developers from different autonomous driving companies.
based on the findings from these interviews we further conducted a large scale survey with ads practitioners to quantitatively validate our findings from the interviews.
we then summarized and triangulated the findings from the surveys and the interviews.
third we conducted an literature review of se papers related to ads testing.
we categorized those papers and developed a taxonomy of ads testing techniques.
by comparing the taxonomy and the emerging needs of ads practitioners we identified the research gaps.
.
interviews interview protocol.
we designed an interview guide1for the semistructured interviews.
the interview began with a short introduction of our study.
then we asked high level questions about the background and expertise of interviewees such as the current job role and how long they have been working on adss the current practices methodologies and tools they used for ads testing and the challenges and difficulties they faced in ads testing.
we first 1the complete interview guide is publicly available here of autonomous driving systems where are we and where should we go?
esec fse november singapore singapore figure research methodology table interview participant background experience responsibilities p1 years recognition algorithm design and testing p2 years simulation testing and real world testing p3 years passenger car development p4 .
years perception system development p5 years ads testing p6 years ads testing p7 .
years perception system testing p8 years ads developing and testing p9 .
years recognition algorithm design and testing p10 .
years ads testing simulation testing conducted pilot interviews based on which we further refined the interview guide.
then we interviewed developers from different autonomous driving companies.
each interview took between minutes and an hour.
the interviews were recorded with permission of participants and then transcribed for analysis.
participants.
we recruited software developers from different autonomous driving companies based on our personal network industrial collaboration and social media.
as shown in table these participants had at least one and a half years of experience .
years on average in ads development and testing.
in addition their responsibilities also covered every aspect of ads testing including modular testing simulation based testing and real world testing.
analysis.
we transcribed a total of hours of interview recordings to text using an audio transcription tool called iflyrec2.
we manually corrected errors in the transcripts.
the first two authors conducted inductive thematic analysis 3using a qualitative data analysis software called maxqda4.
specifically they first independently labeled the transcripts to extract relevant or insightful responses from participants and summarize them into short 3the maxqda codebook is publicly available here texts which are called codes.
then they met each other compared their codes and discussed any inconsistencies.
they continuously refined the codes during the discussion.
then they gro uped related codes into themes.
results of the thematic analysis were regularly reported and discussed with the whole research team.
the final inter rater agreement ratio of the first two authors is .
measured by cohen s kappa .
.
survey since the findings in the interview study are only based on responses from participants we further conducted a large scale survey to validate the interview findings and solicit more feedback from a broader population of ads practitioners.
survey design.
we designed a survey5with questions in sections including background autonomous driving system testing practices and challenges in ads testing needs in ads and follow up.
the background section asked about participants background expertise and their current roles in the company or organization.
the autonomous driving system section asked about the adss participants have worked on.
the testing practices and challenges on ads section asked about three types of ads testing identified from the previous interviews including unit testing simulation testing and on road testing.
for each type of testing we designed multiplechoice questions based on the findings from the interview study.
the options in a multiple choice question were derived from responses of the interview study.
participants can also select others to supplement alternative answers or select i don t know to indicate they have no insights in the particular question.
for each type of testing we also included an open ended question in the end to solicit additional feedback on what participants would like to have or improve on.
the testing needs in ads section listed four common needs identified in the interview study.
we designed a linear scale question for each need and asked participants to provide a numeric response to indicate the importance of each need in a point likert scale from unimportant at all to very important .
the 5the complete survey form is publicly available here november singapore singapore guannan lou yao deng xi zheng mengshi zhang and tianyi zhang follow up section asked participants their contact information and whether they would like to participate in any follow up study.
participants.
we recruited survey participants in three ways.
first we sent out surveys to the autonomous driving companies where our interview participants came from.
second we used the apis provided by twitter and linkedin to scrape the contact information if any of developers with profile associated with autonomous driving.
finally we searched for popular autonomous driving software repositories on github such as apollo and deepdrive .
then we manually identified the public email address if any of those developers contributed to those repositories.
in total we sent out surveys and received responses with a response rate of .
we discarded survey responses since they are not complete.
in the end we collected survey responses that are complete for data analysis.
of survey participants were male were female and did not disclose their gender identity.
of them worked in research institutes worked in technology companies of participants worked in traditional vehicle manufactures and of participants were self employed.
regarding their job roles of participants were in r d positions were in management positions and were engineers including safety engineers software engineers and perception engineers.
of participants had two to three years of working experience in ads had worked in ads for more than three years and had less than two years of experience.
analysis.
for each multiple choice question we plotted the choices made by survey participants in a histogram such as figure .
specifically if a survey participant supplemented an alternative answer that was not identified in our interview study we first checked whether it was similar to an existing choice.
if not we considered it as a unique answer and created a short descriptive label for it.
we then merged all the alternative answers with the same label and plotted their distributions in the histogram as well.
for linear scale questions we calculated the total number and percentage of each option and used the percentage to illustrate survey participants evaluation of the importance of industrial needs such as figure .
for open ended questions the first two authors used maxqda to code each answers individually classified these answers according to sections in this work and discussed with each other to refine codes and classifications.
.
literature review we created the literature review protocol including research question literature search strategy literature selection criteria literature selection procedures data extraction strategy and synthesis of the extracted data following the methodology described in to guide the literature review process.
our research question of literature review is to investigate whether existing research works related to ads testing are adequate for the challenges and needs identified in our interviews and surveys.
the literature search strategy is to search research papers from 28se conferences journals and workshops including icse esec fse ase issta issre icst qrs tse jss and ist.
specifically we used 35keywords to identify research papers related to autonomous driving e.g.
autonomous driving autonomous vehicle traffic scene apollo etc.
6the survey result is publicly available here built a crawler to download papers from publisher websites and found papers that contain at least one of the keywords in their title or abstract.
the literature selection criterion is to include technical papers that propose ads testing methods and empirical papers that discuss challenges and solutions related to ads testing.
we manually reviewed all searched papers and found that papers related to ads among which are specifically about ads testing7.
we categorized these ads testing papers into different categories based on their research questions and solutions.
the result is summarized in section .
.
common practices of ads testing this section summarizes the common practices of ads testing.
section .
discusses the types of adss that our interview and survey participants worked on.
section .
section .
and section .
discuss three commonly used ads testing methods unit testing real world testing andsimulation testing .
we do not separately present the results of the interview study and the survey for two main reasons.
first since the purpose of the survey is to confirm and supplement the qualitative findings from the interview the findings from the interview study and the survey study have a lot of overlap.
therefore if we report the findings separately there will be a lot of redundancy.
second fusing quantitative evidence such as statistics from a large scale survey and qualitative evidence such as quotations from interview participants is more convenient for readers to read and understand the results of the survey.
.
autonomous driving systems under test our participants mainly work on two main types of adss multimodule driving systems andend to end driving models .
multi module driving systems.
the majority of interviewees and survey participants developed and tested multimodule driving systems.
multi module architectures are widely used in industry scale driving systems e.g.
autoware and apollo .
they contain several modules for perception prediction planning and control.
the perception module takes a variety of sensor data as input such as road images point clouds and gps signals to detect surrounding objects.
the prediction module predicts the moving trajectories of these surrounding objects.
given the perception and prediction results the planning module then decides on the route of the ego vehicle.
finally the control module converts the planned route to vehicle control commands including braking force and steering angle.
four interview participants p1 p3 p7 p9 elaborated that the perception and prediction modules in their systems heavily use deep neural networks while the planning and control modules typically contain traditional logic based programs.
this is consistent with a previous study on apollo .
end to end driving models.
of survey participants said they worked on end to end e2e driving models while none of the interviewees worked on e2e driving models.
e2e driving models such as pilotnet and openpilot treat the entire driving pipeline as a single deep learning model from processing sensor data to generating vehicle controls.
during the interview participants pointed out that e2e driving models are less preferred in 7the keyword list venue list and paper list are publicly available at 3fluwcztesting of autonomous driving systems where are we and where should we go?
esec fse november singapore singapore the industry since they cannot handle complicated driving scenarios and often suffer from generalizability issues.
for example p7 said training an e2e driving model requires a large amount of data.
and e2e driving models can easily over fit and perform worse than multi module systems.
common practice the majority of ads practitioners reported to work on multimodule adss rather than end to end driving models.
therefore multi module adss deserve more attention in future research.
.
unit testing of interviewees and of survey participants reported that they conducted unit testing during ads development.
testing target.
in addition to writing unit tests for control logic ads developers also need to test dl models especially those models in the perception and prediction modules.
unlike program source code these models do not have clearly control logic or program states.
ads developers need to manually label and clip driving recordings collected from on road or simulation testing to construct small recording segments for testing these dl models which are referred to as unit tests in ads development.
there interviewees p1 p4 p9 reported that there are too many possible driving scenarios to test and it is time consuming to manually process driving recordings to construct test scenarios.
in addition of interviewees and over of survey participants said their driving systems used at least three of four types of sensors e.g.
cameras lidars radars gps.
this multi modality of sensor data makes it more difficult to generate test cases.
for example data from different sensors with different sample frequencies need to be synchronized e.g.
by timestamp .
furthermore when transforming one type of sensor data such as adding an object other types of sensor data must be updated consistently.
common practice in addition to testing control logic ads developers also need to construct segments of driving recordings to test dl models which take multi modal sensor data as input not just road images.
test metrics.
when measuring the performance of a model ads developers use metrics including accuracy precision recall receiver operating characteristic roc and intersection over union iou .
furthermore of survey participants said they also use specific metrics tailored for different ads modules.
two interview participants p1 p9 elaborated on this consistency is one of their metrics when testing the lane detection model.
the lane detection results between the front and back frames in a video frame should be consistent.
figure common driving scenarios tested in on road testing and simulation testing respectively figure sources of tested driving scenarios common practice ads practitioners not only use common model performance metrics such as accuracy and iou but also custom tailored metrics such as consistency when testing perception models in ads.
.
real world testing all interview participants and of survey participants reported that they have done real world testing.
two types of real world testing are mentioned scenario based testing andon road testing .
scenario based testing.
interview participants p1 p2 p8 p9 and survey participants mentioned they have tested specific driving scenarios in closed automated vehicle proving grounds.
figure shows commonly tested driving scenarios as reported in our survey.
it includes common driving scenarios such as changing lanes following other cars and turning left or right as well as special road sections such as intersections and roundabouts over .
weathers such as rainy days esec fse november singapore singapore guannan lou yao deng xi zheng mengshi zhang and tianyi zhang figure length of on road testing performed by industrial survey participants and snowy days are considered as well.
finally dangerous driving scenarios such as emergency braking and collision are also conducted by and of survey participants respectively.
in the intervew study p1 and p2 said they have built their own scenario database following traffic law and regulations.
p8 and p9 said setting up those driving scenarios were time consuming which often took weeks to month.
figure shows the sources where those driving scenarios were from as reported in the survey .
and of survey participants said those scenarios were based on common real world driving scenes and driving experiences.
of survey participants said they referred to public benchmarks such as cityscapes apolloscape and waymo open dataset .
of survey participants said they referred to traffic laws and regulations.
said they referred to traffic accident reports.
common practice ads practitioners design various driving scenarios based on real world driving scenes public benchmarks traffic laws and regulations and crash reports to test an ads in the field.
on road testing.
in on road testing autonomous vehicles are tested in public roads where various scenarios and unexpected conditions could occur.
in practice ads companies need to carry out long distance on road testing to ensure the reliability of their driving systems.
the number of kilometers an ads travels without human intervention i.e.
km per disengagement in on road testing is used to measure the reliability of their ads.
as shown in the disengagement from california department of motor vehicles waymo conducted over million kilometers of on road testing in and its distance for each disengagement was about km.
during the interview p8 said the entire on road testing required to kilometers which must include different driving scenes such as highways country roads and urban roads.
furthermore p9 mentioned that testers had to sit in the car and record driving data in on road testing.
the collected data would be either saved in local storage or uploaded to cloud platform some of which would be cleaned and labelled for model training and testing.
while on road testing is critical the reality is that due to technical and financial constraints many ads practitioners can only conduct onroad testing within a limited range of mileage.
figure shows that only of participants conducted more than km on road testing and of them conducted to km on road testing.
as discussed in the next section simulation testing is often figure system level metrics used in real world testing considered as a more affordable and safer testing option for the majority of ads practitioners.
common practice on road testing is considered as critical to ensure ads reliability and robustness while only a small portion of ads practitioners have done long distance testing.
test metrics.
compared with metrics used in unit testing more system level metrics are used in real world testing.
as shown in figure four system level metrics are frequently mentioned by survey participants including generalizability passenger s experience robustness and system latency .
generalizability focuses on whether an ads can achieve similar performance in unseen driving scenes.
passenger s experience is another important metric in real world testing.
p4 said when there are many vehicles in a driving scene an ads should not press the brake too frequently which may make passengers uncomfortable.
robustness assesses whether an ads can behave normally when noises external interference or attacks exist.
as an ads is expected to make quick continuous responses to the change of driving scenes system latency is often used to measure the decision making speed of an ads.
common practice test metrics used in real world testing focus more on systemlevel performance including both functional and non functional properties rather than only model accuracy.
.
simulation testing interviewees and of survey participants said they conducted ads testing in a simulation platform such as carla airsim and lgsvl .
when asked why simulation testing is so widely practiced participants mentioned two main reasons.
first of survey participants supported that modern simulation environments are powerful enough to test corner cases that are costly to set up in the real world.
in the interview study p2 and p6 mentioned that for dangerous driving scenarios such as collisions simulation testing is much more preferred due to safety concerns.
as shown in figure more participants did collision test in simulation than in the real world.
second p2 and p9 mentioned that simulators can replay sensor data and vehicle control commands collected from real world testing which can be used to test the performance of a new release of an ads.
of survey participants also support this point of view.
simulation testing is an important part of regression testing in ads development.
when developing an ads it is costlytesting of autonomous driving systems where are we and where should we go?
esec fse november singapore singapore figure the importance of four common needs voted by survey participants.
details of each need are described in section .
and time consuming if a developer tests every commit of ads in the real world.
leveraging the simulation platform industrial practitioners do not need to deploy each commit of ads on the real vehicle and construct real world test scenarios.
common practice simulation testing is widely adopted as a complement for realworld testing.
it is particularly adopted to test new commits as part of regression testing.
test metrics.
test metrics used in simulation testing is similar as on road testing including accuracy based metrics generalizability passenger s experience and robustness.
however as the simulation platform is built as an ideal environment without hardware delay system latency is less considered in simulation testing.
emerging needs this section summarizes four emerging needs of ads testing identified in the interview and survey.
figure shows survey participants agreement on the importance of these needs.
and of survey participants considered need need need and need important or very important.
especially for need and need they are regarded as very important by more than one third of survey participants.
.
need identifying possible corner cases and unexpected driving scenarios as shown in figure and of survey participants rated this need very important andimportant respectively.
while modern driving systems are tested with diverse driving scenarios and extensive on road testing new corner cases are still often found during on road testing.
as p9 said during on road testing on california highways we found it difficult to distinguish lane lines under the sunset.
this was a problem we did not expect when we perform scenario based testing.
based on our conversation with ads practitioners the current industry practice to discover more corner cases seems to be simply performing more and longer on road testing.
however unlike large automotive companies small companiesoften lack resources e.g.
vehicle fleets and on road testing certificates to perform large scale on road testing.
therefore identifying corner cases efficiently is an urgent need for ads practitioners.
.
need speeding up ads testing as shown in figure and of survey participants rated this need very important andimportant respectively.
according to some existing work the catastrophic failure rate of an ads should be minimized to 7to10 9for to hours driving to achieve the goal of high reliability.
to verify that the failure rate falls within one per 107hours one must conduct at least hour testing of an ads about vehicle years .
it is unrealistic to achieve this goal with on road testing.
therefore ads practitioners often resort to simulation testing.
widely used simulators such as carsim support acceleration that only takes one tenth of the time compared with real world testing.
however given the large amount of time required to achieve high reliability i.e.
hour driving test it is still time consuming to conduct test in simulation.
as p2 said our original goal was to do kilometers of testing.
later we found that even if it accelerates the speed by times the speed of the test is still slow compared with our expectation.
therefore simulation acceleration is not a silver bullet to this challenge.
other methods to speed up ads testing are needed.
for example test selection and prioritization approaches have been widely investigated in tradition software systems which can be leveraged to accelerate ads testing.
we discuss this in detail in section .
.
.
need tool support for constructing complex driving scenarios as shown in figure and of survey participants rated this need very important andimportant respectively.
ads practitioners design driving scenarios based on various sources such as realworld driving scenes and traffic accident reports section .
.
after identifying driving scenarios worth testing they need to construct corresponding test cases.
of survey participants found it cumbersome to use toolkits e.g.
domain specific languages libraries etc.
provided by existing simulation platforms to construct a test case of a driving scenario.
take openscenario as an example.
it takes lines of code to construct a simple driving scenario of lane cutting not even to mention complex scenarios.
the main reason is that existing simulation platforms only provide low level apis and domain specific languages dsls to construct driving scenarios.
while such low level api and language design ensures the flexibility and expressiveness to precisely specify arbitrary driving scenarios it imposes significant coding effort.
similar to how google releases keras as a higher level abstraction of tensorflow it would be beneficial to provide a higher level abstraction of the apis and dsls in the simulation platforms.
in addition as mentioned by p8 we already collected traffic accident video from internet but it is still hard to automatically transform them into test cases in simulators.
ads developers wish they can get more tool support that helps them automatically or semi automatically construct driving scenarios in a simulation environment such as translating a natural language description of a traffic scene into the low level code written in apis provided by a simulation environment.esec fse november singapore singapore guannan lou yao deng xi zheng mengshi zhang and tianyi zhang .
need tool support for data labeling as shown in figure and of survey participants rated this need very important and important respectively.
section .
has already discussed that driving data collected in on road testing such as point clouds and road images are often used as test data.
however as mentioned by p8 these driving data need to be manually labelled and clipped first before they can be replayed in a simulation environment or reused to test a dl model.
two typical labels are 2d bounding boxes and semantic segmentation masks.
a 2d bounding box label includes the height and width of a detected object and the type of the object.
and a semantic segmentation mask requires data labelers to manually segment all objects at pixel level.
given the massive amount of driving data collected from on road testing the labeling effort is enormous.
while there have been some assistive labeling tools in recent years labeling driving data still requires many manual effort.
for example amazon sagemaker can automatically assign labels for object detection and image segmentation tasks.
but it requires data labelers to manually go through those labels and make corrections.
several ads companies we have interviewed said they often outsourced the data labeling task to data labeling companies or used crowdsourcing platforms such as amazon mechanic turks .
however even for manually labeled data label quality is still a concern especially for safety critical tasks like autonomous driving.
according to a recent study several well known datasets such as imagenet are riddled with manual labeling mistakes.
therefore ads practitioners wish to get more tool support to analyze recognize and repair labeling errors in their driving data.
literature review and research gaps the previous section summarizes four emergent needs from industrial practitioners in ads testing based on interviews and surveys.
to understand to what extent state of the art ads testing techniques have addressed these needs we surveyed research papers from software engineering conferences and journals and manually assessed them.
this section summarizes our findings and future research opportunities.
.
literature taxonomy figure describes our taxonomy of ads testing techniques based on the papers identified from section .
.
corner case generation.
a variety of techniques have been proposed to generate corner cases for adss.
we categorized them into two lines of research.
one line of research is knowledge based methods .
knowledge based methods generate corner cases using domain specific ontology or metamorphic relations which are designed based on human driving experience traffic accident reports traffic law and regulations.
for example deeptest and deeproad generated corner cases using metamorphic relations from common sense that weather changes should not affect the steering angle prediction of an ads.
ac3r used domain specific ontology and natural language processing to extract information from police crash reports and reconstruct corner cases of crash accidents.
deepbillboard generated corner cases by adding adversarial perturbation patches on real world billbo ards to check whether the e2e driving model keeps the same output of the steering angle.
search based method is another line of research in corner case generation for adss.
these methods aim to find a set of test parameters that introduce behavior discrepancies in an ads such as collisions and lane departures.
to define a parameter search space the majority of search based methods leverage driving patterns .
driving patterns are designed based on the states of an autonomous vehicle such as its position and speed and other vehicles and pedestrians on the road.
the search process is normally guided by manually defined fitness functions such as time to collision and the minimal distance between the ego vehicle and pedestrians.
optimal solutions of such fitness functions are found by applying genetic algorithms .
for example asfault used genetic algorithm to evaluate parameters of road like length and position to make the ego vehicle more error prone on lane keeping task on generated test cases.
abdessalem et al.
proposed a search algorithm that combines the genetic algorithm with a decision tree classifier to guide the test case generation faster towards critical test scenarios.
gladisch et al.
used bayesian optimization as an alternative for genetic algorithms .
test selection and prioritization.
we identified papers on this research direction.
these methods select or prioritize test cases according to the similarity between the vector representation of each test case.
kim et al.
encoded a test case as an embedding vector using the output of a set of selected neuron outputs and used the likelihood based surprise adequacy and mahalanobis distance based surprise adequacy to measure the difference between a test case with others by estimating the density of vector representations of each selected test case.
test cases with high surprise adequacy would be selected as critical test cases.
empirical studies.
we found empirical studies on ads testing.
knauss et al.
and zhang et al.
conducted empirical studies including focus groups and interviews to identify challenges in ads testing.
jahangirova et al.
performed a systematic analysis on metrics of driving qualities and used a mutation analysis to select metrics such as the max lateral position and the standard error of speed as functional oracles for ads testing.
these selected oracles can kill mutants of the e2e driving model with low false alarm rate.
liu et al.
analyzed autonomous vehicle disengagement and collision reports from the california department of motor vehicles and found that the growth of on road testing mileage is not accompanied by the increase of the disengagement ratio.
garcia et al.
investigated on commits and ads bugs in apollo and autoware and classified found bugs into root causes such as incorrect algorithm implementations incorrect condition logic and concurrency.
simulation testing.
se papers have discussed simulation testing.
hu et al.
and masuda et al.
discussed the potential issues in simulation testing including huge input space and precision issues in the simulator.
haq et al.
discussed the reliability of driving data generated by simulators.
leudet et al.
designedtesting of autonomous driving systems where are we and where should we go?
esec fse november singapore singapore figure a taxonomy of ads testing research.
a simulator called ailivesim which is not only focused on autonomous vehicles but can also be used to simulate autonomous ships and autonomous mining machines.
formal verification.
fritzsch et al.
reported their experience of employing bounded model checking on a symbolic model checker nusmv to verify relevant properties for a vehicle control system.
du et al.
used a dsl to specify relationships among driving scenario elements and used stochastic hybrid automata to specify the dynamic behaviors which can then be checked by an existing model checker uppaal smc.
the approach can be used to verify safety related properties of a specific driving scenario.
scenario based testing.
king et al.
proposed a scenario based testing method to test the adaptive cruise control function in ads.
the proposed method can parallel evaluate multiple systems in multiple similar but unknown test scenarios.
and the prototype is safety analysis.
salay et al.
introduced a classification specific safety analysis tool based on failure mode effects analysis.
the method named cfmea is able to identify failure modes and risk levels in perception models of ads.
similarly zhao et al.
used a variant of conservative baysian inference to avoid catastrophic failure due to overconfidence for a few inference tools used in av.
.
gaps and future directions for need among the four emerging needs identified in our study the need of identifying corner cases and unexpected driving scenarios is the one that receives the most attention from the research community.
as discussed in section .
a large number of corner case generation techniques have been proposed for adss.
these techniques have already constituted of good solutions that we believe ads practitioners should try out.
here we summarize several improvement opportunities for the existing techniques.
first for ontology based or metamorphic relation based methods it is worth investigating the generation of more complex driving scenarios e.g.
lane merging overtaking beyond for instance affine transformations and weather conditions.
second for search based methods it is always challenging to define a tractable search space and fitness function for realistic complex driving scenarios.
as a future direction it is worth investigating how to elicit new safety requirements from existing crash reports traffic rules and on road driving recordings.
such requirements can be used to generate new fitness functions or refine existing ones to augment the search space for more missioncritical testing scenarios.furthermore as discussed in section .
all interview participants and of survey participants are now working on multimodule adss.
these multi module adss take multiple types of sensor data as input.
yet the majority of test generation techniques only generate road image data.
therefore it is worth investigating how to generate multi modal sensor data for new driving scenarios.
.
gaps and future directions for need five papers on test selection and prioritization can be applied to address the need of accelerating ads testing .
these techniques can be used to remove redundant testing scenarios and prioritize driving recordings that are more likely to expose errors in an ads.
for example when driving on a highway the ego vehicle often goes straight on a specific lane at a constant speed.
therefore there is no need to replay the entire highway driving recording but only unique driving scenarios during the recording such as lane cutting.
all these technical papers use similarity based test metrics.
researchers can also investigate other kinds of metrics such as confidence based metrics to select or prioritize test cases.
for example deepgini applied gini impurity on confidence to measure the likelihood of misclassification on an input and prioritized test cases with high gini scores.
furthermore instead of using test metrics we also suggest that researchers consider dynamic hd maps which is an intermediate representation of driving scenes used by modern adss.
hd maps incorporate the outputs of perception models and are then fed as input for the following prediction and control modules.
they can be used as a holistic representation for driving scenes.
since current ads test prioritization techniques focus on endto end e2e driving models or only the path planning module in an ads there is an opportunity to develop new techniques for multi module adss.
to account for multi module architectures researchers may want to investigate how to combine test metrics for inner model behaviors such as neuron coverage and surprise adequacy and logic based test metrics such as path coverage to capture the interaction among multiple models and interaction between models and logic based control modules.
one possible solution is to formulate this as a multi objective optimization problem.
a technique should search for a minimal set of test cases that collectively maximize the coverage of individual ml models as well as the path or dependency coverage of an ads.
for example a driving scene at a busy traffic intersection is likely to have higher collective coverage at the model and system levels compared with a highway scene with little traffic since it involves multipleesec fse november singapore singapore guannan lou yao deng xi zheng mengshi zhang and tianyi zhang types of objects e.g.
pedestrians vehicles and traffic lights that may trigger multiple execution paths in an ads and also trigger multiple perception models.
given the large number of possible test case combinations it is worth investigating how to leverage multi objective optimization algorithms to efficiently search for an optimal test set.
.
gaps and future directions for need we have only identified two relevant se papers that addressed the need of constructing complex driving scenarios.
gambi et al.
proposed an automated approach called ac3r that parses crash reports to driving scenarios in a simulation environment.
specifically ac3r leverages nlp techniques to extract key information e.g.
traffic participants and driving actions from crash reports and transform crash information to a lua script to control traffic participants and generate corresponding crash scenarios.
ac3r is limited to some simple crash scenarios like rear end collision of two vehicles.
in addition as crash reports often follow rigid narrative standards ac3r may have a difficult time translating free form driving scene descriptions to an executable driving scene.
as future work it is worth investigating new techniques in nlp and cv to support automated construction of driving scenes from text or video data.
du et al.
proposed a new modeling language that describes specifications in various driving scenarios for the purpose of formal verification.
while this new language is not directly used to construct new test cases it can be adapted as a domain specific language dsl for test generation.
we also searched more broadly online and found some effort in addressing this need from other research communities.
the intelligent vehicle and programming language communities has proposed several higher level dsls to reduce the effort of modeling objects and motions in a simulation platform .
for instance scenic is a probabilistic programming language which enables developers to generate complex traffic jam scenarios with just a few lines of code.
these newly designed dsls are more compact and flexible.
we believe se researchers can also contribute to this line of research.
.
gaps and future directions for need among all four emerging needs the need of tool support for data labeling receives the highest importance rating in the survey study.
of survey participants considered this need as very important or important.
we have only identified one se paper that attempts to address this need.
kim et al.
proposed to surprise adequacy a simple metric to quantify how surprising an input is to a dnn to guide the selection of new road images for labeling.
the result is promising to of manual labeling cost can be saved with negligible impact on evaluation accuracy.
however reducing the amount of labels does not help improve label quality.
despite less effort in this direction so far we have noticed that there is an increasing attention to the general problem of data labeling in the se community.
a case study by amershi et al.
recognized data collection cleaning and labeling as crucial steps in the development pipeline of machine learning applications.
other communities such as database and computer vision have proposed several supervised or semi supervised learning techniques to automaticallylabel data .
we suggest that readers refer to roh et al.
for a detailed survey of data collection and labeling tools built by other research communities.
in the future we believe it is worthwhile developing more automated or semi automated tools such as to support reducing data labeling efforts in adss.
furthermore se researchers can also contribute to data cleaning by developing input validation or outlier detection techniques on driving data.
traditional data cleaning approaches need users to provide a set of specific rules to determine constraints .
such rules are easy to define on tabular data or text data.
however it is challenging to define such rules for sensor data such as videos and point clouds that involve complex driving scenes.
the se community has proposed many techniques to identify failure inducing inputs in software testing and debugging .
for example gulzar et al.
leveraged data provenance to trace error propagation in big data systems and identify fault inducing data.
it would be beneficial to investigate how to adapt or renovate these techniques to identify low quality data that leads to abnormal driving behavior in adss.
threats to validity we discuss the threats to validity following the standard proposed by wohlin et al.
.
external validity.
the external validity concerns about the generalizability of our findings.
to mitigate the threat to external validity we improved the diversity of the interviewees as much as possible.
as shown in section .
these interviewees came from different companies and had different responsibilities.
furthermore to expand the scale of our research we also conducted surveys and these respondents were in a variety of positions and came from various types of companies and organizations as shown in section .
.
in addition ads developed and tested by these interviewees and questionnaire respondents were from level to level which covered all levels of industrial ads.
therefore the interviewees and survey respondents in this study can represent the industrial participants of ads testing.
construct validity.
the construct validity concerns about the design of our empirical study and literature review.
to mitigate this threat for interviews we first conducted two pilot interviews.
based on feedback from these two pilot interviews we refined the interview guide and interview questions.
in addition to not bias participants responses during the interview we conducted semi structured interviews and asked open ended questions which allowed for new ideas and questions to be brought up during the discussion.
though the survey questions were mainly multiplechoice questions we allowed respondents to provide alternative answers.
also open ended questions were added in the survey for respondents to supplement questions and answers not included in the survey.
in the literature review we used broad keywords to include as many relevant papers as possible.
additionally with manual filtering we removed papers that were not relevant to autonomous driving testing.
though in the literature review process we did not apply literature quality assessment as described in the quality of searched papers can be assured because they are all published on high quality se conferences and journals.
we did not create detailed data collection forms for searched papers whichtesting of autonomous driving systems where are we and where should we go?
esec fse november singapore singapore might affect the categorization of reviewed papers.
the process of data collection will be refined in the future work.
internal validity.
the internal validity concerns about how accurate participants responses may reflect their real needs and whether there are other compounding factors that may affect the results.
specifically since interview participants were developers from technology companies some of them may not faithfully reveal the exact and most emergent needs from their team due to confidentiality concerns.
when designing the interview we tried our best to avoid conversations that may involve technical details or make them feel uncomfortable to answer.
in addition before each interview we shared the interview guide with the participant and informed them that our goal was to solicit high level feedback rather than technical details.
to avoid mistakes and biases in the thematic analysis step the first and second authors carried out this step separately.
then two authors continuously adjusted the extraction result until the inter rater agreements between the two coders reached .
in cohen s kappa .
also the collected information was regularly reported and discussed in the whole research team.
conclusion this paper presents an empirical study on the current practices and needs of testing autonomous driving systems.
through an interview study and a large scale survey we identified seven common practices and four common needs of ads practitioners.
these findings provide a deep understanding about how ads practitioners test autonomous driving systems in practice and what kinds of tool support they find helpful.
furthermore we did a literature review of related ads testing research from the se community and assessed to what extent existing work can address those industrial needs.
we found that though one need identifying possible corner cases and unexpected driving scenarios is widely investigated by the se community the other three needs are under investigated.
furthermore most existing work is designed for end to end driving models while multi module driving systems are widely adopted nowadays.
based on these gaps we proposed four future directions to build better tool support for testing autonomous driving systems.
we believe there are many research opportunities for se researchers and therefore call for more attention and effort towards these future directions.