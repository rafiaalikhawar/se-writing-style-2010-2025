lastpymile identifying the discrepancy between sources and packages.
authors duc ly vu university of trento it fabio massacci university of trento it vrije universiteit amsterdam nl ivan pashchenko university of trento it henrik plate sap security research fr antonino sabetta sap security research fr this paper was written within the h2020 assuremoss project that received funding from the european union s horizon research and innovation programme under grant agreement no .
this paper reflects only the author s view and the commission is not responsible for any use that may be made of the information contained therein.
1esec fse august athens greece assurance and certification in secure multi party open software and services assuremoss no single company does master its own national in house software.
software is mostly assembled from the internet and more than half come from open source software repositories some in europe most elsewhere .
security privacy assurance verification and certification techniques designed for large slow and controlled updates must now cope with small continuous changes in weeks happening in sub components and decided by third party developers one did not even know they existed.
assuremoss proposes to switch from process based to artefact based security evaluation by supporting all phases of the continuous software lifecycle design develop deploy evaluate and back and their artefacts models source code container images services .
the key idea is to support mechanisms for lightweigth and scalable screenings applicable automatically to the entire population of software components by machine intelligent identification of security issues sound analysis and verification of changes business insight by risk analysis and security evaluation.
this approach supports fast paced development of better software by a new notion continuous re certification.
the project will generate also benchmark datasets with thousands of vulnerabilities.
assuremoss open source software designed everywhere secured in europe .
more information at .eu.
duc ly vu msc is a phd student at the university of trento italy.
he works on the use of automated techniques to improve software security at a scale.
contact him at ducly.vu unitn.it .
fabio massacci phd is a professor at the university of trento italy and vrije universiteit amsterdam the netherlands.
he received the ten years most influential paper award by the ieee requirements engineering conference in .
he is the the european coordinator of the assuremoss project.
contact him at fabio.massacci ieee.org .
ivan pashchenko phd is a research assistant professor at the university of trento italy.
he was awarded a silver medal at the acm microsoft student graduate research competition at esec fse.
he is unitrento main contact in continuous analysis and correction of secure code work package for the assuremoss project.
contact him at ivan.pashchenko unitn.it .
henrik plate msc is a senior researcher at sap security research.
his current research focusses on the security of software supply chains and the use of open source components.
contact him at henrik.plate sap.com .
antonino sabetta phd is a senior researcher at sap security research.
he is the technical leader of the assuremoss project and the continuous analysis and correction of secure code work package leader.
contact him at antonino.sabetta sap.com .
how to cite this paper duc ly vu fabio massacci ivan pashchenko henrik plate and antonino sabetta.
lastpymile identifying the discrepancy between sources and packages.
proceedings of the 29th acm joint european softwareengineering conference and symposium on the foundations of software engineering esec fse .
acm press.
.
license this article is made available with a perpetual nonexclusive non commercial license to distribute.
the graphical abstract is an artwork by anna formilan.lastpymile identifying the discrepancy between sources and packages duc ly vu ducly .vu unitn .it university of trento italyfabio massacci fabio .massacci ieee .org university of trento italy vrije universiteit amsterdam netherlandsivan pashchenko ivan .pashchenko unitn .it university of trento italy henrik plate henrik .plate sap .com sap security research franceantonino sabetta antonino .sabetta sap .com sap security research france abstract open source packages have source code available on repositories for inspection e.g.
on github but developers use pre built packages directly from the package repositories such as npm for javascript pypi for python or rubygems for ruby .
such convenient practice assumes that there are no discrepancies between source code and packages.
these differences pose both operational risks e.g.
making dependent projects unable to compile and security risks e.g.
deploying malicious code during package installation in the software supply chain.
our empirical assessment of popular packages in pypi with an analysis of around 10m lines of code shows several differences in the wild modifications cannot be just attributed to malicious injections.
yet scanning again all and whole most likely good but modified packages is hard to manage for foss downstream users.
we propose a methodology lastpymile for identifying the differences between build artifacts of software packages and the respective source code repository.
we show how it can be used to extend current package scanning practices for malware injection which only covers less than of the code of deployed packages .
ccs concepts software and its engineering software configuration management and version control systems security and privacy software security engineering permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
copyrights for components of this work owned by others than acm must be honored.
abstracting with credit is permitted.
to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
request permissions from permissions acm.org.
esec fse august athens greece association for computing machinery.
acm isbn .
.org .
.3468592keywords open source software software supply chain python pypi acm reference format duc ly vu fabio massacci ivan pashchenko henrik plate and antonino sabetta.
.
lastpymile identifying the discrepancy between sources and packages.
in proceedings of the 29th acm joint european software engineering conference and symposium on the foundations of software engineering esec fse august athens greece.
acm new york ny usa pages.
.org .
.
introduction the expression software supply chain refers to anything that goes into or affects your code from development through your ci cd pipeline until it gets deployed into production .
in the past decade free and open source software foss has become an integral part of the software supply chain as much as of codebases contain open source code and to of enterprise codebases comes from open source.
one benefit of foss is that source code and additional metadata is publicly available for audit review and even modification.
developers rely on this information e.g.
number of github stars number of downloads from libraries.io to decide whether to add a foss project as a software dependency into their projects .
organizations with high security requirements e.g.
government organizations or vendors of commercial enterprise software commonly establish vetting processes to ensure the quality and security of 3rd party software and services .
in the case of foss this evaluation is performed mostly by manual reviews and automated scans of the source code repository of each dependency .
in theory once code is checked developers could download software dependencies as source files in tarballs and build them in house.
yet this process can be time consuming and requires knowledge of the build systems .
in practice developers download pre built packages from repositories such as npm for javascript pypi for python or rubygems for ruby under the comfortable assumptionesec fse august athens greece duc ly vu fabio massacci ivan pashchenko henrik plate and antonino sabetta startreleasingbuild additional code generation e.g.
swagger codegen release ready codeupload to package repo e.g.
twine generated artifacts possibly os binaries test coverage log documentation automatic generated code select filesfor reviewgenerated artifacts in package repo pypi possibly os binaries test coverage log documentation automatic generated codeautomated check for malware e.g.
pypi malware checks selected files e.g.
setup.py adminreviewverdictsleave artifactpublished benign removeartifactmalicious development build and publication security reviewsource code repo e.g.
github build systems ci cloud services such as travis ci developers workstation etc.
package repo pypi config info ci credientials source coderepo credentialspackage repo credentials figure current development build publication and security review pipeline of pypi packages that no discrepancies are introduced in the last mile between the source code and their respective packages .
yet such discrepancies might be introduced by manual or automated build tools e.g.
metadata python bytecode files or for evil purposes.
for example a backdoor was inserted into the pypi package ssh decorate to collect the users ssh credentials and exfiltrate them to a remote server .
reproducible builds could be a solution.
for it to be practical modifications need to be the exception rather than the norm.
unfortunately the opposite is true on the field.
indeed in the npm ecosystem packages are not easily reproducible from the source code .
the same applies to the pypi ecosystem see section .
in the absence of reproducible builds a vetting process must be extended to cover the risk of malicious code injection in the last mile.
since applications have many direct and transitive dependencies and because every new version has to be verified scalability and integration with existing security review pipelines are key.
these requirements clash with the resources at hand for foss repositories less than ten pypi administrators oversee package owners.
at the time of writing for every new upload pypi s vetting pipeline only checks a script called setup.py for malicious code that would execute upon package installation .
although setup.py is commonly targeted by attackers malicious code is also injected other locations.
other approaches also require a significant effort to reduce false positives and to improve the quality of hand crafted signatures .
while suspicious packages or updates might be flagged too many false alerts are generated for benign packages .
in the administrators had to evaluate new updates per day with an average of files generated by more than developers .
thus the cost of even a single false positive in the evaluation must be multiplied by those numbers.
a key observation is that in code injection attacks only a minimal part of the codebase is modified .
one could simply focus on the last mile differences between the source code and the submitted packages.
hence our first question rq1 can we effectively and efficiently identify differences?a basic solution already exists git log .
for each line in an artifact we check whether it is or at least was in the repository at some point.
by iterating over all commits revisions we ensure that we collect everything in the source code repository and we eliminate the need for identifying the pair of git release tag and pypi release to be compared.
unfortunately that does not scale as git log needs to loop over all revisions and spawns a heavy git process each time it is invoked.
we could also use diffing techniques but they require a mapping of each pypi release onto the corresponding git tag or release which does always exist.
our algorithm lastpymile is a feasible alternative to this problem.
by cleverly combining package scraping and artifact hashing we can extract these differences in a scalable way.
then we can analyze how big is the gap in the field rq2 how big are the normal differences between source code and package repositories?
we show that for more than popular packages in the pypi ecosystem such differences are pervasive.
if a package code differs from the published source code one cannot assume that it has been maliciously modified.
differences are too many of artifacts and of files in our sample and too diverse for reproducible builds to be a solution.
yet only few modifications happen in python source files .
of files so that vetting might be a feasible alternative.
finally we can try to determine whether this solution can make a difference on the end goal improving the vetting and coverage of scanners while keeping the number of false alerts manageable for pypi maintainers given the imbalance ratio between the pypi maintainers and the number of packages .
rq3 can lastpymile be combined with package scanners while keeping the number of alerts manageable by a human?
to be effective in the field we should allow developers and development organizations to use the same tools to scan the source code repository of a package as part of their vetting process.
without protecting their investments in licenses workflows and developer education an excellent technical solution would be doomed to fail.
we show that such an approach is possible with lastpymile .lastpymile identifying the discrepancy between sources and packages esec fse august athens greece terminology source code are human readable instructions that others could check to understand the functionality of a software project.
artifact is a software entity that contains all necessary items e.g.
files to run the software and can be installed or directly used by project consumers.
typically they are produced by the build process .
in python built distributions e.g.
wheels are generated from the source distributions e.g.
tarballs .
package exists to be installed or deployed and is a collection of pre built and versioned artifacts for one or more target environments that is made available to consumers as an entity.
repository is a cloud provider with a versioning system to store and access several versions of a software project.
a source code repository stores and maintains the project source code and a package repository distributes prebuilt packages to consumers.
an artifact present in a package available from a package repository is a published artifact .
phantom is a software entity e.g.
files lines of code present in an artifact but does not match the one submitted to the source code repository.
we use phantom lines to refer to lines of code and phantom files to refer to entire files.
background .
the last mile from source to package figure shows a typical package process of releasing a python package in pypi that consists of three main stages development build and distribution and security review.
the primary activities of the development stage mainly happen at a source code repository e.g.
github gitlab bitbucket etc.
.
at this stage developers write all the code of a project.
developers may run various tools to test the functionality of the project and the absence of security vulnerabilities.
if a project is open source other people could access the code check it and suggest improvements.
the source code repository is often an essential source of information for the developers to decide the quality of a software .
when developers decide to make the software version available for other people i.e.
make a release they move the code to the build stage.
at this stage automated tools such as travis ci jenkins appveyor or github actions use the information stored in the project configuration files to build it.
these tools fetch the source code of the package and execute the build scripts that collect all the necessary dependencies add package metadata generate code e.g.
swagger codegen and create artifacts that are ready to be distributed like source archives linux or windows binaries test coverage logs and documentation.
at the publication stage developers upload the artifacts to a package repository e.g.
pypi npm maven central either .python .org glossary term source distributionor sdist .python .org overview manually or automatically by using the build tool from the packaging stage.
most consumers will actually use the version of the software stored and published via package repositories.
uploaded artifacts need to go through the security review stage of a package repository.
in pypi pypi administrators run multiple checks see subsection .
on uploaded artifacts.
the checks will generate a verdict if an uploaded artifact contains suspicious behavior.
the administrators are then reviewing the verdicts to decide to keep the artifact.
the match between the source code version of a project and the packages that correspond to that version is taken for granted .
however several tools and humans are involved at different stages of the pipeline and some actions may result in a published artifact containing code that is not present in the source code repository.
during the packaging stage building tools add metadata files and augment existing code files e.g.
setup.py with information such as license timestamp3 release version etc.
developers also use tools such as swagger codegen that automatically generate code files e.g.
server stubs and client sdks for apis .
developers may also change the code of a published artifact directly to backport a bug or a vulnerability fix .
developers actions might create difficulties to connect the distributed artifacts and their source code repositories figure .
example .
the pypi page of package robotframeworkselenium2library points to the github repository robotframework seleniumlibrary that contains the code for the releases before v1.
.0and after v3.
.0a1.
the code for other releases is stored in a different github repository robotframework selenium2library .
in this example comparing a specific package version on pypi with the corresponding github tag for the releases in between v1.
.0and v3.
.0a1does not work as the corresponding code is not present in the referenced source code repository.
one could only find the correct mapping between source and package repositories by manually inspecting repository descriptions.
summary differences between the source and package repositories may be due to normal activities.
.
software supply chain attacks software supply chain attacks occur when malicious or vulnerability is injected into differnt stages of the software development chain .
ohm et al.
studied several attacks on different ecosystems and found hijacking and typosquatting attacks to be the most common.
compromising the package owner s credentials would allow attackers to inject malicious payloads into the existing artifacts so that users will download and install them.
some examples of attacks are the injection of backdoors into pypi ssh decorate package ruby rest client package or npm even stream .com pypa wheel issues 248esec fse august athens greece duc ly vu fabio massacci ivan pashchenko henrik plate and antonino sabetta robotframework selenium2library v3.
.0a2 v3.
.
robotframework seleniumlibrary v1.
.
v5.
.
v2.
.
robotframework oldseleniumlibrary v2.
v2.
.2robotframeworkseleniumlibrary v2.
v5.
.0robotframeworkselenium2library v1.
.
v3.
.
pypi .
.
pypi .
.
github pypi when developers move stuff around repositories with different names the automatic traceability between package and source code repositories becomes hard as links in packages solid lines can point to the latest but possibly wrong source repository.
a human must read the docs to find the correct github repository.
figure github tags and pypi releases of seleniumlibrary table discrepancies in files of legitimate and malicious typosquatting packages distrib shows the number of lines of code that are not present in the source code repository for the requests and flask legitimate packages as well as the difference between the malicious packages request and urlib3 from the original legitimate source code repositories of the benign packages the targets reported at filename lines of code source distrib requests .
.
requests models.py flask .
.
flask templating.py urlib3 .
.
setup.py request .
.
hmatch.py package .
attackers can commit malicious code into a source code repository .
package name squatting attacks are more prevalent than package hijacking .
in typo and combosquatting attacks adversaries inject a malicious payload into the code of a popular package.
then they release this new package with a name nearly identical to the name of the original package to trick package users who mistype the package name and install the malicious one.
this attack becomes especially attractive considering the limited automatic controls integrated into the package publishing process and the certain unbalance concerning the number of package users and pypi administrators moderators 40k to .4several attempts were made to identify the typo and combosquatting packages present in the package managers .
example .
a typosquatting pypi package urlib3 impersonated the popular package urllib3 .5urlib3 contains malicious code to exfiltrate user information to a remote server.
urlib3 has a single release urlib3 .
.
.tar and the same github url as urllib3 .
4data collected on feb from .org .org project urllib3 .com urllib3 urllib3table shows the modified files in both legitmate packages requests and flask and malicious packages request and urlib3 .
both kinds of packages differ from the source.
summary discrepancies can also be due to malicious reasons.
attackers can inject malicious code or restore vulnerable code for later exploitation when a package is installed.
.
reproducible builds as an ideal solution reproducible builds is a set of development practices that create an independently verifiable path from source to published artifacts.
they could be the ideal solution to verify that no vulnerabilities or backdoors have been introduced during the build process.
however to achieve the reproducibility of the build process we must eliminate varying elements in release pipelines.
for example builds should not include any cpu timestamp or locale information in distributed artifacts .
hence reproducible builds require a significant overhaul in the languagebased package managers such as pypi or npm because current release pipelines augment packages with more information such as metadata debug data or automatically generated code files see section .
.
some free software distributions such as debian have procedures to identify the original source code and a difference file that includes all changes made specifically for debian including all files related to packaging .
however after trying for seven years debian states that it is a stretch to say that debian is reproducible .
summary reproducible builds are challenging to achieve given the diversity of packaging tools and current implementations of the release pipeline e.g.
embedding timestamp into artifacts .
.
current pypi packages scanners table summarizes the existing tools that support identifying malicious code injections in python packages.
several scanning tools parse files into abstract syntax trees ast and perform rule based searches on their nodes.
applicationinspector and ossgadget use regular expressions to identify suspicious code lines.
however the tool authors mention that their tools generate many false positives if run on the entire package code .
this high number of false positives is to be expected.
establishing a socket connection to a server 2s socket.socket socket.af inet socket.sock stream 3rip m tixl jqyl jix n y4 0na sending the encoded data via the socket 5s.connect base64.b64decode rip listing malicious code snippet opening of a socket to an encoded network address.
.debian .org reproduciblebuildslastpymile identifying the discrepancy between sources and packages esec fse august athens greece table existing tools for analyzing pypi packages regex regular expression bases on the raw lines of code while ast abstract syntax tree requires transforming the code into a tree.
the hybrid analysis consists of metadata ast and dynamic execution of an artifact tool name input technique malware checks setup.py file static regex maloss package hybrid analysis application inspector artifact regex ossgadget package artifactstatic regex ohm et al.
artifact static ast bertu setup.py file static ast decoding a bundle of certs in pem format 2der certs base64.b64decode match.group for match in pem certs re.finditer pem bundle listing legitimate b64decode call in the urllib3 package consider the code snippets from listing and listing .
both code snippets use b64decode function from base64 library.
listing is a malicious fragment that collects the user information and sends it to a remote server via a network socket while the code in listing simply decodes a benign certificate.
a package checking tool that consider b64decode function as suspicious since it is often used in malicious packages will produce a true positive for listing and a false positive for listing .
unfortunately b64decode function is widely used for benign purposes and the tool will generate many false positive alerts as it has no way to distinguish benign from malicious usage without further analysis.
to avoid being overwhelmed by false positives the current pypi security review called malware checks scans only the installation script setup.py .
unfortunately several known attacks had malicious code injected into different files.
hence the review of only setup.py files is not enough.
example .
the typosquatting package jeilyfish mimicked the popular package jellyfish the first l is an i to steal ssh and gpg keys .
there are two injected files setup.py and jellyfish.py in the typosquatting package.
the malicious code is stored in the jellyfish.py as shown listing and then being implicitly called by the package installer via the packages option in the setup.py file listing .
process pure python modules in jeilyfish 2packages listing the file jeilyfish .
.
setup.pytable number of source code repositories found by locations metadata of a package contains multiple fields such as homepage codepage.
package homepage is the main page which contains additional information about a package e.g.
documentation location github repospercentage homepage metadata .
codepage metadata package homepage .
pypi homepage .
total github repos 1zauthss payload decoding and executing the obfuscated payload 3zauthss base64.b64decode zauthss 4zauthss zlib.decompress zauthss 5exec zauthss listing the file jeilyfish .
.
jeilyfish jellyfish.py summary if scanning one file in a package is feasible but not enough and reviewing an entire package is unfeasible due to the high number of false positives a different solution is needed.
rq1 lastpymile to identify code injection the upper part of figure shows the typical process of the security review process in package repositories e.g.
pypi for identifying suspicious artifacts that might occur during the release of a software project.
first the code in the published artifact is undergoing code review and scanning by the pypi administrators by running security checks .
currently they are using two checks setuppatterncheck and packageturnovercheck see section .
depending on the automated tool used by the maintainers this scanning could be done on the entire artifact for backdoor injection e.g.
bandit or on its files e.g.
malware checks .
then the output of the scan is used to decide whether the artifact should be uploaded to the package repository.
the bottom part of figure shows how lastpymile can augment the traditional security process.
as a preliminary lastpymile looks for the github urls of a pypi package in various places including package metadata pypi and package homepage.
table shows the number of github urls we found.
most of the packages declare their github repositories in the metadata available on pypi.
in step lastpymile iterate all commits to compute all file hashes and collect line contents from a source code repository.
to ensure that all the files and lines are collected lastpymile processes commits from all branches and tags in the github repository.
lastpymile supports processing the github repository in parallel so that multiple commits can be processed simultaneously.
besides to avoid processing the same commits in different branches lastpymile maintainsesec fse august athens greece duc ly vu fabio massacci ivan pashchenko henrik plate and antonino sabetta get apackagepypi select filesmalwarechecks foss alternative banditchecksget an artifact comprehensive security reviewidentify source code reposourcecode reviewotherscannersoutput review lastpymileidentify source code repo get an artifacthash files collect lines from repo step hash files collect lines from artifact step identify phantom files and lines step filter inputfilteroutput figure lastpymile in the context of the overall security review pipeline step hashing files and lines from source code repository require the github url of the package githuburl set of file hashes in the repository hs set of lines of files in the repository ls cloned dir clonerepositorytodisk githuburl commits getcommitsfromrepo cloned dir for each c commits do fs checkoutfilesincommit c for each f fsdo h h sha256 f l l readfile f return set of file hashes lines hs ls a shared set of already processed commits for synchronizing the processing tasks.
example .
distributed artifacts nameko .
.
.rcx contain the source code that is stored in the v3.
.
rc branch.
after collecting all the file hashes and lines from the github repository in step lastpymile processes a package artifact to calculate file hashes and collect file lines.
finally lastpymile compares file hashes and lines of distributed artifacts and those in the source code repository to report the phantom files and lines step .
lastpymile takes only .
seconds for scanning jellyfish artifact that consists of unique files and lines on a laptop with four cpu cores and gb ram.
considering the top four most downloaded packages six idna python certifi ands3transfer as shown in table lastpymile is 16x faster than the default iterative approach that relies on calling git log command for every line of an artifact because lastpymile preproceses all commits in a repository and require only a single pass over all code while git log must iterate over all revisions each time it is invoked.
table compares the number of total files and lines present in the analyzed files with the phantom files and lines reported bylastpymile .
we observe that more than half of setup.py files are phantom while the number of phantom lines of codetable running time comparison between lastpymile and git log approaches both approaches had been run in the same environment.
the differences obtained by both the approaches are the same e.g.
number of phantom files and lines package git log seconds lastpymile seconds certifi idna six s3transfer step hashing files and lines from an artifact require a the pypi package artifact to be evaluated set of file hashes in an artifact hp set of lines of files in an artifact lp artifact urls as obtainartifacturls p local artifact downloadartifactfrompypi a fs uncompressartifact local artifact for each f fsdo h h sha256 f ls readlinesfromfile f for each l lsdo lp l l return set of file hashes lines hp lp in the setup.py files is six times smaller compared to the total number of lines in setup.py files.
globally the number of phantom lines of code is times smaller.
table shows that a median artifact contains two phantom lines that include at least one api call e.g.
execute some function and two lines that import some library.
summary lastpymile enables checking the entire codebase of a published artifact 16x faster than the git log approach as lastpymile requires only a single pass over all commits.lastpymile identifying the discrepancy between sources and packages esec fse august athens greece step identifying phantom files and lines in distributed artifacts require hs ls hp lp set of phantom files hd set of phantom lines ld for each h hpdo ifh hsthen hd hd h for each l lpdo ifl lsthen ld ld l end if end if return set of phantom files hashes lines hd ld table number of unique phantom files and lines versus total the columns in the left are the files and lines that are processed by the pypi malware checks and existing scanning tools while lastpymile only processes the phantom files and lines on the right.
phantom files are counted by their unique hashes total different setup.py all setup.py all files lines table statistics about lines not in the repo mean min q25 median q75 max apis imports data collection to select the sample of python packages for our study we start with the list of the top most downloaded packages which is the established approach to study the python ecosystem adopted both in academia and industry and .
we identify packages of the selected python packages that use github to maintain their source code.
among these packages are unique repositories .
for simplicity here we focus only on packages that claim their source code is on github.
table shows the characteristics of the collected repositories.
three repositories contain only two commits8 while several repositories had tens of thousands of commits e.g.
piphas commits9 .
as we aimed to have a tool to be runnable as you wait we set a timeout period of five minutes for analyzing all artifacts of a given package.
as a result the selected packages resulted in artifacts.
we had to exclude artifacts belonging to surviving packages with 8for example .com datamade probableparsing 9at the time of data collectiontable descriptive statistics of github repositories for the selected packages tags includes github tags and branches of a github repository.
unique files and lines are determined by their hashes and contents respectively number of mean min q25 median q75 max tags commits unique files unique lines table number of processed packages and artifacts the processing time threshold is set for a package.
we exclude artifacts that predate the creation time of a github repository step result top most downloaded packages processed artifacts proc.
time min artifacts with corresponding tags in github final artifacts linkable to source early versions being developed on versioning control systems other than git and or with the commit history not being included when moving to github.
we could not use them in our analysis as there was no source code to compare.
the final dataset comprises artifacts from packages of them are gzip are wheel are zip and are eggs.
after checking the differences between the number of different files and code lines between source and package repositories figure we observed that 66artifacts featured a huge number of changes different files .
we manually analyzed those artifacts and found that the explanation lies in developers moving stuff around across repositories making it close to impossible to identify source code repositories by automatic means.
the example in figure requires one to actually read the documentation.
besides the robotframework selenium2library in example we found that sas7bdat package first hosted its source code on github but then was moved to bitbucket.
the other reason for not being able to locate the corresponding source code of a package automatically is the usage of submodules by developers.
we removed such artifacts from our analysis as their source code could not be found automatically.
hence the final list of analyzed artifacts comprises artifacts.
table summarises the number of analyzed packages and corresponding artifacts.
example .
thegsutil package refers to a github repository googlecloudplatform gsutil with two submodules.
for both pyrogram .
.
py3 none any.whl and pyrogram .
.
py3 none any.whl artifacts we could not find the related github tag or release.
our manual analysis of these packages did not reveal malicious injections.esec fse august athens greece duc ly vu fabio massacci ivan pashchenko henrik plate and antonino sabetta outliers removed typically a mismatch between declared and actual versions unique files artifacts a files differing between source and package0 unique lines b lines differing between source and package figure files and lines differing between source and package repositories artifacts files020406080100percentagechanges in python files changes no changes figure percentage of different kinds of changes in artifacts and files rq2 differences between source code and package repositories to answer rq2 first we compared the code distributed in pypi artifacts with the corresponding source code repositories.
figure shows that of artifacts and of files present in pypi have changes with respect to the source code repository.
i.e.
they might have malicious code injected during the package release process.
however only .
of artifacts and .
of files have changes in python files while of artifacts and of files have changes in other files.
these findings suggest that it might be promising to limit the process checking for malicious injections to those artifacts and files that have discrepancies as the other artifacts cannot have malicious injections during the release process.
in this paper we focus on the changed python files as they mightbe the target of attackers for injecting executable malicious commands.
metadata files have a great impact on the number of differences between source code and package repositories table shows that a median artifact has four metadata files10and nine python files twice more .
this difference is also visible at code line level a median artifact has lines in phantom metadata files and lines in phantom python files.
we observe that nearly of python files that have differences with respect to the source code repository are init .pyand setup.py files .
most likely this happens since the building tools introduce some additional information e.g.
timestamps versions etc.
into these files during the packaging process.
similarly the version.py and version.py files are used to identify the package version from a git tag or release automatically.
table shows the top ten regular and api calls related to networking and system in the python files that differ from the source code repository.
many files have calls to such functions as urlopen socket.socket request to open urls and make http requests subprocess.popen and exec to open files.
usage of these functions could be harmful.
at the same time these functions are often used for legitimate operations and one cannot simply mark all lines that include a call to possibly suspicious apis as actually suspicious there would be an unmanageable number of false alerts.
10we identified metadata files as generated by packaging tools e.g.
wheel dependency declaration files e.g.
requirements.txt and documentation files e.g.
readme.md lastpymile identifying the discrepancy between sources and packages esec fse august athens greece table differences between package artifacts and their source code repositories unique files are the files having different hashes while number of lines are the total number of lines in an artifact files mean min q25 median q75 max number of unique files python metadata number of lines python metadata table top different phantom python files in our sample.
phantom files are present in the package source code but have different content than the omonimous file in the source code repository.
the same file name might occur multiple times in the same package with different paths.
init.py and setup.py are the most common phantom files.
filename phantoms percentage init .py .
setup.py version.py .
version.py .
utils.py v1.py .
v2.py .
base.py .
client.py .
exceptions.py .
table top ten api calls in modified python files api calls are grep from the line contents using a set of regular expressions.
we exclude some internal calls of the packages.
top occurences network system occurences init urlopen isinstance socket.socket datetime subprocess.popen ttinfo exec len request read http.request getattr s.setsockopt super requests.post hasattr request.get join os.chmod append platform.system summary the code distributed via package repositories has many changes with respect to the code stored in the corresponding source code repository.
on average there are .
of artifacts and .
of files have changes in python files.
rq3 lastpymile combined with other package scanners the combination of lastpymile with existing security scanners is essential for two reasons first it allows to reuse mature detection techniques of foss and commercial security scan tools.
second by so developers and development organizations can use the very same tools in different stages of the security review process which protects their investments into software licenses the design and implementation of review workflows and developer education.
as shown in figure pypi administrators can achieve the reuse by filtering either the input or the output of such security scanners.
they can feed tools operating on single files malware checks modules or procedures bandit checks with input containing phantom lines which is expected to reduce both the number of findings and the tool s runtime.
scanning tools performing the whole program or inter procedural analyses continue to work on the package s entire code base.
still their output can be filtered to only show findings in phantom lines.
in this paper we focus on input filtering and show the results of combining lastpymile with two well known malware checking tools that are broadly used in the pypi ecosystem warehouse malware checks tool is used by pypi to check the suspicious code lines in every package uploaded to pypi.
at the time of writing the tool supports two checks setuppatterncheck11for performing regular expression based checks of the content of setup.py files for suspicious patterns on package upload and packageturnovercheck12for performing daily scans for suspicious behavior about package ownership.
conceptually malware checks is close to other open source tools for auditing foss packages that rely on regular expressions to the whole artifact.
bandit is a tool supported by the python code quality authority.
bandit was designed to find common security issues in python code by scanning all the files included in a software artifact.
for each file in the artifact the tool creates an abstract syntax tree ast representation and performs rule based analysis plugins of the ast nodes.
most of the bandit rules focus on the vulnerabilities in python code e.g.
start a process with a function vulnerable to shell injection formalware checks we focus on setuppatterncheck .
even though this tool currently only checks setup.py files we have extended it to scan all files of a software artifact.
for the bandit tool we have used the default set of bandit rules and then extended them with additional rules so that the tool is capable of findings all malicious lines of code injected into python packages known to be used .com pypa warehouse tree master warehouse malware checks setup patterns .com pypa warehouse tree master warehouse malware checks package turnoveresec fse august athens greece duc ly vu fabio massacci ivan pashchenko henrik plate and antonino sabetta table lastpymile on malware checks and bandit alerts malware checks alerts x rules on lines while suspicious bandit alerts y rules on files .
the setup.py column of malware checks alerts is what happens now in pypi artifact type in setup.pyproblem size malware checks alerts suspicious bandit alerts files locs all files locs setup.py coverage setup.py setup.pywhole pkglastpy milesetup.pywhole pkglastpy mile urllib3 .
.
benign80 requests .
.
setuptools .
.
urlib3 .
.
maliciousy request .
.
n setup tools .
.
y in typosquatting attacks .
our rule set checks for suspicious api calls e.g.
exec imports e.g.
socket and strings e.g.
an url .
our rules can be found at .
to illustrate how the malware checking tools perform on the artifacts without malicious payloads we compare their outcome on three example benign artifacts that correspond to the following malicious artifacts.
we collected the malicious artifacts from the real attacks by contacting the researchers who reported the attacks.
urlib3 .
.
malicious code was injected into the setup.py file.
it triggered automatic extraction of data and sending it to a remote server using the socket library.
request .
.
while the setup.py file contains the code to trigger the malicious execution from the hmatch.py file the actual malicious functionality was implemented in the hmatch.py file scanning the computer network and sending results to the remote server using urllib3 library.
setup tools .
.
the malicious code injected into thesetup.py file triggered automatic extraction of sensitive data and sending it to the remote server via socket library.
table presents the results of malware checks and bandit tools scans of the selected artifacts.
since the malware checks tool was primarily designed to scan only setup.py files we report the number of findings the tools produced on the setup.py .
then we present the number of alerts when we run the tools on the whole package.
finally we show the number of alerts the tools produced on the lines of phantom code as reported by lastpymile .
the replication package for table can be obtained at .
we observe that malware checks produced at most three alerts on each of the benign and malicious artifacts when only the setup.py file was considered.
while this amount of alerts is manageable by humans checking only the setup.py files allows one to have coverage of around of the total code base of the analyzed artifacts except the malicious request artifact where scanning setup.py has generated coverage of .
.
when malware checks was executed on all files from the package the number of alerts rockets to orders of .python .org library socket .html .readthedocs .io en latest magnitude.
notably the tool produced more alerts on the benign artifacts than on the malicious packages.
this phenomenon corresponds to the more extensive code base of the legitimate artifacts.
we observe similar behavior of the bandit tool.
when applied on the setup.py the tool generated alerts both on benign and malicious artifacts.
however bandit produced significantly more alerts on the malicious artifacts.
when looking at the alerts generated after running the tool on the entire package we observe a large number of alerts.
notably looking only at the number of alerts one could not distinguish between benign and malicious artifacts the number of alerts produced on the benign artifacts exceeds the number of alerts on the malicious artifacts.
after applying lastpymile to the tool results after running them on the entire artifacts we observe a significant reduction of the number of alerts for both tools.
for example bandit tool produced only alerts out of after applying lastpymile on the results of the urlib3 .
.
scan.
similarly the number of alerts produced by malware checks on the setup tools .
.
reduced to instead of .
looking at the outcome of the benign packages lastpymile reduced the number of alerts to zero.
being applied to setup.py files only malware checks tool generates a number of alerts manageable by humans.
however scanning of only setup.py files does not guarantee the artifact to be free from malicious code as the of code is not checked.
the number of alerts that both tools produce after scanning the entire artifacts and false alerts for malware checks andbandit respectively demonstrates that such analysis does not scale for an onupload analysis by pypi maintainers.
in contrast lastpymile shows an excellent potential to improve the scanning results.
first it makes the number of alerts after running a tool on the entire artifact comparable with the current number of alerts generated by the malware checks currently used by pypi .
second we do not observe any alerts for benign artifacts which allows us to easily distinguish benign and malicious artifacts in our manual validation of the alerts.
when run on all malicious code packages available from the literature we were able to preserve all malicious alerts and did not introduce false positives over the current scanning process.lastpymile identifying the discrepancy between sources and packages esec fse august athens greece those properties make lastpymile a candidate for software vetting processes of government organizations or other oss consumers with high security requirements.
the review effort is manageable even though typical development projects have dozens of dependencies with more or less frequent release and patch cycles.
summary lastpymile reduces the number of alerts produced by a malware checking tool to a number that a human can check.
we checked our approach against known malicious packages and we found that lastpymile can detect all of them.
also it removes all the alerts from benign packages allowing a clear distinction between benign and malicious packages.
threats to validity the validity of results reported in this paper is impacted by several choices made during tool and experiment design.
we only consider repositories hosted on github15.
however there are no significant obstacles to cover other version control systems and extend the current implementation to other git service providers e.g.
gitlab or bitbucket as long as they support code commits e.g.
apache subversion .
the current implementation focuses on the python packages in pypi and python files in particular.
the extension to other python ecosystems e.g.
anaconda and interpreted languages and other file types seem straight forward e.g.
node.js npm and ruby rubygems .
yet we only considered the top packages hosted on pypi out of more than packages.
a larger number of packages would need to be considered for an ecosystem analysis.
in terms of design lastpymile checks only the code absent from source repositories even though malicious code could also be included in the versioned code either directly or in tests.
this was the case of the pillow python framework17 that was flagged by more than antivirus vendors.
however this situation lays out of the scope of the paper as the test files should have been spotted during the source code review.
we limit the line by line analysis to files with file extension .py.
the main reason driving this design decision is to focus attention on files whose discrepancies compared to what users can view in the respective source code repository can alter the program flow e.g.
when downstream users install an artifact in their development environment or invoke its api as part of their development project .
other phantom files might be also be used to inject malware.
for example the phantom files under the test directories are required by a popular testing framework like pytest .
another source of phantom files is the upload of modules specific to a developer development environment.
they are usually not versioned with git.
15in our dataset there are packages hosted in bitbucket .org packages hosted in gitlab packages hosted in the sourceforge .net packages are hosted in code .google .com and four of them had been moved to github.
.anaconda .com .com python pillow pillow issues 251example .
the phantom files in pydruid .
.
.tar.gz are the manually built python packages stored in the sitepackages directory.
we can verify the origin of the local installed modules by comparing their code files with the correponding github repository.
by using lastpymile we can check that the code files in the local module called traitlets e.g.
https github .com ipython traitlets of the artifact pydruid .
.
.tar.gz belonging to the correponding github repository.
moreover pypi packages contain other executables e.g.
windows portable executables osx disk image files or c c static libraries.
for example we found many python bytecode files ending with .pyc .
these files should not be uploaded to pypi as this can make the dependent package e.g.
a debian package fail to compile.19investigating these cases would require a distinct paper.
we only check additions of code lines in the present version even though a vulnerability could be introduced by deleting lines from a software artifact e.g.
by removing a sanitizing statement .
albeit lastpymile does not report the deleted lines in such a case it could detect that the files in the uploaded artifacts are different as their hashes would differ if compared to the hashes of the files stored in the corresponding source code repository.
limiting the false alerts in this case would require special care to avoid that the whole file is reported as different.
we leave this case for future work.
some packages contain code automatically generated by tools like swagger codegen or python distutils .
the current implementation of lastpymile would generate conceptually false positives as such files do not conceptually differ from phantom files.
these cases of automatically generated files could be checked by applying the same code generation tool on the code files in the github repository and comparing with the files in published artifacts.
related work zimmermann et al.
study security risks for users of npm including potential vulnerable and malicious code in thirdparty dependencies.
the authors showed that npm suffers from single points of failure in which individual packages could impact large parts of the entire ecosystem.
attackers could compromise a minimal number of maintainers accounts to inject malicious code into most packages.
the paper however does not investigate the potentially malicious code injection in the package artifacts.
our lastpymile approach provides a way to audit the popular packages by identifying the delta in the code that developers consume and the original code developed by vendors in their source code repository.
ohm et al.
presents a taxonomy of attack vectors and a dataset of malicious software packages used in realworld attacks on open source software supply chains on three package repositories npm pypi and rubygems.
this work highlights that typosquatting and infection of an existing .com ipython traitlets .com googleapis google auth library python issues 214esec fse august athens greece duc ly vu fabio massacci ivan pashchenko henrik plate and antonino sabetta package are the two most common attacks.
this work however does not investigate the presence of code injections in legitimate and malicious packages.
our approach involves developing a method to identify the discrepancies between distributed artifacts and source code repositories that could be attributed to the malicious code injection.
several works study the potential impact of typosquatting attacks on pypi packages based on the levenshtein distance and number of downloads of the targeted package.
they show a large number of typosquatting candidates in pypi that pypi administrators should investigate.
however relying only on package names may cause many false positives and a more in depth analysis of distributed artifacts is required.
our approach provides a methodology to verify the potential typosquatting package by highlighting the differences between the typosquatting packages and the github repository.
code based approaches can provide more accuracy in detecting malicious packages.
several approaches scan the setup.py file of the package artifact to identify suspicious code.
bertu statically parses the python installation script setup.py as an ast tree and looks for suspicious patterns e.g.
network connections .
malware checks uses a set of yara rules on the lines of code on the setup.py file.
similarly applicationinspectorandossgadget check the distributed artifacts using a set of regular expressions to identify potential backdoors within a package.
although these approaches are fast and straightforward they can generate many false alerts when scanning setup.py performing legitimate behavior in the installation process e.g.
downloading a dependency from a remote server .
our approach fills this gap by allowing these tools to scan only the phantom lines which were potentially introduced.
several techniques use dynamic analysis to expose the malicious behaviors of the package.
buildwatch dynamically execute package code in the cuckoo sandbox and captures all system calls such as kernel services requested by processes.
duan et al.
propose maloss a hybrid approach which extracts various features of distributed artifacts using metadata static and dynamic analyses.
these methods however are resource heavy which may be challenging to integrate into the development pipeline.
lastpymile uses a lightweight comparison to help these approaches by reducing the number of files and lines that need to be scanned to detect malicious code injections making the existing techniques efficiently adapt to individual developers development pipelines.
garrett et al.
use an anomaly detection based approach on features extracted from packages metadata and source code to detect suspicious package updates in npm.
the method could reduce the review effort by .
however the approach cannot highlight the code injections with the existing features as it analyzes only the published artifacts.
ourlastpymile can highlight the code injections and can be adapted to provide explanations to developers.gonzalez et al.
uses commit logs and repository metadata to detect potential malicious commits automatically.
the method identifies .
of malicious commits while flagging less than of commits in the studied dataset.
our lastpymile instead looks for the code injections into the source code repositories by considering both the packages and source code repositories.
summary although current approaches on auditing packages caught some malicious examples their focus is on detecting malicious patterns in published artifacts which may cause many false alerts.
also scanning the whole code of an artifact would not be effective in case of code injection attacks where only a small subset of code is malicious.
instead our approach focuses on detecting code injections in distributed artifacts thus complementing the current techniques by reducing the number of code lines to be analyzed to detect software supply chain attacks.
conclusion we investigated the discrepancies between published artifacts and source code repositories to understand the risk of malicious injections during the software release process.
our empirical analysis of most downloaded pypi packages shows that there exist differences between packages in pypi and the corresponding source code repositories at different levels of granularity artifacts files and lines .
the differences are attributed to developers and automated tools e.g.
packaging tools and could impact the consumers e.g.
causing compilation issues or representing a potential for containing malicious code injections.
the flexible combination of lastpymile as input output filter with other security tools offers the possibility to reduce the number of findings and the time required by vetting processes.
we instructed malware checks andbandit to only consider phantom code as input and the resulting decrease in false alerts makes it possible to use lastpymile as an additional check in the pypi vetting processes with minimal impact on review efforts.
a replication package is available at and we plan to submit lastpymile as a new check to pypi.
several issues still remain malicious code can be hidden in many other forms such as webpages html with embedded or external javascript or project configuration files requirements.txt with a malicious dependency .
we notice a high number of requirements.txt configuration files which contain the list of dependencies to be installed automatically with pip install .
this could be a potential vector for adversaries to add malicious injections worth further investigations.