toward efficient interactions between python and native libraries jialiang tan yu chen jtan02 email.wm.edu ychen39 email.wm.edu william mary usazhenming liu zliu cs.wm.edu william mary usabin ren bren cs.wm.edu william mary usa shuaiwen leon song shuaiwen.song sydney.edu.au university of sydney australiaxipeng shen xshen5 ncsu.edu north carolina state university usaxu liu xliu88 ncsu.edu north carolina state university usa abstract python has become a popular programming language because of its excellent programmability.
many modern software packages utilize python for high level algorithm design and depend on native libraries written in c c fortran for efficient computation kernels.
interaction between python code and native libraries introduces performance losses because of the abstraction lying on the boundary of python and native libraries.
on the one side python code typically run with interpretation is disjoint from its execution behavior.
on the other side native libraries do not include program semantics to understand algorithm defects.
to understand the interaction inefficiencies we extensively study a large collection of python software packages and categorize them according to the root causes of inefficiencies.
we extract two inefficiency patterns that are common in interaction inefficiencies.
based on these patterns we develop pieprof a lightweight profiler to pinpoint interaction inefficiencies in python applications.
the principle of pieprof is to measure the inefficiencies in the native execution and associate inefficiencies with high level python code to provide a holistic view.
guided by pieprof we optimize realworld applications yielding speedups up to .
on application level.
ccs concepts general and reference performance metrics software and its engineering software maintenance tools .
keywords python profiling pmu debug register both authors contributed equally to this research.
this work is done when jialiang visits at ncsu.
permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
copyrights for components of this work owned by others than the author s must be honored.
abstracting with credit is permitted.
to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
request permissions from permissions acm.org.
esec fse august athens greece copyright held by the owner author s .
publication rights licensed to acm.
acm isbn .
.
.
.
reference format jialiang tan yu chen zhenming liu bin ren shuaiwen leon song xipeng shen and xu liu.
.
toward efficient interactions between python and native libraries.
in proceedings of the 29th acm joint european software engineering conference and symposium on the foundations of software engineering esec fse august athens greece.
acm new york ny usa pages.
introduction in recent years python has become the most prominent programming language for data modeling and library development especially in the area of machine learning thanks to its elegant design that offers high level abstraction and its powerful interoperability with native libraries that delivers heavy numeric computations.
decoupling data analysis and modeling logics from operation logics is the singular mechanism guiding the remarkable improvements in developers productivity in the past decade.
python enables small teams to build sophisticated model that were barely imaginable a few years ago and enables large teams of modelers and numeric developers to seamlessly collaborate and develop highly influential frameworks such as tensorflow and pytorch .
while high level languages to articulate business logics and native libraries to deliver efficient computation is not a new paradigm downstream developers have not always understood the details of native libraries and have implemented algorithms that interacted poorly with native codes.
a well known example of the interaction inefficiency problem occurs when developers who fail to recognize that certain matrix operations can be vectorized write significantly slower loop based solutions.
matlab and mathematica can alleviate the problem since these languages usually are locked with a fixed set of native libraries over a long time and developers can establish simple best practice guidelines to eliminate most interaction inefficiencies matlab contains the command try to vectorize whenever possible .
in the python ecosystem native libraries and downstream application codes evolve rapidly so they can interact in numerous and unexpected ways.
therefore building a list to exhaust all interaction inefficiencies becomes infeasible.
we seek a solution that will automatically identify the blocks of python code that lead to inefficient interactions through closing the knowledge gap between python and native code.
existing profiling tools cannot address this issue.
python profiles cannot step esec fse august athens greece jialiang tan yu chen zhenming liu bin ren shuaiwen leon song xipeng shen and xu liu in native code so they do not know execution details.
native profiling tools can identify hotspots which offer insights into problematic code blocks.
however because these tools do not have knowledge about python code s semantics they cannot render detailed root cause and thus often make debugging remarkably challenging.
we propose pieprof the first lightweight insightful profiler to pinpoint interaction inefficiencies in python programs.
pieprof works for production python software packages running in commodity cpu processors without modifying the software stacks.
its backbones algorithmic module is a recently proposed technique based on hardware performance monitoring units pmus and debug registers to efficiently identify redundant memory accesses hereafter referred to as cl algorithm1 .
cl algorithm intelligently chooses a small collection of memory cells and uses hardware to track accesses to these cells at a fine granularity.
for example when the technique detects two consecutive writes of the same value to the same cell it determines that the second write is unnecessary and flags the responsible statement function for further inspection.
the developer can clearly see where a non opt memory access occurs and why.
the technique already shows its potential for eliminating inefficiencies in monolithic codebases that use one programming language.
pieprof leverages the cl algorithm in a substantially more complex multi languages environment in which a dynamic and predominantly interpretation based language python is used to govern the semantics and native libraries compiled from c c fortran are used to execute high performance computation.
so requires us to address three major challenges that crosscut python and native code.
at the measurement front we need to suppress false positives and avoid tracking irrelevant memory operations produced from python interpreter and python native interactions.
for example memory accesses performed by python interpreters may bait the cl algorithm to waste resources i.e.
debug registers on irrelevant variables such as reference counters.
at the infrastructure front we need to penetrate entire software stacks it cannot see execution details i.e how memory is accessed with only python runtime information or cannot understand program semantics with only native library knowledge.
our main task here is to compactly implement lock free calling context trees that span both python code and native libraries and retain a large amount of information to effectively correlate redundant memory accesses with inefficient interactions.
at the memory safety front we need to avoid unexpected behaviors and errors caused by python runtime.
for example python s garbage collection gc may reclaim memory that our tool is tracking.
so delicate coordination between pieprof and python interpreter is needed to avoid unexpected behaviors and errors.
we note that while most of the downstream applications we examined are machine learning related pieprof is a generic tool that can be used in any codebase that requires python native library interactions.
contributions.
we make the following three contributions.
1chabbi liu algorithm.
we are the first to thoroughly study the interaction inefficiencies between python codes and native libraries.
we categorize the interaction inefficiencies by their root causes.
we design and implement pieprof the first profiler to identify interaction inefficiencies and provide intuitive optimization guidance by carefully stepping through python runtimes and native binaries.
pieprof works for production python software packages in commodity cpu processors without modifying the software stacks.
following the guidance of pieprof we examine a wide range of influential codebases and identify interaction inefficiencies in real world applications and optimize them for nontrivial speedups.
organization.
section reviews the background and related work.
section characterizes the interaction inefficiencies.
section describes the design and implementation of pieprof .
section explains the evaluation.
section presents some case studies.
section discusses some threats to validity.
section presents some conclusions.
background and related work .
python runtime system python basics.
python is an interpreted language with dynamic features.
when running a python application the interpreter translates python source code into stack based bytecode and executes it on the python virtual machine pvm which varies implementations such as cpython jython intel python and pypy .
this work focuses on cpython because it is the reference implementation while the proposed techniques are generally applicable to other python implementations as well.
the cpython pvm maintains the execution call stack that consists of a chain of pyframe objects known as function frames.
each pyframe object includes the executing context of corresponding function call such as local variables last call instruction source code file and current executing code line which can be leveraged by performance or debugging tools.
python supports multi threaded programming where each python thread has an individual call stack.
because of the global interpreter lock gil the concurrent execution of python threads is emulated as regular switching threads by the interpreter i.e.
for one interpreter instance only one python thread is allowed to execute at a time.
interaction with native libraries.
when heavy lifting computation is needed python applications usually integrate native libraries written in c c fortran for computation kernels as shown in figure .
such libraries include numpy scikit learn tensorflow and pytorch .
therefore modern software packages enjoy the benefit from the simplicity and flexibility of python and native library performance.
when the python runtime calls a native function it passes the pyobject2or its subclass objects to the native function.
the python runtime treats the native functions as blackboxes the python code is blocked from execution until the native function returns.
2pyobject is the super class of all objects in python.
1118toward efficient interactions between python and native libraries esec fse august athens greece python applicationpython runtimenative library abstractionstandard modulenative libraryoperating systemhardware figure the typical stack of production python software packages.
python applications usually rely on native libraries for high performance but introduce an abstraction across the boundary of python runtime and native libraries.
figure shows an abstraction across the boundary of python runtime and native library which logically splits the entire software stack.
on the upper level python applications are disjoint from their execution behaviors because python runtime e.g.
interpreter and gc hides most of the execution details.
on the lower level the native libraries lose most program semantic information.
this knowledge gap leads to interaction inefficiencies.
.
existing tools vs. pieprof this section compares existing tools that analyze inefficiencies in python and native codes to distinguish pieprof .
python performance analysis tools.
pyexz3 pysym flake8 and frosted analyze python source code and employ multiple heuristics to identify code issues statically .
xla and tvm apply compiler techniques to optimize deep learning applications.
harp detects inefficiencies in tensorflow and pytorch applications based on computation graphs.
all of these approaches however ignore python dynamic behavior omitting optimization opportunities.
dynamic profilers are a complementary approach.
cprofile measures python code execution which provides the frequency time executions of specific code regions.
guppy employs objectcentric profiling which associates metrics such as allocation frequency allocation size and cumulative memory consumption with each python object.
pyinstrument and austin capture python call stack frames periodically to identify executing memory hotspots in python code.
pyspy is able to attach to a python process and pinpoint function hotspots in real time.
unlike pieprof these profilers mainly focus on python codes with no insights into the native libraries.
closely related to pieprof scalene separately attributes python native executing time and memory consumption.
however it does not distinguish useful wasteful resources usage as pieprof does.
native performance analysis tools.
while there are many native profiling tools from which the most related to python that can identify performance inefficiencies are toddler that identifies redundant memory loads across loop iterations andldoctor that reduces toddler s overhead by applying dynamic sampling and static analysis.
deadspy redspy and loadspy analyze dynamic instructions in the entire program execution to detect useless computations or data movements.
unfortunately all of them use heavyweight binary instrumentation which results in high measurement overhead and they do not work directly on python programs.
.
performance monitoring units and hardware debug registers hardware performance monitoring units pmus are widely equipped on the modern x86 cpu architectures.
software can use pmus to count various hardware events like cpu cycles cache misses et cetera.
beside the counting mode that counts the total number of events pmus can be configured in sampling which periodically sample a hardware event and record event s detailed information.
pmus trigger an overflow interrupt when the sample number reaches a threshold.
the profiler runtime captures interrupts as signals and collects samples with their executing contexts.
for memory related hardware events such as memory load and store precise event based sampling pebs in intel processors provides the effective address and the precise instruction pointer for each sample.
instruction based sampling ibs in the amd processors and marked events mrk in powerpc support similar functionalities.
hardware debug registers trap the cpu execution when the program counter pc reaches an address breakpoint or an instruction accesses a designated address watchpoint .
one can configure the trap conditions with different accessing addresses widths and types.
the number of hardware debug registers is limited e.g.
the modern x86 processor has four debug registers .
interaction inefficiency characterization this section provides a high level preview of the key findings from applying pieprof to an extensive collection of high profile python libraries at github.
we specifically categorize the interaction inefficiencies according to the root causes and summarize the common patterns which serve three purposes i this is the first characterization of interaction inefficiencies based on large scale studies thus rendering a more complete landscape of potential code quality issues that exist in python codebase for ml and beyond ii we see a diverse set of inefficiencies hiding deep in python native library interaction which justifies using heavy machineries profiling tools to automatically identify them and iii these concrete examples explain the common patterns we use to drive the pieprof s design.
.
interaction inefficiency categorization we categorize interaction inefficiencies into five groups.
for each category we give a real example analyze the root causes and provide a fix.
slice underutilization.
listing is an example code from irisdata a back propagation algorithm implementation on iris dataset .
a loop iterates two multidimensional arrays ihgrads andihweights with indices iandjfor computation.
because 1119esec fse august athens greece jialiang tan yu chen zhenming liu bin ren shuaiwen leon song xipeng shen and xu liu 1def train self traindata maxepochs learnrate ... 3for j in range self.nh delta .
learnrate ihgrads self.ihweights delta ... listing interaction inefficiencies in irisdata due to the iteration on numpy arrays within a loop.
1def train self traindata maxepochs learnrate ... 3self.ihweights .
learnrate ihgrads i self.nh ... listing optimized irisdata code with slice notation.
1def rotate self theta 2a np.cos theta 3b np.sin theta 4rotate mtx np.array .
.
.
float 5self.
mtx np.dot rotate mtx self.
mtx ... listing interaction inefficiencies in matplotlib due to the same input theta .
python arrays are supported by native libraries such as numpy and pytorch tensorflow indexing operations i.e.
in a loop trigger native function calls that repeat boundary and type checks .
the so called vectorization slicing eliminates repeated housework and usually enables the underlying blas library to perform multi core computation.
listing shows a simple fix in a speedup for the entire program execution.
repeated native function calls with the same arguments.
functions from native libraries typically have no side effects so applying the same arguments to a native function results in the same return value which introduces redundant computations.
listing shows a code from matplotlib a comprehensive library for visualization and image manipulation.
this code rotates an image and is often invoked in training neural nets for images.
the argument theta for therotate function rotate angle is usually the same across consecutive invocations from deep learning training algorithms because they rotate images in the same batch in the same way.
here pyobject s returned from native functions np.cos np.sin andnp.array in lines have the same values across images that share the same input theta .
this can be fixed by either a simple caching trick or refactoring the rotate funcion so that it can take a batch of images.
we gain a .
speedup after the fix.
inefficient algorithms.
listing is an example of algorithmic inefficiencies from scikit learn a widely used machine learning package.
the code works on x a two dimensional numpy array.
it calls the native function swap from the blas library to exchange two adjacent vectors.
in each iteration swap returns two pyobject s and python runtime assigns these two pyobject s tox.t and x.t respectively.
the loop uses swap to move the first element in the range to the end position.
inefficiencies occur because it requires multiple iterations to move x.t to the final location.1def lars path x y xy none ... ... 3for i in range ii n active x.t x.t swap x.t x.t indices indices indices indices ... listing interaction inefficiencies in scikit learn due to the inefficient algorithm.
1def cec 4 solution none problem size none shift ... 3for i in range dim res np.square x x np.square x ... listing interaction inefficiencies in metaheuristic due to the api misuse in native libraries.
instead of using swap we directly move each element to the target location.
we apply a similar optimization to the indices array as well.
our improvement yields a .
speedup to the lars path function.
api misuse in native libraries.
listing is an example of api misuse from metaheuristic which implements the stateof the art meta heuristic algorithms.
the code accumulates the computation results to res.
since the computation is based on numpy arrays the accumulation operation triggers one native function call in each iteration resulting in many inefficiencies.
in listing shows our fix i.e.
use the efficient sumapi from numpy which avoids most of the native function invocations by directly operating on the numpy arrays.
this optimization removes most of interaction inefficiencies and yields a .
speedup to the entire program.
loop invariant computation.
listing is a code snippet from deep dictionary learning which seeks multiple dictionaries at different image scales to capture complementary coherent characteristics implemented with tensorflow.
lines indicate the computation inputs a d andx.
lines define the main computation.
lines execute the computation with the actual parameters d andx .
the following pseudo code shows the implementation for i 1toiterdo a d x dta wheredandxare loop invariants.
if we expand the computation dxandddtcan be computed outside the loop and reused among iterations shown as pseudo code t1 dx t2 ddt for i 1toiterdo a t1 t2a this optimization yields a speedup to the entire program .
.
common patterns in interaction inefficiencies we are now ready to explain the common patterns in code that exhibits interaction efficiencies which we use to drive the design ofpieprof .
specifically we find that almost all interaction inefficiencies involve i repeatedly reading the same pyobject s of the 1120toward efficient interactions between python and native libraries esec fse august athens greece 1def cec 4 solution none problem size none shift ... 3res np.sum np.square x x np.
square x ... listing optimized metaheuritics code for listing with appropriate native library api.
1a tf.variable tf.zeros shape dtype tf.float32 2d tf.placeholder shape dtype tf.float32 3x tf.placeholder shape dtype tf.float32 4r tf.matmul d tf.subtract x tf.matmul tf.transpose d a 5l tf.assign a r 6for i in range iter 7result sess.run l feed dict d d x x listing interaction inefficiencies in deep dictionary learning due to loop invariant computation.
same values and ii repeatedly returning pyobject s of the same values.
both observations require developing a tool to identify redundantpyobject s which is difficult and costly because it requires heavyweight python instrumentation and modification to python runtime.
further analysis however finds that pyobject redundancies reveal the following two low level patterns during the execution from the hardware perspective.
redundant loads if two adjacent native function calls read the same value from the same memory location the second native function call triggers a redundant memory load.
repeatedly readingpyobject of the same value result in redundant loads.
redundant stores if two adjacent native function calls write the same value to the same memory location the second native function call triggers a redundant memory store.
repeatedly returning pyobject of the same value result in redundant stores.
we use the redundant loads and stores to serve as indicators of interaction inefficiencies.
table shows different categories of interaction inefficiencies which show up as redundant loads or stores.
section describes how we use the indicators.
design and implementation .
overview see figure .
recall that the cl algorithm controls pmus and debug registers to report redundant member accesses of a process.
pieprof interact with python runtime native libraries and the cl algorithm through three major components i safeguard and sandbox.
a thin sandbox is built around python interpreter and native libraries table redundant loads and stores detect different categories of interaction inefficiencies.
inefficiency pattern inefficiency category redundant loadsslice underutilization inefficient algorithms api misuse in native libraries redundant storesloop invariant computation repeated native function calls with same arguments inefficient algorithms api misuse in native libraries applicationnative function call 2python runtimenative librariessandboxcct buildermeasurementcct hardwarememory access sequencecl algorithmnative function call 1 pmu...mmpieprofprocesssafeguarddevdebug register ...... figure overview of pieprof s workflow.
and a safeguard is implemented inside the sandbox to moderate communication between python runtime and the cl algorithm.
ii measurement.
upon receiving an event from the cl algorithm the measurement component determines whether to notify cct calling context tree builder to update the cct and iii cct builder.
upon receiving an update from the measurement component cct builder examines python runtime and native call stacks to update cct.
when an interaction inefficiency is detected it will report to the end user developer .
the measurement component helps to suppress false positive and avoid tracking irrelevant variables e.g.
reference counters the cct builder continuously update the lock free cct and safeguard sandbox ensures that the python application can be executed without unexpected errors.
we next discuss each component in details.
.
measurement cl algorithm.
cl algorithm uses pmus and debug registers to identify redundant loads and stores in an instruction stream.
it implements a conceptually simple and elegant process a sequencea1 a2 ... a mmemory access instructions arrive at the clalgorithm in a streaming fashion.
here airefers to the address of the memory access for the i th instruction.
upon seeing a new memory access instruction ai step i.e in figure the cl algorithm uses pmus to probabilistically determine whether it needs to be tracked step and if so store the address in a debug register step .
if the debug registers are all used a random one will be freed up.
when a subsequent access to ai or any addresses tracked by debug registers occurs step the debug register will trigger an interrupt so that the cl algorithm can determine whether the access is redundant step by using the rules outlined in section .
.
since the number of debug registers is usually limited the cl algorithm uses a reservoir sampling technique to ensure that each instruction and its associated memory accesses has a uniform probability of being sampled.
1121esec fse august athens greece jialiang tan yu chen zhenming liu bin ren shuaiwen leon song xipeng shen and xu liu pyframe1pyframe2pyframe3 tstatecall stackpython runtimenative call path pyeval evalframedefault test.pyimportnumpyasnpdeffunc1 a np.random.rand i b np.random.rand i c np.zeros i ...c a b ...deffunc2 func1 ...if name main func2 ...hybrid call path pyeval evalframedefault pyeval evalframedefaultpyrun simplefileexflagsmaindouble addrun binary simd addsse2 binary add doublec a b func1 func2 pyrun simplefileexflagsmaindouble addrun binary simd addsse2 binary add double tstatetstate ........................ figure constructing a hybrid call path across python runtime and native libraries.
white arrows in call paths denote a series of elided call frames in pvm.
the red circle in the hybrid call path shows the boundary of python and native frames where interaction inefficiencies occur.
improving measurement efficiencies.
first pmus sample instructions at the hardware level so it cannot distinguish memory accesses from the python interpreter from those from the python applications.
in practice a large fraction of memory access sequences are related to updating reference counters for python objects.
therefore most debug registers will be used to track reference counters if we bluntly use the cl algorithm and substantially reduces the chances of identifying memory access redundancies.
second it needs to ignore redundant memory accesses occurring within the same native function call or within a code region of pieprof because they are not related to interaction inefficiencies.
note that tracking redundant memory accesses within the same native function call is worse than merely producing false positives because it can bury true instances.
for example two write instructions w1 andw2of the same value are performed on the same memory from functionfa and later function fbperforms a third write instruction w3of the same value on the same location.
if we track redundant accesses within the same function the cl algorithm says it has found a redundant pair w1 w2 evictsw1from the debug register.
and never detects the redundant pair w1 w3 caused by the real interaction inefficiencies.
pieprof performs instruction based filter to drop a sample if i its instruction pointer falls in the code region unrelated to native function calls e.g.
that of pieprof ii its memory access address belongs to junky range such as the head of pyobject that contains the reference number.
in addition when the cl algorithm delivers a redundant memory access pair to pieprof it checks the python runtime states and drops the sample when these two memory accesses occur inside a same state corresponding to within the same native function call .
.
calling context trees builder this section first explains the construction of call paths and then explains how they can be used to construct signal free calling context trees ccts .hybrid call path.
pieprof uses libunwind to unwind the native call path of a python process to obtain a chain of procedure frames on the call stack.
see the chain of native call path on the left in figure .
here call stack unwinding is not directly applicable to python code because of the abstraction introduced by pvm.
the frames on the stack are from pvm not python codes.
for example the bottom pyeval evalframedefault3shows up in native call path but we need the call to correspond to func2 in python code connected through pyframe1 .
thus pieprof needs to inspect the dynamic runtime to map native calls with python calls on the fly.
.
mapping pyframe to python calls.
first we observe that each python thread maintains its call stacks in a thread local object pythreadstate i.e.
tstates in figure .
to obtain python s calling context pieprof first calls getthisthreadstate 4to get thepythreadstate object of the current thread.
second pieprof obtains the bottom pyframe object corresponding to the most recently called function in the pvm call stack from the pythreadstate object.
all pyframe objects in the pvm call stack are organized as a singly linked list so we may obtain the entire call stack by traversing from the bottom pyframe .
eachpyframe object contains rich information about the current python frame such as source code files and line numbers that pieprof can use to correlate a pyframe to a python method.
in figure pyframe1 pyframe2 andpyframe3 are for python methods main func2 and func1 respectively.
.
extracting pyframe s from native call path.
each python function call leaves a footprint of pyeval evalframedefault in the native call stack so we need only examine pyeval evalframedefault .
each pyeval evalframedefault maps to a unique pyframe in the call stack of the active thread in python runtime.
in addition 3 pyeval evalframedefault is a frame i.e.
a function pointer in the native call stack in runtime that corresponds to invocation of a function or a line of code in python.
4getthisthreadstate is a pvm api to retrieve an object that contains the state of current thread.
1122toward efficient interactions between python and native libraries esec fse august athens greece caller infochildreninodeins infometricslnodecaller infochildreninodecaller infochildreninodeinsinfometricslnodeins infometricslnodeins infometricslnodeins infometricslnode... level 2level 1level 00x12b0x13f0x35f0x4130x6a50x9380xa460xc740x13f0x4130x4130x938 level 3 figure a calling context tree constructed by pieprof .
each parent node applies skip list to organize children.
inode denotes an internal node and lnode denotes a leaf node.
red box shows searching 0xa46 in the example skiplist.
the ordering preserves e.g.
the third pyeval evalframedefault in native call path corresponds to the third pyframe in python s call stack.
therefor use standard python interpreter apis to obtain thepyframe s and map them back to nodes in the native call path.
cct from call paths.
pieprof applies a compact cct to represent the profile.
figure shows the structure of a cct produced by pieprof .
the internal nodes represent native or python function calls and the leaf nodes represents the sampled memory loads or stores.
logically each path from a leaf node to the root represents a unique call path.
as mentioned python is a dynamic typing language and uses meta data to represent calling context e.g.
the function and file names in string form therefore its call stacks are usually substantially larger in space than those in static languages.
one solution is to build a dictionary to map strings to integer ids but the solution must be signal free because it needs to interact with the cl algorithm and pmus which is prohibitively complex.
our crucial observation is that function calls in different threads near the root of a tree usually repeat so unlike solutions appeared in which produce a cct for each thread process pieprof constructs a single cct for the entire program execution.
in this way the same function call appearing in different threads is compressed into one node and space complexity is reduced.
pieprof also implements a lock free signal safe skip list to maintain cct s edges for fast and thread safe operations.
in theory skip list s lookup insert and delete operations have o logn time complexity.
in practice skip list with more layers has higher performance but higher memory overhead.
in a cct the nodes closer to the root are accessed more frequently.
pieprof however proportionally adjusts the number of layers in the skip lists at different levels in a cct to optimize the performance and overhead tradeoffs.
it uses more layers to represent the adjacency lists ofnodes that are close to the root and fewer layers to represent those that are close to the leaves.
.
safeguard pieprof uses two mechanisms to avoid unexpected errors in python runtime.
it will hibernate if it enters a block of code interrupting which will cause state corruption in pvm and will block certain activities from gc if the activities can cause memory issues.
hibernation at function level.
upon seeing an event e.g.
an instruction is sampled or a redundant memory access is detected the pmus or debug registers use interrupt signals to interact with pieprof which will pause python s runtime.
error could happen if python run time is performing certain specific tasks when an interrupt exception is produced.
for example if it is executing memory management apis memory error e.g.
segmentation fault could happen and if python is loading native library deadlock could happen.
pieprof maintains a list of functions inside which pieprof needs to be temporarily turned off i.e.
in hibernation mode .
to do so pieprof maintains a block list of function and implements wrappers for each function in the list.
calls to these functions are redirected to the wrapper.
the wrapper turns off pieprof executes the original function and turns on pieprof again.
dropping events vs. hibernation.
we sometimes drop an event when it is unwanted section .
.
complex logic can be wired to drop an event at the cost of increased overhead.
here hibernating pieprof is preferred to reduce overhead because no event needs to be kept for a whole block of code.
blocking garbage collector.
when python gc attempts to deallocate the memory that debug registers are tracking errors could occur.
here we uses a simple trick to defer garbage collection activities when pieprof monitors memory addresses and it is within apyobject it increases the corresponding pyobject s reference and decreases the reference once the address is evicted.
this ensures that memories being tracked will not be deallocated.
converting addresses to pyobject s is done through progressively heavier mechanisms.
first pyobject s exist only in a certain range of the memory so we can easily filter out addresses that do not correspond to pyobject which will not be deallocated by gc .
second we can attempt to perform a dynamic casting on the address and will succeed if that corresponds to the start of an pytobject .
this handles most of the cases.
finally we can perform a full search in the allocator if we still cannot determine whether the address is within apyobject .
evaluation this section studies the effectiveness of pieprof e.g.
whether it can indeed identify interaction inefficiencies and its overheads.
we evaluate pieprof on a core intel xeon e7 v4 machine clocked at 2ghz running linux .
.
the machine is equipped with gb of memory and four debug registers.
pieprof is compiled with gcc .
.
o3 and cpython version .
is built with enable shared flag.
pieprof subscribes hardware event mem uops retired all stores for redundant stores detection andmem uops retired all loads for redundant loads detection respectively.
1123esec fse august athens greece jialiang tan yu chen zhenming liu bin ren shuaiwen leon song xipeng shen and xu liu table overview of performance improvement guided by pieprof .asdenotes application level speedup fsdenotes functionlevel speedup lrefers to redundant loads and srefers to redundant stores.
program information inefficiency optimization applications library problem code category pattern as fs ta tavolatily.py trend.py slice underutilization l .
.
numpycnn numpy numpycnn.py loop invariant computation s .
.
census main numpywdl ftrl.py loop invariant computation s .
.
lasso scikit learn least angle.py inefficient algorithms s .
.
irisdata numpynn backprop.py slice underutilization l .
api misuse networkneural network network.py repeated nfc l .
.
from scratch cnn from scratch numpy conv.py slice underutilization l .
.
metaheuristics numpyfunctionutil.py api misuse l .
.
functionutil.py slice underutilization l .
.
functionutil.py loop invariant computation s .
.
functionutil.py repeated nfc l .
.
epo.py loop invariant computation s .
.
linearregression linearregression linearregression.py repeated nfc l .
.
pytorch examples pytorch adam.py loop loop invariant computation l .
.
cholesky pytorch cholesky.py slice underutilization l .
.
ggnn.pytorch pytorch model.py loop invariant computation s .
.
network sliming torchvision functional.py slice underutilization l1.
.
pytorch sliming .
.
fourier transform matplotlib transforms.py repeated nfc s1.
.
jax .
.
autograd .
.
.
effectiveness this section assesses the effectiveness of pieprof and the breadth of the interaction inefficiencies problem among influential python packages.
the lack of a public benchmark creates two inter related challenges i determining the codebases to examine inevitably involves human intervention and ii most codebases provide a small number of hello world examples which have limited test coverage.
we aim to include all reasonably important open source projects and use only provided sample code for testing.
while using only sample code makes inefficiency detection more difficult this helps us to treat all libraries as uniformly as possible.
for each of numpy scikit learn and pytorch we find all projects in github that import the library and sort them by popularity which gives us three lists of project candidates.
our stopping rule for each list differs and involves human judgement because we find that the popularity of a project may not always reflect its importance e.g.
specialized libraries could be influential but generally have smaller user bases and are less popular in github s rating system .
for example metaheuristics is important and included in our experiment but it received only ratings at the time we performed evaluation.
at the end we evaluated more than read world applications among which there are more projects that import numpy than the other two libraries.
indentifying a total of inefficiencies is quite surprising because these projects are mostly written by professionals and the sample codes usually have quite low codebase coverage and are usually happy paths that are highly optimized.
the fact that we identify18 new performance bugs as reported in table indicates that interaction inefficiencies are quite widespreaded.
table reports that the optimizations following pieprof s optimization guidance lead to .
to .
application level speedup as and .
to .
function level speedup fs respectively.
according to amdahl s law as approaches fs as the function increasingly dominates the overall execution time.
for the five inefficiency categories we define in section .
and which are common in real applications pieprof s superior redundant loads stores detection proves its effectiveness.
.
overhead this section reports the runtime slowdown and memory bloating caused by pieprof .
we measure runtime slowdown by the ratio of program execution time with pieprof enabled over its vanilla execution time.
memory bloating shares the same measuring method but with the peak memory usage.
since python does not have standard benchmarks we evaluate the overhead of pieprof on three popular python applications scikit learn numexpr and numpydl which contain benchmark programs from scientific computing numerical expression and deep learning domains.
we report only the first half of the scikit learn benchmark due to space limitations and excludevarying expr.py from numexpr cnn minist.py and mlp minist.py from numpydl due to large variations in memory consumption or the runtime errors of vanilla runs cnn minist.py andmlp minist.py .
1124toward efficient interactions between python and native libraries esec fse august athens greece 20newsgrrusscrvertyseglmkiggsbrsrnbrrstinglrfmnistkierarckicalincrementalscalassrsatkrandrmsrrmsagasgdregressirnssarsifytsnemnistbrrleantimingmultidimissue47issue36srlytimingunalignedsimslevmltimingvmltiming2vmltiming3lstmckaracterlmcnnsentencelstmsentencemlsdigitsrnnckaracterlmgermeanmedian 0125untime 6lrwdrwn1.
.
scikit learnnumexprnumpydl a redundant stores detection 20newsgrrusscrvertyseglmkiggsbrsrnbrrstinglrfmnistkierarckicalincrementalscalassrsatkrandrmsrrmsagasgdregressirnssarsifytsnemnistbrrleantimingmultidimissue47issue36srlytimingunalignedsimslevmltimingvmltiming2vmltiming3lstmckaracterlmcnnsentencelstmsentencemlsdigitsrnnckaracterlmgermeanmedian 0125untime 6lrwdrwn1.
.
scikit learnnumexprnumpydl b redundant loads detection figure runtime slowdown of pieprof on scikit learn numexpr and numpydl with sampling rates of 500k 1m and 5m.
the y axis denotes slowdown ratio and the x axis denotes program name.
20newsgroupscovertypeglmkiggsbosonboostinglofmnistkierarckicalincrementalpcalassopatkrandompromsagasgdregressionsparsifytsnemnistbooleantimingmultidimissue47issue36polytimingunalignedsimplevaryingexprvmltimingvmltiming2vmltiming3lstmckaracterlmcnnsentencelstmsentencemlpdigitsrnnckaracterlmgeomeanmedian 01230emory bloating1.
.
scikit learnnumexprnumpydl a redundant stores detection 20newsgroupscovertypeglmkiggsbosonboostinglofmnistkierarckicalincrementalpcalassopatkrandompromsagasgdregressionsparsifytsnemnistbooleantimingmultidimissue47issue36polytimingunalignedsimplevmltimingvmltiming2vmltiming3lstmckaracterlmcnnsentencelstmsentencemlpdigitsrnnckaracterlmgeomeanmedian 012340emory bloating1.
.
scikit learnnumexprnumpydl b redundant loads detection figure memory bloating of pieprof on scikit learn numexpr and numpydl with sampling rates of 500k 1m and 5m.
the y axis denotes slowdown ratio and the x axis denotes program name.
we run each experiment three times and report the average overhead.
furthermore the overhead of pieprof is evaluated with three commonly used sampling rates 500k 1m and 5m.
figure 5a shows the runtime slowdown of the redundant stores detection.
the geo means are .
.
and .
under the sampling rates of 500k 1m and 5m and the medians are .
.
and .
respectively.
figure 5b shows the runtime slowdown of the redundant loads detection.
the geo means are .
.
and .
under the sampling rates of 500k 1m and 5m and the medians are .
.
and .
respectively.
the runtime slowdown drops as sampling rate decreases because more pmus samples incur more frequent profiling events such as inspecting python runtime querying the cct and arming disarming watchpoints to from the debug registers.
redundant loads detection incurs more runtime slowdown compared to redundant stores detection because programs usually have more loads than stores.
another reason is that pieprof setsrw trap for the debug register to monitor memory loads x86 does not provide trap on read only facility which traps on both memory stores and loads.
even though pieprof ignores the traps triggered by memory stores monitoring memory loads still incurs extra overhead.figure 6a shows memory bloating of the redundant stores detection.
the geo means are .
.
and .
under the sampling rates of 500k 1m and 5m and the medians are .
.
and .
respectively.
figure 6b reports memory bloating of the redundant loads detection.
the geo means are .
.
and .
under the same sampling rates and the medians are .
.
and .
respectively.
memory bloating shows a similar trend to runtime slowdown with varied sampling rates and between two kinds of inefficiency detection.
the extra memory consumption is caused by the larger cct required for the larger number of unique call paths.
issue36 vmltiming2 andcnnsentence suffer the most severe memory bloating due to the small memory required by their vanilla runs.
pieprof consumes a fixed amount of memory because some static structures are irrelevant to the testing program.
thus a program has a higher memory bloating ratio if it requires less memory for a vanilla run.
mlpdigits consumes more memory for redundant loads detection because mlpdigits a deep learning program contains a two level multilayer perceptron mlp that has more memory loads than stores.
although lower sampling rates reduce overhead the probability of missing some subtle inefficiencies increases.
to achieve a better 1125esec fse august athens greece jialiang tan yu chen zhenming liu bin ren shuaiwen leon song xipeng shen and xu liu 1def backprop self d l d out learn rate 2d l d filters np.zeros self.filters.shape 3for im region i j in self.iterate regions self.last input for f in range self.num filters d l d filters d l d out im region listing interaction inefficiency in cnn from scratch due to slice underutilization.
1def backprop self d l d out learn rate 2d l d filters np.zeros self.filters.shape 3for im region i j in self.iterate regions self.last input new im region np.repeat im region axis tmp d l d out d l d filters tmp new im region listing optimized code of listing eliminates inefficiencies by performing slice notation.
prepare indexnumpy core multiarray umath.so0x2b728f71ead1array subscriptnumpy core multiarray umath.so0x2b728f72094bd l d filters d l d out im regionconv.py 62 pyfunction fastcalllibpython3.6m.so.
.00x2b7282e99040call functionlibpython3.6m.so.
.00x2b7282e9a061gradient conv.backprop gradient lr cnn.py 55 pyeval evalcodewithnamelibpython3.6m.so.
.00x2b7282e99aaccall functionlibpython3.6m.so.
.00x2b7282e99d74l acc train im label cnn.py 82 pyeval evalcodewithnamelibpython3.6m.so.
.00x2b7282e99aacpyeval evalcodeexlibpython3.6m.so.
.00x2b7282e9a0bepyeval evalcodelibpython3.6m.so.
.00x2b7282e9a0ebpyrun fileexflagslibpython3.6m.so.
.00x2b7282ecf392pyrun simplefileexflagslibpython3.6m.so.
.00x2b7282ecf505mainpieprof bin main0x400bc7 killed by prepare indexnumpy core multiarray umath.so0x2b728f71ead1array subscriptnumpy core multiarray umath.so0x2b728f72094bd l d filters d l d out im regionconv.py 62 pyfunction fastcalllibpython3.6m.so.
.00x2b7282e99040call functionlibpython3.6m.so.
.00x2b7282e9a061gradient conv.backprop gradient lr cnn.py 55 pyeval evalcodewithnamelibpython3.6m.so.
.00x2b7282e99aaccall functionlibpython3.6m.so.
.00x2b7282e99d74l acc train im label cnn.py 82 pyeval evalcodewithnamelibpython3.6m.so.
.00x2b7282e99aacpyeval evalcodeexlibpython3.6m.so.
.00x2b7282e9a0bepyeval evalcodelibpython3.6m.so.
.00x2b7282e9a0ebpyrun fileexflagslibpython3.6m.so.
.00x2b7282ecf392pyrun simplefileexflagslibpython3.6m.so.
.00x2b7282ecf505mainpieprof bin main0x400bc7 figure the redundant load pair reported by pieprof for listing .
trade off between overhead and detecting ability we empirically select 1m as our sampling rate.
case studies this section discusses our three heuristic case studies.
our primary aim is to demonstrate the superior guidance provided by pieprof for inefficiency detection and optimization.
.
cnn from scratch cnn from scratch is an educational project that implements a convolutional neural network.
the code in listing performs tensor computation within a two level nested loop.
d l d filters is a tensor d l d out is a tensor and im region is a tensor.
the inner loop iterates d l d filters by its first dimension iterates d l d out by its third dimension.
in each iteration of inner loop d l d filters performs as a tensor andd l d out is a number.
the computation in line is summarized as a vector cumulatively adding the multiplication of a number and a vector.1def cec 10 solution none problem size none shift ... 3for i in range dim temp for j in range temp i np.abs np.power j x round np.power j x np.power j a np.power temp np.power dim .
... listing interaction inefficiency in metaheuristic due to api misuse and loop invariant computation.
1def cec 10 solution none problem size none shift ... 3tmp dim np.power dim .
4for i in range dim temp for j in range frac whole math.modf np.power j x temp i np.abs frac np.power j a np.power temp tmp dim ... listing optimized code of listing eliminates inefficiencies with an appropriate api and memorization technique.
figure shows a redundant loads pair reported by pieprof .
the redundant pair is represented as hybrid call path and the upper call path is killed by the lower call path.
for each native call path pieprof reports the native function name shared library directory and the instruction pointer.
for each python call path it reports the problematic code piece and its location in the source file.
in this case the call path pair reveals that the interaction inefficiency is introduced by line of conv.py line in listing .
the call path also shows that the inefficiency caused by native function callprepare index array subscript denotes the redundant operations.
this inefficiency belongs to the category of slice under utilization.
for optimization we match the dimension of d l d filters d l d out andim region by expanding the dimension of im region and use slice notation to replace the inner loop as shown in listing .
the optimization yields a .
function level speedup and .
application level speedup.
.
metaheuristics listing is a code snippet from metaheuristics.
it performs complex numerical computation in a two level nested loop where xis a numpy array.
pieprof reports a redundant loads on line where the code triggers the redundant native function call array multiply andlong power .
guided by this we observe that np.abs np.power j x is calculated twice within every iteration because the code aims to get the computation result s fraction part.
to eliminate the redundant computation we use math.modf function to calculate the fraction directly.
this inefficiency belongs to the category of api misuse in native libraries.
pieprof also reports redundant stores in line with native functionlong power .
upon further investigation we find the result ofnp.power dim .
does not change among iterations which belong to loop invariant computation.
for optimization we use a local variable to store the result outside the loop and reuse it among 1126toward efficient interactions between python and native libraries esec fse august athens greece 1def adx self pd.series ... 3adx np.zeros len self.
trs 4tmp self.
n float self.
n 5for i in range self.
n len adx adx adx tmp dx float self.
n ... listing interaction inefficiency in ta due to slice underutilization.
1def adx self pd.series ... 3adx np.zeros len self.
trs 4tmp self.
n float self.
n 5for i in range self.
n len adx adx adx tmp 7adx dx float self.
n ... listing optimized code of listing eliminates inefficiencies by performing slice notation.
iterations.
the appropriate usage of api yields .
applicationlevel speedup and .
function level speedup and eliminating loop invariant computation yields .
application level speedup and .
function level speedup respectively.
.
technical analysis technical analysis ta is a technical analysis python library.
listing is a problematic code region of ta where adxanddxare two multi dimension numpy arrays and a loop iterates them and performs numerical calculations.
pieprof reports redundant loads in line with native function array subscript which denotes the code that suffers from the inefficiency of slice underutilization.
unfortunately we cannot eliminate the loop because adxhas computing dependency among the iterations.
therefor we optimize the access to dxwith slice notation shown in listing .
eliminating all similar patterns in ta yields .
application level speedup and .
function level speedup.
threats to validity the threats mainly exist in applying pieprof for code optimization.
the same optimization for one python application may show different speedups on different computer architectures.
some optimizations are input sensitive and a different profile may demand a different optimization.
we use either typical inputs or production inputs of python applications to ensure that our optimization improves the real execution.
as pieprof pinpoints inefficiencies and provides optimization guidance programmers will need to devise a safe optimization for any execution.
conclusions this paper is the first to study the interaction inefficiencies in complex python applications.
initial investigation finds that the interaction inefficiencies occur due to the use of native libraries in python code which disjoins the high level code semantics with low level execution behaviors.
by studying a large amount of applications we are able to assign the interaction inefficiencies to five categories based on their root causes.
we extract two commonpatterns redundant loads and redundant stores in the execution behaviors across the categories and design pieprof to pinpoint interaction efficiencies by leveraging pmus and debug registers.
pieprof cooperates with python runtime to associate the inefficiencies with python contexts.
with the guidance of pieprof we optimize python applications fix interaction inefficiencies and gain numerous nontrivial speedups.