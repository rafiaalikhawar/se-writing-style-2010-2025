efficient generation of error inducing floating point inputs via symbolic execution hui guo department of computer science university of california davis usa higuo ucdavis.educindy rubio gonz lez department of computer science university of california davis usa crubio ucdavis.edu abstract floating point is widely used in software to emulate arithmetic over reals.
unfortunately floating point leads to rounding errors thatpropagateandaccumulateduringexecution.generatinginputs tomaximize the numerical error is critical when evaluating the accuracy of floating point code.
in this paper we formulate theproblem of generating high error inducing floating point inputsasacodecoveragemaximizationproblemsolvedusingsymbolic execution.
specifically we define inaccuracy checks to detect large precision loss and cancellation.
we inject these checks at strategic program locations to construct specialized branches that whencovered by a given input are likely to lead to large errors in the result.weapplysymbolicexecutiontogenerateinputsthatexercise thesespecializedbranches anddescribeoptimizationsthatmake our approach practical.
we implement a tool named fpgen and presentanevaluationon21numericalprogramsincludingmatrix computation andstatistics libraries.weshow that fpgen exposes errors for of these programs and triggers errors that are on average over orders of magnitude larger than the state of the art.
ccs concepts mathematics of computing numerical analysis softwareanditsengineering softwaretestinganddebugging software verification and validation.
keywords floating point testing catastrophiccancellation roundofferrors symbolic execution acm reference format hui guo and cindy rubio gonz lez.
.
efficient generation of errorinducingfloating pointinputsviasymbolicexecution.in 42ndinternational conferenceonsoftwareengineering icse may23 seoul republicofkorea.
acm newyork ny usa 12pages.
.
introduction floating point numbers are widely used as a standard to represent reals in modern computers.
the limited precision in floating point permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation on the first page.
copyrights for components of this work owned by others than acmmustbehonored.abstractingwithcreditispermitted.tocopyotherwise orrepublish topostonserversortoredistributetolists requirespriorspecificpermissionand ora fee.
request permissions from permissions acm.org.
icse may seoul republic of korea association for computing machinery.
acm isbn ... .
and computation however remains a known threat tothecorrectness accuracyandstabilityoffloating pointprograms.
numerical bugs due to rounding errors nonreproducibility and floating point exceptionsare common in floating pointprograms .inparticular thepropagationandaccumulationofrounding errors have resulted in catastrophic failures .
floating point errors.
the floating point error of a computation refers to the sum of the rounding errors accumulated in the result of the computation.
this includes errors due to inaccurate initial data as well as errors generated during the computation due tofloating pointfiniteprecision.theamountoffloating pointerror includedinthefinalresultofaprogramspecifiestheaccuracyof thecode.whilethereareseveraltools e.g.
that given a set of inputs help detect and identify accuracy and stability problems of floating point code few testing tools have been developed to trigger and expose floating point errors.
existing floating point testing tools mainly focus on triggering floating point exceptions or maximizing code coverage of floating point pro grams while finding inputs to test accuracy is left to developers.
generatinginputsto maximize thenumericalerroriscriticalwhen evaluatingtheaccuracyoffloating pointcode.besidestesting maximizing numerical error is significantly important in identifying inaccurate code areas for automated floating point program repair or optimization .
error inducing floating point inputs.
finding inputs that triggerlargenumericalerrorsisnon trivial.asobservedinaprevious study only a very small portion of the input domain can cause large errors.
it is challenging to identify such inputs because rounding errors are unintuitive and difficult to reason about.
floating point optimization techniques use random inputs that satisfy common distributions or code coverage criteria.
the state of the art error inducing input generators performlimitedanalysisoverthefloating pointerrorsgenerated during execution and mainly rely on searching or sampling to identifyerror inducinginputs.thisleadstoalackofsupportfor numerical programs with multi dimensional input data due to the large input space.
both lsga and eagt are designed for floating point programs with a small number of scalar inputs.
in reality a large number of numerical programs e.g.
matrix computation libraries that are widely used in scientific computing machine learning libraries and software in computer graphics and data analysis take multi dimensional input data such as arrays 1lsgadoesnotprovideanalgorithmtogeneratemultiplefloating pointinputs andis evaluatedonprogramswithatmostfourscalarfloating pointinputs withthemajority taking only one scalar floating point input .
eagt relies on the approximation of conditionnumbers andonlyfocusesonprogramswithonescalarfloating pointinput.
ieee acm 42nd international conference on software engineering icse vectors or matrices.
s3fp is the state of the art tool for generating error inducing multi dimensional floating point inputs.
s3fp divides each input number interval and randomly permutes the subintervals to zoom into tighter input ranges in exploring the inputspace.however itsblack boxnatureresultsinasmallerchance to find inputs that trigger the highest errors.
inthispaper weproposeawhite boxalgorithmtogeneratehigh error inducinginputsforfloating pointprogramsespeciallywith multi dimensionalinputdata.specifically wecheckthefloatingpointerrorsgeneratedduringexecutionandusesucherrorpatterns to identify inputs that are likely to trigger high errors in the result.
byaddingerrorchecks wetransformtheproblemofgenerating high error inducing inputs into the code coverage maximization problem that can be solved by performing symbolic execution.
symbolic execution.
symbolic execution e.g.
enhances program testing by symbolizing inputs to achieve higher codecoverage.insymbolicexecution insteadofconcretevalues the inputs are represented as symbols that indicate arbitrary numbers.
each program operation on concrete values is replaced by an operation on symbolic values and accordingly the value of each variableisanexpressionintermsoftheinputsymbols.whenencounteringaconditionalstatement theexecutionisforkedintotwotoeachfollowthe trueandfalsebranch andeachchildprocessadds the corresponding constraints into its program state to identify the executed path.
once the program terminates or an error occurs e.g.
divisionbyzero thepathconstraintsaresolvedbysatisfiability modulo theory smt constraint solvers to find concrete values for the symbolic inputs.
recent works have incorporated floating point arithmetic insymbolic execution.like integervariables floating point variablesaresymbolizedtobeintegratedintodifferentpathconstraintsandfloating pointinputsaregeneratedthroughsmtsolvers with floating point support e.g.
z3 .
however a floating point input that covers one path of the program does not necessarily trigger large numerical errors on that path which is shown in our evaluation.tofindinputsthattriggerhigherrors amorespecific algorithm is needed.
key insight.
our key insight is that by injecting inaccuracy checks after floating point arithmetic operations we force symbolicexecutiontoexploretheprobabilityoftheoccurrenceofsevere rounding errors or numerical cancellation at each injection site.
severeroundingcancausesignificantprecisionloss whichcould affect the accuracy of the result and a cancellation could be cat astrophic due to loss of significance.
in floating point code it is hardtopredictwhichpartoftheprogramcouldpossiblyinvolve severe rounding or cancellation and what the impact in the result isifeitherhappens.ourtechniqueenablessymbolicexecutionto explore rounding and cancellation possibilities in different code areas.foreachinputgenerated wemeasuretheerroritexposed and select only those that trigger the largest error.
the main challenge stems from an inherent limitation of symbolicexecution pathexplosion .duetotheexponentialgrowth of the number of feasible paths cpu and memory usage becomes high.
moreimportantly asmore constraintsare added intoa path constraint it takes longer for such constraints to be solved.
the necessityforinaccuracycheckinjectionaggravatestheproblembyintroducingadditionalpathstobeexplored.toalleviatepathexplosion we carefully manage the number of symbolic input variables by separating the input variables into two groups and concretizing thegroupwithlargersize.second weonlyinstrumentthefloatingpointoperationsofinterestinthecoreloopofthealgorithm and usetwosamplingstrategiestodynamicallyenableinjection.lastly weformulatetheinaccuracychecksusingbitwiseoperations which significantlyreducethenumberofbranchesateachinjectionpoint.
weimplementourapproachinatoolnamedfpgenanddemonstratethatfpgeniseffectiveatgeneratinginputsthatexposelarge floating pointerrors.ourevaluationon3summationalgorithms and numerical programs from the meschach library and the gnuscientificlibrary showsthatfpgenisabletoexposeerrors for nearly all programs and the order of the magnitude of exposed relative errors is .
on average which indicates that the result has only around accurate digits.
we compare fpgen s generated inputs against random input generation thestate of the arterror inducinginputgenerators3fp andklee float asymbolicexecutionenginethatprovidesfloating pointsupport.theresultsshowthatrandominput generation and s3fp trigger errors in out of programs while fpgen triggers errors in all programs except for one.
furthermore fpgentriggerslargererrorsthanallotherapproachesfor15out of programs.
the order of the magnitude of the exposed relativeerrorsis .69onaverageforrandominputgenerationand .
on average for s3fp.
on the other hand klee float fails totriggererrorsforallprograms.regardingtothemagnitudeoferrors the tools can trigger fpgen improves the state of the art input generator s3fp by more than orders of magnitude.
the contributions of this paper are as follows weenablesymbolicexecutiontofindhigherror inducinginputs by incorporating precision loss and cancellation checks under floating point computations and describe various optimizations toscalesymbolicexecution includingmanagingthenumberof symbolic variables and selecting injection sites section .
we evaluate fpgen on a set of numerical programs including matrixcomputationandstatisticslibraries andshowthatfpgen outperforms the state of the art in the majority of the programs.
moreover fpgen advances the state of the art by triggering errorsthataremorethan2ordersofmagnitudelarger section4 .
therestofthispaperisorganizedasfollows.section2illustrates testingoffloating pointprogramsusing3summationalgorithms.
section3describesourinaccuracychecks andoptimizationsthat make symbolic execution effective at generating error inducinginputs.
section describes our experimental evaluation.
finally section discusses related work and we conclude in section .
floating point accuracy testing in this section we first illustrate the problem of exposing floatingpointinaccuracyusingthreewell knownfloating pointsummation algorithms recursivesummation pairwisesummation andcompensatedsummation.second weshowhowthestateoftheartin error inducinginputgeneration alongwithothertwobaselines fails to find inputs that trigger errors in these algorithms while we successfullycraftsuchaninputmanually.finally wediscussour insight for generating inputs that maximize error.
12621double recursive summation double a int size for int i s i z e i i a a return a a recursive summation 1double pairwise summation double a1 double a2 double a3 double a4 a1 a2 a3 a4 a1 a3 return a1 b pairwise summation 1double compensated summation double a int size double sum a e for int i s i z e i i sum a a a e a sum a e sum a a return a c compensated summation figure floating point summation algorithms.
.
floating point summations to achieve better accuracy when adding floating point numbers avarietyofsummationalgorithmshavebeenproposed.figure1 shows summation algorithms that compute the sum over the elementsofadoublearray.2therecursivesummationalgorithm iteratively adds each element in the array in reverse order.
it is simpleandthemostfrequentlyused butitsaccuracydependson theorderinwhichnumbersaregiven.pairwisesummationadds arrayelements inpairs toavoid largeroundingerrorsintroduced when adding each of the elements to the partial sum.
lastly the compensatedsummationalgorithmuses acorrectionterm i.e.
e line to diminish the rounding error incurred in the addition operation line of the last iteration.
more details on the accuracy of these and other summation algorithms can be found in .
.
error inducing inputs for summations first we investigate the effectiveness of three existing approaches for generating error inducing inputs.
specifically we use the c randfunction as random number generator s3fp the stateof the art error inducing input generator for programs with multidimensionalinputdata andklee float asymbolicexecution enginethatsupportsfloatingpoint.weimplementanadditional128bit quadruple precision version of each summation.
for each input arraygenerated werunbothoriginalandhigh precisionprograms to calculate the error in the result.
as shown in table 1a for an inputarrayofsize4inrange therandomgeneratorand s3fp searched input arrays but failed to find one that exposes error in the summations.
klee float generated an array of zeros thatcoversthe onlypathintheprogramswhileexposingnoerrors.
second we manually crafted an array athat triggers high numericalerroroneachsummationalgorithm.thevaluesforeacharray element can be found in table 1b.
we refer to the manual 2for simplicity and readability we omit the bulky code of pairwise summation for an array of size n and illustrate it using double variables.
h h h h h h devroxwh huuru h uhodwlyh huuru grxeoh suhflvlrq h txdguxsoh suhflvlrq h 5hfxuvlyh 6xppdwlrq h h h h h devroxwh huuru h uhodwlyh huuru grxeoh suhflvlrq txdguxsoh suhflvlrq h 3dluzlvh 6xppdwlrq h h h h h h h devroxwh huuru h uhodwlyh huuru grxeoh suhflvlrq h txdguxsoh suhflvlrq h rpshqvdwhg 6xppdwlrq figure summations on the manually crafted input array.
approachsimplyasmanual.table1ashowsthatmanualexposes arelativeerrorof12intherecursiveandcompensatedsummations and a relative error of in the pairwise summation.
figure shows the computation process of each summation algorithm over the manually crafted input to shed light on the generationoferror inducinginputs.programexecutionsofrecursive summation in double and qadruple precision produce summationresults1 .1e 15and 1e respectively.usingtheresultof qadruple execution as the ground truth the absoluteerror of double execution is .2e and the relativeerror is .
we further examine the result and the error incurred at each addition operation in double precision.
as shown in figure the first addi tionadds a toa .because a islessthantheleastsignificant digit i.e.
ulp of a .4e a is rounded off shown as the rounding error e .
the second addition adds the result so far to a unfortunately both values cancel out.
the local error remains .2e 15sinceno newroundingerrorsoccur.
lastly a which containsthepartialsummationresult0 isaddedto a .1e .
thefinalresult .1e isstoredin a andtheerroraccumulated in the result is .2e .
because the magnitude of the error is close to the result of the summation the relative error is high.
similarly thefirsttwoadditionsinpairwisesummationgenerate twoerrorsbyroundingoffthesmalleroperand andthelastaddition cancels the two partial summation results.
the cancellationcauses themagnitude ofthe errorto be comparableto theresult leadingtoalargerelativeerror.compensatedsummationmaintains 1263table accuracy testing of summation algorithms.
the input is an array of size 4in the range .
a testing results.
maximum relative error approach inputs recursive sum.
pairwise sum.
compensated sum.
random s3fp klee float manual b manual values for input array.
array element fp value a .0a .2e 15a .0a .1e acorrectionterm i.e.
einthethirdsubgraphoffigure2.itcaptures theroundingerrorgeneratedbythecurrentadditionoperation and will be added when applying the next addition.
for example after the first addition e holds the rounding error .2e introduced byadding a anda .however becausethenexttermtoadd a .
hasanulpgreaterthan .2e thecorrectionterm isdropped inthesecond addition.
also cancellationoccurs inthe seconditeration.intheend thecompensatedsummationperforms the same as recursive summation and its result over array ais .1e with a relative error of .
input generation insight.
we observe two general patterns in thesummationsoverthemanualinputarray a a roundingthat particularlyoccurswhenaddingtwofloating pointnumberswhose exponentsvarywidely e.g.
.
.2e and b cancellation thataffectslargeterms.thefirstpatternintroducesroundingerrors in intermediate results while the second pattern exposes the errors bycancelingtheaccuratesignificantdigits.weproposetoinject inaccuracychecks atfloating pointoperationstodetectrounding andcancellations.ourchecksdonotrequiremaintainingahighprecision shadow execution to calculate intermediate errors but checkinaccuraciessolelybasedontheoperandsandtheresultof the computation.
in response to where to inject inaccuracy checks we observe in our example that the rounding pattern arises in the first addi tion while the cancellation pattern occurs on different addition operationsinthe3summationprograms 2ndadditioninrecursive and compensated summation and 3rd addition in pairwise sum mation .
in reality it is unattainable to predict the floating pointoperations at which rounding and cancellation need to happen.
thisisthereasonwhywecreateasearchspaceontheinaccuracies of computations and conduct the search using symbolic execution.
in summary the goal of our inaccuracy checks is to create a searchspacetoallowsymbolicexecutiontoexploretheinaccuraciesofdifferent code areas for high error inducing inputs.
this observation on the inaccuracy patterns can be generalized to other floating point code.
it is highly likely that an input that conforms to our inaccuracycheckswillproduceahighnumericalerrorintheresult.
technical approach ourapproachtogeneratefloating pointinputsthatexposelarge numerical errors consists of three main components which are illustratedinfigure3.wefirstapplyaprogramtransformationthat injects checks for precision loss and cancellation into the program p.second weapplyvariousoptimizationstomitigatepathexplosion during symbolic execution including reducing the numberfigure fpgen workflow.
ofsymbolicvariablesbyconcretizingsomeinputvariablesusing random values.
input specifications are required for the identifi cation of input variables.
symbolic execution is then performedin the transformed program p prime.
finally we assess the quality of the generated inputs i1 i2 ... inby measuring their errors with respect to a higher precision version of the program ph.
the input that exposes the largest error imaxerr is then selected.
we also diagnosethe rootcause ofthe numericalerror tofurtherhelp the programmerinidentifyingtheprogramexpressionsthatcontribute the most to the numerical inaccuracy.
.
inaccuracy check injector thegoaloftheinaccuracycheckinjectoristotransformagiven programsothattheresultofeachinjectedfloating pointarithmeticoperationisexplicitlycheckedforprecisionlossandcancellationer rors.inthissection weassumeathree addresscoderepresentation in which each arithmetic operation hasat most two operands.
we firstdefineeachofthetwochecksseparately andthenwedescribe how we combine the two when injecting them into the program.
.
.
check for precision loss.
rounding errors are inherent to floating point and occur when an operation results in a value that cannot be exactly represented in floating point.
this leads to aloss of precision in the computed result.
in this paper we focuson precision loss that results in most bits of a data value being discarded.
for example a number smaller than .2e 38is rounded to when represented in single precision3.
the rounding error incurred is equal to the data value itself and all bits of precision are effectively discarded.
3assuming no subnormal numbers.
1264in most cases this type of precision loss4is unintentional and can be the symptom of a numerical bug.
for example consider the summation of 1e and .
if we apply the summation in the orderof1 1e insingleprecision thesumis0because 1e 8equals to due to precision loss that causes all bits of precision of 1e 8to be lost.
however if we change the order to 1e weareabletoattaintheexactresultofthesummation 1e without generating numerical errors.
from the view ofprogrammers theintentionistoaddthethreegivennumbers.
however the first order leads to a result that only adds two of the numbersduetoprecisionloss.thisviolatesprogrammers intention and therefore is a hidden numerical bug.
precision loss checks are designed to expose such errors.
weinjectexplicitprecisionlosschecksafterfloating pointadditionandsubtractionoperations.5foreachgivenfloating point operation we compare the exponents of the two operands.
the intuition behind is that the addition of two floating point values of similar magnitude will result in a more accurate result than the addition of two values whose magnitude differ significantly.
we define the precision loss check as follows exp op1 exp op2 whereexp op1 andexp op2 represent the exponents of the twosourceoperands respectively and isanintegerconstantthat definesthelowerboundoftheexponentdifference.inotherwords represents the number of bits of precision that are discarded.
for example if isgreaterthanthenumberofsignificanddigits i.e.
in single precision and in double precision all bits of precision in the corresponding operand will be discarded.
res x 18o r1 or bitsop2 x bitsdiscardedop1 x the figure above visualizes the computation on op1andop2 which leads to bits ofop2being discarded.
each operand and the resultofthecomputationaredescribedinthefloating pointformat that contains three components sign bit exponent bits in float 11bitsin double andfraction 23bitsinfloat 52bitsin double .
as shown the exponent of op1isx greater than the exponentof op2.whenperforminganadditionorsubtractionon op1andop2 thefractionof op2isshiftedtotherightby bits.the first few bits bits in float bits in double of op2 areusedtocomputethefractionoftheresult reswhilethelast bitsarediscarded.finally resisnormalizedanditsexponentcan be adjusted by .
4forsimplicity therestofthispaperrefersto precisionloss whenmostbitsofprecision are discarded.
5among the floating point arithmetic operations addition and subtraction are the common operations that are likely to discard most bits of precision in one of its operand data values.
.
.
check for cancellation errors.
acancellationoccurswhen two floating point numbers with opposite sign and nearly equal magnitudeareadded.themostsignificantbitsarecanceledwiththeleast ofteninaccurate significantbitstakingprecedence.considerthe decimalnumbers .
and .
.
roundingthese numbers to three decimal digits results in .
and .
each with a rounding error of 4e .
if we add these numbers the first three digits cancel each other and the result of the addition is .
which is comparable in magnitude to the rounding errors.
the relativeerroroftheresultis .
.
.
.4e which can be unacceptable.
such a cancellation error can have serious repercussions.
the affected value could change the control flow of the program if used in a conditional expression or be amplified through the rest of the computation thus potentially introducing a large numerical error in the final result.
cancellation checks have been used in prior work t o detectprograminstabilityonthefly.specifically thecancellation check is defined as follows max exp op1 exp op2 exp res whereexp x represents theexponent of floating pointnumber x op1andop2arethetwooperands and resisresultofanaddition orsubtractionoperation.thevalue denotesthelowerboundof thenumberofsignificantbitsthatarecanceled.forexample two numbers are canceled out to if is bits in single precision.
asvisualizedbelow operand op1andoperand op2havethesame exponent x andtheexponentofthecomputationresult resisreduced tox .
the first bits ofop1andop2are discarded due to cancellation.thefewleastsignificantbitsof op1andop2 bitsinfloat bitsindouble whichareinaccuratedueto rounding errors are used to compute the most significant bit of res.
res x 18o r1 or bitsop2 x bitsop1 x bits .
.
check injection.
first weconstructaninaccuracydetector that checks for precision loss and cancellations in floating point computations.
to facilitate symbolic execution we divide the program execution under the computation into three branches.
asshown in figure one branch is guarded by the precision loss conditionformalizedinequation toexploreinputsthatlosepre cisionintheexecution onebranchissecuredwiththecancellation condition described in equation to select inputs that can cause catastrophic cancellation and the third branchsatisfies neither of the two conditions and can be referred as the accurate branch.
precision loss and cancellation conditions are contradictory as cancellationrequiresthe twosource operandstobe nearlyequal and precisionlosshappensonlywhenthetwosourceoperandsarein significant different order of magnitude.
therefore no cancellation occurs in the precision loss branch.
inaccuracythresholds.
weselectthresholds and forprecision lossandcancellation respectively.threshold representsthenumber of bits of precision that are discarded in precision loss from 12653uhflvlrq rvv udqfk 3uhflvlrq rvv rqglwlrq dqfhoodwlrq udqfk ffxudwh udqfk dqfhoodwlrq rqglwlrq dqfhoodwlrq rqglwlrq3uhflvlrq rvv rqglwlrq figure inaccuracy check branches.
figure average of maximum errors on summation programs with different inaccuracy thresholds.
equation and represents the number of bits in the significand thatcancelfromequation .thelarger is themorebitsofprecisionarediscardedintheoperandvaluewiththesmallermagnitudeofthetwo.similarly thelarger is themorebitsofthesignificand are canceled in the two operand values.
both will cause significant inaccuracies.indoubleprecision and arepositiveintegersno greater than the number of bits in the significand .
we select thevaluesof and basedonanempiricalevaluationonthethree summation programs presented in section .
we start the search with the parameter setting and investigate all multiples of for and .6for each parameter setting we compute the average of the top errors triggeredin each program and combine the results of the three programsbycalculatingthemeanvalue.figure5showsthemeanvalueofthe errors in the three summation programs while the threshold parameters and vary.thecoordinateofabarindicates andtheheightdenotesthemeanvalueofthemaximumerrors.the bars use distinct colors for different values of parameter .
the parametersettingthatranksfirstis .weusethis settinginourexperimentalevaluation whichyieldsfruitfulresults.
check conditionbinarization.
the two checkconditions in figure4involvecomputationssuchastheabsolutevalueofaninteger inequation andthemaximumoftwointegersinequation .
these operations generate additional branches in the binary code.
thefollowing twostatements showthese branchesusing theconditional operator ?
in c. 6our initial value is 28because we consider that discarding at least bits could affect precision sufficiently.
define exp bt pa long unsigned long pa 0x7ff a exp define abs mask a a sizeof long define abs bt a a abs mask a abs mask a b abs define max bt a b a a b a b c max figure bitwise utility functions.
abs a a ?a a max a b a b ?a b the expansion of branches increases the number of paths exponentially and makes it more difficult for the symbolic execution engine to find inaccuracy patterns.
to alleviate this problem wedesignedthreehighlyoptimizedbitwiseutilityfunctionsthatdo notincludeanybranches.theutilityfunctionsare exp bttoobtain theexponentofafloating pointnumberwithspecifiedprecisionasa long integer abs btto obtain the absolute value of a long integer andlastly max btthatreturnsthelargestoftwolongintegers.figure6presentsthedetailedimplementationofthethreefunctions in double precision using c macros.
selectinginjectionsites.
inthispaper wemainlyfocusonmaximizing numerical error for floating point code that uses multidimensional input data.
on the selection of injection sites for inaccuracychecks weareparticularlyinterestedinloopsthatiterateontheinputdataandupdatethevariablethatholdstheresult.assum ingthree addresscode weinjectinaccuracychecksundertheaddi tionandsubtractionoperations.unfortunately itisnotpracticaltocheck for inaccuracies in each iteration.
therefore we provide two sampling strategies uniform and logarithmic to dynamically select loop iterations for inaccuracy checks.
both sampling strategies supplytheparameter startandstepforcustomization.parameter startallows the user to start the counter from any iteration and stepspecifies the step to the next sampled iteration.
in logarithmic sampling stepindicatestheinitialstep whichismultipliedby10 each time the counter increases by one order of magnitude.
remark.
basedonourobservationofinaccuracypatterns described in section we inject inaccuracy branches to enable symbolic execution to find error inducing inputs.
note that previous work has used equation to detectcancellation when runningaprogramona givensetofinputs.incontrast ourfocus in thispaper is to generateinputs thatmaximize error.to thebest of our knowledge we are the first to formulate precision loss in which most bits of one operand are discarded and combine it with cancellations for inaccuracy checking.
our technique is the first to enable a widely used technique such as symbolic execution to find floating pointinputsthatmaximizeerror.symbolicexecutionitself however is unable to generate such inputs as shown in section .
.
symbolic execution with concretization after injecting precision inaccuracy checks we proceed to symbolically execute the program under test.
in this paper we use one of the most popular and mature symbolic execution tools klee 1266data input variables invars input specifications inspecs program p program with injected inaccuracy checks p time budget tbudget timeout parameters 0 1 result maximum error the error inducing input 1tstart time random search for an error inducing input.
3randomerrmax inbase null 4rstart time 5whiletime rstart 0do 6generate a random input in the input domain in 7err compute error in p 8iferr emax then randomerrmax err inbase in 10end 11end separate the input variables into operands.
13op1vars op2vars partition variables invars inspecs initilization.
15errmax randomerrmax errinput inbase 16concvars op1vars symbvars op2vars 17whiletime tstart tbudget do concretize convvars using base values.
19concretize the variables in convvars using inbase 20symbolize the variables in symbvars 21stat sinputs symbolic execution convvars symbvars p 1 22ifstat timeout then snum length symbvars s1vars s2vars random divide symbvars snum snum convvars convvars s1vars symbvars s2vars 27else forsinput in sinputs do err compute error join input sinput inbase p iferr errmax then errmax err errinput join input sinput inbase end end snum length symbvars lop2 length op2vars s1vars s2vars random divide op2vars lop2 snum snum convvars op1vars s1vars symbvars s2vars 38end 39end 40returnerrmax errinput algorithm symbolic execution with concretization.
asoursymbolicexecutionengine.kleemodelstheenvironmentto explorealllegalvalueswhileensuringtheaccuracyoftheprogram state maintains memory efficiently to allow exploring as many as hundreds of thousands of paths simultaneously and provides a setofheuristicsearchstrategiesthatuserscanselectfrom.more importantly ithasanextension klee float whichprovides support for floating point arithmetic and thus enables symbolic execution of floating point programs.
symbolic execution allows program inputs to be represented as symbols.
the program is then interpreted using these symbolicvaluesratherthanconcreteinputs.intheexecutionofaconditional statement klee forks the current process into two and each child process updates its program state by adding the branch constraints overtheinputsymbolsintoitspathconstraints.pathconstraints are solved when the program terminates and input symbols are concretizedtospecificvaluesthatexercisethegivenpath.oneofthemainchallengesfacedbysymbolicexecutionispathexplosion.the numberof feasiblepathsgrows exponentiallywiththe sizeofthe program.unfortunately injectinginaccuracychecksexacerbates pathexplosion.toalleviatethisproblem itisimportanttomanage the number of symbolic variables.
we concretize input variablesprior to symbolic execution and find that it significantly reduces thenumberofpathstoexplore makingsymbolicexecutionforour transformed programs practical.
first werefertoinputvariablesasscalars.thearrayandmatrix inputvariablesarebrokendownintomultiplescalarinputvariables forconcretizationandsymbolization discussedintherestofthis section.concretizinginputvariablestomanagethenumberofsymbolic variables is critical for the application of symbolic execution.
first symbolizing all input variables is redundant since symbolizingonlyoneofthetwooperandsinanoperationsuffices.take the operation x yas an example.
to trigger a cancellation in the operation itissufficienttosymbolizeeithervariable xory andthe valueoftheothercanbearbitrary.theconcretizationofredundant symbolic variables is effective in speeding up the constraint solver behind symbolic execution.
second besides the redundant input variables we randomly select input variables for concretization in order to perform symbolic execution.
algorithm1describestheprocedureofsymbolicexecutionwith concretization.givenprogramp programp withinaccuracycheck injections input variables and input specifications that describethe input variables and how they are related in the computation our algorithm returns the maximum error triggered in program pandthecorrespondingerror inducinginputwithinatimebudget.
specifically we first conduct a random search over all input variables line and the input that triggers the highest error is kept asbase values of the input variables for future concretization.
we then partition the input variables into two groups based on the input specifications so that two operand variables are separated into different groups line .
take matrix multiplication mm as an example which performs multiplication over two matrix input variables.
each of the matrices is an operand of the multiplication and in our operand partition the two matrix entries are separated asop1varsandop2vars.
lastly we perform symbolic execution with concretization to maximize the numerical error in program p line .
we firstinitialize the maximum error and the corresponding input using theresultofrandomsearch line15 andthenupdatethemevery timeahighererroristriggered line30 .theinputvariablesare dividedintoconcretevariables shownas concvars andsymbolic variables symbvars .
concrete variables use the corresponding concretevaluesfromthebaseinput inbase line19 andsymbolic variables are declared as symbols line .
thesymbolicexecutionengineisinvokedontheinjectedprogramp withanexecutiontimethreshold 1 line21 .ifsymbolic executiondoesnotterminatewithinthetimethreshold 1 w er educe the number of symbolic variables by half line and 1267repeat.7the initial number of symbolic variables is the number of the operand variables with smaller size line .
if the symbolic executionengineterminates weexamineeachinputitgenerates bycomputingthenumericalerroreachinputtriggersandupdate the largest error to the maximum error errmaxand error inducing inputerrinput line .
finally we shuffle the concrete and symbolic variables in the operand variable op2vars line and repeat the above procedure until time is up.
.
error measurement asdiscussedintheprevioussection theinputsgeneratedbyrandom search and symbolic execution are evaluated by computing thenumericalerrortheytrigger algorithm1 lines7and29 .to measure the error we transform the program into higher precision e.g.
bit precision .
we compare the result produced by the originalprogram againsttheone fromthe high precisionprogram.
moreover the error is represented by the relative error ofthe two program results i.e.
r r0 max flt min r0 where ris the result produced by the original program r0is the result ofthetransformedprograminhighprecision and flt min indicatestheminimumrepresentablepositivefloating pointnumber in float precision.
in addition we print the diagnosis information that contains the log of precision losses and cancellations and thecorrespondingcodeareaan inaccuracyeventoccurs.thiscan helptheprogrammerinidentifyingtheprogramexpressionsthat contribute the most to the numerical inaccuracy.
experimental evaluation we implemented our algorithm in a tool named fpgen.8fpgen includes a floating point computation analyzer for c programsimplemented using libtooling .
the analyzer yields a list of code sites i.e.
statements that contain floating point addition subtraction operations located within loops to select as inaccuracy injection sites.
fpgen then performs symbolic execution with concretizationonthetransformedprogramtomaximizetheerrorin the result.
we use klee float as the symbolic execution engine which is built to run on llvm bitcode files.
intheevaluationof fpgen allexperimentswererunonaworkstationintel r xeon r gold6238cpu 8cores .10ghz 32gb ram and the operating system is ubuntu .
.
lts.
the goal of this evaluation is to answer the following questions rq1how effective is fpgen at finding error inducing inputs?
rq2how does fpgen compare to random input generation the state of the art tool s3fp and klee float?
benchmarks.
we evaluate fpgen on the summation algorithms described in section matrix computation routines from the meschach library and 9uniquestatistics routines from the gnuscientificlibrary gsl .meschachprovidesaseriesofbasic computationroutinesonmatricesandvectorsinc.theroutine sum adds the elements of a vector.
as their names indicate normand 7intheexperimentsdiscussedinsection4 weuse max time 1 tohalttheexecution ofthe symbolicexecutionenginewhen timeisupaccording tothethreshold 1 and check whether it has ever reached any error injections and thus triggered errors with incompleteexecution.ifitreachederrorinjectionsandtriggerederrorswithintime threshold 1 it is considered as an effective termination otherwise considered as non termination i.e.
requiring more time to explore the error paths .
8the source of fpgen is available on github normand normof avector androutines dotandconvolution calculate the dot product and convolution product of two vectors respectively.
mvmultiplies a matrix by a vector and mmmultipliestwomatrices.
luandqrfactoramatrixto different forms.
gsl provides a wide range of mathematical rou tines written in c and c and has been used for evaluation in prior work .
specifically we use the gsl statistics routines thattakearraydataasinput.9theseroutinescomputethemean variance standarddeviationandmoreadvancedstatisticalterms such as absolute deviations skewness and kurtosis for weightedsamples.
the functions mainly take two input arrays one as the samples and one being the associated weights.
experimental setup.
table2presentsthebenchmarksandtheir input characteristics including kind of input the number in the parenthesesindicatesthesizeofeachinputkind sizeofsymbolized input and size of concretized input in both the initial and final configurationsof fpgen.asdescribedinalgorithm1 theinitial partition of symbolized and concretized inputs is based on the input operands.
for the summation programs mm lu and qr half of the elements of an array matrix operand are symbolized and the restoftheinputdataisconcretized.fortheremainingprograms all elements of an array vector operand are symbolized and all elements of the other operand are concretized.
moreover the final configurationonsizeofsymbolizedandconcretizedinputsindicates the partition in which the best relative error is observed.
with regard to the time threshold parameters 0and 1describedinalgorithm1 weuse 0 1 30minforsummation programs 0 10min 1 55minfor meschach programs and 0 20min 1 33minforgslprograms.lastly allbenchmarks usedoubleprecision 11andweinjectinaccuracychecksintothe lastaddition subtractionoperationthatupdatestheaccumulator inthecoreloopofeachprogram.thegeneratedinputsare float numbersin tofacilitatecomparisonwiths3fp which operates on float numbers and requires an input range.
baselines.
we compare fpgen to a random input generator we implemented in c s3fp the state of the art floatingpoint error inducing input generator for programs with multidimensionalfloating pointinput and klee float thefloatingpointsymbolicexecutionengineusedbyfpgen.weusethedefault parametersettings fors3fp cinitisrandomized whileparameters kandnpartare set to the value .
error measurement.
the ground truth for our benchmarks is obtained by running higher precision implementations of theprograms on the generated inputs.
specifically we implemented summations that use bit precision and perform long double precision bit extended precision for meschach and gsl routines.
meschach and gsl support compilation in double and long 9there are a total of floating point statistics routines in gsl however from the standpointofsymbolicexecution 6ofthem wvariance m wsd m wtss m wabsdev m wskew m and wkurtosis m areareplicateof6otherroutines wvariance wsd wtss wabsdev wskew and wkurtosis .
we only report results for distinct routines but the results for all gsl statistics routines are available for full reference.
10thefinalinputsizedoesnotindicatethesizeofsymbolizedandconcretizedinput in the last partition of the search.
for some programs further partitions yield smaller errors.
11gsl routines use long double for the accumulators and we manually modified themtobeinconsistentprecisionwiththesamples i.e.
doubleintheexperiments.
webelievethechangewillnotcauseanyoverflowexceptionssinceallsamplesand their associated weights are in a specific input range.
1268table input characteristics of benchmarks.
initialinput size final input size benchmark s input kind symbolized concretized symbolized concretized summations array sum norm vector norm vector dot convolution vectors mv vector matrix mm matrices lu matrix qr matrix wmean wvariance w wsd w wtss arrays wabsdev wskew wkurtosis arrays wvariance wsd arrays recursive sumpairwise sum compensated sumsum2normdot convolutionmvmmluqr wmean wvariance wsd wvariance wwsd wwtss wabsdev wskew wkurtosis 4100maximum relative errorfpgen random s3fp figure comparison of maximum errors triggered by the error inducing input generators.
doubleprecision.12notethatallbenchmarksaretransformedto higherprecisionatthesourcecodelevel andwedidnotobserve precision specific operations that can potentially cause errors in thetransformation .forallourbenchmarks wecalculatethe relativeerroroftheresultproducedbytheoriginalprogramwith respect to the ground truth.
note that five of our benchmarks produce vectors or matrices as final result.
in these cases we report the maximum relative error observed across all elements.
experimental results.
we evaluate fpgen on the given benchmarks and compare it to random input generation referred to as random the state of the art input generator s3fp and klee float.forallexperimentsweconsideratimebudget of2hours.theresultsareshownintable3.column rel.error indicates the maximum relative error triggered by generated inputs the largest error triggered among the four tools is shown 12thesupportof longdoubleprecisioninmeschachisincomplete andwemanually adjusted few header files.
13s3fponly aimsontriggeringhigh errorforonesingle outputnumber.for vector matrix output we adopts the same methodology described in the paper which reports the relative error for the output element whose computation requires the highestnumberoffloating pointoperations.ifalloutputelementsinvolvethesame number of operations it reports the relative error of the first output element.inbold inputs denotesthetotalnumberofgeneratedinputs and hh mm ss describes the execution time.
as shown kleefloatisnotabletotriggernumericalerrorsonitsownasitsimply searches for inputs that cover program paths.
among the three error inducinginputgenerators fpgengenerateserror inducing inputs for out of benchmarks while the inputs generatedby random and s3fp trigger an error in out of programs.
asshowninthefirstfourrowsintable3 randomands3fpexploredoverfivehundredthousandinputarrays vectorsbutfailed tofindonethatexposesanerrorforthe3summationprogramsand meschach routines.
fpgen however triggered errors in theseprograms except for norm after exploring significantly fewer inputswithinthetimebudget.furthermore thenumericalerrors triggeredbyfpgenareupto1 .
whicharecomparableinorderof magnitudetotheerrorstriggeredbythehandcraftedinputfrom section .
figure7visualizesthemaximumrelativeerroreacherror inducing input generator triggered for all benchmarks except normfor which none of the generators triggered an error.
the y axis that indicates the maximum relative error triggered in each benchmark is proportional to the logarithm of the errors.
as shown fpgen 1269table accuracy testing results for numerical library routines.
recursive summation pairwise summation compensated summation rel.
error inputs hh mm ss rel.
error inputs hh mm ss rel.
error inputs hh mm ss random .0000e .0000e .0000e s3fp .0000e .0000e .0000e 00klee float .0000e .0000e .0000e fpgen .0000e .3174e .0000e sum norm norm rel.
error inputs hh mm ss rel.
error inputs hh mm ss rel.
error inputs hh mm ss random .0000e .0000e .1216e s3fp .0000e .0000e .1170e klee float .0000e .0000e .0000e fpgen .0000e .0000e .2117e dot convolution mv rel.
error inputs hh mm ss rel.
error inputs hh mm ss rel.
error inputs hh mm ss random .7010e .2803e .0000e 00s3fp .5831e .9864e .0000e klee float .0000e .0000e .0000e fpgen .9190e .0446e .9366e mm lu qr rel.
error inputs hh mm ss rel.
error inputs hh mm ss rel.
error inputs hh mm ss random .1102e .0000e .0000e 00s3fp .1102e .0000e .0000e klee float .0000e .0000e .0000e fpgen .5783e .7327e .5912e wmean wvariance wvariance m wsd wsd m rel.
error inputs hh mm ss rel.
error inputs hh mm ss rel.
error inputs hh mm ss random .4290e .5039e .5193e 00s3fp .6620e .5955e .2977e klee float .0000e .0000e .0000e fpgen .0000e .6280e .7439e wvariance w wsd w wtss wtss m rel.
error inputs hh mm ss rel.
error inputs hh mm ss rel.
error inputs hh mm ss random .9593e .9797e .5294e s3fp .0918e .0459e .7739e klee float .0000e .0000e .0000e 25fpgen .2858e .1429e .4513e wabsdev wabsdev m wskew wskew m wkurtosis wkurtosis m rel.
error inputs hh mm ss rel.
error inputs hh mm ss rel.
error inputs hh mm ss random .6840e .5025e .5107e 00s3fp .2077e .1646e .3139e klee float .0000e .0000e .0000e fpgen .0000e .5675e .7733e outperformsrandomands3fpfor15outof20benchmarks.in2of theotherbenchmarks thethreeapproachesarecomparabletoeach other and the order of magnitude of the errors are .
for the remaining3benchmarks fromgsl fpgenfailedtoreachanerror path within the time budget and s3fp triggered the largest error amongtheinputgeneratorsthroughblack boxsearch.itrequires future improvements on symbolic execution to assist fpgen reach more error paths and thus trigger larger errors for these programs.
insummary usingprecisionlossandcancellationchecksiseffective in finding high error inducing inputs especially for numerical programs with multi dimensional input data.
from the evaluationon the summation benchmarks the matrix computation librarymeschach and the gsl statistics functions fpgen significantly outperforms the state of the art.
rq1 fpgen proves to be effective at finding error inducing inputs by triggering errors in out of benchmarks and the errors are .
on average in the order of magnitude.rq2 fpgen significantly outperforms the state of the art by triggeringerrorsin33 moreprogramswhileerrorsaremore than orders of magnitude larger on average.
1270specifically fpgengeneratederror inducinginputsfor20benchmarkprogramswhilethestate of the artgeneratorstriggeranerror for13outof21programs.moreover regardingthemaximumerrors triggeredbythegeneratedinputs fpgen .35onaveragein20 programs improvess3fp .46onaveragein13programs byover two orders of magnitude.
the order of magnitude of the maximum errors triggered by random in programs is .
on average.
discussion.
theerror inducinginputsgeneratedbyfpgencan be used in many contexts including floating point precision tuning and compiler testing for floating point optimizations.
dynamicprecision tuning e.g.
lowers precision while satisfying an accuracyconstraint.suchapproachestunetheprogramswithrespect to a given test set.
augmenting such test sets with inputs generatedbyfpgencouldleadtomorerobustprecisionoptimizations.
moreover compilerstransformcodeforoptimizationsbutthetransformation is risky for floating point code because floating pointarithmetic does not satisfy associative and distributive laws.
to enhance the compiler optimizations for floating point code inputs that maximize the numerical error are required for testing.
with regard to the limitation of our tool first fpgen requires a specification for inaccuracy check injection we used core loops in thispaper .itremainsfutureworktoidentifyothercodeareasto inject inaccuracy checks.
second we mainly rely on optimizations suchasconcretizationtomanagethenumberofsymbolicvariables to alleviate the scalability problem symbolic execution faces.
in thefuture itwouldbeinterestingtocomplementourworkusing techniquestospeedupsymbolicexecution .
related work floating pointtestdatageneration.
s3fp thestate of theart error inducing input generator for numerical programs with multi dimensional input data is black box.
s3fp iteratively divides thesearchrangeofeachinputvariableintotwoandpermutesthem randomly to generate a tighter search space.
the tool evaluateseach subspace by sampling inputs and selecting one for further exploration.theblack boxnatureof s3fpindicatesthatitisnotaseffectiveasfpgenwhentheinputspacebecomeslarge.othererror inducinginputgenerators i.e.
lsga eagt andautornp target numerical program with few scalar inputs.
lsga uses a genetic algorithm to evolve the exponent of the inputs however it does not provide an algorithm in evolving multi dimensional floating point inputs andthe tool is not publicly available.
eagt and autornp compute the approximation of the condition number in selecting inputs and focus on programs with one scalar input.
fpse andcoverme generatefloating pointtestinputs thatmaximize codecoverage.fpse adoptsanumberofsearch heuristicstosolvepathconditions containingfloating pointcomputations.
coverme translates the problem of covering a new branch in the floating point code into amathematical problem thatcanbesolvedbyapplyingunconstrainedprogramming.suchefforts are complementary to our testing approach and can be adopted to enhance our symbolic execution based approach.
floating point input generation tools have been developed to detect other specific problems.
chiang et al .
detect path divergencebetweenafloating pointprogramanditshighprecisionexecution.barretal .
usesymbolicexecutiontodetectfloatingpoint exceptions such as overflows and underflows.
they also performatransformationonthenumericalprogram andsymbolically execute the transformed program to identify inputs that trigger an exception.thetransformation h owever focuses oninjectingexception checks before a floating point operation which is different from ours.
moreover the transformed program is symbolically executed using real arithmetic while we use floating point arithmetic.
floating point dynamic analysis.
benz et al .
perform every floating point computation side by side in higher precision and trackthepropagationoferrorstodetectaccuracyproblems.lam etal.
conductbinaryinstrumentationonfloating pointadditions and subtractions to detect cancellations.
they analyze the exponents of the operands and the result of the instrumented operationstodeterminetheseverityofacancellationandreportstack information for severe cancellations.
besides the runtime detectionofmathematicalcancellations baoandzhang proposetotrack the propagation of the cancellation error which can be suppressed orinflatedinthesubsequentexecution.bothcancellationdetection techniques usethecancellationcheckequationdescribed in our paper.
however their main purpose is to detect cancellation issues for existing inputs and cannot generate error inducing inputs.furthermore itisimportanttocombineprecisionlosswith cancellation in the generation of error inducing inputs.
to the best of our knowledge we are the first to present such an approach.
raive performsfloating pointcomputationwithavector of values tocapture rounding errors and report outputvariations.
similarly tang et al .
perturb the underlying numerical values and expressions to uncover instability problems in numerical code.
suchdynamicanalysesdetectaccuracyproblemsongiveninput data.moreover alargenumberofdynamictechniques e.g.
optimize floating point code using a given input set.
all of these techniques could benefit from the inputs fpgen generates.
conclusion we presented an approach to effectively generate floating point inputsthattriggerlargeerrors.first weformulatedtwoinaccuracychecksforlargeprecisionlossandcancellation.theinjectionofinaccuracy checks after floating point computation enables symbolic execution to explore specialized branches that cause numerical inaccuracy which can lead to large errors in the final result.
second we proposed optimizations to alleviate path explosion.
in particular this was achieved by strategically reducing the number ofsymbolicvariablesviaconcretization.weimplementedouralgorithminatoolnamedfpgen andpresentedanevaluationon21 numericalprogramsincludingmatrixcomputationandstatistics libraries.ourresultsshowthatfpgenisabletoexposeerrorsfor20oftheevaluatedprogramswhilethestate of the arterror inducinginputgenerators3fponlytriggerserrorsfor13outof21programs.
moreover fpgen triggered an error as large as 6on average while the maximum error s3fp triggered is about 8on average.