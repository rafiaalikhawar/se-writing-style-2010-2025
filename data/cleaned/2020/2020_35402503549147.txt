neudep neural binary memory dependence analysis kexin pei kpei cs.columbia.edu columbia university new york usadongdong she dongdong cs .columbia.edu columbia university new york usamichael wang mi27950 mit .edu mit cambridge usa scott geng scott.geng columbia .edu columbia university new york usazhou xuan xuan1 purdue .edu purdue university west lafayette usayaniv david yaniv.david columbia .edu columbia university new york usa junfeng yang junfeng cs .columbia.edu columbia university new york usasuman jana suman cs.columbia.edu columbia university new york usabaishakhi ray rayb cs.columbia.edu columbia university new york usa abstract determining whether multiple instructions can access the same memory location is a critical task in binary analysis.
it is challenging as statically computing precise alias information is undecidable in theory.
the problem aggravates at the binary level due to the presence of compiler optimizations and the absence of symbols and types.
existing approaches either produce significant spurious dependencies due to conservative analysis or scale poorly to complex binaries.
we present a new machine learning based approach to predict memory dependencies by exploiting the model s learned knowledge about how binary programs execute.
our approach features i a self supervised procedure that pretrains a neural net to reason over binary code and its dynamic value flows through memory addresses followed by ii supervised finetuning to infer the memory dependencies statically.
to facilitate efficient learning we develop dedicated neural architectures to encode the heterogeneous inputs i.e.
code data values and memory addresses from traces with specific modules and fuse them with a composition learning strategy.
we implement our approach in neudep and evaluate it on popular software projects compiled by compilers optimizations and obfuscation passes.
we demonstrate that neudep is more precise .
and faster .
than the current state of the art.
extensive probing studies on security critical reverse engineering tasks suggest that neudep understands memory access patterns learns function signatures and is able to match indirect calls.
all these authors contributed equally to the paper permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
copyrights for components of this work owned by others than the author s must be honored.
abstracting with credit is permitted.
to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
request permissions from permissions acm.org.
esec fse november singapore singapore copyright held by the owner author s .
publication rights licensed to acm.
acm isbn .
.
.
.
.3549147these tasks either assist or benefit from inferring memory dependencies.
notably neudep also outperforms the current state of the art on these tasks.
ccs concepts security and privacy software reverse engineering computing methodologies machine learning .
keywords memory dependence analysis reverse engineering large language models machine learning for program analysis acm reference format kexin pei dongdong she michael wang scott geng zhou xuan yaniv david junfeng yang suman jana and baishakhi ray.
.
neudep neural binary memory dependence analysis.
in proceedings of the 30th acm joint european software engineering conference and symposium on the foundations of software engineering esec fse november singapore singapore.
acm new york ny usa pages.
https .
introduction binary memory dependence analysis which determines whether two machine instructions in an executable can access the same memory location is critical for many security sensitive tasks including detecting vulnerabilities analyzing malware hardening binaries and forensics .
the key challenge behind memory dependence analysis is that machine instructions often leverage indirect addressing or indirect control flow transfer i.e.
involving dynamically computed targets to access the memory.
furthermore most commercial software is stripped of source level information such as variables arguments types data structures etc.
without this information the problem of memory dependence analysis becomes even harder forcing the analysis to reason about values flowing through generic registers and memory addresses.
consider the following code snippet where we show two instructions within the same function at different program locations.
the function is executed twice resulting in two different traces.
esec fse november singapore singapore k. pei d. she m. wang s. geng z. xuan y. david j. yang s. jana b. ray address instruction trace trace ...... 0x06 mov rbx rax 0x3 rbx 0x1 rax 0x5 rbx 0x1 ...... 0x1f mov rdi rdi 0x1 rdi 0x0 ...... in intel x86 syntax mov rbx means writing register rbxto the memory pointed by register rax means dereference a memory address.
the two instructions are memory dependent read after write when rax 0x3 trace .
when analyzing the code statically it requires precise value flow analysis to determine what values can flow to raxfrom different program contexts.
over the last two decades researchers have made numerous attempts to improve the accuracy and performance of binary memory dependence analysis .
the most common approach often involves statically computing and propagating an over approximated set of values that each register and memory address can contain at each program point using abstract interpretation.
for example a seminal paper by balakrishnan and reps on value set analysis vsa adopts strided intervals as the abstract domain and propagates the interval bounds for the operands e.g.
registers and memory locations along each instruction.
vsa detects two instructions to be dependent if their intervals intersect.
unfortunately these static approaches have been shown to be highly imprecise in practice .composing abstract domains along multiple instructions and merging them across a large number of paths quickly accumulate prohibitive amounts of over approximation error.
as a result the computed set of accessed memory addresses by such approaches often ends up covering almost the entire memory space leading to a large number of false positives i.e.
instructions with no dependencies are incorrectly detected as dependent .
with the advent of data driven approaches to program analyses state of the art memory dependence analysis is increasingly using statistical or machine learning ml based methods to improve the analysis precision but they still suffer from serious limitations.
for example deepvsa trains a neural network on static code to classify the memory locations accessed by each instruction into a more coarse grained abstract domain such as stack heap and global and use the predicted memory region to instantiate the value set in vsa.
however such coarse grained prediction results in high false positives as any two instructions accessing the same region e.g.
stack will always be detected as dependent even when the instructions access two completely different addresses.
to avoid the precision losses by the static approaches bda uses a dynamic approach that leverages probabilistic analysis to sample program paths and performs per path abstract interpretation.
however as real world programs often have many paths the cost of performing per path abstract interpretation for even a smaller subset of paths adds prohibitive runtime overhead e.g.
taking more than hours to finish analyzing a single program.
it is perhaps not surprising while a dynamic approach can be more accurate than static approaches it can incur extremely high runtime overhead especially while trying to achieve good code coverage.
to achieve higher accuracy in a reasonably faster time we propose an ml based hybrid approach.
our key strategy is to learn to code value flows memory t race ml model execute code representation value flow representation code code value flows memory t race code representation ml model memory dependenciespretraining dynamic finetuning static synthesize interpretfigure the workflow of our approach.
we first pretrain the model to predict code based on its traces and predict traces based on its code.
we then finetune the model to statically infer memory dependencies.
reason about approximate memory dependencies from the execution behavior of generic binary code during training.
we then apply the learned knowledge to static code during inference without any extra runtime overhead see figure .
such a hybrid approach i.e.
learning from both code and traces has been shown promise in several software engineering applications including clone detection type inference and program fixing and synthesis .
however none of these works can reason fine grained value flows through different memory addresses as they do not explicitly model memory.
to bridge this gap we aim to model the memory addresses in the ml based hybrid framework and try to make fine grained predictions differentiating the memory contents of different data pointers.
modeling memory address is however challenging as it requires the model to i distinguish between different memory addresses ii learn to reason about indirect address