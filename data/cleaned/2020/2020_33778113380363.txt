hydiff hybrid differential software analysis yannic noller yannic.noller acm.org humboldt universit t zu berlin germanycorina s. p s reanu corina.pasareanu west.cmu.edu carnegie mellon university silicon valley nasa ames research center usamarcel b hme marcel.boehme acm.org monash university australia youcheng sun youcheng.sun qub.ac.uk queen s university belfast united kingdomhoang lam nguyen nguyenhx informatik.hu berlin.de humboldt universit t zu berlin germanylars grunske grunske informatik.hu berlin.de humboldt universit t zu berlin germany abstract detecting regression bugs in software evolution analyzing sidechannels in programs and evaluating robustness in deep neural networks dnns can all be seen as instances of differential software analysis where the goal is to generate diverging executions of program paths.
two executions are said to be diverging if the observable program behavior differs e.g.
in terms of program output execution time or dnn classification.
the key challenge of differential software analysis is to simultaneously reason about multiple program paths often across program variants.
this paper presents hydiff the first hybrid approach for differential software analysis.
hydiff integrates and extends two very successful testing techniques feedback directed greybox fuzzing for efficient program testing and shadow symbolic execution for systematic program exploration.
hydiff extends greybox fuzzing with divergence driven feedback based on novel cost metrics that also take into account the control flow graph of the program.
furthermore hydiff extends shadow symbolic execution by applying four way forking in a systematic exploration and still having the ability to incorporate concrete inputs in the analysis.
hydiff applies divergence revealing heuristics based on resource consumption and control flow information to efficiently guide the symbolic exploration which allows its efficient usage beyond regression testing applications.
we introduce differential metrics such as output decision and cost difference as well as patch distance to assist the fuzzing and symbolic execution components in maximizing the execution divergence.
we implemented our approach on top of the fuzzer afl and the symbolic execution framework symbolic pathfinder.
we illustrate hydiff on regression and side channel analysis for java bytecode programs and further show how to use hydiff for robustness analysis of neural networks.
permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
copyrights for components of this work owned by others than the author s must be honored.
abstracting with credit is permitted.
to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
request permissions from permissions acm.org.
icse may seoul republic of korea copyright held by the owner author s .
publication rights licensed to acm.
acm isbn .
.
.
.
differential program analysis symbolic execution fuzzing acm reference format yannic noller corina s. p s reanu marcel b hme youcheng sun hoang lam nguyen and lars grunske.
.
hydiff hybrid differential software analysis.
in 42nd international conference on software engineering icse may seoul republic of korea.
acm new york ny usa pages.
introduction the challenge of differential software analysis is to reason about multiple program executions simultaneously.
this may include executions of different inputs on the same program or executions of the same input across multiple programs or variants.
in this paper we focus on the problem of generating inputs that trigger maximal behavioral difference across program executions.
we say that the considered executions diverge if they lead to different observable behavior.
we consider various forms of divergence in terms of control flow paths decision difference observed outputs output difference and resource consumption cost difference which are required for different target applications.
for instance automated regression test generation aims to generate an input such that its execution on two successive versions diverges in terms of control flow paths or observed outputs.
an input that witnesses an output difference may expose a regression bug i.e.
an error that was introduced by the modifications from one version to the next.
many existing regression test generation techniques focus only on the affected paths in the changed version .
however regression testing inherently requires to reason about both program versions simultaneously to mitigate the problem of false negatives.
automated side channel vulnerability detection aims to generate two secret inputs such that given the same public inputs their execution yields different resource consumption .
a difference in observable behavior e.g.
memory consumption or execution time indicates possible information leakage about the secret inputs.
for instance if the time it takes to check a password of length n turns out to be proportional to n an attacker can derive the password length by observing the execution time.
such information leaks represent serious vulnerabilities as demonstrated by the recent meltdown and spectre vulnerabilities.
their detection requires reasoning over multiple program executions.
ieee acm 42nd international conference on software engineering icse icse may seoul republic of korea yannic noller corina s. p s reanu marcel b hme youcheng sun hoang lam nguyen and lars grunske automated robustness analysis of deep neural networks dnns aims to generate two inputs that are only marginally different to an imperceptible degree yet the dnn classifies them differently .
such adversarial perturbations are considered a major safety and security concern.
for instance when a dnn classifier is used in an autonomous car to identify street signs a misclassification undermines the safety of the passengers.
detecting such adversarial behaviors requires reasoning over more than one execution at once.
in this work we present hydiff a hybrid technique that integrates fuzzing a fast but shallow testing technique and symbolic execution a deep but slow analysis technique for a differential software analysis that can handle all of the above application scenarios.
for fuzzing we build on the popular greybox fuzzer american fuzzy lop afl which we extend with a divergence based feedback channel and new search heuristics that aim to maximize the divergence across multiple program executions.
the role of the fuzzer is to generate quickly many inputs by mutating existing seed inputs and favoring the ones that are shown to increase execution divergence according to different divergence metrics.
this enables hydiff to swiftly discover many divergences particularly in the beginning of the campaign.
however fuzzing alone cannot reach very deep into the code grappling with complex branch conditions and paths in low probability domains.
we therefore propose to enhance the fuzzing with a symbolic execution component that can tackle these issues by generating inputs via constraint solving based on conditions collected from the code.
to this end we built hydiff s differential symbolic execution dse component by extending shadow symbolic execution sse a differential analysis technique which represents two program versions in one annotated program and uses four way forking to explore all four decisions resulting from the combined branching behavior of both versions.
we extend sse from with an incremental approach to allow it to periodically check and incorporate the newly available concrete inputs from the fuzzer.
these new concrete inputs are executed concolically to collect symbolic constraints along concrete paths and they help to drive the symbolic analysis in directions of particular interest as directed by our heuristics.
in addition hydiff s dse component avoids the exploration of uninteresting code areas e.g.
in case of regression testing any unchanged program blocks by pruning the search space based on an inter procedural control flow graph icfg analysis.
as a result hydiff s dse implements an efficient four way forking exploration strategy driven by concrete inputs which allows it to cut deeper into the program to reveal divergences.
the integration of these two differential analysis approaches allows us to leverage their strengths and overcome their weaknesses.
both components are executed at the same time while they exchange interesting inputs enhancing each other.
we note that hybrid approaches that combine fuzzing and symbolic execution have been proposed in the past .
however hydiff is the first approach that explores the interplay between the two techniques for a differential analysis.
the problem is significantly harder than a classical program analysis and hence existing hybrid solutions are not applicable.
furthermore while the majority of previous differential symbolic approaches focus on regression testing hydiff is a general approach that is more widely applicable for instance it can compute divergences that are related not only to fuzzing symbolic execution instrumentation import mutate inputsassessment fuzzer output queueprogram versionsseed input fileschange annotated program symbc output queueconstraint solving input generation trieextension assessment explorationicfg setofdivergence revealing testinputsinput odiff ddiff crash cdiff patch dist cov id x x x id x x id x x ... ... ... ... ... ... ...importinput output hydiff figure hydiff overview.
different execution paths but also to different costs associated with the paths and that can be used in a side channel analysis.
we implemented hydiff for the analysis of java bytecode on top of the fuzzer afl and the symbolic execution framework symbolic pathfinder spf .
we evaluate hydiff for three applications i regression test generation ii side channel vulnerability detection and iii robustness analysis of dnns.
for i regression test generation we evaluate hydiff on the traffic anti collision avoidance system tcas several subjects from the defects4j benchmark and regression errors in apache cli .
for ii side channel vulnerability detection we evaluate hydiff on subjects taken from previous studies on side channel vulnerabilities as well as an implementation of modular exponentiation an operation involving non linear constraints and typically used in cryptography .
for iii robustness analysis of dnns we evaluate hydiff on neural networks taken from the mnist dataset .
our results show that hydiff can identify divergences for all examined applications.
furthermore it identifies a divergence faster and can reveal more differences than its individual components.
in summary this work makes the following contributions we present hydiff the first hybrid differential analysis approach that integrates greybox fuzzing and symbolic execution.
we extend greybox fuzzing with a divergence based feedback channel and novel search heuristics.
we extend shadow symbolic execution with incremental and pruning techniques as well as novel heuristics that drive the search towards finding structural and cost related divergences.
we demonstrate hydiff in multiple application scenarios incl.
regression test generation side channel analysis and the robustness analysis of neural networks in adversarial settings.
overview .
hydiff s workflow figure shows an overview of our approach.
hydiff takes several programs and a set of seed files as input top and produces 1274hydiff hybrid differential software analysis icse may seoul republic of korea test inputs classified by the observed divergence bottom .
more specifically the inputs forhydiff are as follows for differential fuzzing hydiff takes the considered program versions a test driver and a target specification.
for differential symbolic execution it takes the change annotated program a test driver and a configuration.
for both it takes seed input files as initial seed corpus.
the seed input files are used to perform an initial exploration of the program s .
the test drivers parse the generated inputs and pass them as parameters to the program s entry point s .
the target specification includes a list of changed program locations and is used to guide the fuzzer to these locations.
the change annotated program includes annotations for the differential symbolic execution.
these annotations are adapted from and handle changed expressions added removed code lines modified functions etc.
the configuration contains technical parameters such as the used constraint solver.
the output ofhydiff is a set of generated inputs classified by the observed divergence see bottom of figure .
we distinguish between differences in output odiff control flow ddiff crashing behavior crash and execution cost cdiff .
together these represent the differential metrics used to guide the search for inputs in our analysis.
furthermore we aim to compute inputs that decrease the distance to a divergence inducing target e.g.
a patch patch dist or increase branch coverage cov .
the middle layer in figure presents hydiff s high level workflow.
the left side shows hydiff s differential fuzzing component which makes use of the inter procedural control flow graph icfg constructed for the program.
marking divergence inducing program locations e.g.
changes in case of regression testing in the icfg allows to compute distance metrics for guiding the exploration in the fuzzer.
the fuzzer output queue is initialized with the seed input files.
our differential fuzzing uses a lightweight instrumentation guided genetic algorithm similar to afl .
the instrumentation allows us to compute the patch distance and other differential metrics for an input dynamically during execution.
the fuzzer stores information about the observed inputs such as minimum patch distance or output differences.
the inputs that are generated by the fuzzer are assessed by checking whether any differential metric gets improved by them.
the goal is to keep only these interesting inputs in the fuzzer queue which improve at least one of the metrics.
these inputs are further modified using byte level mutations to generate new inputs that are executed and assessed again by the fuzzer.
on the middle right of figure we illustrate hydiff s differential symbolic execution dse component.
the central data structure is a reduced symbolic execution tree called trie which encodes succinctly the results of the differential symbolic execution.
this trie is updated incrementally as the analysis progresses.
the nodes in the trie represent the so far covered decision points together with the observed concrete choices for these decisions.
this symbolic execution trieis initialized with the decision points and choices observed along the concrete executions paths of the provided seed inputs.
the trie gets extended when new generated inputs or inputs imported from the fuzzer are executed.
this step is called trie extension and also includes an assessment namely the gathering of multiple differential metrics about each execution e.g.
patch distance and cost difference but also information about the branch0intcalculate int x inty 1intdiv 2switch x 3case div y break 6case div y break ... 10case div y break 13default if x change expression y to y div change y y else div x 20intresult x div change added conditional statement 23if change false result result result 25return result listing example program with annotated changes.
coverage.
each node in the trie gets ranked for its ability to show new interesting behavior in terms of the differential analysis.
an exploration step then picks the most promising node and performs a deeper exploration on alternative paths starting with that node.
this step is performed with a purely bounded symbolic execution as opposed to a concolic execution.
we thus use the trie to guide the symbolic exploration towards interesting paths that have not been explored before.
the resulting satisfiable path conditions are solved and new inputs are generated.
each new input is assessed again for its actual ability to reveal a divergence since the nodes get picked based on heuristics.
.
illustrating example in order to demonstrate the challenges of differential analysis and to illustrate the pertinent concepts of our approach we introduce a simple example for regression testing.
listing shows a changeannotated program which represents two successive versions of thecalculate program.
the changes fix one error but introduce another a typical regression bug.
specifically in line the developer changed the right hand side expression from y to y which fixed a division by zero error for y but introduced another crash for y .
in line the developer added a conditional statement result result ifresult .
this changes the output for all positive results.
however it does not directly fix or introduce any crashes.
hydiff s differential fuzzer component takes the patch as target specification and computes distance values within the icfg.
during fuzzing these distance values will be used as patch distance to guide the differential fuzzer towards the modifications.
the fuzzer 1275icse may seoul republic of korea yannic noller corina s. p s reanu marcel b hme youcheng sun hoang lam nguyen and lars grunske 0intmain string args read input.
2intx readinput args 3inty readinput args execute old version.
5measurement.reset 6intres1 calculate old x y 7boolean dec1 measurement.getdecisions 8long cost1 measurement.getcost execute new version.
measurement.reset 11intres2 calculate new x y 12boolean dec2 measurement.getdecisions 13long cost2 measurement.getcost report differences.
result.setdecisiondiff dec1 dec2 result.setoutputdiff res1 res2 result.setcostdiff cost1 cost2 listing simplified fuzzing driver for the example component executes each generated input on both successive versions of the calculate program compiled separately.
hydiff s differential symbolic execution dse component takes both versions as change annotated integrated program as shown in listing .
the dse component uses these annotations to infer expressions that indicate a difference between the old and the new version cf.
the expression for divin line and the boolean expression in line in listing .
like the fuzzing component the dse component requires a small test driver to interface the change annotated program.
the symbolic test driver reads the input marks symbolic values and calls the change annotated program.
a simple symbolic test driver for the calculate program is shown in listing .
we can see that the symbolic test driver facilitates both a concolic and a symbolic mode.
this is required to enable the exploration and assessment phase figure .middle right .
during the exploration phase the inputs are marked as symbolic lines and the change annotated program is executed symbolically.
during the trie extension phase the given concrete input is marked symbolic lines and the change annotated program is executed concollicaly i.e.
follows the concrete input.
in this example hydiff s hybrid approach detects the regression bug more than nine times faster than hydiff s dse component alone.
the differential fuzzing component alone times out after ten minutes without detecting the regression.
hydiff uses the strengths of both techniques so that it can get into more paths by leveraging symbolic execution and is very fast in finding its first output difference by leveraging fuzzing.
to illustrate the challenges of each individual approach we present some results first for running both hydiff components independently and then together on this example.
the differential fuzzing component finds its first output difference after .
.
sec where the value denotes the confidence interval .
in total it finds .
.
output differences and .
.
decision differences.
the newcrash is not found within the time bound of min.
therefore fuzzing is very fast in finding an output difference less than seconds but the narrow constraint at the end is difficult0intmain string args 1intx y concolic or symbolic execution mode 3if args.length read input.
intvaluex readinput args intvaluey readinput args add symbolic values.
x addsymbolicvalue valuex sym x y addsymbolicvalue valuey sym y else introduce symbolic values.
x makesymbolicvalue sym x y makesymbolicvalue sym y execute change annotated version.
calculate x y listing simplified symbolic execution driver for the example to reach for fuzzing x y .
due to fuzzing s random mutations it is simply unlikely to hit this exact condition.
in contrast the differential symbolic execution component finds its first output difference after .
.
sec.
in total it finds .
.
output differences and .
.
decision differences.
so it reveals much more output differences than fuzzing within the given time bound.
in fact the dse component can traverse all paths in minutes.
in contrast to fuzzing it also finds the new crash after .
.
sec.
nonetheless symbolic execution needs relatively long to find its first output difference.
the switch statement with its large amount of branches is difficult for symbolic execution simply because it takes its time to explore all of them especially when the interesting parts are at the end and symbolic execution traverses it in a deterministic order.
note that the branches in the switch cannot be pruned because there is a change after the switch which makes every path via the switch branches a potential interesting path for exploration.
in order to find an output difference earlier symbolic execution would need a hint to direct the exploration.
for the hybrid analysis with hydiff the differential fuzzing and symbolic execution components are started with the same seed input.
both run their analysis and exchange inputs that are deemed interesting according to the divergence metrics after a prespecified time bound.
the experimental results are as follows first output difference after .
.
sec in total .
.
output differences and .
.
decision differences.
hydiff finds the new crash already after .
.
sec.
the following sections will explain each part and also the hybrid approach in more detail.
differential analysis .
differential fuzzing hydiff s differential fuzzing df component is a heuristic driven greybox fuzzer with a divergence based feedback channel.
by slightly modifiying existing inputs in the seed corpus new test inputs are generated.
generated test inputs that increase coverage or divergence as measured by our differential metrics are added to the seed 1276hydiff hybrid differential software analysis icse may seoul republic of korea corpus for further fuzzing.
more specifically the fuzzing process works as follows we use the provided program the target specification for regression testing we define the locations of the program changes initial seed inputs and the fuzzing driver as input.
by using some instrumentation we can measure various metrics during the program execution to drive the differential analysis.
as the first step the fuzzer imports the initial seed files and starts with mutating these inputs.
by executing resulting mutated inputs with the instrumented program the fuzzer can assess the inputs based on the collected metrics and hence decide whether to keep any of them and use them in further mutation steps.
these interesting inputs will be stored in the fuzzing queue.
this process continues in a loop until a defined time bound is reached or the user aborts the execution.
our core contribution in differential fuzzing is the input assessment i.e.
the selection of the mutated inputs that will be used for further mutations according to the divergence heuristics that we introduce in this work cf.
the gray areas in the upper part of figure .
specifically we use the following differential metrics the output difference the decision history difference the cost difference and the patch distance.
the output difference has a binary value and is determined by comparing the results depending on their type in the fuzzing driver.
output differences also cover observed crashes as long as the two program versions behave differently.
observing an output difference is a clear sign for a divergence revealing input.
we encode the output difference and store it to remember it in further comparisons to avoid duplicates.
the decision history encodes a sequence of boolean values to represent each branching decision.
the difference between two decision histories is used as binary value determined by comparing each boolean value pair.
if a different value pair is found then it means that different decisions were made during program execution.
such a difference does not necessarily mean a semantic divergence e.g.
it could also just represent some refactoring but it is an indication.
similar to the output difference we encode and store this difference.
we call this metric also just decision difference.
the execution cost represents the resource consumption during program execution this can be time which we approximate by counting the executed instructions or some other user specified cost.
observing a cost difference is an indicator for a semantic divergence.
the shortest distance to the predefined targets is calculated by leveraging the information from an icfg of the analyzed program which is generated in advance and stored within the instrumentation.
such a target distance in regression testing also called patch distance is calculated for the new version only because we are interested in reaching the changes in the new program version.
hitting the changed areas is necessary to find a difference in behavior but it does not provide any guarantee for a semantic difference.
the idea is to keep inputs during the mutation process which may not improve any other differential metric but come closer to the patched code regions.
in case of multiple targets we calculate distance values for all of them and keep an input as soon as its distance value for one of the targets improves.
in summary our input assessment keeps an input as soon as one of these metrics reveals a new behavior.
in order to do so the fuzzer stores which differences with which values were alreadyobserved.
additionally the fuzzer also keeps inputs that increase thebranch coverage in general to be able to make progress even if no difference is currently detected.
all metric values besides the output differences are measured via the program instrumentation.
.
differential symbolic execution hydiff s differential symbolic execution dse component runs in two modes concolically which can incorporate inputs from the fuzzer but also purely symbolically being able to make progress on its own even if no inputs from the fuzzer are present.
this has the benefit that dse can operate when for example fuzzing cannot generate interesting inputs because it is stuck at some point but can also benefit from concrete inputs to guide its own execution.
the workflow of the dse component is similar to the one in badger which however is not differential.
it consists of three main phases i trie extension ii exploration and iii input generation cf.
the middle right of figure .
these steps are performed in a loop until the search space was explored exhaustively or the user aborts the analysis.
in the beginning the trie gets extended initialized with the decision points and concrete choices which occur along the paths of the seed inputs.
therefore the inputs are being executed with dynamic symbolic execution which uses the notion of the fourway forking strategy to enable the focused search for divergences similar to .
as illustrated in listing hydiff s dse expects change annotations in the program or in the driver.
these changeannotations specify divergence inducing statements in the program e.g.
modifications for regression testing .
as a novel application we also use them to infer changes in the program input e.g.
for the side channel analysis see section .
.
every executed annotation introduces a so called differential expression which consists of four parts the old symbolic value the old concrete value the new symbolic value and the new concrete value.
for example in line in listing assume the concrete value foryis while the symbolic value of yis denoted by .
the statement div change y y introduces the following differential expression oldsym oldcon new sym new con .
the differential expressions are the key to handling two program executions at once furthermore our exploration strategy is driven by these differential expressions to find paths where the controlflow diverges across executions.
such paths are called diff paths.
as soon as the dse hits such a diff path i.e.
the execution exercises a control flow divergence it switches to the execution of thenew version only.
therefore the subsequent path explorations will only use the second parameter of the change annotations.
this also means that subsequent control flow divergences will not be detected because they are covered by the already identified divergence.
nevertheless deeper control flow divergences might be reachable by paths which do not trigger the prior control flow divergence.
during the extension of the trie its nodes get assessed and ranked according to their ability to reveal divergences.
the exploration step picks the most promising trie node for further exploration.
therefore we calculate for each node the following differential metrics the cost difference and the patch distance.
additionally we determine whether the node is on a diff path and whether the path 1277icse may seoul republic of korea yannic noller corina s. p s reanu marcel b hme youcheng sun hoang lam nguyen and lars grunske condition at this node contains a diff expression.
the information about the diff expression in a path condition is a good indication for a potential future divergence because divergences will be only possible if there is a diff expression present.
therefore we also use this information to rank the nodes.
mirroring the differential fuzzing we also compute the execution cost which is calculated by counting the number of executed bytecode statements or it is user provided.
however in dse we use the symbolic execution framework which interprets every bytecode instruction to count every statement when visited instead of instrumenting the bytecode.
in contrast to differential fuzzing the dse component cannot use the output difference as a search metric since the execution of diff paths is limited to the new version and hence the full information about the output is not always available.
however the intrinsic goal of dse is to push the exploration to diff paths i.e.
to identify decision differences.
for dse the patch distance is computed as the distance to the change statements in the program.
based on the icfg these distances and also the reachability information are pre calculated and stored in memory.
additionally these information are also used in dse to prune all paths that cannot reach any change statement.
after selecting the currently most promising node dse will perform a trie guided symbolic execution from the beginning of the program to the selected trie node.
trie guided means that it uses the choices stored in the trie to select the branch at a conditional statement which makes it very efficient because no constraint solving is invoked.
after reaching the selected node dse starts a bounded symbolic execution to gather new path conditions and generate new inputs cf.
step iii input generation in figure .
all the inputs generated by hydiff s dse component are concretely executed again.
the reason is that the models used by symbolic execution as well as the change annotations may not be precise enough to ensure that every diff path discovered during symbolic execution also triggers a diff path in the real program execution.
therefore we replay the inputs which were generated with symbolic execution with our fuzzing driver and reassess them for the induced difference in order to report the correct results.
in our experiments we use the following heuristics to rank the nodes for exploration prioritize nodes that contain a differential expression but are not yet on a diff path.
prioritize a node without differential expression before a node which is already on a diff path.
note here we only have nodes that can reach the changes .
prioritize new branch coverage.
if two nodes have not yet touched any change then prioritize the node with smaller distance.
prioritize nodes that already have higher cost differences between the two versions.
prioritize higher trie nodes.
the highest priority is to find decision differences i.e.
divergence of control flow.
therefore hydiff s dse component favors such potential nodes points and .
it is the most valuable divergence metric also because output difference cannot be encoded.
it can be simply detected by checking whether we are currently in a diff path.
the next priority is to support the fuzzer during exploration for which it is necessary to solve constraints corresponding to conditions that are difficult for the fuzzer point .
as further indications for a difference we use the information about the patch distance and the cost difference point and .
as last search parameter we favor higher nodes in the trie which leads to a broader explorationof the search space which also supports fuzzing.
these heuristics represent the default configuration setup for our differential analysis and that they can be easily modified.
why do we not just pick nodes on a diff path with highest priority?
when a node is on a diff path then the analysis has already identified an input to trigger the divergences that causes the diff path.
all unexplored branches at this node will be on a diff path as well all of them caused by the same divergence.
therefore our strategy focuses first on other nodes which are not yet on a diff path but show the potential to reach one and potentially trigger a different divergence.
.
hybrid analysis hydiff implements a hybrid approach which combines the above described differential fuzzing and the differential symbolic execution components.
the components communicate with each other to exchange interesting inputs discovered with either technique.
both components get started with the same seed input s .
after a pre defined time property each part checks the other output queue for interesting inputs.
therefore differential fuzzing has to execute the inputs from differential symbolic execution to see whether they improve any of the differential metrics.
differential symbolic execution has to replay the inputs from differential fuzzing to extend the trie check whether the path was already explored and whether a new code area was hit which could introduce differential expressions and update the ranking of the trie nodes.
the default setup for hydiff is to start both components at the same time however this can be changed via its configuration.
for example one component can be started later than the other and use the already generated inputs by the other component as additional seed inputs.
.
implementation details we implemented our approach for the differential analysis of java bytecode.
the fuzzing part is built on top of afl similar to kelinci where afl is used as the underlying fuzzing engine.
a java wrapper is used to relay the program execution triggered by afl to the actual java program.
we instrument the java bytecode with the asm bytecode manipulation framework to measure the differential metrics.
the icfg is constructed by using apache commons bcel .
the symbolic execution part is build on top ofsymbolic pathfinder spf a symbolic execution tool for java bytecode and its extension for shadow symbolic execution .
for the four way forking we had to modify each bytecode instruction interpretation to be able to handle differential expressions and fork the execution accordingly.
applications and evaluation in this section we describe three applications of our hydiff approach regression testing side channel analysis and differential analysis of neural networks.
the broad scope of these case studies illustrates the generality of our hybrid differential analysis.
hydiff is not limited to one type of behavioral difference such as output differences for regression testing.
it also allows to detect other types of differences such as in execution cost differences for side channel vulnerability discovery.
the elegant way of representing changes not only in the programs as in regression testing but also in the input facilitates the differential analysis even of 1278hydiff hybrid differential software analysis icse may seoul republic of korea table results for regression testing t 600sec 10min average over runs .
the bold values represent significant differences to the closest other subject verified with the wilcoxon ranked sum test .
.
subject differential fuzzing df differential symbolic execution dse hydiff changes t odiff tmin odif f ddif f t odiff tmin odif f ddif f t odiff tmin odif f ddif f tcas .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
tcas .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
tcas .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
tcas .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
tcas .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
tcas .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
tcas .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
tcas .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
tcas .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
tcas .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
math .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
math .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
math .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
time .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
cli1 .
.
.
.
.
.
.
.
.
.
.
.
cli2 .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
cli3 .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
cli4 .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
cli5 .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
non traditional software such as the robustness analysis of neural networks.
for all three applications we conducted experiments for differential fuzzing differential symbolic execution and their combination.
our implementation s source code as well as all evaluation artifacts incl.
the subjects and all drivers are published here .
.
experiment infrastructure for our experiments we used a virtual machine with ubuntu .
.
lts featuring 2x intel r xeon r cpu x5365 .00ghz with 8gb of memory openjdk .
.0 191 and gcc .
.
.
due to the randomness in fuzzing we repeated each experiment times and reported the averaged results together with the confidence intervals and the max min values.
although symbolic execution is a deterministic process we observed small variations between experiments mostly in the time until the first observed difference.
the variations can be caused by the constraint solver and other activities on the machine.
therefore we decided to average the results for it as well over repetitions.
the experiments for regression testing use a timeout of min sec the experiments for side channel analysis a timeout of min sec to match the experiments from diffuzz and the experiments with the dnn are executed for hour sec because of the long running program executions.
as seed input we used a randomly generated file but we ensured that this initial input does not crash the application which is a precondition for afl.
the highlighted values in the tables and represent significant differences to the closest other subject verified with the wilcoxon test with significance level .
.
regression testing in regression testing we have multiple versions of the same program and search for regression bugs i.e.
changes in the program that lead to semantic failures.
our motivational example in section .
already shows how the fuzzing and symbolic execution driver would look like.
the fuzzing driver executes both versions with the same input and measures the differences i.e.
decision differences output differences cost differences and target distances .
the symbolicexecution driver executes only a single program version which contains change annotations.
in the case of regression testing our approach aims to find all divergence revealing inputs.
whether an input represents a regression or only a progression i.e.
whether an observable change in the output is intended or a bug is out of scope for this work.
.
.
subjects.
for the evaluation we searched for java applications with multiple available versions.
we started with the traffic collision avoidance system tcas originally taken from the sir repository which was used before in other regression testing work related to spf .
it has loc and contains injected mutations as changes in our case changes per version.
we used the first ten versions of tcas for a preliminary assessment of our approach.
we further analyzed real world applications from the defects4j benchmark which contains a large set of java bugs but not necessarily regression bugs and hence requires some manual investigation.
we searched for regression bugs in the projects math kloc and time kloc and identified four subjects math math math andtime .
they contain between and changes per version where one change means a difference between the program versions that can be represented by one change annotation and hence also can span multiple lines.
additionally we investigated five versions from apache cli loc which was also used before in other regression testing work and contains between and changes per version.
.
.
results.
we collected four metrics t odiff denotes the average time sec until the first output difference incl.
a crash in the new version has been observed tmindenotes the minimum time over all runs for an output difference odi f f denotes the average number of found output differences and ddi f f denotes the average number of found decision differences.
as shown in table hydiff is able to classify the subjects correctly in the given timeout of minutes for all regression subjects except for the cli1 hydiff identifies at least one input that triggers an output difference odiff .
for cli1 there is no 1279icse may seoul republic of korea yannic noller corina s. p s reanu marcel b hme youcheng sun hoang lam nguyen and lars grunske table results for side channel analysis t 1800sec 30min average over runs .
the bold values represent significant differences to the closest other subject verified with the wilcoxon ranked sum test .
.
benchmark differential fuzzing df differential symbolic execution dse hydiff subject version max t max t max t blazer login safe .
.
.
.
.
.
blazer login unsafe .
.
.
.
.
.
.
.
.
.
.
.
themis jetty safe .
.
.
.
.
.
.
.
.
.
.
.
themis jetty unsafe .
.
.
.
.
.
.
.
.
.
.
.
stac ibasys unsafe .
.
.
.
.
.
.
.
.
.
.
.
rsa .
.
.
.
.
.
.
.
.
.
.
.
rsa .
.
.
.
.
.
.
.
.
.
.
.
rsa .
.
.
.
.
.
.
.
.
.
.
.
rsa 30s .
.
.
.
.
.
.
.
.
.
.
.
rsa 30s .
.
.
.
.
.
.
.
.
.
.
.
rsa 30s .
.
.
.
.
.
.
.
.
.
.
.
output difference expected .
df and dse in contrast cannot classify all subjects correctly.
in terms of time to find the first output difference df is not significantly faster than hydiff except for the subject cli5 although it does only mean seconds performance benefit in absolute values.
in fact in most cases hydiff is faster than df.
in comparison to dse hydiff is most of the times comparable but dse is also significantly faster for some subjects e.g.
tcas ortcas .
in such cases the differential symbolic execution part of hydiff is kept busy with importing inputs from the fuzzer which holds off its own analysis progress.
this is a problem which could be tackled with a more fine tuned configuration of hydiff.
note that for most of the cases the absolute difference between hydiff and dse is just a couple of seconds.
in terms of actually finding indicators for a regression namely output and decision differences hydiff shows its benefits.
for the most of the subjects hydiff finds a comparable or larger number of output differences odiff than the single parts.
for example for time andcli5 hydiff can identify way more output differences.
in addition for all cases except math andmath hydiff can identify significantly more decision differences ddiff .
in general the inputs imported by symbolic execution are useful to push the exploration but in this special case symbolic execution does not perform very good in terms of the number of generated paths.
summarized our results show that hydiff clearly outperforms the single techniques in terms of identifying regressions whereas at the same time hydiff only loses some seconds in contrast to dse to identify the first output difference.
.
side channel analysis side channels are dangerous because they allow an adversary to uncover secret program data from observations made over the nonfunctional behavior of a program with respect to a resource consumption such as execution time consumed memory or response size.
traditional techniques for detecting side channels involve the analysis of two program copies via self composition in an attempt to find two secret dependent paths that lead to a noticeable difference in resource consumption.
if no such difference is found this corresponds to the classic notion of non interference meaning no vulnerability was found.
if on the other hand a difference is found this corresponds to a vulnerability that needs to be fixed.
to perform side channel analysis with hydiff we need to fuzz three values one public value and two secret values the approachnaturally extends to tuples of values .
the fuzzing driver calls the program twice each with the same public value but with another secret value.
we measure the cost difference between both executions but also the decision difference and the output difference.
we use all metrics to drive the fuzzing process but at the end the most interesting is the cost difference which is a measure for the severity the side channel vulnerability.
for the symbolic execution part we leverage the change annotations to model the change in the secret part of the input secret chan e secret secret .
this assignment directly occurs in the driver and hence the program itself does not contain any change annotations.
therefore the patch distance is not relevant in this setting.
the differential expression gets introduced straight in the beginning so we do not use any control flow information to prune any node every node in the trie has already touched the change .
this also means that we can use a simpler symbolic exploration strategy for side channel analysis.
in our case we developed the following strategy prioritize new branch coverage.
prioritize higher cost difference.
prioritize higher nodes in the trie.
the primary goal of symbolic execution in the hybrid analysis framework is the support of the fuzzing component by solving complex branching conditions which are infeasible for fuzzing.
hence we prioritize the increase in branch coverage during symbolic exploration point .
the second goal is to find inputs that increase the cost difference since they signal side channel vulnerabilities point .
finally we prefer nodes higher in the trie closer to the root node because this likely leads to a broader exploration of the search space point .
note that it is easy to change the strategies so that different analysis types can be incorporated.
in case of the presented strategy for the side channel analysis we also experimented with different orders in the prioritization but we did not notice an improvement.
side channel analysis is concerned with finding differences with regard to non functional characteristics of the program which are affected by the input size.
in order to be able to handle multiple input sizes we allow to define a maximum input size e.g.
the maximum length of an input array.
the fuzzing driver will read up to the maximum number of values from the input file.
for the symbolic execution the driver will introduce a decision straight in the beginning before actually calling the application which determines the input size.
this decision will reflect a node straight after the root node in the trie.
we note that such an extension of the driver s functionality would be necessary also when incorporating multiple input sizes in the regression analysis.
1280hydiff hybrid differential software analysis icse may seoul republic of korea table results for dnn analysis t 3600sec 60min average over runs .
the bold values represent significant differences to the closest other subject verified with the wilcoxon ranked sum test .
.
differential fuzzing df differential symbolic execution dse hydiff symexe first 10min t odiff tmin odif f ddif f t odiff tmin odif f ddif f t odiff tmin odif f ddif f .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
yet our regression subjects only considered simple input types for which the input size was not relevant.
.
.
subjects.
for the evaluation we selected subjects from previously analyzed in which represent state of the art in side channel analysis blazer login loc and themis jetty loc and a sophisticated authentication procedure stac ibasys loc from which handles complex image manipulations.
they come in unsafe and safe variants where the safe variant usually means that it does not leak any information.
the subject themis jetty safe is known to still leak information but the difference in cost is small .
additionally we analyzed an implementation of modular exponentiation rsa modpow loc from which has a timing side channel that is due to an optimized step in the exponentiation procedure.
in it was shown how a similar vulnerability was exploited to break rsa encryption decryption.
in our experiments we used three different values for modulo.
.
.
results.
we collected three metrics denotes the average cost difference until timeout max denotes the maximum over all runs and t denotes the average time sec until the first greater than zero has been observed.
as shown in table hydiff can detect all side channels i.e.
it finds cost differences greater than zero for all unsafe examples.
dse alone needs quite a long time to actually find its first but then it performs well in maximizing it.
df quickly discovers an input with but needs longer to actually find a large value for .hydiff represents the perfect combination of both single techniques the speed of fuzzing and the reasoning strength of symbolic execution.
hydiff finds very large values for comparable to dse and finds its first in a comparable time as df.
both are important factors for the identification and the assessment of side channel vulnerabilities.
the rsa subjects do not clearly show the same results df performs quite similar as dse and hence hydiff does not show any clear benefit compared to just df.
in order to understand this subject better we also reported the values after sec of the experiments.
these values show that dse is able to generate a high value right in the beginning whereas fuzzing needs more time.
for hydiff this means the following the impact of symbolic execution on hydiff for this subject would be only visible in the first seconds of the experiment.
but after min all techniques show similar results.
.
analysis of deep neural networks we also propose here a non standard application of differential analysis to adversarial generation in neural networks with piecewise linear activation functions.
the analysis of neural networks isnotoriously hard due to the huge number of paths allowing us to evaluate hydiff in domains of high complexity.
given a dnn model we first re write it into the java program form.
while the java translation preserves the prediction ability of the original dnn the advantage is that program analysis techniques and tools can now be applied for analyzing the dnn model.
specifically we used hydiff to find adversarial inputs for an image classification network.
these inputs should differ only slightly but should lead to different classifications.
this problem seems to naturally fit into the differential analysis context.
our idea is to change up to x of the pixels in the image and check if there can be any difference in the output of the network i.e.
the final classification.
for the fuzzing driver we therefore fuzz values for the complete image and we fuzz values and positions of the pixels to change.
hence the fuzzing driver will have two images that differ in only up to x of the pixels.
then it executes the dnn model with both inputs and measures the metrics similar to regression testing.
of course we are particularly interested in the output difference.
for the symbolic execution we introduce changes similar as for the side channel analysis directly in the driver so that we execute the dnn model only once but with a change annotated input.
the dnn analysis specifically searches for differences in the classification i.e.
output differences similar to regression and not cost differences like the side channel analysis.
therefore we use the same heuristics as for regression testing .
.
subjects.
particularly in this experiment we trained a dnn model for handwritten digit recognition using the mnist dataset .
the data set comes with a training set of examples and a test set of examples.
the trained model has an accuracy of .
on the test set.
it consists of layers including convolutional max pooling flatten dense layers with rectified linear unit relu activations contains neurons and uses the max function in the final classification layer.
.
.
results.
for dnn analysis we collected the same four metrics as for regression analysis cf.
section .
.
.
as shown in table hydiff can be used for the analysis of dnns as it finds output differences in the classification of an image when changing only up to of its pixels.
for the dnn subjects we can make the following observations differential fuzzing and differential symbolic execution also find the output differences but perform very differently.
differential fuzzing becomes faster in finding an output difference with more pixels allowed to change which seems reasonable as it is easier to find differences in the classification of two images when they differ largely.
but even for a change differential fuzzing still 1281icse may seoul republic of korea yannic noller corina s. p s reanu marcel b hme youcheng sun hoang lam nguyen and lars grunske needs very long to find an output difference which is caused by the very long runtime of each program execution.
differential fuzzing executes the same program execution several times to assess the input which makes this step even more expensive.
in contrast differential symbolic execution becomes slower with more pixels to change.
first of all it does not need to execute the whole program to generate an input because it might be enough to just look at the first two branches to extract a path condition which leads to another classification.
secondly with more pixels to change symbolic execution will introduce more symbolic variables which will eventually make the path constraints quite complex and hence it needs more time for them to be solved.
our results indicate that due to the complexity of the dnn dse can generate only one interesting input within the given time bound of 60min.
with hydiff in its default setup i.e.
differential fuzzing and differential symbolic execution start at the same time there does not happen any synchronization between both components because the expensive program execution.
hydiff s differential fuzzing does not use any inputs from differential symbolic execution and vice versa because they are busy with their own analysis.
for this reason hydiff does simply produce the combined result of both components running separately.
therefore we decided to alter the setup for the dnn analysis we start differential symbolic execution first and with a 10min delay we start differential fuzzing so that fuzzing can use the already generated inputs from symbolic execution as additional seed inputs.
the result for this setup cf.
table show that hydiff combines both techniques very well hydiff shows comparable times to the first output difference as differential symbolic execution which is significantly faster than fuzzing but shows significantly more output differences than fuzzing.
another observation is that the confidence intervals for hydiff are much smaller than for differential fuzzing which shows that the results are much more robust.
so hydiff does not only combine the results of both components but the components can benefit from each others inputs to further improve the outcome.
.
result summary hydiff does not only combine the outcomes of fuzzing and symbolic execution.
it does perform a continuous synchronization across output queues which helps each part to find even more divergences.
for example in math time cli3 and cli5 cf.
table hydiff finds significantly more output differences than the single components.
in particular for cli3 and cli5 dse itself does not find any of them but the inputs for decision differences identified by symbolic execution push hydiff s differential fuzzer in the right direction.
for the side channel analysis hydiff shows a good trade off between fuzzing and symbolic execution and in particular for themis jetty unsafe the hybrid technique also outperforms the single components in terms of the generated values cf.
table .
in the dnn analysis hydiff finds significantly more output differences and for the majority of the subjects hydiff is also faster in finding the first output difference cf.
table .
.
limitations in addition to the benefits it is important to discuss potential limitations of our approach and evaluation.
firstly there is the requiredmanual effort to prepare a program for differential analysis by hydiff.
as mentioned in our motivating example sec.
.
our approach needs drivers to parse the input and call the programunder test.
additionally our approach expects information about the syntactic changes in the program e.g.
for regression testing .
for fuzzing the change locations need to be specified and for symbolic execution the program needs to be annotated with the changeannotations.
in order to ensure reproducibility of our evaluation we make the test drivers and annotations publicly available .
we believe that these steps can be automated to a large extend.
secondly the purpose of our evaluation was to demonstrate the versatility of hydiff in a few case studies from very different domains.
we cannot claim the results for each case study will generalize for other kinds of programs or classifiers written in other languages or from other domains.
in order to mitigate the impact of randomness on the results we repeated each experiment times and report confidence intervals.
lastly hydiff is inherently parallel while its components are not.
the differential fuzzing df and symbolic execution dse components are run in parallel to boost their advantages and mitigate their weaknesses.
these components communicate via a shared queue.
in our evaluation we compare one instance of hydiff with one instance for each of its constituent techniques.
technically this gives more computational resources to hydiff.
while dse does not support a parallel mode with a shared queue to validate our results we conducted experiments running two instances of df with a shared queue parallel df .
for the regression analysis hydiff still outperformed parallel df in terms of time to discovering an output difference t odiff for about the same number of subjects as df.
parallel df was not able to identify output differences for subjects for which df also did not find any output difference i.e.
the parallel variant was not able to solve the actual limitations of df.
however parallel df produced more test cases that reveal a decision or output difference ddi f f and odi f f which is expected as parallel df also generates about twice as many test cases.
we note that multiple test cases may reveal the same output difference.
to classify output differences we would need to conduct a post processing to further classify the outputs e.g.
in expected and unexpected behavior similar to .
for the side channel subjects parallel df showed a slightly better performance compared to df t but without outperforming hydiff.
for the dnn subjects parallel df also improved the number of identified test inputs for decision and output differences but without any improvement on the time to discovering an output difference t odiff .
we further conducted experiments with giving dse twice the time budget of hydiff but for which dse did not show any significant improvement.
related work existing differential testing techniques include symbolic executionbased and fuzzing based techniques.
with regard to symbolic execution based techniques hydiff leverages four way forking in an incremental manner and introduces novel heuristics to maximize divergence.
with regard to fuzzingbased techniques hydiff contributes a novel divergence based feedback channel to greybox fuzzing and leverages several fitness 1282hydiff hybrid differential software analysis icse may seoul republic of korea functions to evaluate and maximize the divergence across multiple program executions.
differential symbolic execution.
most related to hydiff is shadow symbolic execution sse which we already discussed throughout the paper.
sse uses four way forking along the path s of a concrete input that reaches a change.
hydiff is more general as it also follows branches which are not already affected by a change but still can reach a change annotation.
this allows hydiff to detect more divergences improving upon effectiveness .
novel search heuristics and the integration with fuzzing allow hydiff to detect divergences faster improving upon efficiency .
other related work includes directed incremental symbolic execution dise which leverages program slicing and symbolic execution along these slices to cover changed statements in the source code.
such techniques could not be readily integrated with a fuzzer as do not consider any analysis along concrete inputs.
xu et al.
present several techniques to maintain coverage adequacy of a test suite after the program was changed.
however unlike hydiff this stream of works only considers a single version at a time.
furthermore they are only applicable to regression generation without any consideration about costs.
differential fuzzing.
bert is a blackbox regression testing technique which generates random input values to expose behavioral differences.
in contrast the greybox fuzzing component of hydiff is guided by divergence feedback.
nezha implements both a blackbox and a greybox fuzzing approach showing better performance with the greybox component.
diffuzz exposes side channel vulnerabilities in programs using a resource based feedback channel for greybox fuzzing as well as resource related search heuristics in contrast to diffuzz our fuzzing component incorporates more sophisticated differential metrics as diffuzz only looks at cost differences .
dlfuzz uses greybox fuzzing for differential testing of dnns.
in contrast to all these greybox fuzzing approaches hydiff leverages a novel divergence based feedback channel and a combination of differential metrics that includes output difference decision difference and patch distance.
moreover hydiff works with increased effectiveness due to the integration with a differential symbolic execution engine.
hybrid techniques.
the integration of efficient fuzzing and effective symbolic execution based techniques is an active area of research .
there exist several works that attempt to integrate both approaches .
like hydiff most of these hybrid approaches demonstrate significant benefits of combining the random collateral path exploration of fuzzing with the systematic path enumeration of symbolic execution.
to the best of our knowledge there does not exist an effective integration of both approaches in the context of differential analysis as it is described here.
badger is a hybrid analysis framework that combines fuzzing and symbolic execution for the worst case analysis of java byte code.
similar tohydiff badger runs greybox fuzzing and symbolic execution together which synchronize via their queues.
however badger performs an analysis that does not reason about multiple program paths simultaneously and therefore does not include the advanced features that we presented here.
the fuzzing part of badger only needs to handle a cost metric and the branch coverage measurement in particular it does not need to further guide the fuzzingprocess to areas that show differences between versions.
in contrast hydiff s fuzzing part needs to be guided to e.g.
changed code blocks and needs to be able to handle metrics like output and decision difference.
the symbolic execution part of badger simply performs a concolic execution where nodes get selected for exploration based on their cost value.
in contrast hydiff s symbolic execution needs to handle multiple program behaviors and hence uses a modified form of shadow symbolic execution which was extended as we described in this paper.
adversarial testing of dnns.
recently several quantitative coverage metrics have been proposed to guide the testing of dnns.
different from the adversarial testing works for dnns so far in this paper we adopt a hybrid analysis approach.
moreover when applying hydiff to dnns we benefit from reusing existing software testing tools such as afl and spf.
differential verification.
demonstrating the functional equivalence of two programs for allinputs is known as differential or regression verification.
for example lahiri et al.
present the toolsymdiff which searches for output differences by leveraging the modular verifier boogie to generate the verification condition and the smt solver z3 to solve it.
hydiff s analysis is not limited to detect output differences but also incorporates metrics to detect e.g.
cost differences.
hawblitzel et al.
propose an automated full system verification including proving non interference of the information flow.
compared to such differential verification approaches while it would be interesting to explore the provision of statistical guarantees hydiff cannot provide formal guarantees about the absence of a behavioral differences.
however the lack of formal guarantees is a tradeoff for the scalability necessary for the analysis of real world applications.
conclusion we proposed a hybrid differential program analysis approach hydiff combining fuzzing and symbolic execution which are specially tailored to differential analysis and which support each other to amplify the exploration.
the evaluation presents three applications regression testing side channel analysis and adversarial generation for deep neural networks.
we showed that even when the single techniques failed to find any divergences hydiff succeeded.
additionally our hybrid analysis outperforms the single techniques in terms of the time to the first divergence and the total number of identified divergences.
in the future we plan to extend our case studies and experiment with additional heuristics to continue the investigation of the differential analysis for deep neural networks and to explore more types of change annotations to strengthen the applicability of our differential symbolic execution.