mvd memory related vulnerability detection based on flow sensitive graph neural networks sicong cao yangzhou university yangzhou china mx120190439 yzu.edu.cnxiaobing sun yangzhou university yangzhou china xbsun yzu.edu.cnlili bo yangzhou university yangzhou china lilibo yzu.edu.cn rongxin wu xiamen university xiamen china wurongxin xmu.edu.cnbin li yangzhou university yangzhou china lb yzu.edu.cnchuanqi tao nanjing university of aeronautics and astronautics nanjing china taochuanqi nuaa.edu.cn abstract memory related vulnerabilities constitute severe threats to the securityofmodernsoftware.despitethesuccessofdeeplearning based approaches to generic vulnerability detection they are still limited bytheunderutilizationofflowinformationwhenappliedfordetecting memory related vulnerabilities leading to high false positives.
inthispaper wepropose mvd astatement level memory related vulnerability detection approach based on flow sensitive graph neural networks fs gnn .
fs gnn is employed to jointly embed both unstructured information i.e.
source code and structuredinformation i.e.
control anddata flow tocaptureimplicit memory relatedvulnerabilitypatterns.weevaluate mvdonthe datasetwhichcontains4 353real worldmemory relatedvulnerabilities and compare our approach with three state of the art deep learning basedapproachesaswellasfivepopularstaticanalysisbasedmemorydetectors.theexperimentresultsshowthat mvd achievesbetterdetectionaccuracy outperformingbothstate of theart dl based and static analysis based approaches.
furthermore mvdmakes a great trade off between accuracy and efficiency.
ccs concepts security and privacy software security engineering.
keywords memory relatedvulnerability vulnerabilitydetection graphneural networks flow analysis xiaobing sun and lili bo are the corresponding authors.
permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation on the first page.
copyrights for components of this work owned by others than acmmustbehonored.abstractingwithcreditispermitted.tocopyotherwise orrepublish topostonserversortoredistributetolists requirespriorspecificpermissionand ora fee.
request permissions from permissions acm.org.
icse may pittsburgh pa usa association for computing machinery.
acm isbn ... .
reference format sicong cao xiaobing sun lili bo rongxin wu bin li and chuanqi tao.
.
mvd memory relatedvulnerabilitydetectionbasedonflowsensitive graph neural networks.
in 44th international conference on software engineering icse may pittsburgh pa usa.
acm new york ny usa pages.
introduction asoneofthemostrepresentativevulnerabilities memory related vulnerabilities can result in performance degradation and program crash severelythreateningthesecurityofmodernsoftware .
according to the data released by cve common vulnerabilities andexposures nearlyathirdofthevulnerabilities .
in linux kernel are related to improper memory operations .
many static analysis approaches havebeenproposedtodetectmemory relatedvulnerabilities and shown their effectiveness.
they use some pre defined vulnerabilityrulesorpatternstosearchforimpropermemoryoperations .however well definedvulnerabilityrulesorpatterns are highly dependent on expert knowledge and thus it is difficult to coverallthecases.what sworse thesophisticatedprogramming logic in real world software projects gets in the way of the manual identificationoftherules andthusgreatlycompromisestheperformanceofthetraditionalstaticanalysis basedapproaches .
recently benefiting from the powerful performance of deep learning dl a number of approaches have been proposed to leverage dl models to capture program semantics to identify potential software vulnerabilities.
compared withtraditionalstaticanalysis basedapproaches theycanautomatically extract implicit vulnerability patterns from prior vulnerable codeinsteadofrequiringexpert involvement.howeve r theexisting dl based approaches suffer from two limitations when applied to memory related vulnerability detection as described below.
flow informationunderutilization due to the underutilization of flow information existing dl based approaches failed to detect complicated memory related vulnerabilities in real world projects forthefollowingtwoaspects lackofinterprocedural analysis and partial flow information loss in model training.
fortheformerone mostofdl basedapproaches ieee acm 44th international conference on software engineering icse authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
icse may pittsburgh pa usa sicong cao xiaobing sun lili bo rongxin wu bin li and chuanqi tao takethefunction level vulnerablecodeasinputtoconductintraproceduralanalysisforfeatureextraction ignoringcallrelationsbetween functions.
however in real world programs operations like callingauser definedfunctionwhichrealizesmemoryallocation orfreearewidespread.missinginterproceduralanalysismaycause incompletesemanticmodeling resultinginlowerrecallandprecision.for thelatter one limitedby thecapability ofpopulardl models e.g.
bilstm ggnn and gcn in handling multiple relations partial flow information is lost during the process of model training.
for example devign uses ggnn as the basic model to propagate and aggregate information across multi relational graphs.
since ggnn treats the relational graph as multiple directed graphs without attributes i.e.
feature information is only passed between nodes connected by edgesofthesametype itseffectivenessisoftencompromisedby the tremendous increase in the number of data flow edges with different attributes.
thus devignhas to substitute them with three othertoken level relations i.e.
lastread lastwrite and computedfrom to make it more adaptive for the graph embedding sacrificing partial precise data flow information well preserved in graphs.asimpleinstanceisthatreceivinganormalpointervariable non vulnerable isobviouslynotthesameasreceivingapointer variable which points to the memory just released vulnerable .
coarse granularity the detection granularity of the existing dl based approaches is mostly at the function level orslice level .however developersstillneedto spend a deal of time in manually narrowing down the range of suspiciousstatements oroperations .achievingfine graineddetectionresultsisnon trivial.duetothehugedifferencesbetween variousvulnerabilities existingdl basedapproachesforgeneric vulnerabilitydetectionhavetosacrificeuniquesemanticfeatures specifictocertainvulnerabilitiestoensurethatthetrainedmodel can cover the general characteristics of the majority of vulnerabilities.
in comparison with other vulnerabilities memory related vulnerabilitiesareusuallyfixedwithoneorseverallinesofcode whichmakesfine graineddetectionpossible.forexample memory leakcanbelocatedtothestatementwhichallocatesmemory while use after free can be located to the statement which frees memory.
inthispaper weproposeanovelapproach mvd basedonflowsensitive graph neural networks to alleviate the above limitations.
fully utilizing flow information to capture more comprehensiveandpreciseprogramsemantics mvdcombinesprogram dependence graph pdg with call graph cg to capture interprocedural control and data flow information.
first we conduct interprocedural analysis by extending pdg with additionalsemantic information including call relations and return values between functions using cg.in ourapproach codesnippets and relations i.e.
edges are embedded in compact low dimensional representationstopreserveboththeunstructured i.e.
sourcecode andstructured i.e.
control anddata flow information.furthermore inordertomakethedetectionmodellearneffectivememory relatedvulnerabilitypatternsfromcomprehensiveandpreciseflow information mvdconstructs a novel flow sensitive graph neural networks fs gnn to jointly embed statements and flow information to capture program semantics from vulnerable code.
fine granularity we formalize the detection of vulnerable statements as a node classification problem i.e.
identifying whichstatement s in the program is vulnerable.
specifically mvdreceivesthegraphrepresentationofaprogram inwhichgraphnodesrepresentstatementsandedgesindicatetheirrelations andoutputs node labels i.e.
vulnerable or not .
sincethereiscurrentlynodatasetthatcanbedirectlyusedfor traininga statement level memory relatedvulnerabilitydetection model we construct a dataset which contains real world memory relatedvulnerabilities.thedatasetaswellastheempirical data are available online1.
in summary this paper makes the following contributions weproposeanovelflow sensitivegraphneuralnetworks fs gnn to support effective detection of memory related vulnerabilities.
we formalize vulnerability detection as a fine grained node classification problem to identify suspicious vulnerable state ments.
we evaluate mvdon our constructed dataset and the results showthat mvdcaneffectivelydetectmemory relatedvulnerabilitiesoverstate of the artvulnerabilitydetectionapproaches including three dl based and five static analysis based approaches .
basics and motivation .
definitions program dependence graph.
given a program all the program statementsanddependenciesamongstatementsconstitutea program dependence graph pdg .pdgincludes two types of edges data dependency edges which reflect the influence of one variable on another and control dependency edges which reflect the influence of predicates on the values of variables.
callgraph.
givenaprogram its callgraph cg indicates a series of function calls from call sites caller to the callee.
graph neural networks.
due to the outstanding ability in processinggraphdatastructures graphneuralnetworks gnns have been used in a variety of data driven software engineering se tasks e.g.
coderepresentation clonedetection and bug localization and have achieved great breakthroughs.
the goal of gnns is to train a parametric function via message passing between the nodes of graphs for downstream tasks i.e.
graph classification node classification and link prediction.
.
motivating examples figure1showsatypical use after free vulnerabilitycve inlinuxkernel.thevulnerablefunction smb2 read hasbeen simplified for a clear illustration.
we can observe that the memory space pointed by the pointer reqis released in advance by the memoryreleasestatement cifs small buf release req atline while it is still used at lines .
this operation may allowattackerstowritemaliciousdata.tofixthisvulnerability the pointer reqshouldbereleasedafteritisusedforthelasttime e.g.
line .despitethesupportofprecisedatadependenceanalysis this vulnerability cannot be easily detected by some static analysis basedapproachesbecausetheymaynotknow mempool free at line is a user defined memory deallocation function.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
mvd memory related vulnerability detection based on flow sensitive graph neural networks icse may pittsburgh pa usa 1int smb2 read const unsigned int xid struct cifs io parms io parms unsigned int nbytes char buf int buf type struct smb2 read plain req req null ... cifs small buf release req if rc if rc !
enodata trace smb3 read err xid req persistentfileid io parms tcon tid ses suid io parms offset io parms length rc else trace smb3 read done xid req persistentfileid io parms tcon tid ses suid io parms offset return rc enodata ?
rc else trace smb3 read done xid req persistentfileid io parms tcon tid ses suid io parms offset io parms length cifs small buf release req ... return rc 18void cifs small buf release void buf to free if buf to free null cifs dbg fyi null buffer passed to cifs small buf release n return mempool free buf to free cifs sm req poolp atomic dec smbufalloccount return figure1 a use after free vulnerability cve in linux kernel from this example we can draw the following observations observation .
comprehensive and precise interproceduralflowanalysisisnecessary.
asshowninfigure1 wecanfind that the program semantics of vulnerable code and non vulnerable code are different.in the vulnerable code vulnerable statementat line 5releases reqwhen reqisstillbeingusedafterthat while inthenon vulnerablecode reqisreleasedbythepatchedstatement atline 14only when reqis no longer used.
however due tothe lackofinterproceduralanalysis criticalprogramsemantics i.e.
memory deallocation via mempool free which is involved in the function call to cifs small buf release req at line are ignored by a number of deep learning based approaches resultinginincompleteprogramsemanticmodeling towards vulnerable statement at line .
inourapproach weextendbasicprogramdependencegraph pdg with additional semantic information like call relations and returnvaluesobtainedfromcallgraph cg tocapturecomprehensiveandpreciseinterproceduralprogramsemantics.with such rich information features of memory related vulnerabilities can be extracted for more effective detection.
observation .
sensitive contextual information within flows helps to refine detection granularity.
as shown in the motivating example the premise of identifying the statement at line 5as vulnerable is that we should know in advance that req releasedbythisstatementwillbeusedlater.thus todistinguish vulnerable statements from others the neural networks used as detection models should be able to capture sensitive contextualinformation within flows of vulnerable statements for inference.
however duetothelimitationsofpopulardlmodels in handling multiple relations rich contextual information arelost during the process of model training.
for example funded onlyconsidersone directionaltransmissionofmultiplerelations such as control and data flows and adopts ggnn t o learn vulnerability patterns for detection.
while it is successfulinfunction level vulnerability detection it loses some important contextual information from output flows e.g.
the data flow in formation within edge will not be used for feature updateof vulnerable statement at line .
thus it is hard for funded to identifythestatement line 5asvulnerablebecausecriticaloutput flowinformation i.e.
using reqafterfreeingit isnotpreserved incifs small buf release req .
based on the above observations we propose a novel model fs gnn foreffectivelydetectingmemory relatedvulnerabilities.
fs gnnisanovelflow sensitivegraphneuralnetworktojointly embedbothstatementsandflowinformationforbetterinformation propagation between statements.
with fs gnn rich contextual semanticsofneighborsareaggregatedthroughmultiplerelations to update the embedding of the central node.
our approach mvd figure shows the overview of mvd.
it consists of two phases training phase and detection phase.
thetrainingphaseincludesthreesteps.instep1 mvdconstructs theprogramdependencegraph pdg basedonthecontrol and data flowoftheprogram.tocapturecomprehensiveandprecise program semantics mvdextends the pdg with additional semanticinformationlikecallrelationsandreturnvaluesobtainedfrom call graph cg to conduct interprocedural analysis.furthermore toreduceirrelevantsemanticnoise mvdconductprogram slicing from the program points of interest.
in step mvd uses doc2vec to transform the statements of each slice into low dimensional vector representations.
in step mvduses flowsensitivegraphneuralnetworks fs gnn tojointlyembednodesandrelationstolearnimplicitvulnerabilitypatternsandre balance nodelabels distribution.finally a well trainedmodel isproduced for memory related vulnerability detection at the statement level.
forthedetectionphase withtheinterproceduralanalysis the control and data dependence of a target program is first extracted forprogramslicingtocapturepreciseprogramsemanticsrelated tomemoryusage.then foreachslice bothitsunstructured i.e.
statementembeddingbydoc2vec andstructured i.e.
control and data flow information are used as graph input to feed into the well trained detection model for vulnerability detection.
.
feature extraction first weusethestaticanalysistool joern toparsesourcecode and construct the program dependence graph pdg .
then we extend the pdg with additional semantic information like call relations and return values obtained from call graph cg to conduct interproceduralanalysis whichpreservescomprehensivecontroland data flow information.
however since a function usually contains dozens or even hundreds of code lines while the vulnerabilityexistsonlyinafewlinesofcode simplytakingthewholeprogram to train a detection model will reduce the performance of identifyingkeyfeatures.thus mvdadoptsprogramslicing toperform authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
icse may pittsburgh pa usa sicong cao xiaobing sun lili bo rongxin wu bin li and chuanqi tao detection phase vulnerable node non vulnerable nodedata flow edge control flow edge call edgereturn edgevulnerable nodenon vulnerable nodedata flow edge control flow edge call edgereturn edgevulnerable nodenon vulnerable nodedata flow edge control flow edge call edgereturn edgetraining phase source codesource codewell trained modelstep .
graph learning step .
feature extraction slicesstep .
node embedding nodes flowsstep .
graph learning step .
feature extraction slicesstep .
node embedding nodes flows step .feature extractionstep .
node embedding source codesource codedetection modelprogram slicesgraph inputsource codewell trained modelstep .
graph learning step .
feature extraction slicesstep .
node embedding nodes flows step .feature extractionstep .
node embedding source codedetection modelprogram slicesgraph inputdetection phase vulnerable nodenon vulnerable nodedata flow edge control flow edge call edgereturn edgetraining phase source code well trained model step .
graph learning step .
feature extraction slicesstep .
node embedding nodes flows step .feature extractionstep .
node embedding source codedetection modelprogram slicesgraph input figure overview of mvd 1void memory leak char str this is a string char str1 memory leak func strlen str str1 strcpy str1 str 8void memory leak func int len char stringptr char p malloc sizeof char len stringptr p a exemplary code sample slices str stringptr plen str1 1151pdg str stringptr pstr1len str1 str data flow edge point of interestpoint of interest normal nodenormal node control flow edgecall edge return edgedata flow edge point of interest normal node control flow edgecall edge return edgedata flow edge point of interestnormal node control flow edgecall edge return edgeslices str stringptr plen str1 1151pdg str stringptr pstr1len str1 str data flow edge point of interestnormal node control flow edgecall edge return edge b program slicing figure details of feature extraction backwardandforwardslicingfromtheprogrampointofinterest to avoid noise induced by irrelevant statements.
to ensure that the generated slices contain memory related vulnerabilities we mainly focus on two types of program points of interest systemapicalls and2 pointervariable.asmentionedin previousworks themisuseof systemapicalls isone of the major causes of vulnerabilities including memory related vulnerabilities.
for example syscall buf is a typical system api callrelated tobuffer operations in linux kernel.
itoften occurs in out of boundsread write andothersimilar buffer relatedvulnerabilities.
in total we conclude system api calls from several static memory detectors as slicing criteria for extracting vulnerablecodesnippets.for pointervariable ithasbeenwidely adopted by traditional static analysis based approaches .it should be noted that starting from the program point of interest weperformbackwardslicingaccordingtobothcontrol anddatadependence but forward slicing based on only data dependence because improper memory operations e.g.
allocating memory but not freeing it have been involved in the forward data dependence andusuallyforwardcontrol dependencewillinduceagreatdealof irrelevant statements.
figure provides an example to show the process of feature extraction.asshowninfigure3a itisa memoryleak vulnerability.
atline it allocates memory through malloc in function memory leak func withoutfreeingeventotheendofthe program.inourapproach thecontrol anddata flowinformation ofthevulnerableprogramisfirstextractedtoconstructthepdg of the program which is shown in figure 3b.
then based on interprocedural analysis the call relation i.e.
edge and return value i.e.
edge11 informationisadded.toreduceirrelevant nodes we adopt the sensitive function call at line i.e.
node highlighted in red as the program point to perform backward and forward slicing.
node is control dependent on node with an edge and data dependent on node with an edge .
afterslicing node6isremovedbecauseitisnotdata dependentonnode .
.
node embedding afterfeatureextraction wetransformallstatementnodesinthe graph into low dimensional vectors as input to the graph neural network models.
we use doc2vec to represent code statements as vectors sinceitisawidely usedtechnique toencodethedocuments i.e.
codestatements insteadofanindividualword e.g.
avariable intoafixed lengthvector.then thevectorsofthestatementand context wordsare inputto thehidden layer toobtain theintermediatevectorastheinputof softmaxlayer.finally intheinference stage thevectorofagivenstatementisachievedthroughstochasticgradient descent sgd .
in this way the doc2vec can provide a more precise embedding of the code statement that will preserve the semantic information.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
mvd memory related vulnerability detection based on flow sensitive graph neural networks icse may pittsburgh pa usa .
graph learning to train a model which can learn implicit vulnerability patterns fromsourcecodeandidentifysuspiciousvulnerablestatements we construct a novel graph learningframework flow sensitive graph neural network fs gnn for graph learning.
the details of our approachareshowninfigure4.thekeyinsightoffs gnnisto jointly embed both statement embedding and flows information tocapturesensitivecontextualinformationforsemanticlearning.
fs gnn is composed of three parts graph embedding resampling and classification.
graphembedding.
differentfrommostoftheexistinggraph embedding approaches that embed only nodes in the graph weleverage the entity relation composition operations used in knowledge graph embedding approaches to jointly embed statementnodesandmultipleflowedgestoincorporateedgeembeddingintotheupdateofnodeinformation.tobespecific during theprocessofgraphembeddinginfs gnn thenodeembedding hvof statement node vcan be updated by hv f parenlefttpa parenleftexa parenleftbta summationdisplay.
u r n v w r xu zr parenrighttpa parenrightexa parenrightbta where hvdenotes the updated representation of node v.n v isasetofimmediateneighborsof vforitsoutgoingedges.
is acompositionoperator including subtraction multiplication and circular correlation.
xuandzrdenotesinitialfeaturesfornode u encoded by doc2vec and edge r respectively.
similar to traditional relational graph neural networks rgcn initial edge representationforedge rcanbeencodedbybasisdecomposition aszr b summationtext.
b 1 brvb where vb bisasetoflearnablebasisvectorsand br risalsothelearnablescalarweightspecifictoedge typeandbasis.
w r representsaedgetypespecificparameter.to makefs gnncontext awareandcaptureimportantinformation fromoutgoingedges wedoubleedgesbyaddinginverseedgesand assign different weight parameters according to edge types i.e.
w r wowhenris an initial edge and w r wiwhenris an inverse edge .
similarly the edge embedding hrof edgercan be updated by hr wrelzr where wrelis a learnable transformation matrix which projects all the relations to the same embedding space as nodes.
finally therepresentationofanode vandedge rupdatedafter l layers are shown as hl v f parenlefttpa parenleftexa parenleftbta summationdisplay.
u r n v wl r hl u hl r parenrighttpa parenrightexa parenrightbta hl r wl relzl r notethat h0v xuandh0r zr i.e.
initialrepresentationofnode vand edge r .
withthehelpofourflow sensitivegraphlearning contextual informationcanbecapturedandsensitiveflowinformationisgiven more attention.
for example in figure initial node representationisencodedbydoc2vecandedgerepresentationiscalculated by basis decomposition.
edge matrix is inversed first to capturecontextual feature information.
then to aggregate information fromneighbornodestoupdatetherepresentationofnode3 initial representations of nodes are embedded jointly with their incoming edges i.e.
edges by eq.
to preserve some important features from outgoing nodes.
resampling.
afterllayersgraphlearning directlytrainingthe classifiers on all statement nodes is biased because the distribution of non vulnerable nodes and vulnerable nodes is extremely imbalanced.forexample infigure3 althoughwehavefilteredoutsomeirrelevant nodes by program slicing the number of non vulnerable nodes i.e.
node is still larger than that of vulnera ble nodes i.e.
node .
to generate some synthetic vulnerable nodestore balancethedistribution weadopt graphsmote a graph level oversamplingframework asthebasiccomponentfor our resampling.
concretely it contains two steps node generation and edge generation.
firstly to generate high quality synthetic nodes we utilize the widely used smote algorithm to perform interpolation on vulnerable nodes.
it searches for the closest neighbour nodearoundeachminoritynode i.e.
vulnerablenode intheembedding space and generates synthetic nodes between them.
then edge generator adopts weighted inner production to generate edges and gives link predictions for synthetic nodes by setting a threshold tokeeptheconnectivityofthegraph.ifthepredicted probability of connection between synthetic node v primeand its closest neighbornode uisgreaterthan boththesyntheticnode v primeand edge will be put into the augmented adjacency matrix of originalgraphs.tomaketheanalysiseasier thetypeofallsyntheticedgesissetas control i.e.
syntheticnodesarecontrol dependent on their neighbor nodes .
owing to the contribution of resampling the proportion of memory relatedvulnerablestatementsincreases avoidingthewelltrained detection model biased caused by imbalanced distribution of vulnerable nodes and non vulnerable nodes.
for example in figure4 threesyntheticnodes pink shaded areconnectedwith one vulnerable node i.e.
node and one non vulnerable node i.e.
node .
classification.
beforetrainingtheclassificationmodel fs gnn adopts one layer flow sensitive graph learning block in section .
againtoupdatenodeinformationbyeq.
.bylearningboththeunstructured i.e.
statement embedding and structured i.e.
various flows features from nodes and edges the classification model are employedtodistinguishvulnerableandnon vulnerablestatements.
totrainthemodel weusethe softmaxactivationfunctionasthe last linear layer for node classification and minimize the following cross entropy loss on all labeled nodes i.e.
vulnerable or nonvulnerable min l summationdisplay.
g g1 v summationdisplay.
i vk summationdisplay.
k 1tiklnh l ik wheregis a code slice graph in the training set g vis the setofnodesinourtrainingset.
h l ikrepresentstheprobabilityof nodeibelonging to class k wherek for the binary node 2we omit data dependency flow because during the empirical study we find that a large number of irrelevant synthetic data dependency edges can introduce biases and make the performance of the detection model deteriorate.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
icse may pittsburgh pa usa sicong cao xiaobing sun lili bo rongxin wu bin li and chuanqi tao softmax softmax 1010control control control invcontrol invstr str inv char str1 4char str1 4void memory leak1void memory leak1 memory leak func strlen str str1 memory leak func strlen str str1 char str this is a string char str this is a string controlcontrol invstr char str1 4char str1 4void memory leak1void memory leak1 memory leak func strlen str str1 memory leak func strlen str str1 char str this is a string char str this is a string 3ii i wi wowo str stringptr plen str1 1151part .
graph embedding part .
cl assification part .
resamplingfs gnn softmax 10control control control invcontrol invstr str inv char str1 4void memory leak1 memory leak func strlen str str1 char str this is a string controlcontrol invstr char str1 4void memory leak1 memory leak func strlen str str1 char str this is a string 3ii i wi wowo str stringptr plen str1 1151part .
graph embedding part .
cl assification part .
resamplingfs gnn figure graph learning with fs gnn classification task.
tikdenotes respective ground truth label for nodei.
.
vulnerability detection inthedetectionphase weapplythewell trainedmodeltodetect potential memory related vulnerabilities in programs and identify suspicious statements.
specifically similar to training phase program semantics reflected in the graph representations of source code are captured through interprocedural analysis.
in order to reduce the number ofmemoryoperations irrelevantstatements programsaresliced accordingtopointsofinterest systemapicalls andpointervariable to obtain a batch of program slices section .
.
next statement nodesinprogramslicesareembeddedintolow dimensionalvectors through doc2vec section .
.
finally both unstructured i.e.
statement embedding and structured i.e.
control and data flow informationareusedasgraphinputtofeedintothewell trained detection model for vulnerability detection.
experiments .
research questions rq1.howeffectiveis mvdindetectingmemory relatedvulnerabilities compared to existing deep learning based vulnerability detection approaches?
works most relevant to mvdare deep learning based vulnerability detection approaches.
by investigating this rq we aim to answer how well does mvdperform in comparison with the state of the artdeeplearning basedapproachesinmemory related vulnerability detection.
rq2.how effective is mvdin detecting memory related vulnerabilitiescompared tostatic analysis basedvulnerability detectors?
static analysis based vulnerability detection tools are widelyused and perform well on memory related vulnerabilities.
in addition staticanalysis basedapproachescanidentifythestatementlevel results for vulnerability detection i.e.
fine grained detection results .
therefore the purpose of this rq is to analyze how mvd perform compared with existing static analysis based detectors.rq3.
howeffectiveisfs gnnformemory relatedvulnerability detection?one of the key contributions of our approach is flow sensitive graphneuralnetwork whichjointlyembedsbothunstructured i.e.
code snippets and structured i.e.
control and data flows informationtolearncomprehensiveandpreciseprogramsemantics.
different from rq1 we aim to show whether sensitive contextual informationcapturedbyfs gnncontributestomemory related vulnerability detection in comparison with other popular gnns i.e.
evaluatingtheeffectivenessoffullyutilizingflowinformation .
rq4.howefficientare mvdandbaselinesintermsoftheirtime cost for detecting memory related vulnerabilities?
efficiencyisimportantforevaluatingtheperformanceofmemoryrelated vulnerability detection approaches.
an approach whichcosts too much time for detecting vulnerabilities may encounteradoption barriers in practice.
this rq is to investigate whether mvdcan make a better trade off between accuracy and efficiency.
.
experiment setup .
.
dataset.
since existing vulnerability datasets are either not tailoredformemory relatedvulnerabilities ornot sufficientfortrainingdeeplearningmodels e.g.
speccint2000 wemanually constructed a new vulnerability dataset which covers13commonmemory relatedvulnerabilities includingcwe119 and formodeltrainingandevaluation.ourdatasetisbasedontwo widely adoptedsources sard awell known samplevulnerabilitydataset and cve afamousvulnerabilitydatabase.
in this work we focused on c c programs due to their frequent memory problems caused by low level control of memory and adoptedvulnerabilitytypes i.e.
cwe ids asoursearchcriteria to collect memory related vulnerabilities from sard and cve.
for real world vulnerabilities we only considered cves which contain sourcecodeandfromwhichwecollectbothvulnerablefunctions andcorrespondingpatchedfunctions.forsard wecollectedall test cases labeled as bad .
the statistics of the vulnerable programs in our dataset are shownintable1.itincludes1 208real worldvulnerabilitiesincve covering open source c c projects which are widely adopted as target projects by prior works and vulnerablesamples i.e.
testcases insard.column2representsthescopeofprojectversionsaffectedbyvulnerabilitiesinourdataset.column authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
mvd memory related vulnerability detection based on flow sensitive graph neural networks icse may pittsburgh pa usa table details of vulnerability dataset.
project version samples vertices edges linux kernel .
.
ffmpeg .
.
asterisk .
.
libarchive .
.
libming .
.
libtiff .
.
libav .
libpng .
.x .
.x qemu .
.
wireshark .
.
sard total figure distribution of vulnerability types denotes the number of vulnerable samples.
a vulnerable sample may contain one or more vulnerable functions.
column and column are the number of nodes and edges in slices respectively.
furthermore the distribution of different types of memory related vulnerabilitiesinourdatasetisshowninfigure5 withcwe improper restriction of operations within the bounds of a memorybuffer accountingforthehighestpercentageat40 including vulnerable samples .
.
.
data labeling.
totrainadetectionmodel wefirstneedto conduct datalabeling.thereare twotypes oflabels forstatement nodes in the graph representation of a program vulnerable represents that the node is related to an improper operation in the vulnerable programs non vulnerable represents that the node is relatedtothenormaloperation.tomakethisprocessautomatic we adopted a simple labeling strategy with difffiles.
we first conduct programslicingforeachvulnerablesampletogenerateanumberof slices.
then for each slice of the samples in sard we labeled the statementnodesannotatedwith errors as vulnerable.foreachslice ofthereal worldvulnerabilitiesincve wecomparedstatementsin eachsliceandthatinthecorrespondingvulnerablefunctionaccordingtodifffiles.ifastatementwasdeletedoraltered i.e.
starting with in difffiles it would be labeled as vulnerable and nonvulnerable otherwise.however inpractice partofmemory relatedvulnerabilities did not contain in their patches.
for example in cve memory leaks because allocated memory can notbereleasedwhenmemoryallocationfails.thisvulnerability canbefixedbyaddingamemoryreleasestatement.thus forthese vulnerabilitiescannotbedirectlylabeled wemanuallylabeledvulnerablenodesthroughidentifyingimproperoperations e.g.
memoryallocationordeallocationstatements .inordertoavoidintroducing artificial deviation two postgraduates and one ph.d participatedinthislabelingprocess.iftwopostgraduatesdisagreedon the label of the same sample the sample would be forwarded to the ph.d evaluator for further investigation.
.
.
baseline methods.
to answer the first research question we selected three state of the art dl based vulnerability detectiontechniques i.e.
vuldeepecker sysevr anddevign .
vuldeepecker andsysevrrepresented source code as sequences and used bilstm model for vulnerability detection at the slicelevel.devignconstructed a joint graph structure including ast cfg dfg andcodesequences andusedggnnmodeltodetect vulnerabilities at the function level.
they are widely adopted as baselines in recent works and have been shown to beeffectiveindetectingmemory relatedvulnerabilities e v en though they are designed for generic vulnerability detection.
toinvestigaterq2 weselectedfivepopularstaticanalysis based vulnerability detectors i.e.
pca saber flawfinder rats andinfer .they haveshownrelatively goodperformanceonmemory relatedvulnerabilitiesandarewidelyadopted as baselines in prior works .
.
.
implementation.
we implemented mvdin python using pytorch .ourexperimentswereperformedwiththenvidiagraphics tesla t4 gpu installed with ubuntu .
cuda .
.
the neural networks are trained in a batch wise fashion until converging and the batch size is set to .
the dimension of the vector representation of each node is set to and the dropout is setto0.
.adam optimizationalgorithmisusedtotrainthe modelwiththelearningrateof0.
.weightdecayissetto5 e and over sampling scale is set as .
.
the other hyper parameters of our neural network are tuned through grid search.
for rq1 it is unfair to compare mvdwith other dl based approaches because of our finer granularity.
thus we used thefunction level asacompromiseformula i.e.
ifavulnerablestatement was identified correctly by mvd we would consider the functionitbelongedtowasalsodetectedcorrectly.fordl based baselines we respectively used the vulnerable and non vulnerable functions as positive and negative samples to train the detectionmodels.
for mvd we only trained the detection model based on vulnerable functions i.e.
vulnerable statements are deemed as positivesamples whilenon vulnerablestatementsaredeemedas negative samples .
we randomly chose of the programs for trainingandtheremaining20 fortesting.tomakesurethatour model was fine tuned we used ten fold cross validation to evaluate thegeneralizationabilityofeachapproach.inrq2 weevaluated mvdandstaticanalysis basedapproachesatthe function level and statement level respectively.atthe function level weadoptedthe same experimental setup as rq1.
at the statement level we evaluated each approach by randomly selecting latest real world vulnerabilities reported in from our dataset covering five authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
icse may pittsburgh pa usa sicong cao xiaobing sun lili bo rongxin wu bin li and chuanqi tao table comparison with dl based approaches approach a p r f vuldeepecker .
.
.
.
sysevr .
.
.
.
devign .
.
.
.
mvd .
.
.
.
commonmemory relatedvulnerabilities including memoryleak ml double free df buffer overflow bo use after free uaf andout of boundsread write or w .thesevulnerabilitiesare representative because they cover the vast majority of the vulnerabilitytypesinourdataset.forexample bufferoverflow bo corresponds to multiple cwes including cwe and .
to ensure that the trained model is tested on unseen programs weexcludedthesesamplesfromthetrainingsetof mvd.for answering rq3 we respectively replaced our fs gnn model with threefamousgnnmodels includinggcn ggnn and rgcn to evaluate the contribution of each model to memoryrelated vulnerability detection.
for answering rq4 we recorded theaveragetraininganddetectiontimeofeachapproachinrq1 and rq2 to evaluate time cost of mvdand baselines.
.
evaluation metrics we used the following evaluation metrics to measure the effectiveness of our model accuracy a evaluates the performance that how many instances can be correctly labeled.
it is calculated as accuracy tp tn tp fp tn fn precision p is the fraction of true vulnerabilities among the detected ones.
it is defined as precision tp tp fp recall r measures how many vulnerabilities can be correctly detected.
it is calculated as recall tp tp fn f1score f1 istheharmonicmeanof recallandprecision and can be calculated as f1score 2recall precision recall precision experimental results .
rq1 mvdvs.
dl based approaches table2showstheoverallresultsofeachdeeplearning basedapproach in terms of the aforementioned evaluation metrics.
overall mvdachieves better results and outperforms all of the three referreddeeplearning basedapproaches.onaverage for mvd the accuracyis74.
theprecisionis61.
therecallis69.
and thef1scoreis65.
.moreover intermsofallmetrics mvdcan improve the best performed baseline devignby .
.
.
mvdvs.vuldeepecker.
as shown in table our approach improves accuracy precision and f1 score over vuldeepecker by1void invalid memory access int i char buf c while i buf char malloc sizeof char if buf!
null strcpy buf this is string free buf c buf i if i break psink c a a vulnerability missed by vuldeepecker 1static int init init msp flash void ... msp parts kcalloc ... gfp kernel ... if msp maps .virt null kfree msp parts goto cleanup loop if !msp maps .name kfree msp parts goto cleanup loop ... b a non vulnerable code sample misidentified by sysevr 1static bool try merge free space ... ... right info tree search offset ctl offset bytes if right info rb prev right info offset index left info rb entry rb prev right info offset index struct btrfs free space offset index else left info tree search offset ctl offset if ... ... kmem cache free btrfs free space cachep right info merged true if ... ... info offset left info offse info bytes left info bytes return merged c cve missed by devign figure a case study of rq1 .
.
and .
.
specifically vuldeepecker achieves the recallofonly35.
.bycontrast therecallof mvdisashighas69.
nearly double .98x .
poor recall indicates a great deal of vulnerabilities can not be detected by vuldeepecker.
a main reason is that vuldeepecker onlytakes data flowintoaccountwithout regardto control flow information.
for example as shown in figure 6a it contains a invalid memory access vulnerability at line 9because bufhas been freed at line 8in an infinite whileloop.
however it is missed by vuldeepecker in our experiment because without control flowinformation semanticsof differentbranch structures will be ignored.
mvdvs.sysevr.we can observe from table that in spite of significant improvement .79x in recall .
in comparison withvuldeepecker sysevrstill behaves worse than mvdin terms of each metric.
particularly mvdimproves precision over sysevr by15.
.therootcauseforthisperformancegapisthat sysevr cannot overcome the main limitation of sequence models e.g.
bilstm inprogramsemanticsmodeling.forexample infigure 6b thereisanon vulnerablecodesamplefrom linuxkernel which is misidentified by sysevr.
although sysevrcaptures control and data dependence relations between statements by constructing authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
mvd memory related vulnerability detection based on flow sensitive graph neural networks icse may pittsburgh pa usa table comparison with static analysis based approaches approach a p r f pca .
.
.
.
saber .
.
.
.
flawfinder .
.
.
.
rats .
.
.
.
infer .
.
.
.
mvd .
.
.
.
controlflowgraph cfg anddataflowgraph dfg program semantics implied in these information can not be utilized because sysevrtreats complex code structures as a sequential sequence of tokens which omits the control flow divergence.
thus this sample is misidentified as double free because msp parts is considered to be freed twice by kfreeat line 6and line .
mvdvs.devign.mvdalsooutperformsthebestperformedbaselinedevign.
it indicates that although powerful performance of gnn in inferring potential vulnerability semantics from graph representationoftheprogrammakes devignoutstanding theunderutilization of flow information still restricts the performance of devignin detecting more complex memory related vulnerabilities.
for example as shown in figure 6c it is a real world vulnerability cve inlinux kernel missed by devign.i t may lead to arbitrary address free ordouble free vulnerability by attacker because in certain situations the pointer left info atline 7can be the same as right info atline .
however afterright info hasbeenfreedat line left info whichis thesameas right info willbeusedat line again.there are two main reasons why this vulnerability cannot be detected by devign.ontheonehand duetothelackofinterproceduralanalysis preciseprogramsemanticslikememoryfree kmem cache free atline arehardtobecapturedby devign causingimprecisesemanticmodeling.onthe otherhand since devignprocessesmultipleflowsinformationbypassinginformationineachindividual graphandthenaggregatesthemacrossgraphs left info and right info are treated as different data flows which causes complex semantic relations difficult to be preserved.
answertorq1 incomparisonwiththepopulardl based approaches mvdachievesbetterdetectionperformanceby fully utilizing flow information via interprocedural analysis and fs gnn.
.
rq2 mvdvs.
static analysis based approaches table shows the experimental results of mvdand the static analysis based techniques.
overall mvdoutperforms all baselines with regard to the evaluation metrics.
among all static analysis based baselines pcaandsaberobtain relatively betterdetection performance.
pcaachieves thehighest precision .
andrecall .
duetoitsconsiderationofglobal variablesandaccurateinterproceduralflowanalysis.ourapproach stillimproves pcaby4.
intermsofrecall andby12.
interms9 175126pca saberflawfinderratsinfermvdml df bo uaf or w ml df bo uaf or w 175126pcasaberflawfinderratsinfermvdml df bo uaf or w figure7 thenumberofmemory relatedvulnerabilitiesin real world projects detected by each approach ml mem ory leak df double free bo buffer overflow uaf useafter free or w out of bounds read write 1static int l2tp ip bind struct sock sk struct sockaddr uaddr int addr len ... if !sock flag sk sock zapped return einval ... read unlock bh l2tp ip lock lock sock sk if !sock flag sk sock zapped goto out ... figure a use after free vulnerability cve missed by all static memory detectors we compared of precision.
the reason is that static analysis based approachesmainly rely on well defined vulnerability rules or patterns hand crafted by human experts.
they are effective in simple memory related vulnerabilities e.g.
sard dataset .
however real world vulnerabilitiesare morecomplicated restricting theeffectiveness ofthese staticanalysis based detectors.similar tothese detectors mvdalsoanalyzes interproceduralcontrol and data flowinformation.
owing to the powerful performance of deep learning models mvdcanlearnimplicitvulnerabilitypatternsfromvulnerablecode insteadof explicitrulesor specifications makingit moreeffective in real world scenarios.
figure shows the detection results of each approach for five common memory related vulnerabilities in real world projects.
these vulnerabilities are randomly selected from our dataset.
each detectedindividualvulnerabilitysuccessfullyislabeledbyadark circle and the bars on the left hand side are the total number of successfully detected vulnerabilities.
overall mvdoutperforms all baselinesbydetecting17outof30vulnerabilities includingnine vulnerabilities cannot be detected by baselines.
especially in comparisonwiththebestperformedbaseline pca ourapproachcandetecteightmorevulnerabilities.forexample asshowninfigure8 itisause after free vulnerabilitybecauseaconcurrentcallcouldmodifythesocketflagsbetween sock flag sk sock zapped atline 4andlock sock atline allowing local users to gain privileges or cause a denial of service by making multiple bind systemcallswithoutproperlyascertainingwhetherasockethasthe sock zapped status.
unfortunately it is missed by all the static memory detectors because they cannot detect use after free caused byraceconditionthroughstaticanalysisonly.inourapproach it canbecorrectlydetectedbecauseoftheadvantageofdeeplearning models in mining implicit vulnerability patterns.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
icse may pittsburgh pa usa sicong cao xiaobing sun lili bo rongxin wu bin li and chuanqi tao table contributions of different graph neural networks approach a p r f gcn .
.
.
.
ggnn .
.
.
.
rgcn .
.
.
.
fs gnn .
.
.
.
answertorq2 withtheadvantageofdeeplearningmodels in mining implicit vulnerability patterns mvd performs better in comparison with the popular static analysis based approaches.
.
rq3 fs gnn vs. other gnns table shows the results of different gnns.
we observe that fsgnn can improve the best performed baseline rgcn by .
.
.therearemainlytworeasonsforthis.first fs gnnadds edge types into the process of representation learning.
it can be regarded as the joint learning of edge embedding and node embedding.
thus fs gnn can preserve the comprehensive program semantics based on interprocedural control and data flow improving the flow sensitivity for memory related vulnerabilities.
in addition rgcn aggregates node and edge information throughdirected edge while fs gnn boosts the effect of edge types oncontext by adding corresponding inverse edges.
still taking thedouble free vulnerability as an example information of memory freeindifferentbranchstatementswillaffecttheirconditionnodes jointly.
therefore important features of output nodes are also preservedbyfs gnnfornodeupdateandinformationpropagation.
in addition we can find that although ggnn can process multiple relations across graphs it is still limited by the increasing number of relations resulting in lower performance in comparison with rgcn and fs gnn.
furthermore weobservethattheperformanceofgcnispoor.
the mainreason is thatthe neglectionof edgetypes leads tothe missing of structured code features e.g.
control and data flow .
withoutaccuratecontrol anddata flowinformation theperformance of memory related vulnerability detection drops sharply.
answer to rq3 fs gnncaneffectivelycontributetothe performance of mvd as it can better capture the structured information of vulnerable code.
.
rq4 efficiency table5liststhetimecost inseconds ofeachapproachintraining and detecting vulnerabilities.
the results show that in comparison withthe popularstaticanalysis based approaches mvdachieves lesstimecostoverotherapproaches except pca.thisisbecause pcaspeedsupdatadependencecomputationthroughsacrificing partial detection precision.among the four deep learning based approaches vuldeepecker incurs the least training and detection time because it only considersdata flowsandusesasimplesequencemodel bilstm for model training.
however combining with the results in table wecanfindthatitgeneratesthelowestdetectionresultsbecause the lack of control flows and the limitations of sequence model make it fail to capture the structured information.
compared with other learning based approaches mvdspends relatively longer training and detection time excluding devign because learning complicated program semantics in graphs is more time consuming than in sequence.
however mvdyields better detection results.
infact duetothecharacteristicthatdeeplearningmodelscanbe trainedoffline theirtrainingcostmaynotbethatimportant.based on private vulnerability datasets the users can train their own detection models offline and make a prediction within seconds.
answer to rq4 in spite of a great deal of training time mvdachievesrelativelyshorterdetectiontimewithbetter detectionresults makingatrade offbetweenaccuracyand efficiency.
threats to validity external validity.
the main external threat to our study is the generalizability of our experiment results.
we respectively investigated4 353vulnerablesamplesfrom10distinctc c open sourceprojectsandsard andusedthemixeddatasetformodelevaluationlike prior works.
however due to the huge gap in code complexity detectionresultsinpracticalscenariosmaynotbesosatisfactory.furthermore ourexperimentsarelimitedtomemory relatedvulnerabilitiesinc c programs.resultsmaynotbereproducible when applied to more complex vulnerabilities or languages e.g.
java .nevertheless ourapproachisgenericandcanbeextended for other vulnerabilities and languages.
internalvalidity.
internalvalidityinourexperimentrelatesto twofactors.thefirstisourimperfectnodelabeling.inthiswork wemanuallylabelednodeswhichdidnotcontainany delete statementasvulnerablethroughidentifyingrelatedsensitiveoperations.
thus it is possible that some samples are mislabeled.
to avoid harmful influence caused by incorrect node labels we tried our best to conduct the node labeling for the vulnerable samples in ourdatasetbythreeexperiencedresearchers.inaddition theimplementationofbaselinesalsothreatstheresultsofourexperiments.to compare with existing deep learning based vulnerability detection approaches we have re implemented devignbased on a popular repository3sinceitisclosed source.wetryourbesttobuildand tune thedevignparameters on our dataset.
related works existingmemory relatedvulnerabilitydetectionapproachescanbe dividedinto threemaincategories staticanalysis based dynamic analysis based and learning based approaches.
static analysis based.
static analysis based approaches aim to detect vulnerabilities based on specific vulnerability patterns authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
mvd memory related vulnerability detection based on flow sensitive graph neural networks icse may pittsburgh pa usa table time cost in seconds of different approaches.
n a not applicable method mvd vuldeepecker sysevr devign pca saber infer flawfinder rats training time s .
.
.
.
n a n a n a n a n a detection time s .
.
.
.
.
.
.
.
.
or memory state model.
cherem et al.
proposed a solution namedfastcheck which reduces the memory leak analysis to a reachability problem over the guarded value flow graph.
sui et al.
proposed saber afull sparsevalue flowgraph svfg basedapproach toachievethedef usechainsandvalue flowofthe memory for pointer analysis.
shi et al.
proposed pinpointto optimizewidely usedsparsevalue flowanalysisthroughdecomposing the cost of high precision points to analysis.
fan et al.
presented smoke astagedapproachformemoryleakdetection to solve the scalability problem at industrial scale.
li et al.
proposed pca astaticinterproceduraldatadependencyanalyzer tospeedupdatadependencycomputationthroughpartialcall path analysis.
differently our approach can learn vulnerability features from large amounts of vulnerability data without requiring any prior knowledge of vulnerabilities.
dynamic analysis based.
dynamic detection methods run thesourcecodeanddynamicallytracktheallocation useandrelease of memory at the run time.
leakpoint monitored the state of memory objects based on stain analysis and tracked the last used location of memory and the location where