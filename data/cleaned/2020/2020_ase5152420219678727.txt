evolutionary guided synthesis of verified pareto optimal mdp policies simos gerasimou department of computer science university of york uk simos.gerasimou york.ac.ukjavier c mara department of computer science university of york uk javier.camaramoreno york.ac.ukradu calinescu department of computer science university of york uk radu.calinescu york.ac.uk naif alasmari department of computer science university of york uk nnma500 york.ac.ukfaisal alhwikem department of computer science university of york uk faisal.alhwikem york.ac.ukxinwei fang department of computer science university of york uk xinwei.fang york.ac.uk abstract we present a new approach for synthesising paretooptimal markov decision process mdp policies that satisfy complex combinations of quality of service qos software re quirements.
these policies correspond to optimal designs orconfigurations of software systems and are obtained by trans lating mdp models of these systems into parametric markovchains and using multi objective genetic algorithms to synthesisepareto optimal parameter values that define the required mdppolicies.
we use case studies from the service based systems androbotic control software domains to show that our mdp policysynthesis approach can handle a wide range of qos requirementcombinations unsupported by current probabilistic model check ers.
moreover for requirement combinations supported by thesemodel checkers our approach generates better pareto optimalpolicy sets according to established quality metrics.
i. i ntroduction markov decision processes mdps provide a powerful mathematical framework for modelling and analysing sequential decision making problems under uncertainty .
theirability to capture the complexity and uncertainty of modernsoftware intensive systems has led to numerous mdp appli cations for stochastic control and dynamic optimisation indomains ranging from software product lines and service based systems to self adaptive systems and robotics .
software engineers can employ mdps both during system design to analyse different system architectures and atruntime to support system reconfiguration .
consider aservice based system whose operations can be performed byalternative combinations of functionally equivalent third partyservices that operate with different reliability response timeand cost.
modelling this service orchestration problem as anmdp allows engineers to analyse how the use of different ser vice combinations affects the quality attributes of the system.the solution to the mdp is a policy that determines whichconcrete services should be selected so that a given objective such as the overall system reliability or operational cost isoptimised.
given the mdp representation of such a systemand a temporal logic specification that formally definesthe objective to be optimised probabilistic model checkerslike prism and storm can automatically synthesisean optimal policy for the specification.
software systems often require the simultaneous optimisation of multiple objectives whilst also satisfying a set of strictconstraints.
in a service based system software engineers maybe interested in policies corresponding to services orchestra tion that minimise the system operation cost and responsetime subject to keeping the system reliability above a criticalthreshold.
this is an instance of a multi objective optimisationproblem .
in software intensive systems these objectivesare typically conflicting e.g.
a more reliable or responsiveservice tends to be more expensive.
as such the mdp policysynthesis needs to generate pareto optimal policy sets i.e.
sets of policies that i satisfy all constraints and ii for whichno policy exists that also satisfies the system constraints andachieves better values for all the optimisation objectives .
executing multi objective model checking on mdps for the synthesis of pareto optimal policies is an important andnon trivial problem .
despite recent advances existing approaches either use simple iter ative methods or rely on reductions and simplifications tosolve the problem using linear programming.
this limits theirapplicability to i single objective problems with multiplestrict constraints for which a single best policy exists or ii unconstrained problems with up to three optimisationobjectives.
accordingly these approaches support only asmall fragment of the multi objective mdp model checkingspectrum and cannot synthesise pareto optimal policies formany practical problems encountered for instance in softwareproduct lines .
our paper introduces evopoli an approach that supports the synthesis of pareto optimal policies for mdps with arbi trary combinations of constraints and optimisation objectives.evopoli uses evolutionary algorithms to synthesise poli cies that cover sufficiently the policy space enabling decision makers to obtain a holistic view of the tradeoffs between thepolicies in the objective space and make an informed decision.the crux of our approach is to cast the synthesis of pareto8422021 36th ieee acm international conference on automated software engineering ase 36th ieee acm international conference on automated software engineering ase .
ieee .
ase51524.
.
.
ieee prgho 4r6 frqvwudlqwv rswlplvdwlrqremhfwlyhv0xowlremhfwlyh vhdufk edvhg srolf v qwkhvlvs s frpsoldqw 4r6 frqvwudlqwv rswlplvdwlrq remhfwlyhv fwlrq vsdfh0 wudqvirupdwlrq3duhwr iurqwdssur lpdwlrq3 remhfwlyhv 3duhwr vhwdssur lpdwlrq36 srolflhv fig.
evopoli high level workflow.
optimal policies for mdps as a multi objective search basedproblem and leverage the power of evolutionary algo rithms to compute the required pareto optimal policies.
as shown in figure evopoli takes as inputs an mdp model and a set of quality of service qos constraints andoptimisation objectives formally defined in probabilistic com putational tree logic pctl .
through an mdp analy sis and transformation step evopoli produces a parametricdiscrete time markov chain pdtmc in which the model pa rameters encode the actions of the original mdp and extractsthe action space i.e.
the set of possible actions modelledin the mdp.
during this step evopoli also converts theconstraints and optimisation objectives into equivalent pctlspecifications that comply with the pdtmc representation.next evopoli executes a multi objective search based policysynthesis procedure that successively evolves a population ofcandidate policies until a termination criterion is met eitherthe search budget is exhausted or no improvement occursover a specified number of evolution rounds .
the result isan approximate pareto optimal set of policies along with theassociated approximate pareto front of qos attribute values.
the main contributions of our paper are the evopoli approach for the synthesis of pareto optimalpolicies that extends the multi objective model checkingon mdps to a much broader spectrum of qos softwarerequirement combinations than currently possible an extensive evopoli evaluation on several variants of twomdps modelling real world problems for a wide varietyof constraints and optimisation objectives.
our experimentsshow that evopoli can handle multiple qos requirementcombinations unsupported by current probabilistic modelcheckers.
moreover for requirement combinations sup ported by these model checkers evopoli produces muchbetter pareto optimal policy sets according to establishedquality indicators and statistical analyses .
a prototype open source evopoli tool and case studyrepository both available from our project web page at ii.
p reliminaries a. discrete time markov chains definition discrete time markov chain .
a discrete time markov chain dtmc over a set of atomic propositions ap is a tuple d s si p l r wheres negationslash is a finite set of states si sis the initial state p s s is a transition probability matrix such that for any states s s prime s p s s prime gives the probability of transitioning from stos prime and summationtext s prime sp s s prime for anys s l s 2ap is a labelling function that maps every state s sto the atomic propositions from ap that hold in that state and ris a possibly empty set of functions s r 0that associate non negative values with the dtmc states.
a parametric dtmc pdtmc is a discrete time markov chain whose transition probabilities p s s prime are specified as rational functions over a set of parameters .
b. markov decision processes markov decision processes generalise dtmcs with the ability to model nondeterminism.
definition markov decision process .
a markov decision process mdp over a set of atomic propositions ap is a tuplem s si a l r wheres si landrare defined as for a dtmc a negationslash is a finite set of actions and s a dist s is a partial probabilistic transition function that maps state action pairs to discrete probability distributions over s. in each state s s the set of actions a afor which s a is defined contains the actions enabled in states and is denoted by a s .
the choice of which action from a s to take in every state sis assumed to be nondeterministic.
we reason about the behaviour of mdps using policies.a policy resolves the nondeterministic choices of an mdp selecting the action taken in every state.
mdp policies can beclassified into infinite memory finite memory and memorylesspolicies depending on whether the action selected in a statedepends on all a finite number or none of the previouslyvisited states and on the actions selected in those states .our work and probabilistic model checkers such as prismand storm consider memoryless policies.
memoryless policiescan be further classified into deterministic when the sameaction is selected each time when a state is reached andrandomised when the action selected in a state is given by adiscrete probability distribution over the feasible actions .
inthis work we use deterministic memoryless policies calledsimply policies in the rest of the paper .
definition mdp policy .
a deterministic memoryless policy of an mdp is a function s athat maps each states sto an action from a s .
c. probabilistic computation tree logic probabilistic computation tree logic pctl is used to quantify properties related to probabilities and rewards in system specifications modelled by dtmcs and mdps.
definition pctl formulae .
state pctl formulae and path pctl formulae over an atomic proposition set ap are defined by the grammar true p p r r r r x u u k 843table i quality requirements for tas id type description pctl r1 constraint workflow executions must succeed with probability at least p .
r2 objective minimise the average response time rtime min ?
r3 objective minimise the average operation cost rcostmin ?
where ap is an atomic proposition is a relational operator p is a probability bound r r is a reward bound and k n 0is a timestep bound.
the pctl semantics is defined using a satisfaction relation over the states s. given a state sof an mdp m s means holds in state s and we have alwayss true s iff l s s iff s ands 2iffs 1ands .
the time bounded until formula 1u k 2holds for a path iff 1holds in the first i k path states and 2holds in the i th path state and the unbounded until formula 1u 2removes the bound kfrom the time bounded until formula.
the next formula x holds if is satisfied in the next state.
the semantics of the probability pand reward r operators are defined over all policies ofmas follows p p specifies that the probability that paths starting at a chosen state ssatisfy a path property is pfor all policies r r holds if the expected cumulated reward up to time step kis rfor all policies and r r holds if the expected reward cumulated before reaching a state satisfying is rfor all policies.
replacing p or r from with min ?ormax ?specifies that the calculation of the minimum maximum probability or reward over all mdp policies is required.
for a full description of thepctl semantics see .
iii.
r unning example we illustrate evopoli on a service based tele assistance system tas introduced in .
the tas continually tracksa patient s vital parameters adapts the drug type or dosewhenever needed and takes action in case of emergency.
tas combines three service types in a workflow figure .
when the system receives a request that includes the patient svital parameters a medical service analyses the data and replies with instructions to i change the patient s drug type ii change the drug dose or iii trigger an alarm for firstresponders.when changing the drug type or dose tas notifiesa local pharmacy using a drug service and the alarm to notify the first responders is executed via an alarm service.
the functionality of each service type can be fulfilled by multiple service providers that offer functionally equivalentservice implementations with different levels of reliability performance and cost.
reliability is given by the percentageof service failures over a predefined time period performanceis given by the service s mean response time and cost is theprice per service invocation.
at run time the quality attributes of the services can vary so tas periodically reconfigures its workflow service bindings tele assistance service drug service medical analysis service alarm service pick picktask sendalarm sendalarm altopt alt loop data getvitalparams analysisresult analyzedata data changedrug patientid changedose patientid fig.
tas service workflow adapted from .
to select the combination of service implementations that optimises its operation based on the requirements in table i. the reconfiguration decision can be cast as an mdp policy synthesis problem and modeled using high level specificationlanguages employed by commonly used probabilistic modelcheckers.
figure illustrates the encoding of a tas probleminstance in prism which contains a reconfiguration module reconf lines in charge of selecting the alternativeservice implementations one per service type at the startof the execution.
each of the implementation selections isunderspecified in the model and encoded as a nondetermin istic choice that will be resolved by the policy synthesisprocess lines .
once reconfiguration is complete thetasworkflow module executes the workflow communicating with the different service implementations selected viasynchronous actions with shared labels between in eachcommand .
if a service invocation fails the workflow canhandle timeouts by retrying calls line .
the number ofretries is configurable via parameter max timeouts line .
due to space constraints we only represent a subset ofcommands that bind workflow calls with alternative serviceimplementations.
below the workflow module the figureshows an excerpt of one of the modules that encode serviceimplementations medical analysis service ms1 which accrues cost and time rewards lines respectively whenever a synchronization with tasworkflow actions occurs e.g.
ms1 call lines .
the problem instance presented here is deliberately small for illustration purposes.
however the solution space can growexponentially as alternative service implementations are added resulting in situations in which finding optimal policies forservice selection cannot be achieved using exhaustive search.
8441mdp 2module reconf mssel init0 dssel init0 assel init0 ms sel ms sel ... ms sel ms sel ... ms sel ds sel ds sel ... ds sel as sel as sel ... ds sel as sel as sel endmodule module tasworkflow task initnotselected ... wok bool init false wdone bool init false tos initmax timeouts reconf done task notselected .
task getvitalparams .
task buttonmsg task buttonmsg !msinvoked msinvoked true res sendalarm task getvitalparams !msinvoked msinvoked true msinvoked res patientok wok true wdone true ... tos msinvoked msinvoked false tos tos tos msinvoked wdone true ... task getvitalparams !msinvoked msinvoked true msinvoked !dinvoked res changedrug dinvoked true msinvoked !ainvoked res sendalarm ainvoked true endmodule module ms1 ms1 ok bool init false ms1 ready bool init true ms sel ms1 ready ms1 failure rate ms1 ok false ms1 ready false ms1 failure rate ms1 ok true ms1 ready false ... ms sel !ms1 ready !ms1 ok ms1 ready true endmodule rewards cost true ms1 cost ... true as3 cost endrewards rewards time true ms1 response time ... true as3 response time true as3 response time timeout mult factor endrewardsordered selection of implementation for medical analysis drug and alarmservices encoded asnondeterministic choices.reconf module selects alternative implementations for different service types.
tasworkflow module models the workflow depicted in figure .
once reconfiguration is done picks task with equal probability.
if buttonmsg picked skips analysis goes directly to alarm.
calls handles ms response to check patient s vital parameters.
call to service fails with probability encodingfailure rate for this service implementation.ms determined to change drug dose.
ms determined to raise alarm.
msx dsx asx modules model alternative service implementations.
cost reward accrues economic cost per service call.
time reward accrues time spent on service operations.commands enabled only if service implementation selected.ms timeout handling.
fig.
mdp model of the tele assistance system encoded in the high level modelling language of prism .
iv .
e vopoli a. problem definition evopoli is applicable to systems whose behaviour can be modelled by mdps with the action set a s from definition encoding the choices e.g.
of functionally equivalent services that can be invoked to perform an operation available whenthe system state is modelled by state s sof the mdp.
definition policy decision space .
the policy decision space of an mdp m s s i a l r is the set of allvalid mdp policies ds s a s a s .
the number of such policies is ds producttext s s a s .
in line with the standard practice in the engineering of software intensive systems evopoli considers systemswithn 0constraints andn2 1optimisation objectives.
a constraint specifies a bound for the acceptable values ofa quality attribute while an optimisation objective specifieswhether a quality attribute should be maximised or minimisedsubject to satisfying all n 1constraints.
given an mdp m s si a l r n1 0pctlencoded constraints of the form ci p pi r ri i n1 andn2 1pctl encoded optimisation objectives of the form oi pmax pmin rmax rmin i n2 where is a placeholder for the set of pctl probability and reward properties supported by the constrained multiobjective policy synthesis problem solved by evopoli is to find the pareto optimal set psof mdp policies that satisfy the n1constraints and are pareto optimal with respect to the n2 optimisation objectives.
formally ps ds logicalandtextn1 i 1b m c i prime ds prime whereb m c i bistrue if the constraint ciis satisfied for the mdp model mand policy and false otherwise.
the dominance relation ds ds b assuming minimisation of the optimisation objectives o1 o2 on2 i sg i v e nb y prime ds prime i n2 q m o i q m prime oi i n2 q m o i q m prime oi whereq m o i rdenotes the value of the optimisation objective oifor policy on model m. finally given the pareto optimal policies set ps the paretooptimal front pfis defined by pf q m o ... q m o n2 ps .
example .
requirements r1 r3 from table i define a constrained multi objective optimisation problem for the mdpmodelling the tas system from our running example fig ure where n c1 r1 n2 o1 r2 ando2 r3 .
solving the constrained multi objective policy synthesis problem to establish the set psof pareto optimal policies and the pareto front pf is complex and non trivial .
existing research can only solve simplerforms of this problem i.e.
those for which n i.e.
numerical queries o r n1 i.e.
unconstrained pareto queries .
we explain next how our evopoli approach supports the synthesis of pareto optimal policies for an arbitrary number ofconstraints and optimisation objectives.
furthermore throughexperiments detailed in section vi we illustrate how evopolisubsumes the policies produced by the current state of the arttechniques for the simpler problem variants they can solve.
845b.
mdp to pdtmc transformation to solve the constrained multi objective policy synthesis problem for an mdp m s si a l r we construct a parametric dtmc d m s si p l r with the same state space initial state labelling function and reward function set asm.
for any pdtmc states s s prime swith actions a s a1 a2 ... a n enabled in state s the transition probabilityp s s prime is defined over a parameter x s ... n p s s prime parenleftbig s ax s parenrightbig s prime .
we use the shorthand notation x s nto refer to all the parameters of this pdtmc.
next we define n2pdtmc optimisation objectives o prime o prime ... o prime n2analogous to the mdp optimisation objectives from such that if the i th mdp optimisation objective is pmax ?
theno prime iis maximisep ?
etc.
the next result shows that solving the mdp policy synthesis problem from the previous section isequivalent to solving a similar problem for this pdtmc.
theorem .
ifps primeis the set of combinations of parameter values for which d m satisfies the constraints and is pareto optimal with respect to the objectives o prime o prime ... o prime n2 the solution ps of the constrained multi objective policy synthesis problem for the mdp mis given by policies ps prime s a x ps prime.
s s. s ax s .
proof.
we prove the theorem by contradiction.
first suppose thatpolicies ps prime contains a policy ps and letx ps prime be the combination of pdtmc parameter values associated with this policy.
as x ps prime thed m instance associated withxsatisfies the constraints .
also according to thed m instance associated with xand the mdp munder policy have identical transition probabilities so mmust also satisfy these constraints under policy .
as such ps prime ps.
prime .
additionally for all i n2 d m instance associated with xand the mdp munder policy must yield the same values for the properties evaluated for theoptimisation objectives o iando prime i respectively.
consider now the d m parameter combination x primethat satisfies s s. prime s ai x prime s i. as before since prime ps both the mdp munder policy primeand thed m instance associated with x primemust satisfy the constraints and must yield identical values for the properties evaluated for the optimisation objectives oiando prime i respectively for all i n2.
it follows that x primedominates x and therefore x ps prime which contradicts the assumption we started from.
accordingly policies ps prime ps .
the same reasoning can be used to show that ps policies ps prime and therefore we must have ps policies ps prime .
example .
figure shows the result of applying the mdp to pdtmc transformation described above to the reconf module from the tas system mdp in figure .
this pdtmcfragment shows how the nondeterministic choices from themdp are replaced by choices parameterised by the threepdtmc parameters defined in lines .pdtmc parameters possible values shown in comments 1dtmc 2const int xms sel ... max ms 3const int xds sel ... max ds 4const int xas sel ... max as 5module reconf mssel init0 dssel init0 assel init0 ms sel xms sel ms sel ... ms sel xms sel ms sel ... ms sel ds sel xds sel ds sel ... ds sel as sel xas sel as sel ... ds sel as sel xas sel as sel endmoduleordered selection of service implementations encoded as parameterised choices.
fig.
pdtmc encoding of the reconf module from the tas mdp in figure .
c. evolutionary based policy synthesis using exhaustive analysis to solve the constraint multiobjective synthesis problem is unfeasible since the policy decision space ds cf.
def is typically extremely large.
for instance for the mdp model of our tas running example from section iii ds while for the systems considered in our experimental evaluation ds .
clearly enumerating and evaluating all possible policies is both time consuming and computationally prohibitive.
evopoli reformulates the policy synthesis problem as a search based optimisation problem and uses multi objective genetic algorithms moga like the widely used nsga ii and spea2 algorithms to intelli gently navigate the decision space.
evopoli iteratively evolvesa population of candidate policies to identify promising re gions in the decision space and synthesise a close approx imation of the pareto optimal policies set ps.
evopoli encodes each candidate policy i.e.
solution as a tuple ofgenes.
each state s sfor which the cardinality of its set of enabled actions a s 2is mapped to a gene.
for any states the corresponding gene can take values from the set a s .
we refer interested readers to for a detailed description of this encoding.
algorithm shows the high level process underpinning evopoli for the synthesis of the pareto optimal policies setps and the corresponding pareto front set pf.
given as inputs the dtmc d m induced by the mdp m the decision spaceds and the lists of constraints c c2 cn1 and optimisation objectives o1 o2 on2 evopoli starts with empty psandpf sets line and iteratively evolves them through the loop lines until a termination crite rion is met.
the function t erminate ps ds holds when the maximum number of candidate policy evaluations hasbeen carried out i.e.
budget exhausted or when no newupdates have been made in ps over a fixed number of successive iterations i.e.
the decision space has been ex plored sufficiently yielding diverse and pareto optimal poli846algorithm evolutionary based pareto optimal policy synthesis function synthesis d m ds ci i n1 oi i n2 ps pf while terminate ps ds do g generate candidate policies ds ps for all g do ci i n1 oi i n2 eva l uat e policy d m ci i n1 oi i n2 if i n1 ci then dominated false for all prime ps do if primethen ps ps prime pf pf q d m prime oi i n2 else if prime then dominated true break end if end for if dominated then ps ps pf pf oi i n2 end if end if end for ps pf diversify policies ps pf end while returnps pf end function cies .
within each iteration evopoli initially employs the generate candidate policies function line to create a population gof plausible policies using moga specific crossover and mutation operators.
crossover randomly chooses two fit policies from the current pareto optimal set ps and exchanges their genes to produce new policies.
mutation onthe other hand creates a new policy by randomly changinga subset of the genes of a policy based on its value rangeencoded in the decision space ds.
next the for loop lines evaluates each policy g and establishes its dominance relation cf.
eq.
with respect to the policies in ps.
to this end the e va l uat e policy function line uses a probabilistic model checker to determine the satisfactioncondition of the n 1constraints and obtain the values for the n2 optimisation objectives.
the policy and the objectives tuple are added to ps andpf respectively only if satisfies all constraints and is not dominated by any other policy inps.
similarly policies dominated by are removed from psalong with their associated objectives tuple lines .
the execution of d iversify policies line uses mogaspecific mechanisms for diversity preservation to select poli cies from psthat will participate in the next iteration.
these mechanisms maintain diversity in the population and generatea pf that covers sufficiently the objective space.
for instance the diversity mechanism used by nsga ii combines thenon domination level of each evaluated policy and a crowdingdistance metric i.e.
the population density in its area ofthe search space.
once the evolution terminates the pareto optimal set approximation ps is returned along with the pareto optimal front approximation pf line .fig.
pareto front of policies for the tas quality require ments from table i synthesised using evopoli instrumentedwith nsga ii and spea2 .
example .
figure shows two pareto front pf sets obtained for our tas running example using the quality requirements from table i. as shown the nsga ii instrumented evopoliproduces more policies than its spea2 instrumented counter part.
both mogas had the same experimental setup i.e.
1000evaluations and a population of .
we should also highlightthat neither prism nor storm can produce a paretofront for this combination of objectives and constraints.
v. i mplementation to ease the evaluation and adoption of evopoli we have implemented a prototype tool in java that realises the high levelevopoli workflow from figure .
the mdp transformationcomponent consumes an mdp model specified in the high level modelling language of the prism model checker and the pctl encoded constraints and optimisation objec tives and applies the process described in section iv b toproduce the pdtmc and the pdtmc compliant constraintsand optimisation objectives.
we have developed the synthesismethod from algorithm on top of the search based soft ware engineering tool evochecker .
the open sourcecode of evopoli the full experimental results summarised inthe following section additional information about evopoliand the case studies used for its evaluation are available at vi.
e v aluation a. research questions rq1 validation how does our approach perform compare to existing probabilistic model checkers?
we analyse if our approach can synthesise policies of similar quality to thoseproduced by the probabilistic model checkers prism and storm for the simpler class of problems i.e.
uncon strained pareto queries that these model checkers can solve.
rq2 effectiveness how do evopoli instances instrumented with different mogas compare to each other?
we used this research question to analyse the impact of differentmogas in the performance of evopoli.
to this end we study 847table ii quality requirements for ocean worlds id type description pctl r1 constraint the robotic lander must complete its mission within minsrt r2 objective maximise science value rsv max?
r3 objective maximise probability of success pmax ?
r4 objective minimise energy consumption recmin ?
the quality of evopoli synthesised policies when our approach uses the established mogas nsga ii and spea2 .
rq3 decision support can evopoli provide useful insights into the trade offs between the quality attributesvalues produced by different policies?
to support decision making and help software engineers to make informed de cisions evopoli must synthesise policies with different trade offs.
hence we assessed the trade offs in policies produced byevopoli for the software systems analysed in our evaluation.
b. evaluation methodology software systems.
we performed a wide range of experiments to evaluate evopoli using multiple variants of two software systems derived from different application domains the service based tele assistance system tas adaptedfrom and described in section iii and a prototyperobotic planner software component for ocean world ow exploration which we describe next.
ocean worlds ow .
the ocean worlds autonomy testbed for exploration research and simulation project led by nasa ames research center is developing an autonomy softwaretestbed to spur the development of autonomy technologies forsurface missions .
this testbed is conceived for missionsin which a robotic lander collects and analyses samples and then sends relevant data back to earth.
to completethe mission the robot must choose among xloc alternative excavation locations each of which has an associated science value a measurement of the potential interest of samples in that location and an excavatability risk signifying the safety and difficulty of excavating in that part of the terrain .
foreach successful excavation the robot must choose where todump the resulting rubble by selecting among dloc available dumping locations.
excavating and moving around the robot sarm consumes a corresponding amount of energy.
data is sentback to earth during a specific time window for processing andfurther analysis.
table ii shows the ow mission requirements.
the autonomy software on the robotic lander includes a facility to replace existing plans as the mission progresses withupdated plans coming from earth or generated by automatedplanners on board and or on earth.
one of such plannersemploys mdp policy synthesis to make high level decisionsabout excavation and dumping location selections which areencoded as nondeterministic choices in a mdp model.
forthe excavation location selection each alternative is encodedas a command in which a failure to excavate is associatedwith a probability that encodes the excavatability risk.
three reward structures capture the science value time and energytable iii system variants analysed using evopoli variant details ds trun mean sd tas2 max timeout .
.
tas3 max timeout .
.
tas4 max timeout .
.
ow4 xloc dloc .
.
ow5 xloc dloc .
.
ow6 xloc dloc .
.
consumption associated with each selection.
due to space constraints we omit the full details of the mdp model of thissystem we refer interested readers to our project webpage.
experimental setup.
we performed a wide range of experiments using the tas and ow system variants from table iii.
the details column lists the values specified for thevariables of each system variant i.e.
the maximum timeout max timeout for the tas and the number of excavation xloc and dumping dloc locations for the ow system.the column ds reports the search space of the policies according to def.
.
finally the column t runreports the average running time and standard deviation in parenthesis for completing a policy synthesis run per system variant.
we instrumented the evolutionary based policy synthesis algorithm of evopoli using the established mogas nsga ii and spea2 .
we also used the following configura tion to evaluate our approach evaluations with an initialpopulation of individuals i.e.
generations in total anddefault values for single point crossover probability p c .
and uniform polynomial mutation probability pm .
.
we selected these values based on our experience in thefield and after performing a set of preliminaryexperiments.
to alleviate the potential impact of randomness in the performance and effectiveness of mogas e.g.
when choosingthe crossover point when sampling randomly to execute themutation operation we followed the established procedurein search based software engineering .
we executed 30independent runs per system variant from table iii and eachmultiobjective optimisation algorithm .
all the experi ments were run on a centos linux .
64bit server with two2.6ghz intel xeon e5 processors and 32gb of memory.
statistical analysis.
for real world systems such as those used in our experimental evaluation the policy decision space ds def.
is extremely large.
thus producing the actual pareto front is typically unfeasible.
aligned with the standardpractice for each system variant we produce the reference front comprising the nondominated policies from all the runs executed across all moga based evopoli instances and thepolicies produced by the probabilistic model checkers stormand prism for the simple class of multi objective policysynthesis problems that these models checkers can handle .we used this reference front and the widely used pareto frontquality indicators below to quantify the goodness of fit ofpareto front approximations synthesised by evopoli instances storm and prism.
for each quality indicator we use a boxplot to present its central tendency and distribution.
848fig.
boxplots comparing evopoli nsga ii evopoli spea2 prism and storm for the tas left and ow right system variants and for unconstrained pareto queries i.e.
n1 n2 evaluated using quality indicators ihv i epsilon1andiigd.
theihv hypervolume indicator uses a reference front and measures the volume in the objective space consumedby a pareto front approximation.
i hvmeasures both diversity and convergence and is strictly pareto compliant1 .
better pareto front approximations have larger ihvvalues.
thei epsilon1 unary additive epsilon denotes the minimum additive term needed to alter the objective vector from apareto front approximation to dominate the correspondingobjective vector of the reference front.
this indicator showsconvergence to the reference front and is pareto compliant.smalleri epsilon1values mean better pareto front approximations.
theiigd inverted generational distance indicator measures the euclidean distance in the objective space betweenthe reference front and the pareto front approximation.i igd signifies an error measure and indicates both diversity and convergence to the reference front.
smalleri igd values signify better pareto front approximations.
following the recommended practice we used inferential statistical tests to compare the quality indicator valuesobtained by evopoli instances and the values obtained byprism and storm.
we employed the shapiro wilk test andconfirmed that the quality indicator values do not follow anormal distribution.
thus we used the mann whitney andkruskal wallis non parametric tests with confidence level .
to analyse the results without making assumptions about the data distribution or the homogeneity of its vari ance.
we also performed a post hoc analysis with pairwisecomparisons between the algorithms using the conservativebonferroni correction p crit k kis the number of comparisons to control the family wise error rate.
when statistical significance exists we use cohen s d to quantify the importance of the observed effect .
cohen sd score summarises the difference between two groups as the 1pareto compliant indicators conform to the order specified by the pareto dominance relation on pareto front approximations number of standard deviations with d .
d .5andd .
denoting a small medium and large effect size respectively.
c. results discussion rq1 validation .
since neither prism nor storm can solve the constrained multi objective policy synthesis problem from section iv a we can ensure a fair comparison only bytransforming the problem into an unconstrained pareto query i.e.
n n2 that both model checkers can handle2.
to achieve this we removed constraint r1from both systems and retained requirements r2 r3 minimise response time minimise cost and r2 r4 maximise science value minimise energy for tas and ow respectively.
figure shows the boxplots for the ihv i epsilon1andiigd quality indicators for all six system variants from table iii.undoubtedly for all quality indicators and across all systemvariants there is a clear distance between the quality indicatorvalues obtained by evopoli instrumented with nsga ii orspea2 and those produced by prism and storm.
we con firmed our findings from the visual inspection of the boxplotsby using the kruskal wallis test which showed statisticalsignificance p value .
for all system variants and for all quality indicators.
we also ran a post hoc analysisof pairwise comparisons between the evopoli instances andprism and storm using the mann whitney test.
for allcomparisons we observed statistically significant differencesin favour of evopoli with the p value being in the range and with a high effect size d .
.
this is a key result of our validation experiments that indicates evopoli s capacity to produce pareto fronts ofhigher quality than those produced by prism and storm.
we support further our findings through the pareto front approximations produced by nsga ii based evopoli prismand storm for the ow system variants figure .
evidently 2we selected the maximum number of objectives that both model checkers support storm can handle up to three objectives.
849fig.
pareto front approximation for the ow system variants ow4 left o5 middle ow6 right and objectives r2 maximise science value and r4 minimise energy from table ii using prism storm and nsga ii based evopoli.
fig.
boxplots comparing evopoli nsga ii and evopoli spea2 for the tas left and ow right system variants andrequirements from tables i and ii respectively evaluated using quality indicators i hv i epsilon1andiigd.
the policies synthesised by evopoli for this typical run closelyapproximate those produced by the model checkers while alsocovering a larger spectrum of the objective space.
in general both model checkers found the same policies as shown bythe identical pareto fronts figure and the almost identicalquality indicator values figure in few problem instancesstorm produced more solutions than prism.
irrespectiveof the system variant however the produced policies areconstrained to the boundaries of the objective space.
sincethe model checkers employ linear programming they unsur prisingly have difficulties finding useful policies when theobjective space is non convex .
in contrast evopoli withits moga based specialisation is not sensitive to the shape orcontinuity of the pareto front and thus can synthesise policieswhen the objective space is also discontinuous or concave .we note that due to the iterative nature of mogas usedin evopoli our approach takes more time than prism orstorm.
we have demonstrated however that evopoli producesa richer and more diversified set of solutions than the othermodel checkers.
investigating mechanisms to improve thescalability of evopoli is part of our future work.these findings clearly demonstrate that evopoli can synthesise policies of equivalent quality to those produced byprism and storm for the simpler class of problems i.e.
unconstrained pareto queries that these model checkers cansolve.
also the evopoli produced pareto front is greatly morediverse and covers a wider spectrum of the objective space.
rq2 effectiveness .
we answer this research question by comparing the quality of the pareto fronts synthesised by two evopoli instances using nsga ii and spea2 for the tas and ow system variants and the full set ofrequirements from tables i and ii respectively.
figure showstwo derived pareto fronts for a typical run using these twoevopoli instances.
as shown in figure the distributionsof thei hv i epsilon1andiigd quality indicators for the spea2instrumented evopoli have a larger overall variability.
incontrast the nsga ii based boxplots are more concentratedas indicated by the smaller whiskers and the very few pointsabove or below them.
since both mogas generally followthe same evolutionary algorithm principles and apply elitism i.e.
they propagate the best policies across generations thisbehaviour could occur due to the different diversity preserva850tion mechanisms used nsga ii employs a crowding distance while spea2 invokes an archive truncating procedure .
the statistical comparison using the mann whitney test showed statistical significance across all system variants with p value ranging and .255e .655e for tas and ow respectively.
the effect size was large in all system variant quality indicator combinationsexcept from the tas4 i hvpair where the effect was medium.
these results provide strong empirical evidence that evopoli with nsga ii can synthesise policies that achieve betterquality indicator values than policies synthesised by evopoliusing spea2.
more importantly we have shown that evopolican form effective pareto optimal policies sets using alternativemogas thus demonstrating the ability of evopolito solve theconstraint multi objective policy synthesis problem.
rq3 decision support .
we answer this research question by qualitatively analysing the pareto front approximations to identify actionable insights concerning the trade offs betweenthe quality attributes encoded by the synthesised policies.
first through the use of mogas evopoli can examine efficientlythe discontinuous and likely non convex policy decisionspace to produce pareto front policy approximations thatcover sufficiently the space.
given this information softwareengineers can have a more informed view of the differentquality attributes trade off for their system.
second evopoli enables the identification of the points of diminishing returns where every increase in the valueof a quality attribute incurs a disproportional deterioration tothe other quality attributes.
for the ow6 system variant forinstance one such point is approximately located at .
signifying that policies which contribute higher science val ues consume significantly more energy.
depending on thesystem specific preferences software engineers can use thisinformation to eliminate such policies if a balance in qualityattributes is preferred or analyse further these policies e.g.
equip the robot with a larger battery to accommodate theincreased energy consumption and enable to use this policy .
finally a closer inspection of the pareto policies set revealed multiple policies that yielded the same quality attribute values.from a planning perspective these alternative policies cannotbe shown on the pareto fronts as their values overlap arevery useful as they can support fast system reconfigurationwithout the need to perform another policy synthesis operation.having for instance a repository of policies with the samequality attributes enables the quick selection of the functioningpolicies when a malfunction renders the currently active policyunusable.
this is a unique feature of evopoli that does notexist in either storm or prism.
d. threats to v alidity we limit construct validity threats that could occur due to simplifications in the adopted experimental methodology using the widely studied tas case study .
we obtainedthe information for the ow system from the literature .
we mitigate internal validity threats that could introduce bias when establishing the causality between our findings andthe experimental study by assessing evopoli using independentresearch questions.
we reported results over independentruns per system variant thus reducing threats due to thestochasticity of the employed multi objective evolutionaryalgorithms.
also we used the inferential statistical tests mann whitney and kruskal wallis to check for statistical signif icance .
supported by post hoc analysis using mann whitney s test and bonferroni s correction to controlthe family wise error rate.
finally we employed cohen s d toassess the effect size and calculate the amount of improvement.
we mitigate external validity threats that could affect the generalisation of our approach by developing evopoli on topof the search based software engineering tool evochecker that uses mdp models encoded in the high level modellinglanguage of prism .
the experimental evaluation usingmultiple variants of two software systems reduces furtherthe risk that evopoli may be difficult to use in practice.however further experiments are needed to establish theapplicability feasibility and scalability of evopoli in domainsand applications with characteristics different from those usedin our evaluation.
vii.
r elated work markov decision processes mdp have a wide range of applications in software systems across many domains .
mdp models can leave nondeterministic choicesunderspecified which can be resolved in disparate ways bydifferent control policies that can balance multiple potentiallyconflicting objectives .
in a high optimisationspace there is typically no single policy that optimises allobjectives but rather a set of pareto optimal policies withdifferent tradeoffs that form a pareto front.
for existing modelcheckers pareto fronts are often obtained by either using linearprogramming or iterating over weighted sums ofobjectives .
employing these methods lead tolimited applicability and scalability due to the computationalcost involved constrained search space and the limited numberof optimisation objectives supported .prism and storm for instance are two of the most advancedprobabilistic model checkers currently available and they arelimited to synthesis of mdp multi objective policies that canconsider up to two and three optimisation objectives withoutconstraints in storm and prism respectively or only oneobjective if the problem contains constraints.
in contrast evopoli can handle an arbitrary combination of any numberof constraints and objectives.
also pareto fronts generatedby our approach contain much more diversity because unlikeother approaches the applicability of evolutionary algorithmsis not constrained to convex optimisation problems where theset of achievable values for a pareto query is also convex .
multi objective reinforcement learning rl is a technique orthogonal to model checking for obtaining pareto optimalpolicies.
a major research direction of multi objective rlis currently on improving the efficiency of training .
the approximation of pareto fronts using rl isdetermined by minimising the difference between sampling 851actions and feedback signals.
in contrast to conventional rl multi objective rl uses one scalar feedback signal per ob jective which amplifies training complexity and makes it lessefficient .
another issue of using rl for obtaining paretooptimal policies is that it does not always guarantee safetyproperties although recent works started introducing extramechanisms to mitigate this issue e.g.
by integrating humanor domain knowledge in the training .
however theseapproaches have several limitations i.e.
do not support multi objective optimisation make strong assumptions orneed complex preprocessing .
search based software engineering sbse has been extensively studied in various applications and domains includingproject management software testing model checking and featureselection in software product lines .
sbse has alsobeen extended to synthesising pareto optimal sets of proba bilistic models .
evochecker usesmultiobjective optimisation i.e.
genetic algorithms to au tomatically produce approximate pareto optimal probabilisticmodel sets with respect to given requirements or constraints.
inour work we leverage evochecker as a means of supportingthe synthesis method from algorithm .
evopoli is to the best of our knowledge the first that can solve the multi objective constrained policy synthesis problem.concretely evopoli can approximate a set of pareto optimalpolicies and the pareto front for an arbitrary combination ofany number of optimisation objectives and constraints.
viii.
c onclusion we presented evopoli a tool supported approach for the automated synthesis of pareto optimal policies for mdpswith complex combinations of constraints and optimisationobjectives.
we evaluated evopoli on two case studies fromdifferent domains and demonstrated its ability to synthesisepolicies for problems that can be handled by the probabilisticmodel checkers prism and storm as well as formore complex problems that neither of them can support.
ourfuture work includes extending evopoli to support policysynthesis on timed mdps explore parallelisation methodsto improve evopoli s scalability and applying evopoli toother applications and scenarios.