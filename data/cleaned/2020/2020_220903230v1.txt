autopruner transformer based call graph pruning thanh le cong hong jin kang truong giang nguyen stefanus agus haryono david lo singapore management university singapore singaporexuan bach d. le university of melbourne melbourne victoria australiaquyet thang huynh hanoi university of science and technology hanoi vietnam abstract constructing a static call graph requires trade offs between soundness and precision.
program analysis techniques for constructing call graphs are unfortunately usually imprecise.
to address this problem researchers have recently proposed call graph pruning empowered by machine learning to post process call graphs constructed by static analysis.
a machine learning model is built to capture information from the call graph by extracting structural features for use in a random forest classifier.
it then removes edges that are predicted to be false positives.
despite the improvements shown by machine learning models they are still limited as they do not consider the source code semantics and thus often are not able to effectively distinguish true and false positives.
in this paper we present a novel call graph pruning technique autopruner for eliminating false positives in call graphs via both statistical semantic and structural analysis.
given a call graph constructed by traditional static analysis tools autopruner takes a transformer based approach to capture the semantic relationships between the caller and callee functions associated with each edge in the call graph.
to do so autopruner fine tunes a model of code that was pre trained on a large corpus to represent source code based on descriptions of its semantics.
next the model is used to extract semantic features from the functions related to each edge in the call graph.
autopruner uses these semantic features together with the structural features extracted from the call graph to classify each edge via a feed forward neural network.
our empirical evaluation on a benchmark dataset of real world programs shows that autopruner outperforms the state of the art baselines improving on f measure by up to in identifying false positive edges in a static call graph.
moreover autopruner achieves improvements on two client analyses including halving the false alarm rate on null pointer analysis and over improvements on monomorphic call site detection.
additionally our ablation study and qualitative analysis show that the semantic features extracted by autopruner capture a remarkable amount of information for distinguishing between true and false positives.
permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
copyrights for components of this work owned by others than the author s must be honored.
abstracting with credit is permitted.
to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
request permissions from permissions acm.org.
esec fse november singapore singapore copyright held by the owner author s .
publication rights licensed to acm.
acm isbn .
.
.
.
concepts software and its engineering automated static analysis computing methodologies machine learning .
keywords call graph pruning static analysis pretrained language model transformer acm reference format thanh le cong hong jin kang truong giang nguyen stefanus agus haryono david lo xuan bach d. le and quyet thang huynh.
.
autopruner transformer based call graph pruning.
in proceedings of the 30th acm joint european software engineering conference and symposium on the foundations of software engineering esec fse november singapore singapore.
acm new york ny usa pages.
introduction call graphs construction is crucial for program analyses.
call graphs capture invocations between functions of programs .
an ideal call graph is sound i.e.
it does not miss any true invocations and precise i.e.
it does not produce any false positives.
however even for small programs constructing a sound and precise call graph is difficult .
a call graph analysis should make reasonable trade offs between soundness and precision.
unfortunately recent work has found that widely used tools such as wala or petablox construct imprecise call graphs up to of edges in call graphs constructed by wala are false positives.
to address these issues researchers have proposed to improve pointer analysis which is the core of many call graph constructions algorithms by improving context sensitivity or flowsensitivity of the analysis.
unfortunately a perfect pointer analysis is generally not possible .
specifically pointer analyses usually face an expensive trade off between scalability and precision .
for example a context sensitive analysis by wala only reduces .
false positives rate over a context insensitive analysis while incurring a large performance overhead .
a recent approach which we refer to as cgpruner achieved a breakthrough in improving the quality of call graphs.
instead of directly improving pointer analysis cgpruner performs call graph pruning as a post processing technique on a call graph constructed through static analysis.
using machine learning techniques the call graph pruner removes false positives in a call graph.
specifically cgpruner first extracts a set of structural features from the call graph e.g.
the number of outgoing edges from the call site and the in degree of the callee.
it then leverages a learning model i.e.
arxiv .03230v1 sep 2022esec fse november singapore singapore thanh c. le hong jin kang giang t. nguyen stefanus a. haryono david lo xuan bach d. le thang q. huynh random forest to predict if a caller callee edge is a false positive i.e.
the caller does not invoke the callee in reality .
the call graph is updated by removing edges that are predicted to be false positives.
since the cost of generating predictions is low a machine learningbased approach does not incur a significant performance overhead.
their experiments show that cgpruner successfully improves over traditional call graph analysis by producing call graphs that eliminate a large number of false positives.
however cgpruner is still limited as it does not consider source code semantics and thus is not able to distinguish true and false postives effectively.
in this paper we propose a novel technique autopruner that incorporates both structural and statistical semantic information to prune false positives in call graphs effectively.
autopruner combines structural features extracted from a call graph with semantic features extracted from the source code of the caller and callee functions.
similar to cgpruner autopruner uses handcrafted structural features.
however different from cgpruner autopruner automatically extracts semantic features via deep learning.autopruner thus faces a unique challenge on how to use deep learning to automatically learn from a limited dataset.
to address this we leverage recently proposed transformer models of code i.e.
codebert that has been pre trained on a corpus containing millions of code functions.
as our task differs from codebert s pre training task autopruner first fine tunes codebert such that it captures the statistical relationships between caller and callee functions learning to distinguish between true and false positive edges based on their source code.
next autopruner leverages the fine tuned model to extract semantic features of each edge based on the source code of the caller and callee functions.
each edge then has an embedding that represents the semantic relationship between the caller and the callee.
for each embedding autopruner combines it with the handcrafted structural features to obtain a representation for each edge.
based on this representation autopruner employs a neural classifier to classify each edge in a call graph as a true or false positive.
we evaluate autopruner on call graphs produced by three well known tools i.e.
wala doop and petablox for real world programs taken from the njr benchmark in the same setting of cgpruner .
we compare the call graph generated by autopruner against multiple baselines including the original call graphs produced by wala doop and petablox the call graphs pruned by state of the art approach cgpruner as well as a graph neural network model that applies deep learning to the call graphs.
the latter two baselines consider only structural information.
our experiments show that autopruner improves over the state of the art approach by up to in f measure.
our experiments demonstrate that the use of the semantic features extracted by the transformer based model enables autopruner to outperform approaches that consider only structural information.
we investigate the effect of pruned call graphs produced by autopruner on client analyses which take the call graphs as input to perform other analyses on the programs.
we investigate two client analyses null pointer analysis and monomorphic callsite detection.
on null pointer analysis call graphs pruned by our approach autopruner lead to significantly reduced false alarm rate of only while the call graphs pruned by cgpruner and the call graphs constructed by wala have false alarmrates in null pointer analysis of and .
on monomorphic call site detection autopruner improves over cgpruner by over in terms of f measure.
to better understand autopruner we also perform qualitative analysis on its performance.
we leverage t sne to visualize the embedding of the call graph edges in a two dimensional space.
we find that the semantic features can separate the true and falsepositive edges demonstrating that autopruner captures a remarkable amount of information from the source code associated with each call graph edge.
in summary we make the following contributions we introduce autopruner a novel call graph pruner that uses both code and structural feature to identify false positive edges in a call graph.
we empirically demonstrate that pruned call graph produced by our approach can help analysis tool significantly improve the false alarm rate and f measure.
notably in the analysis client of null pointer analysis autopruner leads to over more reported warnings while decreasing false alarm rate from to .
we perform an ablation study and qualitative analysis to better understand our approach.
our analysis validates the use of our proposed approach for call graph pruning.
the paper is structured as follows section introduces the background of our work.
section describes our proposed approach.
section presents our experimental setup and results.
section discusses our qualitative analysis and threats to validity.
section covers related work.
finally section concludes and describes future directions.
background in this section we discuss a motivating example.
next we present the formal formulation of the call graph pruning problem and introduce transformer based models of code and codebert .
.
motivating example in figure we present a motivating example to motivate our approach and demonstrate the limitations of cgpruner that uses only structural features to prune call graphs.
the source code of the acceptstate function contains a call to the parse function.
in the original unpruned call graph the acceptstate node is connected to multiple parse nodes of classes that implement the mathexpressionparser interface e.g.
the interface is implemented byendofexpressionparser functionleftparenthesisparser and other classes that also override accept .
at runtime the acceptstate function is invoked multiple times with different values of state resulting in calls between acceptstate and the multiple parse nodes.
these edges in the call graph are true edges as they represent calls that occur at runtime.
due to a large number of outgoing edges from the same call site the local structure of each acceptstate toparse edge in the call graph resembles edges that are false positives.
a structuralonly approach such as cgpruner therefore incorrectly prunes all the edges between the acceptstate node and the accept node in the call graph.
this highlights the limitation of considering only the structural features of the call graph and motivates the needautopruner transformer based call graph pruning esec fse november singapore singapore figure the parser.parse call depends on the parameter state .parsers.get returns an object of one of multiple classes implementing mathexpressionparser .
throughout the course of the program execution acceptstate can be invoked with all possible values of state .
therefore despite the large number of outgoing edges from the same call site all edges to the parse nodes from acceptstate in the statically computed call graph are true edges.
however the large number of outgoing edges is a feature used to prune false positives which leads to the incorrect pruning of the edges related to the parse calls.
for guiding call graph pruning with the semantics of the source code.
from analyzing the source code we can correctly identify that a large number of outgoing edges are possible as the specific parse call depends on the parameters of the function.
indeed autopruner correctly leaves the edges unpruned due to its use of semantic features extracted from the source code by codebert.
.
call graph pruning .
.
problem formulation.
in this work we formulate the call graph pruning problem as below.
input a static call graphg v e is a directed graph constructed by a static analysis tool where vis the set of program s functions identified by a function signature and eis the set of edges i.e.
function calls in the call graph.
each edge in eis a tuple of caller callee offset where caller is the calling function callee is the called function and offset is the call site in caller.
output a pruned call graph g v e wherev vand e e to address this problem we aim to train a binary classifier c which can classify each edge in a call graph gastrue positive i.e.
the edge represents a true call or false positive i.e.
the edge does not represents a true call.
using the classifier s output we prune the call graph following algorithm .
we use the classifier cto classify each edge in a call graph.
edges classified as false positives are pruned while edges classified as true positives are retained.
algorithm call graph pruner input call graphg v e classifierc output pruned call graph g v e 1g g 2foreacheingdo 3p c e prediction of binary classifier ifp false positive then 5e e e remove edge from call graph end 7end 8returng .
.
state of the art.
to prune call graphs utture et.
al.
recently proposed cgpruner which uses a machine learning model a random forest classifier based on structural features extracted from a call graph for pruning edges.
their experiments demonstrate thatcgpruner could successfully boost the precision of call graphs from to and reduce the false positive rate in client tool from to .
the approach however also substantially reduces the call graph s recall.
cgpruner relies only on structural features which can not distinguish false positive and true positive edges that share the same characteristics of structure as mentioned in section .
.
similar tocgpruner our approach i.e.
autopruner employs a machine learning model to prune call graphs.
however unlike cgpruner we use the semantic information from the source code of both the caller and callee function of an edge in the call graph.
the information from the source code enables our approach to distinguish true positive edges from false positive edges later demonstrated in section .
.
.
transformer models of code and codebert transformer models are deep learning models based on an encoder decoder architecture.
transformer models employ the attention mechanism and have achieved remarkable performance in field of natural language processing nlp .
nlp models have also been employed for source code related tasks as source code has been found to exhibit characteristics such as repetitiveness and regularity similar to natural language .
recently codebert was proposed as a transformer model for source code.
a codebert model is pre trained on a large corpus containing over million functions and million pairs of commentfunction.
as input codebert can be given a pair of data e.g.
source code and a code comment that describes the semantics of the source code to learn statistical relationships between the pair of data.
codebert is pre trained by two tasks masked language modeling mlm and replaced token detection rtd .
in the mlm task given an input sequence with a single token codebert has to predict the value of the masked token.
in the rtd task given an input sequence where some tokens are replaced with alternative tokens codebert detects the replaced tokens.
previous studies have demonstrated the effectiveness of codebert in multiple tasks including the capability for codebert to be fine tuned for tasks that it was not initially trained for .
prior studies have been built on top of codebert for automating various tasks thatesec fse november singapore singapore thanh c. le hong jin kang giang t. nguyen stefanus a. haryono david lo xuan bach d. le thang q. huynh require an understanding of program semantics e.g.
type inference program repair etc.
motivated by these success cases our proposed solution autopruner built upon codebert for another task namely call graph pruning.
our solution tries to capture the semantic relevance of code in the caller function to that of the callee function to differentiate between true and false edges in a call graph.
different from cgpruner autopruner analyzes the source code of the functions while cgpruner ignores them.
moreover autopruner considers both caller and callee functions while other pure program analysis methods analyze only the caller function.
methodology figure illustrates the overall framework of autopruner .
before autopruner can be applied it has to be fine tuned and trained.
first in the fine tuning phase we fine tune a pre trained codebert model of code to enable it to extract the semantic features of the edges in a call graph.
next in the training phase we use the fine tuned model to extract semantic features for the edges in the call graph.
the semantic features are then combined with structural features extracted from the call graph to construct the representation of each edge.
then we train a feed forward neural network classifier to identify false positive edges.
afterward in the application phase autopruner can be used as a call graph pruner for post processing call graphs to be used in other program analyses.
.
fine tuning in this phase we fine tune codebert.
before codebert can be used for a task different from its pretraining task it has to be finetuned to adapt its weights for the new task.
codebert takes a pair of data as input and in autopruner we pass the source code of the caller and callee functions associated with each edge as input.
specifically autopruner uses a preprocessor that extracts the source code of the caller and callee functions constructing a sequence of input tokens that matches the input format expected by codebert.
then the sequences are input into codebert for fine tuning.
below we explain each component of the fine tuning phase in detail.
.
.
pre processing.
the pre processing step in figure produces the input sequences to codebert enabling it to learn a representation of the semantic relationship between the source code of the caller and callee functions.
initially from the call graph constructed by a static analysis tool e.g.
wala or doop an edge in the call graph is characterized by a pair of function signatures identifying the caller and callee functions associated with it.
we usejava parser1to extract the source code of both the caller and callee functions.
particularly we parse the source code to obtain the method descriptors for every methods and matches them against the output of existing cg generators which identifies methods using their descriptors.
this allows us to link the source code to the methods in the call graph.
then we use codebert tokenizer2 to tokenize the source code.
finally following the input format of we construct an input sequence that encodes the source code of the caller and callee functions in the form of caller s source code callee s source code where and are tokens separating the pair of data as required by codebert.
.
.
codebert fine tuning.
as the pre training tasks of codebert i.e.
the masked language modeling and replaced token detection tasks differs from our task i.e.
identifying false positive edges we perform a fine tuning step to adapt the pre trained codebert model for our task following the common practice in transfer learning and other applications of codebert .
this step aims to transfer the knowledge based on the pre training task associated with an extremely large amount of data onto our task where collecting data is expensive as obtaining the ground truth labels in our task requires careful human analysis and the execution of test cases .
we fine tune the codebert model directly on the training dataset of our task of identifying false positive edges in the call graph.
specifically we feed input sequences in the input format of codebert obtained from pre processing step into the codebert model.
next the model extract features from the input sequences.
then we pass the extracted features into a fully connected layer to classify each edge in the call graph into true and false positive edges in figure .
during the fine tuning phase the parameters of the codebert model are updated by adam optimizer to minimize the crossentropy loss.
after this fine tuning phase we freeze all parameters of the codebert model.
in the subsequent phases autopruner uses the fine tuned codebert model to extract semantic features from the source code of the caller and callee functions associated with each edge.
.
training in the training phase our objective is to train the binary classifier that predicts if a given edge is a true positive or false positive the classifier c in algorithm .
to this end we construct the representation of an edge in a call graph by extracting and combining features of both types semantic features extracted from the source code by fine tuned language model and structural features extracted from the call graph .
then we train a neural classifier to predict whether an edge is true or false positive.
below we explain each component of the pipeline.
.
.
feature extraction.
we extract into a feature set in figure the two types of features as follows semantic features.
the semantic features are extracted from the source code of caller and callee functions using our fine tuned codebert model.
to capture this information we first apply the same pre processing step as described in the fine tuning step in figure .
next the fine tuned codebert model extracts a high dimensional vector that encodes the statistical relationship between the caller andautopruner transformer based call graph pruning esec fse november singapore singapore figure the overview of autopruner table types of structural features feature description src node in deg number of edges ending in caller src node out deg number of edges out of caller dest node in deg number of edges ending in callee dest node out deg number of edges out of callee depth length of shortest path from main to caller repeated edges number of edges from caller to callee l fanout number of edges from the same call site node count number of nodes in call graph edge count number of edges in call graph avg degree average src node out deg in call graph avg l fanout average l fanout value in call graph callee function in figure .
as a result we obtain semantic features of an edge in call graph as follows fsem d vsem vsem ... vsem kce wherekc 768is the embedding dimension of codebert.
structural features.
the structural feature captures graphical information related to each edge.
the features include metrics about the neighborhood of the edge local information or the entire call graph global information .
we usethe same features proposed by utture et al.
.
detailed information of the features is presented in table .
we represent the structural features of an edge in a call graph as follows fstruct d vstruct vstruct ... vstruct kse whereks 22is the number of structural features.
based on the work by utture et al.
there are two features of each type listed in table one for transitive calls and one for direct calls so we have structural features.
.
.
feature fusion.
in this step we combine semantic features and structural features of each edge in the call graph into a final representation.
we first use one fully connected layer for each feature in figure .
then the output of these layers are concatenated to produce the final representation.
more formally f sem fcnkc h fsem f struct fcnks h fstruct f f sem f struct wherefcnm ndenotes a fully connected layer that takes a mdimensional input and outputs a n dimensional vector.
we set h which is the size of the hidden feature vector as .
kcandksis the size of semantic and structural feature vector respectively.esec fse november singapore singapore thanh c. le hong jin kang giang t. nguyen stefanus a. haryono david lo xuan bach d. le thang q. huynh .
.
neural classifier.
given the representation of an edge obtained from feature extraction we obtain a score that approximates the probability that an edge is a true positive.
the score is computed through a feed forward neural network in figure consisting of one hidden layer and one output layer.
more formally f fcn 2h f prob outlayer f where fcnm ndenotes a fully connected layer inputs a m dimensional vector and outputs a n dimensional one outlayer is a softmax function .fandf are the edge representation and output features respectively.
prob probfp probtp is the output probabilities whereprobfpandprobtpis the probability that an edge is false positive and true positive respectively.
an edge with probtplarger thanprobfpis considered as a true positive.
otherwise the edge are considered as a false positive.
during the training phase the parameters of autopruner except codebert s parameters are updated by adam optimizer to minimize the cross entropy loss .
.
application after the training phase autopruner can now be deployed for use as a call graph pruner.
given a call graph generated by a static analysis tool autopruner preprocesses the call graph and extracts semantic and structural features.
based on these features the neural classifier produces predictions for each edge in the call graph.
using the predictions of the neural classifier autopruner removes the edges predicted to be false positives and outputs an improved call graph with fewer false positives.
autopruner can be integrated into other static analyses i.e.
client analyses that takes a call graph as input.
since call graphs pruned by autopruner have fewer false positives compared to the original ones the performance of the client analyses should improve given the more precise call graphs.
empirical evaluation .
research question our evaluation aims to answer the following research questions rq1 isautopruner effective in pruning false positives from static call graphs?
this research question concerns the ability of autopruner in identifying false positive edges in a static call graph.
to evaluate our approach we evaluate autopruner on a dataset of real world programs in njr dataset in terms of precision recall and f measure.
we compare our approach to multiple baselines including the state of the art technique cgpruner as well as a graph neural network and the original call graphs produced by static analysis tools.
rq2 canautopruner boost the performance of client analyses?
this research question investigates the impact of pruned call graphs produced by autopruner on client analysis.
to answer this question we use pruned call graph as input for client analyses and investigate its performance compared to original call graph and cgpruner on two client analyses used by cgpruner null pointer analysis and monomorphic call site detection.rq3 which components of autopruner contributes to its performance?
autopruner uses multiple types of features including the semantic features extracted from both the caller and callee functions and the structural features extracted from the call graph.
we investigate the contribution of each feature in an ablation study by dropping each type of feature and observing the change in autopruner s performance.
.
experimental setup .
.
dataset.
to evaluate effectiveness of our approach we use a dataset of programs initially constructed by utture et al.
from the njr benchmark suite .
we follow the same experimental setting as prior work .
this dataset of programs was curated by utture et al.
based on the criteria that each program has over functions has over call graph edges and has over functions that are invoked at runtime and has a high overall code coverage .
in total the dataset comprises over call graph edges.
the groundtruth label of each edge was obtained based on instrumentation and dynamic analysis .
we use programs as our training set and the remaining programs for the test set.
.
.
evaluation metrics.
we estimate the quality of a static call graph using standard evaluation metrics precision recall and f measure which are defined as follows precision s g s recall s g g f measure precision recall precision recall wheresandgare the edge set in the static call graph and groundtruth respectively.
among these evaluation metrics precision is the proportion of edges in call graph that are true calls.
a high precision is desirable for reducing developer effort in inspecting false positives .
recall refers to the proportion of true edges that are retained in call graph.
finally we consider f measure which is the harmonic mean of precision and recall.
we use f measure as a summary statistic to capture the tradeoff between precision and recall.
following previous work we compute the average precision recall and f measure for the evaluation set by taking the mean over precision recall and f measure of individual programs.
we also report the standard deviation of each metric.
.
.
client analyses.
a better static call graph should lead to practical improvements on client analyses using the call graph.
to assess the effect of the improvements to the call graph from autopruner we run experiments on two client analyses null pointer analysis and monomorphic call site detection using the call graph produced by wala.
to perform a direct comparison the client analyses selected are the same as those considered by utture et al.
.
for each client analysis we compare autopruner against the baseline that produced the best call graph.
null pointer analysis.
in the first client analysis we use analysis by hubert et al.
which is implemented in wala to detect possible null pointer dereferences related to uninitializedautopruner transformer based call graph pruning esec fse november singapore singapore instance fields based on the input static call graph.
this analysis is context insensitive and field insensitive.
improving the analysis would reduce the amount of developer effort spent inspecting false alarms which is known to be a barrier to the adoption of bug detection tools based on static analysis .
for this client analysis we refer to incorrect warnings reported as false alarms to distinguish them from false positives from the call graph construction.
this analysis is independently checked by two human annotators to manually determine if the warnings are false alarms.
in cases where the two annotators disagree on the decision we involve a third annotator an author of the paper for a discussion to reach a consensus.
we report the total number of reported warnings and the false alarm rate of the null pointer analyzer.
as the ground truth labels of all warnings are not known we are not able to compute recall and therefore we do not compare the approaches on f measure.
monomorphic call site detection.
in the second client analysis the static call graph is used to detect monomorphic call sites.
a call site is monomorphic when only one concrete function can be invoked.
the detection of monomorphic call sites is useful for example for function inlining to reduce the runtime cost of function dispatch .
a better call graph would allow us to safely inline more functions improving the performance of programs.
the ground truth of this analysis is determined by running the analysis on the ground truth call graph.
we report the precision recall and f measure of the monomorphic call site detector.
table the classification threshold values of cgpruner for different static call graphs call graph wala doop petablox balanced point .
.
.
default .
.
.
.
.
baselines.
to assess the effectiveness of autopruner we compare our approach with the following baselines theoriginal call graphs are call graphs constructed by static analysis tools.
in this work we consider the cfa static call graphs constructed by three standard static analysis tools wala doop and petablox .
the choice of these three analysis tools follows the previous work for a fair comparison.
arandom baseline that randomly removes n of edges in a call graph.
for a fair comparison we set nas the percentage of edges that are removed by autopruner .
cgpruner is the state of the art technique in call graph pruning task.
cgpruner constructs a decision tree based on the types of structural features listed in table extracted from the call graphs to identify false positive edges.
we run cgpruner using the paper s replication package3.cgpruner uses a classification threshold to determine if an edge is a false positive.
a higher threshold results in higher precision as it accepts only a few edges which are more likely to be the ground truth call graph.
the threshold enables a trade off between precision and recall.
we report the result of cgpruner at two different thresholds.
the first is determined on the balanced point where the threshold is tuned such that the average precision and recall of the call graph are equal when evaluated on the test dataset following the procedure used by utture et al.
to determine the optimal balance between precision and recall.
note that in the cgpruner paper the balanced points are identified using the evaluation dataset.
in this paper we selected the points using the training dataset to reduce likelihood of overfitting.
the second threshold is the default threshold obtained from the replication package.
note that for wala both thresholds share the same value of .
so we report just one set of results.
the thresholds are shown in table .
gcn is an standard off the shelf graph neural network gnn .
in this task we use it perform edge classification.
gnns are common for machine learning on graph structured data.
as input we pass the call graph constructed from static analysis along with types of structural features described in table .
then we use the gcn which considers information based on the nodes in the neighborhood to predict if an edge in the call graph is a false positive.
.
.
implementation details.
forautopruner we implement the proposed approach using pytorch library and the python programming language.
the models are trained and evaluated on two nvidia rtx ti gpu with 11gb of graphics memory.
for codebert we fine tune the model with a learning rate of 1e following prior works and a batch size of in epochs.
we trained the neural classifier with a learning rate of 5e with a batch size of in epochs.
.
experimental results .
.
effectiveness of autopruner.
we report the comparison of our approach autopruner against the baselines approaches.
the detailed results are shown in table .
the evaluation results demonstrate that autopruner successfully boosts the performance of the call graphs produced by wala doop and petablox by .
.
up to improvement .
.
.
in f measure.
overall the use of autopruner led to gains in precision up to improvements which are substantially larger than the slight losses in recall up to just .
with respect to the state of the art baseline cgpruner autopruner further improves the baseline by in terms of f measure for the call graph produced by wala.
for the call graph of doop and petablox our approach improves over the optimally balanced cgpruner by and respectively.
the improvements of autopruner over cgpruner in f measure are statistically significant p value .
using a wilcoxon signed rank test.
note that the results above obtained from cgpruner bal is from cgpruner with a classification threshold carefully tuned on the testing dataset to produce the optimal balance between precision and recall.
therefore cgpruner balrepresents the optimal performance of cgpruner given the testing dataset.
it may not always be possible to obtain the optimal threshold in practice.
despite that we observe that autopruner still outperforms cgpruner on call graphs produced by all three static analysis tools with improvements in f measure ranging from .esec fse november singapore singapore thanh c. le hong jin kang giang t. nguyen stefanus a. haryono david lo xuan bach d. le thang q. huynh table comparison of the effectiveness of autopruner with the baselines on static call graph generated by wala doop and petablox.
cgpruner baland cgpruner defdenotes the result of cgpruner at balanced point where the precision and recall are equal on the test dataset and default threshold as provided in replication package respectively.
for wala these thresholds are the same so we report only one set of results as cgpruner .
the bold and underlined number denotes the best result for f measure.
tool technique precision recall f measure original .
.
.
.
.
.
random .
.
.
.
.
.
wala cgpruner .
.
.
.
.
.
gcn .
.
.
.
.
.
autopruner .
.
.
.
.
.
original .
.
.
.
.
.
random .
.
.
.
.
.
cgpruner bal .
.
.
.
.
.
doop cgpruner def .
.
.
.
.
.
gcn .
.
.
.
.
.
autopruner .
.
.
.
.
.
original .
.
.
.
.
.
random .
.
.
.
.
.
cgpruner bal .
.
.
.
.
.
petablox cgpruner def .
.
.
.
.
.
gcn .
.
.
.
.
.
autopruner .
.
.
.
.
.
when compared against cgpruner def which is not optimally balanced on the testing dataset and uses the threshold listed in table the improvements of autopruner are more evident.
in terms of f measure autopruner outperforms cgpruner by .
our approach performs better than the gcn baseline by and in terms of f measure for call graph of wala doop and petablox respectively.
interestingly gcn undeperforms cgpruner .
both gcn andcgpruner use only structural features from the call graph and differ only in the classifiers used decision tree versus a graph neural network .
this shows that for our task of call graph pruning the more complex classifier does not outperform the simpler classifier.
one possible reason for this result is that the increased complexity of the gcn causes it to overfit the training data.
overall autopruner outperforming both gcn andcgpruner suggests that the semantic features used by autopruner have predictive power.
answer to rq1 overall autopruner outperforms every baseline approach including the state of the art call graph pruner.
the call graphs pruned by autopruner improves over the state of the art baseline by up to in f1 when the baseline is optimally balanced and by up to when it is not.
overall autopruner outperforms all baselines.
.
.
effect on client analyses.
to investigate the effect of our pruned call graph on the client analyses i.e.
static analysis tools we apply our call graph to two client analyses i.e.
null pointer analysis and monomorphic call site detection following the experimental setup of prior work .
table comparison of the effectiveness of autopruner with the baselines and original call graph on null pointer analysis.
the bold and underline number denotes the best result for f measure.
techniques total warnings false alarms rate original cgpruner autopruner null pointer analysis.
to investigate the impact of autopruner in null pointer analysis we pass the pruned call graph as input to a null pointer analysis implemented in wala.
this analysis produces a set of warnings.
each warning is associated with a code location.
if the call graph is less accurate the null pointer analysis produces more false alarms.
to evaluate autopruner and the baseline tools we use the same evaluation procedure as utture et al.
by performing manual analysis on the reported warnings.
specifically one author with four years of coding experience and one non author with two years of coding experience annotator independently manually inspect warnings produced by an analysis implemented in wala.
a warning is considered a true alarm if the author can trace the backward slice of a dereference to an instance field that was uninitialized by the end of a constructor .
if another exception is encountered before dereferencing the null pointer or if the label of a warning cannot be verified in minutes or is otherwise unverifiable by the authors then the warning is considered a false alarm .
this labelling criteria for the human annotators considers only the warnings produced by the program analysis and therefore is not a complete definition of a null pointer dereference.
it is designed for a analysis that is within the cognitive ability of a human annotator to assess the call graphs produced by call graph pruners.
in the cases where the two annotators disagree on the decision we involve a third annotator an author of the paper with three years of coding experience for a discussion to reach a consensus.
finally we compute the false alarm rate of null pointer analysis by dividing the number of false alarms by the number of warnings.
the results are presented in table .
furthermore to assess the inter rater reliability of the two annotators we compute cohen s kappa and obtained a value of .
which is considered as almost perfect agreement .
using the call graph pruned by autopruner the null pointer analysis produces warnings with a false alarm rate of just .
christakis and bird suggest that program analysis should aim for a false alarm rate no higher than which is satisfied byautopruner .
meanwhile both the original call graph and call graph produced by cgpruner resulted in false alarm rates higher than and respectively .
our approach has a false alarm rate that is less than half of the cgpruner s false positive rate while reporting more warnings.
with respect to the original call graph our approach reduces the proportion of false alarms by six times from to .autopruner transformer based call graph pruning esec fse november singapore singapore table comparison of the effectiveness of autopruner with the baselines on monomorphic call site detection using the call graph produced by wala doop and petablox.
cgpruner balandcgpruner defdenotes the result of cgpruner at balanced point where the precision and recall are equal and default threshold as provided in the replication package respectively.
for wala these thresholds are the same so we report only one set of results for cgpruner .
the bold and underlined number denotes the best result for f measure.
tool techniques precision recall f measure original .
.
.
.
.
.
wala cgpruner .
.
.
.
.
.
autopruner .
.
.
.
.
.
original .
.
.
.
.
.
doop cgpruner bal .
.
.
.
.
.
cgpruner def .
.
.
.
.
.
autopruner .
.
.
.
.
.
original .
.
.
.
.
.
petablox cgpruner bal .
.
.
.
.
.
cgpruner def .
.
.
.
.
.
autopruner .
.
.
.
.
.
monomorphic call site detection.
in the task of monomorphic call site detection the call graph is used to identify call sites where there is only one concrete call at a code location.
as shown in table for the call graph constructed by wala autopruner outperforms the original call graph and cgpruner in f measure.
autopruner outperforms cgpruner by in f measure with improvements in both precision and recall.
we observe similar performances on the call graph of doop and petablox.
on doop s call graph autopruner outperforms cgpruner by in f measure.
compared to the original graph autopruner improves in f measure by .
similarly on the call graph produced by petablox autopruner improves over both cgpruner and the original call graph by in terms of f measure.
answer to rq2 the call graph produced by autopruner leads to improvements in both null pointer analysis and monomorphic call site detection.
based on the call graph from wala autopruner decreases the false alarm rate from null pointer analysis by .
on monomorphic call site detection autopruner improves over the state of the art call graph pruner by in f measure.
.
.
ablation study.
in answer this question we investigate two different ablation studies semantic versus structure caller versus callee function semantic vs. structure.
in this experiment we evaluate the relative contribution of autopruner s semantic versus structural features for call graph pruning.
table shows the results of our experiments.
autopruner semrefers to autopruner using only the semantic features extracted from the source code and autopruner struct table comparison of the effectiveness of the semantic features and the structural features.
the bold and underline number denotes the best result for f measure.
techniques precision recall f measure autopruner struct .
.
.
autopruner sem .
.
.
autopruner .
.
.
refers to the autopruner using only the structural features.
using only the semantic features autopruner semoutperforms autopruner struct in f measure by .
by using with both types of features autopruner outperforms autopruner semby in f measure.
the decreases in f measure when either the semantic features or structural features are removed are statistically significant p value .
.
this indicates that both types of features are important but relatively larger decrease in f measure when removing the semantic features indicates that the semantic features are more important compared to the structural features.
overall when autopruner uses only one type of feature autopruner has a lower f measure.
this suggests that both semantic and structural features are important for autopruner to perform effectively.
table comparison of the effectiveness of the caller features and the callee features.
the bold and underline number denotes the best result for f measure.
techniques precision recall f measure autopruner caller .
.
.
autopruner callee .
.
.
autopruner .
.
.
caller vs. callee.
next we assess the relative importance of the features extracted from the caller and callee functions.
we evaluate the performances of autopruner when only considering source code from either caller and callee and compare them with autopruner s. to perform this study we fine tuned codebert with only either the source code of the caller or the callee function.
autopruner caller refers to autopruner using only the source code from the caller function and autopruner callee refers to autopruner using only the source code from the callee function.
autopruner outperforms autopruner caller andautopruner callee by up to .
the decreases in f measure are statistically significant p value .
.
this suggests that the semantic features extracted from the source code of both the caller and callee functions are crucial for the performance of autopruner .
answer to rq3 our ablation study shows that all features contribute to the effectiveness of autopruner .
the semantic features are more important than the structural features while both the caller and callee functions are essential.esec fse november singapore singapore thanh c. le hong jin kang giang t. nguyen stefanus a. haryono david lo xuan bach d. le thang q. huynh figure the visualization of semantic features produced by codebert in sample programs.
the green circles and red triangles represent true positive and false positive edges respectively.
discussion .
qualitative analysis in this section we perform a qualitative analysis of autopruner .
we have seen that autopruner consistently outperforms the stateof the art approach and our ablation study indicates that the semantic features extracted by codebert are essential for the effective performance of autopruner .
here our goal is to investigate if the pre trained transformer model of code i.e.
codebert is able to separate true positive edges from false positives in the call graph.
to this end we use t sne an unsupervised method for visualization to visualize the semantic features from the call graphs of programs in two dimensional space.
if the semantic features have predictive power we would expect the call graph edges which are false positives to be separated from the true positives.
figure presents the visualizations where the green and red points are features of true positive and false positive edges respectively.
indeed we observe that the majority of the green points are clustered and are located relatively close to one another.
furthermore the clusters of green points are also typically far away from the majority of the red points.
the observation suggests that codebert was able to be trained to extract semantic features from the caller and callee function such that the true positives can be separated from the false positives in the vector space.
this validates our use of a fine tuned codebert model for extracting semantic features as the model demonstrates a remarkable ability to distinguish between true and false positives.still a small but significant proportion of red and green points are located close to one another indicating that using only semantic features is not enough to separate these edges.
this suggests that other features e.g.
structural features should be used to improve the model s classifier ability.
indeed as shown in section .
.
the structural features are complementary to the semantic features.
the addition of structural features increases the precision of autopruner by while keeping the same recall leading to improvement on f measure.
nevertheless we acknowledge the modest contribution of the structural features which may be from how the structural and semantic features are combined.
currently after they are independently extracted they are combined with a small feed forward neural network ffnn .
as a result the ffnn may fail to capture more complex interactions between the semantic and structural features.
.
efficiency in this section we investigate the efficiency of autopruner .
for pre training model autopruner uses an existing pretrained model codebert4.
for the offline fine tuning section .
and training section .
phase wherein both the codebert and the binary classifier needs to be finetuned and trained only once autopruner takes around hours.
for the inference phase which is integrated in downstream applications autopruner takes around .
second on average to predict a label for an edge.
transformer based call graph pruning esec fse november singapore singapore .
threats to validity .
.
external validity.
threats to external validity concern the generalizability of our findings.
our experiments are performed on the same dataset as prior work constructed from the njr1 benchmark .
this may be a threat to external validity since autopruner may not generalize beyond the programs outside the njr dataset.
however this threat is minimal as the dataset consists of a large number of data points and the njr benchmark is large and was carefully constructed to ensure their diversity .
.
.
internal validity.
threats to internal validity refer to possible errors in our experiments.
in this study following the experimental procedure of prior work we perform a manual inspection of null pointer analysis which may introduce human error.
to minimize the risk we asked one author of this paper and a non author to independently inspect and label the reported warnings.
we have measured the inter rater reliability obtaining cohen s kappa of .
which can be interpreted as almost perfect agreement .
therefore we believe that there are minimal threats from this issue.
.
.
construct validity.
threats to construct validity relate to the suitability of our evaluation.
to minimize risks to construct validity we have used the same experimental setup as a previous study including the same dataset and ground truth labels.
some bias could be introduced in the construction of the ground truth.
manual labeling requires extensive human effort which limits the scale of the experiments.
hence we use the same automated labeling procedure from prior work that runs test cases to identify ground truth edges.
the imperfect code coverage of the test cases may introduce bias.
however the code coverage in our experiments is higher than the code coverage of real world programs less than reported in prior studies .
another threat to construct validity is the definition of null pointer analysis of warnings produced by .
for analyzing static analysis warnings prior works often employ a human study with several annotators .
this human study is expensive and the task given to the annotators must be within the cognitive ability of humans.
to make the annotation task tractable to humans and reduce its cost we use the true alarm identification task definition used in the prior work .
related work in section we have discussed the studies related to call graph pruning and codebert.
here we discuss other related studies.
call graph construction has been widely studied.
as our approach does not use runtime information it falls into the class of static approaches for constructing call graphs.
approaches that use dynamic analysis result in fewer false positives but are less scalable.
some recent studies on call graph construction have focused on dynamic languages.
salis et al.
and nielson et al.
present approaches for constructing call graphs of python programs and javascript programs.
unlike language specific techniques autopruner can be used to improve call graphs of any language.
there are many client analyses using call graphs.
recently call graphs have been used for practical applications including scanning applications for vulnerable library usage generating exploits ofvulnerabilities and impact analysis .
we have explored two classic client analyses null pointer analysis and monomorphic call site detection to validate that the improvements from pruning the call graph lead to further improvements in practical applications.
apart from applying codebert to call graph contruction researchers have proposed other applications of deep learning models on source code.
other researchers had success using deep learning models for type inference code completion code clone detection program repair fault localization among other analyses on source code .
our work is similar as autopruner successfully applies deep learning techniques on source code analysis but is unique as previous studies have not previously applied deep learning to call graph analysis.
conclusion and future work we propose autopruner a novel call graph pruner that leverages both structural and semantic features.
autopruner employs codebert to extract semantic features from both the caller and callee function associated with each edge in the call graph.
our empirical evaluation shows that autopruner outperforms multiple baselines including the state of the art approach that uses only structural features.
the improvements from autopruner also lead to tangible improvements on downstream applications.
in particular the proportion of false alarms reported by a baseline null pointer analysis is halved decreasing from to just .
our ablation study shows that the semantic features complement the structural features.
moreover our qualitative analysis reveals that the semantic features extracted by codebert effectively separate true and false positive edges.
in the future we will evaluate autopruner on call graphs constructed using additional static analysis tools and for other programming languages as well as assess the impact on call graph pruning on other client analyses.
we will also explore more ways to improve autopruner such as jointly extracting semantic and structural features and providing more contextual information by incorporating the k hop callers e.g.
the caller of the caller of each function call to enrich the semantic features.
another interesting direction is to use autopruner for proposing edges in the call graph missing due to an unsoundness program analysis.
data availability.
autopruner s dataset and implementation are publicly available at acknowledgement this project is supported by the national research foundation singapore and national university of singapore through its national satellite of excellence in trustworthy software systems nsoetss office under the trustworthy computing for secure smart nation grant tcssng award no.
nsoe tss2020 .
any opinions findings and conclusions or recommendations expressed in this material are those of the author s and do not reflect the views of national research foundation singapore and national university of singapore including its national satellite of excellence in trustworthy software systems nsoe tss office .
xuan bach d. le is supported by the australian government through the australian research council s discovery early career researcher award project number de220101057.esec fse november singapore singapore thanh c. le hong jin kang giang t. nguyen stefanus a. haryono david lo xuan bach d. le thang q. huynh