deep learning library testing via effective model generation zan wang 1college of intelligence and computing tianjin university 2state key laboratory of communication content cognition china wangzan tju.edu.cnming yan college of intelligence and computing tianjin university china yanming tju.edu.cnjunjie chen college of intelligence and computing tianjin university china junjiechen tju.edu.cn shuang liu college of intelligence and computing tianjin university china shuang.liu tju.edu.cndongdi zhang college of intelligence and computing tianjin university china zhangdongdi tju.edu.cn abstract deep learning dl techniques are rapidly developed and have been widely adopted in practice.
however similar to traditional software dl systems also contain bugs which could cause serious impacts especially in safety critical domains.
recently much research has focused on testing dl models while little attention has been paid for testing dl libraries which is the basis of building dl models and directly affects the behavior of dl systems.
in this work we propose a novel approach lemon to testing dl libraries.
in particular we design a series of mutation rules for dl models with the purpose of exploring different invoking sequences of library code and hard to trigger behaviors and propose a heuristic strategy to guide the model generation process towards the direction of amplifying the inconsistent degrees of the inconsistencies between different dl libraries caused by bugs so as to mitigate the impact of potential noise introduced by uncertain factors in dl libraries.
we conducted an empirical study to evaluate the effectiveness of lemon with 20release versions of 4widely used dl libraries i.e.
tensorflow theano cntk mxnet.
the results demonstrate that lemon detected 24new bugs in the latest release versions of these libraries where bugs have been confirmed and one bug has been fixed by developers.
besides the results confirm that the heuristic strategy for model generation indeed effectively guides lemon in amplifying the inconsistent degrees for bugs.
ccs concepts software and its engineering software testing and debugging computing methodologies machine learning .
junjie chen is the corresponding author.
permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
copyrights for components of this work owned by others than acm must be honored.
abstracting with credit is permitted.
to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
request permissions from permissions acm.org.
esec fse november virtual event usa association for computing machinery.
acm isbn .
.
.
.
deep learning testing library testing model generation mutation search based software testing acm reference format zan wang ming yan junjie chen shuang liu and dongdi zhang.
.
deep learning library testing via effective model generation.
in proceedings of the 28th acm joint european software engineering conference and symposium on the foundations of software engineering esec fse november virtual event usa.
acm new york ny usa pages.
introduction in recent years deep learning dl techniques are rapidly developed and become one of the most popular techniques.
also they are widely adopted in various domains in practice such as autonomous driving cars face recognition speech recognition aircraft collision avoidance systems and software engineering .
unfortunately dl systems are also shown to be vulnerable to attacks and lack of robustness .
there are also reports of real world accidents caused by dl systems which threaten human lives.
for example an uber autonomous driving car killed a pedestrian in tempe arizona in and there are reports on tesla drivers being killed in autonomous piloting mode .
therefore it is extremely critical to properly test and verify dl systems before they are applied to safety critical scenarios.
compared with traditional software systems dl systems usually involve more complex components e.g.
platform hardware infrastructure deep learning libraries models source programs for training and training and testing corpus .
each component may potentially introduce bugs into dl systems.
figure shows the structure of a typical dl system which consists of the application level library level and infrastructure level.
currently most existing approaches focusing on guaranteeing the quality of dl systems are at the application level e.g.
testing dl models by generating adversarial inputs or measuring the testing adequacy of dl models .
however there is little attention on testing dl libraries which may also contain bugs that directly affect the performance of dl models.
since dl libraries are the basis of constructing dl systems and the impact of bugs in dlesec fse november virtual event usa zan wang ming yan junjie chen shuang liu and dongdi zhang cntkkeras interface cpu gpuos library levelmodeldata developer source program application level infrastructure leveltrainc cudapython mxnettheanotensorflow figure the structure of a typical dl system libraries tends to be much larger than that in a specific dl model it is very critical to explore the problem of testing dl libraries.
however testing dl libraries is challenging.
the difficulties are mainly two folds.
first it is difficult to obtain a large number of dl models to effectively trigger bugs in dl libraries.
different from traditional software systems testing of dl libraries requires dl models which stack many layers consisting of a large number of neurons and connection weights as input.
the dl models are constructed by the training process based on training data.
however due to the expensive training cost and limited available training data it is quite difficult to construct a large number of models let alone the models that can trigger library bugs.
second it is challenging to expose the bugs triggered by the dl models.
in traditional software systems the test oracle problem has been well studied and there are some ways of relieving the test oracle problem .
however due to many uncertain factors in dl libraries such as randomness and floating point computing deviation it is challenging to determine whether a found problem is a real bug in the library or a problem caused by some uncertain factors.
to date few approaches are proposed to target dl library testing.
pham et al.
proposed cradle which is the state of the art approach to detecting bugs in dl libraries.
cradle utilizes available dl models as input to invoke different dl libraries then differential testing is adopted to capture the triggered bugs.
more specifically it defines two metrics to be presented in section to measure the inconsistent degree of prediction outputs and sets a threshold to distinguish real bugs and uncertain impacts.
exciting results are reported by cradle but it still suffers from two major limitations relying on existing models to trigger library bugs can be restricting.
the public available models usually focus on popular tasks and only invoke a limited portion of library code which tends to be well tested.
moreover it is also tedious and even unrealistic to collect a large number of available models that can trigger different portions of library code or explore different usage ways of library code.
since the inconsistent degrees from real bugs may be similar to or even smaller than those from uncertain impacts directly setting a threshold for the measured inconsistent degrees to distinguish them can be restricting.
that is before applying the threshold to distinguish them a smart method is required to amplify the inconsistent behaviors caused by real bugs and thus differentiate with normal diverse behaviors affected by uncertain factors more clearly.
in this paper we propose a novel approach called lemon deep learning library t esting via guided mutation .
lemon is designed to solve the two challenges in dl library testing.
to overcome the first challenge we design a series of model mutation rules including intact layer mutation rules and inner layer mutation rules to automatically generate dl models by changing existing models.the mutation rules are designed with the purpose of exploring unused library code and different invoking sequences of library code.
in this way lemon tries to maximize the ability to explore the code space of dl libraries for the generated models as much as possible.
to overcome the second challenge we propose a heuristic strategy in lemon to guide the process of model generation towards the direction of amplifying inconsistent degrees for real bugs.
in this way lemon increases the differentiation between real bugs and uncertain impacts.
to summarise the main contribution of lemon is generating effective dl models to trigger and expose bugs in dl libraries.
to evaluate the effectiveness of lemon we conducted an extensive study based on 20release versions of four widely used dl libraries i.e.
tensorflow theano cntk and mxnet .
also we used popular existing models based on input sets as initial datasets for testing.
in particular lemon detected new bugs in the latest release versions of these libraries in total where bugs have been confirmed and one bug has been fixed by developers.
the results also demonstrate that the generated models by lemon detected many unique bugs that cannot be detected by the existing models and significantly amplified the inconsistent degrees of the detected inconsistencies i.e.
the average amplified rates over the existing models range from .
to .
across different library versions.
furthermore we investigated the contribution of our heuristic strategy for model generation by comparing with the random strategy and the results confirm the effectiveness of our heuristic based model generation.
to sum up this work makes the following main contributions a novel approach of dl library testing by generating effective dl models via guided mutation.
a practical open source tool implementing the proposed approach including an individual component that conducts efficient mutations for dl models.
an extensive study on versions of four widely used dl libraries demonstrating that lemon detects new bugs in the latest release versions of these libraries and the models generated by lemon significantly outperform the existing models and the models generated without any guidance i.e.
the variant of lemon .
background deep learning model .
a dl model is composed of multiple layers each of which consists of a large number of neurons.
the neurons between layers are connected with links.
different links are associated with different weights which are obtained through training with input data.
each layer conducts a specific kind of transformation such as convolution and pooling for the input data with specific weights.
in particular the same layer can be adopted multiple times in a dl model and the performance for the same kind of layer may be diverse as controlled by the weights on the links.
currently there are two popular kinds of dl models i.e.
convolutional neural network cnn and recurrent neural network rnn .
cnn contains convolution computing and is often used to process data with grid like topology such as images.
rnn uses loops to keep learned information and is mainly used to process sequential data such as natural language.deep learning library testing via effective model generation esec fse november virtual event usa deep learning library .
dl platforms generally provide highlevel and low level libraries.
dl system developers implement their source programs by using high level library apis which invoke the dl algorithms implemented in low level libraries.
different low level libraries are based on different infrastructures and have different input formats and apis while high level libraries can hide the differences between low level libraries and provide a consistent view on model construction and training.
similar to traditional libraries different dl low level libraries provide different implementations according to the same algorithm specification.
developers implement source programs by calling high level libraries which further invoke low level libraries to finish different kinds of transformation operations and training process.
one of the most popular high level libraries is keras which has been widely used in various critical domains .
keras runs on top of four low level libraries i.e.
tensorflow cntk theano and mxnet which cover most of the popular libraries.
similar to the existing work we used tensorflow theano cntk and mxnet as the low level libraries under test and adopted keras as the high level library invoking them.
therefore dl library testing in our work refers to testing low level libraries.
metrics for testing dl libraries .
differential testing has been applied to test dl libraries .
there are various metrics proposed to measure the differences detected between dl libraries.
we introduce those metrics briefly here.
d class is applied to classification models which calculates a score for each prediction result by checking the rank of the ground truth class in the prediction result and then calculates the difference between the two scores.
in particular it considers the rankings beyond top k i.e.
top in the study not interesting i.e.
setting the score to be .
d mad is applied to both classification and regression models and considers all elements in each output vector to calculate its distance with the ground truth vector.
given the ground truth vector denoted as g 1 2 .
.
.
m the prediction output vectors oj andok d mad is calculated based on formulae and .
when the d class ord mad value is larger than a pre defined threshold an inconsistency is detected and the d class ord mad value marks the inconsistent degree of the inconsistency.
o g mm i oi i d mad g oj ok oj g ok g oj g ok g ra a li lj pre pre layer localization metric is also proposed i.e.
by to localize the root cause of the inconsistency.
the formal definition is defined in formula .
a li ljrepresents the output difference defined by formula of a layer abetween liandlj.
preis the maximum output difference of the pre layers of a.rarepresents the change degree between a li ljand pre.
in this formula is set to which is used to avoid the division by zero problem when ais the first layer in m. the larger the value of rais the larger the possibility that the layer ais the root cause of the inconsistency.
approach to effectively test dl libraries there are two main challenges to be addressed.
the first challenge is to obtain a large set of dl models which serve as test inputs for dl libraries to trigger dl library bugs.
different from traditional test inputs e.g.
numerical values and strings a dl model is a structure stacking many layers each of which contains a large number of neurons and connection weights and thus traditional test generation tools cannot be used to generate dl models.
it is non trivial to obtain a large number of dl models due to the expensive training cost as well as the limited available training data.
moreover it is difficult to generate models that can trigger dl library bugs.
the second challenge is that it is hard to expose the bugs triggered by dl models .
although there are many test oracles to help determine whether a bug is detected in traditional software testing it is difficult to distinguish whether it is a real bug for dl libraries since they involve many uncertain factors.
in this work we propose a novel approach called lemon to testing dl libraries via guided mutation.
lemon is designed to solve the above mentioned two challenges.
to overcome the first challenge we design a series of mutation rules to effectively and efficiently generate dl models by mutating existing models presented in section .
.
to overcome the second challenge we design a heuristic strategy to guide the process of dl model generation so as to generate models that can amplify the inconsistency between different dl libraries as much as possible for real bugs presented in section .
.
finally we introduce the test oracle used in lemon in section .
.
figure shows the overview of lemon.
.
model mutation the goal of our mutation is to generate models to test dl libraries as sufficiently as possible by exploring unused library code or different usage ways of library code.
to achieve this goal we design a series of mutation rules at the model level.
we propose to conduct modellevel mutation rather than source level mutation i.e.
mutating a source program used for training a model due to two reasons first source level mutation is more costly than model level mutation since the former has to re train a model after modifying the source program.
in particular the training process tends to take hours even longer .
second model level mutation can introduce more fine grained changes to a model than source level mutation .
a dl model consists of multiple layers each of which contains a large number of neurons.
each layer is responsible to one specific functionality such as convolution and pooling.
therefore we systematically design our model mutation rules in two types i.e.
intact layer mutation and inner layer mutation.
we introduce them in detail in the following.
intact layer mutation .
intact layer mutation involves mutations on the entire layer and thus tends to introduce relatively large changes to a model.
in total we design seven intact layer mutation rules including four i.e.
lr lc la and afrm adopted from the existing work and three newly proposed mutation rules i.e.
ls mla and afrp according to our mutation goal.
in particular to explore unused library code we design mutation rules i.e.
la and mla to insert new layers to a model.
in this way the model could invoke new library code.
moreover mutation rules to modify i.e.
ls lc and afrp or remove i.e.
lr afrm existing layersesec fse november virtual event usa zan wang ming yan junjie chen shuang liu and dongdi zhang keras program inconsistenciestensorflow seed models mutation rules mutated model initial model input feedbackfeedback select select mxnettheano cntk figure overview of lemon are designed in order to explore different usage ways of library code in the model.
please note that an explicit constraint for intactlayer mutation is that the output shape1of one layer and the input shape of another layer to be concatenated should be identical.
the detailed intact layer mutation rules are described in the following layer removal lr removes a layer whose input shape and output shape are consistent from the model.
layer switch ls switches two layers both of which have the same input shape and output shape.
layer copy lc copies a layer whose input shape and output shape are consistent and then inserts the copied layer to concatenate the original layer.
layer addition la selects a layer whose input shape and output shape are consistent from the universal set of layers and then inserts it to a compatible position in the model.
multi layers addition mla la requires the input shape and output shape of the selected layer to be consistent.
mla gets rid of this constraint and creates a bundle of layers by concatenating multiple selected layers where the input shape of the first layer is consistent with the output shape of the last layer in the bundle.
finally mla inserts this bundle of layers to a compatible position in the model.
activation function removal afrm removes the activation function of a layer.
activation function replace afrp replaces the activation function of a layer with a randomly selected activation function from the universal set of activation functions.
inner layer mutation .
inner layer mutation is operated on the neurons of a layer which is more fine grained than intact layer mutation.
the computation of a layer relies on its neurons and thus changing the properties of neurons e.g.
weights and activation states facilitates more sufficiently testing on the library code used in the layer and is also helpful to explore different usage ways of library code.
in particular we design five inner layer mutation rules in total which are adapted from the existing work .
since a layer usually contains a large number of neurons and only changing one neuron has very slight impacts on the model we randomly select of neurons in the layer to apply inner layer mutation.
gaussian fuzzing gf adds noise to the weights of a neuron following gaussian distribution n 2 .
if is large the noise added to the weight is large which is more likely to produce an invalid model.
therefore we set to be 0and 1the shape refers to the number of dimensions and the size of each dimension.to be of the standard deviation of the weights for all the neurons in the layer.
weights shuffling ws shuffles the connection weights of a neuron with the previous layers.
neuron activation inverse nai inverts the activation state of a neuron by changing the sign of the output value of a neuron before passing it to the activation function.
neuron effect block neb eliminates the effects of a neuron on the next layers by setting the connection weights of the neuron to the next layers to be .
neuron switch ns switches two neurons in a layer to exchange their effects on the next layers.
first order and high order mutation .
to increase the diversity of the mutated models lemon considers both first order mutation and high order mutation.
first order mutation refers to applying only one mutation rule to the initial model while high order mutation refers to iteratively applying a series of mutation rules to the initial model.
in other words nth order mutation on the initial model is actually equivalent to first order mutation on the model produced by n th order mutation on the initial model.
as shown in figure the neb mutation rule is applied to the middle dense layer.
of neurons in the layer are blocked to cut off the connections with the next dense layer i.e.
setting the weights to be which is highlighted using the red color anddashed lines in figure .
.
heuristic based model generation since the mutation space is infinite it is infeasible to generate all mutated models and then select a set of models with the largest inconsistent degrees from them to help expose bugs.
please note that in lemon we also adopt differential testing as the test oracle and use d mad in formula to calculate the inconsistent degree of an inconsistency which is to be presented in section .
in detail.
one of the most cost effective solutions is that for each generation we generate a model that can produce larger inconsistent degrees of inconsistencies than before mutation as much as possible.
that is we should generate models towards the direction of amplifying the inconsistent degrees of inconsistencies.
based on this insight we propose our heuristic based model generation method.
more specifically in each iteration of our model generation lemon first selects a seed model to mutate presented in section .
.
and then selects a mutation rule to apply presented in section .
.
.
.
.
seed model selection.
in our context the initial seed model refers to a given existing model.
lemon generates mutated models from this seed model via first order or high order mutation.
since our model generation is conducted iteratively the generated models in the previous iteration can also be used in the following iterations.
in particular to facilitate the model generation towards the direction of amplifying inconsistent degrees of inconsistencies lemon also treats the mutated models which has larger inconsistent degrees than before mutation as seed models.
the metric defined by formula measures the inconsistent degree of an inconsistency produced by a model with an input on different low level libraries.
letmsandmmbe the seed model and the mutated model respectively.
given a set of input i1 i2 .
.
.
in and a set of dl libraries l1 l2 .
.
.
lm acc m n i 1 m j k 1d mad g oji oki k j deep learning library testing via effective model generation esec fse november virtual event usa ...... ............ ...... ...... ...... ............ ............densedense dense densedensedense mutated by neb mutation rulecoat mutated model tensorflow coat theano ankle boot inconsistency v alue .734tensorflow coat theano coat initial model inconsistency v alue .
figure an inconsistency example detected by lemon it is a sketch map for layers neurons and connections indicates the accumulated inconsistent degrees of inconsistencies for all inputs under all dl library pairs for model m. ifacc mm is larger than acc ms we regard the mutated model mmas inconsistent degree amplifying.
intuitively if a seed model is rarely selected to mutate before we should give it a larger chance in order to increase the diversity of the generated models.
for a seed model si lemon records the number of times that sihas been selected to mutate denoted as ci and then calculates a score for si as shown in formula .
the larger the score of a seed model is the higher the chance that the seed model is selected for next mutation is.
score i ci according to the above intuition we design a seed model selection procedure based on roulette wheel selection .
more specifically for a seed model si lemon calculates the probability that siis selected for next iteration among all the seed models based on its score value.
the probability is defined in formula where ris the total number of seed models.
then lemon selects a seed model according to their calculated probabilities in each iteration.
pi score i r k 1score k .
.
mutation rule selection.
based on a selected seed model lemon then selects a mutation rule.
however different mutation rules may have different effectiveness in amplifying inconsistent degrees for a given seed model.
intuitively if a mutation rule has frequently generated models that amplify inconsistent degrees of inconsistencies it should be more likely selected for the following mutations.
therefore for each mutation rule mu lemon calculates its priority score denoted as ratio mu i.e.
the number of times a model generated by muamplifies inconsistent degrees of inconsistencies over the total number of times muis selected for mutations.
then mutation rules are ranked based on the descending order of their priority scores.
however it is not optimal to directly select the top mutation rule since the ranking results are acquired based on historical iterations and cannot totally representfuture results.
therefore each mutation rule should have certain possibility to be selected and in the meanwhile the mutation rule ranked higher should be selected with a larger possibility.
based on the above analysis the mutation rule selection is actually affected by the most recent behavior of mutation rules which makes it a typical markov chain mc .
assuming the desired distribution to be equilibrium distribution lemon adopts metropolis hastings mh algorithm the most popular markov chain monte carlo mcmc method to guide our mutation rule selection.
more specifically mh obtains random samples from a probability distribution which refers to sampling the next mutation rule denoted as mub based on the current mutation rule denoted asmua according to the proposal distribution in our context.
following the existing mcmc work we set the geometric distribution as the probability distribution.
it is the probability distribution of the number xof bernoulli trials needed to obtain one success.
if the success probability on each trial is p the probability thekthtrial being the first success is ps x k p k 1p.
since mutation rules are selected randomly the proposal distribution is symmetric.
therefore the possibility of selecting mubgiven mua is calculated by formula .
in this formula kaandkbare the rank ofmuaandmubin the ranking list of mutation rules.
in particular when ps mub ps mua pa mub mua .
please note that it is possible to select a mutation rule that cannot be successfully applied to the selected seed model lemon skips simply it.
pa mub mua ps mub ps mua p kb ka .
.
overall algorithm.
we formally describe our heuristic based model generation in algorithm .
the initial set of seed models only contains the given existing model and the initial priority score of each mutation rule is .
in this algorithm line randomly selects a mutation rule as the current one mua lines iteratively generate a set of mutated models and line outputs the final set of generated models.
lines conduct the roulette wheel selection process to select a seed model.
lines selects the next mutation rule mu bbased on the current one mua.
lines generate a new model mby applying mubtosand also addminto models .
lines judge whether mamplifies the accumulated inconsistent degrees for all inputs under all dl library pairs and updates the seed model set.
line updates the score ofsaccording to formula .
lines update the priority score ofmubaccording to the ratio defined in section .
.
and then re rank all the mutation rules for the next iteration.
.
test oracle in lemon following the existing work we also adopt differential testing as the test oracle to determine whether a bug in a dl library is detected.
more specifically lemon adopts d mad presented in section to measure the inconsistent degree between two prediction results.
lemon does not use d class since it aims to measure the differences on trained real models i.e.
models trained with real training data such that the ground truth class tend to have a high rank in the prediction result.
however lemon uses mutated models which may produce low ranked prediction results.
therefore thed class value is likely to be 0and thus not informative.esec fse november virtual event usa zan wang ming yan junjie chen shuang liu and dongdi zhang algorithm heuristic based model generation input rules a list of mutation rules seeds a list of seed models n the number of generated models serving as the terminating condition output models a set of generated models 1mua random rules 2while size models ndo foreach ifrom to size seeds do pro calprob seeds calculate the probability for seeds by formula end r random bound foreach ifrom to size seeds do bound bound pro ifr bound then s seeds sis the selected seed model break end end ka position mua do mrb random rules kb position mrb f random while f p kb ka m mutate s mub models models m ifacc m acc s then acc is defined in section .
.
to calculate the accumulated inconsistent degrees seeds seeds m end updatescore s update the score of sdefined in formula updateratio mub update the priority score of mu bdefined in section .
.
rules sort rules mua mub 30end 31return models after acquiring the inconsistent degree between two prediction results i.e.
the d mad value we determine whether a real inconsistency is detected.
following the existing work if the d mad value exceeds a threshold t we regard it as a real inconsistency otherwise the difference is considered to be caused by uncertain factors in deep learning.
in particular since lemon is designed to amplify the inconsistent degrees of inconsistencies it would be clearer to distinguish real bugs and uncertain impacts.
as shown in figure the inconsistent degree produced by the initial model under an input is only .
while that produced by our mutated model under the same input reaches .
.
moreover we manually checked the inconsistencies detected by the two models under the same input and found that both of them are caused by the same buggy layer.
that indicates that our model generation is indeed able to amplify the inconsistent degrees of inconsistencies and thus expose real bugs more effectively.
besides the above discussed inconsistencies there are still other two kinds of bugs.
if the prediction results of some libraries are nan not a number but those of other libraries are not a bug is detected obviously.
we call such bugs nan bugs .
if some models crash during execution but other models do not a bug is also obviously detected.
we call such bugs crash bugs .
to avoid confusion we usetable statistics information of dl libraries under test idtensorflow theano cntk mxnet ver sloc ver sloc ver sloc ver sloc e1 .
.
261k .
.
156k .
.
331k .
.
423k e2 .
.
970k .
.
155k .
.
328k .
.
378k e3 .
.
874k .
.
154k .
.
320k .
.
341k e4 .
.
829k .
.
154k .
.
313k .
.
300k e5 .
.
779k .
.
153k .
.
304k .
.
266k total 713k 773k 596k 708k the inconsistencies to represent the first kind of inconsistencies excluding nan and crash bugs in this paper.
evaluation in the study we address the following research questions rq1 how does lemon perform in detecting bugs in dl libraries?
rq2 does our heuristic based model generation contribute to lemon?
rq3 how does lemon perform in terms of efficiency?
.
libraries and datasets libraries .
as presented in section in the study we used four widely used dl libraries i.e.
tensorflow cntk theano and mxnet as subjects.
to sufficiently evaluate the effectiveness of lemon we used 20release versions of the four libraries in total.
based on the 20versions we constructed five experiments indexed e1to e 5in table to conduct differential testing.
in this table each row represents each differential testing experiment and columns ver and sloc present the library version and the corresponding number of source lines of code.
in our study the total sloc of all studied libraries is up to about million.
in particular the first experiment i.e.
id is e is based on the latest release versions of the four libraries.
we used keras version .
.
as the front end i.e.
the high level library to construct models.
due to limited space we used tf th cn and mx to represent tensorflow theano cntk and mxnet in the following tables and figures.
models and datasets.
to test these dl libraries we used 12popular dl models based on 6popular input sets as the initial seed models in lemon which have been widely used in many existing studies .
in particular we considered the diversity of the models and input sets adopted by considering the model structures including both cnn and rnn models the scales of models including both large and small models in terms of the number of weights and layers in a model and the domains of input sets including both images and sequential data .
here sine wave and stock price are sequential data where the former is a set of sinefunction values and the latter is a set of disneyland stock price data between and .
table shows their detailed information.
for each model we randomly sample 500inputs from the corresponding validation set as the input data in our study.
we can observe that the number of layers ranges from 3to159and the number of weights ranges from 27k to more than 143million which indicates an extremely large mutation space.
please note that we directly loaded weights from keras for models trained with imagenet and trained the otherdeep learning library testing via effective model generation esec fse november virtual event usa table statistics information of datasets id model input set weight layer domain net.
alexnet cifar 251k image cnn lenet5 fashion mnist 413k image cnn lenet5 mnist 62k image cnn lstm sine wave 71k sequential rnn lstm stock price 27k sequential rnn resnet50 imagenet 637k image cnn mobilenetv1 imagenet 254k image cnn inceptionv3 imagenet 852k image cnn densenet121 imagenet 063k image cnn vgg16 imagenet 358k image cnn vgg19 imagenet 667k image cnn xception imagenet 910k image cnn lstm and lstm are two different lstm based models trained with sequential data.
models using their provided source programs and corresponding training sets respectively.
.
measurements number of inconsistencies .
we denote an inconsistency between two libraries liandljproduced by a model munder an input i as a triple m i li lj .
since we aim at testing the low level libraries the input triggering the library executions involves both m andi tom .
therefore we use a tuple m i to denote a libraryinvoking input .
since the mutation rules tend not to change a model behavior in a large manner we assume that the inconsistencies exposed by the library invoking inputs m1 i m2 i .
.
.
mn i where m1 m2 .
.
.
mnare mutants from the same initial model on the library pair li lj are likely to reflect the behavior difference between liandljin the same way.
therefore we keep only one inconsistency among them and use the inconsistency with the largest inconsistent degree as the representative which also avoids the influence of equivalent mutants.
in this way we keep the inconsistencies that can reflect library behavior differences in different ways to a large extent.
we count the number of these inconsistencies as a measurement in our study.
similar to spectrum based fault localization sbfl and automated program repair apr more failure triggering tests referring to library invoking inputs that trigger inconsistencies in our work reflecting a fault in different ways are more helpful to increase the suspicious score of the root cause program element in sbfl and filter plausible patches in apr.
therefore the number of inconsistencies is able to measure the effectiveness of lemon to some degree.
larger is better.
number of detected bugs .
although we acquire the number of inconsistencies it is more important to acquire the number of unique bugs detected by lemon from these inconsistencies.
according to the voting mechanism in differential testing the buggy library for each inconsistency can be identified.
then for each inconsistency we used the localization method presented in section to locate which layer is the most suspicious one to cause the inconsistency.
since the localization method has been demonstrated to be very effective in the existing work we use the localized top layer as the root cause.
here we use a tuple the voted buggy library the localized buggy layer to denote a unique bug.
since the measurements including the localization method and the threshold for identifying an inconsistency may not be completely precise we further manually check each bug by building a one layer modelthat keeps the same parameters of the identified layer to check the result under the same layer input for different libraries.
actually the rate of false positives for lemon is very small i.e.
less than .
in our experiment we count the number of bugs after manual analysis to measure the effectiveness of lemon.
.
compared approaches the state of the art approach to testing dl libraries is cradle which is proposed by pham et al.
.
the main contribution of cradle is the test oracle i.e.
cradle adopts differential testing to detect inconsistencies based on existing models.
lemon on the other hand focuses on model generation i.e.
lemon proposes to generate effective models via guided mutation to trigger and expose inconsistencies to a large extent.
the contributions of the two approaches are actually orthogonal.
since the number of generated models can be very large and collecting the same number of existing models is scarcely possible it is hard to directly compare lemon with cradle.
alternatively for each given existing model i.e.
initial model we analyzed how many inconsistencies bugs detected by lemon are only detected by the initial model and how many inconsistencies bugs detected by lemon are only detected by the models mutated from the initial model.
besides our heuristic based model generation is the core of lemon and thus it is also interesting to investigate the effectiveness of this component.
we compared lemon with its variant that replaces the heuristic based model generation with the random model generation.
more specifically the random model generation is to generate models via mutation without any guidance i.e.
randomly selecting a seed model and a mutation rule in each iteration.
we call this invariant lemon r. .
implementations and data availability we set the threshold tto be .
indicating that an inconsistency is regarded as detected when the value of d mad exceeds .
.
this setting is relatively large so as to avoid introducing too many false positives which is also confirmed by our manual analysis.
for the terminating condition of lemon when the number of mutated models reaches for a given initial model we terminate lemon.
following the setting of pin the mh algorithm we set pto be0.
.
our study is conducted on the intel xeon e5 machine with 128gb ram ubuntu .
.
lts and two gtx ti gpus.
our tool and experimental data are publicly available at our project website .
results and analysis .
effectiveness of lemon .
.
new bugs detected by lemon.
we first investigated the effectiveness of lemon in terms of new bugs detected in the latest release versions of libraries i.e.
versions used in e1 whose results are shown in table .
in total lemon detects new bugs in the latest release versions of these libraries including bugs by analyzing the detected inconsistencies crash bugs nan bugs and performance bug.
more specifically there are tensorflow bugs theano bugs cntk bugs mxnet bugs and surprisingly keras bug the used front end in our study indicating that lemon is able to detect bugs for all the studied libraries.
in particular 7esec fse november virtual event usa zan wang ming yan junjie chen shuang liu and dongdi zhang table the number of new bugs detected by lemon library ic bugs crash nan total tensorflow theano cntk mxnet keras performance bug ic is short for inconsistency and ic bugs refer to the bugs analyzed from inconsistencies.
the last cell refers to the total number of new bugs detected by lemon on all the five libraries.
mxnet tshape out shp out attrs mxnet tshape ret shp.ndim check le shp.ndim t ranspose support at most d imensions ...... check eq std max shp.ndim out shp.ndim param.axes .ndim check eq shp.ndim param.axes.ndim figure the fix of the buggy transpose operator in mxnet bugs have been confirmed in the corresponding issue repositories and one bug has been fixed by developers.
the average number of generated mutants is .
for each detected bug.
more specifically there are five bugs that are detected by generating less than mutants while there are also three bugs that are detected by generating more than mutants.
the average time spent on generating and running these mutants for each detected bug is .
hours.
we then conducted case analysis according to bug types crash bugs.
we regarded the crash bugs with different crash messages as different crash bugs.
one crash bug has been fixed by developers which occurs in mxnet.
this bug cannot be detected by any initial models but is detected by the mutated models from six initial models i.e.
alexnet densenet121 lenet5 f lenet5 m mobilenetv1 and xception showing a large scale influence.
more specifically the crash bug is due to the wrong shape inference of the transpose operator in mxnet whose fix is shown in figure .
the buggy transpose operator only relies on the input tensor for shape inference causing to throw the exception message check failed shp.ndim param.axes.ndim vs even if the model is valid.
the fixed transpose operator uses both the input tensor and output tensor and thus is able to infer all unknown dimension sizes based on these tensors.
bugs from inconsistencies.
the bugs from inconsistencies involve different types of layers including lstm conv2d batchnormalization dense depthwiseconv2d maxpooling2d averagepooling2d in different libraries.
by taking a theano bug as an example for a mutated model from lenet5 fthis bug leads to the accuracy of the mutated model using theano to be .
while the accuracy of the mutated model using the other three libraries is larger than .
indicating the significant influence of this bug confirmed by developers.
we find that the rvalue of the conv2d layer is .
between theano and tensorflow while the maximum rvalue of all the other layers is only .
indicating that conv2d is the localized root cause.
by taking a tensorflow bug as another example among input images for xception theano and cntk have the same prediction results but tensorflow has different results for images.
theroot cause of this bug is identified as the batchnormalization layer i.e.
wrong values of the variables moving mean andmoving var .
another user also replies to our bug report to complain that they suffered from this bug for transfer learning.
nan bugs.
as shown in table lemon detects nan bugs in three libraries.
by taking a theano nan bug as an example for a mutated model from mobilenetv1 the output using theano is nan while that using cntk is normal confirmed by developers.
in particular for the initial model mobilenetv1 the outputs of both theano and cntk are normal.
that demonstrates that our mutation rules are effective to make the calculation process trigger nan bugs.
further we analyzed the output of each layer of this mutated model using theano and find that at the 17thlayer a batchnormalization layer its output starts to be nan.
moreover the outputs of the first layers for the model using theano and cntk are the same.
that indicates that the root cause of this nan bug lies in the batchnormalization layer of theano.
we also find an interesting nan bug in mxnet.
for a mutated model from mobilenetv1 the output using mxnet is nan while that using cntk is normal and in the meanwhile both of them have normal outputs for the initial model mobilenetv1 .
we then analyzed the output of each layer of the mutated model using mxnet but surprisingly no nan happens.
actually directly obtaining the prediction result used in lemon and obtaining the prediction result by getting the output of each layer are two equivalent ways but uses different keras interfaces.
the former calls the interface predict while the latter calls the output attribute of each layer.
moreover the former outputs nan while the output of the latter is normal.
we infer that the root cause of this nan bug is in the interface i.e.
predict between keras and mxnet and we have submitted a bug report for it and are waiting for responses.
performance bug.
lemon also detected an interesting performance bug in keras.
when conducting model mutations in lemon lemon has to repeatedly call the keras functions clone model andset weights but the time spent on each single call becomes longer.
clone model andset weights take about seconds and seconds in the first iteration and the time grows to about seconds and minutes respectively in the 50thiteration.
by a detailed observation we find that the bug is caused by memory leak and this performance bug is detected during the mutation process of lemon thus only using initial models cannot detect this bug which has also been confirmed.
.
.
mutated models v.s.
initial models.
one major contribution of lemon is generating mutated models and thus it is interesting to investigate the unique value of the mutated models.
we present the detailed results in table .
here we investigated the effectiveness of lemon and the unique value of the mutated models for each experiment of differential testing each used model and each studied library respectively.
for example the first number of the third row in table represents the number of tensorflow bugs detected by lemon using the model alexnet in experiment setting e .
from column total in table we find that lemon is able to detect bugs in each library at each differential testing experiment and on average the number of detected library bugs by lemon is 22for the five experiments which demonstrates the effectiveness of lemon.deep learning library testing via effective model generation esec fse november virtual event usa table detailed comparison results in terms of the number of detected bugs id libalexnet densenet inception lenet5 f lenet5 m lstm lstm mobilenet resnet5 vgg16 vgg19 xception total l m i l m i l m i l m i l m i l m i l m i l m i l m i l m i l m i l m i l m i e1tf th cn mx e2tf th cn mx e3tf th cn mx e4tf th cn mx e5tf th cn mx column l presents the number of detected bugs by lemon column m presents the number of unique bugs that are detected by the mutated models but are not detected by the initial model and column i presents the number of unique bugs that are detected by the initial model but are not detected by the mutated models.
lenet5 frefers to the lenet5 model based on the fashion mnist input set lenet5 mrefers to the lenet5 model based on the mnist input set densenet refers to densenet121 mobilenet refers to mobilenetv1 and inception refers to inceptionv3.
table average inconsistent degree comparison for the detected inconsistencies lib paire1 e2 e3 e4 e5 vm vi rate vm vi rate vm vi rate vm vi rate vm vi rate tf th .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
tf cn .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
th cn .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
tf mx .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
th mx .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
cn mx .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
columns v m and v i present the average inconsistent degrees achieved by the mutated models and the initial models across all the used models respectively.
column rate presents the average improved rates of inconsistent degrees achieved by the mutated models over the initial models.
please note that the bugs detected at different differential testing experiments could be duplicate since some detected bugs have been hidden for a long time.
besides among all the cases models differential testing experiments the mutated models are able to detect at least one unique bug in .
out of cases shown in columns m while the initial models detect only one unique bug in only one case shown in columns i which is also detected by the mutated models in other cases.
therefore the results demonstrate the unique value of the mutated models and the bugs detected by the initial models are a subset of the bugs detected by the mutated models.
overall from the detailed results we conclude that regardless of which initial models are used as seed models of lemon lemon does detect a number of bugs including a large proportion of unique bugs largely augmenting the testing capability of the existing models which are the models used in cradle.
.
.
comparison of inconsistent degrees.
to investigate the reason for the superiority of the mutated models we further evaluated whether the mutated models can amplify the inconsistent degrees compared with the initial models which is an objective of our heuristic strategy.
we compared the inconsistent degrees for thedetected inconsistencies for this purpose.
if an inconsistency is detected by either an initial model or the corresponding mutated models using the same input and library pair we compared the inconsistent degrees of the inconsistency between them.
table shows the average results across all the used models for each library pair and each differential testing experiment.
from this table for all the library pairs and all the differential testing experiments lemon indeed significantly amplifies the inconsistent degrees of the inconsistencies successfully achieving its objective.
in particular the average improved rates of inconsistent degrees achieved by the mutated models over initial models range from .
to .
for different library pairs and differential testing experiments.
the results demonstrate that lemon is able to effectively amplify the inconsistent degrees by generating mutated models from initial models which contributes to expose the inconsistencies bugs more effectively.
.
lemon v.s.
lemon r the heuristic based model generation method is one of the main contributions of lemon and thus we further investigated the effectiveness of the heuristic based model generation method comparedesec fse november virtual event usa zan wang ming yan junjie chen shuang liu and dongdi zhang table comparison between lemon and lemon r lib pair only mutated only initial rate lemon lemon rlemon lemon rlemon lemon r tf th .
.
tf cn .
.
th cn .
.
tf mx .
.
th mx .
.
cn mx .
.
columns present the total number of inconsistency only detected by the mutated models generated by lemon or lemon r not detected by initial models across all the models.
columns present the total number of inconsistency only detected by the initial models not detected by mutated models .
column present the average improved rates of inconsistent degrees achieved by the mutated models over initial models.
with the random generation method lemon r. we adopted the library versions used in e 2as the representative.
more specifically for each initial model we ran lemon and lemon rin the same time period i.e.
one hour to test the four libraries for fair comparison.
we repeated the process five times and calculated the average results to reduce the impact of randomness.
due to the cost of identifying the root cause layer we compared lemon and lemon rin terms of the number of detected inconsistencies.
in particular the larger number of detected inconsistencies tends to mean the larger number of detected bugs which have been demonstrated based on the results in section .
.
table presents the comparison results between lemon and lemon r. from this table we find that compared with lemon r the models generated by lemon detect more unique inconsistencies which are missed by the initial models on almost all the library pairs.
the total number of inconsistencies that are only detected by the initial models and missed by lemon is much smaller than that missed by lemon r. moreover the average improved rate of inconsistent degrees achieved by lemon is always larger than that of lemon rfor each library pair.
the results demonstrate that both lemon and lemon rare able to detect many unique inconsistencies that cannot be detected by the given initial models.
lemon detects more than lemon r. lemon ralso misses many inconsistencies detected by the initial models.
we also find that lemon achieves larger improved rates of inconsistent degrees over initial models than lemon r. the reason is that lemon r does not guide the generation of models towards the direction of amplifying inconsistent degrees and thus it is more likely to diminish inconsistent degrees than lemon.
the evaluation results confirm the contribution of the heuristic based model generation method in lemon.
.
efficiency of lemon we also analyzed the efficiency of lemon.
due to the design of our mutation rules carefully considering the input shape and output shape lemon does not generate invalid models.
on average lemon spent .
minutes at each iteration for each given initial model.
more specifically the average time spent on generating a mutated model by lemon is only .
minutes and the average time spent on running all the inputs for a model is .
minutes.
the results demonstrate the efficiency of lemon which facilitates it to be applied in practice.
discussion .
extensions of lemon lemon can be potentially extended on three aspects.
first the current lemon cannot test the library code used for model training since it uses existing pre trained models as seed models and conducts mutations at the model level without retraining.
in the future lemon can be extended to consider mutation rules at the source level which involve the model retraining process and conducts differential testing in the same way.
second lemon adopts differential testing to solve the testoracle problem in dl library testing but it could miss bugs if different libraries produce the same wrong results.
to get rid of this limitation it is promising to introduce metamorphic testing for lemon to help solve the test oracle problem since metamorphic testing does not require different libraries and detects bugs based on the properties of one library.
third dl library testing relies on both models and the input data of the models.
if an effective model does not have proper input data the testing capability of the model cannot be fully manifested.
currently lemon aims to generate effective models to detect library bugs and does not consider the impact of the input data.
in the future we will further explore what kind of input data is helpful to show the testing capability of a specific model generated by lemon as sufficiently as possible.
.
threats to validity the internal threat to validity mainly lies in the implementations of lemon and our scripts in the study.
to reduce this threat two authors have carefully checked the code before submission.
the external threats to validity mainly lie in the used libraries and models in our study.
we adopted four widely used libraries i.e.
tensorflow theano cntk and mxnet as subjects but they may not represent other libraries such as pytorch.
we chose the four libraries since they are supported by the same front end keras while pytorch is not and the current implementation of the mutation rules in lemon only supports the models using the keras front end.
however lemon is a general approach and it can be used to test pytorch by just re implementing the mutation rules in lemon to support the models using pytorch which is also our future work.
to reduce this threat we used 20different release versions of the four libraries in total.
we also try to use a diverse range of model families 12popular models based on 6input sets which have different model structures in order to trigger more library behaviors.
the construct threats to validity mainly lie in randomness settings and measurements in our experiment.
to reduce the impact of randomness in our study we constructed five differential testing experiments instead of repeating each experiment several times.
when comparing lemon and lemon r we set the same time limit i.e.
one hour for each initial model using only one experiment and thus we repeated each approach five times and calculated the average results to reduce the impact of randomness.
the threats from the settings e.g.
the threshold t and measurements have been discussed in sections .
and .
.
to further reduce them we reported bugs to the corresponding bug repositories and some have been confirmed fixed and some are still waiting for responses.deep learning library testing via effective model generation esec fse november virtual event usa related work deep learning testing .
the most related work to ours is cradle proposed by pham et al.
which has been discussed before.
besides zhang et al.
and islam et al.
conducted empirical studies to investigate the characteristics of dl source program bugs.
different from them our work proposes a novel approach to testing dl libraries via effective model generation.
besides there are some work focusing on testing machine learning ml libraries .
for example dwarakanath et al.
adopted metamorphic testing to test ml libraries by conducting transformations on training and testing data.
different from them our work focuses on testing dllibraries and proposes to generate effective dl models.
furthermore there are a great deal of researches focusing on testing dl models in the literature .
many of them proposed criteria to measure test adequacy .
for example ma et al.
proposed a set of multigranularity testing criteria including neuron level and layer level coverage criteria for dl models.
besides many of them proposed to find generate adversarial inputs .
for example xie et al.
proposed deephunter a fuzz testing framework to test dl models which conducts semantic preserving transformation for input of the models under test and uses coverage criteria to guide the fuzzing process to find issues in models.
different from them our work focuses on testing dl libraries rather than dl models.
mutation testing .
our work is also related to mutation testing which is one of the most effective methods to measure test suite quality.
mutation testing has been extensively studied in traditional software systems .
recently in the area of dl testing ma et al.
proposed a mutation testing framework for dl models.
wang et al.
proposed to detect adversarial inputs for dl models by mutating models based on the observation that adversarial inputs are more sensitive than normal inputs in mutated models.
different from them our work aims to test dl libraries by generating effective models via mutating existing models.
that is the mutated models serve as input of dl libraries rather than the subjects under test.
conclusion in this paper we propose a novel approach lemon to testing dl libraries by generating effective dl models via guided mutation.
more specifically we design a series of model mutation rules in lemon to generate dl models by changing existing models.
the design goal is to test dl libraries as sufficiently as possible by exploring unused library code or different usage ways of library code.
we further propose a heuristic strategy in lemon to guide the process of model generation so as to generate models that can amplify the inconsistent degrees for real bugs.
in this way it is clearer to distinguish real bugs and uncertain impacts in dl libraries.
we conducted an empirical study to evaluate the effectiveness of lemon based on 20release versions of tensorflow theano cntk and mxnet.
lemon detected new bugs in the latest release versions of these libraries.
the results also demonstrate that the models generated by lemon outperform existing models and the models generated without guidance in terms of the number of unique bugs inconsistencies and the achieved inconsistent degrees.acknowledgement this work has been supported by the national natural science foundation of china u1836214 and intelligent manufacturing special fund of tianjin .