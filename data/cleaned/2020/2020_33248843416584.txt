metamorphic object insertion for testing object detection systems shuai wang the hong kong university of science and technology shuaiw cse.ust.hkzhendong su eth zurich zhendong.su inf.ethz.ch abstract recentadvancesindeepneuralnetworks dnns haveledtoobject detectors ods that can rapidly process pictures or videos and recognize the objects that they contain.
despite the promising progress by industrial manufacturers such as amazon and google in commercializing deep learning based ods as a standard computervisionservice ods similartotraditionalsoftware may still produce incorrect results.
these errors in turn can lead to severe negative outcomes for the users.
for instance an autonomous drivingsystem thatfails todetect pedestrianscan causeaccidents or even fatalities.
h owever despite their importance principled systematic methods for testing ods do not yet exist.
tofillthiscriticalgap weintroducethedesignandrealizationof metaod ametamorphictestingsystemspecificallydesignedfor odstoeffectivelyuncovererroneousdetectionresults.tothisend we synthesize natural looking images by inserting extra object instancesintobackgroundimages and designmetamorphicconditionsassertingtheequivalenceofodresultsbetweentheoriginal and syntheticimagesafter excludingthe predictionresults onthe insertedobjects.metaodisdesignedasastreamlinedworkflow that performs object extraction selection and insertion.
we develop a set of practical techniques to realize an effective workflow andgeneratediverse natural lookingimagesfortesting.evaluated onfourcommercialodservicesandfourpretrainedmodelsprovided by the tensorflow api metaod found tens of thousands of detection failures.
to further demonstrate the practical usageof metaod we use the synthetic images that cause erroneousdetection results to retrain the model.
our results show that the model performance is significantly increased froman map score of .
to an map score of .
.
ccs concepts softwareanditsengineering softwaretestinganddebugging securityandprivacy softwareandapplicationsecurity computing methodologies neural networks most of the work was done when shuai wang was working at eth zurich.
permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation on the first page.
copyrights for components of this work owned by others than acmmustbehonored.abstractingwithcreditispermitted.tocopyotherwise orrepublish topostonserversortoredistributetolists requirespriorspecificpermissionand ora fee.
request permissions from permissions acm.org.
ase september virtual event australia association for computing machinery.
acm isbn ... .
testing computer vision object detection deep neural networks acm reference format shuai wang and zhendong su.
.
metamorphic object insertion for testing object detection systems.
in 35th ieee acm international conference on automated software engineering ase september virtual event australia.
acm new york ny usa 13pages.https introduction deep learning based object detectors ods identify objects in a givenimageusingconvolutionalneuralnetworks.currently several major industrial manufacturers including google amazon microsoft andlockheedmartin arebuildingandimprovingodsto serve as the basis for various computer vision tasks.
these models arewidely usedinreal worldapplications suchasopticalcharacter recognition ocr robotics machineinspection andpedestriandetection in autonomous cars.
they are also used as an initial step in surveillance and medical image analysis applications which often require highly precise and reliable detection results.
despite this spectacular progress however de ep learning based ods similartotraditionalsoftware canyielderroneouspredictionresultsthatarepotentiallydisastrous.inparticular giventhe widespread adoption of ods in critical applications in the security medical andautonomousdrivingfields incorrectorunexpected edge case behaviors have caused severe threats to public safety or financialloss .forinstance inoneinfamouscasein2016 tesla s autopilot mode caused a fatal crash when the autonomous driving system failed to recognize a white truck against a bright sky .morerecently anuberautonomouscarkilledapedestrian crossing the road which is believed to have been due to its failure in recognizing a pedestrian in dark clothing .
inrecentyears anumberoftechniqueshavebeendesignedto testdeeplearningsystems includingbothconvolutionalneuralnetworks cnn andrecurrentneuralnetworks rnn models .
thetechniqueshavealsobeenappliedtotestdomain specificapplicationssuchasautodrivingsystems andtotestthe underlying infrastructure of deep learning libraries .
however the principles specific for testing ods have not been investigatedsystematicallybyexistingresearch which thus unlikely results in comprehensive systematic testing of ods.
thispapertacklesthisimportantproblembyintroducingametamorphictesting framework metaod tospecificallyand effectivelyexposeerroneouspredictionsofods.givenarealimageasthe background metaodinsertsanobjectinstanceinto the background generates a synthetic image and then employsa metamorphic condition to check the consistency of od results betweenthesyntheticimageandthecorrespondingbackground.to 35th ieee acm international conference on automated software engineering ase effectively generate diverseandnatural looking images that trigger practicalprediction errors metaod is designed as a three step approach performing object extraction object refinement selection andobjectinsertion.theobjectextractionmoduleextractsobject instanceimagesfromalargesetofpicturesusingadvancedinstance segmentationtechniques thusaggregatingmanyobjectsets distinguished by category.
then given a background image the objectrefinement selectionmoduleimplementsasetoflightweight albeiteffective criteriaforselectingcertainobjectsfromobjectsets thatare closelyrelatedtothe background.todetermineinsertion locations the object insertion module uses domain specific criteria andtechniquesinspiredbydeltadebugging tofindlocations thatpresumablytriggerpredictionerrors whileretainingrealism and diversity of the synthetic images.
theproposedworkflowiseffectiveandshowspromisingresults when evaluated on four commercial ods provided by amazon google ibm and microsoft and four pretrained od modelsprovidedbythetensorflowapi .ourtestingrevealed tens of thousands of erroneous od outputs from these popular commercial services.inaddition weretrainedanodmodelusing syntheticimagesthatcausethismodeltooutputerroneousoutputs.
the evaluation results show that the model performance improved substantially after retraining.
in summary this work makes the following main contributions weintroduceanovelmetamorphictestingapproachforods vital components in various computer vision applications e.g.
self drivingcars .ourtechniquetreatsodsas blackboxes .thus itishighlygeneralizablefortestingreal world ods such as remote services on the cloud.
togeneratediverseandnatural lookingsetsofimagesasthe test inputs we design and realize metaod a streamlined workflow that performs object extraction object refinement selection andobjectinsertiontosynthesizeinputimages in an efficient and adaptive manner.
our approach tests ods in a realisticsetting and delineates thecapabilitiesof state of the artcommercialods.
froma total of input images metaod found erroneousdetectionresultsineightpopular commercial ods.
byleveragingsyntheticimagesthattriggererroneousod outputs for retraining we show that the performance of od models can be substantially improved.
wehavereleased metaodongithub .allofour erroneous detection results can be found at .
background of object detection techniques object detection is conventionally addressed using handcrafted featuresandselectiveregionsearches .theinputimages are dissected into small regions each region is called a regionproposal and is likely to contain an object via heuristics .
then featuresareextractedfromeachregionproposalforobject classification.todate twomajorlinesofresearch popularmod els proposed in both line of research are tested in this work seesec.
exist that have drastically improved od techniques with deep learning both of which are briefly introduced below.
two stageregion basedods.
motivatedbytheprimarysuccess in applying dnns for image classification rcnn was figure typical two stage od architectures illustrated by the simplified fast rcnn workflow.
figure2 typicalsingle stageodarchitecturesillustratedby the simplified yolo workflow.
among the first to apply cnn for building ods.
the proposed techniqueformsatwo stagepipelineinwhicheachregionproposal extracted from the input image is an input to cnn for feature extraction.then theextractedfeaturesareforwardedtoansvm classifier and a bounding box regressor to determine the object category and bounding box offsets respectively.
since then od research has focused on rapidly evolving the rcnnarchitecture andremovingexplicitdependence on region proposals to improve speed.
fast rcnn introduced amodern end to end predictionpipeline.asshowninfig.
instead ofregionproposals theentireimageisforwardedtothecnnto generate a convolutional feature map and region proposals areextracted from the feature map first stage .
a region of interest roi poolinglayerisplacedbeforethefullyconnectedlayer fc to reshape each proposal into a fixed size and fc layer s outputs are fedtosoftmaxandbboxregressorlayersforobjectclassificationand for determining bounding box offsets respectively second stage .
single stage ods.
two stage ods use regions explicitly or implicitly for object localization.
another line of research aims to proposeacost effectivesolutionwithoutregionproposalsbydesigning a single stage feed forward cnn network in a monolithic setting.
such networks are usually less computationally intensive by trading precision for speed and are usually more suitable for real time tasks or for use in mobile devices.
the yolo you only look once and ssd single shot detector models are de facto ods that feature single stage architectures.
fig.
2depicts the yolo workflow in which input images are first divided into an s sgrid then a fixed number of bounding boxes are predicted within each grid.
for each bounding box the network outputs a class probability and the bounding 1054box offsets.
a bounding box is deemed to contain objects when its classprobabilityexceedsathresholdvalue.theentirepipelineis typically orders of magnitude faster than region based techniques.
indeed theobjectextractionmoduleof metaod seesec.
.
is built on top of yolact a real time instance segmentation model that was inspired by yolo.
in general given a well trained model region proposal based objectdetectiontechniquescanusuallyachievehighperformances incontrast a unified pipelinessuchasyoloandssdachievehighdetectionefficiencybytradingprecisionforspeed.whileprecision may often be the highest priority unified models have also been commonlyadopted particularlyformobile wearabledevicesand analyzing videos wher espeedis critical.
approach overview metamorphictesting mt hasbeenwidelyusedtoautomatically generateteststodetectconventionalsoftwarefaults and dnn prediction errors .
the strength of mt lies in its capability to alleviate the test oracle problem via metamorphic relations mrs .eachmrdepictsnecessarypropertiesofthetarget software in terms of inputs and their expected outputs.
even if the correctnessofactualoutputsaredifficulttodetermine itispossible to construct and check proper mrs among the expected outputs ofthegiveninputs todetectsoftwaredetects.inthisresearch we applymetamorphictestingtood.toprovideanapproachoverview we start by formulating relevant notations.
byfeedingatestimage itoanod d thepredictionoutputisdenotedasd whichconsistsof nthree elementtuples bk lk ck wherendenotesthenumberofobjectsrecognizedin i bkthelocation of the kth object recognized in i lkthe category label and ck theconfidencescoreoftheprediction.then givenasetofobject instance images oextracted from a large number of real images see fig.
.
and a set cwhere each c cis a d coordinate x y ini a synthetic image i primecan be represented as i prime c o i o oandc c whereois placed such that its cendroid is at the d coordinate specified by c. note that in this research we do notapply any transformationrules rotation blurring etc.
ontheinsertedobjects to preserve realism at our best effort and c cis deliberately constructedsuchthattheinsertedobject odoesnotoverlapwith preexisting objects in the background image i. therefore the mr adopted in this research can be formalized as follows c c o o.e d d bo lo co wherei prime c o i .
here we exclude the prediction result on o i.e.
tuple bo lo co f r o md and eis a criterion asserting theequalityofodresults seesec.
.
.thegivenmrisdefined suchthatnomatterhowtheimage i primeissynthesizedbyinserting anadditionalobject ooni theodresultsareexpectedtobeconsistentwiththoseintheoriginalimage.consequently erroneous predictions can be revealed by checking the failure of this mr. whilethegivenmrholdsforanysyntheticimage i prime c o i one practical challenge is that not all the synthetic images representreal worldscenarios.indeed thereexistsresearchinthecv communitywhereunrealisticimagesaresynthesizedtotrainimageanalysis models for example by placing a car on the table .
while the synthetic unrealistic images may fulfill the requirement of model training we aim to also augment the realism of the synthetic images such that flagged erroneous behaviors unveil practical defects that can cause confusion during daily usage of ods.additionally aswewillexplaininsec.
.
randomlydeciding a position for insertion without considering preexisting objects positions in the background would undermine the effectiveness of the proposed technique.
therefore in this research we gather o prime osuch that o prime containsobjectinstanceimagesthatarecloselyrelatedtothebackground image i see sec.
.
.
we also form favorable insertion locations c prime clikelytotriggerpredictionerrorsbyleveraging empirical evidence and strategies inspired by delta debugging see sec.
.
.
hence the mr is modified as follows c c prime o o prime.e d d bo lo co in all an od system failure indicates a wrong prediction over synthesized image i primew.r.t.
its reference image i i.e.
the ground truth consistentwithexisting seresearchontestingdeepimage classifiers e.g.
.
.
equality criteria assertingthe equalityofodoutputs i.e.
nthree elementtuples bk lk ck istoostrictbecauseboundingboxesofcertainobjects couldslightlydriftwithineachroundofprediction.thecvcommunityinsteadusesastandardmetric averageprecision ap to compensate small localization drifting when measuring ods.
theapscoreiscomputedbytakingboth precision and recall values into account as we will explain soon.
tocomputeap intersectionoverunion iou isusedtomeasure eachobjectdetectionboundaryw.r.t.thegroundtruth.asshown infig.
ioumeasurestheoverlapbetweentwoboundingboxes withthesamepredictionlabel i.e.
elephant anddenoteshow muchthepredictedboundaryoverlapswiththegroundtruth.incase iou is greater than a threshold e.g.
.
the prediction is atruepositive.theprecisionandrecallscoresarethencomputed bytakingallthepredictionresultsintoaccount andtheapscore can be derived by computing the area under the precision recallcurve .
for an image with objects of different categories mean ap map is further computed by averaging all ap scores.
our equality criteria eis derived from map.
in our setting the predictionresultsofthe background image ientailstheground truth and are compared with detection results of the synthetic imagei prime c o i .sinceodoesnotoverlapwithexistingobjectson i and therefore doesnotinterferewithrelevantpredictions the map score is expected to be .
thus eis defined as follows e d d bo lo co doteq map d d bo lo co todate multiplevariantsofthestandardmapdefinitionexist.
weadoptoneofthemostpopularmapcalculationmethods the pascal voc metric in our implementation.
.
case study of od failures edefinedinsec.
.1enablesaunifiedapproachtocheckodfailures itisimagecontentagnosticandthereforecanbeautomatically figure3 oderrorsfoundbymetaod.weslightlycherrypickedimagesinfavorofreadability.browsethefullresultsat .
the inserted objects are pointed by blue arrows.
to preserve realism of the synthetic images at our best effort the inserted objects are resized to the average size of existing objects of the same category.
see our discussions in sec.
.
.
figure intersection over union iou .
conducted.
from a holistic perspective the following categories of od defects can be found by asserting e recognition failures represent errors which treat an arbitraryregionontheimagecontainingnoobjectasan object or fail to recognize an existing object.
classification failures represent labeling errors for instance labeling a human being as a bird.
localization failures representthefailurewheretheod usesatoolargeortoosmallboundingboxtolocalizeobjects.
asillustratedinfig.
toolargedriftings iou onthe bounding box are not allowed.
nevertheless after manually checking od failures found by metaod we only find recognition failures.1metaod has successfullyfoundalargenumberofodfailuresbyeightpopularods see table2 .
fig.3reports three cases where the background images on the first row are from the berkeley deepdrive dataset 1wefoundover28kimagestriggeringoderrors reportedinsec.
.wemanually checkedabout800imagesbyre queryingtheremoteserviceswiththeerrortriggering images and screened the detection outputs.andthecocodataset .imagesonthesecondrowaregeneratedbyinsertingoneextraobjectontheircorrespondingreference background.
by inserting extra objects indicated by the blue arrows into thebackgroundandcheckingtheequalitycriteria e sec.
.
we wereabletouncovermanydetectiondefects.thefirstcolumnin fig.3illustrates a recognition failure indicated by the red arrows where a bike rider and several cars in the traffic scene image could notberecognizedafteranewvehiclewasinserted.similarly the synthetic images in the second and third columns unveil detection failures where after inserting one extra object into imagesof real world scenes existing objects moon and frisbee cannotbe recognized.
we note that fig.
3demonstrates the diversity in theissueswefound metaodsynthesizestestimagesof different scenes and therefore can find a broad set of defects.
in contrast existing relevant efforts primarily transform or synthesize imagesofonlydrivingscenes seesec.
.
.also wenotethatwhile thesyntheticimagesreasonblyrepresentreal lifescenes making insertedobjects fullyconsistentwitharbitrarybackgrounds couldbe extremely challenging if at all possible.
see our further evaluation and discussion on this matter in sec.
.3and sec.
.
.
application scope it is worth noting that we are nottesting extreme cases to stress ods .
apparently we can synthesize images that are highly challenging to human beings and therefore challenging to odsas well for instance by tweaking the contrast of objects and its background .therefore whileinthisresearchweproposeaset of techniques toselect realistic objects for insertion see sec.
.
and sec.
.
we still define a conservative test oracle such that we excludethe prediction over the newly inserted object and check only the consistency of the remaining predictions.
figure workflow of metaod.
metaod is designed as a general framework to treat ods as black boxes.whiledefactoimplementationsofods arecurrently all on the basis of dnn metaod could also be used to assess the performance of ods based on other techniques.
in addition existing approaches on testing computer vision models applypredefined severeweatherconditions e.g.
foggyandrainy to transform or directly synthesize entire images.
they are not tailoredtopinpointingodfailures andareconceptually orthogonal to the object level mutations proposed in this work.
also theirtransformations may be inapplicable to mutate arbitrary images while preserving realism.
for instance applying severe weather conditions toward images of indoor scenes is likely unreasonable.
design fig.5depictsaholisticviewoftheproposedtechnique.togenerate imagei prime c o i fortesting metaodisconstructedasastreamlined workflow that includes object extraction object selection refinement andobjectinsertionmodules.byprovidingmetaodwithasetofimages e.g.
imagesfromthecocodataset itsobject extractionmoduleperformsadvancedobjectinstancesegmentation techniques to identify and extract object instances sec.
.
.
then givenanimageasthe background theobjectselectionmodule determines an appropriate object to be inserted in the background sec.
.
using a set of criteria to find similar objects rule out low qualityobjectsandadjusttheobjectsize.whilethefirsttwo stepsaddressthechallengeof whattoinsert foraparticularbackgroundimage weneedtofurtheranswerthequestionof where toinsert.
weaggregateempiricalevidenceandderiveheuristics to select insertion positions.
furthermore motivated by how delta debugging is applied to test conventional software we propose techniques to identify more locations for object insertion and therefore synthesize more images sec.
.
.
.
object extraction westartbyperformingobjectextractiontoidentifyandextracta poolofobjectinstancesfrominputimages.whileobjectextraction isgenerallyconsidereddifficult deeplearning based instancesegmentation models have been shown to work well to extract objects from images .
for example given the two elephants image in fig.
instance segmentation models can recognize both elephants and put two masks over both elephant objects.
similar to od instance segmentation model design also has twoprimaryfocuses accuracy andspeed which usually cannot coexist.
in this work we concentrate on models that emphasize speed over accuracy.
the object extraction moduleis designed to swiftly extract objects from large sets of diverseimages.
therefore speed takes priority over accuracy although in practiceour adoptedinstance segmentationmodel hasa good accuracy as well .
in sec.
.
we compensate for the accuracy of extractedobjectsbyproposingtechniquestoruleoutlow quality objectimages.byorchestratingobjectextractionandrefinement modules in pipeline we output sets ofhigh quality labeled object images with a modest cost and high speed.
tothisend wereuseyolact arecentlydevelopedreal time instancesegmentationtool tobuildtheobjectextractionmodule.
our empirical evidence also reported in its paper shows that yolact has impressive speed and quite good accuracy in practice when processing real world images.
yolact outputs a mask over each recognized object instance.
we extend yolact by reusing theobjectmaskstoextracteachobjectfromthebackgroundimage and save each object into an individual image.
.
object refinement and selection despite significant progress instance segmentation remains a difficult problem and we have observed that some of its outputs are of lowquality.according to our observations these low quality objectimages occurfor twomain reasons someobjects inthe input image are too small and some objects overlap and therefore fragmentary object images are extracted.2we acknowledge the general difficultyof outputting high quality object images.instead our object extraction module processes large sets of images athighspeed and we further prune low quality objects and select appropriate objects closely related to a background image.
small object image pruning.
asshowninfig.
theoutputof objectextractionconsistsofmultiplesetsofimages whereeachset contains object instances with the same label.
during this step we firstprunesmallobjectimageswithineachobjectset whichpresumably include low resolution or fragmentary images unsuitable for use.
to perform pruning we sort the object instance images within each set by image size and remove the majority of object images in our implementation we empirically decided to remove of the object images .objectimagesimilarityanalysis.
foraparticular background image with several preexisting objects we aim to find object instance images from the pool that are closely related to the backgroundtofulfilltherequirementoftestingodwhilealsopreserving the realism of the synthetic images as much as possible.
to this 2suchgeneralchallengesstillexistevenifwetentativelytriedmore heavy weight instancesegmentationmodelslikethetensorflowimplementationofmaskrcnn .
1057end we perform an image similarity analysis using image hashing techniques.imagehashingisastandardtechniqueforpixel level image similarity analysis.
the process creates similar hashes for similar images.
in contrast when using a crypto hash algorithm such as md5 one byte ofdifference can lead todrastic hash value changes due to the avalanche effect .
given animage iwith three birds we start bycomputing the averageimagehashvalueofthese bird objectimages.thenwe iterateoverallthe bird imagesinthepool seefig.
andidentify a bird whoseimagehashvaluehastheshortesthammingdistance with the average hash value.
this bird will be used for insertion.
if imageicontains objects with ndifferent labels we repeat the procedure ntimes.therefore nobjectsofdifferentcategorieswill be selected for insertion.
in this way we ensure the realism of thesyntheticimagesasmuchaspossible.ourobservationsshow thattheselected similar objectimagescanusuallyexhibittexture and resolution that are close to those of the background image.
for the implementation we use the average hash which is astandardimplementationforimagehashing.ourtentativetests showedthatthismethodhelpsfindsimilarobjectstoagoodextent at modest cost.
nevertheless we acknowledge the difficulty if itis at all possible of finding semantically similar objects through aunifiedandcost efficientapproach.indeed imagehashinguses pixel level similarityinsteadofreflectingonthe meaning ofeach object instance.
we leave for future work to explore practical techniques to comprehend the semantic information of each object instance and refine object selection at this step.
object image resizing.
there is a relationship between object sizeandits distance intheimage.atinyobjectcanbe further away and challenging to identify for even human eyes and is thusnotconsideredinthiswork.hence beforeinsertingaselectedobjectintoabackgroundimage i weadjusttheobjectsizetomatch thatoftheexistingobjectsinimage i.weresizetheobjectimage to the average size of objects in ithat belong to the same category.
also asnotatedinsec.
besidesresizing wedonot transform objects rotation blurring etc.
topreserverealismatourbesteffort.
.
object insertion after selecting proper objects we then seek proper locations on the background image for insertion.
as discussed in sec.
.
the softwareengineering se communitytransformsentireimagesfor testing while the computer vision cv community primarily concernswiththevisualappearanceoftheinsertedobject ratherthan the background intowhichtheobjectisplaced .several studies have attempted to infer reasonable insertion locations usingstatisticalmethodssuchasprobabilisticgrammarmodelsand haveonlyappliedthemto imagesofindoorscenes .however building a generalized model for arbitrary scenes if at all possible ishighly challenginginthisresearch wherelarge scalesynthetic images are required to reveal erroneous od results.
giventhegeneraldifficultyofleveragingheavy weightstatistical methods to infer optimal insertion locations we propose lightweightstrategies.inthissection westartbyconductingempirical studies on locations where insertion can presumably trigger od defects.
then motivated by delta debugging used in testing m1 y1 n1 x1 m2 m1 n2 n1 figure the guided insertion strategy to insert a bird.
theblue region is symmetrical and centered on the larger elephant.
traditional software we generate more synthetic images by progressively relocating inserted objects on background images.
determiningobjectinsertionlocations.
ourpreliminarystudies show that inserting objects close toexisting objects in an image referredtoas guidedinsertion laterinthispaper islikelytotrigger erroneous predictions.
this section presents empirical results to supportourobservation.tosetupthestudy werandomlyselected 50imagesfromthecocoimageset andtentativelyinserteda bird image.wetestedeightpopularodsandshowtheevaluation results descriptions of these ods can be found in table .
weadopttwoinsertionschemes randominsertion andguidedinsertion.
guided insertion works by randomly selecting one existing objectfromthebackgroundandinsertingextraobjects closetoit.
as shown in fig.
after randomly selecting one elephant e.g.
the largerone onthebackgroundanddecidingtousea bird object we create a blueregion that is symmetrical andcenteredon the selectedelephant.3werandomlyselectlocationswithinthe blue regionasthecentroidofthe bird .oursamplingguaranteesthat the bird will not overlap with the larger elephant.
moreover overlapping with any other objects is notallowed either whenever the bird is sampled over existing objects in iwe discard the synthetic image and resample.
incontrast therandominsertionschemeimplementsasimple strategyinwhichobject oisplacedrandomlyonthebackground.
again wedisallowoverlappingof owithexistingobjectsandresamplewhenever overlappingoccurs.
additionally for eachbackground image iwithnexisting objects we perform nguided orrandominsertions.
wereporttheerroneous odoutputsfound w.r.t.
these two setups as follows od see table 2for errors found by errors found by synthetic descriptions randominsertion guided insertion images amazonrekognintion microsoft azure vision ibmvision google automl vision ssdmobilenet ssdinception rcnnresnet rcnninception total 3when deciding the size of the blueregion we find that if it is too narrow the search space of object insertion locations are too small and undesired.
similarly if the blue regionistoowide itmayoverlapwithotherexistingobjects.sincewedisallowthe inserted object to overlap with existing objects higher chance of overlapping leads to lower chance of finding proper insertion locations and is thus undesired as well.
!
!
!
figure move object instance image otoward the centroid.
since ods introduced soon intable identify different numbers of objects from each image we synthesize different amount of imagesfortesting.theresultsshowthattheguidedsettingnotably outperforms the first setting.
this is consistent with our intuition by inserting images near the local region of existing objects the inserted images may disturb the regions or grids used for object recognition and thus cause failures in ods.4as a result metaod is configured with the guided insertion strategy.
objectrelocation.
whiletheproposedmethodsprovidepractical guidelines on object insertion guided insertion primarily focuses onlocations closetoexistingobjectsandmaymissopportunitiesfor objectinsertioninotherimageregions.wefurtherproposetechniquestoidentifyadditionallocationsforobjectinsertion whilestill maintaining the realism of generated images insofar as possible.
to accomplish this we first compute the centroidof objects in the backgroundimage then motivatedbytheuseofdeltadebugging for conventional software the inserted object is progressively relocated toward the centroid to generate visually more diverse images while retaining to cause prediction errors.
theprocedureisillustratedinfig.
whereourrelocationscheme isimplementedtoexplorelocationsclosesttothecentroid.starting from aninsertionlocation foundby theguided insertion strategy that can trigger od failures we relocate the inserted bird to the centroidofexistingobjectsonthebackground.ifnoerrorcanbe provokedregardingthenewlysyntheticimage wejumpbackto the middle and recheck the od.
in case this time prediction errors dooccur wesearchforwarduntilthe bird becomestoocloseto thecentroid theprevioussuccessfulinsertion i.e.
triggering predictionerrors withthelongestdistancefromthestartingpoint or the starting point itself.
again for this step we disallow any overlap between the inserted object and existing objects on the background whenever overlapping occurs we jump back as well.
it is worth mentioning that while the prototype implementation of metaodisequippedtouse centroid astheexplorationdestination any locations could be configured at this step to synthesize diverse and realistic images with respect to user requirements.
implementation metaod is implemented in python in approximately lines of code see our released codebase at .
the object extraction module of metaod is implemented by extending a popular instance segmentationmodule yolact .weextendedyolactby using the instance mask to crop the input image and extract object 4theimplementationdetailsofthefirstfourcommercialodsarenotdisclosed.see further discussions in sec.
.instanceimages.yolactisbuiltwithpytorch ver.
.
.
andcontains a model pretrained with a de facto object detection dataset coco .
this dataset contains objects with approximately labels and we use the pretrained model to perform instance segmentation.asaforementioned onedesirablefeatureofyolact is that it performs instance segmentation rapidly indeed all the instancesegmentationtasksarelaunchedononenvidiageforce gtx gpu with promising processing time see sec.
.
evaluation table2lists the ods used in the evaluation the speed and coco map of four tensorflow pre trained models are disclosed by google and speed of four commercial apis are estimated by us .
we use four commercial od apis provided by industrygiants for the evaluation .
python scripts are written tointeractwiththeseremoteservicesandretrievetheprediction results in json format .
to the best of our knowledge the odmodels used within these commercial services are not disclosed single stage models are presumably employed given their rapid predictionspeed sec.
.
googlealsosupportsdirectlydeployingitstensorflowodapis on google cloud and provides the flexibility to choose different models pretrained on the coco dataset .
we follow the official tutorial to setup tensorflow od on google cloud and from a total of five pretrained models suggested in the tutorial wechoosefourmodels i.e.
tensorflow modelsintable and exclude another pre trained model rfcn resnet.
rcnn inception resnetmodel yieldsthebestaccuracy map37 buthasthe slowestspeed.wealsochoseanotherrcnnmodel andtwo ssdmodels thatexhibitmediumpr edictionspeedandgood accuracy.
the tutorial reports that rfcn resnet has a very similar accuracy with faster rcnn resnet and therefore we skip to evaluaterfcn resnet.asmentioned in sec.
thetworcnn based modelshavetwo stageregion basedarchitectures whilethessd models have single stage architectures that are much faster.
.
evaluation overview table1summarizestheevaluationresults.toacquirethesedata we extracted object instances from randomly selected images from the coco image set .
we then randomly selected images from the same dataset as background images.
from the complete set of images metaod extracted a total of 843object instances clustered with respect to different categories person dog etc.
.
as previously mentioned sec.
.
the object refinement module of metaod sorts object images with respectto their size and eliminates of the small object images the remaining10 oftheobjectimagesarekeptasinsertioncandidates.
given an image i ods can find different numbers of objects fromi the third column of table 1reports the total number of objects found by an od .
as discussed in sec.
.
suppose that an odfinds mobjectsin i then metaodgenerates10 msynthetic images following the guided insertion strategy to test the od.
when a test image i primetriggers prediction errors that image is used to generate additional test inputs following the delta debugging style procedure sec.
.
.
the total number of images synthesized for each od is reported in the second column of table .
1059table result overview.
due to the limited space the detector names are simplified in this table and also in the rest of the paper.
note that processing time includes the prediction time of ods.
od syntheticimages detected objects images causing detection failures processing time hours total cost usd amazon .
.
.
google .
.
.
microsoft .
.
free ibm .
.
free ssd mobilenet .
.
.
ssd inception .
.
.
rcnn resnet .
.
.
rcnn inception .
.
.
total .
.
.
table ods evaluated in this research.
odname speedcocomap amazon rekognintion api fast n a google automl vision api fast n a microsoft azure vision api fast n a ibmvision api fast n a tensorflow ssd mobilenet fast tensorflow ssd inception fast tensorflow faster rcnn resnet medium tensorflow faster rcnn inception resnet slow thenumberofimagestriggeringpredictionerrors not number of bugs in the models is reported in the fourth column of table .
atleast10 ofthesyntheticimagestriggerederroneouspredictions of the evaluated ods.
since we randomly decide locations to insert objects into background images see sec.
.
error triggering images are very unlikely identical.
like typical software testing scenarios not every test input can trigger a bug.
having bug triggering tests consistently across different models is very promisingandshowsthatmetaodprovidesageneral practical and consistent approach to finding od errors.
overall table shows that od failures are a general concern regardless of the underlyingmodel.moreover whenamodeldetectsmoreobjects in images the number of images that can trigger failures also increases.thisisexpected asrecallthat foranimageof mobjects our guided insertion strategy generates msynthetic images sec.
.
.also whiletheimplementationofcommercialapisare unknown and are generally deemed as fast see table we suspect thatthey are notusing similar models since their prediction capabilities are very different cf.
the third column in table .
processing time.
this evaluation was conducted on a machine equipped with an intel i7 cpu and 16gb ram.
the instance segmentationmodulerunsonasinglenvidiageforcegtx1070 gpu with cuda .
.
table 1reports the processing time.
commercialapis particularlythegoogleandmicrosoftservices take less time for prediction than the tensorflow pretrained models.
althoughtheimplementationdetailsoftheseremoteservicesare not disclosed from the results we can assume that the commercial remoteservicespresumablyleveragehighlyoptimizedsingle stage od models that are faster but usually find fewer objects in images.
financial cost.
enabledbymoderncloudcomputinginfrastructures all of these ods are designed as pay as you go models users are charged based on how many queries they send to the services forthefirstfourservices orhowmanycomputingresources they use for the tensorflow services .
we report the amount in figure8 efficiencyofobjectrelocation.recallweleveragea delta debugging style method to relocate the inserted objectstowardthecentroid .x axisreportsthathowfar theinsertedobjectcanproceedtowardthecentroid in dicates that the object is placed at the centroid.
termsof usdthatwearechargedbytheseservicesintable .due to erroneous behavior some queries were indeed wasted.
more importantly given that commercial services have been adopted in supporting critical computer vision applications e.g.
surveillance cameras weenvisionreal worldscenarioswheretheprediction errors can cause financial loss or fatal errors.
.
efficiency of object relocation asdiscussedinsec.
.
inspiredbydeltadebugging wepropose techniques to mutate synthetic images by progressively moving an inserted object that triggers erroneous predictions toward the centroid of objectsin the background image.
we preserve the realism of synthetic images at our best effort by placing the inserted object into a realistic position while finding more insertion locations and augmenting the visual diversity of the synthetic images.
wereportthebreakdownofsyntheticimagescausingoderrors intable3.thesecondcolumnreportsthenumberofimagestriggeringpredictionerrorsthataresynthesizedbyinsertingobjects into the background image while the third column reports the number of images triggering prediction errors and are synthesized by relocating inserted objects toward the centroid.
since the same object could be inserted at different positions on a background image andthenreachingtothe samecentroid wealsomeasurethe uniquenumberofsyntheticimagesatthisstep thelastcolumn .
as shown in table the object relocation step successfully finds a 1060table breakdown of images causing od failures.
by addingthesecondandthelastcolumns wegetthe images causing detection failure column in table .
od synthetic synthetic unique synthetic imageswith imageswith imageswith inserted obj.
relocated obj.
relocated obj.
amazon google microsoft ibm ssdmobilenet ssdinception rcnnresnet rcnninception large number of unique images retaining prediction errors.
among atotalof28 959syntheticimagescausingpredictionerrors .
uniqueimages arecreated viaobject relocation.moreover wereporttheaveragedistance intermsofpercentage bywhich the inserted object can be relocated in fig.
we consider arriving atthecentroidas100 andstayingatthestartingpositionas0 .
note that fig.
8has excluded all the cases where objects stay at the starting positions.
as shown in fig.
.
of objects on averagecanbeplacedat thecentroidwhileretainingerrors and .
of objectsare relocatedby atleast40 ofthe distances.the overallresultsaspromising illustratingthataconsiderablenumberofsyntheticimagescouldbegeneratedthatretainprediction failures and also make the images visually more diverse.
.
naturalness of synthetic images while the naturalness of a synthetic image may be subjective as noted by existing research natural images are deemed to have certainstatisticalregularities .therefore followingthecommonlyadoptedconventioninthecomputervisionliterature the naturalness of synthetic images is measured by first computing a histogram of oriented gradients hog of both synthetic imagesandtheir correspondingbackgroundimages andthencom putingtheintersectionofthesetwohogs.hogisapopularmetric extracting distribution histograms of directions of gradients as features ofanimage.bysummarizingthemagnitudeofgradients this metric captures abrupt intensity changes in theimage object edges object corners etc.
and therefore is usually effective for comprehending high level representations of images with multiple objects.
in contrast pixel level similarity metrics sec.
.
leveragedinmetaodfocusonsingleobjectinstancecomparison and arenotapplicableinthisevaluation.consistentwithpreviousresearch thecomparisonoutput i.e.
hogintersection avalue between0and1 illustratesthenaturalnessofsyntheticimages.we provide discussions regarding image naturalness in sec.
.
table4reports hog intersection rates second column by comparingsyntheticimageswithinsertedobjectsandtheircorresponding background images and hog intersection rates third column by comparing synthetic images with relocated objects and their corresponding backgrounds.
consistent with our intuition all syntheticimageshavehighly similarhogregularitieswiththeircorresponding backgrounds and are deemed natural in contrast we report that the hog intersection rate of two randomly selected imagesfromthecocodatasetisbelow50.
.also whilemosttable4 naturalnessevaluationw.r.t.averagehogintersection highervalueisbetter .wereportevaluationresultsofbothsyntheticimageswithinsertedobjects secondcolumn and relocated objects third column .
odaverage hog intersection average hog intersection rate for inserted obj.
rate for relocated obj.
amazon .
.
google .
.
microsoft .
.
ibm .
.
ssdmobilenet .
.
ssdinception .
.
rcnnresnet .
.
rcnninception .
.
synthetic images with relocated objects have hog intersectionsidentical to those of the synthetic images with inserted objects therearethreecasesforwhichthesyntheticimageswithrelocated objectsexhibitaslightlylowerrate.intuitively relocationgenerates visually more diverse images and can potentially lead to lower similarity comparingtotheircorrespondingbackgroundimages.
.
retraining with error triggering images to capitalize on the synthetic images that triggered prediction failures we show that such synthetic images can be used to retrain models and substantially improve their performances.
we use a popularautonomous drivingdataset berkeleydeepdrive for this evaluation.
this dataset contains images that depict realtime driving experiences under different weather conditions and at varioustimes.experimentsinthissection i.e.
modelretraining are conductedonaserverequippedwithanintelxeoncpue5 with gb of ram and eight nvidia geforce rtx gpus.
we downloaded the ssd mobilenet object detection model pretrainedbytensorflowandretrainedthemodel withtensorflow ver.
.
.
byusing900imagesannotatedwith10commoncategoriesfortrafficscenesfromthedeepdrivetrainingset.weactuallyimitatedhowodmodelsarecustomizedandusedinpractice based on transfer learning pretrained models are adapted to similar tasks by fine tuning the model parameters on a new dataset.
at this step we reuse the default configuration shipped with the mobilenet pretrained model the batch size is which means the wholetrainingsetwillbeprocessedoncewithin19steps.weset up three retraining strategies config as follows westartbyretrainingthemobilenetmodelwith900images for 200k steps 200k is the default setting in the model sconfiguration and exporting the retrained model m0.w e alsoformanevaluationsetbyrandomlyselecting100images from the deepdrive evaluation set.
we then use metaod to generate new synthetic images from the images and collect synthetic images that cause prediction failures of m0.
this step generates images denoted as i triggering prediction errors.
config1 starting from m0 we resume retraining with the images for another 10k steps.
config2 startingfrom m0 weextendtheoriginaltrainingset of900imageswith900imagesrandomlyselectedfrom i andresumethemodelretrainingwiththese1 800imagesfor 1061another10ksteps.tolabeleachsyntheticimage wereuse the label of its reference input image see sec.
.
.
we also use metaod to generate another set of images denotedas i .wedonotcheckwhethertheseimagescan trigger prediction failures or not.
config3 starting from m0 we extend the training set of images with images in i and resume the model retraining for another 10k steps.
again to label each synthetic image the label of its reference input is reused.
duringtheretrainingofintotal210k steps wemeasurethetotal loss and map score regarding the evaluation set of images.
figure9 smoothedtotalloss firstdiagram andmapscores second diagram during model retraining.
due to limited space we show performance starting from 130k steps.
asreportedinfig.
forthelast10ksteps config1showsconsistenttrendingcomparedtothefirst200ksteps.
config2outperforms the other two by having lower total loss.
moreover the map score ofconfig2clearly outperforms those of the other configurations.
config3exhibits a slightly better total loss decrease than that of config1 but yields an even lower map score which may be due to overfitting .
we report that the average map scores of the three configurations within the last 10k steps are as follows config1config2config3 map .
.
.
asthetableshows modelperformanceisincreasedbyretraining withthesyntheticimagesofthepredictionerrors.notethataccording to od surveys e.g.
table two in and table seven in onepointmapscoreincreaseissignificant.overall weinterpret the evaluation result as promising the failure aware retraining demonstrated in this section sheds light on practical usages of the modelpredictionerrorsfoundbymetaodandprovidespromising directions to improve model accuracy.
we acknowledge that the evaluation while being fair may not illustrate the best practice to promote model performance fig.
9indicates that the sweet spot might be around 8k steps of retraining where the map score is approximately .
.
overall we consider that providing guidelines of best practice is beyond the scope of this research but the reported results have illustrated the potential.
additionally images are synthesized from the existingtrainingset inotherwords wedo notneednewrealimages.
overall failure aware retraining is orthogonal to standard model retrainingtechniquesandcanpotentiallybeorchestratedtogether.
discussion and future work in this paper we presented the design implementation and evaluation of metaod a systematic workflow for automatically testing the erroneous behaviors of object detection systems.
the proposed techniques can be adopted to promote object detector training and to motivate this emerging lineof research.
in this section we presentadiscussionandseveralpotentiallypromisingdirections for future research.
comparisonwithworkinthecvcommunity.
parallel to se community s efforts on testing deep learning systems the cv communitygeneratessyntheticinputsbymutatingrealimagestotrain dnns.
we compare and illustrate the novelty of metaod with related cv research along several aspects blackboxvs.whitebox.
most existing cv research considers a white box setting e.g.
.
such efforts either require an in depthunderstandingofthemodelstructuretoadaptivelysynthesizeinputs orusethehiddenlayersofdnnsandcomputed gradientstoguideinputsynthesis .asaforementioned weconsiderblackboxsettingforsoftwaretestingandintroducesmetaod to effectively test commercial remote od models.
trainingwithsyntheticinputsvs.re trainingwithbug triggering syntheticinputs.toourknowledge relatedcvresearchdirectly uses synthetic inputs for model training.
contrarily metaod suggests a novel failure aware model retraining scheme sec.
.
t o effectively improve model accuracy which sheds light on future work to continue testing the re trained model i.e.
the whole process would loop to iteratively re train the model.
we expectthe model accuracy to further improve until reaching saturation.
as evaluated in fig.
model re training with arbitrarily generated syntheticimagesmayleadtodecreasedmodelaccuracy whileretraining with bug triggering synthetic inputs leads to significantly improvedaccuracy.thisinterestingobservationsuggestsfurther research opportunities for both the cv and se communities.
fine grainedmodeling tuningonsyntheticimagefortraining vs.genericframeworktosynthesizeimagesfortesting.
as sec.
will review existing cv research mostly performs heavyweight fine grained modeling to generate synthetic images e.g.
specif ically modeling motion trajectory to synthetic images and trainsurveillance cameras .
these works usually focus on specific applicationdomains andleverage domainknowledge tofine tune and optimize the synthetic images with statistical tools.
we have a differentdesigngoalofproposingageneralframeworktoefficiently producealargeamountofqualityinputsfortesting.metaodis in general agnostic of image semantics except labels of existing objectsintheimage andthereforecanbemoreefficientandrobust.
novelty w.r.t.
dnn testing work in the se community.
as discussedinsec.
mostexistingtestingworkinthesecommunity 1062focuses on image classification models e.g.
or the underlyinginfrastructuresoftensorflow pytorch e.g.
.
toourknowledge nopriorworkfocusesondesigningageneral effective pipeline to test od models another class of fundamental models usedin manyreal worldcritical applications.
metaodmutatesandobservesthedetectionofindividualobjectsinanimage while existing research on testing image classification performs mostlywholeimage wisemutations e.g.
addingfoggyandrainy conditions .
some of these transformations are not applicable to ourscenario discussedinsec.
.
andourapproachisgenerally orthogonal to these whole image wise mutations.
wealso demonstratethefeasibilityof failure drivenretraining sec.
.
withnotablyimprovedmodelaccuracy.thisevaluation initializes a promising step toward addressing a typical concern in the se community on how to use findings of dnn testing which has not been systematically explored by previous works.
measuring naturalness of synthetic images.
as noted in sec.
.
we follow conventions in the cv community t oc o m paresyntheticimageswithnaturalimagesw.r.t.hogasawayof measuring the naturalness .
nevertheless as discussed in sec.
.
itischallenging ifnotimpossible tounderstandthe semantics of an object and make it fully consistent with arbitrary backgrounds i.e.
more natural .
for instance the traffic image in fig.
3can be more natural if the perspective of the inserted car slightly turns left rather than entering the sidewalk.
to our knowledge cv community is exploring statistical tools to indepthly comprehend only a few specific scenes and objects e.g.
mutating human gestures within indoor scenes .
in contrast this work introduces a general efficient pipeline for arbitrary images.reason to preserve naturalness of synthetic images.
we notethat realism naturalness of syntheticimagesdoes nothave directinfluenceontesting.randomlymutatingpixelstogenerate fuzzy and unreal imagesasthetestinputs whicharechallenging for human eyes to recognize objects could also be used for stresstesting ods.
however we argue that preserving the realism of synthetic imagesatourbesteffortwhendesigningtheworkflowof metaod is indeed beneficial.
first as noted in sec.
.
we are not testing extreme cases to stress ods not like a typical fuzz testing setting .
stress testing of dnns would be different.
second synthesizing more realistic imagesfacilitatethepracticalusageof metaod.
as mentioned in sec.
we aim to augment the realism to a certain extent suchthatsyntheticimagestriggeringerroneouspredictions could imply real life failures of od systems leading to confusions duringthedailyusage.also wearguethatusingrealisticanderrortriggering images to retrainod models sec.
.
deems a more reasonableapproachthanusingarbitrarilymutatederror triggering inputs.
related work testing ofdeeplearning systems.
testingtechniquesforconventionalsoftwarehavebeenrecentlyappliedfordeeplearningsystems includingfuzztesting mutationtesting metamorphictesting andalsosymbolicexecution .
the majority of existing work focuses on image classification and itsadoptiononautonomousdrivingsystems .nlpmodels aswellastypicaldownstreamapplications e.g.
machine translation havealsobeentestedusingvarioustestingschemes .
we note that previous work on testing deep learning systems often adopts a differential testing scheme .
however od models can usually recognize different number of objects from an image due to the model capability leading to the general challenge for cross comparison.
for instance when analyzing the beach sample image provided by tensorflowdevelopers amazonrekognitionapi locates13objects while microsoft azure api locates only four.
in contrast our work adopts metamorphic testing as an effective and adaptive testing strategy to reveal defects in these commercial ods.
regarding testingoracleselection neuroncoverage andotherfinergrained coverage metrics have been proposed .
also in addition to the deep learning models the underlying infrastructures e.g.
tensorflow andpytorch havealsobeentested to find implementation bugs .
data augmentation for od model training.
inparalleltothe se community s progress in testing dnns data augmentation which generates synthetic inputs by mutating real images is an important technique to train dnns.
to train deep learning mod els e.g.
for object detection augmentation methods vary from geometricaltransformationssuchashorizontalflippingtocolorperturbations to adding noise to an image e.g.
mimic severe weather conditions .modelaccuracycanusually be improved by including such synthetic images into training data .
most existing work prioritizes localrather than global consistency when augmenting images.
for instance when inserting new objects into training images they focus more on the realism of insertedobjectsthanonthecontextsurrounding.manysynthetic images are unrealistic from a global point of view such as putting a car on the table .
a few studies leverage heavyweight statistics methods to infer a realistic location for object insertion they assumes a white box setting and can handle only a few domain specific scenes .
our work proposes a lightweight and systematic new focus to promote synthetic images by considering both local and global realism.
we take a black box setting that facilitatesthetestingofcommercialremoteods.inaddition our testing focus enables failure aware model retraining sec.
.
which effectively improves the model accuracy.
conclusion odsystemshavebeencommonlyusedinreal worldscenessuchasbuildingautomateddrivingcars.thispaperhasintroducedanovel metamorphic testing approach toward reliable ods.
evaluation results are promising metaod can find thousands of prediction errorsfromcommercialapisandodmodels.wealsoshowthat thegeneratedimagescanbeusedforretrainingandsubstantially improving od model accuracy.