feature driven end to end test generation parsa alian university of british columbia vancouver canada palian ece.ubc.canoor nashid university of british columbia vancouver canada nashid ece.ubc.camobina shahbandeh university of british columbia vancouver canada mobinashb ece.ubc.ca taha shabani university of british columbia vancouver canada taha.shabani ece.ubc.caali mesbah university of british columbia vancouver canada amesbah ece.ubc.ca abstract end to end e2e testing is essential for ensuring web application quality.
however manual test creation is timeconsuming and current test generation techniques produce incoherent tests.
in this paper we present a utoe2e a novel approach that leverages large language models llms to automate the generation of semantically meaningful feature driven e2e test cases for web applications.
a utoe2e intelligently infers potential features within a web application and translates them into executable test scenarios.
furthermore we address a critical gap in the research community by introducing e2eb ench a new benchmark for automatically assessing the feature coverage of e2e test suites.
our evaluation on e2eb ench demonstrates that autoe2e achieves an average feature coverage of outperforming the best baseline by highlighting its effectiveness in generating high quality comprehensive test cases.
index terms feature inference end to end testing large language models i. i ntroduction end to end e2e testing assesses whether various integrated components in an application work together correctly from the user interface ui to the back end by simulating real user interactions and verifying the application s functionality.
in e2e the application is tested as a whole in its entirety and from the perspective of the end user .
the predominant method of creating e2e tests has relied heavily on human intervention with developers manually assessing application features and using frameworks such as selenium to script the user scenarios.
efforts to automate e2e test generation have explored reinforcement learning rl and model based approaches .
more recently the rise of large language models llms has spurred their application to various testing tasks.
while llms have shown promise in generating unit tests for various applications and mobile testing their application to web app e2e test generation remains an open area of research.
our recent work formnexus has focused on automating web form testing highlighting the potential for llms to enhance e2e testing methodologies.
in this paper we formalize the notion of feature driven e2e testing including definitions of application features and a new metric called feature coverage for assessing e2e tests.
then we propose a utoe2e the first technique designed to generate feature driven e2e tests autonomously.
our approach is centered on the ability to automatically infer features embedded within the web application and translate them into a sequence of user actions that form an e2e test scenario.
we approximate potential features and employ a novel probabilistic scoring method that deduces the likelihood of a feature s existence based on its observed frequency within the web application.
in our probabilistic approximation we leverage llms such as gpt o or c laude which exhibit enhanced abilities to comprehend content within applications compared to traditional models.
a critical challenge we encountered was the absence of a suitable dataset for evaluating e2e test cases.
to address this we create a novel benchmark called e2eb ench comprising open source web applications.
for each application we extract all available features and employ instrumentation techniques to monitor front end code enabling us to track the actions performed on the web application during e2e tests.
we establish a mapping between each application s features and the corresponding sequences of actions performed.
as part of the benchmark we develop a tool capable of automatically monitoring e2e test suite execution and assessing its coverage across all existing features within each application.
in summary this work makes the following contributions a formal formulation of feature driven e2e test case generation providing a theoretical foundation for developing practical automated e2e testing tools.
a probabilistic method for automatically inferring features in a web application.
our feature inference system assesses the likelihood of feature existence based on the frequency of the observed user actions.
a novel technique called a utoe2e capable of autonomously generating feature driven e2e test cases.
each test contains a sequence of actions to cover an inferred feature.
e2eb ench a novel benchmark designed for automatic evaluation of e2e test suites quantifying their effectiveness in feature coverage.arxiv .01894v2 jan a select search bar b search for a product c select the product d add to cart fig.
add to cart feature on amazon s web application our evaluation results demonstrate that a utoe2e achieves a feature coverage of surpassing the best baseline crawljax by and a significant improvement over the best llm agent based baseline b rowser gym highlighting the effectiveness of our methodology for automated e2e test generation.
in addition to achieving superior coverage a utoe2e generates more complex test cases.
furthermore the test cases ranked as more likely to exist by our likelihood estimation system exhibit a higher correspondence with actual features within the web applications further validating the effectiveness of our approach.
ii.
f eature driven e2e t esting to illustrate the challenges and opportunities in e2e test generation we utilize the amazon web application as a motivating example with a few representative pages illustrated in figure .
before deploying such apps developers must conduct rigorous testing to guarantee proper functionality.
testing can occur at various levels including unit tests integration tests and e2e tests.
e2e tests in particular focus on executing specific features and functionalities that users will engage with from start to finish ensuring that different features and scenarios within the app behave as expected.
within the context of e2e testing we define definition user operation .a user operation denoted byu is a sequence of user actions ai e.g.
clicking submitting forms .
each user operation can be classified into one of the following types entity operations these operations involve creating reading updating or deleting data entities within the system.
an entity operation is represented by a tuple x e m p where xsignifies the crud action create read update or delete edenotes the target entity or entity set mis a boolean indicating whether the operation affects single or multiple entities and pis a set of parameter values providing additional context or control.
configuration operations these operations modify system configurations or settings.
they are represented by a tuple c p where cidentifies the specific configuration being altered and pspecifies the new value.
on the amazon web application searching for a product is classified as an entity operation specifically a read operation x read on the product entity set e product .
as a search typically returns multiple results the multiplicity istrue m true and the parameter set includes the search term entered by the user p search term .
it is important to distinguish between viewing a list of search results m true and viewing the details of a single product m false as these are distinct operations within the system.
configuration operations are prevalent in various software systems.
for example logging into a system involves updating theauthentication configuration to reflect the user s authorized status.
toggling a dark mode setting modifies the application s visual appearance while changing a language configuration alters the language in which content is displayed to the user.
definition application feature .an application feature denoted by f is characterized by the following properties fcan be realized through a finite ordered sequence of user operations definition denoted as u1 u2 un where each uirepresents a distinct user operation.
each user operation uiwithin the sequence is essential for achieving f. removing any uiwould result in an altered or unattainable outcome.
the outcome oof executing the sequence u1 u2 .
.
.
u n is visually presented to the user upon completion signifying the successful realization of f. the label lis an abstract natural language description of the feature f independent of the parameters piin the operations ui.
for instance consider the common feature fon the amazon web application labeled as adding a product to the shopping cart .
as illustrated in figure this feature entails a specific sequence of user operations ui viewing read a list of products viewing read the details of a specific product creating a cart item.
this operation chain culminates in a visible change to the user s cart representing the outcome o. each operation in this sequence is crucial for the successful completion of f. for instance removing the search operation would prevent the user from finding the desired product while omitting the product selection step would leave the system without a specific item to add to the cart.
in contrast operations not essential to achieving the feature such as changing the application s language or background color should not be included in the defining sequence.
the abstract nature of flabeling implies that it should notbe tied to specific parameters from the constituent operations.
whether the user searches for shoes or electronics or chooses a particular brand or model the fundamental feature of adding a product to the shopping cart remains unchanged.
manual testing.
in practice manual e2e test creation often relies on developers or quality assurance qa engineers exploring the application or utilizing design documents to extract features functionalities and user flows within the application outlining key scenarios to test.
after specifying the features test scripts for those features are often written using specialized frameworks like selenium cypress or playwright to simulate user interactions within the app.
these scripts typically involve executing specific actions on the app such as clicking buttons filling out forms and navigating through pages.
they also include assertions to verify that the application responds as expected at each stage.
test generation.
model based testing has emerged as a prominent technique for automated e2e test generation in web applications .
this approach involves systematically exploring the application s state space by exercising available actions such as clicking links hovering over elements and submitting forms.
the resulting state transitions are then captured and integrated into a model representing the application s behavior.
for instance consider a model of the amazon web application illustrated in figure .
this model would encompass the states and action sequences necessary to add an item to the shopping cart.
furthermore it would incorporate transitions facilitated by persistent navigation elements such as the menu bar enabling navigation between key pages like the landing page login page and shopping cart from any point within the application.
once constructed this model serves as the foundation for automatic test case generation.
test cases are derived as sequences of actions extracted from the model s transitions with the objective of achieving comprehensive coverage based on predefined criteria such as state coverage or transition coverage.
listing illustrates a model based generated test case showcasing a path within the amazon web application.
1test generated test case cy.visit cy.get search bar .type smartwatch assertion cy.get login .click assertion cy.get home .click assertion cy.get cart .click assertion listing sample model based generated test case this cypress based test simulates user interactions such as searching for a product smartwatch navigating from the search results to the login page returning to the landing page and finally proceeding to the cart page.
at each stage assertions are made to verify the correctness of the application sstate ensuring the presence of expected elements validating displayed content and confirming successful navigation.
challenges in e2e testing.
both manual test creation and automated test generation present distinct challenges.
developer written test cases while potentially comprehensive are often expensive and time consuming to develop.
modelbased techniques offer a partial solution by automating test case generation.
however the resulting tests may lack the coherence and relevance of human written scenarios.
this is evident in the sample model based test case listing which despite covering several states and transitions the sequence of actions performed is not relevant to a specific application feature definition .
while developer written tests typically follow meaningful features e.g.
adding an item to a cart model based tests prioritize coverage over coherence leading to seemingly random sequences of actions.
this trade off between coverage and relevance highlights a key challenge in automated test generation.
to more effectively evaluate the quality of generated e2e tests we propose a new metric feature coverage definition feature coverage .letf f1 f2 .
.
.
f m be the set of all features definition in an application and lett t1 t2 .
.
.
t n be a set of test cases in a test suite designed to test these features.
define a relation r t f where each ti fj rindicates that test case tiexercises feature fj.
feature coverage cis then defined as the ratio of the number of unique features exercised by the test suite to the total number of features given by c fj f ti t such that ti fj r f where each test case titargets exactly one feature fjand it is permissible for multiple test cases to cover the same feature.
this metric shifts the focus from purely syntactical code coverage or structural coverage such as state and transition coverage to a more user centric perspective emphasizing the testing of distinct application features.
automating test case creation while achieving a high feature coverage necessitates a nuanced understanding of the application s context and content a capability that remains absent in existing automation techniques.
to address this gap a novel feature driven e2e test generation approach is required.
this approach must be capable of inferring the features existing within the app connecting the available actions to those features and generating the sequence of actions corresponding to the coverage of each feature as a test case.
iii.
a pproach in this work we introduce a utoe2e a novel approach for automatically generating semantically meaningful e2e tests each targeting a distinct application feature definition aiming to achieve high feature coverage definition .
our primary focus is addressing the challenge of inferring application features from the contextual information present in various application states.
we propose a method that assessesexecute next actionextract actions iii.b exploration loop action list crawling queue webpage actioniii.c feature inference context context extractor feature extractor screenshot metadata mapinsert feature list feature db action feature dbupdate scoresiii.d feature aggregation filter iii.e test casesfig.
overview of our framework the likelihood of features existing within an application based on observed user actions.
by integrating this method with llms we establish a workflow to identify the features present in the application and the corresponding sequences of actions required to trigger them.
these action sequences are then transformed into comprehensive test cases for the application.
the architecture for a utoe2e is illustrated in figure .
a. feature inference modeling we first formalize the feature inference task in order to leverage llms more effectively.
a web app typically consists of various application states and transitions between them definition application states and transitions .an application state sirepresents a snapshot of the web app at a particular moment characterized by the runtime values of relevant variables as well as the dynamic structure and content as rendered in the browser.
a transition aiinitiated by a user action e.g.
clicking a button submitting a form can cause a state change e.g.
from s1tos2.
figure provides a visual representation of this concept where each image depicts a distinct state within the amazon web application.
furthermore the actions available within these images represent potential transitions to other states.
given a web app with kstates s1 s2 .
.
.
s k and mpotential features f1 f2 .
.
.
fm the task of inferring features becomes that of constructing a generative model to estimate the following distribution p f1 f2 .
.
.
fm s1 s2 .
.
.
s k p f s in this formulation the probability distribution p f s represents the likelihood of a feature set fbeing present within an application given the information observed in the set of states s. a generative model could learn this distribution from data and subsequently generate a feature set fthat maximizes this probability.this approach aligns with how humans typically extract features and design test scenarios.
users explore the application s interface inferring available features based on observations.
for instance when presented with the application states depicted in figure a human can intuitively infer the presence of features such as searching for products purchasing products viewing account details and reviewing order details.
these inferences are based on the visual cues and interactive elements present in the observed states leading to a higher likelihood of these features being available within the amazon web application.
however constructing a generative model capable of accurately estimating p f s is a challenging task due to the vast complexity of both the feature and state space.
to address this challenge we introduce a simplified model that enhances tractability while retaining the essence of the generative approach.
feature independence given complete access to all states swithin an application the inference of individual features fican be considered independent.
while certain features may often imply the existence of others e.g.
an add to cart feature suggests a remove from cart functionality knowledge of the complete state space allows for direct observation and inference.
for instance the presence of a remove button on the cart page confirms the existence of the remove from cart feature independent of knowledge about the add to cart feature.
leveraging this feature independence given s the joint probability distribution in equation simplifies to p f s p f1 s p f2 s .
.
.
p fm s based on this notion instead of attempting to infer all features simultaneously we can leverage the conditional independence and generate features individually using the distribution p fi s .
by sampling the top mgenerated values from this distribution we can effectively identify the most probable existing features within the application.
action centric feature inference feature determination in web applications can typically be accomplished through an action centric lens focusing on the available actions on a page rather than the specific content.
as illustrated in figure 1d the add to cart feature on a product page is discernible solely from the context of the page and the presence of the corresponding action regardless of the product s details.
having a general context for the page is particularly valuable when dealing with actions that have ambiguous descriptions such as a continue button.
in such cases the context of the current page e.g.
checkout page aids in clarifying the intended purpose of the action.
by adopting this action centric perspective we shift the focus from analyzing the entirety of the application s state information to a more targeted examination of the actions and their associated contextual information.
formally we can express this as p f s p f a1 a1 .
.
.
a k nk where ai jandnirepresent the j th action and the number of actions on state sirespectively.
sequential action chains the features within web apps are designed to be executed through a sequential chain of actions as can be observed in definitions and .
for a given feature f there exists an ordered sequence of actions a1 a2 .
.
.
a nthat leads to its execution f a1 a2 .
.
.
an crucially a feature should be derivable solely from its action chain.
for example when adding an item to a shopping cart the presence of actions for rating or commenting on products is irrelevant.
this allows us to eliminate unrelated actions from the context of equation focusing solely on the actions ai relevant to the feature p f s p f a1 a2 .
.
.
a n then we can use bayes theorem and chain rule of probabilities to simplify this to p f a a2 .
.
.
a n p a1 a2 .
.
.
a n p f p a1 f p a2 a1 f .
.
.
p an a1 .
.
.
f p a1 a2 .
.
.
a n dependence of subsequent actions the sequential nature of user interactions within web applications can be modeled by recognizing the dual dependency of each action an action aidepends on the immediately preceding action ai 1and the specific feature fthe user intends to execute.
this dependency allows us to estimate the most probable subsequent actions based on the current action and feature.
consider the scenario illustrated in figure 1c where a user clicks on a product within a list of search results.
if the user intends to purchase the product feature f we can predict that the next likely action would be clicking on add to cart.
conversely if the user intends to rate the product a different feature f the most probable next action would be clickingon a rating value.
crucially this estimation of the next action relies solely on the current action and the intended feature regardless of the user s prior interactions and the specific path taken to reach the current state.
whether the user arrived at the product page through searching browsing categories or any other means is irrelevant.
consequently based on this property we can simplify equation p f s a p f p a1 f ny i 2p ai ai f p f p a1 f p a1 p f a1 p ai ai f p f ai ai p ai ai p f ai p f s a p f a1 ny i 2p f ai ai p f ai in the presented equations a and a denote generalized action probabilities.
these terms are not specific to any particular application or feature but rather capture the inherent likelihood of observing certain actions across all the different web interactions.
for instance these terms might encapsulate the probability of encountering a login action in any web application essentially providing a baseline expectation for the occurrence of actions.
since our goal is to maximize the distribution over f these functions become irrelevant.
therefore we can further simplify the task of feature inference into the following equation f arg max fnx i log p f ai ai log p f ai this result has an intuitive interpretation.
if we are predicting the existence of a certain feature based on an action we should observe further evidence supporting that feature after performing the action.
equation provides a flexible foundation for various implementations as it applies broadly to web applications and is not constrained by any specific implementation details in its derivation.
in this work we implement our method based on this equation by utilizing llms to estimate the distributions p f ai andp f ai ai .
this is achieved by feeding ai and ai ai as context to the llm respectively and prompting it to infer features based on this context.
we then aggregate the generated results to assess the likelihood of existing features within the application.
the remaining sections of our approach will detail how we leverage llms and aggregate their outputs to infer both features and their corresponding chains of actions.
b. exploration loop as illustrated in figure a utoe2e operates on an exploration loop paradigm interfacing with the target web application capturing user actions and systematically queuing themfor execution.
each executed action potentially reveals new application states driving exploration until no further novel states are discovered or a timeout occurs.
a utoe2e employs a breadth first search bfs strategy for state exploration queuing and recursively crawling neighboring states from the current state.
feature extraction inferences are performed concurrently during state visits feeding the extracted actions into the rest of the workflow to infer features.
c. feature inference as the exploration loop discovers new states and extracts their associated actions a utoe2e concurrently analyzes each action to infer the specific features with which it interacts.
for the following sections imagine our exploration has led us to state sivia the action sequence a1 .
.
.
ai .
in this state we observe a set of available actions ai ai1 ai2 .
.
.
a in where aijdenotes the jth action on si.
state context extraction as discussed in equation actions are represented alongside their corresponding context the high level purpose of the page where the action occurs.
this contextual information is essential for accurate feature inference particularly when the content associated with an action is ambiguous e.g.
a button labeled continue and requires further disambiguation.
identifying page context requires multiple data sources.
the application s description and category provide high level information while the page s content text html images offers more specific details.
we prioritize image based analysis over html due to html s verbosity.
additionally the history of actions leading to the current page provides further contextual clues.
consequently our context extraction employs a multimodal approach incorporating a screenshot of the sirendered in a browser a description of the entire application and the most immediate action ai 1leading to si.
as an example the following is the extracted context for the page in figure 1c a webpage displaying search results for a product query allowing users to browse and filter options for purchasing.
feature extraction following the extraction of contextual information from si we can now utilize that context in conjunction with the actions present on the state ai and prompt an llm to predict possible features connected to each action.
we follow the result in equation derived in section iii a to infer the features by querying the llm twice.
the first prompt requests the llm to generate features based on the individual actions in si corresponding to p f aij ai .
the second prompt asks the llm to generate features based on the actions in siplus the most recent action that led to the current state representing p f aij ai ai .
to illustrate this process consider figure 1d.
for the first prompt the llm would be asked to generate features solely based on the add to cart button.
however for the second prompt the llm would consider both the add to cart button and the preceding action that led to this page which is clicking the product link in figure 1c.
estimating the probability of a result generated by an llm particularly in proprietary models is not always feasible.
thislimitation hinders the direct calculation of p f aij ai andp f aij ai ai in equation .
to address this we incorporate chain of thought cot prompting in the llm prompt asking it to generate a list of rfeatures ordered by their perceived probability of existence.
cot prompting encourages the llm to provide more reasoned and reliable responses increasing the validity of the feature ordering.
having access to this ordering we employ a geometric distribution to estimate the probability of an inferred feature based on its rank rank score r r r log p fis ranked r log p r 1p r log p log p where pis a manually set parameter.
a pvalue close to creates a significant difference in probability between the topranked item and the rest while a pvalue near assigns nearly equal probability to each rank.
as there is often more than one feature associated with an action we seek a balance that allows our model to recognize these multiple features while still distinguishing between higher and lower ranked items.
therefore we set pto .
.
since the list of our inferred features is limited to the top r we must also take into account the probability that a feature is not in the top r but appears at a certain rank if we extend our list.
for every feature that does not appear in the top r inferred features we use a constant score rank score r r r rlog p log p this constant score is used in the aggregation phase.
d. feature aggregation during the exploration process upon encountering a new state we extract potential features associated with each action within that state.
importantly these feature inferences are conducted in isolation.
features derived using the current action context aij are independent of those inferred using both the current and preceding actions aij ai .
furthermore both sets of newly inferred features are initially disconnected from any previously generated features.
to reconcile these disparate inferences we enter the aggregation phase.
to manage the aggregation we employ two interconnected databases.
feature database fd the feature database fd is a vector database storing a global list of discovered features.
each entry in fd contains a label i.e.
a textual description of the feature its corresponding embedding and a confidence score derived from equation .
this score reflects the likelihood of the feature s existence within the application.
action feature database afd fd is complemented by the action feature database afd .
each row in afd associates an action within a state with its corresponding inferred features from fd.
additionally it records a rank score calculated using equation and indicates whether the inference utilized solely the current action aijor both the current state s action and preceding action aij ai 1as context.the information stored in fd and afd is dynamic evolving as the application is explored.
these databases continuously interact influencing each other to update the overall confidence scores of features.
this iterative refinement ensures that the feature model remains accurate and comprehensive as new observations are made.
mapping inferred features to fd to update feature scores we first map the newly inferred features to existing entries in the fd.
this is achieved by leveraging the textual embeddings of feature descriptions stored in fd.
we query fd using the embedding of an inferred feature and retrieve the top results based on cosine similarity.
this metric identifies features in fd that are semantically closest to the inferred feature.
by establishing these connections we can then update the confidence scores of the corresponding features in fd incorporating the information gained from the new observations.
while querying the fd using textual embeddings can identify semantically similar features it does not guarantee a perfect match.
to ensure accuracy we introduce an additional validation step using an llm.
this step involves querying the llm to assess whether the inferred feature aligns with any of the similar feature descriptions retrieved from fd.
the llm acts as a semantic arbiter determining if any of the retrieved descriptions truly describe the same feature.
listing provides a concrete example of this process showcasing how the llm helps refine the initial matches obtained from fd for an add to cart action s feature in figure 1d.
a feature inferred for an action add a product to the cart fd retrieval results adding to the cart exact match view product details mismatch remove item from the cart mismatch explore product categories mismatch navigate to homepage mismatch listing example for fd querying if no match is found in fd this indicates that the feature is a novel observation within the application.
in such cases the feature data along with an initial confidence score of is inserted into fd.
following the matching or insertion of a feature in fd we then create a corresponding entry in the afd.
this entry includes a pointer to the relevant fd entry establishing the connection between the two databases.
with these updates in place we can then proceed to refine the confidence score of the feature in fd incorporating the information gained from the new observation.
updating the scores for each action aij we have inferred a corresponding set of features fj1 fj2 .
.
.
as detailed in section iii c. to update the feature scores based on these new observations we employ the following formula derived from equations and score update fjk rank score fjk aij ai rank score fjk ai this formula calculates the change in the score for feature fjk the kth feature associated with action aij based on the observed action sequence.
the first term rank score fjk aij ai represents the probability of the feature given both the current and preceding actions.
the second term rank score fjk ai represents the probability of the feature given only the preceding action.
the difference between these two terms reveals the incremental impact of action aijon our confidence in the existence of feature fjk.
to address cases where feature fjkexists in the llm s inference for aij ai but not for ai we substitute the rank score fjk ai term in equation with the constant ranking score from equation .
using the score update formula we then locate fjk s corresponding entry in fd and update its score.
this process is repeated throughout the app exploration.
e. generating test cases following the exploration phase we sort the features within the fd.
from this sorted list we filter and retain the topscoring features as those identified within the application.
this filtering process involves selecting a lower bound cutoff determined by equation as log p .
this choice of cutoff is motivated by the possibility of single action features which could be correctly predicted by the llm with a rank of and a corresponding score of log p .
by setting the cutoff at this value we ensure the inclusion of such features in our generated tests.
after filtering we then extract the corresponding chains of actions from the afd and translate them into test cases.
this process leverages the accumulated evidence gathered during exploration to identify the most likely features and their associated action sequences ultimately generating test cases that semantically cover the application features.
f .
implementation autoe2e is implemented in python using the langchain framework offering flexibility in llm selection.
for our evaluations we opted for c laude .
s onnet due to its recognized performance among the most advanced llms.
textual embeddings for feature descriptions and fd utilize the ada architecture and the e2e tests are generated in selenium .
our databases fd and afd are hosted on mongodb atlas1 which provides a vector search functionality well suited for querying the feature description embeddings.
iv.
b enchmark construction assessing e2e test cases presents a significant challenge in software testing automation.
to the best of our knowledge there is an absence of datasets for e2e test case evaluation that hinders further progress in this area of study.
to address this gap we embarked on the creation of such a benchmark called e2eb ench .
this section elucidates the complexities inherent in dataset creation and outlines the methodological steps undertaken to achieve this goal.
benchmark construction challenges.
the lack of a benchmark for assessing feature coverage in e2e test cases arises the inherent challenges of evaluating this metric.
as evident in definition this evaluation hinges on two critical steps identifying the features within an application and mapping e2e test cases to these features to measure coverage.
the first challenge in this process is the identification and quantification of features within a web application.
features are often difficult to define and vary widely depending on the context making their extraction difficult and subjective.
once features are identified the second challenge is determining which specific feature a test case targets.
this becomes particularly complex in large scale applications like amazon illustrated in figure where a feature such as viewing the product s details can be accessed through multiple pathways whether by clicking on a product from the landing page filtering through categories or using the search function.
as the number of available actions increases so does the complexity of tracking these diverse paths.
for example the amazon web application with millions of products could have numerous valid e2e test cases for viewing product details each following a distinct path.
an effective evaluation tool must be capable of accounting for and managing this inherent path redundancy.
feature identification.
regarding the first challenge we have established a precise and formal definition of a feature definition in this work providing a foundation for systematic and objective identification of features within software applications.
instrumentation for feature mapping.
to address the second challenge in mapping test cases to features we need to track user i.e.
e2e test interactions within web applications.
to automate this tracking we select open source web applications for our benchmark enabling us to directly instrument their code.
the instrumentation adds logging mechanisms to capture every user action within the app encompassing clicks hovers and various input types selects texts radio buttons checkboxes .
each unique action component within the app generates a distinct log message containing a unique identifier.
to handle path redundancy we leverage the inherent modularity of web applications.
for example consider an open source e commerce application products are typically rendered using a collection of product components.
by leveraging this component based structure we can instrument component code to track the interactions by the e2e test cases.
this approach effectively circumvents the challenge of nearinfinite pathways as each action within a path is implemented within a discrete component regardless of its frequency of occurrence.
feature grammar extraction.
with the tracking system established we then map the chain of logs to specific features within each subject application.
this process involves identifying the available features for each subject in the benchmark and executing sequences of actions to trigger them while tracking the corresponding logs.
these logs are subsequently transformed into a feature grammar which serves as a groundtruth reference for assessing e2e test cases.
to illustrate asample feature grammar for purchasing a product in an ecommerce application would be the following c1 product element c10 add to cart c22 cart icon c12 checkout button t5 credit number t16 credit date t23 credit cvv c35 complete purchase listing feature grammar for product purchase in this feature grammar the sequence of actions begins by clicking on the product followed by adding it to the cart and navigating to the cart page.
subsequently the checkout button is clicked leading to the purchase page where credit card information is required.
the input fields for credit card details can be filled in any order represented by the logical or operator.
additionally the information in the text boxes can be modified multiple times denoted by the sign indicating repetition.
finally the purchase is completed by clicking a confirmation button.
the extraction of feature grammar for each subject was conducted independently by each author followed by a collaborative discussion to consolidate the findings.
this iterative process ensured a comprehensive identification of features with consensus reached on both the features themselves and any alternative paths to achieve the same functionality.
the resulting grammars then serve as a basis for evaluating the coverage of a test suite over all of the functionalities.
benchmark subjects.
a list of the apps in our benchmark is available in table i. these applications most of which have been previously used in web testing research encompass a diverse range of categories including bug tracking mantisbt e commerce saleor and translation management evertraduora .
automatic coverage evaluation.
during test case execution our benchmark continuously monitors the performed actions trying to map the sequence to one of the identified functionalities within the application.
this allows us to assess the coverage of an e2e test suite across all the distinct features in our benchmark subjects.
the calculation of feature coverage is performed completely automatically based on the grammar extracted in the previous phase resulting in an objective measurement of the feature coverage definition .
v. e valuation we have framed the following research questions to measure the effectiveness of a utoe2e rq1 how effective is a utoe2e in generating featuredriven e2e tests?
rq2 how accurate is the feature inference of a utoe2e?
rq3 how does a utoe2e compare to other state of theart techniques?
process.
we use e2eb ench to evaluate the efficacy of autoe2e and other methods in achieving feature coverage.
for running our experiments we set the temperature parameter of the llms to to produce the same response every time.table i benchmark subjects app name category features loc petclinic health 51k conduit blog 53k taskcafe task manager 67k dimeshift expense tracker 10k mantisbt bug tracker 118k evertraduora translation manager 25k saleor storefront e commerce 58k saleor dashboard e commerce admin .1m baselines.
to the best of our knowledge no existing technique directly addresses feature driven e2e test generation.
recent advances in llm based agents such as w ebcanvas and b rowser gym have demonstrated the potential to navigate web applications and execute user instructions.
however adapting these agents for e2e test generation poses several challenges.
first they often require pre existing feature extraction which is the primary focus of our approach.
second these agents may struggle to interpret abstract task descriptions and instead require concrete detailed instructions for execution.
to assess the effectiveness of our proposed methodology we evaluate a utoe2e against these specific purpose agents w ebcanvas and b rowser gym both of which utilize gpt4oas their underlying llm.
we also compare a utoe2e with more generalized agents autogpt which employs gpt ofor both task planning and execution and opendevin a code focused agent that utilizes the c laude llm.
additionally we benchmark against a model based technique represented by c rawljax s test generation module .
all agents are instructed to navigate web applications and generate end to end e2e test cases.
a. effectiveness rq1 the primary objective of our method is to maximize the extent of feature coverage as defined in definition .
as described in section iii a utoe2e generates a set of e2e test cases.
we evaluate the generated tests using the methodology detailed in section iv.
autoe2e demonstrates the ability to generate test cases that cover an average of of features across the applications in the e2eb ench benchmark.
considering all features across all applications a utoe2e achieves a total feature coverage of .
a more granular breakdown of the feature coverage for each app is presented in the recall column of table ii.
these results underscore the effectiveness of autoe2e in effectively inferring features and generating corresponding test cases across a diverse range of applications.
b. feature inference rq2 as described in section iii a utoe2e infers a list of features along with their scores by the end of the inference phase.
table ii provides statistics for both correct and incorrect predictions within the inferred feature list.
a utoe2e achieves a total precision of .
indicating that of the generatedtest cases were correct based on the evaluation metrics.
the total recall of the model which is the same as the average feature coverage across all features in all applications reaches .
.
this means that our generated test cases successfully cover of the total features present.
the precision and recall values result in an f1 score of .
demonstrating a reasonable balance between a utoe2e s ability to identify relevant test cases and its ability to capture the full spectrum of application features.
table ii inference statistics app name total correct precision recall f1 petclinic .
.
.
conduit .
.
.
taskcafe .
.
.
dimeshift .
.
.
mantisbt .
.
.
evertraduora .
.
.
storefront .
.
.
dashboard .
.
.
total .
.
.
however the effectiveness of our approach is not solely determined by the number of correct features.
as detailed in section iii we employ a scoring and filtering system to prioritize feature generation and test case creation.
if this system functions as intended features with higher scores should be more likely to correspond to actual features within the application.
figure illustrates the coverage of top kfeatures in relation to the ratio of kto the total number of features present in the application referred to as the rank ratio .
the left half of this figure demonstrates the coverage against the rank ratio for autoe2e while the lower half displays the moving average of coverage for a utoe2e and the baseline methods.
in an ideal scenario where all top kinferred features are accurately identified the plotted line would follow a degree trajectory.
the figure reveals the extent of coverage achieved as the feature list expands to encompass more candidates.
as evident in the figure a utoe2e generally follows the expected degree line up to a rank ratio of approximately .
.
this indicates that on average for an application with nfeatures the first .75ngenerated test cases are almost all correct.
however a divergence is observed beyond this point suggesting that while the remaining generated test cases may be correct in certain instances they do not consistently cover features with the same level of accuracy.
c. comparison rq3 we evaluated the generated tests by each baseline against e2eb ench as described in section iv.
the feature coverage results for different subjects and baselines are presented in figure .
a utoe2e achieves an average feature coverage rate of significantly outperforming c rawljax .
w ebcanvas b rowser gym .
a utogpt .
and o pendevin .
.
notably a utoe2e surpasses the0.
.
.
.
.
expected petclinic storefrontconduit taskcafe traduoradimeshift mantisbt dashboard .
.
.
.
.
expected autoe2eopendevin autogptbrowsergym crawljax rank ratiofeature coveragefig.
feature coverage vs. rank ratio next best performing tool c rawljax by and best agent based tool b rowser gym by .
w ebcanvas has not been included in figure since it did not generate any test cases.
the f1 scores for the generated test cases were .
for crawljax .
for b rowser gym .
for a utogpt and .
for o pendevin compared to .
for a utoe2e.
feature complexity while the coverage rate treats all features equally it is important to acknowledge that features vary in complexity.
some features within an application necessitate longer chains of ordered actions to be successfully executed.
different tools may encounter difficulties with extended action chains due to the challenge of maintaining context over longer periods.
table iii provides a statistical analysis of action chain complexity across different tools.
the average length of feature chains in the benchmark is .
actions.
notably a utoe2e demonstrates proficiency in handling longer chains averaging .
actions per feature compared to .
for c rawljax .
for b rowser gym .
for a utogpt and .
for o pendevin .
test case count the number of test cases generated varies across different tools as each tool employs its own criteria for determining the appropriate quantity.
this raises petclinicstorefrontconduittaskcafe traduora dimeshift mantisbtdashboard0 feature coverageautoe2e opendevinautogpt crawljaxbrowsergymfig.
feature coverage of different methods on the subjects table iii feature action chain length tool name min max average median autoe2e .
crawljax .
webcanvas .
browser gym .
autogpt .
opendevin .
all features .
the question of whether forcing a tool to generate more test cases would necessarily lead to increased feature coverage.
the lower half of figure sheds light on this by illustrating the moving average of feature coverage for the methods across all subjects.
notably the baselines reach a plateau in coverage at a relatively low rate suggesting that simply increasing the number of test cases does not guarantee a corresponding increase in feature coverage.
vi.
d iscussion the framework developed in this work particularly the findings from section iii a is platform and implementationagnostic.
this means the underlying principles can be extended to generate test cases for other platforms such as mobile applications.
furthermore this implementation independence allows for significant potential improvements in performance and cost effectiveness in future iterations as the framework is not rigidly tied to any specific technology or tool.
additionally the introduction of e2eb ench provides a standardized and automated means of evaluating e2e test case generation techniques.
this benchmark fills a crucial gap in the research community enabling more rigorous comparison and development of novel approaches in the field of automated e2e test generation.
limitations.
despite its strengths our approach has limitations.
currently a utoe2e focuses on a one to one mapping between test cases and features whereas real world scenariosoften require multiple test cases per feature to assess diverse interactions.
additionally our implementation generates assertions using the entire state after each action which may not always be the most meaningful or targeted approach.
threats to validity.
it is important to acknowledge potential threats to the validity of our findings and the steps taken to mitigate them.
one such threat lies in the representativeness of the web applications selected for e2eb ench .
to address this we have carefully curated a diverse set of applications spanning a wide range of categories.
this diversity aims to enhance the generalizability of our results and reduce potential biases associated with specific application types.
another potential threat stems from the inherent subjectivity in defining and extracting features.
to mitigate this we have established a precise and formal definition of a feature definition .
furthermore we employed multiple authors in the feature identification process during benchmark construction promoting a more objective and comprehensive perspective.
finally the use of different llms in the evaluation process could pose a threat to validity.
while our goal was to maintain consistency by utilizing the same llms across all methods certain constraints necessitated variations.
specifically among the selected agents and baselines only o pendevin supported c laude .
s onnet while others a utogpt webcanvas browser gym lacked support for anthropic models at the time of evaluation requiring the use of gpt4o.
however it is important to note that both c laude .
sonnet and gpt oexhibit very similar performance in reported benchmarks .
therefore we anticipate that these variations in llm usage would not significantly impact the overall performance trends observed in our evaluation.
vii.
r elated work web navigation agents.
in the academic context extensive research has been conducted on automating the execution of tasks defined in natural language .
the aim is for an agent to determine and execute a sequence of actions within a web application that fulfills these instructions.
this research is divided into two principal categories traditional methods utilizing reinforcement learning rl agents and newer approaches that focus on llms.
the traditional techniques involve deep learning models to translate natural language instructions into embeddings .
these embeddings are then mapped to specific actions on the web page.
variations in these methods are seen in the architecture of the deep learning models the strategies of the rl policies and how actions are modeled.
additionally some methods might include or omit certain components.
techniques in this category often incorporate demonstrations by expert users use heuristics based on human designed systems or confine the agent s actions to a predetermined set .
contrastingly newer methods leveraging llms typically forgo the rl training phase.
these models delegate the decision making about subsequent actions to the llms .
these newer agents have been proposed by academic research open source communities and large scale companies .
llm based testing.
recent studies have increasingly focused on using llms to automate software and web testing processes.
some research concentrates on software unit test generation .
some studies focus on accessibility testing utilizing llms to identify and address accessibility issues .
other studies have directed their attention towards gui testing including software gui testing and mobile application gui testing .
our recent work has focused on automated web form testing where llms simulate user interactions and validate form functionalities through constraint based testing .
e2e test generation.
a specific but less extensive area of research focuses on generating end to end e2e test scenarios.
earlier approaches in this field worked on mapping applications to page objects and creating test cases for them .
however recent studies use llms for automated test generation .
for example a recent prominent study uses prompting patterns to track executed actions directing the llm to select actions based on the high level task in the application.
these actions are then formulated into test cases for the overarching task.
viii.
c onclusion automated e2e test case generation remains challenging.
in this paper we formally defined the problem introduced a novel methodology a utoe2e for feature driven test generation and developed e2eb ench a benchmark for automated evaluation.
a utoe2e achieves feature coverage outperforming baselines by .
future work includes enhancing autoe2e s performance and exploring assertion generation for more comprehensive test coverage.
ix.
d ata availability we have made a utoe2e and e2eb ench publicly available to facilitate reproducibility of our results.
detailed instructions for replicating our experimental setup are also provided.