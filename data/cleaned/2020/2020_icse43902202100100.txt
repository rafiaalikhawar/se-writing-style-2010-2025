white box analysis over machine learning modeling performance of configurable systems miguel velez carnegie mellon universitypooyan jamshidi university of south carolinanorbert siegmund leipzig university sven apel saarland informatics campus saarland universitychristian k stner carnegie mellon university abstract performance influence models can help stakeholders understand how and where configuration options and their interactions influence the performance of a system.
with this understanding stakeholders can debug performance behavior and make deliberate configuration decisions.
current black box techniques to build such models combine various sampling and learning strategies resulting in tradeoffs between measurement effort accuracy and interpretability.
we present comprex a white box approach to build performance influence models for configurable systems combining insights of local measurements dynamic taint analysis to track options in the implementation compositionality and compression of the configuration space without relying on machine learning to extrapolate incomplete samples.
our evaluation on widely used open source projects demonstrates that comprex builds similarly accurate performance influence models to the most accurate and expensive black box approach but at a reduced cost and with additional benefits from interpretable and local models.
i. i ntroduction configuring software systems is often challenging.
in practice many users execute systems with inefficient configurations in terms of performance and often directly correlated energy consumption .
while users can adjust configuration options to tradeoff between performance and the system s functionality this configuration task can be overwhelming many systems such as databases web servers and video encoders have numerous configuration options that may interact possibly producing unexpected and undesired behavior.
for this reason understanding how options and their interactions affect the system s performance and making suitable configuration decisions can be difficult users often have at most vague intuitions .
we aim at efficiently building performance influence models without machine learning that characterize how options influence the system s performance.
we intent our models to be easy to inspect and interpret by developers and users to ease performance debugging and to make informed configuration decisions.
good performance influence models help users understand how where and why options and their interactions influence the performance of the system in a specific way .
in the situations where these models are useful simple manual experiments are often not practical due to a system s exponentially large configuration space.
for example a developer considering whether to enable encryption would likely expect that encryption would slow down the system.
however the interpretable x not interpretable r50 random configurations r200 random configurations lr stepwise linear regression rf random forest comprex our approach cost minutes error mape 20comprex xr200 rf r200 lr xr50 rf1000 r50 lrdensity converter fig.
our white box approach comprex builds similarly accurate low error performance influence models to the most accurate and expensive sampling and machine learning approaches but can often be built more efficiently low cost and are interpretable.
additionally our models are significantly more accurate than other sampling and machine learning approaches that produce interpretable linear models.
developer may need to perform numerous experiments to quantify the effect of the option itself and of its interactions with other configuration decisions in a given environment and workload.
to understand why and where encryption causes the slow down a developer would have to carefully profile or debug the system in different configurations.
most existing techniques build global performanceinfluence models and treat the system as a black box measuring the system s execution in an environment with a given workload for a subset of all configurations and learning a model from these observations.
the sampling i.e.
selecting which configurations to measure and learning techniques used result in tradeoffs among the cost to build the models and the accuracy and interpretability of the models .
for example larger samples are more expensive but usually lead to more accurate models random forests with large enough samples tend to learn more accurate models than those built with linear regression but the models are harder to interpret when users want to understand performance or debug their systems see fig.
.
in this paper we introduce comprex a white box approach to build accurate interpretable and local performance10722021 ieee acm 43rd international conference on software engineering icse .
ieee influence models at low cost.
our approach departs drastically from traditional black box approaches it analyzes and instruments the source code to accurately capture configuration specific performance behavior without relying on machine learning to extrapolate incomplete samples.
we reduce measurement cost by simultaneously analyzing and measuring multiple code regions of the system building a local linear performance influence model per region with a few configurations an insight we call compression .
subsequently we compose the local models into a global model for the entire system.
we use an iterative dynamic taint analysis to identify where and how load time configuration options influence control flow statements in the system through control flow and data flow dependencies.
our empirical evaluation on 4medium to large scale widely used open source projects demonstrates that comprex builds similarly accurate performance influence models to those learned with the most accurate and expensive black box approach but at a reduced cost.
furthermore comprex generates interpretable and local models which quantify the influence of individual options and interactions on performance and can even map the influence to code regions.
in summary we make the following contributions an approach that combines compression andcomposition to accurately infer the influence of options on the performance of numerous independent regions of a system with a few configurations composing the influence in a full performance model.
an iterative dynamic taint analysis to identify how configurations influence the performance of independent regions and a conjecture to reduce the cost of running the analysis to build accurate performance influence models.
an empirical evaluation on 4medium to large scale open source systems demonstrating that our white box approach builds interpretable but similarly accurate models with less cost compared to the state of the art.
a replication package with subject systems experimental setup and data of several months of measurements .
ii.
p erformance models for config .
systems there is substantial literature on modeling the performance of software systems .
performanceinfluence models solve a specific problem explaining how options and their interactions influence a system s performance for a given workload and environment designed to help users understand performance and make deliberate configuration decisions.
traditional performance models are typically used by designers and developers to model and analyze the performance of a system s architecture e.g.
using queuing networks petri nets and stochastic process algebras and workload in the design stage of a project .
at this stage design decisions are usually modeled as configuration options .
by contrast performance influence models describe the performance behavior of a system implementation1defmain list workload 2a getopt a b getopt b 3c getopt c d getopt d ... execution 1s 5inti tmain 1a 6if a variable depends on option a ... execution 1s foo b variable depends on option b i 10else ... execution 2s i 13while i bar c variable depends on option c i 16deffoo boolean x tfoo 1a 3ab 17if x ... execution 4s 18else... execution 1s 19defbar boolean x tbar 15a 10c 30ac 20if x ... execution 3s 21else... execution 1s fig.
example system with three colored regions methods influenced by configuration options.
local performance influence models for a specific workload are shown per region.
in a given workload and environment and are typically learned by observing the behavior of the system implementation.
in the context of configurable systems performanceinfluence models predict a system s performance in terms of configuration options and their interactions .
some models are explicitly designed toexplain how specific options and their interactions influence a system s performance .
for example the sparse linear model 15a 10c 3ab 30ac captures the execution time of the system in fig.
which predicts the performance of arbitrary configurations and explains how the optionsa b andcand their interactions influence the system s performance.
the model can be inspected by developers for example to determine whether the large performance impact when combining aandcis an unexpected performance bug.
building performance influence models performanceinfluence models are typically built by measuring a system s execution time with the target workload in the target environment under different configurations .
almost all existing approaches are black box in nature they do not analyze the system s implementation and measure the end to end execution time of the system.
the simplest approach is to observe the execution of all configurations in a brute force approach.
the approach obviously does not scale as the number of configurations grows exponentially with the number of options.
in practice most approaches measure executions only for a sampled subset of all configurations and extrapolate performance behavior for the rest of the configuration space using machine learning which we collectively refer to as sampling and learning approaches.
specific approaches differ in how they sample learn and represent models common sampling techniques include uniform random feature wise and pair wise sampling design of experiments and combinatorial sampling .
common learning techniques include linear regression regression 1073trees fourier learning and neural networks .
different sampling and learning techniques yield different tradeoffs between measurement effort prediction accuracy and interpretability of the learned models .
goals of performance influence modeling performanceinfluence models can be used for different tasks in different scenarios which benefit from different model characteristics.
in the simplest case a user wants to optimize a system s performance by selecting the fastest configuration for their workload and in the target environment.
performance influence models have been used for optimization though metaheuristic search e.g.
hill climbing is often more effective at pure optimization problems as they do not need to understand the entire configuration space.
in other scenarios users want to predict the performance of individual configurations.
scenarios include automatic reconfiguration andruntime adaptation where there is no human in the loop and online search is impractical.
for example when dynamically deciding during a robot s mission which options to change to react to low battery levels .
in these scenarios the model s prediction accuracy is important across the entire configuration space but understanding the structure of the model is not important.
in this context deep regression trees fourier learning and neural networks are commonly used which build accurate models but are not easy to interpret by humans .
when performance influence models are used by users to make deliberate configuration decisions e.g.
whether to accept the performance overhead of encryption interpretability regarding how options and interactions influence performance becomes paramount.
in these settings researchers usually suggest sparse linear models such as 15a 10c 3ab 30ac above typically learned with stepwise linear regression or similar variations .
in such models users can directly recognize the influence of an option or an interaction.
in addition to end users who configure a system developers who maintain the system can also benefit from performanceinfluence models to understand and debug the performance behavior of their systems .
for example when presenting performance influence models to developers in high performance computing kolesnikov et al.
reported that a developer was surprised to see that had only a small influence on system performance indicating a potential bug.
in such setting understanding how individual options and interactions influence performance is again paramount favoring interpretable models.
ideally models would also indicate where the influence occurs in the implementation.
for example in prior work we shared experience of how mapping performance influence of options to specific code regions was useful in identifying several inconsistencies between documentation and implementation.
in this paper we build performance models that can be used in all of these scenarios.
the models are accurate for optimization and prediction they are interpretable explaining how options and interactions influence performance and they!
.
.
fig.
building performance influence models is compositional instead of building a single model for the entire system dotted black arrow we can simultaneously build a local model per region and compose those models dashed blue arrows .
map performance influence to code regions explaining where performance influence manifests.
our white box approach comprex builds these models by analyzing and observing system internals without using machine learning.
iii.
c omprex we introduce comprex a white box approach to efficiently and accurately generate performance influence models without using traditional sampling and learning techniques.
similar to black box approaches we build performanceinfluence models by observing the execution of a system in different configurations but we guide the exploration with a white box analysis of the internals of the system.
for a given input a system with a set of boolean options ocan exhibit up to2 o distinct execution paths one per configuration.1if we measure the execution time of each distinct path we can build a performance influence model that accurately maps performance differences to options and their interactions without any approximation through machine learning.
the resulting models can be expressed as familiar linear models.
our approach to efficiently build performance influence models relies on two insights performance influence models can be built compositionally by composing models built independently for smaller regions of the code cf.
fig.
.
multiple performance influence models for smaller regions can be built simultaneously by observing a system s executions often with only a few configurations which we call compression.
first building performance influence models is compositional we can measure the performance of smaller regions in the system e.g.
considering each method as a region and build a performance influence model per region separately which describes each region s performance behavior in terms of options.
subsequently we can compose the local models to describe the performance of the entire system computed 1for simplicity we describe comprex in terms of boolean options but other option types can be encoded and discretized.
the distinction between inputs and options is subjective and domain specific.
we consider options as special inputs with a small finite domain e.g.
boolean that a user might explore to change functionality or influence quality attributes.
we consider fixed values for other inputs.
note that a user might fix some configuration options and consider alternative values for inputs e.g.
use an option for different workloads .
however we explore the performance influence of options with finite domains assuming all other inputs are fixed at specific values.
this setting results in a finite but typically very large configuration space.
!
.
.
.
.
.
?
a 9b .
8a9 .
c .
a 9b .
d e .
.
a .
.
.
f c4.
d d e m 16a 10c ... b e .
.
fig.
overview of comprex s three components.
as the sum of the individual influences in each model e.g.
composing 4a and1 1a 2b to6 3a 2b .
compositionality helps reduce the cost of our approach as many smaller regions of a system are often influenced only by a subset of all options confirmed by prior empirical research .
hence the number of distinct paths to observe in a region is usually much smaller than the number of distinct paths in the entire system.
if we have an analysis that can identify the subset of options that directly and indirectly influence the smaller region see sec.
iii a we can build a local performance influence model by observing all distinct paths in a region often with only a few configurations.
second compression makes our approach scale without relying on machine learning approximations when executing a single configuration we can simultaneously observe the execution of multiple regions.
in addition if the regions are influenced by different options a common case confirmed by prior research then we can separately measure in one configuration the influence of different options in different regions in the system instead of exploring all combinations of all options.
for example three independent regionsif a if b if c influenced by optionsa b andc respectively each have two distinct paths.
instead of exploring all 8combinations of the three options we can explore all distinct paths in each region with only2configurations as long as each option is enabled in one configuration and disabled in the other configuration.
our approach combines compositionality and compression to build accurate performance influence models without traditional sampling or machine learning techniques.
the resulting models can be presented in an interpretable format and even be mapped to individual code regions.
key to our approach is the property that not all options interact in the same region instead influencing different parts of the system independently a pattern observed empirically in configurable systems .
to operationalize compression and compositionality for building accurate and interpretable performance influence models with low cost we need three technical components as illustrated in fig.
first we identify which regions are influenced by which options to select configurations to explore all paths per region and to map measured execution times to options and their interactions sec.
iii a .
second we execute the system to measure the performance of all regions sec.
iii b .
third we build local performance influence models per region and compose them into one global model for the entire system sec.
iii c .
a. analyzing options influence on regions as a first step we identify which options directly or indirectly influence control flow decisions in which code regions.
we use this information to select configurations to explore all paths per region and map measured performance differences to options and their interactions sec.
iii b .2to this end we track information flow from configuration options sources to control flow decisions sinks in each region.
if a configuration option flows directly or indirectly including implicit flows into a control flow decision in a region this implies that selecting or deselecting the option may lead to different execution paths within the region.
thus we should observe at least one execution with a configuration in which the option is selected and another execution in which the option is not selected.
more specifically we conservatively partition the configuration space per region into subspaces such that every configuration in each subspace takes the same path through the control flow decisions within a region and that all distinct paths are explored when taking one configuration from each subspace.
formally a set of boolean options oforms a configuration space c p o where each configuration c cis represented by the set of selected options.
a partition of the configuration space p p c is a grouping of configurations into nonempty subsets which we call subspaces such that each configuration is part of exactly one subspace.
for notational convenience we describe subspaces using propositional formulas over options.
for example llbracketa b rrbracket describes the subspace of all configurations in which option ais selected and option bis deselected.
to track information flow between options and control flow decisions in regions we employ a dynamic taint analysis and iteratively collect information through repeated executions of the system in different configurations until we have explored all distinct paths in each region.
a taint analysis typically used in the security domain tracks how values are affected by selected inputs sources and are used in specific locations sinks .
during each execution we track how api calls load configuration options lines in fig.
sources and propagate them along data flow and control flow dependencies including implicit flows to the decisions of control flow statements sinks .
we use a dynamic rather than a static analysis since it scales to larger systems and avoids some overtainting problems by tracking actual executions .
incrementally partitioning the configuration space alg.
describes how we partition the configuration space per region based on incremental updates from our dynamic taint analysis.
intuitively we execute the system in a configuration 2we focus on different execution paths caused by configuration changes fixing all other inputs.
we focus on configuration changes in control flow statements as a system s execution time changes in those statements depending on which branch is executed and how many times it is executed confirmed by empirical research .
execution differences caused by nondeterminism are orthogonal and must be handled in conventional ways e.g.
averaging multiple observations or controlling the environment .
1075algorithm iterative dynamic taint analysis input configurable system p output partition for each region r p p c 1functionpartion all regions p partitions r c executed configs untilexplored all subspaces executed configs partitions do cc get next config executed configs partitions executed configs executed configs cc duringexecute taint analysis p cc when reaching a control flow decision with taints tdandtcin region r partitions partitions get part t d tc cc end end return partitions 11end input executed configurations ec p c partitions r p p c output true orfalse 12functionexplored all subspaces ec partitions all subspaces uniontextimage partitions return s all subspaces.
c ec.
c s 15end input data flow taints td control flow taints tc current configuration cc output partitionp p p c for the current decision 16functionget part t d tc cc 17sreach c c o tc.
o c o cc 18p braceleftbig c sreach bracerightbig subspace of config.
that might not reach decision add one subspace for every combination of options in data flow taints fora p td do s braceleftbig c c o td.
o c o a bracerightbig p p s sreach end returnp 24end and observe when data flow and control flow taints from options reach each control flow decision in each region and subsequently update each region s partition whenever we reach a control flow statement during execution we identify based on taints that reach the condition of the statement the sets of configurations that would possibly make different decisions thus updating the partition that represents different paths for this region line .
since a dynamic taint analysis can only track information flow in the current execution but not for alternative executions i.e.
for paths not taken we repeat the process with new configurations selected from the partitions identified in prior executions updating partitions until we have explored one configuration from each subspace of each partition main loop line that is until we have observed each distinct path in each region at least once.
note that some subspaces in the region might make the same control flow decision as other subspaces but we do not know which subspace will make which decision until we actually execute those configurations.
updating partitions works as follows when we reach a control flow statement in a region with data flow taints td this indicates that the options in tdaffect the control flow decision but other options do not.
thus we know that all configurations that share the same selection for all options in tdwill result in the same control flow decision while configurations with different selections of these options may result in different decisions.
since the taint analysis tells us only that the options in tdmay somehow directly or indirectly affect the decision s condition but not how we will need to explore at least one configuration for every possible assignment to these options even though multiple or even all may end up takingthe same branch.
therefore we partition the configuration space at this decision corresponding to all combinations of the options in td lines .
for example for a decision influenced by options aandb we partition the configuration space into four subspaces all configurations in which aandb are selected together all configurations in which ais selected but notb all configurations in which bis selected but not a and all configurations in which neither anorbare selected.
finally we update the region s partition with the partition derived for the decision by computing their cross product line .
this operation reflects that to explore all paths among multiple control flow decisions in a region including multiple executions of the same control flow statement we need to explore all combinations of the individual paths in the region.
distinguishing data flow taints from control flow taints allows us to optimize the exploration of nested decisions e.g.
if a if b ... .
control flow taints specify which options directly or indirectly influenced outer control flow decisions which indicates that different assignments to options in the control flow taints may lead to paths where the current decision is not reached in the first place.
hence we do not necessarily need to explore all interactions of options affecting outer and inner decisions.
instead of exploring combinations for all options of data flow and control flow taints we first split the configuration space into those configurations for which we know that they will reach the current decision as they share the assignments of options in control flow taints sreach line and the remaining configurations which may not reach the current decision c sreach line .
then we only create subspaces for interactions of options in data flow taints within sreach lines and consider the entire set of configurations outside sreach as a single subspace line .
the iterative nature of our analysis ensures that at least one of the configurations outside sreach will be explored and if the configuration also reaches the same decision the region s partition will be further divided.
the iterative analysis executes the system in different configurations until one configuration from each subspace of each partition in each region has been explored.
that is we start by executing any configuration e.g.
the default configuration which reveals the subspaces per regions that could make different decisions.
the algorithm then selects the next configuration to explore unseen subspaces in the regions line which may further update the regions partitions.
to select the next configuration we use a greedy algorithm to pick a configuration that explores the most unseen subspaces across all regions.
example we exemplify running the iterative analysis in our running example from fig.
considering each method as a region.
if we execute the configuration a d in which optionsaanddare selected and the other options are 3to avoid enumerating an exponential number of configurations we use a greedy algorithm that picks a random subspace and incrementally intersects it with other non disjoint subspaces which seems sufficiently effective in practice.
the problem can also be encoded as a maxsat problem representing subspaces as propositional formulas to find the configuration that satisfies the formula with the most subspaces.
1076deselected the taint analysis will indicate that the value of the variable ais tainted by option a from line when reaching the ifstatement in line region main .
thus all configurations in which ais selected result in the same controlflow decision and all configurations in which ais not selected result potentially in the same or a different decision.
hence we derive the initial partition llbracketa rrbracket llbracket a rrbracket for this method.
continuing the execution we next reach the ifstatement in line region foo where the value of the variable xis tainted with control flow taint a from line and data flow taint b from variable b .
thus all configurations in whichaandbare selected result in the same control flow decision all configurations in which ais selected and bis not selected may result in a different control flow decision and all configurations in which ais not selected may not reach this decision.
hence we derive the partition llbracketa b rrbracket llbracket a rrbracket llbracketa b rrbracket for this region.
note how we explore this nested ifstatement with 3instead of 4subspaces by separately tracking data flow and control flow taints.
further in the execution the decision in the while statement line depends on the tainted value of the variablei implicit flow in each loop iteration resulting in llbracketa rrbracket llbracket a rrbracket which is consistent with main s existing partition.
hence the cross product does not change the partition.
similarly the decision in line region bar repeatedly depends on data flow taint cand control flow taint a resulting in the partition llbracketa c rrbracket llbracket a rrbracket llbracketa c rrbracket .
after this first execution we identified six distinct subspaces among the partitions of the three regions llbracketa rrbracket llbracket a rrbracket llbracketa b rrbracket llbracketa b rrbracket llbracketa c rrbracket and llbracketa c rrbracket of which llbracketa rrbracket llbracketa b rrbracket and llbracketa c rrbracket were explored with the initial configuration.
in the next iteration we select a configuration for example a b c to explore unseen subspaces in the regions and update partitions.
in this case however nothing changes.
we continue executing new configurations to explore unseen subspaces possibly updating the regions partitions until we have explored all subspaces in the regions.
after executing only 4out of16configurations for example a d a b c and c we have explored at least one configuration from each subspace of each partition in each region and the iterative analysis terminates.
the subspaces derived for the three regions s partitions are llbracketa rrbracket llbracket a rrbracket llbracketa b rrbracket llbracketa b rrbracket llbracket a c rrbracket llbracket a c rrbracket llbracketa c rrbracket llbracketa c rrbracket.
discussion note how the iterative analysis explores regions independently and does not explore paths for options that do not influence that region e.g.
we do not explore the interaction of bandcand never explore configurations specifically for d .
also note how the taint analysis tracks both direct and indirect dependencies interprocedurally.
the iterative analysis is guaranteed to terminate as it explores new configurations during each iteration.
in the worst case all configurations in the system finite set will be executed but in practice often much fewer executions are needed.
our algorithm will produce the same partitions independent of the order in which configurations are executed.
all subspaces that are derived during any execution of the taint anal ysis will be derived at some point because we eventually explore all paths in each region and we update the partition of each region with the commutative cross product operation.
theoretically we can measure performance while running the taint analysis.
in practice though running a dynamic taint analysis with control flow tracking imposes significant overhead which significantly alters measurement results.
a second reason for separating performance measurement from taint tracking is an optimization to perform taint tracking on a different smaller workload than the one used for performance measurement which we discuss in sec.
iv.
b. measuring performance of regions we measure the execution time of each region when executing a configuration resulting in performance measurements for each pair of configuration and region.
to this end we use an off the shelf profiler.
we measure self time per region to track the time spent in the region itself which excludes the time of calls to execute code from other regions.
since we measure performance in a separate step than the iterative analysis we can pick a new and possibly smaller set of configurations to explore all paths per region.
ideally we want to find a minimal set of configurations such that we have at least one configuration per subspace of each region s partition.
since finding the optimal solution is np hard4 and existing heuristics from combinatorial interaction testing are expensive we developed our own simple greedy algorithm incrementally intersecting subspaces that overlap in at least one configuration until no further such intersections are possible.
then we simply pick one configuration from each subspace.
however we never found a smaller set of configurations than the one used in the iterative analysis.
thus we use the same set of configurations to measure performance.
example four configurations cover all subspaces for the three regions of our example e.g.
a c a b c .
c. building performance influence models in the final step we build performance influence models for each region based on the partitions identified per region and the performance measured per region and observed configuration.
then we compose the local models into a performance influence model for the entire program.
since we collect at least one measurement per distinct path through a region building models is straightforward.
for a region with a partition and a set of configurations with corresponding performance measurements we associate each measurement with the subspace of the partition to which the configuration belongs.
if multiple measured configurations belong to the same subspace of the region s partition we expect the same performance behavior for that region modulo measurement noise and average the measured results.
as a result we can map each subspace of a region s partition to 4the problem can be reduced to the set cover problem in which the union of a collection of subsets all subspaces equals a set of elements called the universe the union of all subspaces .
the goal is to identify the smallest sub collection whose union equals the universe.
1077a performance measurement.
for instance for region main in our example we report an execution time of 2seconds for configurations in llbracketa rrbracketand3seconds for configurations in llbracket a rrbracket.
for interpretability to highlight the influence of options and avoid sets or propositional formulas we write linear models in terms of options and interactions for example mmain 1a.
the global performance influence model is obtained simply by aggregating all local models we add the individual influences of each model.
note that local models can be useful for understanding and debugging individual regions as they describe the performance behavior of each region.
example in our running example we derive the local models mmain 1a mfoo 1a 3ab and mbar 15a 10c 30ac which can be composed into the global performance influence model m mmain mfoo mbar 15a 10c 3ab 30ac.
iv.
d esign optimizations and implementation dynamic taint analysis overhead comprex executes a dynamic taint analysis with control flow tracking which imposes significant overhead in the system s execution.
for instance one execution of our subject system berkeley db takes about1hour with the taint analysis whereas about 300configurations can be executed in the same time!
in general we observe26 to300 overhead from taint tracking which varies widely between systems.
to reduce cost we separate the iterative analysis and performance measurement in two steps and perform the former with a drastically reduced workload size.
this optimization is feasible when the workload is repetitive and repetitions of operations are affected similarly by options which we conjecture to be common in practice.
many performance benchmarks execute many operations which are similarly affected by configuration options.
for instance berkeley db s benchmark populates a database where options determine for example whether duplicates are allowed and the durability characteristics of a transaction.
the benchmark can be scaled by a parameter that controls the number of entries to insert but does not affect which operations are performed.
in our evaluation we show that comprex generates accurate models using a significantly smaller workload in the iterative analysis.
we conduct the actual performance measurements with the original workload to record realistic performance.
granularity of regions our approach can be applied to different levels of granularity but with different tradeoffs.
on one extreme we could consider the entire system as a single region but would not benefit from compression.
at the other extreme we could consider each control flow statement as the start of its own region ending with its immediate postdominator which allows maximum compression but results in excessive measurement cost.
note the latter is analogous to using an instrumentation profiler but instead of focusing on few locations of interest as usually recommended one would add instrumentation throughout the entire system at control flow statements.
in our evaluation we show that considering each method as a region is a practical compromise.when considering methods as regions we may lose some compression potential compared to more fine grained regions if multiple control flow statements within a method are influenced by distinct options.
on the other hand we can use off the shelf sampling profilers that accurately capture performance with low overhead and simply map the performance of methods to the closest regions on the calling stack.
our empirical evaluation shows that method level regions do not require more configurations compared to more fine grained regions but significantly reduce the measurement overhead.
implementation we implemented comprex for java systems .
we used phosphor a state of the art tool for dynamic taint analysis to track options.
we annotated the apis to load options as sources and control flow statements as sinks.
we encoded subspaces as propositional formulas and use sat4j for operations on those formulas.
we used jprofiler10.
to measure performance at method level.
v. e valuation to evaluate the efficiency and effectiveness of our approach we compare comprex to state of the art performanceinfluence modeling approaches for configurable systems in terms of the cost to generate the models and their accuracy and discuss their interpretability.
we evaluate the efficiency of compression by choosing regions at different granularities.
specifically we address the following research questions rq1 how does comprex compare to state of the art performance modeling approaches in terms of cost accuracy and interpretability?
rq2 how efficient is compression at different granularities to reduce the cost to build models?
a. experiment setup subject systems we selected 4configurable widelyused open source java systems that satisfy the following criteria common in our domain a medium to large scale systems with over 40k sloc and over 20options b systems with binary and non binary options c systems with fairly stable execution time despite nondeterminism and concurrency we observed execution times within usual measurement noise for repeated execution of the same configuration and d systems with different performance behaviors see fig.
.
table i provides an overview of all subject systems.
we focus on a large subset of all options that are potentially relevant for performance.
we considered options for which the systems documentation indicated that they would affect performance but excluded options that might not influence performance e.g.
help .
this selection is representative of common use cases where users are interested in the performance behavior of many but not all options.
following the evaluation of state of the art approaches we selected for non binary options two different values and encoded the values as a binary option.
we executed a long running benchmark shipped with the system representative of a user analyzing the system s per1078configurations24262830323436performance s apache lucene three discernible steps configurations20406080performance s h2 discernible stepssubstantial jump configurations510152025performance s berkeley db complex behavior with several steps configurations50100150200performance s density converter one discernible stepcomplex behavior fig.
performance behaviors of our subject systems from simple to complex.
we randomly selected configurations and sorted their execution time from fastest to slowest.
table i subject systems.
system domain kloc opt.
conf.
v id apache lucene index search 131k .
.
h2 database 65k .
.
berkeley db database 65k .
.
density converter image processor .9m 110c4 opt options conf configurations v id version commit id interface to several libraries for processing images with .5k sloc included in the evaluation as the system has a large configuration space.
formance under different configurations.
detailed information about the benchmarks is included in our appendix .
for each system we changed the workload parameter to run the iterative dynamic taint analysis with a smaller workload by factors ranging from 20to50000 depending on the system.
the smaller workload reduced the iterative analysis time for a single configuration for example on average from 1hour to5seconds for berkeley db.
information about the changes in the workload can be found in our appendix .
hardware analyses and measurements were executed on an ubuntu .04lts desktop with a .4ghz8 core intel core i7 processor 16gb of ram and java hotspottm bit server vm v1.
.
0 202 .
performance measurement we established a large evaluation set for quantifying accuracy by measuring the performance of randomly selected configurations as the configuration spaces of the subject systems are intractably large.
we executed each configuration five times and used the median to reduce the effects of measurement noise.
we initiated one vm invocation per configuration thus all measures include startup time .
for comprex we profiled each system with jprofiler s default sampling rate of 5ms.
b. rq1 comparison to the state of the art with rq1 we evaluate the cost to generate performanceinfluence models with comprex at method granularity asses their accuracy and interpretability and compare them to state of the art approaches.
specifically we compare comprex to numerous combinations of sampling and learning approaches.
for learners we evaluate variations of linear regressions decision trees and random forests and a neural network.
for sampling we evaluate uniform random sampling with 50and200 configurations feature wise sampling i.e.
enable one option at a time and pair wise sampling i.e.
cover all combinationstable ii cost comparison.
sample apache lucene h2 berkeley db density conv.
bf r50 r200 fw pw comprex the time to measure configurations for brute force bf is extrapolated from randomly selected configurations.
a cost of sampling configurations.
approach apache lucene h2 berkeley db density conv.
r50 lr .9s .6s .7s .9s r200 lr .8m .6m .9m .6m fw lr .4s .3s .7s .8s pw lr .7m .8s .6m .5m rf .2s .2s .3s .2s comprex .9m .3m .2m .5m b learning analysis time.
bf brute force r50 random configurations r200 random configurations fw feature wise pw pair wise lr stepwise linear regression rf random forest results stable across all samples.
of all pairs of options .
we selected 50and200random configurations to use more configurations than other sampling strategies and use sampling sets comparable to ones used in related research.
due to space restrictions we report results only for stepwise linear regression and random forest.
the other results can be found in our appendix .
note that we do not compare against approaches for selecting the fastest configuration as those approaches solve a pure optimization problem where modeling the entire configuration space is not necessary.
we do not evaluate existing white box approaches due to their limitations .
none of the approaches could analyze any of our subject systems except for a subset of density converter s code base which we discuss in sec.
vi.
cost metric we report the number of configurations executed to generate a model and time to measure configurations.
for the learning approaches we report the learning time.
for comprex we report the time to execute the iterative analysis.
accuracy metric we report the mean absolute percentage error mape which measures the mean difference between the values predicted by a model and the values actually observed i.e.
the baseline lower is better.
as profiling the performance of regions with our approach 1079table iii mape comparison lower is better .
approach apache lucene h2 berkeley db density conv.
r50 lr .
.
.
.
r200 lr .
.
.
.
fw lr .
.
.
.
pw lr .
.
.
.
r50 rf .
.
.
.
r200 rf .
.
.
.
fw rf .
.
.
.
pw rf .
.
.
.
comprex o .
.
.
.
comprex c .
.
.
.
.
.
.
.
lr stepwise linear regression rf random forest r50 50random configurations r200 random configurations fw feature wise pw pair wise o original model c model corrected for profiler overhead reporting mean and standard deviations over corrections.
bolded values in cells indicate similarly low errors.
1non linear profiling overhead might have increased the error .
adds some overhead about in our subject systems we expect our models to be systematically biased.
we performed an optional linear correction to account for the average overhead in our subject systems learned from measurements with and without profiling of 5randomly selected configurations.
we separately report these corrected mape values in our results.
interpretability we intend our models to also be used in understanding and debugging tasks see sec.
ii .
unfortunately measuring interpretability of models is nontrivial and controversial.
in the machine learning community interpretability is an open research problem with an active community but without a generally agreed measure or even definition for interpretability .
generally interpretability captures the ability of humans to make predictions understand predictions or understand the decisions of a model .
when the model is complex e.g.
the model includes numerous decisions humans have more difficulty understanding the model directly.
some simpler forms of models are usually considered inherently interpretable because humans can inspect and understand the models directly.
for example scientists have decades of experience using and interpreting linear models e.g.
much of empirical software engineering research relies on interpreting linear model coefficients .
models with more complex structures and very large numbers of decisions e.g.
deep neural networks with millions of weights or random forests with hundreds of trees exceed human capacity for directly understanding the model.
with these more complex models the trend is to develop post hoc explanations where tools provide explanations for specific aspects of the model e.g.
the reason for a given prediction without having to understand the model s internals .
the use of post hoc explanations is however controversial as the explanations usually are only approximations that may be unreliable or even misleading .
we do not attempt to quantify interpretability.
instead we generally consider sparse linear models as inherently interpretable assuming a moderate numbers of terms .
this is supported by prior interviews that have shown that developers understand linear performance influence models with a few dozen terms .
by contrast we consider random forests and neural networks as not inherently interpretable and do notevaluate the reliability or usefulness of post hoc explanations.
to assure readers that the linear models that we produce are indeed sparse and hence likely interpretable by humans we report the number of terms they contain.
as our algorithm to build these models sec.
iii c does not include any machine learning and regularization the algorithm detects and reports even minuscule amounts of measurement noise.
hence we exclude all trivial terms that do not make meaningful contributions to the systems performance.
we report the number of terms options or interactions that contribute at least .
seconds which is approximately of the execution time of the default configurations of our subject systems.
our appendix contains additional data at other thresholds .
results we report the main results in table ii cost and iii accuracy and our appendix includes results for additional learners neural networks decision trees .
overall comprex builds models that are similarly accurate to those learned by the most accurate and expensive black box approach random forests with samples but our models are interpretable and usually built more efficiently despite the cost of the additional taint analysis step.
comprex outperforms other approaches that build linear models by a wide margin.
while random forest with samples produced slightly more accurate models than comprex our approach was usually more efficient in some cases building models in half the time while also generating local and interpretable models see fig.
.
the efficiency originates from comprex s white box analysis to identify a small number of relevant configurations to capture the performance relevant interactions.
by contrast as our results show black box approaches perform significantly worse on such small samples e.g.
compare r50 and r200 results .
the linear models produced by comprex are moderate in size with and72performance relevant terms options or interactions for lucene h2 berkeley db and density converter respectively.
our models are similar in size to models learned with linear regression from samples e.g.
and30terms using r200 lr but much more accurate.
at this size we argue that manual inspection of the models is still plausible.
more importantly the performance influences can be mapped to and9specific regions in the code for the four systems respectively.
rq1 in summary models produced with comprex have comparable accuracy to the most accurate and expensive black box approaches but can often be built more efficiently.
additionally the models significantly outperform other black box approaches that produce interpretable linear models.
the models are interpretable and can be mapped to specific code regions.c.
rq2 compression efficiency with rq2 we explore the impact of choosing regions at different granularities on the efficiency of comprex both 1080in terms of the number of configurations to measure and the overhead to perform these measurements.
procedure for rq1 we executed the taint analysis considering each method as a region.
we additionally tracked partitions for control flow statements and derived partitions for the entire program by combining the partitions of all methods.
result number of configurations in table iv we report the size of the minimum set of configurations needed to cover each subspace of each region s partition for each granularity.
when considering the entire program as a region significantly more configurations need to be explored as we do not benefit from compression.
interestingly though while there are as expected fewer regions at the method level than at the control flow statement level the number of configurations needed is the same.
these results show that compression at finer grained levels than the method level do not yield additional benefits in our subject systems.
we found that the control flow statement regions combined within a method are usually partitioned in the same way.
only in3out of the method level regions the method s partition had more subspaces than the corresponding controlflow statement regions e.g.
two ifstatements depending on different options .
however in all three cases the additional subspaces were already explored in other parts of the program.
hence no additional configurations needed to be explored.
we conclude that fined grained compression is highly effective but that control flow granularity does not seem to offer significant compression benefits over method granularity.
results measurement overhead measuring performance at different granularities requires different strategies each with vastly different amounts of measurement overhead.
measuring at the program level is cheap as a single end to end measurement is sufficient to measure the entire program e.g.
unix time .
at finer granularities multiple measurements of different parts of the program are required.
instrumenting the program at control flow statements and corresponding post dominators leads to significant measurement overhead as the measurement instructions are executed frequently similar to an instrumentation profiler .
for instance in the time to measure methods e.g.
berkeley db executed 144configurations in .2minutes not a single configuration finished measuring control flow statements.
by contrast measuring the performance of numerous methods is inexpensive with a sampling profiler cf.
comprex in table iia for which we observed a mostly linear overhead of about in our subject systems.
rq2 in summary compression at method and controlflow granularities is highly efficient to reduce measurement effort.
compression at method granularity provides a good compromise between compression potential and measurement overhead.table iv number of regions and configurations to measure with compression at different region granularities.
control flow method program system reg.
conf.
reg.
conf.
reg.
conf.
lucene h2 berkeley db density converter reg number of regions conf number of configurations.
bolded values in cells indicate the minimum number of configurations to cover all partitions subspaces.
d. limitations and threats to validity limitations of the taint analysis our approach to compute partitions per region may produce inaccurate results due to two sources of inaccuracy a standard dynamic taint analysis cannot reason about paths not taken and thus may miss some taints and our use of a small workload to reduce the cost of the iterative analysis may lead to some missed interactions.
the former threat is somewhat mitigated by exploring multiple configurations and using the cross product when updating partitions we see both branches of each control flow decision.
the latter issue depends on how the workload is shortened see sec.
iv but will likely have a low impact in highly repetitive workloads.
both threats can lead to generating inaccurate models.
importantly our results for rq1 suggest that inaccuracies on the regions partition caused by these threats resulted in at most minor accuracy degradation in our performanceinfluence models given the consistently high accuracy achieved across all subject systems.
furthermore we used a debugging strategy to identify potential effects of inaccurate partitions.
as discussed in sec.
iii c multiple executions of configurations within the same subspace of a region s partition must have the same performance behavior.
significant differences beyond normal measurement noise indicate that the region s partition might be inaccurate and not capturing all relevant interactions.
specifically we analyzed the performance measurements of all regions searching for regions with a significant performance influence .1ms in any observed configuration and with a high variance among the execution times of the same subspace in a region coefficient of variation of the execution times .
.
among the method level regions that we analyzed we found only 8of such regions all in lucene.
we executed the iterative analysis with the regular workload which resulted in additional subpaces in 7out of8regions due to slightly different taints in the shorter workload.
while the missing subspaces slightly decreased the mape from .
to7.
as a result of slight changes in the coefficients in the model not from new options nor interactions becoming performance relevant the time to run the taint analysis with the regular workload is extremely expensive 11hours instead of29minutes to run the same 26configurations.
in fact the iterative analysis did no finish executing after 24hours in the other subject systems!
we argue that the extremely high cost and inability to use 1081the regular workload does not outweigh a potential slight accuracy increase of the already highly accurate models that we generated.
these results support our conjecture that inaccuracies on the regions partition caused by using an unsound analysis with a small workload are only a minor issue in practice.
threats to validity beyond the limitations of the taint analysis measurement noise cannot be excluded and may affect allresults.
we reduced this threat by repeating measurements on a dedicated machine and using the median.
the primary threat to external validity is the selection of subject systems.
while we selected medium to large scale widely used open source java configurable systems from different domains readers should be careful when generalizing results.
for instance all analyzed systems are multithreaded but had mostly deterministic performance behavior.
additionally we analyzed a single configurable system whereas systems composed of numerous configurable systems deployed in distributed environments and implemented in different languages are beyond the scope of this paper.
another threat is the selected subset of options which might not affect performance at all making modeling a trivial task.
we selected options for which the systems documentation or the options functionality indicated that they would affect performance and we observed a wide range of execution times for the configurations that we measured see fig.
.
vi.
r elated work in sec.
ii we discussed performance modeling in general and evaluated closely related state of the art black box approaches for performance influence modeling to comprex.
in this section we discuss additional research to position comprex in a broader context of prior work.
only few researchers have explored white box performance modeling of configurable systems in prior work .
siegmund et al.
introduced the idea of white box analysis but assumed a specific programming style that provided a static mapping from options to regions and ignored data flow between regions severely limiting the systems that could be analyzed.
in prior work we developed configcrusher which used static data flow analysis to map options to regions.
configcrusher also measures the performance of regions and builds local performance influence models.
configcrusher is however limited by the overhead of the static analysis and was unable to scale beyond small systems e.g.
it never terminated when we tried it on our subject systems .
by contrast comprex uses a dynamic data flow analysis that scales to large systems demonstrating the feasibility of white box approaches to efficiently build accurate performance influence models for large scale configurable systems.
for comparison we evaluated both approaches on density converter though comprex analyzed all used libraries resulting in comparable accuracies .
3with configcrusher vs. .4with comprex in terms of mape but measuring fewer configurations with configcrusher vs. 88with comprex .
in prior work we also adapted splat for performance modeling originally designed for testing configurablesystems.
splat uses lightweight instrumentation to observe which options are accessed during execution and in which order to explore all combinations of options that it encounters during execution.
this type of analysis is cheaper than our taint tracking but explores many spurious interactions resulting in splat essentially exploring all configurations.
li et a. used intraprocedural control flow analysis to identify usage patterns of individual options in the source code for predicting performance properties based on the patterns.
in contrast to our work they do not measure performance build performance influence models nor consider interactions.
while our line of work focuses on the influence of configuration options which are easy to change by users without modifying the implementation there is a active research field to identify bottlenecks and performance bugs generally using different forms of static or dynamic analysis e.g.
.
for example castro et al.
use both techniques to identify performance bottlenecks that can be analyzed and optimized in isolation.
these kinds of approaches are focusing on different concerns than performanceinfluence models but are likely complementary for developers seeking to understand a system s performance behavior.
at the same time researchers have used static and dynamic analyses to characterize and track options in configurable systems .
for example toman and grossman use dynamic taint analysis to identify the use of stale configuration data.
our work is inspired by insights from analyzing configurable systems and uses similar analysis strategies as foundations to map options to regions.
vii.
c onclusion we presented comprex a white box approach that efficiently builds accurate and interpretable performance influence models for configurable systems without relying on traditional sampling and learning techniques.
comprex employs an iterative dynamic taint analysis to identify where options influence the system building and composing local linear performanceinfluence models.
our empirical evaluation on 4systems demonstrates the accuracy and efficiency of comprex.
viii.
a cknowledgements we specially want to thank katherine hough and jonathan bell for their indispensable help with phosphor.
we thank chu pan wong jens meinicke and florian sattler for their comments during the development of this work the fosd meeting participants for their feedback on the iterative dynamic taint analysis and claire le goues and rohan padhye for their feedback on earlier drafts of this paper.
this work has been supported in part by the software engineering institute nsf awards and nasa rasperry si 80nssc20k1720 the german federal ministry of education and research bmbf 01is19059a and 01is18026b and the german research foundation dfg si si ap .
1082references sat4j.
.
available jprofiler .
.
available com products jprofiler overview.html m. al hajjaji s. krieter t. th m m. lochau and g. saake incling efficient product line testing using incremental pairwise sampling in proc.
int l conf.
generative programming and component engineering gpce .
acm oct. pp.
.
s. apel d. batory c. k stner and g. saake feature oriented software product lines concepts and implementation.
springer verlag .
s. arzt s. rasthofer c. fritz e. bodden a. bartel j. klein y .
le traon d. octeau and p. mcdaniel flowdroid precise context flow field object sensitive and lifecycle aware taint analysis for android apps in proc.
conf.
programming language design and implementation pldi .
acm jun.
pp.
.
t. h. austin and c. flanagan efficient purely dynamic information flow analysis in proc.
workshop programming languages and analysis for security plas .
acm jun.
pp.
.
s. becker h. koziolek and r. reussner the palladio component model for model driven performance prediction j. syst.
softw.
vol.
no.
pp.
jan. .
j. bell and g. kaiser phosphor illuminating dynamic data flow in commodity jvms sigplan notices vol.
no.
pp.
oct. .
p. d. o. castro c. akel e. petit m. popov and w. jalby cere llvm based codelet extractor and replayer for piecewise benchmarking and optimization acm trans.
archit.
code optim.
taco vol.
no.
pp.
apr.
.
j. cito p. leitner c. bosshard m. knecht g. mazlami and h. c. gall performancehat augmenting source code with runtime performance traces in the ide in proc.
int l conf.
software engineering companion proceeedings.
acm pp.
.
z. dong a. andrzejak d. lo and d. costa orplocator identifying read points of configuration options via static analysis in proc.
int l symposium software reliability engineering issre .
ieee oct. pp.
.
f. doshi velez and b. kim towards a rigorous science of interpretable machine learning arxiv preprint arxiv .
.
n. esfahani a. elkhodary and s. malek a learning based framework for engineering feature oriented self adaptive software systems ieee transactions on software engineering vol.
no.
pp.
nov. .
a. georges d. buytaert and l. eeckhout statistically rigorous java performance evaluation sigplan notices vol.
no.
pp.
oct. .
a. grebhahn n. siegmund and s. apel predicting performance of software configurations there is no silver bullet .
m. grechanik c. fu and q. xie automatically finding performance problems with feedback directed learning software testing in proc.
int l conf.
software engineering icse .
ieee jun.
p. .
j. guo k. czarnecki s. apel n. siegmund and a. w asowski variability aware performance prediction a statistical learning approach in proc.
int l conf.
automated software engineering ase .
acm nov. pp.
.
j. guo d. yang n. siegmund s. apel a. sarkar p. valov k. czarnecki a. wasowski and h. yu data efficient performance learning for configurable systems empirical software engineering vol.
pp.
.
h. ha and h. zhang performance influence model for highly configurable software with fourier learning and lasso regression in proc.
int l conf.
software maintance and evolution icsme sep. pp.
.
h. ha and h. zhang deepperf performance prediction for configurable software with deep sparse neural network in proc.
int l conf.
software engineering icse .
ieee may p. .
a. halin a. nuttinck m. acher x. devroey g. perrouin and b. baudry test them all is it worth it?
assessing configuration sampling on the jhipster web development stack empirical software engineering jul.
.
s. han y .
dang s. ge d. zhang and t. xie performance debuggingin the large via mining millions of stack traces in proc.
int l conf.
software engineering icse .
ieee jun.
pp.
.
x. han and t. yu an empirical study on performance bugs for highly configurable software systems in proc.
int l symposium empirical software engineering and measurement esem .
acm sep. pp.
.
m. harchol balter performance modeling and design of computer systems queueing theory in action 1st ed.
cambridge university press .
a. hervieu b. baudry and a. gotlieb pacogen automatic generation of pairwise test configurations from feature models in proc.
int l symposium software reliability engineering nov. pp.
.
a. hervieu d. marijan a. gotlieb and b. baudry optimal minimisation of pairwise covering test configurations using constraint programming information and software technology vol.
pp.
mar.
.
a. hubaux y .
xiong and k. czarnecki a user survey of configuration challenges in linux and ecos in proc.
workshop variability modeling of software intensive systems vamos .
acm jan. pp.
.
f. hutter h. h. hoos and k. leyton brown sequential model based optimization for general algorithm configuration in proc.
int l conf.
learning and intelligent optimization.
springer verlag jan. pp.
.
p. jamshidi and g. casale an uncertainty aware approach to optimal configuration of stream processing systems in int l symp.
modeling analysis and simulation of computer and telecommunication systems mascots sep. pp.
.
p. jamshidi n. siegmund m. velez c. k stner a. patel and y .
agarwal transfer learning for performance modeling of configurable systems an exploratory analysis in proc.
int l conf.
automated software engineering ase .
acm oct. .
p. jamshidi m. velez c. k stner and n. siegmund learning to sample exploiting similarities across environments to learn performance models for configurable systems in proc.
int l symp.
foundations of software engineering fse .
acm nov. pp.
.
p. jamshidi m. velez c. k stner n. siegmund and p. kawthekar transfer learning for improving model predictions in highly configurable software in proc.
int l symp.
software engineering for adaptive and self managing systems seams .
ieee may pp.
.
g. jin l. song x. shi j. scherpelz and s. lu understanding and detecting real world performance bugs in proc.
conf.
programming language design and implementation pldi .
acm jun.
pp.
.
m. jovic a. adamoli and m. hauswirth catch me if you can performance bug detection in the wild in proc.
int l conf.
object oriented programming systems languages and applications oopsla .
acm oct. p. .
c. kaltenecker a. grebhahn n. siegmund and s. apel the interplay of sampling and machine learning for software performance prediction ieee software .
c. kaltenecker a. grebhahn n. siegmund j. guo and s. apel distance based sampling of software configuration spaces in proc.
int l conf.
software engineering icse .
ieee may .
c. h. p. kim d. marinov s. khurshid d. batory s. souto p. barros and m. d amorim splat lightweight dynamic analysis for reducing combinatorics in testing configurable systems in proc.
europ.
software engineering conf.
foundations of software engineering esec fse .
acm aug. pp.
.
s. kolesnikov n. siegmund c. k stner a. grebhahn and s. apel tradeoffs in modeling performance of highly configurable software systems software and system modeling sosym feb. .
s. kounev performance modeling and evaluation of distributed component based systems using queueing petri nets ieee transactions on software engineering vol.
no.
pp.
.
r. krishna m. s. iqbal m. a. javidian b. ray and p. jamshidi cadet a systematic method for debugging misconfigurations using counterfactual reasoning .
d. r. kuhn r. n. kacker and y .
lei introduction to combinatorial testing 1st ed.
chapman hall crc .
f. lange.
jan. measure java performance sampling or instru1083mentation?
c. lemieux r. padhye k. sen and d. song perffuzz automatically generating pathological inputs in proc.
int l symp.
software testing and analysis issta .
acm pp.
.
c. li s. wang h. hoffmann and s. lu statically inferring performance properties of software configurations in proc.
european conf.
computer systems eurosys .
acm apr.
.
m. lillack c. k stner and e. bodden tracking load time configuration options ieee transactions on software engineering vol.
no.
pp.
.
s. m. lundberg and s. i. lee a unified approach to interpreting model predictions in advances in neural information processing systems .
curran associates inc. pp.
.
f. medeiros c. k stner m. ribeiro r. gheyi and s. apel a comparison of sampling algorithms for configurable systems in proc.
int l conf.
software engineering icse .
acm may pp.
.
j. meinicke c. p. wong c. k stner t. th m and g. saake on essential configuration complexity measuring interactions in highlyconfigurable systems in proc.
int l conf.
automated software engineering ase .
acm sep. pp.
.
c. molnar interpretable machine learning github.io interpretable ml book .
d. c. montgomery design and analysis of experiments.
john wiley sons .
v .
nair t. menzies n. siegmund and s. apel using bad learners to find good configurations in proc.
europ.
software engineering conf.
foundations of software engineering esec fse ser.
esec fse .
acm aug. p. .
t. nguyen t. koc j. cheng j. s. foster and a. a. porter igen dynamic interaction inference for configurable software in proc.
int l symp.
foundations of software engineering fse .
ieee nov. .
c. nie and h. leung a survey of combinatorial testing acm comput.
surv.
csur vol.
no.
pp.
feb. .
a. nistor p. c. chang c. ra and s. lu caramel detecting and fixing performance problems that have non intrusive fixes in proc.
int l conf.
software engineering icse .
ieee may pp.
.
a. nistor t. jiang and l. tan discovering reporting and fixing performance bugs in proc.
int l conf.
mining software repositories.
ieee may pp.
.
a. nistor l. song d. marinov and s. lu toddler detecting performance problems via similar memory access patterns in proc.
int l conf.
software engineering icse .
ieee pp.
.
j. oh d. batory m. myers and n. siegmund finding near optimal configurations in product lines by random sampling in proc.
europ.
software engineering conf.
foundations of software engineering esec fse .
acm sep. pp.
.
r. olaechea d. rayside j. guo and k. czarnecki comparison of exact and approximate multi objective optimization for software product lines in proc.
int l software product line conference splc .
acm sep. pp.
.
m. t. ribeiro s. singh and c. guestrin why should i trust you?
explaining the predictions of any classifier in proc.
int l conf.
knowledge discovery and data mining kdd .
acm aug. pp.
.
c. rudin stop explaining black box machine learning models for high stakes decisions and use interpretable models instead nature machine intelligence no.
pp.
.
a. sarkar j. guo n. siegmund s. apel and k. czarnecki costefficient sampling for performance prediction of configurable systems inproc.
int l conf.
automated software engineering ase .
ieee nov. pp.
.
g. serazzri g. casale m. bertoli g. serazzri g. casale and m. bertoli java modelling tools an open source suite for queueing network modelling andworkload analysis in proc.
int l conf.
the n. siegmund a. grebhahn s. apel and c. k stner performanceinfluence models for highly configurable systems in proc.
europ.
software engineering conf.
foundations of software engineering es quantitative evaluation of systems qest sep. pp.
.
ec fse .
acm aug. pp.
.
n. siegmund s. s. kolesnikov c. k stner s. apel d. batory m. rosenm ller and g. saake predicting performance via automated feature interaction detection in proc.
int l conf.
software engineering icse .
ieee jun.
pp.
.
n. siegmund m. rosenm ller m. kuhlemann c. k stner s. apel and g. saake splconqueror toward optimization of non functional properties in software product lines software quality journal vol.
no.
pp.
sep. .
n. siegmund a. von rhein and s. apel family based performance measurement in proc.
int l conf.
generative programming and component engineering gpce .
acm oct. pp.
.
s. souto and m. d amorim time space efficient regression testing for configurable systems journal of systems and software .
e. trumbelj and i. kononenko explaining prediction models and individual predictions with feature contributions knowledge and information systems vol.
no.
pp.
.
t. th m s. apel c. k stner i. schaefer and g. saake a classification and survey of analysis strategies for software product lines acm comput.
surv.
csur vol.
no.
pp.
jun.
.
j. toman and d. grossman legato an at most once analysis with applications to dynamic configuration updates in european conf.
object oriented programming ecoop .
staccato a bug finder for dynamic configuration updates inproc.
european conf.
object oriented programming ecoop .
schloss dagstuhl leibniz zentrum fuer informatik jul.
.
p. valov j. c. petkovich j. guo s. fischmeister and k. czarnecki transferring performance prediction models across different hardware platforms in proc.
int l conf.
on performance engineering icpe .
acm apr.
pp.
.
m. velez p. jamshidi f. sattler n. siegmund s. apel and c. k stner configcrusher towards white box performance analysis for configurable systems autom softw eng .
m. velez p. jamshidi n. siegmund s. apel and c. k stner whitebox analysis over machine learning modeling performance of configurable systems supplementary material .
n. viswanadham and y .
narahari performance modeling of automated systems.
phi learning pvt.
ltd. .
s. wang c. li h. hoffmann s. lu w. sentosa and a. i. kistijantoro understanding and auto adjusting performance sensitive configurations in proc.
int l conf.
architectural support for programming languages and operating systems asplos .
acm mar.
pp.
.
m. weber s. apel and n. siegmund white box performanceinfluence models a profiling and learning approach in proc.
int l conf.
software engineering icse .
ieee may .
t. xu l. jin x. fan y .
zhou s. pasupathy and r. talwadker hey you have given me too many knobs!
understanding and dealing with over designed configuration in system software in proc.
europ.
software engineering conf.
foundations of software engineering esec fse .
acm aug. pp.
.
t. xu x. jin p. huang y .
zhou s. lu l. jin and s. pasupathy early detection of configuration errors to reduce failure damage in proc.
conf.operating systems design and implementation osdi .
usenix association nov. pp.
.
t. xu j. zhang p. huang j. zheng t. sheng d. yuan y .
zhou and s. pasupathy do not blame users for misconfigurations in proc.
symp.
operating systems principles.
acm nov. pp.
.
t. yu and m. pradel pinpointing and repairing performance bottlenecks in concurrent programs empirical softw.
eng.
vol.
no.
pp.
oct. .
y .
zhu j. liu m. guo y .
bao w. ma z. liu k. song and y .
yang bestconfig tapping the performance potential of systems via automatic configuration tuning in proc.
symposium cloud computing socc .
acm pp.
.