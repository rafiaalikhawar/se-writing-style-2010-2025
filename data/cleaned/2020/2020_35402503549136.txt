agilectrl a self adaptive framework for configuration tuning shu wang linkedin sunnyvale california usa shuwang uchicago.eduhenry hoffmann university of chicago chicago illinois usa hankhoffmann cs.uchicago.edushan lu university of chicago chicago illinois usa shanlu uchicago.edu abstract software systems increasingly expose performance sensitive configuration parameters or perfconfs to users.
unfortunately the right settings of these perfconfs are difficult to decide and often change at run time.
to address this problem prior research has proposed self adaptive frameworks that automatically monitor the software s behavior and dynamically tune configurations to provide the desired performance despite dynamic changes.
however these frameworks often require configuration themselves sometimes explicitly in the form of additional parameters sometimes implicitly in the form of training.
this paper proposes a new framework agilectrl that eliminates the need of configuration for a large family of control based selfadaptive frameworks.
agilectrl s key insight is to not just monitor the original software but additionally to monitor its adaptations and reconfigure itself when its internal adaptation mechanisms are not meeting software requirements.
we evaluate agilectrl by comparing against recent control based approaches to self adaptation that require user configuration.
across a number of case studies we find agilectrl withstands model errors up to saves the system from performance oscillation and crashes and improves the performance up to .
it also auto adjusts improper performance goals while improving the performance by .
ccs concepts software and its engineering software configuration management and version control systems software performance software reliability computer systems organization cloud computing.
keywords software configuration performance distributed systems selfadaptive control acm reference format shu wang henry hoffmann and shan lu.
.
agilectrl a self adaptive framework for configuration tuning.
in proceedings of the 30th acm joint european software engineering conference and symposium on the foundations of software engineering esec fse november singapore singapore.
acm new york ny usa pages.
.
permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
copyrights for components of this work owned by others than acm must be honored.
abstracting with credit is permitted.
to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
request permissions from permissions acm.org.
esec fse november singapore singapore association for computing machinery.
acm isbn .
.
.
.
introduction modern software systems provide great flexibility to users by allowing them to customize or tune the software s configuration parameters.
these configuration parameters determine the size of critical data structures the thresholds to trigger time consuming operations the parallelism of the process and many other aspects of system operation .
many of these configurations can greatly affect system performance metrics such as request latency job throughput memory and disk consumption and others.
unfortunately these performance sensitive configurations perfconfs for short are typically numerical variables whose optimal settings are difficult to determine and vary based on run time situations.
their mis configuration easily leads to performance degradation or even crashes .
indeed a recent study finds that of configuration related issues in distributed systems cassandra hbase hdfs mapreduce involve performance concerns .
to ensure that software is configured optimally despite dynamic changes in operating environment prior works have proposed selfadaptive frameworks including but not limited to smartconf dac ottertune poet simca capes aeneas jouleguard and caloree .
such frameworks monitor software performance and automatically adjust perfconfs to ensure optimal operation despite unpredictable external changes.
for example aeneas dynamically adjusts android s gps accuracy gpsprio and update interval gpsupdate to meet performance requirements e.g.
per hour battery drain rate .
by dynamically configuring the perfconfs such self adaptive frameworks make software substantially more robust than approaches that must stick with a single perfconf setting for their lifetime .
however these approaches do not eliminate all the burden of managing perfconfs as self adaptive frameworks themselves expose configuration parameters that need to be set by users.
we call these adapconfs to distinguish the parameters of a self adaptive framework from the perfconfs of the systems it should control.
for example to use a self adaptive framework based on control theory users must set an explicit adapconf called the pole that determines the tradeoff between adaptation s reaction time and noise sensitivity .
if the pole is too small the self adaptive framework is more sensitive to disturbances and it may crash the software if the pole is too large the framework is slow to change the perfconf which leads to sub optimal performance and negates the benefits of using the self adaptive framework in the first place.
in addition to these explicit adapconfs there are implicit adapconfs which are not directly set by users but are computed based on the training or profiling data that is provided by users.
for example in a machine learning based self adaptive framework training data determine implicit adapconfs e.g.
weights used in neural networks .
when the training inputs and environment do esec fse november singapore singapore shu wang henry hoffmann and shan lu not match that at deployment the self adaptive frameworks will not react appropriately and can crash the system under control or fail to deliver the required performance .
for example if the training inputs for a web server consist of only small requests the system could crash when processing larger requests .
in summary self adaptive frameworks have the potential to automatically configure software systems but they do not completely solve the configuration management problem because they typically have their own explicit and implicit configuration parameters.
in other words prior works proposing self adaptive frameworks replace perfconfs with adapconfs which must still be set by users.
and much like perfconfs the optimal settings for these adapconfs depend on the target software the hardware platform the run time workload and environment.
like perfconfs these adapconfs become a new source of bugs either from setting the explicit adapconf incorrectly or through providing insufficient or unrepresentative training data for the implicit adapconf.
unsuitable adapconfs lead to sub optimal performance system instability or even system crashes.
thus a configuration free both perfconfs and adapconf free self adaptive framework for general software systems is highly desired.
in this work we propose a novel self adaptive control framework agilectrl which extends general control based self adaptive systems by automatically adjusting its internal adapconfs so that explicit adapconfs can be completely eliminated and much larger errors in implicit adapconfs training can be tolerated.
to better motivate agilectrl we first experimentally show how a state of the art self adaptive framework smartconf can handle some training deployment mismatches and yet greatly suffers from performance degradation performance oscillation and even crashes when mismatch becomes large i.e.
when the error in any explicit or implicit adapconf settings becomes high section .
to help self adaptive frameworks agilectrl s design leverages two insights first agilectrl adjusts its own adapconfs based on how well its own internal adaptations are performing measured by how accurately it predicts future performance.
this is in contrast to prior work that adjusts only perfconfs based on how closely the system meets its pre defined goal.
agilectrl adjusts both the perfconfs like prior work using the difference between the performance goal and the measured performance and its internal adapconfs using the difference between the predicted and measured performance.
second agilectrl leverages a simplified mit rule1 to adjust adapconfs so that the predicted software performance stays close to the observed software performance to ensure that agilectrl s adapconf adjustments always drive the software system to its overall performance goal.
putting these two insights together agilectrl allows a large family of self adaptation frameworks specifically those based on control theory to dynamically adapt their own adaptation logic accommodating different run time dynamics and a wide range of 1the mit rule was developed at the instrumentation laboratory now draper laboratory at the massachusetts institute of technology.training or profiling deficiencies without any extra configuration requirements for users.
the details are in section .
finally we apply the agilectrl to widely used open source distributed systems cassandra hbase and hdfs in section .
without introducing any additional adapconf agilectrl greatly enhances the system through the model and robustness self adjustment.
for model self adjustment agilectrl withstands errors up to a factor of and saves the system from performance oscillation and crashes.
for uncrashed systems agilectrl can further improve the performance up to .
for robustness self adjustment agilectrl can automatically reset the goal requirement while improving the performance by .
to summarize agilectrl makes the following contributions exposing adapconfs used in self adaptive frameworks as a potential source of bugs and demonstrate the importance of properly setting adapconfs.
proposing that self adaptive frameworks can be designed to reduce these potential bugs by constructing them to observe their own behavior and automatically modify their own internal adapconfs.
proposing agilectrl to show how to use self monitoring principle in self adaptive frameworks based on control theory.
evaluating agilectrl against multiple advanced self adaptive frameworks and demonstrate that agilectrl greatly enhance the system robustness with performance improvement.
background we first discuss the common properties of self adaptive frameworks in general.
we then describe a large class of such frameworks distinguished by their use of control theory.
.
the benefits of self adaptive frameworks modern software must deliver non functional requirements such as performance energy consumption and others while facing unexpected changes at run time such as resource contention and workload fluctuations .
self adaptive frameworks help developers meet these requirements by automatically adjusting the software s perfconfs based on observed run time behavior.
self adaptive frameworks can be generally classified as either control theory based or machine learning based approaches with some representative ones listed in table .
as the table shows all these systems contain two or more adapconfs that users must set either explicitly or implicitly.
note that smartconf adss and poet all use multiple adapconfs to automate a single perfconf thus the total number of adapconfs is actually larger than that of perfconfs .
as indicated by the last column of table these parameters can affect the framework s internal model or its robustness to error .
intuitively the accuracy of the internal model affects the average performance achieved while the robustness to error affects the ability to tolerate variance in the underlying system.
all frameworks have internal models that are used to predict how a change in a perfconf will affect the observed performance.
for example both smartconf s andottertune s neural network weights ware essential for each framework to predict the performance that could be achieved with a specific perfconf setting.
other parameters affect 460agilectrl a self adaptive framework for configuration tuning esec fse november singapore singapore table partial adapconfs used in self adaptive frameworks e explicit adapconf and i implicit adapconf systemcategoryadapconftypehow to set ?role smartconf controlpole i profiling robustness i profiling model vg i profiling robustness adss pole e expert robustness i profiling model poet pole e expert robustness i profiling model qb e expert model mv e expert model simca pole e expert robustness i profiling model brownout pole i profiling robustness i profiling model aeneas machine learning e expert model e expert model e expert model ottertune w i profiling model ds e expert model lr e expert robustness do e expert robustness dac nt i expert model tc i expert model lr i expert robustness actgan w i profiling model kh de expert model lr e expert robustness rfhoc ps e expert model mp e expert robustness cp e expert robustness the framework s robustness to tolerate some error or uncertainty in terms of the unexpected workloads environments or constraints.
for instance in control based approaches setting the pole pproperly avoids aggressive adaptation and makes the software stable during transient disturbances in learning based approaches setting a suitable learning rate lr avoids model over fitting so the framework better generalizes to unseen data.
overall adapconfs are common important and complicated.
the importance of setting suitable adapconfs is underestimated and the consequence of improper adapconfs have not been thoroughly examined this paper illustrates some problems with adapconfs in the smartconf framework in section .
.
control based self adaptive frameworks control theory is an increasingly popular set of techniques for implementing self adaptive frameworks.
the benefit of using control theory is that it supports formal analysis of the self adaptive framework implementers can reason about the conditions under which the software system will or will not meet its goals.
the drawback is that control based approaches often require some expert knowledge to deploy effectively.
in other words many such approaches expose explicit adapconfs e.g.
adss poet and simca from table that must be set by users.to alleviate this burden and reduce the total number of parameters exposed to users including both perfconfs and adapconfs some approaches have eliminated explicit adapconfs from their interface leaving only implicit ones that are set through profiling.
smartconf brownout and dac are all examples of this idea see table .
while eliminating the explicit adapconfs makes it easier for non experts to deploy these systems the implicit adapconfs must still be properly set to avoid bugs as we demonstrate in the next section .
to further understand the challenges with implicit adapconfs we focus on those from a state of the art self adaptive framework smartconf that applies proportional integral derivative pid control techniques to automatically adjust perfconfs in distributed systems.
smartconf represents a large family of self adaptive frameworks that combine a linear model with traditional pid controller .
other examples of this approach include poet adss acma sthira tangram sama controlvae brownout simca caloree jouleguard and others.
smartconf uses adapconfs for each perfconf model coefficient pole p and virtual goal ratio vg .
the former two are also used in many other control based self adaptive frameworks as shown in table .
coefficient is a key parameter for the underlying linear model.
it approximates how the current performance skat timek reacts to the perfconf valueck e.g.
queue size cpu frequency at timek .
this value is typically set through offline profiling where a linear regression model is built to quantify the effects as following sk ck b. a positive means increasing configuration increases the performance metric a negative means the opposite.
the larger s absolute value is the more sensitive the system performance is to any configuration changes.
because this coefficient is a key parameter of many control systems the recent mod2 framework automatically detects when the workload has drifted outside of a valid model and adapts this coefficient dynamically .
this approach uses a kalman filter to perform this dynamic adjustment which provides greater robustness.
unfortunately the kalman filter itself requires additional adapconfs and kalman filter based solutions can still lead to catastrophic failures when the model error is sufficiently high see our evaluation in section .
pole p is a key parameter for a pid controller as the pole determines how aggressively the controller reacts to the current performance error ek whereckis the perfconf at time k ck ck p ek.
insmartconf pis set based on a profiling measurement of how un stable the software under control is the more stable the smallerpis and hence the controller would react more aggressively.
specifically smartconf computes an un statbility metric n n 13 i mi where iandmi are the standard deviation and mean of the performance measured w.r.t minimum performance under the i th sampled configuration value.
smartconf setspto bemax .
461esec fse november singapore singapore shu wang henry hoffmann and shan lu 20tail latency s request index100 cpu cpu20 cpu cpu figure hd4995 under different cpu resources virtual goal ratio vg is brought in when there is a hard constraint of performance like never overshooting memory limits.
thevgis a real number between to .
it reserves some potential performance gain as cushion space to trade for robustness to system instability like environment or workload changes .
the more unstable the system is the larger the cushion space needs to be.
specifically the virtual goal ratio vg n n 1 i mi where iand miare the standard deviation and mean of the performance measured under the i th sampled configuration value based on offline profiling.
then virtual goal can be calculated by vg s where sis the desired performance goal.
insmartconf like other systems that use implicit adapconfs these parameters are set through profiling runs.
users provide representative workloads and the framework collects statistics from those workloads to set the adapconfs.
the next section demonstrates some problems that can arise from this approach.
motivating example to better motivate agilectrl we investigate how implicit adapconfs are used in smartconf which sets its adapconfs during training then uses these fixed values throughout run time.
we show these fixed values can lead to system performance degradation or crashes when the deployment environment differs significantly from the training environment.
we take two benchmarks from smartconf hd4995 and hb3813 as examples.
while this specific example uses smartconf to illustrate the points the general problems and behaviors are shared by all self adaptive frameworks that use offline profiling data to set implicit adapconfs.
.
run time resource mismatch our first example hd4995 reveals that although smartconf can tolerate some training deployment mismatch in terms of run time resources it severely malfunctions when the mismatch increases.
here the target system hdfs has a perfconf content summary.limit that limits the number of files traversed before du a hdfs command for estimating file space usage has to release a highly contested lock.
if this perfconf value is too large write requests would be blocked for long if too small dulatency hurts.
100request size used memory mb completed workload 1mb 2mb 5mb 10mbfigure hb3813 under different workloads.
we use the same training workload used in smartconf with cpu resources which is based on the distributed file system benchmark testdfsio .
through training smartconf computes adapconfs p vg as .00005s .
.
with indicating the average latency to traverse a single file to be .00005s.
in the deployment runs we gradually decrease the cpu allocated to hdfs from to .
as shown in figure smartconf provides some robustness when the environment is a little bit different from training under both cpu resources green curve and cpu resources blue curve smartconf gradually reduces the tail latency to the required goal 20s .
however when the cpu resource drops to the smartconf acts too aggressively with the tail latency oscillating around the goal pink curve .
even worse with cpu allocated to hdfs the system fails to converge with the tail latency jumping between 1s and 90s orange curve .
the rationale is that the hdfs file directory processing speed slows down when the cpu resources drop causing the ideal setting of the adapconf to increase.
without adjusting the controller s setting at run time the whole system s performance oscillates.
.
run time workload mismatch our second example hb3813 shows when the run time workloads differ from the training workloads the smartconf may overshoot the hard constraint and result in crashes.
the perfconf max.queue.size determines the largest size for an rpc queue used in hbase.
a large queue can lead to an out ofmemory oom when under memory pressure while a small queue reduces rpc throughput.
we use ycsb workload a with 1mb request size and read write ratio as the training workload under which smartconf computes three adapconfs p vg as .25mb .
.
.
specifically characterizes the average request size inside the queue.
at runtime we gradually increase the request size from 1mb to 10mb.
as shown in figure for 1mb workload green curve smartconf works as expected keeping the memory consumption under the specified constraint the red horizontal line .
for a slightly larger request size 2mb blue curve smartconf can still efficiently utilize 462agilectrl a self adaptive framework for configuration tuning esec fse november singapore singapore the memory as smartconf has some ability to accommodate for training deployment workload mismatch.
however when the request size increases to 5mb the system exceeds the memory limits after finishing around of the total workload and then crashed.
unsurprisingly hbase also crashed with 10mbrequest size with only workload finished.
the rationale is that the ideal setting of the adapconf increases with the hbase request size.
without adjusting its setting at run time smartconf underestimates the memory impact of the rpc queue causing out of memory failures.
our two motivational experiments reveal that fixed adapconfs are sources of system under performance or crashes.
while existing self adaptive frameworks like smartconf eliminates explicit adapconfs to avoid direct human misconfiguration it still has implicit adapconfs set based on user designed training data.
as our experiments show when the training data does not match with the run time characteristics resources or workloads the adapconfs settings become problematic.
therefore eliminating any explicit adapconf and self adjusting any implicit adapconf are highly desirable for a robust self adaptive system.
4agilectrl design the previous section shows how self adaptive frameworks may fail to meet software requirements if their operating environment diverges significantly from the profiling environment.
specifically if the environment does diverge implict adapconfs representing either the framework s internal model or robustness to error might be set incorrectly leading to performance oscillation i.e.
failure to meet the requirements or even system crashes.
the key insight of this paper is to augment such self adaptive frameworks with an ability to observe themselves and adjust their adapconfs to prevent this bad behavior.
we note that one approach could be to monitor different aspects of the environment e.g.
resource availability or workload properties .
the problem with this approach is that there could be any number of environmental factors to observe and it is not clear ahead of time which of these factors matter or even which can be easily monitored.
thus we propose that self adaptive frameworks should be modified to observe both how well they are meeting the performance requirements and the same metrics that were used to set any implicit adapconfs during profiling.
this modification can be done internally to the framework with no change required from users.
it is also robust to any environmental factor that affects the framework s ability to meet goals and it does not require collecting any new information beyond what the framework already collects during profiling.
specifically as adapconfs affect either the framework s internal model or its robustness to errors we propose to monitor how well the self adaptive framework predicts future performance on average and how close the framework comes to its goal by both mean and standard deviation .
the first of these allows our approach to make dynamic adjustments to the model while the second allows adaptive adjustments to the adapconfs that affect robustness.
controllerperformance goalmeasured performance systemagilectrl perfconf adjustmentperfconfcalibrated performancemodel adjustment disturbance adapconf vgrobustness adjustmentperformance modelperformance calibrationpredicted performancefigure the overall agilectrl which extends a generic control based self adaptive framework.
.
overview we apply the above insights to smartconf a state of the art and general self adaptive framework.
specifically shown in figure agilectrl collects both the measured performance from the target system and the predicted performance based on current controller status for model adjustment .
moreover agilectrl leverages the stability of measured performance w.r.t to the goal for robustness adjustment vgandpole .
together agilectrl enhances the system with model and robustness self adjustment during the run time.
our proposal is to make online adjustments to adapconfs within a self adaptive framework.
in other words we want to estimate the best setting for these adapconfs based on the software s current operating conditions.
in deciding how to estimate these values we face a design choice they can be estimated directly or indirectly based on the properties of each adapconf .
for direct estimation adapconfs use design equations to reparameterize the model.
this approach has a shorter response time but it assumes that there is low noise in the samples and that inaccurate estimation will not lead to catastrophic failure.
indirect estimation recursively estimates i.e.
slowly approaches the best value for each adapconf as it collects feedback.
this approach is much more resistant to transient noise because a single erroneous or outlier observation will not change the overall trajectory in which the adapconf setting is moving .
the underlying ideas of agilectrl can be applied to other selfadaptive frameworks besides smartconf .agilectrl can be applied with almost no changes to the increasingly large number of control based self adaptive frameworks e.g.
which all have one or more parameters that capture the model relating perfconf settings to performance analogous to in this paper .
similarly while not all control methods use a virtual goal all have some parameter relating to robustness to error and that parameter can be tuned following the same methodology shown below.
for multiple input multiple output mimo systems the correlation between configuration parameters and performance metrics can be captured as a matrix instead of a scalar.
agilectrl can leverage a vector of performance metrics to update the model matrix based on the difference between measured and predicted performance metrics.
in other words the principle of updating the model based on observed behavior still applies.
interesting future work could investigate applying the same principles to tune machine learning based models as well although 463esec fse november singapore singapore shu wang henry hoffmann and shan lu the application of the proposed methods to such models is not straightforward.
learning methods train an internal model relating perfconfs to performance.
updating that model online would require retraining as the learning based framework evaluates its dynamic behavior so it is not clear that retraining cost would be worthwhile.
it is possible a learning based system would also benefit from observing the dynamic volatility in the environment and adjusting its own robustness related adapconfs e.g.
the learning rate to tailor online behavior to the actual environment rather than assuming the run time will be the same as the profiling but applying this approach would require a careful understanding of the relationship between ml hyperparameters and the desired performance.
.
tuning adapconfs related to the model an accurate performance model is important for self adaptive frameworks to provide theoretical guarantees for instance that the software will converge to the desired performance.
as shown in sec.
model deviation threatens both these formal guarantees and even system availability.
for control based self adaptive frameworks coefficient or analogous parameter is the most important adapconf for characterizing the system model.
it has the following properties its sign is the primary determinant of whether the software converges to the goal since the sign determines whether to increase decrease the underlying perfconf while its magnitude determines how aggressively the adjustment moves in the direction indicated by the sign.
its magnitude usually has a wide range as designers want meaningful parameters and prior studies show that of the configuration are either integer or floating point values .
its performance is sensitive to changing from .
to .
could result in perfconf changed by times based on equation .
for all these reasons we use the most conservative self adaptive strategy for tuning.
furthermore we make the design choice that it is preferable to reduce convergence speed while reducing the chance for divergence.
we therefore split the process of model adjustment into two parts determining the sign or direction of and then determining the magnitude once the sign is established.
coefficient sign as mentioned above is the key for performance convergence or divergence.
moreover it is the only adapconf that captures the trend positive or negative correlation of performance configuration and thus determines whether the underlying perfconf should be bigger or smaller equation .
it is also important to note that none of other adapconfs s magnitude polepnorvg in sec .
have the property that incorrect setting would result in tuning in the wrong direction.
in other words the trend remains the same even all other adapconfs are wrong.
thus we can indirectly detect the wrong sign based on tracking the trend of how well the software system is meeting its goal.
specifically we can calculate the performance error ekas the current performance w.r.t the performance goal note that all controlbased approaches already track this value .
ideally the traditionalcontroller is asymptotically stable which means ek should decrease while gradually reducing to zero .
therefore we check the trend of ekby comparing consecutive errors whether the last i2errors are decreasing or not.
the noise could occasionally affect the temporary trend but the long term trend remains the same.
specifically we flip the sign when the last ierrors are in ascending order algorithm i.e.
the performance is diverging further and further away from the goal.
algorithm wrong sign detection input g performance goal ck current performance measured at time k i lastisamples output updated alpha sign 1calculate current error ek g ck 2ifek ek ek i 1then incorrect ektrend flip the sign 3 k k 4end coefficient magnitude determines how the magnitude in change for the underlying perfconf.
for example if the perfconf controls the maximum size of a software data structure then s magnitude determines how much that size might be changed at one time.
specifically if is too big the controller might not be able to react to the system changes fast enough resulting in performance degradation.
conversely if is too small then the system becomes unstable causing performance oscillation or even crashes.
agilectrl approaches the ideal gradually without introducing extra adapconfs through indirect estimation.
in fact it is much easier and more robust to determine to enlarge or reduce magnitude iteratively than acquiring optimal magnitude directly .
specifically we leverage model reference adaptive control used in control theory to build another feedback loop to evaluate the controller s performance and propose a simple adaptation rule to estimate s magnitude.
specifically we make a time varying quantity k. we then determine a ratio where so that we can write k k. in control theory the mit rule proposes to adjust such that the quadratic loss function j p c k true 2c2 is minimized.
here pandcare the predicted and current performance cis current configuration and true represents the actual coefficient of the system which cannot be measured .
essentially the loss function jrepresents the error between the predicted and current performance we expect the predicted performance to be the same as the actual measurement if kis accurate.
thus we can approximate true by noting that if the predicted performance is far from the current performance then the current kmust also be far from true as well.
specifically the true value for is true k but since we cannot measure true we approximate the ratio of the true to current kas true k true ck b true ck b k ck b k ck b ck ck pk k ck b ck ck pk ck .
of course we assume the system is subject to noise so we regularize this approximation using g ck g 2foragilectrl we set i .
see sec.
.
for more discussions.
464agilectrl a self adaptive framework for configuration tuning esec fse november singapore singapore as an exponent on this ratio.
when the current performance already meets the goal then the exponent is close to and remains the same.
when the current performance is far away from the goal the exponent is close to which allows maximum changes on .
putting this all together we indirectly estimate kas k k ck ck pk ck g ck g whereck 1andckare the previous and current performance pkis the predicted performance and gis the performance goal.
specifically we update based on algorithm .
as long as the ratio ck ck pk ck 1is close true k then we prove that a0 k k true by induction which means kwill converge to true.
algorithm dynamic adjustment input g performance goal ck current performance measured at time k output updated alpha magnitude 1predict further performance pkat timekbased onck using equation 2update k k ck ck pk ck g ck g smartconf assumes a linear model equation with bounded errors for perfconf and the linearity assumption can cause failures shown in section .
agilectrl relaxes such assumption through dynamically updating the approximation algorithm .
.
tuning adapconfs related to robustness besides model accuracy robustness is another important property of any self adaptive system.
the robustness means the system can accommodate unexpected changes in workload or environment.
for control based self adaptive framework robustness is captured by both the pole pand the virtual goal vg.
for agilectrl the polepdoes not need to be adjusted dynamically since it is set to tolerate erros in which are already addressed in sec.
.
and andpare correlated and together constitute a coefficient that determines how aggressively the controller reacts to the performance error.
therefore p 0is used in agilectrl .
recent works introduce a virtual goal vg that is smaller than actual goal to avoid overshooting and it can be calculated based on inherent system noise sec.
.
unlike vgis in the range .
also vgitself characterizes the system noise which can be statistically estimated.
therefore vgcan be self adjusted through direct estimation at run time.
to re calculate vg one needs to compensate for performance variation caused by different configurations since perfconfs are continuously changed by self adaptive framework.
to solve it we leverage the system configuration performance model.
specifically wecalibrate the performance by compensating the measured performance difference with the configuration differences as shown in algorithm .
we take n3pairs of performance configuration for virtual goal adjustment.
we calibrate performance pas if it is measured with configuration ckbased on the system model i.e.
3foragilectrl we set n suggested by sample size rule of thumb .
see sec.
.
for more discussions.based on kas computed above and obtain calibrated performance p line .
then we can simply recalculate the kandmkbased on calibrated performance and recalculate the virtual goal as usual.
algorithm virtual goal self adjustment input p current performance c current configuration n lastnsamples output vgk updated virtual goal 1s 2while s n do calibratepk stop k s pk s k ck s ck s 5end 6calculate standard deviation kand meanmkofp 7updatevgk n n 1 k mk .
putting it all together all above mentioned components are integrated into agilectrl and can function seamlessly.
in fact sign correction is independent of others since it does not require value orvgto be accurate.
the magnitude adjustment will continuously update the performance model to match the run time and it does not depend on either the sign orvgadjustment.
the vgadjustment only relies on an accurate performance model.
there is no circular dependency among all those components.
as result all components in agilectrl operate together to achieve a self adaptive system.
evaluation .
evaluation methodology machines we used the chameleon cloud for our experiments.
each server has core intel xeon e5 2670v3 cpu with 128gb ram.
ubuntu .
jvm .
and jvm .
compatible with ca6059 are installed.
baseline and benchmarks we compare agilectrl with smartconf from three aspects sign magnitude and vg.
we evaluate all benchmarks used in smartconf except for mr28204 as shown in table .
among those benchmarks hd4995 and hb2419 have a constraint on latency and the other three benchmarks have hardlimit constraints on memory usage to avoid out of memory failures.
workload for database related benchmarks hbase and cassandra hb3813 hb6728 hb2149 and ca6059 standard performance testing framework ycsb is used while we use testdfsio for file system related benchmark hdfs hd4995 .
run time as shown in table we consider a separated run time settings for evaluating model self adjustment sign and magnitude adjustment and robustness self adjustment vgadjustment .
4for mr2820 the main goal is to restrict the maximum ood exceptions within one job smaller than the threshold to avoid job failure and the exception is limited by the number of machines the job tried.
agilectrl is expected to work well for a large cluster.
however given the small cluster size in our experiment agilectrl failed to correct the improper adapconfs fast enough.
further discussions on agilectrl limitation are in section .
.
465esec fse november singapore singapore shu wang henry hoffmann and shan lu table benchmark suite and run time setting for evaluation.
idissue description metrics run time setting the primary constraint is put earlier the trade off constraint is later primary secondary sign magnitude vg hd 4995content summary.limit limits files traversed before dureleases locks.
write du man limit cpu reducetoo big write blocked for long too small dulatency hurts.
latency latency uallyusage to vgtohb 2149global.memstore.lowerlimit decides how much memstore is flushed.
tail violated flip100 too big write blocked for too long too small write blocked too often.
latency latency hb 3813ipc.server.max.queue.size limits rpc call queue size.memorythrough signtoo big oom too small read write throughput hurts.
put increase hb 6728ipc.server.response.queue.maxsize limits rpc response queue size.memorythrough size to too big oom too small read write throughput hurts.
put ca 6059memtable total space in mb limits the memtable size.memory latencymb too big oom too small write latency hurts.
table sign evaluation primary the normalized primary performance w.r.t the goal the closes to the better.
secondary the secondary trade off performance speedup w.r.t smartconf the larger the better.
benchmarksmartconf agilectrl primary secondary primary secondary hd4995 .
.
.
.
hb2149 .
.
.
hb3813 .
.
.
hb6728 .
.
.
ca6059 .
.
.
for sign the wrong sign mostly comes from insufficient profiling or human mistakes which we simulate by flipping the sign of the initial rather than workload or run time resources changes.
for magnitude magnitude are usually affected by different types of runtime settings.
for benchmarks hb2149 and hd4995 their primary performance metric is about latency which is directly affected by cpu resources.
therefore we limit cpu resources by a factor of and namely limit cpu usage to and with linux cpulimit tool.
for benchmarks hb3813 hb6728 and ca6059 their primary metric is memory usage which is affected by workload.
therefore we increase every request size by the same factor from 1mb up to 10mb .
forvg sincevgreflects the chaos of the runtime environment and an improper vgmeans a mismatch between offline and online virtual goal setting we reduce the initial virtual goal by and and compare smartconf andagilectrl .
.
agilectrl evaluation .
.
model self adjustment our experiment with the wrong sign shows that agilectrl performs much better than the baseline smartconf .
as shown in table smartconf can achieve only of the primary performance goal.
on the contrary agilectrl keeps tracking of the moving direction of the primary performance and hence can auto correct the sign of and achieves mostly more than of the primary performance goal even with an incorrectly initialized sign.
moreover agilectrl also improves the secondary performance compared with smartconf .table magnitude evaluation.
c the system crashes.
o primary performance oscillates around the goal.
neither c nor o the normalized secondary performance speedup with agilectrl being the higher the better.
bench change level sc olr kf agilectrl hd4995 resource .
.
.
.
.
.
.
.
o .
.
.
o .
.
.
hb2419 .
o .
.
.
o .
.
o o .
.
o o o .
hb3813 workload .
c .
.
.
c .
.
c c .
.
c c c .
hb6728 .
c .
.
.
c .
.
c c .
.
c c c c ca6059 .
c .
.
.
c .
.
c c .
.
c c .
.
our experiment with the wrong magnitude compares agilectrlwith not only smartconf but also two prior techniques that adjust through online linear regression olr or kalman filter kf .
as shown in table online linear regression olr performed the worst causing system crashes mainly due to out of memory problems or severe performance oscillation in all but one benchmark.
this result shows that directly re setting the value of using the same offline linear regression algorithm used during profiling as in olr does not work.
smartconf sc is just slightly better than olr.
kalman filter kf can eliminate most of the crashes and oscillations encountered by olr and sc but still performs significantly worse than agilectrl .
it also introduces extra configuration tuning which we explain below.
in contrast agilectrl 466agilectrl a self adaptive framework for configuration tuning esec fse november singapore singapore only failed in one extreme case of hb6728 where other strategies also failed.
agilectrl performs the best for meeting primary performance goals without oscillations or crashes and enabling better secondary performance without introducing any new adapconfs.
kalman filter is a recursive filter that indirectly estimates the internal parameters of a system given noisy measurements .
in general it suffers from two limitations compared with agilectrl .
it assumes gaussian noise but software performance s noise often does not follow a normal distribution .
it contains two additional parameters process noise and observation noise that are hard to be set correctly.
in our experiment we actually tuned these two additional parameters by exhaustively search.
finally we quantify the model robustness of agilectrl against other alternative solutions by calculating their error tolerance .
specifically we first calculate the ideal alpha sysbased on the offline profiling.
then we vary the ctrlmagnitude and find the lowest and highest boundary alpha lowest bound and highest bound under the same workload that system is about to crash or oscillate.
therefore the error tolerance etlandeth for the particular benchmark and strategy can be defined as etl sys lowest bound eth highest bound sys by definition both etlandethare greater than .
the larger etl orethis the better ability to tolerate the errors in the system has thus the better system robustness is.
in other words the system is stable if ctrlis within sys etl syseth .
if none of can save the system from crash or oscillation we set et 0to indicate such a solution can not be used for adjusting the alpha magnitude.
table overall error tolerance for agilectrl compared with alternative approaches etl eth the lowest highest alpha that corresponding approach can correct without causing performance oscillations or system crashes.
no such alpha without causing performance oscillations or crashes benchmarksc olr kf agilectrl etlethetlethetlethetleth hd4995 hb2419 hb3813 hb6728 .
ca6059 table shows agilectrl can greatly extend both the lowest bound and highest bound compared with all alternative approaches which means it can tolerate a larger range of wrong ctrlused by the controller.
well tuned kalman filter approach achieves slightly worse performance and online linear regression failed to provide any robustness in out of all cases.
the baseline solution smartconf can only provide only limited tolerance but it is more stable than online linear regression.
.
.
robustness virtual goal self adjustment specifically we investigate how much secondary performance improved if the initial virtual goal is only and of the ideal virtual goal obtained from the profiling.
our experiment shows across all benchmarks smartconf fails to correct the wrong initial vg whichtable virtual goal vg evaluation the speedup on the secondary performance metric w.r.t smartconf under different initial virtual goal ratios.
benchmarkinitial virtual goal ratio hd4995 .
.
.
.
hb2149 .
.
.
.
hb3813 .
.
.
.
hb6728 .
.
.
.
ca6059 .
.
.
.
leads to poor secondary performance as well.
agilectrl resets the wrong initial goal requirement so that the primary performance meets the ideal goal while improving secondary performance by on average as shown in table .
.
case study 400used memory mb virtual goal acutal usage 18alpha mb items time s tolerable alpha ideal alpha actual alpha figure both initial s magnitude and initial virtual goal are 10x different from the ideal setting and the initial s sign is also flipped.
all modules of agilectrl are enabled and able to fix wrong and virtual goal for hb3813 we take a close look at how agilectrl handles one representative case hb3813.
we considers an extreme buggy scenario.
none of sign magnitude and vgare right and it required all components to work together.
then we analyze how each component functions in this representative case.
again in hb3813 the perfconf max.queue.size limits the largest size for an hbase rpc queue.
out of memory oom is more likely to happen with a large queue while rpc throughput is reduced with a small queue.
the smartconf alleviated the hb3813 issues to accommodate different workloads maintain the memory consumption without oom and improve the system throughput.
however smartconf introduces two representative adapconfs vg to the system where represents the size of the average request and vgreserved a portion of memory for safety.
in fact 467esec fse november singapore singapore shu wang henry hoffmann and shan lu hb3813 contains the following challenges that are unique to selfadaptive for software configuration tuning it requires online tuning since online request size could be much larger or smaller than offline.
it has a hard constraint on the performance e.g.
the memory limit cannot be violated the performance memory usage has large variations due to java gc.
ideally a full combination of different s magnitude s sign and virtual goal variations should be tested thoroughly.
however the target system is more likely to suffer from performance degradation or crash when attributes or virtual goal deviate from the ideal setting.
therefore we consider the following situation where both initial s magnitude and initial virtual goal are different from ideal and s sign is also flipped compared to ideal sign specifically initial .125andvginitial .
.
as shown in fig.
though the initial andvgare both wrong from the beginning agilectrl can quickly adjust the virtual goal back to the ideal setting of max memory and sign is flipped to the positive and quickly converge to ideal alpha magnitude.
this demonstrates that agilectrl s feasibility of fixing multiple errors at the same time.
.
limitations of agilectrl agilectrl has its limitations.
first magnitude adjustment depends on mit rule where itself is not globally convergent nor stable .
compared with smartconf agilectrl sacrifices statistical guarantees provided by the traditional controller in return for system robustness.
though the statistical guarantees we gave up as shown previously the agilectrl outperforms smartconf empirically.
second ideally agilectrl can fix the both andvgproblem no matter its initial magnitude.
for example in our evaluation agilectrl can tolerate improper by106 due to human error.
this error tolerance could vary in different scenarios that affect the system performance model.
for example in hb3813 if the request size is enlarged from 1mbto106mb 1tb and any hbase with less than 1tbheap memory resources will crash directly.
this is due toagilectrl is an asymptotic approach to bridge the gap between the system model and control model.
it does require a certain response time to react to unexpected changes in the environment or workload.
yet in the previous example the memory was already used up before receiving the first full request so there is no time for agilectrl to realize the workload changes and take any precautions.
besides response time the computational precision should also take into consideration when we deal with the extreme adapconfs values.
third we introduce two parameters i algorithm and n algorithm .
unlike other adapconfs these two parameters provide statistical guarantees.
for example in hb3813 when the setting ofiis smaller than the default setting we observe that a large percentage of executions fail due to frequent sign flipping for i 2and for i .
wheniis not smaller than the default setting none of the executions fail.
with a larger i algorithm is less sensitive to the system noise but takes a longer time to detect the incorrect sign.
similarly for sample size nthat is less than the default setting like when nis10or20 all executions would fail due to inaccurate vgestimation.
in general selecting a suitable sample size is covered by best practices in statistics and is out of the scope of this paper.fourth agilectrl is designed to automate adapconfs and vg used in control based self adaptive framework.
for machine learning based self adaptive system they introduce a different set of adapconfs learning rate weight etc which are not solved by existing agilectrl .
related work automatic configuration tuning large modern software contains hundreds to thousands of configurations and those configurations are usually badly documented and are hard for both developer and user to set .
great efforts have been made towards automatic configuration tuning in recent years.
specifically existing approaches can be classified as model based tuning search based tuning and learning based tuning.
model based tuning relies on the accurate performance model of the system.
such model synthesis usually requires domain specific knowledge to abstract software with a mathematical model.
the model is highly abstracted and very specific to the analyzed software.
search based tuning treats the software as a black box and uses a searching algorithm to find the optimal settings.
however those approaches suffer from exploration and exploitation problems and are not suitable for dynamic adjustment during the runtime.
learning based tuning usually builds a performance model based on the profiling and finds the best configuration during the runtime.
the performance models could be regression model or machine learning model .
however all those works mainly focus on improving the system performance for the similar workload or environment.
in fact both workload and environment have important impacts on software performance and they are unusually hard to model and learn.
smartconf a control theory based solution provides a formal guarantee that systems can achieve desired performance when the environments changes are within a small and pre defined boundary.
agilectrl is designed specifically for extending the system robustness without sacrificing the performance gain.
for previous works the parameters are statically determined by the offline profiling workload and environment.
however agilectrl automatically adjusts those parameters during the runtime to accommodate the workload and environment changes.
consequently the system error tolerance is greatly extended and system performance is improved.
in fact agilectrl is designed to eliminate the offline process every parameter obtained from offline profiling should be adjusted as well.
though agilectrl has only been applied to smartconf in this paper the idea of agilectrl should be applied to any automatic configuration tuning framework based on either static performance model static searching algorithm or offline profiling.
machine learning machine learning has been widely used to learn the system performance model as the foundation for searching the optimal performance .
in general those approaches require a huge amount of effort on data collection e.g.
tens of hours for one workload let alone infinitely many disturbances workloads and environment.
a limited amount of training data is not enough for the machine learning technique to work in dynamics.
the ability to adjust the machine model itself 468agilectrl a self adaptive framework for configuration tuning esec fse november singapore singapore based on dynamics during the runtime is needed.
in contrast control theory is designed for system dynamics with formal guarantee .
empirical studies comparing control and learning solutions have observed that control techniques approach the goal with less error .
moreover the machine learning model such as neural networks and deep learning usually are hard to interpret as the target system is treated as a black box .
therefore machine learning is not suitable for dealing with dynamics.
adaptive control traditional control framework can still maintain its properties if the applied system is slightly different from its model synthesis or suffers from environment changes.
to further advance the controller for unexpected dynamic disturbances the adaptive control aims at adapting its underlying model during the runtime to compensate for the environment or workload changes.
though various adaptive control techniques have been proposed most of them are designed for specific systems.
for example it has been successfully applied to aerial vehicles engine control distillation column and so on.
however the adaptive control is hard to be generalized to different applications because of different underlying system models.
agilectrl is designed specifically to enhance general control frameworks which approximates the system model as a linear model without taking the high order correlations into consideration.
agilectrl does not require additional assumptions other than the control framework.
moreover adapconf is adjusted based on its internal performance instead of analyzing the external system and environment.
as demonstrated in the evaluation section with different benchmarks disturbances and performance goals agilectrl is robust enough across different deployment scenarios and different environmental settings that cause errors in adapconfs.
thus agilectrl itself is general with respect to different applications as well as different types of system disturbances.
most importantly adaptive controllers are inherently nonlinear and complex and prior researches focus on establishing stability analysis of the adaptive control.
however most adaptive control system introduces additional parameters which require the control expert to set.
for non expert those parameters are hard to set and error prone.
previous work copper poet and mod2 took the first step for adjusting controller key parameters using kalman filter.
however it requires setting two additional parameters namely process and observation noise with the assumption of gaussian distribution.
agilectrl aims at allowing non expert to use without setting additional parameters.
conclusions self adaptive frameworks have been successfully applied to automate configuration tuning with better performance.
those selfadaptive frameworks explicitly or implicitly introduce a set of adapconfs to the system and the proper adapconfs setting depends not only on the understanding of adapconfs but also complicated environment or workloads during the runtime.
we argue that self adaptive frameworks should automate not only perfconfs but also adapconfs.
we proposed agilectrl to automatically modify adapconfs based on how well self adaptive is performing.
our evaluation demonstrates that compared with other well tuned approaches agilectrl can tolerate larger workload or environmentchanges while achieving a similar performance without introducing adapconfs.