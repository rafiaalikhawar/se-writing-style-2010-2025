exais executable ai semantics richard schumi singapore management university singapore rschumi smu.edu.sgjun sun singapore management university singapore junsun smu.edu.sg abstract neuralnetworkscanberegardedasanewprogrammingparadigm i.e.
insteadofbuildingever morecomplexprogramsthrough often informal logical reasoning in the programmers mind complex ai systemsarebuiltbyoptimisinggenericneuralnetworkmodels withbigdata.inthisnewparadigm aiframeworkssuchastensorflowandpytorchplayakeyrole whichisasessentialasthecompiler for traditional programs.
it is known that the lack of aproper semantics for programming languages such as c i.e.
acorrectness specification for compilers has contributed to manyproblematic program behaviours and security issues.
while it isin general hard to have a correctness specification for compilersdue to the high complexity of programming languages and theirrapid evolution we have a unique opportunity to do it right thistime for neural networks which have a limited set of functions andmostofthemhavestablesemantics .inthiswork wereport our effort on providing a correctness specification of neural network frameworks such as tensorflow.
we specify the semantics of almost all tensorflow layers in the logical programming language prolog.wedemonstratetheusefulnessofthesemanticsthroughtwo applications.
one is a fuzzing engine for tensorflow which featuresastrongoracleandasystematicwayofgeneratingvalid neuralnetworks.
theother isamodel validationapproachwhich enables consistent bug reporting for tensorflow models.
keywords aiframeworks ailibraries deeplearningmodels semantics specification testcasegeneration modelvalidation aimodelgeneration acm reference format richard schumi and jun sun.
.
exais executable ai semantics.
in 44thinternationalconferenceonsoftwareengineering icse may21 pittsburgh pa usa.
acm new york ny usa pages.
https introduction artificial intelligence ai refers to intelligence expressed by machines.
it can be based on imitating human intelligence or learning behaviour.
for example the technique called deep learning dl appliesartificialneuralnetworkstosimulatetheneuronsofnatural permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation onthe firstpage.copyrights forcomponentsof thisworkowned byothersthan the author s mustbehonored.abstractingwithcreditispermitted.tocopyotherwise or republish topostonserversortoredistributetolists requirespriorspecificpermission and or a fee.
request permissions from permissions acm.org.
icse may pittsburgh pa usa copyright held by the owner author s .
publication rights licensed to acm.
acm isbn ... .
dramaticgrowthofdataandcomputingpowerhasledtothespreadofdlapproacheswhichenabled numerous new technologies like autonomous driving language processing and face recognition .
inprinciple aisystemscanbeseenasanewprogrammingparadigm.insteadofbuildingprogramsthrough ofteninformal logical reasoning by programmers ai systems are built by training neural networkmodelswithbigdata.forconventionalprogramming compilersorinterpretersaremajordevelopmenttools.similarly forthe development of neural networks the focus is on ai frameworks or libraries such as tensorflow and pytorch which provide utilities algorithms and various types of layers that constitute dl models.
the lack of a proper semantics or correctness specifications for programming languages has resulted in many critical issuessuch as inconsistencies or vulnerabilities.
generally it is hard to developacomprehensivespecificationforcompilersduetothehighcomplexityandtherapidevolutionofprogramminglanguages .
however webelievethatitismorefeasibleforaiframeworks since the semantics of ai frameworks are usually stable and simpler i.e.
thesetoffunctionsandlayersusedinpopularmachinelearning models are usually limited.
althoughaisystemshavebeenprovensuccessfulinmanyapplications they are not error free.
especially in safety critical applications likeautonomousdriving ormedicalsystems evensmall bugscanhavesevereconsequences.thus weneedsystematicwellgrounded analysis methods for ai systems.
while the lack of a properlanguagespecificationhashinderedmanyprogramanalysistasks wehavehereauniqueopportunitytostartafreshbybuildingaformalsemanticsofaisystems whichthenservesasasolidfoundation for developing ever more sophisticated analysis methodsfor ai systems.
in this work we make such an attempt by devel oping an executable formal semantics for ai frameworks.
thatis we introduce a prolog specification for almost all tensorflow layers.
our specification provides the foundation for solving many ai analysis problems such as ai test generation model validation and potentially ai model synthesis.
in the following we present one example application of the semantics ai test generation.
recently testing dl systems has become a popular research topic with a variety of approaches .
in comparison testingaiframeworkshasgainedlessattention.abuginanailibrarycanpotentiallyputallsystemsthatwerebuiltwiththelibraryatrisk.hence itiscrucialtoensurethecorrectnessoftheselibraries.multi pleresearchersmadesomeearlyattempts although existing approaches suffer from at least two major issues.
first existing approaches often have a weak oracle i.e.
a test case passesifsomesimplealgebraicpropertiesaresatisfied orr esultsinsimilaroutputsontwoimplementations whichcan make it difficult to find deep semantic bugs.
second existing approaches fail to systematically generate valid ai models i.e.
to our ieee acm 44th international conference on software engineering icse authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
icse may pittsburgh pa usa richard schumi and jun sun knowledge the state of the art approach has a success rate of in generating valid models after a complicated process combining nlp techniques with manually designed templates .
ourexecutablesemanticssolvesthesetwoissuesnaturally.first given an ai model our semantics can be executed to compute precisely the constraints that are satisfied by the output based on the prolog sunderlyingunificationandrewritingsystem whichserves as astrong testoracle.
second our semantics facilitatesthe developmentofafuzzing basedtestgenerationmethodtosystematically producevalidaimodels.oursemanticsfacilitatesthegeneration process by providing feedback in the form of a badness value that indicateshowfarthemodelisawayfrombeingvalid i.e.
satisfying the precondition of all layers of the model .
our evaluation shows thatwesignificantlyimprovethesuccessrateofgeneratingvalid aimodel e.g.
andcangeneratediversemodelarchitectures consisting of various layers in the form of sequences and complex graphs as well as layer arguments weights and input data.
besides having anexecutable semanticsof anailibrary opens thedoorforarangeofotherexcitingresearch.forinstance itallows systematic validation and bug reporting for ai models e.g.
by investigatingautomaticallywhethercertainpreconditionsrequired by a specific ai component are violated and by checking if the architectureofamodelisvalid.weremarkthatexistingdebugging techniques for ai systems rely on simple oracles such as shape mismatch which is preliminary compared to the oracle that isprovided by our semantics.
for another instance our semantics potentiallysupportsthedevelopmentofsynthesisingtechniques for ai models.
that is given certain user requirements e.g.
on the input format the output constraints and perhaps a model sketch theproblemofsynthesisingaimodelscanbereducedtoasearch problembasedonthewell specifiedsemanticsofallcomponents inexistingaiframeworks i.e.
bycomposingthecomponentsin different ways and checking if the user requirements are satisfied.
to sum up we present the following contributions in this work.
we introduce an executable semantics of an ai library i.e.
tensorflow which captures the behaviour of the dl layers.
to demonstrate the relevance of our semantics we present a novel testing method for ai libraries that applies the semantics as test oracle and utilises it to generate valid ai models.
our method was able to reveal issues and bugs in tensorflow.
we illustrate a model validation method that can identify issues of invalid ai models like a wrong model architecture based on our semantics and that supports consistent bug reporting.
structure.
therestofthepaperisstructuredasfollows.insect.
we introduce our semantics and show how we specify different layers.in sect.
wepresent twoapplicationsof thesemantics.
in sect.
weevaluatethesetwoapplicationssystematically.lastly we review the related work in sect.
and conclude in sect.
.
ai framework semantics inthissection westartwithabriefintroductionofthelogicprogramminglanguageprolog thatweadoptforthedevelopment of our ai framework semantics.
afterwards we describe our approach on developing the semantics through examples.
in general to support a variety of analysis tasks including testing debugging andevensynthesisingaimodels itisimportantthatthesemanticsfulfilsthefollowingrequirements .first thesemanticsmust be declarative and high level so that it avoids complications dueto implementation level optimisation and to facilitate a concise specificationthatisindependentofimplementationdetails.second it must support symbolic reasoning to allow various property consistency and correctness checks and thus it must be specified in logic.
lastly it must be executable so that it can be used to support a variety of automated analysis tasks like testing or debugging.
.
prolog prolog is a declarative language that relies on first order logic.
programsinprologarebuiltwithrulesandfacts whichareusually concerned with mathematical relations.
hence we believe that prologissuitableforaformalsemanticrepresentation.theremight be more formal mathematical semantic models that e.g.
rely on coq but such notations are not as flexible and would make it difficult to support a large number of layers.
in prolog a user can ask queries and the answer is computed automaticallybasedon therules andfacts witha unificationalgorithm.thefollowingexampleshowstwofactsstatingthat average andflatten are layers and a rule that says that layers are ai componentsai components.
layer average .
layer flatten .
ai components x layer x .
ausermayaskqueriessuchas ai components flatten .
which is simplyanswered by true or ai components x .
where xis a variable which produces the following results.
x average x flatten.
a rulecan generallybe seen asa predicatethat hasarguments in the header and describes the relation between these arguments withaconjunctionofclausesinthebodyoftherule.arguments can be atoms lowercase or variables uppercase .
prolog supports a number of data types and has built in features for various mathematical operations.
moreover it includes functions for list and string processing and higher order programming notations .
prolog is a well suited specification language for our purpose formultiplereasons.first itis largelyintuitiveandconvenientto use i.e.
byspecifyingrulesandfacts andhasareasonablylarge user base which is extremely important as we intend to invite the open source community to collaboratively maintain the semantics.
second itsupportsvariouslistoperationsandmathematicalexpressions whichishelpfulforcapturingthesemanticsofailibraries that involve mathematical operations on multidimensional data.
third prologsupportsautomatedreasoning throughanunderlyingrewritingandsearchsystem whichisessentialforourpurpose.
lastly prolog is a well studied declarative programming language whichisfundamentallydifferentfromtheimperativeprogramming that isused toimplement ai frameworks.this makes itunlikely that our semantics will have the same bugs in the implementation.
.
specifying the semantics inthiswork wefocusondevelopingasemanticsforthetensorflow framework since it is the most popular ai framework.
tensorflow authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
exais executable ai semantics icse may pittsburgh pa usa line countfrequency figure1 histogramofthefrequenciesoflinenumbersused to specify the layers in prolog.
isacomplexframeworkthatprovidesvarioustools implementations and features for the development of ai systems.
we systematicallygothrougheverycomponentinthetensorflowframework andidentifyallthecomponentswhicharerelevanttoaimodels themselves rather than components for the training process .
our goal is to implement a comprehensive semantics for one of its core components i.e.
thelayers .wespecifythesemanticsofnearly alllayersexceptafewlayersforpracticalreasons.adetaileddiscus sion of the omitted layers is in sect.
.
in total we specify the layerfunctionalitythatisrequiredtoperformapredictionof72layersof different types we did not implement any tensorflow algorithmsthat areconcerned with the trainingof models ordata processing.
afulllistoftheselayersisavailableinourrepository .foreach layer we systematically go through the documentation and run tests to understand the semantics.
unfortunately the semantics of quite a numberof layers are under specified and we have to seek further help from online forums and or the authors.
in multiple cases we identify under specified or mis specified behaviours like wrong handling of unexpected layer arguments or missing restrictions for layer inputs more details are in sect.
.
this suggests thatformalisingthesemanticsaloneisalreadyuseful andcanhelp to improve ai frameworks.
thesemanticsofeachlayerisspecifiedusingoneormorerulesin prolog.figure1showsahistogramofthefrequenciesofthenumber oflines orrules requiredforthelayers.itcanbeseenthatmany layers only require less than lines.
the reason is that they reuse predicatesofotherlayers orbuilt inrules.amajorfractionoflayersrequiresnomorethan40lines andtheremaininglayershavenearly all less than lines.
one outlier the dot layer has lines sincethe implementation supports various axis combinations for the dot product.intotal thesemanticsconsistsofabout3200linesofprolog code and on average lines per layer when shared predicatesare considered .
the implementation of nearly all layers has anone to one correspondence with the deterministic functionalityof the tensorflow layers.
this allows us to given an ai model straightforwardlyinvoketherelevantrulesinoursemanticsand apply them to generate constraints on the model output.
weremarkthatsincetheseprologrulesarespecifiedbyhumans theyarepotentiallybuggyaswell.standardpracticesareappliedto ensure the correctness of the semantics itself such as code review manualtesting e.g.
usingdocumentationexamples andautomated testing e.g.
using our own fuzzing engine .
while we cannot becompletely sure that the semantics is correct we have reason tobelieve that it is reasonably so.
in general one can always argue1 dense layer iws bs depth dense node comp i iws bs o dense layer is iws bs os .
dense layer iws bs depth d d dense layer i iws bs o dense layer is iws bs os .
dense layer .
dense node comp res0 res multiply list with iw i res1 add lists res0 res1 res2 dense node comp is iws res2 res .
dense node comp res res .
listing prolog semantics of the dense layer.
that correctness is an illusion and all there is is consistency e.g.
between manually programmed tensorflow and manually writtenprologsemantics .thatis aslongasthesamebugisnotpresentin boththeimplementationandthesemantics inconsistencywould ariseandeithertensorfloworoursemanticswillbefixed.inthe following we illustrate our semantics with multiple examples.
dense layer.
listing shows our prolog semantics of a dense layer .itisastandarddenselyconnectedlayer whichcontainsa number of nodes and each is connected with all inputs.
the output iscomputedbytheweightedsumofallinputsateachnodewith anaddedbiasvalue.ourspecificationworksasfollows.therule startinginline1 hasmultipleparameters alist aweight arrayiws andabiasarray bs whichcanbeintuitivelyregarded as inputs and a list os which can be regarded as the output .
the list notation enables accessto the firstelement iand the remaining elements isof a list.
line constrains the depth of the nestedinputtotwo.wehandlehigherdimensionalinputseparately.
line applies a predicate that is true when ocan be unified as the expected output for an input i and line is a recursive constraint which intuitively continues with the next inputs.
the rule in lines is similar except that it handles layer inputs with a higher dimension which is checked in line andrecursivelyuses ourinitialpredicatefromline1since thedense layeronlyperformscomputationsintheinnermostlistevenwhenitreceiveshighdimensionalinputdata.line11 andline18 arethe base cases for the recursion i.e.
when only an empty list remains.
thepredicateinline13encodesthemainlayerfunctionalityand becomes true when the resvariable is the expected output for the input .ithasthesameargumentsasourfirstruleandanadditional temporary variable res0for the result.
it consists of clauses for multiplying the weight arrays iwwith each input iand for addingtheresultsinline16.thepredicates multiply list with andadd lists are straightforward and are therefore omitted.
with this prolog semantics we can now answer a variety of queries e.g.
to compute the expected output of a dense layer.
the followinglistingshowssomeexamples.thefirstisabasicquery with two inputs and two nodes and the second has three nodes and more complex input.
it can be seen that even such a small and simple specification can handle high dimensional input with just a few lines of code.
the third query fails due to invalid arguments authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
icse may pittsburgh pa usa richard schumi and jun sun since the number of nodes must be equivalent to the size of the bias array and also to the second dimension of the weight array.
manylayershavenon trivialpreconditionslikethat.thismakesthe generation of test data difficult.
in section we will illustrate how wecanidentifysuchinvalidinputsandproduceusefulinformation about the source and severity of such issues to support our model validation and test generation approaches.
dense layer x .
x dense layer x .
x dense layer x .
false.
conv1dlayer.
aconvolutionlayer shiftsakernel orpool over the input space and produces the weighted sum of the ele ments within the kernel.
it can for instance be used for imagepreprocessing or recognition.
listing illustrates the simplified forthesakeofpresentation semanticsofthislayer.line1showsa predicate for the layer which has the layer input data is a numberkernelsize for theone dimensional sizeof the window that shouldbeshifted aweightarray iwsforthekernelelements abias arraybsofvaluesthatareaddedtotheoutput astepsize strides a boolean padding for optionally enlarging the input data e.g.
by surroundingitwithzeros andtheoutputdata os asparameters.
lines apply predicates for checking the validity of the layer inputs and arguments i.e.
to ensure that the input dimensions are asrequired tocheckthatthekernelisnottoolargefortheinput andtoverifythattheweightsarevalid.anexampleimplementationofsuchapreconditionisgiveninsect.
.
.line5appliesthe pool1dpredicate whichisagenericpredicatefordifferenttypes of poolingor convolutionaloperations and itbecomes truewhen oscan be unified with the result of the operation.
line shows the pool1dpredicate which has the same arguments as the conv1d layer with an additional poolfunc metapredicate to decide what should happen within the pool and an argument multilayerpool to specify if the pool should be shifted overthesecondaxisoftheinputspace.next thereisacalltoasubpredicate for one sample of the input in line with initialisations ofcoordinatesandatemporaryoutputvariable line9iteratesover the other samples and line is a simple stopping clause.
in lines we apply padding with the calc padding predicate that is true when leftp andrightpare padding sizes to maintain the input shape after pooling and by using these vari ables for the padding1d predicate that succeeds when is1isis withpadding.thepredicateinlines19 24doestheactualapplication of the convolution.
line utilises the pool predicate i.e.
the weighted sum of the kernel for a given position x y which is then appended to the output in line .
next line has a con ditional clause that introduces new variables x1 y1for the next coordinates given the current pool position and finally line performs recursion to continue with the next coordinates.
lines are defined similarly except that the pool is also shifted over the second axis by iterating over the ycoordinate1 conv1d layer is kernelsize iws bs strides padding os 2check dimensions is 3check valid kernel is kernelsize padding 4check valid weight shapes is kernelsize iws bs pool1d sum is kernelsize strides padding iws bs false os .
pool1d poolfunc poolsize strides padding iws bs multilayerpool pool1d poolfunc i poolsize strides padding iws bs multilayerpool o pool1d poolfunc is poolsize strides padding iws bs multilayerpool os .
pool1d .
pool1d poolfunc is poolsize strides true iws bs multilayerpool os atomic i length is l calc padding l poolsize strides leftp rightp padding1d is x leftp rightp is1 pool1d poolfunc is1 poolsize strides false iws bs multilayerpool os .
pool1d poolfunc is x poolsize strides false iws bs false os0 os atomic i length is lx get pool res1d poolfunc is x y poolsize strides iws bs false o insert pool field os0 o true x y strides os1 x strides poolsize lx x1 is x strides x1 is lx pool1d poolfunc is x1 poolsize strides false iws bs false os1 os .
pool1d poolfunc is x y poolsize strides padding iws bs true os0 os atomic i length is lx get pool res1d poolfunc is x y poolsize strides iws bs true o insert pool field os0 o true x y strides os1 x strides poolsize lx x1 is x str ides y1 is y x1 is y1 is y pool1d poolfunc is x1 y1 poolsize strides padding iws bs true os1 os .
pool1d is x y false os os atomic i length is lx x lx length ly y ly .
listing simplified prolog specification of a pooling layer.
insteadofjustusingthesumoverthesevalues.finally lines33 show a stopping clause which becomes true when one of the indexesx yis outside the input space.
similarly with the above semantics we can now query this layer as shown in the following examples.
the first example has integerandthesecondhasfloating pointinputs.itcanbeseenthat variables are not limited to a specific type our implementations works for integers as well as floating point numbers.
conv1d layer false x .
x conv1d layer .
.
false x .
x an interesting aspect of this layer is that a lot of the functionality canbereusedforotherlayers.inparticular the pool1dpredicateis authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
exais executable ai semantics icse may pittsburgh pa usa dropout layer is os rate acceptedratediff 2count atoms is n count atoms os no no n 3count occurrenc es is nzeroorig 4count occurrenc es os nzeronew 5realrate is nzeronew nzeroorig n nzeroorig 6diff is abs rate realrate diff acc eptedratediff write expected rate writeln rate write actual rate writeln realrate false true .
listing prolog specification of the dropout layer.
defined generic so that it can be applied for the semantics of many related layers.
for example it is applied for simple pooling layers like global average or max pooling and for other convolutional layers like separable convolution and locally connected layers.
non deterministiclayers.
althoughmostlayershavedeterministic behaviour when their weights are known there are a few exceptionsincluding layerssuch asdropout alphadropout spatialdropout gaussiandropout and gaussiannoise.
all of them either have built in non determinism i.e.
random behaviour or areprobabilisticinnature i.e.
producingoutputsthatfollowsacer tainprobabilitydistribution .wedefinedprologrulesthatconstrain these layers to satisfy high level properties which are documented in the respective documentation e.g.
if the layer is expected toproduceresultsthatareaccording toa specific distribution they should.
we demonstrate how this is done for the dropout layer .
thislayerisexpectedtosetvaluesoftheinputtozeroaccordingto agivenrate.
additionally thelayeralsoaddsnoisetothedata but we neglect this feature in the example for brevity.
listing shows a predicate that checks if the dropout actually occurs at a given rate.theargumentsaretheinputs is theoutputsfromtensorflow os the rate and a threshold acceptedratediff for the maximum difference to the observed rate.
line shows predicates which are true when nandnocan be unified with the number of input and outputvalues whichmustbeequal.line3doesthesameforthe number of zeros in the input and line for the number of zeros inthegivenoutput.next line5sets realrate totheobservedrateof dropouts while considering the already existing zeros in the input andline6applies the absfunctiontoobtainthedifferencetothe expected rate.
finally line checks if the difference is bigger than our threshold and writes a message if that is the case.
applications of the semantics thesemanticshasmanyapplications.inthissection wedemonstratetwoofthem.weillustratetheoveralldesignofourtesting and model validation approaches and show step by step examples.
.
ai framework testing recently multipleresearchersstarted working onai frameworktesting .
while an impressive number of bugs have been identified there are still many open challenges.
based on our executable semantics we introduce a novel ai frameworktestingmethodwhichimprovestheexistingapproachesby addressing the following problems.
the oracle problem i.e.
how we verify if the output is correct .
the test generation problem i.e.
how can we effectively generate valid test cases .
forthe first problem the existing approaches focus on differential testing orasimpleformofmetamorphictesting .
for differential testing multiple libraries or implementations are comparedagainsteachother andbugsareidentifiedwhenaninconsistency is found.
the kind of metamorphic testing done on ai frameworks introduces changes in the test input i.e.
an ai model that should not affect the output.
a different output would thus indicate a bug.
in other words such testing relies on the algebraic propertythat deadcode doesnotchangethemodel sbehaviour.
differential testing is powerful since a second implementation can serve asa good test oracle.however a secondindependent implementation is not always available especially for new algorithms.
evenifitisavailable itisstillpossiblethatitsuffersfromthesame bugsduetoreasonssuchasusingthesameunderlyinglibraryor implementingcertainoptimisationinthesame wrong way.our methodcanalsobeseenasaformofdifferentialtesting butitis unlikelythatoursemanticswill suffersfrom thesamebugssinceit is developed in a different modelling paradigm at a high level e.g.
where little performance optimisation is involved .
on the other hand metamorphic testing is usually limited to specific types ofbugs based on algebraic properties i.e.
a very small piece of thesemantics which are used to guide the test generation.
anotherissue that limits the applicability of both approaches is the non deterministic behaviour of the layers e.g.
inconsistency may bedue to non deterministic or probabilistic behaviours rather thanbugs.usually thetrainingofaimodelscontainsrandomfactorsthat cause small discrepancies in different implementations and makeanexactcomparisonandtheidentificationofbugsdifficult.
thisissueissometimesresolvedbyrelyingonapproximatingoracles that accept a range of inputs.
this is not an ideal solutionsinceitoftenrequiresmanualadjustments .basedonoursemantics we have an alternative more powerful solution for thisproblem.
by developing our semantics with a focus on the highlevelbehaviourofthelayers wecantesttheresultsofanaimodel independentlyofthenon deterministictrainingalgorithms.this facilities the detection of subtle bugs without the interference of underlying non deterministicor probabilistic behaviours.
the second problem i.e.
the test case generation problem is oftenaddressedbyusingexistingbenchmarkexamplesorbymodifying these examples e.g.
via mutation .
the problem of the formeristhatexistingexamplesarelimitedinbothnumbersandva riety.
the problem of the latter is that test cases generated through mutation are often invalid e.g.
due to non trivial preconditions thatmustbesatisfiedbythelayers.mostailibrariescontaindozensofdifferentlayersthatcanbeconnectedinsequencesorincomplex graphstructurestoformdeeplearningmodels.therearesimple layers like a densely connected layer and also highly complicated layers which apply operations on multidimensional inputs or even combinethefunctionalityofotherlayers.usually theyneedanumber of configuration arguments e.g.
for specifying the number ofneuronsorafiltersize.mostlayershavepreconditionsforthe inputsandhencetheycannotbefreelycombined.toaddressthis problem a recent approach proposes to extract information about theinput requirements from thelibrary documentation and togenerate valid testcasesaccordingly.however afterallitseffort it still has very limited capability in producing valid test data i.e.
the success rate is around .
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
icse may pittsburgh pa usa richard schumi and jun sun test case generationprolog specificationai library test casesexecution with ai libexecution with specification test outputstest outputsoutput comparison pass fail verdictinput output artefact process figure2 overviewofthedataflowofourtestingapproach.
inthiswork wedevelopafuzzingmethodwhichutilisesfeedbackfrom oursemanticstoenable asystematicwayof producing validtestcases i.e.
byfindinglayers andassociatedarguments that are compatible with each other.
moreover our approach exploresvariouslayerargumentsinordertofindinterestingcombinationsthatmight reveal bugs.
the overallw orkflowisdepictedin fig.
.
next we will explain the involved tasks and components.
ourmethodhastwomaincomponents.first themostimportant component is the oracle which is our executable prolog semantics.
given a deep learning model in the form of collection of layers and their arguments and the input data the oracle executes the semantics to produce a prediction in a similar fashion as it is done byanailibrary.second thetestcasegeneratorisatoolthatproduces test data in the form of multidimensional arrays anda deep learningmodelasacollectionoflayersandtheirrespectivearguments.
our test case generator is based on fuzzing techniques and produces random inputdata and models.
thefocus of the generationistoproducecomplexmodelswithgraphstructuresinordertoextensivelytestcombinationsofdifferentlayersinvarioussettings.
inthefollowing weusethesimplifiedsemanticsoftheconvolution layer that we showed in the last section to demonstrate the test generation.
the test case generator produces test input dataas well as a deep learning model including layer arguments toreveal bugs or inconsistencies in the ai library.
the model andthe input data for performing a prediction together form a test case.
a test case is automatically generated in the form of a prolog query which is given to the prolog interpreter to compute a result withaunificationalgorithm.forexample asimplequeryforour convolutional layer is as follows.
conv1d layer false x .
the same test case for tensorflow is expressed as a simple python program as shown in listing .
the first lines are imports and configurations.
lines define the actual deep learning model.
in lines we overwrite the weights for the kernel and the biases in1 import tensorflow as tf numpy as np fromtensorflow.keras import layers m odels 3model tf.keras.sequential layers.conv1d strides input shape 5w model.get weights 6w np.array 7w np.array 8model.set weights w 9x tf.constant print np.array2string model.predict x steps listing tensorflow example of a conv1d layer.
order to support a deterministic prediction.
usually these weights areinitialisedrandomlyandtunedthroughtraining.line9setsthe input data and line performs a prediction with the model for the input data which gives us the test output.
finally wecomparetheoutputofthetestprogram thatincludes theailibrary totheoutputofthesemantics.atestfailsiftheconstraints produced by the semantics are not satisfied by the output from the python program.
in general such a failure can be caused bybugsinthelibraryandpossiblybybugsinthesemantics.for ourexample theoutputwas inbothcases which represents a successful test.
a bug is identified when there is an inconsistency in the outputs prediction results of the tensorflow programandofoursemantics.ifthereisaninconsistency welocalisethebugbycheckingwhichlayerspecificationisviolated and by manually checking the cause.
.
test case generation the test case generator is a tool that can produce models in the form of python scripts that use tensorflow as well as models represented as prolog queries.
it also generates random test inputs intheformofmultidimensionalarraysthatneedtohaveaspecific shape or number of dimensions depending on the first layer fora prediction with a model and layer arguments which can alsobe the weights of layers.
the generation is done by the test casegenerator alongside the ai model generation while considering input requirements.
the details about the required arguments can be found in the tensorflow documentation.
a test case is a model together with the associated test inputs.
the main functionality of the test generator is the generation of diversefunctionalmodels.
pseudocodeofthegenerationprocess is illustrated in algorithm .
it consists of two major functions forrandomlybuildingamodelandforfindingavalidmodel.the first is a recursive function line that starts by selecting aninitial root layer and continues to connect random layers ontoit.
the algorithm increases the probability of stopping based onthe levelthat represents the distance of the current layer to the root layer line to prevent too large models.
many layers cantake the output of one layer as input and some can have inputs from multiple layers e.g.
to perform mathematical operations like addition or multiplication of the inputs.
hence there is a variable forthenumberofinputs whichissetaccordingtothegenerated layer lines5 .finally therecursionisperformedforeachinput aconnectionisformedwiththeassociatedfunctions byfeedingtheoutputofalayerasinputtoanotherlayer andthelayerisreturned.
the model in this case is just the root layer that is connected to other layers.
note that the models produced by this function are authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
exais executable ai semantics icse may pittsburgh pa usa algorithm pseudo code of the test model generation.
input genhelper helper class containing a map of layer generators layer.name generator semantichelper helper class for the execution of the semantics function recursivegeneration level rand iflevel rand.nextbool then allow deeper graph based on the random result returnnull end of the recursion layer genhelper .generatelayer generates a random layer incl.
arguments inputnumber iflayer.hasmultipleinputs then check if layer requires multiple inputs inputnumber rand.nextinteger fori 1toinputnumber do layer1 recursivegeneration level rand layer1.setparent layer layer.addchild layer1 connect layer returnlayer function findvalidmodel layer maxtries rand findvalidmodelgiventherandommodel fori 1tomaxtries do success error semantichelper .run layer run the semantics get success error ifsuccess then returnlayer else iferror.getlocation lasterror.getlocation error.getbadness lasterror.getbadness then layer lastlayer error lasterror restore model if no improvement else lastlayer layer lasterror error layer1 error.getlocation ifrand.nextbool then layer1.regenerateargs reset the layer arguments else if rand.nextbool then options layer2 genhelper .generatelayer options generate one of the options layer1.insertlayerbeforechild layer2 insert layer before input else if rand.nextbool then layer2 genhelper .generatelayer layer1.replacewith layer2 replace current layer with another layer else if rand.nextbool then layer2 genhelper .generatelayer layer1.replacechildwith layer2 replace input layer with another layer returnnull most likely invalid and for simplicity it produces models in the form of trees.
the semantics also supports more complex graphs.
thesecondfunctiontakesthis model asabasistofindavalid model with the help of the semantics line .
our semantics can identify invalid models based on layer preconditions which are defined as part of the corresponding prolog rules.
these precon ditionsgivefeedbackin theformofabadnessvalueto guidethe generationprocesstowardsvalidmodels.givenaconcretemodel andapreconditiontobesatisfied thebadnessvalueisdefinedin the same wayas fitness in search based software testing .
it is a distance metric that increases when the model is further away frombecomingvalid i.e.
werankthepreconditionsbasedonseverityandcalculateavaluebymultiplyingaseverityfactorwiththe difference of e.g.
an expected argument value to an observed one.
line14showsthatweapplya semantichelper torunoursemantics and to retrieve a success or an error message.
if the semantics was executed successful then the model is valid and the algorithm stops line .
if an error occurs during the execution we check ifitoriginatesfromthesamelayerasapreviouserror andifitismoreseverethanthelasterror basedonthebadnessvalue whichwould indicatethatthelastmodelchangedidnotimprovethemodel.in this case we restore the last model line .
otherwise we try to adoptthe modelto graduallyimprove itsvalidity lines21 .
this is done by randomly selecting a potential model modification forthelayerthatcausesinvalidity likeregeneratingarguments in sertingalayertochangetheinputshapes dimensions orreplacingthe layer with one of its input layers.
this process is repeated until a valid model is found or a maximum number of tries is reached.
an example graph model that was generated with our approach is illustrated in fig.
.
the nodes in the model represent layers and figure model visualisation in graph form.
thearrowsshowthedataflow.itcanbeseenthatthemodelincludes various layers like convolutional or reshape and the output of themodelisderivedfromtherootlayer i.e.thataveragelayerat thebottom.thecorresponding tensorflowandprologmodelare available online in our repository .
.
model validation another application of our semantics is the model validation by identifying bugs in faulty or invalid ai models.
it can be challenging to create working models especially since the layers have numerous preconditions that need to be fulfilled when they areusedorcombined.forexample commonerrorsarewronginput shapes and dimensions or arguments that are invalid for the input data like a convolution kernel or an axis value that is too large for an input dimensions .
ai libraries like tensorflow already produce error message to detect such issues.
however they can be difficult to understand the messages are not always consistent for the same type of issue and in rare cases there is no error for aproblematicmodel seetheexamplebelow .hence weprovide an alternative way to validate models by identifying and reporting issues precisely and consistently with the help of our semantics.
by converting an existing tensorflow model into our prolog representation we can exploit our semantics to check if there are any precondition violations in the model which would make it invalid.
an example precondition is shown in listing .
it checks if a croppinglayerappliestoomuchcropping whichwouldresultin anemptyoutput.thereisapredicate check empty cropping that hasthelayerinputandoutputasargumentsanditistruewhenthe output is not empty.
otherwise an exception is thrown.
first in lines1 2thereisarecursiverulefortheinspectionofmultidimensionaloutput.next theruleinline3makesourpredicatetrue if anynumericalvalueisfoundintheoutput.ifthatisnotthecase then we generate an error message lines .
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
icse may pittsburgh pa usa richard schumi and jun sun 1check empty cropping is 2check empty cropping is o .
3check empty cropping o number o .
4check empty cropping is 5writeln invalid model s1 cropping error input shape 6shape is shape term string shape t string concat s1 t s 7throw s .
listing prolog code of a layer precondition.
import tensorflow as tf numpy as np fromtensorflow.keras import layers m odels 4in0 tf.keras.layers.input shape 5in1 tf.keras.layers.input shape 6max layers.maxpool1d pool size name max in0 7con layers.conv1d padding valid name con in1 8cro layers.cropping1d cropping name cro con 9con1 layers.c oncatenate axis name con1 11model models.model inputs outputs con1 13w model.get layer con .get weights 14w np.array 15w np.array 16model.get layer con .set weights w 17in0 tf.constant 18in1 tf.constant print np.array2string model.predict steps listing simple example model bug in a tensorflow.
an example tensorflow model that contains a corresponding cropping issue is shown in listing .
it can be seen that our model consists of four layers a convolutional layer that is connected with a cropping layer a maximum pool layer and a concatenate layer that takes the outputs of the cropping and pool layers.
the same model in prolog is shown in listing .
this model has a slightly different structure as our previous model queries.
first we assign the layers to variables which we then pass in a list to the exec layers function.
thisfunction is asimple wrapperfor the execution of a list of layers that helps to identify the name of a layer that violates a precondition.
themodelmightseemvalidatafirstglance butinvestigating the cropping arguments shows that the values are too big.
thiscauses an empty intermediate output in the cropping layer.
expectedly oursemanticsisabletoidentifythisissueandproduces anerror.tensorflowhasnoerrormessage .themodelisjust executed and the concatenation is performed with the empty output which meansthatthefirst branchofthe modeliscompletely ignored.
especially in large models it can be challenging to findsuchissuessinceonlyintermediateresultsrevealsuchproblems.
the tensorflow developers confirmed that this should not happen and that an additional check will be added .
our semantics are not only important for the test generation but they also enable a reliable way to identify issues in ai models.
error messages in ai libraries are not always consistent becauseof multiple or device specific implementations of a layer.
our preconditionsareeasytodefine andcanspeed uptheidentification of issues by highlighting problematic layers and by presenting consistent messages that could e.g.
support automatic error handling.
in future work we aim to provide a more user friendly tool with a graphical user interface in order to facilitate the usage of both our1a max pool1d layer false max 2b conv1d layer .
.
false con 3c cropping1d layer con cro 4d concatenate layer con1 exec layers con1 con1 listing simple example model bug in a prolog.
testcasegenerationandmodelvalidationapproachesinapracticalsetting e.g toproducetestmodelsforvariouspurposesandtofind issues with existing models.
evaluation we implemented our semantics for almost all tensorflow layers anddevelopedtwoexampleapplications i.e.
aiframeworktesting and model validation to find invalid ai models.
in this section we evaluate the effectiveness of the approaches.
we design multiple experiments to answer the following research questions rq .
rq1 is prolog expressive and efficient enough for ai semantics analysis?
therearevariousspecificationlanguagesthatmight besuitedfordevelopingasemanticsofanaiframework.hence we want to highlight the advantages of using prolog.
rq2 doesthesemanticsallowustoeffectivelygeneratevalidai test cases?
this is important since one of the applications of our semanticsisaiframeworktestingandforthatitisnecessaryto produce good test models.
rq3 isourtestgenerationmethodbasedonthesemanticseffective for finding ai framework bugs?
to further motivate the usage of our testing method we show what bugs and issues it can reveal.
rq4 howwellcanoursemanticsreportbugsofinvalidaimodels?
another application of our semantics is the model validation.
we will show the advantages of our method compared with the default bug reporting capabilities of tensorflow.
the experiments were performed on a 7th gen. lenovo x1 carbon thinkpad with a 8th gen i7 cpu with four .
ghz cores and 16gbram.we mainlytestedtensorflow2.
butalsodiscovered issues in version .
.
for executing the prolog semantics we used swi prolog .
.
and the test generator was built in java .
.
.
below are our answers to the research questions.
rq1 isprologexpressiveandefficientenoughforaisemanticsanalysis?inordertoanswerthisquestion wereportourfindingson developingourprologsemantics.fromthetensorflowdocumentation we identified unique non abstract and non wrapper layersthatwewantedtoimplement.forpracticalreasons wecouldnotsupportalllayers butwewereabletodevelopourspecificationfor72layersofvarioustypes likemathematical normalisation convolutional recurrent pooling dense activation cropping padding dropout andmostoftheselayerssupportnearlyallarguments.we implemented the core functionality of these layers to be able to perform predictions.
our specification is not concerned with learning trainingalgorithms datapreprocessingandmodel accuracy evaluations or optimisations.
a full list of the layers is availableonline .
we did not develop a specification for the remaining layers activityregularization additiveattention attention densefeatures lambda multiheadattention stackedrnncells authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
exais executable ai semantics icse may pittsburgh pa usa .
.
.
model size number of layers run time figure run time of the semantics for rising model sizes.
since they have too generic or flexible input requirements like a generic iterable that can contain other layers or arbitrary func tions or queries.
moreover we could not fully support all layerargumentsandfeatures e.g.
weimplementedthemaskinglayeras a stand alone layer but not the influencing behaviour that itcan have on other layers.
we had to omit some layer argumentssince they would have violated our specification requirement of staticweights i.e.
thereareinitialisers regularisers forweights kernels or biases that we did not implement since we statically set these attributes.
moreover we did not implement activation or dropout features within the layers since the same behaviour can be achieved by adding an independent activation or dropout layer.
we left out some arguments like constraints data formats or a trainableoption duetotheircomplexityorbecausetheyhavean influenceoutsidethescopeofoursemanticswhichisnotconcerned with the training of ai models.
some layers like gru have an optiontochooseaspecificimplementationofthelayer.forsimplicity weimplementedthedefaultimplementations.itshouldbenoted that only seven layers had detailed mathematical descriptions inthedocumentation 44wereexplainedwithexamplesorhada reference paper and the remaining layers were under specified orhadjustverylimitedexamples.fromour72implementedlayers seven had non deterministic properties hence instead of exactlyspecifying their behaviour we defined prolog rules that check if theyfollowthedescribedpropertiesfromthedocumentationsas explained in sect.
.
for the remaining layers we directly specifiedthefunctionality whichenablesaneasyexecutionandanexact comparison of the prediction results from our semantics to tensorflow.
the implementation effort of the semantics was about eight work months which partially also includes the time to acquire the relevant domain knowledge.
we evaluated the execution time of our semantics in order to illustrate the applicability for non trivial use cases.
figure shows the achievedrun timesfor increasingmodel sizes.we createdthe modelsbyadoptingthelevelvariableofthetestgenerationfrom algorithm1 bysettingtheinputdatasizeto4kb andbytakingthe averageovertenmodelsforeachdatapoint.itcanbeseen thatfor small modelswith aboutten layersand non trivialinputs therun time of the semantics is only about .6s and even for models with about50layers apredictioncanbedoneinlessthan3s.hence we believe our semantics is fast enough for reasonable models.
a major advantage of using prolog is its declarative and highlevelspecificationstyle whichenablesacompactandstraightforward implementation.
we only needed about lines of code for all layers and on average lines per layer because prolog has alreadyalotofbuilt infunctionality likelistoperations anditalso facilitates the reuse of code.
in contrast tensorflow has a hugetable found tensorflow issues and bugs.
issue typefixed or confirmedpending or unconfirmedtotal tensorflow bugs error message bugs documentation bugs total code base with about three million lines of code.
hence we believe our specification provides a good opportunity to ai developers to learn more about the inner workings of layers and that prolog is a well suited specification language since it supports a compact and convenient implementationof most layers.
rq2 doesthesemanticsallowustoeffectivelygeneratevalidaitest cases?in order to evaluate the effectiveness of our test generation approach weusedourtestgeneratortoproduce10 000testmodels.
the run time of the generation was about hours on average .6spermodel ofwhichmosttimewasspentongraduallyfinding a valid model with feedback information from the execution of the semantics.
our generated ai models had an average size of .89layers excluding input layers and we used small inputs with a range of one to four values per dimension since bigger sizes vastly increased the overall size of our highly dimensional input data.
compared to state of the art approaches for testing ai frameworks ourgeneratedmodelshavemorediversityintermsoflayers andstructure.arelatedfuzzingmethod onlytestssinglelayers anditisunclearhowmanylayersitcantestwithvalidinputs.a differential testing approach can produce valid models with mutation but they are less diverse since the mutations are only concernedwithsequentialmodelaspects andtheycanonlyadd24 types of layers to the mutants.
other related approaches have less variety since they only use existing models or adopt the input data.
outofthe10 000testcases99.
werevalid i.e.wewereableto producethesamepredictionresultwithoursemanticsastensorflowforthesamemodelandinputs.seventestcasesfailedbecause of a dependency issue of the masking layer that we could not fully support.
almost all layers work independently but the maskinglayerisanexception.itrequiresallfollowinglayerstoskipa specific input time step.
two tests failed due to rare inputs which causedinconsistencieswiththetensorflowinputargumentchecks.
wearestillinvestigatingthisissuebecauseofitsrareoccurrence.
finally one test failed due to a minor inconstancy in the handling offloating pointvalues whichonlyoccurredveryrarelywhena lot of computations with recurrent layers were performed.
the high percentage of valid ai models that we were able to achieve with our test case generation shows that our method iseffective especially considering the low percentage of the related work .
moreover we were able to reveal various issues andbugsaswewillseeintheanswertothenextresearchquestions.
rq3 isourtestgenerationmethodbasedonthesemanticseffective forfindingaiframeworkbugs?
withourgeneratedtestcases we were able to discover various issues and bugs in tensorflow.
some ofwhichwereactualfaultsintensorflow afewissueswererelated to wrong or misleading error messages and there were some documentationbugs.table1showsanoverviewofthefoundissues their type and if they were confirmed or not.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
icse may pittsburgh pa usa richard schumi and jun sun the most interesting bug that we found was related to the popular activation function or layer called relu which showed a wrong behaviour for negative thresholds that violated the descriptionofthedocumentation .webelievethatthisbugisthemost significantsince itisconcernedwith oneofthemost commonactivation functions and ai models that used this function with a negative threshold and negative values might have suffered from inaccuracy ormight have produced unexpectedprediction results.
another bug was regarding the convlstm2d layer which produced potentially wrong prediction results in rare cases and one was an ignored argument .
anissuewasregardinganerrormessagethatsuggestedthatanothernumberformatisrequired butwhentheformatwaschanged thenthemessagestatedtheoriginalformatwasneeded .there were various similar error message related issues .
a documentation bug was about a missing preconditions description that caused an error when certain arguments were notequal in a separableconv layer .
a number of similar issues were also related to documentation inconsistencies.
in total we found issues that we reported to the tensorflow developersandthathelpedtoimprovetheframework.tenissues wereconfirmedorarealreadyfixed fourareunconfirmedorstill pending.
note that our method focuses on semantic bugs like the relubug thatarehardertofind.relatedworkcannotdirectly becomparedduetosimplertypesoforacles whichwewillexplain in sect.
.
hence we believe itis reasonableeffective andthe fact thatwefoundamajorbuginoneofthemostcommonactivation layers highlights the need for a good executable semantics.
rq4 howwellcanoursemanticsreportbugsofinvalidaimodels?
in order to evaluate the bug finding or localisation capabilitiesof our semantics we generated invalid models by running our test case generation method that gradually finds valid models.
retrieving the last model of this process allowed us to have invalidmodels that only contain a single bug which facilitates the manual analysis of the issues.
we evaluated the type of issues that madethe models invalid and compared the bug finding and reporting capabilities of our semantics to tensorflow.
table2showsanoverviewofthetypesandfrequenciesofissues and the number of tensorflow inconsistencies that we found.
the majority ofthemodelswereinvalidduetodimensionerrors caused by layers requiring input data with a maximum minimum orspecificdimension orwhenalayerhasmultipleinputsandtheir dimensions are not matching.
the next large portion models wereinvalidduetoinconsistentinputdatathatoccurswhenalayer takesmultipleinputsandthereisarequirementthattheinputsneed tobethesameshapeorthesizeofsomedimensionsmustmatch.
the remaining models were invalid due to argument errors like apool orkernelsize thatistoo large or inconsistenciesinweight or biases shapes.
most convolutional layers require weight arrays tohaveaspecificshapethatcandependontheinputsize.hence a modelcan e.g.
becomeinvalidwhentheshapeoftheweightsis inconsistent with the input shape.
many error messages from tensorflow were inconsistent as indicated in the last column of table .
even for simple cases like a wrong input dimension there are different messages valueerror input of layer x is incompatible with the layer expected ndim table overview of the identified model validation issues.
model issue occurrencestensorflow inconsistencies dimension error inconsistent input shapes argument error found ndim .
or valueerror shape must be rank but is rank forx.
or valueerror inputsshouldhaverank4.receivedinput shape ... .
the reason for these differences might be that the error messagesare produced independentlyin differentlayers.
in contrast wecaneasilyreuseapreconditionthatproducesthesame message in all layers.
this facilitates automatic error processing.
there were cases in which tensorflow did not produce an error althoughthereshouldbeone.forexample whencroppinglayers are used with a too large cropping values then tensorflow will justproduceanemptyoutput moredetailsareinsect.
.
.a similar issue was regarding the input shape verification that did not occur with specific prediction methods .
sameastensorflow oursemanticswasabletoidentifythelayers that were causing an invalid model in all cases.
in four cases there were discrepancies regarding the type of error.
the reason for that issimple.someissuescanhavemultiplecauses e.g.
whenaweight shape is inconsistent with an input then either of them may be wrong.generally ourproducedmessagesaresimpler consistent andatahighlevel.tobefair tensorflow serrormessagescould beattimesmoredetailed forbetterdebugging butourfocusisonautomaticerrorhandling.notethatthereseemstobenootherwork investigatingtensorflow serrormessagesforaimodels.finally withourapproachitismucheasiertoaddpreconditionsforspecial usecasesortypesoflayerssincethecodeismuchmorecompact which makes it easy to find the right place to add a precondition.
discussion.
athreattothevalidityofourevaluationmightbe that there are limited ways that we can compare with existing works.
this might have been interesting.
however there were not manyrelatedapproachesthatcouldbeusedforafaircomparison since the closest related work for generating ai models worked with a much weaker oracle and only focused on simpler bugs.
one might argue that our ai framework semantics is limited sinceitismostlyconcernedwiththebehaviouroflayers.aiframeworks have other important components e.g.
it would be interesting to specify the learning algorithms.
however in this work wefocusedonthestaticbehaviouroflayerssincewebelieveitis a good start for more general ai framework semantics and our specificationisvaluablesinceitcanperformpredictionsforvariouscomplexaimodels.moreover weillustratedhownon deterministic properties can be evaluated with prolog.
anotherpotentialthreattothevalidityofourevaluationcouldbe thatthe testinputs weused togenerate aimodelswere toosmall for a realistic study.
ai models can handle huge data like largeimages or videos.
hence it is true that an evaluation with larger test inputs might be more realistic but bugs in the ai frameworks as well as in ai models could be independent of the input size.
we believe that our test models with rather small inputs were still reasonable and did not represent a big limitation.
moreover it is well known that small test cases can reveal various bugs .
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
exais executable ai semantics icse may pittsburgh pa usa onemightarguethatourmodelvalidationapproachisnotas useful as tensorflow s bug reporting capabilities.
it is true that the produced error messages from tensorflow are more sophisticated and they might be better for debugging.
however our goal was to produce simple and consistent error messages that can be used for applications such as automatic error handling or even model repair.
moreover we wanted to provide an easy way to add new preconditionsandreportingcapabilities whichcanbehelpfulsince not all model issues were identified by tensorflow.
related work executable semantics for programming languages are related to our work because ai libraries have a similar purpose as a compiler.
for example there are various executable semantics for popular programminglanguagesthatwerebuildwiththekframework .
inthesamewayasouraiframeworkspecification suchsemanticscanbeusedasastrongtestoracleandfacilitatethetestgeneration.
arelatedapproachthatalsoworkswithaispecificationswas presented by selsam et al.
.
the authors apply an interactive proofing tool and partial synthesis of some system components to construct an ai system and to prove its correctness.
such a system can also be seen as a formal specification similar to ours since it canbeusedtodetectbugs.however inthisworktheauthorsfocus more on an alternative library implementation that is correct by design andthey only focuson a limitedai system.
moreover the authors point out that their proof relies on an idealised setting withinfinite precisionrealnumbersthatarereplacedforaconcrete execution which can be a potential source for bugs.
the closest related work to our testing approach was presented by wang et al.
.
the authors show a differential testing approach called lemon that uses mutations to produce test cases anditappliesaheuristic strategytoguidethegenerationinorder to amplify inconsistencies between different dl libraries.
theydo this to get rid of noise introduced by non determinism in dl libraries.withourapproach wecandirectlytestmanylibrarycomponentsdeterministically whichmakestheidentificationofbugs much easier.
moreover we do not have to rely on the existenceof other libraries.
our semantics can also be used to test newlydeveloped features that are only provided by a single library.
a similarapproachcalledcradlewaspresentedbyphametal.
.
cradle alsoperforms differential testing and itapplies distance metrics to detect inconsistent outputs.
it localises the source of an inconsistencybytrackingandanalysinganomaliesintheexecution graph.
similarly srisakaokul et al.
show a differential method for supervised learningsoftware and demonstrateit for k nearest neighbour and naive bayes implementations.
arelatedfuzzingmethodwasillustratedbyli .theapproach relies on extracting information from ai library documentations to find input requirements of deep learning layers which are needed to generate testdata.
in contrast toour work thismethod only has verylimitedcapabilitiestoproducevalidtests about25 andtheir oracle can only detect documentation bugs or input violations.
dwarakanath et al.
have developed new metamorphic relationsformetamorphictestingofailibraries.forexample they perform permutations rearrangements or rotations of the input datathatshouldnotchangetheoutput.then theyidentifybugsbased on unexpected changes in the output.
they evaluate theirmethod by artificially introducing bugs into image classificationsystems.
a similar metamorphic method for validation was presented by ding et al.
.
the approach works with metamorphic relationsthat e.g.
add orremove imagesorimagecategoriesto the training test or validation data.
they also work with image classifiers.anothermetamorphicmethodthatpermutatesrowsand columns shufflesandrenamesinputfeaturesinordertoevaluate the balancedness of machine learning classifiers was introducedby sharma and wehrheim .
in contrast to these approaches oursemanticswillworkwithmuchmoreaiapplications andits strong oracle supports the detection of a wider range of bugs.
related to our model validation method are some debugging approaches for ai models that offer features like visualisation or auditing to find issues.
however such approaches are usuallylimitedtospecifictypesofmodels e.g.
classifiers andtheir focus is not on introducing custom validation options.
conclusion wehaveintroducedanovelexecutablesemanticsforaiframeworks andillustratedtwoofitsapplications.oursemanticsisimplemented in prolog and it focuses on the deterministic behaviour of deep learning layers.
with prolog we could develop almost all layers of tensorflow in a convenient and compact specification style.
one major application of our semantics is the automatic generation of test ai models.
we applied a fuzzing approach that incorporatesfeedbackfromthesemanticstograduallyfindvalidmodels.
theapproachwasabletoconsistentlyproducevalidmodelsin99 of the cases which is much higher than related approaches.
moreover weevaluated theeffectivenessof thismethodfor findingai framework bugs and the results were encouraging.
we discovered variousissuesandbugsintensorflowandcouldtherebyhelpto improve this ai framework.
most notably we even found a bug in the well established relu function.
another application that we presented is the validation of deep learningmodels.oursemanticsisbuildwithvariouspreconditions that can find bugs in invalid ai models.
the evaluation showed thatwecanproduceconsistenterrormessages andwewereable to identify issues that could not be discovered by tensorflow.
webelievethatthesetwoapproacheshighlighttheusefulness and generality of our semantics which will also enable further applications.inthefuture weaimtoexploredifferenttestgeneration methods and ai model synthesis.