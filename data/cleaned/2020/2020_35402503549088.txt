shadesofself admitted technical debt an empirical study onmachine learningsoftware david obrien dept.
ofcomputerscience iowa stateuniversity ames ia usa davidob iastate.edusumonbiswas schoolofcomputerscience carnegiemellonuniversity pittsburgh pa usa sumonb cs.cmu.edusayem imtiaz dept.
ofcomputerscience iowa stateuniversity ames ia usa sayem iastate.edu rabe abdalkareem schoolofcomputerscience carletonuniversity ottawa on canada rabe.abdalkareem carleton.caemad shihab concordia university montreal qc canada emad.shihab concordia.cahridesh rajan dept.
ofcomputerscience iowa stateuniversity ames ia usa hridesh iastate.edu abstract in software development the term technical debt td is used to characterizeshort termsolutionsandworkaroundsimplemented insourcecodewhichmayincuralong termcost.technicaldebt has a variety of forms and can thus affect multiple qualities of software including but not limited to its legibility performance and structure.
in this paper we have conducted a comprehensive study on the technical debts in machine learning ml based software.
tdcanappeardifferentlyinmlsoftwarebyinfectingthedatathat mlmodelsaretrainedon thusaffectingthefunctionalbehaviorof ml systems.
the growing inclusion of ml components in modern software systems have introduced a new set of tds.
does ml software have similar tds to traditional software?
if not what are the new types of ml specific tds?
which ml pipeline stages do these debts appear?
do these debts differ in ml tools and applications and whentheyget removed?
currently we donot knowthe state ofthemltdsinthewild.toaddressthesequestions wemined 820self admittedtechnicaldebts satd fromalltherevisionsof a curated dataset consisting of popular ml repositories from github along with their introduction and removal.
by applying anopen codingschemeandfollowinguponpriorworks weprovide a comprehensive taxonomy of ml satds.
our study analyzes ml satd type organizations their frequencies within stages of ml software the differences between ml satds in applications andtools andquantifiestheremovalofmlsatds.thefindings discovered suggest implications for ml developers and researchers tocreate maintainablemlsystems.
at the time this work was completed sumon biswas was a graduate student at iowa stateuniversity esec fse november 14 18 singapore singapore copyright heldby theowner author s .
acm isbn .
softwareanditsengineering softwarecreationandmanagement computing methodologies machine learning .
keywords technicaldebt machine learning open source datascience acm reference format david obrien sumon biswas sayem imtiaz rabe abdalkareem emad shihab andhrideshrajan.
.23shadesofself admittedtechnicaldebt an empirical study on machine learning software.
in proceedings of the 30th acm joint european software engineering conference and symposium on the foundations of software engineering esec fse november 14 singapore singapore.
acm newyork ny usa 13pages.https introduction therecentuprisingandrapidintegrationofmachinelearning ml modelshasempowereddeveloperstotackleproblemspreviously infeasible such as safety criticalsystems financial fraud detection andmedicaldiagnostics .however thesuddenemergence and adoption of ml models risks the creation of hastily planned machinelearningsoftwaredeployedlong term .thus thefunctionalitiesoffuturemachinelearningsoftwaredependsuponthe maintainability ofpresent day machine learningsoftware.
throughdecadesoftraditionalsoftwarepractices theterm technical debt td was coined by ward cunningham to characterize short term solutions workarounds or unfinished implementations that exist in long term software.
td can worsen software s legibility performance andquality consequentiallycomplicatingits maintenance lifetime.
similar to fiscal debt td becomes more expensive thelongeraninstanceexists costingaheavyamountof developers time effort andknowledgetopayoff.therefore the awarenessoftdtypeshashistoricallyinformeddevelopershowto bestmanagetheirsoftwaretominimizethetdaccumulatedand prioritizetheirtd management .
ml software contains additional components not found within traditionalsoftwaredevelopment.
sculleyetal .exploredthehidden tdinmltodescribechallengesencounteredwhengoogleengineersweremaintainingmlsoftware .becausemlsoftware thiswork islicensedunderacreativecommonsattribution4.0international license.
esec fse november14 18 singapore singapore david obrien sumonbiswas sayem imtiaz rabe abdalkareem emad shihab andhrideshrajan isaccompaniedbychallengesnativetoitsowndomain itissusceptibletonewformsoftdnotencounteredbytraditionalsoftware practices.
forexample because ml software has an implicit dependence upon the quality of its training data problems in the data are reflected upon the resulting model behavior .
previous work has provided a framework to contain the contagion of td in ml software through multi level evaluations .
moreover tang et al.
further studied td in ml software through studying refactoringsandtheircorrespondingremovalstrategiesfoundin java ml software.
historically thenotionofself admittedtechnicaldebt satd describes a developer s expressed beliefs on necessary improvementstocurrentimplementationsofsoftware .satdismost commonly associatedwith source codecomments documentinga potentialchange althoughsatdhasalsobeenfoundinananalysis ofsoftwareissue trackers .
satdhasbeenusedasaproxyto studytd sincesatdcontainsnaturallanguagetocommunicate proposed changes to source code.
a large financial organization in practice discovered that their developers used satd to guide themanagementoftheirtd furtheremphasizingthevalueof examining satd.
because previous studies have used satd to indicate td patterns itmayprovideinsightsonmlspecifictd symptoms.however to the best of our knowledge no study has been conducted to understandtheml specificsatdtypesandtheircharacteristics present inthe ml software.
motivatedbythis wecreatedandfilteredadatasetconsisting of popular ml repositories written in python which have been usedinpreviousstudies .wechosepythonbecauseithas been referred to as the de facto language for ml development duetoitspopularity thenperformedalabelingprocessto create astatistically significantdataset of 856labeledinstances of satdwithintheserepositoriestoanswerthefollowingresearch questions rq1 what types of satd are found in our studied ml software?
satd can indicate the presence of td and is more human understandablebynatureofnaturallanguagecomments.arethere newtypesofsatdsthatexistinmlsoftwarethatpreviousworks haven tdiscovered?
rq2 what is the distribution of satd types in the different ml pipeline stages?
the ml pipeline splits up the ml development workflow into distinct objectives .
do different stages have unique frequencies of satd types?
does a satd appearance changeindiffering stages?
rq3 is there a difference in satd types between ml applications vs ml tools?
ml application developers and ml tool developers have differentgoals.doesthisinfluencethesatdthattheyencounter?
rq4 howmucheffortisneededtoremovesatdtypesinmlsoftware?since satd indicates problems affecting ml software s maintainability itisimportanttounderstandwhichtypesofsatd comments have historicallybeen difficult to remove.
our findings indicate that ml developers are most concerned withimprovinghowtheirsoftwaremeetstheirproject sfunctional and non functional requirements.
moreover our observations find a substantial focus on the configuration of data processing code acrossmultiplepipelinestages.additionally ourstudyfindsthattable filtering overview.
stage name remaining comments extracted changes length changes satd detector keywordsearch 787changes removedautogenerated 912changes removednon unique removals 599comments not in site packages folder 820comments mltoolscontainmoresatdinvolvingdependenciesonoutside code than ml applications.finally our observationssuggests that varioustypesofmlsatdstakevaryingdegreesofefforttoremove.
to allow replication and future research our labeled dataset of identifiedsatd inml repositories isavailable to the public1.
the rest of the paper is organized as follows.
section presents our methodology to gather and filter a dataset of source code comments aswellasourstrategytoconstructmlsatdtaxonomies.
the resultsof our fourrqs are presented in section .
we discuss the implications of our work in section .
the limitations of our studyarehighlightedinsection5.section6discussestherelated works andsection 7concludes the paper.
methodology in this study we will manually analyze source code comments found in ml systems.
this section describes the dataset utilized ourfilteringandsamplingprocesses ourclassificationscheme and our classification process.
.
dataset our study involves open source machine learning repositories presented in which has been used in a prior study examining ml bugs associationswith programminglanguages .thisdataset contains popular ml repositories including ml tools repositories supplying ml functionality such as the scikit learn2repository and ml applications repositories applying ml to a problem such asdeepfake sfaceswaprepository3.therepositoriesfoundinthe dataset have been filtered so that every software repository within has more than stars or forks must have been active in andmust bea non trivialsoftware project.although therepositoriesweregatheredin2019 wegeneratethedatausingthesource code data as of january .
the resulting dataset contains repositories spanning across topic labels on github indicating a representation of a variety of ml topics.
although the resulting datasetcontains5 224repositoriesacrossavarietyofprogramming languages this study will only analyze the which have been writteninpythonduetoitspopularityinthemlcommunity .
from the repositories present in the dataset were not present on github when our dataset was generated resulting in totalprojectsbeing analyzedinthis study.
.
identifying satdcomments this section describes the filtering process used to extract satd comments that have existed in the repositories described in the previous section.
table 1providesan overviewof the process.
73523shades of self admittedtechnical debt anempirical studyonmachinelearning software esec fse november14 18 singapore singapore weuseboa alanguagespecificallydesignedtominedata from software repositories which has demonstrated capabilities to analyze data science repositories .
boa analyzes each revision to determine when a source code comment has been introduced or removed .
127commentchangesareextractedfrom ourdatasetinthismanner.aftermanualinspectionofthedataset s contents wefoundcommentswithatextlengthofonecharacter likely do not represent satd or contains enough information to classify an satd comment.
we remove such comments leaving 024comment changes remaining.
tofilterour commentchangestoincludeonlysatdcomment changes we use both a previously trained classifier and a keyword search.
first we use the satd detector classifier created by whichwastraineduponcommentsfrom8activesoftwarerepositoriestoobtainanaveragef1 scoreof0.
.however sincesatd foundinmlsoftwaremaydifferfromsatdintraditionalsoftware wemeasuredtheperformanceofthisclassifieronasampleof1 mlsourcecodecomments where35werelabeledtobesatdby theauthors.previouswork sclassifierobtainedaprecisionof82.
and a recall of .
on this sample.
however we found that many ofthefalsenegativesfromthisexperimentcontainedakeyword discoveredtoindicateasatd todo fixme hacky etc.
.
therefore wetaketheunionofcommentsclassifiedassatdby previous work and comments which contain a keyword presented in to reach a recall of .
.
comment changes remain after filtering inthis manner.
additionally weremovecommentswhicharelikelyirrelevant tosatdasdoneinpreviouswork .therefore wemanuallyobservecommentsinourdatasetwhichappearmostoftentoidentify casessuchas commentsdescribingsoftwarelicensing comments which have been automatically generated i.e.
generated protocol buffer and comments to assist linters i.e.
noqa as cases which likelydonotcontainsatd.
912commentchangesremainafter removingsuch comments.
we thenorganizeour commentchanges toseparate comments whichhavebeenremovedornotintheirrepositorieslifetime.prior work shows that data from github has been found difficult to minecleanlydueto eventssuch as merges rebases androllbacks among others .
additionally a repository may have multiple copies of the same satd comment.
therefore we follow a similar procedureto by consideringa commentremovedif thereis a uniqueremoval of a comment after its introduction.
we find unique comments inthis manner.
following manual evaluation we identified the case where a source code comment is not native to the analyzed repository.
rather the source code comment is found in the site packages directory.becausethegoalofthisstudyistoanalyzesatdcomments in ml repositories we choose to filter out comments which appearinthisdirectory.afterthisstep wefind68 820comments remaining inour dataset.
wetook astatisticallysignificantsample ofour filtereddataset with a confidence interval of and a margin of error of .
to calculatethesizeofoursampledataset.then wesamplecomments similartoapreviousstudyonsatdcomments wherethesatd datasetissampledsothattheresultingsample scharacteristicsis proportionaltotheoriginaldataset.table 2illustratestherespective proportionsofthe dataset andits sample.table totaland sampled satd comments datasetbucket of satd comments of sampled satd comments tool comment removed tool comment not removed app.
comment removed app.
comment not removed total .
building satdclassification scheme in this section we will describe the classification schemes used to label our sampleddataset.
previousworkontdinmlapplicationsarguedthatmlsoftware can become indebted in similar ways to traditional software development aswellasinwaysuniquetomlsystems .therefore wereviewpriorworksontraditionalsoftwaresatdtypes to construct a taxonomy which this study refers to as software satd types .
this study also presents a taxonomy consisting of satds which appear in ml specialized software.
to accomplish this we identify td types found in ml software from previous studies .
using these prior works we construct a taxonomy of satds from the corresponding tds which this study will refer to as mlsatd types .
weusethemlpipelinedefinedinapreviouswork which analyzed3representationsofthemlpipelineatvaryinglevelsto find 7well definedpipeline stageswhichisusedto answer rq2.
weperformedapilotstudyusingpreviousworks taxonomies onasampleof100commentsfromthedatasetfilteredinsection .
.
although every type in previous works ml td taxonomy was notreachedinthe100samples wedidnoticebeneficialimprovementsthatcouldbeproposed.forexample weobservedthatthe configuration debt was too broad to effectively analyze and reason aboutits symptoms and effects.
therefore we split the configuration debtintofivespecifictypesofconfigurableoptions data configuration data storage configuration weight configuration hyper parameter configuration layer configuration .
additionally we also propose new types not found in previous studies machine learningdependency machinelearningknowledge machinelearning reliability modelinterpretability predictionquality .
.
classifying satdrelatedcomments once we created the classificationschemes we want to apply our classification scheme on the sampled satd comments.
we performed a coding process .
to do so an initial training meeting with three of the authors to discuss the classification schemes and thepilotstudydescribedpreviously.followingthismeeting two oftheauthorswouldindependentlylabel30 40satdcomments then discuss in the presence of the third author acting as a moderator.sinceourclassificationispronetohumanbias wecalculate the cohen s kappa coefficient to measure the agreement between two annotators.
cohen s kappa coefficient is a common statistical method that is used to evaluate the inter rater agreement level for classification scales by discarding the possibility of random agreement.theresultingcoefficientisscaledtorangebetween .
and1.
whereanegativevaluemeanspoorerthanchanceagreement zeroindicatesexactlychanceagreement andapositivevalue indicates betterthanchance agreement.
736esec fse november14 18 singapore singapore david obrien sumonbiswas sayem imtiaz rabe abdalkareem emad shihab andhrideshrajan thetwolabelingauthorsachievedacohen skappacoefficient of between their first independently labeled sets on their second and80 ontheirthird.becausetheauthors cohen skappa coefficienthadreachedverystrongagreement theylabeledonce moreindependentlytoachievecohen skappacoefficientof83 which is considered to be excellent agreement .
after each labelingsession thetwolabelingauthorsandthethirdmoderating author would meet to reconcile any disagreements held in the classifications whilealsodiscussingthecauseofthedisagreements.
aftermeetingtoreconcilethefourthindependentlylabeledsets the authors then labeled the rest of the unlabeled data.
in cases where an author was not confident on the appropriate label to assigntoansatdcomment otherauthorswereconsultedinorder toreachadecisionontheappropriatelabelsforthosecases.finally theentiredatasetwasreviewedsothateverycommentwaschecked byat leasttwoauthors.
results in this section we investigate our labeled dataset to answer the fourresearchquestions.
as a result of our manual classification process and literature review we ended up with different software satd types which are describedandexemplifiedintable .
afterconductingourpilotstudyonsatdtypesinmlsoftware wefoundthatsomesatdcommentswerenotwelldescribedby pre existing works or are too broad to describe unique characteristics .tobestfixthesescenarios weproposeanewmlsatd classificationschemeconsistingof23mlsatdtypesconsistingof pre existing td in ml software types and new types as well as split up types proposed in this study which were used to label our dataset.
all ml satd types presented upon have at least one comment in our labeled dataset.
to further analyze the aspect by which a satd in ml software is concerned with we further organize the ml satd types found in section .
into high levelgroupsthatwillbereferredtoas mlsatdgroups .we believemlresearchersandpractitionerscanusethishierarchical classification scheme to guide and evaluate ml software maintenance.
table shows a detailed description of the ml satd types organizedbyml satd groups.
.
rq1 whattypesofsatdarefoundin our studiedml software?
in this section we analyze the distributions within our dataset to present commonly found satd types in ml software their symptoms andexample comments.
ourresults are organized as such table 3presents thedistributionofallsoftwaresatdtypecommentsthatoccur.itisimportant to note some comments were not well described by one of the software satd types and was then left blank.
similarly if an satdcommentinourlabeleddatasetwasfoundtobedescribed by multiple ml satd types then it is counted as a unique debt for each ml satd type it received.
for example the comment todo experiment with more layers received the labels layer configuration andmachine learning knowledge so it is counted in thetotalsforbothmlsatdtypes.theresultsfromperforming this study are shownintable .finding requirement debt accounts for .
of the software satd typesinml software.
as seen in table more than a third of satd comments in our labeled dataset which have a software satd type received therequirement debt label.
requirement debts are concerned with shortcomingsinvolvingincompletefunctionalityornon supported features functional requirements as well as poorly performing code non functional requirements ml specific examples of these areprovidedintable .becausemlisanactiveareabothinindustryandacademia therearerapiddiscoveriesandimprovementsthat canbemadetomlsoftware .casessuchasalgorithmicconfigurations apiupdates anddeveloperimprovementcouldcontribute to the resolution of non functional requirement debts.
similarly codereviews issuetrackers andfeaturerequestsaremethodologies which may identify functional requirement debts.
however the abundance of requirement debts in our studied ml software repositories may indicate that ml developers prefer to focus on othermattersbesidesfunctionalandnon functionallyindebtedsubsystems leadingtotheintroductionoftheseself admittedtechnical debts.
ourfindingsindicatethatmldevelopersshouldbeawareofhow fast pacedmldevelopmentcanbeandhowchangestorequirement specificationscouldaffecttheevolutionandmaintenanceoftheir software.additionally mlframeworkdevelopersshouldalsobe awarethatthefunctionalitiestheyprovidemayleadtotheintroductionof requirement debtsintheapplicationswhichusethem throughapimisuse unclearintents and cascadingupgrades .
we recommend that ml framework developers should design apis such that its users are supplied with a complete pictureofitsrequirementsandlimitations.
forexample the satdcomment todo add param for relative path vs just folder names revealstherequirementsandlimitationsfoundin an evaluation utilities class.
knowledge of this limitation can save developer timelaterindevelopment.furthermore mldevelopers should carefullyconsider howtheircurrentimplementations may holdupagainst future requirement changes .
finding when compared to traditional software ml software containsless prioritized codedebts.
to put our results in perspective the results from prior work on satd types in traditional software development by bavota and russo are shown in table .
they analyzed software repositories resulting in the mining of billion comments and the labeling of satd comments with the same classification scheme we used to construct our taxonomy of the software satd types.
when we compare our results in ml software to bavota and russo weseethatourinvestigationsindicatethatmldevelopers might differ in their satd management to traditional software developers.
instead of requirement debt codedebt is the satd typewhichappearsmostinbavotaandrusso sstudyontraditional softwaresatd .codedebtinvolvesareasofpoorlylegiblesource code.casesof codedebtsincludesectionsofcodewherecodelogic can be simplified to allow for easier understanding variables or functionscanberenamed afunctioncanberefactored orcodecan be reformatted to adhere to expected coding standards.
example satd comments of codedebts found in our dataset include hackier fixme to use regex or something andit s only 73723shades of self admittedtechnical debt anempirical studyonmachinelearning software esec fse november14 18 singapore singapore table definitions andexamples ofthe6 identified software satd types.
satd types description example comment of occ.
of occ.
requirement requirementdebtscanbefunctionalornon functional.inthefunctionalcase implementations are left unfinished or in need of future feature support.
in the non functional case the corresponding code does not meet the requirement standards speed memory usage security etc... todo handle channel modalities later todo make efficient todo implement conv transpose .
.
code bad coding practices leading to poor legibility of code making it difficult to understand and maintain.todo this next code is dense and confusing.
clean up at some point.
.
test problems found in implementations involving testing or monitoring subcomponents.xxx should we rather test if instance of estimator?
.
defect identifieddefects in the system that should beaddressed.
todo this will fail if a parameter cant handle size n .
design areaswhichviolategoodsoftwaredesignpractices causingpoorflexibilityto evolvingbusiness needs.todo maybe improve this so it doesn t use a global .
documentation inadequatedocumentation that exists within the softwaresystem.
todo update doc above .
needed for a specific purpose in the short term will go.because the two types of developers differ in the types of satd they accrue it may be the case that the nature of the software domain affects the developers maintenance patterns.
as speculated by previous work some ml developers may notbeprimarilysoftwaredevelopers.instead theymightbedata scientists researchers or domain experts.
therefore developers in these roles may not be as prepared to maintain software solutions.
regardless a comparison between bavota and russo s study andourownsuggeststhattherearedistinctionsbetweenthesatd patternsbetweenbothtypesofdevelopers.additionally thelanguages which are used by the studied software in both studies are different.
bavota and russo studied repositories which are written in java while our study analyzes python projects both languages are studied together in a previous work on technical debt .therefore thedifferenceinprogramminglanguageusage maycause ashift insatd management.
finding3 .
ofmldevelopers ml specificsatdis due todatadependency .
as seen in table data dependency is the most used ml satd group.mlsoftwarefunctionalityisheavilydependentuponthe quality structure andconsistency ofmodels training data.
therefore thecodethatprocessesorstoresthisdatamayhavebecame anaturalfocus for ml developers .becausedata isinfluenced andthroughmlmodelscaninfluencethe outsideworld itiscrucial that ml developers ensure their data is well monitored and well understood.
misunderstood data can cause unintended consequences and as a result can effect the outside world when naively deployed .
basedonourmanualanalysis weobservethatmldevelopers mayleavemore datadependency debtsthananyothergroupofml satds.technicallyindebteddatacanbeharmfulformlmodels because it implies that the current data has identified shortcomings similar to how code can be described with technical debt.
for example the comment text todo expand proper nouns for common words around word admits a preprocessing task that should be improved upon.
because this current short term solution exists not only is the software suffering from a satd butthedatamaybeconsideredtechnicallyindebted aswell.althoughmany datadependency debtsobservedinour datasetinvolvedatapreprocessingtasks thereareothercaseswhich datadependency canbeconcernedwith.otherexamplesof data dependency involveddebtsincludethoseassociatedwithdatavisualizations todo add general distribution data storagemanagement todo check the local cache and cloud for different images of same name configuringqualitiesoftraining data todo weight by length here and interfacing with modeloutput fixme only keeping the first label .
whiledata dependency satd comments can involve how data isprocessed represented and usedthroughml software we also find reoccurring symptoms in the data dependency satd comments.
these symptoms indicate an implied problem or suggested fixonmlcodethatinteractswithdata.wefindthatthesesymptomstypicallyindicateachangeinvolvingtheaddition removal improval replacement reapplication orhandlingan edgecaseof somedatainvolvedcomponent.anadditionindicatesaspotwhere anewdataprocedurecanbeused todo add hebrew to aramaic converter .
a removalindicates a procedure that may needto be removed fixme don t l2 normalize for any metric .
an improvement is an area where the data procedure can be modified to perform better note probably more efficient to sort then stride by nt regions .
a replacement indicates where a different data involved functionality can be used todo hard coded for now looking for better extraction methods .a reapplication involves the reuse of a pre existing procedure todo it could be nice if this method was run on entire data not just a sample .
finally symptoms can indicate cases where thecurrentproceduresfailordonotbehaveasexpected double newlines seem to mess with the rendering .
therefore mldevelopersshouldconsiderhowtheirdataconfiguration implementations could evolve overtime.
if a particular componentdoesnotallowforthefixofoneofthesymptoms describedabove thenanunderlyingdata dependenttdmay exist.since our data suggests that these problems are encountered commonly in ml software preparation for these modifications can save maintenanceactivity.
finding4 awareness account for17.
ofour ml satd.
awareness consistsofdebtstypeswherethelackofdevelopers knowledge or understandingnegatively affects its associated software.satdcommentsofthiskindmaybefoundintheformofa question suchasthecomment todo does this handle n dim tensors correctly?
.also awareness debtsmaybecausedbythe natureofworkingwithmlmodelswhosefunctionalitycanbeconsideredablackbox .whensuchcasesarise thedemandfor newfunctionality mayarisetobetterunderstandmodelbehavior.
forexample thecommentinourdataset todo model precision admitsanewevaluationmetrictobeusedtobetterunderstandthe performanceofamlmodel andwasconsideredan awareness debt underthis context.
738esec fse november14 18 singapore singapore david obrien sumonbiswas sayem imtiaz rabe abdalkareem emad shihab andhrideshrajan table definitions and examples of the identified ml satd types awareness awr readability rdb duplicate codeelimination dce configurableoptions cfo codedependency cdd data dependency dtd modularity mdl performance prf andscalability scl .
new ml satd type proposed inour study.
dim.name definition exampleawrmachinelearning knowledge machine learning software carries plenty of unique challenges.
uneducatedsolutions byunaware developers mayhave to be revisited.fixme can i backprop error through both model interpretability machine learning models are a black box causing poor understanding ofmodel sfunctionality.this can leadto unknownbehavior.todo model precisionrdbmodelcode comprehension model code carries extra legibility concerns that do not occur in traditionalsoftware.
i.e.
poorlynamedtemporary matrixvariables .todo refactor second part of if statement when implementing live model predictiondceduplicate model code code duplicationfrequently occurs inmodelcode.
todo basically identical to test intra cv target transform except for repeated kfold duplicate feature extraction code code duplicationfrequently occurs infeature extractioncode.
xxx de duplicate this with code from montage somewhere?cfoweight configuration editingcode that involves the weightsof aml model or configuring aml model sweightsdirectly.fixme non uniform sample weights not yet supported layer configurationeditingcodethatdealswithmlmodels layers orconfiguringaml model slayers itself.todo experiment with more layers hyper parameter configurationconfiguring hyper parameters of ml model or editing the default valuesofoff the shelf model.todo convert this to x y params?cddmachinelearning dependency when a needed change in ml software occurs because of its dependency on an external library or other piece of the ml software system.
usually indicates a condition that is waiting to be met before removal.todo add test for keypoints once their handling was improved in convolve glue code supporting code written to interface with other code inhibiting improvements dueto peculiarities ofdependent code.fixme xxx implement by rewriting functions above copied from autoresolve.py custom data type using data types provided by general purpose packages can cause extensive inter operating withexternal libraries.todo repeat elements and tf.split doesn t support dynamic splits.
multiple languages componentswritteninotherlanguagesmayintroducedifficultiesin ml development.todo sonots implement in c unnecessary modelcode model code that either bottlenecks performance is unreachable or deprecated orisunnecessary andshould be removed.depricate?
i don t think this is needed anymoredtddata processing configuration configuringthewaythatdataisprocessedeitherbyeditingthedata directly orbyaddinginnewprocessing steps.todo normalize true states plain old data type usingrawdatatypesinmlcausesconfusionwheninterpretingprocesses.todo handle record value which are lists at least error data storage configuration configuring how data is represented within the source code data structure orhowdata isstoredexternally database .todo json?mdlabstraction lackofabstractionsinmlsystemsandsubsystemscausecascading changes when changes are introducedto one component.todo split into separate functions boundary erosion lack of boundaries between subsystems creating difficulties when maintainingsoftware andisolating changes madeinml software.
todo nrows is for testing only!
modelcodemodifiability modelcodeshouldbeimplementedinwaysthatenableeasymaintenanceandfuture modifications.todo init this somewhere else in a more principled way model code reusability modelcodeshouldbegeneralizedtobeabletobereusedinvarying situations.todo at the moment lhuc is rnn specific.prfprediction quality previousworkinevaluatingmlworkflows showsthatchanges mayaffectperformance.todo compare the performance!
machinelearning reliability machinelearningmodels functionalitiesaredeterminedbythequality oftheirdata measures should be inplaceto ensure robustness.todo extract an eval func more robustlysclprototype small scale prototypes being deployed into full systems can be dangerous.todo this matching process is slow.
make it faster avoid loops where possible.
73923shades of self admittedtechnical debt anempirical studyonmachinelearning software esec fse november14 18 singapore singapore table distribution ofml satd groups.
ml satd group name of occur.
of occur.
data dependency .
codedependency .
awareness .
modularity .
configurableoptions .
scalability .
readability .
performance .
duplicate codeelimination .
symptoms of awareness debts include doubts on the correctness of algorithmic procedures doubts onthe current design decisions lackofknowledgeofproperapiusage erroneouscaseswherea solutionisnotidentified andlackofdomainknowledge.doubts on algorithmic procedures either by interfacing with other softwareorcorrectnessofalgorithmscanleadto awareness debt todo figure out what exactly size does fixme what if we never find a fail high?
.doubtsoncurrentdesigndecisions canbeduetoquestioningthequalitiesofacurrentimplementation todo something smarter?
orquestioningthedesigndecisions in place todo do we want gainsbiases to be trainable?
.
lackofproperapiunderstandingcanalsobeasymptomof awarenessdebts todo check if self.
mean squared error w precision can be used here .
additionally cases where errors are encountered or incorrect behavior is discovered but a solution is not yet known can also be a symptom todo skip on error???
.
finally since ml software can be applied in various domains it is not surprising that a lack of domain knowledge contributestoquestionablesoftwarebehavior todo figure out how to distinguish oxidation states .
consistentlyupdateddocumentationcanalleviatesuchsatds disclosing properapiusageand possible design intentions.since priorworkshowsthatmostsatdisaddressedbyadifferentdeveloper than the one who self admitted it including documentation details such as limitations advantages and defense of the currentimplementationcaninformfuturedevelopersofidentifiable improvements.forexample thecomment to do this causes very long running when unique numbers are high.
find a workaround for this describes the symptoms and limitations of presentimplementations andgivesanactionablestartingpointfor futuredevelopers.therefore themoreinformationwhichcanbe disclosedbyadeveloperina awareness debtscenario mayenable timely removals of these debts regardless of the symptoms they contain.
our findingsindicatethat ml satds mayreflectthe fast paced environment of ml software through a large amount of requirementdebts setting itself apart from traditional software development.furthermore datadependentcodeandlackofdeveloper awareness are majorfactors contributingto satd.
.2rq2 what is the distribution of satd types in thedifferentml pipeline stages?
this section further analyzes distributions of ml satds by also considering which stage of the ml pipeline every satd comment appearswithin.becausethemlpipelineconsistsofuniquetasks whichmlsoftwarecommonlyworksthrough wequestionwhethertable results frompriorworkby bavotaand russo .
satd type of satd comments of sampled satd comments codedebt .
defectdebt .
requirement debt .
design debt .
documentation debt .
test debt .
total somemlsatdsoccurmorefrequentlyinvaryingstages.weutilized prior works studying the ml pipeline to construct ourtaxonomyofmlpipelinestageswhichinclude dataacquisition data preprocessing modeling training prediction evaluation and other.theotherstageisreservedfortasksthatcanoccuranywhere inthemlpipelineforavarietyofreasons i.e.
datavisualization anddatastorage aswellascaseswheretheauthorswerenotconfident on a pipeline label due to lack of distinguishable information.
table7presents the distribution of the ml satd groups amongst the pipeline stages.
finding data preprocessing is the pipeline stage with themostsatd.
datapreprocessing isthestageinthemlpipelinethathasthe most satd comments out of all pipeline stages.
rq1 found that data dependency is the most used ml satd group.
however sincedata preprocessing contains the most satd in our dataset it suggests that ml developers leave satd comments of a wide variety in data preprocessing code.
for example the comment todo validation split is not used exemplifies an unnecessarymodelcode debtthatwasfoundinthe datapreprocessing stage.
similarly the comment fixme does pytorch has something similar to tf.add n which sum over a list?
is amachine learningknowledge andcustomdatatype debtthatappearedin thedata preprocessing stage as well.
the high satd activity in the data preprocessing stage could be caused by feature engineering components having the largest body of code therefore there is more code to self admit technical debts.
sculley et al .
showed that a mature ml system may be at most ml code.
the rest of the system may consist of subsystems such as process managing tools or feature engineering code among others.
regardless thehighactivityofsatdwithin datapreprocessing codestresses the importance for rigorous review on code which handles data preprocessing.
finding data dependency is the satd type which is dominantin5 outofthe pipelinestages.
our observations find that data acquisition data preprocessing evaluation prediction andother stagesexhibit datadependency astheirprimarysatdtype.thisobservationindicatesthatsubsystemsacrossthemlpipelineencountersatdamountswhich involve adjustments to data interactions.
to demonstrate that data dependency debtscantakedifferentshapesamongstthepipeline stagesconsiderthe evaluation stagecomment fixme don t l2 normalize for any metric which involves the normalization means in the evaluation stage of a speaker diarization pipeline.
meanwhile thecomment todo combine these values to get a final prediction!
describes functionality to be implemented foransvmmodelinthe prediction stage.ourmanualanalysis suggeststhatpotentialsolutionstorepairingdata dependent 740esec fse november14 18 singapore singapore david obrien sumonbiswas sayem imtiaz rabe abdalkareem emad shihab andhrideshrajan table ml satd groupsby pipelinestage ml satd groupsml pipelinestages acqu.
prep.
mod.train.
pred.
evalu.
oth.
awareness codedependency configurableoptions data dependency duplicatecode elimination modularity performance readability 1scalability repo typeml satd group awarenesscode dependencydata dependency modularity performance readability of satd of satd of satd of satd of satd of satdapplication tool22.
.
.
.
.
.
.
.
.
.
.
.
ml satd group by repo type ml satd group awareness code dependency data dependency modularity performance readability of total count of ml td type for each repo type broke n down by ml satd group.
color shows details about ml satd group.
the marks are labeled by of tot al count of ml td type.
the data is filtered on ml td type which excludes null.
the view is filtered on ml satd group which excludes configurable options duplicate code elimination and scalability.
p ercents are based on each row of the table.
figure ml satd groupingsdistribution by repotype satds may be completely different between pipeline stages despite their broad similarities.
another explanation to this observationistheconceptofpipelinejunglesintroducedbysculley et al.
where there is little independent responsibility given to eachpipelinestage.becauseofthis datapreprocessingisnotisolated to one coherent stage rather data preprocessing is performed asneeded .thus theplacementofdatapreprocessingcode withinothermlpipelinestagesaccruestechnicaldebt sincethe debugging or refactoring must consider the data transformation implementations acrossmultiple stages.
we observethat data preprocessing isthemost popularpipeline stage stressingtheimportanceofmindfuldatahandlingimplementations.
similarly data dependency debts are the biggest contributorto5pipelinestagesinourdataset thetwoexceptions being the modeling andtrainingstages.
.
rq3 isthereadifference in satdtypes betweenml applicationsvsml tools?
inthissection weseparateourfindingsintothemlrepositories that apply ml towards a task applications and ml repositories that provide ml functionalities tools as labeled by the original dataset creators .
figure 1illustrates the mlsatd group distributionsbyrepositorytypetovisualizedifferencesbetweenthem.forviewingpurposes onlythemlsatdgroupswhichdifferbymorethan2 are shown.
finding7 ouranalysisofsatdcommentssuggeststhat codedependency debtsappearmoreofteninmltoolsthan ml applications.
according to figure code dependency related debts may be more common in ml tools than ml applications.
code dependency referstoasimilarconceptto on holdsatd explainedbymaipraditetal.
.intheseinstances ansatdiswaitingforacondition to be met before taking action e.g.
waiting for an update or other developmenttaskstocomplete suchasthecomment todo modify mu and sigma once feature scaling is built into thelogistic regression .
we describe code dependency as satd whichdependsuponothercode.casessuchasinterfacingwithspecificdatatypes todo repeat elements and tf.split doesn t support dynamic splits changestosoftwareandapiswhich causeversioningupdates todo assertwarns exist only for python .
test in all versions or cascading changes throughoutsoftwaresystems todo it s worth to switch back to the correct preprocess input when inceptionresnetv2 model is re trained .
mltoolsfindthemselvesinacompetitiveenvironmentamongst themselves to provide efficient techniques for their users.
previous workhasdescribedthetemptationthatashortertime to market bringstodeeplearningframeworkdevelopers .itcouldbethat in order to stay relevant ml tools implementations must interoperatewithotherevolvingmltools.thus codedependency debts may occur when other tasks take priority above resolving these identified problems.
our observations suggest ml tool developers sufferfromtheseoccurrencesmorethanmlapplicationdevelopers.
we believe that ml tool developers can benefitfrom these observationsbyfurtherevaluatingtheimplementationswhichthey dependon andwhattheadvantagesofevolvingincorrespondence withthoseimplementationsmaybring.furthermore weencourage ml tool developers to consider how severe of a refactoring that an api change may have upon depending systems and to allow for upgradingversionsto be performedwithease.
finding8 inourdataset mlapplicationsencountermore modularity debts.
modularity debts describe cases where weak modular boundariesexistbetweenmlsubsystems.anexampledebtinthe modularitygroup isboundary erosion an example comment of whichis todo nrows is for testing only!
whichdescribesa casewhere a parameterintended fortestingpurposes was instead usedwithindatavisualizationcode.another modularity exampleis theabstraction debt comment todo refactor as independent function which admits the task of creating a new abstraction within afeature engineeringprocess.
our analysis suggests that modularity debts are found more often in ml applications than ml tools hinting at a possible differencebetweentheirsoftwaremaintenancepatterns.apossible explanationmaylieinthecommonuseofjupyternotebooksbyapplicationdevelopersasexploredbypimentel etal.
.inajupyter notebook application developers usean interactive environment to debug and monitor their code.
however the transition from jupyter notebook to an object oriented oo design may be difficult and instances of modularity satd may be left wherethesetransitionswereattempted.
tangetal .
also speculates how ml developers may not be familiar with object orientedprogrammingbestpractices leadingtotheintroduction ofsuch technical debts.
itwasfoundthatmltoolssufferfrommuchmore codedependencydebts possiblyasideeffectfrominter operatingwithother libraries.
additionally our results suggest that ml application developers incur more modularity debts.
74123shades of self admittedtechnical debt anempirical studyonmachinelearning software esec fse november14 18 singapore singapore figure ml satd groupingsremoval characteristics.
.
rq4 howmucheffort isneeded to remove satdtypesin ml software?
thissection analyzestheeffortconductedtoremovesatdinml software.inordertoaccomplishthis weonlyanalyzeoursatd commentswhichhavebeenremovedatthetimeofdatageneration.
we define effort of removing an satd comment as a comparison between the time passed since its introduction and size of the commit which removes it.
since an satd may take multiple commitstoremovebecauseofunknownsolutionsorlowerprioritization we follow the advice presented by bird et al .
to connect a comment removing commit to a comment introducing comment ofthesametext.becauseallcommitsarenotthesamesize wealso usetheboalanguageanditsinfrastructurecreatedbydyeretal .
to perform the gumtree algorithm to compute the edit script of asource code change at the abstract syntax tree ast level.withthismethodology wecountthenumberofastnodes modified in the revision which removes the satd comment to get an indication of work which removed it.
due to larger repositories causing timeout errors some commit revisions are unable to be quantifiedinour dataset.
figure2illustratesourresultsonthemlsatdgroups.sincewe wanttopresentondatawithlargerbodies themlsatdgroups shownarethosewhichcontain10ormoreremovedinstances.inaddition figure3illustratesourresultsacrossthemlpipelinestages.
we measure our statistics in median because it is unaffected by outliers since it has been shown that an satd comment may have been removed without any additional code change or alongside large refactorings.
.
finding data dependency configurable options and awareness may require less removal effort.
thelownumberofcommitsandlowastcountintheremoving commit suggest that these debts are more convenient to remove.
for example the satd comment todo modify this later is adata dependency debt describing a sampling modification was removed in commits with modified ast nodes.
because of these lower quantities involved in these comments removals it could be that ml developers understand these satds better since muchofmlsoftwareinvolvesoperatingwithdatadependentcode configurable apis and unknown solutions.
dilhara et al.examined common code changes made in ml software by reapplying refactorminer to python programs .
however further work is neededtounderstandthechallengesinvolvedwhenmldevelopers identifyandimplement differing code changes.
median amount of commits until removal0100200300400median modified ast amountsheet ml pipeline stage data acquisition data preprocessing evaluation modeling other prediction training median of amount of commits until removal vs. median of modified ast amount.
color shows details about ml pip eline stage.
the view is filtered on ml pipeline stage which excludes null.figure ml satd removal amongst pipelinestages finding10 modularity debtshaveahigheramountofast nodes intheir removing commits.
ouranalysissuggeststhat modularity debtremovalshavelarger commitsandshorterremovaltimes.therefore highactivityinalow amountoftimemaysuggestthatidentified modularity debtsarethe mosturgenttoremove.considerthecomment todo promote this to a funsor subclass.
which involves reorganizing software classeswhoseremovalinvolved355modifiedastnodes.apossible explanationis thatthe heavier refactoring of modularity debts are viewed as more valued improvements to ml developers and are prioritizedsooner despitetheir larger changesize.
therefore ml developers can benefit from this finding by carefullyconsideringtheirmodulardecisionsoverpotentially simpler decisionsearlierindevelopment.sinceourresultsindicateheavier activity is required from modularity debt resolutions earlier decisions involving abstractionsand modulardesign are more important in a software s lifetime than issues which are lighter to resolve.
finding our analysis suggests that satd in prediction andevaluationstages have largerremoval characteristics.
figure shows the complexities of debt removals by the ml pipeline stages.
our study suggests that debts removed in the evaluationstagehavealargeamountofmodifiedastnodes anddebts removed in the prediction stage are removed after a larger number ofcommits have passed.
thesefindingsmayindicatethatdebtsremovedinthe evaluation stage may require larger activity possibly due to reused evaluation metricsacrossmultiplemodelcodes.
therefore achangemadein this stage may have a wide reach of consequential changes.
if a debt in this stage goes unnoticed its resolution may take a heavier amountofwork asissuggestedbythelargeramountofastnodes modifiedincomment removals in evaluation stagecode.
ourobservationsindicatethatdebtsfoundinthe prediction stage gounresolvedforlargernumberofcommits possiblyhintingatml developer spriorities whenworkingacrossthe pipelineforlarger periodsoftime.ratherthanimproveuponpredictinginvolvedcode it may be that ml developers choose to prioritize the immediate removal of satds elsewhere.
thus the prediction stage may be an areaofmlsoftwarewheretheremovalofansatdisnotasurgent.
742esec fse november14 18 singapore singapore david obrien sumonbiswas sayem imtiaz rabe abdalkareem emad shihab andhrideshrajan ourstudysuggeststhat awareness configurableoptions anddata dependency debts are easier to remove than modularity debts.
moreover there are heavier debts to pay off in the evaluation pipeline stage anddebtsinthe prediction stagelast the longest.
discussion ml techniques are increasingly adopted by developers to solve previously difficult to solve problems thus there is a benefit to understandinghowthesesystemsevolve.althoughsculleyetal .
previously explored the hidden technical debts encountered atgoogleand tang etal.examinedhowrefactoring accompanies technicaldebtsinmlsoftware tothebestofourknowledge nopreviousstudyhasexaminedhowml specifictechnicaldebts permeateasself admittedtechnicaldebt.thestudyofsatdhas previouslybeenfruitfultopractitionersandresearcherssincean organization has reported that satd guides their technical debt management .
this large scale study ofsatdin ml software can also provide researchers and practitioners with insights on ml software evolution from our analysisofml satd.
themlsatdtaxonomydepictedintable4isasynthesisofprior works studying td in ml software and our manual analysis of satdcomments.thistaxonomynotonlyincludesnewtypesoftd throughsatd analysis but alsosplits previous typeswhichwere previously described a large assortment of issues.
our proposed taxonomyishierarchicalinnature providingmldevelopersand researchers a classification scheme for reasoning about issues in mlsoftwaremaintenance.webelievethistaxonomycanguideml developers in ml development as well as provide researchers with areas to further explore.
additionally the ml pipeline has been a focus of researchers recently yetno prior study has examined the satd which persist through the individual stages evolution.
our analysis of satdinthesepipelinestagesisastepinunderstandingtheunique challenges each stage encounters overtime.
moreover this study is thefirsttoanalyzehowdifferingtypesofmlprojectsencounter satd to researchers interested in improving ml developer experience.
finally we provide a study quantifying the efforts needed to remove various satds in ml software although further work can complementthesefindings.
.
implications ourstudysuggeststhatsatdinmlsoftwarecanbeinspected onvariouslevels suchashowtraditionalsoftwareevolvesin additiontomlspecificways.ourproposedtaxonomycanguide ml practitioners in their ml software maintenance describing 23uniqueproblemswhichhavebecomeevidentthroughour satdanalysis.akeyfindingisthatmlsoftwareencounters debtsfrequentlyinvolvethemanipulationofdataprocessing means including the introduction removal improvement and reuseofcodewhichhandlesthedatafromdataacquisitionto model evaluation.
therefore ml developers should consider thedatarequirements distribution organization appearance etc... for every pipeline stage in their software and where theserequirements are not met.
traditional software developer and ml developers differ in theirsatdactivity.
mldevelopers mayprefer toevolve theirsoftwarethroughfunctionalandnon functionalrequirement changes as new capabilities become available or their software interacts with the real world.
because of this ml software maybenefitfromdistinctsolutionsandtoolsthantraditional software.
consequentially researchers may be interested if thereuseof traditionaldeveloper assistingtoolsmaynot adequatelyaddressthesatdissuesencounteredbymldevelopers.
wefindthatmldevelopers satdchangesdependingonthe type of ml software being maintained.
this is an interesting direction showing that different typesof developers may gain greater benefits from various techniques.
for instance we find that ml tool developers accrue larger debts from interacting with fellow evolving libraries and ml application developers can benefit from more focused modular designs implementedearlierinproduction.
threats to validity in this section we discuss the threats to internal construct and external validity ofour study.
internal validity concerns factors that could have influenced our results.
our findings depend largely on the data labeled.
in ordertoensurethatourlabeleddataisprecise twoauthorswent throughanextensiveperiodwheretheircohen skappacoefficient wascalculated anddisagreementsinlabelingweresettledinthe presenceofathirdauthoruntiltheircohen skappacoefficientwas above .
whenassociatingcomment introducingrevisionswithcommentremovingrevisions weonlyconsiderthecaseswherethecomment appeared the same during both commits.
the comment could have beenmodifiedin between orotherunusualcasesmighthaveoccurred .becauseofthis ourseparationofcommentsthathave beenremovedandcommentsthatstillexistwithintheirprojects may be inaccurate.
this should only affect cases where a comment was incorrectly placed as not removed.
all comments that were found to have been removed should be true positives which are the casesanalyzedinrq4.
it is possible our methodologies of measuring effort rather measures priority or system impact .
however we argue that there may be no perfect way to measure effort since development patterns and activity likely differ across software projects.
for this reason we utilized multiple measures change size and time to quantify effort which can be adopted in future research to complementour findingsfurther.
construct validity considers the relationship between theory andobservation.ithasbeenshownthattheremovalofansatd comment is a naive indication that a td was also removed .
a comment could be removed without any fix to the satd or a satdcommentcouldberemovedatalatertimethantheresolution or the comment could never be removed at all.
to mitigate this the authors examined the code around the satd comment and wereabletoidentifyafewcaseswherethesatdcommentisno longerrelevant.
thesecaseswere thenremovedfromourlabeled data.additionally thequantitativedataofrq4wasmeasuredby its median to avoid influence byoutliers.
the projects analyzed within this project may not be indicative ofpresentmlsoftwarepractices.however thedatasetwascreated 74323shades of self admittedtechnical debt anempirical studyonmachinelearning software esec fse november14 18 singapore singapore through extensive queries of the github api with a variety of keywords consisting of topics subtopics technologies and techniques relatedtoml .becauseofthis webelieveourstudyhasawide representation ofml topics.
although the satd comment classifier used has historically performed well it still may produce false predictions when our dataset was filtered.
however when labeling the authors would removeanyfalsepositivesamples.theinclusionofusingakeyword searchalongwithusingthecommentclassifier soutputwasusedto recoveranyfalsenegativesamplesthecommentclassifierproduced.
externalvalidity concernsthegeneralizationofourresults.in this study we examined only open source python repositories that are divided into applications and tools used in previous studes .
hence our findings may not be generalized to to other nonpythonrepositoriesornon open sourcerepositories.thatsaid our decisionofstudyingpythonrepositorieswasmadebyitspopularity among the ml community .
also our dataset size of ml pythonrepositoriesthatmaynotrepresentthewholepopulation ofml software written inpython.
related work inthissection wedescribetherelatedwork.wedividedtherelated workintotwosections workrelatedtotechnicaldebtmanagement ingeneralandworkrelatedtothemanagementoftechnicaldebt inmachine learningrepositories.
generalmanagementoftechnicaldebt.
severalearlierworksstudiedthemanagementanddetectionoftechnicaldebt e.g.
.forexample brownetal .
kruchtenetal .
andseaman and guo made several observations about the term technicaldebt andmentionedthatitisregularlyusedtocommunicate developmentissuestomanagers.similarly zazworkaetal .
performedastudytomeasuretheimpactoftechnicaldebtonsoftware quality.otherworksbyfontanaetal .
investigateddesigntechnical debt indicated in the form of code smells.
furthermore ernst et al.
conducted a survey involving more than participantsandfoundthatarchitecturaldecisionsarethemostimportant sourceoftechnicaldebt.similarly inthispaper westudytechnical debt insoftware applications.
however ourstudy focuses on gainingabetterinsightintotheexistenceofthetechnicaldebtin ml repositories.
recently proposedtheconceptofself admittedtechnical debt satd which considers debt that is intentionally introduced oridentifiedbydevelopers.
analyzedmorethanahundredthousandcodecommentsfromfourprojectstocomeupwith62patterns that indicate self admitted technical debt.
also their findings reveal that approx.
of the files in a project contain self admitted technical debt.
more specifically they found that the majority of the self admittedtechnical debt isremoved in the immediate next release developerswithhigherexperiencearemostlytheones who introduce the self admitted technical debt release pressure doesnotplayamajorroleintheintroductionofself admittedtechnicaldebt.inafollow upstudy bavotaandrusso replicatedthe studyofsatdonalargesetofprojectsandconfirmedthefindings observedbypotdarandshihabintheirearlierwork .
otherworksinvestigatedifferentaspectsrelatedtosatd including automaticallyidentifysatdfromsourcecode e.g.
examinethemaintenanceandtheremovalofsatd and discusshowtheexistenceofsatdmayleadtotherejectionofpull requests by developers .
we refer the reader to a recent survey by foramorecomprehensivelistofstudiesonself admitted technicaldebt.similartotheworkmentionedabove ourstudyuses source code comments to detect self admitted technical debts in ml repositories.
managementoftechnicaldebtinmachinelearningapplications.
in recent years examining the characteristics of machine learning applicationshasgainedmomentum.oneofthefirststudiesrelatedto technicaldebtinmlapplicationsintroducedtheconceptofimplicit td in ml software through experiences encountered during ml projectsatgoogle .thisworkwasthenfurtheredby where new ml specific refactoring and td categories were introduced accompanied by recommendations of best practices to facilitate long termmlsoftwaredevelopment.similarly theworkby discussesaworkflowtoevaluatemlsoftwaredevelopmentpractices at thedata model infrastructure and monitoring levels that wasthenperformedacrossmultiplemlprojectsatgoogle.liuetal .
examined the existence of td in deep learning frameworks.
theirstudyshowedthatdesigndebt defectdebt documentation debtare mostpresentedtd indeep learningframeworks.
several studies examinethe developmentofml repositories in general.
humbatova et al .
and islam et al .
examined deeplearning systemsto systematicallybuild ataxonomy of bugs that impact deep learning systems and recent works propose techniquestoaddresstheseidentifiedissues .nguyenetal .
proposesatechniquetoleveragerepositoriesofmodelstoassistml developers.
amershi et al .
investigates the unique challenges faced by software developers when developing ml applications.
ml models can exhibit new qualities unfamiliar to traditional software such as model fairness .
dilhara et al .
conducted an empiricalstudytoexaminetheevolutionandusageofmllibraries.
conclusion nowadays ml solutions are being adopted by software developers to accomplishotherwise infeasibletasks.
similar to traditional software there are uniquecosts to impractical design decisions in ml software that result in technical debts .
in this study we have analyzedself admittedtechnicaldebtsinmlsoftwarethroughastatistically significant sample of satd comments from open source repositories.
furthermore we propose a classification scheme consisting of software satd types ml satd types and new ml satd groups.
this classification scheme can provide practitioners and researchers a structure for discovering and managing their satd.additionally weprovideananalysisofsatdcharacteristics astheyappearamidstpipelinestagesandrepositorytypeaswell as an analysis of satd removal effort.
the results discussed can assist developers and researchers to create more maintainable and improvableml software solutions.