deepcv a automated commit level vulnerability assessment with deep multi task learning triet huynh minh le david hin roland croft and m. ali babar crest the centre for research on engineering software technologies the university of adelaide australia cyber security cooperative research centre australia triet.h.le david.hin roland.croft ali.babar adelaide.edu.au abstract it is increasingly suggested to identify software vulnerabilities svs in code commits to give early warnings about potential security risks.
however there is a lack of effortto assess vulnerability contributing commits right after they aredetected to provide timely information about the exploitability impact and severity of svs.
such information is important toplan and prioritize the mitigation for the identified svs.
wepropose a novel deep multi task learning model deepcv a to automate seven commit level vulnerability assessment taskssimultaneously based on common vulnerability scoring system cvss metrics.
we conduct large scale experiments on 229vulnerability contributing commits containing different svsin real world software projects to evaluate the effectivenessand efficiency of our model.
we show that deepcv a is thebest performing model with to .
higher matthewscorrelation coefficient than many supervised and unsupervisedbaseline models.
deepcv a also requires .
times less trainingand validation time than seven cumulative assessment models leading to significantly less model maintenance cost as well.
over all deepcv a presents the first effective and efficient solution toautomatically assess svs early in software systems.
index terms software vulnerability vulnerability assessment deep learning multi task learning mining software repositories software security i. i ntroduction software vulnerabilities svs are security weaknesses that can make systems susceptible to cyber attacks thus it is critical to assess svs .
sv assessment is a process ofdetermining characteristics of svs such as attack vectors andimpacts to help practitioners prioritize remediation for ever increasing svs .
for example svs with simple exploitationand severe impacts likely require high fixing priority.
the expert based common vulnerability scoring system cvss is a commonly used sv assessment framework.cvss provides metrics to quantify the exploitability impactand severity level of svs.
however there is usually delay inthe manual process of assigning cvss metrics to new svsconducted by security experts .
hence there is an apparentneed for automation in assessing reported detected svs.
existing techniques e.g.
to automate bug sv assessment have mainly operated on bug sv reports but these reports may be only available long after svs ap peared in practice.
our motivating analysis revealed that therewere days on average from when an sv was injectedin a codebase until its report was published on nationalvulnerability database nvd .
our analysis agreed withthe findings of meneely et al.
.
to tackle late detectedbugs svs recently just in time commit level approaches e.g.
have been proposed to rely onthe changes in code commits to detect bugs svs right afterbugs svs are added to a codebase.
such early commit levelsv detection can also help reduce the delay in sv assessment.
even when svs are detected early in commits we argue that existing automated techniques relying on bug sv reportsstill struggle to perform just in time sv assessment.
firstly there are significant delays in the availability of sv reports which render the existing sv assessment techniques unusable.specifically sv reports on nvd generally only appear sevendays after the svs were found disclosed .
some of thedetected svs may not even be reported on nvd e.g.
be cause of no disclosure policy.
user submitted bug sv reportsare also only available post release and more than of thereports are filed more than days after developers detectedthe bugs svs .
secondly code review can provide fastersv assessment but there are still unavoidable delays fromseveral hours to even days .
delays usually come fromcode reviewers late responses and manual analyses dependingon the reviewers workload and code change complexity .thirdly it is non trivial to automatically generate bug svreports from vulnerable commits as it would require non codeartifacts e.g.
stack traces or program crashes that are mostlyunavailable when commits are submitted .
performing commit level sv assessment provides a possibility to inform committers about the exploitability impactand severity of svs in code changes and prioritize fixingearlier without waiting for sv reports.
however to the best of our knowledge there is no existing work on automatingsv assessment in commits.
prior sv assessment techniquesthat analyze text in sv databases e.g.
alsocannot be directly adapted to the commit level.
contrary totext commits contain deletions and additions of code withspecific structure and semantics .
additionally wespeculate that cvss metrics can be related.
for example ansql injection is likely to be highly severe since attackerscan exploit it easily via crafted input and compromise dataconfidentiality and integrity.
we posit that these metrics wouldhave common patterns in commits that can be potentiallyshared between sv assessment models.
predicting relatedtasks in a shared model has been successfully utilized forvarious applications .
for instance an autonomous car is 36th ieee acm international conference on automated software engineering ase 36th ieee acm international conference on automated software engineering ase .
ieee .
ase51524.
.
.
ieee driven with simultaneous detection of vehicles lanes signs and pavement .
these observations motivated us to tackle anew and important research challenge how can we leverage the common attributes of assessment tasks to performeffective and efficient commit level sv assessment?
we present deepcv a a novel deep multi task learning model to automate commit level vulnerability assessment.
deepcv a first uses attention based convolutional gated re current units to extract features of code and surroundingcontext from vulnerability contributing commits i.e.
commitswith vulnerable changes .
the model uses these features topredict seven cvss assessment metrics i.e.
confidentiality integrity availability access v ector access complexity au thentication and severity simultaneously using the multi tasklearning paradigm.
the predicted cvss metrics can guide svmanagement and remediation processes.
our key contributions are summarized as follows we are the first to tackle the commit level sv assessmenttasks that enable early security risks estimation andplanning for sv remediation.
we propose a unified model deepcv a to automateseven commit level sv assessment tasks simultaneously.
we extensively evaluate deepcv a on our curated large scale dataset of vulnerability contributing commitswith svs from real world projects.
we demonstrate that deepcv a has to .
higher matthews correlation coefficient mcc than var ious supervised and unsupervised baseline models usingtext based features and software metrics.
the proposedcontext aware features improve the mcc of deepcv aby .
.
the feature extractor with attention basedconvolutional gated recurrent units on average adds52.
mcc for deepcv a. multi task learning alsomakes deepcv a .
more effective and .
timesmore efficient in training validation testing than separatemodels for seven assessment tasks.
we release our source code models and datasets at .
paper structure.
section ii introduces preliminaries and moti vation.
section iii proposes the deepcv a model for commit level sv assessment.
section iv describes our experimentaldesign and setup.
section v presents the experimental results.section vi discusses our findings and threats to validity.section vii covers the related work.
section viii concludesthe work and proposes future directions.
ii.
b ackground and motiv a tion a. vulnerability in code commits commits are an essential unit of any version control system e.g.
git and record all the chronological changes made to thecodebase of a software project.
as illustrated in fig.
changesin a commit consist of deletion s and or addition s ineach affected file.
vulnerability contributing commits vccs are commits whose changes contain svs e.g.
using vulnerable li braries or insecure implementation.
we focus on vccs ratherthan any commits with vulnerable code in unchanged parts !
!
!
!
!
!
!
!
!
!
fig.
.
exemplary sv fixing commit right for the xml external entity injection xxe cve and its respective sv contributing commit left in the xstream project.
since addressing vccs helps mitigate svs as early as they are added to a project.
vccs are usually obtained based onvulnerability fixing commits vfcs .
an exem plary vfc and its respective vcc are shown in fig.
.
vfcsdelete modify or add code to eliminate an sv e.g.
disablingexternal entities processing in the xml library in fig.
andcan be found in bug sv tracking systems.
then vccs arecommits that last touched the code changes in vfcs.
our workalso leverages vfcs to obtain vccs for building automatedcommit level sv assessment models.
b. commit level sv assessment with cvss common vulnerability scoring system cvss has been an expert maintained standard for sv assessment.
cvss base metrics are prevalently used to determine through whichattack vectors svs can be exploited and assess their potentialimpacts.
this allows developers to better plan and prioritizethe mitigation of such svs.
the base metrics are confidentiality integrity availability access v ector access complexity authentication and severity.
we use cvss version of base metrics to assess svs as version is still more predominantlyused than version introduced in .
svs before 2015are also still relevant in the modern context e.g.
cve discovered in was exploited in a cryptoattack in .
based on cvss version the vcc cve in fig.
has a considerable impact on theconfidentiality.
this sv can be exploited with low access complexity with no authentication via public network accessv ector making it an attractive target for attackers.
despite the criticality of these svs there have been delays in reporting assessing and fixing them.
concretely the vcc infig.
required and days to be reported 1and fixed in vfc respectively.
existing sv assessment methods basedon bug sv reports e.g.
would need to wait morethan days for the report of this sv .
however performingsv assessment right after this commit was submitted canbypass the waiting time for sv reports enabling developersto realize the exploitability impacts of this sv and plan to fixit much sooner.
to the best of our knowledge there has notbeen any study on automated commit level sv assessment i.e.
assigning seven cvss base metrics to a vcc.
our workidentifies and aims to bridge this important research gap.
!
.
fig.
.
workflow of deepcv a for automated commit level sv assessment.
the vcc is the one described in fig.
.
c. feature extraction from commit code changes the extraction of commit features is important for building commit level sv assessment models.
many existing commitlevel defect sv prediction models have only considered com mit code changes e.g.
.
however we arguethat the nearby context of code changes also contributesvaluable information to the prediction.
for instance the sur rounding code of the changes in fig.
provides extra details e.g.
the method return statement is modified and the returntype is xmlinputfactory.
such a type can help learn patterns of xxe sv that usually occurs with xml processing.
besides the context we speculate that sv assessment models can also benefit from the relatedness among the assessmenttasks.
for example the xxe sv in fig.
allows attack ers to read arbitrary system files which mainly affects theconfidentiality rather than the integrity and availability of asystem.
this work investigates the possibility of incorporatingthe common features of seven cvss metrics into a singlemodel using the multi task learning paradigm insteadof learning seven cumulative individual models.
specifically multi task learning leverages the similarities and the interac tions of the involved tasks through a shared feature extractor topredict all the tasks simultaneously.
such a unified model cansignificantly reduce the time and resources to train optimizeand maintain update the model in the long run.
iii.
t hedeep cv a m odel we propose deepcv a see fig.
a novel deep learning model to automate commit level vulnerability assessment.
deepcv a is a unified and end to end trainable model thatconcurrently predicts seven cvss metrics i.e.
confidential ity integrity availability access v ector access complexity authentication and severity for a vulnerability contributingcommit vcc .
deepcv a contains i preprocessing context extraction and tokenization of code commits section iii a ii feature extraction from commits shared by seven assess ment tasks using attention based convolutional gated recurrentunits section iii b and iii simultaneous prediction of sevencvss metrics using multi task learning section iii c .to assign the cvss metrics to a new vcc with deepcv a we first preprocess the commit obtain its code changes andrespective context and tokenize such code changes context.embedding vectors of preprocessed code tokens are thenobtained and the commit feature vector is extracted using thetrained feature extractor.
this commit feature vector passesthrough the task specific blocks and softmax layers to getthe seven cvss outputs with the highest probability values.details of each component are given hereafter.
a. commit preprocessing context extraction tokenization to train deepcv a we first obtain and preprocess code changes hunks and extract the context of such changes.
we then tokenize them to prepare inputs for feature extraction.commit preprocessing.
preprocessing helps remove noise incode changes and reduce computational costs.
we removenewlines spaces and inline multi line comments since they donot change code functionality.
we do not remove punctuations e.g.
and stop words e.g.
and or operators to preserve code syntax.
we also do not lowercase codetokens since developers can use case sensitivity for namingconventions of different token types e.g.
variable name system vs. class name system .
stemming i.e.
reducing a word to its root form such as equals toequal i s not applied to code since different names can change codefunctionality e.g.
the built in equals function in java .
context extraction algorithm.
we customize sahal etal.
s closest enclosing scope ces to identify the context of vulnerable code changes for commit level sv assessment see section ii c .
sahal et al.
defined an enclosingscope to be the code within a balanced amount of openingand closing curly brackets such as if switch while for blocks.
among all enclosing scopes of a hunk the one withthe smallest size lines of code is selected as ces to reduceirrelevant code.
sahal et al.
found ces usually containshunk related information e.g.
variable values types preceding 719public class plainnegotiator implements saslnegotiator ... private static final string utf8 standard charsets.utf 8.name private static final charset utf8 standard charsets.utf 8 ... end of the plainnegotiator class fig.
.
code changes outside of a method from the commit 4b9fb37 in the apache qpid broker j project.
changes .
ces also alleviates the need for manually predefining the context size as in .
some existing studies e.g.
only used the method function scope butcode changes may occur outside of a method.
for instance changes in fig.
do not have any enclosing method but wecan still obtain its ces i.e.
the plainnegotiator class.
there are still two main limitations with the definition of ces in .
firstly a scope e.g.
for while in java with single line content does not always require curly brackets.secondly some programming languages do not use curlybrackets to define scopes like python.
to address these twoissues we utilize abstract syntax tree ast depth firsttraversal see algorithm to obtain cess of code changes as ast covers the syntax of all scope types and generalizesto any programming languages.
algorithm contains i the extract scope function for extracting potential scopes of a code hunk lines and ii the main code to obtain the ces of every hunk in a commit lines .
the extract scope function leverages depthfirst traversal with recursion to go through every node in anast of a file.
line adds the selected part of an ast to thelist of potential scopes potential scopes of the currenthunk.
the first root ast is always valid since it encompassesthe whole file.
line then checks whether each node sub tree of the current ast has one of the following types class interface enum method if else switch for while do try catch and is surrounding the current hunk.
if the conditions are satisfied the extract scope function would be called recursively in line until a leafof the ast is reached.
the main code starts to extract themodified files of the current commit in line .
for each file we extract code hunks code deletions additions in line andthen obtain the ast of the current file using an ast parser inline .
line calls the defined extract scope function to generate the potential scopes for each hunk.
among theidentified scopes line adds the one with the smallest size i.e.
the number of code lines excluding empty lines andcomments to the list of cess all ces .
finally line 18of algorithm returns all the cess for the current commit.
we treat deleted pre change added post change code changes and their cess as four separate inputs to be vectorizedby the shared input embedding as illustrated in fig.
.
foreach input we concatenate all the hunks cess in all the af fected files of a commit to explicitly capture their interactions.
code aware tokenization.
the four inputs extracted from a commit are then tokenized with a code aware tokenizer toalgorithm ast based extraction of the closest enclosing scopes cess of commit code changes.
input current vulnerability contributing commit vcc commit scope type scope types output cess of code changes in the current commit allces 1function extract scope ast hunk visited global potential scopes potential scopes potential scopes ast visited visited ast foreach node ast do ifnode visited and type node scope types and start node start hunk andend node end hunk then extract scope ast hunk visited return 9files extract files commit 10allces 11foreach fi files do hunks extract hunk commit f i ast i extract ast f i foreach hi hunks do potential scopes extract scopes ast i hi allces allces a r g m i n size potential scopes 18return allces preserve code semantics and help prediction models be moregeneralizable.
for example a andb are tokenized as a band explicitly giving a model the information about oneincrement operator .
tokenized code is fed into a shareddeep learning model namely attention based convolutionalgated recurrent unit ac gru to extract commit features.
b. feature extraction with deep ac gru deep ac gru has a three way convolutional neural network to extract n gram features and attention based gated recurrent units to capture dependencies among code changes and their context.
this feature extractor is shared by four inputs i.e.
deleted added code hunks context.
each input hasthe size of n l where nis the no.
of code tokens and lis the vector length of each token.
all inputs are truncated or padded to the same length nto support parallelization.
the feature vector of each input is obtained from a sharedinput embedding layer that maps code tokens into fixed length arithmetic vectors.
the dimensions of this embedding layerare v l where v is the code vocabulary size and its parameters are learned together with the rest of the model.
three way convolutional neural network.
we use a shared three way convolutional neural network cnn to ex tract n grams n of each input vector.
the three way cnn has filters with three sizes of one three and five respectively to capture common code patterns e.g.
public class integer.
the filters are randomly initialized andjointly learned with the other components of deepcv a. wedid not include grams and grams to reduce the requiredcomputational resources without compromising the modelperformance which has been empirically demonstrated insection v b. to generate code features of different windowsizes with the three way cnn we multiply each filter withthe corresponding input rows and apply non linear reluactivation function i.e.
relu x m a x x .w e 720repeat the same convolutional process from the start to the end of an input vector by moving the filters down sequentiallywith a stride of one.
this stride value is the smallest and helpscapture the most fine grained information from input code ascompared to larger values.
each filter size returns feature mapsof the size n k f wherekis the filter size one three or five and fis the number of filters.
multiple filters are used to capture different semantics of commit data.
attention based gated recurrent unit.
the feature maps generated by the three way cnn sequentially enter a gatedrecurrent unit gru .
gru defined in eq.
is anefficient version of recurrent neural networks and used toexplicitly capture the order and dependencies between codeblocks.
for example the return statement comes after the function declarations of the vcc in fig.
.
z t wzxt uzht bz rt wrxt urht br ht tanh w hxt uh rt ht b h ht zt ht zt ht wherewz wr wh uz ur uhare learnable weights bz br bhare learnable biases is element wise multiplication is sigmoid function and tanh is hyperbolic tangent function.
to determine the information h t at each token time step t gru combines the current input xt and the previous time step h t using the update zt and reset rt gates.
htis then carried on to the next token until the end of the input tomaintain the dependencies of the whole code sequence.
the last token output of gru is often used as the whole sequence representation yet it suffers from the information bottleneck problem especially for long sequences.
to address this issue we incorporate the attention mechanism into gru to explicitly capture the contribution of each inputtoken as formulated in eq.
.
out attention m summationdisplay i 1wihi wi softmax w stanh w ahi ba exp w stanh w ahi ba m summationtext j 1exp w stanh w ahj ba wherewiis the weight of hi ws waare learnable weights bais learnable bias and mis the number of code tokens.
the attention based outputs out attention of the three grus see fig.
are concatenated into a single featurevector to represent each of the four inputs pre post changehunks contexts .
the commit feature vector is a concatenationof the vectors of all four inputs generated by the shared ac gru feature extractor.
this feature vector is used for multi task prediction of seven cvss metrics.
c. commit level sv assessment with multi task learning this section describes the multi task learning layers of deepcv a for efficient commit level sv assessment using a single model as well as how to train the model end to end.multi task learning layers.
the last component of deepcv aconsists of the multi task learning layers that simultaneouslygive the predicted cvss values for seven sv assessmenttasks.
as illustrated in fig.
this component contains twomain parts task specific blocks and softmax layers.o nt o p of the shared features extracted by ac gru task specificblocks are necessary to capture the differences among theseven tasks.
each task specific block is implemented using afully connected layer with non linear relu activations .specifically the output vector task i of the task specific block for assessment task iis defined in eq.
.
task i relu w txcommit bt wherexcommit is the commit feature vector from ac gru wtis learnable weights and btis learnable bias.
each task specific vector goes through the respective softmax layer to determine the output of each task with the highestpredicted probability.
the prediction output pred i of task i is given in eq.
.
pred i a r g m a x prob i prob i softmax w ptask i bp softmax z j exp z j nlabels i summationtext c 1exp z c whereprobicontains the predicted probabilities of nlabels i possible outputs of task i wpis learnable weights and bpis learnable bias.
training deepcv a. to compare deepcv a s outputs with ground truth cvss labels we define a multi task loss thataverages the cross entropy losses of seven tasks in eq.
.
loss deepcv a summationdisplay i 1loss i loss i nlabels i summationdisplay c 1yc ilog probc i yc i ifcis true class else whereyc i probc i andnlabels iare the ground truth value predicted probability and all labels of cvss task i respectively.
we minimize this multi task loss using a stochastic gradient descent method to optimize the weights of learnable components in deepcv a. we also use backpropagation to automate partial differentiation with chain rule and increasethe efficiency of gradient computation throughout the model.
iv .
e xperimental design and setup all the experiments ran on a computing cluster that has cpu cores with 16gb of ram and tesla v100 gpu.
a. datasets to develop commit level sv assessment models we built a dataset of vulnerability contributing commits vccs and their cvss metrics.
we used vulnerability fixing commits vfcs to retrieve vccs as discussed in section ii a. .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.7confidentialityintegrity availabilityaccess vectoraccess complexityauthenticationseverity0 completepartialnone completepartialnone completepartialnone networklocal highmediumlow singlenone highmediumlowpercentage fig.
.
class distributions of seven sv assessment tasks.
vfc identification.
we first obtained vfcs from three public sources nvd github and its advisory database2as well as a manually curated verified vfc dataset vulasdb .
intotal we gathered vfcs that had dates ranging fromjuly to october .
we selected vfcs in java projectsas java has been commonly investigated in the literature e.g.
and also in the top five most popularlanguages in practice.
3following the practice of we discarded vfcs that had more than files and linesof code to reduce noise in the data.
vcc identification with the szz algorithm.
after the filtering steps we had remaining unique vfcs to identifyvccs using the szz algorithm .
this algorithm selectscommits that last modified the source code lines deleted ormodified to address an sv in a vfc as the respective vccsof the same sv see fig.
.
as in we first discardedcommits with timestamps after the published dates of therespective svs on nvd since svs can only be reportedafter they were injected in a codebase.
we then removedcosmetic changes e.g.
newlines and white spaces and single line multi line comments in vfcs since these elements do notchange code functionality .
like we also consideredcopied or renamed files while tracing vccs.
we obtained1 unique vccs 4of svs in real world java projects and their corresponding expert verified cvss metricson nvd.
distributions of curated cvss metrics are illustratedin fig.
.
the details of the number of commits and projectsretained in each filtering step are also given in table i. notethat some commits and projects were removed during thetracing of vccs from vfcs due to the issues coined as ghostcommits studied by rezk et al.
.
we did not removelarge vccs with more than files and 10k lines aswe found several vccs were large initial first commits.
our 4the sv reports of all curated vccs were not available at commit time.table i t he number of commits and projects after each filtering step .
no.
filtering step no.
of commits no.
of projects all unfiltered vfcs removing duplicate vfcs removing non java vfcs 4removing vfcs with more than files 10k lines1 5tracing vccs from vfcs usingthe szz algorithm3 6removing vccs with nullcharacteristics cvss values removing duplicate vccs fig.
.
time based splits for training validating testing.
observations agreed with the findings of meneely et al.
.
manual vcc validation.
to validate our curated vccs we randomly selected samples i.e.
confidence leveland error for two authors to independently examine.the manual vcc validation was considerably labor intensive which took approximately man hours.
the cohen s kappa inter rater reliability score was .
i.e.
almostperfect agreement .
we also involved the third authorin the discussion to resolve disagreements.
our validationfound that of the vccs were valid.
in fact the szzalgorithm is imperfect but we assert that it is nearlyimpossible to obtain near accuracy without exhaustivemanual validation.
specifically the main source of incorrectlyidentified vccs in our dataset was that some files in vfcswere used to update version documentation or address anotherissue instead of fixing an sv .
one such false positive vcc wasthe commit 87c89f0 in the jspwiki project that last modified the build version in the corresponding vfc.
data splitting.
we adopted time based splits for training validating and testing the models to closely represent realworld scenarios where incoming future unseen data is not present during training .
we trained validated andtested the models in rounds using equal folds split basedon commit dates see fig.
.
specifically in round i folds i i andi were used for training validation and testing respectively.
we chose an optimal model with thehighest average validation performance and then reported its respective average testing performance over rounds whichhelped avoid unstable results of a single testing set .
b. evaluation metrics to evaluate the performance of automated commit level sv assessment we utilized the f1 score and matthews correlation coefficient mcc metrics that have been commonlyused in the literature e.g.
.
these two metricsare suitable for the imbalanced classes in our data seefig.
.
f1 score has a range from to while mcc takes 722values from to where is the best value for both metrics.
mcc was used to select optimal models since mcc explicitlyconsiders all classes .
to evaluate the tasks with more thantwo classes we used macro f1 score and the multi classversion of mcc .
mcc of the multi task deepcv a modelwas the average mcc of seven constituent tasks.
note thatmcc is not directly proportional to f1 score.
c. hyperparameter and training settings of deepcva hyperparameter settings.
we used the average validation mcc to select optimal hyperparameters for deepcv a s components.
we also ran deepcv a times each round to reducethe impact of random initialization on model performance.we first chose for the input length of the pre post change hunks context see fig.
which has been commonlyused in the literature e.g.
.
using a shorter inputlength would likely miss many code tokens while a longerlength would significantly increase the model complexity andtraining time.
shorter commits were padded with zeros andlonger ones were truncated to ensure the same input size forparallelization with gpu .
we built a vocabulary of10k most frequent code tokens in the input embedding layer assuggested by .
note that using 20k sized vocabulary onlyraised the performance by yet increased the model com plexity by nearly two times.
we selected an input embeddingsize of i.e.
a standard and usually high limit value formany embedding models e.g.
and we randomlyinitialized embedding vectors .
for the number offilters of the three way cnn as well as the hidden units ofthe gru attention and task specific blocks we tried similar to .
we picked as it had at least better validation performance than and .
training settings.
we used the adam algorithm the state of the art stochastic gradient descent method for trainingdeepcv a end to end with a learning rate of .
and abatch size of as recommended by hoang et al.
.
toincrease the training stability we employed dropout witha dropout rate of .
and batch normalization betweenlayers.
we trained deepcv a for epochs and we wouldstop training if the validation mcc did not change in the last five epochs to avoid overfitting .
d. baseline models we considered three types of learning based baselines for automated commit level sv assessment as learning based models can automatically extract relevant sv patterns featuresfrom input data for prediction without relying on pre definedrules.
the baselines were i s cv a supervised singletask model using either software metrics or text based fea tures including bag of words bow or token count andword2vec ii x cv a supervised extreme multi class model that performed a single prediction for all seven tasksusing the above feature types and iii u cv a unsupervised model using k means clustering with the same features as s cv a x cv a. note that there was no existing techniquefor automating commit level sv assessment so we could onlycompare deepcv a with the compatible techniques proposedfor related tasks as described hereafter.
software metrics e.g.
and text based features bow word2vec e.g.
have been widelyused for commit level prediction.
we used software metricsproposed by for defect sv prediction.
amongthese metrics we converted c c keywords into java onesto match our dataset.
the list of software metrics used inthis work can be found at .
as in in each round infig.
we also removed correlated software metrics that hada spearman correlation larger than .
based on the trainingdata of that round to avoid performance degradation e.g.
no.ofstars vs. forks of a project.
for bow and word2vec we adopted the same vocabulary size of 10k to extract featuresfrom four inputs described in fig.
as in deepcv a. featurevectors of all inputs were concatenated into a single vector.for word2vec we averaged the vectors of all tokens in aninput to generate its feature vector which has been shown tobe a strong baseline .
like deepcv a we also used anembedding size of for each word2vec token.
using these feature types s cv a trained a separate supervised model for each cvss task while x cv a used a singlemulti class model to predict all seven tasks simultaneously.x cv a worked by concatenating all seven cvss metricsinto a single label.
to extract the results of the individualtasks for x cv a we checked whether the ground truth labelof each task was in the concatenated model output.
for s cv a and x cv a we applied six popular classifiers logisticregression lr support v ector machine svm k nearestneighbors knn random forest rf xgboost xgb and light gradient boosting machine lgbm .
theseclassifiers have been used for sv assessment based on sv re ports .
the hyperparameters for tuning these classifierswere regularization l1 l2 regularization coefficient .
.
for lr and .
.
for svm no.
of neighbors distance norm and distance weight uniform distance for knn no.
of estimators max.
depth unlimited max.
no.
of leaf nodes unlimited for rf xgb and lgbm.
these hyperparameters have been adapted from relevant studies .
unlike s cv a and x cv a u cv a did not require cvss labels to operate therefore u cv a required less human effortthan s cv a and x cv a. we tuned u cv a for each task withthe following no.
of clusters k .
to assess a new commitwith u cv a we found the cluster with the smallest euclideandistance to that commit and assigned it the most frequent classof each task in the selected cluster.
v. r esearch questions and experimental results a.rq1 how does deepcva perform compared to baseline models for commit level sv assessment?
motivation.
we posit the need for commit level software vulnerability sv assessment tasks based on seven cvss 723table ii t esting performance of deep cv a and baseline models .notes o ptimal classifiers of s cv a x cv a and optimal cluster no.
k ofu cv a are in parentheses .b ow w2v and sm are bag of w ords w ord 2vec and softw are metrics respectively .the best performance of deep cv a is from the run with the highest mcc in each round .b est row wise v alues are in grey .
cvss metricevaluation metricmodel s cv a x cv a u cv a deepcv a best in parentheses bow w2v sm bow w2v sm bow w2v sm confidentialityf1 score .
.
.
.
.
.
.
.
.
.
.
mcc0.
lr .
lgbm .
xgb .
lr .
lr .
xgb .
.
.
.
.
integrityf1 score .
.
.
.
.
.
.
.
.
.
.
mcc0.
lgbm .
lgbm .
rf .
lgbm .
lr .
lgbm .
.
.
.
.
availabilityf1 score .
.
.
.
.
.
.
.
.
.
.
mcc0.
rf .
lgbm .
xgb .
lr .
lr .
xgb .
.
.
.
.
access vectorf1 score .
.
.
.
.
.
.
.
.
.
.
mcc0.
xgb .
lr .
lr .
lgbm .
lr .
lgbm .
.
.
.
.
access complexityf1 score .
.
.
.
.
.
.
.
.
.
.
mcc0.
lr .
xgb .
lgbm .
lr .
xgb .
svm .
.
.
.
.
authenticationf1 score .
.
.
.
.
.
.
.
.
.
.
mcc0.
svm .
xgb .
lgbm .
rf .
svm .
xgb .
.
.
.
.
severityf1 score .
.
.
.
.
.
.
.
.
.
.
mcc0.
lr .
xgb .
xgb .
lr .
lgbm .
xgb .
.
.
.
.
averagef1 score .
.
.
.
.
.
.
.
.
.
.
mcc .
.
.
.
.
.
.
.
.
.
.
metrics.
such tasks help developers to understand the exploitability and impacts of svs as early as they are introducedin a system and devise remediation plans accordingly.
rq1evaluates our deepcv a for this new and important task.
method.
we compared the effectiveness of our deepcv a model with the s cv a x cv a and u cv a baselines seesection iv d on the testing sets.
we trained validated and tested the models using the time based splits as described insection iv a. because of the inherent randomness of gpu based implementation of deepcv a 5we ran deepcv a times in each round and then averaged its performance.
thebaselines were not affected by this issue as they did notuse gpu.
for deepcv a we used the hyperparameter trainingsettings in section iv c. for each type of baseline we usedgrid search on the hyperparameters given in section iv d tofind the optimal model with the highest validation mcc see section iv b .
results.
deepcva outperformed all baselines x cva scva and u cva in terms of both mcc and f1 score7 for all seven tasks see table ii .
deepcv a got average and best mcc values of .
and .
i.e.
and .
better than the second best baseline x cv a with word2vecfeatures respectively.
task wise deepcv a had .
.
.
.
.
and .
higher mcc than thebest respective baseline models for confidentiality integrity availability access v ector access complexity authentica tion and severity tasks respectively.
notably the best deep cv a model achieved stronger performance than all baselineswith mcc percentage gaps from .
confidentiality to82.
access complexity .
the average and task wise f15 started faq how can i obtain reproducible resultsusing keras during development 6mcc values of random and most frequent class baselines were all .
.
7precision .
recall .
of deepcv a were than all baselines.score values of deepcv a also beat those of the best baseline x cv a with word2vec features by substantial margins.we found that deepcv a significantly outperformed the bestbaseline models in terms of both mcc and f1 score averagingacross all seven tasks confirmed with p values .
using the non parametric wilcoxon signed rank tests .
theseresults show the effectiveness of the novel design of deepcv a. an example to qualitatively demonstrate the effectiveness of deepcv a is the vcc ff655ba in the apache xerces2 j project in which a hashing algorithm was added.
this algorithm waslater found vulnerable to hashing collision that could be ex ploited with timing attacks in the fixing commit 992b5d9.
this sv was caused by the order of items being added to the hashtable in the put string key int value function.
such an order could not be easily captured by baseline modelswhose features did not consider the sequential nature of code i.e.
bow word2vec and software metrics .
more detailsabout the contributions of different components to the overallperformance of deepcv a are covered in section v b. regarding the baselines the average mcc value .
of x cv a was on par with that .
of s cv a. this resultreinforces the benefits of leveraging the common attributesamong seven cvss metrics to develop effective commit levelsv assessment models.
however x cv a was still not asstrong as deepcv a mainly because of its much lower trainingdata utilization per output.
for x cv a there was an averageof output combinations of cvss metrics in the trainingfolds i.e.
commits per output.
in contrast deepcv a had13.
times more data per output as there were at most threeclasses for each task see fig.
.
finally we found supervisedlearning s cv a x cv a and deepcv a to be at least .
more effective than the unsupervised approach u cv a .
thisresult demonstrates the usefulness of using cvss metrics toguide the extraction of commit features.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
confidentiality integrity availability access vector access complexity authentication severitymcc difference with respect to deepcva no context .
ast inputs .
ngrams only .
no attention based gru .
no three way cnn .
no attention mechanism .
no task specific blocks .
no multi task learning .
fig.
.
differences of testing mcc multiplied by for readability of the model variants compared to the proposed deepcv a in section iii.
note the average mcc values without multiplying by of the model variants are in parentheses.
b.rq2 what are the contributions of the main components in deepcva to model performance?
motivation.
we have shown in rq1 that deepcv a significantly outperformed all the baselines for seven commit level sv assessment tasks.
rq2 aims to give insights intothe contributions of the key components to such a strongperformance of deepcv a. such insights can help researchersand practitioners to build effective sv assessment models.
method.
we evaluated the performance contributions of the main components of deepcv a i closest enclosing scope ces of code changes ii cnn filter size iii three waycnn iv attention based gru v attention mechanism vii task specific blocks and vi multi task learning.
for each component we first removed it from deepcv a retrained themodel variant and reported its testing result.
when we removed attention based gru we used max pooling after the three way cnn to generate the commit vector.
whenwe removed multi task learning we trained a separate modelfor each of the seven cvss metrics.
we also investigated anabstract syntax tree ast variant of deepcv a in whichwe complemented input code tokens with their syntax e.g.
i n ta is avariabledeclarationstatement where ais an identifier and1is anumberliteral .
this ast based variant explored the usefulness of syntacticalinformation for commit level sv assessment.
we extracted thenodes in an ast that contained code changes and their ces.if more than two nodes contained the code of interest wechose the one at a lower depth in the ast.
we then flattenedthe nodes with depth first traversal for feature extraction .
results.
as depicted in fig.
the main components 8uplifted the average mcc of deepcva by .
for seven tasks.
note that model variants except the model with noattention mechanism outperformed the best baseline modelfrom rq1.
these results were confirmed with p values .
using wilcoxon signed rank tests .
specifically thecomponents 8of deepcv a increased the mcc values by .
.
.
.
.
.
and .
for 8we excluded the deepcv a variant with no attention mechanism as its performance was abnormally low affecting the overall trend of other variants.confidentiality integrity availability access v ector accesscomplexity authentication and severity respectively.
for the inputs using the smallest enclosing scope ces of code changes resulted in a .
increase in mcc comparedto using hunks only while using ast inputs had .
lowerperformance.
this finding suggests that code context is im portant for assessing svs in commits.
in contrast syntacticalinformation is not as necessary since code structure can beimplicitly captured by code tokens and their sequential orderusing our ac gru.
the key components of the ac gru feature extractor boosted the performance by .
grams vs. grams .
attention based gru .
three way cnn and142 attention .
note that deepcv a surpassed the state of the art gram and gram cnn only architecturesfor commit level sv defect prediction.
these results showthe importance of combining the gram three way cnnwith attention based grus rather than using them individually.we also found that grams did not significantly increasethe performance p value .
confirming our decision insection iii b to only use sized filters.
for the prediction layers we raised .
and .
mcc of deepcv a with task specific blocks and multi task learn ing respectively.
multi task deepcv a took s .
hours and .
s to train validate and test in rounds runs which were .
and .
times faster compared to those of sevensingle task deepcv a models respectively.
deepcv a wasonly .
and .
slower in training validating and testingthan one single task model on average respectively.
thesevalues highlight the efficiency of training and maintaining themulti task deepcv a model.
finally obtaining severity usingthe cvss formula from the predicted values of the othersix metrics dropped mcc by .
for this task.
this resultsupports predicting severity directly from commit data.
c.rq3 what are the effects of class rebalancing techniques on model performance?
motivation.
recent studies e.g.
have shown that class rebalancing techniques i.e.
equalizing the class distribu tions in the training set can improve model effectiveness fordefect sv prediction.
however these rebalancing techniques 725can only be applied to single task models not multi task ones.
the reason is that each task has a unique class distribution see fig.
and thus balancing class distribution of one taskwill not balance classes of the others.
rq3 is important totest whether multi task deepcv a still outperforms single taskbaselines in rq1 rq2 using rebalancing techniques.
method.
we compared the testing performance of multi task deepcv a with baselines in rq1 rq2 using two popular oversampling techniques random oversampling ros and smote .
ros randomly duplicates the existing samples of minority classes while smote randomly generatessynthetic samples between the existing minority class samplesand their nearest neighbor s based on euclidean distance.
wedid not consider undersampling as such models performedpoorly because of some very small minority classes e.g.
low access complexity had only samples .
we applied ros and smote to only the training set and then optimized all baseline models again.
like we also tuned smoteusing grid search with different values of nearest neighbors .
we could not apply smote to single taskdeepcv a as features were trained end to end and unavailableprior training for finding nearest neighbors.
we also did notapply smote to x cv a as there was always a single sampleclass in each round producing no nearest neighbor.
results.
ros and smote increased the average performance mcc of baselines except x cva see table iii .
however the average mcc of our multi task deepcvawas still .
higher than that of the best oversampling augmented baseline single task deepcva with ros .o v e r all mcc increased by .
and .
for s cv a ros s cv a smote and single task deepcv a ros respectively.
these improvements were confirmed significantwith p values .
using wilcoxon signed rank tests .
we did not report oversampling results of u cv a as theywere still much worse compared to others.
we found single task deepcv a benefited the most from oversampling prob ably since deep learning usually performs better with moredata .
in contrast oversampling did not improve x cv aas oversampling did not generate as many samples for x cv aper class as for s cv a i.e.
x cv a had times on average more classes than s cv a .
these results further strengthen theeffectiveness and efficiency of multi task learning of deepcv afor commit level sv assessment even without the overheadsof rebalancing oversampling data.
vi.
d iscussion a. deepcva and beyond deepcv a has been shown to be effective for commit level sv assessment in the three rqs but our model still has falsepositives.
we analyze several representative patterns of suchfalse positives to help further advance this task and solutionsfor researchers and practitioners.
some commits were too complex and large to be assessed correctly.
for example the vcc 015f7ef in the apache spark project contained additions and deletions across 29files whereas the untrusted deserialization sv occurred in justtable iii t esting performance mcc of optimal baselines using oversampling techniques and multi task deep cv a. note denotes tha t the oversampled models outperformed the non oversampled one reported in rq1 rq2.
cvss tasks cv a ros s cv a smote x cv a ros single task deepcv a ros multi task deepcv a confidentiality .
.
.
.
.
integrity .
.
.
.
.
availability .
.
.
.
.
access vector .
.
.
.
.
access comp.
.
.
.
.
.
authentication .
.
.
.
.
severity .
.
.
.
.
average .
.
.
.
.
one line in launcherconnection.java.
recent techniques e.g.
can pinpoint more precise locations e.g.
individual files or lines in commits of defects.
suchtechniques can be adapted to remove irrelevant code in vccs i.e.
changes that do not introduce or contain svs .
morerelevant code potentially gives more fine grained informationfor the sv assessment tasks.
note that deepcv a provides astrong baseline for comparing against fine grained approaches.
deepcv a also struggled to predict assessment metrics for svs related to external libraries.
for instance the sv in the commit 015f7ef above occurs with the objectinputstream class from the java.io package which sometimes prevented deepcv a from correctly assess ing an sv .
if an sv happens frequently with a package inthe training set e.g.
the xml library of the vcc bba4bc2 in fig.
deepcv a still can infer correct cvss metrics.pre trained code models on large corpora along with methods to search generate code and doc umentation as well as sv related information fromdeveloper q a forums can be investigated to provideenriched context of external libraries which would supportmore reliable commit level sv assessment with deepcv a. we also observed that deepcv a alongside the considered baseline models performed significantly worse in terms ofmcc for access v ector compared to the remaining tasks seetable ii .
we speculate that such low performance is mainlybecause access v ector contains the most significant classimbalance among the tasks as shown in fig.
.
for single task models we found that using class rebalancing techniquessuch as ros or smote can help improve the performance as demonstrated in rq3 see section v c .
however it is stillunclear how to apply the current class rebalancing techniquesfor multi task learning models such as deepcv a. thus wesuggest that more future work should investigate specificclass rebalancing and or data augmentation to address suchimbalanced data in the context of multi task learning.
b. threats to v alidity the first threat is the collection of vccs.
we followed the practices in the literature to reduce the false positives of the szz algorithm.
we further mitigated this threat by performingindependent manual validation with three of the authors.
another concern is the potential suboptimal tuning of baselines and deepcv a. however it is impossible to try the entire 726hyperparameter space within a reasonable amount of time.
for the baseline models we lessened this threat by usinga wide range of hyperparameters from the previous studiesto reoptimize these models from scratch on our data.
fordeepcv a we adapted the best practices recommended in therelevant literature to our tasks.
the reliability and generalizability of our findings are also potential threats.
we ran deepcv a times to mitigate theexperimental randomness.
we confirmed our results using non parametric statistical tests with a confidence level .
our results may not generalize to all software projects.
however we reduced this threat by conducting extensive experimentson real world projects of different scales and domains.
vii.
r ela ted work a. data driven sv prediction and assessment public security databases like nvd and expert based sv scoring frameworks like cvss have provided large scaledata to determine different characteristics of svs.
bozorgi etal.
pioneered this area by developing a support v ectormachine model to predict when svs would be exploited.
afterthat sv information on nvd has been utilized to infer thetypes severity level and exploitability of svs.recently many studies have used data driven techniques to obtain various cvss metrics for svassessment from sv reports on nvd.
other studies have leveraged code patterns in fixing commits of third partylibraries to assess svs in such libraries.
our work is funda mentally different from these previous studies since we arethe first to investigate the potential of performing assessmentof all sv types not only vulnerable libraries using commitchanges rather than bug sv reports fixes.
our approach allowspractitioners to realize the exploitability impacts of svs intheir systems much earlier e.g.
up to days before seesection ii b as compared to using bug sv reports fixes.
lessdelay in sv assessment helps practitioners to plan prioritizesv fixing with fresh design and implementation in theirminds.
moreover we have shown that multi task learning i.e.
predicting all cvss metrics simultaneously can significantlyincrease the effectiveness and reduce the model developmentand maintenance efforts in commit level sv assessment.
b. sv analytics in code changes commit level prediction e.g.
has been explored to provide just in time information for developers about code issues but such studies mainly focused on generic software defects.
however sv is a special type of defects that can threaten the security properties of a software project.thus sv requires special treatment and domain knowl edge .
meneely et al.
and bosu et al.
conductedin depth studies on how code and developer metrics affectedthe introduction and review of vccs.
besides analyzing thecharacteristics of vccs other studies alsodeveloped commit level sv detection models that leveragedsoftware and text based metrics.
different from the previousstudies that have detected vccs we focus on the assessmentof such vccs.
sv assessment is as important as the detectionstep since assessment metrics help early plan and prioritizeremediation for the identified svs.
it is worth noting that theexisting sv detection techniques can be used to flag vccsthat would then be assessed by our deepcv a model.
viii.
c onclusions and future work we introduce deepcv a a novel deep multi task learning model to tackle a new task of commit level sv assessment.deepcv a promptly informs practitioners about the cvssseverity level exploitability and impact of svs in codechanges after they are committed enabling more timely andinformed remediation.
deepcv a substantially outperformedmany baselines even the ones enhanced with rebalanced data for the seven commit level sv assessment tasks.
notably multi task learning utilizing the relationship of assessmenttasks helped our model be .
more effective and .
timesmore efficient than single task models.
with the reported per formance deepcv a realizes the first promising step towardsa holistic solution to assessing svs as early as they appear.
we plan to extend deepcv a to other programming languages and different sv assessment metrics to make the modeleven more practical for developers.
we also aim to investigatedeepcv a for sv detection and fixing tasks to provide an all in one solution for practitioners to detect assess and fix svs.
a cknowledgments the work was supported by the cyber security research centre limited whose activities are partially funded by theaustralian government s cooperative research centres pro gramme.
this work was supported with supercomputing re sources provided by the phoenix hpc service at the uni versity of adelaide.
we would also like to sincerely thankthe members from the centre for research on engineeringsoftware technologies crest faheem chadni bushra mubin and huaming as well as the anonymous reviewers forthe insightful and constructive comments to improve the paper.
r eferences s. khan and s. parkinson review into state of the art of vulnerability assessment using artificial intelligence in guide to vulnerability analysis for computer networks and systems.
springer pp.
.
v .
smyth software vulnerability management how intelligence helps reduce the risk network security vol.
no.
pp.
.
first common vulnerability scoring system.
.
available a. feutrill d. ranathunga y .
yarom and m. roughan the effect of common vulnerability scoring system metrics on vulnerability exploit delay in sixth international symposium on computing and networking candar .
ieee pp.
.
a. lamkanfi s. demeyer e. giger and b. goethals predicting the severity of a reported bug in 7th ieee working conference on mining software repositories msr .
ieee pp.
.
z. han x. li z. xing h. liu and z. feng learning to predict severity of software vulnerability using only vulnerability description in ieee international conference on software maintenance and evolution icsme .
ieee pp.
.
g. spanos and l. angelis a multi target approach to estimate software vulnerability characteristics and severity scores journal of systems and software vol.
pp.
.
t. h. m. le b. sabir and m. a. babar automated software vulnerability assessment with concept drift in ieee acm 16th international conference on mining software repositories msr pp.
.
t. h. le h. chen and m. a. babar a survey on data driven software vulnerability assessment and prioritization arxiv preprint arxiv .
.
nist national vulnerability database.
.
available https nvd.nist.gov a. meneely h. srinivasan a. musa a. r. tejeda m. mokary and b. spates when a patch goes bad exploring the properties of vulnerability contributing commits in acm ieee international symposium on empirical software engineering and measurement.ieee pp.
.
t. hoang h. k. dam y .
kamei d. lo and n. ubayashi deepjit an end to end deep learning framework for just in time defect prediction in2019 ieee acm 16th international conference on mining software repositories msr .
ieee pp.
.
y .
kamei e. shihab b. adams a. e. hassan a. mockus a. sinha and n. ubayashi a large scale empirical study of just in time qualityassurance ieee transactions on software engineering vol.
no.
pp.
.
h. perl s. dechand m. smith d. arp f. yamaguchi k. rieck s. fahl and y .
acar vccfinder finding potential vulnerabilities in open sourceprojects to assist code audits in proceedings of the 22nd sigsac acm conference on computer and communications security pp.
.
l. yang x. li and y .
y u vuldigger a just in time and cost aware tool for digging vulnerability contributing changes in globecom ieee global communications conference.
ieee pp.
.
l. g. a. rodriguez j. s. trazzi v .
fossaluza r. campiolo and d. m. batista analysis of vulnerability disclosure delays from thenational vulnerability database in anais do i workshop de seguranc a cibern etica em dispositivos conectados.
sbc .
a. d. sawadogo t. f. bissyand e n. moha k. allix j. klein l. li and y .
l. traon learning to catch security patches arxiv preprint arxiv .
.
f. thung d. lo l. jiang f. rahman p .
t. devanbu et al.
when would this bug get reported?
in 28th ieee international conference on software maintenance icsm .
ieee pp.
.
a. bosu and j. c. carver peer code review in open source communities using reviewboard in proceedings of the acm 4th annual workshop on evaluation and usability of programming languages and tools pp.
.
p .
thongtanunam s. mcintosh a. e. hassan and h. iida investigating code review practices in defective files an empirical study of theqt system in ieee acm 12th working conference on mining software repositories.
ieee pp.
.
k. moran m. linares v asquez c. bernal c ardenas and d. poshyvanyk auto completing bug reports for android applications in proceedings of the 10th joint meeting on f oundations of softwareengineering pp.
.
t. hoang j. lawall y .
tian r. j. oentaryo and d. lo patchnet hierarchical deep learning based stable patch identification for the linuxkernel ieee transactions on software engineering .
y .
zhang and q. yang a survey on multi task learning arxiv preprint arxiv .
.
s. chowdhuri t. pankaj and k. zipser multinet multi modal multitask learning for autonomous driving in ieee winter conference on applications of computer vision .
ieee pp.
.
authors reproduction package.
.
available com lhmtriet deepcv a r. future exploiting old vulnerabilities.
.
available a. sabetta and m. bezzi a practical approach to the automatic classification of security relevant commits in ieee international conference on software maintenance and evolution icsme .
ieee pp.
.
e. sahal and a. tosun identifying bug inducing changes for code additions in proceedings of the 12th acm ieee international symposium on empirical software engineering and measurement pp.
.
h. tian k. liu a. k. kabor e a. koyuncu l. li j. klein and t. f. bissyand e evaluating representation learning of code changes for predicting patch correctness in program repair in 35th ieee acminternational conference on automated software engineering ase .ieee pp.
.
y .
li s. wang and t. n. nguyen dlfix context based code transformation learning for automated program repair in proceedings of the acm ieee 42nd international conference on software engineering pp.
.
u. alon m. zilberstein o. levy and e. yahav code2vec learning distributed representations of code proceedings of the acm on programming languages vol.
no.
popl pp.
.
y .
kim convolutional neural networks for sentence classification in proceedings of the conference on empirical methods in naturallanguage processing emnlp pp.
.
v .
nair and g. e. hinton rectified linear units improve restricted boltzmann machines in icml .
d. bahdanau k. cho and y .
bengio neural machine translation by jointly learning to align and translate arxiv preprint arxiv .
.
s. ruder an overview of gradient descent optimization algorithms arxiv preprint arxiv .
.
d. e. rumelhart g. e. hinton and r. j. williams learning representations by back propagating errors nature vol.
no.
pp.
.
s. e. ponta h. plate a. sabetta m. bezzi and c. dangremont a manually curated dataset of fixes to vulnerabilities of open sourcesoftware in ieee acm 16th international conference on mining software repositories msr .
ieee pp.
.
s. mcintosh and y .
kamei are fix inducing changes a moving target?
a longitudinal case study of just in time defect prediction ieee transactions on software engineering vol.
no.
pp.
.
j. sliwerski t. zimmermann and a. zeller when do changes induce fixes?
acm sigsoft software engineering notes vol.
no.
pp.
.
c. rezk y .
kamei and s. mcintosh the ghost commit problem when identifying fix inducing changes an empirical study of apache projects ieee transactions on software engineering .
w. g. cochran sampling techniques.
john wiley sons .
m. l. mchugh interrater reliability the kappa statistic biochemia medica vol.
no.
pp.
.
h. hata c. treude r. g. kula and t. ishio .
million links in source code comments purpose evolution and decay in ieee acm 41st international conference on software engineering icse .
ieee pp.
.
y .
fan x. xia d. a. da costa d. lo a. e. hassan and s. li the impact of changes mislabeled by szz on just in time defect prediction ieee transactions on software engineering .
d. falessi j. huang l. narayana j. f. thai and b. turhan on the need of preserving order of data when validating within project defectclassifiers empirical software engineering vol.
no.
pp.
.
m. jimenez r. rwemalika m. papadakis f. sarro y .
le traon and m. harman the importance of accounting for real world labellingwhen predicting software vulnerabilities in proceedings of the 27th acm joint meeting on european software engineering conferenceand symposium on the f oundations of software engineering pp.
.
s. raschka model evaluation model selection and algorithm selection in machine learning arxiv preprint arxiv .
.
a. luque a. carrasco a. mart n and a. de las heras the impact of class imbalance in classification performance metrics based on thebinary confusion matrix pattern recognition vol.
pp.
.
j. gorodkin comparing two k category assignments by a k category correlation coefficient computational biology and chemistry vol.
no.
pp.
.
j. devlin m. w. chang k. lee and k. toutanova bert pre training of deep bidirectional transformers for language understanding arxiv preprint arxiv .
.
a. radford j. wu r. child d. luan d. amodei and i. sutskever language models are unsupervised multitask learners openai blog vol.
no.
p. .
m. pradel and k. sen deepbugs a learning approach to name based bug detection proceedings of the acm on programming languages vol.
no.
oopsla pp.
.
t. mikolov i. sutskever k. chen g. corrado and j. dean distributed representations of words and phrases and their compositionality arxiv preprint arxiv .
.
p .
bojanowski e. grave a. joulin and t. mikolov enriching word vectors with subword information transactions of the association for computational linguistics vol.
pp.
.
d. p .
kingma and j. ba adam a method for stochastic optimization arxiv preprint arxiv .
.
n. srivastava g. hinton a. krizhevsky i. sutskever and r. salakhutdinov dropout a simple way to prevent neural networks from overfitting the journal of machine learning research vol.
no.
pp.
.
s. ioffe and c. szegedy batch normalization accelerating deep network training by reducing internal covariate shift in international conference on machine learning.
pmlr pp.
.
s. lloyd least squares quantization in pcm ieee transactions on information theory vol.
no.
pp.
.
y .
zhou and a. sharma automated identification of security issues from commit messages and bug reports in proceedings of the 11th joint meeting on f oundations of software engineering pp.
.
d. shen g. wang w. wang m. r. min q. su y .
zhang c. li r. henao and l. carin baseline needs more love on simple word embedding based models and associated pooling mechanisms arxiv preprint arxiv .
.
t. chen and c. guestrin xgboost a scalable tree boosting system inproceedings of the 22nd acm sigkdd international conference on knowledge discovery and data mining pp.
.
g. ke q. meng t. finley t. wang w. chen w. ma q. ye and t. y .
liu lightgbm a highly efficient gradient boosting decision tree advances in neural information processing systems vol.
pp.
.
t. h. m. le d. hin r. croft and m. a. babar puminer mining security posts from developer question and answer websites with pulearning in proceedings of the 17th international conference on mining software repositories pp.
.
f. wilcoxon individual comparisons by ranking methods in breakthroughs in statistics.
springer pp.
.
t. h. le h. chen and m. a. babar deep learning for source code modeling and generation models applications and challenges acm computing surveys csur vol.
no.
pp.
.
g. lin j. zhang w. luo l. pan y .
xiang o. de v el and p .
montague cross project transfer representation learning for vulnerable functiondiscovery ieee transactions on industrial informatics vol.
no.
pp.
.
c. tantithamthavorn a. e. hassan and k. matsumoto the impact of class rebalancing techniques on the performance and interpretation ofdefect prediction models ieee transactions on software engineering vol.
no.
pp.
.
z. li d. zou j. tang z. zhang m. sun and h. jin a comparative study of deep learning based vulnerability detection system ieee access vol.
pp.
.
n. v .
chawla k. w. bowyer l. o. hall and w. p .
kegelmeyer smote synthetic minority over sampling technique journal of artificial intelligence research vol.
pp.
.
w. zheng j. gao x. wu f. liu y .
xun g. liu and x. chen the impact factors on the performance of machine learning basedvulnerability detection a comparative study journal of systems and software vol.
p. .
s. wattanakriengkrai p .
thongtanunam c. tantithamthavorn h. hata and k. matsumoto predicting defective lines using a model agnostictechnique arxiv preprint arxiv .
.
l. pascarella f. palomba and a. bacchelli fine grained just in time defect prediction journal of systems and software vol.
pp.
.
t. hoang h. j. kang d. lo and j. lawall cc2vec distributed representations of code changes in proceedings of the acm ieee 42nd international conference on software engineering pp.
.
x. gu h. zhang and s. kim deep code search in ieee acm 40th international conference on software engineering icse .
ieee pp.
.
x. hu g. li x. xia d. lo and z. jin deep code comment generation in ieee acm 26th international conference on program comprehension icpc .
ieee pp.
.
t. h. m. le r. croft d. hin and m. a. babar a large scale study of security vulnerability support on developer q a websites in evaluation and assessment in software engineering pp.
.
m. bozorgi l. k. saul s. savage and g. m. v oelker beyond heuristics learning to classify vulnerabilities and predict exploits inproceedings of the 16th acm sigkdd international conference onknowledge discovery and data mining pp.
.
s. neuhaus and t. zimmermann security trend analysis with cve topic models in ieee 21st international symposium on software reliability engineering.
ieee pp.
.
g. spanos l. angelis and d. toloudis assessment of vulnerability severity using text mining in proceedings of the 21st pan hellenic conference on informatics pp.
.
b. l. bullough a. k. yanchenko c. l. smith and j. r. zipkin predicting exploitation of disclosed software vulnerabilities using open source data in proceedings of the 3rd acm on international workshop on security and privacy analytics pp.
.
c. elbaz l. rilling and c. morin fighting n day vulnerabilities with automated cvss vector prediction at disclosure in proceedings of the 15th international conference on availability reliability and security pp.
.
x. gong z. xing x. li z. feng and z. han joint prediction of multiple vulnerability characteristics through multi task learning in2019 24th international conference on engineering of complex computer systems iceccs .
ieee pp.
.
s. e. ponta h. plate and a. sabetta beyond metadata code centric and usage based analysis of known vulnerabilities in open source soft ware in ieee international conference on software maintenance and evolution icsme .
ieee pp.
.
detection assessment and mitigation of vulnerabilities in open source dependencies empirical software engineering vol.
no.
pp.
.
x. yang d. lo x. xia y .
zhang and j. sun deep learning for justin time defect prediction in ieee international conference on software quality reliability and security.
ieee pp.
.
f. camilo a. meneely and m. nagappan do bugs foreshadow vulnerabilities?
a study of the chromium project in ieee acm 12th working conference on mining software repositories.
ieee pp.
.
f. peters t. t. tun y .
y u and b. nuseibeh text filtering and ranking for security bug report prediction ieee transactions on software engineering vol.
no.
pp.
.
m. gegick p .
rotella and t. xie identifying security bug reports via text mining an industrial case study in 7th ieee working conference on mining software repositories msr .
ieee pp.
.
a. bosu j. c. carver m. hafiz p .
hilley and d. janni identifying the characteristics of vulnerable code changes an empirical study inproceedings of the 22nd acm sigsoft international symposium onf oundations of software engineering pp.
.
x. chen y .
zhao z. cui g. meng y .
liu and z. wang largescale empirical studies on effort aware security vulnerability predictionmethods ieee transactions on reliability vol.
no.
pp.
.