similar but patched code considered harmful the impact of similar but patched code on recurring vulnerability detection and how to remove them zixuan tan jiayuan zhou xing hu shengyi pan kui liu xin xia zhejiang university hangzhou zhejiang china centre for software excellence huawei toronto canada huawei hangzhou zhejiang china tanzixuan xinghu shengyi.pan zju.edu.cn jiayuan.zhou1 huawei.com brucekuiliu gmail.com xin.xia acm.org abstract identifying recurring vulnerabilities is crucial for ensuring software security.
clone based techniques while widely used often generate many false alarms due to the existence of similar but patched sbp code which is similar to vulnerable code but is not vulnerable due to having been patched.
although the sbp code poses a great challenge to the effectiveness of existing approaches it has not yet been well explored.
in this paper we propose a programming language agnostic framework fixed vulnerability filter fvf to identify and filter such sbp instances in vulnerability detection.
different from existing studies that leverage function signatures our approach analyzes code change histories to precisely pinpoint sbps and consequently reduce false alarms.
evaluation under practical scenarios confirms the effectiveness and precision of our approach.
remarkably fvf identifies and filters .
of false alarms from four vulnerability detection tools i.e.
redebug vuddy mvp and an elementary hash based approach without yielding false positives.
we further apply fvf to real world software projects and construct a real world sbp dataset containing sbp functions.
due to the sbp nature the dataset can act as a strict benchmark to test the sensitivity of the vulnerability detection approach in distinguishing real vulnerabilities and sbps.
using this dataset we demonstrate the ineffectiveness of four state ofthe art deep learning based vulnerability detection approaches.
our dataset can help developers make a more realistic evaluation of vulnerability detection approaches and also paves the way for further exploration of real world sbp scenarios.
index terms vulnerability management software maintenance software security i. i ntroduction code reuse is one of the most frequent activities in software development .
by copying and pasting code snippets with or without modification developers reuse existing code to improve the efficiency of programming.
however vulnerabilities in the original code may also spread to downstream software.
for example more than open source software projects are exposed to the vulnerability cve for the reuse of unsafe code snippets in the popular graphic library libpng .
due to poor software maintenance these cloned similar vulnerabilities introduced from the reuse process are difficult to detect .
therefore it is crucial corresponding author commit 4071bf12 on may a patch for cve commit message this patch changes allocation mode of netlink message from gfp kernel to gfp atomic in order to prevent sleep in atomic bug.
the gfp atomic flag makes memory allocation operation could be used in atomic context.
file path net nfc netlink.c int nfc genl fw download done struct nfc... ... struct sk buff msg void hdr msg nlmsg new nlmsg default size gfp kernel if !msg return enomem ... vulnerable function patched functionint nfc genl fw download done struct nfc... ... struct sk buff msg void hdr msg nlmsg new nlmsg default size gfp atomic if !msg return enomem ... similar but patchedfig.
.
an example showing the subtle difference between a vulnerable function cve and the patched version .
for software maintainers to detect similar vulnerabilities in their codebases effectively.
the code clone detection based clone based approaches are commonly used to detect similar vulnerabilities .
generally these techniques extract various signatures from vulnerable code and match similar code snippets as potential vulnerabilities.
however due to the subtle differences between vulnerable code and its corresponding patched versions it is a challenge for clone based approaches to differentiate them effectively see section iv a for our experimental result .
this often leads to the misidentification of such similar but patched sbp code as vulnerable thus causing many false alarms.
figure shows an example of sbp code in the linux kernel related to cve .
the vulnerability was simply fixed by altering an argument of the nlmsg new function from gfp kernel togfp atomic .
in this case with only a single argument difference the vulnerable function is closely similar to the patched version sbp .
moreover a piece of an sbp code could even exactly match a vulnerability.
for example if a vulnerability patch is reverted for various reasons e.g.
obsolescence or substitution with a better patch the reverted code would become the same as the vulnerable code but without maintaining its vulnerability since the vulnerability condition will not be triggered see figure .
this poses a significant challenge for clone based approaches that aim to determine vulnerability by only examining current code.arxiv .20740v1 dec 2024in practice the inability to distinguish vulnerable and sbp code can lead to a large number of false alarms requiring substantial human effort to manually verify the results which is not always feasible and hinders the application of these approaches .
mvp proposed by xiao et al.
designed a function level signature scheme to distinguish a vulnerability and an sbp.
however the proposed signature scheme is programming language specific and lacks generalizability.
furthermore mvp cannot handle the reverted type sbp because its signature is identical to that of the vulnerability.
in this study we propose a programming language agnostic framework fvf fixed vulnerability filter to reduce false alarms in clone based vulnerability detection by identifying and filtering the sbp code.
the core idea behind fvf is to leverage code change histories to determine whether the detected potentially vulnerable code snippet has already been patched.
fvf works as a post processing step for existing vulnerability detection approaches.
when a potentially vulnerable code snippet similar to a known vulnerability is detected fvf queries the vulnerability feature database for a patch log which records the code change history of the vulnerability fix.
it then retrieves the function change log of the target code snippets.
following existing recurring vulnerability detection approaches focusing on detecting function level vulnerabilities fvf generates the change and patch logs at the function level.
if the patch log is detected in the function change log it indicates that the potentially vulnerable code snippet has been patched previously known as an sbp code snippet .
we evaluate the effectiveness of fvf in reducing false alarms i.e.
sbp in real world scenarios.
we adopt nine major versions of two popular open source projects namely the linux kernel and redis to evaluate how fvf can improve existing clone based vulnerability detection approaches.
we employ four popular clone based vulnerability detection approaches redebug vuddy mvp and implement a simple hash based approach as baseline vulnerability detectors.
the experimental results show that the overall false alarm rate far for these detectors is .
which is far from satisfactory and impractical.
after applying fvf the overall far is reduced to .
with a significant improvement rate of .
.
we further analyze where and why fvf makes false predictions including false positives of fvf and false negatives and we find no false positives and summarize false negatives into two situations.
based on the findings we conduct a qualitative study on the characteristics of filtered sbps that confuse clone based vulnerability detection approaches.
we categorize sbp code into three categories which shed light on future research possibilities.
to evaluate the generalizability and scalability of fvf we apply fvf on historically vulnerable and popular open source software oss projects written in c c and java programming languages.
in total we collect sbp functions and construct a dataset.
using the dataset we study the prevalence of the sbp code in the real world and observe that of oss projects studied contain at least one instanceof the sbp code.
the results confirm the prevalence of the sbp phenomenon emphasizing the need to address the challenge.
besides clone based vulnerability detection techniques deep learning based dl based techniques have gained promising performance in controlled lab environments.
however prior studies reveal that dlbased approaches sometimes leverage spurious features that are unrelated to the vulnerabilities resulting in inferior performance in real world scenarios.
given the subtle differences between vulnerability and sbp dl based approaches may also fail to distinguish them leading to a large number of false alarms.
unfortunately only a limited number of studies have considered sbp code and existing datasets such as devign and big vul overlook the inclusion of sbp code.
as a result dl based approaches failed to learn sbp patterns during training and evaluations become misaligned with realworld data distributions.
the impact of the sbp code on dlbased approaches is not well explored.
using the collected dataset we evaluate the performance of state of the art dl based vulnerability detection approaches.
we select two token based approaches linevul and vulberta and two graph based approaches devign and ivdetect for the study.
we use these approaches to detect vulnerabilities on the sbp dataset to assess the impact of sbp on dl based vulnerability detection approaches.
the experimental results show that these approaches perform poorly on the dataset.
all these approaches have a false alarm rate of more than .
the token based approaches mistakenly predict almost all sbp code as vulnerable and the two graphbased approaches have a false alarm rate of .
and .
respectively.
the results demonstrate the inability of these approaches to distinguish sbp from real vulnerabilities thus emphasizing the discriminative effectiveness of our dataset.
our dataset can help developers make a more realistic evaluation of existing vulnerability detection tools and also paves the way for further exploration of real world sbp scenarios.
our contributions are summarized as follows to the best of our knowledge we are the first to systematically study the phenomenon of sbp and its impact on vulnerability detection.
we find that while sbp code is prevalent in real world scenarios clone based and dlbased vulnerability detection approaches are incapable of distinguishing sbp code leading to a large number of false alarms in practice.
we propose an effective framework fvf to identify sbp and help clone based vulnerability detection approaches reduce false alarms.
experimental results show that fvf can significantly reduce false alarms of popular clonebased approaches such as vuddy and redebug .
we construct a real world sbp dataset consisting of sbp functions in three programming languages from real world projects using fvf which can contribute to a more realistic evaluation of vulnerability detection tools.
our replication package can be accessed using the link .the remainder of the paper is organized as follows section ii describes the overview and design of our proposed framework.
section iii and section iv discuss the evaluation steps and results of fvf.
in section v we discuss other features of fvf such as programming language agnostic and the impact of sbp code on promising deep learning based approaches.
in section vi we discuss the threats to the validity of our approach.
section vii summarizes related work in the field.
we conclude the paper in section viii.
ii.
fvf t heproposed approach the goal of fvf is to enhance existing clone based vulnerability detectors by reducing false alarms caused by already patched vulnerabilities i.e.
sbp .
the core idea is to take the code changes that fix historical vulnerabilities as a reference to check whether the detected vulnerable code has been fixed in the past.
in this section we first present the overall framework and our design choices of fvf followed by the details of each component.
a. overall framework following the existing recurring vulnerability detection approaches that focus on detecting function level vulnerabilities fvf also identifies sbp at the function level.
the overall fvf framework as shown in figure consists of four key components function change log generator vulnerability patch log finder vulnerability feature database and fix behavior matcher .
the vulnerability detector identifies vulnerabilities in the target repository and produces the detected potentially vulnerable functions matched function in figure to the function change log generator to generate a function change log .
simultaneously the detector produces the matched vulnerable function vuln.
function in figure to the vulnerability patch log finder which queries the vulnerability feature database to retrieve the patch logs .
finally thefix behavior matcher examines the function change log for the presence of fix behaviors indicated in the patch logs .
if the same fix behavior is detected the potentially vulnerable function is considered to have been previously fixed and is non vulnerable i.e.
a false alarm .
otherwise it remains potentially vulnerable and requires further review.
b. vulnerability detector the vulnerability detector aims to detect recurring vulnerabilities in the target project.
when analyzing a target code repository the detector produces two types of information the matched function matched function and the known vulnerable function vuln.
function .
the matched function represents the potentially vulnerable function detected in the target code repository.
the detector outputs the location including the name parameter definitions and return value of the matched function.
the vulnerable function refers to known vulnerable code that matches the detected potentially vulnerable function.
by requiring only the vulnerable functions and the matched similar functions fvf supports diverse typesof recurring vulnerability detectors varying from string matching methods like redebug signature based methods like vuddy to more advanced slice based techniques such as mvp and tracer .
this design ensures fvf s versatility and broad applicability.
after detection the matched and vulnerable functions are passed to the function change log generator andvulnerability patch log finder respectively.
c. function change log generator given the matched function from the detector the function change log generator retrieves the change history of the function in the version control system to build a function change log .
a function change log is a sequence of code changes denoted as fc1 fc2 ... fcm where fc iis a linelevel code change on the function.
the function change log generator first utilizes the git log command with the file path and function name as parameters to obtain the change history of the function.
then all the change histories are concatenated in chronological order to generate the function change log .
as retrieving the history in a large codebase can be very costly and slow down the whole process we set a retrieval window to limit how far back in the version history we should look for changes.
we consider the original vulnerability fix date to be the earliest date we should retrieve as a cloned vulnerability is unlikely to be fixed earlier than the original one recorded in cve.
additionally we empirically set a threshold of to limit the number of retrieval operations.
this threshold is a configurable option and we discuss efficiency and performance under different thresholds in section v d. in practice we find the retrieved history may be truncated in specific cases when the matched function is renamed or moved.
hence we retrieve file level change histories as a supplement.
specifically when the function level retrieval stops before reaching the window size threshold we further retrieve the file change history and extract all modifications to the function.
d. vulnerability patch log finder and feature database db the vulnerability patch log finder retrieves the appropriate patch log for the vulnerable function.
it first gets the necessary information e.g.
the signatures and line numbers about the vulnerable functions from the vulnerability detector.
then it queries the vulnerability feature database with cve id and vulnerable function signature for the patch log .
apatch log records all the fix actions represented as a sequence of line level code diffs concatenated from a series of patches on the function chronologically.
figure shows an example of generating a patch log for the function tun set iff and the vulnerability cve .
if multiple fixes have been applied to the same function the last post fix version is considered the fully fixed version.
thus the patch log records each patch diff chronologically from the first patch to the last patch making it naturally support multi patch scenarios.vulnerability detector vulnerability patch log finder patch log vuln.functionfunction change log generator function change log git log potentially vulnerablepatched fix behavior detected fix behavior not detected vulnerability feature dbtarget repository fix behavior matchermatched function vulnerabilities patch logs query fixing commits cve fig.
.
overview of fvf.
static int tun set iff ... ... if !dev return enomem dev net set dev net ...vuln.
function patch log fully patched function commit err dev get valid name net dev name if err goto err free dev if err if err static int tun set iff ... ... if !dev return enomem err dev get valid name net dev name if err goto err free dev dev net set dev net ...commit fixhistory fig.
.
an example of generating the patch log for function tun set iff and vulnerability cve .
the patch log contains two fixes .
the vulnerability feature database stores the patch logs of all the disclosed vulnerabilities for the vulnerability patch log finder to query.
specifically we collect the patch information of the disclosed vulnerabilities from vulnerability databases e.g.
nvd and process to generate patch logs for each vulnerable function modified in the vulnerability patch.
besides the database is continuously updated with the patch log of newly disclosed vulnerabilities ensuring that the latest vulnerability information is always available for querying.
e. fix behavior matcher given a function change log and a patch log the fix behavior matcher determines if the patch log is already contained in the function change log .
if the condition is true it means the function has fix behaviors in the past suggesting the vulnerability has already been fixed.
hence the detected result is an sbp case and is considered a false alarm.
formally for function change log fc log fc1 ... fcm and patch log pat log pc1 ... pcn if there exists a set of indexes where i1 i2 ... i n msuch that sim pcj fcij threshold for j n we consider patlog to be contained in fc log.
if it is contained it indicates that the potentially vulnerable function detected is an sbp one.
therefore this detection result is a false alarm.
instead of direct string matching we employ similarity to make fvf more robust when the cloned version has different literal representations such as using different variable names or function names etc.
we denote simas a similarity calculator and calculate the bleu score.
the bleu scorequantifies the similarity of grams i.e.
consecutive pairs of words making it especially applicable in scenarios where only the identifier name varies.
since fvf is only interested in the subsequence of the patch log during the matching process the code changes in the function history that are not related to the patch do not affect the result.
iii.
e xperiments in this paper we aim to answer the following research questions rq1 how effective is fvf in identifying sbp and reducing false alarms?
clone based vulnerability detection approaches are often not practical as they struggle to distinguish vulnerabilities and sbp code resulting in a large amount of false alarms .
the goal of this rq is to evaluate the false alarm rate of the existing clone based vulnerability detection approaches and then the effectiveness of fvf in reducing false alarms.
rq2 what are the false predictions of fvf in identifying false alarms?
in this rq we look into the details of when fvf fails in identifying sbp code.
especially we investigate the fps i.e.
real recurring vulnerabilities that are incorrectly identified as sbp code snippets and fns i.e.
real false alarms that are not identified of fvf.
rq3 what are the characteristics of filtered sbp code snippets?
in this rq we further conduct a qualitative study on the filtered sbp code snippets to gain empirical insights on their characteristics including the categories of sbp code snippets and the reason for each category.
a. data collection and preprocessing our experiment data include two parts vulnerability feature database and target project source code.
the vulnerability feature database contains information on existing vulnerabilities which is used by fvf.
the target project is the project from which fvf identifies sbp code snippets.
figure illustrates the workflow of our data collection process.
we describe the process in detail below.mitre vuln.
fix commitscve oss listbranch info branch urlfork info fork url github giteetarget project source codevuln.
feature db patch logs vulnerabilities matched clone vuln.devign big vulfig.
.
an overview of the data collection approach.
vulnerability feature database the database includes two main parts vulnerability information and patch logs .
initially vulnerability information is collected from multiple reliable sources followed by the generation of patch logs .
the process of vulnerability feature database construction is outlined as follows step collecting vulnerability fix commits vfcs .
vulnerability fix commits are commits in the version control system that fix vulnerabilities.
we collect vfcs from two existing vulnerability datasets namely devign and bigvul resulting in and vfcs respectively.
additionally we extract more vfcs from the reference links of the cve records in the authoritative vulnerability information source the mitre cve database .
note that we only keep vfcs modifying c c source files.
after deduplication we collect a total of vfcs distributed across projects.
step cleaning noisy data.
it is important to note that not all changes within a vfc are related to fixing vulnerabilities.
some commits contain multiple intentions e.g.
code refactoring which could introduce additional noise.
we conduct a statistical analysis on the number of files modified in each commit within the dataset and find that the 99th percentile of the number of modified files per vulnerability fix is .
accordingly vfcs that modify more than files are excluded.
we additionally exclude noisy commits that only revise comments or adjust white spaces.
step extracting vulnerability relevant functions.
we extract both pre and post commit versions of modified functions from each vfc using pydriller .
following previous studies the pre commit version is labeled as vulnerable while the post commit version is considered patched.
in the case of multiple vfcs for a single vulnerability only the post commit version of the latest vfc is considered patched otherwise it remains vulnerable.
step generating patch log.
figure shows an example of generating a patch log .
a patch log is a sequence of modification lines beginning with or which records every code change made to the vulnerable function from the initial vfc to the latest one chronologically.
specifically the modification lines related to the vulnerable function in each vfc are concatenated into a unified sequence to build apatch log .
in total we collect vulnerable functions and patch logs are generated.table i details of selected branches of target oss.
oss branch abbr.
status function loc linux kernel6.
rc5 l. .
mainline 657k 16m .
.
l. .
stable 656k 16m .
.
l. .
lts 616k 15m redis7.
.
r. stable 7k 154k .
.
r. lts 5k 105k table ii details of selected forks of target oss.
ossdownstream forkabbr.commits aheadcommits behindlast update linux kernelasahi linux l.a linux kernel lib.
l.l o.h.
linux kernel .
l.o redis birdisle r.b target project source code we follow the existing clone based vulnerability detection approaches to adopt the linux kernel and redis two widely used oss projects with extensive branches and forks as our target projects.
linux is a widely used operating system kernel while redis is a popular key value database system extensively used by companies.
then we further collect the source code of the branches and forks of the target oss projects.
table i provides details of the branches we select for the linux kernel and redis.
for linux we select the presently latest version tag .
rc5 on the master branch a stable release tag .
.
and a long term support version tag .
.
.
for redis we select one stable version tag .
.
and one long term support branch tag .
.
.
in supplement of branches we select oss forks that make customization and still actively commit in the most recent six months.
details of the forks for the linux kernel and redis are outlined in table ii.
the term commits ahead denotes the number of exclusive commits in the forked version indicating the evolving history of the project.
commits behind denotes the number of upstream commits not yet to be incorporated into the fork indicating the level of outdatedness.
for linux three downstream forks are chosen asahi linux which aims to adapt the linux kernel to apple silicon mac computers.
linux kernel library focusing on reusing linux kernel code as a library for user level applications.
openharmony linux kernel .
a customized linux kernel maintained by openharmony o.h.
an open source project for the internet of things iot devices.
regarding redis one fork is selected birdisle a modified redis version that operates as a library within another process.
b. baselines we evaluate our approach with four baselines including three well known vulnerable code clone detection approaches i.e.
redebug vuddy and mvp and a hash based approach.
redebug extracts vulnerable signatures from vulnerability patches and leverages a pattern matching approach to detect unpatched code clones.
redebug takes the deleted lines andthe surrounding context lines in the patch file to generate the vulnerable signature.
vuddy employs abstraction and normalization techniques to generate coarse grained and vulnerability preserving function signatures for vulnerable code clone detection.
mvp employs program slicing techniques to extract vulnerability and patch signatures identifying recurring vulnerabilities that match the vulnerability signatures while not matching the patch signatures.
hash based is a simple function matching approach that aims to evaluate the effectiveness of fvf even for such a trivial approach.
this approach generates a hash id for a given function as the signature of the function.
for a given function the approach compares the signature with all signatures of known vulnerable functions.
if two signatures are matched the function is considered to be a recurring vulnerability.
we simply abstract the names and parameters of functions to obtain a slight generalization ability.
c. test scenarios we evaluate the false alarm rate of baselines before and after applying our proposed approach in detecting vulnerabilities of target projects.
specifically we run the baseline vulnerability detection tools on each target project then apply fvf on the detected potential vulnerabilities to identify false alarms caused by sbp.
due to the inherent challenge of identifying vulnerabilities there is no definitive ground truth on all possible vulnerabilities.
to establish a fair and reliable ground truth we engage a team of three security professionals each with at least three years of experience in software security to manually validate each potential vulnerability detected by the baselines.
the validation process starts with two security professionals independently labeling the potential vulnerabilities identified by the approach.
specifically each professional is asked to first review the detailed disclosed information of the source vulnerability including the cve description and the vulnerability patch to gain a comprehensive understanding of the vulnerability root cause.
then based on such understanding of the source vulnerability the professional evaluates whether the detected vulnerability is truly a recurring vulnerability.
subsequently the labeling results of the two professionals are cross verified.
we employ cohen s kappa to measure the inter rater reliability resulting in a value of .
which indicates a substantial agreement.
to increase reliability the remaining discrepancies are resolved by the third professional using a similar review approach.
the professionals have ample time for thorough inspections and are well compensated for their effort and expertise.
d. evaluation metrics as our goal is to minimize the number of false alarms in clone based vulnerability detection we evaluate the baselines and the improvement made by fvf through three false alarmcentric metrics the number of false alarms the false alarm rate equivalent to false alarm precision and the improvement rate.we do not calculate recall since we do not have the ground truth of detected negatives for the baseline detector.
false alarm fa represents the number of false alarms produced by the baselines.
a higher fa indicates a lower detection accuracy of an approach.
false alarm rate far is the ratio of false alarms to the total number of predicted positives.
far reflects the accuracy of positive predictions made by the detector.
a higher far indicates lower quality in detection performance.
improvement rate ir is the observed improvement rate of false alarms i.e.
the reduction in far before and after applying our proposed approach.
a higher ir indicates a more substantial enhancement brought by fvf.
e. implementation details we implement fvf in .5k lines of python code.
our experiments are performed on an ubuntu .
server with intel xeon gold 6226r cpus and 256g ram.
for redebug we follow the original configuration to set the length of n gram to .
for vuddy we use the online platform offered on their official website .
we first generate signatures locally and then upload them to the platform for detection.
for mvp we reimplement the algorithm strictly according to the methodology in the original paper and use the recommended parameters as the original paper as well.
for the hashbased approach we leverage the md5 algorithm to generate hash ids and compare the hash ids.
iv.
e xperimental results a. rq1 the effectiveness of fvf in identifying sbp and reducing false alarms in total the four baselines produce potential vulnerabilities after deduplication.
three security professionals with at least three years of security experience manually verify all potential vulnerabilities produced.
the manual verification process is described in detail in section iii c. after verification potential vulnerabilities are confirmed as real i.e.
true positives tp in total.
the results are presented in table iii.
for the linux kernel all tps are detected in the l.l project indicating a poor security maintenance status.
regarding redis the latest version r. is well maintained but missing fixes are found in r. and r.b.
among all approaches the hash based model is the most trivial.
for the linux kernel the detection results of the hashbased model are false alarms except for the lkl l.l project.
after applying fvf the far decreases and ranges from .
to .
.
the ir ranges from .
to .
.
for redis the far ranges from .
to .
.
after applying fvf all the false alarms are identified and filtered.
vuddy generates more coarse grained function level signatures than the hash based model to achieve better performance.
however vuddy performed the worst among the baselines.
for the linux kernel all the results reported by vuddy are false alarms with the exception of the lkl project which exhibits a notably high far of .
.
for redis the far ranges from .
to .
.
one possibletable iii the performance of baselines in detecting vulnerabilities in linux and redis before after adopting fvf tp t rue positive fa f alse alarm far f alse alarm rate ir i mprovement rate .
proj.
abbr.approach tp original perf.
after fvf fa far fa far ir l. .3hash based .
.
.
vuddy .
.
.
redebug .
.
.
mvp .
.
.
l. .2hash based .
.
.
vuddy .
.
.
redebug .
.
.
mvp .
.
.
l5.15hash based .
.
.
vuddy .
.
.
redebug .
.
.
mvp .
.
.
l.ahash based .
.
.
vuddy .
.
.
redebug .
.
.
mvp .
.
.
l.lhash based .
.
.
vuddy .
.
.
redebug .
.
.
mvp .
.
.
l.ohash based .
.
.
vuddy .
.
.
redebug .
.
.
mvp .
.
.
r.7hash based .
.
.
vuddy .
.
.
redebug .
.
.
mvp .
.
.
r.5hash based .
.
.
vuddy .
.
.
redebug .
.
.
mvp .
.
.
r.bhash based .
.
.
vuddy .
.
.
redebug .
.
.
mvp .
.
.
total .
.
.
explanation for the high fa could be the quality of the vulnerability database.
vuddy relies on its private online database for detection which may be outdated and not comprehensive.
after enhancing vuddy by applying fvf the far in linux is effectively reduced dropping by .
.
.
for redis all false alarms are identified and filtered.
redebug constructs vulnerability signatures using partial information on vulnerabilities to identify cloned vulnerabilities which makes redebug more robust but also introduces more false alarms.
for the linux kernel redebug produces to false alarms with a far of .
across all versions except for the lkl which is .
.
for redis the far ranges from .
to .
.
after applying fvf the fars on the linux kernel projects decreased significantly dropping by .
to .
.
furthermore fvf filtered out all false alarms on redis.
mvp leverages code slicing techniques on the vulnerable static int ghash final struct shash desc desc u8 dst struct ghash desc ctx dctx shash desc ctx desc struct ghash ctx ctx crypto shash ctx desc tfm u8 buf dctx buffer if !ctx gf128 return enokey ghash flush ctx dctx memcpy dst buf ghash block size return static int ghash final struct shash desc desc u8 dst struct ghash desc ctx dctx shash desc ctx desc struct ghash ctx ctx crypto shash ctx desc tfm u8 buf dctx buffer ghash flush ctx dctx memcpy dst buf ghash block size return file path crypto ghash generic.c file path arch x86 crypto ghash clmulni intel glue.ccommit 7ed47b7d on oct t he partial patch for cve vulnerable function and the patch in green detected similar false alarmfig.
.
a false alarm falls outside of sbp.
the complete patch for cve2011 includes two identical code changes.
here we show the first.
and patched function to generate vulnerability signatures which makes the signature more comprehensive in detecting potential similar vulnerabilities.
however it still predicts many false alarms due to not considering reverted type sbps.
for the six versions of the linux kernel mvp predicts to similar vulnerabilities and the false alarm rate is between and .
for redis mvp predicts to similar vulnerabilities and the false alarm rate is between .
and .
after applying fvf the fars on the linux kernel projects decreased significantly by .
to .
.
for redis all the false alarms are identified and filtered by fvf.
in summary the overall far of all four baselines is .
which is far from satisfactory and impractical.
fvf identifies fixed vulnerabilities in potential vulnerabilities reducing the overall far from .
to .
.
even with the trivial hash based approach fvf reduces far from .
out of to .
out of .
these results demonstrate the effectiveness of fvf in reducing false alarms in clone based vulnerability detection.
rq1 result the false alarm rate of the four existing clonebased vulnerability detection approaches are high and far from satisfactory.
fvf is proven to be effective in reducing false alarms.
b. rq2 false predictions of fvf in identifying false alarms of clone based vulnerability detection approaches fvf aims to reduce the false alarms of clone based vulnerability detection approaches by identifying sbp code snippets.
in this rq we further look into the details of when fvf fails.
false positives of fvf false positives of fvf refer to real recurring vulnerabilities that are incorrectly filtered as sbp code by fvf.
this may hinder the actual vulnerabilities and is often unacceptable.
we manually verify all sbp code snippets identified in rq1 and find no false positive case.
fvf employs an evidence based process and adopts a conservative strategy to identify sbp code snippets.
specifically fvf considers a vulnerable function detected by a clone based vulnerability detection approach as sbp if and only if all code changes in the vulnerability patch log are rigorously contained in the function change log.
this ensures that the sbp identified by fvf must have been historically patched.
false negatives of fvf false negatives are false alarms produced by the underlying clone based vulnerability detectors but not filtered by fvf.
while fvf can significantlyfix and revert commit for cve revert c ommit ced21a4c on apr .... the skbis consumed by htc send epid so it needn t release again ... non vulnerable functionfix c ommit 853acf7c on sep ... if time out happens theallocated buffer needs to be released .
otherwise there will be memory leak... ... if !time left dev err target dev ... kfree skb skb return etimedout vulnerabl e function patched function... if !time left dev err target dev ... return etimedout file path drivers net wireless ath ath9k htc hst.c ... if !time left dev err target dev ... return etimedout fix revertfig.
.
an example of patch reversion.
commit ced21a4c reverts the change made by commit 853acf7c the fix for cve .
reduce false alarms specifically the sbp code as shown in rq1 there are cases where fvf misses certain false alarms.
in rq1 there are false alarms that fvf does not identify.
we manually conduct a qualitative study to investigate the reason why fvf fails and summarize two situations lack of vulnerability trigger point.
we observe cases that do not have fix behaviors in the past however are not vulnerable.
what makes the difference is the calling context i.e.
the contextual conditions.
the contextual conditions required for the vulnerabilities are not satisfied for the detected functions therefore they are false alarms.
figure shows a failed example for cve and the detected false alarm.
the root cause of the vulnerability is a null pointer dereference due to the pointer ctx gf128 could be null.
the vulnerability was fixed on oct by adding a null pointer check and returning an error code in the null case.
the detected false alarm with the same name ghash final is also in the linux project but exists in a different file.
since the pointer is not used within that file there is no vulnerability or need for a null check.
in such cases contextual information such as function calls and value flow becomes critical in determining if a similar function is truly a vulnerability.
to identify this type of false alarm inter procedural analysis could be introduced.
however filtering such cases is out of the scope of fvf while we focus on false alarms caused by sbp code.
trivial clone false alarms.
there are false alarms failed to be identified which code is neither related to the vulnerabilities nor the patches.
these cases are mostly short auxiliary functions or even non function code and are hard to associate with any vulnerabilities.
all these cases are produced by redebug which constructs vulnerability signatures using partial context lines in patch diffs.
although this improves the scalability it also introduces more false alarms.
filtering out such false alarms falls is also out of the scope of fvf.
rq2 result in our evaluation fvf has no false positives and keeps a low false negative rate in reducing false alarms.
it is important to note that the few missed false alarms are mainly out of the scope of fvf.
c. rq3 the characteristics of identified sbps in total fvf identified and filtered out false alarms in rq1.
after manual verification we confirm that all of themare already patched and should be filtered out.
in this rq we further analyze the characteristics of these filtered false alarms to gain empirical insights.
we categorize them into three categories patch reversion cases minor difference cases and customized patch cases .
patch reversion refers to the cases where a vulnerable function is first fixed but then the modification is rolled back.
there are patch reversion cases in total.
reverting a commit involves un the change made before.
it is found to be a common operation during software development due to reasons such as unexpected software regression and the introduction of new bugs .
we observe that patch reversion also occurs in the context of vulnerability fixing.
figure shows an example of a patch of cve and the corresponding reversion.
the root cause is that when timed out the allocated socket buffer skb is forgotten to be released resulting in a memory leak.
however the patch made on sep was reverted on apr since skb is consumed by another function htc send epid .
therefore it is incorrect to release it again.
after reverting the patch the function is the same as the vulnerable one first reported in cve but is no longer vulnerable.
most existing vulnerability detection approaches e.g.
the clone based vulnerability detection dl based vulnerability detection fail to distinguish reverted functions from vulnerable ones since they only rely on the information of the function itself.
this also verifies the unique advantages of our proposed fvf by considering the function change logs.
we further analyze the messages of the revert commits and identify two primary reasons for patch reversions contextual change .
in cases the commit messages suggest that the vulnerable version is no longer vulnerable due to a change in context.
inadequate patch .
in cases the original patch is found to be incorrect or inadequate to fix the vulnerability and it is easier to develop a new patch from scratch rather than revise the original patch.
this phenomenon indicates the secrecy of the reverted patches.
it is noteworthy that the cases of patch reversions are not rare and the corresponding research is insufficient.
so far no baseline can handle the reverted patches.
minor difference refers to false alarms where a patched function is wrongly detected as vulnerable but not due to patch reversion or customized patch.
there are such cases in total.
we analyze the difference between vulnerable and patched functions based on three metrics lines of code loc added lines of code aloc and removed lines of code rloc .
the median values are and respectively.
this confirms the challenges in distinguishing patched functions from vulnerable ones due to the subtle differences.
customized patch refers to false alarms in which developers apply the original patches from upstream but then customize the patched code to fit the downstream.
after customization the signatures of the customized functions become similar to those of the vulnerable functions resulting in false alarms of clone based vulnerability detection approaches.
wehistorical vuln.
popular projectsfvf framework sbp dataset vulnerability detector fig.
.
sbp dataset construction.
observe eight false alarms of the customized patch.
due to the customization requirements upstream patches may require additional development or refactoring as discussed in previous studies .
some existing approaches such as redebug also consider patch information.
however these approaches may still fail to distinguish customized patches from vulnerabilities.
the reason is that most fix information is typically extracted from the mainline version and customized patches are often not taken into consideration .
fvf can identify these false alarms by analyzing the code change history.
by detecting the core fix behaviors fvf can detect the function as a potential false alarm.
in conclusion among the filtered sbp related false alarms .
cases are patch reversion false alarms .
cases are minor difference false alarms and .
cases are customized patch false alarms.
all three cloned vulnerability detection approaches fail to correctly distinguish these fixed vulnerabilities generating a large number of false alarms.
in contrast our proposed approach fvf can effectively reduce these false alarms caused by sbp.
rq3 result we categorize the filtered false alarms into three categories and provide insights of each category patch reversion minor differences and customized patch.
our analysis demonstrates the unique advantages of fvf in reducing the false alarms caused by sbp code by utilizing the function change logs.
v. d iscussion in this section we further generalize fvf to large scale realworld open source software oss projects and construct an sbp dataset.
we aim to answer can fvf be generalized to large scale real world projects?
what is the impact of the sbp code on deep learning based vulnerability detection approaches?
we also discuss the prevalence of sbp code in real world projects as well as the efficiency and the programming language agnostic nature of fvf.
a. prevalence of sbp code in open source projects we leverage the same framework as in section ii a to construct the sbp dataset.
figure presents an overview of the construction of the dataset.
we employ vuddy j an extended version of vuddy that supports java programming language as the vulnerability detector with vulnerability source collected from mitre to scan for vulnerable code clones on a large number of oss projects.
the detected potentially vulnerable code clones are further verified by fvf to identify the instances of sbp which forms our dataset.the scanned projects are selected from two sources historically vulnerable projects from cve and popular projects in the wild.
historically vulnerable projects provide cases where the fixed function e.g.
backported patches is similar to the vulnerable function.
popular projects allow us to investigate the presence of the sbp phenomenon in the wild.
the top most starred projects on github for the c c and java programming languages are selected respectively.
in total we collected projects for detection.
since a project may contain different software versions in different branches the detection is only performed on active branches with code commits within the last five years.
after deduplication we collect sbp functions which are similar to vulnerable functions associated with vulnerabilities.
to ensure the functions included in our dataset are truly sbps we manually check randomly sampled sbp functions with a confidence level of and a margin of error of and verify that all of them are patched.
this is not ideal but manually examining all samples requires enormous human labor and is not feasible.
moreover we have shown in rq2 that fvf as an evidence based approach achieves a precision of i.e.
no falsely identified sbps .
it is noteworthy that all the sampled functions are confirmed as real sbp code demonstrating the accuracy of fvf and its low false positive rate.
we assess the prevalence of sbp code in three perspectives project vulnerability and function.
out of the oss projects studied projects contain at least one instance of sbp.
among the vulnerabilities vulnerabilities have at least one vulnerable function with sbp variants.
additionally among the vulnerable functions collected vulnerable functions have corresponding sbp variants.
these results demonstrate the significant presence of sbp emphasizing the importance of addressing the challenge of sbp.
b. programming language agnostic the sbp dataset is only collected from c c and java projects however the core design of fvf is programming language agnostic and fvf can easily extend to other programming languages.
in fvf generation of the function change log andpatch log only relies on the history tracking feature of version control systems e.g.
git and svn which is a general feature regardless of programming languages.
the matcher module applies log comparison which is also not limited to specific languages.
hence fvf is compatible with any programming language as long as the source code is managed with the standard version control system.
c. impact of sbp code on deep learning based vulnerability detection approaches dl based vulnerability detection approaches have shown promising performance in controlled lab environments.
however the sbp cases are not well considered in the previous work.
in the sbp dataset the vulnerable code and the sbptable iv performance of state of the art dl based vulnerability detection techniques on the sbp dataset .
approachtoken based graph based linevul v cnn v mlp devign ivdetect false alarms fa rate .
.
.
.
.
code share subtle differences but the vulnerability just manifests itself in these differences.
in the experiment we evaluate two token based and two graph based state of the art dl based vulnerability detection approaches with the sbp dataset.
similar to rq1 section iii d we employ fa and far as metrics.
we select the following state of the art dl based approaches linevul utilizes a transformer based language model to generate vector representations enabling both the prediction of vulnerable functions and the localization of vulnerable lines.
vulberta utilizes roberta a transformer based deep learning model with a custom tokenization pipeline to detect vulnerabilities.
it has two variants a convolution neural network v cnn and a multilayer perceptron v mlp .
devign utilizes a gated graph neural network ggnn to learn program dependencies features on code property graphs enabling effectively detection of function vulnerabilities.
ivdetect utilized a sliding window technique combined with an interpretable graph neural network to detect vulnerabilities and provide fine grained explanations.
it extracts five different scale features from the code and archives state ofthe art performance on multiple datasets.
for all techniques we use the pre trained model weights provided by the authors and the default parameters mentioned in the original papers.
as these deep learning models are designed mainly for c c we only use the c and c data about of all .
the evaluation results are presented in table iv.
the average false alarm rate fa rate of all models in the sbp dataset is as high as .
.
specifically token based models predict almost all sbp cases as vulnerable.
for example the vulberta cnn model predicts that all sbp samples are vulnerable.
for the graph based models .
of the devign predicted positives are sbp code and .
of ivdetect predicted positives are sbp code.
the results demonstrate that the dl based approaches also fail to distinguish the sbp code accurately and the sbp code poses large challenges to these approaches.
therefore the sbp dataset can serve as a benchmark for evaluating the sensitivity of existing vulnerability detection approaches to accurately identify real vulnerabilities among the sbp data.
d. time and efficiency in this section we discuss the efficiency and overhead of fvf.
fvf leverages the standard software version control system to retrieve function change log s queries patch logs from the vulnerability feature database and then uses a highly efficient code change log matching to match the twotable v the time efficiency and performance under different thresholds of retrieval window size .
fa f alse alarm far false alarm rate ir i mprovement rate avg.
a verage time .
threshold fa far ir time s avg.
s .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
log sequences.
the key overhead of fvf is the process of generation of function change logs.
in a large repository with numerous commits retrieving histories for specific functions or files is usually a heavy operation which slows down the overall process.
however without sufficient change logs fvf may fail to filter false alarms.
therefore the size of the retrieval window is critical for the accuracy and efficiency of the algorithm.
for this reason we conduct an empirical analysis to determine the optimal retrieval window size.
figure presents the empirical cumulative distribution function ecdf of required retrieval times of filtered false alarms in rq1 which demonstrates that all filtered false alarms can be filtered within a maximum retrieval window size of .
additionally the majority of successful cases are filtered by retrieving only a few change histories.
the hard cases which require more retrievals and time only constitute a minority of the overall cases.
then we experiment to determine the best retrieval window size for optimal performance and efficiency.
we use the false alarm data in rq1 section iv and then reapply fvf under different maximum retrieval window size settings to test its performance.
we use the same metrics fa far and ir.
additionally we also measure the elapsed time and compute the average processing time for each case.
the results as shown in table v indicate that with a larger retrieval window the improvement rate increases while the time and the average time are longer.
considering this trade off between efficiency and performance we empirically recommend a maximum retrieval window size of .
e. extensibility of fvf similar to prior works fvf is primarily designed for singlefunction similar vulnerability detection.
however fvf can also be extended to vulnerabilities across multiple functions i.e.
the inter procedural vulnerabilities .
since the core design of fvf is to utilize the fix behavior to detect similar interprocedural vulnerabilities fvf can further utilize all fix behaviors of relevant vulnerable functions to generate the multifunction patch log for the inter procedural vulnerabilities which we plan as future work.
vi.
t hreats tovalidity internal validity .
threats to internal validity are associated with bias and errors in the experiment.
one potential threat is the absence of a ground truth in rq1 where the predicted results are manually analyzed potentially introducing bias.
to1 retrieval timescumulative distributionfig.
.
ecdf of required retrieval times of filtered fas.
mitigate the bias we engage security professionals with at least three years of experience in software security to conduct the manual analysis.
another potential threat is the accuracy of the sbp dataset.
to mitigate the threat we conduct a manual verification process on a random sample of sbp functions with a confidence level of .
another threat is the comprehensiveness of our vulnerability feature database.
vulnerabilities can be fixed through custom fixes that are different from the records in the cve database.
to mitigate the threat we gather vulnerability fix commits from various public vulnerability databases and datasets to enhance our database.
external validity .
threats to external validity are related to the quality of vulnerability data.
previous research reveals that developers often group multiple changes into a single commit resulting in a tangled code change which produces large noise and bias.
in fvf we remove vfcs that modify more than files or only modify comments white spaces or test log files to mitigate the threat.
this could still be improved using commit untangling techniques such as .
another threat is associated with the selection of tested projects.
in this study we select projects with extensive branches and forks as our targets but there may be better factors we encourage future studies to investigate more factors in selection.
vii.
r elated work clone based vulnerability detection.
various approaches have been proposed for detecting recurring or similar vulnerabilities .
for example jiang et al.
and kim et al.
consider code as token sequences to detect vulnerability clones.
bowman et al.
leverage code property graphs to enhance the robustness of the matching algorithm against code modifications.
xiao et al.
consider code snippets that match the vulnerable version and not match the fixed version as recurring vulnerabilities.
kang et al.
use taint analysis traces to detect recurring vulnerabilities but are limited to taint style c c vulnerabilities and do not incorporate code change history.
woo et al.
consider the oldest disclosed and patched versions of the vulnerable function to generate more robust signatures to find modified vulnerable code clones.
however these works focus only on the code snippets and overlook the extensive information contained in the change histories resulting in many false alarms in clone based vulnerability detection.
in contrast our work pays attention to the fix reversions of vulnerabilities in real world scenarios utilizes a broader history to make more comprehensive decisions and significantly reduces the number of false alarms.deep learning based vulnerability detection.
deep learning based approaches have made periodic achievements in vulnerability detection .
these works typically utilize deep neural networks to learn vulnerable patterns from various forms of code representation such as lexical tokens program dependence graphs and a mixture of multiple representations .
linevul employs a transformer based architecture to generate vulnerability representations for line level vulnerability detection.
devign introduces ggnn to learn data and control dependencies features of vulnerable code.
shi et at.
train a graph convolutional network gcn on historically vulnerable functions and correlations to detect cloned vulnerabilities in downstream operating system distributions.
concoction extracts both static and dynamic features of the code and uses a bidirectional transformer network for vulnerability detection.
however these works often struggle to distinguish subtle differences between vulnerabilities and their corresponding fixed versions and therefore showed poor performance on sbp cases see experimental results in section v c .
other kinds of vulnerability detection approaches.
various works and techniques are also available in the field of vulnerability detection.
static analysis based approaches detect vulnerabilities through induction of possible variable values.
fuzzing based approaches aim to crash the program using random input to uncover vulnerabilities.
symbolic execution based approaches explore feasible execution paths by symbolizing variables to assist testing.
compared to these techniques fvf is lightweight and does not require compiling or executing the code which is a costly operation.
furthermore fvf can also be complemented with these techniques.
after eliminating sbp style false alarms other techniques can be applied for further validation.
viii.
c onclusion in this paper we focus on the sbp phenomenon in vulnerability detection.
we propose a new programming language agnostic framework fvf to identify sbp cases and reduce false alarms in vulnerability detection.
our evaluation conducted with four cloned based vulnerability detection tools and across nine versions of the linux and the redis project demonstrates that fvf can significantly reduce false alarm rates.
we further apply fvf to real world projects and construct a real world sbp dataset containing sbp functions.
using the dataset we demonstrate the ineffectiveness of state of the art dl based vulnerability detection approaches in distinguishing sbp data.
the dataset can help developers make a more realistic evaluation of existing vulnerability detection approaches and also paves the way for further exploration of real world sbp scenarios.