misbehaviour prediction for autonomous driving systems andrea stocco universit della svizzera italiana lugano switzerland andrea.stocco usi.chmichael weiss universit della svizzera italiana lugano switzerland michael.weiss usi.ch marco calzana universit della svizzera italiana lugano switzerland marco.calzana usi.chpaolo tonella universit della svizzera italiana lugano switzerland paolo.tonella usi.ch abstract deep neural networks dnns are the core component of modern autonomous driving systems.
to date it is still unrealistic that a dnn will generalize correctly to all driving conditions.
current testing techniques consist of offline solutions that identify adversarial or corner cases for improving the training phase.
in this paper we address the problem of estimating the confidence of dnns in response to unexpected execution contexts with the purpose of predicting potential safety critical misbehaviours and enabling online healing of dnn based vehicles.
our approach selforacle is based on a novel concept of self assessment oracle which monitors the dnn confidence at runtime to predict unsupported driving scenarios in advance.
selforacle uses autoencoderand time series based anomaly detection to reconstruct the driving scenarios seen by the car and to determine the confidence boundary between normal and unsupported conditions.
in our empirical assessment we evaluated the effectiveness of different variants of selforacle at predicting injected anomalous driving contexts using dnn models and simulation environment from udacity.
results show that overall selforacle can predict misbehaviours up to six seconds in advance outperforming the online input validation approach of deeproad.
ccs concepts software and its engineering software testing and debugging.
keywords misbehaviour prediction testing deep learning anomaly detection acm reference format andrea stocco michael weiss marco calzana and paolo tonella.
.
misbehaviour prediction for autonomous driving systems.
in 42nd international conference on software engineering icse may seoul republic of korea.
acm new york ny usa pages.
.
permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
copyrights for components of this work owned by others than acm must be honored.
abstracting with credit is permitted.
to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
request permissions from permissions acm.org.
icse may seoul republic of korea association for computing machinery.
acm isbn .
.
.
.
introduction self driving cars are one of the emerging technologies nowadays and possibly the standard way of transportation in the future.
such autonomous driving systems receive data from a multitude of sensors and analyze them in real time using deep neural networks dnns to determine the driving parameters for the actuators.
to test such complex software systems companies perform a limited number of expensive in field tests driving a car on real world streets or within closed course testing facilities .
this provides detailed sensor data of the vehicle that are recorded played back and recreated within a simulator to obtain comprehensive test scenarios.
simulation based test scenarios allow re testing new autopilot releases on a large numbers of nominal conditions as well as challenging e.g.
adverse weather and dangerous circumstances e.g.
a pedestrian suddenly crossing the road at a low cost .
the potentially unlimited number of testable driving scenarios combined with the lack of human interpretability of the internal functioning of dnns makes it difficult to predict the vehicle s mis behaviour with respect to unforeseen edge case scenarios.
misbehaviours span a wide range of situations associated with different degrees of severity from cases where the car does not drive smoothly e.g.
excessively high derivative of the steering angle over time up to safety critical failures and casualties .
in this respect promptly detecting unexpected untested execution contexts is of paramount importance so as to make sure that humandriven or self healing corrective actions take place to ensure safety.
in this paper we tackle the self assessment oracle problem for autonomous driving system i.e.
the problem of monitoring the confidence level of a dnn based autonomous driving system in order to timely predict the occurrence of future misbehaviours.
the problem is critical because a failure in detecting an unexpected condition may have severe consequences i.e.
a fatal crash whereas false alarms even if not dangerous may cause driver s discomfort and negatively affect the driving experience.
creating a self assessment oracle that evaluates the confidence of a dnn at runtime and predicts whether the system is within a low confidence zone is a largely unexplored research problem.
challenges arise because unexpected driving conditions are by definition unknown at training time otherwise they would be used to train a better dnn .
as a consequence the problem being addressed belongs to the unsupervised class of data analysis and we have to infer the unexpected only by looking at the normal driving scenarios.
moreover the ensemble of possible misbehaviours for a dnn based system is vast and necessarily domain dependent being associated with deviations from the functional requirements.
ieee acm 42nd international conference on software engineering icse icse may seoul republic of korea a. stocco et al.
in recent years researchers have proposed solutions for testing autonomous driving systems software .
a number of approaches propose input generation techniques that produce adversarial or corner cases used to improve the robustness of self driving car modules by re training .
other works target test case generation to expose faults for extreme conditions such as the vehicle colliding with a pedestrian or driving off the road .
all these approaches concern offline solutions for improving the robustness and reliability of dnns achieved by enhancing the training data and the autopilot module which are extended to include underrepresented critical scenarios.
in this paper we propose a novel self assessment oracle for autonomous vehicles based on confidence estimation probability distribution fitting and time series analysis.
our technique is implemented in a tool called selforacle which leverages reconstruction based techniques from the deep learning dl field to analyze spatiotemporal historical driving information.
the reconstruction error is used as a black box confidence estimation for the dnn.
during probability distribution fitting selforacle captures the behaviour of the self driving car under nominal conditions and fits a gamma distribution to the observed data.
analytical knowledge of gamma s parameters allows selforacle to estimate an optimal confidence threshold as a trade off between prediction of all misbehaviours and false alarms.
by observing a decreasing confidence trend over time selforacle can anticipate a misbehaviour by recognizing unexpected conditions timely enough to enable healing actions such as manual or automated disengagement.
we have evaluated the effectiveness of selforacle on the udacity simulator for self driving cars using dnns available from the literature.
we have modified the simulator to being able to inject unexpected driving conditions i.e.
day night cycle rain fog or snow in a controllable way.
in our experiments on simulations selforacle is able to safely anticipate out ofbound episodes crashes up to seconds in advance.
a comparative experiment with the online input validation strategy of deeproad shows that selforacle achieves substantially superior misbehaviour prediction on all the considered effectiveness metrics.
our paper makes the following contributions technique an unsupervised technique for misbehaviour prediction based on confidence estimation probability distribution fitting and time series analysis implemented in the tool selforacle which is available .
simulator an extension of the udacity simulator to inject unexpected driving conditions dynamically during the simulation.
evaluation an empirical study showing that the reconstruction error used by selforacle for time series analysis is a promising confidence metric for misbehaviour prediction outperforming the online input validation approach of deeproad.
dataset a dataset of labeled simulation based collision and out of bound episodes that can be used to evaluate the performance of prediction systems for autonomous driving cars.
background dnn based autonomous vehicles.
self driving cars sdc hereafter have benefited from many technological advancements bothin hardware and in software.
data gathered by lidar sensors cameras and gps are analyzed in real time by advanced dnns which govern over the actual maneuvers of the car i.e.
steering braking acceleration .
in order to manage a wide variety of driving scenarios sdcs necessitate a large amount of driving data combining nominal and adversarial scenarios .
to date it is still unlikely for a dnn to generalize correctly to the plethora of driving situations met everyday by human drivers.
as such a component monitoring the confidence of the dnn may promptly detect when the sdc is entering a low confidence zone and activate healing strategies that bring the vehicle to a safe state.
in self driving cars depending on the level of autonomy the self healing procedure can either involve the human driver or can be delegated to an automated system.1at both levels early and accurate misbehaviour prediction is an essential precondition to enable safe healing and an overall pleasant driving experience.
confidence measures in dnns.
the prediction must consider dnn uncertainties originating from the measurements in response to possible adverse environmental conditions in which the sdc operates.
the confidence level of a sdc can be measured through white box or black box techniques.
white box metrics monitor the internal behaviour of a dnn component.
for simple classifiers measuring softmax probabilities or information theoretic metrics such as entropy and mutual information may suffice.
for more complex networks such as those than operate on a sdc softmax probabilities and entropy are known to be unreliable confidence estimators .
moreover white box metrics require a transparent access to the network and substantial domain knowledge for the creation of nontrivial probabilistic models that approximate the network s uncertainty.
black box techniques differently model the sdc uncertainty by monitoring the relation between the current input images and the input data used during training.
for instance consider a sdc which has been trained only with images representing highways.
if images representing a narrow city street are given to the dnn the model will still output steering angles but ideally we would like to warn the sdc of a drop in the confidence level.
the main advantages of black box confidence metrics consist in being independent from the specific sdc architecture requiring no modifications to the existing dnn model because they use information which is readily available for analysis and in being therefore highly generalizable.
in this paper we focus on black box confidence estimation.
we next describe autoencoders and time series analysis which are the main building blocks of our approach.
autoencoders.
an autoencoder ae is a dnn designed to reconstruct its own input.
it consists of two sequentially connected components an encoder and a decoder that are arranged symmetrically.
the simplest form of autoencoder sae is a three layer dnn the input layer the hidden layer and the output layer.
the hidden layer encodes any given input x rdto its internal representation code z rzwith a function f x z. usually z d where zis the dimension of encoded representation and dis the dimension of the input.
the output layer decoder decodes the encoded input with a reconstruction function z x where x is the reconstructed input x. the autoencoder minimises a loss 360misbehaviour prediction for autonomous driving systems icse may seoul republic of korea functionl x f x which measures the distance between the original data and its low dimensional reconstruction.
a widely used loss function in autoencoders is the mean squared error mse .
the input and output layers of autoencoders have the same number of nodes.
if multiple hidden layers are used the architecture is referred to as deep autoencoder dae .
the surge of novel kinds of dnns has correspondingly produced variants of autoencoders based on such architectures.
for example convolutional autoencoders allow learning powerful spatial preserving relationship within images at a lower training time with respect to fully dense layers.
another interesting proposal are variational autoencoders vae that are able to model the relationship between the latent variable zand the input variable xby learning the underlying probability distribution of observations using variational inference .
time series analysis.
traditional feedforward dnns assume that all inputs and outputs are independent of each other.
however learning temporal dependencies between inputs or outputs is important in tasks involving continuous streams of data.
thus a predictive model can take advantage of information from the previous inputs outputs to enhance its predictive capability.
time series analysis can be applied to the output sequence produced by a dnn to identify the trend and predict future values.
among the numerous models available for time series analysis the most widely used ones are autoregressive ar integrated i and moving average ma models along with their combinations.
an ar model of order kpredicts the next value xtas a linear combination of past values xt .
.
.
xt k xt 0 k i 1 ixt i t where coefficients 0 .
.
.
kcan be estimated by the least square method and trepresents the error term.
processing of a sequence of inputs can be achieved by recurrent neural networks rnn equipped with long short term memory lstm which is capable of dealing with both short and long range dependencies.
in lstm outputs are influenced not only by the current input but also by the state of the rnn which encodes the entire history of past inputs.
problem formulation we focus on sdcs that perform behavioural cloning i.e.
the dnn learns the lane keeping behaviour from a human driver.
models such as the ones by nvidia or the udacity self driving challenge are trained with visual inputs i.e.
images from car mounted cameras that record the driving scene paired with the steering angles from the human driver.
the dnn then learns how to drive by discovering underlying patterns within the training images representing the shape of the road and predicting the corresponding steering angle.
for classification problems e.g.
hand written digit recognition misbehaviours can be defined as inputs that can be confidently labeled by humans while they are misclassified by a dnn.
differently for regression problems such a definition is more challenging because there is no expected outcome for an individual output of the dnn and it is only the overall behaviour resulting from thednn predictions that may or may not be acceptable depending on the specific application domain.
in steering angle prediction it is challenging to decide if the steering angle produced by a dnn is wrong because the optimal steering angle is generally unknown for a new test scenario and even if it were known the amount of difference between predicted and expected steering angle that qualifies as an error is difficult to decide a priori.
it is instead more realistic to figure out whether a chain of inaccurate predictions ultimately leads to a misbehaviour because of the cumulative prediction errors.
in fact the very definition of misbehaviour should be decoupled from the notion of correct wrong dnn output being instead linked to the ability of a dnn of abstracting from the training examples and learning how to drive in different ways conditions.
it is the task of the dnn to generalize the training knowledge to make the model robust with respect to slightly different conditions from those observed in the training set for example adapting the driving style to different weather conditions.
.
misbehaviour of autonomous vehicles in the context of this paper a dnn exhibits a misbehaviour in a given test scenario if the overall system that contains the dnn does not respect its requirements due to the outputs produced by the dnn.
in the autonomous driving domain there are many possible misbehaviours associated with the different requirements that such systems are supposed to realize.
safety requirement violations are by far the most critical requirements as a misbehaviour in the steering component may cause a crash of the vehicle with potential casualties.
however in general a sdc might violate also other driving requirements e.g.
related to ride comfort such as excessive derivative of the steering angle unstable movement around the centerline or excessive deceleration.
in this paper we focus on the prediction of two safety critical misbehaviours collisions and out of bound episodes obes .
the rationale for this choice are as follows.
first they represent the vital requirement to be satisfied and thoroughly tested i.e.
the car should stay in lane and avoid whatsoever collision without which autonomous driving vehicles would be hardly accepted in production.
second leveraging a simulation environment such as udacity s allows us to safely test such critical scenarios and precisely define observe and measure them in order to support crash analysis and reproduction.
to conclude the problem we aim to address in this paper is predicting when a self driving car is within a low confidence area because of an unexpected execution context timely enough to take countermeasures before the vehicle crashes or drives off road.
approach the goal of our approach is to monitor the confidence level of a sdc as it runs and to promptly predict whether drops in confidence correlate with potential future misbehaviours.
our approach works in an end to end fashion analyzing directly the input data as retrieved by the car an image from the center camera making the approach independent from the specific architecture of the self driving component requiring no modifications to the existing dnn model and being therefore highly generalizable.
361icse may seoul republic of korea a. stocco et al.
figure confidence levels of nvidia s dave in response to changing driving scenarios.
the picture shows frames captured during the execution of the sdc along one of our testing tracks under different conditions lap sun lap light rain lap sun and lap heavy rain.
the picture juxtaposes the reconstruction error by the anomaly detector of selforacle which is used as a proxy for the dnn confidence.
we can notice that the reconstruction error is low when the car drives under sunny conditions i.e.
conditions similar to those observed during training whereas the error increases moderately with adverse conditions the car does no longer follow the center of the road and grows above a given threshold when facing heavy rainy conditions at night time which cause the sdc to drive off the road .
the main working assumption is that a prediction model trained on normal data should learn the normal time series patterns.
when the model is used on a sdc in the field it should worsen its performance as the car approaches previously unseen regions as compared to normal known regions figure .
then using a decision boundary mechanism we can timely alert the human driver nhtsa level or the main self driving component nhtsa level .
we now detail each step of our approach which consists of two main phases model training under nominal driving behaviour and field usage of the trained model.
.
training of selforacle under nominal driving behaviour figure illustrates the training phase of our approach which consists of several steps.
.
.
reconstructor.
the first step consists in retrieving a model of normality from the training driving scenarios.
thus in the training set we capture the visual input stream of the sdc under nominal situations.
then we train our driving scenario reconstructor with such normal instances.
the motivation for the use of reconstructors is due to the results obtained in the field of anomaly detection by reconstruction based techniques.
particularly autoencoders have proven effective as anomaly detectors because the proximity in their latent space translates into low reconstruction error and are computationally very efficient.
let us consider a training set x x1 x2 .
.
.
xn ofnimage frames where the index i ofxi xrepresents the discrete time t. depending on the considered architecture a reconstructor can be singled image orsequence based.
for singled image reconstructors only one image frame is considered at a time.
when the discrete time is t i xiis the input and the reconstructor recreates it into x i. for sequence based reconstructors assuming k image frames preceding xiare used to reconstruct xi the sequence xi k .
.
.
xi is the input used to output x i a prediction of the actual current frame xi.
for instance for k 3andi thereconstructor considers the sequence x1 x2 x3 in order to predict the current frame x4.
at the end of this task each reconstruction error ei d xi x i can be computed where dis a proper distance function such as the euclidean distance.
this results in the set of reconstruction errors e e1 e2 .
.
.
en available for all elements in the training set x. .
.
probability distribution fitting.
we build a model of normality for the reconstruction errors e e1 e2 .
.
.
en collected in nominal driving conditions and automatically determine a threshold that brings the expected false alarm rate in nominal conditions below some acceptable configurable level e.g.
or .
to this end we use probability distribution fitting to obtain a statistical model of normality.
indeed using the raw reconstruction error distribution is unreliable because high error values are rare as such distribution is obtained from nominal data.
therefore any estimation above a reasonably high threshold becomes inaccurate if done directly on the raw data because the estimated false alarm rate would be incorrectly assumed to be equal to zero when only a few or even no data points are observed on the right of the chosen threshold.
the reconstruction error e d x x can be computed by comparing the individual pixels of the images xandx and taking the mean pixel wise squared error.
assuming images have width w height handcchannels usually rgb channels for colour images the reconstruction error is defined as follows d x x w hcw h c i j c x x we assume that the pixel wise error e x x follows a normal distribution with pixel dependent variance e n c i j .
correspondingly the sum of the squares of pixel wise errors e follows a gamma distribution e d x x .
we get a gamma distribution instead of a 2distribution because pixel wise errors have different channel pixel dependent non unitary variances.
362misbehaviour prediction for autonomous driving systems icse may seoul republic of korea figure model training under nominal driving behaviour.
definition of gamma distribution.
gamma is a probability model for a continuous variable on which is widely used in engineering science and business to model continuous variables that are always positive and have skewed distributions .
the probability density function of a random variable x is f x x 1e xx where is the shape parameter which affects the shape of the distribution is the rateparameter or inverse scale which stretches shrinks the distribution and is the gamma function.
when is large the gamma distribution closely approximates a normal distribution with the advantage that the gamma distribution has non zero density only for positive real numbers.
the gamma function can be seen as a solution to the interpolation problem of finding a smooth curve that connects the points n m with m n !at any positive integer value for n. such a definition was extended to all complex numbers with a positive real part by bernoulli as a solution to the following integral z 0xz 1e xdx r z fitting the gamma distribution.
one effective method to estimate the parameters of a distribution that best fit the data is by maximum likelihood estimation mle which we briefly report next.
the likelihood function reverses the roles of the variables in equation the values of xare known and are the fixed constants figure fitted gamma distribution of reconstruction errors from a vae on the dave dataset.whereas the unknown variables are the parameters and .
mle involves calculating the values of these parameters so as to obtain the highest likelihood of observing the values of xwhen the given parameters are supplied to f. under the assumption of independence of the data the likelihood of the data given the parameters of the distribution is conveniently defined as the logarithm of the joint probability of the data for a given choice of the parameters.
in the case of a gamma distribution with a dataset consisting of reconstruction errors e e1 e2 .
.
.
en we get l e nn i 1logf ei n loge nlog n log ne where e loge is the mean log reconstruction error over e. to find the values of parameters and that maximizelwe have to find a solution to the equations l l .
the second equation can be easily solved analytically resulting in e .
by substituting the value of into the first equation we get an equation that unfortunately cannot be solved analytically.
however the newton method can iteratively converge to the solution quite quickly.
the output of such numerical estimation will be the pair of parameters and of the gamma distribution that best fit the reconstruction errors.
example of threshold estimation.
let us consider a set of reconstruction errors.
figure shows the histogram of those produced on the dave dataset when the reconstructor is a vae.
on such dataset the mle method estimates the following gamma parameters .
figure shows the gamma distribution obtained with such parameter values.
let us to set a false alarm rate .
the threshold with a probability mass above the threshold equal to 2can be easily obtained as the inverse of the cumulative gamma distribution f x f .
this ensures that the cumulative probability of values is1 leaving only a probability of to the tail following .
we use the estimated as threshold to distinguish anomalous conditions reconstruction error from normal ones reconstruction error .
.
usage scenario figure shows how selforacle is used online for misbehaviour prediction after model training i.e.
after fitting the gamma distribution and estimating the threshold .
misbehaviour prediction is executed online as the sdc drives.
in this phase the sdc generates data continuously and the reconstructor recreates the incoming stream of images.
the sequence of reconstruction errors is passed 363icse may seoul republic of korea a. stocco et al.
figure usage scenario of selforacle.
through the autoregressive model fand the resulting filtered error is compared against the threshold which determines whether an anomaly is detected or not.
in the former case self healing is triggered and the sdc is brought to a safe state.
.
.
time aware anomaly score prediction.
the reconstruction error etat time tmight be susceptible to single frame outliers which are not expected to have a big impact on the driving of the car but would indeed make the misbehaviour predictor falsely report an anomalous context.
for this reason we smooth such noisy oscillations by applying an autoregressive filter the sequence of reconstruction errors is passed to a module that performs time series analysis.
in figure this corresponds to the ar filter f. the output of this filter instead of the raw reconstruction error et is compared with the threshold to recognize unexpected driving conditions.
in our experiments we used a simple ar model see equation with 0 0and i kfori .
.
.
k i.e.
the arithmetic mean of reconstruction errors over the last kframes.
empirical evaluation .
research questions we consider the following research questions rq1 effectiveness how effective is selforacle in predicting anomalies for autonomous vehicles?
what are the best reconstructors to use?
rq2 prediction how does the misbehaviour predictions of selforacle change as we increase the reaction period i.e.
we anticipate the time of prediction ?
rq3 comparison how does selforacle compare with deeproad s online input validation?
.
self driving car models we evaluate our framework on three existing dnn based sdcs nvidia s dave epoch and chauffeur .
we choose these models because they are robust sdc models and they are publicly available thus they can be trained and evaluated on the simulator.
moreover they have been objects of study of other testing works .
dave consists of three convolutional layers followed by five fully connected layers.
chauffeur uses a cnn to extract the features of input images and a rnn to predict the steering angle from previous consecutive extracted features.
epoch is implemented as a simple cnn with three convolutional layers.
.
simulation platform as common industrial practices require for our empirical study we used a simulation environment of the whole system in operation.
the motivation for this choice is twofold.
first unlikeprevious works we cannot rely on existing driving image datasets such as the ones released by udacity because they lack any episode of crash or cars driving off road whatsoever.
indeed a major problem in anomaly detection research is the lack of labeled benchmark datasets and the self driving car domain is no exception.
second for online testing our definition of misbehaviour section requires the creation of a set of controllable unexpected conditions that may potentially cause them along with a way to precisely record them.
the use of a simulation platform is viable according to a recent paper by haq et al.
showing that simulator generated data yield similar prediction errors as those obtained on real world datasets and that offline testing is less viable in exposing safety violations that occur during in field testing.
thus we investigated the effectiveness of our approach in predicting safety critical misbehaviours in the udacity simulator .
the udacity simulator is developed with unity a popular cross platform game engine.
the simulator provides two default tracks for testing dnns models.
the simulator executes in two modes training mode in which the user manually controls the car while the simulator records her actions and autonomous mode in which the car is controlled by an external agent such as a dnn based autonomous driving system.
moreover we added a third track to the existing set and we implemented two additional components namely an unexpected context generator and a collision obe detection system.
.
.
unexpected context generator.
first we developed a method to gradually inject unseen conditions during autonomous mode i.e.
conditions diverse from the training mode s defaults .
the first condition deals with illumination.
our extension of the simulator can gradually change the lightning condition of the track simulating the passage between day and night day night cycle .
the component that controls illumination can produce changes in a gradual way is applicable to all tracks and is customizable in order to increase or decrease the brightness or darkness as well as control the duration of a simulated day night cycle.
the sun and the moon objects are rotated around the zero point vector according to the current time of the day by extracting how many degrees the celestial bodies should rotate after each update interval.
this effect produces realistic changes in the shadows of allobjects in the scene night sky and illumination brightening and dimming.
we fixed the retro illumination when the sun is positioned below the scene by deactivating it when the y axis component becomes negative.
the sun is switched off at sunset and switched on at sunrise accordingly and intensities during the simulations are varied by applying linear interpolation from the minimum to the maximum intensity along the chosen day length s in our experiments .
364misbehaviour prediction for autonomous driving systems icse may seoul republic of korea figur e top day night cycle sunrise day night and bottom weather effects snowy lake track foggy jungle track and rainy mountain track .
the second kind of unseen environmental condition relates to weather effects.
we implemented rain snow and fog effects with a variable intensity during the simulation.
for the implementation we used a specific unity component called particle system which can simulate the physics of a cluster of particles with high performance.
the particle system spawns particles according to a predefined and optimized algorithm such as per point area volume and the particles can be updated only through fixed values according to fixed events update particles color size direction speed or acceleration when a timer ends a collision occurs or randomly .
after creating the rain snow and mist effects we wrote a script to localize the particles around the car in motion handling the movement of the effects in response to that of the car and to control the intensity of the effect.
it applies linear interpolation to decrease or increase the number of particles produced over time visually changing the impact of the effect.
specifically the rain particles emission rate ranges between a minimum of light rain to a maximum of particles s heavy rain fog between particles s and snow between particles s. the simulation platform is also in charge of changing the sun intensity the sun color and the sky box according to the selected effect.
figure shows a few examples.
.
.
collision obe detection system.
following our definition of safety critical misbehaviours we implemented an automated collision obe detection system acods that records any unwanted interaction of the sdc with the environment allowing us to experiment the effectiveness of selforacle at anticipating such episodes during the occurrence of unexpected scenarios section .
.
.
we implemented acods based on colliders which are consolidated building blocks of modern game engines to simulate the physical interaction between objects.
we approximate the car body with a geometry mesh and implemented a collider callback that informs the simulator of any physical interaction of the car with scene objects.
when the car hits the road it means the car is actually on track.
differently when the car collides with any other object the callback registers whether it is a crash against some object figure left or whether it is an obe figure right .
we also implemented an automatic restart mechanism that restores the sdc to a safe position after a crash obe allowing us to record multiple simulations without the need for manual restart.
this was implemented leveraging track waypoints i.e.
phantom objects that are used to mark certain positions and directions in a 3d scene.
essentially each consecutive pair of waypoints wn wn figur e simulator crash obe detection.
defines a track sector which also gives us a way to monitor and control the length of the simulations .
automated restart is performed as follows.
if the car crashes at some sector wn wn we tag the sector as not complete and the system automatically moves the car to the waypoint wn adjusting position and angle according to the waypoint orientation.
.
procedure .
.
data generation training set .
training data were collected by the authors in training mode by performing laps on each track following two different track orientations normal reverse .
overall we obtained a dataset of training images at fps divided as follows for track lake for track jungle and for track mountain .
differences depend on the track lengths.
to allow a smooth driving and a correct behaviour capture i.e.
lane keeping the maximum driving speed was set to mph the default in the udacity simulator.
.
.
sdc model setup training.
all sdcs models were trained on images from the three cameras.
we used data augmentation as a consolidated practice for building more reliable and generalizable sdcs limiting the lack of image diversity in the training data.
specifically of the data was augmented through different image transformation techniques e.g.
flipping translation shadowing brightness .
we cropped the images to x and converted them from rgb to yuv colour space.
all sdc models were trained for epochs with batch size of on a machine featuring an i9 processor gb of memory and an nvidia gpu geforce rtx ti with 11gb of memory.
basically the training was meant to create solid models for testing i.e.
able to drive multiple laps on each track under nominal conditions without showing any misbehaviour in terms of crash obe.
.
.
evaluation set.
to collect the evaluation data we executed simulations sdc x conditions x tracks in autonomous mode each consisting of two laps.
as in the data generation phase the maximum speed was set to mph.
specifically for each sdc and for each track we performed one simulation in the same normal conditions as the training set.
this allowed us to estimate the number of false alarms false positives in nominal conditions.
second we performed four simulations activating in turn a single unexpected condition day night cycle rain snow fog.
third we performed three simulations activating in turn a combined condition day night cycle rain day night cycle snow day night cycle fog.
2all such conditions may actually occur in nominal runs as well.
there is no special reason for this specific choice of normal anomalous conditions and different permutations would be of course allowed e.g.
normal day night rainy anomalous snowy .
the only important prerequisite is that the chosen anomalous condition is unseen at training time.
365icse may seoul republic of korea a. stocco et al.
figure labelling of anomalous and normal windows in driving image stream.
in our experiments we used a value of s both for the day night cycle and for the loop between the minimum and maximum intensity of the effects.
this value was chosen empirically given the relatively short speed of the sdc and the small length of the tracks allowing us to test the behaviour of the sdc on each of the tracks subsets under all possible conditions.
for example the bridge part of track1 lake has been driven on under both dawn day sunset night conditions day night cycle and minimal maximal intensity of rain fog snow.
overall we obtained a dataset of images divided as follows for track lake for track jungle and for track mountain with unknown conditions and for track for track and for track in known conditions.
.
.
selforacle s configurations.
we used four autoencoders taken from existing guidelines sae simple autoencoder with a single hidden layer dae deep five layers fully connected autoencoder cae convolutional autoencoder alternating convolutional and max pooling layers and vae variational autoencoder .
all autoencoders take as input a single image.
we added images taken by the side cameras of the car left right to allow better generalization.
lastly we performed further data augmentation on of the inputs as described in section .
.
.
as an additional sequence based reconstructor we also implemented an lstm consisting of two lstm layers and one convolutional layer.
all our code is publicly available in the replication package accompanying this paper .
.
.
baseline.
we use the input validation technique of deeproad as baseline for selforacle.
due to the unavailability of an open source version of such technique we implemented of our own version based on the authors description which is publicly available in our replication package .
for input validation deeproad uses the pre trained vgg19 imagenet classifier to extract style and feature vectors from a given image.
principal component analysis pca is then used to reduce all style and feature vectors concatenated into a matrix to three dimensional representations which support distance similarity estimation.
to allow a fair comparison we integrated it within selforacle as reconstructor.
however unlike autoencoders deeproad is computationally very expensive and memory demanding due to the size of the matrix supplied to pca .
in the paper authors reduced their training set to images which were resized to 120x90.
during input validation the three dimensional representation of an online input image is compared to the nominal images by measuring the average of the top minimum distances from the training set.
our own implementation relaxed the restrictions above by considering a training set consisting of randomly sampled images i.e.
improvement with respect to the original implementationdescribed in the paper resized to 224x224 which is the default input size for vgg19 .
keeping the fraction of the training set constant we compute similarity based on the average of the top minimal distances.
.
evaluation of simulation results we evaluated all approaches offline by splitting the evaluation set of recorded images in windows of consecutive frames which we labelled as either anomalous or normal figure .
in anomalous windows selforacle is expected to predict the shortly following misbehavior.
.
.
labelling of anomaly and normal windows in evaluation data.
letx x1 x2 .
.
.
xn be the sequence of considered images frames .
misbehaviors are represented as mj where mj 1iff a misbehavior is recorded at xj x. we define a healing period as a sequence of hmisbehaviour free frames following a misbehaviour at time t. we define a reaction period as a sequence ofrmisbehaviour free frames preceding a misbehaviour at time t and not intersecting any healing period.
we define an anomalous window asaconsecutive misbehaviour free frames followed by a reaction period that does not intersect any healing period.
we define a normal window asbconsecutive misbehaviour free frames followed by an anomalous window or a normal window that does not intersect any healing period.
this is illustrated graphically in figure .
formally assuming any misbehavior recorded at time t i.e.
mt window xt 1toxt his labelled as healing period if mt andmj j furthermore the window xt 1toxk 1is also labelled as healing period if mk 1with k tandk t h and mj j window xt rtoxt 1is labelled as reaction period iff mt mj j and no healing period contains any frame from xt rtoxt window xitoxi a 1is labelled as anomaly window iff a reaction period starts at xi a mj j and no healing period contains any frame from xitoxi a window xitoxi b 1is labelled as normal window iff an anomaly or a normal window starts at xi b mj j and no healing period contains any frame from xitoxi b .
moreover if mj 0for all j all consecutive windows of size bstarting within xktoxn r a 1which do not intersect any healing period are labelled as normal.
the labelling described above ensures that after the last misbehavior in a sequence hhealing images are ignored i.e.
not labeled before another anomaly or normal window is defined.
the value of hmust be fine tuned appropriately so that the car is ensured back safely on the road 366misbehaviour prediction for autonomous driving systems icse may seoul republic of korea table evaluation results for all variants of selforacle across all sdcs.
.
.
.
.
unexpected nominal unexpected nominal auc prc auc roc tp fp tn fn tpr fpr f1 prec.
fpr tp fp tn fn tpr fpr f1 prec.
fpr dave vae .
.
.
.
.
.
.
.
.
.
.
.
dae .
.
.
.
.
.
.
.
.
.
.
.
sae .
.
.
.
.
.
.
.
.
.
.
.
cae .
.
.
.
.
.
.
n.a.
n.a.
lstm .
.
.
.
.
.
.
.
.
.
deeproad .
.
.
.
.
.
.
.
.
.
.
.
epoch vae .
.
.
.
.
.
.
.
.
.
.
.
dae .
.
.
.
.
.
.
.
.
.
.
.
sae .
.
.
.
.
.
.
.
.
.
.
.
cae .
.
.
.
.
.
.
n.a.
n.a.
lstm .
.
.
.
.
.
.
.
.
.
.
deeproad .
.
.
.
.
.
.
.
.
.
.
.
chauffeur vae .
.
.
.
.
.
.
.
.
.
.
.
dae .
.
.
.
.
.
.
.
.
.
.
.
sae .
.
.
.
.
.
.
.
.
.
.
.
cae .
.
.
.
.
.
.
n.a.
n.a.
lstm .
.
.
.
.
.
.
.
.
.
deeproad .
.
.
.
.
.
.
.
.
.
.
.
totals vae .
.
.
.
.
.
.
.
.
.
.
.
dae .
.
.
.
.
.
.
.
.
.
.
.
sae .
.
.
.
.
.
.
.
.
.
.
.
cae .
.
.
.
.
.
.
n.a.
n.a.
lstm .
.
.
.
.
.
.
.
.
.
deeproad .
.
.
.
.
.
.
.
.
.
.
.
when the next windows are labelled.
furthermore rimages occur in between an anomaly window in which the system is supposed to predict the upcoming misbehavior and the actual misbehavior.
this period would in practice be used by the self healing system to execute countermeasures against the predicted future misbehavior.
intuitively misbehavior prediction is expected to be much harder as the value of rincreases.
in our experiments we set the value ofn b 30frames i.e.
normal anomalous windows which is 3s.3the size of the healing window was set to h 5s frames and the size of the reaction window to r 4s frames.
.
.
metrics used for analysis.
if the loss score for an image is higher than the automatically estimated threshold section .
selforacle triggers an alarm.
consequently a true positive is defined when selforacle triggers an alarm during an anomalous window early enough to predict a misbehavior.
conversely a false negative occurs when selforacle does not trigger an alarm during an anomalous window thus failing at predicting a misbehaviour in time for triggering self healing.
a false positive represents a false alarm by selforacle whereas true negative cases occur when selforacle detects correct detection of normality.
we assume that a single alarm immediately starts the self healing system such that multiple consecutive alarms within the healing time are ignored.
correspondingly once a fp occurs and the self healing system is running additional consecutive fp windows have no effect in practice and are thus excluded from our analysis.
3in our setting udacity frame rate was approximately fps.our goal is to achieve high recall or true positive rate tpr defined as tp tp fn i.e.
true alarms while minimizing the complement of specificity or false positive rate fpr defined as fp tn fp i.e.
labelling safe situations as unsafe.
we are also interested in the f1 score f1 precision recall precision recall because in practice it is informative to have a high f1 score at a given threshold.
we also consider two threshold independent metrics for evaluating classifiers at various thresholds such as auc roc area under the curve of the receiver operating characteristics and auc prc area under the precision recall curve .
we included auc prc because auc roc may be not indicative when data are heavily unbalanced which is our case since anomalies are rare .
.
results effectiveness rq .table presents the effectiveness results on a per sdc model basis.
columns and show threshold independent measures of auc prc and auc roc.
the remaining of the table shows the effectiveness metrics across two confidence thresholds that we found interesting for analysis and correspond to .
and .
at lower values of both fpr and tpr get close to zero making the misbehaviour predictor useless .
overall lstm and vae are the best performing reconstructors on the auc prc and auc roc metrics.
columns and nominal fpr show fpr under conditions similar to those of the training set.
values are almost always near to zero and occasionally even equal to zero this is indicated by omitting the decimals across the variants of selforacle.
this is an empirical validation of the accuracy of the gamma distribution as a statistical model for the 367icse may seoul republic of korea a. stocco et al.
reconstruction errors.
in fact at .
most fpr reported in column are very close to the theoretical value see e.g.
rows under totals .
at .
some values drop to zero.
this means that in those configurations selforacle will raise no false alarm when the sdc drives in nominal conditions.
for instance with both thresholds lstm never raised false alarms within the normal windows.
in terms of tpr to be maximized and fpr to be minimized the best reconstructors are vae and sae with comparable overall performance tpr fpr of vae and sae at .
vae and sae at .
.
it can be noticed that fpr is higher than vs and vs with both reconstructors.
this was expected since we are measuring fpr in tracks with injected anomalies.
these tracks may differ substantially from the nominal tracks when anomalies are injected with low intensities.
these conditions are often not so extreme to cause a misbehaviour which explains why the fpr under anomalous conditions is over approximated.
however it is important to notice that even in such non nominal conditions in most cases the fpr remains low and not too far from the theoretical prediction .
to answer rq reconstructors vae and sae achieve a fpr in nominal conditions close to the theoretical expectations respectively and in the two considered configurations that in anomalous conditions fpr increases by a moderate amount respectively and .
the achieved tpr is quite high with vae sae respectively and .
the relation between area difference dand precision recall delta is quadratic thus precision recall improvements are expected to be the order ofp d .
for instance in table sae vs dae dave we have d .
for the specific threshold that ensures .
the corresponding improvements for tpr and fpr are .
and .
respectively.
prediction rq .figure shows the auc prc of the various configurations of selforacle over different reaction periods.
the general trend is that predictions get harder when the sdc is far from a critical scenario having a longer reaction period to prevent the misbehavior but quite surprisingly there is no drop in performance as we move away from the misbehaviour.
our explanation of this unexpected finding is that the tracks used for the evaluation of the approach contain always a relatively high degree of anomalous features which might trigger a self healing reaction.
occasionally the level of detected anomalies surpasses the threshold and the misbehaviour predictor raises an alarm.
correspondingly although slightly reduced the signals of an upcoming misbehaviour exist in images quite far even frames around s from the misbehaviour.
to answer rq the performance of selforacle degrades smoothly as we anticipate the prediction auc prc remains quite high up to s before the misbehaviour .
in our experiments selforacle is not sensitive to the choice of kif chosen in the range w normal window size .
we remark that this result must be taken with care and may be partially due to the characteristics of the considered tracks which contain a continuously and smoothly increasing degree of injected anomalies by design.
figure misbehavior prediction capability over time.
comparison rq .in our experiments selforacle is constantly superior to deeproad at predicting misbehaviours.
results of aucprc and auc roc show significant improvements across all thresholds regardless of the technique being used and the reaction period considered in figure deeproad is the lowest curve .
with .
resp.
.
vae and sae see table predict correctly more than twice the misbehaviours exposed by deeproad with a tpr vs respectively vs at comparable false positive rate fpr vs respectively vs .
concerning the runtime in our experiments the autoencoders took ms per prediction whereas deeproad took ms per prediction increment .
while such runtime measures seem acceptable in practical scenarios it is worth remembering that deeproad required us to dramatically sub sample the training set available for our experiments.
sdc manufacturers use much larger training datasets than the one used for our empirical study and deeproad s runtime is quite sensitive to the size of the training set which makes it quite unsuitable for online misbehaviour prediction because both computationally very expensive.
on the contrary autoencoders are a promising option given their relatively simple architecture.
in particular sae is very efficient yet it has comparable performance as the more sophisticated vae.
to answer rq selforacle outperforms deeproad in all respects computational cost accuracy of misbehaviour prediction see tpr and minimization of false alarms see fpr and auc prc .
.
threats to validity internal validity.
we compared all variants of selforacle and deeproad under identical parameter settings and on the same evaluation set.
the main threat to internal validity concerns our custom implementation of unexpected conditions within the simulator.
however this was a mandatory choice since we are not aware of open source driving simulators that can inject unexpected execution contexts in a controllable way.
another possible threat may be the choice and the training of our own sdcs which may exhibit a large number of misbehaviours if trained inadequately.
we 368misbehaviour prediction for autonomous driving systems icse may seoul republic of korea mitigated this threat by training and fine tuning the best publicly available driving models.
our own implementation of deeproad may be another threat to internal validity that we mitigated by developing an implementation which improves the original one by processing more information.
external validity.
we used a limited number of self driving systems in our evaluation as well as tracks which pose a threat in terms of generalizability of our results.
we tried to mitigate this threat by choosing popular real world sdc models which achieved competitive scores in the udacity challenge.
reproducibility.
all our results the source code of selforacle the simulator and all subjects are available .
related work autoencoder based anomaly detection.
a major testing issue with machine learning based systems is finding a confidence uncertainty metric of the machine learning component and being able to distinguish the nominal vs abnormal behaviours of the system in operation.
to this extent the machine learning literature has seen a proliferation of autoencoder based anomaly detection techniques applied to different domains among which time series surveillance videos robot assisted feeding or web applications .
all such papers propose and evaluate their techniques mostly for classification problems on which the concept of misbehaviour is more easily tractable.
differently we target online misbehaviour prediction for autonomous driving systems i.e.
complex dnns that predict the car s actuators values.
our work aims to improve the dependability of a whole autonomous driving system and prevent the occurrence of future failures rather than focusing on individual dnn s model level inaccuracies.
concerning the very definition of unseen situation bolte et al.
provide a definition of misbehaviour based on non predictable relevant objects in a relevant location around the car.
such a definition can be used in our framework by replacing our reconstruction error component with an object recognition component.
several works leverage anomaly detection techniques to identify unexpected execution contexts during the system s operation whereas a few papers are related to online risk assessment and failure probability estimation for mls .
in the context of autonomous driving systems henriksson et al.
use the negative of the log likelihood of the images generated by a vae as an anomaly score for driving images.
however their evaluation is performed on unrealistic scenarios because the data distribution of the images in the test set urban scenes is by far quite different from that of the training set highway scenes .
in our experiment we create the anomalous set by gradually injecting anomalous conditions starting from the training set tracks which allows a more realistic transition from nominal to unexpected scenarios.
adversarial input generation.
adversarial input generation approaches aim at generating inputs that trigger inconsistencies between multiple autonomous driving systems or between the original and transformed driving scenarios .
these works exploit the well known fragility of dnns to adversarial examples.
therefore their main use case concerns the identification of underrepresented scenarios in the training data e.g.
snowy weather condition to support re training and better generalization afterre training.
the only comparable technique is the online input validation of deeproad for which we carried out an explicit comparison in our empirical study finding poor performance when used for online misbehaviour prediction.
despite the different goal test generation vs misbehaviour prediction we share with these works the problem of how to empirically validate the proposed technique in the absence of a precise oracle that defines the expected behaviour of a self driving car.
the prevalent choice in test generators is to address the oracle problem by differential testing i.e.
by comparing the behaviours of multiple dnns or by metamorphic testing i.e.
by comparing the behaviour before and after applying a metamorphic transformation to the input.
approaches based on verification are also being under investigation .
in this paper we adopt a precise definition of dnn misbehaviour which gives us a very accurate functional oracle with no need for differential testing metamorphic testing or verification.
search based test generation.
abdessalem et al.
combine genetic algorithms and machine learning to test a pedestrian detection system.
mullins et al.
use gaussian processes to drive the search towards yet unexplored regions of the input space whereas gambi et al.
propose asfault a search based test generator for autonomous vehicles based on procedural content generation.
asfault uses search operators which mutate and recombine road segments to construct road networks for testing the lane keeping functionality of self driving cars.
their goal is to generate extreme and challenging roads maximizing the number of observed obes while our goal is to predict obes.
conclusions and future work in this paper we studied the problem of estimating the confidence of the dnn based autonomous in response to unexpected execution contexts.
our tool selforacle was able to anticipate by several seconds many potentially safety critical misbehaviours such as out of bound episodes or collisions with a low false alarm rate outperforming the input validator of deeproad.
future work concerns experimenting with other white box dnn confidence metrics as well as other types of reconstructors among which denoising autoencoders and adversarial autoencoders .
on the same line more elaborate lstm based solutions other than the simple architecture proposed in this paper will be investigated.
it would be also interesting to characterize and predict other kinds of misbehaviours e.g.
derivative of steering angle in order to allow confidence guided self healing within the simulator and leverage more sensor information sources e.g.
lidar to improve selforacle s prediction accuracy.
we believe that our promising results in online misbehaviour detection united with the availability of a labeled dataset of crashes and a simulation environment can foster novel approaches for online prediction and self healing of autonomous driving systems.