modeling review history for reviewer recommendation a hypergraph approach guoping rong yifan zhang lanxin yang fuli zhang hongyu kuang he zhang state key laboratory of novel software technology software institute nanjing university nanjing jiangsu china ronggp nju.edu.cn yifanzhang590 gmail.com yang931001 outlook.com mg1932016 smail.nju.edu.cn khy nju.edu.cn hezhang nju.edu.cn abstract modern code review is a critical and indispensable practice in a pull request development paradigm that prevails in open source software oss development.
finding a suitable reviewer in projects with massive participants thus becomes an increasingly challenging task.
many reviewer recommendation approaches recommenders have been developed to support this task which apply a similar strategy i.e.
modeling the review history first then followed by predicting recommending a reviewer based on the model.
apparently the better the model reflects the reality in review history the higher recommender s performance we may expect.
however one typical scenario in a pull request development paradigm i.e.
onepull request pr such as a revision or addition submitted by a contributor may have multiple reviewers and they may impact each other through publicly posted comments has not been modeled well in existing recommenders.
we adopted the hypergraph technique to model this high order relationship i.e.
one prwith multiple reviewers herein and developed a new recommender namely hgrec which is evaluated by oss projects with more than 87k prs 680k comments in terms of accuracy andrecommendation distribution.
the results indicate that hgrec outperforms the state of the art recommenders on recommendation accuracy.
besides among the top three accurate recommenders hgrec is more likely to recommend a diversity of reviewers which can help to relieve the core reviewers workload congestion issue.
moreover since hgrec is based on hypergraph which is a natural and interpretable representation to model review history it is easy to accommodate more types of entities and realistic relationships in modern code review scenarios.
as the first attempt this study reveals the potentials of hypergraph on advancing the pragmatic solutions for code reviewer recommendation.
ccs concepts software and its engineering collaboration in software development information systems recommender systems.
permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
copyrights for components of this work owned by others than acm must be honored.
abstracting with credit is permitted.
to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
request permissions from permissions acm.org.
icse may pittsburgh pa usa association for computing machinery.
acm isbn .
.
.
.
modern code review reviewer recommendation hypergraph acm reference format guoping rong yifan zhang lanxin yang fuli zhang hongyu kuang he zhang.
.
modeling review history for reviewer recommendation a hypergraph approach .
in 44th international conference on software engineering icse may pittsburgh pa usa.
acm new york ny usa pages.
introduction as a popular software practice code review is believed to be paramount to software quality for both commercial projects and open source software oss projects .
through manually scrutinizing source code reviewers aim to identify possible issues or improvement opportunities and thereby prevent issue prone code snippets from being incorporated into project repositories .
in addition to secure quality code review is also helpful in knowledge dissemination team collaboration etc.
however studies show that code review highly relies on the experience and knowledge of reviewers which implies that the identification of suitable reviewers is crucial to review efficacy.
nowadays an informal asynchronous and tool based code review practice that is known as modern code review mcr is widely adopted in software development .
in the oss community mcr is an essential step in a so called pull request development paradigm where developers make changes to some code snippets and submit a pull request pr to the project repository.
then potential reviewers including project owners examine the prand provide feedback through an issue tracking system e.g.
jira1 gerrit2 etc.
if the issues related to the prwere properly addressed one project owner then merges the printo the project repository .
studies indicate that mcr quality is subject to many factors among which the reviewers expertise and workload can make a significant difference .
in this sense it is also crucial to find suitable reviewers for a certain pr especially in the context of the oss development where the potentially massive participants are usually geographically distributed and not necessarily known to each other.
in fact as thongtanunam et al.
pointed out inappropriate assignment of code reviewer may take days longer to approve a code change in oss development thus a recommendation tool is necessary to speed up a code review process .
in the past decade researchers have worked out a number of reviewer recommendation approaches recommenders in order to ieee acm 44th international conference on software engineering icse authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
icse may pittsburgh pa usa guoping rong yifan zhang lanxin yang fuli zhang hongyu kuang he zhang automatically assign a prto potentially suitable reviewers.
in general recommenders are developed by following a similar strategy i.e.
to predict recommend a reviewer based on a model from historical reviews.
for example heuristic based recommenders model the review history by mining simple rules based on the relationships among source files revisions and participants.
that is whoever most frequently revised or reviewed the source code snippets included in a certain prpreviously should be recommended to perform the review first.
learning based recommenders model the review history by machine learning techniques and then use the trained models to determine the most potentially suitable reviewers.
it is widely agreed that models play a vital role in all recommenders.
however the models behind heuristics based recommenders are combinations of simple rules reflecting relationships which is very likely to miss crucial information e.g.
the mutual impacts among reviewers .
this may be one of the reasons that most heuristics based recommenders can not achieve satisfactory recommendation accuracy .
meanwhile the learning based recommenders may be able to process more information of the review history yet the low interpretable models behind and heavy workload on feature engineering also prevent them from evolving to quickly adapt themselves to new situations.
recently some researchers began to apply graph techniques to model the relationships among entities such as source code participants prs etc.
as the modeling data structure a graph is able to support more sophisticated heuristics algorithms.
besides it is also able to support multiple machine learning algorithms and improve model interpretability .
however since a single edge in an ordinary graph can only associate two vertexes it is difficult if not impossible to model a common phenomenon in oss development i.e.
one prmay involve multiple reviewers.
as a result most graph based recommenders also have not presented satisfactory recommendation accuracy .
ordinary graph n1 n2 n4n3n6 n5 w n1 n2 n3 n4 n5 n6n1n2n3n4n5n6hypergraph hyperedge group n1 n2 n4n3n6 n5n1 n2 n4n3n6 n5n1 n2 n4n3n6 n5e1e2 e1 e2e3 e4e5e6 h1 concathyperedge group n1n2n3n4n5n6 e3 e4h2 n1n2n3n4n5n6 e5 e6h3 n1n2n3n4n5n6 e1 e2h1 n1n2n3n4n5n6 e3 e4h2 e5 e6h3 hyperedge group figure ordinary graph and hypergraph recently a technique namely hypergraph has been utilized to model the complex relationships among multiple entities.
briefly a hypergraph is a generalization of an ordinary graph in which an edge can associate any number of vertexes.
for example as shown on the right of figure a hyperedge e2simultaneously connects three vertexes n2 n5 n6 .
in contrast in an ordinary graph an edge connects exactly two vertexes shown on the leftof figure .
take figure as a review example there are three reviewers namely reviewer a reviewer b andreviewer c having reviewed the identical pr.
in an ordinary graph the review history is modeled as reviewer pairs i.e.
reviewer a b reviewer b c andreviewer a c have reviewed one same pr.
however the fact that reviewer a b andcactually have reviewed the same pris not able to be reflected in an ordinary graph.
since certain form of familiarity e.g.
similar review experience history forms the basis for most reviewer recommenders the loss of this information will inevitably impact the recommendation performance.
in contrast since multiple vertexes can be included in one edge hypergraph offers more natural approaches to model the review history portrayed in figure which provides more information for recommenders to perform recommendation.
figure one prinvolves multiple reviewers in practice in this study we applied the hypergraph technique to model the aforementioned complex relationship among various entities in a natural and interpretable way.
based on this model we also developed a new reviewer recommender namely hgrec to explore the feasibility and effectiveness of this strategy.
an extensive empirical study based on oss projects with more than 87k prs and 680k review comments indicates the superiority of hgrec in terms of recommendation accuracy as well as workload balance among reviewers.
the contributions of this study can be highlighted as below.
to the best of our knowledge this is the first effort that hypergraph is used to model code reviews as well as complex relationships among participants e.g.
one reviewer may be affected by others comments.
we developed a new recommender i.e.
hgrec based on hypergraph technologies.
we empirically evaluated hgrec the results indicate that hgrec not only outperforms the state of the art recommenders in terms of recommendation accuracy but to some extent mitigates the workload congestion issue.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
modeling review history for reviewer recommendation a hypergraph approach icse may pittsburgh pa usa related work .
code reviewer recommendation .
.
recommenders.
automated reviewer recommendation has attracted a lot of attention in the past decade.
a number of recommenders have been proposed which follow a similar strategy in general i.e.
modeling review history and use the result model to recommend a new reviewer.
in general there are three main types of recommenders according to different modeling approaches i.e.
the heuristics based learning based and graph based recommenders respectively.
heuristics based recommenders.
this type of recommenders suggests new reviewers with simple heuristic rules.
for example thongtanunam et al.
proposed a recommender based on file path similarity which subsequently evolved into revfinder .
the revfinder is based on the similarity between the file paths of a previous pr and a new pr.
zanjani et al.
developed a recommender chrev that determines candidates on a basic premise that the reviewers who have reviewed target code snippets before are most likely to be recommended.
rahman et al.
proposed a recommender correct that utilizes external library similarity and technology expertise similarity of reviewers which provides a possibility for cross project reviewer recommendation.
jiang et al.
analyzed several attributes related to the code review and found that activeness based recommender ac performed the best.
other rules adopted in the heuristics based recommenders include line rule expertise recommender code ownership and expertise cloud etc.
usually the models used by the heuristicsbased recommenders are merely simple statistics or comparison results on the original review history.
most heuristic based recommenders are easy to understand.
however research indicates that most of them suffer from low accuracy.
moreover it is usually hard to add more elements information to enhance the models based on simple heuristic rules which impacts their evolvability.
learning based recommenders.
this type of recommenders assumes that the prprofile and reviewers personal expertise can be automatically learned from the review history by training.
among them support vector machine svm random forest rf and bayesian network bn are widely applied .
de lima j nior et al.
investigated several kinds of learning based recommenders including na ve bayes nb decision tree j48 rf and sequential minimal optimization smo and found that rfoutperforms others in terms of recommendation accuracy.
in general learning based recommenders usually perform better than simple heuristics based recommenders however the models behind these recommenders need a heavy workload on feature engineering training and longterm maintenance.
besides they are normally not interpretable also which becomes a barrier for future extension and improvement for the recommenders.
graph based recommenders.
recently graph techniques have been adopted to model the review history through which personal profiles and social relationships or networks between developers and reviewers are thus formalized into graph vertexes and edges.
using graph as the model both sophisticated heuristics and learning algorithms can be used to design recommenders.
for example yu et al.
found that developers whoshare common interests with a proriginator are potentially suitable reviewer candidates.
liao et al.
combined prtopic model with social networks to build the connections between collaborators and prs.
s l n et al.
used software artifact traceability graphs to recommend reviewers who potentially are familiar with a given artifact.
.
.
recommendation distribution.
the rationale behind nearly all the recommenders implies that one reviewer who conducted the most reviews in the history tends to be recommended in a future review.
as a matter of fact it is common that a few core reviewers took over the most workloads on code review which becomes a severe issue of workload congestion for some core reviewers leading to review overload for these core reviewers .
recent studies have proposed some solutions to alleviate the workload congestion.
asthana et al.
proposed a recommender whodo where reviewers scores are reduced by his her incomplete prs so as to decrease his her chance to be recommended.
al zubaidi et al.
presented a workload aware recommender wlrrec by utilizing nsga ii a multi objective search based approach to address two main objectives maximizing the chance of participating in a review and minimizing the skewness of review workload distribution.
rebai et al.
balanced the conflicting objectives of expertise availability and history of collaborations with multiobjective search techniques.
mirsaeedi et al.
systematically take expertise workload and knowledge distribution for collaborators in recommending new reviewers.
in short the workload congestion issue has raised wide concern in the research community on reviewer recommenders and should not be neglected in designing and evaluating recommenders.
.
hypergraph approach for software engineering a hypergraph is an extension of the ordinary graph that consists of multiple vertexes and hyperedges which can depict the highorder relationships among entities .
therefore unlike the pairwise relationships depicted in an ordinary graph hypergraph has the ability to express complex relationships in the real world which prevents information loss as far as possible .
this merit enables hypergraph techniques to be used in some software engineering scenarios.
for example g de et al.
used hypergraph based models on cloned code fragments and analyzed clone evolution in mature projects.
thom et al.
used hypergraph to implement a search driven string constraint solving algorithm to detect vulnerabilities in the program.
jiang et al.
used hypergraphs to represent code and implemented a framework for interring program transformations.
while the studies that use hypergraph techniques to model the complex relationships among software artifacts are not rare to the best of our knowledge this technique has never been used in reviewer recommendation which usually involves both entities such as humans and artifacts as well as the complex and high order relationships among different entities.
this motivates the hypergraph based recommender i.e.
hgrec that is proposed in this study.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
icse may pittsburgh pa usa guoping rong yifan zhang lanxin yang fuli zhang hongyu kuang he zhang start repository add a new prhypergraphgbase end recommend reviewer candidates for a incoming prconstruct a hypergraph gbase to model review historya2a1p1 p2r1 r2 r3e1 e2 e3e4e5initialize rank candidates score .
score .
r2r1 score .
r3 recommendation list for pt1st reviewer 2nd reviewer 3rd reviewer hypergraphgta2a1p1 p2r1 r2 r3vertex set add hyperedge relationship a2a1p1 p2r1 r2 r3 atpte1e2 e3e4e5 e6e7 e8 contributor pr reviewerpr contributor edge pr pr edge pr reviewer edge new hyperedge the values here are just examples.
figure overview of hgrec approach there are two major steps to design and implement hgrec i.e.
hypergraph construction and reviewer recommendation respectively.
in this section we elaborate these two steps in detail.
.
approach overview figure depicts the two major steps of hgrec.
the top segment shows the process to construct a base hypergraph gbase which is based on the review history retrieved from project repositories the bottom of figure presents the process to recommend potentially suitable reviewers for an incoming new pr saypt.
the basic idea is to add ptand corresponding contributor at to the existing hypergraph gbase to form a new hypergraph gtusing the similar strategy to construct gbase.
then a hypergraph based search strategy which calculates vertex score using a localized first order approximation is applied to rank and recommend candidate reviewers.
details of the hypergraph construction and reviewer recommendation will be elaborated in the following subsections.
table key notations notations descriptions prs the set of pull request pr s withnprs at first pi i aprinprs ai the contributor of prpi ri the set of reviewers to prpi rij j a reviewer in ri fi the set of changed file paths involved in prpi fik k a file path infi g the hypergraph constructed based on prs v the set of vertexes in g e the set of hyperegdes in g in order to eliminate ambiguity we first define some key notations in table .
to be specific the review history of an oss project is represented by a set of prs prs including the contributors ai reviewers ri and changed file paths fi involved in each pr pi .
a hypergraph gbase is used to model the review history based on which a new hypergraph gt is generated by adding an incoming new pr saypt togbase.
.
hypergraph construction intuitively for a target pr the adjacent prs in terms of file paths share certain similarities regarding content or function which mayalso be able to reflect the similarity regarding experience and familiarity towards the target pramong the contributors and reviewers involved in these prs.
using hypergraph the relationships among different entities involved in these prs can be created in a succinct and natural representation.
two major steps are included to construct a hypergraph i.e.
the architecture building and the edge weight respectively.
as shown in algorithm function constructiondepicts the former step while the latter step is described by the function buildedge.
algorithm hypergraph construction input pr set prs contributor list a a1 a2 ... a n reviewer set r r1 r2 ... r n output hypergraphgbase vbase ebase 1function construction prs a r 2vbase ebase forpi prsdo vbase vbase pi ai ri add vertexes edgeepc buildedge pi ai add pr contributor edge edgeepr buildedge pi ri add pr reviewer edge ebase ebase epc epr end forpi prsdo edge setei forpj prsdo edgeepp buildedge pi pj add pr pr edge ei ei epp end sortweightaddfilter ei select high weight edges in set ebase ebase ei end 18gbase vbase ebase returngbase 20endfunction 21function buildedge pi x edgee addvertex pi x xcan be the contributor ai or reviewer set ri or pr pj 23w caculateweight pi x setweight e w add weight to edge returne 26endfunction in general function construction describes the main logic for hypergraph construction which takes review history contributors reviewers prs etc.
as inputs.
lines initializes the vertex set vbase and hyperedge set ebase.
the for loop in lines updates hypergraph by adding new vertexes of prs contributors and reviewers as well as hyperedges of pr reviewer andpr contributor.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
modeling review history for reviewer recommendation a hypergraph approach icse may pittsburgh pa usa the hyperedges representing pr pr relationship should be separately processed in lines since global information is needed to calculate edge weight.
finally line returns the result hypergraph gbase.
note that function construction invokes the function buildedge to calculate the weights for hyperedges according to different relationships which is detailed in lines .
since different types of relationships require different methods to calculate the edge weight we elaborate them in detail as the following.
pr reviewer the relationships between prs and reviewers are necessary for all kinds of graph based recommenders.
in a pullrequest development paradigm one prmay experience multiple revisions and re submissions which would usually engage multiple reviewers and they may impact each other by publicly posted review comments.
therefore in addition to the regular relationship i.e.
a pair of one reviewer and one pr reviewers who comment on the same prare connected with a hyperedge in a hypergraph.
inhgrec the weight of a pr reviewer edge is set by aggregating all reviewers contributions which is formulated in equation .
w r1i r1o1i j 1 j 1etij te te ts where reviewers in set r1participated in the prp1 reviewerr1i madeo1icomments in the prp1.
the creation time of each comment istij.
the hyperparameter in equation works for mitigating the influence of comments cf.
subsection .
for details .
moreover reviewers activeness was also considered in hgrec i.e.
the closer reviews are the greater influence they carried.
tsandteare the start time and the end time of dataset in equation .
pr contributor contributors and reviewers may play different roles in a pull request development paradigm.
therefore they are treated differently in hgrec by defining the pr contributor relationship and the corresponding weight.
as equation the more recent activity is the higher weight.
w t1 ts te ts t1is the creation time of prp1.tsandtetake the same meaning as in equation .
pr pr the profiles e.g.
language code lines and content e.g.
the source code included in prs to a certain degree can reflect the expertise of contributors.
moreover it is also common that closely located source files share similar functions and hence can be used for reviewer recommendation .
therefore the weight of pr pr relationship is achieved by considering the distances between prs in the file path set as shown in equation .
w f1 f1 f2 f2similarity f1 f2 f1 f2 e t1 t2 te ts where function similarity is calculated as equation similarity f1 f2 lcp f1 f2 max len f1 len f2 wheref1 f2are the file path sets contained in two prs sayp1and p2.f1andf2are the specific file paths that belong to the file path setsf1andf2.we also model developers turnover as an exponential function to smoothen the distance between two prs.
in the exponential function of equation tsandteare the creation and end time of dataset t1andt2are the creation time of two prs respectively.
through this way within a certain time scope the latest prs are preferentially considered.
to reduce calculation cost we restricted the number of neighbors for a certain prand simplified the hypergraph that only top mpr pr connections cf.
subsection .
for details were included.
moreover we employed a min max strategy to normalize the weight for each type of edge.
.
reviewer recommendation with a constructed hypergraph in hand we then can perform a recommendation calculation based on the hypergraph.
in general we formulated reviewer recommendation as a ranking task on a hypergraph.
previous studies e.g.
used random walk strategy to choose neighborhood as the next vertex with a certain probability which is somehow low effective.
inspired by we applied an advanced search and ranking strategy in hgrec which is elaborated briefly in this subsection.
given a hypergraph gbase and a newly submitted pt we first develop pr pr relationship by calculating its file path similarities with existing prs ingbase and then we connect ptwith the most similar prs.
by following a similar strategy algorithm we can establish the pr contributor relationship.
in this way both new prs and contributors are merged into the original hypergraph gbase to form a new gt vt et .
for a hypergraph g the key of this ranking strategy is to find the appropriate ranking vector f r v which is able to minimize the objective function q f defined as below q f ft i a f f y t f y wherey r v is a query vector with multiple elements one for each vertex of the hypergraph gwhich will be set to for a target prand its contributor otherwise .
hg r v e is a vertex hyperedge incidence matrix wg r e e is a weight matrix dgvis a vertex degree matrix and dgeis a hyperedge degree matrix a dgv 1hgwgdge 1hgt and is the regularization parameter.
through a series of deductions and transformations we have the optimal f as f i a 1y i a 1y where .
having ranked on the hypergraph we can recommend the top k reviewers as the candidates.
the whole recommendation process is presented in algorithm .
algorithm takes hypergraph gbase prsetprs and target pras its inputs.
line initializes candidate list ct. line is to add vertexes of three types of entities.
lines also invoke function buildedge cf.
algorithm to build relationships of pr contributor andprpr.
line generates the query vector ytbypt.
line optimizes objective function q f and get the ranking vector.
lines rank and return a recommendation list according to ranking strategy.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
icse may pittsburgh pa usa guoping rong yifan zhang lanxin yang fuli zhang hongyu kuang he zhang algorithm hypergraph based recommendation input hypergraphgbase pr set prs target prpt contributor at output recommend list ct 1function recommendtaion gbase prs pt at 2ct 3vt vbase pt at add new vertexes to gbase edge setet edgeepc buildedge pt at add pr contributor edge forpi prsdo edgeepp buildedge pt pi add pr pr edge et et epp end sortweightaddfilter et select high weight edges in set 11et et epc 12gt vt et 13yt queryvector vt pt at use search and ranking strategy 14f ranking gt yt get candidates score 15ct filterandsort f get recommendation list returnct 17endfunction .
hyperparameter setting the hyperparameters i.e.
m play critical roles in hgrec.
is the regularization parameter.
the smaller the larger influence of regulation that is the weight of vertexes access to query vector y. in this case the nearby reviewers around target prs and contributors have more chances to be recommended.
mrepresents the maximum connections of a pr represents the influence posed by a reviewer in a history review.
increasing hgrec tends to recommend non core reviewers which is important to mitigate workload congestion issue discussed in section .
.
.
increasingmor reducing hgrec tends to recommend core reviewers.
since there are no specific rules to determine mand we set them by a trial and error approach.
after many rounds of trial calculations we found that hgrec can produce relatively good results under the following combination of parameters i.e.
.
m .
.
evaluation design .
research questions two research questions rqs are proposed for the evaluation which are rq1 to what extent can the proposed hgrec accurately recommend code reviewers?
rq2 to what extent can the proposed hgrec alleviate workload congestion issue?
rq1 evaluates the performance of hgrec in terms of accuracy whereas rq2 assesses hgrec s capability of dealing with the other concern workload congestion issue.
.
data preparation github provides multiples apis to assess various project data.
for potential comparison and calibration the chosen projects are the common ones from previous studies.
since the evaluation involves several time consuming tasks as a balance between resources e.g.
time computing resource etc.
and the capability to generalize the evaluation results we selected those projects that appear at least in two of the previous studies containing the baseline recommenders cf.
subsection .
.
.
as a result we chose well known projects in github to evaluate the performance of hgrec as well as other recommenders in order to position our recommender.
the time span of the dataset is from to .
detailed demographics of the dataset are presented in table .
table overview of the selected projects project prs comments reviewers contributors akka angular baystation12 bitcoin cakephp django joomla cms rails scala scikit learn symfony xbmc total .
experiment settings .
.
baselines.
to evaluate hgrec thoroughly the following representative traditional recommenders and state of the art recommenders as well are compared as the baselines which are ac that recommends reviewers based on recent activities of the candidates.
reviewers who leave comments frequently in recent prs are determined to be active and prone to be recommended otherwise inactive.
revfinder that recommends reviewers by leveraging the file path similarities of prs i.e.
the files located in close files may share similar functionality and therefore should be reviewed by reviewers with similar experience.
chrev that recommends reviewers on the premise that who previously reviewed the code files is tended to be candidate reviewers for a target pr.chrev formulates reviewers expertise based on how many who performed and when reviews were performed .
cn that recommends reviewers by aggregating developers who share common interests with the contributor of target pr.cnmines historical comment traces to construct a comment network to make recommendations.
rf that recommends reviewers by applying supervised machine learning i.e.
collecting project attributes and prs to construct classifiers and rank candidates.
earec that recommends reviewers by constructing a graph architecture to depict the expertise and authority of developers as well as their interactions.
the recommendation is performed using graph searching algorithms.
the considerations are three fold.
first acandrfhave shown impressively good performance in terms of accuracy in many studies .
second cnandearec both adopt graph an ordinary graph as the underlying model.
last but not least as two classical recommenders revfinder and chrev have been used as the comparison basis frequently in many existing studies.
.
.
metrics.
to address rq1 we need to evaluate the performance of hgrec in terms of accuracy.
we take two common metrics authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
modeling review history for reviewer recommendation a hypergraph approach icse may pittsburgh pa usa in recommender evaluation studies i.e.
accuracy acc defined as equation and mean reciprocal rank mrr defined as equation .
accuracy acc prs p prsistrue p k where prsis a set of target prs indicator function istrue p k returns if the recommended reviewer within top kcandidates finally reviewed the target pr p otherwise returns .
mean reciprocal rank mrr prs p prs1 rank p k where function rank p k returns the location where the true reviewer places in the sorted reviewer list.
mrr rewards score if the first choice was correct and rewards if the second choice was correct and so on.
while if the recommended reviewer is not contained in the candidate list then mrr rewards .
the final mrr is calculated as the average value of all the scores.
to answer rq2 we defined recommendation distribution rd as equation to measure the extent that diverse reviewers can be recommended.
recommendation distribution rd rd log2nn i 1p i log2p i where nis the total number of reviewers p i is a percentage that indicates the workload of the ithreviewer.
the larger rd the more diverse that a recommender recommends reviewers.
as a popular standard in the related studies we evaluated the top k k performances of the recommenders.
to further test the difference we established hypotheses and applied the wilcoxon signed rank test on acc mrr andrd.
the null and alternative hypotheses can be stated as follows h0 m there is no significant difference on the metrics m between hgrec and r. h1a m hgrec is significantly better than r on metrics m. h1b m hgrec is significantly worse than r on metrics m. where mcan be acc mrr andrdand correspondingly rrepresents one recommender introduced in section .
.
.
.
.
data pre processing.
following the similar method in we applied a time series strategy to evaluate the recommenders performance in terms of acc mrr and rd.
to be specific all the reviews in were initiated as the original training set and hereafter each monthly review until jun played the role of the test set.
therefore we eventually performed rounds of evaluation in total as shown in figure .
take the first round for example the first month data is fed into all the recommenders and then the data of the 13th month is used to calculate acc mrr andrdusing equation and respectively.
training set months test set month training set month training set months training set months the prs in chronological order test set month test set month round round round round 30test set month figure dataset setting for evaluation results and analysis following a common strategy we compare hgrec with other recommenders in terms of acc mrr andrdusing top top3 and top criteria respectively.
this section presents the results and the corresponding analysis.
.
accuracy rq1 table shows the performance of each recommender in terms of acc.
the results in bold mean the best recommender regarding acc for a certain project.
for example hgrec performed the best in project akka with all the top top and top criteria.
in general hgrec acandrfperformed relatively better than other recommenders in most cases.
to be specific hgrec takes the lead on projects in terms of top top top acc.
as the close competitors acwins on projects rfleads on projects using the same top top top criteria.
the last row in table lists the average acc for all the recommenders which further indicates hgrec s superiority.
with all the top top top criteria hgrec produces the best average acc.
besides compared with other two recommenders i.e.
cnandrarec using graph techniques hgrec outperforms the others regarding acc for both solo project and the overall average indicating the advantage of hypergraph technique to model the review history.
moreover as the comparison basis the acc given by recommender revfinder andchrev is not ideal which to a fair degree is in line with other studies .
to further test the difference a wilcoxon signed rank test has been conducted on acc using the data from all the projects.
note that there are data points in each project according to the experimental setting elaborated in subsection .
.
.
due to page limits3 we present the number of projects in which we are not able to reject a certain hypothesis i.e.
h0 m h1a mandh1a m where mdenotes acc with p value .
.
the results are listed in table the columns under acc .
take the first row as an example in out of projects hgrec produces a significantly better acc than recommender revfinder using the top criteria meanwhile there are projects in which no significant difference onacc between revfinder andhgrec has been observed.
the rest is similar which also confirms our intuitive observation derived from table i.e.
hgrec performed the best on acc among the recommenders involved in this study.
3the dataset source code and complete results are now public online through authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
icse may pittsburgh pa usa guoping rong yifan zhang lanxin yang fuli zhang hongyu kuang he zhang table acc of recommenders revfinder cn ac chrev rf earec hgrec akka .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
angular .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
baystation12 .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
bitcoin .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
cakephp .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
django .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
joomla cms .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
rails .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
scala .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
scikit learn .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
symfony .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
xbmc .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
avg .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
table mrr of recommenders revfinder cn ac chrev rf earec hgrec akka .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
angular .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
baystation12 .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
bitcoin .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
cakephp .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
django .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
joomla cms .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
rails .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
scala .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
scikit learn .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
symfony .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
xbmc .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
avg .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
table rdof recommenders revfinder cn ac chrev rf earec hgrec akka .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
angular .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
baystation12 .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
bitcoin .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
cakephp .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
django .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
joomla cms .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
rails .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
scala .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
scikit learn .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
symfony .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
xbmc .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
avg .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
table number of projects by wilcoxon signed rank test onacc mrr rdof recommenders acc mrr rd m top kh1a mh0 mh1b mh1a mh0 mh1b mh1a mh0 mh1b m revfinder1 cn1 ac1 chrev1 rf1 earec1 mrr also measures the performance regarding recommendation accuracy.
based on table and table we are able to observe similar results i.e.
hgrec leads the performance on recommendation accuracy among all the recommenders mentioned in this study.
.
workload rq2 recently researchers raise a new concern other than the accuracy of recommenders.
that is most recommenders tend to suggest a small group of core reviewers i.e.
the reviewers who reviewed the most prs in a certain project have more chance to be recommended .
this phenomenon may cause severe problems in projects with massive prs within a relatively short period.
rdis quantified to show the status of workload congestion.
similarly we also evaluated recommenders performance regardingrdand further tested the difference using wilcoxon signed rank test.
table lists the results of rdfor all the recommenders on all the projects.
in general chrev performs the best in all the recommenders.
meanwhile next to chrev hgrec andcnpresent comparable performance regarding rd.
nevertheless chrev and cnshowed relatively poor performance regarding acc.
a noteworthy point is that among the best recommenders regarding acc hgrec outperforms the others i.e.
rfandacby a discernible margin.
the wilcoxon signed rank test results listed in table also confirm these observations.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
modeling review history for reviewer recommendation a hypergraph approach icse may pittsburgh pa usa .
.
.
.
.
.
chrev39 .
.
.
.
.
.
hgrec3939 .
.
.
.
.
.
cn .
.
.
.
.
.
rf76 .
.
.
.
.
.
revfinder6969 .
.
.
.
.
.
ac .
.
.
.
.
.
earec0.
.
.
.
.
.
chrevhgreccnrevfinderrfacearec39 examplethe prs assgined to each reviewer ... figure top workload distributions of recommenders on project angular recommended reviewers in x axis prs assigned to each reviewer in y axis to present an intuitive concept take project angular as an example figure shows the workload distribution resulting from diverse recommenders based on the number of prs in one month for project angular .
each column represents one reviewer s workload i.e.
prs assigned the broken line represents accumulated workload on diverse reviewers.
for top accurate recommenders hgrec tends to create a relatively balanced workload for top core reviewers.
take rffor example the top core reviewers are recommended for reviewing and prs in just one month which might be huge burdens for them.
as a comparison the top core reviewers are recommended by hgrec for merely and prs.
the reason behind this phenomenon is that by properly tuning and inhgrec the importance score for some reviewers sharing the review experience on the same prs has been increased which increases their chances to be recommended even they may not be active reviewers in the past.
discussion .
graph technology for recommenders to represent relationships in a review recommendation paradigm is a basis of a recommender.
although some graph technologies have been adopted to model the relationships when developing recommenders the primary innovation in hgrec lies in the introduction of hypergraph to model multiple participants involved in onepr which is very common in oss projects and easy to understand.
compared with the traditional recommenders that are based on the ordinary graphs hgrec consists of multiple vertexes and hyperedges that can naturally model the complex high order relationships among prs contributors and reviewers.
besides hgrecsupports a flexible recommendation architecture that is more entities and relationships e.g.
organization comments can be involved inhgrec if necessary.
when it comes to recommenders with similar technologies cn only considers simple relationships such as developer vertexes their interactive relationships e.g.
review activities are formulated by directed edges.
cnsuggests candidate reviewers who share common interest with contributors but neglects the prinformation itself.
on the contrary earec includes both prand reviewer vertexes and recommends candidates by matching the characteristics of target prand expertise of candidates.
however earec does not consider the information of contributors internal relationships e.g.
the social relationships which may not be able to be directly obtained from reviewer s profile.
hgrec systematically combines multiple roles including prs content and interactive relationships among the three entities i.e.
prs contributors and reviewers .
more importantly hgrec is able to model the complex in an intuitive manner close to the reality.
.
model interpretability in recent years ai artificial intelligence ml machine learning techniques are widely used in software engineering such as software defect prediction continuous integration prediction software defect developer recommendation code reviewer recommendation etc.
the interpretability of ai ml model has naturally become the focus of these studies.
according to the interpretability of ai ml model is the degree to which a human can understand the reasons behind a decision.
for example the model interpretability should reflect the relationship of feature on the outcome the importance of each feature the decision rule of each authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
icse may pittsburgh pa usa guoping rong yifan zhang lanxin yang fuli zhang hongyu kuang he zhang feature etc .
the importance of model interpretability in software engineering is obvious since without proper understanding towards the model practitioners may not trust and adopt the model in practice .hgrec models the review history using hypergraph which explicitly includes the interaction among contributors prs and reviewers.
besides the setting of parameters directly reflects the recommendation inclination.
these characteristics of hgrec obviously make the rationale of reviewer recommendation much easier to be understood.
.
capability to support future improvements hypergraph distinguishes itself not only by its straight adaption to code review but also its architecture s flexibility and extensibility which supplies a promotion for improvement in the future.
for example due to its architecture and search strategies cnand earec hardly make any adjustments.
on the contrary hgrec at this stage has presented the advantages to model review history using the hypergraph technique yet it still has the capability to involve more entities and relationships which is worthy of exploration.
for example potential reviewers belonging to the same organization may share a similar background thus impacting the weight w calculation.
in addition the content of review comments may bring a new feature to characterize a pr.
to conclude hgrec supports a flexibility to adjust diverse contexts and future improvements.
.
recommender selection revfindercn acchrev rf earechgrec .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
rd acc figure synthetical evaluation regarding acc andrd we use the top accuracy a common way to evaluate recommenders combined with recommendation distribution to visually illustrate the performance of all the recommenders involved in our study.
figure .
presents the average acc andrdfor the projects.
the advantages of hgrec are thus easy to identify i.e.
it achieves the most accurate recommendation in all recommenders and the best balanced workload in the top three accurate recommenders.
nevertheless although recommendation accuracy should be the primary consideration in most cases otherwise the value of recommendation will be lost reviewer recommendation should be applied with sufficient considerations in the application context which involves multiple factors such as the number of potential reviewers the number of prs etc.
take project angular for example as shown in figure workload balance may not be an ignorable factor since the core reviewers have already undergone heavy review tasks.
to present a general concept we portray the figure monthly prs of the projects number of prs per month for the projects involved in our study as depicted in figure .
obviously recommendation distribution aka workload balance means more in projects such as angular joomla cms etc.
where there are normally hundreds of newlysubmitted prs need to be reviewed.
on the contrary in projects such as cakephp and scala where there are usually only dozens of new prs per month the core two or three reviewers to handle all the prs may seem to be acceptable.
.
threats to validity several threats to validity are elaborated in this subsection.
.
.
construct validity.
the threats to the construct validity of this study may be related to one of the common concerns of research on reviewer recommendation i.e.
the ground truth set of reviewers for evaluation .
the actual reviewers recorded in review history may not be able to guarantee suitable reviewers and further justify an appropriate recommendation.
in this sense the recommended reviewers are only potentially suitable reviewers for a certain pr.
.
.
internal validity.
the threats to the internal validity of this study may result from the data preparation phase.
the personal organization of oss projects is significantly loose which brings participants frequent turnovers and once in all reviews.
recommending these gone or accidental reviewers is inappropriate.
in this study we left out reviewers who had already deleted accounts or participated in less than two reviews so did the robot users.
on the other hand the opening prs were also removed as they are uncertain.
another related threat is that some noise data e.g.
casual superficial comments such as ok fine etc.
exists in both the training set and test set which may not be able to guarantee a qualified reviewer recommendation.
however the evaluation on hgrec and other recommenders is based on the same dataset which may mitigate these threats to a fair degree.
meanwhile reviewers who posted these casual superficial comments may also have subtle relationships e.g.
certain familiarity mutual influence etc.
.
therefore we did not refine the dataset to remove noise data at this stage.
instead hgrec takes the advantage to use the possible relationships behind the casual superficial comments and their corresponding reviewers.
.
.
external validity.
we experimented with the proposed recommender on the oss projects that are retrieved from github.
however the proposed recommender could suffer risks on external validity as several studies investigated other contexts e.g.
gerrit authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
modeling review history for reviewer recommendation a hypergraph approach icse may pittsburgh pa usa projects or mixed projects both oss and industrial projects .
therefore the findings and conclusions are only valid in the given context.
we have confidence that this study is representative because all the included projects were mentioned in the previous studies and the data is up to date.
besides given the population of oss projects from github projects tested in our study may only represent a small portion.
nevertheless the comparably consistent performance i.e.
recommendation accuracy in our study and previous studies is able to mitigate this external threat to validity to a fair degree.
.
.
conclusion validity.
to avoid threats to conclusion validity we followed a systematic rigorous experiment and analysis procedure.
the recommender proposed in this study has been experimented on oss projects with the history in three and a half years including more than 87k prs 680k review comments.
all the dataset is clearly elaborated e.g.
the name of projects the time range etc.
and publicly accessible online.
this ensures a high degree of reliability that the conclusion drawn in the study is directly traceable to the raw data and hence can be replicated by other researchers.
conclusions with the proliferation of the pull request development paradigm nowadays as a key and perhaps daily practice modern code review mcr may impact massive software projects.
while the importance of suitable reviewers has been widely recognized among oss projects their identification is indeed a challenge.
although many recommenders have been proposed in the past decade their adoption is far from satisfactory .
several critical issues such as low accuracy workload congestion incapable of extension and improvement have been raised and investigated in several related studies.
this paper proposes hgrec a hypergraph based recommender to perform automatic reviewer recommendation in oss projects.
by applying hypergraph we managed to model high order relationships in mcr an essential step in oss development.
a relatively extensive evaluation based on oss projects with more than 87k prs and 680k comments indicates that the proposed approach i.e.
hgrec outperforms the state of the art recommenders in terms of accuracy.
moreover among the top accurate recommenders hgrec is more likely to recommend new reviewers out of core reviewers which may help to alleviate the workload congestion issue to some extent.
last but not least with flexible and natural model architecture hgrec can support modeling more elements e.g.
entities attributes and relationships in a way that more modern learning techniques or sophisticated heuristic algorithms could be incorporated into the recommender.
to this end better performance can be expected with exploration in the future.