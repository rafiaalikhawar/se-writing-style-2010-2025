how does misconfiguration of analytic services compromise mobile privacy?
xueling zhang university of texas at san antonio san antonio tx usa xueling.zhang utsa.eduxiaoyin wang university of texas at san antonio san antonio tx usa xiaoyin.wang utsa.edurocky slavin university of texas at san antonio san antonio tx usa rocky.slavin utsa.edu travis breaux carnegie mellon university pittsburgh pa usa breaux cs.cmu.edujianwei niu university of texas at san antonio san antonio tx usa jianwei.niu utsa.edu abstract mobile application app developers commonly utilize analytic services to analyze their app users behavior to support debugging improve service quality and facilitate advertising.
anonymization and aggregation can reduce the sensitivity of such behavioral data therefore analytic services often encourage the use of such protections.
however these protections are not directly enforced so it is possible for developers to misconfigure the analytic services and expose personal information which may cause greater privacy risks.
since people use apps in many aspects of their daily lives such misconfigurations may lead to the leaking of sensitive personal information such as a users real time location health data or dating preferences.
to study this issue and identify potential privacy risks due to such misconfigurations we developed a semiautomated approach privacy aware analytics misconfiguration detector pamdroid which enables our empirical study on misconfigurations of analytic services.
this paper describes a study of popular apps using top analytic services in which we found misconfigurations in apps.
in of the apps misconfigurations lead to a violation of either the analytic service providers terms of service or the app s own privacy policy.
keywords privacy mobile application program analysis analytic services configuration acm reference format xueling zhang xiaoyin wang rocky slavin travis breaux and jianwei niu.
.
how does misconfiguration of analytic services compromise mobile privacy?.
in 42nd international conference on software engineering icse may seoul republic of korea.
acm new york ny usa pages.
permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
copyrights for components of this work owned by others than acm must be honored.
abstracting with credit is permitted.
to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
request permissions from permissions acm.org.
icse may seoul republic of korea association for computing machinery.
acm isbn .. .
.
introduction mobile apps often rely on third party services to enhance user experience through features such as social network integration and crash analysis.
among the most popular types of third party services analytic services enable app developers to gather user behavior information to improve their products and monetize their apps with targeted ads.
such analytic services can be integrated into apps through package libraries to collect user activities and send user behavior to their servers for analysis.
server side analysis can then generate aggregated reports for the app s developers.
for example such aggregated reports may describe how many users are from new york city how many users reached a specific activity or how long they tend to spend on a specific activity.
analytic services provide specific methods that allow app developers to set attributes for their users we refer to those methods asattributes setting methods asms .
for example one commonly used category of asms is set user identifier which allows app developers to store a user id for the individual using their apps.
these methods are usually optional and can be used to recognize the same user across multiple usages of an app.
once a unique id is assigned through such a method the user s behavior reports will be labeled with the provided user id.
these identifiers are strictly used for identification with respect to the service and do not need to be personally identifying.
for example a random unique number or hash value could be used instead of an email address.
using personally identifiable information pii 1as an id would be considered as bad practice in this case as it presents an unnecessary exposure of sensitive data.
by misusing pii e.g.
email username device id with asms this effectively un anonymizes the reports produced by the analytics service resulting in privacy risk.
furthermore such misuse may violate the app s own privacy policy the analytic service providers terms of service or general best practices e.g.
data overuse least privilege .
a major privacy risk associated with third party analytic services is the data usage after the behavioral reports have been collected by the analytic service.
once the data have left the app and reached an analytic service the developers and users lose control of the information.
even if the third party service is trusted not to misuse the data accumulated long term storage of un anonymized user 1we use the union of gdpr and google analytics definitions for pii .
ieee acm 42nd international conference on software engineering icse behavioral data is susceptible to theft or leakage .
not expecting pii to exist in the collected behavioral reports third party services may share the data to their business partners or do not provide enough protection for them.
furthermore when multiple apps use the same pii for the same analytic service multiple behavioral reports can be combined to build more comprehensive personal profiles.
legal requirements such as eu general data protection regulation gdpr requires lawful basis e.g.
legal obligation explicit consent to process users data unless the data is anonymized .
for these reasons it is imperative that unnecessary use of pii for behavioral report labeling to be eliminated.
many of the most commonly used analytic services provide documentation specifically discouraging or prohibiting the use of pii as user attributes when using their asms.
for example google s firebase includes the following in their documentation for configuration of asm setuserproperty when you set user properties be sure to never include personally identifiable information such as names social security numbers or email addresses even in hashed form.
flurry another popular analytics service has the following text in its documentation for asm setuserid warning it is a violation of our terms of service to track personally identifiable information such as a device id e.g.
android id using this method.
if you have a user login that you wish to send to flurry using this method you must anonymize the data using a hashing function such as md5 or sha256 prior to calling this method.
app developers may also attempt to reduce pii related misconfigurations by adopting privacy policies that require anonymization or aggregation of data when used with analytic services.
for example the privacy policy for the app shopclues claims shopclues.com may also aggregate gather up data across all user accounts personally identifiable information and disclose such information in a non personally identifiable manner to advertisers and other third parties for other marketing and promotional purposes.
despite such documents and policies it is not clear whether app developers always follow them in reality as they may neglect them during development.
in this paper we perform a study to understand how app developers invoke asms in practice and whether those practices comply with the documents and policies of the analytic service providers and the apps themselves.
it should be noted that while there exist research efforts on data collection behavior over privilege and leak detection for third party libraries our work is different in that it studies the cause of leaks related to misconfiguration of third party services.
specifically we try to answer the following four research questions in this study.
rq1 what configuration methods do analytic service provide and how do apps invoke those methods?
rq2 how commonly do app developers use pii when configuring analytic service?
rq3 do analytic services provide mechanisms to protect anonymity in the case of misconfiguration as a result of rq2?
rq4 do analytic service misconfigurations result in violations of apps own privacy policies and analytic service providers documents policies?
to answer these research questions we developed a semi automatic approach privacy aware analytics misconfiguration detector for android pamdroid to detect and analyze misconfigurations that may lead to privacy risk.
in this approach we first investigated the documentation of the most popular analytic services in the mobile analytic ecosystem as listed in appbrain .
we acquired the methods provided by these analytic services through their application program interface api specifically for configuring user attributes asms .
we also collected the configuration instructions and terms of service notices from these analytic services when available to gather their guidelines and recommendations for use.
with this data we designed and conducted an experiment to dynamically and automatically evaluate the top google play store apps that contained at least one asm invocation in their code.
we detected invocations to attribute setting asms at run time and recorded parameter values to study what the common practices were and whether they abode by the app s privacy policies the analytic service guidelines and best practices concerning pii for using analytic services.
we also investigated the analytic reports generated by the analytic services to study whether the services applied any mechanisms to anonymize or aggregate the collected data.
we have the following major findings based on the results of our semi automated approach out of top apps from the google play store had at least one asm invocation observed at run time and of them used pii to configure analytic service without encryption.
all the analytic services we investigated provide behavior reports on individual users to app developers and the reports are labeled with exactly the same identifiers provided by app developers.
therefore if pii is used as an identifier they will be directly linked to the user behavior reports resulting in targeted non anonymous and non aggregated information.
we manually inspected the policies of the apps and found of them may violate their own privacy policies by using pii as user attributes.
using pii with analytic services may also violate the terms of service tos of analytic services.
among the analytic services we studied we found that four of them explicitly require app developers to avoid passing pii to asms.
they are firebase google analytics flurrry and mixpanel and they have the app market shares of .
.
.
.
respectively.
although only four analytic services state this requirement explicitly firebase google analytics and flurry are the top three market share 1573table analytic services collect user events by default firebasead click ad exposure ad impression screen view user engagement session start app clear data app exception etc.
mixpanelfirst app open app updated app crashed app session in app purchase.
holders and dominate the market so we believe this requirement is a standard for analytic services.
our result shows that apps which are using the four analytic services did set user s pii to the asms and thus may violate analytic services terms of service firebase google analytics flurrry or privacy guidelines mixpanel .
background on analytic services for a better understanding of users behavior app developers often choose to utilize analytic services.
analytic services usually provide client libraries that app developers could utilize in their app which will record an app user s interaction with the app and send the corresponding data to the server of the analytic service.
later the analytic services can link the activity of a mobile app user over time into a behavior report.
the behavior report includes detailed usage information about this user.
the analytic services can then aggregate all the users reports and provide analytic data to the app developers so that they can improve their product or make better business decisions based on the analytic report.
in this section we describe the background information about analytic services especially about the user events they track their attribute setting methods and terms of service.
.
tracked user events analytic services automatically collect some events that are triggered by basic interactions such as ad impressions ad clicks and screen transitions.
table shows the default events collected by firebase and mixpanel.
from the table we can see that the collected events contain detailed information about the user s usage of the app and interactions with the ads.
.
analytic service configuration analytic services provide attributes setting methods asms that enable developers to customize the analytic service by setting some attributes for their users.
developers can set identifiers or other attributes such as age gender and location on each app user.
later developers can use those attributes as a filter or metrics in their analytics reports.
for instance a developer may want to know the geography distribution or age distribution of their users.
the data that developers pass to those asms will be associated with the users collected events and then sent to the server of analytic services.
to protect users privacy analytic services have certain guidelines or suggestions for how the developer should use those asms.
we list two from some analytic services here as examples in firebase when you set user properties be sure to never include personally identifiable information such as names socialsecurity numbers or email addresses even in hashed form.
note you are responsible for ensuring that your use of the user id is in accordance with the google analytics for firebase terms of service.
... for example you cannot use a user s email address or social security number as a user id.
in mixpanel if you wish to track users truly anonymously however then your tracking implementation should not use userspecific information such as the user s email address.
instead use a value that is not directly tied to a user s pi personal information whether it be a unique anonymous hash or a non pi internal user identifier.
these instructions require the app developers to not use any pii to configure analytic services and encourage them to use anonymous data instead.
.
personally identifiable information we consider pii as the union of the definitions by google analytics and the eu general data protection regulation gdpr .
the following statement is from google analytics .
google interprets pii as information that could be used on its own to directly identify contact or precisely locate an individual.
this includes email addresses mailing addresses phone numbers precise locations such as gps coordinates but see the note below full names or usernames the following statement is from gdpr .
personal data ... an identifiable natural person is one who can be identified directly or indirectly in particular by reference to an identifier such as a name an identification number location data an online identifier or to one or more factors specific to the physical physiological genetic mental economic cultural or social identity of that natural person.
gdpr also defines online identifiers which we include as pii online identifiers natural persons may be associated with online identifiers provided by users devices application tools or other identification tag and it could be used to associate with natural persons because online identifiers may leave traces which in particular when combined with unique identifiers and other information received by the servers may be used to create profiles of the natural persons and identify them.
3pamdroid and study design the goal of this research is to detect misconfigurations in analytics services as they may lead to privacy risks.
to this end we developed 1574pamdroid a semi automated approach to detect the misconfiguration of analytic services due to setting pii to asms.
as illustrated in figure there are two manual preparation steps of pamdroid.
first we manually collect a set of most popular analytic services and android apps.
for each analytic service we investigate its api documentation to collect all asms that app developers can use to set user attributes.
second we set up an android device and collected all its information to construct a reference user profile.
the profile includes different platform ids e.g.
device id serial number android id advertising id a synchronized google account e.g.
user name user email address age gender date of birth and other sensitive information e.g.
location ip address mac address .
after these two steps pamdroid first performs static smali code analysis on the apps to filter out the apps that do not invoke any asms at all.
then pamdroid automatically instruments all asms detected with static smali code analysis to print their argument values to system log.
after that pamdroid uses monkey to test the instrumented apps user interface.
note that many apps trigger analytic services only after a user is logged in.
as a supplement of monkey we perform manual login for all apps that require login to get to the start page.
finally pamdroid compares the collected system logs with the reference user profile.
when certain types of information in the reference user profile show up in the system log pamdroid detects an asm misconfiguration.
after all misconfigurations are detected we manually inspect the corresponding apps privacy policies and corresponding analytic services terms of services to detect violations and misalignments.
it should be noted that the major goal of this research is to study the commonality and characteristics of asm misconfigurations andpamdroid is developed for the study so we supplemented it with manual analysis to acquire most comprehensive and accurate results.
if we do not perform manual log in and adopt existing automatic approaches for policy analyses pamdroid can be made fully automatic but its effectiveness is not clear and it is not the focus of this paper.
we next introduce the details of our study setup with the pamdroid approach.
.
collection of apps and analytic services we identified the most popular analytic services using published statistics provided by appbrain a company specializing in app marketing and promotion.
after that we identified the asms provided by the selected analytic services.
the top free apps containing at least one invocation of the studied asms were collected from playdrone a collection of metadata for android apps on the google play store.
we identified those apps which invoked asms by analyzing their smali code2.
if an app obfuscated the asms it invoked we could not apply our approach to it.
furthermore we also ruled out apps that were incompatible with our device and those no longer existing in google play due to being removed since being included in the playdrone database.
to determine whether an app had an invocation of a studied asm we first decoded the analytic libraries into smali format using apktool and identified each asm s smali signature.
we then decompiled each app s apk android package file into smali format 2assembler for the dex format used by dalvikand scanned the resulting file for occurrences of asm signatures.
only apps containing at least one asm signature were kept for consideration.
.
runtime information collection there are multiple approaches to detect information flow to asms.
the first approach we considered was using static taint analysis.
to this end we used flowdroid to analyze the apps and defined asms as sinks and personal information sources from susi as sources.
the result showed that flowdroid only identified data flows from sources to sinks.
through further investigation we found that the sources of pii sent to asms are often not android api methods but system files or databases.
furthermore pii often flow through paths that are not handled by flowdroid such as android.content.sharedpreferences which is a data structure in android system that stores user information such as username device id etc.
if we add all these api methods as sources offlowdroid it will report many false positives as files databases and android system data structures may also contain a lot of nonpii.
to make sure our study is conservative all reported misconfigurations are real we ultimately utilized value based dynamic taint analysis.
as mentioned earlier we prepared a reference user profile to match arguments sent to asms.
to make sure values in our user profile are not confused with other values we designed very strange information e.g.
user name email address for the synchronized google account.
to make sure our matching is robust for the values in the reference user profile we further generate values with different value transformations such as reverting and truncating.
we also produced hashes for all pii using common hashing algorithms provided by android api methods so that we could identify hashed values although in the study we did not find hashes being sent .
note that we manually confirmed all matched results to make sure that our value transformations do not lead to wrong matches.
one limitation of value based taint analysis is that we cannot detect encrypted pii with an app specific key.
notably using encrypted pii as user attributes on analytic service already reduces the risk to privacy because the unencrypted pii will not be combined with collected user behavior.
in order to catch the arguments of asm invocations during runtime we instrumented all asms in smali code by adding a call to the android logger to report the invocation at the beginning of the asm implementation.
this allows us to use the android system log to analyze method argument values being set at runtime.
after inserting the code we rebuilt the smali code back into apk format for testing.
we used the android debug bridge adb to automatically install the rebuilt apps onto our test device and run the apps and then executed monkey to perform the testing.
for each app we automatically installed executed tested uninstalled and saved the system log into the local file system for later inspection.
during testing we found apps requiring login to an account to show the app s start page so we manually created accounts for these apps using the reference user profile to complete the login process.
finally pamdroid searched the system logs generated during testing and extracts argument values of asms based on flags inserted during instrumentation.
table is an example where line 1575figure privacy aware analytics misconfiguration detector pamdroid shows our inserted flag line shows the asm that be invoked firebase.setuserproperty and line shows our flag and the first argument value that was passed to the asm vivino email .
line shows the second argument value which was the email address represented as gmail.com .
study results in this section we present the results of our study and answer the research questions.
.
apps usage of analytic services to answer rq1 for each analytic service we first investigated their documentation and collected the asms.
we noticed that every analytic service provides the methods that allow developers to set attributes for their users such as setuserid setcustomeruserid orsetuseridentifier etc.
firebase provides an method called setuserproperty which allows developer to set any attributes to describe their user.
it takes two arguments which are similar as a pair of key and value .
other methods include setuseremail setlocation setage setgender setdeviceid setphonenumber etc.
the full list of asms are available at our anonymous project website3.
four analytic services firebase google analytics flurry mixpanel explicitly require app developers to avoid setting pii to asms.
a method to set user identifier e.g.
setuserid is provided by every analytic service and mostly commonly invoked in our test.
for example crashlytics.setuseridentifier was invoked in apps and flurry.setuserid was invoked in apps.
we present these frequencies in table .
in the table the first column presents the analytic service name the second column presents the total number of apps that invoked the asms from this analytic service.
the third column represents the asm name and the fourth column presents the number of apps that invoked the corresponding asm.
among the apps that contain asm invocations in their smali code apps invoked asms from different analytic services during our runtime testing.
table shows that firebase figure apps invoking different types of asms and crashlytics are the most commonly invoked analytic services.
note that a single app could use more than one analytic services within one analytic service the app could invoke multiple asms to set user attributes.
to understand how apps use different types of asms over all analytic services we categorized all asms in table into a number of categories according to their purposes.
in particular the categories are set user identifier set user properties set device identifier set user email set username set age and set location .
in figure we present the number of apps that invoke different categories of asms.
we observed that apps set user identifiers to at least one analytic service showing that many app developers set identifiers for users to differentiate individual user interactions through the analytic service and the function is also well supported by analytic services in general.
furthermore apps set user properties to at least one analytic service.
since asms in the set user properties category are very general and can be used to set almost any data it is difficult to statically tell what information is sent through them.
finding .
our answer to rq1 is that all our studied analytic services provide asms for app developers to set user attributes and more than half of of apps trigger asms to label user behavior reports.
.
pii set to asms in misconfiguration to answer rq2 we further studied what types of data are set to asms in our studied apps.
by matching the logged method 1576table system log of asm invocation .
w system.err java.lang.exception third party api invoke detection print stacktrace with parameter .
w system.err at com.google.firebase.analytics.firebaseanalytics.setuserproperty unknown source .
w system.err at com.vivino.android.a.a.a firebasehelper.java ... ... .
i third party api invoke detection print stacktrace with parameter vivino email .
i third party api invoke detection print stacktrace with parameter gmail.com table apps invoke different asms analytic library apps method apps firebase 216setuserid setuserproperty crashlytics 163setuseremail setuseridentifier setusername appsflyer 81setandroididdata setappuserid setcustomeruserid flurry 70setage setlocation setuserid tune 38setandroidid setdeviceid setuseremail setusername setuserid setfacebookuserid setgoogleuserid settwitteruserid ironsource setuserid mixpanel identify applovin setuseridentifier leanplum 12setdeviceid setuserid setuserattributes branch setidentity google analytics 7setclientid appsee 6setuserid newrelic 4setuserid arguments to the controlled user profiles see section .
we can detect misconfigurations on the fly.
table presents the number of apps setting different types of pii to asms.
in particular columns present the type of pii asm name the number of apps setting certain type of pii to a certain asm and the total number of apps setting certain type of pii to all asms.
we make three major observations.
first overall apps set pii or pii s transformation apps to asms.
it should be noted that a single app may set multiple data types so the values in column do not add up to .
second among the apps apps set android id to asms apps set users email addresses to asms and apps set users registered username to asms.
note that registered usernames are used to uniquely identify users in the app and many users use the same username across apps so google analytics explicitly lists username as pii .
third one type of pii is observed to be set to asms for multiple purposes.
forexample android ids are mainly set to asms in the category set user identifier but it is also set to crashlytics.setusername andfirebase.seruserproperty .
email addresses are also set to asms in the categories of set user properties and set user identifier .
so the vagueness and generality of asm design may have aggravated their misuse.
in figure we further show the number of apps that set different pii to different analytic services.
in the figure we organize the number of apps setting various pii to each analytic service as a separate column chart.
in each sub column chart the x axis shows different analytic services and the y axis shows the number of apps setting different personal information type in that analytic service.
from the figure we can see that crashlytics and appflyer are receiving pii from the most number of apps and crashlytics also received user email addresses from the most number of apps.
furthermore firebase and flurry which explicitly require app developers to not send pii to them both receive various types of pii including android id device series number and username.
firebase further receives email address and flurry further receives imei.
finally figure presents the category distribution of our dataset and the percentage of apps in each category setting pii to asms.
each bar represents the total number of apps in the specific category while the dark portions represent the number of apps in the category that set pii to the asms.
we further label the percentage of dark bar portion for each bar.
the figure shows that there is not a specific category of apps that are much more likely to use pii as user attributes.
compared with others apps in photography communication and shopping have higher possibility of setting pii to asms.
besides pii our test result shows that apps used advertising ids which can be changed by users and sometimes encouraged by analytic services to be used as user identifiers.
however if users do not change advertising ids frequently they can still be actually pii.
since we want our study results to be conservative we do not include them as pii in our study results.
finding .
our answer to rq2 is that among the apps we studied at least apps detected by pamdroid misconfigure asms with pii.
in particular android id in apps user email in apps username in apps imei in apps and serial number in apps are the types of pii being set to asms.
.
enforcement of aggregated and anonymous reports to answer rq3 we studied all analytic services being invoked to find out whether they have enforcement mechanisms to reject pii being set to asms.
unfortunately none of services have such built in enforcement mechanisms.
only one of them appsflyer 1577figure apps set different pii to different analytic services table apps setting different pii to asms personal info tracker api apps total android idfirebase.setuserid 79firebase.seruserproperty appsflyer.setandroididdata appsflyer.setcustomeruserid flurry.setuserid mixpanel.identify tune.setandroidid tune.setdeviceid crashlytics.setuseridentifier crashlytics.setuseremail crashlytics.setusername applovin.setuseridentifier googleanalytic.setclientid appsee.setuserid emailfirebase.seruserproperty 24mixpanel.identify tune.setuseremail tune.setusername crashlytics.setuseremail crashlytics.setuseridentifier crashlytics.setusername usernamefirebase.seruserproperty 19flurry.setuserid tune.setusername crashlytics.setusername crashlytics.setuseridentifier leanplum.setuserattributes leanplum.setuserid imeiflurry.setuserid tune.setdeviceid crashlytics.setuseridentifier serial numberflurry.setuserid 23firebase.seruserproperty provides a method to set user email address with encryption but none of apps in our data set actually invoked this method.
furthermore we studied whether the information set to asms is encrypted before they are combined with behavior reports and no analytic service is performing the encryption.
it should be noted that all the figure apps distribution in categories figure a demo report in dashboard of flurry analytic services which we studied use encrypted network connection e.g.
https to send collected information.
however if the pii set to the asms is combined with behavior reports in un encrypted form the anonymity of the collected user behavior is already lost as the whole data will be decrypted later.
it is very challenging to tell how data is stored and processed on servers of analytic services.
however we can predict their practice from the behavior reports they provided to developers.
therefore we further studied whether the analytic services provide reports on individual user behaviors.
we found that for all analytic services that we investigated their online analysis reports for developers are 1578not limited to aggregated data but are instead itemized by received user attributes.
figure figure and figure presents example report screen shots from flurry mixpanel and crashlytics.
from the three figures we see that reports are organized by user attributes and presented to app developers and the identifiers e.g.
user email username or device ids are presented without anonymization.
figure shows that flurry s report not just contains the userid but also user s latitude and longitude data.
finding .
our answer to rq3 is that analytic services do not have any mechanisms to vet or anonymize pii they received from asms.
the pii are directly combined with behavior reports when stored and provided to app developers.
.
policy violations and misalignment we present our answer to rq4 in this subsection.
as we discussed in our results above it is a privacy risk when pii was set by app developers on analytic services without encryption or anonymization.
such misconfiguration may cause two types of policy related issues.
first to protect user privacy and avoid legal liabilities analytic services may state in their tos that they do not allow developers to set pii to their asms.
so the misconfiguration of asms will cause tos violations.
second the app s own privacy policy may claim anonymous data analytics or fail to describe the sharing of pii to analytic services so the misconfiguration of asms will cause misalignment between code and privacy policies.
.
.
tos violations.
figure shows that apps set pii on ten analytic services.
as we mentioned in section four analytic services firebase google analytics flurry mixpanel explicitly require app developers to avoid setting pii to asms in their terms of service firebase google analytics flurry note that they are the top three market share holders in analytic services or privacy guidance mixpanel .
based on our experiment results apps have set pii to asms of firebase google analytic or flurry and thus we believe that the misconfiguration of asms actually violates their terms of services.
furthermore apps have set pii to asms of mixpanel so they are violating mixpanel s privacy guidance.
it should be noted that although the remaining apps did not violate the policies of analytic services their practice of setting pii to asms still jeopardizes users privacy.
also the top market share holders have relatively less misconfigurations maybe because they have instructions of asms in their documentation and tos which help avoid misconfigurations.
.
.
misalignment of apps privacy policies.
misconfiguration of asms may also cause misalignment between an app s code and privacy policy.
to find such apps for each of the apps that set pii to asms three of the authors independently read the app s privacy policy and wrote arguments on why he she believes using pii for analytic services is a potential policy misalignment or not.
then the authors met to discuss the arguments for each app and voted to determine whether the misconfiguration is misaligned with the privacy policy.
we found out of apps have misconfigurations that are misaligned with their own privacy polices.
apps vaguely mentionedin their privacy policy that they may share pii of users with third parties.
apps have no misalignment with their own privacy policies as they explicitly indicate that they will share specific personal information type to third parties.
the remaining apps either have a non english privacy policy or the privacy policy web page is not available.
the detailed discussion record of all apps is available in our anonymous website and misalignment examples are presented later in this subsection.
privacy misalignment.
we consider an app to be misaligned with its privacy policy if the policy does not indicate that it will share pii with third parties or if the policy claims anonymous data collection.
for example the social app emojidom s privacy policy states that do third parties see and or have access to information obtained by the application?
only aggregated anonymized data is periodically transmitted to the analytics tools which help us evaluate the application s usage patterns and improve the application over time.
however our test results show that this app set user email addresses to crashlytics which is misaligned with this privacy policy.
vague privacy policies.
privacy policies should inform users about types of user information are shared with third parties.
third party analytic services also request app developers to make this sharing explicit in their apps privacy policies.
for example crashlytics is one of the most popular third party analytic services for helping developers to analyze crashes in their apps.
crashlytics requires that all developers maintain a privacy policy that fully and accurately discloses the type of information shared with crashlytics .
among apps that send pii to analytic services of them abstractly indicate that they may share personal information to third parties without specifying what the information types are.
for example the shopping app staples sets user email address to crashlytics and its privacy policy states that we may share your personal information with our thirdparty service provider to process transactions or provide services on our behalf including but not limited to providers of product delivery services for example ups and fedex and website analytics for example google analytics .
no misalignment.
we consider an app has no misalignment with its privacy policy if it clarifies the data types being shared with third party service providers.
finding .
our answer to rq4 is that among apps with misconfiguration of asms the misconfigurations cause termsof service violation of analytic services in apps and privacy policy misalignment in apps.
.
threats to validity the major threat to internal validity of our study is the false positives and negatives in our misconfiguration detection process.
since 1579figure a demo report in dashboard of mixpanel figure a demo report in dashboard of crashlytics we report only observed misconfigurations at run time we should not have false positives.
it is possible that our dynamic analysis failed to trigger some misconfigurations our collected asms are not complete or our matching process missed some sophisticated transformed argument values.
so our reported number of misconfigurations is actually an under estimation which will not undermine our major findings.
to reduce this threat we carefully scanned the documentation of analytic services combined monkey and manual log in to enhance the code coverage and considered various value transformations when matching the reference user profile with system logs.
since most developers will perform configuration of analytic libraries when the app is started the false negative rate caused by uncovered misconfiguration should not be high.
the major threat to external validity of our study is that our findings may apply to only the apps under study.
to reduce this threat we chose the top apps from google play store and these apps covers almost all different app categories.
lessons learned in this section we discuss the potential privacy risks found and our recommendations for different parties involved in the configuration of analytic services.
.
privacy risks although top analytic services advise app developers to not use pii as user attributes many app developers still do so and no mechanism has been provided either by android or the analytic services themselves to prevent app developers from using pii.
this means that the analytic services may unintentionally link a behavior report to a specific individual.
based on our experiment results a non trivial number of apps are using emails and device identifiers e.g.
android id imei serials number as user attributes.
these identifiers are long lived and can be used to construct a user s comprehensive profile from multiple apps using the same analytic service.
since most analytic services further share their collected data to third parties for business purposes the personal identifiablecomprehensive profiles can be exposed to more risk due to the neglect of pii inside the data.
since analytic services and app developers hold a large amount of valuable user data it is very likely that they can be targeted for information theft leakage attacks.
when an information leakage incident happens if the data stored on the server is not in an anonymous and aggregated form the consequence will be much more severe than the scenarios where they are anonymized and aggregated.
because analytic services do not expect app developers to set pii to the asms they may not have corresponding mechanism to detect pii in the collected data and thus may not use protection mechanisms e.g.
encryption on the collected data.
.
actionable suggestions base on our study the five parties involved in analytic services may take some counteractions to reduce the privacy risk caused by asm misconfigurations.
research community in order to precisely and comprehensively detect misuse of analytic service asms new static techniques are desired to detect the data flow from pii sources to the asms.
although it is possible to take advantage of off the shelf information flow analyses the challenge still remains of detecting pii sources and asms.
for pii sources many types of pii e.g.
username user s email are user defined so their source may be a text box a local file or a database which cannot be easily differentiated from other non pii information.
therefore more precise techniques to identify pii sources or intermediate sources e.g a variable that loads pii values from a file or the database are required.
for asms although we manually constructed asm sets for popular analytic services in the study the analytic services are continuously evolving and new analytic services may become popular.
for this reason our sets can quickly become out of date.
therefore novel techniques to automatically identify asms and their behaviors are desirable.
another potential research endeavor is studying how analytic services can vet and anonymize pii so that they can enforce the privacy requirement of using asms.
one challenge is that the analytic services do not know where the argument values come from.
so a likely solution is value based detecting of pii where a classification model may be learned to detect pii values in run time arguments.
privacy profiles are automatically extracted from apps to provide fine grained information of collected and shared information types but they cannot handle advanced privacy properties such as data anonymity and aggregation.
anonymity may be verified by checking whether data is combined e.g.
concatenated put into one object or key value pair with pii.
aggregation may 1580be verified by checking whether individual data is destroyed e.g.
freed at the end after they are read.
app developers.
app developers should take more care in following asm documentation terms of service and avoid setting any pii as user attributes.
instead of using raw pii developers could encrypt or hash the data before it is passed to analytic services or use non pii instead.
for example if the differentiation of users helps on more precise statistics e.g.
how many users are using their app or certain activity they can use advertising ids randomly generated ids or encrypted hashed pii as user s identifier.
app developers should pay attention to their privacy policies as well as they need to make sure the policy is consistent with their practice of using analytic services.
at the same time a clear profile on what kind of pii is set to asms can help users understand how their privacy data can be used by analytic services.
analytic services.
analytic service developers should enhance and enforce data anonymity and aggregation in their code base.
in particular just like google analytics firebase flurry and mixpanel other analytic services should also try to provide a more clear and easily reachable instruction about privacy aware configuration.
meanwhile when designing and implementing methods analytic service developers should avoid or limit the usage of overbroad vague methods e.g.
setproperties and methods that are meant to receive pii e.g.
setuseremail setuserlocation .
they should also add encryption features for methods that may receive pii from the app.
second when an app sets pii to asms analytic services could have mechanisms to detect and anonymize the pii e.g.
regular expressions .
in this way analytic services could add vetting mechanisms in the implementation of asms to reject pii or raise warnings on detection.
alternatively instead of transparently handing over the pii to app developers in their reports they could encrypt the pii or replace it with other non pii and then perform analysis on the pre processed data.
after that analytic services should generate a report that only contains aggregated data about user behaviors.
platform providers.
the android platform has applied some strategies to reduce the privacy risk over the years.
for example in android version .
and higher android id is no longer a constant value for different apps installed on the same device.
this mechanism helps to prevent the analytic services from gathering an individual user information across multiple apps.
since the android platform has access to much pii for the device s users such as google email account android id device id it should be able to vet such data sent to asms of analytic services.
working together with analytic services e.g.
asking them to annotate asms the android sdk could provide on the fly suggestions on which apis and api options should be used while app developers are coding.
furthermore the android platform could provide the option to automatically reset the advertising id periodically for users.
app users.
app users should be aware that they can be un anonymously tracked if app developers do not properly set their attributes on analytic service.
our study found that some app developers use usernames in analytic services so we suggest app users to avoid using their real names or pii when registering with different apps.in addition google advertising id has been encouraged to be used as the individual identifier in the analytic services.
however if a user does not reset the advertising id frequently it becomes another long lived online identifier.
so we encourage app users to reset their advertising ids periodically to avoid being identified as the same individual for a long time period.
related work in this section we categorize related existing research efforts into the following three categories studies on the data collection and sharing of analytic services general information leak detection techniques and privacy policy analysis.
.
data collection and sharing of analytic services existing research efforts mainly studied what user activities are tracked by analytic services and what information they may collect.
liu et al.
investigated the types of user activities being tracked by analytic services.
their results reveal different levels of useractivity tracking on different ui event types.
since analytic libraries are integrated into the app they receive the same privilege e.g.
permissions of the enclosing app from the android platform.
this allows the analytic services to collect some personally sensitive device information.
seneviratne et al.
show that of paid apps are connected to analytic services that collect personal data compared to of free apps.
they perform static analysis on android api calls inside the analytic libraries and summarize the type of personal data collected by the analytic services from the android platform.
compared with these works our approach focuses on misconfiguration of asms where pii can be combined with user behavior reports to compromise their anonymity.
this is a novel aspect that has never been investigated in the above efforts.
.
detection of general information leaks there has been a lot of work on the detection of information leask on mobile platform.
in particular cluefinder leverages nlp technology for building a learning system to identify sensitive data leaks from apps to third parties.
flowdroid leverages static taint analysis with tunable sensitivity to trace information from sources to sinks so it can also be used to detect information leaks.
taintdroid is one of the most popular android taint systems for tracking the information flow.
their study shows that two thirds of apps introduce potential privacy risks to sensitive user data.
vetdroid is a dynamic analysis platform to construct permission use behavior during runtime by intercepting the invocations of android apis which can be used to analyze information leaks.
han et al.
uses dynamic taint analysis to study how apps expose personal data and persistent identifiers in information flow.
they present a prototype privacy control which inserts code checks at all android api invocations that access sensitive data.
network traffic analysis techniques have also been applied to detect personal data that app share with third parties .
razaghpanah et al.
detect third party advertising and analytic services at the traffic level.
ren et al.
instrument vpn servers to identify privacy leaks in network traffic.
vallina et al.
analyze mobile isp traffic logs to identify advertisement traffic.
compared with these works 1581ourpamdroid also uses value based dynamic taint analysis to detect information leaks.
however our major contributions include identifying the asm misconfiguration problem and the construction of asm sets for popular analytic services.
we also performed a study to reveal the severity of the asm misconfiguration problem in practice.
.
privacy policy analysis privacy policies inform users on how their information will be collected used and disclosed.
existing works have been working on detecting misalignment between privacy policy and the actual data practice in app code .
they analyzed the app code and detected what sensitive information types from user input or android platform api invocations are sent to network.
after that they compared the collected and shared with information types with the statements in privacy policies.
different from these previous studies our work tries to investigate whether developers practice on analytic services configuration may compromise anonymity and aggregation of users behavioral reports.
we developed pamdroid to detect miconfigurations of asms and our study shows that a non trivial number of apps set pii to asms of analytic services.
as a result our work further detects tos violations of analytic services and privacy policy misalignment related to anonymity and aggregation which are never reported by above research efforts.
conclusions in this paper we developed a semi automated approach pamdroid to investigate whether mobile app analytic services are really anonymous as they are often claimed and how asms can be misconfigured by app developers.
our study on popular apps has shown that most analytic services provide asms such as setuserid to differentiate users.
these asms can be misconfigured by developers so that individual user behavior profiles can be disclosed which might impose greater privacy risk to users.
we found that misconfiguration of asms in apps leads to violations of analytic services terms of service and misconfiguration of asms in apps leads to privacy policy misalignment.
in future we plan to further study what user behaviors are collected by analytic services besides the events collected by default and to investigate whether piis can also be leaked through user events.
moreover we are going to develop a fully automated framework to detect piis being set to asms without encryption.