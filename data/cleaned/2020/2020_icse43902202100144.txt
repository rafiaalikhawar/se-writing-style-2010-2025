restoring execution environments of jupyter notebooks jiawei wang faculty of information technology monash university melbourne australia jiawei.wang1 monash.eduli li faculty of information technology monash university melbourne australia li.li monash.eduandreas zeller cispa helmholtz center for information security saarbr ucken germany zeller cispa.saarland abstract more than ninety percent of published jupyter notebooks do not state dependencies on external packages.
this makes them non executable and thus hinders reproducibilityof scientific results.
we present snifferdog an approach that collects the apis of python packages and versions creat ing a database of apis analyzes notebooks to determinecandidates for required packages and versions and checks which packages are required to make the notebook executable and ideally reproduce its stored results .
in its evaluation we show that snifferdog precisely restores execution environments for the largest majority of notebooks making them immediatelyexecutable for end users.
index t erms jupyter notebook environment python api i. i ntroduction jupyter notebooks interactive documents that combine code text mathematics plots and rich media have become a prime medium for scientists to document replicate andillustrate their findings.
in contrast to a regular scientific paper a notebook allows its writers to directly interact with data and code updating tables and diagrams on the spot.
this alsoextends to users who can re execute the notebook code say with their own data or changes to the algorithms and see howthis affects the final results.
this makes jupyter notebooks one of the most promising tools to allow for widespread replication and reuse of research results.
what sounds good in theory need not be true in practice though and jupyter notebooks are no exception.
recent stud ies have shown that the vast majority of published jupyternotebooks can only be read by users but not re executed.one reason is incompleteness such as the raw data not being supplied and there is not much users can do about this.
however there are also reasons for notebooks being non executable that can be easily avoided.
one reason is that notebook codecells can be executed interactively in any order and data scientists happily do so recent approaches thus focuson restoring the actual order based on internal dependencies.another important reason however is that jupyter notebooks depend on specific environments in which they were created such as specific libraries in specific versions.
in principle python code in notebooks provides import statements which state the external modules are to be used.
corresponding authorhowever python users install packages not modules and the names of imported modules may be different from thename of the package that provides them.
different versions of packages may provide different apis hence one has to determine compatible versions.
also packages may depend on other tools or packages to be installed.
this is why python like other languages in good software engineering tradition has long introduced explicit means to specify dependencies between libraries and packages.
python package managers e.g.
pip and conda for instance expect python packages to provide an explicit list of dependencies stating which other packages need to be installed in which versions.
writers of jupyter notebooks however are first andforemost data scientists and not software engineers hence they neither know about principles of reusable software norwould this be in their focus.
indeed as we show in this paper around of notebooks do not formally state or document dependencies among those who do nearly are not reliable.
in consequence users who want to executepublished and complete jupyter notebooks will very likely faceerrors of missing packages or incompatible versions.
in this paper we introduce a novel approach to automatically restore the experimental dependencies of jupyter notebooks.
our snifferdog tool takes a python jupyter notebook and automatically detects which packages are required to reproduce notebook results.
to this end snifferdog creates an api bank a database which holds api information for each python library and each version .
by analyzing the pythoncode embedded in the notebook snifferdog then determines library candidates that would be api compatible.
snifferdog then can automatically install the recommended dependencies and check if they allow the notebook to be executed and reproduce the original results stored in the notebook.
when users thus apply snifferdog on a notebook they at least obtain a list of detected required libraries and their versions.
if theseare complete the notebook can become executable and in the ideal case the notebook is shown to fully reproduce theoriginal results.
striving for executability reproduction and considering library versions is also what sets snifferdog apart from earlier python specific approaches .
snifferdog is efficient and effective it finishes the analysis of notebooks in .
seconds .
seconds per ieee acm 43rd international conference on software engineering icse .
ieee notebook .
in an experiment with notebooks known to be executable snifferdog was able to automatically determine dependencies for over of them.
the remainder of this paper is organized as follows.
after providing background about python packages and jupyter notebooks section ii we make the following contributions a study on the prevalence of dependency issues injupyter notebooks section iii .
in a preliminary study we investigated causes that make jupyter notebooks non executable with and without environmental dependencies.
a novel approach to restore dependencies of jupyter notebooks section iv .
we present the design of our approach and its implementation in the snifferdog prototype.
an evaluation of our approach section v .
we evaluate the effectiveness of snifferdog on a variety of notebooks showing that it precisely restores execution environments for the largest majority of notebooks.
after discussing related work section vi we close with conclusion and future work section vii .
ii.
b ackground we start with discussing background knowledge including python libraries and jupyter notebooks.
a. python libraries python is well known for its immense ecosystem providing more than third party packages also known as libraries to developers.
such python libraries need to be locallyinstalled onto developers implementation environment before being accessed.
the python packaging authority team officially maintains a standard package management tool calledpip which allows users to install these libraries from different sources pypi .
in addition to package management systems python developers can also install a library from itssource code project.
figure 1illustrates a typical code structure example of a python library.
a python file named setup.py installs the library locally.
however this file will not install the library senvironmental dependencies and hence requires its users to fulfill them beforehand.
a top level package giving the library its name i.e.
pandas is stored in the same level of setup.py.
such a package in python is a directory that contains a specific file named init .pyresponsible for initializing the package.
python packages provide a way to structure python s module namespace offering an easy means for library users to accessits apis.a module in python is a specific term used in python to specify python s source code i.e.
files containing python definitions and statements .
each python file represents a python module for instance setup.py defines a python module named setup.
directories under the top level package are thelibrary s sub packages.
similarly the python files under subpackages are deemed as sub modules.
for example as shownin figure the python file base.py is defined as a sub module named base in sub package pandas.io.excel.pandas init .py io excel base.py init .pytop level package initialize the pandas package initialize the pandas.io.excel sub package define a module named pandas.io.excel.
base or a sub module in sub package pandas.io.excel pandas setup.pytop directory project name responsible for installing the pandas library api.py fig.
a typical code structure example of python libraries.
this partial code structure is extracted from a popular pythonlibrary called pandas.
in each python module or python file a set of methods can be declared and implemented.
these methods can be accessed by other modules or module users and hence are referred to as apis.
for example the pandas.io.excel.base module contains an api called read excel with the fully qualified name being pandas.io.excel.
base.read excel .
when python libraries evolve their declared api sets will likely be updated.
in this work we will leverage this information to implement snifferdog so as to infer environmental dependencies for python jupyter notebooks.
b. jupyter notebooks jupyter notebooks are sequences of cells which either contain text in markdown format or executable code and its results .
in text cells authors describe using markdown and html for rich formatting the objective of the notebook and the rationale behind the code presented in the following cells.
incode cells authors write actual programming code most frequently python code.
figure 2presents a typical example of a jupyter notebook containing three text cells and six python code cells.
each code cell can be directly executed by the underline jupyter engine which provides the necessary computationalenvironment such as library dependencies.
the code cells in jupyter notebooks can be executed in any order producing errors if its prerequisites are not satisfied .
after one cell isexecuted jupyter will assign an execution order aligning with its execution order.
for example the first executed cell willbe marked as in while the fourth executed cell will be marked as in .
cells can be repeatedly executed.
in sucha case the latest execution counter will overwrite the previousone.. looking closely at figure we see that the last code cell is executed before the fourth and fifth code cells.
astutereaders may have also observed that there is no information i.e.
in indicating the fifth executed code cell.
this isbecause when code cells are repeatedly executed the original execution counter will be overwritten by the last executioncounter called a skip of execution counter.
skips make it 1623hard to reproduce the original outputs of a notebook because the skipped execution counters are not recorded at all .
if the execution of a code cell generates an output text or pictures such as diagrams the output will also be recorded and displayed in the notebook.
in figure a histogram at the end is the output of the last code cell.
import pandas.io.excel.
base base.read excel ... in pandas.dataframe.hist ... in execution countercode cellthe following code cells illustrate different ways to import python modules and execute python their apismarkdown cell outputfrom pandas.io.excel.
base import read excelread excel ... import pandaspandas.read excel ... in in from pandas import read excel as re re ... read excel ... from pandas import read excel ... in in the following code cell demonstrates how to draw a histogram using pandas s dataframe.this is an example of jupyter notebook.
fig.
an example of jupyter notebook.
iii.
p reliminary study and motiv ation in pimentel et al.
presented a large scale empirical study on the quality and reproducibility of jupyter notebooks.
in this study the authors looked into 166notebooks collected from github among which only roughly .
of them were provided with module dependency information describing how the notebooks environ mental dependencies should be set up.
in other words thevast majority of existing notebooks in the community do notprovide sufficient information such that notebook users could execute and replicate them.
since easy replication is one of thepromises of jupyter notebooks there is a need for dependable automated approaches to infer environmental dependencies forjupyter notebooks.
how serious is this problem?
we have conducted a lightweight replication study of pimentel et al.
s work onrecent jupyter notebooks.
we limit our replication study toreplicating the executibility of notebooks when supplying dependencies provided by the notebook authors to identifythe main causes for non reproducibility and thus specifically address execution environments.
to fulfill this purpose wepropose to answer the following research questions rq1 to what extent do public jupyter notebooks provide environment setup information?
rq2 how useful is dependency information in helping notebook users configure the execution environment?
rq3 does the provided environment information help notebook users to execute and reproduce the notebooks?if not what are the root causes making them nonexecutable?
to answer these research questions we have collected a dataset consisting of notebooks with and without experimental setup information.
our source for notebooks is github one of the world s leading software repository hosting platforms.we randomly downloaded notebooks from github.
table isummarizes our study results.
among notebooks less than of them or .
.
and .
respectively for the three selected criteria have been provided with environmental dependency information .
this rate is even lower than the rate calculated similarly reported by pimentel et al.
two years ago.
note that prior work by pimentel et al.
has investigated three sources for notebook environment setup information requirements.txt pipfile and setup.py.
as dis cussed previously setup.py is usually used to locally install a python library from the source.
it is not responsible forinstalling library dependencies.
after manually investigatingnotebooks that use setup.py we confirm that setup.py is indeed not relevant to the environment setup of jupyter notebooks.
therefore we exclude the third criteria setup.py for this study.
furthermore when conducting the previous manual analysis we additionally find that notebook contributors may provide environmental setup information through anaconda e.g.
via environments.yml .
as a result in our study we replace the third criteria setup.py with anaconda environments.
table i distribution of notebooks being provided with environmental dependency information w.r.t.
the selected threecriteria.
requirements.txtenvironments.yml anaconda pipfile total notebooks notebooks .
installable executable rq1 to what extent do public jupyter notebooks provide environment setup information?
among notebooks only less than provide environmental dependency information for helping users execute their notebooks.
for the notebooks that have been provided with environmental dependencies we further check how reliable these are.
to this end we implemented scripts to automaticallyinstall such dependencies using anaconda to create individual environments for each of the aforementioned jupyter 1some notebooks may provide two types of information for helping users setup the execution environments.
for example there are notebooks contain both requirements.txt and anaconda information.
requirements.txt 2pandas without specifying versions 3scipy .
.
must be version .
.
4sklearn .
.
.
minimum version .
.
conda environment.yml 7name env name 8dependencies numpy .
.
py35 0 openssl .
.2h vc14 0 pandas .
.
np111py35 0 pipfile 15url 16verify ssl true 17name pypi 20pandas 21sqlalchemy .
.
fig.
example of the requirement files anaconda environment.yml and pipfiles.
notebooks.
after that we leveraged a tool named nbconvert2 to evaluate the execution of notebooks.
since nbconvert in python .
or its lower versions are no longer supported by the official jupyter team we had to exclude notebooks that cannot be analyzed by our scripts.
after automatically installing the remaining notebooks we resort to their logs to check whether the installations are successful or not.
based on our observation when an installation fails it will contain one of the following threemessages a installationerror occur as the runtime exception b error and c cannot find a version for .
of the notebooks notebooks failed to have theirdependency information installed giving a failure rate of29.
.
rq2 how useful is dependency information in helping notebook users configure the execution environment?
in our evaluation .
of the environmental dependency information provided by notebook contributors was found to be unreliable and or insufficient.
for the notebooks that we can successfully install their environmental dependencies we go one step deeper to check if the installed dependencies are adequate to support the execution of the notebooks.
recall that notebook code cells can be executed in any order and can be repeatedly executed resulting inskipped execution counters .
hence it is practically impossible to infer the actual execution order initially conducted by the notebook contributor.
in this preliminary study we simply execute the code cells top down.
we believe this order reflects the natural flow indicating how its contributor has attempted to implement the notebook.
the execution time is set minutes for every notebook.
psruw uuru loh1rw rxqg uuru 1dph uuru 7lphg rxw wwulexwh uuru qwd uuru 9doxh uuru sh uuru .huqho lhg fig.
top runtime exceptions from executions of notebooks whose dependency files can be successfully installed.
the last row of table ipresents the number of notebooks i.e.
installable ones that can be executed without errors.
in other words among notebooks that have been provided with installable dependency information .
of them can not be successfully executed following the straightforward top down execution strategy.
there are various reasons causing execution of these notebooks to fail.
indeed on the one hand the provided depen dency information may not be perfectly reliable resulting in dependency related errors.
on the other hand even if the environmental dependencies are correctly set up notebooksthemselves may contain implementation errors that can also lead to runtime exceptions.
figure 4enumerates the top errors summarized from the unsuccessful notebooks.
the fact that the top ranked errors are related to environmental dependencies shows that environmental dependency seems to be the primary reason causing execution errors of the aforementioned notebooks.
thetop ranked errors i.e.
module not found and import error are indeed caused by the inadequate runtime environment where the imported modules cannot be located .
in fact notebooks linked to these two errors have accounted nearly half .
and .
respectively of the aforementioned unsuccessful notebooks.
example modulenotfounderror from github project benjaminbossan mink requirements.txt 4scikit learn ... module sklearn.grid search was removed since scikit learn version xxx 8error no module named sklearn.grid search example importerror from github project stargaser astrodata2016 requirements.txt 14astroquery ... scale image api was removed from module astropy.visualization since astroqueryversion xxx 18error cannot import name scale image from astropy.visualization listing two real world examples suffering from runtime errors due to unmatched library versions.
1625among various reasons causing notebooks failing to be successfully executed we further look into some of the failures related to the top types of errors and find that a significantamount of failures are due to different versions of libraries areinstalled.
indeed when providing environmental dependencies cf.figure notebook contributors are not required to specify theexact versions of the dependent libraries.
as a result the unmatched library versions might be installed and hence leadto runtime errors.
listing 1demonstrates two of such examples respectively for modulenotfounderror and importerror obtained from real world notebooks.
due to the fast evolvingnature of software systems such as python libraries certainapis might be deprecated and subsequently removed.
if the wrong library versions are used client applications if not changed will likely be subject to compatibility issues andhence result in runtime errors.
therefore we argue thatwhen specifying the environmental dependencies for jupyter notebooks it is essential to also clearly specify the required versions of required libraries.
rq3 does the provided environment information help notebook users to execute and reproduce the notebooks?
for .
of notebooks the provided dependencies are not sufficient for re executing them without errors.
iv .
snifferdog in this section we present our approach to automatically inferring environmental dependencies for python jupyter notebooks implemented in our snifferdog prototype.
figure summarizes the working process of snifferdog including mainly three modules library api mapping library identification and api standardization and api usageanalysis.
we now detail these three modules respectively.
library api mapping api bank library identi fication api standardiationapi usage analysis jupyter notebook projectpython libraries environmental dependencies fig.
the working process of snifferdog.
a. problem statement before providing the details of our approach we formally define the problem that we plan to address in this work.
atfirst we need to pre build an api bank l l v lv2 lv3 ... that records a large number of popular python libraries api sets in which lv jstands for the set of apis defined in library ljat version v. then given a python jupyter notebook nas an input we need to precisely parse its accessed api set p a1 a2 a3 ... where aiis an api used in p. after that based on the pre built api bank l the goal of this approach is hence to identify a set of libraries lthat fulfill the followingconstraints l l and ai p lv j lthat ai lvj.
b. library api mapping the first module library api mapping is not directly related to the working process of analyzing concrete jupyter notebooks but plays an independent step in building the core infrastructure of our approach.
the output of this module will be an api bank that provides an extensible and on growing database recording mappings from popular python libraries to their apis.
given a python library planned to be included in the api bank this module first builds a directory tree following the file and directory composition of the library aiming at providing a clear way to referring library apis e.g.
from top level package to the leaf module .
in this directory tree python packages or sub packages are represented by non leaf nodes and python source code files are represented by leaf nodes.
figure presents such an example representing a partial code structure tree of the popular python library pandas.
this module then builds abstract syntax tree ast trees for each leaf node orpython file and traverses the trees to locate public functions including their positional and keyword parameters.
the outputof this step can already build a mapping from the library in a certain version to its defined apis.
unfortunately this approach may overlook certain api usages.
applying it to pandas figure the api read excel defined in the base.py module can be referenced via its full qualified name pandas.io.excel.
base.read excel o r base.read excel or read excel if module pandas.io.excel.
base or the api itself pandas.io.excel.
base.read excel is imported as respectively shown in the second and third code cells in figure .
however as demonstrated in the first fourth and fifth code cells figure api read excel could be invoked via another forms such as pandas.read excel i.e.
it can be directly imported from the pandas module despite it being defined in the pandas.io.excel.
base module.
this ambiguity is part of the complicated python import mechanism which has been implemented in a transitive manner.
let xf ybe importing api ffrom module xto module yvia statement from x import f in the source of y. transitivity enables xf y i fyf zandxf z. this feature offered by python runtime has been frequently leveraged by many python libraries to provide simplified means for users to access their apis since it can transparently shorten the full qualified api names.
to resolve this feature while parsing python source code we further conduct an import flow analysis to find all the possible alternatives or aliases of directly defined apis.take the api read excel again as an example regarding the simplified source code shown in figure a the import flow analysis would lead to the following two flows.
pandas.io.excel.
baseread excel pandas.io.api pandas.io.apiread excel pandas 1626fig.
an example of enhanced directory tree for python library pandas.
by taking transitivity into consideration we could further deduce the following flow.
pandas.io.excel.
baseread excel pandas subsequently at the end of this module we further leverage these inferred and deduced import flows to enhance the direc tory tree initially constructed for the library cf.
figure b before recording them into the api bank.
the enhanced directory tree allows us to generate a complete list of apisfor each library integrated into the api bank.
c. api identification and standardization as shown in figure the second module api identifiation focuses on analyzing jupyter notebook projects rather than python libraries as that being targeted by the first module to identify and standardize library api usage.
python code in notebooks can access methods available in local modules that are often developed by the notebooks contributors python standard methods i.e.
often known as system apis that are provided by the core python modules and library methods i.e.
often known as library apis that are developed by third parties and should be imported from externalresources.
in this module we are only interested in the third type of methods namely library apis.
to distinguish library methods from local modules and system apis we considerall the methods that are not defined locally and are not from pythons system apis as library apis .
following the same approach implemented in the library api mapping module we first build ast trees for the notebook s python code and then traverse the trees to identify library apis.
after that this step goes one step deeper toexpand the identified apis to their fully qualified names based on the information extracted from the import and fromimport statements.
for example for the api call statement base.read excel in the second code cell in figure the standardized api will be pandas.io.excel.
base.read excel .
if the identified api is an alias i.e.
re in the fifth code cell in figure 2defined by statement from pandas import read excel as re we will further replace it with its actual name whileconducting the api standardization step.
the standardized version will hence be pandas.read excel .
observant readersmay have observed that our approach will lead to two full qualified names for the same api read excel .
indeed at this stage it is non trivial for our approach to be aware of that by simply analyzing the notebook code.
we hence considerthem as two independent apis.
nevertheless as discussed inthe previous subsection both of these two full qualified apinames will be recorded in the api bank thanks to the importflow analysis.
hence any imprecision in the analysis will not impact the overall precision of our approach.
moreover python code may involve instances of library classes that are initialized by calling constructor methods.
theapis invoked by those instances should also be appropriatelyidentified and expanded.
however in python there is generally no syntax level difference between initializing constructormethods and accessing standard methods.
therefore additional efforts are needed to distinguish them and thereby to allow the identification of classes instances and their accessed apis.
as an example consider the code snippet in listing 1from ximport y 2m y 3m.fun listing an example of qualifying object member function calls.
in listing our approach will first identify that m.fun is a member function call and then trace back to its construction call m y hence method fun is an api in module x. subsequently the fully qualified name of this api will be x.y.fun.
d. library usage analysis the last module of snifferdog library usage analysis is straightforward.
based on the second module s outputs i.e.
a set of apis this module queries these apis against the apibank to find possible library candidates who have providedthese apis.
normally because each api has been provided with a full qualified name the api bank can often precisely locate its belonging library.
the query output will hence be multiple releases or versions of the same library.
by integrating the query results of all the identified apis the objective of this module is hence to find a minimal list of libraries andtheir maximum version ranges that cover all the identified apis leveraged by the input notebook.
snifferdog will then produce its output in common formats that describe python environmental dependencies such pipfile orrequirements.txt.
v. e v aluation to evaluate the effectiveness of snifferdog we address the following research questions rq4 issnifferdog effective in mapping python libraries to their apis?
rq5 how accurate is snifferdog in inferring environment dependencies for python jupyter notebooks?
rq6 to what extent can snifferdog assist users in reproducing jupyter notebooks?
1627a.
experimental setting dataset of jupyter notebooks.
recall that the goal of this work is to automatically infer environmental dependencies for jupyter notebooks so as to help users execute and reproducenotebook outputs.
to evaluate if our approach can achieve thisobjective we resort to the approach introduced by pimentelet al.
to collect jupyter notebooks from github to fulfill our experiments.
github is the world s leadingsoftware development platform hosting millions of software repositories.
the notebooks are retrieved from github projects containing files with jupyter notebook .ipynb formats and declaring python as their programming language.
dataset of selected python libraries.
recall that the api bank of our approach is built based on existing libraries andit can be easily extended to include more libraries.
generally the more libraries considered the more comprehensive theapi bank will be and subsequently the more precise and sound results snifferdog can achieve.
since we aim at generating dependencies for as many notebooks as possible we start by selecting the most popular modules importedby the aforementioned jupyter notebooks.
we thenleverage pypi the official python package index to query the installation wheel files which contain the source codeof library implementation these selected modules.
because several modules may belong to the same library or somemodules have not yet been indexed by pypi we can onlylocate python libraries with different releases for the selected top modules.
therefore in this work we leverage distinct python libraries with releases to construct the api bank.
b. rq4 effectiveness of api bank in this research question we are interested in evaluating the usefulness of the api bank.
from the selected python libraries the library api mapping module extracts apis to fill the api bank.
figure 7illustrates the distribution of the number of apis in each selected library giving median and mean values at and respectively after excluding outliers.
fig.
the distribution of the number of apis per libraryacross all its version after removing outliers.
towards evaluating the correctness of the constructed api bank we resort to a manual process to check if these apis arecorrectly recorded in the api bank.
to this end we randomlyselected apis from the api bank to be manually validated.the number of selected apis is decided by an online samplesize calculator with a confidence level at and a confidence interval at .
for each of the selected apis wemanually check it against its source code and find that ofthem are correct results giving a precision of .
for our api bank construction approach.
in addition to the aforementioned manual investigation we further resort to a dynamic testing approach to evaluate the correctness of the constructed api bank.
giving a mapping from a library version to its apis when the library with the given version is installed all its apis should be able to beimported.
to this end we implement a prototype tool to fulfillthis process automatically.
specifically we first randomlyselect libraries accounting for in total apis fromthe api bank and install them respectively.
for each of the installed libraries we then extract all of its recorded apis from the api bank and conduct runtime import testings to checkwhether these apis can be imported at runtime.
among the3 considered apis only of them fail to be imported in our experiment leading to a success rate of .
.
after analyzing the traceback information of import errors we find that most of such failures are related to missing dependencies that are further required by the libraries under evaluation.
rq4 effectiveness of library mapping is snifferdog effective in mapping python libraries to their apis?
the api bank constructed by the library api mapping module is precise .
of apis are correctly extracted .
can be successfully imported.
among the apis inferred from the libraries of them could further introduce compatibility issues to their client applications if incorrect library versions are installed resulting in for example module not found errors and import errors.
the incompatible apis include .
newly added apis after the first libraries releases .
removed apis compared to the libraries latest versions and .
apis have their parameterschanged over the libraries evolution.
figure 8further presents the distribution of newly added removed and updated apisin each of the considered libraries respectively.
given the fact that .
of the apis including added removed and updated ones without duplication may introducecompatibility issues there is a strong need to also infer thecorrect versions of the dependent libraries when inferring the environmental dependencies for jupyter notebooks our api bank records the detailed evolution changes of considered libraries and is designed to infer not only the dependent libraries but also their correct versions.
rq4 usefulness of api bank is snifferdog effective in mapping python libraries to their apis?
in our evaluation more than half of the library apis were added removed or updated at some point in the libraries life cycles.
this underlines the need to check for compatible library versions as snifferdog does.
1628added removal updated fig.
the median values for the number of added and removed and updated apis are and respectively after excluding outliers.
c. rq5 effectiveness of snifferdog let us now evaluate the effectiveness of snifferdog in inferring environmental dependencies for jupyter notebooks.
we evaluate the effectiveness through one in the lab and one in the field experiment.
in the lab experiment recall that our preliminary study has identified notebooks that are provided with in stallable required dependencies and demonstrated to be executable after the provided dependencies are installed.
we hence take these notebooks as the ground truth to fulfillour in the lab experiment because these notebooks are knownexecutable .
unfortunately out of the notebooks have accessed libraries that are not yet considered by the current api bank constructed based on around libraries .
therefore we have to exclude them from the ground truth.
our final ground truth is hence made up of jupyter notebooks and their required libraries.
for the notebooks we then apply snifferdog to automatically generate experimental dependencies for them.
afterthat we follow the same approach as discussed in section iii to automatically install the generated libraries and execute the corresponding notebooks.
experimental results show that snifferdog can successfully generate installation requirements for .
notebooks among which are successfuly executed giving a recall rate at .
.
the installation failures are mainly related to library compatibility issues brought by the selected python version which is usually not provided by notebook contributors and the underline python setuptools .
for the non executable cases our manual investigation reveals that the failures 8importerror modulenotfounderror and other type of rumtime errors are caused by inaccurate version constraintsyielded by snifferdog.rq5 in the lab how accurate is snifferdog in inferring environment dependencies for python jupyter notebooks?
in a lab setting snifferdog is effective in automatically inferring execution environments for jupyter notebooks successfully generating installation requirements for .
of notebooks.
.
of notebooks couldbe executed automatically.
in the field experiment in this setting we randomly select notebooks and launch snifferdog to generate execution environments for them.
snifferdog completes its analysis in .
seconds or .
seconds per notebook on average.
we now check to which extent the generated environments support the execution of notebooks.
to reduce human influenceto a minimum we restrict ourselves to a subset of notebooks to fulfill this purpose as it is time consuming to evaluate a notebook which involves installing all the dependencies and executing all of its code cells.
to this end we apply the following inclusion criteria to retain notebooks that have been provided with pre defined dependencies which however cannot support their executions and are within the capacity of our api bank.
this gives us notebooks for the in thewide experiment.
among the notebooks snifferdog can successfully generate installable dependencies for of them among which of them can further lead to successful executions of the corresponding notebooks.
note that over half of the notebooks remain non executable.
why is that so?
our manual analysis reveals the following twomain reasons apart from issues raised by notebooks codequalities .
reason the majority of notebooks fail to be executed because of the existence of so called optional dependencies which are not directly accessed by the notebooks hence overlooked by snifferdog but are required by the notebooks directly dependent libraries.
reason a number of failed notebooks are due to the usage of magic functions a special jupyter notebook feature allowing the access of python modules without following python s syntax .
at the moment magic functions are simply ignored by snifferdog.
moreover for the failed notebooks we further look into their error messages and compare them against that outputedfrom executions with their own dependencies consideredas the baseline .
in this experiment only such notebooksthat fail on both sides are considered.
figure 9presents the comparison results.
clearly the number of errors related to theexecution environment for snifferdog is significantly smaller than that of the baseline.
oppositely snifferdog leads to more errors related to the code quality of the notebooks e.g.
filenotfound nameerror or httperror compared to that of the baseline.
this experimental result shows that while the notebooks fail to be executed in both environmental settings the settings resulted from snifferdog are more likely to be 1629correct than its counterpart new runtime exceptions can be further triggered when dependencies are supplied e.g.
for filenotfounderror the file is not provided .
hence even ifthe notebook is not executable yet the dependencies producedbysnifferdog can assist users in getting closer to their goal.
psruw uuru loh1rw rxqg uuru7lphg rxw 1dph uuru .huqho lhg 0rgxoh1rw rxqg uuru7 sh uuru 9doxh uuru vvhuwlrq uuru wwulexwlrq uuru uuru dvholqh 6qliihu rj fig.
top runtime error types resulted from notebooks that can be not executed by environments recommended bysnifferdog and their original ones.
rq5 in the field how accurate is snifferdog in inferring environment dependencies for python jupyter notebooks?
applied on random notebooks snifferdog is effective in automatically inferring execution environments.
when notebooks remain non executable dependencies inferred by snifferdog help users to get them closer to the goal.
d. rq6 reproducing jupyter notebooks in the last research question we evaluate if snifferdog helps users not only execute but reproduce jupyter notebooks i.e.
achieving the same outputs as that recorded originally in the notebooks .
to resolve the problem of cell ordering we make use of a prototype tool called osiris that restores the order in which cells are to be executed .
for our evaluation we resort to the notebooks that have been demonstrated to be executable previously.
we attemptto reproduce these notebooks through the following two experiments experiment osiris baseline .
we create execution environments for different python versions and install all default packages including more than library packages .
then we apply osiris in this environment to analyze the notebooks.
experiment osiris snifferdog .
in this experiment we use the dependencies recommended by snifferdog to set up the environment and we launch osiris in this environment on the same notebooks.
figure 10presents the experimental results.
interestingly although with over popular python libraries installed in the execution environment around one fourth of notebooks cannot be fully executed.
compared to the default environment thefailure rate decreases to less than when the executionenvironment is set up based on the outputs of snifferdog .
regarding reproducibility osiris reports that with the help ofsnifferdog additional notebooks could be reproduced compared to the notebooks reproduced with the defaultosiris configuration.
these experimental results show that our approach is indeed effective in helping users execute and reproduce jupyter notebooks.
hfxwdeoh 5hsurgxfleoh 2vlulv hidxow 2vlulv 6qliihu rj fig.
running osiris in a default environmental setting osiris default vs. running osiris in a snifferdog generated environmental setting osiris snifferdog .
rq6 to what extent can snifferdog assist users in reproducing jupyter notebooks?
compared to a default environment setting environments restored by snifferdog makes significantly more notebooks executable and reproducible.
e. threats to v alidity the experimental findings may suffer from various threats to validity.
the notebooks selected in this work may not be representative.
we attempt to mitigate this threat by starting from real world jupyter notebooks.
we also resort tomanual analysis to summarize the execution errors as well asconfirm some of our experimental results.
such manual processes are known to be error prone.
we have cross validatedthe results to mitigate potential errors.
vi.
r elated work we now discuss the closely related works from three aspects restoring execution environments studies on jupyternotebooks and python dependency analysis.
a. restoring execution environments the most related work to ours is dockerizeme inferring environment dependency configurations for python code snippets collected from github gist.
dockerizeme is implemented based on a pre acquired knowledge base of known python packages using static analysis which is similar to the approach of ours.
however in addition to static analysis it further leverages dynamic analysis to achieve its purpose being able to achieve improvement in reducing importerror 3ideally there should be no failed cases because those notebooks have been demonstrated to be executable with the same environment.
however in practice osiris is implemented in python and per se is dependent on several libraries which may again conflict with the libraries recommended bysnifferdog.
1630messages.
while in principle dockerizeme could also be applied to fully analyzed jupyter notebooks there are important conceptual differences compared to ours.
first dockerizeme only considers the latest version of packages.
it hence cannotdeal with programs containing deprecated removed renamed apis in the latest version of packages.
indeed as empiricallyreported by horton et al.
by an empirical study aboutthe executability of python code snippets on github.
their experimental results show that most gists are not executablein a default python environment and while a naive approachcan infer dependencies for some gists it fails to do so in themajority of cases.
second dockerizeme does not execute code to validate its findings let alone compare results against published results whereas snifferdog automatically determines the configuration that makes the notebook executable ideally even reproducing the results.
the authors further proposedthe tool v2 that takes the program crashes information to guide the search for correct environment dependencies .
however this approach relies on repeated execution of code snippets and does not handle the case when no crash happenand dependencies are incorrect.
on the contrary snifferdog is a static approach that analyzes dependencies using pre builtknowledge.
b. studies on jupyter notebooks despite their popularity research on jupyter notebooks is still limited.
in pimentel et al.
conducted a large scale study on the executability and reproducibility issues of overone million selected notebooks .
their experimental resultsshow that around of the notebooks can be executed without any runtime errors and among which only .
of them can eventually produce the original results.
loenzen etal.
empirically investigate the code duplication and reusein jupyter notebooks and find that notebook repositories havea mean self duplication rate of .
.
more recently wang et al conduct a large scale study on the code quality and empirically find that even notable jupyter notebooks arefrequently suffered from technical debts e.g.
deprecated api uses .
following the discovery of low reproducibility issues among jupyter notebooks wang et al.
went further to propose to address the root causes leading to non reproducible notebooks by offering the community a tool called osiris.
thistool attempts to reproduce jupyter notebooks by leveraging code instrumentation to find out and address the uncertaintieswhen executing jupyter notebooks.
however due to a lack of appropriate execution environments around selectednotebooks failed to be fully executed.
following this researchline fangohr et al.
have further proposed another tool called nbval implemented as a plugin for pytest aiming at supporting automated testing and validation of jupyter note books.
as argued by the authors nbval could be leveraged to promote reproducible science such as checking that deployed software behaves as its documentation suggests.
in addition to researches from the software engineering community jupyter notebooks have been selected frequentlyas subjects by our fellow researchers in other domains .
for example perkel et al.
have studied why jupyter notebooks are popular among data scientists.
kery et al.
have introduced a tool named v erdant to support users with efficient retrieval and sensemaking of messy version data.
itallows users to compare replay and trace the relationshipsamongst different versions of artifacts of both non code andcode in the editors.
furthermore rule et al.
look into the notebooks from the aspects of human factors and empirically observed that computational notebooks may lack the explana tory textual information.
c. dependency analysis one of the most representative ones targeting python dependencies would be the work recently proposed by ying et al.
who attempt to resolve dependency conflicts in thepython library ecosystem .
they designed and imple mented a tool named watchman to detect dependency conflicts among libraries indexed by the pypi repository.
they also reported potential dependency issues to the developers of the corresponding projects.
despite python has becomeone of the most popular programming languages nowadays studies on python projects focus on library api issues and their evolution patterns there has not been muchrelevant research aiming at resolving python dependencies.
nevertheless dependency analysis has been a hot research topic for many other programming languages .
the concepts of these approaches such as resolving compatibilityissues caused by the evolution of libraries automated replacing outdated libraries or updating deprecated library apis we believe should also be appliable topython software applications.
vii.
c onclusion and future work jupyter notebooks may be touted as a prime means to obtain reproducible and replicable research results.
in practice however they suffer from problems that software engineering has solved long ago bad code quality insufficient documentation and as shown in this paper little to nonexistent management of dependencies.
it will take time until thecommunity of jupyter notebook authors will learn to see theirnotebooks not only as entities to be published but also as living code that should be designed to be readable reusable and maintainable.
until then it will be up to the softwareengineering community to reverse engineer notebooks suchthat they can be executed and tested.
in this paper we have taken a major step towards this goal namely restoring the execution environments of jupyternotebooks.
we found that dependencies are hardly ever stated explicitly and that this problem seriously impedes reexecution of jupyter notebooks.
by analyzing imports and api usages in notebooks and matching them against python libraries in various versions our tool snifferdog can identify library candidates that were used for notebook creation.
bysearching for candidate configurations that make the notebookexecutable again and hence fully reproducible snifferdog 1631provides notebook users with essential information that makes notebooks usable again.
given the popularity of notebooks snifferdog thus shows how software engineering can make an important contribution towards reproducible and extensiblescience.
there is still lots to do though.
our future work will focus on the following topics larger api bank.
our api bank is only built based on libraries.
while these make up the most popular libraries having a larger api bank will further extend the capability of our approach.
python and c code.
a small number of cython libraries combine both c and python syntax to achieve c like performances letting a small set of library apis be overlooked.
advanced features.
as already stated in section v some advanced jupyter notebook and python features are not yet supported by snifferdog notably magic functions and indirect dependencies.
beyond python.
the snifferdog principles are not limited to python.
we plan to extend snifferdog to other popular jupyter notebook languages such as r and julia.
beyond notebooks.
the snifferdog principles also extend beyond notebooks.
snifferdog could be equally applied to c source code to determine which library versions wouldbe required for construction and execution.
a version ofsnifferdog for l atex that automatically determines required packages and versions may be especially welcomein scientific communities.
snifferdog is available as open source with explicit dependencies of course .
a complete replication package including all experimental data is available at r eferences j. f. pimentel l. murta v .
braganholo and j. freire a largescale study about quality and reproducibility of jupyter notebooks in2019 ieee acm 16th international conference on mining software repositories msr .
ieee pp.
.
j. wang t. y .
kuo l. li and a. zeller assessing and restoring reproducibility of jupyter notebooks in the 35th ieee acm international conference on automated software engineering ase .
j. m. perkel why jupyter is data scientists computational notebook of choice nature vol.
no.
pp.
.
e. horton and c. parnin dockerizeme automatic inference of environment dependencies for python code snippets in proceedings of the 41st international conference on software engineering ser.
icse .
ieee press pp.
.
.
available pip user guide.
.
available guide requirements files anaconda software distribution .
.
available https docs.anaconda.com the python language reference.
.
available python.org reference import.html python module index.
.
available py modindex.html python module index.
.
available modindex.html python module index.
.
available py modindex.html python module index.
.
available py modindex.html python module index.
.
available py modindex.html python module index.
.
available py modindex.html python module index.
.
available py modindex.html python module index.
.
available py modindex.html python module index.
.
available py modindex.html sample size calculator.
.
available com sscalc.htm documentation .
.
available io en latest built in magic commands .
.
available readthedocs.io en stable interactive magics.html e. horton and c. parnin gistable evaluating the executability of python code snippets on github in ieee international conference on software maintenance and evolution icsme .
ieee pp.
.
v2 fast detection of configuration drift in python in proceedings of the 34th ieee acm international conference onautomated software engineering ser.
ase .
ieee press p. .
.
available a. koenzen n. ernst and m. a. storey code duplication and reuse in jupyter notebooks arxiv preprint arxiv .
.
j. wang l. li and a. zeller better code better sharing on the need of analyzing jupyter notebooks in the 42nd international conference on software engineering nier track icse .
h. fangohr v .
fauske t. kluyver m. albert o. laslett d. cort esortu no m. beg and m. ragan kelly testing with jupyter notebooks notebook validation nbval plug in for pytest arxiv preprint arxiv .
.
d. koop and j. patel dataflow notebooks encoding and tracking dependencies of cells in 9th usenix workshop on the theory and practice of provenance tapp .
m. b. kery and b. a. myers interactions for untangling messy history in a computational notebook in ieee symposium on visual languages and human centric computing vl hcc .
ieee pp.
.
m. s. rehman towards understanding data analysis workflows using a large notebook corpus in proceedings of the international conference on management of data pp.
.
a. rule i. drosos a. tabard and j. d. hollan aiding collaborative reuse of computational notebooks with annotated cell folding proceedings of the acm on human computer interaction vol.
no.
cscw pp.
.
s. samuel and b. k onig ries provbook provenance based semantic enrichment of interactive notebooks for reproducibility.
in international semantic web conference p d industry bluesky .
a. watson s. bateman and s. ray pysnippet accelerating exploratory data analysis in jupyter notebook through facilitated accessto example code in edbt icdt workshops .
h. nguyen d. a. case and a. s. rose nglview interactive molecular graphics for jupyter notebooks bioinformatics vol.
no.
pp.
.
h. fangohr m. beg m. bergemann v .
bondar s. brockhauser c. carinan r. costa c. fortmann d. f. marsa g. giovanetti et al.
data exploration and analysis with jupyter notebooks in 17th biennial international conference on accelerator and large experimentalphysics control systems no.
talk .
m. garc a dom nguez c. dom nguez j. heras e. mata and v .
pascual jupyter notebooks for simplifying transfer learning in international conference on computer aided systems theory.
springer pp.
.
a. rule a. tabard and j. d. hollan exploration and explanation in computational notebooks in proceedings of the chi conference on human factors in computing systems pp.
.
y .
wang m. wen y .
liu y .
wang z. li c. wang h. yu s. c. cheung c. xu and z. zhu watchman monitoring dependencyconflicts for python library ecosystem in proceedings of the acm ieee 42nd international conference on software engineering pp.
.
j. wang l. li k. liu and h. cai exploring how deprecated python library apis are not handled in the 28th acm joint meeting on european software engineering conference and symposium on the foundations of software engineering esec fse .
z. zhang h. zhu m. wen y .
tao y .
liu and y .
xiong how do python framework apis evolve?
an exploratory study in ieee 27th international conference on software analysis evolutionand reengineering saner .
ieee pp.
.
c. tucker d. shuffelton r. jhala and s. lerner opium optimal package install uninstall manager in 29th international conference on software engineering icse .
ieee pp.
.
j. patra p. n. dixit and m. pradel conflictjs finding and understanding conflicts between javascript libraries in proceedings of the 40th international conference on software engineering pp.
.
c. soto valero a. benelallam n. harrand o. barais and b. baudry the emergence of software diversity in maven central in ieee acm 16th international conference on mining software reposi tories msr .
ieee pp.
.
y .
wang m. wen z. liu r. wu r. wang b. yang h. yu z. zhu and s. c. cheung do the dependency conflicts in my project matter?
inproceedings of the 26th acm joint meeting on european softwareengineering conference and symposium on the foundations of softwareengineering pp.
.
y .
wang m. wen r. wu z. liu s. h. tan z. zhu h. yu and s. c.cheung could i have a stack trace to examine the dependency conflict issue?
in ieee acm 41st international conference on software engineering icse .
ieee pp.
.
l. li t. riom t. f. bissyand e h. wang j. klein and y .
le traon revisiting the impact of common libraries for android related investigations journal of systems and software jss .
x. zhan l. fan t. liu s. chen l. li h. wang y .
xu x. luo and y .
liu automated third party library detection for android applications are we there yet?
in the 35th ieee acm international conference on automated software engineering ase .
l. li t. f. bissyand e h. wang and j. klein cid automating the detection of api related compatibility issues in android apps in the acm sigsoft international symposium on software testing and analysis issta .
h. cai z. zhang l. li and x. fu a large scale study of application incompatibilities in android in the 28th acm sigsoft international symposium on software testing and analysis issta .
y .
wang b. chen k. huang b. shi c. xu x. peng y .
wu and y .
liu an empirical study of usages updates and risks of third party librariesin java projects in ieee international conference on software maintenance and evolution icsme .
ieee pp.
.
l. li j. gao t. f. bissyand e l. ma x. xia and j. klein cda characterising deprecated android apis empirical software engineering emse .