adapting requirements models to varying environments dalal alrajeh department of computing imperial college london uk dalal.alrajeh ic.ac.ukantoine cailliau icteam uclouvain belgium antoine.cailliau uclouvain.beaxel van lamsweerde icteam uclouvain belgium axel.vanlamsweerde uclouvain.be abstract the engineering of high quality software requirements generally relies on properties and assumptions about the environment in which the software to be has to operate.
such properties and assumptions referred to as environment conditions in this paper are highly subject to change over time or from one software variant to another.
as a consequence the requirements engineered for a specific set of environment conditions may no longer be adequate complete and consistent for another set.
the paper addresses this problem through a tool supported requirements adaptation technique.
a goal oriented requirements modelling framework is considered to make requirements refinements and dependencies on environment conditions explicit.
when environment conditions change an adapted goal model is computed that is correct with respect to the new environment conditions.
the space of possible adaptations is not fixed a priori the required changes are expected to meet one or more environment independent goal s to be satisfied in any version of the system.
the adapted goal model is generated using a new counterexample guided learning procedure that ensures the correctness of the updated goal model and prefers more local adaptations and more similar goal models.
ccs concepts software and its engineering requirements analysis software evolution model driven software engineering.
keywords requirements adaptation requirements evolution context dependent requirements formal verification logic based learning acm reference format dalal alrajeh antoine cailliau and axel van lamsweerde.
.
adapting requirements models to varying environments.
in 42nd international conference on software engineering icse may seoul republic of korea.
acm new york ny usa pages.
permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
copyrights for components of this work owned by others than acm must be honored.
abstracting with credit is permitted.
to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
request permissions from permissions acm.org.
icse may seoul republic of korea association for computing machinery.
acm isbn .
.
.
.
introduction the engineering of adequate consistent and complete software requirements is known to rely on properties and assumptions about the environment in which the software will operate .
in particular lower level requirements conjoined with such properties and assumptions must entail the higher level requirements to which they contribute .
the documentation of requirements satisfaction arguments showing this is an important aspect of the requirements engineering re process notably for traceability management and requirements verification purposes .
properties and assumptions about the environment called environment conditions hereafter are subject to change over time and space as the system evolves over time or as system variants are being considered over space.
the originally engineered requirements may no longer be adequate consistent nor complete when those properties and assumptions change.
as a consequence the original requirements must be adapted to ensure their adequacy consistency and completeness in the new environment.
this paper uses a goal oriented re framework in order to make requirements refinements and dependencies on environment conditions fully explicit .
to illustrate the problem addressed in the paper consider an example of an urban traffic control system aimed at enforcing low emission zones.
air pollution is estimated to be responsible for premature deaths in europe each year causing more of these than road accidents .
low emission zones lezs are urban areas where the most polluting vehicles are regulated.
consider a software house developing lez enforcement software for cities across europe .
a high level goal for such system is that urban traffic death toll shall be reduced .
to achieve this the goal is refined by prescribing the subgoal g polluting vehicles shall be penalized among others.
when developing the london product the latter goal is refined into subgoal sg polluting vehicles shall be charged when entering designated lez among others.
the latter goal depends on a number of environment conditions e.g.
being in london where polluting vehicles are admitted within such zone but must pay a charge of .
for cities like brussels frankfurt and stockholm the higher level goal gremains the same in spite of different environment conditions.
for brussels in particular the london environment conditions do not hold since polluting vehicles are not admitted in lez in brussels the lower level london goal sgthus no longer makes sense it must be adapted to match the brussels regulations e.g.
by issuing fines .
the problem for the software re team gets exacerbated as regulations are not only varying over space across different countries and cities but also over time as regulations within the same city evolve in unpredictable ieee acm 42nd international conference on software engineering icse icse may seoul republic of korea dalal alrajeh antoine cailliau and axel van lamsweerde ways in brussels they changed once over the last two years .
advanced vehicle technologies e.g.
electric cars are also expected to call for other types of system evolutions.
assume a lez enforcement software product is developed for london.
options for delivering this product to other cities worldwide would currently include a adapt the software implementation directly regardless of the london requirements the resulting implementation would then be requirements free or inconsistent with the original requirements making it impossible to enable requirements based testing traceability management and so forth b develop a set of business rules or a feature diagram along a product line approach for deciding which requirements to consider in which city this appears highly unfeasible given the huge variation space its expansion over time and the unpredictability of evolving city regulations c manually adapt the london requirements to match the specifics of each city a costly and error prone task given for similar reasons and the interdependency among requirements or d provide automated support for the requirements adaptation process as we propose in this paper.
the requirements adaptation problem can be more precisely defined in terms of the well known re reference framework transposed to goal models .given i a set of system goals g a set of lower level subgoals sgcontributing to g one or more common environment independent goals cg to be found in any system variant or evolution to which gcontributes a set of environment conditions esuch that sg e gand g e cg where denotes logical entailment ii an environment variation e ofe compatible with the preservation of the original high level common goal s cg find adapted goals g and lower level subgoals sg where sg e g and g e cg.
the new environment conditions should thus allow one or more common high level goals to remain stable through all system evolutions or variants it would not make much sense to consider ones leading to an adapted system having no common purpose with the original.
little research attention has been paid to provide automated support for this adaptation problem.
much of re work on adaptation so far focuses on reconfiguration within an adaptation space known in advance .
the preservation of requirements satisfaction arguments under environment changes is never addressed there.
work on requirements variants in static or dynamic product lines also assumes the space of all possible variations to be known a priori e.g.
in a feature diagram .
a significant amount of work on requirements evolution has been devoted to requirements traceability and requirements organization for easier change management .
the work closest to ours is where a learning technique for revising goal models is also described.
the problem in is however different and the solution there is not adequate for the adaptation problem considered here.
in environment conditions are not changing and assumed to be correct new conditions may be added but none removed.
preservation of goal model correctness w.r.t.
higher level goals is not considered.
in contrast our aim here is to generate adaptations that preserve model correctness across varying environments.
additionally the learning technique there can only modify goal specifications the goal model structure remains fixed.
our adaptation problem may require other types of changes such as changing the refinementstructure .
finally the learning technique in does not yield revisions guaranteed to be local and similar to the original model.
in predefined sets of countermeasures to goals obstructions are dynamically selected at system runtime to reduce the monitored obstruction rates.
note that our requirements adaptation problem might sometimes be addressed at system runtime runtime adaptations are however not discussed here.
this paper provides a formal tool supported approach to address the adaptation problem defined above at system development time.
for this purpose we use the kaos goal oriented re framework to model requirements and reason about their adaptations.
this framework is chosen because i requirements dependencies on other requirements and on environment conditions is made fully explicit ii multiple abstraction levels are supported iii requirements can be formally specified enabling the use of formal analysis tools and iv the modelling framework has been used in industry e.g.
for huawei smartphones .
thus given a source goal model the proposed approach computes model adaptations for a different target environment where the adaptations may cover model evolution over time or model variants over space the space of variations is not explicitly known in advance it is however constrained by the preservation of environmentindependent goals to be commonly met across adaptations the approach preserves model correctness it is driven by satisfaction arguments of the form sg e g and g e cg given the original model where sg e gand g e cg.
at the heart of our solution is a novel counterexample guided learning technique for adapting requirements expressed in metric linear temporal logic mltl .
in brief given a correct goal model where the source original environment conditions are replaced with the target new ones our procedure verifies the correctness of the refinements of each goal in the model.
if the verification finds an incorrect refinement counterexamples demonstrating this are automatically generated.
these traces are then used as examples by a logic based learning procedure to revise goals appearing in the refinements so as to eliminate this violation.
the procedure iterates until an updated goal model is obtained that fulfils the satisfaction arguments for every goal refinement in the model.
a key aspect of our technique is its ability to search for adaptations of an existing goal model that best meet some preference criteria.
our technique generates adaptations to goals and their refinements that are syntactically as close as possible to the original ones with the fewest goals being adapted whilst ensuring the model s correctness.
the paper makes the following contributions a dedicated notion of context and context dependent property for reasoning about dependencies on changing environment conditions in the re process a novel adaptation method for formal goal models at development time that is guaranteed to produce minimal adaptations a software tool that integrates model checking and logic based learning with preferences our implementation supports multiple degrees of automation from fully automated mode to semiautomated mode allowing for human intervention to guide the search towards relevant adaptations 51adapting requirements models to varying environments icse may seoul republic of korea an evaluation of the correctness and the applicability of our approach on real adaptation problems.
we particularly show how adaptations to goal specifications goal refinement tactics and goal refinement depths are effectively computed.
the paper is organized as follows.
section recalls some required material on goal modelling and logic based learning.
section reviews the sources of variability in goal models.
section defines the requirements adaptation problem.
section gives an overview of our solution.
section details the adaptation procedure.
section discusses our tool implementation.
section evaluates the approach with respect to correctness and applicability.
we discuss aspects of scalability and human intervention in section .
section reviews related work while section concludes our work.
background .
goal oriented system modelling in kaos agoal is a prescriptive statement of intent to be satisfied by cooperation of the agents forming the system.
the word system refers to both the software and its environment including people legacy software devices like sensors and actuators etc.
anagent is an active system component having responsibilities in goal satisfaction and capabilities in terms of conditions the agent can monitor or control.
a environment property is a descriptive statement about the system e.g.
a physical law or a regulation.
we focuse on behavioural goals whose satisfaction is determined in a clear cut sense .
a behavioural goal defines a maximal set of behaviours declaratively.
a behaviour violates a goal if it is not among the behaviours prescribed by it.
to enable formal analysis behavioural goals are specified in a metric linear temporal logic mltl .
the syntax of mltl formulae is defined over a finite nonempty set of propositional variables the logical constants trueand false the standard boolean connectives and the temporal operators next state sometime in the future d sometime in the future before deadline d always in the future and d always in the future up to deadline d .
the formulae pand p where p p are called positive and negative literals respectively.
a behavioural goal gis of type achieve ormaintain.
the specification pattern for achieve goals is current target orcurrent target for short as in where current and target conditions are boolean formulae and d d .
the pattern for maintain goals is current target shortened to current target .
we refer to behavioural goals written in mltl as goal specifications.
their semantics is defined over infinite sequences of states in the standard way .
each state siis uniquely identified by the valuation of variables.
we consider lasso shaped traces of the form w1 w2 where w1 s1s2...andw2 sksk ...are finite sequences .
we use j to denote the jth state of .
agoal model is an and or graph showing how goals are refined and how their responsibilities are assigned to system agents.
anand refinement defines a set of subgoals and environment conditions that together entail the parent goal.
an or refinement captures an alternative and refinement.
leaf goals of the and or graph are assigned as responsibilities to single agents.
a goal assigned to a software agent is a software requirement whereas a goal assigned to an environment agent is an environment assumption.
as a precondition for assigning a leaf goal to an agent the goal urbantrafficdeathtollreduced inputspeedmonitoredenteringvehiclemonitoredspeedlimitenforcedlezenforced anpr camera speed detector column widthspeedingvehiclesfinedpollutingvehiclepenalised chargepaidwhenpollutingvehicleadmittedvehicleplaterecognised pollutionclassdetermined fineissuedforpollutingvehicles vehicletypechargedpollutingvehiclesadmitted pollutingbyvehicletype twentytwopaidwhenchargepaid finesetbyvehicleandoffencetype electronic fee collector electronic fee collectorlez checker electronic fee collector fineissuedbyoffencetypepenalisedvehiclesissuedfineorchagepaidfigure goal model for london s low emission zone.
must be realizable by the agent that is it must have finite bounds in case of an achieve goal and the propositional variables in the target part of the goal specification must be controllable by the agent whereas the propositional variables in the current part must be monitorable by it .
an agent s capabilities are defined by the sets of propositional variables it can monitor and control.
a goal is defined in terms of a name type its refinement a formal specification and an agent assignment for leaf goals.
an environment condition is defined by a name and a formal specification.
the notation gx where x type refinedby spec resp refers to specific components of a goal definition and similarly for environment conditions.
g xi means the goal definition excluding the components in xi .
a goal model is a collection of goal and environment condition definitions.
it is captured diagrammatically with goals environment conditions and agents represented by parallelograms trapezes and hexagons respectively.
edges connected by a white circle capture an and refinement link.
directed edges from hexagons capture agent assignments.
fig.
shows a goal model fragment for the lez example.
the root goal is and refined into two subgoals which are in turn further and refined.
the leaf goal vehicletypecharged is assigned to the electronicfeecollector agent.
a goal model is correct if all its and refinements are complete consistent and minimal.
an and refinement of a parent goal pginto subgoals sg1 ... sgn iscomplete if the subgoals sgi and environment conditions eare sufficient to satisfy pg sg1 ... sgn e pg complete refinement the refinement is consistent if the subgoals are consistent with the environment conditions sg1 ... sgn e false consistent refinement the refinement is minimal if it contains a minimal set of subgoals sgi necessary to satisfy the parent goal pg k jsgk e pg minimal refinement where we represent a conjunction of conjuncts as a set of conjuncts for convenience.
52icse may seoul republic of korea dalal alrajeh antoine cailliau and axel van lamsweerde .
logic based learning logic based learning is a symbolic machine learning technique concerned with inductively inferring general logical theories that with a given background knowledge explain a given set of examples .
state of the art tools referred to as non monotonic logic learning systems are capable of learning generalizations from examples and revisions of existing logical theories expressed as normal logic programs i.e.
logic programs with negation as failure .
arevision task is a tuple b o o k where bis acorrect logical theory a set of clauses called the background theory o ando are sets of atomic formulae called positive andnegative observations a.k.a.
examples respectively and kis a possibly incorrect logical theory called the revisable theory such that bandkdo not cover all examples in o and or do not exclude all examples in o formally o m b k where m b k denotes the semantic model of b k and o m b k .
typically the semantic model m is the set of atomic formulae that follow from .
aninductive solution to such task is a revised theory ekthat together with b covers all examples in o that is o m b ek and excludes all negative ones o i.e.
o m b ek .
the computation of ekis typically achieved through a transformation function that applies change operations adding deleting literals or clauses to k. to make the problem tractable the search for revisions is generally performed within the scope of a search space defined by a mode bias i that reduces the set of candidate solutions by restricting the set of literals that can be added to or removed from the revisable theory k. further restrictions can be imposed by declaring structural constraints don the set of logical expressions that may be included within the solution space see for details .
in this setting a revision task is now defined as a tuple b o o k i d .
a logical theory ekis an acceptable revision if and only if a it is an inductive solution b it is is within the scope of the search space defined by the mode bias i and c it satisfies all structural constraints d. recent state of the art learning systems as the one used in this paper implement a revision task as a satisfiability problem for which efficient solvers exist .
typically logic based learning algorithms generate minimal solutions i.e.
ones with the fewest number of clauses and literals.
when learning revisions minimal solutions are ones whose generation involves the smallest number of change operations.
this enables the revision task to search for solutions that for instance minimize the sum of weights of the derivable consequences in the highest priority level and then those in the next lower level and so forth.
a solution is minimal if the sum of weights of atomic formulae that hold is maximal or minimal as required by the statement among all semantic models of b ek.
environment conditions in changing contexts as introduced in section environment conditions are properties and assumptions about the environment in which the software is intended to operate.
they can take one of three forms i descriptive properties of the environment these are the environment properties introduced in section e.g.
the trapeze pollutingvehiclesadmittedin fig.
ii prescriptive assumptions about the environment these are the goals assigned to environment agents as introduced insection e.g.
the leaf goal vehicleplaterecognized assigned to the anpr camera agent in fig.
and iii descriptive assumptions about the environment these are often implicitly assumed and are needed for refinements to be correct e.g.
vehicle car lorry bus .
environment conditions may hold in specific contexts only e.g.
pollutingvehiclesadmitted holds only in the london context but not in the brussels one.
a context is defined as a set of monitorable facts that are subject to change over time or space and that restrict the validity of an environment condition.
a context has a name called context label e.g.
london and a context predicate e.g.
inlondon .
in the general case a context may be specified in disjunctive normal form where each literal corresponds to a monitorable fact e.g.
inlondon inbrussels .
contexts form a boolean lattice under and operators with false andtrue as bottom and top respectively.
we can thus consider environment conditions whose validity spans over unions or intersections of contexts.
acontext dependent environment condition holds only in a restricted set of context s .
it is written as c for environment condition holds only in context labelled c e.g.
london polluting admitted and brussels polluting admitted.
auniversal environment condition holds in all contexts.
it corresponds to true where true represents the set of all possible context labels.
a context dependent environment condition c can be made universal through an implication pc where pc is the context predicate specifying the context labelled by c. in practice we may wish to avoid this for a simpler formulation.
an environment condition valid in a set of contexts is valid in each member context if c1 ... cn then ci .
we write ec efor the subset of environment conditions in edependent on c. an and or graph may integrate context specific goal model adaptations as alternative or refinements.
this enables moving back to previously considered contexts.
it is therefore convenient toannotate goal refinements involving a context dependent environment condition with the label of the context in which this condition is valid.
context dependent refinements are thereby captured as in .
in fig.
the three bottom and refinements are context dependent and should be annotated with the context label london.
this label propagates up to a common or node to be created when an alternative context labelled brussels is introduced.
the requirements adaptation problem changing contexts may invalidate the context dependent environment conditions within a goal model.
hence a new goal model has to be computed that accounts for the environment conditions of the new context while preserving model correctness.
there might be several model adaptations whose qualities differ.
we identify here two qualities for desirable adaptations.
similarity .
it appears highly desirable to favour model adaptations that maintain similar functionalities across different contexts.
we measure similarity between a goal gand its adaptation egin terms of their respective types refinements formal specifications and agent assignments.
more precisely the similarity measure for these two goals is determined by summing up the number of definitions that are common to the two and then deducting the number of definitions that are specific to gand those that are specific to eg 53adapting requirements models to varying environments icse may seoul republic of korea as commonly done in analogical reasoning .
the similarity measure for two goal models is the sum of the similarity measures of their corresponding goals.
locality.
the impact of an adaptation can range from being local e.g.
affecting goals assigned to a single agent to system wide e.g.
affecting goals involving multiple agents .
adaptations brought about by changes that are localized to parts of a goal model are preferred over adaptations made of disperse changes across the whole goal model.
this principle is inspired by the software evolution literature where disperse changes risk introducing new errors .
in our case disperse changes to a goal model may lead to new incorrect refinements.
to measure locality of an adaptation we introduce the notion of distance between connected goals in a goal model as the total number of refinement links between them.
we say an adaptation gm1ofmis more local than gm2ofmif the sum of the distances of all adapted goals in gm1is smaller than in gm2.
to constrain the space of admissible adaptations to local adaptations and similar goal models we introduce the concept of anchor goals .
here an anchor goal in a goal model is a non leaf goal that should together with its ancestors remain unchanged in any adapted version of the model.
in the lez example for instance an anchor goal should be pollutingvehiclespenalized since in any foreseeable context for lez enforcement vehicles categorized as polluting are expected to be penalized even though how this goal is realized might vary from one context to another.
to favour similarity among models and locality of adaptations anchor goals should be selected at lowest possible levels in the model to be adapted whilst being compatible with the new context.
an anchor goal whose refinement is correct in context c1is said to be compatible with a context c2if it has a correct refinement in context c2.
our adaptation task can be described more precisely as follows given an adaptation problem e c m c a n where eare the environment conditions cis a source context mis a source goal model that is correct under caccording to properties in section .
c is a target context ais a set of anchor goals in m andnare agents capabilities specifications find a target goal model emadapted from msuch that emis correct under the target context c each anchor goal ag a is unchanged inem every leaf goal flginemis realizable emis a maximally local adaptation of m andemis maximally similar to m. goal model adaptation overview fig.
shows the basic workflow of our approach called respire for requirements adaptation in varying environments.
thickbordered input boxes are mandatory.
at development time the analyst provides i an and or graph m ii a setaof anchor goals1 iii a source context c iv a target context c and its environment conditions ec and v the agents capabilities specification nfor the target context2.
we assume context names correctly label the corresponding context dependent refinements in m each refinement is correct and the source context cis indicated inm.
step 1in fig.
acquire contextual changes checks if malready contains a model variant through its or branches that is labelled 1if empty respire assumes every root goal in mto be an anchor goal.
2if no agents capabilities specification is provided then the realizability condition is dropped from the task specification.
goal and or graphagent specification acquire contextual changes learn model adaptation 3a check model completeness and consistencyexisting adaptation found?
noyes column widthanchor goals yesadapted goal model consolidate and or graph updated goal and or graph model found?no extract reference model complete consistent?
minimal?
update model adaptationnonoyes more anchors?yes noyestarget context environment conditions 3b check minimal refinementsfigure respire workflow.
with the target context c .
if found no adaptation is required and the model variant emis returned as the target goal model.
if the target model is not in m extract reference model step 2in fig.
computes from mand the source context a reference goal model to be used for the adaptation process.
this model comprises all and refinements that were labelled with the source context c but in which all environment conditions of the source context are replaced by those from the target context.
this step defines a new adaptation problem as described in section .
respire then first a goal ag a according to some assumed selection rule in our case the left most anchor goal appearing in the graph and uses it to guide a two stage adaptation process described below the two stages are sequentially applied to each anchor goal in this model.
the first stage involves a counterexample guided learning loop enclosed in dashed lines in fig.
.
the following steps are repeatedly called starting from the reference goal model step 3a check model completeness and consistency under the target context.
this involves i constructing completeness and consistency properties given the selected anchor goal ag ii generating counterexamples that violate the completeness and consistency properties under the target context and iii generating witness examples to the satisfiability of the completeness and consistency properties under the target context step learn goal model adaptation of the reference goal model so that refinements in the adapted model are violated in the counterexamples but hold in the witness examples go to step 3a.
the loop repeats until all refinements of the selected anchor goal agare complete and consistent in the adapted goal model or the learner fails to find such a model.
the latter may occur owing to incompatibilities between the anchor goal and some new environment conditions.
if the refinements are complete and consistent with respect to the anchor goal ag then the second stage of the adaptation is triggered.
this second stage involves checking that the refinements of ag in the model generated from the first stage satisfy the minimality 54icse may seoul republic of korea dalal alrajeh antoine cailliau and axel van lamsweerde property in the check minimal refinements process step 3bin fig.
.
if not satisfied then update model adaptation step 5in fig.
removes refinement links until all refinements satisfy it.
if there remain anchor goals in athat have not been checked for correctness respire chooses one and instigates another iterative adaptation process as described above steps 3a 3band .
the iteration terminates once the refinements of all anchor goals are correct under the target environment conditions considered or no correct goal model adaptation is found by the learner.
if successful in finding a correct model adaptation the procedure proceeds to consolidate and or graph step 6in fig.
where the original graph and or mis updated with an or refinement representing the computed target model.
the output of respire is the newly computed target model and the updated mgraph.
respire can run with varying degrees of human intervention within the dashed lines in fig.
e.g.
for leaf goal selection or for acceptance rejection or modification of generated adaptation traces see discussions in sections and .
the respire procedure this section details the core steps 3a 3band 5in fig.
.
we start with a reference model m0 c in which all context dependent environment conditions are now those of c and anchor goals are labelled as anchors.
in our running example the specifications of thelondon dependent environment conditions penalizedvehiclesissuedfineorchargepaid pollutingvehiclesadmitted fineissuedbyoffencetype and pollutingbyvehicletype are replaced by the following brussels dependent environment conditions respectively brussels penalized fineissued brussels polluting admitted brussels polluting diesel euro petrol euro brussels fineissued firsttime onehundredfiftyfine firsttime twohundredfiftyfine whilst the london environment condition twentypaidwhenchargepaid is deleted.
the obvious anchor goal here is pollutingvehiclespenalized since any lez enforcement system has to meet this.
.
checking model correctness this step takes a goal model emc at start this is the reference model m0 c and checks if all its and refinements are correct under the target context c steps 3aand 3bin fig.
.
the outcome is a confirmation that either i the input model is correct ii the input model is complete and consistent but not minimal or iii the input model is incomplete or inconsistent and a counterexample trace.
given an anchor goal agina respire constructs satisfaction arguments for the completeness and consistency of its refinements first and verifies these to generate counterexamples and witness examples if these arguments do not hold.
an obvious option would be to construct these arguments between the anchor goal as conclusion and its immediate subgoals in the premises first check the satisfaction of these and learn an adaptation before recursively proceeding to the construction of arguments for descendent subgoals in a top down fashion.
this option would deem some computations wasteful as the satisfaction argument for a parent goal may become invalidated by adaptations to its subgoals.
in contrast respireconstructs satisfaction arguments for refinement completeness consistency between leaf goals and their ancestral anchor goals.
this provides several benefits i the traces generated by the checks and used by the logic based learning algorithm are guaranteed to be consistent with the agents capabilities specification this in turn guarantees that the adapted goals are realizable ii the generated traces are more concrete and provide the learning algorithm with finer grained examples highlighting which parts of the goal specifications need to be adapted and iii unnecessary re computations of adaptations to parents are avoided as changes to the leaf goals automatically produce changes to their parent goals and ensure the progress of all ancestral refinements towards correct ones.
the construction of satisfaction arguments for checking minimality is discussed in section .
.
.
the three main checks respire conducts for verifying the adapted model s correctness are now further detailed.
.
.
checking completeness.
respire first verifies the completeness of refinements of the anchor goal agin the input model under the target context c .
in what follows emi c denotes the goal model generated in the ith iteration of the counterexample guided learning loop thus representing the ith adaptation of the reference goal model m0 c .
initially i .
the verification is done by model checking that all leaf goals satisfy their anchor goal leaves ag emi c pc ec ag where leaves denotes the set of leaf goals descending from agin emi c a counterexample to the argument is a witness to the incompleteness of ag s refinement.
in our example the reference model m0 brusselscontains the anchor goal pollutingvehiclespenalized specified as polluting penalized .
its refinement is incomplete since there is a trace in which the leaf goals finesetbyvehicleandoffencetype and vehicletypecharged specified as lorry bus euro car diesel euro petrol euro twentytwopaid firsttime sixtyfivefine firsttime onehundredninetyfivefine lorry bus euro car diesel euro petrol euro twentytwopaid respectively and the environment conditions of the target context specified in are satisfied but pollutingvehiclespenalized is not.
the problem is demonstrated by the trace s1 s2 with s1 polluting admitted chargepaid lorry twentytwopaid diesel petrol euro euro euro firsttime sixtyfivefine onehundredninetyfivefine onehundredfiftyfine twohundredfiftyfine fineissued penalized car bus s2 fineissued penalized onehundredfiftyfine the truth values for all variables are shown for the initial state denoted s1 followed by their values in consecutive states only if changed from the previous state.
otherwise their truth values are assumed to persist.
this counterexample violates pollutingvehiclespenalized ins2where polluting is true but penalized is false.
if a counterexample to is found it is added to the set which accumulates all negative traces demonstrating incomplete 55adapting requirements models to varying environments icse may seoul republic of korea refinements.
this set is then used by the learner in the next step to prune out adaptations that falsify the anchor goals.
on the other hand to guide the search towards correct adaptations respire seeks to find positive traces that exhibit how anchor goals may be achieved in the target context.
to this end respire selects a leaf goal lginleaves ag emi c at random or according to some ordering provided by the analyst.
it then constructs and model checks the argument anchors lg emi c pc ec lg where anchors denotes the set of anchor goals that are ancestral to the leaf goal lginemi c .
traces violating the above argument are called adaptation traces.
they demonstrate situations in which the anchor goal and the pre adapted leaf goal are not satisfied together under the target context hence requiring an adaptation .
in the lez example we may consider the leaf goal finesetbyvehicleandoffencetype whose payment of pollution charges is irrelevant in brussels.
relevance may be assessed from the target environment conditions for instance a goal is relevant if the propositional variables appearing in its goal specification also appear in at least one environment condition of the target context.
to generate an adaptation trace respire checks the argument where the specifications of finesetbyvehicleandoffencetype as lg and pollutingvehiclespenalized as its single ancestral anchor respectively.
a counterexample to this is the trace s1s2 s3 s1 polluting admitted chargepaid lorry diesel euro twentytwopaid firsttime sixtyfivefine onehundredninetyfivefine onehundredfiftyfine fineissued penalized twohundredfiftyfine s2 twentytwopaid s3 twentytwopaid the original leaf goal is violated above as a lorry whose euro category is less than and which did not pay the charge is not set the correct fine of sixtyfivefine ins1.
this is acceptable behaviour in the target context where the correct fine of onehundredfiftyfine for a first time offender is set.
note that as twentytwopaid is irrelevant in the brussels context its truth value does not affect the acceptability of the trace since we will see in section .
adaptations are restricted to the language relevant to the target context.
traces violating the argument are added to the set .
a counterexample to the satisfaction of a leaf goal could be deemed unacceptable by the analyst.
section shows how our implementation of respire supports human in the loop to assess the acceptability of and modify the counterexample before it is added to .
the output of a failed completeness check is two sets of traces containing traces violating the anchor goal in the target context c and containing traces that satisfy it in c .
.
.
checking consistency.
to ensure that refinements in the adapted goal model are consistent respire constructs and modelchecks the following argument.
ag pc ec leaves ag emi c a violation to is a demonstration of the leaf goals consistency.
the satisfaction of this argument on the other hand shows that at least one of the goals in leaves ag emi c cannot be satisfied together with the other leaf goals under the target context thus requiring adaptation.
in this case respire selects a leaf goallg leaves ag emi c searches for an adaptation trace violating lgas per argument and adds this trace to the set .
consistency checks are performed only once for each anchor goal.
the reason is that the subsequent learning steps guarantee by construction that all adapted goals are true in each adaptation trace.
inconsistency can only arise between goals of the reference goal model em0 c and the target environment conditions leading to the vacuous satisfaction of the completeness property.
the output of this check is an updated set of adaptation traces.
.
.
checking minimality.
if the and refinements of anchor goal agare complete and consistent then respire proceeds to step 3bin fig.
where every such refinement in emi c is checked for its satisfaction of the minimality property of section .
.
in contrast with completeness checks minimality checks are conducted for every refinement starting from the anchor goal and its immediate subgoals and recursively in a top down fashion.
minimality checking considers the direct refinement of a parent goal dropping a subgoal and checking for completeness of the remaining subgoals with respect to the parent goal.
this top down strategy avoids unnecessary checks for refinements that would be eliminated in step 5by the removal of ancestral refinements violating the minimality property.
if a refinement is found to be not minimal the procedure moves to step 5in fig.
.
.
learning model adaptations step 4in fig.
takes as input the anchor goal ag reference goal model m0 c target context c and environment conditions ec agents capabilities specifications n and sets and produced by the completeness and consistency checks above.
the aim of this step at the ith iterated adaptation of the reference model is to find a model adaptation emi c where a for every eg emi c we have eg b for every we have leaves ag emi c c each anchor goal ag a is unchanged in emi c d every leaf goal eginemi c is realizable e emi c is a maximally local adaptation of m0 c f emi c is maximally similar to m0 c .
the second requirement above ensures the correctness of the adapted model since every trace in violates an anchor goal it should also violate at least one goal in its refinement.
this step deals with a restricted form of the adaptation task defined in section it considers correctness of the adapted model w.r.t.
traces in and .
we call this a trace driven adaptation task .
we thus introduce a weaker notion of completeness and consistency.
given a trace parent goal pgand subgoals sgi pgrefinedby sgi is atrace complete refinement w.r.t.
iff sg1 ... sgn e implies pg it is said to be a trace consistent refinement w.r.t.
iff sg1 ... sgn e a goal model is trace consistent and complete w.r.t.
if every refinement is trace consistent and complete w.r.t.
respectively.
3the selection of leaf goals can be done at random automatically or user driven.
this is discussed in section .
56icse may seoul republic of korea dalal alrajeh antoine cailliau and axel van lamsweerde to compute such adaptations the learning step comprises four main sub steps i encode the trace driven adaptation task into a learning based revision task ii define the space of preferred adaptations iii compute an adaptation as a solution to the revision task and iv encode the solution to the revision task back into an adapted goal model.
the first three sub steps are described below the last is simply the inverse of the first.
.
.
encoding the adaptation problem.
our learning algorithm relies on a canonical representation of goal models on the semantics of correct refinements and on the syntax and semantics of the class of mltl formulas expressible as normal logic programs.
we thus develop an encoding jk that extends the one presented in with the rules below.
the symbol l resp.
l corresponds to a constant uniquely representing the formula resp.
trace l is a constant representing agent s name.
mon p resp.
ctrl p denotes the set of monitorable resp.
controllable propositional variables for this agent.
the main property of this encoding is that for any given trace and mltl safety property we have i iff true l i l m j k j k .
jgresp kdef assigned to g name gresp jganchor kdef anchor g name if g anchor true else empty jckdef context pc jnkdef monitorable l x x mon and n controllable l x x ctrl and n j kdef true x i l x i and false x i l x i and jgkencodes g s definition.
the background theory bcomprises the encoding of anchor goals definitions in m0 c excluding their refinement links the target context and its environment conditions agent capabilities specification and traces in and jag refinedby k ag anchors lg m0 c jc k jec k jnk j k j k in addition balso comprises a declarative representation of the semantics of trace complete refinements for all pg m0 c true sg name l sg m0 c and sg pgrefinedby true pg name l false pg name l true sg name l sg m0 c and sg pgrefinedby where l is a universally quantified variable over .
the first is a direct encoding of .
the latter encodes the requirement b described above.
the trace consistent refinement property is encoded implicitly in the examples as discussed below.
to learn model adaptations whose refinements comprise new goals bmay be extended with placeholders for goal definitions.
the revisable theory k instead includes an encoding of definitions of all goals descending from an anchor goal that is an ancestor to the selected leaf goal and an encoding of the refinement relations between anchor goals and their subgoals as follows.
jagrefinedbygk ag anchors lg m0 c jgk g desc ag m0 c and ag anchors lg m0 c the examples o o capture the trace consistent refinements requirement it necessitates all adapted goal specifications in ektohold in every trace in and not in o true g name l g m0 c and and o false ag name l ag m0 c and .
to guide the learning procedure towards adaptations yielding correct refinements and realizable leaf goals respire specifies i a mode bias ithat restricts the propositional variables allowed to appear in goal specifications to those relevant to the new context and ii structural constraints dover the set of specifications and refinements relations to which any candidate goal model must adhere.
the interested reader is referred to the extended version of this paper in for details of the mode bias iand structural constraints d. note that the encoding for all the above definitions is generated once for every selected anchor goal.
only new counterexamples and adaptation traces are encoded in subsequent iterations.
.
.
defining preferred adaptations.
one key novelty in our learning procedure is the use of soft preferences to guide the revision task towards adaptations that meet the similarity andlocality requirements defined in section .
respire implements these notions by defining an adaptation cost and adaptation impact.
adaptation cost.
when computing adaptations respire applies a series of change operations to goal definitions encoded in k. these include the following operations modify a type add delete a refinement relation add delete a literal to from a specification or delete a responsibility assignment.
the application of these operations defines an adaptation mapping between goal definitions.
given the definition of two goals g1and g2 an adaptation mapping is the smallest set of change operations that can be applied to g1to obtain g2.
the costof a goal adaptation is given by the size of the adaptation mapping between g1andg2.
we assume a uniform cost of one for change operations.
the total cost of an adaptation of mis the sum of all goal adaptations costs.
the learning aims at finding adaptations that minimize this cost.
the adaptation cost implicitly captures a measure of similarity between two sets 1and 2based on tversky s similar 1 2 x x 1 2 x x 1andx 2 x x 1andx 2 when 1 2are elements then similar 1 2 1if 1 2 0otherwise.
similarity between goals is thereby defined as the similarity between their types specification refinements and responsibility assignments similar g eg similar gtype egtype similar gspec egspec similar grefinedby egrefinedby similar gresp egresp where similar gspec egspec is the sum of the similarity measures between their respective current and target condition and temporal operators.4forsimilar current g current eg for instance the first term of equation corresponds to literals that are unchanged in the current condition of ginek.
the second corresponds to those deleted from the current condition of ginkand the third corresponds to those added to it.
goals not included in any refinement link in emare considered to be deleted from m. the similarity measure between goal models is defined as the sum of the similarity measures between every goal ginmand its adaptation eginem.
the cost of the adaptation denoted cost m gm1 is the inverse of the similarity measure.
we say that an adaptation 4note that we consider here syntactic similarity.
we reserve discussion on semantic similarity for section .
57adapting requirements models to varying environments icse may seoul republic of korea m1ofmis less costly than gm2iffsimilar m gm1 similar m gm2 .
the learning procedure aims to minimize the adaptation cost i.e.
maximize the similarity between a goal model and its adaptation .
adaptation impact .
impact measures how local the changes are in the reference goal model m0 c .
to measure the impact of an adaptation we define a notion of distance between goals in a goal model.
the distance between two connected goals g1and g2in model m denoted by dist g1 g2 m is the minimum number of refinement links connecting them.
respire computes this measure by keeping track of all leaf goals selected in step 3a.
we denote this set as selected m .
the locality of an adaptation emtomis calculated by summing the distances between every leaf goal lg selected m and goal xinmwhere both have been modified in em and in the case where a new goal xis added to em the distances between the selected lgand between the goal xand some common ancestral anchor appearing in both mandemas given below.
local m em lg x i1 lg x y i2 lg y z i3 lg z i1 lg def dist lg x m x mandex emand xname exname and x .ex i2 lg def dist lg x m x mand x em i3 lg def dist lg g m dist g x em g m em and g is the closest ancestor to lg in m g ances x em and x mand x em the impact of an adaptation emofm denoted impact m em is the sum of the locality measures w.r.t.
all lg selected m .
thus an adaptation em1has less impact on i.e.
more local in mthan an adaptation em2iffimpact m em1 impact m em2 .
the learning procedure aims to minimize the impact of an adaptation.
.
.
computing adaptations.
the learning algorithm attempts to find an inductive solution that optimizes the preference criteria described above.
conflicts may arise when attempting to minimize both the adaptation cost and impact.
to resolve these we deploy a pre emptive optimization strategy in which cost minimization is prioritized over impact minimization.
if a solution exists the adapted goal specifications are guaranteed to hold in all traces of but in none of thus meeting the trace consistent and complete refinement properties.
for our lez example the learning step returns for instance the following adaptation of finesetbyvehicleandoffencetype compactly specified as euro diesel euro petrol firsttime onehundredfiftyfine firsttime twohundredfiftyfine since the leaf goals and both of which appear in em were modified we have impact m em1 brussels 4as there are 4refinement links connecting them i.e.
i1 lg 4andi2 lg i3 lg .
cost m em1 brussels 14for the deletion of the literals lorry bus car twentytwopaid and euro which appear in both and sixtyfivefine andonehundredninetyfivefine from and and the addition of onehundredfiftyfine andtwohundredfiftyfine to .
once a solution is generated the adapted model emi c is checked for complete refinements w.r.t.
agas per section .
.
.
.
updating adaptations towards minimality as noted in section .
.
once all refinements of an anchor goal in the adapted goal model are complete and consistent respire conducts a minimality check for every parent goal in the adapted model step 3bin fig.
.
the aim of this step is to remove subgoals that violate the minimality property of .
starting at the anchor goal if removing a direct subgoal maintains completeness the subgoal and its descendants are removed.
finding a minimal set of subgoals satisfying is np hard.
however it is assumed that parent goals in well structured models have a small number of immediate children making this computation tractable.
column widthpollutingvehiclepenalised fineissuedforpollutingvehicles pollutingvehiclesnotadmitted pollutingbyfueltype finesetbyvehicleandoffencetype electronic fee collectorfineissuedbyoffencetypepenalisedvehiclesissuedfine figure adapted goal model for brussels lez.
in our lez example two more iterations over the anchor goal pollutingvehiclespenalized result in a complete refinement.
the minimality check finds that dropping the subgoal chargepaidwhenpollutingvehicleadmitted maintains completeness of the goal pollutingvehiclespenalized s refinement.
therefore this subgoal and its subtree are removed.
the updated goal model is shown in fig.
.
implementation we developed a prototype toolset in python implementing the adaptation procedure detailed in section .
the toolset integrates a number of third party libraries and software.
we use the python boolean library to rewrite the current conditions of specifications into a standard form.
we use the nusmv2 .
symbolic model checker to i check the correctness of goal models and ii generate counterexamples.
we built upon the raspal learning based revision tool for our learning engine.
we built an automated translator to convert goal specifications into nusmv and raspal syntax and vice versa.
the tool can run in fully automated mode or in interactive mode.
the automated mode forms the base setting in which i all propositional variables appearing in the environment conditions of the target context agents capabilities specifications and anchor goals are considered when computing adaptation ii leaf goals of the anchor goal are selected at random when verifying argument iii all generated adaptation traces are accepted without modification and finally iv the size of the adapted goal model is fixed.
the interactive mode supports various degrees of human control including i selecting the variables that may appear in the target model ii selecting the leaf goal to be checked iii confirming the suitability of the automatically generated adaptation trace iv providing an alternative adaptation trace if not and finally v enlarging the size of the search space by allowing respire to increase the number of goals in the target model or its refinement depth or to explore alternative refinement tactics.
each of these features can be enabled when respire is launched.
they are introduced to speed up the adaptation process towards relevant models.
58icse may seoul republic of korea dalal alrajeh antoine cailliau and axel van lamsweerde evaluation in this section we evaluate our approach in terms of its correctness and applicability to real world problems.
.
correctness theorem termination .
the respire adaptation procedure is guaranteed to terminate.
proof sketch.
there are three loops in the adaptation procedure.
the loop over anchor goals terminates as the set of anchor goals is finite.
the counterexample guided learning loop within the dashed lines in fig.
is guaranteed to terminate since i counterexamples and witness examples are accumulated in the sets and thus ensuring that a new goal model is learned in every iteration that is semantically different from previous ones and ii the adaptation space is finite since the sets of change operations and of propositional variables are finite.
the loop for minimality checking and model updating also terminates as the set of subgoals is finite.
theorem soundness and completeness .
let and be sets of traces generated by respire for the adaptation problem e c m c a n .
if respire returns a goal model emc thenemc is correct under the target context.
if respire returns then no adaptation exists in the constrained search space that is trace consistent and complete w.r.t.
and under c .
proof sketch.
soundness is guaranteed since respire only constructs well formed goal models that satisfy the correctness properties of section .
moreover the learning procedure fails in two cases i the sets of examples provided by the analyst are not well separated i.e.
a trace can appear as both a positive and negative or ii no solution exists within the search space.
theorem similarity and locality .
let e c m c a n be an adaptation problem and the traces generated by respire andemc an adaptation solution.
then emc is a maximally similar adaptation to m0 c. it is a maximally local adaptation within the space of a maximally similar adaptations.
this follows from the definition of the reward function in the learning step see section .
.
respire supports the search for similar goal models by providing the learning step with the reference goal model m0 c as input.
as the search for a solution is driven by the sample of traces used a local minimal solution to the adaptation problem rather than a global minimal one is ensured.
.
applicability we briefly report on the application of respire to two real computeraided ambulance dispatch cad systems one for belgium and one for wales .
three common anchor goals were considered yielding three sub models to be adapted from belgium to wales b w and three vice versa w b .
a description of the number of goals and environment conditions in the sub models rooted on the same anchor goal across the two contexts is given in table .
anchor id eb gb ew gw table description of source target sub models considered.our respire tool was applied in two modes the fully automated mode and the interactive mode.
in the interactive mode the analyst could i assess and manually change the automatically generated adaptation traces to suit the target context and ii increase the the size of any adapted model to be computed.
the first author acted as the analyst.
all other steps were done automatically.
experiments were conducted using a .
ghz intel core i7 processor.
the fully automated mode often terminated unsuccessfully in at most two iterations owing to either the automatically generated adaptation traces being inadequate for the target context the need to increase size of the adapted model or missing environment properties.
consider the anchor goal an ambulance shall arrive at the scene of a reported incident on time .
checking its completeness in the wales context results in an adaptation trace for the leaf goal maxinterventiontimeis12minutes where an ambulance requires more than minutes to arrive without any problem along the way this scenario is inadequate in the wales context.
by modifying the ambulance s arrival time in the trace as indicated by ew respire finds the correct solution.
hence we focus in our discussion on the interactive mode experiments.
respire terminated successfully for all six adaptation problems.
it effectively covered different types of adaptations requiring modifications to goal specifications gs refinement links rl refinement tactics rt by transforming a case driven goal refinement into a milestone driven one and vice versa and the goal model s depth rd .
table gives a summary of the results.
lrn g t min.
g t iter.
type avg.
cost avg.
reward b w gs rl b w gs rt b w gs rd rl w b gs w b gs rt rl .
w b gs rd table summary of second experiment results.
lrn.
g tgives the number of learned goals in the adapted submodel of the target context.
min.
g tis the number of goals in the updated goal model after the minimality check and model updating.
iter.
is the number of completeness checks performed until respire terminates.
the column type gives the form of adaptation involved.
the last two columns give the average costs and impact of all adapted models computed until respire terminates.
for instance we know from table that the source sub model rooted on the anchor goal with id 1contained four environment conditions which were replaced by two environment conditions for the wales context.
the original belgium sub model contained two goals including the anchor goal whilst the wales one contained three.
from table we see that respire learned two goals in solving the adaptation problem b w for the sub models rooted on the anchor goal with id i.e.
b w both were maintained after the minimality check.
two iterations were needed to termination.
the adaptation involved changes to the goal specification and addition of a refinement link of distance .
the average cost of the adapted models computed over the iterations is 4and the average impact is .
we notice that rd adaptations are typically more costly as they require learning the full specification of the new leaf goals.
fig.
plots the time in seconds y axis spent by the model checking blue and the learning red components in an application of respire to each adaptation problem x axis .
the variance in 59adapting requirements models to varying environments icse may seoul republic of korea each box is over time spent in iterations of the counterexampleguided learning loop.
overall the time spent by the two components did not exceed .
sand the time spent by each component increased linearly as the number of iterations increased.
b w w b b w w b b w w b .
.
.
.
.
.
.
.
model checking learning figure performance of respire in interactive mode.
discussion scalability.
respire s scalability relies on that of the model checking and learning procedures.
we use nusmv an efficient bddbased checker heavily deployed in practice.
the learning engine is implemented using the answer set solver clingo whose scalability is comparable to sat solvers.
a crucial point is the size of the search space.
the interactive mode therefore also allows the analyst to restrict the search space to a practical scope.
human control.
having analysts in the loop is important in producing adequate models for unseen contexts.
this was particularly apparent in the choice of adaptation traces as these guide the outcome of the learning procedure and subsequently generated counterexamples.
we argue that respire s benefits are not hindered by this modifying trace examples is often considered less error prone than modifying the specifications .
in our experience trace modification typically involved changing the truth values of one or two propositional variables in the automatically produced trace at most.
we also found that allowing the analyst to assess the adaptation traces often highlighted implicit environment conditions e.g.
critical highlycritical inw b .
though the fully automated mode terminated unsuccessfully initially for w b two goals were correctly computed.
increasing the number of goals in the adapted model in interactive mode here by lead to successful termination.
semantic similarity.
respire searches for syntactically similar goal models which may yield semantically different models i.e.
in terms of the set of behaviour they prescribe .
we can leverage for this by extending the step 3awith an additional query to the model checker namely desc ag m0 c pc ec ag .
counterexamples are then added to .
we will treat this in future work.
related work much of re work on adaptation so far has focused on reconfiguration within a fixed predefined adaptation space .
none is driven by satisfaction arguments.
in a general problem definition framework is proposed for requirements based runtime adaptations as an alternative to which this work builds on.
the work in also presents a notion of contextual goal models where goals and refinements are decorated with context conditions that are monitored at run time for switching to more appropriate alternative refinements.
the work in addresses the selection of most appropriate configurations for a dynamic software productline.
the requirements there are assumed to be known at re time and are fixed.
our technique might be seen as complementary by learning modified requirements that could be taken as input.
the techniques proposed in and compute new specifications that satisfy modified requirements.
in both techniques the computed specifications are evaluated in terms of a the number of elements in common with the current specifications b the change effort required to modify the current specifications and c the reuse of previous specifications.
our technique might complement these approaches by providing the modified requirements as input.
learning based solutions include .
in the authors define a probabilistic logic based learning approach to revise behaviour models for reactive planning at run time.
their focus is restricted to revising probabilities over environment assumptions expressed as condition event invariants .
the work of as noted in section differs substantially including in a purpose and problem addressed finding countermeasures to obstacles in a single environment vs. finding model adaptations across varying environments b method type of model checking and learning tasks when how to perform these c degrees of automation d types and properties of model revisions e.g.
refinement minimality and e specifications semantics event based vs. state based the latter being better suited for reasoning about goal models .
as in however goal models are represented as normal logic programs and our inductive learning solutions can be classified as oracle guided.
respire shares its essence with counterexample guided learning methodologies e.g.
for invariant discovery .
the closest work to our learning methodology are .
unlike ours however a their learning approaches are based on incremental refinement which reduces the prescribed behaviour monotonically b preferences are not specified over the solution space and c both approaches assume an event driven asynchronous semantics of goal models.
conclusion and future work the adequacy completeness and consistency of software requirements depend on the software environment.
environment conditions are involved in satisfaction arguments an important aspect of the re process .
in varying environments such arguments may be invalidated.
a tool supported approach was presented for adapting a given goal model automatically to new environment conditions.
this approach combines verification learning cycles constrained by preserving higher level goals and by minimizing the adaptation cost and impact.
unlike other approaches to requirements adaptation the space of possible changes needs not be explicit in advance.
the application of respire to documented variations of a real ambulance system revealed that our approach goes far beyond mere renaming of variables in goal specifications.
this work builds a theoretical foundation for and assesses the feasibility of learning requirements adaptations.
further experiments into factors affecting the performance of respire such as leaf goal selection and its usability is part of our future work.
common challenges of using formal methods at re time remains.
in particular the environment knowledge used in satisfaction arguments has to be made explicit complementary means are thus needed for handling the common tacit knowledge problem in re.
in addition we intend to expand respire for runtime adaptations e.g.
using a runtime verifier.
60icse may seoul republic of korea dalal alrajeh antoine cailliau and axel van lamsweerde