towards understanding the characteristics of code generation errors made by large language models zhijie wang zijie zhou da song yuheng huang shengmai chen lei ma tianyi zhang university of alberta edmonton ab canada university of illinois urbana champaign champaign il usa the university of tokyo tokyo japan purdue university west lafayette in usa zhijie.wang ualberta.ca zijiez4 illinois.edu dsong4 ualberta.ca yuhenghuang42 g.ecc.u tokyo.ac.jp chen3301 purdue.edu ma.lei acm.org tianyi purdue.edu abstract large language models llms have demonstrated unprecedented capabilities in code generation.
however there remains a limited understanding of code generation errors that llms can produce.
to bridge the gap we conducted an indepth analysis of code generation errors across six representative llms on the humaneval dataset.
specifically we first employed open coding and thematic analysis to distill a comprehensive taxonomy of code generation errors.
we analyzed two dimensions of error characteristics semantic characteristics and syntactic characteristics .
our analysis revealed that llms often made nontrivial multi line code generation errors in various locations and with various root causes.
we further analyzed the correlation between these errors and task complexity as well as test pass rate.
our findings highlighted several challenges in locating and fixing code generation errors made by llms.
in the end we discussed several future directions to address these challenges.
index terms empirical study code generation large language models i. i ntroduction automatically generating code from natural language has been a long term pursuit across multiple research communities.
recent advances in large language models llms have led to rapid unprecedented improvements on this task .
despite this great progress llms still cannot reliably generate correct code for many tasks.
currently there is a lack of deep understanding of the cases where llms fail.
specifically it remains unclear what types of code generation errors an llm typically produces andwhether different llms make similar errors .
answering these questions would help researchers gain insights into the limitations of existing models and identify opportunities for model improvement.
to bridge this knowledge gap we conducted an in depth analysis of code generation errors made by llms.
we focused on six popular llms codegen 16b incoder .3b gpt .
gpt santacoder and starcoder .
these models produced incorrect code solutions on the tasks from the humaneval dataset .
four of the authors worked together to locate the erroneous parts of these incorrect solutions and manually fix them.
specifically for some tasks llms may propose an alternative solution that differs from the ground truth solution in humaneval e.g.
using a lambda expression to process a sequence of data instead of using a the first three authors contributed equally to this work.
zijie zhou was a remote research intern at purdue university.loop.
to avoid overfitting the ground truth the authors manually located and fixed errors following the problem solving direction of the llm instead of simply comparing the llm generated code with the ground truth.
we performed multiple rounds of open coding and iterative refinement to analyze the characteristics of the located errors.
specifically we analyzed these errors alongside two dimensions the semantic characteristics andsyntactic characteristics of these errors semantic characteristics can help identify the high level root causes of these code generation errors.
representative semantic characteristics include missing condition wrong logical direction incorrect condition etc.
analyzing these semantic characteristics can help understand the limitations of current llms in interpreting task requirements and generating semantically correct programs.
syntactic characteristics can help localize where the error occurs in an incorrect code solution.
representative syntactic characteristics include incorrect code blocks incorrect function arguments etc.
understanding these characteristics allows for a better assessment of current llms abilities to generate different kinds of code constructs.
it can also help inform the design of new techniques for localizing and repairing code generation errors made by llms.
our analysis shows that the majority of code generation errors involve multiple lines of code rather than simple errors.
these errors often require substantial code restructuring and repair rather than simple fixes.
furthermore while the overall distribution of the syntactic characteristics of these errors i.e.
error locations is similar across different llms the semantic characteristics of the errors i.e.
root causes vary significantly for different llms even for the same task.
interestingly most of the incorrect code solutions are compilable and runnable without any compilation errors.
thus we cannot easily capture these errors via compiler check.
careful code review and highquality test cases are necessary to capture these errors.
this also implies that modern llms have adequately learned the syntax rules of programming languages but struggle with understanding intricacies in natural language task descriptions and generating delicate code with sophisticated logic.
in summary this paper makes the following contributions we established a taxonomy of both syntactic and semanticcharacteristics of code generation errors through open coding and thematic analysis.
our labeling results are available at a github repository .
we analyzed the similarities and differences in the errors made by different llms as well as the bug fixing effort the impact of task complexity and the correlation between test pass rates and different kinds of errors.
we discussed the implications and future opportunities for improving llms for code generation.
we developed an interactive data analysis website to help researchers and developers examine and explore code generation errors in different categories.
the website is available at ii.
m ethodology a. research questions this study investigates the following research questions.
rq1 what kinds of code generation errors do different llms make?
this question aims to uncover the common characteristics and distinctions of code generation errors made by different llms.
this can help us understand whether it is feasible to develop generic methods to improve llms or whether these models need specialized treatment.
rq2 how much effort is needed to fix code generation errors?
in practice it is unrealistic to expect llms to generate fully correct code for every possible scenario.
existing studies show that some incorrect code can still serve as a useful starting point for developers .
thus it is important to understand what efforts are needed to fix the incorrect solutions and whether it is possible to automate the repair.
this question aims to fill this knowledge gap.
rq3 how does the task complexity affect an llm s code generation?
intuitively complex tasks are more challenging to solve than simple tasks.
yet it is unclear whether different llms exhibit different code generation capabilities when solving tasks of different complexity levels.
specifically it would be useful to find out whether there is an upper bound on the complexity of tasks that llms can eloquently solve which can then be used to guide or estimate the effort required for code review testing and repair.
rq4 does partially failed code exhibit different characteristics compared with fully failed code?
this question explores the distinctions between code that fails a subset of test cases and code that fails all test cases.
it can offer insights into the specific challenges faced in achieving full correctness.
b. code generation llms in this study we focus on six representative code generation llms codegen 16b incoder .3b gpt .
gpt santacoder and starcoder .
as shown in table i these models cover a wide range of model sizes and model performance.
codegen 16b was trained on 217gb python code from bigpython .
incoder .3b was trained on 159gb of open source repositories from github gitlab and stackoverflow.
santacoder and starcoder were trained on the stack dataset .
the training data of gpt .
and gpt 4table i code generation llms used in this study model release sizeperformance pass incorrect solutions codegen 16b mar.
16b .
incoder .3b apr.
.3b .
gpt .
nov. 175b .
gpt mar.
.7t .
santacoder apr.
.1b .
starcoder may.
.5b .
are currently unknown.
as gpt .
and gpt are constantly evolving we used gpt .
turbo and gpt the two most recent model checkpoints at the time of our analysis.
c. collection of incorrect code solutions in this study we utilize the widely used humaneval benchmark to collect code generation errors made by llms.
humaneval includes hand written python programming tasks each accompanied by an average of .
unit tests.
these tasks involve language comprehension reasoning algorithms and simple mathematics.
for each task we followed the common practice in benchmarking the performance of code llms to prompt each llm with the original prompt from humaneval which includes a task description and several exemplary test cases .
on average .
while there are more advanced prompting strategies to augment llms for code generation we are more interested in the innate capability of llms as the first step to understanding their limitations.
nevertheless we discuss this as a threat to validity in sec.
vi.
we also used greedy decoding with the temperature set to to ensure the reproducibility of our results.
then we executed the test cases to identify incorrect solutions.
we also performed a round of manual checks to find solutions that pass test cases but are not fully correct since some tasks may not have sufficient test cases.
we found such cases.
example shows an incorrect solution generated by gpt .
which fails to handle the case where xis .
in this scenario the output should be instead of an empty string.
however such test cases are absent in the humaneval benchmark.
in the end we identified a total of incorrect code solutions generated by the six models.
table i shows the distribution.
change numerical base of input x to base.
def change base x base result while x result x str x base result x base return result example incorrect solution that passed all test cases d. manual analysis of incorrect code solutions we performed open coding to analyze the characteristics of the incorrect code solutions and developed a taxonomy of code generation errors made by llms.
open coding.
from the incorrect solutions we first randomly sampled of them as a starting point for analysis.
the sample size is statistically significant with a confidence level and a .
margin of error.
two authors independently identified the erroneous parts of each incorrect solution and documented the root causes of the errors.
for incorrect code solutions with multiple errors the authors labeled the characteristics of each individual error.
since llms maytable ii taxonomy of semantic characteristics of code generation errors made by llms.
error characteristic example of incorrect solutions correct solution condition error missing condition codegen 16b def double the difference lst sum for iinlst ifi and i !
sum i 2return sum ground truth def double the difference lst ans for num inlst ifnum and num 0and .
not in str num ans num 2return ans incorrect condition gpt .
def change base x base r while x rem r x base str rem r x x base return result ground truth def change base x base ifx return ret while x !
ret x str x base ret x basereturn ret constant value error constant value error santacoder def remove vowels text vowels aeiou return .join char for char intext if char not in vowels ground truth def remove vowels text return .join list filter lambda ch ch not in aeiouaeiou text reference error wrong method variable incoder 1b def decimal to binary decimal return str decimal db ground truth def decimal to binary decimal return bin decimal db undefined name codegen 16b def starts one ends n ifn return return starts one ends n ends one starts n ground truth def starts one ends n ifn return return n operation calculation errorincorrect arithmetic operation incoder 1b def change base x int base int digits while x digits.append str x base x base return .join reversed digits ground truth def change base x int base int ifx return ret while x !
ret str x base ret x basereturn ret incorrect comparison operation codegen 16b def is equal to sum even n return n and n ground truth def is equal to sum even n return n and n garbage code only comments incoder 1b def compare game guess regenerate the task description.
ground truth def compare game guess return guess for iin range len game meaningless code snippet starcoder def is equal to sum even n pass ground truth def is equal to sum even n return n and n wrong logical direction incoder .3b def find closest elements numbers closest to one closest to two numbers numbers for number innumbers ifnumber closest to one closest to one number ifnumber closest to two cloeset to two number return closest to one closest to two incoder .3b def find closest elements numbers min diff min pair float inf none for l r in zip numbers numbers diff r l ifdiff min diff min diff diff min pair l r return min pair incomplete code missing stepsmissing one step incoder 1b def count distinct chars string return len set string ground truth def count distinct chars string return len set string.lower missing multiple steps memory error infinite loop codegen 16b def make a pile n ifn return make a pile n else return make a pile n ground truth def make a pile n ans num n for in range n ans.append num num 2return ans generate alternative solutions compared with the ground truth solution from humaneval we chose to manually debug the incorrect solution rather than simply comparing it with ground truth.
specifically the two authors executed the failed test cases and performed step by step debugging to locate the errors and identify their root causes.
the authors documented all error locations and root causes and discussed them with other authors after the initial coding.
they refined code labels and came up with an initial codebook.
at this stage we found that code generation errors made by llms can be categorized along two dimensions based on their semantic andsyntactic characteristics.
semantic characteristics help identify the high level root causes of code generation errors such as a wrong logical direction to solve the task.
in contrast syntactic characteristics assist in error localization such as determining whether the error is in the method name or the arguments.
the initial codebook includes seven semantic characteristics and eight syntactic characteristics.
iterative refinement of the codebook.
after obtaining the initial codebook we invited another two authors to iteratively improve the codebook.
the four authors first independently analyzed incorrect code snippets following the same procedure describedabove and labeled the error characteristics based on the initial codebook.
if a new characteristic was identified an author created a new label to describe the characteristic.
after the first round of labeling we computed fleiss kappa to measure the inter rater agreement.
we used fleiss kappa instead of cohen s kappa since we had more than two labelers and more than two labels.
the initial scores were .
and .
for semantic characteristics and syntactic characteristics respectively .
to figure out where the disagreements were the four authors met to discuss the disagreements and exchanged opinions about updating the codebook.
they found that the low agreement was due to missing error characteristics in the initial codebook.
the four authors then refined the codebook with semantic characteristics and syntactic characteristics and labeled another batch of incorrect solutions.
the fleiss kappa scores of this round of labeling were .
and .
for semantic characteristics and syntactic characteristics respectively indicating substantial agreement .
the authors further discussed the disagreements and refined the codebook with semantic characteristics and syntactic characteristics.
then they conducted the third round of labeling with a new batch oftable iii taxonomy of syntactic characteristics of code generation errors made by llms.
error characteristic example of incorrect solutions correct solution conditional error if error codegen 16b def double the difference lst sum for iinlst ifi and i !
sum i 2return sum ground truth def double the difference lst ans for num inlst ifnum and num and .
not in str num ans num 2return ans loop error for error gpt .
def solution lst sum for iin range len lst iflst !
sum lst return sum ground truth def solution lst return sum x for idx x in enumerate lst ifidx and x while error return error incorrect return value gpt .
def rounded avg n m ifn m return avg round sum range n m m n return bin avg ground truth def rounded avg n m ifn m return avg round n m return bin avg method call error incorrect function name starcoder def same chars s0 s1 return sorted s0 sorted s1 ground truth def same chars s0 s1 return set s0 set s1 incorrect function arguments incorrect method call target assignment error incorrect constant incoder .3b def is equal to sum even n return n 4and n ground truth def is equal to sum even n return n 8and n 0incorrect arithmetic incorrect variable name incorrect comparison import error import error starcoder def sum squares lst return sum int math.ceil i 2for iin lst ground truth def sum squares lst import math return sum map lambda x math.ceil x lst code block error incorrect code block incoder .3b def starts one ends n count while n count n count n 10return count ground truth def starts one ends n ifn return return n missing code block codegen 16b def next smallest lst if len lst return none lst.sort return lst ground truth def is prime n if len lst return none sorted list sorted lst for xinsorted list ifx!
sorted list return x errors.
the authors did not find any new error characteristics in this round and the fleiss kappa scores increased to .
and .
.
at this point the authors believed that the codebook was comprehensive enough.
the final codebook includes semantic characteristics and syntactic characteristics.
analyzing the remaining dataset.
the two authors used the final codebook to label the remaining incorrect solutions.
the final fleiss kappa scores were .
and .
for semantic and syntactic characteristics indicating perfect agreement .
they had disagreements on errors semantic characteristics and errors syntactic characteristics.
these disagreements were resolved after discussing them with all the authors.
no new error characteristics were found.
the final coding results were documented in a spreadsheet and shared on github .
the whole labeling process took about person hours.
e. analysis of repair effort to investigate the repair effort rq2 we employ three different metrics to measure the similarity between incorrect model generated code and the corresponding correct solution.
to ensure a fair comparison we first removed all llmgenerated comments before calculation.
we used levenshtein distance to compute the minimum number of edits i.e.
insertions deletions or substitutions required to change an incorrect solution to the correct solution.
we also used jaccard similarity as another textual similarity metric.
both of them are widely used for fault localization .
we further used codebertscore to measure the semantic similarity between the incorrectly generated code and the ground truth.
note that for some tasks an llm may propose an alternative solution with errors compared with the ground truth solution in humaneval.
we identified incorrect solutions where thellm proposed an alternative way to solve the task but did not correctly solve it.
in such cases it is unfair to directly compare the incorrect code with the ground truth.
to address this issue one author manually solved the task following the llm s solution and computed the metrics by comparing the incorrect solution with the alternative correct solution.
iii.
r esults in this section we denote the programming tasks in humaneval as task .
due to the page limit some code examples are simplified.
we refer the readers to our github repository for more details .
a. rq1 characteristics of code generation errors table ii and table iii present the finalized taxonomy of code generation errors made by llms.
the taxonomy categorizes code generation errors based on their semantic characteristics i.e.
root causes and syntactic characteristics i.e.
error locations .
in total there are semantic characteristics in categories and syntactic characteristics in categories.
we elaborate on each of them below.
semantic characteristics condition error includes missing condition andincorrect condition .
missing condition is when a necessary condition is omitted while incorrect condition is when an condition is incorrectly formulated in an if statements or a loop leading to errors.
constant value error is an error that occurs when an incorrect constant value is set which can occur in function arguments assignments or other parts of the code.
reference error involves incorrect