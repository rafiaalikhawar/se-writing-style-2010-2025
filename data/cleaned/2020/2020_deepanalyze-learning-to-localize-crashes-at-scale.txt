deepanalyze learning to localize crashes at scale manish shetty t mamola microsoft.com microsoft research bangalore indiachetan bansal chetanb microsoft.com microsoft research redmond usasuman nath sumann microsoft.com microsoft research redmond usasean bowles sbowl microsoft.com microsoft redmond usa henry wang hewang microsoft.com microsoft redmond usaozgur arman oarman microsoft.com microsoft redmond usasiamak ahari sahari microsoft.com microsoft redmond usa abstract crash localization an important step in debugging crashes is challengingwhendealingwithanextremelylargenumberofdiverse applications and platforms and underlying root causes.
large scale error reporting systems e.g.
windows error reporting wer commonlyrelyonmanuallydevelopedrulesandheuristicstolocalizeblamed frames causing the crashes.
as new applications and features are routinely introduced and existing applications are run undernewenvironments developingnewrulesandmaintaining existing ones become extremely challenging.
weproposeadata drivensolutiontoaddresstheproblem.we start with the first large scale empirical study of kcrashes and their blamed methods reported to wer by tens of thousands of applicationsrunninginthefield.theanalysisprovidesvaluableinsights on where and how the crashes happen and what methods to blame for the crashes.
these insights enable us to develop deepanalyze a novel multi task sequence labeling approach for identifyingblamedframesinstacktraces.weevaluateourmodelwith overamillionreal worldcrashesfromfourpopularmicrosoftapplicationsandshowthatdeepanalyze trainedwithcrashesfrom one set of applications not only accurately localizes crashes of the sameapplications butalsobootstrapcrashlocalizationforother applications with zero to very little additional training data.
acm reference format manish shetty chetan bansal suman nath sean bowles henry wang ozgur arman and siamak ahari.
.
deepanalyze learning to localize crashesatscale.in 44thinternationalconferenceonsoftwareengineering icse may pittsburgh pa usa.
acm new york ny usa pages.
introduction when software crashes in the wild often the primary sources of information available for debugging are crash stacks stack traces permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation onthe firstpage.copyrights forcomponentsof thisworkowned byothersthan the author s mustbehonored.abstractingwithcreditispermitted.tocopyotherwise or republish topostonserversortoredistributetolists requirespriorspecificpermission and or a fee.
request permissions from permissions acm.org.
icse may pittsburgh pa usa copyright held by the owner author s .
publication rights licensed to acm.
acm isbn ... .
.acrashstackcontainswhatmethods were executing during a crash.
it may also contain other valuable information such as executed binaries and code locations that can hint as to what might have caused the crash.
due to its importance manyerrorreportingsystems e.g.
windowserrorreporting wer apple crash reporter mozilla crash reporter chrome crash reporter have been deployed to automatethe collectionof crashstacks alongwith otherinformation suchasmemorydumps .animportantstepininvestigatinga crashiscrashlocalization identifyingthemethodinthecrashstack that contains or is the closest to 1the crash location.
we denote such a method as the blamed method and the stack frame containing it as the blamed frame.
blamed methods play an important role inorganizingcrashreportsinto buckets i.e.
categories whichin turn help developers prioritize frequently seen buckets .
moreover investigation of a crash often starts from the blamed method as it helps developers isolate the crash location.
crash localization needs to be automated in large scale error reporting systems such as wer as they receive millions of crash reports per day .
a common practice is to use a collectionofmanuallywrittenheuristicssuchas nevermark foo asa blamedmethod bar canbeablamedmethodonlyifthesymbol bazappearsinthecrashstack andsoon.thesystemthenscans through the frames of a crash stack to identify a blamed method that is consistent with these rules.
ideally the rules should be consistent i.e.
notcontradictory witheachother andhavegoodaccu racyandcoverage.thisisnontrivialforlargeandevolvingsystems whenanewfeatureorapplicationisintroduced someonewithgood domainknowledgeneedstowritenewapplication specificrules.
wer currently has such application specific libraries of rules.
prior work in crash analysis has heavily focused on crash bucketization .
but in order to do effective bucketization crash localization is critical.
wu et al.
proposed crashlocator which leverages source code along with the static call graph forcrashlocalization.however thisisnotfeasibleatthescaleof wer that needs to localize crashesfor a multitude of applications inthewild.thispaperaddressestheselimitationswithafreshdatadriven approach.
inspired by the abundance of data in existing error reporting systems and recent advancement in deep learning techniques wedemonstratehowtolearnfrompastcrashestoidentify the blamed method in a new crash stack with high accuracy.
1when a stack trace does not contain the true crash location we consider identifying the method closest to the crash location in caller callee relationship.
ieee acm 44th international conference on software engineering icse authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
icse may pittsburgh pa usa manish shetty chetan bansal suman nath sean bowles henry wang ozgur arman and siamak ahari 7msedge elf.dll!crash reporter dumpwithoutcrashing msedge.dll!base debug dumpwithoutcrashing msedge.dll!gl directcompositionchildsurfacewin releasedrawtexture msedge.dll!gl directcompositionchildsurfacewin swapbuffers msedge.dll!gl directcompositionchildsurfacewin swapbuffers msedge.dll!gl glsurfaceadapter postsubbuffer msedge.dll!gpu passthroughimagetransportsurface postsubbuffer ... a crash stack 7igd10iumd64.dll!openadapter10 2 d3d11.dll!ndxgi cdevice rotateresourceidentities dxgi.dll!cdxgiswapchain presentimplcore dxgi.dll!cdxgiswapchain presentimpl dxgi.dll!cdxgiswapchain present1 msedge.dll!gl directcompositionchildsurfacewin releasedrawtexture msedge.dll!gl directcompositionchildsurfacewin swapbuffers ... b crash stack figure examples of crash stacks from microsoft edge and their crash locations red frame as a first step towards our data driven approach we analyze 362kcrash stacks collected by wer from .7ksoftware components.
our analysis highlights the huge diversity of crash stacks theycomefrommanydifferentfirstandthirdpartybinaries and from many different methods and namespaces within each binary.
the underlying problem classes which denote high level root cause typessuchasheapcorruptionorstackoverflow arealsodiverse.
finally a crash trace often contains many methods only one of whichneedstobeidentifiedastheblamedmethod.alloftheabove highlightthechallengesofmanuallydevelopingandmaintaining application specific crash localization heuristics.
ouranalysisalsoprovidesseveralinsightsthatguideourchoice of an effective machine learning solution.
we first tried a linear binary classifier logistic regression that given features of an individualframe predictsthelikelihoodofitbeingtheblamedframe.
asweshowinsection5.
thissimplemodel however didnotwork wellformanyproblemclasses.uponfurtheranalysisofourdataset wefoundthat thecontextinwhichamethodappearsinacrashstack e.g.
methods that appear before and after it plays an important role in it being a blamed method or not.
consequently a method can be the blamed method in one crash stack but not in another.
this is illustrated with two crash traces from microsoft edge shown in figure1.boththetracescontainedge smethod releasedrawtexture butweridentifiesitastheblamedmethodonlyforthefirsttrace.inthefirsttrace methodsaround releasedrawtexture arerelatively less crash prone based on their past history e.g.
the logging methodsabove it .inthesecond trace however releasedrawtexture hasmorecrash pronemethodsfromausermodeintelgraphicsdriver one of which is blamed by wer.
we use this insight on the importance of context in a novel formulation of crash localization as sequence labeling.
sequence labeling widelyusedinnaturallanguageprocessing usescontexttoassignacategoricallabel e.g.
partsofspeech toeachmemberofasequence.inourformulation wetreatacrashstackasasequenceofframesandaimtoassigntoeachframeabinarycategoryindicating whetheritisablamedframeornot.but applyingsequencelabeling to crash localization requires addressing several challenges.
first like many other machine learning tasks we need to select agoodsetoffeaturesandasuitablemodelthatcancapturecontext.
here we revisit our data analysis to seek insights.
our analysis shows that even though a stack trace may contain many methods only a small number of them are likely to be a crash location e.g.
methods that appear towards the top of the stack have global semanticimportance andthatareimplementedinapplicationcode ratherthantheunderlyingsystem.wethereforeextractfeatures figure an overview of wer that summarize these properties of a stack frame.
we also observe thatcontextforaframedependsonthecallchainthroughwhich itisinvoked.wecapturethissequentialcontextflowinthestack usingabi directionallongshort termmemory bi lstm layer that interprets the stack both top down and bottom up.
second traditional sequence labeling may label multiple tokens withthesamecategory.inourcontext however onlyoneframe in a stack trace can be blamed.
to address this we first use an attentionmechanism toidentifysectionsofastacktracethat aremorelikelytocontainthecrashlocation.then wemodelthe frame level labeling task jointly using linear chain conditionalrandom fields crf .
finally to tackle constantly evolving software itisimportantthatmodelslearnedfromcrashesinone setof applications areusefulnotonly forthose butalso forother applications e.g.
newly released ones that have very little training data.
we propose a transfer learning approach to achieve this goal.
in this work we present and package our models in a system calleddeepanalyze a deep learning based solution for largescalecrashlocalization.wehaveevaluateddeepanalyzewithover amillionreal worldcrashstacksfromfourpopularmicrosoftapplications edge word excel and outlook .
our results show that deepanalyze snovelmulti tasksequencelabelingapproachhasan average accuracy of .
and it outperforms several baselines.
also we show that using transfer learning our model learned from one set of applications can also be effectively .
accuracy used for completelynewandunseenapplicationswithnonewtrainingdata.
lastly we show that these models can be easily fine tuned to new applications where the accuracy quickly approaches .
with as little as a few thousands additional training samples.
in summary we make the following contributions weconductthefirstlarge scaleempiricalstudyofcrashes in the wild and discuss new insights about crash sources problem types and characteristics of their blamed methods.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
deepanalyze learning to localize crashes at scale icse may pittsburgh pa usa a top crashing binaries b top software component types figure distribution of crashing binaries and software components weproposedeepanalyze anovelmulti tasklearningbased approach for crash localization only using stack traces.
we evaluate deepanalyze on popular windows applicationsshowingthatithasanaverageaccuracyof0.9andoutperforms several baselines.
weleveragetransferlearninganddemonstratethatwitha smallamountofdata wecanlocalizecrashesfornew unseen applications with high accuracy.
background .
windows error reporting releasedsoftwareoftencontainsbugsthatcausethesoftwareto crashinthefield.toautomatecollectingcrashinformation large software companies deploy error reporting systems.
for example microsofthasbuiltadistributederror reportingsystemcalledwindows error reporting wer which has been in operation forovertwodecadesnow.whenamicrosoftsoftware suchaswindows word andedge crashesinthefield withuserpermission itsendstowera crashreport.acrashreportcontainscrashstacks informationofthecrashedapplicationanditsruntime andoptionally a memory dump collected during the crash figure .
so far wer hascollectedtensofbillionsofcrashreportsfrombillionsofdevices.
akeyfunctionalityofweristoassign bucketstothecrashes sothatsimilarbugscande duplicatedandtriagedtogether.once thenumberofcrashesinabuckethasexceededacertainthreshold a bug report is created and it is triaged to the appropriate developerusingthebucketmetadata.abucketisbasicallyasignature to identify a unique bug.
here is an example of a bucket memory corruption c0000005 contoso.exe!writetochild .
it contains the problem class exception code and the blamed frame which caused the crash.
the bucket is computed by analyzing a crash report as described next.
.
crash localization in wer in order to analyze a crash report wer uses !analyze a debugger extension which uses the call stack from the crash dump alongwithmetadatasuchasloadedmodules memorydumpand exceptioncodetoidentifyblamedframeandtheunderlyingproblem class that caused the crash e.g.
out of memory stack overflow .
!analyze has been built and maintained for more than two decades usingover200 000linesofcodeandhundredsofheuristics written by domain experts.
!analyze also provides an extensibility mechanism that both microsoft and external developers useto build plug ins for extending or overriding the default logic with application specific rules.
!analyze currently has such extensions.
the extensions can be nontrivial.
for example the extension for edge consists of over 2k loc!
!analyze sourcecodehasbeenthroughmanyyearsofimprovement and updates for analyzing different error codes and buckets.
tounderstandthepainpointsof !analyze wetalkedtoseveralapplication owners.
at present the rules for crash report analysis are required to be written into the code.
this results in huge deployment overheads for instance updating or deploying new rules can rangeanywherebetweenonetothreemonths.further therules often tend to be very specific and need to be updated as the applicationcodebaseevolves.fornewapplications theapplication ownerand !analyze developersneedtoworktogethertoimplementthelogicofthenewrulesintothecodebase.also bringing up a new application is usually time consuming and requires deep domainknowledgeof !analyze codebase.withdeepanalyze our goalistoeliminateorsignificantlysimplifythislaboriousandtime consuming process with an agile and fast data driven solution.
table basic statistics of the dataset used in our study of crash stacks 362k of unique software components .7k of unique binaries .3k of unique namespaces 38k of unique methods 85k of unique blamed methods 18k empirical analysis of crashes in this section we analyze a large collection of crashes collectedby wer to understand various properties of crash stacks.
our datasetcontains362 249uniquecrashstacks uniformlysampled fromcrashescollectedbywerina1w eekp eriod.wealsostudy properties of their problem classes and blamed frames methods as determined by !analyze with its manually written heuristics.
.
crash sources wer collects crash stacks from thousands of applications developed by both microsoft and non microsoft developers.
our sampledatasetcontainscrashstacksfrom .3kbinariesof .7k softwarecomponents2 includingpopularmicrosoftapplications 2we use the term software component to denote various types of software systems including user mode applications os or infrastructure systems libraries drivers etc.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
icse may pittsburgh pa usa manish shetty chetan bansal suman nath sean bowles henry wang ozgur arman and siamak ahari a stack depth b distinct binaries per stack c avg stack depth for top software components figure properties of crash stacks suchasexcel word outlook edge etc.thecrashstacksinclude 85kunique methods from 38kunique namespaces.
table summaries the statistics.
figure3showsdistributionsoftopbinariesandsoftwarecomponents where crashes occur.
the distribution has a long tail with most applications contributing a small fraction of crash stacks.
as shown in figure a there are only binaries in our dataset each of which accounts for .
and the top binary accounts for of the total crashes.
we also analyzed the types of top software components in terms of their crash frequencies.
as showninfigure3 b ofthemareuser modeapplications e.g.
microsoft excel or underlying systems e.g.
windows desktop windowmanager dwm withtheremaining25 beingdrivers libraries and services.
this shows that in a large scale error reportingsystemlikewer crashstackscomefrommanydifferent sources.
hence application specific mechanisms to identify blame frames do not scale well.
finding crash stacks come from many different sources and hence application specific crash localization does not scale well.
.
crash stacks stackdepth.
stackdepth i.e.
numberofframesinthestack atthe timeofacrashindicateshowdeepthecrashhappens intermsof nestedmethodcalls.figure4 a showsthedistributionofthedepths i.e.
number of frames of all crash stacks in our dataset.
mean and mediandepthsare16and9respectively.whilemajorityhavefewer than frames some stacks are very deep maximum frames .
framesinastackmaycontainmethodsfrommultiplebinaries when one binary calls methods from another.
figure b shows thedistributionofdistinctbinariesappearinginastack average .
multiple binaries in a stack indicate that crashes can happen in binaries outside of the entry binary of an application.
stack depthand softwaretypes.
stack depth varies a lot across software components and their types.
for example we find that device drivers usually have smaller stack depth average than applications average and systems average .
this is most likely because compared to applications systems drivers are lesscomplexintermsofthenumberofdependencies andhence tend to make fewer nested method calls.
figure c shows theaverage stack depths of most frequent software components.the average depths differs significantly from to across these software components.
finding stack depthssignificantly differ across software components and their types.
.
problem classes and blamed frames problem classes.
figure 5a shows top classes of problems that causethecrashes.weobtainproblemclassesfrom !analyze which uses several heuristics to identify them from the exception context stacktraces andotherinformationinthecrashdump.asshown most ofthe key problemclasses are memoryrelated for instance whentheapplicationistryingtoreadapointerthatpointstoinvalid memory invalid pointer read or is trying to read a pointer that is null null pointer read .
these memoryrelated classes account for of all crashes.
another major problem category is application fault which is the default class when no more specific class could be identified.
finding most of the crashes are caused by memory related errors.
blamed frame location.
figure 5b shows the distribution of normalized location of a blamed frame in its crash stack.
locations are normalizedsothatthetopframeandthebottomframeinastack have locations and respectively.
as shown frames at the top of stacks are more likely to be blamed.
more specifically the topmost frameisindeedtheblamedframein67 crashstacks.intheremaining cases however blamed frame is not the top frame.
an example is shown in figure a where the third frame is the blamed frame andtoptwoframescorrespondtoharmlessloggingmethods.
also in cases blamed frame is at the bottom half of the stack.
finding blamed frames are more likely to be locatedatthetop ofthestack.in33 cases however blamed frame is below the top frame.
contextdependence.
canamethod onceidentifiedastheblamed method in a crash stack always be blamed in other crash stacks?
if yes one could easily identify the blamed method in a new crash stackbymatchingitsmethodswithalistofknownblamedmethods blame list .
does this simple blame list based approach work?
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
deepanalyze learning to localize crashes at scale icse may pittsburgh pa usa a top problem classes in crashes b normalized crash location c distribution of blame ratio figure properties of problem classes and blame frames to answer this we compute blame ratio of methods.
the blame ratio of a method is the ratio of the number of crash stacks where the method is the blamed method to the number of crash stacks containingthemethod.figure5cshowsthedistributionofblame ratioinourdataset.whilealargefractionofmethodshaveablame ratioof1 asignificantfractionofmethodshaveblameratiosless than1.aratiolessthan1meansthatablamedmethodinonestack maynotalwaysbeblamedinothercrashstacks andhenceablamelist based approach would not work for these methods.
whydosomemethodshaveblameratioslessthan1?acloserexaminationrevealsthatwhetheramethodisindeedablamedmethod oftendependsonits context methodsthatappearinframesabove andbelowit.let sconsidertheexampleinfigure1again.here the method releasedrawtexture isidentifiedastheblamedmethod inthefirstexamplewhereitappearsbelowtworelatively harmlessloggingmethods.ontheotherhand thesamemethodisnotblamed in the second example where more crash prone driver methods appearaboveit.theblamedframe sdependenceoncontextcanbeex plainedbythefactthatframesinastackarenotindependent rather they are ordered based on the caller callee relationship of methods intheframes.thedatasuggeststhatwhetheramethodisblamedornotdependsonthecallchainthroughwhichitisinvoked.
finding whether a method is blamed or not oftendependsonthecontextitappearsin i.e.
methods that appear above and below it in the stack.
our approach in this section we use the insights from section to design a datadriven solution to the large scale crash localization problem.
our goal is to utilize large scale historical crash data consisting ofcrashstacksandtheirlabelledblamedframes tolearnmodels that given a new crash stack can identify its blamed frame and method .ourfirstattemptwastolearnalinearbinaryclassifier e.g.
logistic regression that given various features of an individual frame predictsthelikelihoodofitbeingtheblamedframe.aswe show in section .
this simple model however did not work well for many problem classes.
this is explained by one of our findings insection3 thecontextinwhichamethodappearsinacrashstack e.g.
methodsthatappearbeforeandafterit playsanimportantrole forittobeacrashmethodornot.wethereforeaimtobuildmodelsnatural language processing crash dump analysis sentence a sequence of words stack a sequence of frames johnlivesinseattle f0f1f2f3 sequence labeling crash localization john perlives oin oseattle locf0 !bff1 !bff2 bff3 !bf figure analogy between nlp and crash dump analysis and features thatcan effectively capture suchcontext.
we achieve this with a novel solution that formulates the crash localization task as a sequence labeling task as described next.
.
crash localization as sequence labeling sequencelabeling wellexploredinnaturallanguageprocessing nlp involves assigning a categorical label to each memberofa sequenceofobservedvalues.
forexample named entity recognition a sequence labeling task can locate and label entities in a sentence as predefined categories.
it treats a sentenceasasequenceofwordsandconsiderscontext i.e.
surrounding words ofeachwordtoidentifyitscategory.forexample infigure6 thenamedentity johnisidentifiedasa personandseattlealocation.
to formulate crash localization as sequence labelling we consideracrashstackasasequenceofframes analogoustoasentenceanditsconstituentwords.wethenperformsequencelabellingwith abinarycategorylabel blameframe and!blameframe.thus the problemisformulatedasfollows givenacrashstack i.e.
asequence of frames label each frame with whether it is a blame frame or not.
for example in figure the third frame f2 is identified as the blameframe bf while the rest are labeled !blameframe !bf .
for traditionalsequencelabeling onecanuseexistingmodelsthathave been proposed previously.
however applying them to crash localization requires addressing some unique challenges.
whatfeaturestouse?
toaccuratelysummarizeacrashstack featuresneedtocapturebothsemanticsanddomain specificinformation.so wemakeuseoftf idf basedfeatures aswellasfeatureshighlightedbyourempiricalstudy suchas frame depth that are strongly correlated to crash locations.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
icse may pittsburgh pa usa manish shetty chetan bansal suman nath sean bowles henry wang ozgur arman and siamak ahari table features to represent stack frames for crash localization feature group feature name description semantics namespace ndimensional tf idf vector of the namespace method ndimensional tf idf vector of the method t y pe so fc od e is appname in frame does the frame contain the application s name?
is first app frame is it the 1stframe with the application s name?
is kernel code does the frame contain kernel code?
is ntdll code does the frame contain ntdllcode?
is exception in frame does the frame contain an exception?
other norm frame position normalized position of the frame is method unknown is the method unknown?
is method empty is the method empty?
is binary unknown is the binary unknown?
is empty frame is the entire frame empty?
how to blame exactly one frame?
in traditional sequence labeling itispossibleformultipletokenstobelabeledasthe samecategory e.g.
sentencewithmultipleplaces.inacrash stack however there is only one blame frame and hence we need appropriate models that satisfy such constraints.
intherestofthesection wedescribethedesignandarchitecture of our deepanalyze model that addresses these challenges.
.
model features guidedbydomainexpertiseandourempiricalstudy weengineered featuresshownintable2 fordata drivenmodels.thesefeatures transform individual frames in the crash stack into real valued vectorsthatcanbeusedbyourmodels.thefeaturesaregeneric they apply to crashes across applications and can be grouped into the broad types briefly described below semantics thesefeaturesrepresenttheimportantcontentsofa frame such as the namespace and method name.
here we observe thattoolssuchas !analyze utilizealargelistofallow listsand heuristics to localize crashes deeper in the stack.
such approaches do not consider the global semantics andrelevance of the function in a frame i.e.
how a function contributes to the crash.
to include these semantics we utilize a simple term frequency inverse document frequency tf idf vectorization method .
with thisapproachweautomaticallyextractaweightedlistofimportant tokens from namespaces and methods in frames.
t y p e so fc o d e code from applications stand 3rdparty are more likely to have bugs and cause crashes when compared to to kernel code and core os user mode code .
to incorporate suchinformation weusefeaturesthatcheckthepresenceoftheapplication s name in the frame i.e.
the binary name .
we also extractfeaturesthatrepresentkernelcode coreosmodules and exceptions.
these features can help models de prioritize frames that are less likely to contain the root cause for crashes.
other information asshowninsection3 framesatthetopof stacks aremore likely to beblamed.we thusutilize the normalized framepositiontomodelhowdeepinthestackthecrashlocation can be.
also at times frames can be incomplete or have missing symbolsinscenariossuchassome3 rdpartysoftware andlinuxoscomponents or standard libraries.
to de prioritize such frames we use multiple boolean features that check for unknown and missing information in the frame.
by transforming frames using the features described in table a stack can now be visualized as a sequence of featurized frames.
.
deepanalyze model in the following subsections we describe components of our multitask model as shown in figure in detail.
.
.1model overview .as our empirical analysis in section shows whetherastackframeisblamedornotoftendependsonits context framesaboveandbelowit.hence whilemodeling we needtoconsidercontextflowinginbothdirectionsinthestack top downandbottom up.forthis weutilizeabi directionallstm bi lstm that interprets the stack both forwards and in reverse.
while the bilstm can model sequential context flow dependenciesbetweenframescanbewidelydistributedinthestack.also asshowninsection3 weobservethatstackscanbeverylong and bilstms can sometimes fail to handle long range dependencies .
to overcome these challenges we implement an attention mechanism.
itfavours themodel toattend tosections ofthe stack more likely to have the crash location.
with a bi lstm and attention layer deepanalyze encodes frames and stacks into robust neural representations that can be usedtolocalizecrashes.here weseethatunlikesequencelabeling for natural language there is a constraint where we can only label a single frame in the stack as the blame frame.
to learn such structural constraints we usea conditional randomfields crf layer.
it is a discriminative classifier that models decision boundaries between labels in a sequence.
lastly contextforcrashlocalizationcanalso be externalinformationthatcomplements thestack.specifically symptoms problem classes associated with a crash such as invalid pointers zero division and heap corruption .forinstance iftheproblemwasa stack overflow causedbytailrecursion thenthestack wouldcontainarepeatingsequenceofframes.inthiscase thecrash canbequicklylocalizedbyattendingtotherepeatingpattern.based authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
deepanalyze learning to localize crashes at scale icse may pittsburgh pa usa figure deepanalyze multi task model architecture ontheseinsights weutilizemulti tasklearningtoperform problem class prediction alongside the primary task blame frame prediction.
.
.2bi directional lstm .long short term memory lstm networks areatypeofrecurrentneuralnetworks rnns that have been widely used to process sequential data in a variety of taskssuchaslanguagemodelling speechprocessing and codecomment generation .
ittakes asequence of inputs x1 x2 ... xn as and return a sequence of vectors h1 h2 ... hn that encodes information at every time step i.e.
frame level here .
in our scenario a frame f receives context from other frames thatoccuroneithersides.weachievethisrepresentationusinga secondlstmlayerinterpretingthesequenceinreverse i.e.
abidirectionallstm bi lstm .finally eachframeisrepresented by concatenating its left and right context hf .
.
.3attention mechanism .attentionmechanism has becomeakey componentofstate of the artsolutionsto quantify distributeddependenciesinsequences.ithasbeenusedfortasks like machinetranslation sentiment classification parsing and even image classification .
here we implement attention mechanism at the frame level with a learnable parameter wa as described in equations .
it takes as input the hidden states h from the bi lstm and generates a weighted context vector h of the stack.
this weighting mechanism urges themodeltofocusonsectionsofthestackthataremorelikelyto have the crash location.
scores wt ah softmax scores h tanh h t .
.4conditional random fields .the above discussed layers encode stack information into neural representations.
next we move on to labeling the crash location.
here we could simply predictlabelsindependentlyforeachframe.butweobservethatthis disregards some structural constraints in our problem.
specifically unliketraditionalsequencelabeling wecanonlylabeloneframe as the crash location.
to enforce such restrictions we model the frame level labeling task jointly using linear chain conditional random fields crf .
given an input sequence x the crf layer computes the probability of observing an output label sequence y i.e.
p y x s x y n summationdisplay.
i 0ayi yi n summationdisplay.
i 0pi y i p y x es x y summationtext.
y prime yes x y prime here pis a probability matrix of shape n kfrom the attention layer where kis the number of distinct tags and nis the sequence length.arepresentsthematrixofscoresfortransitionsbetween outputlabels.finally toextractlabels thelayerpredictstheoutput sequencewiththehighestprobability y argmaxy prime yp y prime x .
withthisapproachthemodellearnstoincludestructuralvalidity in predicted output sequences.
.
.5multi tasklearning .multi tasklearning mtl isanapproach to improve generalization in models using the inductive bias in jointly learning related tasks .
in the context of classification and sequence labeling mtl improves performance of individual tasks by learning multiple tasks simultaneously .
in our scenario the primary task for deepanalyze is crash localization.
as stated before we observe that localizing crashes not only depends on the frames but also on the class of problems that mighthavecausedthecrash.forinstance acrashcausedduetoan invalidpointer wouldgenerallybelocalizedtothestackframes particularly as shown in figure we utilize a multi head architecture toshare low level features bilstmlayer .
then thearchitecture splits into task specific branches one for blame frame prediction and the other for problem class prediction.
for both tasks we use categorical cross entropy as the loss function.wefirstcalculatelossindividuallyforbothobjectives say l1 andl2.
we then compute and minimize a combined loss by averaging lossc l1 l2 .
during training the objective we minimizeisthecombined lossc.but duringback propagation wemake suretouse theindividualtasklosses l1andl2 toupdateweights oftask specificbranchesofthenetwork figure7 .withsuchan approach thesharedlayer bilstm istrainedbybothtasks becauseboth l1andl2updateitviaback propagation.whereasthe taskspecificlayers attentionandcrf aretrainedonlyontheir respective individual loss functions.
authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
icse may pittsburgh pa usa manish shetty chetan bansal suman nath sean bowles henry wang ozgur arman and siamak ahari .
cross application crash localization as stated in section hardcoding heuristics into code creates challengeswithscaleandgeneralizability forunknownfuturescenarios.softwareconstantlyevolvesasnewapplications apis andprogramminglanguagesareintroducedandbecomepopular.handling crashesinsuchnewcasesusuallyrequiresalotoftimeanddeep domainknowledgetowritecustomrulesandpluginsforexisting solutions.here learningamodelinstead canhelpaddressthescalability and generalizability challenges with ever growing software.
but even with supervised machine learning for a new application itisnontrivialtodevelopaccuratecrashlocalizationmodels astherewouldbeminimallabeledtrainingdata.however in crashes webelievethattherearemanypatternstobelearntthat are common across applications especially the large portion of frames that represent the underlying system see figure b .
this implies that models trained on crashes from a global set of applications source canbeusedtolocalizecrashesforanewanddisjoint set target cross application crash localization.
in this work we use this to overcome the above mentioned challenges with a transferlearning andfine tuning approach.
formally followingpanandyang transferlearninginvolves the concepts of a domain and a task.
a domain dconsists of parts a feature space xand a marginal probability distribution p x wherex x1 ... xn x. given a specific domain d x p x a taskthas components a label space yand an objective f i.e.
t y f thatcanbelearnedfromtraining data.
given this transfer learning is defined as transfer learning given a source domain dsand learning task ts target domain dtand learning task tt transfer learning aims toimprovethelearningofthetargetpredictivefunction ft indt using the knowledge in dsandts whereds dt o rts tt.
inourscenario weobserve ds dt wheredsistheglobal set of application crashes and the target dtis a new unseen application scrashes.specifically weseethatthefeaturespace x ofthesourceandtargetaresame whilethemarginalprobability distributions p x are different.
this case is generally known as domain adaptation .
withthat inmind for cross application crashlocalization wefirstpre trainadeepanalyzemodelonalarge datasetofcrashesspanningmultipleapplications globalmodel .
this model learns general and common information about crashes.
then foranewapplicationscenario weusetransferlearningto adapttheweightsofthisglobalmodeltotheapplicationofinterest withminimal labeled data.in section5 wetest ourhypothesis and extensively evaluate this approach.
evaluation implementation.
we have implemented deepanalyze and all othermachinelearningmodelsdiscussedinthisworkinpython .
.
withkeras .
.4andthetensorflow .
.0backend.thesemanticvectorizersareimplementedusingthestandardtf idfvectorizer in scikit learn.
for our bi lstm crf based models the length of the sequence is limited to a maximum of as collected bywer.also thehiddenlayersizeissetto200cellsalongwith adropoutof25 topreventoverfittingbyignoringrandomlyselectedneuronsduringtraining.further weuseanearlystoppingtable evaluation of app specific model accuracy model application avg edge excel word outlook topframe .
.
.
.
.
secondframe .
.
.
.
.
mostfreqtopframe .
.
.
.
.
logistic regression .
.
.
.
.77bilstm crf attn .
.
.
.
.85deepanalyze .
.
.
.
.
mechanism to stop training when model performance on a validationdatasetstartsto degrade.lastly ourmodels aretrainedon an ubuntu .
lts machine with core intel xeon e5 v3 cpu .60ghz gb memory and bit operating system.
the machine also has a nvidia tesla p100 gpu with gb ram.
wenextconsidertwosettingsandevaluatethe accuracyofdeepanalyze thefractionoftestcrashstacksforwhichdeepanalyze correctly identifies the blame frame.
.
application specific evaluation we first consider an application specific setting where the training andtestdatacomefromthesameapplications.thismakessense when the target application has sufficient labelled training data.
setup.we here use crash stacks from popular client applications frommicrosoft edge excel word andoutlook.toevaluateina realisticsetup wetrainandtestourmodelsatdifferentpointsin time.webeginbycollectingasampleof .2millionusermode crashesoftheseapplicationsoverawindowof2weeks.foreach application weutilizedatafromthefirst11daysfortrainingand next3daysfortesting .also weuseacombined hashofthestack blamedframe andothermetadatatode duplicate our datasets avoiding multiple evaluations of the same problem.
lastly we establish ground truth using !analyze as used by wer.
we compare our multi task model described in section .
againstmultipleheuristicsandmachinelearningbaselines.intable wereporttheaccuracy ratioof correctlylocalizedcrashesto total crashes and evaluate models on different applications.
heuristic baselines.
first we have a topframe baseline that alwayspicks the1stframein thestack.
thisisbased onthe insight thatalargeproportionofcrashlocationsareatthetopofthestack.
but we also observed that in some cases the top frame is an exception raised by the method below it.
we represent this using oursecondframe baselinethatalwayspicksthe2ndframe.next with mostfreqtopframe weintroducetheuseoffrequentpatterns.
thisbaselinepickstheframethatwasmostfrequentlyblamedin the past.
in caseof ties or unseen frames it favours frames higher inthestack.fromtable3 weseethattheseheuristicapproaches perform well only on certain crashes and do not generalize well.
linear model.
next we havealogisticregression baseline.itis linearbinaryclassifierthat givenfeaturesofanindividualframe described in section .
predicts the likelihood of it being the blame frame.
then we pick the frame in the stack with maximum authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
deepanalyze learning to localize crashes at scale icse may pittsburgh pa usa figure logistic regression lr vs deepanalyze da likelihood.asseenintable3 thissimpledata drivenmodelperforms better than naive heuristics .
avg accuracy .
but on furtheranalysis wefoundthatthismodelperformspoorlyforspecific problemclasses.forinstance infigure8 weseethatfor cppexception and stack overflow it correctly predicts only of cases.
here we observed that such problems have diverse crashes where amethodcanbeblamedinonecrashstackbutnotinanother.that is the logistic regression approach lacks in capturing context.
sequence labeling.
lastly weevaluatemodelsthatincorporate the missing context using our novel sequence labeling formulation bilstm crf attn and deepanalyze.
here we use bilstmcrf with attention mechanism as a baseline as it is a state of theart model for sequence labeling in nlp .
also note that this bilstm crf attn model is similar to the deepanalyze model architecture but without multi task learning.
as shown in table it achieves an average accuracy of around .
.
whereas our deepanalyzemulti taskmodel describedinsection4.
achievesahigheraverageaccuracyof0.90andbeatsallbaselinesacrossappli cations.italsoreachesamaximumaccuracyof0.94forexcel.with deepanalyze combining context information and complementary informationusingmulti tasklearning weareabletooutperform strongbaselinessuchaslogisticregressionandbilstm crf attn.
also though in figure we mention only some problem classes we find that deepanalyze is always better than logistic regression.
table significance of improvements improvement areaapplication avg edge excel word outlook semantics context multi task improvements.
table shows the significance of important aspectsofourapproach namelyframesemantics contextdependence andmulti tasklearning.wecomputesignificancebycalculatingthepercentagedifferenceinaccuracy a ofpairsofmodels i.e.
am1 am2 avg am1 am2 .
to capture significance of semantics we compare logistic regression that uses semantic features with the naive topframe baseline.
as shown introducing frame features semantics generatesconsiderableimprovementsacrossappli cations average13 .next weevaluatethevalueof context.here table feature importances ve feature imp ve feature imp method memory .0namespace std .
namespace file0.73method error .
method thread .49method exception .
wecomparedeepanalyze acontext awareapproach tologistic regression.
the boosts achieved with our approach highlightstheimportanceofcontextincrashlocalization.also incorporatingcontextprovidesthelargestgainsonaverage .lastly deepanalyze leverages both context and complementary information using multi task learning.
thus by comparing the multi task deepanalyzemodelwithbilstm crf attn weseethatmulti task learning also provides notable increases in accuracy average .
whatdoesdeepanalyzelearn?
togaininsightintowhatdeepanalyzelearns weuseamodelweightinspectiontechnique.itis commonly used to interpret black box models in image processing and medical domains .
here we extract the weights of the1stlayerofdeepanalyze wherethereisadirectinteractionon the raw inputs to generate normalized feature importances.
table summarizes the top positive and negative features all of which aretf idfsemanticfeatures.asshown deepanalyzeintelligently learns that methods performing memory file and thread operationsarepositivefeaturesastheyworkwithpointersandtendto causecrashes.thisissupportedbyourempiricalanalysisinsection3onfrequentproblemclasses.ontheotherhand deepanalyzealsolearnstonegativelyassociatestandardlibraries namespace std and methods that raise errors exception with crash locations supporting our observation in figure b that crashes are relatively less frequent in libraries.
.
cross application evaluation we now evaluate deepanalyze in a cross application setting where we have a recent new application with minimal labeled crashes.
forthis weattempttoevaluatetheefficacyofourtransferlearning approachforcross applicationcrashlocalization section4.
.to summarize wehypothesisthatmodelslearntfromcrashesofasetof applications can localize crashes in new unseen applications.
here we evaluate our hypothesis on target applications edge excel.
setup.we start with the dataset used in section consisting of 362kcrashstacksfrommanysoftwarecomponents sampledovera periodof1week.tosimulateacross applicationsetting wechoose a target application and remove all its associated crashes from our dataset.then wetrainadeepanalyzemodel globalmodel ontheresultantdatasetandtestoncrashesofthetarget domaintransfer .further wefine tuneourglobalmodeltothetargetapplicationwith minimal labeled crashes.
similar to the application specific evaluation in section .
for each target application we utilize uniformly sampled data from the first days for fine tuning and next days fortesting.toevaluate wecomparethistransferlearningapproach against an application specific deepanalyze model local model .
figure9showtheresultsofourexperimentsfor2targetapplications edge left and excel right .
the fine tune global blue line indicates the accuracy of our global model on fine tuning i.e.
our transfer learning approach .
the from scratch local red authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
icse may pittsburgh pa usa manish shetty chetan bansal suman nath sean bowles henry wang ozgur arman and siamak ahari .
.
.
.
.
.
.
training samplestest accuracy fine tune global from scratch local .
.
.
.
.
.
.
training samplestest accuracy fine tune global from scratch local figure fine tuning vs training from scratch for edge left and excel right line indicates the accuracy of an application specific model trained fromscratch.thex axishasthenumberofsamplesusedforfinetuning the global and training the local model respectively.
accuracy.
as seen for both edge and excel our transfer learning approach significantly outperforms a local model trained from scratch at all amounts of training data.
this is mainly because a globalmodelreceivesasignificantheadstartbylearningsignalsand patterns in crashes that are application agnostic and hence transferable.specifically weobservethatourglobalmodelachieves high accuracies .
for edge .
for excel without observing a singleapplication specificcrash 0trainingsamples .thisshows thatdeepanalyzecanindeedlearnfromaglobalcrashdatasetto effectivelylocalizecrashesinnew unseenscenarios.also weobservethatourmodelsgraduallyimprovewithminimallabeleddata.
forinstance usingtransferlearning weachieve .90accuracy with as few as samples for both edge and excel.
this encourages that our transfer learning approach can be used in a real wordsetting whereforanewapplicationatfirstwedirectly useaglobalmodel.but overtime wewouldcollectapp specific labeled data and improve our models.
cost savings.
furthermore during our experiments we observed that transfer learning not only reduces training data requirements but also training time compared to application specific models.
to evaluate we make use of our edge and excel models trained on large datasets in section .
.
note these models are comparabletothefine tunedmodelsbecausetheyaretestedonthesamesetof crashes.
these models took on average hours to train andreceived an average accuracy of .
.
on the other hand from figure comparable global models .
acc with samples tookonaverage10minutestobefine tuned.thatis we seenearly18 xreductionintrainingtime andthuscomputecost with a transfer learning approach.
this is particularly encouraging of the usability of such an approach to quickly develop accurate models for newly deployed scenarios.
related work crash analysis.
debugging and triaging of crashes at scale can beexpensiveandintractable.ourworkismostcloselyrelatedto priorworkonlarge scaleanalysisofrealworldsoftwarecrashes.
the windows error reporting wer distributed system was builtbymicrosoftforcollectingandanalyzingcrashtraces.withdeepanalyze weleverageanovelmachinelearningbasedapproachforcrashlocalizationusingthecrashtracescollectedbywerinthe wild.ourapproachnotonlygeneralizeswellforseveralexisting applications but can also extend to new applications with verylimitedamountoflabelleddatausingtransferlearning.wuetal.
proposedcrashlocatorwhichusescallstackinformationin the crash reports along with the static call graph information from thesourcecodetopredicttheblameprobabilityofeachframein the stack.
in deepanalyze since we are crash localizationat scale in the wild we don t have access to the source code.
so we only use the call stacks from the crash traces to do the crash localization.further weleveragerecentadvancesinthemachine learningandnlpdomainforcrashlocalization.crashbucketization is an important part of triaging crash reports.
the wer system leveragesmorethan500heuristicsforbucketing.dangetal.
proposed rebucket which uses crash stack similarity to assignthem to appropriate buckets.
similarly tracesim leverages tf idfandlevenshteindistanceoncrashreportsformeasuring similarityofcrashtracesforbettertriagingandde duplication.our work is complementary to these efforts since more precise crash localization can aid with crash bucketization and triaging.
multi tasklearning.
multi task learning mtl is a wellstudiedtechniqueinthemachinelearningcommunity.mtlisused to improve the generalization and performance of ml models on a given task by jointly training on other related tasks.
mtl has been utilizedinseveraldomainssuchasnlp speech and healthcare .
in the nlp domain collobert et al.
proposed a novel convolutional network architecture which uses mtl to jointly perform several nlp tasks such as pos tagging named entity extraction and measuring semantic similarity.
in the software engineering domain mtl has been leveraged to a limited extent.
prior work has heavily focused on using mtl for building language models for source code and software artifactslikebugreportsanddiscussions .wanget al.
propose mulcode a mtl based approach to learn a unified representation of source code by jointly training on three tasks author attribution comment classification andduplicate function detection.
their evaluation show the efficacy of mtl by outperforming state of the approaches which addressed these tasks separately.tothebestofourknowledge deepanalyzeisthefirsteffort to use mtl in context of debugging.
it leverages mtl to jointly authorized licensed use limited to lahore univ of management sciences.
downloaded on august at utc from ieee xplore.
restrictions apply.
deepanalyze learning to localize crashes at scale icse may pittsburgh pa usa perform crash localization and problem class identification from crash stacks.
based on the experiments on several popular applications mtl significantly boosts the accuracy.
discussion conclusion in this paper we proposed a novel data driven solution to address thecrash localizationproblematscale.wepresentedthefirstlargescale empirical study of kcrashes and their blamed methods reported to wer by many microsoft applications running in the wild.
the analysis provides valuable insights on where and how the crashes happen and what methods to blame for the crashes.
theseinsightsenableustodevelopdeepanalyze anovelmulti task sequencelabelingapproachforidentifyingblamedframesinastack trace.
we evaluate our model with real world crashes from four popular microsoft applications and show that deepanalyze when trained with crashes from one application can not only accurately localize crashes with accuracy of the same application but alsobootstrapcrashlocalizationforotherapplicationswithzero to very little training data.
this makes deepanalyze a practical solution to be used in the wild for a large number of applications.
as next step we are planning to integrate deepanalyze with the wer service along with a feedback loop.
using the feedbackprovided by developers we will train deepanalyze in an onlinelearning setting.
while in this work we tackle the fundamental problemofcrashlocalization systemslikeweraidinvariousother tasks.
for instance they also perform crash bucketization and root cause hypothesis testing.
current solutions for these tasks similar tocrashlocalization aremostlyrulebasedwhichdoesnotscaleand generalizeeasilytonewscenarios.lastly wewillalsobelooking at new problems like inter crash dump correlation when there are multipleosrunningonasingledevice suchasingamingconsoles.
similarly cross platformandcross oscrashlocalizationinadata efficient manner is also critical.
we plan to extend deepanalyze to solve these challenges with the overarching goal of simplifying debugging in the large.