deepdiagnosis automaticallydiagnosingfaults and recommendingactionable fixes in deep learningprograms mohammadwardat wardat iastate.edu dept.
ofcomputerscience iowa state university 226atanasoff hall ames ia usabreno dantascruz bdantasc iastate.edu dept.
ofcomputerscience iowa state university 226atanasoff hall ames ia usa wei le weile iastate.edu dept.
ofcomputerscience iowa state university 226atanasoff hall ames ia usahridesh rajan hridesh iastate.edu dept.
ofcomputerscience iowa state university 226atanasoff hall ames ia usa abstract deep neural networks dnns are used in a wide variety of applications.
h owever as in any software application dnn based appsareafflictedwithbugs.previousworkobservedthatdnnbug f ix patterns are different from traditional bug f ix patterns.
furthermore thosebuggymodelsarenon trivialtodiagnoseand f ixdue to inexplicit errors with several options to f ix them.
to support developers in locating and f ixing bugs we propose deepdiagnosis anovel debuggingapproach thatlocalizesthefaults reportserror symptoms and suggests f ixes for dnn programs.
in the f irst phase our technique monitors a training model periodically checking for eighttypesoferrorconditions.then incaseofproblems itreports messages containingsufficientinformationto performactionable repairstothemodel.intheevaluation wethoroughlyexamine444 models 53real worldfromgithuband stackover f low and391 curatedbyautotrainer.deepdiagnosisprovidessuperioraccuracywhencomparedtoumluatanddeeplocalize.ourtechnique is faster than autotrainer for fault localization.
the results show that our approach can support additional types of models whilestate of the artwasonlyabletohandleclassi f icationones.
our technique was able to report bugs that do not manifest as numericalerrorsduringtraining.also itcanprovideactionableinsights for f ix whereasdeeplocalize can only report faults that lead tonumericalerrorsduringtraining.deepdiagnosismanifeststhe best capabilities of fault detection bug localization and symptoms identi f icationwhencompared to other approaches.
ccsconcepts computingmethodologies neuralnetworks software andits engineering software testinganddebugging .
permissionto makedigital or hard copiesof allorpart ofthis work forpersonal or classroom use is granted without fee provided that copies are not made or distributed forpro f itorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation on the f irst page.
copyrights for components of this work owned by others than acm mustbehonored.abstractingwithcreditispermitted.tocopyotherwise orrepublish topostonserversortoredistributetolists requirespriorspeci f icpermissionand ora fee.request permissions frompermissions acm.org.
icse may21 pittsburgh pa usa 2022association forcomputingmachinery.
acmisbn ... .
deep neural networks fault location debugging program analysis deeplearningbugs acmreference format mohammadwardat brenodantascruz weile andhrideshrajan.
.
deepdiagnosis automaticallydiagnosingfaultsandrecommendingactionable fixes in deep learning programs.
in 44th international conference on software engineering icse may pittsburgh pa usa.
acm newyork ny usa 12pages.
introduction deep neural networks dnns are becoming increasingly popular due to their successful applications in manyareas suchas healthcare transportation and entertainment .
but the intrinsic complexity of deep learning apps requires that developers build dnnswithintheirsoftware systemstofacilitate integration anddevelopmentwithotherapplications.theconstructionofsuch systemsrequires popular deeplearninglibraries .
despite the increasing popularity and many successes for using deep learning libraries and frameworks dnn applications still suffer from reliability issues .
these faults are harder to detectanddebugwhencomparedtotraditionalsoftwaresystems as the bugs are often obfuscated within the dnns.
therefore it is important and necessary to diagnose their faults and provide actionable f ixes.
to that end software engineering research has recently focused on improving the reliability of dnn based software.
for instance there have been studies on characterizing dnn bugs on testing frameworks for deep learning on debugging deep learning using differential analysis and f ixingdnns .therearealsoframeworksandtoolsfor inspecting and detecting unexpected behavior in dnns.
however they requirethatspecialistsverify thevisualization whichis only availableupon completingthetraining phase .
due to the complexity of using existing frameworks to debug and localize faults in deep learning software recent se research has introduced techniques for automatically localizing bugs .
deeplocalize performs dynamic analysis during training to localize bugsby monitoring values produced atthe intermediate nodes of the dnns .
if there is a numerical error then this approachtracesthatbacktothefaultylayer.debar isastatic analysis tool that detects numerical errors in the dnns.
while both approaches have signi f icantly advanced the state of the art in ieee acm 44th international conference on software engineering icse icse may21 pi t tsburgh pa usa mohammadwardat brenodantas cruz weile andhridesh rajan debuggingdnns theydonotdetectbugsthatmanifestastrends ofvalues e.g.vanishinggradient explodinggradient accuracynot increasing and donotofferpossible f ixes.
we propose deepdiagnosis dd an approach for localizing faults reporting error symptoms diagnosing problems and providingsuggestionsto f ixstructural bugsin dnns.our approach introducesthreenewsymptomsofstructuralbugsandde f inesnew rulestomapfault locationtoits rootcause indnnprograms.we implemented dd as a dynamic analysis tool and compared and contrasted it against state of the art approaches.
dd outperforms umlaut and deeplocalize in terms of efficiency and autotrainerintermsofperformance .forexample assume theunchanged weight symptom which occurs when the weights in the network are not changing for several iterations.
in that case ddwouldidentifytherootcauseasthatthe learningrateistoolow orthattheoptimizerisincorrect andthenrecommenda f ix.
insummary this paper makes thefollowing contributions westudydifferenttypesofsymptomsandproposeadynamic analysisfordetectingerrorsandrecommending f ixes.
weintroduceddeepdiagnosis dd thereferenceimplementationof ourapproach.
weevaluatedddagainstsota.we foundthatddismore efficient than umlaut and deeplocalize .
also dd has better performance than autotrainer .
we provide a set of models that practitioners can use to evaluatetheir fault localizationapproaches.
we make dd available its source code evaluation results andtheproblem solutions for444buggymodelsat .
to the best of our knowledge deepdiagnosis provides the f ixed location and the concrete f ix at the dnn source code level.
our approach detects problems during the training process and can handle a broad class of problems e.g.
compared to deeplocalize that do not manifest themselves as numerical errors.
it is challenging to provide a correct f ix for an observed symptom.
islamet al.
show that solving a single problem may lead to additional ones.
deepdiagnosis addresses the issue by building the connectionbetweensymptomstorootcauses.toobtainsuitable solutions weproposea decision tree to mapsymptoms to f ix.
the rest of the paper is organized as follows 2describes the motivationofourapproach.
3describesourdynamicfailuresymptoms detection algorithm.
4describes the evaluation of our approach compared with prior works.
5discusses the threats to validity.
6discussesrelatedworks and 7concludesanddiscusses futurework.
a motivating example in this section we motivate our work by providing an example to illustrate the complexity oflocalizing faults and reporting their symptomsin dnn programs.
1model sequential 2model.add dense 3model.add activation relu 4model.add dropout .
5model.add dense 6model.add activation relu 7model.add dropout .
8model.add dense 9model.add activation softmax 10model.compile loss binary crossentropy optimizer rmsprop 11model.
fit x y batch size epoch validation data x test y test listing1 badresultfor simple model considerthecodesnippetinlisting 1fromstackover f low with an example of a dnn.
this model showed erratic behavior during training and returns bad results.
at line the developer constructedasequentialmodelandaddedadenseinputlayeratline with the activation functions reluspeci f ied at line .
then the developer added a dropout layer at lines and .
lines and are densehiddenlayerswiththeactivationfunctions reluandsoftmax speci f iedatlines6and9 respectively.thedeveloperthencompiled the model at line and trained it using the fit function at line .
when compiling the developer must specify additional properties such as loss function and optimizer.
in this example the developer used as loss binary crossentropy and optimizer rmsprop at line .
finally at line the developer speci f ies the trainingdata batch size epoch and validation data .
the developer noticed that the dnn program was providing badaccuracyandcouldnotdiagnosethe problemnor f ixit stack over f low post while following the keras mnist example .
the main issue with the code in listing 1is that it handles a binaryclassi f ication problem andthereforeitshould notusethe activation function softmax in line .
as the softmax works for multi class classi f ications problems.
instead it should use sigmoid as it is the best suited for binary classi f ication and will provide the bestaccuracyforthetask.
table resultfrommotivating example approach ouput umlaut nooutput deeplocalize layer numericalerrorin delta weights autotrainersolution times issue list train result describe .
selu .
using selu activationin eachlayers .
bn .
using batchnormalization ... unsolved.. for moredetails deepdiagnosislayer numericalerrorin delta weights change the activation function at layer the current state of the art for dnn fault localization is limited in terms of s peed accuracy and efficiency.
table 1summarizes the analysis results from three tools deeplocalize umluat autotrainer and our approach deepdiagnosis to diagnose the dnn model in listing .
to apply umluat for the above example we made semantic changes that were validated by the authors .
after .
seconds the training was terminated withumlautnotreportinganyproblems.toapplydeeplocalize we followed the instructions in the github repository .
deeplocalize prints the following message after .
seconds layer numericalerrorindeltaweights.
thismessageindicatesthatthere isanumericalerrorinthebackpropagationstageduringtraining.
indicating fault location butit does not help developersto f ix the problem.toapplyautotrainer wefollowedtheinstructions in the github repository .
after performing the training phase autotrainerdidnotsolvetheproblemandtook495.83seconds.
speci f ically autotrainerdetectsadyingrelusymptom butit doesnotprovidethefaultlocation whetheritisinline3or6.autotrainer tries to automatically f ix the issue by trying different 562deepdiagnosis automaticallydiagnosingfaultsandrecommending actionable fixes indeeplearningprograms icse may21 pi t tsburgh pa usa 0rgho dooedfn edfn lq hljkw qlwldol dwlrq rfdwlrq wr l qfruuhfw fwlydwlrq hduqlqj 5dwh psurshu dwd qfruuhfw rvv hwhfw dloxuh pswrpv 6dwxudwhg fwlydwlrq sorglqj 7hqvru hdg 1rgh ffxudf 1rw qfuhdvlqj sorglqj udglhqw8qfkdqjhg hljkw 9dqlvklqj udglhqw rvv 1rw hfuhdvlqj pswrp 3kdvh rfdwlrq o g l 0rgho 9l k l 7udlqlqj 8k g hwhfwlqj figure overviewof deepdiagnosis.
strategies i.e.
substitutingactivationfunctions adding batchnormalization layer and substituting initializer which unfortunately areunsuccessful.
ourapproachdeepdiagnosiscorrectlyreportsthefaultlocation anditssymptomsafter35.03seconds.also itprovidesasuggestion toperforma f ixintheformofamessage.speci f ically deepdiagnosisreportsthatthebugislocatedinthebackpropagationstage oflayer7atline8.also itprintsoutanumericalmessage error in delta weights which indicates the type of the symptom.
it also reportsthattherootcauseistheactivationfunctioninlayer8at line9 softmax .finally itanswersthedeveloper squestion there is indeed a problem with the activation function in the last layer andnotin thetraining dataset.
approach inthissection weprovideanoverviewofourapproachforfault localization.weprovidedescriptionsoffailuresymptomsandtheir rootcauses.also wedescribetheprocessofmappingsymptoms to their root causes.
our approach monitors the key values during training like weights and gradients.
during training it analyzes the recorded valuetodetectsymptomsanddeterminewhetheratrainingproblem exists.
if a symptom is detected our approach invokes a decision tree to diagnose repair information based on a set of predeterminedrules.otherwise thetrainingwillterminatewiththe trained model and reportthemodel iscorrect.
.
anoverview figure1shows an overview of our approach for fault localization deepdiagnosis and for suggesting locations f ix.
dd starts by receiving as input the initial model architecture with a training dataset and passing our callback method as a parameter to the fit method figure 1leftcomponent .keras callbacksarea set ofmethodsthatenable developerstocheck theirmodel sintermediatefeatures e.g.
weights gradients .also callbacksenablethe developers to inspect the model s behavior during training.
our callbackapproachisinspiredbypriorwork .inparticular our callbacks allow capturing and recording the key values i.e.
weight gradient etc.
during feed forward and backward propagation stages figure 1middle component .
then dd applies a dynamicdetectorduringtrainingtoreportdifferentsymptomsat different stages based on error conditions see section .2for more details .
if dd detects a symptom it further analyzes the recorded key values to determine the input model s probable location forthe f ix figure 1rightcomponent .finally ddreportsthesymptomtype whichlayersandstagethesymptomwasdetected and suggestsalocation f ix.
.
failuresymptoms androot causes ourgoalistodetectfailuresymptomsassoonaspossibleduring development.
so that if the model is incorrect developers would not have to wait until the end of the training to f ind that model haslowaccuracy thuswastingcomputationalresources.tothat end wecollected8typesoffailuresymptomsandtheirrootcauses frompreviouswork intheai research community .
we provide more details of each of the symptoms and their root causesbelow.
.
.1symptom 1deadnode .thedeadnodesymptomtakes place when most of a neural network is inactive.
for example assume that most of the neurons of a dnn are using the relu activationfunction whichreturnszerowhenreceivinganynegative input.
if the majority of the neurons receive negative values e.g.
due to a high learning rate they would become inactive and incapableofdiscriminatingtheinput.thednnwouldendupwith poor performance .
to identify this symptom we compute the percentage of inactive neurons per layer.
if the majority of the neuralnetwork isinactive thenwecallit dead node.
root causes this problem is likely to occur when learningrateistoohigh low.
thereisalargenegativebias.
improper weight orbiasinitialization.
.
.2symptom saturated activation .the saturated activationsymptomtakesplacewhentheinputtothelogisticactivation function e.g.
tanhorsigmoid reachedeitheraverylargeoravery small value .
at the saturated point the function results would equal zero or be close to zero thus leading to no weight updates.
ourexperimentsshow thatthebehaviorof sigmoidandtanh have a minimum saturated point at x and a maximum saturated point at x .
previous work showed that the saturated function affects the network s performance and makes the network difficult to train .
rootcauses this problem is likely to occur when the inputdataaretoolargeortoosmall improperweightorbias initialization learningrateistoo high ortoo small.
.
.3symptom exploding tensor the exploding tensor symptomtakesplacewhenthetensors valuesbecometoolarge leadingtonumericalerrorsinafeed forwardstage.
forexample if 563icse may21 pi t tsburgh pa usa mohammadwardat brenodantas cruz weile andhridesh rajan table methodsfor detectingfailure symptoms id method name input output description s1 explodingtensor weight uni0394 weight and layeroutputt ftheproceduredetectsanynumericalerrorsuchasin f inite nan notanumber orzero.tothatend itcomputes the input s mean value.
then it checks for a numerical error is detected.
in case of error it returns true otherwise false.
s2 unchangeweight weight uni0394 weight layer outputt fthe procedure stores the value for a given numberof steps n .
then it compares the value for the current step with the mean value stored in for previous n steps.
the evaluation takes place for every given number ofsteps.theprocedure returns trueif the valueis not changing otherwise false.
s3saturatedactivation input of activation functiont fthe procedure detects if the tanh or sigmoid activation functions or other logistic functions are becoming saturated.
it does so by checking if their input has reached either a maximum or minimum value.
saturated functions derivatives would be equal to zero at those points.
the procedure counts the activity of a close or greater node than to the max threshold or less than min threshold of the activation function if the percentage of total activity nodes is greater than the threshold layer .
percent of the nodes are saturated theprocedure returns true otherwise false.
s4 deadnode reluoutput t fthis procedure takes the output of recti f ied linear unit relu activation function as input then computes howmanyinactivenodesdroppedbelow threshold .
.ifthepercentageofinactivenodesisgreaterthan layer threshold .
it returns true otherwise false.
s5 outofrange outputoflast layert fthe procedure detects if the activation function s output is becoming out of range for the labeling training dataset y. to that end it f inds the range maximum and minimum of the activation function s output.
then compareitwithylabelingdata.ifthevalueisoutoftheboundary theprocedurereturns true otherwise false.
s6lossnotdecreasing lossvalue t fthe procedure stores the loss value for every number of steps n then compares the loss value for the currentstepwiththemeanvalueoflossesstoredintheprevious n steps.theevaluationhappensforevery numberofsteps n .theprocedure returns trueif the lossis not decreasing otherwise false.
s7accuracynotincreasing accuracy valuet ftheprocedurestorestheaccuracyvalueforeverynumberofsteps n thencomparestheaccuracyvalue for the current step with the mean value of accuracy stored in previous n steps.
the evaluation happened every numberofsteps n .theprocedure returns trueif accuracyis not increasing otherwise false.
s8 vanishinggradient deltaweight t fthis procedure detects the vanishing gradient problem by checking the gradients when they become extremely smallor drop to zero.theprocedure computesthe mean ofthe gradients absolutevalues thenchecksif their means drop below a speci f ied threshold .
.
in the case of a positive detection it returns true otherwise false.
thistableshows proceduresdescriptions from .t f indicatesthat theprocedurereturnstrue falserespectively.
table methodsfor mapping fromfailure symptoms to locationfix no method name input output description c1 improperdata trainingdata t fcheckifthemaximumandminimumvalueoftrainingdatasetliewithinspeci f icrangeof .ifthevalue withintheboundary theprocedure returns true.otherwise false.
c2weightinitialization weight for eachlayert fthisprocedurechecksthevarianceofweightinputsacrosslayerstodetermineifaneuralnetworkhasbeenpoorly initialized.
the procedure checks if the variance of weights per layer is equal or very close to min threshold .
orifitexceedsthe min threshold theprocedure returns true.otherwise false.
c3 tunelearn learning rate weight and uni0394 weightl hthe procedure evaluates the learning rate heuristically by computing the ratio of the norm of the gradient weight to the norm of weight for each layer.
this ratio should be somewhere around learn threshold 1e .ifitislowerthan learn threshold 1e thenthelearningratemightbetoo low.ifitishigherthan learn threshold 1e thelearningrateis likely too high.
this tableis showing all the functionality of the procedures.
t f indicates the procedure returntrue false respectively.
l h indicates the procedure return low highrespectively.
weborrowed thesemethods from existing literature theweightoroutputlayergrowsexponentiallymorethanexpected becoming either in f inite or nan not a number .
eventually this problem causes a numerical error making it impossible for the model to learn.
rootcauses this problem is likely to occur when the learning rate is too large there exist improper weight or biasinitialization orimproper inputdata.
.
.4symptom accuracy not increasing symptom lossnotdecreasing .bothsymptomsaccuracynotincreasing and loss not decreasing are very similar.
the accuracy not increasingsymptomtakesplacewhentheaccuracyofatargetmodel is not increasing for n steps but instead it is decreasing or f luctuating during training.
while for the loss not decreasing symptom the loss metric is the one that is not decreasing for n steps but is f luctuating.thesebehaviorsindicatethatthenetworkwillnot achievehighperformance.thesesymptomsareoftencausedbythe incorrectselectionofdnnhyperparameters suchaslossfunction activation function for the last layer learning rate optimizer orbatch size.rootcauses this problem is likely to occur when thereexistimpropertrainingdata thenumberoflayersistoo large small and thelearningrateisveryhigh low and there existincorrectactivation functions.
.
.5symptom 6unchangedweight .theunchangedweight symptom takes place when the dnn weights do not have a noticeablein f luenceontheoutputlayers.thisbehaviorleadstounchanging parameters andnetworkstacks whichfurther prevents themodel from learning .
rootcauses this problem is likely to occur when learning rate is very low the optimizer is incorrect there existincorrectweights initialization and there existsincorrect loss activationatthelast layer.
.
.6symptom 7explodinggradient .thisproblemoccurs during the back propagation stage.
in it gradients are growing exponentially from the last layer to the input layer which leads to non f inite values either in f inite or nan not a number .
this issue makes learning unstable and sometimes even impossible.
consequently updating the weights becomes very hard and the training model ends up withahigh loss orvery low accuracyvalues.
564deepdiagnosis automaticallydiagnosingfaultsandrecommending actionable fixes indeeplearningprograms icse may21 pi t tsburgh pa usa rootcauses this problem is likely to occur when the learning rate is very high there is an improper weight or bias initialization there are improper data input and the batchsizeisvery large.
.
.7symptom vanishing gradient .the vanishing gradientproblemoccursduringthebackwardstage.whencomputing the gradient of the loss concerning weights using partial derivatives the value of the gradient turns out to be so small or drops to zero.
the problem causes major difficulty ifit reachesthe input layer whichwillpreventtheweightfromchangingitsvalueduring training.
since the gradients control how much the network learns during training the neural network will end up without contributingto thepredictiontask orleadingto poorperformance .
rootcauses this problem is likely to occur when the network has too many layers the learning rate is low the hiddenlayersimproperlyused tanhorsigmoid and thereexists theincorrectweight initializationproblem.
.
detecting failuresymptoms in table2from method s1 to s8 we describe the failure symptoms discussedinsection .
usingitsname input output andthedetection procedure.
algorithm 1shows an example of a dynamic analysis procedure which deepdiagnosis uses to detect failure symptoms during training table 2description .
also the algorithm1reports failure locations such as in which layer and phases i.e.
feed forwardandbackwardpropagation .incaseafailureis detected the algorithm will trigger the mapping procedure to identify the location in the original dnn source code.
by so it willlocalizethebugand determinetheoptimal f ix.
atline1 algorithm 1iteratesoverthetrainingepochs withthe trainingdatasetdivided intobatches.line3showsthedivisionof the training dataset into a mini batch.
on lines the algorithm runs one batch of the training dataset before updating the internal model parameters.
the neural network can be divided into two stages first theforwardstage inwhichthealgorithmperforms dynamic analysis and symptom detection including numerical error deadnode saturatedactivation andout ofrange at lines .
second the backward stage in which the algorithm performs dynamicanalysistodetectadditionalsymptoms suchasnumerical error vanishinggradient and unchanged weight atlines23 .
.
.
feed forward stage.
at lines of the algorithm i t computestheoutputofafeed forwardbeforeandafterapplying theactivationfunction.atline7 itinvokesthe explodingtensor procedure s1 in table to determine if the output contains a numerical error obtained from the output value before after applying activation function respectively.
if there is an error the algorithm reportsthensmessageasshownintable .next itinvokesthe mapping procedurefromthedecisiontreeinfigure 2byproviding thesymptom ns location stage fw andlayer l .thedecision tree returns the best actionable f ix for the model see section .
formoredetails .
atline8 thealgorithm 1invokesthe unchangeweight s2in table2 proceduretodetectwhethertheoutputbefore afterapplyingtheactivationfunctionisnolongerchangingacrosssteps.ifthe procedureindicatesthatthevaluedoesnotchangeforniterations wefollow andsetn .the unchangeweight procedurecan be applied either to the output before after the activation function.
thealgorithmreportsthemessageucs asshownintable .atline the algorithm invokes the saturatedactivation procedure s3 in table2 forthelayer thathasalogistic activation function i.e.
tanhorsigmoid todetermineifthelayerisbecomingsaturated.
thisproceduretakestwoarguments thevaluebeforeapplying the activationfunction v 1 andthenameoftheactivation function v 2.name .
if the procedure determines that the layer is saturated thealgorithmreports themessagesas as shown in table .
atline10 thealgorithm 1invokesthe deadnode procedure s4 in table to check the layers that use the recti f ied linear unit relu activation function.
the goal is to determine if the output after applying the activation function has dropped below a threshold .
this procedure is invoked only after applying the activation function.
the algorithm reports the message dns as shown in table 5when the error is detected.
similarly at line it invokes the outofrange procedure s5 in table in the last layer.
the goal is to determine if thedeveloper has chosen the correctactivationfunction.thealgorithmreportsthemessageors as shown in table 5if theerrorisdetected.
in lines the algorithm interprets and validates how well the model is by computing the loss and accuracy metrics respectively.thenitdeterminesifthereisanynumericalerrorin those metrics at lines respectively.
thealgorithm invokes lossnotdecreasing andaccuracynotincreasing s6 s7 in table2 tocheckifthelossortheaccuracyhasnotchangedforalong time.inbothcases thealgorithmreportsamessagelndsoranis as shown in table .
.
.
backpropagationstage.
duringthisstage thealgorithm computes the gradient of loss function uni0394weight for the weight bychainrulesineachiteration.atline24 thealgorithminvokes backward toapply stochasticgradientdescent andthisfunction returns the weight and uni0394weight in each iteration.
at line the algorithm invokes the vanishinggradient procedure s8 in table2 and passes uni0394weight to check if the gradients become extremely small or close to being zero.
in the same way at line the algorithm can determine if there is a numerical error in the weight or the gradient weight in each layer by invoking the explodingtensor procedure s1 intable .thebackpropagation algorithmworksiftheweightisupdatedusingthegradientmethod and the loss value keeps reducing to check if the backpropagation works effectively.
in the backward propagation we also invoke theunchangeweight procedure s2intable todetectwhether theweightor uni0394weightisnolongerchangingacrosssteps.ifany procedure decides that there is an issue then the algorithm will return a message to indicate the type of symptom as shown in table5 l represents a faulty layer number.
then the algorithm invokesmapping and passes the symptom location and layer to f ind the best actionable change to f ix the issue in the model.
finally if the algorithm did not detect any type of symptom it will terminateafter f inishingthetrainingatline29andprintamessage indicatingthatthereisno issue in themodel cm .
565icse may21 pi t tsburgh pa usa mohammadwardat brenodantas cruz weile andhridesh rajan table abbreviation of actionable changes nomessageguideline abbreviation 1improper data msg0 2changethelossfunction msg1 3changetheactivationfunction msg2 4changethelearningrate msg3 5changetheinitializationof weight msg4 6changethelayer number msg5 7changetheoptimizer msg6 table abbreviation of failure symptoms nosymptoms abbreviation 1numericalerrors ns 2unchanged weight ucs 3saturated activation sas 4deadnode dns 5outof range ors 6lossnotdecreasing lnds 7accuracy not increasing anis 8vanishinggradient vgs 9invalidloss ils 10invalidaccuracy ias 11correctmodel cm .
mappingsymptomsto location f ix decisiontree themaingoalofthisstepistomitigatemanual effortandreducethetimefordiagnosing and f ixingbugs.tothat end themapping procedureinalgorithm1provides f ixsuggestions based on the detected failure symptoms.
figure 2shows a representationofthedecisiontreewhichthe mapping procedure usesto providea f ix recommendation.
the decision tree consists of rules which corresponds to decision paths.
each rule provides a mapping from failure symptomsanddetectedlocationstoactionablechanges.thetreede f ines a binary classi f ication rule which maps instances in the format problem symptom location layer into one of seven classes of changes .
in the decision tree the root node represents the problem orange nodes the symptoms blue nodes the locations gray nodes the layer type green nodes the conditions and red nodes theactionablechanges.
table 3showsthemethods data weight andlearn which are used to compute the conditions.
eachdecisiontreeinstancemapsapathfromtheroottooneof theleaves.
forexample assumethatadeveloperwantstocheckthecode in listing .
to that end the developers can use the algorithm 1to verifythemodel.thealgorithminvokesthe mapping procedure line26 bypassingthesymptomns location stagebw backward and layer .
this procedure traverses the path under the ns node inthedecisiontree figure .sincetheproblemoccurredinthe bwstage thealgorithmtakestherightpathtosatisfythecondition.
then itveri f iesthelayertype .sinceit f indsanissueinthelayer theprocedure returns the message msg2 changethe activation function .
heuristics we developed a set of heuristics based on the root causes see section .
.
there are three main root causes data preparation parameter tuning and model architecture.
foralgorithm1 failuresymptomsdetection input training data input label dnn program output failuresymptoms andlocations layers iterations epoch 1for u1d452 0to u1d452 u1d45d u1d45c u1d450 uni210e u1d460do 2for u1d456 0to u1d43f u1d452 u1d45b u1d454 u1d461 uni210e u1d456 u1d45b u1d45d u1d462 u1d461 step u1d44f u1d44e u1d461 u1d450 uni210e u1d460 u1d456 u1d467 u1d452 do u1d44b u1d456 u1d45b u1d45d u1d462 u1d461 u1d44c u1d459 u1d44e u1d44f u1d452 u1d459 for u1d43f 0to u1d43f u1d452 u1d45b u1d454 u1d461 uni210e u1d43f u1d44e u1d466.alt u1d452 u1d45f u1d460 do u1d4491 u1d43f u1d44e u1d466.alt u1d452 u1d45f .
u1d439 u1d45c u1d45f u1d464 u1d44e u1d45f u1d451 u1d44b u1d4492 u1d43f u1d44e u1d466.alt u1d452 u1d45f .
u1d434 u1d450 u1d461 u1d456 u1d463 u1d44e u1d461 u1d456 u1d45c u1d45b u1d4491 if u1d438 u1d465 u1d45d u1d459 u1d45c u1d451 u1d456 u1d45b u1d454 u1d447 u1d452 u1d45b u1d460 u1d45c u1d45f u1d4492 u1d4491 then return ns u1d440 u1d44e u1d45d u1d45d u1d456 u1d45b u1d454 u1d441 u1d446 u1d439 u1d44a u1d43f if u1d448 u1d45b u1d450 uni210e u1d44e u1d45b u1d454 u1d452 u1d44a u1d452 u1d456 u1d454 uni210e u1d461 u1d4492 u1d4491 then return ucs u1d440 u1d44e u1d45d u1d45d u1d456 u1d45b u1d454 u1d448 u1d436 u1d446 u1d439 u1d44a u1d43f if u1d446 u1d44e u1d461 u1d462 u1d45f u1d44e u1d461 u1d452 u1d451 u1d4491 u1d4492.
u1d45b u1d44e u1d45a u1d452 then return sas u1d440 u1d44e u1d45d u1d45d u1d456 u1d45b u1d454 u1d446 u1d434 u1d446 u1d439 u1d44a u1d43f if u1d437 u1d452 u1d44e u1d451 u1d441 u1d45c u1d451 u1d452 u1d4492 then return dns u1d440 u1d44e u1d45d u1d45d u1d456 u1d45b u1d454 u1d437 u1d441 u1d446 u1d439 u1d44a u1d43f if u1d442 u1d462 u1d461 u1d45c u1d453 u1d445 u1d44e u1d45b u1d454 u1d452 u1d4492 u1d44c u1d43f u1d43f u1d44e u1d460 u1d461then return ors u1d440 u1d44e u1d45d u1d45d u1d456 u1d45b u1d454 u1d442 u1d445 u1d446 u1d439 u1d44a u1d43f u1d44b u1d4492 u1d43f u1d45c u1d460 u1d460 u1d436 u1d45c u1d45a u1d45d u1d462 u1d461 u1d452 u1d43f u1d45c u1d460 u1d460 u1d4492 u1d44c if u1d43f u1d45c u1d460 u1d460is equal to nan or u1d456 u1d45b u1d453then return ils u1d440 u1d44e u1d45d u1d45d u1d456 u1d45b u1d454 u1d43c u1d43f u1d446 u1d434 u1d450 u1d450 u1d462 u1d45f u1d44e u1d450 u1d466.alt u1d436 u1d45c u1d45a u1d45d u1d462 u1d461 u1d452 u1d434 u1d450 u1d450 u1d462 u1d45f u1d44e u1d450 u1d466.alt u1d4492 u1d44c if u1d434 u1d450 u1d450 u1d462 u1d45f u1d44e u1d450 u1d466.alt is equal to nan or inf or 0then returnias u1d440 u1d44e u1d45d u1d45d u1d456 u1d45b u1d454 u1d43c u1d434 u1d446 if u1d43f u1d45c u1d460 u1d460 u1d441 u1d45c u1d461 u1d437 u1d452 u1d450 u1d45f u1d452 u1d44e u1d460 u1d456 u1d45b u1d454 u1d43f u1d45c u1d460 u1d460 then returnlnds u1d440 u1d44e u1d45d u1d45d u1d456 u1d45b u1d454 u1d43f u1d441 u1d437 u1d446 if u1d434 u1d450 u1d450 u1d462 u1d45f u1d44e u1d450 u1d466.alt u1d441 u1d45c u1d461 u1d43c u1d45b u1d450 u1d45f u1d452 u1d44e u1d460 u1d456 u1d45b u1d454 u1d434 u1d450 u1d450 u1d462 u1d45f u1d44e u1d450 u1d466.alt then returnanis u1d440 u1d44e u1d45d u1d45d u1d456 u1d45b u1d454 u1d434 u1d441 u1d43c u1d446 u1d451 u1d466.alt u1d44c for u1d43f u1d43f u1d452 u1d45b u1d454 u1d461 uni210e u1d43f u1d44e u1d466.alt u1d452 u1d45f u1d460 to0do u1d4493 u1d44a u1d43f u1d44e u1d466.alt u1d452 u1d45f .
u1d435 u1d44e u1d450 u1d458 u1d464 u1d44e u1d45f u1d451 u1d451 u1d466.alt if u1d449 u1d44e u1d45b u1d456 u1d460 uni210e u1d456 u1d45b u1d454 u1d43a u1d45f u1d44e u1d451 u1d456 u1d452 u1d45b u1d461 u1d44a then return vgs u1d440 u1d44e u1d45d u1d45d u1d456 u1d45b u1d454 u1d449 u1d43a u1d446 u1d435 u1d44a u1d43f if u1d438 u1d465 u1d45d u1d459 u1d45c u1d451 u1d456 u1d45b u1d454 u1d447 u1d452 u1d45b u1d460 u1d45c u1d45f u1d4493 u1d44a then return ns u1d440 u1d44e u1d45d u1d45d u1d456 u1d45b u1d454 u1d441 u1d446 u1d4493 u1d437 u1d44a u1d43f if u1d448 u1d45b u1d450 uni210e u1d44e u1d45b u1d454 u1d452 u1d44a u1d452 u1d456 u1d454 uni210e u1d461 u1d4493 u1d44a then return ucs u1d440 u1d44e u1d45d u1d45d u1d456 u1d45b u1d454 u1d448 u1d436 u1d446 u1d449 u1d437 u1d44a u1d43f u1d451 u1d466.alt u1d4493 29returncm datapreparation thealgorithmchecksifthedataisnormalized c1 improperdata intable3 .forparametertuning ourapproach checksifthehyperparameters suchaslearningrate wereassigned correctly.
also to check if the weights were initialized correctly thealgorithminvokesthe weightinitialization .thetunelearn procedureveri f ieswhetherthelearningrateisveryhighorvery low c2 and c3 in table respectively .
for model architecture the algorithm searches for a relation between the location and the stage of the symptom.
it performs this step to pinpoint which apis arebeingmisused in themodel e.g.
loss activation function .
wecollectedtherootcausesforeachsymptomfromprevious work more details in section .
.
to arrive at a possible f ixforagivensymptom wechoosethemostfrequentroot 566deepdiagnosis automaticallydiagnosingfaultsandrecommending actionable fixes indeeplearningprograms icse may21 pi t tsburgh pa usa cause.
we follow this approach as our f indings show that changes in the order we check for the possible root causes do not affect the results onlyonthetotaltimeto arriveatasolution.for example assume that a model has the dead node symptom.
in terms of frequency improper data tends to happen more often than weight andlearningrate.ifthethreerootcausesarecorrect ourapproach checksthemodelarchitecture whichistheleastcommoninthis case.
thus arrivingat animproperactivation functionastheroot causeof this symptom.
evaluation intheevaluation weanswer thefollowing researchquestions rq1 validation canourtechniquelocalizethefaultsand reportthesymptomsindeeplearningprogramseffectively?
rq2 comparison howdoesourtechniqueforfaultlocalizationcomparedtoexistingmethodologiesintermsoftime andeffectiveness?
rq3 limitation in which cases do our technique fail to localizethefaultsand reportthesymptoms?
rq4 ablation to what extent does each type of symptomwedeveloped contribute to theoverallperformanceof deepdiagnosis?
.
experimentalsetup .
.
implementation.
weimplementeddeepdiagnosisontopof keras2.
.
andtensorflow .
.
.
also we implemented algorithm 1by overriding the method called on epoch end epoch logs none .forthedecisiontreeinfigure weimplementedit as a decision rule consisting of a set of conditional statements.
the overridden method invokesthe decision tree onceupon detecting a symptom.
then it passes the symptom type as a parameter for thedecisiontree.
weconductedalltheexperimentsonacomputerwit ha4ghz quad core intel core i7 processor and gb mhz ddr3 gb of ram runningthe64 bit imac version .
.
.
.
benchmark.
in total we collected models from prior work .
from these we removed rnn models as our approach does not support them.
the resulting models are composed of which are known to have bugs from .
we refer to these models sgs benchmark as they come from stackover f low github and schoop etal.
.also the391models from areinthecompiled .h5format.theremaining391models are divided into two sets.
in particular the f irst with correct models without any known bugs and the second with buggymodels withbugs.
mostmachine learning developers share the sourcecode or the trainedweightsoftheirmodelsin .h5format.toallowothersto improve the understanding of how a model operates and inspect it withnewdata weimplementedthe extractor tool .itextracts thednnsourcecodefroma .h5 f ile.the extractor followsthree stepstogeneratethekerassourcecode f irst itsavesthemodel s layer information to a json f ile.
then it generates the abstract syntax tree ast from the json f ile.
finally it converts the ast to thesource code.
to build the ground truth for the sgs benchmark we manuallyreviewedallmodelsandtheirrespectiveanswersfrom stackover f low andcommitsfrom github.
weperformthis veri f ication processtodeterminetheexactbuglocationanditsrootcauses.for the remaining models buggymodels and not buggy models we usedour extractor togenerate thesourcecode for each modelbefore afterperforminga f ix weusedthedifflib module to generate the diff f ile from the f ixed model.
we use the diff to locate the changes in the model thus locating the root causes and the actual location of its corresponding f ix.
we consider a model successfullyrepaired if itsaccuracyhasimproved after the f ix.
.
.
results representation.
table6shows the summarized evaluation results of the following approaches umluat deeplocalize autotrainer andourapproachdeepdiagnosis.
pleaserefertothereproducibilityrepository forthecomplete table.the f irstcolumn shows thesource ofthe buggymodel.the secondcolumnliststhemodelid.thethirdcolumnprovidedthe stack over f low post and the model name from github repositories collected by wardat et al.
and also the name of the modelintroducedbyschoop etal.
respectively.tocompareour approach with the results generated from previous approaches we reportedtheresultsinthefollowingcolumns fromlefttoright time identifybug ib faultlocalization fl failuresymptom fs and location fix lf and ablation ab .
time in seconds reports how long each tool takes to report its results.
the columns identify bug ib and fault localization fl show whether the approach successfullyidenti f ies thebugand the faultlocation.
failure symptom fs and location fix lf columns show whether the tool correctly reports a symptom and an actionable change model repair f ix .
finally the ablation ab column shows which of the procedures listed in table 2detects the failure symptoms.
under each approach the yes and no status indicates whether ithassuccessfullyreportedthetargetproblem.also the status denotes if the approach does not yet support the target problem.
lastly we use method id in table 2to indicate which procedure is used to detectthefailuresymptom.
table7summarizes the analysis results from four approaches usingbenchmarkscollectedfromthreedifferentsources .
the second column total lists the total number of buggy models for each dataset.
to compare our approach with previous approaches wereportedtime inseconds theaveragetimeeachtool takes to report its results for each dataset.
to mitigate randomness during the training model we followed the procedure described in andraneachmodel5times.thecolumnidentifybug ib shows how many each approach successfully identi f ies the bug from each dataset.
our approach is capable of handling eight types of symptoms with different types of datasets usingdifferent types of model architectures.
table 8shows the number of symptoms detected from different types of datasets.
.
rq1 validation andrq2 comparison table6and7show theevaluation results forrq1and rq2.
deepdiagnosis dd hascorrectlyidenti f ied46outof53buggy modelsfromthesgsbenchmark.ddcorrectlyreportedthefault location for models and the failure symptoms for models.
also ddcorrectlyidenti f iedtheactionablechangesfor28outof faulty models.
lastly dd identi f ied out of the buggy 567icse may21 pi t tsburgh pa usa mohammadwardat brenodantas cruz weile andhridesh rajan figure mapping symptoms to fixlocation table comparing the results from umlaut um deeplocalize dl autotrainer at and deepdiagnosis dd nopost time identifybug ib faultlocalization fl failuresymptom fs locationfix lf ab um dl at ddumdlatddumdlatddumdlatddumdlatdd stackoverflow .
.
.
.27yesyesyesyesyesyes yesyesyesyesyesyesnonoyes .
.
.
.
noyesnononoyes nonoyesnononononono .
.
yes yes no yes yes yes no yes .
.
.
.75noyesyesyesnoyes yesnoyesyesyesnonoyesyes .
.
no yes no yes no yes no yes .
.
.
.12yesyesnoyesnoyes yesnoyesnoyesnononoyes github 7gh .
.
.
.90yesyesyesyesnono nononoyesnononoyesno 8gh .
.
no no no no no no no no 9gh .
.
yes yes yes yes no yes no yes 10gh .
.
.
.
yesyesyesyesnono noyesnoyesnononoyesno 11gh .
.
.
.
yesyesnoyesnoyes yesnoyesnoyesnononono 12gh .
.
.
nonono no no nonono nonono schoopetal.
13a1 c .
.
.
.75yesyesyesyesyesyes yesyesyesnoyesyesnonoyes 14a2 c .
.
.
.44yesyesnoyesnoyes yesyesyesnonoyesnonono 15a3 c .
.
.
.03yesyesyesyesnono noyesnonoyesyesnonono 16b1 c .
.
.
.17yesyesyesyesnono noyesyesyesyesyesnonono 17b2 c .
.
.
.44yesyesnoyesnoyes yesyesnonoyesyesnonoyes 18b3 c .
.
.
.49yesyesnononono noyesnononoyesnonono total c indicatesto themodel using cifar dataset andf m indicatesto themodel using fashion mnistdataset.
table runtime overhead vs. problem detects time identify bug ib dataset totalum dl at ddumdlatdd stack overflow .
.
.
.
github .
.
.
.
schoopet al.
.
.
.
.
blob .
.
.
circle .
.
.
mnist .
.
.
.
cifar .
.
.
.
models from the autotrainer dataset correctly reporting fault location failuresymptoms and actionablechanges.
deeplocalize dl identi f ied out of the models from the sgs benchmark and indicated fault locations for .
it reported symptoms for only models but it cannot provide any suggestions to f ix these faults.
regarding the autotrainer dataset dl identi f ied 191outofthe 203buggymodels andcorrectlyreported theirfaultlocation.however dldidnotprovideanysuggestionsfor f ixing thosemodels.lastly dlcan onlydetectbugs related to numericalerrors.
autotrainer at forthe53models sgsbenchmark at identi f ied buggy models.
out of these at successfully reported symptoms for only .
at was only able to repair models.
ddcanhandlemorevarietiesofsemanticallyrelatederrorsthan at as shown in table .
please refer to for at s evaluation results whileanalyzing itsdataset.
umluat um identi f ied buggy models out of the fromthe sgsbenchmarkand found the fault locationsfor .also umreportedthesymptomsfor17modelsandprovidedthelocation f ix for out of .
um correctly identi f ied models and reported possible f ix solutions to problems from out of buggy models of the autotrainer dataset.
um only supports classi f ication problems whileddsupportsadditionaltypes suchasregression andclassi f ication.
toevaluatetheapproaches overallperformance wecollected their total execution time while analyzing the benchmarks.
figure3shows the results.
um dl at and dd require on average .
.
.
and .
seconds respectively for all the 568deepdiagnosis automaticallydiagnosingfaultsandrecommending actionable fixes indeeplearningprograms icse may21 pi t tsburgh pa usa figure comparison between umluat um vs deeplocalize dl vs autotrainer at vs deepdiagnosis dd interms of seconds stackover f low sof benchmarks.forthegithub gh benchmark the four approaches require on average .
.
.
and .
seconds respectively.
for the schoop et al.
s benchmark thefourapproachestakeonaverage193.
.
.
and .
seconds respectively.
for the autotrainer dataset thefourapproachesrequire onaverage .
.
.
and74408.07seconds respectively tocompletetheiranalysis.lastly theoverallaveragetimeforum dl at anddd forallbenchmarks is2972.
.
.
and .
seconds respectively.
dd s runtime overhead is mainly due to its online dynamic analysis.ddrunsitsdynamicanalysisontheinternalparametersof the neural networks such as the changes of weights and gradients duringthetrainingphase.ddisthemostefficientfor stackover f low and schoop et al.
s model and is slower than um on the github models.
the reason is that dd collects more information than um duringtrainingand checksadditionaltypes of errorconditions.
dd is faster than at on all benchmarks except for the blob and circledatasets.thatisbecauseatchecksthetargetmodelafter f inishingthetrainingphase.ddrequiresadditionaltimebecause itvalidatesthemodelattheendofeachepochduringtraining and thenumber of epochs forthese modelsisbetween200to .
.
rq3 limitation out of programs our technique failed to identify faults in and localize faults in .
dd failed to report symptoms for programs andfailedtoprovidethelocationof f ixfor24 tables 2and6 .inthe following weprovideafew examples of failed fault localization.
ourtechniquedoesnotyetsupportmodelwith fit generator insteadof fit function.
fit generator isusedforprocessing a large training dataset that is unable to load into the memory .
inthefuture weplantocovermoreapis suchas fit generator .
both b3 c10 and b3 c10 programsarerelatedto checkingvalidationaccuracy .themodelsplitsthetraindata intotrainingandvalidationdata andthenprovidethevalidation databypassing validation data x val y val intothe f it method.
the buggymodelreported high accuracy for the validation dataset.
theremayexistanoverlapbetweentrainingdataandvalidationtable thesymptoms resultsfromdeepdiagnosis dd symptoms datasetnsucssasdnsorslndsanisvgsiasils stack overflow github schoopet al.
blob circle mnist cifar data.
but our approach would not indicate any symptom as it does notsupportproblems related to training and validation.
both a2 c10 and a2 c10 programs are related to the dropout rate in the dropoutlayer .
the idea of the dropout istoremoveacertainpercentageofneuronsduringiterationsto prevent over f itting.
the buggy model sets a high dropout rate .
which is more than the acceptable rate of .
our approach isnotabletoprovideacorrectsuggestionto f ixthemodel.inour future work we plan to investigate more hyperparameters such as the batch size epoch and dropout rate to handle the above models.
dd supports deep learning models of various structures including convolutional neural networks cnns and fully connected layers.
but recurrentneuralnetworks rnns are notsupported byourcurrentreferenceimplementation.developerscanextend ourddto supportrnns and other architectures.
umonlysupportsclassi f icationproblems inwhichthelastlayer issoftmax.
otherwise it reports false alarms.
dl only supports numericalproblems anditdoesprovideanysuggestionsonhowto f ixadetectedproblem.atsupportsclassi f icationproblemsanddoes notsupportproblemsinthemodelarchitecture i.e.
lossfunction activationfunctionatlastlayer andsomeapis e.g.
f it generator .
in terms of efficiency at takes longer to f ind a f ix as it tries all possiblesolutionsuntilarrivingatthecorrectone.incaseitdoes not f indanimprovement it markstheproblem as unsolvable.
.
rq4 ablation the ablation column of table 6shows which procedure in table2isusedtoreportthesymptomineachbuggymodelforsgs dataset.
we found that explodingtensor detects buggy models saturatedactivation detects deadnode reports outofrange detects unchangeweight f inds invalidaccuracy detects accuracynotincreasing andvanishinggradient reportsonlyone buggymodel.table 8showsdatasetnames andcolumnscontain the number of symptoms which were detected successfully by the correspondingprocedureintable .fromtable wefoundthat explodingtensor detects73buggymodels vanishinggradient detects unchangeweight f inds accuracynotincreasing deadnode reports13 saturatedactivation detects12 outofrange detects5 and invalidaccuracy reportsonlytwobuggy models.
although the incorrect dnn models related to parameters and structures often manifest as numerical errors during training ddprovidedfurtherreasoningandcategoriesofcausesusingthese procedures which can help quickly f ix the bugs.
our study also foundthatdatapreparationisafrequentlyoccurringissueandthus theimproperdata procedure is frequently invoked.
sgs benchmarkdoesnothaveaverydeepmodelthatcontainsmanylayers.
thus we did not use vanishinggradient detector very frequently.
on the other hand vanishinggradient is invoked very frequently inautotrainermodels becausethisdatasethasmanylayers 569icse may21 pi t tsburgh pa usa mohammadwardat brenodantas cruz weile andhridesh rajan using sigmoid and tanh as activation functions.
h owever when nlayersusealogisticactivationfunction likesigmoidortanh nsmall derivativesaremultiplied together.
thus thegradientdecreasesexponentiallyand propagates down to theinputlayer.
.
resultsdiscussions we compared and contrasted three approaches against our approach dd .
from table we found our approach detected more problems in the sgs dataset than autotrainer.
also it detectedfewerproblemsinautotrainerdatasetthantheatapproach.
the reason is that our approach only reported the problem andsolutionifitdetectedoneof8symptoms.ontheotherhand at inspects themodel based on thetraining accuracythreshold .
for our evaluation we used normal models from .
from those 78aremnist 35arecifar 36arecircle and39areblob.
um reported the message warning possible over f itting for out mnist models.
it reported the following message error input data exceeds typical limits for out cifar models becausethetrainingdataisnotintherange .dlreportedthe message mdl model does not learn for out circle models and out blob models.
for all mnist and cifar models dl reported different messages.
at checks if a model has training accuracy less than or equal to the threshold of .
to make a fair comparison between the approaches we changed the training accuracy threshold to .
at reported different symptoms for out of circle out of blob models and models with problems out of the mnist models.
our approach reported one saturated symptom for circle which is not supported in at reported8symptoms saturatedactivations and2the accuracy is not increasing.
for the mnist model our approach reported symptoms dead nodes and one is a numerical problem we investigatedthismodelandfounditsaccuracyis20 .forcifar models dd reported models with dead node out of models.
alldetailed experimentresults arepubliclyavailable .
.
summary ddsigni f icantlyoutperformedthebaselinesum dl andatinthe sgsdataset tables 6and7 .inparticular identi f ied46outof53 buggy models correctly performed fault localization in models andreportedsymptomsfor37ofthose.ddalsoprovidedalocation to f ix out of faulty models.
regarding total analysis time dd outperformed at because it does not require the training phase to f inish to detect bugs.
also dd uses a decision tree figure approachtoreducethesearchspacewhenmappingsymptomsto theirroot causes.
furthermore ddismorecomprehensivethanpriorwork asit supports several varieties and semantically related errors in classi f ication andregression models.
also ddsupports8 failure symptoms whilepriorapproachessupportfewer in section .
finally dd does not support some apis e.g.
f it generator as weconsiderproblemsrelatedto hyperparameters forexample epoch batch size and dropoutrate as outof scope.
threats to validity external threat we have collected real world buggy dnn models from stack over f low github and models from priorwork .thesemodelscoveravarietyoffailuresymptoms andlocationtoperform f ixes however ourdatasetmaynotinclude alltypesofdnnapisandtheirparameters.tomitigatethethreatof behaviorchangescausedbytheextractortool wemanuallyveri f ied theaccuracyofeachmodelbeforeandaftertheirconversion.we used the extractor to extract the source code from the models from autotrainer .
in terms of execution time different hardware con f igurations may offer varying response times.
we mitigatedthisthreatbyexecutingourexperimentsseveraltimes andcalculated their averages.
internal threat when implementing algorithm decision tree figure andtables 2and3 weusedtheparametersde f ined by prior works .
these selected values may not workforsomeunseenexamples.tomitigatethisthreat wehave validated these selected parameters against our benchmarks collectedfromadiversesetofsources .foreachofthese benchmarks ourselectedparametersworkconsistentlywell.although we have carefully inspectedourcode ourimplementation may still contain some errors.
we manually constructed ground truthsregardingfaultlocation failuresymptoms andlocationto f ix for all the buggy models based on the data from the previous research .
this processmay haveintroduced errors.
relatedwork faultlocalizationindeepneuralnetworks therecentincrease inthepopularityof deeplearningappshasmotivatedresearchers to adapt fault localization techniques to this context.
with the intent of validating different parts of dl based systems and discoveringfaultybehaviors.thegoaloffaultlocalizationistoidentify suspicious methods and statements to isolate the root causes of program failures and reduce the effort of f ixing the fault .
wardatetal.
presentedanautomaticapproachforfaultlocalization called deeplocalize.
it performsdynamic analysis during training to determinesif a targetmodelcontainsanybugs.
itidenti f ies the root causes by catching numerical errors during dnn training.
whiledeeplocalizefocusesonidentifyingbugsandfaultsbased on numerical errors deepdiagnosis aims to perform fault localizationbeyondthatscope.furthermore ourapproachcanreport symptomsandprovideactionable f ixesto aproblem.
debar is a static analysis approach that detects numerical bugs in dnns.
debar uses two abstraction techniques to improve its precision and scalability.
deepdiagnosis uses dynamic analysis tolocalizefaultsandreportsymptomsofamodelduringtraining.in contrast debarusesastaticanalysisapproachtodetectnumerical bugswithtwo abstraction techniques.
schoopetal.
proposedumluat auserinterfacetoolto f ind understand and f ixdeep learning bugs usingheuristics.
itenables users to check the structure of dnn programs and model behavior during training.
then it provides readable error messages to assistusersinunderstandingand f ixingbugs.section 4showsthe comparison between umluat and deepdiagnosis.
deepdiagnosisismorecomprehensive efficient andeffectivethanumlaut whichonlysupportsclassi f icationmodels.
deepfault is an approach that identi f iessuspicious neurons of a dnn and then f ixes these errors by generating samples for retrainingthemodel.deepfaultisinspiredbyspectrum basedfault 570deepdiagnosis automaticallydiagnosingfaultsandrecommending actionable fixes indeeplearningprograms icse may21 pi t tsburgh pa usa localization.itcountsthenumberoftimesaneuronwasactive inactivewhenthenetworkmadeasuccessfulorfaileddecision.it then calculates a suspiciousness score such as the spectrum based faultlocalizationtooltarantula.incontrast deepdiagnosisfocuses on identifying faults and reporting different types of symptoms for structurebugs.
bug repair in deep neural networks zhanget al.
p r o posed apricot an approach for automatically repairing deep learningmodels.apricotaimsto f ixill trainedweightswithoutrequiring additional training data or any arti f icial parameters in the dnn.
mode is a white box approach that focuses on improving the model performance.
it is an automated debugging technique inspired by state differential analysis.
mode can determine whether a model has over f itting or under f itting problems.
compared with mode and apricot which focus on training bugs e.g.
insufficient training data deepdiagnosis focuses on structure bugs e.g.
activationfunctionmisused .
zhangetal.
introducedautotrainer anapproachfor f ixingclassi f icationproblems.zhang etal.de f ine f ivesymptoms andprovideasetofpossiblesolutionsto f ixeachone.onceautotrainer detects a problem it tries the candidate solutions one byone untilitaddressestheproblem.ifnoneofthesolutions f ix theproblem itreportsafailuremessage.theevaluationusedsix populardatasetsandshowedthatautotrainerdetectsandrepairsthemodelsbasedonaspeci f icthreshold.autotrainerwas abletoimprovetheaccuracyforallrepairingmodelsonaverage .
.deepdiagnosisanalyzesthemodel ssourcecodeduringthe trainingphasetolocalizethebug.deepdiagnosissupportseight symptoms while autotrainer supports f ive.
deepdiagnosis does not perform automated f ixes but it provides actionable recommendationsthatdeveloperscanfollow.autotrainertriesall possible strategies in its search space to f ix a problem and outputs whether or notthe f ixwas successful.
incontrast deepdiagnosis usesadecisiontreetoreducethesolutionsearchspace thussaving time and computational resources.
in summary the goals of deepdiagnosisandautotraineraredifferent deepdiagnosis focuses on fault localization while autotrainer on automaticallyrepairing amodel.
conclusions and futurework this paper introduces a dynamic analysis approach called deepdiagnosisthatanon expertcanusetodetecterrorsandreceiveuseful messages for diagnosing and f ixing the dnn models.
deepdiagnosis provides a list of veri f ication procedures to automatically detect types of common symptoms.
our results show that deepdiagnosis can successfullydetect different types of symptoms and report actionable changes.
it outperforms the state of the art tool such as umluatanddeeplocalize anditisfasterthanautotrainer forfaultlocalizationand providesuggestions to f ix theissue.
wehaveidenti f iedseveralfutureworkdirections.first wewould like to extend our approach to support additional model types failure symptoms and automatic repair.
second we would like to conduct studies on how to improve dnn bug repair on nonfunctional bugs such as fairness bugs .
third we would liketoextendourapproachtosupportadditionaltypesofbugsin different stages of the ml pipeline .
lastly we would like toexplorehowtoleverageour f indingstoimprovetheperformance of automl models .
acknowledgment this work was supported in part by the us national science foundation nsf through grants cns and ccf .
all opinionsareoftheauthorsanddonotre f lecttheviewofsponsors.