scalable program clone search through spectral analysis tristan benoit benoit.tristan.info gmail.com universit de lorraine cnrs loria nancy francejean yves marion jean yves.marion loria.fr universit de lorraine cnrs loria nancy frances bastien bardin sebastien.bardin cea.fr cea list universit paris saclay saclay france abstract we consider the problem of program clone search i.e.
given a target program and a repository of known programs all in executable format the goal is to find the program in the repository most similar to the target program with potential applications in terms of reverse engineering program clustering malware lineage and software theft detection.
recent years have witnessed a blooming in code similarity techniques yet most of them focus on functionlevel similarity and function clone search while we are interested in program level similarity and program clone search.
actually our study shows that prior similarity approaches are either too slow to handle large program repositories or not precise enough or yet not robust against slight variations introduced by compilers source code versions or light obfuscations.
we propose a novel spectral analysis method for program level similarity and program clone search called programs spectral similarity pss .
in a nutshell pss one time spectral feature extraction is tailored for large repositories making it a perfect fit for program clone search.
we have compared the different approaches with extensive benchmarks showing that pssreaches a sweet spot in terms of precision speed and robustness.
ccs concepts security and privacy software reverse engineering malware and its mitigation .
keywords binary code analysis clone search spectral analysis introduction binary code similarity approaches identify similarities or differences between pieces of assembly code e.g.
basic blocks binary functions or whole programs .
we focus on program level similarities coined program similarity in the following that is computing a similarity index between whole programs which is capable of telling at which degree two programs are similar with potential applications in terms of reverse engineering program clustering malware lineage and software theft detection.
program clone search .
given a query composed of a target program and a repository the program clone search ranks repository programs by their program similarity to the target program.
the search is successful if the most similar program is a clone of the target program.
these clones may be i compiled with slightly different compiler chains or ii produced from a slightly different version of the source code or iii altered by slight obfuscations.
applications .
searching program clones between x86 or arm binaries over a large program repository is necessary when the original program written in source code is unavailable which happens with commercial off the shelf cots legacy programs firmwareor malware.
for example detecting malware clones is a major issue as most malware are actually variants of a few major families active for more than five years1.
another application is the identification of libraries which is both a software engineering issue and a cybersecurity issue due to vulnerabilities inside dynamically linked libraries.
the problem of library identification while in between programs and functions in terms of size is much closer to the case of program clones by its nature as libraries are not arbitrary collections of functions and require inter procedural analysis.
the situation is similar for patch and firmware analysis or software theft detection which also need to consider a global view of the code.
in all these cases we see function clone search as only a proxy to a problem that is by nature at the level of programs.
prior work .
given its potential applications and challenges the field of similarity detection has been extremely active over the last two decades starting from the pioneering work of dullien in on call graph isomorphisms and the popular bindiff tool for recognizing similar binary functions among two related executables.
other approaches include for example symbolic methods graph edit distances and matching techniques .
interestingly the last five years have seen a strong trend toward machine learning based approaches to binary function similarity .overall most prior work focuses on function clone search and function level similarity.
the challenges .
program clone search presents specific challenges compared to standard function similarity.
as already stated it requires comparing programs i.e.
much larger objects than functions hence similarity checks must be scalable in typical program sizes we do not consider two programs taken in isolation but a target program and a possibly large program repository hence the need for very efficient similarity checks that will be iterated over all the programs in the repository the repository could contain similar but slightly different programs due to variations in compilers or code versions.
clone search must be robust to such variations finally the technique must work equally well on stripped binary codes where symbols have been removed at compile time handle the case where external function names are unavailable for example iot device firmware and handle lightweight obfuscations such as adding deadcode or hiding literal identifiers .
all these constraints do not fit well with prior work on similarity as state of the art is increasingly focused on function level similarities2 with unclear scalability toward the program level case.
for example we found in our experiments that smit takes more than hours to compute a similarity index between the main library of geany and the cp command while deepbindiff is 2according to haq and caballero since among binary code similarity approaches only approaches have taken programs as input.
1arxiv .13063v3 aug 2023tristan benoit jean yves marion and s bastien bardin reported to take minutes to compute basic bloc matching on small binaries from the coreutils package.
goal .from the program clone search point of view there is a strong need for a binary level program level similarity technique that is precise robust to slight variation and fast enough to operate over large code bases.
this is exactly what we want to address in this paper.
our proposal .
we explore the application of spectral graph analysis to the problem of program clone search.
it seems a very good starting point as on graphs it is both affordable and competitive against graph edit distances ged in terms of precision while ged is arguably a very good but expensive to compute notion of graph similarity.
yet programs are not standard graphs on the one hand programs seen as graphs can be very large especially at the binary level while on the other hand they are highly structured due to their function hierarchy.
we take advantage of this specificity and propose program spectral similarity pss the first spectral analysis tailored to program similarity.
the techniques extract eigenvalues related features from both function call graphs and control flow graphs and take advantage of a preprocessing step done once for the whole program repository to achieve similarity checks in time linear in the number of functions of the program done for each program in the repository making it a perfect fit for program clone search most prior works have at least a quadratic runtime.
we experimentally show that pssoutperforms state of the art approaches and is resilient to code variations as well as lightweight obfuscations e.g.
instruction substitution bogus control flow control flow flattening .
moreover pssdoes not rely on literal identifiers e.g.
function names constant string values making it robust against a range of basic obfuscations.
in our experiments a program clone search with pss optimized version takes on average less than 3s .3s and .4s for linux and iot benchmarks where as a comparison the function embedding gemini requires roughly minutes per clone search.
we set up a strong comprehensive evaluation framework competitors and baselines to systematically compare psswith state ofthe art methods covering string based methods graph edit distance n grams vector embedding standard spectral methods and matching algorithms .
our experiments cover our own dataset of diverse open source projects along with classical coreutils diffutils findutils and binutils packages along two dimensions optimization levels and code versions for a total of programs.
moreover we consider part of the binkit dataset 98k samples covering four optimization levels compilers architectures and obfuscations.
finally we gather 959iot malware and 992windows goodware.
contribution .
as a summary we claim the following a novel technique named pss together with its optimizationpsso for code similarity section tailored to program clone search over large repositories.
pssis the first spectral technique tailored to program level similarity.
especially psstakes advantage of a preprocessing step to perform latter similarity checks in time linear w.r.t.
the number of functions in the program making it a perfect fit for program clone search over large repositories a comprehensive evaluation framework for program clone search section encompassing programs from binkit iot malware windows programs and a smaller linux dataset of programs and three baselines and 14state of the art methods 10of them being reimplemented.
the complete framework is available online which is rare in this field experimental evidence sections that pssreaches a sweet spot in terms of speed precision and robustness making it a perfect fit for program clone search where prior works in the field are more specialized to function level similarity evaluation.
especially pssappears to scale well and to retain good precision in demanding clone search scenarios cross compilers cross architecture or obfuscation finally as another notable result we show that prior work targeting function clones cannot cope with program clones due to scalability issues.
besides providing a novel and efficient method for program clone search our results also shed new light on prior work on code similarity.
first we make the case for the program clone search application scenario and show that it behaves differently enough than the well studied pairwise function similarity setting requiring dedicated methods.
second we are the first to pinpoint the separation in prior work between techniques using literal identifiers and those that do not.
as a side result during our experiments we identify two simple methods based on literal identifiers string values and external function names which despite their simplicity appear to perform well when these identifiers are available.
these methods came from the simplification of ideas coming from the state of the art in library identification by using literal identifiers .
third we show the potential of dedicated spectral methods for program clone search.
overall we believe that these results pave the way for novel research directions in the field.
research artifacts are available on zenodo .
problem statement .
program clone search procedure given an unknown target program pand a program repository r the goal is to identify a clone ofpinr.
a clone of a program pis defined as follows a programqcompiled from the same source code sasp but with a different compiler toolchain is a clone of p. for example phas been compiled with gcc v9.
using the optimization level o0 from the source code s andqhas also been built from susing the same compiler but another optimization level say o3 a programqcompiled from another version of psource code is a clone of p. for example both instances of the git application compiled from two source code versions say v2.
.
and v2.
.
are clones.
2scalable program clone search through spectral analysis in the last case we have to be a bit careful.
indeed we can only consider incremental versions of an application or library not major revisions that completely change the source code.
in our experiments the newest and oldest versions of most packages are usually separated by years.
however it goes up to years for the most standard packages coreutils diffutils and findutils.
unknown program similarity checksquery preprocessing features repository1 svn git cmp ........ .
.
.
.... similarity metricsvn figure architecture of a program clone search procedure figure illustrates a clone search procedure architecture.
note that all along we suppose that there is no exact copy of pin the repositoryr.
the repository is a database containing enough information for a clone search procedure.
as a result in practice a repository is quite an extensive program database w.r.t.
the application domain firmware plagiarism malware etc.
.
an evaluation of clone search procedures should take into consideration the three criteria below in order to be realistic the efficiency w.r.t.
both the size of the unknown target program and the size of the repository the robustness not only to compiler toolchains but also to slight program variations coming from different source code versions the ability to deal with stripped programs.
moreover external symbols are not necessarily available when dealing with firmware lightweight obfuscations or yet from payload extracted from packers .
as we said previously the main difference between program clone search and function clone search is the size of the binary codes which is much larger in the case of programs.
at a high level all program clone search procedures work in a similar way.
the repository is already built and the query process is divided into three steps query preprocessing.
upon query we receive the target programp.
we can perform some preprocessing at this step extracting relevant features for the rest of the procedure similarity checks.
for each program q r we perform a similarity check with a similarity metric mon p q possibly taking advantage of the preprocessing and record the computed similarity index m p q decision.
the program qbestwith the highest similarity index is considered the most similar.
the program clone search succeeds if qbestis a clone of p otherwise it fails.
.
motivating example let us consider a repository containing libraries obtained from the compilation of 20libraries3with four optimization levels five versions of gcc four versions of clang and to the and bits x86 3from packages libiconv coreutils libtool gss gdbm libtasn1 gsl libmicrohttpd osip readline gsasl lightning recutils gmp libunistring and glpk.table clone searches results framework average total runtime precision preprocess.
time included asm2vec .
35h gemini 17h safe .
160h diff 140h libdb 2h pss 26s includ.
26s of preprocess learning time not included platforms.
next let us imagine we have the libraries as targets compiled for x86 bits with gcc .
and the o2 optimization level .
lifting function level clone searches in order to detect programlevel clones is attractive.
however to obtain a similarity index between two programs from function embedding methods we need to find a distance between two sets of function embeddings.
letembeds p be the set of function embeddings of a program p. a first solution is to perform a matching between the two sets.
such matching could be an instance of the assignment problem where assigning a function embedding xofpto a function embedding y ofp has a cost x y .
however this problem has complexity o n3 wherenis the number of functions.
we relax the matching so that a function embedding of a program pcan be assigned to multiple function embeddings of a program p .
we definefas the similarity metric for an embedding embeds f p p x embeds p min y embeds p x y we consider the following function level methods and lift them to programs as just explained asm2vec gemini safe diff .
we also consider libdb which is directly designed for libraries i.e.
large pieces of code .
results .
we report in table the average precision equivalent to the proportion of successful clone searches as well as clone searches total runtime.
pssis precise and successful in all clone searches.
most function level methods can also find a clone in all clone searches.
however psstakes only 26s in total while pure function embedding methods take from 17h with gemini to 160h with safe .
even with pre filtering libdb is close to 2h.
moreover pssruntime is due to its preprocessing the total similarity checks runtime is negligible.
as a result pssscales up to large repositories with good precision.
3tristan benoit jean yves marion and s bastien bardin background graph similarity ged and spectral distance .
as programs can be naturally seen as graphs any good notion of graph similarity is in principle a good candidate for a good program similarity metric.
graph edit distance ged is such a good notion .
ged is the smallest cost of an edit path between two graphs i.e.
the smallest transformation going from one of the graphs to the other.
graph edit operations typically include removing or adding a vertex or an edge.
yet the main drawback of ged is that its computation is nphard.
worst usual approximations have a complexity of o n3 wherenis the number of nodes in the graph which is far too expensive for graphs coming from programs.
as an example the graph edit distance method smit is the slowest method we have tested cf.
table with hours of computation on a task where our method takes 1h18m.
the spectral distance between graphs provides an interesting trade off as it gives a decent approximation of the graph edit distance between graphs for an affordable linear cost once eigenvalues are computed.
we introduce spectral analysis and define spectral distance hereafter.
spectral graph analysis .
spectral graph analysis is a method used to investigate properties of graphs by studying the eigenvalues or spectrum of standard matrices associated with the graph such as the adjacency matrix or the laplacian matrix.
patterns and structures within the graph can be identified providing key insights about how the graph nodes are interconnected.
distances between graph spectra are called spectral distances.
the starting intuition for using graph spectrum is that two isomorphic graphs have the same spectrum however the converse is not true.
nevertheless the spectrum may be used as a proxy for graph similarities.
more formally an undirected graph g v e ofnvertices is represented by an n nadjacency matrix a whereai jis one if vi vj eand zero otherwise.
let dibe the degree of the vertex vi.
it is useful to compute the laplacian matrix lof g. an eigenvalue and its corresponding eigenvector uis a solution to the equation l i u .
the spectrum is the set 1 g ... g g where 1 g ... g g and where g is the number of vertices ing.
the enhanced lanczos algorithm computes the spectrum in time o dn2 wheredis the average degree of g. we define the spectral distance between g1andg2 analogous to sd g1 g2 min g1 g2 i i g1 i g2 .
program spectral similarity pss spectral analysis is suitable for comparing graphs because it provides quantitative metrics such as spectral distances which can be used to compare key graph properties regarding connectivity structure and distribution.
this approach also allows for the normalization of graph size enabling fair comparisons among varying graph scales.
however computing the spectrum of a graph is cubic in its number of nodes.
therefore applying spectral analysis to a whole program cfg is too expensive.
moreover the cfg itself is not stable with respect to compiler toolchains optimizations and obfuscations.
as a result our key insight is that a program has more structure than a mere graph there is a call graph over functions while localfunctions hold their own control flow graph.
we take advantage of this hierarchical structure to devise a quick and stable similarity metric called program spectral similarity pss .
the pssmethod is based on the combination of two criteria.
the first measure is the spectral distance between call graphs including both internal and external calls4.
moreover most compiler optimizations have a small scale effect on the call graph as they only impact the content of functions the second measure is a coarse spectral analysis of function control flow graphs simply considering their number of edges as it is related to the sum of the eigenvalues as shown below.
since we use only one number to represent a function cfg we can fit these numbers into a vector comparable to the eigenvalues vectors.
adding function embeddings to the second measure is left for further work.
by the way we tried to consider only the control flow graphs and we found that the results were worse than when both above criteria were considered.
the pssmethod proceeds into two independent steps the preprocessing step which is done once and for all and the similarity check step which is made for each candidate.
.
preprocessing .mempcpy mempcpymain sub 403780 .exit.bindtextdomain sub 402380 .setlocale .getopt long .
fprintf chk figure a call graph given a program p the preprocessing first begins by building the function call graph cgofp including local and external api calls.
an example of a function call graph is given in figure .
it contains external calls such as a call to mempcpy as well as local functions such as sub 403780 .
from this we extract two key vector features v w ofpas follows from an undirected version of the call graph cg we compute the spectrum 1 cg ... n cg and we compute v the normalized spectrum of the call graph we compute the number of edges e e1 e2 ... ek from each control flow graph fiof local functions in descending order and we normalize eas previously w e e .
external functions are ignored at this step since we do not have access to their control flow.
note also that the number of edges is a simple sort of spectral measure since it is related to the spectrum by the relation ei j fi .
recall that 2is the euclidean norm.
we normalize features vand wto deal with differences between program sizes.
4call graphs are useful for a number of tasks.
for example graphevo has been able to understand software evolution through call graphs.
4scalable program clone search through spectral analysis .
similarity check given two programs p0andp1 the preprocessing step has computed features v0 w0 fromp0 and v1 w1 fromp1.
the similarity check outputs a similarity index by averaging two measures.
the first measure is related to call graphs while the second is related to function control flow graphs.
then the similarity metric pssis defined as the average of both above measures equation .
simcg p0 p1 vuutmin v0 v1 i v0 i v1 i simcfg p0 p1 vuutmin w0 w1 i w0 i w1 i pss p0 p1 simcg p0 p1 simcfg p0 p1 .
the psso optimization we found out that psspreprocessing may be quite long over large programs cf.
our own windows dataset in section .
where computing all eigenvalues of a call graph takes .95seconds per program clone search.
.
in order to tackle this issue instead of computing the complete spectrum we propose to compute only the firstkgreater eigenvalues so that 1 cg ... k cg .
for this we can take advantage of a variant of the lanczos algorithm proposed by the arpack library .
we plot in figure the preprocessing runtimes and precision scores see section .
for different values of kfrom to on our windows data set .
we remark that runtimes grow quickly withk going from .06s to .31s.
on the other hand there is little change in the precision score between and the score varies from .
to0.
.
we select 100as the value for ksince the preprocessing runtime per clone search is only .39s and the precision score is already .
.
we thus propose psso an optimized version of pssthat computes only the first k 100greater eigenvalues.
.
method runtimes recall that a repository is a database of preprocessed programs.
a given unknown target program is first preprocessed then from the extracted features a similarity check is made on the repository.
it is clear that the query runtime linearly depends on the size of the repository.
in other words for a repository size of m andnthe number of functions inside a program if the runtime of a similarity check ist n and the preprocessing runtime is pt n then the complexity of a query is bounded by m t n pt n .
as a result all methods with similarity checks with superlinear time complexity are not feasible over large repositories of large codes which is confirmed by our experiments.
pssandpssoruntimes .
graphs and laplacian matrices are sparse in our application domain offering quick eigenvalues computation.
nevertheless the complexity of the query prepossessing described in section .
is still o dn2 wherenis the number of functions anddis the average number of calls per function.
however once figure impact on the windows dataset of the number of largest eigenvalues computed by pss optimized version table complexity of program clone search procedures method class similarity preprocess.
check smit ged o n4 o dn cgc matching o n4 o dn mutantx s n gram o o i asm2vec functions ml o n2 o n gemini functions ml o n2 o n safe functions ml o n2 o n diff functions ml o n2 o n libdx strings o s o s libdb functions ml o n2 s o n s and strings deepbindiff ml o n3m3 no preproc.
pss spectral o n o dn2 psso spectral o n o dn n functions i instructions s constant string values d calls per function m basic blocks in a function between two programs performed once for the whole clone search such prepossessing is done the runtime of a similarity check described in section .
is o n .
moreover the runtime of the query preprocessing of pssois reduced to o dn .
comparison with prior work .
that is in contrast with function embedding methods which have a similarity check runtime of o n2 on this problem using a direct adaptation see section .
for further details .
moreover deepbindiff contains a step with a linear assignment between basic blocs with a runtime of o n3m3 .
worse both the graph edit distance approximation smit and the matching method of xu et al.
have a complexity of o n4 .
however the runtime of mutantx s designed to scale up to large repositories is only o yet experiments tables and in section .
show that its robustness is not fully satisfactory.
5tristan benoit jean yves marion and s bastien bardin systematic evaluation we evaluate the potential of pssin terms of speed precision and robustness the ability to overcome changes in compilation.
then we consider here the following research questions rq1 what are the fastest methods for clone search?
rq2 what are the most precise methods for clone search?
rq3 what are the most robust methods for clone search?
rq4 what is the impact of each component of pss?
.
datasets basic dataset .
we first collect a limited dataset of 950programs to study the full range of methods along different optimization levels and code versions.
the average program has a size of 442kb.
this dataset covers the coreutils diffutils and findutils packages compiled with gcc v5.
on the x86 architecture and taken from the deepbindiff dataset.
moreover we add the binutils package as well as open source projects including bash code blocks dia graphviz geany git lua make openssh openssl perl ruby sdl svn and vlc compiled by gcc v9.
on an x86 architecture.
each unique source code comes in four different version levels and four different optimization levels .
these programs are all clones of each other.
binkit dataset .
to study scalable methods along different optimization levels compilers architectures and obfuscations we reuse two linux programs datasets from binkit normal from gnu software packages unique source codes were extracted.
they are compiled with different toolchains for a total of programs of an average size of 201kb.
it covers eight architectures arm x86 mips and mipseb each available in and bits nine compilers five versions of gcc and four versions of clang and the four optimization levels from o0 to o3 obfuscation four obfuscation options instruction substitution sub bogus control flow bcf control flow flattening fla and all combined are considered using obfuscator llvm as a compiler.
the same architectures and optimization levels as before are covered for a total of programs of an average size of kb .
iot malware dataset .
we consider iot malware samples with an average size of 84kb from malwarebazaar5 submitted between march and may spanning architectures mostly arm mips motorola and sparc .
using available meta data from antivirus reports and yara rules we split the data into only three families of clones mirai gafgyt and tsunami.
windows dataset .
we assemble a dataset of benign programs running under windows operating systems x86 visual studio .
this amounts to more than 50gbof raw programs with an average size of 771kb.
excluding security updates the dataset contains more than dynamic link libraries.
samples are divided by target platforms e.g.
windows .
we consider that two programs sharing the same file name and the same target platform are clones yielding programs with a clone.
methodology atest field t r comprises targets set tand a repository r. we break down basic datasets along version levels and optimization levels.
for instance the test field o0 o1 of the subdataset coreutils option consists of a repository of coreutils programs compiled with o1 paired with the same programs but compiled with o0 as targets.
similarly we break down binkit datasets along optimization levels compilers architectures and obfuscations.
measures of success precision .
program clone search is an information retrieval task.
the standard evaluation metrics of information retrieval are precision and recall.
this study uses the evaluation metric described in the asm2vec paper that is precision at position precision .
precision is equal to one if and only if a clone of the target is the most similar program in the repository as ranked by a similarity metric.
we define the precision score of a similarity metric as the average precision for every target in every test field against a repository.
.
competitors we evaluate competitors baselines and two new heuristics based on literal identifiers constant string values and external function names cf.
table .
of these frameworks have been adapted a to the case of program clone search as it was not their primary objective e.g.
function embedding .
moreover had to be reimplemented r because the original implementation was unavailable or due to inherent challenges in effectively utilizing the original implementation within the specific domain of clone search.
as highlighted by marceli et al.
code similarity artifacts are rarely available and even when they are they are often incomplete.
baseline .
we first investigate basic heuristics such as bsize the size of the program and dsize the size of the disassembled program.
for instance the similarity metric bsizeis defined as bsize a b a b whereaandbare program sizes in bits.
we also consider a crude shape of the call graph.
let n1ande1 respectively n2and e2 be the number of vertices and edges of the first respectively second call graph.
then the similarity measure shape is defined as shape n1 e1 n2 e2 min n1 n2 max n1 n2 min m1 m2 max m1 m2 standard spectral methods .
from the spectral method developed by fyrbiak et al.
we derive two methods.
the first ascg a r is based on the call graph.
let xandybe the two spectrums in descending order of laplacians of the two call graphs.
there is a normalization x x x0andy y y0.
then ascg x y min x y i x i y i likewise we derive a method based on the control flow graph ascfg a r .
instead of computing the spectrum from the call graph we select the top eigenvalues from a reduced control flow graph as vectors xandy.
graph edit distance .
we implement various basic ged based methods.
first we implement ged a r a basic computation of the ged applied between call graphs.
the algorithm goes back to the work of sanfeliu and fu .
second we implement ged l a r a computation of the ged between call graphs with labels.
6scalable program clone search through spectral analysis the algorithm is presented by fyrbiak et al.
.
in our application labels are sets of external function names.
third we implement the specific ged computation of hu et al.
called smit r .
we do not integrate the indexing tree of smit as we are more interested in their ged measure.
matchings .
we compare with the matching algorithm cgc r from xu et al.
.
this algorithm needs three parameters along with a complete classification of mnemonics.
we perform preliminary works to find good values for these parameters.
table methods included in the evaluation framework class arsimilarity lir check bsize baseline o dsize baseline o shape baseline o ascg spectral o n ascfg spectral o ged ged o n3 mutantx s n gram o asm2vec function ml o n2 gemini function ml o n2 safe function ml o n2 deepbindiff ml o n3m3 pss spectral o n psso spectral o n ged l ged o n3 smit ged o n4 cgc matching o n4 diff function ml o n2 libdx strings o s libdb strings and o n2 s function ml stringset strings o s functionset strings o n a adapted for program clone search r reimplemented lir some literal identifiers are required n gram .
we reproduce mutantx s r from the work of hu et al.
.
we extended it to multiple architectures.
each program is represented by the frequencies of grams obtained from the opcode sequence.
these frequencies are embedded into a dimension vector by hashing.
function embeddings .
as previously we use the similarity metric fto compare sets of vector embeddings refer to equation in section .
.
we first consider asm2vec a .
we employ an unsupervised training strategy on the basic dataset inspired by the original paper.
multiple training phases are performed with each time one optimization level for training and one for testing.
then we take gemini a embedding from xu et al.
in an optimistic setting.
we build a version of the basic dataset retaining function names and employ these as ground truths for training.
moreover we use the embedding of massarelli et al.
with safe a .
we downloaded a pre trained model made available by one ofthe authors6.
lastly we reproduce diff a r from the framework of liu et al.
.
it is tailored to binary function similarity between versions.
we sample of the diff dataset7as our training set.
diffincorporates external function names and in out degrees in the call graphs.
deepbindiff .
the framework deepbindiff from duan et al.
attempts to match basic blocs between two binaries.
the similarity metric computes the number of matched basic blocs by deepbindiff between two programs.
due to its runtime we were unable to perform experiments and it is only considered inside the preliminary evaluation.
libdx .
we reproduce the framework libdx r from kim et al.
.
it extracts constant string values from well defined read only sections of programs.
constant string values are compared with matchings and the tf idf statistic.
libdb .
we reproduce the framework libdb r from kim et al.
.
they combine function embeddings and matchings while using constant string values as pre filters.
we reimplemented libdb with our trained gemini model and scann as the nearest vector search engine.
function set method .
xu et al.
describe a simple method that first matches functions between two programs by using only external function names and mnemonics similarities.
then the similarity measure is computed by a distance over the two function sets.
we simplify this idea and invent the similarity metric functionset which computes the jaccard similarity index8between external function names.
let fabe the external function names set of a programa.
the similarity metric is functionset a b fa fb fa fb .
string set method .
we invent a straightforward metric that compares constant string values inside programs.
let sabe the set of all constant string values of a program a. the similarity metric is stringset a b sa sb sa sb .
we present in table the characteristics of the different methods considered here.
we record the runtime complexity of a similarity check between two programs.
we note with n m ands the number of functions basic blocs in a function cfg and literal identifiers respectively.
we indicate whether a method requires literal identifiers.
note that machine learning approaches require a learning phase andgemini andgcg require manual mnemonics classification.
implementation .
disassembly is implemented by running the ida pro disassembler v7.
along with a script from the kam1n0 assembly analysis platform9.
see the recent survey of pang et al.
on disassembling for more details.
our experiments are run on a cloud server node containing two cpus with a frequency of .
ghz and cores per cpu.
all reported runtimes are equivalent to runtimes using only one core.
7tristan benoit jean yves marion and s bastien bardin table rq0 total runtimes on the basic dataset bsize 1h30m dsize 1h30m shape 1h30m ascg 1h30m mutantx s 1h30m pss 1h30m psso 1h30m libdx 1h30m stringset 1h30m functionset 1h30mascfg 128h ged 81h ged l 46h smit 3634h cgc 171h asm2vec 141h gemini 102h safe 655h diff 642h libdb 16h fast methods selected for further analysis learning time not included .
preliminary evaluation method selection first we want to identify methods unable to scale to large benchmarks in order to not consider them in further analysis.
we perform a speed assessment on the basic dataset of programs and remove the methods unable to achieve it in less than 1h30m.
results .
results are presented in table .
please note that we could not experiment on deepbindiff with an observed average of more than minutes per similarity check we estimate that it would have taken more than 000h to apply it to the whole basic benchmark and the training time of ml based methods is not counted in the reported timing.
results show a significant dichotomy between methods of them being able to succeed in less than 1h30m often far less while the other ten methods require far more time from 16h to 3634h .
conclusion .
this preliminary experiment shows that functionlevel clone search methods typically based on ml or graph edit distance approaches cannot scale to program level clone search.
in the following we will consider only the scalable enough methods namely our three baselines bsize dsize shape as well as ascg mutantx s libdx and our own pss psso stringset andfunctionset .
.
rq1 evaluation of speed we report in table the runtimes and the preprocessing time on each dataset to be fully comprehensive.
basic .
on the basic dataset containing programs our method is the slowest and takes 1h18m.
nearly everything is spent during the prepossessing.
the adapted spectral method for call graph ascg has similar runtimes.
pssotakes only 15m8s the optimization dividing the runtime of pssby more than .
libdx takes 1m4s and stringset 38s.
the n gram method mutantx s and the functionset method are very fast and take less than ten seconds.
binkit .
on the binkit dataset which contains programs of an average size of ko psstakes 190h psso116h and mutantxsis slower with 220h.
with literal identifiers libdx andstringset are much slower 1965h and 542h resp.
.
functionset is fast 37h .
iot malware .
on the iot dataset containing iot malware psstakes only 2h9m.
it is faster than mutantx s 3h34m .
surprisingly pssois a bit slower than pssand takes 2h12m.
amongtable rq1 total runtimes.
include preprocessing time.
significant preprocessing times reported in .
dataset basic binkit iot windows programs 1k 98k 20k 85k bsize 6s 43h 47m 8h41m dsize 5s 43h 47m 8h45m shape 1m22s 21h25m 21m26s 4h16m ascg 1h18m 143h 1h23m 243h preproc.
1h18m 81h 19m12s 228h mutantx s 4s 220h 3h34m 41h pss 1h18m 190h 2h9m 263h preproc.
1h18m 81h 16m42s 233h psso 15m8s 116h 2h12m 31h29m preproc.
15m6s 14h3m 33m3s 5h23m libdx 1m4s 1965h 7h47m 170h stringset 38s 542h 9h21m 253h functionset 3s 37h 7m47s 27h34m table rq1 runtimes per clone search sec .
include preprocess.
time.
significant preprocess.
times reported in .
dataset basic binkit iot windows programs 1k 98k 20k 85k bsize .
.
.
.
dsize .
.
.
.
shape .
.
.
.
ascg .
.
.
.
.
.
.
.
mutantx s .
.
.
.
pss .
.
.
.
.
.
.
.
psso .
.
.
.
.
.
.
.
libdx .
.
.
.
stringset .
.
.
.
functionset .
.
.
.
methods using literal identifiers functionset is fast with less than minutes in total.
libdx takes 7h47m while stringset is the slowest with 9h21m.
windows .psstakes 263h on the windows dataset.
that is far higher than mutantx s 41h and a bit higher than stringset 253hh .
however pssotakes less than 32hours.
table reports average runtimes per clone search.
we can see that psspreprocessing time can sometimes be important e.g.
on large windows binaries .95s on similarity checks .
first note that preprocessing time does not increase with the repository size.
second pssois especially optimized for such cases and its preprocessing time remains low in all cases.
conclusion rq1 pssis often roughly as fast as mutantx s on larger datasets yet it struggles on large windows programs.
pssoremedies this default and is consistently faster than other approaches but the baselines and functionset .
interestingly stringset is slow on large benchmarks.
8scalable program clone search through spectral analysis table rq2 precision scores dataset basic binkit iot windows bsize .
.
.
.
dsize .
.
.
.
shape .
.
.
.
ascg .
.
.
.
mutantx s .
.
.
.
pss .
.
.
.
psso .
.
.
.
libdx .
.
.
.
stringset .
.
.
.
functionset .
.
.
.
random .
.
.
.
.
rq2 evaluation of precision we compute precision scores on each dataset.
we report the results in table .
binkit .pssandpssoattain a score of .619on binkit while the other spectral method ascg has only .
.mutantx s is well behind with .
.
in fact we show in table that it achieves scores of .01in cross architecture scenarios as well as against obfuscations.
with literal identifiers stringset attains .970and libdx .
.
the functionset method has only a score of .
.
iot malware .psshas a score of .
close to mutantx s .
.
pssois very close with .
while ascg attains .
.
with literal identifiers stringset achieves a score of .
.
other literal identifier methods have some troubles.
functionset has a score of .644because only very few external names are available.
moreover libdx attains .707because libdx extracts constant string values from read only sections which are scarce inside iot firmware.
windows .pssattains a score of .475on windows just above mutantx s .
and well above ascg .
.pssois a bit behind pssandmutantx s with .
.
among methods with literal identifiers stringset attains .
.libdx attains only .
.
again libdx extracts constant string values from well defined read only sections which are not prevalent in windows programs.
as before functionset has a rather low score here of only .
.
conclusion rq2 pssandpssoare usually as precise as mutantx s except in cross architecture and obfuscations scenarios for which mutantx s fails.
when literal identifiers are meaningful stringset is the most precise method in all datasets while functionset andlibdx struggle on iot and windows datasets.
.
rq3 evaluation of robustness the last evaluation measures the robustness of the ten clone search methods that survived the speedtest.
for this we consider four scenarios with i cross optimization ii cross compiler iii crossarchitecture and iv in the presence of obfuscations.
the evaluation leans on the binkit dataset that we presented earlier.results .
we report the most crucial test field scores in table .
when literal identifiers are available stringset andlibdx are very stable in all scenarios.
functionset is stable except in scenarios involving cross architecture because external function names differ between architectures.
note that a strong limitation to this finding is that the considered obfuscations do not hide nor encrypt literal strings and external calls api while it is common practice.
pssandpssoare much more robust than mutantx s in crossarchitecture cross optimization and obfuscations scenarios.
for instance mutantx s falls to .02from the arm to mips architecture while pssmaintains a score of .
.
the more basic spectral method ascg also falls to .08in this scenario.
interestingly pssandpsso perform better in the cross architecture test fields than in the o0 o3 and o0 o2 test fields.
we hypothesize that while the architecture does not impact that much the produced call graph advanced optimizations do function inlining is precisely turned on by the o2 optimization level in both gcc and clang.
statistical analysis .
a common pitfall of similarity detection is that a method could in the end consider as similar two programs based on some side aspects e.g.
architecture compiler used or optimization version irrelevant from the clone search point of view.
we evaluate the sensitivity of the different approaches to such bias by computing rank biserial correlations between a similarity rank in new clone searches and b sharing an optimization level.
we report average correlations in table the lower the better and less sensitive .
pss psso ascg andlibdx have very small correlations of less than .
.
on the other hand the stringset method correlation is moderate .
indicating some bias.
surprisingly this bias does not seem to impact the robustness of stringset .
the n gram method mutantx s has a lower correlation of .33andfunctionset has a small correlation of .
.
conclusion rq3 pssandpssoare robust to cross optimization cross compiler cross architecture and obfuscations scenarios while mutantx s suffers significant precision loss in the cross architecture and obfuscations cases.
.
rq4 ablation study in table we report the precision scores of the two components of pss simcg and simcfg .
the first is a comparison between eigenvalues of the call graph while the second is a comparison between the number of edges of functions control flow graphs.
pss always attains a higher precision score than simcg andsimcfg on every dataset.
we remark that simcfg alone is not precise on the windows dataset .163vs.
.459forsimcg .
in table we report each component s average runtimes per clone search.
as expected pssruntimes are the addition of simcg and simcfg runtimes.
therefore pssis at worse one second slower than simcg .
conclusion rq4 pssis more precise than its components for the price of a slight increase in runtimes.
9tristan benoit jean yves marion and s bastien bardin table rq2 rq3 precision scores on the binkit dataset category optimization level cross compiler cross architecture vs. obfuscation o0 o0 o0 o1 o1 o2 gcc clang clang arm arm mips vs. o1 o2 o3 o2 o3 o3 gcc clang gcc mips x86 x86 bcf fla sub all bsize .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
dsize .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
shape .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
ascg .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
mutantx s .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
pss .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
psso .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
libdx .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
stringset .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
functionset .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
random clone search results in a precision score inferior to .005on all test fields.
the binkit dataset does not consider any obfuscation of literal identifiers table rq3 average rank biserial correlation for h framework basic dataset bsize .
dsize .
shape .
ascg .
mutantx s .33framework basic dataset pss .
psso .
libdx .
stringset .
functionset .
table rq4 components precision scores dataset basic binkit iot windows simcg .
.
.
.
simcfg .
.
.
.
pss .
.
.
.
table rq4 components runtimes per clone search sec .
include preprocess.
time.
significant preprocess.
times reported in .
dataset basic binkit iot windows simcg .
.
.
.
.
.
.
.
simcfg .
.
.
.
pss .
.
.
.
.
.
.
.
table informal summarized comparison method speed precision robust.
beware ascg mutantx s pss psso libdx str.
extraction str.
obf.
stringset str.
obf.
functionset fun.
name obf.
static linking5.
summary of our main results our novel spectral methods pssandpssoreach a sweet spot regarding the trade off between speed precision and robustness.
they do not need any training phase scale very well to large repositories and are very robust even in cross architecture or cross compiler scenarios and in case of lightweight obfuscation.
therefore they are the best candidates for intensive program clone search.
also it is worth mentioning that direct adaptations of graph based spectral methods lack precision compared to pss and that the optimization pssois necessary over large programs.
a summarized informal comparison with other methods is given in table .
this large study also allowed us to highlight that most prior approaches in the field mostly focused on functionlevel similarity are far too slow for program clone search.
related works binary code similarities are extensively studied.
as a testimony the review of haq and caballero reports numerous input and output granularities on which to study similarities.
pioneering approaches .
dullien in introduced a graph based program diffing approach that constructs a call graph isomorphism.
a follow up extended it to match basic blocks inside matched functions.
these two results are the basis for the popular bindiff program diffing plugin for the ida disassembler.
bindiff aims to recognize similar binary functions among two related executables.
in kruegel et al.
presented an approach based on coloring small graphs with fixed size from the control flow graph to identify structural similarities between different worm mutations.
in gao et al.
proposed binhunt to find differences between two versions of the same program.
binhunt employs symbolic execution with a constraint solver to prove that two basic blocks implement the same functionality.
program similarity .
the few recent works about program level similarity have already been thoroughly discussed.
still we can mention a few more approaches.
n gram methods compare instruction sequences .
while we could have employed more fine grained methods than mutantx s for 10scalable program clone search through spectral analysis example expos considers trigrams inside a function matching it quickly leads to serious scalability issues.
some other works explore similarities based on dynamic executions and input output observations .
nevertheless it is hard to thoroughly explore the execution space with dynamic traces leading to poor precision and handling large code repositories requires automating the task of detecting the sources of input and output of all programs in the repository which can be very complicated.
bruschi et al.
tackle the problem of detecting some malware inside a program by matching control flow graphs.
but again this approach suffers from scalability issues in the size of the programs and is thus not amenable to the search over large code repositories.
the symbolic method by luo et al.
is robust to simple obfuscations as well as simple changes.
however the running time of symbolic execution is a critical issue on large programs and anti analysis obfuscation hinders symbolic approaches .
we have already studied the matching method cgc .
the complex matching by xu et al.
outperforms a baseline based on external function names and mnemonics.
however we propose stringset a faster highly precise method comparing sets of constant string values.
a few other matching approaches share the same strengths and weaknesses.
function similarity .
the last five years have seen a tremendous increase in the popularity of binary function similarity with machine learning .
yet as already discussed these methods lead to poor scalability when applied to a program similarity setting.
more expensive methods than function embeddings do exist.
notably dynamic analysis seeks to build upon the semantics of binary codes instead of their mere structural properties.
bingo analyzes various execution traces with concepts such as pruning.
the work of hu et al.
emulates binary functions to create semantic signatures.
pewny et al.
propose to translate binary code to an intermediate representation.
this representation allows observing inputs and outputs of basic blocs.
these frameworks suffer from the already mentioned pitfalls of dynamic execution the exploration is either imprecise or very slow.
furthermore it is unclear how to lift these methods to the case of program similarity as comparing all functions between multiple codes is costly.
built on the idea of intermediate representation several approaches perform simplification before comparing.
in firmup the matching between intermediate representations incorporates multiple functions.
the formula has to be transformed into an embedding.
the larger the code segment it represents the less precise the embedding is.
finally other feature selection methods have been investigated rendez vous extracts statistical features at various granularities while discovre and genius extract features such as the number of arithmetic instructions.
gemini leverages static features from genius into a machine learning framework.
source code similarity .
computing source similarities can be performed with different structures such as abstract syntax trees or program dependency graphs .
it is also possible to normalize instructions and compare code fragments .
matching tokens fragments and structures is effective because there is no compiler optimization step which would introduce variations.
moreover critical information such as types are lost by compilation while data dependencies are harder to retrieve on binary programs.graph similarity .
a key question in program similarity is how to compare graphs efficiently.
new suggestions for graph similarities include novel graph kernels and the use of machine learning to approximate intractable properties such as graph edit distance .
recently the work of bay ahmed et al.
introduced a new graph similarity metric incorporating both spectral information from the adjacency matrix and from the laplacian.
moreover the work of crawford et al.
proposed spectral analysis as a similarity metric of real world networks.
furthermore the study of fyrbiak et al.
reveals that spectral analysis can compete with more energy intensive approaches such as ged.
library identification .
the pioneering bat has proposed three methods for library identification based on strings compression algorithms and edit distances between bit sequences.
they report that edit distance computations are too costly while strings can be easily obfuscated.
osspolice has developed similarity measures based on strings.
the special structure of java programs allows the use of properties such as class and package inclusions in order to identify android libraries.
discussion and limitations while pssandpssoperform well in our experiments there are still a number of potential corner cases that must be considered.
generally speaking these methods will suffer on program clones with very different call graphs.
such differences could come for example from significant source code revisions it is why we support only incremental changes of an application or library or from aggressive inter procedural compiler optimizations such as function inlining or function sharing link time optimizations may be a growing problem here or from aggressive inter procedural obfuscation schemes such as function merging or virtualization.
also as the programs we consider mainly come from c c source codes it would be interesting to evaluate all the considered methods over programs written in emerging programming languages e.g.
rust go that may contain language specific function call patterns.
conclusion we consider the problem of searching program clones in large code repositories.
while most prior works have been devoted to function clones the few existing techniques for program similarity suffer either from scalability issues low precision or low robustness to code variations.
we propose a novel method called program spectral similarity pss and especially its optimized version psso that reaches a sweet spot in terms of speed precision and robustness even in cross compiler or cross architecture setups.