trans regex multi modal regular expression synthesis by generate and repair yeting liyx shuaimin lix zhiwu xu jialun caoz zixuan chenyx yun hu x haiming cheny shing chi cheungz ystate key laboratory of computer science institute of software chinese academy of sciences beijing china xschool of computer science and technology university of chinese academy of sciences beijing china college of computer science and software engineering shenzhen university shenzhen china zthe hong kong university of science and technology hong kong china science technology on integrated infomation system laboratory institute of software chinese academy of sciences beijing china yfliyt chenzx chmg ios.ac.cn xlishuaimin17 mails.ucas.ac.cn xuzhiwu szu.edu.cn zfjcaoap sccg cse.ust.hk huyun2016 iscas.ac.cn abstract since regular expressions abbrev.
regexes are difficult to understand and compose automatically generating regexes has been an important research problem.
this paper introduces t rans regex for automatically constructing regexes from both natural language descriptions and examples.
to the best of our knowledge t rans regex is the first to treat the nlp and example based regex synthesis problem as the problem of nlp based synthesis with regex repair.
for this purpose we present novel algorithms for both nlp based synthesis and regex repair.
we evaluate t rans regex with ten relevant state of theart tools on three publicly available datasets.
the evaluation results demonstrate that the accuracy of our t rans regex is .
.
and .
higher than that of nlp based approaches on the three datasets respectively.
furthermore trans regex can achieve higher accuracy than the stateof the art multi modal techniques with to higher accuracy on all three datasets.
the evaluation results also indicate trans regex utilizing natural language and examples in a more effective way.
index terms regex synthesis regex repair programming by natural languages programming by example i. i ntroduction as a versatile mechanism for pattern matching and searching regular expressions abbrev.
regexes have been widely used in different fields of computer science such as programming languages natural language processing nlp and databases due to the high effectiveness and accuracy .
unfortunately despite their popularity regexes can be difficult to understand and compose even for experienced programmers .
to alleviate this problem prior research has proposed techniques to automatically generate regexes.
for example several techniques generate regexes from natural language nl descriptions while others synthesize regexes from examples .
though these techniques help lessen the difficulties of automatic regex synthesis they have obvious drawbacks as follows.
corresponding author.existing nlp based techniques can only generate regexes similar in shape to the training data and have relatively low accuracy on simple benchmark datasets e.g.
s oftregex achieved only .
accuracy on benchmark nl rx turk .
furthermore nlp based techniques are impeded by the ambiguity and imprecision of nl even for stylized english .
for example according to among incorrectly predicted regexes over .
are caused by ambiguity of nl descriptions and .
are from imprecision.
additionally zhong et al.
found that nlpbased techniques may not make correct prediction if words in these nl descriptions are not covered by the training data.
on the other hand the example based synthesis approaches rely on high quality examples provided by users.
the synthesized regexes may be under fitting or over fitting when the given examples do not meet the implicit quality requirements e.g insufficient or not characteristic enough .
however examples with high quality are often unavailable in practice.
it poses difficulties in applying purely example based approaches.
in addition these approaches have severe restrictions on the kinds of regexes that they can synthesize e.g.
absence of kleene star limited character occurrences or constraining to binary alphabet .
therefore to better synthesize regexes it would be ideal to take advantage of both nl and examples called nlp andexample based synthesis or multi modal synthesis the use of advanced nlp based techniques can reduce the amount of required characteristic examples meanwhile alleviate the amount of effort from users while the use of examples can effectively disambiguate or correct errors in the descriptions.
further a survey on posts on regex synthesis shows that many programmers actually use nl descriptions as a major resource and leverage some example s to resolve the ambiguities of nl .
on the other hand insufficient characteristic examples limit the generalization ability of example based approaches while incorporating nl can improve the generalization ability and help to drastically narrow down the ieee acm 43rd international conference on software engineering icse .
ieee search space .
actually there have been recent attempts in this direction in which they first translated the nl description into a sketch1 then searched the regex space defined by the sketch guided by the given examples.
however the forms of translated sketches are restricted.
this prevents regexes from being synthesized correctly when the generated sketches are inappropriate e.g.
logically incorrect .
in such a case the incorrectness will be inherited from sketches to the subsequent regex.
moreover while these works have achieved relatively high accuracy on simple datasets they did not perform well on complex and realistic datasets.
in latter datasets the nl descriptions are longer more complicated and describe the regexes which are more complex in terms of length and tree depth .
we observe that most of the incorrect regexes generated by nlp based techniques are very similar to the target regexes with subtle differences and can be made equivalent2to the target regexes with only minor modifications e.g.
reordering revising characters or quantifiers .
this motivates us to view the nlp and example based regex synthesis problem as the problem of nlp based synthesis with regex repair and develop the first framework t rans regex to leverage both nl and examples for regex synthesis by using nlp based and regex repair techniques.
t rans regex uses an nlpbased synthesizer to convert the description into a regex.
if the synthesized regex is inconsistent with the given examples it then leverages a regex repairer to modify the synthesized regex guided by the examples and returns the revised regex.
considering that the lack of focus on validity in previous nlp based works e.g.
on the dataset structuredregex less than half of the regexes predicted by d eep regex locascio et al.
are valid see section iv d we propose a twophase nlp based synthesis model s2reto solve this problem as follows.
by rewarding the s2remodel with validity in addition to the semantic correctness reward used in previous works our model is towards generating more valid regexes than previous models.
if the generated regexes are still invalid after that the invalid2valid model wherein the structure of s2reis reused is used to transform them into valid ones to further guarantee the validity of regexes.
there are various drawbacks or limitations in existing repair techniques such as only supporting positive or negative examples not supporting regexes with the conjunction operator or having the problems of under fitting overfitting .
to overcome these drawbacks or limitations we present a novel and efficient algorithm s yncorr based on neighborhood search ns to repair an incorrect regex to achieve that the repaired regex is consistent with the examples.
particularly s yncorr alleviates the under fitting over fitting problem via preserving the integrity of the small sub regexes.
trans regex can greatly reduce the aforementioned errors caused by ambiguity imprecision or unknown words in nl descriptions via using the example guided regex repairer.
1a sketch is an incomplete regex containing holes to denote missing components.
2two regexes are equal iff their corresponding languages are equivalent.in comparison with existing multi modal works trans regex avoids their limitations by not restricting the sketches of the generated regex.
furthermore t rans regex modularizes the synthesis problem as the nlp based regex synthesis and example guided regex repair allowing one to use his own algorithms or any other new algorithms instead.
we evaluate t rans regex by comparing t rans regex against ten state of the art tools on three publicly available datasets.
our evaluation demonstrates the accuracy of our trans regex is .
.
and .
higher than that of nlp based works on the three datasets respectively.
further trans regex can achieve higher accuracy than the state ofthe art multi modal works with to higher accuracy on all three datasets.
our evaluation also reveals our nlp based model s2recan generate valid regexes on complex dataset whereas other nlp based tools can synthesize .
to .
valid ones.
finally the evaluation results on regex repair also show that our s yncorr has better capability than existing repair tools.
the contributions of this paper are listed as follow.
we propose t rans regex an automatic framework which can synthesize regular expressions from both nl descriptions and examples.
to the best of our knowledge trans regex is the first to treat the nlp and examplebased regex synthesis problem as the problem of nlpbased synthesis with regex repair.
we introduce a two phase algorithm s2re for regex synthesis from nl.
by rewarding the s2remodel with validity and using the invalid2valid model s2regenerates more valid regexes while having similar or higher accuracy than the state of the art nlp based models.
we present a novel algorithm s yncorr for regex repair that i leverages neighborhood search ns algorithms to guide the search for a better regex which is consistent with the given examples from the neighborhoods of the incorrect regex and ii utilizes some rewriting rules for sub regexes abstraction to preserve the integrity of some small sub regexes thereby alleviating under fitting overfitting and efficiently reducing the search space.
we conduct a series of comprehensive experiments comparing t rans regex with ten state of the art synthesis tools.
the evaluation results demonstrate that the accuracy of our t rans regex is .
.
and .
higher than that of nlp based approaches on the three datasets respectively while t rans regex can achieve higher accuracy than the state of the art multimodal techniques with to higher accuracy on all three datasets.
the evaluation results also indicate trans regex utilizing natural language and examples in a more effective way.
ii.
o verview in this section we present an overview of t rans regex .
as illustrated in fig.
t rans regex consists of two steps namely the nlp based regex synthesis section iii c and theexample guided regex repair section iii d .
in the first 1211natural language descriptionnlp based regex synthesizer regex repairer examples regex output regexyn users consistent with examples ?regex examplesfig.
.
an overview of framework t rans regex for regex synthesis.
step nlp based regex synthesis takes the given nl description as input and tries to synthesize a regex from the nl description via an nlp based synthesizer.
after that if the synthesized regex is consistent with the given examples then trans regex outputs the regex.
otherwise example guided regex repair modifies this synthesized regex based on the provided examples by an example guided repairer and returns the repaired regex.
next we illustrate the main ideas behind trans regex using a motivating example.
example ii.
.
consider the task of constructing a regex .
.
.
the nl description nl the positive examples p and the negative examples n are shown in fig.
.
natural language description nl items with a vowel preceding a numeral at least times positive examples p negative examples n e18043699 u. u530136382 jz b u65972791327 o45 u82433805 fbcw i3390716928 i4k s o789821610 u u4765749255 i .
e6204251 a e6868266 uv o50693106874 o20m3u5817 fig.
.
a pair of a description and examples.
first t rans regex utilizes our nlp based synthesizer s2re to translate the nl description nl into a regex.
as shown in fig.
the encoder of s2re generates latent vectors from the given description nl and the decoder of s2re synthesizes the corresponding regex .
.
according to the latent vectors from the encoder.
however it is clear that this synthesized regex is invalid.
s2rethen converts this invalid regex into a valid one .
.
usingour pretrained invalid2valid model.
it is easy to verify that the valid regex generated by s2reis inconsistent with the provided examples such as the positive example e18043699 l .
.
.
intrinsically the descriptionnl shown in fig.
is ambiguous i.e.
it is unclear what part of the string should appear at least times resulting in the incorrect regex generated by s2re.
.
.
aeiou aeiou .
.
aeiou aeiou .
.
aeiou aeiou avowel preceding at anumeral least times with items valid ?s2remodel y n invalid2valid modeloutput regex fig.
.
the process of the algorithm s2re.
so after that t rans regex employs the algorithm s yncorr that is based on neighborhood search ns to repair the incorrect regex given in fig.
.
as we have mentioned in section i the incorrect regexes generated by s2remay be very similar to the target regexes with subtle differences.
therefore s yncorr first converts the above incorrect regex to the abstract regex r vow s num s q with symbolic symbols obtained by executing the function preprocess so that the integrity of small sub regexes e.g.
and can be retained as much as possible in the subsequent steps.
then s yncorr calls the function transformations to get the neighbours of r i.e.
some abstract regexes e.g.
vow s num q s that 1212step .
input anincorrect regex r!
aeiouaeiou .
step .
r preprocess r!
l step .
step .
step .
calculate fforeach r nr .
.
.
.
step6.
return therepaired regex r aeiouaeiou .
.
.
.
nr unpreprocess nr l aeiouaeiou .
aeiouaeiou .
.
aeiouaeiou .
aeiouaeiou .
vow s num q s nr transformations r vow q s num s vow s q num s vow q s num s vow q s num s. .
fig.
.
the process of the algorithm s yncorr.
are similar to rthrough a series of subtle transformations3 e.g.
quantifier adjustment orelement replacement etc.
.
next syncorr maps these abstract regexes into corresponding concrete regexes via using the function unpreprocess and calculates thefvalue4of each regex.
finally s yncorr returns the regex .
.
withfvalue of1.
leveraging nlp based synthesis with regexs repair our trans regex is able to synthesize the correct one mentioned above.
this success case shows that our t rans regex can well deal with the ambiguity of nl and the invalidity of regexes produced by some nlp based synthesizers.
in addition it is worth noting that on the same example and the incorrect regex mentioned above the repair tool rf ixer produces the incorrect regex .
.
.
specifically rfixer cannot generalize for some unseen examples e.g.
a positive example a1234567 this will result in the regex produced by rf ixer without some characters like a i.e.
the generated regexes will be over fitting.
in contrast s yncorr avoids over fitting well by preserving the integrity of the small sub regexes.
however considering that s yncorr is an algorithm based on ns and thus may trap in local optimum we will continue to use rf ixer to repair if s yncorr fails.
as demonstrated in table iv s yncorr rf ixer can achieve more than higher success rate of repair than s yncorr on the experimental datasets.
further if there will be more powerful repair tool than rf ixer by combining s yncorr we can achieve even higher success rate which is a future work.
iii.
r egex synthesis algorithm in this section we present the details of our synthesis algorithm t rans regex .
before that we first provide the background.
3in fig.
we only demonstrate transformation quantifier adjustment in step .
for all transformations see section iii.
4thefvalue of a regex represents to which degree the regex meets the given examples.
especially a regex with fvalue 1will accepts all positive examplespand rejects all negative examples n.a.
background let be a finite alphabet of symbols.
the set of all words over is denoted by .
the empty word and the empty set are denoted by and?
respectively.
regular expression regex .
expressions of ?
anda2 are regular expressions a regular expression is also formed using the operators r1jr2r1r2r1 r2 r r1r1fm ng wherec c6 f g or?is a set of characters m2n n2n f1g and m n. besides r?
r r andrfigwherei2nare abbreviations of rf0 1g rf0 1g rf1 1gandrfi ig respectively.
rfm 1gis often simplified asrfm g. the languagel r of a regular expression ris defined inductively as follows l ?
?
l f g l a fag l c l r 1jr2 l r l r l r 1r2 fvwjv2l r w2l r g l r r2 fvjv2l r v2l r g l r fvjv 2l r g l rfm ng s m6i6nl r i. if an expression follows the syntax above then it is a valid one otherwise it is invalid.
for instance the expressionab is valid but the expression ab is invalid.
b. the main algorithm our synthesis algorithm is shown in algorithm which aims to synthesize regexes from nl descriptions and examples.
in detail our algorithm first employs an nlp based synthesizer s2reto generate a regex rfrom the given nl descriptionnl line which is introduced in section iii c. then ifris consistent with the given positive and negative examples t rans regex outputsr line .
otherwise trans regex leverages two example guided repairers to fix the incorrect regex rbased on the provided positive and negative examples which are described in section iii d and returns the repaired regex lines .
algorithm trans regex input a natural language description nl positive examplesp and negative examples n output a regex 1r s2re nl 2ifp l r andn l r ?then return r 3else 4r syncorr r ifp l r andn l r ?then return r else return rfixer r c. regex synthesis from natural language descriptions to synthesize a regex from the nl description we build a seq2seq model with attention mechanism as our regex synthesis model s2re.
it consists of an encoder and a decoder.
the encoder initializes the words in the nl sequences as vectors then it encodes the vectors as hidden states which 1213represents the semantic representations of the nl sequences.
the decoder generates the corresponding regex according to the latent representations from the encoder.
the training of our neural s2re model consists of two stages using two different strategies.
maximum likelihood estimation mle in the first stage we use mle to maximize the likelihood of mapping the nl description to corresponding regex argmaxx nl r 2dlog p rjnl wheredis the training set p rjnl is the probability that the seq2seq model generates a regex rfrom a nl description nl.
policy gradient mle may fail to consider the semantic equivalence of the regexes that might be different in syntax and the validity of the regexes especially for complex and realistic datasets .
therefore in the second stage we gradually train ours2remodel via policy gradient by rewarding the model according to the following two indicators.
semantic correctness following park et al.
s work we reward the s2remodel if it generates a regex that is semantically equivalent to the ground truth that is the semantic reward rc r is1if the regex r is semantically equal with ground truth and otherwise syntactic validity we also reward the s2re model if it generates regexes that are valid5 that is the syntactic rewardrv r is1if the regex r is valid and otherwise.
finally the objective of the second stage is to maximize the following function j x nl r 2dp rjnl r r r r rc r rv r where and are hyper parameters.
thes2remodel helps to generate more correct and valid regexes than the previous models.
however it still can not guarantee to generate valid regexes for all the input nl descriptions.
to solve this problem we reuse the structure of thes2re model to build our invalid2valid model wherein onlyrvis used .
specifically the invalid2valid model is trained on invalid and valid regex pairs which are collected as following get a valid regex randomly from the dataset structuredregex make it invalid by performing some minor changes on it adding or deleting or modifying positions randomly if the changed regex is still valid then discard it.
the whole process of generating regexes from nl descriptions is shown in fig.
.
it shows that the algorithm first uses ours2remodel to generate a regex.
if the generated regex is invalid it then transform this regex fast to a valid one using 5the syntax checking is implemented via the re.compile function in python.the pretrained invalid2valid model.
the experiments show that after the s2remodel and the invalid2valid model we obtain valid regexes in syntax.
d. regex repair from examples the regexes generated by s2remay be incorrect but very similar to the target regexes with subtle differences.
in this section we present our algorithm s yncorr to repair these incorrect regexes.
the key idea is to search for a better regex which accepts more positive examples and rejects more negative examples from the neighborhoods of input regex.
to start with we define the neighborhood and an evaluation criterion of regex r. given a regex r we define its neighborhood denoted as n r as the set of regexes which can be obtained by applying a transformation on r transformations are given later .
in order to select a regex ramong a set of regexes we define a measure fonrwith respects to positive examplespand negative examples nas f r p n jtpj jtnj jfpj jfnjjpj jnj wheretp fw2l r jw2pg tn fw 2l r jw2ng fp fw 2l r jw2 pg fn fw2l r jw2ng.
intuitively the higher the fvalue the better the regex r. especially the regex rwithfvalue of 1will accepts all positive examples and rejects all negative examples.
algorithm syncorr input positive examples p negative examples n and an incorrect regex r0 output a regex 1forlmax to do 2r preprocess r0 lmax while thestop conditions not meet do 4n r apply the transformations on rin parallel 5r unpreprocess r lmax 6n r unpreprocess n r lmax 7rm arg max r02n r f r0 p n iff rm p n f r p n then iff rm p n then return rm elser preprocess rm lmax else break 12returnr0 the algorithm s yncorr is shown in algorithm .
in order to facilitate neighborhood search s yncorr sets the highest level of rewriting rules lmax ranges from 2to0 line .
first syncorr preprocesses the given regex r0with the given highest level lmax and keeps the result regex in r line2 .
next it applies the transforms on rto get the neighborhood n r and unpreprocess randn r lines .
then s yncorr selects the regex with the maximum fvalue denoted as rm from the neighborhoods of r line .
after that it compares 1214thefvalues between the current regex rand the selected regex rm line .
if the selected regex rmgets a higher fvalue then s yncorr checks whether the fvalue equals to .
if it is s yncorr returnsrm line .
otherwise to start with the next iteration the regex rmis preprocessed and assigned to r line .
if the selected regex rmdoes not get a higher f value thenrmmay be a local maximum so s yncorr fails to repair regex r0and breaks the loop line .
for each lmax the processing above runs until the stop conditions meet lines .
finally s yncorr returnsr0if s yncorr fails for all lmax values line .
rewriting rules.
in order to preserve the integrity of the small sub regexes probably the correct part and reduce the search space we define some rewriting rules for the regexes to abstract some small sub regexes.
the resulting regexes are called the abstract forms of the original regexes.
specifically we rewrite some special small regexes to unique symbolic nodes which are listed as follows !
c c fm ng !
qm n r!
sl r r !
slr r r !
nsr r const!
c const r !
n r r !
sr r r !
nsl r r !
nslr r whereconst denotes a string in regex consisting of characters in e.g.
abc ris or aconst and the suffix indicates the level lof the rule.
the rewriting rules are performed greedily and depending on its level.
in our implementation we use some meaningful names for some special regexes e.g use num let cap and vow for and respectively and keeps the rewriting mappings in dictionaries i.e.
dict lfor the level l .
preprocess and unpreprocess.
given a regex rand the highest level lmax the preprocess is to abstract i.e.
from left to right raccording the rewriting rules whose level l ranging from lmax to in order.
the rules with high level are performed first.
take r0in fig.
as an example.
if lmax the rules with level l are performed first but without changing r0because of no rules with level l are applicable.
then the rules with level l are applied yieldingr1 srvow srnum .
finally the rules with levell is applied yielding the final preprocessed regexr srvow srnum q .
iflmax the same preprocessed regex ris returned.
if lmax directly apply the rewriting rules with level l yielding the final preprocessed regex vow s num s q .
the unpreprocess is the reversion of the preprocess.
stop conditions.
we can set the maximum number of iterations and the maximum running time of the program as independent or mixed stop conditions.
transformation.
we observe that most of the incorrect regexes generated by s2re can be made equivalent to the target regexes with only minor modifications.
for that we design a series of transformations on regexes which are listedbellow where we use element s to denote the small regexes that the rewriting rules can apply on and generalized element s to denote the regexes containing at least a pair of brackets.
binary element insertion this transformation inserts a binary element i.e.
disjunction concatenation or conjunction from a candidate set into the current regex.
generalized element deletion this transformation deletes a generalized element from the current regex.
generalized element replacement this transformation replaces a generalized element in the current regex with an element from a candidate set.
quantifier insertion this transformation inserts a quantifier whose minimum and maximum values are selected according to the positive and negative examples to a generalized element in the current regex.
quantifier modification this transformation modifies a quantifier of a generalized element in the current regex where the minimum and maximum values are set according to the positive and negative examples.
quantifier adjustment this transformation adjusts the generalized element restricted by a quantifier in the current regex from its original restrict generalized element to another generalized element.
operator insertion this transformation inserts an operator i.e.
negation disjunction or conjunction into the current regex.
operator deletion this transformation deletes an operator from the current regex.
element adjustment this transformation adjusts an element in the current regex from its original position to another position.
generalized element exchanging this transformation swaps two generalized elements in the current regex.
in our implementation we take the elements collected in the dictionaries as the candidate set.
and to search the neighbour fast we perform the transformation in parallel as there are no data races between each transformation.
iv.
e valuation we implemented t rans regex in python and conducted experiments on a machine with cores intel xeon cpu e5620 .40ghz with 12mb cache 24gb ram running windows operating system.
under this experiment settings we then designed our experiments to answer the following research questions rq1 can s2remodel generate correct and valid regexes from natural language descriptions?
iv d rq2 can s yncorr repair incorrect regexes from examples?
iv e rq3 can t rans regex synthesize regexes accurately?
iv f rq4 can t rans regex synthesize regexes efficiently?
iv g 1215a.
datasets in the experiment we evaluate t rans regex on three public datasets kb13 nl rx turk and structuredregex .
among them kb13 consists of pairs of nl descriptions and the corresponding regexes constructed by regex experts.
nl rx turk includes pairs of nl descriptions and regexes collected through crowdsourcing.
structuredregex comprises long english descriptions which are .
to .
times longer than the first two datasets paired with complex regexes and associated positive negative examples using crowdsourcing.
as our approach requires examples which are absent in the first two datasets we adopt the corresponding positive and negative examples for the first two datasets provided by ye et al.
.
specifically the positive examples are enumerated by randomly traversing the deterministic finite automaton dfa of the given regex resp.
the negative examples are synthesized by stochastically traversing the dfa of the negation of the given regex .
b. training setting we train s2re on the three public datasets shown in table i. we adopt the same train validation test sets as those used by previous works for the sake of comparison.
table i thetrain validation and testsets in three datasets .
dataset train set validation set test set kb13 nl rx t urk structuredre gex in detail the encoder and the decoder of the s2remodel consist of two stacked bilstm layers respectively.
the dimension size of the word embeddings is set to and the hidden size is .
we train the s2remodel with mle loss for and epochs on kb13 nl rx turk and structuredregex respectively.
then we further train the model with policy gradient for epochs on kb13 nl rxturk and structuredregex respectively.
the hyper parameters and are set to .
and .
.
c. baselines we compare three variants of t rans regex i.e.
t ransregex s2re s yncorr t rans regex s2re rfixer t rans regex s2re s yncorr rf ixer with ten relevant works including our nlp based algorithm s2re.
they are mainly fall into two paradigms.
nlp based works only used nl descriptions to synthesize regexes i.e.
semantic unify d eep regex locascio et al.
deep regex ye et al.
s emregex s oftregex and our s2re.
on the other hand nlp andexample based works took both nl and examples for regex synthesis including d eep regex ye et al.
e xs grammar sketch mle d eepsketch mle and d eepsketch mml .
among them s emantic unify learns a probabilistic grammar model to parse nl descriptions into regexes.
d eep regex locascio et al.
deep regex ye et al.
s emregex softregex and ours2re are a series of algorithms and the main idea of these algorithms is to translate nl into regexes based on the seq2seq model.
d eep regex ye et al.
e xsis an extension of d eep regex ye et al.
which takes examples into account by simply filtering the k best regexes based on whether regexes consistent with the given examples.
in addition g rammar sketch mle d eepsketch mle and d eepsketch mml are a family of algorithms and these algorithms first use a grammar based or neural semantic parser to parse the nl into sketches then search the regex space defined by the sketches and find a regex that is consistent with the given examples.
for implementation d eep regex locascio et al.
and s oftregex are open source programs so we are able to reproduce the results of them.
while other baselines do not release their source code so we excerpted the statistics from their paper and left blanks if they did not report it.
d. rq1 effectiveness of s2re to answer the first question we compare our algorithm s2rewith five state of the art nlp based algorithms.
table ii shows the evaluation results on accuracy of semantic unify d eep regex locascio et al.
d eepregex ye et al.
s emregex softregex and our model s2re.
on these three datasets the accuracy of our s2re model is similar to or slightly better than s oftregex and is always better than the other four nlp based models i.e.
semantic unify d eep regex locascio et al.
d eepregex ye et al.
and s emregex .
besides the evaluation results on validity are summarized in table iii.
the validity of synthesized regexes is crucial.
it guarantees the quality of regex synthesis from nl .
further in our approach it ensures that the regex synthesized from nl is provided as a valid input to example guided regex repair.
the results show that the validity of existing tools e.g.
d eepregex locascio et al.
and s oftregex is unsatisfactory on the last dataset structuredregex which is much more complex than the first two.
as we can see less than half of the regexes generated by d eep regex locascio et al.
are valid and the most advanced nlp based model s oftregex achieves .
.
by contrast our model s2reachieves validity ratio because it utilizes both the syntactic validity reward and invalid2valid model.summary to rq1 s2recan achieve similar or better accuracy than the state of the art nlp based models.
meanwhile s2recan synthesize more valid regexes.
the advantage of high validty of s2rebecomes more obvious on complex datatsets.
e. rq2 effectiveness of syncorr to answer the second question we collected and incorrect regexes predicted by s2re on kb13 nl1216table ii thedfa equivalent accuracy on three datasets .
approach kb13 nl rx t urkstructur ed regex semantic unify .
.
.
deep regex locascio et al.
.
.
.
deep regex ye et al.
.
.
.
semregex .
.
softregex .
.
.
s2re .
.
.
deep regex ye et al.
e xs .
.
.
grammar sketch mle .
.
deepsketch mle .
.
deepsketch mml .
.
transregex s2re s yncorr .
.
.
transregex s2re rf ixer .
.
.
transregex s2re s yncorr rf ixer .
.
.
table iii thenumber of valid regexes generated by the three nlp based models on three datasets .
approach kb13 nl rx turkstructured regex deep regex locascio et al.
.
.
softregex .
.
s2re rx turk and structuredregex respectively.
we compared syncorr with the state of the art tool rf ixer .
table iv shows the number of successful repairs6.
rf ixer successfully repaired .
.
and .
on dataset kb13 nl rx turk and structuredregex respectively.
in contrast syncorr can repair .
.
and .
more regexes than rf ixer on the three datasets respectively.
in addition the repair success rate of s yncorr rf ixer is .
.
.
.
and .
.
higher than that of s yncorr rf ixer alone on dataset kb13 nl rx turk and structuredregex respectively.
we further demonstrate the advantages and disadvantages of rf ixer and s yncorr through a few cases in table v. as cases and shown in table v our algorithm syncorr has the high generalization performance compared with rf ixer .
case in table v illustrates that s yncorr can handle regexes with well but rf ixer cannot.
similar to case in table v in some cases s yncorr will fall into a local optimum and rf ixer can solve them.
based on the above analysis we can conclude that s yncorr and rfixer are complementary and simultaneously useful for our trans regex .
summary to rq2 syncorr can more effectively repair regexes compared with the state of the art tool rf ixer .
in addition s yncorr and rf ixer are complementary and simultaneously useful for our t rans regex .
6the regex that is successfully repaired must not only consistent with the given examples but also be equal to the target regex.table iv thenumber of successful repairs by syncorr and rfixer on three datasets .
approach kb13 nl rx t urkstructur ed regex rfixer .
.
.
syncorr .
.
.
rfixer s yncorr .
.
.
f .
rq3 effectiveness of transregex to answer this question we compared t rans regex with six nlp based baselines and four multi modal baselines.
we can see from table ii that on average nlp based works performed worse than multi modal works on all three datasets.
in general the accuracy on the first dataset kb13 is much higher than that on the other two datasets for nlp based methods and the accuracy achieved by nlp based methods are up to lower than that achieved by multi modal methods on average.
particularly on the first two datasets the accuracy of nlp based works range from .
to .
compared with .
to .
achieved by existing multi modal works.
on comparison t rans regex achieved approximate higher accuracy than these baselines reaching .
to .
on the first two datasets.
the superiority of our work is more obvious on the last dataset which is much more complex than the first two.
the accuracy achieved by t rans regex .
almost doubled the accuracy achieved by d eep regex ye et al.
exs .
.
let us present a few example regexes that are synthesized incorrectly from nl descriptions but are synthesized correctly by our t rans regex to illustrate the benefits of leveraging both nl and examples.
as case in table vi the description is ambiguous i.e.
it is unclear what part of the string would appear at least times resulting in thats2repredicted a regex embedding other meanings.
our trans regex utilizes examples e.g.
a positive example adogbdogcdog to help disambiguate the description and fix the incorrect regex .
dog .
to the correct regex .
dog.
.
similar to cases and in table vi the errors that are caused by imprecision unknown words in descriptions or false prediction by nlp based approaches can be corrected by t rans regex through using the example guided regex repairer.
further we analyze the possible reasons why the other multi modal works are not as effective as ours as follows.
as mentioned above d eep regex ye et al.
e xssimply uses examples to select the k best regexes among the candidates produced by d eep regex ye et al.
.
if there is no correct regex in the candidates the examples will not help.
the three variants algorithms i.e.
g rammar sketch mle d eepsketch mle and d eepsketch mml rely heavily on the quality of the sketches synthesized in their first step.
in other words the incorrection of sketches will be inherited by the generated regex in the next step.
while t rans regex does not have the above mentioned drawbacks.
in addition 1217table v examples of repair by rfixer and syncorr.
no.
incorr ect regex ground truth rfixer syncorr .
.
f7 g .
f7 g .
.
.
f2 g .
f7 g. f2 3g f2 3g f3 4g f2 3g f3g f3 4g f2 g abcdefl npvwxy f2 3g f3 4g f2 3g f3 3g f3 4g j f1 g .f6 8g .
j .
.f6 8g .
.
not supporting regexes with .f6 8g .
j .
f3 g f3 gn f2 4g f3 g f3 g njg f2 4g f3 g f3 g f2 4g trapping in local optimum table vi examples illustrating the benefits of leveraging both natural language and examples in trans regex .
no.
description ground truth s2re success type items with a capital letter preceding dog at least times .
dog.
f3 g .
dog f3 g .
ambiguity of nl thestring should start with at least or more capital i then it is followed by letters.lf1 g f3g f1 g f3g imprecision of nl thestring must begin with or more letter s. after this grouping it is a digit number.
after this digit number there a letter z. after the letter z the string must contain or .the string can end with an optional string of to capital letters.sf2 g f3gz j f3 4g ?sf2 g f3gz f3g f3 4g ?unkno wn or rare words alist of comma separated strings of lowercase letters.
false prediction by s2re although t rans regex is also a two step algorithm the second step of t rans regex is not only not affected by the errors of the first step but also specifically correct the errors of the first step guided by the given examples.
summary to rq3 trans regex can achieve higher accuracy than the nlp based works with .
.
and .
and the state of the art multi modal works with to higher accuracy on all three datasets.
the experiment results also indicate t rans regex utilizing natural language and examples in a more effective way than other multi modal works.
g. rq4 efficiency of transregex table vii average running time per benchmark on three datasets .
approach kb13 nl rx t urkstructur ed regex deep regex locascio et al.
.
s .
s .
s s2re .
s .
s .
s transregex s2re s yncorr .
s .
s .
s transregex s2re rf ixer .
s .
s .
s transregex s2re s yncorr rf ixer .
s .
s .
s to evaluate the efficiency of three variants of t ransregex we compared the average running time of synthesizing per regex with the open source baseline d eepregex locascio et al.
and our s2re in table vii.
in general we can see that t rans regex takes longer time to synthesize regexes on the last dataset than on the first two and nlp based baselines take less than t rans regex on average.
in particular t rans regex takes an average .
seconds and .
seconds on the first two datasets compared with .
to .
seconds achieved by baselines.
while on the last dataset t rans regex takes longer time due tothe complexity of the dataset.
considering together with the accuracy t rans regex achieved the accuracy .
that doubles the accuracy .
achieved by s2re taking only around more seconds running time.
table vii also reveals the rationality of our algorithms the adopting of s yncorr helps us to accelerate the repair process in some cases while rfixer takes care of the rest.
summary to rq4 trans regex can synthesize regex efficiently.
especially when considering together with accuracy trans regex can takes an average .
to .
seconds to achieve around more accuracy on simpler datasets and takes more accuracy at the cost of more seconds on the more complex dataset.
v. t hreats to trans regex svalidity trans regex is not guaranteed to generate correct regexes for each benchmark mainly due to the following aspects uncharacteristic examples.
although t rans regex has greatly reduced the amount of required examples the quality of t rans regex still depends on characteristic examples.
when the examples provided by users are not characteristic it is difficult for t rans regex to get the correct regexes.
for instance the positive examples from case in table viii belongs to both the incorrect one and ground truth i.e.
fail to distinguish between the incorrect one and ground truth.
this may cause s yncorr or rf ixer to fail to repair the incorrect regex.
if the user further provides examples e.g.
a positive example aaaaaa that can distinguish the two ones our methods can easily get the correct one.
1218table viii examples of failed cases generated by trans regex .
no.
description positive examples negati ve examples ground truth predicted results failure type fsuhordkrugrfirj qmnvf s2re 13lower case letters followed by more ipthladppnkuxprwo qmnva syncorr a z uncharacteristic than letters.
a z examples rfixer astring that consists of upper or lower k0 !
s2re case letters special characters !
.
.
orthe number and sy 0m0 !0t0f!
e !
!kx syncorr .
wrong exampleswhose length is or more characters .
.
long.
rfixer notsupporting regexes with alist of semicolon separated strings o0culdvs 0ctycf h mlnwmxydw x9e5pdvf a s2re .
thefirst and second strings begin with 3any combination of letters or digits 80oymq 2t2myvsz dzg 5xsxe xtc8jv q syncorr time out!
very complex regexes these strings end with to lower ordescriptions case letters the third part is any number of capital letters.
rfixer notsupporting regexes with wrong examples.
wrong examples provided by users resulting in that our algorithms are misled to synthesize regexes in the wrong direction.
more concretely our algorithms repair incorrect regexes in the wrong direction and even fix the correct regexes produced by s2reinto the incorrect one.
as case in table viii if we only use the nl description we can get the accurate regex .
which is the same as the ground truth.
however the user provides some wrong examples e.g.
a positive example k0 which leads our algorithms to believe that the regex .
is not accurate and then our algorithm uses the wrong examples to fix the accurate regex into an incorrect one.
very complex regexes or descriptions.
similar to case in table viii if the nl description is very long and complicated or the target regex is very complex in terms of length and tree depth the regex synthesized by s2re may be very different from the target one.
this kind of regex which is very different from the target one and required very large fixes is difficult for our algorithms to repair into a correct one in a limited time and space.
vi.
r elated work a. regex synthesis regex synthesis from examples.
the problem of automatic regex synthesis from examples has been explored in many domains .
alpharegex is a searchbased algorithm for synthesizing simple regexes for introductory automata assignments.
alpharegex exploits over underapproximations to effectively prune out a large search space.
however all the regexes produced by alpharegex are over alphabets of size .
regexgenerator is a state ofthe art approach for the synthesis of regexes from positive and negative examples.
the fact that regexgenerator utilizes genetic programming means that it is not guaranteed to generate a correct solution i.e.
accepting all the positive examples while rejecting all the negative examples.
lots of existingworks focus on xml schemas inference via resorting to infer regexes from examples.
these approaches usually aim to tackle restricted forms of regexes from positive examples only.
li et al.
presented a novel algorithm flash regex to generate anti redos regexes from given positive and negative examples by reducing the ambiguity of these regexes and using sat techniques.
however one of the main issues in the above example based techniques is the quality of the synthesis i.e.
whether it would generalize and correct for unseen examples.
specifically if users can not provide sufficient and characteristic examples the synthesized regexes will be under fitting or over fitting.
regex synthesis from nl.
several works from the natural language processing nlp community address the problem of generating regexes from nl specifications .
kushman and barzilay introduced a technique for learning a probabilistic combinatory categorial grammar model to parse a nl description into a regex.
to avoid domainspecific feature extraction locascio et al.
described the deep regex model based on standard sequence to sequence seq2seq model which regards the problem of generating regexes from nl descriptions as a direct machine translation task.
to solve the problem that d eep regex model may not generate semantically correct regexes the s emregex model based on reinforcement learning method was presented.
it leverages dfa equivalence as a reward function to encourage the model to generate semantically correct regexes.
to speeds up the training phase of s emregex model park et al.
devised the s oftregex model which determines the equivalence of two regexes using deep neural networks.
there are three major bottlenecks in existing nlp based techniques that affect the quality of synthesis i ambiguity and imprecision of nl .
ambiguity of nl results in predicting a regex embedding other meanings resp.
imprecision of nl affects the correctness of synthesis ii unknown words and rare words.
there are unknown words or rare words in nl descriptions which will lead to failure to generate correct regexes iii seq2seq model.
seq2seq based approaches can only synthesize regexes similar in shape to the training data.
1219regex synthesis from nl and examples.
ye et al.
proposed structuredregex a new dataset for regex synthesis from nl and examples.
ye et al.
introduced a baseline model d eep regex f ilter which uses d eep regex as base model and considers examples by simply filtering the k best regexes.
however the positive and negative examples are not considered in the training and inference phase.
the latest two works presented new two step frameworks for regex synthesis from nl and examples.
first a semantic parser converts the nl description into an intermediate sketch.
then a synthesizer searches the regex space defined by the sketch and returns a concrete regex that is consistent with the given examples.
although both adopting a two step paradigm these works have an apparent limitation incorrect sketches generated in the first step will subsequently induce the final regexes.
in other words the incorrection of sketches will be inherited by the synthesized regexes in the next step.
on the other hand our work overcomes this limitation the second step of t rans regex i.e.
example guided regex repair fixes the incorrect regex by examples if needed.
in this manner the inherited inconsistencies in our first step i.e.
nlp based regex synthesis will be fixed in our second step.
b. regex repair regex repair from examples.
there are several works targeting at repairing regexes from examples.
we discuss two main paradigms of them.
in the first paradigm works only consider either positive or negative examples.
li et al.
proposed relie which can modify complex regexes by rejecting the newly input negative examples.
by contrast rebele et al.
proposed a novel way to generalize a given regex so that it accepts the given positive examples.
on the other hand works in the second paradigm take both positive and negative examples into consideration.
pan et al.
designed rf ixer a tool for repairing incorrect regexes using both examples.
it took advantage of skeletons of regexes i.e.
sketches to effectively prune out the search space and it employed smt solvers to efficiently explore the sets of possible character classes and numerical quantifiers.
our work applies rf ixer in our regex synthesis from nl and examples.
li et al.
described algorithm r epairing re based on neighborhood search ns to repair incorrect or redosvulnerable regexes from positive and negative examples.
similar to r epairing re our algorithm s yncorr also uses ns to repair regexes but the difference is that r epairing re uses automaton directed repair while we use regex directed repair.
like the above example based synthesis algorithms these repair algorithms also may cause under fitting or over fitting results.
to alleviate the problems of under fitting over fitting our s yncorr leverages some rewriting rules for sub regexes abstraction to preserve the integrity of some small sub regexes.
c. program synthesis programming by example pbe .
pbe techniques have been the subject of research in the past few decades and successful paradigms for program synthesis allowing end usersto construct and run new programs by providing examples of the intended program behavior .
recently pbe techniques have been successfully used for string transformations data filtering data structure manipulations table transformations sql queries and mapreduce programs .
programming by nl pbnl .
there has been a lot of progress made in pbnl .
specifically several techniques have been proposed to translate nl descriptions into python sql queries shell scripts spreadsheet formulas test oracles javascript function types and java expressions .
program synthesis from nl and examples.
sinece program synthesis from nl and examples techniques can well overcome the shortcomings of pbe and pbnl techniques at the same time provide a more natural and friendly interface to the users recent years they have been widely used in several areas for example string manipulation programs and program sketches .
in this paper we focus on an important subtask of the program synthesis from nl and examples problem synthesizing regexes from both nl and examples.
vii.
c onclusion we propose an automatic framework t rans regex for synthesizing regular expressions from both natural language descriptions and examples.
to the best of our knowledge trans regex is the first to treat the nlp and examplebased regex synthesis problem as the problem of nlp based synthesis with regex repair.
for nlp based synthesis we devise a two phase algorithm s2re which generates more valid regexes while having similar or higher accuracy than the state of the art nlp based models.
while for regex repair we present a novel algorithm s yncorr that leverages ns algorithms to guide the search for a target regex and uses rewriting rules to alleviate under fitting over fitting and efficiently reduce the search space.
the evaluation results demonstrate that the accuracy of our t rans regex is .
.
and .
higher than that of nlp based works on the three publicly available datasets respectively.
further trans regex can achieve higher accuracy than the state ofthe art multi modal works with to higher accuracy on all three datasets.
the evaluation results also indicate trans regex utilizing natural language and examples in a more effective way.
acknowledgment the authors would like to thank the anonymous reviewers for their comments and suggestions.
this work is supported in part by national natural science foundation of china grants national key research and development program of china under grant 2019yfe0198100 guangdong basic and applied basic research foundation under grant 2019a1515011577 and huawei phd fellowship msra collaborative research grant.
1220references l. g. m. iv j. donohue j. c. davis d. lee and f. servant regexes are hard decision making difficulties and risks in programming regular expressions in 34th ieee acm international conference on automated software engineering ase san diego ca usa november pp.
.
y .
shen y .
jiang c. xu p. yu x. ma and j. lu rescue crafting regular expression dos attacks in proceedings of the 33rd acm ieee international conference on automated software engineering ase montpellier france september pp.
.
c. chapman p. wang and k. t. stolee exploring regular expression comprehension in proceedings of the 32nd ieee acm international conference on automated software engineering ase urbana il usa october november pp.
.
a. bartoli a. d. lorenzo e. medvet and f. tarlao inference of regular expressions for text extraction from examples ieee trans.
knowl.
data eng.
vol.
no.
pp.
.
j. c. davis c. a. coghlan f. servant and d. lee the impact of regular expression denial of service redos in practice an empirical study at the ecosystem scale in proceedings of the acm joint meeting on european software engineering conference and symposium on the foundations of software engineering esec sigsoft fse lake buena vista fl usa november pp.
.
j. c. davis l. g. m. iv c. a. coghlan f. servant and d. lee why aren t regular expressions a lingua franca?
an empirical study on the reuse and portability of regular expressions in proceedings of the acm joint meeting on european software engineering conference and symposium on the foundations of software engineering esec sigsoft fse tallinn estonia august pp.
.
e. spishak w. dietl and m. d. ernst a type system for regular expressions in proceedings of the 14th workshop on formal techniques for java like programs ftfjp beijing china june pp.
.
x. liu y .
jiang and d. wu a lightweight framework for regular expression verification in 19th ieee international symposium on high assurance systems engineering hase hangzhou china january pp.
.
b. luo y .
feng z. wang s. huang r. yan and d. zhao marrying up regular expressions with neural networks a case study for spoken language understanding in proceedings of the 56th annual meeting of the association for computational linguistics acl melbourne australia july volume long papers pp.
.
n. kushman and r. barzilay using semantic unification to generate regular expressions from natural language in human language technologies conference of the north american chapter of the association of computational linguistics proceedings june westin peachtree plaza hotel atlanta georgia usa pp.
.
n. locascio k. narasimhan e. deleon n. kushman and r. barzilay neural generation of regular expressions from natural language with minimal domain knowledge in proceedings of the conference on empirical methods in natural language processing emnlp austin texas usa november pp.
.
z. zhong j. guo w. yang j. peng t. xie j. lou t. liu and d. zhang semregex a semantics based approach for generating regular expressions from natural language specifications in proceedings of the conference on empirical methods in natural language processing brussels belgium october november pp.
.
j. park s. ko m. cognetta and y .
han softregex generating regex from natural language descriptions using softened regex equivalence in proceedings of the conference on empirical methods in natural language processing and the 9th international joint conference on natural language processing emnlp ijcnlp hong kong china november pp.
.
x. wang s. gulwani and r. singh fidex filtering spreadsheet data using examples in proceedings of the acm sigplan international conference on object oriented programming systems languages and applications oopsla part of splash amsterdam the netherlands october november pp.
.
s. gulwani s. jha a. tiwari and r. venkatesan synthesis of loopfree programs in proceedings of the 32nd acm sigplan conferenceon programming language design and implementation pldi san jose ca usa june pp.
.
g. j. bex f. neven t. schwentick and s. vansummeren inference of concise regular expressions and dtds acm trans.
database syst.
vol.
no.
pp.
.
g. j. bex w. gelade f. neven and s. vansummeren learning deterministic regular expressions for the inference of schemas from xml data acm trans.
web vol.
no.
pp.
.
d. d. freydenberger and t. k otzing fast learning of restricted regular expressions and dtds theory comput.
syst.
vol.
no.
pp.
.
m. lee s. so and h. oh synthesizing regular expressions from examples for introductory automata assignments in proceedings of the acm sigplan international conference on generative programming concepts and experiences gpce amsterdam the netherlands october november pp.
.
y .
li z. xu j. cao h. chen t. ge s. c. cheung and h. zhao flashregex deducing anti redos regexes from examples in 35th ieee acm international conference on automated software engineering ase melbourne australia september p. to appear.
q. chen x. wang x. ye g. durrett and i. dillig multi modal synthesis of regular expressions in proceedings of the 41st acm sigplan international conference on programming language design and implementation pldi london uk june pp.
.
z. zhong j. guo w. yang t. xie j. lou t. liu and d. zhang generating regular expressions from natural language specifications are we there yet?
in the workshops of the the thirty second aaai conference on artificial intelligence new orleans louisiana usa february pp.
.
m. h. manshadi d. gildea and j. f. allen integrating programming by example and natural language programming in proceedings of the twenty seventh aaai conference on artificial intelligence july bellevue washington usa .
x. ye q. chen x. wang i. dillig and g. durrett sketch driven regular expression generation from natural language and examples trans.
assoc.
comput.
linguistics vol.
to appear .
x. ye q. chen i. dillig and g. durrett benchmarking multimodal regex synthesis with complex structures in proceedings of the 58th annual meeting of the association for computational linguistics acl online july pp.
.
y .
li r. krishnamurthy s. raghavan s. vaithyanathan and h. v .
jagadish regular expression learning for information extraction in conference on empirical methods in natural language processing emnlp proceedings of the conference october honolulu hawaii usa a meeting of sigdat a special interest group of the acl pp.
.
t. rebele k. tzompanaki and f. m. suchanek adding missing words to regular expressions in advances in knowledge discovery and data mining 22nd pacific asia conference pakdd melbourne vic australia june proceedings part ii pp.
.
r. pan q. hu g. xu and l. d antoni automatic repair of regular expressions proc.
acm program.
lang.
vol.
no.
oopsla pp.
.
r. j. williams simple statistical gradient following algorithms for connectionist reinforcement learning mach.
learn.
vol.
pp.
.
a. bartoli g. davanzo a. d. lorenzo e. medvet and e. sorio automatic synthesis of regular expressions from examples ieee computer vol.
no.
pp.
.
y .
li x. zhang j. cao h. chen and c. gao learning k occurrence regular expressions with interleaving in database systems for advanced applications 24th international conference dasfaa chiang mai thailand april proceedings part ii pp.
.
d. e. shaw w. r. swartout and c. c. green inferring lisp programs from examples in advance papers of the fourth international joint conference on artificial intelligence tbilisi georgia ussr september pp.
.
k. ellis and s. gulwani learning to learn programs from examples going beyond program structure in proceedings of the twenty sixth international joint conference on artificial intelligence ijcai melbourne australia august pp.
.