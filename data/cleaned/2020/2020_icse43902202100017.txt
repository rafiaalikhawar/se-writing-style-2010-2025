verifying determinism in sequential programs rashmi mudduluru university of washington rashmi4 cs.washington.edujason waataja university of washington jwaataja cs.washinton.edusuzanne millstein university of washington smillst cs.washinton.edumichael d. ernst university of washington mernst cs.washinton.edu abstract when a program is nondeterministic it is difficult to test and debug.
nondeterminism occurs even in sequential programs e.g.
by iterating over the elements of a hash table.
we have created a type system that expresses determinism specifications in a program.
the key ideas in the type system are type qualifiers for nondeterminism order nondeterminism and determinism type well formedness rules to restrict collection types and enhancements to polymorphism that improve precision when analyzing collection operations.
while state ofthe art nondeterminism detection tools rely on observing output from specific runs our approach soundly verifies determinism at compile time.
we implemented our type system for java.
our type checker the determinism checker warns if a program is nondeterministic or verifies that the program is deterministic.
in case studies of lines of code the determinism checker found previously unknown nondeterminism errors even in programs that had been heavily vetted by developers who were greatly concerned about nondeterminism errors.
in experiments the determinism checker found all of the non concurrency related nondeterminism that was found by state of the art dynamic approaches for detecting flaky tests.
index terms nondeterminism type system verification specification hash table flaky tests i. i ntroduction a nondeterministic program may produce different output on different runs when provided with the same input.
nondeterminism is a serious problem for software developers and users.
nondeterminism makes a program difficult to test because test oracles must account for all possible behaviors while still enforcing correct behaviors.
test oracles that are too strict lead to flaky tests which sometimes pass and sometimes fail .
flaky tests must be re run or developers ignore them in either case their utility to detect defects is limited.
nondeterminism makes it difficult to compare two runs of a program on different data or to compare a run of a slightly modified program to an original program.
this hinders debugging and maintenance and prevents use of techniques such as delta debugging .
nondeterminism reduces users and developers trust in a program s output .
these problems motivate the field of deterministic replay .
nondeterminism is common even where it is not expected.
for example a program that relies on the iteration order of a hash table or on any other property of hash codes may produce different output on different runs.
so may any program that uses default formatting such as java s object.tostring which includes a memory address.
other nondeterministic apis include random date and time functions and accessing system properties such as the file system or environment variables.
another source of nondeterminism is concurrency but our work focuses on sequential programs.
the high level goal of our work is to provide programmers with a tool for specifying determinism properties in a program and verifying them statically.
other researchers have also recognized the importance of the problem of nondeterminism.
previous work in program analysis for nondeterminism has focused on unsound dynamic approaches that identify flaky test cases .
these techniques have been able to identify issues in real world programs some of which have been fixed by the developers.
identifying and resolving nondeterminism earlier in the software development lifecycle is beneficial to developers and reduces costs .
we have created an analysis that detects nondeterminism or verifies its absence in sequential programs.
our analysis permits a programmer to specify which parts of their program are intentionally nondeterministic and it verifies that the remainder is deterministic.
the programmer specifies whether a particular part of the program is allowed to be nondeterministic or not.
the tool reports when the program deviates from that behavior.
any deviation is a bug either in the possibly defaulted specification or in the program.
the tool identifies nondeterminism where the specification does not permit it.
then the programmer can fix the inconsistency.
our approach is based on type systems that analyzes determinism at compile time.
it does not rely on examining output from specific runs.
type systems are as expressive as any other static analysis .
a type based approach divides the responsibility between the user and the tool.
ours is a specification and verification approach.
the user writes a specification of the intended behavior of the program and the tool reports whether the program violates the specification.
if our analysis issues no warnings then the program produces the same output when executed twice on the same inputs modulo the limits of the analysis see section viii .
our analysis works at compile time giving a guarantee over every possible execution of the program unlike unsound dynamic tools that attempt to discover when a program has exhibited nondeterministic behavior on a specific run.
our analysis permits calls to nondeterministic apis and only issues a warning if they are used in ways that may lead to nondeterministic output observed by a user.
like any sound analysis it can issue false positive warnings.
ieee acm 43rd international conference on software engineering icse .
ieee our main contributions are a type system for expressing determinism properties section ii and an implementation for java in a tool called the determinism checker section iii .
while the approach is applicable to any statically typed objectoriented programming language our implementation works only for java.
to validate our work we performed case studies and experiments.
in the case studies we ran our analysis on loc projects including ones whose developers had already spent weeks of testing and inspection effort to make deterministic section iv .
the determinism checker discovered instances of nondeterminism that the developers had overlooked.
the developers fixed most of these issues when we reported them.
figure shows an example.
in the experiments we compared our tool against state of the art flaky test detectors on their benchmarks sections v and vi .
the determinism checker found all the non concurrency nondeterminism found by the other tools.
ii.
a type system for determinism this section presents the key aspects of our type system.
section ii a reviews the notion of type qualifiers and how they help type checking.
section ii b introduces determinism type qualifiers informally.
section ii c formalizes the type system gives examples and proves soundness.
section ii d discusses how polymorphism enables more precise specification of non deterministic behavior.
a. preliminaries and notation a programming language provides basetypes such as int.
a type qualifier on a basetype adds additional constraints that is it reduces the set of values that the type represents.
an example type qualifier is positive and an example type is positive int.
a type qualifier constrains the set of possible run time values that is positive int int.
as a result a qualifier type system does not allow any values that the original type system does not in the same program without qualifiers.
however the qualifier type system may reject more programs and thus affords stronger guarantees.
b. determinism types the core of the determinism type system is the type qualifiers nondet ordernondet det.
nondet indicates that the expression might evaluate to different values in two different executions.
ordernondet indicates that the expression is a collection iterator or map that contains the same elements in every execution but possibly in a different order or that the expression evaluates to equal values in all executions.
detindicates that the expression evaluates to equal values in all executions for a collection or a map iteration also yields the values in the same order.
ordernondet may only be written on collections and maps.
a map is a dictionary or an associative array such as a hash table.
our type system largely treats a map as a collection of key value pairs.
both collections and maps may be det ordernondet or nondet.
the basetypes of their elements can be specified independently of the collection basetypes.
however an element type qualifier must be a subtype of the collection type qualifier see fig.
.
our approach is applicable to any object oriented programming language.
for concreteness our formalism and implementation build upon java.
c. formalizing our type system we formalized a core language as an extension to featherweight generic java fgj figure in .
due to space constraints the full formalism and detailed proofs appear in .
our language adds the following language features to fgj determinism type qualifiers aliasing mutation collection classes from the jdk and arrays.
our core language adds aliasing and mutation to fgj via expressions e f eande e f. additionally basetypes in our language include arrays and consequently array accesses e e and array mutations e e. collection classes are invariant with respect to the determinism qualifier.
that is a nondet collection is unrelated by subtyping to an ordernondet collection which is unrelated to a det collection for details see section ii c5 .
arrays are treated as covariant with respect to determinism type qualifiers.
this is sound because we forbid mutating arrays of type nondet e ornondet e .
these core language features express the essential features of our type system.
type well formedness and collection types ordernondet may not be written on types other than collection iterator and map.
figure gives examples.
the type qualifier on the type argument of a collection must be a subtype of the type qualifier on the collection type.
our design uses types to distinguish between expressions that evaluate to the same values on each execution and those that may not.
to achieve this goal determinism is a deep rather than a shallow property if an expression of collection or array type is nondeterministic then so are its elements and if an expression of reference type is nondeterministic then so are its fields.
behavior of order nondeterministic collections a collection whose type qualifier is ordernondet has the following properties elements retrieved from it via access iteration searching etc.
have type nondet.
size related operations and queries of whether an iterator has more elements return a deterministic result.
to restate the first point the typical type for a list access operation such as get is8e listhei int!e but this type is correct only when both arguments are det.
the precise type is more complex because if either argument to getis ordernondet ornondet then the result is nondet.
section ii d shows how to express this polymorphism.
typing rules and field accesses in our type system whenever a field is accessed on the rhs of a pseudo assignment the type qualifier of that expression is the least upper bound lub of the type qualifier of the field type and 38nondet listhnondet inti nondet listhordernondet seti nondet listhdet inti ordernondet listhnondet inti ordernondet listhordernondet seti ordernondet listhdet inti det listhnondet inti det listhordernondet seti det listhdet inti fig.
a collection s type qualifier must be a supertype or equal to the element type qualifier.
the struck out types are invalid.
that of the field s class type.
to illustrate the need for this rule consider the example below class myclass det integer dfield nondet integer getfieldoffirst ordernondet list det myclass list nondet myclass element list.get return element.dfield the iteration order of the formal parameter list of type ordernondet list is arbitrary.
therefore the type of list.get has the type qualifier nondet.
in other words element could have different values across executions.
as a result the expression element.dfield isnondet even though dfield is declared as det.
an assignment x f yis valid iff the type qualifier on the type ofxis a subtype of the type qualifier on the declaration type off.
the following example justifies this rule class myclass det integer dfield void bad ordernondet list det myclass list nondet myclass element list.get element.dfield ... this is invalid since element could have different values across executions it isnondet.
suppose list had two elements elem1 and elem2.
in one execution list.get could return elem1 and the statement element.dfield .. would set a field of elem1.
in another execution list.get could return elem2 and the assignment statement would set a field of elem2.
in other words the method badcreates a nondet alias to a detinstance which allows the instance to be mutated non deterministically.
to prevent this unsoundness our type system forbids the assignment to element.dfield.
theorems and proofs the following theorems imply that our type system is sound it suffers no false negatives.
if our type system issues no warnings then no expression with deterministic type evaluates to a different value on different runs over the same inputs.
theorem type preservation .
when an expression ereduces to another expression e0 e0 s type is a subtype of e s type.
more formally if e tande!e0then e0 t0for somet0such that t0 t proof.
by induction on the derivation of e!e0 similar to the proof of theorem .
.
in .
we show the cases for our new reduction and type validity rules.
case e1 e2 f.e2 f!e0impliese0 lub v wheree2 u f v. here are type qualifiers andu v are basetypes.
upon execution of the statement e1 e2 f e1reduces toe2 f. so the type of e1is exactly the type ofe0which satisfies e0 e1.
case e1 f e2.the assignment is either invalid or trivially preserves types e fhas the same type as that ofe2 .
case e1 e2 .similar to case .
case e1 e2.similar to case .
the determinism type qualifiers do not change reduction rules they only affect subtyping and type validity.
invariant collections only add constraints to subtyping which does not affect the reduction e!e0.
theorem progress .
ifeis well typed then one of the following applies .
econtains a failed downcast .
e contains a failed assignment due to the violation of field assignment rule .
econtains a failed assignment due to the violation of array assignment rule or .
there is a valid reduction rule.
proof.
this theorem is proved by a case analysis of all expression types.
the only difference from the proof of theorem .
in is due the type validity of field and array accesses on the lhs.
in the case of field assignment e1 f e2 either the expressione1 fis invalid or it reduces to the same type as that ofe2.
a similar analysis handles array accesses.
collection aliasing mutation and invariance this section discusses why collection classes are invariant with respect to determinism type qualifiers.
assume for the sake of contradiction that collections are not invariant w.r.t.
type qualifiers.
that would make the following code valid void test det list det string dlist nondet list det string nlist nondet list det string ndlist dlist ndlist.addall nlist the above code is unsafe because nlist and dlist are aliases to the same list object and nlist.addall nlist mutates the det reference dlist non deterministically.
that is it would violate case of the proof of theorem .
to avoid such unsoundness our type system disallows collection instances to have two aliases that differ in their determinism types.
it achieves this by declaring all collection classes to be invariant with respect to determinism type qualifiers.
d. polymorphism as described so far our type system is sound but it suffers from poor expressiveness.
an implementation would issue many false positive warnings because programmers could write only coarse specifications of methods.
adding polymorphism to our type system increases its expressiveness without compromising soundness .
this section focuses on precise specifications method signatures rather than on the 39type checking that ensures that the method body conforms to the specification.
section ii d1 first describes basic polymorphism over type qualifiers and over basetypes.
the subsequent sections describe polymorphic extensions.
qualifier and basetype polymorphism our type system supports parametric polymorphism .
a polymorphic abstraction a class or method is written and type checked once.
informally it acts as if it has multiple different types and each use site is typechecked using the most specific applicable instantiated non polymorphic type.
our type system supports both basetype polymorphism and qualifier polymorphism.
to achieve typical type polymorphism use both basetype polymorphism and qualifier polymorphism.
for example the type of the identity function is 8t t!t which can be equivalently written as u u!
u. qualifier polymorphism is commonly needed.
for example the length method on strings has type length string!
int.
this paper adopts the convention that polymorphism is not instantiated in ways that would create invalid types.
for example the length polymorphic function would not be instantiated at ordernondet this makes no difference for the length function because such an instantiation would never be the most specific applicable one.
polymorphism rules for collections as described so far polymorphism cannot express the collection behaviors of section ii c2.
consider this potential typing for the size method in class collectionh ei size collectionh ei!
int it cannot be instantiated at ordernondet as size ordernondet collectionh e i!
ordernondet int because such an instantiation would include the invalid return type ordernondet int.
our type system resolves this problem by introducing two operators over polymorphic type variables and .
the operator converts ordernondet tonondet and leaves the other qualifiers unchanged.
the upward pointing arrow is a mnemonic for replacing ordernondet by something higher in the type hierarchy.
the operator is analogous but it converts ordernondet todet which is lower in the type hierarchy.
the precise type for size is size collectionh ei!
int this can be instantiated at all three type qualifiers without creating any invalid types size nondet collectionh e i!
nondet int size ordernondet collectionh e i!
det int size det collectionh e i!
det int these instantiations implement the semantics of section ii c2.
an example use of is in a method that returns the first element of a list.
its type is first listh ei!
e which can be instantiated as first nondet listh ei!
nondete first ordernondet listh e i!
nondete first det listh ei!
detens ds nondet string det string l nondet listhnondet stringi l.add ns l.add ds l nondet listhdet stringi l.add ns l.add ds l ordernondet listhdet stringi l.add ns l.add ds l det listhdet stringi l.add ns l.add ds table i addinvocations for a well formed list.
in addition to the and operators our type system also defines the shu e operator which converts detto ordernondet and leaves the other qualifiers unchanged.
this enables precise specification of certain collection operations.
for instance the type of the hashset constructor is hashset e!shu e hashseth ei that is invoking the hashset constructor with an argument of type det e will construct an ordernondet hashset.
differentiating binding and use precisely specifying mutation operations on collections requires another extension to polymorphism.
we discuss our approach to annotating mutation methods in three parts determinism types on nonreceiver parameters excluding ordernondet aliasing.
a determinism types on non receiver parameters consider a mutator method add.
its type without determinism qualifiers is add listhstringi string!
.
for simplicity this discussion treats the return type of addasvoid even though in the jdk it is string.
table i shows all possible invocations of addfor a wellformed list type.
the specification for addmust reject the calls that are struck out or else the body will not type check and unsafe client code would type check .
the specification should permit all the calls that are not struck out or else some safe client code will not type check.
it achieves these goals via another variant of qualifier variables use which represents a useof that does not affect the instantiation of .
ordinarily a polymorphic function is instantiated at the least upper bound of the types of all the arguments that correspond to uses of the type parameter.
for example function f int det int int int is instantiated at the least upper bound of the types of its first third and fourth arguments at a given call.
if no such instantiation exists with valid types or if any other argument does not conform to its corresponding formal parameter type the call does not type check.
by contrast function f int det int use int int is instantiated at the least upper bound of the types of its first and fourth arguments and the third argument must conform to that instantiation.
that is the type qualifier of the third argument must be a subtype of the least upper bound of the type qualifiers of the first and fourth arguments.
given this type system feature the type of list s addmethod can be precisely specified add listh ei use e!
at a call site if is not a subtype of the list type is invalid and the call does not type check.
as another example for the use operation the precise type of addall is 40addall listh ei use collectionh i!
boolean b excluding ordernondet the specification of the jdk must prohibit certain mutation operations on collections.
for example the annotations in the jdk must prohibit removing from ordernondet collections at deterministic indices.
the following client code must not type check void mustbeprohibited ordernondet list det string lst det int index lst.remove index since the iteration order on ordernondet collections is not guaranteed the element at index could differ across executions.
as a result lst.remove index could remove different elements on different executions leaving lstwith different contents on different executions which violates the contract of the ordernondet type qualifier.
however the specification of remove should permit removal from detand nondet collections.
a precise type is remove 2fnondet detg listh ei use int!
section iii c gives the java syntax of this qualifier polymorphism that excludes ordernondet.
c aliasing it is possible to create nondet aliases to ordernondet ordetcollections.
for instance by calling next orget.
consider the example below void aliastest ordernondet set det list det string set nondet int index det string str nondet list det string lst set.iterator .next lst.add index str variable lsthas type nondet listhdet stringi as a result of set iteration but an alias has type det listhdet stringi as a member of set .
the call list.add is unsafe and must not typecheck.
it mutates lstnon deterministically thereby violating the determinism guarantees provided by the detreference.
our type system prevents the unsafe behavior by prohibiting any mutation of collections having types nondet collectionhordernondet eiornondet collectionhdet ei.
it achieves this via jdk annotations on collection classes that guarantee that in the above example list.add does not typecheck.
a few jdk operations like iteration or access can create such unsafe aliases among otherwise invariant collection types.
these operations can return a nondet alias to an ordernondet or a det type.
our approach of preventing mutations on nondet collectionhordernondet eiand nondet collectionhdet eiis sufficient to prevent unsafe behavior.
iii.
i mplementation of our type system we implemented our type system for java in a tool named the determinism checker.
the implementation consists of lines of java code built atop the checker framework plus lines of tests annotated library methods a line manual etc.
all line measurements are non comment non blank lines.
the determinism checker works with java version and .
it is publicly available at sections iii a to iii c discuss java type qualifiers qualifiers for collections and polymorphic qualifiers respectively.
section iii d describes how the determinism checker implements invariant types for collections.
to reduce the annotation burden on the programmer the determinism checker uses defaulting and type refinement as presented in sections iii e and iii f. a. determinism type qualifiers a type qualifier is written in java source code as a type annotation.
a type annotation has a leading and is written immediately before a java basetype.
the determinism checker supports the type qualifiers nondet ordernondet and det plus others described below.
the meaning of det is with respect to value equality not reference equality.
for simplicity section iii uses the term collection and the type collection to represent arrays and any type that implements the iterable oriterator interfaces this includes all java collections including list set and user defined classes.
b. java collection types amapis deterministic if its entryset is deterministic.
the most widely used mapimplementations have the following properties hashmap is implemented in terms of a hash table which never guarantees deterministic iteration over its entries.
a det hashmap does not exist.
linkedhashmap like list can have any of the nondet ordernondet or det type qualifiers.
iterating over a linkedhashmap returns its entries in the order of their insertion.
an ordernondet linkedhashmap can be created by passing an ordernondet map to its constructor as in new linkedhashmap myondmap .
treemap can be det or nondet.
an ordernondet treemap does not exist because the entries are always sorted.
the determinism checker prohibits the creation of a det hashmap or an ordernondet treemap.
c. polymorphism java does not provide a syntax that can be used for qualifier polymorphism so the determinism checker follows the checker framework convention and uses a special type qualifier name polydet.
polydet stands for polymorphic determinism qualifier .
a qualifier polymorphic method m with type8 int det boolean!
string is declared as polydet string m polydet int det boolean .
each use of polydet stands for a use of the qualifier variable and there is no need to declare the qualifier variable .
qualifier polymorphism is common on methods that a programmer might think of as deterministic.
for example an addition method should be defined as polydet int plus polydet int a polydet int b ... this can be used in more contexts than det int plus det int a det int b ... 41just as a qualifier variable is written as polydet in java source code is written as polydet up as polydet down and shu e as polydet shuffle .
an occurrence of a qualifier variable that does not affect the binding of that variable use in section ii d3 is written polydet use .
a qualifier variable that excludes ordernondet is written as polydet noordernondet .
an occurrence of a qualifier variable that does not affect the binding of polydet noordernondet is written polydet use noordernondet .
all of this syntax is legal java code that can be compiled with any java or later compiler.
d. determinism invariant types a class or interface annotated with hasqualifierparameter is treated as invariant with respect to determinism type qualifiers.
for example the collection class is annotated as hasqualifierparameter nondet.class public interface collection e extends iterable e .. every subtype e.g.
list of a type annotated with hasqualifierparameter inherits this annotation and is therefore invariant w.r.t.
determinism qualifiers.
at a use site suppose a list type is annotated as nondet list det string lst.
any polymorphic field that is a field whose type qualifier is polydet in list accessed via lstwill resolve to nondet.
e. defaulting the determinism checker applies a default qualifier at each unqualified java basetype except uses of type parameters which already stand for a type that was defaulted at the instantiation site where a type argument was supplied .
this does not change the expressivity of the type system it merely makes the system more convenient to use by reducing programmer effort and code clutter.
defaulted type qualifiers are not trusted they are type checked just as explicitly written ones are.
in other words defaulting is a syntactic convenience that does not change the semantics or expressiveness of the type system.
as a result defaults never lead to false alarms.
the tool might issue an alarm that indicates that the default specification is not consistent with the code.
this is not a false alarm.
rather it indicates that the programmer needs to write the specification for that part of the program.
formal parameter and return types default to polydet.
the programmer can change the default for formal parameters and return types to det.
the det default makes it easier to annotate a codebase and requires less use of the determinism checker s polymorphism features but it makes the code usable by fewer clients it is appropriate for programs but not for libraries.
fields of a class annotated with hasqualifierparameter default to polydet.
types are inferred for unannotated local variables see section iii f. the default annotation for other unannotated types is det because programmers generally expect their programs to behave the same when re run on the same inputs.
f .
type refinement via dataflow analysis our type system is flow sensitive .
that is an expression may have a different type qualifier on everybugs warning annoproject loc found suppressions tations randoop checkstyle cf dataflow analysis bcel util bibtex clean html pretty print icalavailable lookup multi version control options plume util reflection util require javadoc table ii results of the determinism checker case studies line of the program based on assignments and side effects.
type preservation theorem is not violated because the refined type is always consistent with that is a subtype of the declared type.
type refinement does not apply to types that are invariant annotated with hasqualifierparameter because they have no subtypes.
flow sensitive type refinement applies to arbitrary expressions including fields and pure method calls.
a type refinement is lost whenever a side effect might affect the value.
this flow sensitive type refinement achieves local variable inference freeing programmers from writing many local variable types.
although the determinism checker performs local type inference within method bodies it does not perform wholeprogram type inference.
this makes separate compilation possible.
iv.
c ase studies to evaluate the usability of the determinism checker we applied it to several projects randoop a test generator checkstyle a linter the checker framework s dataflow analysis and the plume lib utilities.
all the materials are publicly available at for reproducibility.
we chose randoop because it is frequently used in software engineering experiments and its developers have struggled with nondeterminism .
we chose checkstyle because it was the only buildable project with a confirmed non concurrency determinism bug in deflaker s experiments.
we chose the dataflow analysis because while building the determinism checker on top to the checker framework we discovered a determinism bug in this component.
we began our case study after that bug was fixed.
we chose the plume lib utilities because they are used by randoop and thus were subject to the same extensive vetting process and have the same maintainers who were responsive to us.
some of the projects are libraries and some are programs.
table ii shows the results of the determinism checker case studies.
for reasons of space this paper discusses the randoop case study in greatest detail and the others more briefly.
42a.
case study randoop randoop is intended to be deterministic when invoked on a deterministic program .1however randoop was not deterministic.
this caused the developers problems in reproducing bugs reported by users in reproducing test failures during development and in understanding the effect of changes to randoop by comparing executions of two versions of randoop.
the developers took extensive action to detect and mitigate nondeterminism.
they used docker images to run tests to avoid system dependencies such as a different jdk having a different number of classes or methods.
they wrote tests with relaxed oracles assertions that permit multiple possible answers for example in code coverage of generated tests.
they used linters such as error prone to warn if tostring is used on objects such as arrays that do not override object.tostring and therefore print a hash code which may vary from run to run.
they used a library that makes hash codes deterministic by giving each object of a type a unique id that counts up from rather than using a memory address asobject.hashcode does.
they wrote specialized tools to preprocess output and logs to make them easier to compare such as by removing or canonicalizing hash codes dates and other nondeterministic output.
these efforts were insufficient.
in july the randoop developers spent two weeks of full time work to eliminate unintentional nondeterministic behavior in randoop commits e15f9155 32f72234 .
their methodology was to repeatedly run randoop with verbose logging enabled look for differences in logging output find the root cause of nondeterminism and eliminate it personal communication .
some of the nondeterminism was in libraries such as the jdk.
the most common causes were tostring routines and iteration order of sets and maps.
the most common fixes were to change the implementations of tostring and to use linkedhashset and linkedhashmap or to sort collections before iterating over them.
the developers did not make every setand mapalinkedhashset orlinkedhashmap because that was unnecessary and would have increased memory and cpu costs.
they chose not to make every ordernondeterministic list aset for similar reasons deduplication was not always desired and even where it was acceptable it would have increased costs.
that coding sprint did not find all the problems.
the developers debugged and fixed additional determinism defects over the next months using a similar methodology commits c15ccbf2 44bdeebd 5ff5b4c4 22eda87f and b473fd14 .
we analyzed randoop after all these fixes.
methodology we wrote type qualifiers in the randoop source code to express its determinism specification then we ran the determinism checker.
each warning indicated a mismatch between the specification and the implementation.
we addressed each warning by changing our specification 1users of randoop can pass in a different seed in order to obtain a different deterministic output.
randoop has command line options that enable concurrency and timeouts both of which can lead to nondeterministic behavior.intypevariable.java public list typevariable gettypeparameters set typevariable parameters new hashset super.gettypeparameters new linkedhashset super.gettypeparameters parameters.add this return new arraylist parameters fig.
the fix made by the randoop developers in response to our bug report about improper use of a hashset.
lines starting with were removed and those starting with were added.
our tool the determinism checker confirmed that other uses of new hashset were acceptable as were uses of new hashmap.
reporting a bug in randoop or suppressing a false positive warning.
we annotated the core of randoop the src main java directory which contains 25k non comment non blank lines of code.
we did not annotate randoop s test suite.
we annotated one package at a time starting with the packages that are most depended upon.
within a package we followed a similar strategy annotating supertypes first.
we reverse engineered each specification largely from the methods it calls.
if the determinism of classes and methods had been documented then our annotation effort would have been easy just converting english into type qualifiers.
the effort would have been much easier for someone familiar with randoop and yet easier if done while code is being written and is malleable.
running .
gradlew clean compilejava takes seconds to compile all files of randoop.
while also running the determinism checker as a compiler plugin the command takes seconds.
these numbers are the median of trials on an 8core intel i7 cpu running at .40ghz with 32gb of memory.
results the determinism checker found previouslyunknown nondeterminism bugs in randoop.
the randoop developers accepted our bug reports and committed fixes to the repository.
a summary of these bugs follows according to the randoop developers categorization severe issues nondeterminism in randoop output.
hashset bug the code under test is the code randoop is testing contrast to randoop s source code which the determinism checker is verifying .
suppose that in the code under test a type variable s bound has a type parameter that the type variable itself does not have.
this situation does occur even in randoop s test suite.
then randoop s output depends on the iteration order of ahashset.
the developers fixed this by changing hashset tolinkedhashset commit c975a9f7 shown in fig.
.
the determinism checker confirmed that other uses of new hashset were acceptable as were uses of new hashmap.
classpath bug randoop used the classpath environment variable in preference to the classpath passed on the command line.
this can cause incorrect behavior both in randoop s test suite and in the field if a user sets 43the environment variable.
the developers fixed both the problems by changing randoop to not read the environment variable commit 330e3c56 .
the determinism checker verified that all other uses of system and java properties did not lead to nondeterministic behavior.
moderate issues nondeterministic diagnostic output comparator bug is user visible on stdout in the default configuration .
hashmap bug randoop iterated over a hashmap in arbitrary order making the diagnostic output difficult to compare across different executions.
the class already implemented comparable so the developers changed methodweights.keyset tonew treeset methodweights .keyset in a forloop commit f212cc7e .
comparator bug randoop prints a list of methods in code under test that might be flaky sorted by a flakiness metric.
this list was itself nondeterministic when randoop considered two methods to be equally likely to be flaky.
the developers added a secondary sort key to a comparator commit 3d6cfb33 .
library bug the jacoco library uses a hashmap internally and returns a collection built from it.
this led to nondeterministic diagnostic output when randoop iterated over the collection.
the randoop developers sorted before iterating commit .
minor issues hash codes and timestamps.
the randoop developers may have overlooked these issues because their log postprocessing tools remove timestamps and some hash codes from the log.
hash code bug diagnostic output printed a hash code for brevity.
the developers changed it to have deterministic output commit 661a4970 .
this is similar to problems the randoop developers fixed in the past.
timestamp bug diagnostic output printed a timestamp.
the randoop developers fixed it by making the diagnostic code obey an existing option about whether to print timestamps commit a460df97 .
tostring bugs four classes inherited the object .tostring implementation so they printed nondeterministically.
the developers defined tostring methods commit f8bdf992 .
formatting bug diagnostic output used objectcontract .tostring which is inherited from object.
the developers changed the call to tocodestring which is deterministic and is more informative commit dff32159 .
unfixable issues the determinism checker issued other true positive warnings because randoop processes java code as part of its input.
the determinism checker identified that the code under test might behave nondeterministically.
the randoop developers could do nothing about these problems.
randoop is documented to behave nondeterministically only if the code under test is also nondeterministic.
b. case study checkstyle the checkstyle bugs were due to dependence on system properties instances nondeterministic logging 5instances and nondeterministic exception messages instances .
of the nondeterministic logging instances one was due to iteration over an ordernondet collection.
we suggested a fix for this bug which was accepted by the developers of checkstyle commit 5d2df145 .
c. case study checker framework dataflow analysis the determinism checker revealed instances in which the control flow graph data structure is nondeterministic.
these are similar to the problem that we encountered when building the determinism checker we had difficulty debugging because small changes in one part of the graph changed other parts.
it also significantly changed logging output and error messages by affecting iteration order.
we did not discover a case in which an algorithm s output was semantically different due to this nondeterminism.
the maintainers fixed all of these commits 601b6b58 3057728a 8e7287b0 18f22f83 67702a13 0a0ea102 .
the determinism checker revealed instances in which debug output was nondeterministic because it included hash codes.
the maintainers fixed these by assigning each object a unique id that is printed instead of a hash code commits bcba3cb7 24148f91 0ffe4902 .
the id is based on order of creation so it is deterministic across runs.
d. case study plume lib utilities the determinism checker found determinism bugs across the plume lib utilities.
one of the true positives is because of nondeterminism in logging output commit 1a9ad3bd .
the remainder are in normal user visible output and their causes are use of nondeterministic tostring the file system system properties mutating polymorphic collections and collection ordering .
the file system nondeterminism is dependence on files in the user s home directory we did not count merely reading files passed on the command line as nondeterminism.
e. false positive warnings the determinism checker issued a total of false positive warnings across all benchmarks or about for every lines of code.
the most common reasons responsible for of false positive warnings were an algorithm is used that does not depend on the ordering of its input but the determinism checker cannot verify this.
for instance the elements of an ordernondet list during iteration are nondet but some computations sum max searching etc.
are det.
other instances of order insensitive operations include merging collections and mutating all elements of an ordernondet collection deterministically.
all classes that implement an interface define tostring to return det string but the tostring method of the interface is not so annotated.
this is the case for the java.lang.reflect.type interface.
some of the false positives in this category were due to calling object.tostring in contexts where we could not establish 44whether the invoked tostring method was deterministic.
we counted these as false positives but the code is error prone changes anywhere in the code could change which values flow to the invocations making them nondeterministic.
as part of future work we could enhance the determinism checker with an analysis to track which expressions have a run time class that overrides tostring deterministically.
this will eliminate these false positives or it will show them to be true positives.
the determinism checker should relax conservative rules when it is safe to do so.
for example it should be legal to pass a det list to a method that expects an ordernondet list if the method never mutates its input.
uses of caches.
even if a cache is populated with nondeterministic keys so long as the key value mapping is deterministic looking up a det key yields a det value.
the determinism checker cannot verify a method that iterates over all the elements of an ordernondet collection to create another ordernondet collection.
array sorting can type refine an array from ordernondet to det but only if there are no aliases whose type is not refined.
our type system does not incorporate an alias analysis so it forbids the type refinement to avoid a type loophole.
iterating over a polydet collection to create or modify another polydet collection.
for example the following code is safe but the call to adddoes not type check because variable elthas type polydet up .
void m polydet list polydet string input polydet list polydet string output new polydet arraylist for string elt input output.add elt a class type parameter has upper bound polydet but the determinism checker does not always instantiate it with the most precise type.
for example if a method has a det receiver inside that method the upper bound can be treated as det.
the determinism checker should treat polydet up as equivalent to polydet for noncollection types.
if a class is declared as det then any instance with polydet type should also be treated as det rather than as polydet.
an object has a tostring method that returns det or polydet but the determinism checker s analysis loses track of this fact before the call to tostring so the determinism checker issues a warning.
a method iterates over an ordernondet collection and calls a log method that uses a sortedset in its implementation.
the determinism checker flagged a code pattern that is illegal in general assigning a detvalue to anordernondet variable but is safe in these specific instances because the value is immutable or there is no aliasing.
of the false positives are caused by a bug in our implementation checker framework issues .
discusses how to improve the determinism checker to address some of these false positive.
f .
annotation effort the number of annotations one per lines of code is much higher than we would prefer.
nonetheless it compares favorably to the extensive effort by the randoop developers section iv a .
moreover the determinism checker found issues in large software randoop checkstyle and cf dataflow that the developers did not.
as another point of comparison the code contains fewer total determinism type qualifiers than java generic type arguments.
in other words java generics cause more clutter than determinism types do.
v. c omparison to nondex the state of the art in flaky test detection is nondex .
section ix explains how nondex works.
this section compares the errors reported by nondex and the determinism checker.
a. case study with nondex we ran nondex on versions of the projects that contain all nondeterminism bugs that the determinism checker found.
nondex found none of those bugs.
it did find two flaky tests both in checkstyle.
in each case the nondeterministic code was in the test not in checkstyle proper.
our case study did not detect them because we ran the determinism checker on each project s source code but not its tests.
many of the bugs are not detectable by nondex.
for example in randoop only hashset bug andclasspath bug are covered by test cases apparently the randoop developers had already found most of the nondeterminism problems that are covered by a test case.
the reason for nondeterminism in classpath bug was a call to the system.getproperty method which is not modeled by nondex.
b. the determinism checker on nondex benchmarks section v a shows that the determinism checker finds errors that nondex does not.
this section determines whether nondex finds errors that the determinism checker does not.
its authors ran nondex on opensource projects and nondex found flaky tests in of them .
the flakiness that nondex found was due to methods getdeclaredfields getdeclaredmethods getfields getzonestrings entryset keyset values in classes class dateformatsymbols hashmap .
for every compilable project where the nondex paper stated a source of flakiness we ran the determinism checker on the part of the project that the nondex authors determined as flaky.
in every case the determinism checker issued a warning on the nondeterministic code.
in other words the determinism checker s recall was .
45static public fieldaccess get class type ... while nextclass !
object.class field declaredfields nextclass.getdeclaredfields ... fig.
nondeterministic code from reflectasm.
getdeclaredfields returns its result in arbitrary order.
figure shows a sample of nondeterministic code from these benchmarks.
we annotated the type of field declaredfields as det field det .
that type means a deterministic array of deterministic fields analogously to det list det field .
the determinism checker issued a warning at the assignment because getdeclaredmethods returns det field ordernondet which is an order nondeterministic array of deterministic fields.
the nondex authors state we found that manually inspecting these failures was rather challenging and we leave it as future work to automate debugging test failures.
the determinism checker reports source locations which makes it easier for the programmer to fix issues and the annotation effort serves as valuable documentation and prevents regressions.
vi.
c omparison to deflaker deflaker like nondex reports tests that could be flaky.
we were unable to run deflaker on any of our case studies other than checkstyle which we chose from deflaker s experiments because deflaker works with projects built with maven but the projects other than checkstyle use gradle as their build system.
the determinism checker found bugs in checkstyle section iv b whereas deflaker found .
a. the determinism checker on deflaker benchmarks deflaker found previously unknown flaky tests in projects that were being actively developed at the time the paper was written.
the authors reported of these tests out of which were addressed by the maintainers of those projects .
we ran the determinism checker on the part of each of these codebases where the reported bug was fixed as in section v b. the determinism checker reports errors at the source of nondeterminism whereas deflaker reports the test case where this nondeterminism manifests.
the rationale for choosing these tests is that we could perform a fair comparison between the output of the determinism checker and the root cause reported by the developers in the respective issue trackers.
four of the seven flaky tests two in achilles one each in jackrabbit oak and togglz were caused by a race condition which the determinism checker cannot detect.
this is a strength of deflaker over the determinism checker.
the determinism checker also found the source of flakiness in checkstyle.
this bug was in a test case that treated an array returned by class.getdeclaredconstructors as deterministic.
this is erroneous because getdeclaredconstructors returns an order nondeterministic array.
we were unable to build togglz and nutz which had one flakiness issue each.
however weextracted the source code causing the flakiness in these repositories into test cases after looking at the corresponding issues on github.
the determinism checker detected the errors.
vii.
d iscussion while the overhead of annotation for our approach is high the benefits are also high.
ours is the only approach that discovers all determinism errors and guarantees that no more remain.
the trade off may not be worthwhile for every programmer and for every program.
when determinism is important our approach is easier and more effective than testing based approaches.
future work such as type inference can further improve our approach making it more attractive to programmers.
type inference can reveal what the program s behavior is but not whether that behavior is desired.
to find bugs requires comparing the program s behavior to a specification.
in our specification and verification approach the programmer provides the specification and the tool does the verification.
the programmer s specification may permit nondeterminism in some parts of the program.
an alternative would be for a tool to guess a specification and report wherever the program deviates from the guessed specification.
such an approach would be easier for programmers to use.
however this approach is inherently unsound and incomplete so it does not meet our design goal of soundness.
in addition such an approach requires access to the whole program including any libraries or clients it might be linked against and it often has poor scalability.
future work could compare such an approach to ours.
we also see great value in specifying some parts of the program and using inference on the rest and future work could explore such a combination.
as an alternate design strategy one could imagine providing a different deterministic implementation of the collection library methods.
however determinism is not necessary or desirable in all parts of a program.
for example a map that is not iterated over has no need for deterministic order.
a deterministic version of map iteration would be less performant and would be incompatible with the assumptions of existing programs.
this approach does not address other types of nondeterminism such as coin flipping dates and times system properties etc.
this approach also does not address nondeterminism in the user program.
viii.
t hreats to validity our type system does not capture nondeterminism from concurrency.
it could be combined with a type system for concurrency see section ix .
in our case study we disabled two checks in the determinism checker because they led to many false positives.
one check gives all caught exceptions nondet type to account for the fact that unchecked libraries might use nondeterministic values in thrown exceptions.
the other check requires conditional expressions to be det to prevent implicit flows .
implicit flows are a well known challenge for dataflow analysis and standard approaches lead to imprecise 46abstract values e.g.
in a taint analysis most of the program state becomes tainted .
a programmer can work around the problem by declaring more types to be detrather than polydet but that reduces the contexts in which a library can be used.
the determinism checker only examines the code it is run on.
unchecked libraries with incorrect specifications might introduce nondeterminism even if the determinism checker issues no warnings.
the determinism checker is sound with respect to reflection.
the case studies found important previously unknown errors but their results might not generalize to other programs.
we mitigated this problem by showing that the determinism checker finds a superset of the non concurrency nondeterminism identified by other tools.
ix.
r elated work the state of the art for detecting nondeterministic tests is nondex .
nondex uses a hand crafted list of methods unique method names in classes as potential sources of flakiness.
for each of the identified methods the authors built models that return different results when called consecutively.
a modified jvm then runs a given test multiple times and reports the test as being flaky if it observes diverging test output.
while this approach produces precise results it requires manual inspection and considerable debugging effort to locate and fix the source of flakiness.
the determinism checker in contrast reports the cause of nondeterminism a line of code at compile time requiring little debugging effort.
however the determinism checker requires much more upfront effort and it produces false positive warnings.
nondex s approach of identifying and modeling methods with nondeterministic specifications is analogous to our library specifications.
so far we have annotated methods across classes in the jdk and junit.
deflaker is another approach for flaky test detection.
it relies on a version control history.
it computes a diff of the code covered in the current version and the previous one.
if there exists a test case whose code coverage does not include this diff but still produces different results on the two versions being compared the test case is flagged as being flaky.
this approach does not require jvm modifications and integrates easily with production software.
deflaker reported previously unknown bugs in open source projects of which were addressed by the developers of these projects.
deflaker is agnostic to the code under test and can therefore report flakiness arising out of concurrency which the determinism checker cannot.
nondeterminism in tests is of interest to both researchers and software developers alike .
empirical analysis suggests that most of the flakiness in tests is caused by async await concurrency or test order dependency.
our approach is complementary to such techniques and aims to prevent nondeterminism from causing harmful effects.
eilers et al.
propose constructing product programs to help verify hyperproperties i.e properties that reason about multiple program executions .
this dynamic approach checkshyperproperties over kexecution traces by comparing the program state after executing the product program with that of the original program.
specifying properties over collections would require quantification over every element in the array.
in the authors study the effect of nondeterminism in mapreduce programs with a specific focus on nondeterminism caused by non commutative reducers.
several techniques have been proposed to test whether a deterministic implementation conforms to its nondeterministic finite state machine .
presents an approach that can automatically verify properties in branching time temporal logic systems that are inherently nondeterministic.
bocchino et al.
present a type and effect system that provides compile time determinism guarantees for parallelism.
they ignore other sources of nondeterminism.
our work is complementary and addresses a previously overlooked problem.
failing tests that are unrelated to code changes can be expensive in monetary costs and in developer effort.
proposes techniques to classify tests as false alarms if they are known to be caused by testing infrastructure or other environment issues.
presents an approach that detects brittle assertions in tests by performing a taint analysis on inputs classified as controlled and uncontrolled.
investigates the effects of the test independence assumption on other techniques such as test prioritization selection etc.
other approaches analyze test dependencies and either prevent them or use this information for other optimizations.
the approaches in focus on differentiating bugs due to tests from those caused by source code.
x. c onclusion we designed a type system that expresses determinism specifications for sequential programs.
to the best of our knowledge ours is the first compile time verification approach addressing the problem of nondeterminism in sequential programs.
we implemented our type system in java and applied it to real world software.
our tool the determinism checker found errors that the developers had missed despite spending extensive effort on the problem of nondeterminism.
in experiments the determinism checker found a superset of the nondeterminism bugs in sequential programs that were found by the state of the art flaky test detectors nondex and deflaker .