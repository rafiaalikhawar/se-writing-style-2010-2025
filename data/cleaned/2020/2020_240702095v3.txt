tiger a generating then ranking framework for practical python type inference chong wang jian zhang yiling lou mingwei liu weisong sun yang liu and xin peng college of computing and data science nanyang technological university singapore chong.wang jian zhang weisong.sun yangliu ntu.edu.sg school of computer science and shanghai key laboratory of data science fudan university china yilinglou pengxin fudan.edu.cn school of software engineering sun yat sen university china liumw26 mail.sysu.edu.cn abstract python s dynamic typing system offers flexibility and expressiveness but can lead to type related errors prompting the need for automated type inference to enhance type hinting.
while existing learning based approaches show promising inference accuracy they struggle with practical challenges in comprehensively handling various types including complex parameterized types and unseen user defined types.
in this paper we introduce tiger a two stage generatingthen ranking gtr framework designed to effectively handle python s diverse type categories.
tiger leverages fine tuned pre trained code models to train a generative model with a span masking objective and a similarity model with a contrastive training objective.
this approach allows tiger to generate a wide range of type candidates including complex parameterized types in the generating stage and accurately rank them with user defined types in the ranking stage.
our evaluation on the manytypes4py dataset shows tiger s advantage over existing methods in various type categories notably improving accuracy in inferring user defined and unseen types by .
and .
respectively in top exact match.
moreover the experimental results not only demonstrate tiger s superior performance and efficiency but also underscore the significance of its generating and ranking stages in enhancing automated type inference.
index terms type inference pre trained code models generating then ranking contrastive learning i. i ntroduction python s dynamic typing system while fostering adaptable and expressive code can pose challenges like code comprehension maintainability and type related errors .
python enhancement proposals peps were introduced to enhance python s type hinting system advocating for type hints to improve code quality and support tools like static type checking .
despite this manual type annotation can be labor intensive and error prone .
to this end there is a growing trend towards adopting automated approaches for inferring variable types through contextual analysis encompassing both rule based and learningbased methodologies.
rule based approaches rely on predefined patterns and rules for accurate type hinting but may lack comprehensive coverage for diverse scenarios .
learning based approaches gaining prominence transform corresponding author jian zhang jian zhang ntu.edu.sg .type inference into different tasks.
they can be classified into three types classification based .
utilize classification models trained on contextual features to predict variable types .
similarity based utilize deep learning similarity calculation models to assess candidate types based on their similarity scores ranking them accordingly.
generationbased utilize generative models to produce types based on given inputs .
however these learning based approaches face limitations in considering various visible types notably parameterized types and unseen user defined types.
note that user defined types in this paper also include third party types.
classification based approaches rely on fixed sized type vocabularies e.g.
types for typewriter leading to numerous out of vocabulary oov types such as complex parameterized types e.g.
dict or unseen user defined types.
similarity based approaches use import information to gather user defined types and rank candidate types based on contextual similarities.
however these approaches struggle to cover the myriad parameterized types e.g.
union formed by elementary types e.g.
union str int .
generation based approaches can generate creative types including complex parameterized types but most struggle with recognizing and predicting unseen user defined types not in the training set.
large language models llms such as chatgpt are increasingly utilized for type inference tasks.
for instance peng et al.
introduced typegen a generation based approach that utilizes parameter frozen llms and incorporates visible user defined types in prompt construction.
however it faces accuracy challenges for function arguments as discussed in their paper due to intricacies and robustness issues with prompt engineering on non tunable parameter frozen llms .
furthermore chatgpt based approaches including typegen face practical limitations regarding inference cost and scalability.
typegen relies on external apis for interactions with chatgpt and employs voting mechanisms for accurate inference resulting in significant time and financial overhead.
to overcome these limitations we introduce a two stage framework named generating then ranking gtr framework arxiv .02095v3 aug .
generating .
rankinggenerated types user defined types ranked typesexpected typefig.
.
the generating then ranking framework as depicted in figure .
this framework combines the strengths of both generation based and similarity based approaches allowing for the consideration of comprehensive visible types .
in the initial generating stage our objective is to produce diverse candidate types including commonly used elementary types like uuid and parameterized types like union to fill the type placeholders i.e.
type in figure .
subsequently in the ranking stage visible user defined types potentially unseen during training such as idmap and idmapkey are effectively ranked alongside the generated candidates based on similarities.
furthermore for efficiency and cost considerations we opt for relatively lightweight pretrained code models like the 220m parameter codet5 specifically fine tuned for type inference diverging from the use of llms like chatgpt.
we present tiger a novel type inference approach that implements the generating then ranking framework.
to facilitate the online gtr inference depicted in figure tiger initiates with offline training of a generation model and a similarity model with collected annotated python functions.
during the generation model training tiger masks annotated types with type placeholders to create type missed functions.
these functions are employed with the span masking objective to train the model in generating types to fill the placeholders.
for training the similarity model tiger analyzes import statements to identify visible user defined types which are combined with the types generated by the generation model to form a set of candidate types.
subsequently a contrastive training objective is utilized to train the model to learn robust representations for both type missed functions and candidate types facilitating effective measurement of contextual similarities between them.
during online inference armed with the trained models tiger performs the twostage generating then ranking process.
given a type missed function containing a type placeholder this process generates type candidates using the generation model.
these are then ranked based on their similarity to user defined types visible in the scope using the similarity model.
we extensively evaluate tiger s inference effectiveness and efficiency on the manytypes4py dataset a widely adopted benchmark in previous studies.
our results demonstrate tiger s superiority in inference accuracy across all type categories compared to six baseline models.
specifically tigerachieves an impressive accuracy rate of .
and .
in top exact match for predicting user defined and unseen types respectively marking significant improvements of .
and .
over the best baseline approach rq1 .
furthermore tiger exhibits enhanced robustness across various variable categories encompassing local variables function arguments and return values rq2 .
we also assess the efficiency of tiger highlighting its potential for optimization in largescale inference scenarios rq3 .
finally our ablation study validates the significant contributions of both the generating and ranking stages to tiger s overall performance rq4 .
to summarize this paper makes the following contributions a novel two stage framework generating then ranking which systematically generates and ranks candidate types alongside user defined types facilitating a comprehensive consideration of visible candidate types.
tiger a practical python type inference approach that implements the two stage framework through fine tuning pre trained code models with specific training objectives.
extensive experiments on the manytypes4py benchmark demonstrate the effectiveness and robustness of tiger across diverse type and variable categories particularly for unseen user defined types prevalent in real world scenarios.
additionally efficiency evaluations of tiger showcase its potential for optimization in large scale inference scenarios.
ii.
r elated work a. rule based type inference rule based methods in type inference rely on predefined rules for inferring variable types.
a rule can only be activated when all the underlying premises are known after which it determines the type of the variable based on a set conclusion .
to address the imperative for static type hints within dynamically typed programming languages numerous techniques have emerged for the purpose of type inference and verification.
notable examples include pyright and pylance microsoft pyre meta pytype google and python s official type checker mypy .
apart from industry tools several academic methodologies have emerged for type inference across various programming languages like python and javascript .
while these approaches excel in terms of accuracy they confront a significant challenge stemming from dynamic language features and external function calls .
this challenge manifests as a limitation in their coverage hindering their ability to provide comprehensive type inference scenarios.
b. learning based type inference classification based approaches.
in addressing the type inference problem supervised learning has been employed by researchers with large scale training data to train classificationbased models.
pradel et al.
introduced typewriter which utilizes probabilistic type prediction and search based refinement to infer function types from partially annotated code and validate them using a gradual type checker.
wei etal.
introduced a probabilistic type inference approach for typescript that employs a graph neural network to analyze a program s type dependency graph facilitating predictions of both standard and user defined types.
yan et al.
proposed dlinfer an approach that collects slice statements for variables through static analysis and employs a bi directional gated recurrent unit gru model to learn type propagation information for inference.
additionally typebert demonstrated that by harnessing the token sequence inductive bias found in bert style models and having access to ample data it is feasible to surpass the type annotation performance of even the most advanced models.
these approaches encounter practical challenges when dealing with oov types including unseen user or library defined types.
as a result they struggle to accurately predict types for a significant portion of variables in real world projects.
similarity based approaches.
allamanis et al.
presented a graph neural network model that leverages probabilistic reasoning and deep similarity learning to predict types including rare and user defined types based on a program s structure names and patterns.
mir et al.
proposed type4py a hierarchical neural network model employing deep similarity learning to infer likely types for program elements by distinguishing between similar and dissimilar types in a high dimensional space.
peng et al.
introduced hityper a hybrid type inference approach combining static inference and similarity based models by leveraging type dependency graphs tdgs to record and integrate type dependencies among variables facilitating iterative static inference and neural predictions until the complete inference of tdgs.
while these approaches demonstrate the capability to handle arbitrary types they require pre determined candidates limiting their effectiveness in adequately considering numerous parameterized types.
generation based approaches.
following the type annotation conventions recommended in peps the python type inference problem can be transformed into a conditional generation problem.
for instance it can be treated as a clozestyle fill in blank task where a type placeholder is inserted after a variable that requires annotation.
pre trained code models are then employed to generate types fill in the placeholder with types based on their learned code naturalness.
to fully leverage their generation capability some studies have fine tuned these pre trained models to improve inference accuracy.
these generation based approaches with fill in blank task formulation lack awareness of unseen user or library defined types.
in a recent study peng et al.
introduced a generation based approach known as typegen for python type inference which relies on parameter forzen llms like gpt .
andgpt .typegen integrates type dependencies derived from lightweight static analysis with incontext learning to construct few shot chain of thought cot prompts.
these prompts are employed to generate both type predictions and accompanying explanations.
while this llm based generative approach demonstrates notable effectiveness in type inference it faces practical challenges 3fig.
.
type placeholders for three categories of variables particularly with regard to the scalability concerns arising from the resource intensive interactions with expensive llms.
c. pre trained code models in se recent research indicates that pre trained code models encapsulate valuable information about code syntax and semantics identifier and namespace concepts and natural language naming.
to harness this rich code information for downstream software engineering tasks researchers commonly fine tune these models on task specific data.
examples of such tasks include code generation completion code search defect detection vulnerability detection location and program repair .
researchers have explored the application of prompt based approaches with pre trained code models in various software engineering tasks.
for instance wang et al.
investigated the effectiveness of prompt learning in code intelligence tasks such as clone detection and code summarization.
another study by wang et al.
utilized pre trained code models as knowledge bases and employed prompt learning for variable explanation.
in this study we strategically fine tune pre trained code models to facilitate practical type inference.
iii.
p roblem definition we define the type inference problem within a python function as a cloze style fill in blank task focusing on three categories of variables local variables function arguments and return types.
to annotate the type for a target variable we insert a type placeholder based on its category adhering to the annotation guidelines outlined in the peps.
in figure the three numbered type represent the type placeholders inserted for local variables function arguments and return types respectively.
in practical applications we address one target variable in a given python function at a time following the approach adopted in previous studies .
functions containing type placeholders are referred to as type missed functions where suitable types need to be predicted to fill the placeholders with difference categories of types including builtin types parameterized types and use defined or third party types.
iv.
a pproach the overview of tiger is presented in figure .
tiger first offline trains a generation model and a similarity model by fine tuning existing pre trained code models i.e.
base models using annotated python functions i.e.
1and2 .
the trained models are used to support the online two stage generatingthen ranking inference i.e.
.annotated functions type masking import analysisgenerative fine tuning contrastive fine tuning generation model similarity modeltype generating type ranking user defined types type missed function expected type 1generation model training 2similarity model training 3two stage type inferencetype missed function userdefined types ranked type list n nfig.
.
overview of tiger 1when training the generation model tiger employs a process where it masks variable types in annotated functions replacing them with type placeholders to create type missed functions.
these type missed functions along with the corresponding expected types are then utilized for fine tuning a base model.
the fine tuning process is guided by a generative span masking objective which directs the model to generate appropriate types to fill the placeholders.
2for the training of the similarity model tiger conducts an analysis of import statements to identify user defined types available for the type missed functions.
these identified types are then combined with the types generated by the generation model to form a comprehensive set of candidate types.
tiger employs a contrastive training objective to fine tune a base model instructing it to differentiate expected types from all candidate types based on their contextual similarities with the type missed functions.
3with the trained generation model and similarity model tiger executes type inference for a given type missed function that contains a type placeholder.
this process adheres to the gtr inference framework which encompasses both the generation of candidate types and their subsequent ranking alongside available user defined types.
in the ranking stage candidates are ranked by combining the generative likelihood and the contextual similarity yeilded by the generation model and similarity model respectively.
a. model architecture selection we select encoder decoder architecture models such as codet5 as the base model for the gtr framework and provide a concise overview of its encoding decoding process.
encoder decoder model encoder decoder models typically undergo specific pre training on a code corpus with the masked span prediction task compelling the model to fill in masked span token sequence placeholders within the code.
moreover with the encoder decoder architecture such models can capture bidirectional context within code while generating token sequences of arbitrary length and combination to fill the placeholders .
this dual capability perfectly aligns with ourfill in blank type inference task distinguishing it from encoderonly models e.g.
codebert and graphcodebert and decoder only models e.g.
incoder .
encoding decoding process the encoding decoding process of an encoder decoder model is a critical aspect for the fill in blank task of type inference.
encoding.
after tokenizing a given type missed function into a token sequence x where bos and eos denote the beginning and end of the sequence the encoder processes x and generates corresponding hidden states hx i.e.
feature vectors .
these vectors capture bidirectional contextual information from x and the encoding process is mathematically expressed as hx encoder x decoding.
the resulting hxis then fed into the decoder tasked with sequentially processing an input partial token sequence and predicting the next token.
specifically at each decoding step the t th step the decoder takes hxand the partial sequence y t as input to compute the corresponding hidden states h t y fory t h t y decoder hx y t subsequently the decoder then utilizes a classification head i.e.
linear layers on hyt 1to predict a v dimensional probability distribution pt corresponding to the token vocabulary v as expressed by pt head hyt guided by the distribution p the decoder predicts the next token y t either by greedily selecting the token with the highest probability or employing specific sampling techniques .
the decoding process concludes when the eos is fed.
after finishing all the decoding steps on the input token sequence y we denote the corresponding hidden states and predicted token sequencesmasking type missed functionfig.
.
type annotation masking with type placeholder by the decoder as hy and y y y ... y n eos respectively.
b. generation model training the training of the generation model within tiger commences with the retrieval of type annotations present in python functions adhering to the guidelines outlined in the pep proposals.
subsequently fine tuning of a base model i.e.
a pre trained encoder decoder model is carried out employing a generative span masking objective .
type annotation masking given a python function with annotated local variables function arguments and return types following peps guidelines tiger systematically processes these type annotations.
it applies a masking procedure to each annotation replacing them with the placeholder type .
this operation results in the creation of a type missed function complemented by the corresponding expected type.
for instance by masking the type annotation idmapkey associated with the function argument key tiger generates a typemissed function containing a type placeholder as illustrated in figure accompanied by the expected type idmapkey .
after processing all annotated python functions tiger obtains a training data that consists of type missed functions and the corresponding expected types.
generative fine tuning tiger proceeds with the training of the generation model involving the fine tuning of a base model based on acquired type missed functions and their corresponding expected types.
for each pair comprising a type missed function func and its corresponding expected typetype tiger initiates the process by tokenizing them into their respective token sequences denoted as xandy using the model s tokenizer.
subsequently tiger employs the encoding decoding process of the base model as detailed in section iv a2 and calculates the loss.
specifically tiger employs the encoder to generate the hidden states hxforx cf.equation .
subsequently in the decoding process it feeds the first t tokens in y i.e.
y t into the decoder computing the probability distribution ptusing equations and .
following this the cross entropy loss is computed based on the expected next token ytandpt adhering to the span masking objective that is commonly utilized in the pre training encoder decoder models .
the fine tuning process involves minimizing this loss guiding the optimization of model parameters using the adam optimizer which aims to enhance the model s capability to maximize the probability of predicting ytwithin pt.
resulting generation model after fine tuning the resulting generation model in tiger serves two primary purposes candidate type generation.
when presented with a type missed function func tiger initially tokenizes it into the corresponding token sequence x. subsequently tiger feeds xinto the generation model s encoder and utilizes the decoder to generate a token sequence y adhering to the encoding decoding process outlined in section iv a .
it is essential to note that during the decoding process the previously predicted tokens serve as the decoder s input to predict the next token.
in other words when predicting the next token y tat the t th decoding step the input partial token sequence y t cf.
section iv a comprises the previous predicted t tokens i.e.
y t bos y ... y t by the decoder.
upon completing the decoding process the generated token sequence y undergoes conversion into a candidate type.
additionally tiger integrates beam search into the decoding process generating multiple token sequences and consequently yielding multiple candidate types for the placeholder within the given type missed function.
generative likelihood computation.
when presented with a type missed function func and a candidate type type tiger initiates the process by tokenizing them into the corresponding token sequences xandy.
employing the encoding decoding process detailed in section iv a tiger feeds xinto the generation model s encoder.
subsequently it sequentially inputs the tokens in yinto the decoder to compute the generative likelihood of y. specifically at the t th decoding step the decoder takes as input the initial t 1tokens in y i.e.
y t and predicts the probability distributionpt.tiger retrieves the probability of the next token yt inyfrompt denoted as p yt and computes the generative likelihood of type by multiplying all probabilities when finishing inputting all decoding steps on y lik func type y yt yp yt c. similarly model training the purpose of the similarity model is to effectively gauge the contextual similarity between the given type missed function and the candidate types.
to achieve this tiger employs a contrastive training objective which seeks to cultivate generalizable and robust representations for both type missed functions and candidate types.
this objective achieves this goal by maximizing the similarity between the type missed function and the expected type while minimizing the similarity between the type missed function and other candidate types.
import analysis tiger incorporates user defined types for the type placeholder within the given type missed function while constructing the training dataset for contrastive learning.
this data is derived by analyzing import statements existing in the same project environment as the type missed function in accordance with established practices .
specifically tiger parses the current source file containing the target function and gathers candidate user defined types from two distinct sources.
firstly all type definitions in the current file are directly considered as candidate user defined types.
additionally tiger examines import statements in the current file to identify the source files being imported.
it then includes the types defined in these imported files in the list of candidate user defined types.
the gathered user defined types might be project specific with names that are not encountered unseen in other projects.
contrastive fine tuning the fine tuning process for the similarity model consists of three pivotal components negative instance construction similarity computation and model training.
adhering to the terminology commonly used in contrastive training conventions we designate the type missed function as the anchor the corresponding expected type as the positive instance and other candidates as negative instances .
negative instance construction.
constructing suitable negative instances for the expected type is crucial for effective contrastive training.
tiger achieves this by generating knegative instances from two distinct sources.
for the given type missed function i.e.
anchor the first source utilizes the trained generation model employing a beam search algorithm during model decoding to generate k candidates cf.section iv b .
these candidates typically encompass builtin types commonly used third party types and parameterized types.
the second source involves userdefined types obtained through import analysis.
tiger combines the types from both sources excluding the positive instance and randomly selects kones as the negative instances.
similarity computation.
to quantify contextual similarity between the anchor namely func and a positive negative instance namely type tiger tokenizes them into their respective token sequences xandy.
subsequently these sequences undergo processing by a pre trained base model i.e.
a pre trained encoder decoder model executing the encoding decoding process described in section iv a .
upon completion of the process tiger computes the average of the hidden states hxproduced by the encoder as the vector representation of func and the average of the hidden states hyproduced by the decoder as the vector representation of type.
the two representations namely a vg hx and a vg hy are employed to assess the contextual similarity between func andtype by calculating their cosine similarity sim func type cosine a vg hx a vg hy model training.
given the anchor func tiger computes the infonce loss based on it its corresponding positive instance pos and the generated negative instances n. the loss function is defined as follows l logesim func pos esim func pos p neg nesim func neg maximizing this loss function guides the model to enhance the disparity between the similarities of the positive instance and the negative instances allowing the model to learn to distinguish the most suitable type for the given typemissed function.
the optimization process utilizes the adam optimizer to update the model s parameters.
resulting similarity model following fine tuning the resulting similarity model demonstrates an effective capability to measure the contextual similarity between the provided type missed function and its associated candidate types as depicted in equation .
due to the contrastive training objective and the incorporation of negative instances from two distinct sources the similarity model exhibits strong generalizability and robustness encompassing both generated candidates and user defined types.
d. two stage type inference leveraging both the generation model and the similarity model tiger employs the two stage gtr strategy for type inference as depicted in figure .
type generating when presented with a function and a variable slated for annotation tiger initially inserts a type placeholder after the variable based on its category i.e.
local variable function argument or return value creating a type missed function func akin to the example in figure .
subsequently this type missed function undergoes processing by the generation model employing beam search during decoding to generate ktoken sequences thereby forming kcandidate types cf.section iv b3 .
type ranking tiger conducts import analysis as detailed in section iv c to acquire user defined types available for the type placeholder in func .
these user defined types combined with the generated candidates constitute a more comprehensive candidate pool.
note that if a generated candidate is neither a built in type nor a parameterized type whose base is a built in type and it is not found in the user or library defined types we exclude it from the candidate pool.
subsequently tiger ranks all candidates in the pool by considering both generative likelihood and contextual similarity for each candidate.
for a given candidate cand in the pool tiger computes its generative likelihood using the generation model cf.section iv b and its contextual similarity with func using the similarity model cf.section iv c3 .
the final score of candidate cand is determined by the sum of generative likelihood lik func cand and contextual similarity sim func cand expressed as score cand lik func cand sim func cand ultimately all candidates for the given type missed function are ranked based on their scores in descending order forming a ranked list of types for the variable intended for annotation.
the inclusion of both generative likelihood and contextual similarity in the score calculation is motivated by specific considerations inspired by the methodology utilized in contrastive text generation .
solely relying on generative likelihood as discussed in section iv b could lead tobiased rankings.
during training the decoding process is guided by the ground truth input which is absent during generation .
this mismatch introduces exposure bias making the decoding process less robust in distinguishing between good and bad tokens in the certain decoding steps.
in contrast the similarity model generates robust and generalizable representations for both the generated candidates and the user defined types.
this is achieved by combining these two sources during the construction of negative instances for contrastive learning .
therefore by integrating both generative likelihood and contextual similarity tiger capitalizes on the task alignment benefits of the generation model and the generalizability and robustness of the similarity model.
this dual consideration enhances the overall effectiveness of thegtr inference process.
v. e valuation we conduct extensive experiments to assess the effectiveness oftiger in python type inference from various dimensions.
the research questions are summarized as follows rq1 effectiveness how effectively can tiger infer types for variables?
how effectively can tiger handle with various categories of types especially parameterized types and unseen user defined types?
rq2 robustness how robust is tiger in inferring types for different categories of variables including local variables function arguments and return types?
rq3 efficiency how effectively can tiger infer types for different sources of types encompassing elementary types parameterized types and unseen user defined types?
rq4 ablation study are the two stages in gtr useful for type inference?
a. setup we present the experimental setup for the evaluation encompassing the implementation dataset baselines and metrics.
implementation in our current implementation we utilize codet5 as the base model for training both the generation and similarity models given its widespread use as an encoderdecoder pre trained model for code.
we implement tiger in python using the transformers library a widely used library for language models.
the base models for training the generation and similarity models is downloaded from the hugging face hub .
following established practices we consider the top candidate types for predictions setting k i.e.
beam size during both the training and inference stages of tiger .
the training hyperparameters for both the generation model and similarity model include a training epoch of a learning rate of 1e and a training batch size of .
dataset in line with prior studies we conduct the evaluation on the manytypes4py dataset which is partitioned into training and test sets with an project ratio no overlapping projects between training set and test set resulting in instances for training and instancestable i overview of training and test sets .
datasettype category variable category ele par usr unseen var arg ret training .
.
.
.
.
.
test .
.
.
.
.
.
.
for testing.
for the typegen evaluation the authors further sampled instances from the entire test set to reduce the computational cost associated with calling large language models llms .
to maintain consistency in our experimental setup we employ this sampled subset as the definitive test set for all experiments pertaining to rq1 rq4.
among the test instances involving user defined types instances require the inference of types that are previously unseen in training set .
these unseen types are challenging to predict and provide insights into the practicality of the inference approach.
the training set is utilized for training both tiger and baselines as well as providing few shot examples for the prompt construction in typegen .
the test set is then employed to assess the type inference effectiveness of tiger and baselines.
table i provides an overview of the training and test sets illustrating the distributions of different type and variable categories.
ele par and usr unseen represent different type categories denoting elementary parameterized and unseen user defined types respectively.
var arg and ret represent different variable categories denoting local variables function arguments and return values respectively.
baselines we include several state of the art learningbased type inference approaches as baselines.
we omit rulebased approaches from consideration given that learning based methods have demonstrated superior effectiveness in prior studies .
typewriter a classification based type inference approach that utilizes rnns to encode various code features e.g.
identifiers and code tokens to predict types for target variables.
note that typewriter cannot process local variables therefore the metrics are calculated only on the subset consisting of function arguments and return types.
type4py a similarity based type inference approach classifies new python programs by assigning them to a specific type clusters using those clusters as the predicted types for the target variables.
hityper a hybrid type inference approach combining static inference and similarity based models by leveraging type dependency graphs tdgs to record and integrate type dependencies among variables.
codet5 zs a pre trained codet5 base model utilized for zero shot variable type inference treating the problem as a cloze style fill in the blank task similar totiger.
codet5 ft a fine tuned codet5 base model trained with the same training data of tiger also treating the problem as a cloze style fill in the blank task.
typegen an llm generation based type inference approach that leverages prompt engineering techniques including in context learning and chain of thoughts to harness the capability of llm for generating types for target variables.
for the baselines we utilize the released replication implementations and data.
we opt not to compare our approach with the other two learning based type inference methods namely the classification based dlinfer and the generation based typet5 .
these approaches heavily rely on static analysis and were originally trained and evaluated on smaller datasets and projects respectively .
despite our attempt to apply dlinfer and typet5 to the larger manytypes4py dataset projects scalability issues rendered them inapplicable.
additionally methodological differences such as dlinfer segmenting source code into syntax broken short snippets e.g.
incomplete statements and typet5 not processing local variables within functions make a fair comparison challenging.
metrics following established practices we employ two commonly used metrics to evaluate the inference accuracy of tiger and the baselines exact match em this metric calculates the ratio of type predictions made by an approach that exactly matches the type annotated by developers.
base match bm this metric calculates the ratio of type predictions made by an approach that shares the common base type i.e.
the outermost type with the type annotations provided by developers.
for example union is base matched but not exact matched with union .
b. effectiveness rq1 we evaluate the effectiveness of tiger and the six baseline approaches in python type inference.
the detailed inference accuracy of tiger and the baselines on the test set consisting of instances is provided in table ii.
overall results across the entire test set column all our approach tiger demonstrates top and exact match metrics of .
.
and .
respectively and top and base match metrics of .
.
and .
respectively.
considering fine grained type categories columns ele par and usr unseen tiger achieves either the best or second best results in terms of exact match and base match.
particularly noteworthy are the substantial improvements see rows compared with the best baseline in almost all type categories especially in unseen user defined types up by .
and .
in top exact and base match respectively with minimal declines less than observed in few type categories such as top exact match for elementary types ele .
an interesting observation is that the base match metrics of all the approaches are notably higher than the exact matchmetrics for parameterized types i.e.
column par compared with the other two type categories columns ele and usr unseen .
this discrepancy arises because inference approaches correctly predict the base type base but face challenges predicting the specific combinations of .
comparison with classification based approach tiger significantly outperforms the classification based baseline approach typewriter for all type categories in terms of exact match and base match metrics.
specifically in top exact match tiger demonstrates a significant improvement over typewriter with an overall enhancements of .
across the entire test set and ranging from .
to .
for fine grained type categories.
the superiority is attributed to the limitations of classification based approaches such as typewriter which rely on fixed sized type vocabularies.
such vocabularies often fail to comprehensively cover diverse parameterized types and userdefined types in their visible candidate set.
tiger addresses this limitation by leveraging the capacity of its generating stage to produce complex parameterized types and the ranking capability of its ranking stage to handle unseen user defined types.
notably while typewriter achieves about accuracy for unseen types as its type vocabulary covers a portion of unseen types in the manytype4py test set it is unable to predict types beyond its vocabulary limit.
comparison with similarity based approaches while demonstrating comparable accuracy for elementary types tiger significantly outperforms the similarity based baseline approaches type4py and hityper for parameterized types and unseen user defined types in terms of exact match and base match metrics.
specifically in top exact match tiger achieves notable improvements over type4py and hityper with enhancements of .
and .
respectively across the entire test set ranging from .
to .
over type4py and from .
to .
over hityper for parameterized types and user defined types.
the enhancements achieved by tiger can be attributed to the following reasons.
while similarity based approaches can handle commonly used parameterized types e.g.
list they struggle with inferring diverse parameterized types due to the vast number of possible combinations.
in contrast tiger leverages the creative type generation capacity of its generation model during the generating stage to overcome this limitation.
moreover in the case of unseen user defined types tiger s superior performance is primarily attributed to its robustness and generalizability in the ranking stage facilitated by the contrastive training objective .
comparison with generation based approaches among the three generation based baseline approaches codet5 zs exhibits poor accuracy due to its application in a zero shot setting while the fine tuned codet5 ftand typegen achieve the second best or the co best results for specific type categories and metrics.
specifically codet5 ftdemonstrates effectiveness for elementary types column ele and parameterized types column par but is relatively ineffective for user defined types column usr unseen whereas typegen achievestable ii inference accuracy of tiger and baseline approaches .
cls sim and gen represent classification based similarity base and generation based respectively .
the best and second best results for each category are are highlighted .
metric approach catetorytop top top ele par usr unseen all ele par usr unseen all ele par usr unseen all exact match em typewriter cls .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
type4pysim95.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
hityper .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
codet5 zs gen34.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
codet5 ft .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
typegen .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
tiger gen sim .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
to the best baseline .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
base match bm typewriter cls .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
type4pysim95.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
hityper .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
codet5 zs gen38.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
codet5 ft .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
typegen .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
tiger gen sim .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
to the best baseline .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
typewriter and hityper are capable of inferring types for and test instances respectively.
consequently their metrics are calculated using only these instances.
good effectiveness for user defined types but struggles with handling parameterized types effectively.
codet5 ft s lower efficacy in handling user defined types stems from its inability to grasp project specific contexts while the limited effectiveness of typegen for parameterized and unseen user defined types can be attributed to its reliance on prompt engineering techniques to leverage the capability of llms which often poses challenges in designing an optimal prompt template .
in comparison our approach tiger consistently achieves substantial inference accuracies for all type categories especially unseen user defined types column usr unseen with enhancements of .
.
and .
.
compared to codet5 ftand typegen respectively in top exact match.
these improvements are attributed to the comprehensive visible candidate pool and robust inference capacity integrated within the two stage inference framework.
considering the prevalence of encountering unseen user defined types in real world projects our approach proves to be more practical and applicable.
summary tiger outperforms all six baseline approaches across the entire test set achieving a top exact match metric of .
.
for fine grained type categories tiger consistently achieves almost the highest accuracies particularly for unseen user defined types with enhancements of .
and .
compared to the best two baselines codet5 ftand typegen respectively in top exact match.table iii top e xact match of codet5 ft typegen and tiger for different variable categories .
the best and second best result for each category are are highlighted .
approachtop em top em top em var arg ret var arg ret var arg ret codet5 ft .
.
.
.
.
.
.
.
.
typegen .
.
.
.
.
.
.
.
.
tiger .
.
.
.
.
.
.
.
.
c. robustness rq2 as noted in prior research type inference for certain variable categories such as function arguments and return values poses greater difficulty.
hence we delve deeper into the robustness of tiger and the best two baselines in rq1 codet5 ftand typegen across various variable categories.
the evaluation results are outlined in table iii.
overall tiger demonstrates superior robustness across different variable categories.
specifically codet5 ftexhibits significant disparities .
in top exact match with tiger for function arguments column arg while achieving comparable results for local variables column var and return values column ret .
conversely typegen displays notable differences .
and .
in top exact match with tiger for local variables column var and return values column ret while attaining comparable results for function arguments column arg .
in summary our approach tiger consistently achieves consistently accurate results for all the three variable categories.
tiger achieves consistently strong results across all three variable categories for two main reasons.
first compared to typegen tiger formulates the inference problem as a unified cloze style fill in the blank task aligning perfectly with the pep guidelines and the pre training tasks of the base models.
this allows for effective leveraging of the capacity of the pre trained models.
in contrast typegen depends on distinct prompt templates tailored for each variable category constraining the consistent utilization of llms across all categories.
second compared to codet5 ft which also utilizes the unified fill in the blank task formulation the contrastive training employed in tiger s similarity model training enhances robustness in discriminating multiple candidates .
although inferring types for function arguments is particularly challenging as their corresponding definition statements are often unavailable within the given function tiger can effectively discriminate candidate types for function arguments based on limited code context such as the usage information of the arguments.
summary in comparison to codet5 ftand typegen our approach tiger showcases strong and more consistent inference accuracy across all three variable categories particularly for function arguments and return types.
d. efficiency rq3 we evaluate the inference efficiency of tiger alongside the best two baselines codet5 ftand typegen using a set of test instances randomly sampled from the test set.
all three approaches are executed on the same machine with a stable network connection.
for codet5 ftand tiger a single nvidia v100 32g is utilized and the test instances are processed one by one sequentially i.e.
batch size of .
for typegen we adopt the default settings from their original implementation.
the average inference time of the three approaches for each instance is depicted in figure .
notably our approach tiger and codet5 ftcan process one instance within second on average while typegen requires significantly more time for inference more than seconds .
this discrepancy can be attributed to the fact that tiger and codet5ftemploy relatively smaller models compared to typegen 220m parameters vs. 175b parameters and do not rely on complex program analysis such as code slicing.
furthermore both tiger and codet5 fthave the potential for further optimization in large scale inference scenarios by leveraging parallel processing on gpus e.g.
increasing the batch size .
however typegen faces scalability challenges due to its reliance on openai s online apis for accurate inference which significantly impacts the efficiency of typegen given potential issues such as unstable network connections api request frequency limits and high financial costs.
fig.
.
average inference time of codet5 ft typegen and tiger.
table iv contributions of the two stages .
the best and second best results for each category are are highlighted .
ablationtop exact match ele par usr unseen var arg ret all tiger .
.
.
.
.
.
.
.
only generating .
.
.
.
.
.
.
.
only ranking .
.
.
.
.
.
.
.
the non zero values arise from certain user defined types sharing names with elementary types.
summary on average our approach tiger processes each instance in approximately second a performance comparable to codet5 ftand significantly more efficient than the llm based typegen.
moreover tiger s efficiency can be further enhanced for large scale inference scenarios through gpu parallel processing.
e. ablation study rq4 we conduct an ablation study to explore the contributions of the two stages of tiger.
table iv showcases the inference results of tiger and its variants only generating andonly ranking .
when solely utilizing the generating stage the inference achieves robust accuracy for most type and variable categories except for unseen userdefined types column usr unseen .
conversely when only employing the ranking stage the inference demonstrates the highest accuracy for unseen user defined types but performs poorly for the other type and variable categories.
by synergizing the strengths of both stages tiger harnesses the creativity of the generation model and the discriminative ability of the similarity model resulting in consistently practical inference accuracy across all type and variable categories.
summary the results of the ablation study confirm the significant contributions of both stages i.e.
generating andranking to robust and practical type inference.
f .
case study we have identified certain suboptimal cases as illustrated in figure concerning user defined types.
in figure a tiger s generation model produces complex parameterized types for a type missed function with their corresponding generative likelihoods i.e.
lik .
however the expected type promise does not appear in the candidate list.defthen self callback on error none ifnotisinstance callback thenable callback type promise callback on error on error ifself.cancelled callback.cancel returncallback ... omittedground truth promise a user defined type thenable lik .
callable lik .
union thenable lik .
union callable lik .
union thenable lik .
candidates by generation model of tiger promise sim .
thenable sim .
...candidates by similarity model of tiger1 thenable score .
promise score .
lik .
...final resultsby tigercomplexparameterizedtypedare generated promise is ranked as top candidate by similarity promise is ranked after thenable in final resultsdue to its lower likelihood a example predictions for missing type promise defonbatchend self run id epoch type epoch num batch num timer data type results ifepoch typeinself.detailed batch epoch types details log database.batchdetails.create data data results results else details none ... omittedground truth data a user defined type dict lik .
list lik .
list lik .
str lik .
dict lik .
candidates by generation model of tiger data sim .
results sim .
...candidates by similarity model of tiger1 str score .
dict score .
dict score .
list score .
data score .
lik .
final resultsby tigerdiverseparameterizedtypedare generated data is ranked as top candidate by similarity data is ranked th in final resultsdue to its low likelihood b example predictions for missing type data fig.
.
two suboptimal cases conversely tiger s similarity model ranks the ground truth type as the top candidate with a high similarity score i.e.
sim .
when the two models are combined tiger eventually returns promise as the 2nd result just after thenable .
similarly in figure b the expected data type is absent from the candidates generated by the generation model but is ranked 1st by the similarity model.
however in the final results it only appears in 5th place.
these suboptimal outcomes can be attributed to the fact that some user defined types which are not generated as candidates by the generation model tend to have lower likelihoods compared to model generated candidates.
as a result even with high similarities from the similarity model their final scores as calculated by eq.
remain lower.
while we have attempted to adjust the weights of the two measures in eq.
finding anoptimal balance has proven challenging.
in the future we plan to explore more effective methods for combining these two measures such as incorporating likelihood into the contrastive loss.
vi.
t hreats to validity the primary internal threat to validity arises from potential data errors within the training and test sets.
to mitigate this threat we employ the widely used manytypes4py dataset for training and evaluating python type inference approaches ensuring consistency with common practices in the field.
another potential internal threat to validity pertains to the settings of model training hyperparameters.
to address this concern we adhere to standard values for training hyperparameters including learning rate and epoch numbers.
regarding the external threat although we have consdiered a varity of baselines the absence of a comparison with dlinfer in our evaluation also poses a external threat to validity.
the lack of a publicly available implementation and the complexity of reimplementation make it challenging to include dlinfer for a fair comparison.
instead we compared with the more recent state of the art approach typegen which also leverages code slicing similar to dlinfer.
vii.
c onclusion and future work this paper introduces tiger a novel python type inference approach employing a gtr framework.
tiger trains a generation model with a generative span masking objective and a similarity model with a contrastive training objective.
both models contribute to the gtr inference process generating and ranking candidate types alongside user defined types based on generative likelihood and contextual similarity.
evaluation on the manytypes4py dataset reveals that tiger performs effectively across various type categories notably demonstrating significant improvements in unseen user defined types.
furthermore the evaluation results underscore the resilience and efficiency of tiger underscoring the significance of the employed two stage approach.
in the future we plan to extend the applicability of tiger to other dynamic programming languages such as javascript and explore the further integration with static analysis for type validation.
additionally we aim to adapt tiger to address other practical type inference challenges including those related to partial python functions.
data availability our replication package is publically available at .
acknowledgement this research project is supported by the national research foundation singapore and the cyber security agency under its national cybersecurity r d programme ncrp25 p04taicen .
any opinions findings and conclusions or recommendations expressed in this material are those of the author s and do not reflect the views of national research foundation singapore and cyber security agency of singapore.