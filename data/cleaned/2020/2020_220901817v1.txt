an exploratory study on the predominant programming paradigms in python code robert dyer rdyer unl.edu university of nebraska lincoln lincoln ne usajigyasa chauhan jchauhan2 huskers.unl.edu university of nebraska lincoln lincoln ne usa abstract python is a multi paradigm programming language that fully supports object oriented oo programming.
the language allows writing code in a non procedural imperative manner using procedures using classes or in a functional style.
to date no one has studied what paradigm s if any are predominant in python code and projects.
in this work we first define a technique to classify python files into predominant paradigm s .
we then automate our approach and evaluate it against human judgements showing over agreement.
we then analyze over 100k open source python projects automatically classifying each source file and investigating the paradigm distributions.
the results indicate python developers tend to heavily favor oo features.
we also observed a positive correlation between oo and procedural paradigms and the size of the project.
and despite few files or projects being predominantly functional we still found many functional feature uses.
ccs concepts software and its engineering multiparadigm languages object oriented languages functional languages imperative languages .
keywords python programming paradigms empirical study acm reference format robert dyer and jigyasa chauhan.
.
an exploratory study on the predominant programming paradigms in python code.
in proceedings of the 30th acm joint european software engineering conference and symposium on the foundations of software engineering esec fse november singapore singapore.
acm new york ny usa pages.
https introduction python s popularity has been rising the last few years especially in fields such as data science.
the python language is often taught as the first programming language to students at many universities and has been gaining rapid ground in recent years .
the python language is considered a multi paradigm programming language with full support for object oriented programming.
every value in the language is actually an object with many built in methods use dir to view them e.g.
dir .
the language also supports several other programming paradigms to varying degrees such as functional programming lambda list comprehensions etc esec fse november singapore singapore .
acm isbn .
.
.
.
programming if while etc procedural programming def and aspect oriented programming mixins .
despite the language s popularity to date no one has investigated if there are predominant paradigm s utilized within python code and projects.
by predominant paradigm we mean essentially how someone would answer the question what paradigm is this code?
due to the mixed nature of python almost every file is technically mixed to some degree.
however when humans look at the code if for example of the code is utilizing procedures we would tend to call it procedural .
thus procedural would be the predominant paradigm for such code.
in cases where people might hesitate to confidently answer such a question those wind up being labeled mixed .
questions one might ask about the predominant paradigm of python code include do developers tend to favor object oriented or functional features when writing code in python?
do projects tend to utilize mostly a single paradigm s features or features from many paradigms?
does the size of the project have any relation to the particular feature s it utilizes?
these questions are important to understand as they could help guide future research.
for example the program comprehension community is interested in how people understand existing python code and knowing what paradigm if any is predominant could help focus those efforts as it may be a confounding factor they could better control for.
researchers investigating the maintenance of python code could benefit knowing the predominant paradigm as certain techniques may work better or worse on specific paradigms .
researchers looking at code smells may want to focus on defining new smells in the most predominant paradigm s or may want to correlate object oriented oo smells with oo code in python to see if the frequencies match.
if they don t figuring out why python has more less instances of a smell could lead to better language designs in the future.
educational researchers could benefit from knowing the predominant paradigm so when they provide code examples they can focus on language features new programmers are more likely to encounter.
in this work we investigate the use of language features in the python language by analyzing over 100k open source python projects from github.
to do this we develop an automated classification script using boa .
this script is able to take python source files and classify each as functional object oriented procedural and or imperative.
we show that this script agrees with human judgements over of the time based on a small sample.
we then leverage this script to investigate how often python source files and projects as a whole utilize each paradigm.
1arxiv .01817v1 sep 20221class mynumbers func oo x oo imp def m self oo def m3 oo proc return oo proc y m3 oo proc return y oo def iter self func oo self.x oo return self oo def next self func oo y self.x oo self.x oo return y oo 15x mynumbers oo figure python program showing multiple paradigms our results show that overall python developers tend to favor an oo paradigm.
however many single file projects the often contain utility scripts seem to favor a procedural paradigm.
despite the low number of files and projects classified as functional we still observe some functional features as highly used as oo features.
we motivate the need to classify a source file s dominant paradigm in the next section.
then we pose several research questions in section and outline our approach in section .
we then discuss the results of applying our approach in section .
then in section we discuss threats to the validity of the study.
in section we discuss closely related works.
finally we conclude in section .
motivation there are many programming paradigms such as imperative programming which includes object oriented oo and procedural programming and declarative programming which includes functional dataflow reactive and logic programming.
most modern programming languages are actually multi paradigm in the sense that while they typically have a predominant paradigm they support and emphasize they also include features from other paradigms.
python is one example of such a language as table shows.
python is predominantly an oo language as every value is represented by an object.
for example if you ask the interpreter type it tells you the type is class int .
but while python is at its core an oo language it also supports other paradigms.
this multi paradigm support often also extends to common python libraries.
for example the django web framework supports both class based and function based procedural approaches for implementing views in the framework.
this is partially a result of the evolution of the framework but both approaches are supported today and there seems to be disagreement on which one people should prefer to use .
1functional features as defined in python s official functional how to guide .this can be confusing to new users of the language as they are not only learning a new language but might not know how to utilize some of the paradigms.
classifying such features is also difficult as some such as iterators exhibit properties of more than one paradigm.
in figure and the discussion below we show an example and explain how we classify those statements.
imperative programming in imperative programming developers specify exactly how something should be computed using statements that modify a program s state.
while procedural and object oriented programming are both derivatives of imperative here we classify a statement as imperative only if it does not explicitly use features from another paradigm.
this ignores paradigms assigned to it from its enclosing scope which we clarify next.
for example in figure while the mention of names e.g.
mynumbers and iter on lines and is an imperative feature because those lines also include class or function declarations we do not mark them imperative.
however the second line assigningx is imperative as that line ignoring its enclosing scope makes no use of other paradigms.
after marking that statement in isolation we also look at the statement s enclosing scope and so wealso count it as oo since it is a member of a class.
procedural programming procedural programming organizes code into re usable elements called procedures note that python calls these functions in this paper we call them procedures to avoid confusion with functional programming features that can be called with different arguments.
an example procedure is shown in figure on lines and it is called on line .
note that in this example the procedure is nested inside a class method.
declaring a method and declaring a procedure in python look very similar but we consider methods to have a class as its immediate enclosing scope.
this includes class and static methods.
object oriented programming object oriented programming provides abstractions in the form of classes and instances of those classes called objects.
users can define classes that contain state fields and operations on that state methods .
instances can be created and then passed around via reference.
and classes support data hiding in the form of private members.
we consider any declaration of a class including the entire body of the class to be a use of oo in python.
this also includes accessing lines and and creating objects line .
we also classify method calls on objects as oo.
when classifying the paradigm used one should first look at each statement inside the class body and ignore it exists inside the class.
does it use functional lines and or procedural line features?
if so it is actually utilizing multiple paradigms and we classify it as such.
functional programming python s official documentation includes a guide on writing functionally with the language .
in this paper when we talk about functional python programming this guide is explicitly what we are referring to .
functional programming is a declarative style of programming compared to the prior three which are all imperative .
this means when writing functional code developers focus more on describing what they want the program to do and focus less on how they want the program to do it.
the basic module in functional programming is a function.
in python functions in the functional 2table classification of python language features to programming paradigm s python language feature imperative procedural object oriented functional1 if else elif x while loop x break x continue x assert x del x array indexing x pass inside loop x pass inside class x x pass inside def x x return x function def x nested function def x class declaration x inheritance x method def x with x x try x x except x x finally x x raise x x forloop x x not inoperator x x yield x x function as arg x lambda functions x list comprehension x decorators x generator expressions x iterators next iter x x x x send into generator x x iter x x map x x sorted x x filter x x any x x all x x itertools.
x x functools.
x x enumerate x x zip x x sense are lambda s. in functional programming users create and compose functions together.
iteration is a core tenant of functional programming and typically accomplished with recursive functions.
it is important to understand how frequently people are using functional features in python as it helps inform future changes to the language.
there are several python enhancement proposals peps accepted or under consideration to add additional functional features such as the already added generator expression pep and co routine support for generators pep and the proposed structural pattern matching pep .
research questions in this paper we focus on the following exploratory questions rq1 what is the distribution of programming paradigms for python projects on github for each project and for each individual file?
is one paradigm used more frequently than the others?
how often are files and projects utilizing multiple paradigms?
rq2 what are the most and least used features for some programming paradigms?
are there differences in how 3language features are used for the most and least used paradigms?
rq3 are project size and predominant paradigm related?
are size metrics like number of committers commits files or statements related to the predominant paradigm?
rq4 how does programming paradigm use change over time?
do files change their predominant programming paradigm over time?
what are common first last predominant paradigms?
next we outline our approach to answer these questions.
approach in this section we outline the approach used to answer the posed research questions.
first we discuss the tool and dataset used for our analyses.
next we discuss a manual classification of python projects to programming paradigms.
finally we discuss an automated solution and compare with the manual approach.
.
tools and dataset to answer the research questions we needed a large number of python projects from many different domains.
we had originally looked at utilizing a boa dataset containing python projects however that data was limited to data science related projects and we wanted a broader dataset.
as such we opted to utilize boa s open source compiler infrastructure to build our own dataset of python projects.
we utilized the public github api to query for any project indicating python as the primary programming language and sorted based on stargazer count.
we then cloned the results and built a dataset.
table shows some statistics for that dataset.
table statistics for the python data analyzed in this paper projects all revisions revisions with a python file python files python files main branch python file snapshots asts the dataset seemed to contain a large number of files with duplicate asts ignoring comments and whitespace differences so we identified the duplicates found by converting the ast into json format then hashing that string similar to lopes et al .
and keep only one instance from each set.
we removed a total of duplicate files .
of all files .
all numbers shown in this paper are already deduplicated.
the dataset contains over 100k projects.
there are over million revisions half of which contain python files and .
million unique python source files comprising over billion abstract syntax tree ast nodes.
table shows the per project statistical distribution for various size metrics showing the median project has revisions files with statements and 35k ast nodes.table per project statistics for the python dataset revisions python files statements asts mean std min max for most analyses we only example the latest snapshot of the main branch.
for rq4 and part of rq3 that involve committers or commits we also examine the full history of each file.
for analysis we then query this data using the boa language.
the output of those queries is a specific text format which we then converted to csv.
we finally process the csv files using python scripts and the pandas library.
all data queries and scripts are provided in our replication package .
.
manual paradigm classification first we need the ability to classify python files into the programming paradigm s used.
to do this we took a sample from the previously published boa python dataset containing a total of source files.
from those files sorted by project url then filename we systematically sampled every 985thyielding files.
some of the projects files no longer exist on github so if we found such a case we would simply move to the next file until we found one that still existed.
this resulted in a sample size of source file urls giving us a confidence level of with a confidence interval of .
.
we then had three people from our research lab including the authors perform a manual classification task.
the task was given a source file a url to view it on github indicate the predominant programming paradigm s you see this file as using.
the raters were explicitly told to ignore imports we discuss this more in a later section and were allowed to mark zero one or more than one paradigm.
the goal was not to look and see if a single use of a paradigm occurred but rather to answer the question would you call this file functional oo procedural imperative?
each human rater was unaware of the judgements from the other two raters at the time of rating.
from this data we computed fleiss kappa to measure the interrater agreement level.
fleiss s kappa was used over cohen s kappa as there were more than two raters.
the result was a kappa value of .
.
this is often interpreted as good agreement among the raters with .
being very good .
after all three raters finished their judgements a discussion round was held.
the discussion focused only on files where there was not unanimous agreement.
discussion was ordered based on paradigms meaning all files where the judgement on functional was not agreement were discussed then all files for oo procedural and finally imperative.
when discussing the person who had disagreed gave a case for why they rated the file either as or 4not as that particular paradigm.
then all three raters were free to update their score.
this repeated for all disagreements.
table human and machine judgements on a sample human judgements machine judgements imperative mixed oo procedural after discussion we then re calculated the fleiss s kappa and found a value of .
meaning very good inter rater agreement was reached.
this final set of judgements shown on the left of table were then used to help calibrate our automated approach which we describe next.
.
automatic paradigm classification once we had some manual judgements on a sample of data we were able to more clearly see some of the features that influenced the human judgements.
we first listed as many syntactical and some api features from python that might indicate a particular programming paradigm.
the results of this classification were already shown in table .
next we discussed and assigned each feature in the table to a single predominant paradigm our goal was a assignment which was not always possible .
based on this classification we wrote a boa query to classify each statement into one or more paradigms.
the goal was to map each statement approximately based on the classification in the table.
so for example the following code o.setresult list map lambda x x would be analyzed and generate the following counts that indicate there was use of functional features the map call and the lambda use of oo features calling setresult on object o use of procedural features the list call uses of imperative features and total statement.
while some numbers might intuitively seem wrong we explain how we obtain them.
writing this script required several important decisions.
first some of the language features being identified are expressions and we were aiming to classify at the statement level as an analog to line numbers which boa does not contain .
thus we had to introduce a function to clamp the counts at the statement level as a single statement might contain or more paradigm uses.
this ensured that a paradigm was counted at most once per statement.
second boa simply parses the source code and provides abstract syntax trees asts .
it does not attempt to resolve types or provide type information for analysis.
this complicates several of the mappings.
to get around this issue we first track all imports in the file to help see what names might be a module.
we also analyze the imports to see specifically if a function was imported from thefunctools oritertools modules as we classify all of those functions as functional paradigm.
third we had to attempt to assign calls of the form expr.m as either procedural or oo.
if expr is an object this is an oo methodcall on that object.
if expr is a module it is a normal procedural call.
we utilize the imports to aid this process.
fourth we decided to treat imperative a bit special.
we found that almost every line of code at least in python seems to contain at least one imperative feature such as using a name assignment or simple expression arithmetic .
as such many of the imperative counts were nearly identical to the statement counts.
we decided to make a simple change that stated if the statement directly used another paradigm do not increment imperative.
thus the imperative counts we obtain are counts of statements that are fully imperative.
fifth we had to decide how to handle large blocks.
for example when a class is declared how should we count its body?
clearly the line declaring the class is oo.
we decided the entire body should contribute to oo regardless of what the individual statements did.
but we did have to handle some corner cases such as what do we do with a function nested inside of a method?
in that case it counts as both procedural and oo as it is clearly a procedural method it does not take self as an argument but as it is contained within a class s method it is contributing to the functionality of that method and thus is part of the oo nature of the file.
finally we had to decide how to handle imports in terms of contributing toward counts.
it was clear these should count as statements toward a file s total statement count.
what was less clear was if it should contribute toward counts for the paradigms.
part of the issue was that with the lack of resolved types we are not usually certain what item is being imported.
and in the case of importing a module should we analyze the whole module to determine what paradigms that used?
what if it was an external library?
these issues led us to decide to only count them as statements and ignore any potential paradigm count s .
.
.
accuracy.
to verify the accuracy of our automated approach we first built an oracle repository of hand coded python files containing various features and named them with the counts we expected.
we then built a local boa dataset from only that repository and used it as a test case to identify and fix issues.
we also added regression tests to the repository as we found interesting cases that seemed to give weird results.
we then verified the results in comparison to the human judgements described in the previous section.
here we used the same sample of files and had the machine classify the file s paradigm.
the goal was to take a file s counts and label it with a single label either a paradigm or mixed .
we tried various strategies all variants of taking the largest number.
ties or all values result in mixed labels regardless of strategy.
we set cutoffs requiring that the winning value must be a certain percentage of the file s statements and tried cutoffs of and .
we then looked at the performance compared to the human judgements.
surprisingly the cutoff at performed the best meaning the machine simply looked at the largest number and as long as there were no ties that was declared the winner.
this agreed with the humans on .
of the projects.
when we computed the cohen s kappa to see how well this rating agrees with the human ratings here it is a single set of values based on majority agreement we saw a kappa of .
meaning good agreement.
.
.
classifying entire projects.
the approach described so far only classifies a single file into a paradigm.
we also need the ability 5to classify entire projects into a paradigm.
for this task we utilize the counts generated from the prior tool.
first for each project we add the counts across all their files in the latest snapshot of the main branch.
this gives us a total count across all files which is what we utilize to classify the project.
unlike the prior approach however we do not simply go with the largest value wins.
similar to classifying individual files if there is a tie for first or if the counts somehow are all we would mark the project as mixed.
for the other cases we utilized the following algorithm 1if second or largest case return mixed 3if second .
and largest second .
case return mixed 5if largest .
and largest second .
case return mixed while the authors did not perform a full sensitivity analysis to determine the cutoff points we did try several variations and picked the best performing values based on our intuitions the data observed and lengthy discussion.
note that it is possible for more than of the statements in a file to be classified to more than one paradigm.
this is due to our classification technique where we consider each statement and classify what paradigm s it uses.
for example in figure on line we classify that statement as both oo and procedural.
depending on the statements it is possible the entire file is classified as up to into multiple paradigms.
thus we needed to consider the edge cases shown in the algorithm above.
here largest is the largest count by percentage of total statements and second the second largest.
when discussing the strategy the authors quickly realized that some cases were easy to distinguish.
for example if two or more paradigms account for at least of the statements then this project is clearly mixing paradigms.
similarly if the most used paradigm only accounts for of the total statements it was also mixed.
these are the first case.
the second case was if the two highest used paradigms are both over and within of each other then we also considered it mixed.
finally the third case was if the most used paradigm is less than half the statements and within of the second most used paradigm we considered it mixed.
exploratory study in this section we discuss the results of analyzing the python dataset based on the research questions posed.
we also discuss the important findings discovered during analysis and what the implications are of those findings to the community.
.
rq1 what is the distribution of programming paradigms in python?
the first question we want to investigate is simply what the distribution of programming paradigms is for python files and projects.
to answer this question we first look at each individual file.
we only consider files from the repository s main branch .
the results are shown in figure as both a box plot and a summary table.first we look at the statistics on the number of statements in a file.
the median value is statements per file but there is a lot of variance from typically empty init files up to 858k but most files are relatively smaller.
next we look at the statistics on the paradigm counts for files.
here we can see the median values for oo and imperative are the highest with procedural having a lower median value but otherwise performing similarly to imperative.
next we look at the files in terms of what percent paradigm each file is.
figure shows the results.
here it becomes a bit more obvious that at the file level oo seems to really dominate the files with the median percentage of a file being around oo and imperative.
functional is the least percentage of files.
finally we use our automated approach to classify each file to a particular paradigm.
the results are shown in figure .
here we introduce the new category called mixed meaning at least two paradigms dominate the file.
once the script starts classifying files we can see a clear lead for oo with almost more files classified oo compared to the second highest procedural .
finding overall it appears that python files are predominately written in an oo style.
.
.
classifying projects.
next we investigated how projects as a whole classify in terms of paradigm.
table shows the results.
as you can see procedural and oo are the most frequently used paradigms when classifying whole projects.
given the individual file classifications this is not too surprising though imperative being lower than mixed is a bit surprising.
however this is explained by the strategy used to classify projects being slightly different from files and having more opportunities to mark projects as mixed.
table rq1 classification of projects all projects no toy projects file projects classified functional oo procedural imperative mixed there is also a possible threat that including toy projects might bias the results somehow.
when designing the approach we discussed the idea of filtering out small projects with little history.
we decided to keep them in however as the questions we are asking are about python projects as a whole including these so called toys.
that said we did look into how things might change if we excluded them.
the results are shown in the middle column of table .
here we removed any project with a revision count less than .
when comparing these results to the full dataset results on the left we see removing toy projects did not change the trends.
finding when considering projects with or without toys excluded almost no functional projects are found andoo is the most common paradigm used over of all projects followed by procedural over of all projects .
6statements functional oo procedural imperative mean .
.
.
.
.
std .
.
.
.
.
min .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
max .
.
.
.
.
note the boxplot has outliers removed while the table is a summary of the raw data including outliers.
figure rq1 distribution of statements in every unique file exact duplicates removed and their assigned classifications figure rq1 percentage of a file that is each paradigm figure rq1 classification of files to paradigmwe also looked at cases where a project has just a single source file.
the original thought was these might be toys possibly hello world style examples where people were simply trying python out for the first time.
the results are shown in table .
the results show a mixture of paradigms.
a manual inspection of a small sample of procedural files showed quite a few were utility scripts.
finding small single file python projects are predominately written in a procedural style and often serve as utility scripts.
.
rq2 what are the most and least used features for some programming paradigms?
when looking at the results of the previous research question it becomes obvious that some paradigms are highly used in python oo procedural and other paradigms are extremely rarely used functional according to the classification of both files and projects.
given these results we were interested in seeing how one of the top paradigms such as oo2 compares to the lowest functional in terms of the use of their individual features.
in other words given that so many projects and files use oo and so few use functional would we also see that functional features are not often used?
we ran a query to find and count how many times the functional and oo features from table were used in the main branch with duplicate files removed.
the results are shown in table .
oo features are highlighted with gray backgrounds.
given the huge discrepancy between oo and functional in terms of number of files and projects figure and table and also given the much lower file percentages that are functional compared to oo figure we expected to see substantially more use of oo features compared to functional.
however the results clearly show that even if files and projects are not being classified as functional functional code is still frequently used across python projects.
finding despite the low number of files being classified as functional functional features are still commonly used in python.
2we chose oo over procedural as oo has many more features to look at.
7figure rq3 is there a relationship between the number of statements in a file and its predominant paradigm?
here the x axis is the number of statements in a file binned into deciles.
table rq2 counts for functional and object oriented programming python features count feature method declarations class declarations class inheritance for each built in functions functools itertools array comprehensions try except in method decorators raise with not in lambda higher order functions yield class decorators finally generators iterable .
rq3 are project size and predominant paradigm related?
next we were interested to see if a project s size has an relationship to the programming paradigm it uses.
for this question we consider different metrics for measuring a projects size including total number of committers number of revisions and total number of statements in all source files.
first we look at the number of statements.
the results are shown in figure .
we use a histogram to display the values with data figure rq3 number of committers vs paradigm placed into bins at each decile.
since the maximum values for functional are considerably smaller compared to the other paradigms we split it out into its own chart on the left.
what we are looking for in these histograms is if the trends seem similar.
in other words as the project size increases going right across the x axis do we see a similar trend for each paradigm?
what we see are different trends decreasing increasing and no trend.
as the project size is increasing it appears that the number of files classified as oo or imperative increases showing a positive correlation.
meanwhile the number of procedural and mixed files decrease.
and interestingly the number of functional files seems completely uncorrelated.
finding the number of statements in a project seems positively correlated to using oo or imperative paradigms and negatively correlated to using procedural or mixed paradigms.
the analysis on the number of committers figure does not show any correlation most likely due to the extremely skewed data as most projects only have a few committers.
similarly no correlation was observed when analyzing number of revisions possibly again due to the skewed nature of the data.
we omit these results from the paper but they are included in the dataset.
8finding the number of committers and a project s revision history have no correlation to the project s dominant paradigm.
.
rq4 how do programming paradigm uses change over time?
the final research question is looking at how the paradigm choice of a file changes over time if at all.
for this we look at the first and last revision of each unique file on all branches and see if the classification changes or not.
the results are shown in table .
table rq4 do files change their classification from their first revision to their last?
files changed?
false true as you can see a small percentage of files .
change classification over time.
if a file is using a particular paradigm the probability of it continuing to use that paradigm is high.
this is good news for developers as if they are comfortable with the paradigm features used in a file they shouldn t worry about having to learn a new paradigm s features in the future.
we also looked at the 8m files that changed classification to see if there were any trends in how those changes occurred.
the results are shown in table with counts indicating how many files were classified as different paradigms in their first and last versions.
in table we also show the file counts for a file s first and last classification.
oo was the most common first and last classification with imperative close behind.
we do not see any obvious trends in the data.
finding a small number of files .
change their classification over time meaning most files pick a paradigm and stick with it.
threats to validity here we consider some potential threats to the validity of our study.
the biggest threat to construct validity is that we rely on inferring paradigm use from already produced code without speaking with the developers of the project.
so while we may judge a project to be oo based on the analyzed use of various language features it is possible the developers of the language consider it to be different e.g.
procedural or mixed.
a follow up study surveying developers based on the results of this study could help confirm or deny that the use of features alone is sufficient to make such a judgement.
the biggest threats to internal validity are the human judgement s section .
and the classification of features to paradigm .
not everyone will agree with how some of the features are mapped.
we attempted to pick an objective mapping especially for the functional features by using guidelines from the language designers themselves .
the human judgement s served as the basis for calibrating the automated approach so if those judgements were poor the automatedtable rq4 for files that changed classification how do they change?
files first last functional oo procedural imperative mixed oo functional procedural imperative mixed procedural functional oo imperative mixed imperative functional oo procedural mixed mixed functional oo procedural imperative table rq4 first and last file paradigms files first functional imperative mixed oo procedural 718files last functional imperative mixed oo procedural approach likely also performs poorly.
while this is a threat we feel the high inter rater agreement .
indicates the judgements were high quality and helps mitigate this threat.
however we note the initial agreement was lower .
and after computing the cohen s kappa to see how well the automated approach agreed with the humans the human raters started questioning some of their own prior judgements based on the differences from the automated tool.
for example in one source file3the humans judged it as oo and the machine called it mixed.
we suspect it was because there was a single statement spanning lines where each line contained a method call on an object.
humans probably interpreted this visually large block of text as several oo uses while the machine would count this as a single use.
08ecb7eea2645a1cecafe21370423fb7393d3bee analytics analyze kmeans.py l18 9in another source file4 there were several lines containing code like cfradial.
ncvar to dict ncvars .
it can be difficult for both humans and the script!
to determine if this is an oo method call or a procedural call without global knowledge.
a nonlocal static analysis would make this result more accurate.
this shows that some projects most likely fall into a gray area where even humans would most likely disagree on exactly what to classify it as while the automated tool has to make sometimes seemingly arbitrary deterministic choices.
in the future we might utilize machine learning to train a classifier however currently we lack enough human judgements to build an accurate model.
another internal threat to validity deals with how the set of features in python has changed over time.
as such some features have existed longer than others and this may impact some of the observed results e.g.
the feature counts in table .
a threat to external validity deals with how our results generalize.
while we attempted to utilize a broad range of github projects we still can t say with certainty those projects are representative of all python programs projects and thus the results might not generalize to the population as a whole.
additionally the study focused purely on python and results almost certainly do not generalize to other programming languages.
related works in this section we discuss prior works that study the python language studies about specific language features and studies on the use of multiple programming languages.
.
studies on the python language peng et al .
analyzed open source python projects to see what language features are commonly used.
they found inheritance decorators keyword arguments for loops and nested classes as the top used language features.
orr et al .
looked at the use of inheritance in python programs.
they observed python programs have more classes inherited from compared to java programs.
in contrast to these works we analyzed almost 100k projects but with a different goal in mind.
still similar to these works we also found that inheritance for loops and decorators are commonly used language features.
kerblom and wrigstad looked at the use of polymorphism in python projects by collecting dynamic traces of the programs.
their results showed that while many projects use polymorphism most are actually monomorphic.
kerblom and wrigstad looked at python programs to measure their polymorphic behavior.
they observed many systems while heavily using polymorphism are actually monomorphic in behavior.
while these works focuses on the use of inheritance and polymorphism we look at language features used including oo inheritance from a static standpoint and utilize that information for classifying the paradigm s used.
kerblom et al .
used dynamic program tracing to investigate the use of some language features of python that are difficult to analyze statically such as dynamically generated code eval exec .
while their work looks at specific language features they are not pyart aux io arm vpt.py l97attempting to categorize programming paradigms those features belong to or determine the predominant paradigm.
alexandru et al .
looked at how developers perceive common idioms in python known as the pythonic way of solving a problem.
as some idioms might imply a particular paradigm their work is complementary to our own.
we are not looking at prescribed ways to write code just observing what was already done.
lin et al .
conducted an empirical study using pyct focused on kinds of source code changes made by developers.
out of four research questions one of the questions focused on how often do dynamic features change in source files.
while we do not look at dynamic features we did investigate how often predominant paradigm changes in source files.
.
language feature studies on other languages several other studies have looked at the use of language features often lambdas in other programming languages often java .
for example mazinanian et al .
looked at where developers were using lambdas in java and then surveyed them to find the reasons for using them.
they observed increased use as well as different reasons from increased readability to simulating lazy evaluation.
lucas et al .
looked at if the introduction of lambdas into java helped with programmer comprehension.
they found contradictory results that lambdas seem to improve program comprehension while simultaneously decreasing readability.
nielebock et al .
looked at the use of lambda expressions to aid writing concurrent object oriented code in java c and c and found that in general programmers appear to not favor the use of lambdas in the context of concurrent code.
petrulio et al .
looked at the support for lambdas in the java ecosystem and found many top apis do not yet support functional interfaces.
zheng et al .
looked at why developers remove existing lambdas in java.
they found seven common reasons to remove lambdas including reasons such as readability and performance.
they also recommended places to avoid introducing lambdas.
these works focused on a single language feature while our study focused on identifying the predominant paradigm.
our work could help focus future studies by indicating which paradigm s are most common and thus which feature s might be best to study.
.
multi language studies kochhar et al .
studied the relationships between multilanguage usage and bug categories.
they observed if the use of multiple languages causes more bugs.
they built regression models to study the correlation of using different languages on the number of bug fixing commits.
they noted that languages when used with other languages can make software more bug prone.
mayer and bauer investigated the use of multiple programming languages in 1k open source projects.
they used associationrule mining to infer how project size and number of commits related to the languages used.
they also discovered several groupings of language ecosystems.
uesbeck and stefik addressed the issues programmers face while using multiple programming languages.
they performed a control study to determine what kinds of problems programmers 10face when switching between multiple programming languages such as java and sql.
the study was small and designed as a pilot for future studies.
bunkerd et al .
investigated python projects to see if the history of developers on those projects and their experience with other programming languages affects the naturalness of their python code.
they show that greater diversity of contributor programming experience can impact and make the code less natural.
chakraborty et al .
studied q a on stack overflow for three languages go swift and rust.
they monitored the challenges developers initially faced while working with new languages in comparison to more mature languages.
they conducted the study by extracting features understanding the developer s background as a contributor.
the study promoted better design for languages and documentation by the sponsors owners.
these works study the use of multiple languages while we focus on the use of multiple paradigms within a single language.
conclusion python is a multi paradigm programming language but to date no one has investigated what paradigms are predominant in python code.
in this work we saw that many files and projects favor the oo paradigm.
single file projects appear to be utility scripts and favor a procedural paradigm.
the size of the project in terms of statements is positively related to using oo and negatively related to using functional procedural or mixed paradigms.
finally we saw the vast majority of files rarely change predominant paradigm over time providing stability to developers working on those files.
in the future we hope to have a follow up study to investigate in more detail exactly how humans classify the predominant paradigm of a file.
while it was easy for humans to classify results that are polarized the middle area was much more difficult.
we would like to perform a survey to investigate why that was the case.