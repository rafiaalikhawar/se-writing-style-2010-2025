semantic bug seeding a learning based approach for creating realistic bugs jibesh patra university of stuttgart germany jibesh.patra gmail.commichael pradel university of stuttgart germany michael binaervarianz.de abstract when working on techniques to address the wide spread problem of software bugs one often faces the need for a large number of realistic bugs in real world programs.
such bugs can either help evaluate an approach e.g.
in form of a bug benchmark or a suite of program mutations or even help build the technique e.g.
in learning based bug detection.
because gathering a large number of real bugs is difficult a common approach is to rely on automatically seeded bugs.
prior work seeds bugs based on syntactic transformation patterns which often results in unrealistic bugs and typically cannot introduce new application specific code tokens.
this paper presents semseed a technique for automatically seeding bugs in a semantics aware way.
the key idea is to imitate how a given real world bug would look like in other programs by semantically adapting the bug pattern to the local context.
to reason about the semantics of pieces of code our approach builds on learned token embeddings that encode the semantic similarities of identifiers and literals.
our evaluation with real world javascript software shows that the approach effectively reproduces real bugs and clearly outperforms a semantics unaware approach.
the seeded bugs are useful as training data for learning based bug detection where they significantly improve the bug detection ability.
moreover we show that semseed created bugs complement existing mutation testing operators and that our approach is efficient enough to seed hundreds of thousands of bugs within an hour.
ccs concepts software and its engineering software creation and management software testing and debugging computing methodologies machine learning keywords bugs bug injection machine learning dataset token embeddings acm reference format jibesh patra and michael pradel.
.
semantic bug seeding a learningbased approach for creating realistic bugs.
in proceedings of the 29th acm joint european software engineering conference and symposium on the foundations of software engineering esec fse august permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
copyrights for components of this work owned by others than acm must be honored.
abstracting with credit is permitted.
to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
request permissions from permissions acm.org.
esec fse august athens greece association for computing machinery.
acm isbn .
.
.
.
greece.
acm new york ny usa pages.
.
introduction bugs are one of the key challenges in software development and various techniques have been proposed for bug detection bug fixing and bug prevention.
a common problem faced when working on bug related techniques is the need for large amounts of known realistic bugs.
such bugs can serve multiple purposes.
one of them is to provide a benchmark for evaluating and comparing bug related tools.
for example static bug detectors and fuzz testing tools are evaluated against sets of known bugs and bugs created via mutations are useful for evaluating the effectiveness of test suites .
unfortunately real bugs are scarce and without precise knowledge about where exactly a bug is assessing whether a problem reported by a tool is indeed a bug requires manual effort.
as a result many tool evaluations are limited to a small number typically a few dozens of bugs e.g.
bugs manually gathered from open source projects .
another purpose of known bugs is to help build a bug related technique.
for example learning based bug detectors defect prediction models and repair tools rely on bugs to learn from.
these techniques require large amounts of training data typically in the form of code known to contain a specific kind of bug.
since obtaining large amounts of bugs is non trivial current techniques either focus on bugs created through simple code transformations on noisy datasets that e.g.
approximate buggy code as any code changed in the next version of a program on manually curated bug datasets or on code changes that are heuristically linked with bug reports .
this paper presents semseed which addresses the need for large amounts of known realistic bugs through a semantics aware bug seeding technique.
the key idea is to generalize a bug observed in the past and to seed variants of the bug at other code locations either in the same or another program.
to reason about the semantics of code we exploit token embeddings a learned representation of code elements such as identifier names and literals.
to the best of our knowledge we are the first to use learned embeddings for bug seeding.
semseed addresses three important challenges which as shown below are not sufficiently considered in previous work.
c1 where where in a target program to seed bugs that resemble a given bug toimitate?
we address this challenge by checking which locations in the target program semantically fit the bug to imitate.
c2 how how to adapt the bug to imitate to the target program ?
semseed addresses this challenge by semantically adapting identifiers and literals to the target location.
c3 unbound tokens how to handle 906esec fse august athens greece jibesh patra and michael pradel table comparison with other bug seeding techniques.
approach kinds of bugstarget locations c1 adaptation to target location c2 unbound tokens c3 mutation operators few manually definedeverywhere syntactic not supported inferred mutat.
operators many inferredeverywhere syntactic not supported neural machine translation many inferredimplicit by modelimplicit by modelnot supported bug synthesis memory updateshard to trigger pathsn a n a this work many inferredbased on semantic fitsemantic supported tokens in the buggy code that do not occur in the correct code e.g.
when the buggy code refers to an application specific identifier name or literal?
we address this challenge called unbound tokens through semantic analogy queries in the token embedding space that find a token that resembles the bug to imitate but fits the bug seeding location.
table summarizes and contrasts semseed with other work on automatically seeding bugs.
first mutation testing seeds bugs based on pre defined code transformations.
however mutation operators cover only a small set of the syntactic transformations that occur in the wild and only sometimes represent real world bugs .
second some work infers mutation operators from past bug fixes .
both pre defined and inferred mutation operators are applied in a purely syntactic way without considering whether a code transformation semantically fits a code location c1 or how to adapt the transformation to the location c2 .
third neural models can learn from past bug fixes how to inject bugs .
such approaches implicitly select target locations for seeding bugs and adapt the seeding to these target locations but the details are hidden within the neural network.
finally work aimed at evaluating fuzz testing tools seeds bugs along execution paths that are non trivial to trigger.
even though these bugs may appear realistic from an execution perspective they are easy to detect statically making the approach unfit for evaluating or training static bug detectors.
none of the above approaches addresses the problem of unbound tokens c3 which our evaluation shows to prevent existing work from seeding the majority of bugs that appear in the wild.
we evaluate semseed by learning from real world bugs and by seeding hundreds of thousands of new bugs.
the evaluation focuses on javascript because it has become one of the most popular languages and is used in various domains but the approach is not specific to this language.
the results show that semseed is effective at creating realistic bugs that the seeded bugs complement bugs created with traditional mutation operators and that our implementation can seed hundreds of thousands of bugs within an hour.
using the seeded bugs as training data for a learning based bug detector significantly improves the bug detection ability compared to the state of the art.
abstraction into bug seeding pattern ... hasfailed item.errcode if hasfailed process.arch x64 ... ... hasfailed item.errcode if hasfailed process.arch !
x86 ... semantic matching apply patternconcrete bug fix bug seeding pattern target program program with realistic seeded bugcandidate seeding locations1 ... id1.id2 lit1 ... ... id1.id2 !
lit2 ... ... if process.platform darwin ... ... if process.platform !
win32 ... figure overview of the approach and running example.
in summary this paper makes the following contributions we are the first to use learned token embeddings for bug seeding .
we present a semantics aware technique to decide where to seed a bug how to adapt a given bug to imitate to the target location and how to handle unbound tokens.
we present an efficient algorithm for semantic bug seeding which chooses from thousands of candidate bugs the semantically most suitable within about .
seconds on average.
we show empirical evidence that semseed seeds realistic bugs outperforms a purely syntactic bug seeding technique complements traditional mutation operators and yields bugs useful for training more effective bug detection models.
our implementation and all data to reproduce our results are publicly available overview this section illustrates the key ideas of our approach with an example.
at a high level semseed consists of three main steps abstraction semantic matching and pattern application.
given a set of concrete bug fixes e.g.
gathered from version histories the first step abstracts away project specific details such as the identifier names.
this abstraction step results in bug seeding patterns that describe how to syntactically transform a piece of code to introduce a new bug.
the top part of figure shows one concrete bug fix that the approach takes as an input.
the middle part of the figure shows the corresponding bug seeding pattern.
the concrete identifiers e.g.
process andplatform are abstracted based on their syntactic category e.g.
into id1andid2.
intuitively the bug pattern could be described as wrong comparison with wrong literal .
907semantic bug seeding a learning based approach for creating realistic bugs esec fse august athens greece the second step of the approach matches the inferred bug seeding patterns with a given target program addressing challenge c1.
a naive baseline approach would apply a pattern at every syntactically matching location.
for our example target program in figure the wrong comparison with wrong literal pattern could be applied at every binary expression that compares some id1.id2 with some lit1 using .
however such a purely syntactic approach will lead to a large number of unrealistic bugs.
a key idea of semseed is to not apply patterns at every syntactically matching code location but only at locations that are semantically similar to the locations where a pattern was derived from.
for the example in figure semseed s semantic matching component may select the code location process.arch x64 because it also is about checking whether some platform matches a string descriptor of a platform.
the challenge in finding such a location is that the semantic similarity may not be obvious to a program analysis that is unaware of domain knowledge.
for our example the approach needs to understand that the identifiers platform andarchitecture refer to similar concepts and that the literals darwin and x64 both describe platforms.
the third and final step of semseed applies bug seeding patterns at the candidate seeding locations identified by the second step addressing challenges c2 and c3.
the key idea is to adapt the syntactic bug seeding pattern to the selected location in the target program.
specifically the approach instantiates the pattern with identifiers and literals that are semantically similar to a location where the pattern was derived from c2 and it finds suitable tokens for identifiers not present in the original target program c3 .
as a result the approach semantically generalizes the given concrete bugs to other code locations which yields fewer but more realistic seeded bugs than syntactic bug seeding.
to determine how similar two code locations are we rely on neurally learned embeddings of identifier names and literals which have been used for other program analysis tasks in the past but to the best of our knowledge have not yet been used for bug seeding.
to seed a bug at the selected location semseed transforms the code as shown at the bottom part target program of the figure.
this transformation not only instantiates the bug seeding pattern but it also picks a suitable platform descriptor x86 .
the approach picks this literal based on identifiers and literals used in the vicinity of the bug seeding location mimicking a mistake a developer might also make.
as a result the seeded bug resembles the original bug that the pattern was derived from while adapting it to the local context.
approach this section presents the three steps of our semseed approach in detail.
at first section .
describes how to extract bug seeding patterns from concrete bug fixes in version histories.
then section .
presents how our approach semantically matches these bug seeding patterns against previously unseen code to find candidate locations for seeding new bugs.
finally section .
describes how to apply a bug seeding pattern to a given code location by semantically adapting a specific bug to imitate.
.
abstraction into bug seeding patterns the first step of semseed analyzes bug fixing code changes in the version histories of popular code repositories to generalize them into bug seeding patterns.
the basic idea is that reverting and generalizing a code change that fixes a bug will yield a pattern that we can then use to introduce this kind of bug into other code.
.
.
selecting bug fixing commits.
to gather examples of bugfixing code changes we mine the commit histories of code repositories.
for a given repository semseed filters all commits based on four criteria which are designed to identify simple bug fixing commits.
first we select only those commits where the commit message contains any one of the words bug fix error issue problem and correct which we assume to indicate that the commit is fixing a bug.
second we select only those commits that have a single parent commit to avoid merged commits.
third we select commits where the number of changed files is one and where the changed file is written in the target programming language i.e.
javascript in this paper.
finally our fourth criterion is to omit commits where the number of changed lines is higher than one.
both the third and the fourth criterion help with omitting commits that fix more than a single bug or that intermingle a bug fix with other code changes.
prior work shows single line bugs to be relevant and frequent in practice .
since identifying bug fixing code changes is a non trivial problem our four filters are designed to rather exclude some bug fixing commits than to include many other commits.
of course there is no guarantee that the commits obtained using these four filters are bug fixing code changes.
manual inspection by previous research of commits mined with a similar approach has shown of their commits to be bug fixing.
.
.
extracting concrete changes from commits.
given a set of bug fixing code commits semseed next extracts code changes into a format suitable for the remainder of the approach.
due to our filtering of commits each commit changes exactly one line of code.
one option would be to consider the entire changed line which may however include parts unrelated to the bug fix.
including such noise would make it harder to identify recurring patterns and to find suitable locations for seeding bugs based on these patterns.
another option would be to consider only those tokens of the line that have been modified which may however miss surrounding tokens important to capture the context of the change.
including some contextual information helps semseed identify the most suitable locations for seeding bugs with a given pattern.
to extract the changed tokens along with some context semseed uses the ast of the old and the new file to find a subsequence of the changed line s tokens that forms a complete syntactic entity i.e.
a complete subtree of an ast.
focusing on complete syntactic entities instead e.g.
on all tokens in a changed line increases the chance to find recurring patterns.
to this end the approach converts both the buggy and the correct file into asts and maps each ast node to its corresponding range of line numbers in the file.
next the approach prunes all ast nodes that do not comprise any changed line.
from the remaining nodes of a file semseed selects the subtree that encompasses the maximum number of source code tokens in the changed line and then emits the sequence of tokens rooted at 908esec fse august athens greece jibesh patra and michael pradel this node.
the result is two sequences of tokens for the buggy and correct files respectively definition .
aconcrete bug fix cbug ccorr is a pair of sequences of tokens where the sequence cbug tb ... tbm corresponds to a subtree in the ast of the buggy file and the sequence ccorr tc ... tcn corresponds to a subtree in the ast of the corrected file.
for example consider the concrete bug fix in figure .
analyzing the modified line in the buggy file shown in red on the top left semseed selects the ast subtree that represents the process.platform !
win32 expression and hence yields the tokens in this expression.
for the correct file shown in green on the top right the analysis yields the tokens in process.platform darwin even though both extracted token sequences correspond to the same kind of ast subtree in this example the sequences may correspond to different syntactic entities in general.
.
.
from concrete fixes to bug seeding patterns.
to enable semseed to seed new bugs based on the extracted concrete bug fixes the approach generalizes bug fixes into bug seeding patterns.
during this step we abstract identifier tokens and literal tokens.
the rationale is that these kinds of tokens often are application specific and hence must be adapted to a specific bug seeding location.
definition .
abug seeding pattern pcorr pbug is a pair of sequences of tokens where a token is either idkorlitk for some k n or a non identifier and non literal token of the target programming language.
our approach for abstracting a concrete bug fix into a bug seeding pattern starts from the token sequence in the correct part of the change i.e.
ccorr.
the algorithm traverses all tokens in the concrete bug fix and abstracts all identifiers and literals into placeholdersidiandlitj whereiandjare incremented whenever a new identifier or literal occurs.
to consistently abstract tokens that occur multiple times the algorithm maintains for each concrete bug fix a map mfrom concrete to abstract tokens .
finally we discard concrete bug fixes that have more than tokens and that occur only once which discards about of all bug seeding patterns.
the threshold of tokens was selected after manually inspecting various bug fixes and avoids learning obscure patterns unlikely to apply anywhere else.
for our running example the middle part of figure shows the bug seeding pattern.
the algorithm abstracts the identifiers process andplatform intoid1andid2 respectively and the literals win32 and darwin intolit1andlit2 respectively.
.
matching bug seeding patterns against code based on the inferred bug seeding patterns the second step of semseed is to find code locations for seeding the bug defined by the pattern into a target program.
the approach matches the correct part of a pattern against token sequences extracted from the target program.
we call the matching token sequences candidate seeding locations .
one key contribution of semseed is to determine candidate seeding locations not only by syntactically matching a patternagainst the target program but also by semantically reasoning about the similarity of the involved identifiers and literals.
.
.
extracting token sequences from target program.
given a target program where semseed should seed bugs the approach extracts various token sequences to match against the inferred bug seeding patterns.
similar to the pattern extraction step semseed starts by parsing the target program into an ast and then extracts sequences of tokens that correspond to subtrees of the ast.
given a node and its corresponding token sequence c t1 ... t n the approach applies the same abstraction algorithm as in section .
.
to get the abstracted token sequence cabstr .
for example consider the target program in figure .
the approach extracts multiple ast subtrees and corresponding token sequences.
two of the extracted subtrees represent binary expressions and the corresponding token sequences are for both sequences abstracting identifiers and literals results in the following abstracted token sequence .
.
.
syntactic matching.
given a set of token sequences extracted from the target program semseed matches each abstracted token sequence against each bug seeding pattern.
for a sequence cabstr and a pattern pcorr pbug the approach checks whether cabstr matchespcorr i.e.
the correct part of the pattern.
as a first step semseed performs a simple syntactic matching wherecabstr and pcorr pbug match ifcabstr is equal topcorr.
note that the syntactic matching is similar to a corresponding step in previous work on seeding bugs with inferred mutation operators .
for our example the two token sequences abstracted into are both equal to the correct part of the bug seeding pattern from section .
.
hence both binary expressions in the target program are retained as candidate seeding locations.
.
.
semantic matching.
syntactically matching bug seeding patterns against a target program yields a large number of candidate seeding locations.
unfortunately seeding bugs at all these locations would result in many seeded bugs that do not semantically resemble the concrete bugs that semseed is learning from.
for example applying the bug seeding pattern of our running example both to item.errcode and to process.arch x64 would yield two seeded bugs.
however only the second seeded bug would be semantically similar to the concrete bug that the pattern was learned from the bug is about incorrectly checking the name of a platform against a string that describes a platform process.platform darwin and a similar bug could occur in the process.arch x64 expression.
in contrast the other possible candidate seeding location item.errcode matches the original bug only syntactically but not semantically.
to ensure that semseed seeds realistic bugs the approach focuses on bugs that semantically resemble a given concrete bug fix.
checking whether two code locations are semantically similar is a hard problem which we address by borrowing ideas from machine learning based natural language processing.
an important research problem in that field is to identify semantically similar words such 909semantic bug seeding a learning based approach for creating realistic bugs esec fse august athens greece algorithm semantically match a token sequence against a bug seeding pattern.
input token sequence cand concrete bug fix cbug ccorr output true ifcis a semantic match false otherwise t1 ... t n c tokens of target location t ... t n ccorr tokens where real bug occurred s fori 1tondo ifkind ti identifier literal then v emb ti v emb t i appendsimil v v tos returnavg s matching threshold m as chicken and fowl .
a state of the art approach to address this problem is word embeddings learned from a corpus of text e.g.
using word2vec or fasttext .
an embedding maps each word into a real valued vector so that semantically similar words have similar vectors.
for example the word vectors of chicken and fowl will be close to each other in the embedding space.
to determine how similar two word vectors v ware in an embedding space we compute their cosine similarity simil v w v w v w semseed computes embeddings of source code tokens and uses them to reason about the semantic similarity of tokens.
as the embedding technique we build on fasttext which we choose for two reasons.
first fasttext does not suffer from the out ofvocabulary problem because it reasons about the n grams in a token instead of relying on a fixed size vocabulary.
second fasttext has been shown to more accurately represent the semantic similarities of code tokens than other popular embeddings .
algorithm summarizes how semseed checks whether a given token sequence semantically matches a bug seeding pattern.
the approach semantically compares the concrete tokens ccorr where the bug described by the pattern has occurred with the tokens c in the target program.
the algorithm computes for each identifier and literal token in cits semantic similarity to the corresponding token inccorr.
if the average similarity for all tokens in cexceeds a thresholdm which we call the matching threshold then the algorithm returns true and semseed marks cas a candidate seeding location.
averaging the similarity across embeddings of individual tokens is inspired by work on representing natural language sentences and documents and captures how well a bug would fit a target location.
for bug seeding patterns derived from multiple concrete bug fixes the approach invokes the algorithm multiple times and considers ca candidate seeding location if cresembles at least one of the concrete bug fixes.
our evaluation studies the impact of the matching threshold min practice.
for the example semseed invokes algorithm for the two syntactically matching code locations.
the first invocation where c contains the tokens in item.errcode is likely to return false depending on the matching threshold because the compared tokens e.g.
item vs.process or darwin vs. are dissimilar.
in contrast the second invocation is likely to return true because the tokens in process.arch x64 have a high pairwise similarity with the tokens in process.platform darwin .
.
applying bug seeding patterns the third and final step of semseed is to apply bug seeding patterns at the bug seeding locations in the target program.
.
.
unbound tokens.
the main challenge in this step is tokens that appear in the buggy part but not in the correct part of the pattern which we call unbound tokens .
for example recall the bug seeding pattern in figure and in particular the lit2 token in the buggy code.
when applying the pattern to a program this token is unbound i.e.
it is unclear what concrete token to insert instead of lit2 .
prior work on automatically seeding bugs based on inferred bug patterns ignores the problem of unbound tokens and hence can apply only bug seeding patterns without any such tokens.
however as we show in our evaluation the majority of all bug seeding patterns contains unbound tokens i.e.
ignoring them would ignore many bug seeding opportunities.
before presenting our approach for applying bug seeding patterns with unbound tokens we consider a few alternatives.
suppose we want to apply a bug seeding pattern pcorr pbug which was inferred from a concrete bug fix cbug ccorr and has an unbound tokent?.
the question is which concrete token to use instead of t?
when concretizing pbugin the target program.
one option would be to replace t?with the concrete token it is bound to incbug.
however this token may not be a natural fit for the target program.
for example when t?is an identifier then simply replacing it with the corresponding identifier from cbugis likely to result in an undefined variable resulting in a rather unrealistic bug.
another option would be to replace t?with a random token sampled from the vocabulary of all tokens which again is likely to result in an unrealistic bug.
a third option would be to sample a token from all tokens in the same file or same function as the bug seeding location.
while this approach increases the chance of resulting in realistic code it is still likely to yield a token that does not fully fit the context of the bug seeding location e.g.
because it uses a variable of a wrong type.
.
.
binding tokens via analogy queries.
to address the challenge of binding an unbound token in a way that fits the bug seeding location and hence ultimately create a realistic bug we again take inspiration from natural language processing.
given a learned word embedding word analogy tasks intend to answer similarity questions involving two or more pairs of words.
for example one may ask the analogy question what word is to france what tokyo is to japan ?
which is likely to yield the answer paris .
adapting this idea to unbound tokens semseed uses the bound tokens of a bug seeding pattern to resolve any unbound tokens in the same pattern.
figure illustrates our analogy based technique for binding unbound tokens using the example in figure .
given the bug seeding pattern the token lit2 is unbound.
in contrast process andarch are bound because id1andid2occur both in the correct and the buggy part of the pattern.
semseed searches for a suitable token for lit2 by asking three analogy questions what token is to x64 what win32 is to darwin ?
this analogy is represented by the two upward arrows in figure .
910esec fse august athens greece jibesh patra and michael pradel embedding space platform win32 process x86 arch x64 darwin figure example of analogy queries to bind unbound tokens.
algorithm apply bug seeding pattern to candidate token sequence input a candidate token sequence c a concrete bug fix cbug ccorr and its corresponding bug seeding pattern pcorr pbug a settof identifier and literal tokens.
output tokenscseedof seeded bug cseed fori 1tolength cbug do ifkind cbug i identifier literal then appendcbug i tocseed copy token else ifpbug i bound totbound then appendtbound tocseed use bound token else vtgt bind token via analogy queries fortabstr pcorrdo torig token thattabstr is bound to in cbug tseed token thattabstr is bound to in c vtgt emb tseed emb cbug i emb torig addvtgttovtgt t?
arg max t tsimil emb t avg vtgt appendt?tocseed what token is to arch what win32 is to platform ?this analogy is represented by the two downward left arrows in figure .
what token is to process what win32 is toprocess ?
this analogy is represented by the downward right arrow in figure where a single arrow is sufficient because process occurs both in the imitated bug and the target program.
the token embedding answers these questions by returning the three blue points in the vector space we explain below how exactly these points are computed .
intuitively these points provide three target locations around which to search a suitable token for the unbound token.
semseed combines the these target locations into a single target location by averaging the three blue points into the pink point shown in the figure.
semseed retrieves a suitable token forlit2 by searching the nearest neighbor of the target location as indicated by the gray sphere in figure .
the nearest neighbor in our example is the literal token x86 and hence semseed seeds a bug using this token.
.
.
algorithm.
after providing an intuition of the approach algorithm presents in detail how semseed applies a bug seeding pattern.
the algorithm takes three inputs.
first a candidate token sequencec identified as described in section .
which the algorithm will mutate to seed a bug.
second a concrete bug fix cbug ccorr and its corresponding bug seeding pattern pcorr pbug .
the algorithm will seed a new bug by imitating the given bug and by semantically adapting it to the context of the candidate token sequence.
third a set tof literal and identifier tokens from which the algorithm selects tokens to use for unbound tokens.
for example this set may consist of all identifiers and literals in the file where the bug is seeded or the nmost common tokens in a corpus of code.
our evaluation compares different ways of computing the set t. the main loop of the algorithm goes through all tokens in the bug to imitate cbug and iteratively builds a new sequence cseed of buggy tokens.
for each token to generate the algorithm distinguished three cases.
the first case line handles tokens that are neither identifiers nor literals but standard tokens of the programming language such as operators or parentheses.
each such token is directly copied from the bug to imitate into cseed.
the second case line handles bound identifier and literal tokens i.e.
tokens that appear in the candidate token sequence.
the algorithm uses the concrete token tbound from the candidate token sequence and appends it to cseed.
for our running example the first two cases handle the tokens process .
arch and !
.
these cases are sufficient to handle bug seeding patterns without any unbound tokens where it suffices to rearrange the tokens in the candidate token sequence into the buggy token sequence.
in contrast unbound tokens such as lit2 in our example require including a new token into the sequence cseed.
the third case line in algorithm handles unbound tokens by computing a set vtgtof target points in the vector space of the token embedding.
for each abstract token tabstr that appears in the correct part pcorrof the bug seeding pattern the algorithm computes a target point based on the concrete tokens torigandtseed thattabstr is bound to in the bug to imitate and the candidate token sequence respectively.
the target point is computed at line which implements an analogy query.
the query starts from the embedding of tseedand adapts it by adding the vector that leads from the embedding of torigto the corresponding token cbug i in the bug to imitate.
for our running example the algorithm computes three target locations which correspond to the three analogy questions from above vtgt emb x64 emb win32 emb darwin emb arch emb win32 emb platform emb process emb win32 emb process that is the algorithm finds the difference between the vectors of darwin and win32 and adds it to the vector of x64 and similar for the other two queries.
the resulting three target locations are the blue points in figure .
given the set vtgt the algorithm queries tfor the token whose embedding is most similar to the average of all target points.
intuitively this token is the available token that is semantically closest to the token observed in the bug to imitate.
once retrieved the algorithm adds the token to the sequence cseedof result tokens.
911semantic bug seeding a learning based approach for creating realistic bugs esec fse august athens greece our implementation uses a variant of algorithm which binds unbound tokens not only with the available token that is most similar to the average of the target points but to consider the knearest neighbors of the average.
for a given candidate token sequence and bug to imitate this variant seeds not only one but kbugs.
to avoid breaking the syntactic correctness of target programs semseed checks for each seeded bug whether it yields syntactically correct code by parsing the complete file after seeding the bug.
for example a bug seeding pattern where the correct part is and the buggy part is may deem a candidate location like var num for seeding bug.
created on june author jibesh patra the seeded bug may result in code such as var var num which is syntactically incorrect.
in practice we find that of all seeded bugs are syntactically correct and filter out the remaining ones.
implementation we implement semseed as an end to end bug seeding tool with javascript as the target programming language.
we use the api provided by github to get a list of the most popular javascript repositories that we clone locally.
after the initial filtering of commits based on the commit message etc.
the correct and buggy javascript files are obtained using built in commands in git.
the static analysis on the javascript programs to extract nodes the corresponding tokens the kind of tokens etc.
has been implemented using esprima .
to obtain token embeddings we pre train fasttext on token sequences extracted from a corpus of 150k javascript files.
as mentioned at the end of the introduction our implementation is publicly available to foster future work.
evaluation we evaluate semseed based on bug fixes extracted from the version histories of popular javascript projects.
the evaluation addresses the following research questions rq1 how effective is semseed in reproducing real world bugs?
rq2 how does semseed compare to a semantics unaware variant of the approach?
rq3 what is the impact of the configuration parameters of the approach?
rq4 how useful are the seeded bugs for training a learningbased bug detector?
rq5 how do the seeded bugs compare to bugs created with traditional mutation operators?
rq6 how efficient is semseed in seeding bugs?
.
experimental setup we gather bug fixing commits from the version histories of the javascript projects that have most stars on github.
for each repository we extract all commits and filter them as explained in section .
.
resulting in concrete bug fixes.
we split the bugs into guiding bugs used to extract bug seeding patterns and as concrete bugs to imitate and held out bugs .
the split is datebased using older commits as guiding bugs and newer commits asheld out bugs so we can evaluate whether imitating bugs from the past creates bugs that have occurred later on.
extracting bug seeding patterns from the guiding bugs yields bug seeding patterns.
the frequency of the patterns follows a long tail distribution which shows that real world bugs are diverse and that extracting bug seeding patterns from a large dataset is worthwhile.
the approach depends on three configuration parameters that control how many and which bugs get seeded the matching thresholdm the settof tokens to choose unbound tokens from and the number kof bugs to seed per code location.
as a default we usem .
k andtas all tokens in the file where the bug gets seeded plus the most frequent tokens across all files with guiding bugs.
rq3 further evaluates the impact of these parameters.
.
rq1 effectiveness in reproducing real world bugs we evaluate semseed s ability to seed realistic bugs by comparing the seeded bugs with the held out bugs.
there are two preconditions for semseed to be able to reproduce a specific bug.
first the bug seeding pattern of the bug must occur across the guiding set and the held out set.
due to the long tail distribution of bug seeding patterns many of the patterns occur only once and we focus on the concrete bugs that have a pattern in the intersection of guiding bugs and held out bugs.
second for bugs that involve tokens not present in the correct code i.e.
unbound tokens the unbound token must be in the set tof tokens the approach chooses from when applying a bug seeding pattern.
for our default configuration of t out of the bugs that fulfill the first precondition also fulfill the second precondition.
we use this set of held out bugs as the target bugs and compute how many of them semseed reproduces i.e.
the seeded bug is exactly the same as the original bug.
given the files in which the target bugs should be seeded the semantic matching identifies all locations as a target location.
of the target bugs are rearrangements of existing tokens i.e.
similar to the inferred mutation operators of prior work .
seeding these bugs is straightforward and semseed reproduces all of them.
the remaining involve unbound tokens and semseed s algorithm for binding these tokens is successful for all but six of the bugs.
overall the approach reproduces out of the target bugs.
table shows three examples of successfully reproduced realworld bugs.
for each example we show the correct and buggy variant of both the bug to imitate and the seeded bug.
the first example is a bug without unbound tokens but which requires rearranging existing tokens only.
the second example is a bug with an unbound identifier token where the following analogy queries help to select the identifier stdout what token is to parent what official is to catalog ?
what token is to stderr what official is tocomplete ?
what token is to onwhat official is togetreleaseversion ?finally seeding the third bug requires binding two unbound tokens which semseed again successfully finds by searching for tokens similar to the tokens in the buggy code e.g.
finding timeout as a token similar to connectiontimeout .
semseed reproduces out of bugs that are in scope for the approach.
912esec fse august athens greece jibesh patra and michael pradel table examples of reproduced real world bugs.
correct code buggy code bug to imitate commit b776e2b7 of jquery var opt speed typeof speed object var opt typeof speed object seeded bug commit b94532c2 of chart.js if style typeof style object if typeof style object bug to imitate commit ad708ca5 of meteor catalog.
complete .
getreleaseversioncatalog.
official .
getreleaseversion seeded bug commit bd74fb4c of node.js parent.
stderr .on data function ... parent.
stdout .on data function ... bug to imitate commit 1027871e of webpack optimization chunkids named optimization namedchunks true seeded bug commit 28f346e8 of freecodecamp db connectiontimeout db timeout .
rq2 comparison with semantics unaware bug seeding semseed relies on the semantic information embedded in identifiers and literals in two ways i to select the locations for imitating a given bug and ii to bind unbound tokens.
to show the importance of these ideas we compare our approach against a semanticsunaware variant of semseed which i applies a bug pattern at every syntactically matching location and ii binds unbound tokens by randomly picking from all tokens in the set t. this baseline approach reproduces only out of the target bugs from rq1.
all of these bugs do not have any unbound tokens.
for bugs that need unbound token we repeat the experiment for ten times with different seed values and randomly select a token from t. in none of the ten repetitions does the random selection pick the correct token required to seed a bug.
the reason why randomly binding unbound tokens is ineffective is that picking the right token by chance from tis unlikely.
in our default configuration tcontains more than tokens and even when tconsists only of tokens that appear in the same function there typically are several dozens of identifiers and literals to choose from.
to further illustrate the importance of handling unbound tokens table lists some bug seeding patterns that semseed finds alongtable ten most frequent and five randomly selected bug seeding patterns.
unbound tokens are highlighted .
correct buggy nb.
id1 lit1 id1 lit2 lit1 lit2 lit1 lit3 id1.id2 lit1 id1.id2 lit2 var id1 lit1 var id1 lit2 id1 lit1 id2 lit1 id1 lit1 id1 lit2 throw new id1 lit1 throw new id1 lit2 id1.id2 lit1 id1.id2 lit2 id1 lit1 id1 lit2 return lit1 return lit2 id1 lit1 in id2 id1 !
!id2.
id3 id1.id2 lit1 id3 .id4 id1.id2 lit1 id3 id1.id2 id3 id1.id2 id4.id5 var id1 id2.id3 id4 var id1 id2.id3 var id1 id2.id1 var id1 id2.
id3 .
.
.
.
.
.
.
.
.
.
.
match threshold minimum similarity required for seeding 020406080100percentage syntactic matching least similar area effectiveness of semantic matchingseeded out of all bugs seeded with threshold .
reproduced out of figure influence of matching threshold mon seeded bugs.
with their frequency in our dataset.
all of the five most common bug seeding patterns top shown in table and of all bug seeding patterns contains at least one unbound token.
prior work on bug seeding based on past bug fixes does not handle unbound tokens and hence could not benefit from these patterns.
a semantics unaware variant of semseed reproduces only out of target bugs and not handling unbound tokens misses of all bug seeding patterns.
.
rq3 impact of configuration parameters .
.
matching threshold m.the matching threshold mdetermines in algorithm whether to apply a bug pattern to a code location.
a threshold of means that the seeding location need not be similar to the bug to imitate at all i.e.
the decision to apply a bug seeding pattern is purely syntactic.
in contrast a threshold of requires the tokens to perfectly match the original bug.
figure shows how the matching threshold influences the bugs that semseed creates.
the two curves show two percentages in blue the percentage of seeded bugs out of all bugs that a purely syntactic 913semantic bug seeding a learning based approach for creating realistic bugs esec fse august athens greece number k of bugs seeded per code location25303540455055number of reproduced bugs target bugs tokens alsofrom most frequent tcommon tokens also from the same file tfile tokens from the same function tfct figure reproduced real world bugs depending on token settand number kif bugs to seed.
approach i.e.
with m would seed in red the percentage of reproduced target bugs rq1 among the seeded bugs.
as expected both percentages decrease when the matching threshold increases.
intuitively if filtering potential matching locations based on the matching threshold is effective at guiding semseed towards realistic bugs then the blue curve should decrease faster than the red curve.
indeed the figure shows a clear gap between the two curves i.e.
the semantic matching of target locations is effective.
for example with a matching threshold of .
the approach seeds a bug at only of all possible locations but still reproduces of all bugs that semseed can reproduce.
compared to purely syntactic matching of bug patterns the semantic matching increases the chance to seed realistic bugs.
.
.
token set tand number kof bugs to seed.
another parameter is the set tof tokens to consider when binding unbound tokens section .
.
.
we experiment with three variants of t tfct search for unbound tokens only in the function where the bug gets seeded.
tfile in addition to tfct search among all tokens in the file where the bug gets seeded.
tcommon in addition to tfile search among the most frequent tokens across all files in the guiding set.
a larger search space increases the chance that the token required to reproduce a bug exists in t but also makes it more difficult to choose the right token i.e.
a token that indeed produces a realistic bug.
a related parameter is how many bugs to seed for a given code location and bug seeding pattern.
our approach seeds one bug for each of the kmost likely tokens found by algorithm and we evaluate values of kranging from to .
figure illustrates the effect that the token set tand the number kof bugs to seed have on the number of real world bugs that semseed reproduces.
we see that using a more restricted search space of tokens yields fewer reproduced bugs than a larger search space.
regarding the influence of k considering more than the single most likely token significantly increases the number of reproduced bugs in particular for larger t. our default configuration of t tcommon andk 10yields reproduced bugs.
depending on the token set tand the number kof bugs to seed semseed reproduces between and of the target bugs.
.
rq4 usefulness for training a learning based bug detector to evaluate the usefulness of semantic bug seeding we explore one of the applications of semseed seeded bugs as training data for learning based bug detection.
we build on deepbugs which learns from examples of correct and incorrect code and then predicts bugs in previously unseen code.
deepbugs supports several bugs patterns of which we focus on two that are particularly challenging to seed bugs for wrong assignment bugs where the right hand side of an assignment is incorrect e.g.
writing i o instead of i .
wrong binary operands where a developer uses an incorrect operand in a binary expression e.g.
accidentally writing length height instead of length breadth .
the other bug patterns e.g.
swapping function arguments are simpler to seed and do not require to select unbound tokens.
we train deepbugs using two configurations that differ in the way the incorrect code examples are generated.
one configuration called artificial uses deepbugs s default generation of incorrect code examples which randomly applies purely syntactic transformations and binds unbound tokens at random from tfile.
the other configuration generates incorrect examples with semseed which we configure to seed only bugs that match the two bug patterns targeted by deepbugs.
we apply both configurations to the same code corpus a de duplicated version of a javascript corpus which consist of 120k files.
generating for each correct example at most one incorrect example the artificial configuration yields .
million wrong assignments and .
million wrong binary operands.
since semseed focuses on locations that have a semantic match with one of the guiding bugs it creates fewer incorrect examples namely 248k wrong assignments and 267k wrong binary operands.
once trained we measure the ability of deepbugs to detect realworld bugs.
as the bug patterns targeted by deepbugs are relatively rare we gather the bugs in three ways i those of the held out bugs that match the two bug patterns ii additional bugs gathered from popular github javascript projects using the methodology in section .
.
and iii bugs from the javascript variant of an existing dataset of single statement bugs .
this process yields bugs wrong assignments and wrong binary operands .
we measure precision i.e.
how many of all reported warnings are among the known bugs and recall i.e.
how many of all known bugs deepbugs finds.
for each warning deepbugs returns a probability for the location to be buggy.
figure shows the precision and recall of deepbugs depending on the probability threshold used to decide which warnings to report.
overall using semseed generated bugs instead of artificial bugs significantly increases the effectiveness of deepbugs with clearly improved recall and roughly the same precision.
for example using a threshold of .
semseed increases the detected bugs from to .
to understand why semseed improves the bug detection ability of learned bug detectors consider two bugs seeded into the following code for var i i coordinates.
length i 914esec fse august athens greece jibesh patra and michael pradel .
.
.
.
.
.
threshold for classifying a bug0.
.
.
.
.
.0recallsemseed artificial a recall wrong assignments.
.
.
.
.
.
.
threshold for classifying a bug0.
.
.
.
.
.0precisionsemseed artificial b precision wrong assignments.
.
.
.
.
.
.
threshold for classifying a bug0.
.
.
.
.
.0recallsemseed artificial c recall wrong binary operand.
.
.
.
.
.
.
threshold for classifying a bug0.
.
.
.
.
.0precisionsemseedartificial d precision wrong binary operand.
figure precision and recall of deepbugs with artificially seeded and semseed seeded bugs.
semseed seeds a bug by turning length into another identifier that also refers to a dimension and that semantically fits the surrounding tokens i.e.
a bug that a developer might actually introduce for var i i coordinates.
offsetheight i in contrast deepbugs uses an arbitrary other identify from the same file resulting in a rather unrealistic bug for var i i coordinates.
enableclickbuster i as illustrated by this example a model trained on the artificial bugs tends to identify obvious yet unrealistic mistakes.
instead training deepbugs with semseed s bugs teaches the model to identify subtle yet more realistic mistakes.
more broadly the results also illustrate a quality versus quantity tradeoff in bug seeding the semseedgenerated bugs yield more effective bug detectors despite being an order of magnitude fewer than the artificially created bugs.
using semantically seeded bugs as training data for a learningbased bug detector allows for finding significantly more bugs.
.
rq5 comparison with traditional mutation operators existing code mutation approaches such as mutandis for javascript and major for java use pre defined mutation operators.
we compare the mutation operators in mutandis with the bugs created by semseed.
based on the guiding bugs we seed bugs into a random sample of javascript filesand then compare the seeded bugs to the mutation operators in mutandis.
.
of the semseed generated bugs go beyond the predefined mutation operators.
the .
of the bugs that are shared with mutandis correspond to out of the guiding bugs.
for example one of the mutandis patterns is about changing a literal in a condition a change semseed also performs.
another example is about removing the varkeyword from a variable declaration a pattern that semseed also learns and applies.
inversely mutandis also creates some bugs that semseed cannot seed.
out of the mutandis operators semseed has a corresponding bug seeding pattern for .
for out of these semseed seeds at least one bug while for the remaining three no suitable bug seeding location is found.
among the remaining 7mutandis operators two are out of scope for semseed because the code transformation affects more than one line e.g.
swapping two nested loops.
for the other five operators semseed could in principle seed bugs but there is no corresponding guiding bug.
these are mostly about changes to javascript apis e.g.
removing the integer base argument from calls like parseint .
semseed complements traditional mutations by seeding many bugs beyond a fixed set of pre defined mutation operators.
.
rq6 efficiency we measure the efficiency of semseed by keeping track of the time it needs to seed the bugs into the files from rq5.
this experiment is performed on a machine with intel xeon e5 cpu cores and 64gb of memory.
because some files allow for thousands of seeded bugs we set a time limit of minutes per file.
out of the files semseed could seed bugs into files where it found at least one matching bug seeding pattern.
in total seeding bugs takes minutes.
analyzing what part of the approach takes the most time we find that the analogy queries are the biggest bottleneck.
semseed takes on average .
seconds to seed a bug and hence can generate a large number of bugs in very little time.
limitations and threats to validity semseed focuses on single line bugs for two reasons i we can gather a large set of these bugs automatically which facilitates the evaluation and ii these bugs are relevant and important in practice .
for example karampatsis and sutton show that there is an instance of one out of common patterns of singleline bugs every to lines of code.
to generalize semseed to more complex bugs one would consider token sequence that span multiple lines.
one challenge we anticipate is that the probability that a complex bug to imitate syntactically matches code in another program is smaller than for single line bugs.
addressing this challenge e.g.
by approximately matching bug seeding patterns to code locations remains for future work.
among the many applications of bug seeding we select learningbased bug detection to evaluate semseed s usefulness.
based on our 1mutandis can also use runtime information to decide which bugs to seed which we ignore here because our focus is on static bug seeding.
915semantic bug seeding a learning based approach for creating realistic bugs esec fse august athens greece comparison with traditional mutation operators we are optimistic that the approach could also be useful e.g.
for mutation testing and envision future work on this and other applications.
our evaluation measures the realism and the usefulness of the seeded bugs but it does not confirm that each seeded bug indeed changes the behavior of the target program.
future work could measure to what extent the seeded bugs affect a program s semantics e.g.
by executing the program s test suite.
we implement the approach for javascript and cannot draw conclusions about how well it would work for other languages.
the fundamental challenges that semseed addresses i.e.
where to seed bugs how to adapt a given example bug to a target location and how to handle unbound tokens are language independent.
related work bug seeding.
one approach to bug seeding is to apply mutations e.g.
based on a predefined set of transformation patterns .
similar to our work propose to infer such patterns from code changes.
in contrast to these approaches semseed decides where to apply a bug seeding pattern and how to adapt it to the local code context based on semantic similarities of code elements.
tufano et al .
use neural machine translation nmt to learn and apply mutations.
their approach requires hundreds of thousands of bug fixing commits to be trained properly.
in contrast semseed learns from few examples in the extreme case one can use a single example bug to seed similar bugs at various target locations.
in general an nmt based approach could also seed bugs in a semantics aware way and comparing such an approach against semseed will be interesting future work.
one advantage of our work over nmt based approaches is that semseed enables seeing and possibly filtering the bug seeding patterns.
for example to train a deepbugs like learning based bug detector we focus on bug patterns supported by deepbugs by selecting the corresponding bug patterns.
an important difference between semseed and both and is that our approach handles unbound tokens seeding bugs even if this requires an application specific identifier or literal.
tailored mutation operators e.g.
insert code fragments that occur elsewhere in a project.
in contrast to such approaches the mutations applied by us are based on previously seen bug fixing patterns and not project specific as in or hard coded as in .
ibir also learns from past bugs how to seed new bugs .
it uses natural language in a bug report to decide where to seed a bug whereas semseed focuses on the tokens including natural language identifiers in the code.
ibir neither adapts bugs to a target location and nor addresses the unbound token problem which we show to be crucial for the majority of bug patterns.
motivated by the abundance of fuzz testing tools automatically seeded bugs have been proposed for evaluating fuzz testing .
these seeded bugs aim at being non trivial to trigger in an execution but are easy to detect on the source code level e.g.
because the seeded bug relies on magic numbers.
mining code change patterns.
osman et al .
describe an empirical study of frequent bug fixing code changes.
negara et al .
identify repetitive code changes from fine grained sequences of code changes recorded in an ide.
in contrast our approachmines only concrete changes that correspond to a bug fix rather than any change made by a developer.
nguyen et al .
mine semantic change patterns by converting the correct and buggy files to program dependence graphs.
instead of a graph we leverage embeddings of tokens as the semantic representation and extract changes as a sequence of tokens.
kim et al .
manually inspect human written patches to infer common fix patterns.
neural machine translation can learn to apply bug fixes .
semseed addresses the inverse problem of seeding bugs instead of fixing them.
bug benchmarks.
several bug benchmarks have been proposed including sir defects4j bugswarm bugbench begbunch ibugs manybugs codeflaws dbgbench .
our work complements such manually curated bug datasets by automatically seeding bugs into a target program.
finding matching code.
code clone detection relates to the semantic matching part of semseed.
these approaches find matching code pieces via string based parse tree based or token based comparisons.
our semantic matching relates to the token based techniques but differs by using token embeddings to find a match.
token embeddings.
recent work shows that token embeddings enable learning based program analysis e.g.
to detect bugs to predict types to de obfuscate code or to map apis across programming languages .
our work is the first to use pre trained token embeddings for bug seeding.
future work could adapt semseed to other kinds of token embeddings e.g.
contextual embeddings .
conclusion this paper presents semseed an approach for seeding bugs in a semantics aware way.
given a possibly small set of example bugs the approach infers bug seeding patterns and then imitates the given bugs at various code locations in a target program.
the key novelty is to go beyond purely syntactic bug seeding by i checking if a code location semantically matches the bug to imitate ii adapting the bug seeding pattern to the local code context and iii binding unbound tokens based on semantic analogy queries.
to reason about the semantics of code elements semseed builds on learned token embeddings which have not been used for bug seeding before.
our evaluation with thousands of real world bugs shows that the approach effectively seeds realistic bugs while being efficient enough for creating hundreds of thousands of bugs within an hour.
the created bugs complement traditional mutation operators and are useful as training data for learning based bug detectors allowing them to find many otherwise missed bugs.