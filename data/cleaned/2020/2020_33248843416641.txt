bigfuzz efficient fuzz testing for data analytics using framework abstraction qian zhang university of california los angeles zhangqian cs.ucla.edujiyuan wang university of california los angeles wangjiyuan g.ucla.edumuhammad ali gulzar virginia tech gulzar cs.vt.edu rohan padhye carnegie mellon university rohanpadhye cmu.edumiryung kim university of california los angeles miryung cs.ucla.edu abstract asbigdataanalyticsbecomeincreasinglypopular data intensive scalablecomputing disc systemshelpaddressthescalabilityissue of handling large data.
however automated testing for such data centric applications is challenging because data is often incomplete continuouslyevolving andhardtoknowapriori.fuzz testing has been proven to be highly effective in other domains such as security however it is nontrivial to apply such traditional fuzzing to big data analytics directly for three reasons the long latencyofdiscsystemsprohibitstheapplicabilityoffuzzing na ve fuzzingwouldspend98 ofthetimeinsettingupatestenvironment conventionalbranchcoverageisunlikelytoscaletodisc applications because most binary code comes from the framework implementation such as apache spark and random bit or byte levelmutationscanhardlygeneratemeaningfuldata whichfails to reveal real world application bugs.
we propose a novel coverage guided fuzz testing tool for big data analytics called bigfuzz.
the key essence of our approach isthat a wefocusonexercisingapplicationlogicasopposedto increasingframeworkcodecoveragebyabstractingthediscframeworkusingspecifications.
bigfuzzperformsautomatedsourceto sourcetransformationstoconstructanequivalentdiscapplication suitableforfasttestgeneration and b wedesignschema aware datamutationoperatorsbasedonourin depthstudyofdiscapplicationerrortypes.
bigfuzzspeedsupthe fuzzingtimeby78to 1477x compared to random fuzzing improves application code coverage by20 to and achieves33 to improvement in detecting application errors.
when compared to the state of the art that uses symbolic execution to test big dataanalytics bigfuzz is applicable to twice more programs and can find more bugs.
keywords fuzz testing big data analytics test generation ase september australia copyright held by the owner author s .
acm isbn .
reference format qianzhang jiyuanwang muhammadaligulzar rohanpadhye andmiryung kim.
.
bigfuzz efficient fuzz testing for data analytics using framework abstraction.
in 35th ieee acm international conference on automated softwareengineering ase september21 virtualevent australia.acm new york ny usa pages.
introduction emerging technologies are producing much data and the importanceofdata centricapplicationscontinuestogrow.data intensivescalablecomputing disc systems suchasgoogle smapreduce apache hadoop and apache spark have shown great promisestoaddressthe scalability challengeofbigdataanalytics.
although disc systems are becoming widely available to industry disc applications are difficult to test and debug.
data scientists of ten test disc applications in their local environment using sample data only.
these applications are thus not tested thoroughly and may not be robust to bugs and failures in the production setting.
the correctness of disc applications depends on their ability tohandlereal worlddata however dataisinherentlyincomplete continuously evolving and hard to know a prior.
motivated by the successesofsystematictestgenerationtools afewhave been proposed for dataflow based disc applications .
for example bigtest uses symbolic execution to automaticallyenumeratedifferentpathconditionsofadiscapplicationandgenerateconcreteinputsusingansmtsolv er.howeve r itsapplicabilityislimitedtothedataflowoperators e.g.
map reduce join etc.
where symbolic execution is supported and limited by the pathexplorationcapabilityoftheunderlyingsymbolicexecution engine and an smt solver.
in other words developing a robusttest generation tool for disc applications remains an open problem.
in recent years coverage guided mutation based fuzz testing hasemergedasoneofthemosteffectivetestgenerationtechniques for large software systems .
such fuzz testing techniques are based on implicit assumptions that it takes a relatively short amountoftimetorepetitivelyrunprogramswithdifferentinputs and arbitrary byte level mutations are likely to yield reasonableinputs.
in fact most fuzzing techniques start from a seed input generate new inputs iteratively by mutating the previous inputs andaddnewinputstotheinputqueueiftheyexerciseanewbranch.
this researchwas done whilethe thirdandfourth authorsweregraduate students at ucla and uc berkeley respectively.
35th ieee acm international conference on automated software engineering ase this work is licensed under a creative commons attribution international .
license.
however our experience tells us that fuzzing cannot be applied to big data analytics directly.
first the long latency nature of disc systems prohibits the efficacy of traditional fuzzing.
while tradi tional fuzzing techniques assume thousands of invocations per second for example apache spark applications would need about 10to15secondstoinitializethespark contextforeachrun job scheduling data partitioning and serialization all contribute to increasedlatency.second low levelmutations e.g.
flippingabit orbyte inexistingna vefuzzerscanhardlyexplorecornercases that represent realistic application bugs.
lastly grammar aware fuzzers existtoreducethetimerequiredforconstructing meaningful inputs.however they requirea userto provide gram mar rules and by definition they do not produce inputs violating the user provided grammar rules.
in this paper we lay the groundwork for embodying a coverageguided mutation basedfuzztestingapproachforbigdataanalytics.
the key insight behind bigfuzzis thatfuzz testing of disc applications can be made tractable by abstracting framework code and byanalyzingapplicationlogicintandem.ourkeyideaistoperform source to source transformation of a disc application to a semantically equivalent yet a framework independent program that is more amenable to fuzzing.
basedontheinsightthatadiscapplicationdeveloperwritesapplicationlogicintermsofuser definedfunctionsandconnectsthemusingdataflowoperatorsinthediscframework bigfuzzfocuseson exercising application logic as opposed to the disc framework implementation.
bigfuzzuses a two level instrumentation method to monitorapplication specificcoverage whilemodelingthedifferent outcomesofdataflowoperations.assuchcombinationofbehav ior modeling is independent of the underlying disc frameworkimplementation wecanabstracttheframeworkwithexecutable specificationsandgenerateasparkcontextfreeprogramtomitigatethelonglatencycausedbythediscframework.anapplicationdeveloper is not required to write any custom specifications because thespecificationsfordataflowoperatorssuchas mapandreduce do not need to be re written for each application.
bigfuzzfully automatesthisprocessofconstructingasemanticallyequivalent disc application through source to source transformation.
as opposed to random bit or byte level input mutations we designschema awaremutationoperationsguidedbyreal worlderror types.thesemutationoperationsincreasethechanceofcreating meaningful inputs that map to real world errors.
to inform the designofsuchdatamutationoperators weconductedasystematic study on common error types and root causes in apache spark and hadoop applications using two complementary sources stack overflow andgithub .thestudyidentifiedtencommonerror types which we map and encode in terms of six different mutation operators in bigfuzz.
weevaluate bigfuzzonabenchmarkoftwelveapachesparkapplications.wecomparethetimetogeneratetestinputsandtheirassociated error finding capabilities against two baseline techniques randomfuzzing andsymbolic executionbasedtesting.withframework abstraction bigfuzzis able to speed up the fuzzing time by to 1477x compared to random fuzzing.
schema aware mutation operations can improve application code coverage by to with valid inputs as seeds which leads to to improvement indetectingapplicationerrors whencomparedtonaiverandomfuzzing.
even without valid input seeds bigfuzzimproves applicationcodecoverageby118to271 anderrordetectionby58to157 demonstratingitsrobustness.weshowthat bigfuzzisapplicable to twice more applications and can find more bugs than the state of the art bigtest.
in summary this work makes the following contributions we propose a fuzz testing technique called bigfuzzthat targetsdiscapplicationsbyautomaticallyabstractingthedataflowbehaviorofthediscframeworkwithexecutable specifications.this novelapproach canalso be generalized to other systems with long latency.
we propose an automated instrumentation method to monitorapplicationlogicinconjunctionwithhowdataflowoperators are exercised in terms of their dataflow equivalence class coverage.
wepresentschema awaremutationoperationsthatareguided byreal worlderrorsencounteredindiscapplications.to our knowledge we are the first to design a fuzz testing technique by empirically studying and codifying mutations that correspond to real world disc bugs.
our experimental evaluation on apache spark applicationsdemonstratesthat bigfuzzoutperformspriorworkin terms of code coverage and error detection capability.
weprovideaccesstoartifactsof bigfuzzat qianzhanghk bigfuzz.
background apache spark.
bigfuzztargetsapache spark awidely useddata intensive scalable computing system but can generalize to other disc frameworks.
spark achieves scalability by creating resilient distributeddatasets rdds anabstractionofdistributedcollection .programmerscantransformrddsinparallelusingdataflow operations e.g.
val newrdd rdd.map s s.length .dataflow operators such as filter map andreduceare implemented as higher order functions that take a user defined function udf as an input argument.
the actualevaluation of an rdd occurs when an action such as countorcollect is called.
for example a spark applicationdeveloperwritesapplicationlogicintermsofudfsandconnects them using dataflow apis.
to execute the program spark first translates a program into a directed acyclic graph dag whereverticesrepresentvariousoperationsontherdds andthen executes each stage in a topological order.
thecommonindustrypracticefortestingsuchbigdataanalytics applications remains running them locally on a randomly sampled dataset.testingwithsampledataisoftenincompletewhichleadstorare buggy cases in production runs.
often spark programs run for daysandthencrashwithoutanobviousreason.additionally the start up latency associated with invoking the spark framework and blockmanagermaster cantakeseveralsecondsforsimplysetting up an execution environment and repetitive data partitioning job scheduling serialization and deserialization to support distributed execution all contribute to increased latency.
thus random fuzzing would be prohibitively expensive to test big data analytics.
fuzztesting.
fuzztestingsuchasafl hasbeenproventobe highly effectivein synthesizing test inputsthat achieve high code coverage and find bugs.
given an input program it instruments 723figure approach overview of bigfuzz 1valloan sc.textfile account history.csv input with zipcode base loan years and rate .map line valcols line.split cols cols .tofloat cols .toint cols .tofloat return zipcode base loan years and rate .map s 8vala s. 2 9for i to s. 3 a a s. 4 s. 1 a return zipcode and final loan 13vallocations sc.textfile zipcode.csv input with zipcode and city .map s valcols s.split cols cols return zipcode and city .filter s s. 2 new york 20valoutput loan.join locations .map s 22if s. 2.
1 property loan 23else if s. 2.
1 car loan 24else credit debt return three categories based on the loan amount .reducebykey a a disc application loantype.scala1arraylist string results0 loanspec.read inputfile1 2arraylist tuple4 results1 loanspec.map1 results0 3arraylist tuple2 results2 loanspec.map2 results1 4arraylist string results3 loanspec.read inputfile2 5arraylist map3 results4 loanspec.map3 results3 6arraylist map3 results5 loanspec.filter1 results4 7arraylist join2 results6 loanspec.join1 results5 results2 8arraylist map1 results7 loanspec.map4 results6 9arraylist map1 results8 loanspec.reducebykey1 results7 b a transformed program loantype.java with executable specifications 1publicarraylist map3 map3 arraylist string input 2arraylist map3 output new arraylist 3for string item input output.add map3.apply item 5returnoutput c specification implementation of map3inloantypespec.java 1publicclassmap3 2static final map3 apply string line2 3stringcols line2.split 4return new map3 cols cols d the extracted udf from lines to of figure 2a is represented as map3.java figure example code transformation and framework abstraction the program s bytecode iteratively generates new inputs by mutating several bits or bytes of the seed input and collects coverage feedback by executing the instrumented program with new inputs.
all inputs that exercise a new code branch are then be saved for furthermutation.theimplicitassumptionunderlyingsuchiterative fuzzing is that the target program can run fast i.e.
thousands ofinvocations persecond unfortunately this assumptionisfalse formanylonglatency applications suchasbigdataanalytics.for example initializing the spark context in local model to initiate adistributeddatapipelinetakes19seconds whichcorrespondto of the total execution time with a typical testing input.
the long latency prohibits the applicability of fuzzing for efficient test generation.
besides naively monitoring branch coverage in disc applications is unlikely to exercise application logic adequately since most binary code comes from the disc framework implementation e.g.
roughly700 klocfor apachespark .under this circumstance naiveattempttoincreasecodecoveragemayeventu allyrunoutofmemory.furthermore randombyte levelmutations can hardly generate meaningful structured or semi structured data to explore application logic effectively.
approach bigfuzzcontainsthreecomponentsthatworkinconcerttomake coverage guided fuzz testing tractable for big data analytics.
fig ure shows a abstraction of dataflow implementation using source to source transformation with extracted user defined functions discussed in section .
b two level instrumentation for coverage monitoring discussed in section .
and c input mutationsgearedtowardsbigdataanalyticerrorsbasedonourempiricalstudy discussedinsection3.
.thisapproachisbasedontheinsightthat wecanreducelonglatencyofdiscapplicationsbyabstract ingdataflowimplementationinadiscframeworkusingexecutable specifications and we can focus on exercising application logic ratherthantheentireframeworkbymonitoringcodecoverageof user defined functions in tandem with equivalence classes of abstracted dataflow behavior.
although bigfuzzis designed for spark programs its key idea can generalize to other disc frameworkssuch as hadoop by rewriting the dataflow operator apis to our current set of corresponding specification implementation.
.
framework abstraction for fuzzing as discussed in section disc applications have high latency making them not suitable for traditional fuzz testing because they 724table dataflow operator and corresponding equivalence classes spark dataflow operator transformed operator equivalences classes def filter udf t boolean rdd arraylist t filter arraylist t input f1 non terminating t.ud f t true return an rddthat satisfies a predicate udf t boolean return an arraylist of elements passing udf f2 terminating t.ud f t fa l s e whereudf t booleean is implemented in filter def join other rdd rdd arraylist t join arraylist t1 l arraylist t2 r j1 non terminating tl tr.tl key tr key return an rddcontaining all pairs of elements with return an arraylist of elements from left arraylist tl lj2 terminating tl tr.tl key!
tr key matching keys in thisandother rdds.
and right arraylist tr r with matching keys tl key tr keyj3 terminating tr tl.tr key!
tl key def map udf t u arraylist t map arraylist u input return a new rdd by applying udf t u return a new arraylist by applying a udf t utothis m non terminating always non terminated tofthis rdd.
arraylist whereudf t uis implemented in map.
def reducebykey udf v v v rdd arraylist t reducebykey arraylist t input merge the values for each key using an associative merge the values for each key using udf v v v r non terminating always non terminated reduce function.
whereudf v v vis implemented in reducebykey spendseveralsecondsjusttoinitializespark sexecutioncontextfor each run.
theoretically the long start up latency can be somewhat reduced by sharing one spark execution environment for multiple runs however suchpracticeisstillnotenoughtoachievemillionsof executionsperminute becauseeachrunstillneedstopassthrough a data partitioner a query optimizer a job scheduler and a data serializer deserializer etc.
indiscframeworks theimplementationofdataflowandrelationaloperatorsisinfluencedbyanduniversallyagreeduponthe semantics of such operators .
for example although a dataflow operator joinmay have a specialized physical implementation in each framework e.g.
hash join it has the same consistent logical semantics across all disc frameworks.
bigfuzztakes advantage of this observation rewrites a disc application into an equivalent applicationthatusesdataflowspecifications andmonitorsdifferent equivalence class coverage of dataflow operations.
for example filterhastwoequivalenceclasses onepassingthefilterpredicateandtheothernotpassingthefilter.becausedataflowoperators aredeterministic andstate less the transformed program is guaranteed to be equivalent to the original program.
for example map x x willalwaysgivethesameoutputforthesame input for both the spec based program and the original program.
we map each dataflow operator s implementation to a correspondingsimplifiedyetsemantically equivalentimplementation which we call executable specifications.
such specifications help eliminatethedependencyontheframework scode transforming adiscapplicationintoanequivalent simplifiedjavaprogramthat can be invoked numerous times in a fuzzing loop.
bigfuzzautomatesthisprocessofrewritingintwosteps udf extractionand sourcetosourcetransformation.figure2illustratesthisprocessusinganexamplediscapplicationthatidentifiesthefrequencyofeachloantypewithinametropolitanarea.thisprogram is a variation of one of the disc benchmark .
we formulateadistributed rdd basedimplementationusingspark sapis in figure 2a to a simplified executable specification of mapin figure2c.table1showsafewsamplemappingsbetweensparkrdd s dataflowimplementationapis equivalentspec implementations usingarraylist andasetofcorrespondingequivalenceclasses for each dataflow operator.step .
user defined function udf extraction.
to re write adiscapplicationtouseexecutablespecificationsonly bigfuzzdecomposes the application into two components a direct acyclic graph dag ofdataflowoperatorsand alistofcorresponding udfs.internally bigfuzzdecompilesthebytecodeoftheoriginalapplication into java source code and traverses abstract syntax tree ast tosearchforamethodinvocationcorrespondingtoeach dataflow operator.
the input arguments of such method invocations represent the udfs which are stored as separate java classes as shown in figure 2d.step2.sourcetosourcetransformation.
bigfuzzusesthedag extractedin thepreviousstepto reconstructthediscapplication inthesame interconnecteddatafloworderusingexecutablespecifi cations.suchdataflowspecimplementationtakesinan arraylist object as input applies the corresponding udf on each elementof the input list and returns an output arraylist .
for example classloanspec.map3 in figure 2b represents the equivalent spec implementation using arraylist that corresponds to map in figure 2a.
it takes in results3 from its upstream operators and returns an arraylist result4 for downstream operator loanspec.filter1 .bigfuzzselects the corresponding udfs from the list of udfs extracted from step and weaves them with the equivalent specifications shown in column of table .
for example javaclass map3hasmethod applymappingtotheoriginaludf in figure 2a and this method is invoked on each element of the input list as seen in figure 2c.
the above rewriting from a spark application in scala or java to an equivalent java application reduces the latency of running a discapplication whileretainingthesamesemantics.italsomakes it easier to collect guidance metrics such as branch coverage byleveraging existing tools jqf which takes java bytecode as input and collects various guidance metrics for fuzz testing.
.
application specific coverage guidance priorworkfindsthatbranchcoverageisaneffectiveguidancemechanism for feedback guided fuzz testing pushing test generationtowards hard to reach corners .
generally feedbackguided fuzzing techniques instrument a program s bytecode to labeleachconstituentbranchandifaninputexercisesapreviouslyunseenbranchoftheprogram thisinputisappendedinaninput queue and the branch coverage is fed back into the fuzzer.
however weobservethatsuchbranchcoverageguidancemechanismcannotbeappliedtofuzztestingofbigdataanalyticsfortwo reasons.first itcannotdifferentiateuser definedfunctionsfrom framework code and can thus push test generation naively toward exploring the internals of disc framework as opposed to application logic.
second it cannot effectively monitor different equivalenceclassesofdataflowoperatorsthoughpriorstudies argue that numerous errors originate from untested equivalence 725table data collection for error type study.
keyword totalinspected apache spark exception top stackoverflow spark apache spark error top apache spark wrong unexpected inconsistent result output hadoop exceptions top hadoop error top stackoverflow hadoop hadoop wrong output top hadoop wrong result top hadoop unexcepted inconsistent result github sparkcontext classesofdataflowoperators.for example whentestingoperator join it is important to test three equivalence classes j1 there exists a key that appears in both tables passing the joined result to the next operator j2 an input record in theleft table does not haveamatchingkeyontherighttable terminatingitsdataflow and j3 aninputintherighttabledoesnothaveamatchingkey on the left terminating its data flow discussed in table .
toaddressthesetwoproblems bigfuzzdesignsatwolevelinstrumentationandmonitoringmethodforapplicationspecificcoverage guidance.
the key insight here is that bigfuzzmonitors regular branchcoverageforuser definedfunctionsonlyandfordataflow operators itmonitorsatthelevelofequivalenceclasses.below wedescribe how we extend traceevent in jqf to monitor which equivalence classes are exercised for individual dataflow operators.
traceevent in jqf.
bigfuzzis built on top of jqf a javabasedfuzztestingframeworkthatusesasm toinstrumentjava bytecode on the fly as classes are loaded by the jvm.
jqf instruments all application classes by injecting a static method call with auniqueidentifieraftereverybytecodeinstruction.itfocuseson control flow instructions such as method calls e.g.
invokestatic invokeinterface etc.
andbranchinginstructions e.g.
if cmpne goto etc.
.
jqf collects these instructions and groups them to a higher level abstraction called traceevent e.g.
callevent and branchevent which are then emitted to its coverage logger.dataflowevent in bigfuzz.
to keep track of equivalence class coverageforindividualdataflowoperators bigfuzzextendstraceeventinjqfandcreatesaspecific dataflowevent .inadditiontoan identifier dataflowevent has an additional booleanorinteger variable to keep track of which subset of equivalence classes is exercised by the corresponding dataflow operator.
for example filterevent isaspecific dataflowevent classforkeepingtrackof whichequivalenceclasseisactivatedfor filter.
filterevent arm represents the non terminating equivalence class where the filter predicate holds true and individual data records thus passthrough the filter predicate.
filterevent arm indicates the other terminating case where the filter predicate holds false thus individual data records stop at this filter.bigfuzzinstruments tracelogger.get .emit new filterevent arm in specification implementation of filterto emitfilterevent with a specific arm to the trace logger.
in this way bigfuzzretains the disc framework s behavior on the original application code while abstracting its coverage guidance mechanism to the level of equivalence classes for individual dataflow operator uses.
coverage guidance foruser defined function.
disc applicationdeveloperwritesapplicationlogicintermsofuser definedfunctions udfs andconnectsthemusingdataflowoperators.these udfs are standard library based scala or java implementations.
to restrict normal coverage guidance to the body of udfs e.g.
figure2d bigfuzzusesaselectiveinstrumentationschemeinasm whileignoringallotherdependentlibraries.thiscombinationof monitoringdataflowequivalencecoveragetogetherwithcontrol flow events in the body of udfs constitutes the joint dataflow and user definedfunctionpathcoverage jdupathcoverage which essentially represents the behavior of application logic.
.
mutations for big data analytics infeedback guidedfuzzing commonlyusedinputmutationsareeither bit level or byte level mutations in which random bits or bytes are flipped in an input represented as a series of bits .
the example program in figure takes as an input string that containscomma separaterowentries whereeachentrycontains the zipcode of borrower the loan amount the number of yearssince the loan was issued and the interest rate respectively e.g.
.
.whentraditionalfuzzingisappliedtothis example program if no seed is provided it may first generate aseries of random bits e.g.
which maps to a character .afterwards thisinputismutated byflippingseveral bits e.g.
which is the character n .
both cases above would generate meaningless inputs that fail at the program entry and arethusincapableofadvancingthecoveragegoals.ifthefuzzing process starts with a user provided seed input it will take thisseed as bit series and flip several bits at a random position.
inthis way traditional fuzzing can easily find data format errors when the program terminates at a earlier stage however it can hardly generate meaningful data that drives the program to a deep execution path since bit flipping is more likely to destroy the data formatordata type.infact ourexperimentfinds thatover90 of inputs generated by random fuzzing fail at the entry point without exercising code further.
in contrast bigfuzzdesigns a two fold approach towards mutatinginputs.first ittriestogeneratevalidinputs suchthattheinputs are consistent with the input parsing logic of the program.
second it introduces record level schema aware mutations modifying data with respect to the structured data types as well as value ranges.
unlikerandombit levelmutationsthatproduceunnaturalinputs each of the schema aware mutations mimics a real world error in discapplicationsthatmayleadtoprogramcrashesorfailuresat runtime.tothisextent weextensivelyinvestigatediscapplication errors posted on popular q a forums and code repositories.
a study of common error types.
to collect real world disc applicationerrors wefirstperformedakeyword basedsearchon stackoverflow q a forum and github repositories using spark 726table common error types in disc applications type portion example fix mutation type mismatch .
data type is not double as expected by spark s kmeans change type m2 illegal data for udf .
nullpointerexception caused by null values check udf m4 split related errors .
the user uses .split when .split is expected change delimeter m3 m4 incorrect column access .
column access el .sum.todouble where el.len check data length m5 incorrect offset access .
used substring instead of substring check offset m6 incorrect code logic .
the user uses a mutable data when it shouldn t be used check code m1 incorrect api usage .
to match columns equalto api is expected in join operation check api usage m1 join related errors .
join gives null values leading to a nullpointerexception in map check data m1 semantic errors .
minimum word appearance count in spark word2vec model is not met change api n a framework bugs .
the expected result is a single row but the user got two lines update library n a libraries.
table shows the number of posts and issues for each keyword search.
as for stackoverflow we studied both spark and hadoop related posts and manually examined posts in total.
weremovedpostsrelatedtoperformanceorconfigurationerrors to focus on analyzing posts reflecting either application or data errors.
as for github we inspected projects that use the apache spark framework and their code repositories and bug reports.
we examined the accepted answers and comments if any to understandtherootcauseofunderlyingerrorsandsummarizetheir solutions.
we then distilled and grouped these root causes into ten categories each reflecting a unique underlying programming issue.
table shows the error type of posts for this error type a representative example and a solution to fix the error.
for instance the mostfrequentlyencounterederrortypeisrelatedtoanincorrect columnaccesswhichcomprisesof16.
oftotalerrors.arepresentative example of such error is when a user accesses the 25th column el .sum.todouble fromdatawithonly22columns el.len .thenextmostfrequentlyoccurringerror .
is whenthe inputdoes not conformto theexpected data type e.g.
arecord entrydoesnot complywith date.todouble resulting in numberformatexception.
error type guided schema aware mutations.
instead of bitlevel mutations bigfuzzuses a user defined schema to perform coarse grained record levelmutations.intheschema ausercan indicate the number of columns data type and data distributionfor each column of the input data.
the following code snippet representsasampleuser providedschemaforinput loaninfigure 2a which dictates that each input entry comprises of four commaseparated columns the first column must be a bit number string with prefix the second column must be a random number with float type the third column is an integer within range andthelastcolumnisafloatnumberwithin0 .fromsuchschema wecanderivevalidinputconstraintswithrespecttodataformat data type and data distribution.
number string float integer float basedonourstudy wedesignsixmutationoperationsm1 m6 asshownintable3toreflecttheirassociationwitheachrealworld error type.
we enumerated these mutation types below data distributionmutation m1 mutatesarecordtobe eithervalidorinvalidintermsoftheallowedrangebasedon the data distribution given in the schema e.g.
an inte ger value corresponding to the range integer mutated to 25or .
data type mutation m2 modifies the data type of a selected column while keeping the same value e.g.
20correspondingto integer canbemutatedto .
leading tonumberformatexception in line figure 2a .
dataformatmutation m3 mutatesacolumn separating delimiter mentioned in the schema e.g.
replacing delimiter to .
datacolumn mutation m4 insertsoneorseveralcharacters e.g.
replicating arrayindexoutofboundsexception instackoverflowpostno.
whenarandom is inserted to data that is ctrl a separated .
null data mutation m5 mutates the input row by removingoneormorecolumns e.g.
replicating nullpointerexception in stack overflow post no.
b ya c cessing positions that do not exist .
empty data mutation m6 mutates a random column to an empty string leading to stringindexoutofboundexception caused by incorrect string operations.
compared to random bit level mutations because these schemeawaremutationsareinspiredbyreal worlderrors theyaremore effective for producing valid and invalid inputs which we empirically demonstrate in section .combined data generation and mutation.
based on a userprovided schema bigfuzzautomatically constructs an applicationspecificmutationgeneratorthatcombinesvalidinputgeneration andsixerror typeguidedmutations.givenaseedinput bigfuzz will either randomly mutate the seed input or randomly generate valid inputs followed by mutating such inputs to increase cumulative coverage.
it can run under any of the two options and does not require having a valid seed.
so a user may start bigfuzz with any string as a seed.
empirically as we discuss in section starting with a valid seed does slightly improve performance by avoidingcrashingtooearlyfromaninvalidinput.forexample ifa validseedsuchas .
.
isprovidedforfigure2a bigfuzzresults in higher error detection than without.
however even an ill formatted string is given as a seed bigfuzzdoes retain high performance with its data generation option.
evaluation our evaluation seeks to answer the following research questions rq1is a widely used fuzzing tool such as afl applicable to big data analytics with long latency?
rq2doesframeworkabstractioneffectivelyspeedupfuzztesting?
727table statistics on subject programs subject o f o f bigtest bigfuzz randomfuzza id program output operators jdu paths covered covered covered p1 wordcount find the frequency of words p2 commute type people count using each form of transport for daily commute p3 externalcall find the frequency of words p4 findsalary total income of individuals earning weekly p5 studentgrade list of classes with more than failing students p6 movie rating total number of movies with rating p7 insidecircle check whether the point x y is in a circle n a p8 mapstring string mapping n a p9 numberseries find the numbers whose 3n series length is n a p10 ageanalysis total number of people with different age ranges n a p11 incomeaggregation average income per age range in a district n a p12 loantype the frequency of each loan type within a metropolitan are n a rq3doesschema awaremutationeffectivelyimprovecodecoverage and error detection capability?
rq4how much improvement in applicability and error detection doesbigfuzzachieve comparedtoanalternativesymbolic execution based technique?
benchmarks.
weusetwosetsofsubjectprogramsasbenchmarks.
they include twelve spark programs written in scala listed in table .
for these subjects p1 p2 and p4 p6 are directly from prior work p3isfrom andp12isreproducedbyusbasedonthe informationofastackoverflowpost .p7 p8arefromsparkexamples andtheremainingprogramsarehandcraftedbytheauthors.
wecompare the generatedtest inputs andtheir associatederrorfinding capabilities with two baselines a conventional fuzzing and b symbolicexecutionbasedtestingforbigdataanalytics which is publicly available on github.
experimentalenvironment.
weusespark slocalrunningmode toperformexperimentsonasinglemachinewithintel r core tm i7 8750h .20ghz cpu and gb of ram running ubuntu .
.
.
faulty benchmarks to evaluate error detection capability we inject code errors to the subjectprogramsbymappingreal worlderrortypesintable3to corresponding code modifications.
type mismatch errors and splitrelated errors are injected by changing the required data type and delimiter in the program.
changing an array or a string index can injectincorrectarrayorstringaccesserrors.toinjectincorrectlogic errors weswapbinaryoperatorsifarelationaloperatorappears in a branch condition e.g.
the user uses when is expected or we replace a multiplication operator e.g.
a b to a division e.g.
a b toinduceadividebyzeroerror.wealsoupdateconstants orreplacesvariables.forexample ifweinjectalargenumberto aredecebykey thatdoesaccumulationbykey anoverflowerror mayoccurwhentheintermediatevalueisbeyondthecapacityof itstype.whenwereplaceadataflowoperatorsuchas joinwith itscounterpartsuchas left join wemayreduceerrorsrelated to join operator or incorrect api usage.
this error seeding process is done automatically through source to source transformation on each subject.
we traverse the abstract syntax tree ast of each program and apply one of the aboveinjections to a random location if applicable.
if code update can be applied to multiple locations we choose one location randomly.thisnewlytransformedastistranslatedintosource sothatwecan see the error location.
in total we create error seeded versions.
.
applicablity of afl rq1 almost all fuzz and random testing techniques are built on the assumption that the program under test can be executed millions of times within a matter of hours.
to quantify this limitation ofapplying naive fuzzing to disc applications we use afl on the twelve subject programs.
afl is a mature fuzzing tool designed forc c and jqf makes afl available for java programs.
when using afl with 9216m as memory and seconds as timeout setting itrunsatanextr emelylowspeed 0to9.68execs per sec anaflreportedmetrictoindicatethenumberoftestexpectations invoked from a fuzzing loop per second .
the extremely low speed is because spark applications spend significant time on setting up asparkcontext whichattributestomostexecutiontime.further as most binary code comes from disc framework implementation withmillionsoflinesofcode afl sattempttoincreasecodecoverage eventually leads to running out of memory after only executionsonaverage.evenbeforeitdies aflwitharandomseedexploresonly18 oftheapplicationcodeonaverageforallsubjectsexceptp1 p3 andp8 whichtakeanunstructuredrandomstringas input.
this empirically demonstrate that naive fuzzing is too slow and insufficient to generate meaningful structured data and reveal disc application errors.
.
comparison against random fuzzing wecreatetwoseparatedowngradedversionsof bigfuzzbydisabling frameworkabstractionanderror typeguidemutationsrespectively.
wecalltheversionwithoutframeworkabstractionas randomfuzzm asitretains mutation capabilityonly.wecalltheversionwithout error type guided mutations as randomfuzza as it retains frameworkabstraction capability only.
rq2 speedupwithframeworkabstraction.
toassessspeedup enabled by abstracting disc frameworks in isolation we use a downgradedversion randomfuzzm whichdisablessourcetosource transformation for framework abstraction.
we measure the runningtimeofboth bigfuzzandrandomfuzzm with1000iterations forprogramsp1 p12.theterm iteration referstoasingletestexecution invoked from a fuzzing loop.
we repeat the experiment ten 728p1 p2 p3 p4 p5 p6 p7 p8 p9 p10 p11 p12104106108time ms bigfuzz randomfuzzm figure running time with iterations times and report the average results in figure y axis is milliseconds in log scale.
bigfuzzis significantly faster than randomfuzzm speeding up the fuzzing time by 78x to 1477x.
rq3 coverageanderrordetectionimprovementwitherrortypeguidedmutation.
for rq3 to evaluate the benefit of errortypeguidedmutationsinisolation wecreateadowngradedversion randomfuzza that disables error type guided mutations.
we assess how fast bigfuzzandrandomfuzza generate inputs exercising more jdu paths within the same iteration limit.
we run bigfuzz andrandomfuzza for iterations and report the cumulative ofexercisedjdupathsand ofdetectederrors.werepeatthe experiments four times and report averages.
figures4and5reporttheresultswhenstartingfuzzingwithand without a valid seed.
please note that bigfuzzdoesnotrequire a usertoprovideavalidseedandcanrunundereitheroptionbutwepresentbothtoestimateitscapabilityaccurately.underthenormalscenariowhen randomfuzza isstartedwithoutavalidseed itsoverallperformanceislowerthanbeingbootstrappedwithavalidseed becausemutatingavalidseedcanavoidearlycrashes.however as we discuss below bigfuzzcan achieve similar performance with or without a valid seed demonstrating robustness.
whenstartedwithoutavalidseed thenormalscenario bigfuzz provides118to271 improvementinjdupathcoverageincomparison to starting randomfuzza without a valid seed leading to to improvementinerrordetection.whenfuzzingisstartedwith avalidseed thefavorablescenario bigfuzzcanimprovejdupath coverage by to which leads to to improvement in detecting errors in comparison to randomfuzza with a valid seed.
the overall numbers of covered jdu paths among different runs are reported in the rightmost two columns in table .
because bigfuzzis was to achieve jdu path coverage for all benchmarks exceptp4 wedidnotrun bigfuzzfor24hours assuggestedinprior work .theuncoveredpathstartswithastringwhoselength mustbelargerthan7 howeveritsintegervalueshouldbelessthan300.longerexecutiontimemaycoverthispath.formostprograms randomfuzza srandomlygenerateddatacanhardlyexerciseadeep execution path or dataflow equivalence classes.
.
comparison with symbolic execution based testing rq4 applicability.
we assess how many spark programs are testable using bigfuzz in comparison to an alternative symbolic execution based approach bigtest .
symbolic execution based testing requires a symbolical interpretation of each dataflow operatorusedintheprogramalongwiththeudf.theapplicability ofsuchtechniquescouldbelimitedbythecapacityofunderlyingsmt solvers and the ability to completely represent the entire programsymbolically.wereporttheresultsintable4 where n a represents bigtestis not applicable.
bigfuzzcan be applied to twice as many programs as bigtest.
forprogramsp1 p6 bigtestcangeneratetestinputssuccessfully whileitfailstorunonprogramsp7 p12.weinvestigatethepublicly available source code of bigtestand find three primary reasons behinditsinapplicabilityontheseprograms.aswithmanysymbolic execution based test generation techniques bigtestrestricts its symbolic exploration of unbounded collections and loops toa user defined bound k default is .
some programs such as p9 requireahighvalueofloop bound k toreachcriticallyimportant jdu paths which leads to inability of bigtestto maintain many symbolicstates.duringprogramdecomposition bigtestextracts each dataflow operator s argument assuming that the argument is alwaysaudf.however inp7 apointertoaudfispassedinstead of the udf itself which results in incorrect udf extraction.
on thecontrary bigfuzzleveragesstatic dereferencinginsuchcases.
furthermore in scala a forloop iterating over a collection is compiled into an mapmethod call on the collection.
we find such cases in program p12 in which bigtestconsiders the mapmethod call on collections as a dataflow operator resulting in incorrect dag interpretation.rq4 error detection capability.
we evaluate the error detection capability of bigfuzzin covering more jdu paths and generatinginputsthatleadtoerrorsthatcannotbefoundby bigtestfor programs p1 p6 that both tools are applicable.
columns bigtestandbigfuzzin table summarize the jdu path coverage for bigtestandbigfuzzrespectively.
for all the test inputs generated by both tools we manually inspect their covered execution path in udfs and dataflow equivalence classes.
in terms of tool setting we set the user specified bound kas a default value forbigtestand set the fuzzing iterations as for bigfuzz.
for all the subjects p1 p6 except p4 bigfuzzis able to achieve coverage on jdu paths within the number of iterations leading to to improvement in path coverage compared to bigtest.
table error detection capability of bigfuzzandbigtest subject programs p1 p2 p3 p4 p5 p6 injected errors bigtest bigfuzz table reports a comparison of error detection capability of bigfuzzandbigtestintermsoffindingautomaticallyinjectederrors.
bigfuzzgeneratesinputstodemonstratealloftheinjectederrors and detects .
more injected errors than bigteston average.
in addition bigfuzzhas the unique capability of finding errors that cannot be detected by bigtest.
in p1 bigtestwith default k 2setting cannotfind an inputfor theruntimeoverflowwhenweinjectalargenumber2147483600to reducebykey because this error appears only when the minimum appearance number of a word is larger than three.
in p3 whenthe filter v. 2 is replaced with filter log10 v. 2 bigtestfails to generate a constraint for this path that contains an external method call on a symbolic value.
the injected divide 729101102103020406080100p1 101102103020406080100p2 101102103020406080100p3 101102103020406080100p4 101102103020406080100p5 101102103020406080100p6 iterationscumulative of total jdu paths coveredp7 iterationsp8 iterationsp9 iterationsp10 iterationsp11 iterationsp12 randomfuzza with a valid seed bigfuzzwith a valid seed randomfuzza without a valid seed bigfuzzwithout a valid seed figure joint dataflow and udf coverage 101102103020406080100p1 101102103020406080100p2 101102103020406080100p3 101102103020406080100p4 101102103020406080100p5 101102103020406080100p6 iterationscumulative of total errors detectedp7 iterationsp8 iterationsp9 iterationsp10 iterationsp11 iterationsp12 randomfuzza with a valid seed bigfuzzwith a valid seed randomfuzza without a valid seed bigfuzzwithout a valid seed figure error detection capability by zero error in p2 as well as the injected type matching errors in p4 p6arebeyond bigtestbecauseitsunderlyingsmtsolverfails to generate concrete inputs that satisfy such path constraints.
related work fuzz testing has gained popularity in both academia and industry due to its black grey box approach with a low barrier to entry .
thekeyideaoffuzztestingoriginatesfromrandomtestgeneration where random inputs are incrementally produced with the hope to exercise previously undiscovered program behavior randomtesting.
onedifficultyinpurerandomtestingisgeneratingvalid inputs especiallyforobject oriented programs.jcrasher uses java reflection to understand the parameter space and the typeofamethodundertestandgeneratesrandominputsaimingtoproduceajavaexception .randoop permutesmethod sequences to construct valid input executes the new sequence andobservesregressionoruser definedcontractviolations while eliminating those leading to redundant execution by keeping track of the method sequences.
evosuite also generates test suites to revealprogramcrashesandconstructstestoraclesintheformof assertions to check for the expected program behavior .fuzz testing.
fuzz testing is similar to random test generation inmanyaspects.itmutatesaseedinputthroughits fuzzertoexposepreviouslyunseeninternalstatesoftheprogram.aflisthe most widely used coverage guided fuzzing tool .
generally traditional coverage guided fuzz testing has limited efficiency andeffectiveness due to a vast space of inputs and unbounded pro gram paths.
lemieux et al.
identify rarely executed branches inthe program with afl generated inputs and then create custom mutations so that the generated inputs gravitate toward exercising rare branches .
as a result it requires fewer fuzzing loops and 730achieveshighercoverageinlesstime.otherapproachesincorporatesymbolicexecutioninfuzzingtoguidecarefulselectionand mutation of the inputs invoking unique program paths .
padhye et al.
incorporate the semantic validity of input mutations in zest .
zest reduces the search space of inputs by mapping bit level changes to valid structural changes in the input.
anotherangletominimizeunfruitfulfuzzingloopsistogenerate only legal inputs for the program.
le et al.
propose a grammarbased fuzzing approach called saffron that relies on a user defined grammar .duringfuzzing ifaninputgeneratedbythegrammarleadstoaprogramfailure saffronreconstructsthegrammar according to newly learned input specifications of the program.
wang et al.
leverage a user provided grammar but instead of arbitrarymutations theyintroducegrammar specificmutationsto diversify test inputs for tightly formatted input domains such as xml and json .
gopinath et al.
highlight that the state of art grammar awarefuzzer dharma isstilltwoordersofmagnitude slower than a random fuzzer and suggest guidelines for efficient grammar awarefuzzing .intheirfollow upwork theypresent an approach to infer an input grammar from the interactions between an inputparser and input data .
in discapplications a largeproportionofprogramfailuresareduetoill formattedinputs which are hard to know in advance and are not taken into account during development.
therefore grammar aware fuzzing may not be practical in revealing errors in disc applications because ifa user were to prescribe grammar rules up front it may be too restrictive to generate meaningful error inducing inputs.
almostallfuzzandrandomtestingtechniquesarebuiltonthe assumptionthat theprogramundertestcanbeexecutedmillionsof times within a matter of hours.
in the domain of data intensive scalablecomputing userapplicationsarebuiltontopofframeworks suchasapachesparkorhadoopmapreduce containingcomplex distributed systems.
therefore a single program run may take severalminutes ifnothours includingaconstantclusterspin uptime.
therefore the performance and resource expense of state of art fuzzing and random testing for disc applications are prohibitive.
to speed up test exe cution while fuzzing untracer dynamically strips out code coverage instrumentation for lines of codethat have already been covered.
for disc applications the overhead is not due to instrumentation but indeed due to the extensive framework code.
bigfuzzis the first fuzzing tool that transforms the target application by simplifying framework logic.softwaredebloating.
codedebloatingtechniques strip off unnecessary logic or library functions that are not used by an application with the primary motivation to reduce the attacksurfacesortoreducebinarysize.unlikedebloatingtechniquesthat removeunusedcodeviareachabilityprogramanalysis bigfuzz s framework abstraction replacescritical dataflow operators with semanticallyequivalentimplementationstoreducetheimpactof bloated code for fuzz testing.symbolicandconcolicexecution.
symbolicexecutionhasbeen extensivelyusedforadiversesetofusecases includingautomatedtestgeneration programverification securityanalysis andcodeop timization.itallowsprogrammerstoexecutetheirprogramsymbolically to verify correctness .
tools such as klee pex and javapathfinder brought symbolic execution to the forefrontofsystematictestgenerationbydiscoveringuncoveredprogramregionsandusingconstraintsolverstogenerateadditional test data to reveal faults in previously uncovered regions .
however symbolicexecutionbasedtestingisoftenlimitedby an enormousnumber ofprogram paths emergingfrom largecode.
severalheuristics basedapproachesaddressthisproblemofpath explosion .
burnim et al.
leverage static analysis toguidesymbolicexecutiontoward uncoveredpathstoprioritize specific program paths .
as with any other heuristics based approach thesetechniquesproducemanyfalsenegatives asthey prioritize exploration of certain program paths over others.
consequently itmayleadtolowtestquality orfaultdetectionrate of thegeneratedtestsuite.experimentalresultsfrompriorworkshow that symbolic execution may have lower fault detection capability than black box fuzzing or random testing .
discapplicationsdependonmillionsoflinesofcodeindisc framework whichmakesitinfeasibletonaivelyapplysymbolicex ecutiontotheresultingcodeasis.evenifheuristics basedsymbolic execution is used to model the entire disc application s binary code the resulting test suite would mostly concentrate on finding thedefectsinthediscframework asopposedtofindingbugsin application code.
testing sql and data analytics.
qex follows the traditional symbolic execution based test generation playbook and maps a sql query to an smt query .
it is loaded with custom theories foreachrelationaloperator.cosettemapsarelationalquerytoa symbolicrepresentationbyeither a provingequivalenceamong two queries or b generating counterexamples that explain con flicting answers from two queries .
miao et al.
leverage hardcoded specifications of relational operators and generate database rows to explain the output difference between two queries .
domino uses tailored domain specific operators based on randomvaluestogeneratetestdataforrelationaldatabaseschemas.
guptaetal.pivottheirmutation basedtestgenerationtechnique for sql queries .
they define a set of mutations for selected relational operators such as inner join or join and specify rules needed for each type of join to kill the mutant.
sql integrated applications are widely used in practice and they invoke sql queries programmaticallyusingdatabaseconnectionssuchasodbc or jdbc .
variants of symbolic execution are used to generate both application inputs and database states .
relational database applications rarely use user defined functions udf whichareprevalentindiscapplications.thustheabove mentionedtoolscannotrevealfaultsfromtheinteractionofudf anddataflowoperatorsortheudfalone makingthemnotapplicable to disc applications.
testingdiscapplications.
today discapplicationsare almost always composed of both udf and dataflow relational operators.
gulzaretal.model thesemanticsoftheseoperatorsinfirst order logicalspecificationsalongsidewiththesymbolicrepresentation ofudfs andgenerateatestsuitetorevealfaults.priordisc testing approaches either do not model the udf or model the specificationsofdataflowoperatorspartially .lietal.proposea combinatorialtestingapproachthatautomaticallyextractsinput domaininformationfromschemaandboundsthescopeofpossible input combinations .
731however all these symbolic execution use a heuristic loop iteration bound k during path exploration which may lead to false negatives and they are also limited in applicability due to their symbolic execution scope.
testinglargescalesystems.
gulzaretal.studytheuseofdifferential testing for large scale end to end systems instead of tra ditional unit testing and find unit testing either incomplete orinfeasible in practice due to the system s complexity .
they furtherobservethatmorethan40 oftestsinreal worldproductionsoftwaretakebetween15minutestoseveralhours stressing theinfeasibilityoffuzztestingonlarge scale long latencysystems.
other studies at microsoft and google concur exceedingly long runningtesttimes intheorderofhours ontheirproducts such as microsoftwindows .
thesestudies further validate our hypothesis that fuzz testing that assumes fast repetitive re runs is not suitable for such large systems with long latency.stateless computation.
long startup time is a well known problem for disc applications and jvm applications in general.
hottub reduces latency by amortizing the warm up overhead over the lifetime of a cluster node instead of over a single job.
restler is a stateful fuzzer that analyzes the api specification ofacloudserviceandgeneratessequencesofrequeststhatautomatically test the service through its api.
different from these stateful computations dataflowoperationsarestatelessanddeterministic whichisthekeyinsightthat bigfuzzusestocreateasemantically equivalent fuzzing friendly program.
conclusion fuzztestinghasemergedasoneofthemosteffectivetestgenerationtechniques.toadaptfuzzingtodiscapplicationswithlong latency we propose bigfuzzthat leverages dataflow abstraction usingsource to sourcetransformation tandemmonitoringof equivalence classbaseddataflowcoveragewithcontrolflowcoverageinuser definedfunctions and schema awaremutations that reflect real world error types.
bigfuzzachieves to 1477x speed up compared to random fuzzing improves application code coverage by to leading to to improvement in detecting application errors.
acknowledgement wethankkoushiksenforhisfeedbackandtheanonymousreviewersfortheircomments.theparticipantsofthisresearchareinpartsupportedbynsfgrantsccf ccf ccf onr grant n00014 intel capa grant samsung grant googlephdfellowship andalexandervonhumboldtfoundation.