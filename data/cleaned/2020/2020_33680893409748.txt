boosting fuzzerefficiency an informationtheoreticperspective marcel b hme monash university australia marcel.boehme acm.orgvalentin j.m.man s csrc kaist korea valentinmanes outlook.frsangkil cha csrc kaist korea sangkilc kaist.ac.kr abstract inthispaper wetakethefundamentalperspectiveoffuzzingasa learningprocess.
supposebefore fuzzing we knownothing about the behaviors of a program p what does it do?
executing the first test input we learn how pbehaves for this input.
executing the next input we either observe the same or discover a new behavior.
as such each execution reveals some amount of information aboutp sbehaviors.aclassicmeasureofinformationisshannon s entropy.
measuring entropy allows us to quantify how much is learnedfromeach generatedtestinputaboutthebehaviorsofthe program.
within a probabilistic model of fuzzing we show how entropyalsomeasuresfuzzerefficiency.specifically itmeasuresthe generalrateatwhichthefuzzerdiscoversnewbehaviors.intuitively efficientfuzzers maximizeinformation .
from this information theoretic perspective we develop entropic an entropy based power schedule for greybox fuzzing whichassignsmoreenergytoseedsthatmaximizeinformation.we implemented entropic intothepopulargreyboxfuzzer libfuzzer .
our experiments with more than open source programs millionloc demonstrate asubstantiallyimproved efficiencyand confirmour hypothesis that an efficient fuzzer maximizes information.entropic hasbeenindependentlyevaluatedandinvited forintegrationintomain line libfuzzer .entropic nowrunson more than machines fuzzing hundreds of security critical software systemssimultaneouslyandcontinuously.
ccs concepts software andits engineering software testing .
keywords software testing fuzzing efficiency information theory entropy acmreference format marcelb hme valentinj.m.man s andsangkilcha.
.boostingfuzzer efficiency an information theoretic perspective.
in proceedings of the 28th acm joint european software engineering conference and symposium on the foundations of software engineering esec fse november 8 virtual event usa.
acm new york ny usa 12pages.https permissionto make digitalor hard copies of allorpart ofthis work for personalor classroom use is granted without fee provided that copies are not made or distributed forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation onthefirstpage.copyrights forcomponentsofthisworkownedbyothersthanthe author s mustbehonored.abstractingwithcreditispermitted.tocopyotherwise or republish topostonserversortoredistributetolists requirespriorspecificpermission and or a fee.
request permissions from permissions acm.org.
esec fse november 8 13 virtual event usa copyright heldby the owner author s .
publicationrightslicensed to acm.
acm isbn ... .
introduction duetoitsefficiency fuzzinghasbecomeoneofthemostsuccessful vulnerability discovery techniques.
for instance in the three years since its launch the clusterfuzz project alone has found about 000bugsinthechromebrowserandabout11 000bugsinover open source projects only by fuzzing .
a fuzzer typically generates random inputs for the program and reports those inputs that crash the program.
but what isfuzzerefficiency?
in this paper we take an information theoretic perspective and understandfuzzingasalearningprocess.1wearguethatafuzzer s efficiencyisdeterminedbytheaverage information thateachgeneratedinputrevealsabouttheprogram sbehaviors.aclassicmeasure of information is shannon s entropy .
if the fuzzer exercises mostlythesamefewprogrambehaviors thenshannon sentropy is small the information content for each input is low and the fuzzer is not efficient at discovering new behaviors.
if however most fuzzer generated inputs exercise previously unseen program behaviors then shannon s entropy is high and the fuzzer performs muchbetterat discoveringnewbehaviors.
weleveragethisinsighttodevelopthefirstentropy basedpower schedule for greybox fuzzing.
entropic assigns more energy to seeds revealing more information about the program behaviors.
the schedule s objective is to maximize the efficiency of the fuzzer by maximizing entropy.
a greybox fuzzer generates new inputs by slightly mutating so called seed inputs.
it adds those generated inputstothecorpusofseedinputswhichincreasecodecoverage.
theenergyof a seed determines the probability with which the seed is chosen.
a seed with more energy is fuzzed more often.
a powerschedule implementsapolicytoassignenergytotheseeds in the seed corpus.
ideally we want to assign most energy to those seedsthat promise to increasecoverageat amaximal rate.
weimplementedourentropy basedpowerscheduleintothepopulargreyboxfuzzer libfuzzer andcallourextension entropic .
libfuzzer isawidely usedgreyboxfuzzerthatisresponsiblefor thediscoveryofseveralthousandsecurity criticalvulnerabilities in open source programs.
our experiments with more than open sourceprograms millionloc demonstrateasubstantially improved efficiency and confirmour hypothesis that an efficient fuzzermaximizesinformation.
entropic hasbeenevaluatedindependentlybythedevelopers oflibfuzzer andwithfurtherimprovementsisnowenabledby default.
on fuzzbench entropic turnslibfuzzer from the least well performing to the best performing fuzzer.
libfuzzer powersgoogle sossfuzz andclusterfuzz aswellasmicrosoft s onefuzz fuzzing platforms.
ossfuzz alone fuzzes more than often critical open source projects on more than 000machines simultaneouslyandcontinuously.
1as in learning about the colorsin anurn full of colored balls by samplingfrom it.
esec fse november8 13 virtualevent usa marcelb hme valentin j.m.man s andsangkilcha in order to stand our information theoretic perspective on solid foundations we explore a probabilistic model of the fuzzing process.wedemonstratehowshannon sentropyquantifiestherate at which a non deterministic blackbox fuzzer discovers new behaviorsinan hypothetically infinitelylongfuzzingcampaign.simply speaking if we are interested in achieving code coverage shannon s entropy quantifies the gradient of the coverage increase.
we alsoshowhownon deterministic greybox fuzzingcan be reduced toaseriesofnon deterministicblackboxfuzzingcampaigns which allowsustoderive thelocal entropyforeach seed andthe current globalentropyforthefuzzer.toefficientlyapproximateentropy we introduce several statisticalestimators.
ourinformation theoreticmodelexplainstheperformancegains of our entropy based power schedule for greybox fuzzing.
our schedule assigns more energy to seeds that have a greater local entropy i.e.
thatpromisetorevealmoreinformation.however we alsonotethatthisinformation theoreticmodeldoesnotimmediatelyapplytodeterministicfuzzerswhichsystematicallyenumerate all inputs they can generate or whitebox fuzzers that systematically enumerate all interesting paths they can explore.
for our probabilisticmodeltoapply thefuzzershouldgenerateinputsin a random manner with replacement .
if a deterministic phase is followedbyanon deterministicphase e.g.
inthedefaultconfiguration of the afl greybox fuzzer we can compute shannon s entropy only for the non determinsticphase.
in summary our work makesthe following contributions we develop an information theoretic foundation for nondeterministicfuzzingwhichstudiestheaverageinformation eachtest reveals aboutaprogram s behaviors.
weformallylinkshannon sentropytoafuzzer sbehavior discoveryrate i.e.
weestablishefficiencyasaninformationtheoreticquantity.
weintroduceseveralpracticalestimatorsofinformationthat are useful inthe contextoffuzzing.
we present the first entropy based power schedule to boost the efficiency ofgreybox fuzzers.
weprovideanopen sourceimplementation called entropic whichwillbe linkedhere uponacceptance.
we present a substantial empirical evaluation on over widely used open sourcec c programsproducingover2 cpuyearsworthofdata.ourdataandrscriptsareavailable here .
a probabilistic frameworkfor blackboxfuzzing fuzzing is an automatic software testing technique where the test inputsaregeneratedinarandommanner.basedonthegranularity oftheruntimeinformationthatisavailabletothefuzzer wecan distinguishthreefuzzingapproaches.a blackboxfuzzer doesnot observe or react to any runtime information.
a greybox fuzzer leveragescoverageorotherfeedbackfromtheprogram sexecution to dynamically steer the fuzzer.
a whitebox fuzzer has a perfect viewof the execution of aninput.
for instance symbolic execution enumeratesinterestingprogram paths.kk k s n test inputs ns figure the expected number s n of program behaviors that a test generator discovers as the number of generated testinputs nincreases.therate n s n s n atwhich behaviorsarediscovereddecreasesovertime.function n gives the currentdiscovery rate when the n th test is generated.
in the limit the expected number of behaviors discovered approachestheasymptote s. non deterministic blackbox fuzzing lends itself to probabilisticmodelingbecauseofthesmallnumberofassumptionsabout thefuzzingprocess.unlikegreyboxfuzzing blackboxfuzzingisnot subjecttoadaptivebias.2weadopttherecentlyproposedstads probabilisticmodelfornon deterministicblackboxfuzzing each generated input can belong to one or more species.
beyond the probabilistic model stads provides biostatistical estimators e.g.
toestimate afterseveralhoursoffuzzing theprobabilityofdiscoveringanewspecies orthe total number of species.
.
softwaretestingas discoveryofspecies letpbe the program that we wish to fuzz.
we call as p sinput spacedddthesetofallinputsthat pcantakein.thefuzzingof pis astochasticprocess f xn xn ddd n n ofsampling ninputswithreplacement fromtheprogram sinput space.wecall fasfuzzingcampaign andatoolthatperforms f as anon deterministic blackbox fuzzer .
suppose we can subdivide the search space dddintosindividual subdomains di s i 1calledspecies .
an input xn fissaid to discoverspeciesdiifxn diandtheredoesnotexistapreviously sampled input xm fsuch that m nandxm di i.e.
diis sampledforthefirsttime .an input sspecies isdefinedbasedonthe dynamic program properties of the input s execution.
for instance each branch that is exercised by input xn dddcan be identified as a species.
the discovery of the new species then corresponds to an increaseinbranchcoverage.
globalspeciesdiscovery .weletpibetheprobabilitythatthe n th generatedinput xnbelongs to species di pi p 2unlike for ablackbox fuzzer foragreybox fuzzer theprobability to observecertain programbehaviors during fuzzing changes as newseedsareadded to the corpus.
679boosting fuzzer efficiency aninformationtheoreticperspective esec fse november8 13 virtualevent usa fori i sandn n n. we call pi s i 1the fuzzer sglobal species distribution .
the expected number of discoveredspecies s n can be derivedas s n s summationdisplay.
i bracketleftbig pi n bracketrightbig s s summationdisplay.
i pi n. figure 1shows an example of a species discovery curve s n i.e.
the number of species covered with ngenerated test cases.
we can showthatthenumber ofspecies sthatthefuzzerdiscovers inthe limit i.e.
the asymptotic totalnumber ofspecies isgiven as s limn s n .
thediscovery rate n i.e.
the expected number of species discovered with the n th generated test input is defined as n s n s n .
discovery rate n provides an excellent stopping rule .
one could abort fuzzing when an insufficient progressismadeforalongperiodoftime i.e.
when n for some .
.
mutation basedblackbox fuzzing weextendthestadsframeworkwithamodelformutation based fuzzing.
let cbe a set of seed inputs called the seed corpus and qtbetheprobabilitythatthefuzzerchoosestheseed t c.3for each seed t letdddtbe the set of all inputs that can be generated byapplyingtheavailablemutationoperatorsto t.themutational fuzzingof tisastochasticprocess ft braceleftbig xt n xt n dddt bracerightbignt n ofsampling ntinputswithreplacement byrandommutationofthe seedt.wecallallspeciesthatcanbefoundbyfuzzingaseed tas the species in t sneighborhood .
localspeciesdiscovery .weletpt ibetheprobabilitythatthe nthinputxtnwhichisgeneratedbymutatingtheseed t cbelongs to species di pt i p xt n di fori i sandn n n. we call pt i s i 1thelocal species distribution in the neighborhood of the seed t. for a locally unreachable speciesdj we have pt j .
note that global and local distributions bythe law oftotalexpectation are relatedas pi summationdisplay.
t cqt pt i. fori i ssuch that byequation s n s summationdisplay.
i bracketleftbigg parenleftbigg summationdisplay.
t cqt pt i parenrightbiggn bracketrightbigg .
isthespeciesdiscoverycurveforamutation basedblackboxfuzzer.
3thisprobabilityis also called the seed s energy weight orperf score afl .
.
assumptions forourprobabilisticmodelofnon deterministic mutational blackboxfuzzing werequirethatglobalandlocalspeciesdistributions areinvariant throughout the fuzzingcampaign i.e.
pi p p and pt i p xt n di p xt n di fori i sandn n n whereqtis the probability that the fuzzer chooses the seed t c wherexnandxn 1are then th and n thtestinputsthatthefuzzergenerates respectively and wherextnandxt n 1arethen thand n thtestinputsgenerated byfuzzingthe seed t respectively.
thisissatisfiedif foranyprograminput d dintheprogram s input space we have that p p i.e.
the probability to generate some input dis invariant throughout the campaign.ourmodelaccommodatesthatablackboxfuzzermay generateinputsfromanon uniformdistribution i.e.
foranytwo inputsd1 d2 d it is entirely possible that the probability that n th test inputis d1ord2differs i.e.
p nequalp .
for random testing tools and for generation or mutation based blackboxfuzzersthatgenerateinputsbysomerandomprocessitis realistictoassumethattheprobabilitytosamplefromasubdomain di ddddoesnotchangeduringthefuzzingcampaign.withoutany dynamic program feedback a non deterministic blackbox fuzzer has no reason to vary its fuzzing heuristics duringthe campaign.
a mutation basedblackboxfuzzerusuallyhasafixed sizeseedcorpus candfixed sizesetofmutation operators.
otherwise we make noassumptions aboutthenumber s relative abundance pi s i or distribution of species in the fuzzer s searchspace.specifically thereisnoassumptionthatspeciesare distributed equally.
some rare species i.e.
piis very small may well be clusteredwithin asmall regionof the inputspace.
aninformation theoretic measure offuzzer efficiency we provide an information theoretic foundation for non deterministic blackbox fuzzing.
in the context of fuzzing shannon s entropyhhas several interpretations.
it quantifies the average information a generated test input revealsabout the behaviors i.e.
species oftheprogram.alternativelywesay ageneratedtestinput reducesour uncertaintyby hinformationunits e.g.
natsorbits onaverage.entropyalsogivestheminimumnumberofinformation units needed to reliably store the entire set of behaviors the fuzzer iscapableoftesting.moreover entropyisameasureofdiversity.a low entropy means that the program does either not exhibit many behaviors or most generated inputs test the same behaviors i.e.
belong to an abundant species .
in this work we show how entropy quantifiestheefficiencyof ablackboxfuzzerintermsofthespeciesdiscoveryrate.however thereareseveralchallenges thatweneedtoaddress.first shannon s entropy is defined in the case where each input belongs to exactly one species.
how can we define an entropy when an input can belong to multiple species?
second we cannot determine all the species of pand their probabilities with regards to funless we 680esec fse november8 13 virtualevent usa marcelb hme valentin j.m.man s andsangkilcha urn1.p1 p2 h .56urn2.p1 p2 h .69urn3.p1 p2 p3 h .
figure learning colors by samplingwith replacement.
know test cases for each species beforehand.4how can we quickly compute an approximate entropy?
third we develop informationtheoretic boosting for greybox fuzzing.
yet for greybox fuzzers the probabilities pi s i 1can vary throughout the fuzzing campaign whichviolatesourassumptions sec.
.
.isthereapracticalway to enforceour assumptions for agreybox fuzzer?
.
information theoryin anutshell shannon sentropy h measurestheaverageamountofinformationineachsample xn faboutthespeciesthatcanbeobserved byexecutingtheprogram p.whenthereare sdistinctspecies the entropyhis h s summationdisplay.
i 1pilog pi .
figure2illustratestheconceptinformally.eachcolorrepresents adifferentspecies.welearnaboutthecolorsineachurnbysampling.
just how much we learn from each sampling differs from urn to urn.
for instance in urn it is three times more likely to draw a white ball than a black.
it takes more attempts to learn about black balls in urn compared to urn .
hence we expect less information about the urn s colors in a draw from urn .
in fact given the same number of colors s the entropy is maximal whenallcolorsareequiprobable p1 ... ps.amongthethree urns weexpecttogetthemaximalamountofinformationabout the urn s colors by drawing from urn .
even though there is still adominatingcolor black thereis now an additional color blue whichcan be discovered.
.
if each input belongsto multiplespecies shannon sentropyisdefinedforthemultinomialdistributionwhere eachinputbelongstoexactlyonespecies e.g.
exerciseexactlyone path .
however an input can belong to several species so that summationtext.1s i 1pi .forinstance consideringabranchin pasaspecies each input exercises multiple branches.
the top level branch is exercisedwith probabilityone.whenit ispossiblethat summationtext.1s i 1pi chaoetal.
andyooetal.
suggestto normalize theprobabilitiesandcompute h summationtext.1s i 1p ilog p i suchthat p i pi summationtext.1s j 1pj.
this normalization maintains the fundamental properties of informationbasedonwhichshannondevelopedhisformula i.e.
that information due to independent events is additive that information is a non negative quantity etc.
the normalized entropy his 4determining shannon s entropy hmay require probabilistic symbolic execution whichinvolvesconstraint solving and modelcounting .computedas h s summationdisplay.
i 1p ilog p i log parenlefttpa parenleftexa parenleftbtas summationdisplay.
j 1pj parenrighttpa parenrightexa parenrightbta summationtext.1s i 1pilog pi summationtext.1s j 1pj we refer to the appendix for the derivation of this formula.
we note that equation reduces to equation for the special case where summationtext.1s j 1pj .
we also note that the resulting quantity is technically notthe averageinformation per input.
.
the localentropyofaseed recallfrom section2.
thatwecalltheprobabilities pt i s i 1that fuzzing a seed t cgenerates an input that belongs to species di as thelocal species distribution oft.
moreover we call the set of species di pt i i s astheneighborhood oftheseed t. fromthelocalspeciesdistributionof t wecancomputethe local entropyhtoftas astraight forwardapplicationof equation12 ht log parenlefttpa parenleftexa parenleftbtas summationdisplay.
j 1pt j parenrighttpa parenrightexa parenrightbta summationtext.1s i 1pt ilog pt i summationtext.1s j 1pt j. the local entropy htoftquantifies the information that fuzzing t reveals aboutthe species in t sneighborhood.
.
information theoretic efficiencymeasure intuitively the rate at which we learn about program behaviors i.e.
the species in the program also quantifies ablackbox fuzzer s efficiency.
we formally demonstrate how shannon s entropy h characterizesthe generaldiscovery rate n as follows.
theorem1.
letshannon sentropybedefinedasinequation .
let n betheexpectednumberofnewspeciesthefuzzerdiscovers withthe n thgenerated test input then h log c summationdisplay.
n n cn characterizes the rate at which species are discovered in an infinitely long runningcampaign where c summationtext.1s j 1pjisanormalizingconstant.
proof.we refer to the appendix for the proof.
according to theorem entropy measures the species discovery rate n overaninfinitelylong runningfuzzingcampaign where discoveryisgraduallydiscountedasthenumberofexecutedtests ngoes to infinity.
in figure notice that n foralln .
if we simply took the sum of n over alln we would compute the total number of species s summationtext.
n n .
however sprovides no insight on the efficiency of the discovery process.
instead the diminishing factor nin equation reduces the contribution of species discovery as testing effort nincreases.
the number of speciesdiscoveredatthe beginning ofthecampaignhasahigher contributionto hthenthenumberofspeciesdiscoveredlater.in otherwords ashorter ramp up time yieldsahigher entropy.
.
maximumlikelihoodestimator weestimateshannon sentropy hbasedonhowoftenwehaveseen each observed species.
the incidence frequency yifor species diis the number of generated test inputs that belong to di.
undetected 681boosting fuzzer efficiency aninformationtheoreticperspective esec fse november8 13 virtualevent usa speciesyield yi .anunbiasedestimatorofthelocaldiscovery probability piis pi yi n wherenisthetotalnumberofgenerated test inputs.
by plugging piinto equation we can estimate the entropyhusingmaximum likelihood estimation .
in our model the estimatedentropy hmleofhis hmle log parenlefttpa parenleftexa parenleftbtas summationdisplay.
j 1yj parenrighttpa parenrightexa parenrightbta summationtext.1s i 1yilog yi summationtext.1s j 1yj where we assumethat summationtext.1s j 1yj .
.
tackling adaptivebiaswhen estimating theglobalentropyofagreybox fuzzer we introduced our probabilistic model for non deterministic blackbox fuzzing which satisfies the assumption that the global species distribution pi s i 1is invariantduring the campaign section .
.
however thisassumptiondoes notholdforgreyboxfuzzingwhich leveragesprogramfeedback.generatedinputsthathavediscovered new species i.e.
increased coverage are added to the corpus.
the availabilityofadded seedschanges the globalspecies distribution butnotthelocaldistributionsforeachseed andthustheglobal entropy for a greybox fuzzer.
in other words a greybox fuzzer becomes more efficient over time.
global entropy .
clearly our probablistic model does not directly apply to model the efficiency of a non deterministic greybox fuzzer.
however it is still worthwhile to derive a reasonabe heuristic to estimatethe currentglobal entropy for a greybox fuzzer.
we propose to consider greybox fuzzing as a series of mutation based blackboxfuzzing campaigns f1 f2 ... fm each startingwith a fixed size corpusright after a new seed hasbeen added to the corpus.hence forgreyboxfuzzerswesuggesttoestimatetheglobal entropy onlyfrom incidence frequenciesthat have been collected since the last seedwasadded.we callthis a de biased estimator .
figure .top5shows the maximum likelihood estimate mle hmleovertimeforablackboxfuzzer.6wecanseethattheestimate approaches the true value reasonably fast from under one minute onwards the entropy appears as a straight line.
hence it is fair tosay thatamonotonic increasein entropywould demonstratea dynamicincreaseinfuzzerefficiency.
figure .bottom shows two entropy estimates over time for a greybox fuzzer the unmodified adaptively biased mle and the de biasedmle.weexpectthattheefficiencyofagreyboxfuzzer and thus the entropy increases over time.
as more seeds are added previously rare species become less rare .
indeed we observe a monotonicincrease.the maximumlikelihoodestimator mle biased is computed from unmodified incidence frequencies yiwhile thede biased estimator mle de biased is computed from incidence frequencies that are reset to zero whenever a new seed is added.consideringagreyboxfuzzingcampaignasaseriesofblackboxcampaigns resettingwillpreventanyimpactofadaptivebias onthe currententropy estimate.
infigure3.bottomweobservethatthede biasedmleapproaches thefinalentropyestimatemuchfasterthantheunmodifiedmle.it takestheunmodified adaptivelybiasedmlemorethan10hoursto 5ourexperimental setupfor figure3andfigure4is discussed in section5.
.
.
6libfuzzer withoutthe ability to addgenerated inputsto the corpus.
.
.
.
.
.
time in min efficiency estimateestimate blackbox mle .
.
.
.
.
.
.
.
time in h efficiency estimateestimate greybox mle biased greybox mle de biased figure entropy estimates of a blackbox fuzzer s entropy top andagreyboxfuzzer sentropy bottom overtime.for eachspecies di wecountthenumberofgeneratedinputs yi belonging to diand in regular intervals compute hmleper eqn.
.forthede biasedestimator bottom weresetthe incidencefrequencies yi 0wheneveranew seed is added.
generate the same entropy estimate that the de biased mle generatesinanhour.thedrawbackofresettingtheincidencefrequencies tozeroiscompensatedbyarelativeincreaseinthequalityofthe collecteddata.
localentropy .unlikeafuzzer sglobalentropy aseed slocal entropyis notsubjecttoadaptivebias.givenseed t letmbethe greybox fuzzer s mutation operators ltbe the set of locations intwhere a mutation operator can be applied.
without loss of generality suppose the fuzzer generates an input t only when applyingthe operator m mto location l lt.7then p xt n t p at n m p bt n l and p xt n t p xt n t wherextnis then th input that is generated from tby fuzzing t xt n 1isthe n thinputgeneratedfrom tbyfuzzing t atnandbtn are the mutation operator and mutation location in t respectively andboth are chosenat random when generatinginput xtn.
hence a seed s local entropy within a greybox fuzzer is unbiased .
thelocaldistribution pt i s i 1isinvariantthroughoutthecampaign.
the probability pt ito generate an input that belongs to species di byfuzzingseed tisthe same every time tischosenfor fuzzing.
information theoretic boosting wepresentanentropy basedboostingstrategyforgreyboxfuzzing thatmaximizestheinformationeachgeneratedinputrevealsabout the species i.e.
behaviors in a program.
our technique entropic 7theapplicationofamutationoperatortoamutationlocationismerelyanabstraction.
concretely it means to randomly choose from a large but fixed set of possible modifications tot.
for instance the application of multiple concrete mutation operators can still beconsidered as the applicationof one abstractoperator.
682esec fse november8 13 virtualevent usa marcelb hme valentin j.m.man s andsangkilcha algorithm1 entropic algorithm.
input program p initialseedcorpus c while timeout do forallt c.assignenergy t power schedule total summationtext.
t ct.energy normalizing constant forallt c.t.energy t.energy total normalized energy t sampletfromcwithprobability t.energy t mutate t fuzzing ifp t crashesthen return crashing seed t else ifp t increasescoverage thenaddt toc for allcoveredelements i pexercisedby t do yt i yt i local incidencefreq.
end for end while returnaugmentedseedcorpus c isimplementedintothepopulargreyboxfuzzer libfuzzer which isresponsibleforatleast12 000bugsreportedinsecurity critical open sourceprojectsandover16 000bugsreportedinawidely used browser.
after a successful independent evaluation of entropic by the company that develops libfuzzer our tool entropic is currentlythesubjectofpubliccodereview8tobeintegratedinto main line libfuzzer .
.
overviewof entropic agreyboxfuzzer startswithacorpusofseedinputsandcontinuouslyfuzzesthesebyapplyingrandommutations.generatedinputs thatincreasecoverageareaddedtothecorpus.theprobability i.e.
frequency with which a seed is chosen for fuzzing is called the seed senergy.
the procedure that assigns energy to a seed is called the fuzzer s power schedule .
for instance libfuzzer s standard schedule assigns more energy to seeds that were found later in the fuzzingcampaign.
itisthis power schedulethat we modify.
algorithm 1shows how greybox fuzzing is implemented in libfuzzer our changes for entropic are shown as green boxes.
in a continuous loop the fuzzer samples a seed t cfrom a distributionthatisgivenbytheseeds normalizedenergy.thisenergy is computed using assignenergy which implements one of our information theoretic power schedules.
the seed tis then mutated using random bit flips and other mutation operators to generate aninputt .
iftheexecutioncrashesorviolates thefuzzersecurity policy enactedbylimitsonexecutiontime memoryusage orsanitizers t is returned as crashing input and libfuzzer stops.
if the execution increases coverage t is added to the corpus.
we call the number of inputs generated by fuzzinga seed t cand that belong to species diaslocal incidencefrequency yt i. .
entropy basedpowerschedule ourentropy basedscheduleassignsmoreenergytoseedsthatelicit more information about the program s species.
in other words the fuzzerspendsmoretimefuzzingseedsthatleadtomoreefficient 8recallthattheesec fsechairsadvisedustoblindthenameofourtool thename ofthebaselinetool andthenameofthecompanythatisdeveloping libfuzzer .to understandourchoiceofbaselinesintheexperiments weshouldalsomentionthat entropic isnotdeveloped orbuiltontopof the popular aflgreyboxfuzzer.
.
.
.
time in h estimator biasestimator entropy lap entropy mle figure mean estimator bias over time.
we monitored estimates for the same seed tover 6h across runs.
estimatorbiasisthedifferencebetweenthemeanestimateandthe truevalue htdividedbythetruevalue ht wherehtistheaverage ofbothmean estimates at hours into the campaign.
discovery of new behaviors.
the amount of information about the species in the neighborhood of a seed tthat we expect for each generated test input is measured using the seed s local entropy ht.
the entropy based power schedule is inspired by active slam a problem in robot mapping an autonomous robot is placed in an unknown terrain the objective is to learn the map of the terrain as quickly as possible.
general approaches approximate shannon s entropy of the map under hypothetical actions .
the next move is chosen such that thereduction inuncertainty is maximized.similarly ourschedulechoosesthenextseedsuchthat the information aboutthe program s species ismaximized.
.
.
improved estimator.
during our experiments we quickly noticedthatthemaximumlikelihoodestimator hmleinequation15 cannotbeused.anewseed tthathasneverbeenfuzzedwillalways beassignedzeroenergy ht mle .hence itwouldneverbechosen for fuzzing and forever remain with zero energy.
we experimented withascreeningphasetocomputearoughestimate.eachnewseed was first fuzzed for a fixed number of times.
however we found that too much energy was wasted gaining statistical power that could have otherwisebeen spentdiscoveringmore species.
to overcome this challenge we took a bayesian approach.
we knowthatentropyismaximalwhenallprobabilitiesareequal.fora new seed t we assume an uninformative prior for the probabilities pt i i.e.
pt ... pt s wherept iis the probability that fuzzing t generates an input that belongs to species di.
with each input thatisgeneratedbyfuzzing t theprobabilitiesareincrementally updated.
the posterior is a beta distribution over pt i. the estimate pt iofpt iis thus the mean of this beta distribution which is also knownas the laplace estimator oradd one smoothing pt i yt i s summationtext.1s j 1yt j wheres s n isthe number of globallydiscoveredspecies.
thus we define the improved entropy estimator ht lap lap as ht lap log parenlefttpa parenleftexa parenleftbtas s summationdisplay.
j 1yj parenrighttpa parenrightexa parenrightbta summationtext.1s i yi log yi s summationtext.1s j 1yj 683boosting fuzzer efficiency aninformationtheoreticperspective esec fse november8 13 virtualevent usa figure 4illustrates the main idea.
both estimators are nearly unbiased from two hours onwards.
in other words they are within fromthetruevalue i.e.
ht x ht .9inthebeginning the mleisnegativelybiasedandapproachesthetruevaluefrombelow whilethelapispositivelybiasedandapproachesthetruevalue fromabove.bothestimatorsrobustlyestimatethesamequantity but only lap assigns high energy when seed thas not been fuzzed enough for an accurateestimateofthe seedsinformation ht.
.
.
measuring information only about rare species.
during our initial experiments we also noticed that the entropy estimates for different seeds were almost the same.
we found that the reason is a small number of very abundant species which have a huge impactontheentropyestimate.there aresomeabundantspeciesto which each and every generated input belongs.
hence we defined aglobalabundancethreshold andonlymaintainlocalincidence frequencies yt iofglobally rare species dithat have a global incidencefrequency yi .insection5 wereportonthesensitivity ofthe boostingtechniqueonthe abundance threshold .
experimentalevaluation .
research questions our main hypothesis is that increasing information per generated input increases fuzzer efficiency.
to evaluate our hypothesis we implemented entropic andask the following researchquestions.
rq.1whatistheempiricalcoverageimprovementoverthebaseline?
rq.2how much fasterarebugsdetected compared to thebaseline?
rq.3how does the choice of abundance threshold influence the performance ofour technique?
rq.4whatis thecost ofmaintainingincidencefrequencies?
.
setup andinfrastructure .
.
implementation and baseline.
we implemented our entropybased power schedule into libfuzzer lines of change and call our extension as entropic .libfuzzer is a state of the art vulnerabilitydiscoverytooldevelopedat whichhasfoundalmost 30kbugsinhundredsofclosed andopen sourceprojects.
asacoverage basedgreyboxfuzzer seealg.
libfuzzer seeks tomaximizecodecoverage.hence our speciesisacoverageelement called feature.
a featureis a combination of branch covered and hitcount.forinstance twoinputs exercisingthesamebranches have a different feature set if one exercises a branch more often.
hence feature coverage subsumes branch coverage .
in contrast to libfuzzer entropic also maintains the local and global incidence frequencies for each feature.
we study the performance hit in rq4.
libfuzzer s original power schedule assigns more energy to seedsthathavebeenaddedlaterinthefuzzingcampaign.
entropic implementsourentropy basedpowerschedule sec.
.
whichis parameterized by the abundance threshold .
we investigate the impact ofthe choiceof inrq3.
ourextension entropic hasbeenindependentlyevaluatedby the company that is developing libfuzzer and was found to improve onlibfuzzer withstatisticalsignificance.
entropic wasinvited for integrationintothemain line libfuzzer andiscurrentlysubjectto 9in contrast to global entropy h local entropy htisnotsubject to any adaptive bias seesection3.
.publiccodereview.onceintegrated entropic ispoisedtorunonmore than25 000machinesfuzzing hundredsofsecurity criticalsoftware systems simultaneouslyand continuously.
.
.
benchmarksubjects.
wecompare entropic withlibfuzzer on2benchmarkscontaining250 open sourceprogramsusedin many different domains including browsers.
we conducted almost 000one hourfuzzingcampaignsand2 000six hourcampaignsto generatealmosttwocpuyears worth of data.
fts programs .2m loc hour repetitions is a standardsetofreal worldprogramstoevaluatefuzzerperformance.the subjects are widely used implementations of file parsers protocols and data bases e.g.
libpng openssl and sqlite amongst others.
eachsubjectcontainsatleastoneknownvulnerability cve some of which require weeks to be found.
the fuzzer test suite fts allows to compare the coverage achieved as well as the time to findthefirstcrashontheprovidedsubjects.thereareoriginally subjects but we removed those programs where more than of runscrash leaving12programswith1.2m loc .as libfuzzer aborts when the first crash is found the coverage results for those subjectswouldbeunreliable.we seta8gbmemorylimitandran libfuzzer for1hour.togainstatisticalpower werepeatedeach experiment times.this required40 cpudays.
oss fuzz 263programs .3mloc 6hours 4repetitions is an open source fuzzing platform developed by google for the large scale continuous fuzzing of security critical software.
at the time of writing oss fuzz featured executable programs in 176open sourceprojects.weselected263programstotaling58.
millionlinesofcodebychoosingsubjectsthatdidnotcrashorreach the saturation point in the first few minutes and that generated morethan1 000executionspersecond.evenforthechosensubjects we noticed that the initial seed corpora provided by the project areoftenforsaturation featurediscoveryhaseffectivelystopped shortly after the beginning of the campaign.
it does not give much room for further discovery.
hence we removed all initial seed corporas.weran libfuzzer forallprogramsfor6hoursand given the large number of subjects repeated each experiment times.
this requiredatotalof526cpudays.
.
.
computationalresources.
allexperimentsfor ftswereconducted on a machine with intel r xeon r platinum .10ghz cpus with cores and 126gb of main memory.
all experiments foross fuzzwereconductedonamachinewithintel r xeon r cpue5 2699v42.20ghzwithatotalof88coresand504gbofmain memory.
to ensure a fair comparison we always ran all schedules simultaneously same workload each schedule was bound to one hyperthread core and of cores were left unused to avoid interference.
in total our experiments took more than cpu years whichamountsto more than2weeksof wall clocktime.
.
.
setupforfigures 3and4.throughoutthepaper wereported ontheresultsofsmallexperiments.inallcaseswhennototherwise specified we used libfuzzer with the original power schedule to fuzz the libpng project from the fuzzer test suite fts started withasingle seedinput.
for figure we conducted10 runs of20 hours using libfuzzer both as blackbox and as greybox fuzzer.
in blackbox mode no seeds are added to the corpus.
for figure we conducted20runsof6hours andmonitoredthe singleseedinput 684esec fse november8 13 virtualevent usa marcelb hme valentin j.m.man s andsangkilcha entropy .
entropy .
entropy .
entropy .
entropy .
entropy .
entropy .
entropy .
entropy .
entropy .
entropy .
entropy .
sqlite vorbis wpantund openssl .
.0c x509 openthread ip6 openthread radio lcms libjpeg turbo libpng .
.
freetype2 guetzli harfbuzz .
.
time in minutes number of featuresschedule original entropy figure mean coverage in a minute fuzzing campaign 12subjects 2schedules 40runs 1hour 40cpudays .
thedashed verticallinesshowwhen entropic achievesthe samecoverageas libfuzzer in1hour.thevaluesatthebottomrightgive thevargha delaney effectsize a12.
that we started libfuzzer with.
we printed all four estimates in regularintervals.
rq1.1codecoverage on fts empiricalresults confirmourhypothesisthatincreasingthe average informationeachgeneratedinputrevealsabouttheprogram sspecies increases therate at whichnewspeciesare discovered.
bychoosing theseed that revealsmoreinformation efficiencyis improved.
figure 5shows the mean coverage over time and the varghadelaney effect size a12.
values above .
.
.
indicate a small medium and large effect size respectively.
more intuitively the values indicate how much more likely it is for an entropicrun to cover more features than a libfuzzer run or less likely if under .
.
values in stars a12 indicate statistical significance wilcoxon rank sum test p .
.
for instance for vorbis entropic with our entropy based schedule covers about features in under minutes while libfuzzer withthe originalschedule takes one hour.
subjects in a meancoverageincrease .
forx of subjects entropic achievesat least y morecoveragethan libfuzzer .
number of subjects subjects in time in hours b time to coverage .
forx of subjects entropic achievesthe same coveragein yhours that libfuzzer achievesin hours solid line .
.
.
.
time in min proportion of wins c entropic getsbetteratachieving coverage .
afterxseconds of fuzzing entropic achievesmorecoveragethan libfuzzer fory of the 263subjects.
figure oss fuzz coverage results subjects schedules runs hours .
cpu years .
entropic substantiallyoutperforms libfuzzer withintheonehour time budget for of subjects.
for two out of three cases wherethe a12effectsizeisconsideredmedium themeandifference in feature coverage issubstantial and increasefor libpng andopenssl .
.0c resp.
.inalmostallcases entropic ismorethan twice as fast 2x as libfuzzer .
the same coverage that libfuzzer achievesinonehour entropic canachieveinlessthan30minutes.
alldifferencesarestatisticallysignificant.thecoveragetrajectories seemtoindicatethatthe benefit ofour entropyschedulebecomes evenmorepronouncedforlongercampaigns.weincreasecampaign length to hfor our experiments withoss fuzz rq2 .
rq1.2large scalevalidationon oss fuzz results for 263open source c c projects validate our empirical findings.entropic generallyachievesmorecoveragethan libfuzzer .
thecoverageincreaseislargerthan10 foraquarterofprograms.
entropicis more than twice as fast as libfuzzer for half the programs.
theefficiencyboost increases withthe length ofthe campaign.
figure6.
a showsthemeancoverageincreaseof entropic over libfuzzer on a logarithmic scale over all263 subjects.
the dashed 685boosting fuzzer efficiency aninformationtheoreticperspective esec fse november8 13 virtualevent usa .
.
.
.
.
percentage of runstime to error in h figure oss fuzz crash time to error results .
cpu years .x of runs crashed in yhours or less.
entropic dashed and libfuzzer solid .lowerisbetter.
line represents the coverage increase of libfuzzer overentropic for the cases when libfuzzer achieves more coverage.
we can see thatentropic achieves more coverage than libfuzzer after six hoursoffuzzingforabout77 ofsubjects.
entropic coversatleast more features than libfuzzer for about of subjects.
we investigatedmore closelythe of thesubjects where entropic achieveslesscoverage.first forhalfofthem thecoveragedifferencewasmarginal lessthan2 .second thesesubjectsweremuch larger twicethenumberofbranchesonaverage .aswewillseein rq4thattheperformanceoverheadincurredby entropic grows linearlywiththe number ofbranches.
figure6.
b showshowmuchfaster entropic isinachievingthe coveragethat libfuzzer achievesinsixhours.again thedashed line shows the inverse when libfuzzer achieves more coverage at the six hour mark.
we can see that entropic achieves the same coveragetwiceasfastforabout50 ofsubjectsandfourtimesas fastfor25 ofsubjects.morespecifically entropic achievesthe samecoveragein1.5h as libfuzzer achievesin6h for 66subjects.
figure6.
c showstheproportionofsubjectswhere entropic achieves more coverage than libfuzzer i.e.
wins over time.
both fuzzersbreakevenatabout10minutes.after30minutes entropic alreadywinsfor64 ofsubjects untilat6hours entropic wins for about of subjects.
we interpret this result as entropic becoming more effective at boosting libfuzzer as saturation is being approached.
in the beginning of the campaign almost every newinputleadstospeciesdiscovery.laterinthefuzzingcampaign itbecomesmoreimportanttochoosehigh entropicseeds.moreover estimator biasisreducedwhen more inputshave been generated.
rq2.
crash detection in our experimentswith oss fuzz entropic foundmost crashes faster than libfuzzer .
some of these crashes were found only by entropic .
these crashes are potential zero day vulnerabilities in widely used security critical open sourcelibraries.
figure7showsthetimeittakestofindeachcrashasanaggregate statistic in ascending order over all crashes that have been discoveredinanyofthefourrunsofallsubjectsforbothfuzzers.
for instance for .
of 4runs entropic finds a crash in .
hoursorlesswhile libfuzzer takes2hoursorless.thecrashesare real and potentially exploitable.
all subjects are security criticaloriginal entropy schedule max.
abundance 0x100 0x1000 0x10000 a12 a12 a12 freetype2 .
.
.
.
.
.
.
guetzli .
.
.
.
.
.
.
harfbuzz .
.
.
.
.
.
.
.
.
lcms .
.
.
.
.
.
.
libjpeg turbo .
.
.
.
.
.
.
libpng .
.
.
.
.
.
.
.
.
openssl .
.0c x509 .
.
.
.
.
.
.
ot ip6 .
.
.
.
.
.
.
ot radio .
.
.
.
.
.
.
sqlite .
.
.
.
.
.
.
vorbis .
.
.
.
.
.
.
wpantund .
.
.
.
.
.
.
figure sensitivity to abundance threshold which constitutes rare feature subjects x abundance thresholds x runs x 1h each cpu days .
showing mean coverage and vargha delaney effect size a12 .
bold values indicate statistical significance.
and widely used.
google maintains a responsible disclosure policy forbugsfoundbyoss fuzz.thisgivesmaintainerssometimeto patchthecrashbeforethebugreportismadepublic.threebugs are discoveredonly by entropic .
rq3.
sensitivityanalysis overall entropic performs best for an abundance threshold of i.e.
0x1000 for the fts subjects.
weanalyzethesensitivityoffuzzerperformanceontheabundance threshold .
the abundance threshold specifies an upper limit on the global incidence frequencies yibelow which a species isconsideredas rare .onlyincidencefrequenciesofrarespecies areusedwhencomputingaseed senergy see section4 .thisovercomes the challenge of overly abundant species dominating the energy values a challenge we observed in our initialexperiments.
in order to study the behavior of entropic schedules we vary the abundance threshold on a logarithmic scale.
to gain statistical power allexperiments of one hour are repeated40 times.
figure 8shows the mean coverage for libfuzzer original and entropic aswellasthevargha delaneyeffectsize.thevaluesin boldindicatestatisticalsignificanceoftheobserveddifference.a closerlookatthetablerevealsthatoftenthebestperformingthresholdvalueappearstobesubject specific.thisopenstheopportunity for researchonhyper parameter tuning.
rq4.
performance overhead thereisa2 medianoverheadacrossthe12ftssubjectsformaintaining incidence frequencies when compared to the entire fuzzing process.
thereis a12 medianoverhead when compared to the time spentonly in thefuzzer and not in the subject .
figure9showstheproportionofthetimethat entropic spends in the different phases of the fuzzing process.
in all cases the most time is spent executing the subject bright gray .
entropic executesthesubjectbetween10 000and100 000timespersecond.the remainder of the time is spent in the fuzzer where the darker gray barsrepresent functionsthat libfuzzer normallyperformswhile the blackbars represent the overheadbrought by entropic .
686esec fse november8 13 virtualevent usa marcelb hme valentin j.m.man s andsangkilcha .
.
.
.
.
subjectsproportion of execution frequency updates fuzzer maintenance subject execution figure entropic instrumentation overhead.
themaintenanceofincidencefrequenciestakesmoretimeaway fromthefuzzingprocessthanweexpected giventhesubstantial performance gains discussed in rq1 and rq2.
note that entropic outperforms libfuzzer despitethis additional overhead.
entropic is a prototype.
we are confident that there are plenty of opportunities to reduce this overhead to further boost entropic s efficiency.
threats to validity like for any empirical study there are threats to the validity of our results.weadoptedseveralstrategiestoincrease internalvalidity .
in order to put no fuzzer at a disadvantage we used default configurations provided the exact same starting condition and executed each technique several times and under the same workload.
the timewhenthefuzzercrashesidentifiesunambiguouslywhenabug is found.
to define species in our experiments we use the natural measure of progress for libfuzzer and its extension entropic .
to mitigatethreatsto constructvalidity suchasbugsin entropic or observedperformancedifferencesthat are notdueto ourdiscussed improvements weextendedthebaseline libfuzzer usingareadily comprehensible lines of code.
we adopted several strategies to increaseexternal validity .
we repeated all experiments from which wederiveempiricalstatements rq1 rq2 rq4 atleast40times.
toincreasethegeneralityofourresults weconductedexperiments onoss fuzztotaling 263c c programs and58.
millionloc.
for a sound statistical analysis we followed the recommendations of arcuri et al.
and klees et al.
to the extent to which our computationalresourcespermitted.
related work webeginwithanoverviewofexistingapproachestoincreasethe efficiencyofgreyboxfuzzing andcontinuewithearlierapplications ofinformation theory to software testinganddebugging.
fuzzing has recently gained substantial academic interest 32 36 .werefertoarecentsurvey foracomprehensiveoverview.wooetal.
modelblackboxfuzzingasa multi armedbanditproblem wherethefuzzerassignsmoreenergy toseedsthathavepreviouslybeenobservedtocrash.perffuzz assigns more energy to seeds that maximize execution counts to discover algorithmiccomplexityvulnerabilities.fairfuzz and aflfast aregreyboxfuzzersthatassignmoreenergytoseeds thatexerciselow probabilitypathsorbranchestodiscovermore low probabilitypathsorbranches.incontrast entropic computes theenergyofaseed tbasedonthediscoveryprobabilitiesofspecies in theneighborhood oftrather than of t s species itself.
moreover entropic ismotivatedbyourkeyinsightthatmaximizing informationeachinputrevealsaboutaprogram sbehaviorsincreases the fuzzer s efficiency.
information theory has previously found application in software test selection .
givena testsuite tand theprobability p t that test caset tfails onemay seekto minimizethe numberoftest cases t tto execute while maximizing the information that executing twould reveal about the program s correctness.
yang et al.
give several strategies to selecta test case t t orasize limited setoftestcases t t suchthat ifweweretoexecute t ort theuncertaintyabouttestcasefailure i.e.
entropy is minimized .
unlikeourmodel themodelofyangetal.requirestospecifyfor each input the expected output as well as the probability of failure i.e.
theobservednotmatchingtheexpectedoutput .hence yang s modelispracticalonlyinthecontextoftestselection butnotin the context of automated test generation.
similarly feldt et al.
proposeaninformation theoreticapproachtomeasurethedistance between test cases based on kolmogorov complexity and uses it to maximize diversity of selected tests.
although their idea is complementarytoours itiscomputationallytooexpensivetobe directlyappliedtotestgeneration.finally byconsideringfuzzingas arandomprocessinamulti dimensionalspace ankou enables the detection ofdifferent combination infuzzers fitness function.
informationtheoryhasalsofoundapplication in softwarefault localization .givenafailingtestsuitet supposewewanttolocalize thefaultystatementasquicklyaspossible.yoo harmann andclark discussanapproachtoexecutetestcasesintheorderofhow much information they reveal about the fault location.
specifically testcases whichmostreducetheuncertaintythatastatement is thefaultlocation willbeexecutedfirst.camposetal.
propose a search based test generation technique with a fitness function thatmaximizestheinformationaboutthefaultlocation.incontrast our objective is to quantify and maximize the efficiency of the testgenerationprocessin learningabouttheprogram sbehaviors includingwhether ornot itcontains faults .
bugfindingefficiencyandscalabilityareimportantpropertiesof a fuzzingcampaign.
b hmeand paul conducteda probabilistic analysis of the efficiency of blackbox versus whitebox fuzzing and provide concrete bounds on the time a whitebox fuzzer can take per test input in order to remain more efficient than a blackbox fuzzer.b hmeandfalk empiricallyinvestigatethescalability ofnon deterministicblack andgreyboxfuzzingandpostulatean exponential cost of vulnerability discovery.
specifically they make the followingcounter intuitive observation findingthe samebugs linearlyfasterrequireslinearlymoremachines.yet findinglinearly more bugs in the same time requires exponentially more machines.
alshahwanandharman introducedtheconceptof output uniqueness as blackbox coveragecriterion whereonetestsuiteis consideredasmoreeffectivethananotherifitelicitsalargernumber of unique program outputs.
this blackbox criterion turns out to be similarlyeffectiveaswhiteboxcriteria suchascodecoverage in assessingtestsuiteeffectiveness.inourconceptualframework a unique output might beconsidered as a species.
entropy could be used as blackbox measure of the efficiency of discovering different unqiue outputs duringtesting.
687boosting fuzzer efficiency aninformationtheoreticperspective esec fse november8 13 virtualevent usa conclusion in this paper we presented entropic the first greybox fuzzer that leveragesshannon sentropyforschedulingseeds.thekeyintuition behind our approach is to prefer seeds that reveal more informationabouttheprogramundertest.ourextensiveempiricalstudy confirms that our information theoreticapproach indeedhelpsin boosting fuzzing performance in termsof bothcode coverageand bugfindingability.
information theory .
we formally link entropy as measure ofinformation tofuzzerefficiency developestimatorsandboosting techniques for greybox fuzzing that maximize information and empirically investigate the resulting improvement of fuzzer efficiency.
we extend the stads statistical framework to incorporatemutation basedblackboxfuzzingwhereanewinputis generatedbymodifyingaseedinput.wehopethatourinformationtheoretic perspective provides a general framework to think about efficiency in software testing irrespective of the chosen measure of effectiveness i.e.
independent ofthe coveragecriterion .
practical impact .ourimplementationof entropic hasbeen incorporated intolibfuzzer one of the most popular industrial fuzzers.atthetimeofwriting entropic wasenabledfor50 of fuzzingcampaignsthat arerunonmore than25 000machinesfor findingbugsandsecurityvulnerabilitiesinover350open source projects including google chrome.
after several additional improvements rapidly facilitated by the fuzzbench team entropic nowoutperforms all other fuzzers available on fuzzbench google s fuzzer benchmarking platform.
this result highlights the practical impact ofour approach.
open science and reproducibility .
the practical impact of entropic is a testament to the effectiveness of open science open source and open discourse.
there is a growing number of authors thatpubliclyreleasetheirtoolsandartifacts.conferencesareadoptingartifactevaluationcommitteestosupportreproducibility but asalways more can be done to accommodatereproducibility as first class citizens into our peer reviewing process.
we strongly believethat openness isareasonablepathwaytofosterrapidand soundadvancesinthefieldandtoenableameaningfulengagement between industry andacademia.
we make our scripts and experimental data publicly available at weprovidedetailedinstructionstoreproduceourresultsat ourresultsfor entropic havebeenindependentlyreproduced at .