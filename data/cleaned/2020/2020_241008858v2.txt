decoding secret memorization in code llms through token level characterization yuqing nie beijing university of posts and telecommunications beijing china jiangsha bupt.edu.cn guoai xu harbin institute of technology shenzhen china xga hit.edu.cnchong wang nanyang technological university singapore singapore chong.wang ntu.edu.sg guosheng xu beijing university of posts and telecommunications beijing china guoshengxu bupt.edu.cnkailong wang huazhong university of science and technology wuhan china wangkl hust.edu.cn haoyu wang huazhong university of science and technology wuhan china haoyuwang hust.edu.cn abstract code large language models llms have demonstrated remarkable capabilities in generating understanding and manipulating programming code.
however their training process inadvertently leads to the memorization of sensitive information posing severe privacy risks.
existing studies on memorization in llms primarily rely on prompt engineering techniques which suffer from limitations such as widespread hallucination and inefficient extraction of the target sensitive information.
in this paper we present a novel approach to characterize real and fake secrets generated by code llms based on token probabilities.
we identify four key characteristics that differentiate genuine secrets from hallucinated ones providing insights into distinguishing real and fake secrets.
to overcome the limitations of existing works we propose d esec a two stage method that leverages token level features derived from the identified characteristics to guide the token decoding process.
d esecconsists of constructing an offline token scoring model using a proxy code llm and employing the scoring model to guide the decoding process by reassigning token likelihoods.
through extensive experiments on four state of the art code llms using a diverse dataset we demonstrate the superior performance of d esecin achieving a higher plausible rate and extracting more real secrets compared to existing baselines.
our findings highlight the effectiveness of our token level approach in enabling an extensive assessment of the privacy leakage risks associated with code llms.
i. i ntroduction large language models llms have revolutionized the field of natural language processing enabling groundbreaking advancements in various domains.
a notable sub domain of llms is code llms which specialize in generating understanding and manipulating programming code.
code llms have found extensive applications in code completion code generation bug fixing and code summarization demonstrating their significant impact on software development practices and productivity .
despite the remarkable capabilities of llms they raise a significant privacy concern.
specifically llms are trained on vast amounts of data sourced from a wide range of locations including public repositories forums and websites.
this comprehensive training process inadvertently leads to the memorization of sensitive and private these authors contributed equally to this work co first authors .
corresponding author.information present in the training data .
consequently code llms become prone to leaking sensitive and critical information e.g.
user credentials and secrets during the code generation process posing severe privacy risks and breaches.
existing studies on memorization in llms have primarily employed prompt engineering techniques to elicit the memorized information from the models .
while these approaches have provided valuable insights they suffer from two main limitations.
first forcing or eliciting the llm to output secret information might lead to widespread hallucination where the llm generates false secrets resulting in a high number of false positives.
this can significantly hinder the accurate assessment of the true extent of memorization and privacy leakage risks.
second the prompt engineering based approaches generat output randomly which can be inefficient in extracting the target sensitive information memorized by llms.
this randomness may lead to repeated extraction of similar secrets across multiple queries while missing other unique secrets potentially underestimating the true extent and variety of sensitive information memorized by llms and hindering an effective assessment of the associated privacy risks.
to fully grasp the intricacies of memorization in llms and overcome these limitations it is imperative to delve deeper into the internal workings of these models and examine the issue at a more granular level.
our work.
in this paper we present a novel approach to characterize real and fake secrets generated by code llms based on token probabilities.
through extensive observation and analysis we have identified several key characteristics that distinguish genuine secrets from hallucinated ones such as the stabilization of real secret tokens at high probabilities c1 higher overall probabilities of real secret tokens compared to fake ones c2 more pronounced probability advantages of real secret tokens c3 and the ability to identify certain fake secrets early in the decoding process using secret strength metrics like shannon entropy c4 .
while we illustrate these characteristics using google api keys it is important to note that they are generalizable to various types of secrets.
to overcome the aforementioned limitations from existingarxiv .08858v2 apr 2025works in the literature we propose a method named d esec that leverages token level features derived from the identified characteristics to guide the token decoding process.
d esec consists of two stages offline token scoring model construction which utilizes a proxy code llm to generate training data and train a scoring model to predict the likelihood score that a token belongs to a real secret and online scoring model guided decoding which leverages the scoring model to predict a score for the tokens at each decoding step combining it with the original llm predicted probability to reassign token likelihoods and guide the selection of tokens.
through extensive experiments on five state of the art code llms stablecode codegen2.
deepseek coder codellama and starcoder2 and a diverse dataset of code files containing various types of secrets across multiple programming languages we demonstrate the superior performance of d eseccompared to existing baselines.
d esecachieves an average plausible rate pr of .
across the five code llms significantly outperforming hcr .
and bs .
.
moreover d esecsuccessfully extracts a total of real secrets from the victim models surpassing the numbers obtained by hcr real secrets and bs real secrets .
these results highlight the effectiveness of our token level approach in guiding the decoding process to generate more diverse and accurate secrets enabling a more comprehensive assessment of the privacy leakage risks associated with code llms.
contributions.
we summarize the contributions as follows identification of key characteristics distinguishing real and fake secrets.
we identify four generalizable key characteristics that differentiate genuine secrets from hallucinated ones generated by code llms based on token probabilities and secret strength metrics.
development of a token level approach for secret extraction.
we propose d esec a two stage method that constructs an offline token scoring model using a proxy code llm and employs it to guide the decoding process by reassigning token likelihoods based on token level features derived from the identified characteristics.
extensive evaluation on state of the art code llms.
we evaluate d esecon four state of the art code llms using a diverse dataset demonstrating its superior performance in achieving a higher plausible rate and extracting more real secrets compared to existing baselines.
ethical considerations.
in conducting this study we prioritized ethical considerations to ensure responsible research practices.
we strictly limited our use of the derived secrets to validating their authenticity without exploiting or misusing them in any way.
furthermore we have taken great care to mask all the information presented in this paper including any personal or sensitive data to prevent potential leakage and real damage.
by adhering to these ethical principles we aim to contribute to the understanding of memorization in code llms without causing any unintended consequences.ii.
b ackground and related work a. code llms code llms based on large language model technology and trained on vast code datasets are designed to understand and generate programming code .
they show significant potential in tasks such as code generation autocompletion and error detection .
researchers are dedicated to enhancing their capabilities leading to the emergence of various code llms including codex codeparrot codebert codegpt and codellama .
these models have become indispensable tools for software developers worldwide with applications such as google s codesearchnet using codebert for code search visual studio code integrating github copilot and codegeex as extensions and kaggle s ai code competition using codex to help beginner programmers learn to code.
b. memorization in llms llms can remember a large amount of training data during the training process.
this memorization mechanism enables the model to reproduce information from the training data when generating text.
for a large model ftrained on a dataset d given an input sequence x x1 x2 .
.
.
x n the model generates an output sequence y y1 y2 .
.
.
y m .
the parameters of the model fare denoted as .
if there exists a prompt psuch that f p s s d then the model fis said to have memorized the string s. since sstrictly exists in the training set d this phenomenon is summarized as exact matching in the study .
additionally lee et al.
defined a more lenient phenomenon called approximate matching for f p s if there exists a corresponding string sin the training set dsuch that sands are within a specified edit distance then the model fis also said to have memorized the string s. many existing works have explored memorization in llms.
feldman proposed that memorization of labels is necessary for near optimal generalization error in data following natural distributions.
studies reveal that attackers can perform training data extraction attacks by querying llms.
carlini et al.
investigated factors influencing llm memorization finding that increases in model capacity data repetition and prompt length significantly enhance memorization.
memorization also exists in code llms with studies confirming that code models can memorize their training data.
yang et al.
conducted a systematic study on memorization in code models discussing factors such as data repetition and model size.
for multimodal large language models chen et al.
developed metrics to measure data leakage during multimodal training.
the memorization in code llms leads to privacy issues such as the reproduction of sensitive information and the leakage of proprietary code.
al kaswan et al.
proposed a targeted attack to identify whether a given sample in the training data can be extracted from the model.
niu et al.
explored the impact of temperature values on the generation of private information by github copilot finding that about8 of the prompts resulted in privacy leaks.
huang et al.
proposed hcr in which copilot generated hard coded credentials and codewhisperer produced keys during code completion tasks.
yao et al.
introduced codemi a membership inference method that determines whether a given code sample is present in the training set of a target black box model by analyzing the output features of shadow models.
iii.
t oken level secret characterization we initially conduct a study to investigate the characteristics of real secrets and fake secrets generated by code llms at token level aiming to answer the research question rq1 what are the token level characteristics of secret memorization in code llms?
a. motivation while existing researches have shown that code llms can memorize secrets or privacy from training datasets the characteristics of these memorized secrets remain underexplored.
additionally given that code llms may generate fake secrets due to hallucination issues it is necessary to explore the differences between the characteristics of real and fake secrets .
to this end we conduct an in depth analysis of secret memorization in code llms at the token level.
we aim to extract the most common types of commercial secrets included in the prior study which together constitute .
of all secrets.
for ease of management these secrets follow structured formats that can be defined using regular expressions.
table i lists these types of secrets along with their corresponding regular expressions.
b. study setup we construct code completion prompts and input them into code llms to predict the missing secrets based on these prompts.
during this process we collect the predicted token probabilities at each decoding step and analyze their characteristics.
source file collection for the types of secrets we use their regular expressions to search for code files containing them from open source repositories through sourcegraph .
we choose sourcegraph for two reasons i it integrates a vast number of open source code repositories ii it supports efficient code search using regular expressions which perfectly meets our requirement for searching secrets.
in the search process we only consider languages namely html java javascript php and python which are commonly used in web applications that may require the types of secrets for online api requests.
after duplication code files are identified as of june .
to ensure data quality we apply the filtering rules adopted in the starcoder project .
files that meet the following criteria are excluded files with an average line length exceeding characters or a maximum line length exceeding characters.
files with less than alphabetic characters.
files containing the string ?xml version within the first characters.
fig.
an example of completion prompt for html files we filter out files with less than visible text or fewer than characters of visible text.
these filtering operations remove approximately .
of the files.
subsequently we perform an additional examination of the characters surrounding the matched content to filter out the mismatched code files.
for example the middle part highlighted in blue of ...kbdaiza...bvv ... matches the regular expression for google api key but the surrounding characters indicate that it is not a valid google api key.
ultimately .
of the original search results are retained resulting a set of code files.
table ii shows the language and secret distribution in the final results.
we randomly select code files for each type of secret totaling files for subsequent method evaluation section v .
the proportion of each programming language within each type of secret remains consistent with its proportion in the raw data.
as a result code files are retained for analysis in this study.
completion prompt construction from the remaining code files we randomly sample files for each type of secret to construct completion prompts.
note that the numbers of files for stsk siwu tcsi and acak are fewer than so we additionally collect files in other languages like go and c using sourcegraph to reach .
in total code files are used to construct completion prompts.
for each code file we locate the secret s position and remove all content after the fixed secret prefix e.g.
aiza for google api key .
we then retain the line containing the secret and up to preceding lines as the completion prompt which provides sufficient context without overwhelming the model based on the preliminary observations and previous study .
for example as illustrated in fig.
the fixed prefix aiza of a found google api key is retained while all subsequent content is removed.
after processing all code files we obtain completion prompts.
llm based secret generation we feed these prompts into a proxy code llm to perform the code completion and predict the missing google api keys.
in this study we select starcoder2 15b as the proxy llm which is a 15bparameter model trained on multiple programming languages from the stack v2 supporting various tasks such as code completion and code generation.
starcoder2 15b is chosen as the proxy llm because it shares the same common decoderonly architecture as the other code llms in our study.
this ensures consistency in studying secret token generation.
starcoder2 15b generates a token sequence step by steptable i target secret types and their formats secret type acronym format regular expression token constraint google api key gak aiza google oauth client id goci .apps .googleusercontent .com stripe test secret key stsk sktest slack incoming webhook url siwu https hooks.slack.com services tencent cloud secret id tcsi akid alibaba cloud access key id acak ltai table ii distribution of collected code files html java javascript php python total gak goci stsk siwu tcsi acak total based on an input prompt.
at each step it generates a token probability distribution based on the context provided by the prompt and the previously predicted tokens.
to avoid generating erroneous secrets that violate the format constraints in table i we set the probabilities of invalid tokens to .
we then apply beam search with a width of to select the next token keeping the token sequence with the highest likelihood score as the final generated secret.
the generation stops once the target secret s required length character number is reached.
during the generation process we record the predicted token probability distribution of each step for further analysis.
generated secret verification for each generated secret we validate it through a combination of online api request and github code search as follows api request we develop verification scripts that send connection requests to the relevant services using the secret and observe the returned status codes.
if the services are connected successfully the secret is real and still active.
github search if the secret cannot be validated through an api request we use github code search to search for it.
if it can be found through this search and is not merely a usage example e.g.
akidz8...example it is also considered a real memorized secret.
the verified dataset consists of secrets real and fake.
it includes real and fake secrets each for google api key stripe test secret key and tencent cloud secret id totaling plus real and fake secrets for google oauth client id due to limited availability .
slack incoming webhook urls and alibaba cloud access key ids are excluded as the model does not generate real secrets for these types.
c. characterization based on our observation and analysis of token probabilities we characterize the real and fake secrets generated by the code llm as follows.
note that these characteristics are generalizable to different types of secrets we simply use google api keys to illustrate see our replication package for stsk tcsi and goci .
fig.
token probability scatter plot for google api keys fig.
token probability advantages scatter plot for google api keys c1 tokens in real secrets tend to stabilize at relatively high probabilities after initial few decoding steps.
fig.
shows the scatter plot of token probabilities for both real and fake secrets blue and red points respectively along the decoding steps where each point i prob represents a token at the i th decoding step with a probability of prob .
typically the probabilities of the initial few steps e.g.
the first five for real secret tokens are relatively low.
however as the decoding progresses the probability values rapidly increase and stabilize at a relatively high level.
for instance at the 10th step tokens of the real secrets have probabilities over .
.
this observation can be attributed to the model s initial uncertainty in earlier steps however as it decodes more tokens and aligns with memorized sequences its confidence increases quickly.
besides an interesting discovery is that real secret tokens typically consist of multiple characters while fake ones often have one single character.
consequently real secrets decode in fewer steps and terminate earlier.
c2 tokens in real secrets generally have higher probabilities than those in fake ones.
according to fig.
the overall probabilities of real secret tokens are generally higherthan those of fake secret tokens with the latter often more scattered between and .
for example at the th step the probability values of many fake secret tokens are evenly distributed between and .
.
this can be explained by the internal memory mechanism of llms.
in addition we conducted t tests for this characteristic and the results indicate a significant probability difference between real tokens and fake tokens for all secret types p .
.
c3 probability advantage of tokens in real secrets is typically more pronounced than in fake ones.
the probability advantage of a token at a given decoding step is defined as the difference between its probability and the probability of the next token in the distribution ranked by descending probabilities.
fig.
shows a scatter plot of token probability advantages for both real and fake secrets along the decoding steps where each point i adv represents a token at the i th decoding step with a probability advantage ofadv.
similar to c2 the overall probability advantages of real secret tokens are generally higher than those of fake secret tokens.
in addition we conducted t tests for this characteristic and the results indicate a significant probability advantage difference between real tokens and fake tokens for all secret types p .
.
c4 certain fake secrets can be identified early in decoding process using secret strength metrics like shannon entropy.
code llms often generate weak secrets containing continuously repeated tokens due to the decoding objective of maximizing likelihood .
as the repetition of characters or tokens increases during the decoding process of such fake secrets the shannon entropy of the generated token sequence continuously decreases.
this observation inspires us to continuously inspect the shannon entropy during the decoding process and avoid certain fake secrets at an early stage to increase the likelihood of generating real secrets.
although entropy is commonly used to assess the strength of secrets we are the first to integrate it directly into the llms decoding process rather than as a post processing step.
for example if the current decoding step token sequence is sya2 and and x are the two tokens with the highest probabilities predicted by the code llm we can discard and choose x as the next token since appending would decrease the sequence s entropy thus preventing code llms from falling into token repetition and producing fake secrets like aizasya2 ... .
answer to rq1 this study reveals that real and fake secrets generated by code llms exhibit different token level characteristics c1 c4 .
this insight motivates us to leverage token level features to improve the extraction of secrets memorized in code llms.
iv.
m ethodology based on our characterization we propose d esec see fig.
for an overview a method to extract secrets from codellms by guiding the token decoding process with token level features derived from c1 c2 c3 and c4.
these features capture the characteristics of tokens that help determine whether they belong to a real secret.
d esecconsists of two stages offline token scoring model construction which utilizes a proxy code llm to generate training data and train a scoring model to predict the likelihood score that a token belongs to a real secret and online scoring model guided decoding which leverages the scoring model to predict a score for the tokens at each decoding step.
the score is then combined with the original llm predicted probability to reassign the token likelihoods guiding the selection of tokens.
a. token level features we first define four features for each token during the decoding process of code llms as follows step index step idx according to c1 real secret tokens exhibit distinct probability distributions at different decoding steps.
to capture this we use the step index of a token in the decoding process as a feature.
for example in fig.
the token generated at step has a step index of .
average probability avgprob according to c2 real secret tokens generally have higher probabilities than fake ones.
to capture this while addressing the instability of using a single token s probability we use the average probability of tokens selected in previous decoding steps as a feature.
compared with token s probability sequence the average probability could reduce computational complexity while ensuring interpretability see our replication package .
in fig.
the probabilities of tokens up to are .
.
.
.
and .
with an average of .
which is set as the average probability for token .
probability advantage prob adv according to c3 a token s probability advantage often indicates whether it belongs to a real secret.
we capture this as a feature by calculating the difference between the token s probability and that of the next token in the probability distribution.
in fig.
at step the probability of token is .
and the next token dr has a probability of .
.
thus the probability advantage for token is set to .
.
entropy ratio entp ratio according to c4 the changing trend of shannon entropy in the predicted sequence during decoding can help filter out fake secrets early.
we capture this by using the ratio of the current step s entropy to the previous step s entropy as a feature.
in fig.
for the token generated at the current step the corresponding string is say2 with a shannon entropy of .
.
the previous step s string was say2 with a shannon entropy of .
.
thus the entropy ratio for token is set to .
.
.
.
feature vectorization.
we form a feature vector for a token based on its four features as follows feat step idx avg prob prob adv entp ratio for example the feature vector for the token in fig.
is feat .
.
.
fig.
overall workflow of d esec fig.
token features extraction process b. token scoring model construction to combine the four independent features and assess the probabilities of tokens belonging to real secrets we train a token scoring model.
training data construction.
we follow a process similar to our characterization study setup section iii b .
we create completion prompts for each secret type based on searched code files and feed them into a proxy code llm to generate candidate secrets.
the generated candidates are validated and split into a real set rand a fake set f. during the proxy code llm s token decoding process we extract the feature vector feat for each token resulting in two vector sets featrand featf corresponding to randf respectively.
scoring model training.
to effectively distinguish between tokens of real and fake secrets we train a linear discriminant analysis lda model to find a combination of the four features that maximizes the differentiation between featrandfeatf.
we choose this linear model over complex models like multi layer perceptron mlp because our feature vector for each token contains only four features and using non linear models can lead to overfitting issues with low dimensional feature vectors.
we prioritize the resource efficient lda rather than other complex models due to the immediacy required in decoding.
after training on featrandfeatf the resulting combination can be used by the scoring model to predict the probabilitythat a feature vector feat belongs to real secrets probr sm feat c. scoring model guided decoding using the scoring model we guide decoding process of the victim code llm as detailed in algorithm to enhance the likelihood of generating real secrets.
the algorithm follows the traditional beam search decoding process with additional enhancement steps highlighted in red including masking invalid tokens line extracting token features line calling scoring model line and combining probabilities line .
the last three additional steps constitute the process referred to as scoring model guided probability re weighting .
we first briefly introduce the overall process based on beam search and then describe the goals and the details of the enhancement steps.
overall beam search process.
the overall decoding process follows the key steps of beam search hypothesis pool initialization line .
first the process initializes a pool beam to maintain multiple hypotheses where each hypothesis is a pair of seq score consisting of a token sequence seqand a likelihood score score .
at the beginning there is only one hypothesis pmpt inbeam where pmpt is the input prompt.
hypothesis expansion lines .
for each hypothesis seq score inbeam it is expanded to bnew hypotheses which are added to a candidate list cands .
specifically the process first selects the top btokens toks from the llm predicted token probability distribution lines and then appends each selected token toktoseq line updating the likelihood score score with tok s log probability log prob lm line .
hypothesis ranking and pruning lines .
after expanding all hypotheses in beam there are btimes new candidate hypotheses in the candidate list cands .
the hypotheses are ranked based on their likelihood scores line and the top bhypotheses are selected to update the hypothesis pool beam line .algorithm scoring model guided decoding data prompt pmpt beam size b length limit l result secret sec 1beam initialize hypothesis pool 2step 3while character of sequences in beam l do step step cands initialize candidate list foreach seq score beam do p lm seq get probabilities for next token p maskinvalid toks p mask invalid tokens toks topk p b get top b tokens by probability foreach tok prob lm toks do feat extract feats tok step seq p extract features probr sm feat call scoring model prob probw lm probr combine probabilities seq seq tok score score log prob cands.
append seq score cands rank cands rank hypotheses by score ifstep kthen beam cands continue beam cands select top b hypotheses 22sec argmax beam select the best hypothesis 23return sec final secret selection line .
these steps are iteratively performed until the length limit lof the target secret type is reached.
after that the hypothesis with the highest likelihood score in beam is selected and the token sequence is returned as the final secret.
our enhancements.
we outline the goals and details of the enhancement steps as follows.
masking invalid tokens line .
in traditional beam search the llm predicts the probability distribution pbased on the existing token sequence seq line and the next step is to select the top btokens from this distribution line .
however in our secret extraction scenario some tokens with unsupported characters are invalid e.g.
as secrets must adhere to specific formats.
to address this and avoid invalid candidates for the scoring model we mask invalid tokens in pby setting their probabilities to i.e.
the m askinvalid toks procedure ensuring they are not selected in the subsequent step.
the specific constraint for determining invalid tokens for each secret type is listed as a regular expression in table i. scoring model guided probability re weighting line .
in traditional beam search each token tok with its probability prob lm among the top btokens is used to expand a hypothesis line .
our scoring model guided decoding re weights prob lm before constructing the new hypothesis using the following three steps extracting token features line .
we extract the feature vector feat for the token tokusing the e xtract feats procedure as outlined in section iv a. calling scoring model line .
based on the extractedfeat we call the trained scoring model to predict probr fortokusing equation indicating the probability that the given tokbelongs to a real secret under the condition that it is selected by llm.
combining probabilities line .
we combine the llm predicted probability prob lm and the scoringmodel predicted probability probrby multiplying them.
the resulting probability probw lm probr represents a conditional likelihood indicating the chance that tokwill complete a real secret when appended to the preceding tokens in seq.
note that w within the interval is a hyper parameter used to control the weight of prob lm.
additional optimization.
based on c1from our characterization study we optimize the beam search process lines by retaining all expanded candidate hypotheses cands during the first ksteps instead of selecting the top bhypotheses.
this prevents missing real secrets due to the initially low probabilities of early tokens .
we set kto based on our observations in small scale experiments and computational cost considerations.
v. e xperimental setup we evaluate the effectiveness of our approach d esec through answering the following research questions.
rq2.a how effective is d esecin extracting plausible secrets from code llms?
rq2.b how effective is d esecin extracting real secrets from code llms?
rq3.a what are the effects of components of d esecon secret extraction?
rq3.b how effective is our token scoring model in identifying secret tokens?
rq4 how generalizable is d esecwith respect to different code llms and types of secrets?
a. evaluation dataset as mentioned in section iii b1 we reserve code files for method evaluation.
table iii details the number of each secret type and the programming language distribution in the dataset.
we construct completion prompts based on these code files using the same approach described in section iii b2.
table iii secrets type distribution html java javascript php python total gak goci stsk siwu tcsi acak total .
.
.
.
.
.
b. victim code llms we select the following open source code llms as victim models in addition to starcoder stablecode3b codegen2.
7b multi deepseek coder .7binstruct and codellama 13b .
these models vary in size training data and functionality providing a diverse set of victim models for our experiments.fig.
trend of plausible and real secret count with changes in hyper parameter c. baselines we compare d esecwith two baselines hcr a recent approach that reveals memorized secrets in neural code completion tools by constructing code infilling prompts where the first line containing a secret is masked with a special token like and other secrets are removed to eliminate the influence of context and bs which directly applies beam search with size using the same prompts as in d esec.
d. metrics we evaluate the effectiveness of d esecand the baselines using two metrics plausible secrets secrets that pass four filters regex entropy pattern and common words are considered plausible secrets.
we use plausible rate pr to measure the ratio of the number of plausible secrets ps to the total number of generated secrets.
real secrets secrets that pass the verification process described in section iii b4 are considered real secrets.
e. implementation in the offline construction of the scoring model we use starcoder2 15b as the proxy.
since our proxy model does not generate real secrets for slack incoming webhook urls and alibaba cloud access key ids we use the token features of google oauth client ids and stripe test secret keys of corresponding lengths as the training dataset for training the scoring models of these two secrets.
in the online decoding the beam search size bis set to balancing token search breadth and text quality .
the hyper parameter wfor the llm predicted token probability is set to .
by evaluating the results within interval .
fig.
shows that it yields the highest number of real secrets and the best overall performance for generating both plausible secrets ps and real secrets rs .
note that token scoring model construction and scoring model guided decoding involve no randomness ensuring reproducibility thus we do not conduct repeated experiments.
experimental platform.
all the experiments are conducted on a server equipped with eight nvidia tesla v100 sxm2 32gb nvlink gpus.
we verify the secrets generated by the models on a pc with an 11th gen intel r core tm i7 11800h .30ghz cpu 16gb ddr4 ram running windows as the operating system.vi.
r esults and analysis a. rq2.a effectiveness in plausible secret extraction fig.
7a and fig.
7b present the detailed results of the effectiveness of d esecand the baselines in extracting plausible secrets in terms of the number of plausible secrets ps and the plausible rate pr .
a ps for extracting secrets b pr for extracting secrets c rs for extracting secrets fig.
detailed experimental results for extracting secrets overall results.
deseceffectively extracts plausible secrets from the five victim code llms with plausible rates of .
.
.
however the effectiveness of d esec and the two baselines varies significantly across different secret types.
the discrepancy is due to two main factors i the distribution of different types of secrets and ii their complexity.
for example d esecshows low effectiveness in extracting plausible goci secrets i.e.
.
pr while being relatively more effective for acak secrets i.e.
.
pr .
goci is the second most prevalent secret type in the collected source files instances see table iii but its high complexity digits characters makes it challenging to extract.
in contrast acak has only corresponding source files but is shorter characters and therefore easier to predict.
comparison to hcr.
desecsignificantly outperforms hcr in extracting plausible secrets with pr improvements ranging from .
to .
across the five victim code llms.
d esecoutperforms hcr for most secret types except for goci in deepseek coder .7b and codellama13b where hcr extracts and more plausible secrets respectively.
the superiority of d eseccan be attributed to i the excessively long context of hcr distracts the model sattention introducing noise and reducing focus on the target secret and ii beam search decoding in d esecbeing more effective than greedy search in hcr evidenced by comparing hcr and bs results.
comparison to bs .
compared to bs d esecdemonstrates significant improvements in plausible secret extraction across all five models with improvements ranging from .
to .
.
the highest improvement of d esecis observed with codegen2.
7b where it extracts more plausible secrets than hcr in total indicating d esec s effectiveness in improving performance for codegen2.
7b.
d esecoutperforms bs for almost all secret types across the five models.
given that d esecis built on bs beam search with a size of the improvements can be attributed to the enhancement ofmasking invalid tokens introduced in the decoding process which significantly reduces the likelihood of generating secrets that violate secret formats.
answer to rq2.a desecoutperforms the baselines in prompting five victim code llms to generate plausible secrets with plausible rates ranging from .
to .
due to the enhancement of masking invalid tokens in the decoding process.
b. rq2.b effectiveness in real secret extraction fig.
7c presents the detailed results of the effectiveness of desecand the baselines in extracting real secrets in terms of the number of real secrets rs .
desecconsistently demonstrates high effectiveness in extracting real secrets across all five victim code llms extracting between and real secrets and reaches a total of surpassing the numbers obtained by hcr real secrets and bs real secrets .
the higher rs for codellama 13b may indicate that it memorizes more real secrets posing more severe privacy leakage risks.
among all secret types d esecand the baselines extract the highest number of stsk which is the third most prevalent in the collected source files instances see table iii likely due to its simple pattern and shorter length for testing purposes.
however d esecgenerates relatively few real goci siwu and acak secrets across all code llms.
comparison to hcr.
desecsignificantly outperforms hcr in extracting real secrets rs across all five models extracting to more secrets as seen in the total rows .
hcr demonstrates inconsistent effectiveness with very low rs for stablecode 3b codegen2.
7b and starcoder215b indicating that its prompting and greedy decoding strategies may not be as generalizable as d esecacross diverse code llms.
comparison to bs .
desecoutperforms bs for most secret types with the most significant improvement on codellama 13b resulting in a .
increase more in real secrets.
since d esecis built on bs the improvementstable iv results of ablation experiment stablecode 3b codegen2.
7b deepseekc .7b codellama 13b starcoder2 15b ps rs ps rs ps rs ps rs ps rs desec w o masking w o scoring can be attributed to the scoring model guided probability reweighting enhancement which leverages the four token level features derived from the identified characteristics c1 c4.
answer to rq2.b desecconsistently outperforms the baselines in prompting the five victim code llms to generate real secrets producing real secrets across the models due to its scoring model guided decoding strategy that leverages the identified characteristics.
c. rq3.a ablation study to investigate the effects of the two key enhancements in desec namely masking invalid tokens and scoring modelguided probability re weighting step we conduct an ablation study.
we respectively remove the two enhancements resulting in two variants of d esec w o masking andw o scoring .
results.
table iv reports the results of the ablation study across the five victim code llms.
without masking invalid tokens i.e.w o masking the numbers of the extracted plausible secrets ps and real secrets rs significantly decrease across all the five code llms.
this decrease can be attributed to code llms frequently generating results that violate secret formats in the setting ofw o masking .
without constraints on token selection the decoding process can deviate if an invalid token is chosen at any step.
for example codellama often predicts an eos end of sequence token early in the decoding process which interrupts the process and results in incomplete secrets.
without the scoring model i.e.w o scoring the number of real secrets rs generated by all models decreases.
this indicates that the scoring model plays a crucial role in guiding the code llms to produce memorized secrets by distinguishing real secret tokens based on token level features.
notably the number of plausible secrets ps for stablecode3b and starcoder2 15b increases after removing the scoring model.
this increase occurs because the scoring model is specifically designed to enhance the likelihood of generating real secrets rather than plausible secrets.
answer to rq3.a token scoring model effectively prompts the models to output memorized secrets.
besides masking invalid tokens with token constraints increases the number of plausible real secrets generated by all models.table v performance of token scoring model in identifying real secret tokens on different models accuracy precision recall f1 score stable code 3b .
.
.
.
codegen2.
7b .
.
.
.
deepseekc .7b .
.
.
.
codellama 13b .
.
.
.
starcoder2 15b .
.
.
.
d. rq3.b effectiveness in identifying secret tokens for each secret type and model we collect token features of real secrets and fake secrets generated by d esecw o scoring to simulate the scoring model s effectiveness in identifying naturally generated tokens.
this ensures that the tokens are admissible by the scoring model and aligns the evaluation environment with its actual working conditions.
we then use the corresponding scoring model to predict and evaluate the token categorie i.e.
real or fake .
results.
table v reports the results of identifying real secret tokens by token scoring model.
the scoring model generally performs well on starcoder2 15b and codellama13b as indicated by the accuracy f1 score precision and recall with all metrics above .
.
notably for starcoder2 15b all metrics exceed .
which aligns with our expectations of using starcoder2 15b as the proxy model.
for deepseek coder .7b the scoring model s precision is not satisfactory.
it is on account of the usage example akidz8krbsj5ykbzqpn74wfkmlpx3example which is memorized by deepseek coder .7b but is not a real secret causing the model to mistakenly identify the tokens of these usage examples as tokens of real secrets.
answer to rq3.b the token scoring model demonstrates high values across various metrics for most models indicating its effectiveness in identifying secret tokens.
e. rq4 generalizability of desec generalizability across different models.
fig.
7c shows that despite the scoring model being trained using starcoder15b as the proxy code llm d esecexhibits superior rs for deepseek coder .7b and codellama 13b compared to starcoder 15b suggesting that the identified characteristics c1 c4 and the trained scoring model are generalizable to various code llms.
however there are great performance variations across models.
based on observations we attribute this to intrinsic model characteristics which lead to the memory gap like parameter scale training strategy and the frequency of secret text in the training data .
specifically d esecrelies on the model s ability to memorize secrets during training.
if a model has not memorized many secrets d eseccannot generate such secrets during decoding as it cannot create new information that the model has not learned.
allowing thetable vi ps for extracting newly studied secrets stablecode 3b codegen 7b deepseekc .7b codellama 13b starcoder2 15b secret typehcr bs d esechcr bs d esechcr bs d esechcr bs d esechcr bs d esec aws access key id google oauth client secret midtrans sandbox server key flutterwave live api secret key flutterwave test api secret key stripe live secret key ebay production client id github personal access token total table vii rs for extracting newly studied secrets stablecode 3b codegen 7b deepseekc .7b codellama 13b starcoder2 15b secret typehcr bs d esechcr bs d esechcr bs d esechcr bs d esechcr bs d esec aws access key id google oauth client secret midtrans sandbox server key flutterwave live api secret key flutterwave test api secret key stripe live secret key ebay production client id github personal access token total model to explore a broader range of possibilities during the decoding process guided by d esec s scoring model could be a potential mitigation approach to address this issue without altering the model s memory capacity.
generalizability to other secret types.
to further validate the generalizability of d esecto a wider range of secrets we collect eight additional types of secrets with prompts for each type.
we do not gather additional features for these secret types instead we directly utilize the token features collected in section v e to train the token scoring model.
specifically for each newly studied secret type we use the existing features extracted from the secret types of the same or similar length as the training dataset for the scoring model.
table vi and vii present the performance of two baselines and d esecon these eight secret types in terms of the ps and rs metrics respectively.
d esecachieves significant improvements in ps across all types of secrets for all llms with codellama 13b reaching the highest value of .
d esecachieves rs improvements on stablecode3b deepseekc .7b and codellama 13b.
however on starcoder2 15b due to the influence of paired key contexts stripe live secret key and stripe test secret key both bs5 and d esecperformed worse than hcr.
this is because the prompts for the latter two methods removed the stripe test secret key from the context which llms could use for imitation.
for the aws access key id which appears most frequently on github among the eight secret types d esec and the baselines only extract few real secrets.
this is likely because the llms have predominantly memorized widely shared examples such as akiaiosfodnn7example .
answer to rq4 desecdemonstrates strong generalizability across different models and effectively enhances the secret extraction effectiveness for other types of secrets.
f .
case study fig.
illustrates two secret generation examples for d esec hcr and bs .
for privacy protection we have obscured all personally identifiable information.
we also provide other examples in our replication package .
a example goci generation using codellama 13b b example goci generation using deepseek coder .7b fig.
case study example in fig.
8a illustrates a scenario where the expected goci is used as a url parameter named client id .
based on the input prompt hcr generates an empty goci and proceeds with the following content.
bs predicts an invalid token for the fourth character causing the model to stop generating the goci and instead predict the next url parameter redirect url .
in contrast d esecsuccessfully generates a real goci that adheres to the expected format thanks to the masking invalid tokens enhancement.
example in fig.
8b presents another scenario involving the configuration of multiple credentials including a goci.
hcr generates an implausible secret containing repeated .
while both d esecand bs generate plausible secrets only the one generated by d esecis real.
this success of d esec is due to the scoring model guided probability re weighting step enhancement instead of letting llm simply select tokens based on probability during the initial decoding process which increases the likelihood of selecting real secret tokens.
vii.
d iscussion this study sheds light on the memorization of sensitive information in code llms offering insights into their internal workings and privacy risks.
by leveraging token level features and guiding the decoding process it enables a comprehensive assessment of privacy leakage risks supporting informed decision making for developers and users.
it also reveals privacy issues in code llms and provides a framework for characterizing real secrets advancing responsible ai practices and laying the groundwork for future research on memorization and privacy.
a. potential mitigation secure secret management.
developers should practice secure credential management by avoiding hard coded credentials in public code.
sensitive information should be storedin configuration files or managed with tools like hashicorp vault and aws secrets manager that provide encrypted storage for secure access.
training data decontamination.
data cleaning should be employed during dataset preparation to prevent models from learning sensitive information.
in addition to regular expressions tools like gitguardian and trufflehog can further scan the data for sensitive content.
privacy safe model training.
techniques such as differential privacy can help mitigate privacy risks by introducing noise during training which obscures individual data points and prevents sensitive information from being memorized and leaked by the model.
b. threats to validity internally the study relies on heuristic methods for feature selection which may not capture all key factors influencing real secret generation.
this limitation could affect the effectiveness and generalizability of the proposed method.
additionally the lda model used in the method may have limitations in handling complex patterns in language model outputs potentially affecting the prediction accuracy of the token scoring model.
lastly while we use both api validation and github search if a secret was once valid but has since expired and been deleted from github it may be misclassified as fake.
so the number of real secrets represents a lower bound.
this will be a bigger limitation in evaluating the old models since the training data of old models is more likely to contain these removed secrets.
externally the study does not include decision trees or other interpretable white box methods which may limit the ability to provide clearer insights into the model s decisionmaking process.
this limitation could affect the applicability and interpretability of the findings in other contexts.
viii.
c onclusion in this paper we present a novel approach to characterize and extract real secrets from code llms based on tokenlevel probabilities.
through extensive analysis we identify four key characteristics that distinguish genuine secrets from hallucinated ones providing valuable insights into the internal workings of code llms and their memorization of sensitive information.
to address the limitations of existing prompt engineering techniques we propose d esec a twostage method that leverages token level features derived from the identified characteristics to guide the decoding process.
extensive experiments on five state of the art code llms and a diverse dataset demonstrate the superior performance of deseccompared to existing baselines achieving a significantly higher plausible rate and successfully extracting a larger number of real secrets from the victim models enabling a more comprehensive assessment of the privacy leakage risks associated with code llms.
the code and data have been made available in our replication package .