lightweight concolic testing via path condition synthesis for deep learning libraries sehoon kim yonghyeon kim dahyeon park yuseok jeon jooyong yi mijung kim unist south korea sehoon yonghyeon tryness jsjeon jooyong mijungk unist.ac.kr korea university south korea ysjeon korea.ac.kr abstract many techniques have been recently developed for testing deep learning dl libraries.
although these techniques have effectively improved api and code coverage and detected unknown bugs they rely on blackbox fuzzing for input generation.
concolic testing also known as dynamic symbolic execution can be more effective in exploring diverse execution paths but applying it to dl libraries is extremely challenging due to their inherent complexity.
in this paper we introduce the first concolic testing technique for dl libraries.
our technique offers a lightweight approach that significantly reduces the heavy overhead associated with traditional concolic testing.
while symbolic execution maintains symbolic expressions for every variable with non concrete values to build a path condition our technique computes approximate path conditions by inferring branch conditions via inductive program synthesis.
despite potential imprecision from approximation our method s light overhead allows for effective exploration of diverse execution paths within the complex implementations of dl libraries.
we have implemented our tool p athfinder and evaluated it on pytorch and tensorflow.
our results show that p athfinder outperforms existing api level dl library fuzzers by achieving more branch coverage on average up to higher than titanfuzz and higher than freefuzz.
p athfinder is also effective in bug detection uncovering crash bugs of which were confirmed by developers as previously unknown with already fixed.
index terms fuzzing concolic testing deep learning libraries i. i ntroduction deep learning dl continues to be a dominant approach in the field of artificial intelligence ai and has been extensively used for building various ai systems.
it has become a common practice to build ai systems using dl libraries such as pytorch and tensorflow .
that is bugs contained in dl libraries can be propagated to the applications and hurt the performance of the implemented models .
accordingly research on dl library testing has recently been gaining traction.
to test dl libraries researchers have developed various api level fuzzing techniques to generate inputs for dl library apis.
these techniques use valid seed inputs obtained from api usage examples or large language models extract api input constraints and borrow inputs from the work was done when yuseok jeon was at unist.
corresponding author.equivalent apis within the same library or counterpart apis across different libraries .
although these techniques have proven effective in detecting unknown bugs improving api coverage and enhancing code coverage they still suffer from limited code coverage .
this limitation arises because most existing techniques perform blackbox fuzzing which does not consider the internal code structures of the program under test during input generation.
consequently low code coverage may affect the bug detection capability of a fuzzing technique as bugs cannot be detected without being executed.
a potential approach to address low code coverage issues can be greybox fuzzing such as libfuzzer which leverages coverage feedback to guide the input generation to explore untested parts of the code.
if a generated input increases coverage it is added to the seed corpus as a mutation candidate for further fuzzing.
however greybox fuzzing may still suffer from low coverage.
due to the random nature of mutation operators mutated inputs are highly likely to be rejected by input validity checks and thus often fail to increase code coverage.
another possible approach to address low coverage can be concolic testing also known as dynamic symbolic execution or whitebox fuzzing which systematically explores different execution paths .
concolic testing can be a better solution than greybox fuzzing for improving the coverage since it maintains path conditions and generates inputs that traverse the corresponding paths via constraint solving.
hence it does not suffer as much as greybox fuzzing from repeated precondition violations.
however performing concolic testing on dl libraries still presents significant challenges due to its well known drawbacks .
first due to the high software complexity of dl libraries concolic testing requires high computational overhead to handle the symbolic execution and constraint solving for a large number of paths.
second concolic testing has limited support for programs involving nonlinear expressions in the program e.g.
x y w due to the difficulty in solving nonlinear constraints.
note that dl libraries such as pytorch and tensorflow heavily use nonlinear expressions in their implementations.
to fill this gap we develop a lightweight concolic testingkernel code written in c python apisc apisfig.
a layered structure of a typical dl librarydef torch.nn.functional.affine grid theta size align corners none ... check that shapes and sizes match if len size if theta.dim !
or theta.shape !
or theta.shape !
raise valueerror some error msg spatial size size elif len size a python apiinline tensor torch nn functional affine grid const tensor theta const intarrayref size bool align corners false ... check that shapes and sizes match if size.size torch check theta.dim theta.size theta.size some error msg else if size.size b c api fig.
pytorch s affine grid api in python and c technique designed to systematically explore diverse execution paths for dl libraries.
the key idea of our approach is derived from how to deal with the path condition which is the main vehicle for guiding input generation.
our approach infers an approximate path condition after running the program while traditional concolic testing collects an exact path condition during program execution.
as a simple example consider the following program foo int x if x ... suppose we want to infer a path condition x without collecting the actual one during the program execution.
suppose two different inputs x andx are generated.
after running the program with these inputs we observe that two executions explore two different paths.
based on this observation we can infer that x is a feasible candidate for a path condition.
our technique infers such conditions by using an off the shelf inductive program synthesis tool such as duet .
a big advantage of our approach is that it does not require heavyweight instrumentation like traditional symbolic execution for evaluating symbolic expressions of each program variable during the whole execution.
for our approach lightweight instrumentation is sufficient for inferring path conditions because all we need to check is which branches are taken like greybox fuzzing.
another key idea of our approach is that it refines approximate path conditions towards more precise ones in subsequent fuzzing iterations.
unlike concolic testing where a generated input executes exactly the same path for solved constraints in our approach a generated input may execute a different path for solved constraints due to potential inaccuracy induced by approximation.
based on observations from the previous and current executions our technique keeps refining the path conditions and exploring new paths.
we implemented our approach in a tool called pathfinder .
we conduct extensive experiments on popular real world dl libraries pytorch and tensorflow.
our results show that p athfinder outperforms existing api level dl library fuzzers by achieving more branch coverage on average up to higher than titanfuzz and higher than freefuzz.
p athfinder detected new bugs of which were confirmed by developers.
in summary this paper makes the following contributions novel technique.
we propose a novel lightweight concolic testing technique for deep learning dl libraries.
our workis the first concolic testing approach for generating dl api inputs by inferring approximate path conditions using program synthesis.
thorough experiments.
we implement our technique in a tool called p athfinder and perform an extensive evaluation with pytorch and tensorflow demonstrating its effectiveness in achieving high code coverage and detecting previously unknown bugs.
replication package.
the artifact for this work including the implementation and experimental data is publicly available on github1and zenodo2.
ii.
b ackground and motivation a. deep learning libraries figure shows a typical layered structure of a dl library.
its core parts which are called kernels are implemented in low level languages like c .
most users of dl libraries access these kernels through high level apis which are provided in either python or c .
figure shows an example of an api affine grid in python and c .
these apis perform the same input validation checks as shown in figure then call the kernel functions when the input is valid.
python apis and their c counterparts in principle implement the same functionalities as illustrated in the example code.
in this work we use c apis for testing to perform a streamlined code instrumentation of both the kernel code and the c apis.
it is worth noting that our approach is also applicable to python apis through code instrumentation of python apis.
b. concolic testing symbolic execution executes the program with symbolic input values instead of concrete input values.
it maintains a symbolic state which maps variables having non concrete values to symbolic expressions and a path condition pc which is a first order formula over symbolic expressions.
both the map and pc are updated during the symbolic execution.
at the end of the symbolic execution solving the pcusing a constraint solver generates a test input that executes the same path as the symbolic execution.
conv2d tensor input tensor weight int padding int dilation int groups torch check e passes if eis true otherwise throws an exception.
5torch check b1 input.dim 6torch check b2 input.dim weight.dim 7bool forward checked weight.size groups weight.size groups input.size weight.size groups if forward checked bool kernel size correct input.size padding dilation weight.size input.size padding dilation weight.size if kernel size correct compute conv2d input weight padding dilation ... a simplified code snippet of conv2d api c1 input rank c2 input rank weight rank c3 weight dim0 groups c4 weight dim0 groups c5 input dim1 weight dim1 groups c6 input dim2 padding0 dilation0 weight dim2 c7 input dim3 padding1 dilation1 weight dim3 b exact pc path condition for line ca input rank cb weight rank cc weight dim0 groups cd input dim0 groups ce input dim1 groups weight dim1 cf true cg input dim3 weight dim3 c approximate pc inferred by our tool for line fig.
motivating example concolic testing also called dynamic symbolic execution maintains both a concrete state and a symbolic state.
it executes a program starting with some random concrete input and collects path conditions pc 1at conditional statements along the execution path taken by this input.
at the end of this concolic execution by negating an individual branch condition inpc a new path condition pc 2can be obtained.
then solving pc 2using a constraint solver generates a test input that follows a different program path.
this process is repeated systematically until all execution paths are explored or the time budget expires.
c. motivating example this section motivates our technique by illustrating why approximate path conditions inferred from our approach are beneficial for testing dl libraries concolically.
figure 3a presents partial code of a c pytorch api torch.nn.functional.conv2d .
suppose we want to test a statement at line .
to reach line we need an input that satisfies complex path conditions presented in figure 3b.
existing blackbox dl api fuzzers struggle to generate such inputs because they do not examine the source code during input generation.
approaches using constraints extracted from documentation or source code are also insufficient as a solution as they rely on manually defined extraction rules which often lead to incomplete constraints.
a traditional concolic testing technique would collect the exact path conditions expressed with symbolic input values e.g.
input rank weight dim0 etc.
shown in figure 3b.
however even though this exact path condition can be obtained by a symbolic execution engine concolic testing may struggle to solve non linear conditions such as c4 c5 c6 and c7in figure 3b concolic testing may not be able to generate input that explores this path.
moreover the full path condition collected beyond line would be much more complex in real world dl libraries.
for this reason adopting concolic testing to dl libraries is challenging and has never been addressed in previous research.
our technique successfully adopts concolic testing to dl libraries by reducing the heavy overhead required to collect exact path conditions.
instead of extracting exact path conditions shown in figure 3b our technique infers path conditions based on execution results as demonstrated in figure 3c.
while some synthesized path conditions such as catocc are inferred precisely others are often approximate like those from cdtocg due to our data driven path condition inference.
nevertheless obtained approximate path conditions can still be effective in guiding path exploration as will be shown in the next section and throughout the paper.
iii.
o verview our approach p athfinder guides the exploration of execution paths using path conditions similar to symbolic execution.
however beyond this similarity p athfinder differs as described below.
a. inductively learning path conditions in symbolic execution path conditions are deductively extracted .
for example when an if conditional expression if x y is symbolically executed the current path condition is updated into x y or x y depending on which branch is taken.
more generally the rules for updating path conditions are pre defined for each operation of the programming language and at runtime these rules are deductively applied.
while the usefulness of symbolic execution has been shown extensively in the literature deductively constructing path conditions also imposes several issues such as incomplete applicability e.g.
path condition update rules may not be available for all operations e.g.
system calls and high computational overhead updating path conditions typically involves running instrumented code as in crest or using a dedicated interpreter as in klee .
in contrast our approach avoids the aforementioned issues by inductively learning path conditions from a set of all inputs executed so far.
below we describe how we learn path conditions.
given an execution path defined as a sequence of branches b1 b2... bntaken during the execution of a program its path condition is represented as n k 1ckjbkkwhere ckjbkk denotes the condition for branch bklearned as described below.suppose we have a set of inputs iposand ineg whose execution paths share the same prefix b1 b2... bk 1but diverge afterward that is every input in iposexecutes b1 b2... bk bk while every input in inegexecutes b1 b2... bk bkwhere b denotes the branch that represents the opposite direction of b. under this setting p athfinder learns ckjbkkby synthesizing a boolean condition that separates ipos i.e.
positive inputs and ineg i.e.
negative inputs .
thus ckjbkkis evaluated to true for all inputs in iposandfalse for all inputs in ineg.
due to the inductive nature of our approach an obtained path condition is likely to be only an approximation of the actual path condition.
however as will be explained shortly these approximate path conditions are still useful in guiding the exploration of execution paths.
b. path exploration guided by approximate path conditions consider testing the conv2d function shown in figure 3a.
suppose that for an initial random input i1 the first parameter input is of the tensor type with rank thus input.dim is and the second parameter weight is also a tensor but with rank thus weight.dim differs from input.dim .
given this input the execution path takes the if branch of the first torch check statement at line i.e.
b1is true and the else branch of the second torch check statement at line i.e.
b2is false .
that is i1takes the path b1 b2.
at this point only one input i1 is available for learning and as a result a typical inductive synthesizer such as duet would synthesize true as for c1jb1kandc2j b2k.
as a result we obtain true true as the approximate path condition for path b1 b2.
we will use notation to denote an approximate path condition and to denote a usual non approximate path condition.
unlike concolic execution we do not negate a conjunct of the path condition to guide the exploration.
instead we perform a different path exploration strategy as described below.
in our approach an approximate path condition may represent multiple execution paths as is evident in our running example currently we have only one approximate path condition true capturing all execution paths.
to proceed pathfinder chooses an approximate path condition from the available ones and generates an input that satisfies .this corresponds to exploring the part of the computation tree satisfying .from the perspective of fuzzing it can also be viewed as fuzzing the sub input space satisfying .
in our example suppose that p athfinder generates input i2 where the tensor input has a rank of which trivially satisfies the current approximate path condition of true .
given this generated input the execution path takes the elsebranch of the first torch check statement at line i.e.
b1is false .
based on i1andi2taking different branches ofb1 the inductive synthesizer refines c1jb1kfrom true to a stronger condition say input rank .
we now have two approximate path conditions c1jb1k c2j b2kand c1jb1k which are simplified in our example to input rank andinput rank respectively.
we then generate thenext input that satisfies either of the two approximate path conditions and repeat the process.
as the process continues p athfinder refines the approximate path conditions with increasing accuracy for the following two reasons.
first both positive and negative inputs will be available for more branches which will have the synthesizer produce a non true condition for those branches.
second as more examples will be available for each branch the synthesizer will be able to produce more precise conditions.
c. comparison with other path exploration techniques we here summarize our approach by comparing it with other path exploration techniques such as symbolic execution and fuzzing.
in symbolic execution each feasible path condition identifies a distinct execution path.
thus every generated input is guaranteed to take a new execution path.
however this guarantee comes at the cost of high computational overhead.
to extract a path condition symbolic execution typically requires heavyweight code instrumentation or a custom interpreter.
in comparison p athfinder requires only lightweight instrumentation to monitor branch directions during execution.
in exchange for faster execution p athfinder s inductive learning may not produce precise path conditions.
in other words p athfinder trades off the precision of path conditions for the efficiency of extracting them.
our efficiency over precision approach is akin to that of fuzzing.
however unlike typical fuzzing p athfinder uses learned path conditions to guide the exploration of execution paths.
it can be viewed that we divide the input space into subspaces based on the learned path conditions each subspace corresponds to a distinct approximate path condition.
overall p athfinder sits between symbolic execution and fuzzing.
compared to symbolic execution p athfinder generates inputs at a faster pace.
while a fuzzer can generate inputs more quickly than p athfinder since p athfinder invokes an smt solver to generate new inputs p athfinder can explore execution paths more effectively by using learned path conditions.
this balance between efficiency and effectiveness is the key strength of p athfinder .
at the early phase of exploration p athfinder can quickly generate inputs covering new paths without the need for precise path conditions.
at the later phase p athfinder can generate inputs that cover new paths effectively by using learned path conditions whose precision has been improved as more inputs are collected.
iv.
m ethodology in this section we describe the algorithm of p athfinder iv a and its optimizations iv b .
a. algorithm algorithm shows the algorithm of p athfinder .
it takes as input a target function to test and returns a bug revealing input found in the given time budget.
given the target function f pathfinder automatically generates the precondition offbased on the type information of each parameter.
for example if a parameter has a tensor type precondition algorithm pathfinder algorithm input a target function f output a bug revealing input i none if not found step initialization precond gen f f s precondition is automatically generated based on the type of each parameter i a set of executed inputs true a set of approximate path conditions while time elapsed time outdo step input generation choose i geninput i step running fwith input i b a sequence of executed branches b crashed runjfk i ifcrashed true then return i end if step refining refine b i i i i i end while return none includes a constraint that all tensor dimensions should be positive.
more details are provided in section v a. while running p athfinder maintains a set of approximate path conditions defined as follows definition approximate path condition consider an execution path following a sequence of branches b. then the approximate path condition of this execution path is n k 1ckjbkk where ckjbkkrepresents the inductively inferred branch condition of the k th branch bk b and nis the length of b. ckjbkkshould satisfy the following properties ckjbkkshould be expressed as a boolean formula over formal parameters of the target function.
consider a set of all inputs iexecuted so far and its two subsets iposand inegsatisfying the following.
iposcontains all inputs in ithat executes a sequence of branches b1 b2 ... bk bk.
meanwhile inegcontains all inputs in ithat executes a sequence of branches b1 b2 ... bk bk where bdenotes the branch that represents the opposite direction of b. then for all inputs ipinipos applying ckjbkktoipshould return true and for all inputs ininineg applying ckjbkkto inshould return false .
note that there can exist only ipos without ineg.
in this case ckjbkk true .
in the beginning p athfinder initializes the set of approximate path conditions as true line .
once pathfinder enters the main loop lines p athfinder b1b2b3 i1 i1 b1b4 b1b2b3 i1 i2 b1b4 b1b2 i2 b3 b3 i1 i3 i1 i2 i1 i2 i3 compact prefix tree t1t2t3fig.
efficiently refining approximate path conditions using compact prefix tree.
iand represent the set of executed inputs and the set of approximate path conditions respectively.
repeats the following three steps input generation running the target function with the generated input and refining a set of approximate path condition based on the execution result.
we below describe each step.
input generation to generate the next input to execute we choose an approximate path condition from the current line .
in the current implementation we randomly select an approximate path condition while using other selection strategies should be possible.
we then use an smt solver to generate an input ithat satisfies and the precondition of the target function line .
running the target function in the next step we run the target function fwith the generated input i line .
while executing f we record the sequence of executed branches b. iffcrashes we return the crashing input i. refining the approximate path conditions given the sequence of branches b b1 b2 ... bnexecuted with the input i we refine the set of approximate path conditions line .
we iterate over each branch bkinband construct iposand inegas described in definition .
we then synthesize a boolean formula ckjbkkthat separates iposfrom ineg.
this way we obtain an approximate path condition for band add it to .
we also refine the existing approximate path conditions in .
consider an approximate path condition defined as m k 1ckjb kk.
we refine ckjb kkif for all jsuch that j k b jis identical to bj b. that is the approximate path condition and the new input ifollow the same branches up to the k th branch.
in this case we refine ckjb kkto ckjbkk a new branch condition inferred from iposand ineg.
we efficiently perform the aforementioned task as below.
efficient data structure .to efficiently refine approximate path conditions we represent the set of approximate path conditions using a compact prefix tree also known as a radix tree.
consider an example from figure .
it presents a scenario where p athfinder generates three inputs i1 i2 and i3in sequence see the first row.
the second row illustrates for each input how we refine the compact prefix tree i.e.
t1 t2 t3 .
the last row presents a set of approximate pathconditions represented by the compact prefix tree.
suppose when the target function is run with input i1 it follows the execution path b1 b2 b3.
since we have only one execution path the compact prefix tree t1has only one root node and a leaf node i.e.
i1 .
these two nodes are connected by an edge labeled with the sequence of branches b1 b2 b3.
suppose the next input i2 deviates from b1and takes an opposite direction b1 followed by b4.
we add a new edge labeled with b1 b4.
since we now have both positive and negative examples for branch b1 the synthesizer can infer a non true condition c1jb1k.
in the running example the updated compact prefix tree t2has now two paths whose approximate path conditions are c1jb1kand c1jb1k respectively.
now suppose that we generate the next input i3 satisfying c1jb1k expecting to execute the path b1 b4.
however due to the imprecision of the approximate path condition the use of i3may lead to a different execution path b1 b2 b3.
accounting for this counter example p athfinder refines c1jb1ktoc 1jb1kwhich separates the positive examples i1andi3 from the negative example i2.
also a new branch condition c3jb3kis inferred based on i1andi3.
b. other optimizations we here describe the other optimization strategies used in pathfinder to improve the efficiency of the testing process.
efficient use of the synthesizer many modern inductive program synthesizers including duet are syntaxguided i.e.
they synthesize programs that follow a given grammar and examples based i.e.
they synthesize programs that satisfy a set of input output examples in our setting the output is a boolean value indicating the direction of the branch.
for efficient use of the synthesizer we control the grammar and the number of examples used for synthesis as described below.
staged synthesis .duet is a syntax guided synthesizer all synthesized conditions should follow the given grammar.
in general the more complex the grammar the more time the synthesizer takes to find a solution.
using simple grammar can also be beneficial for input generation as finding a solution for a simple path condition is easier.
considering these we initially use a simple grammar shown in figure 5a.
only if synthesis fails with the simple grammar we use the more complex grammar shown in figure 5b.
tolerant branch condition refinement .our main goal is to efficiently explore execution paths to find bugs rather than to synthesize precise branch conditions.
as will be shown in our experimental results using approximate branch conditions is often sufficient for exploring new paths and finding bugs.
to avoid spending too much time on synthesizing precise conditions we refrain from synthesizing conditions when the current approximate path condition is already accurate enough.
consider a branch condition ckjbkksynthesized from positive inputs iposand negative inputs ineg.
suppose ckjbkkis not precise and applying it to a new input ireturns true while the actual execution takes the opposite direction.
we measurecond cond const n cond var x y cond var const var var a level grammar cond cond expr1 const cond cond var cond cond const var cond var const cond expr0 expr0 var const expr0 expr0 const n expr0 expr1 var x y expr0 expr0 expr0 expr0 b level grammar fig.
grammar for branch conditions the accuracy of ckjbkkusing iposand ineg i using mcc matthews correlation coefficient .
only if the accuracy is below a threshold we empirically use .
we refine ckjbkk.
sampling examples .another factor that affects the synthesis time is the number of examples used for synthesis.
to reduce the synthesis time we set a limit non the number of examples used for synthesis.
in our experiments we set nto .
nondeterministic branch pruning when exploring the execution paths based on path conditions an underlying assumption is that the executed branches are deterministic.
however this is not always the case.
for example consider rand .
including such nondeterministic branches in the path condition can deteriorate the performance of the synthesizer as demonstrated in vi b. we remove nondeterministic branches from the compact prefix tree.
for example in figure if b2is nondeterministic we remove it from the compact prefix tree.
to avoid incurring an extra cost of checking nondeterminism we identify nondeterministic branches only opportunistically when the same input is generated again during the testing process if different subsequences of branches are observed between two executions we identify nondeterministic branches using a variant of myers algorithm and prune them from the approximate path condition.
diverse input generation generating diverse input is crucial when performing testing.
p athfinder generates an input satisfying the inferred approximate path condition .
while we need to generate diverse input satisfying an smt solver such as z3 we use often generates the same input when the same is given.
to obtain more diverse inputs we strengthen into where is a random constraint.
we construct with a template x y where xandyare randomly chosen from input parameters and is randomly selected from .
v. e xperimental setup to evaluate our technique p athfinder we investigate the following three research questions table i type based precondition generation rules param internal param precondition int n n int val min n int val max float r r r .
.
.
float val max tensor t t dtype dt min t dtype dt max t rank t rank t dim0 t dim0 int val max t dim4 t dim4 int val max rq1 how effective is p athfinder in achieving code coverage?
rq2 how do various optimization strategies of pathfinder affect its performance?
rq3 how effective is p athfinder in detecting bugs?
a. implementation we implemented p athfinder in c .
our implementation includes an automatic test driver generator given a target api fof pytorch or tensorflow our tool generates a test driver that invokes fwith the inputs generated by pathfinder .
while automatically generating a test driver for an arbitrary function is challenging we found that supporting pytorch tensorflow apis is feasible.
to synthesize branch conditions we use an inductive program synthesizer duet .
for input generation we use z3 smt solver .
precondition generation .when testing a target api f the inputs generated by p athfinder should satisfy the preconditions of f as we described in iv a. depending on the type information of f s parameters we enforce different constraints on the inputs as shown in table i. for example given an integer type parameter n we enforce that n s value should be within the range of int val min andint val max .
for a floating point type parameter r we restrict its value to be one of the predefined floating point constants.
this is to expedite input generation using an smt solver.
for the tensor type we enforce constraints on the tensor s data type rank and dimensions.
once values satisfying these constraints are generated we put them into a tensor object and pass it to the target api.
b. baseline tools we compare p athfinder with five existing techniques freefuzz deeprel titanfuzz acetest and ivysyn .
we selected freefuzz deeprel and titanfuzz because they are state of the art api level fuzzing tools for dl libraries like p athfinder .
although a recent work fuzzgpt is also an api level fuzzer we could not include it in our evaluation because the tool is not publicly available.
we also included acetest and ivysyn which target kernel functions of dl libraries.
these tools require test drivers for kernel functions and we use p athfinder s test driver generator to prepare them.
c. dl libraries and apis we consider both pytorch v2.
and tensorflow v2.
since they are the two most popular dl libraries and are widely studied in the literature.
for comparison withtable ii number of target apis for p athfinder and the baselines.
p athfinder denotes target apis selected for comparison with the baselines.
pathfinder pathfinder freefuzz deeprel titanfuzz acetest ivysyn pytorch tensorflow ivysyn we use pytorch v1.
which is supported by ivysyn s replication package because it does not support pytorch v2.
target apis .table ii lists the number of target apis used in our experiments.
our test driver generators successfully create test drivers for c apis in pytorch and c apis in tensorflow respectively.
for the comparison evaluation with the baselines we selected pytorch and tensorflow apis denoted as pathfinder in table ii having exact python counterpart apis e.g.
torch nn functional max pool1d in c and torch.nn.functional.max pool1d in python .
we obtained each baseline s target apis from its replication package.
for a fair comparison we extracted those common apis shared by both p athfinder and the baseline.
for example as shown in table ii we collected common pytorch apis shared between p athfinder s and deeprel s target apis.
for freefuzz pytorch we used the same set of target apis from deeprel because it shares the same fuzzing engine as freefuzz and supports a larger set of apis.
for acetest and ivysyn their pytorch target functions indicated by in table ii are internal kernel functions rather than high level apis.
we collected the kernel functions used in the replication packages of acetest and ivysyn and considered those functions for which our driver generator could successfully produce drivers.
in rq1 out of ivysys s targets we used functions that terminate without a crash because ivysyn cannot measure coverage when a crash occurs.
finally we excluded tensorflow for ivysyn because its target internal functions lack the type information required by our driver generator.
d. experimental environment environment .we conducted our experiments on two machines.
for the pytorch experiment we used a machine equipped with intel xeon platinum cpu and nvidia rtx a6000 gpus.
for the tensorflow experiment we used a machine with amd epyc cpu and nvidia rtx a6000 gpus.
we also ensured each fuzzing task was allocated a single cpu core during the experiments.
fuzzing budget .by default we use a minute fuzzing budget per target api.
unlike p athfinder that does not require any preparation process before fuzzing all baseline techniques except ivysyn require additional preparation time.
this includes gathering seed inputs for freefuzz deeprel and titanfuzz or extracting input constraints for acetest .
in this experiment we exclude such preparation time for all baselines from the time budget.
meanwhile we conduct the coverage analysis in rq1 and the ablation study in rq2 five times and report the average number.
s48 s51 s48 s48 s54 s48 s48 s57 s48 s48 s49 s50 s48 s48 s48 s49 s48 s48 s48 s48 s50 s48 s48 s48 s48 s51 s48 s48 s48 s48 s52 s48 s48 s48 s48 s53 s48 s48 s48 s48 s54 s48 s48 s48 s48 s55 s48 s48 s48 s48 s56 s48 s48 s48 s48 s57 s48 s48 s48 s48 s80 s121 s84 s111 s114 s99 s104 s66 s114 s97 s110 s99 s104 s32 s67 s111 s118 s101 s114 s97 s103 s101 s84 s105 s109 s101 s32 s40 s115 s101 s99 s111 s110 s100 s115 s41 s32 s80 s97 s116 s104 s70 s105 s110 s100 s101 s114 s32 s68 s101 s101 s112 s82 s69 s76 a deeprel vs p athfinder s48 s51 s48 s48 s54 s48 s48 s57 s48 s48 s49 s50 s48 s48 s48 s49 s48 s48 s48 s48 s50 s48 s48 s48 s48 s51 s48 s48 s48 s48 s52 s48 s48 s48 s48 s53 s48 s48 s48 s48 s54 s48 s48 s48 s48 s55 s48 s48 s48 s48 s56 s48 s48 s48 s48 s57 s48 s48 s48 s48 s49 s48 s48 s48 s48 s48 s80 s121 s84 s111 s114 s99 s104 s66 s114 s97 s110 s99 s104 s32 s67 s111 s118 s101 s114 s97 s103 s101 s84 s105 s109 s101 s32 s40 s115 s101 s99 s111 s110 s100 s115 s41 s32 s80 s97 s116 s104 s70 s105 s110 s100 s101 s114 s32 s84 s105 s116 s97 s110 s70 s117 s122 s122 b titanfuzz vs p athfinder s48 s51 s48 s48 s54 s48 s48 s57 s48 s48 s49 s50 s48 s48 s48 s49 s48 s48 s48 s48 s50 s48 s48 s48 s48 s51 s48 s48 s48 s48 s52 s48 s48 s48 s48 s53 s48 s48 s48 s48 s54 s48 s48 s48 s48 s55 s48 s48 s48 s48 s56 s48 s48 s48 s48 s57 s48 s48 s48 s48 s80 s121 s84 s111 s114 s99 s104 s66 s114 s97 s110 s99 s104 s32 s67 s111 s118 s101 s114 s97 s103 s101 s84 s105 s109 s101 s32 s40 s115 s101 s99 s111 s110 s100 s115 s41 s32 s80 s97 s116 s104 s70 s105 s110 s100 s101 s114 s32 s70 s114 s101 s101 s70 s117 s122 s122 c freefuzz vs p athfinder s48 s51 s48 s48 s54 s48 s48 s57 s48 s48 s49 s50 s48 s48 s48 s49 s48 s48 s48 s48 s50 s48 s48 s48 s48 s51 s48 s48 s48 s48 s52 s48 s48 s48 s48 s53 s48 s48 s48 s48 s54 s48 s48 s48 s48 s55 s48 s48 s48 s48 s80 s121 s84 s111 s114 s99 s104 s66 s114 s97 s110 s99 s104 s32 s67 s111 s118 s101 s114 s97 s103 s101 s84 s105 s109 s101 s32 s40 s115 s101 s99 s111 s110 s100 s115 s41 s32 s80 s97 s116 s104 s70 s105 s110 s100 s101 s114 s32 s65 s67 s69 s84 s101 s115 s116 d acetest vs p athfinder s48 s51 s48 s48 s54 s48 s48 s57 s48 s48 s49 s50 s48 s48 s48 s49 s48 s48 s48 s48 s50 s48 s48 s48 s48 s51 s48 s48 s48 s48 s52 s48 s48 s48 s48 s53 s48 s48 s48 s48 s80 s121 s84 s111 s114 s99 s104 s66 s114 s97 s110 s99 s104 s32 s67 s111 s118 s101 s114 s97 s103 s101 s84 s105 s109 s101 s32 s40 s115 s101 s99 s111 s110 s100 s115 s41 s32 s80 s97 s116 s104 s70 s105 s110 s100 s101 s114 s32 s73 s118 s121 s83 s121 s110 e ivysyn vs p athfinder fig.
results of rq1 for pytorch bug detection .we manually analyzed each detected bug and identified the unique ones.
in particular we focus on finding crash bugs in our experiments.
vi.
e xperimental results a. rq1 branch coverage analysis to evaluate the effectiveness of p athfinder in exploring diverse program paths we measure branch coverage a common metric for evaluating the effectiveness of test generation tools.
to ensure a fair comparison without bias towards any specific api language i.e.
c or python we measure coverage of only c kernel codes.
the results are shown in figures and where we compare pathfinder with the five baselines mentioned in v b freefuzz deeprel titanfuzz acetest and ivysyn.
the x axis shows the elapsed time in seconds and the y axis shows the number of covered branches across all target apis.
a coordinate x y indicates that at time x ybranches are covered across all target apis.
we repeat the experiment five times for each target api and present the mean results in the figure along with confidence intervals illustrated as shades around the mean line.
as for the time budget we set it to minutes for each pair of a tool and an api of pytorch.
for tensorflow we could not identify a clear winner in the initial minutes so we extended the time budget to minutes.
our results show that p athfinder substantially outperforms all existing state of the art tools we compare with.
we below discuss notable observations from the results.
s48 s54 s48 s48 s49 s50 s48 s48 s49 s56 s48 s48 s50 s52 s48 s48 s51 s48 s48 s48 s51 s54 s48 s48 s48 s49 s48 s48 s48 s48 s50 s48 s48 s48 s48 s51 s48 s48 s48 s48 s52 s48 s48 s48 s48 s53 s48 s48 s48 s48 s84 s101 s110 s115 s111 s114 s70 s108 s111 s119 s66 s114 s97 s110 s99 s104 s32 s67 s111 s118 s101 s114 s97 s103 s101 s84 s105 s109 s101 s32 s40 s115 s101 s99 s111 s110 s100 s115 s41 s32 s80 s97 s116 s104 s70 s105 s110 s100 s101 s114 s32 s68 s101 s101 s112 s82 s69 s76 a deeprel vs p athfinder s48 s54 s48 s48 s49 s50 s48 s48 s49 s56 s48 s48 s50 s52 s48 s48 s51 s48 s48 s48 s51 s54 s48 s48 s48 s49 s48 s48 s48 s48 s50 s48 s48 s48 s48 s51 s48 s48 s48 s48 s52 s48 s48 s48 s48 s53 s48 s48 s48 s48 s54 s48 s48 s48 s48 s55 s48 s48 s48 s48 s84 s101 s110 s115 s111 s114 s70 s108 s111 s119 s66 s114 s97 s110 s99 s104 s32 s67 s111 s118 s101 s114 s97 s103 s101 s84 s105 s109 s101 s32 s40 s115 s101 s99 s111 s110 s100 s115 s41 s32 s80 s97 s116 s104 s70 s105 s110 s100 s101 s114 s32 s84 s105 s116 s97 s110 s70 s117 s122 s122 b titanfuzz vs p athfinder s48 s54 s48 s48 s49 s50 s48 s48 s49 s56 s48 s48 s50 s52 s48 s48 s51 s48 s48 s48 s51 s54 s48 s48 s48 s49 s48 s48 s48 s48 s50 s48 s48 s48 s48 s51 s48 s48 s48 s48 s52 s48 s48 s48 s48 s53 s48 s48 s48 s48 s84 s101 s110 s115 s111 s114 s70 s108 s111 s119 s66 s114 s97 s110 s99 s104 s32 s67 s111 s118 s101 s114 s97 s103 s101 s84 s105 s109 s101 s32 s40 s115 s101 s99 s111 s110 s100 s115 s41 s32 s80 s97 s116 s104 s70 s105 s110 s100 s101 s114 s32 s70 s114 s101 s101 s70 s117 s122 s122 c freefuzz vs p athfinder s48 s54 s48 s48 s49 s50 s48 s48 s49 s56 s48 s48 s50 s52 s48 s48 s51 s48 s48 s48 s51 s54 s48 s48 s48 s49 s48 s48 s48 s48 s50 s48 s48 s48 s48 s51 s48 s48 s48 s48 s52 s48 s48 s48 s48 s53 s48 s48 s48 s48 s54 s48 s48 s48 s48 s55 s48 s48 s48 s48 s84 s101 s110 s115 s111 s114 s70 s108 s111 s119 s66 s114 s97 s110 s99 s104 s32 s67 s111 s118 s101 s114 s97 s103 s101 s84 s105 s109 s101 s32 s40 s115 s101 s99 s111 s110 s100 s115 s41 s32 s80 s97 s116 s104 s70 s105 s110 s100 s101 s114 s32 s65 s67 s69 s84 s101 s115 s116 d acetest vs p athfinder fig.
results of rq1 for tensorflow.
ivysyn is excluded for tensorflow as discussed in v c. pytorch vs. tensorflow .while p athfinder outperforms all baselines its early stage performance for tensorflow is not as good as for pytorch.
this seems related to the fact that tensorflow uses nondeterministic branches more frequently than pytorch.
the average number of nondeterministic branches found in pytorch apis is .
while in tensorflow apis it is .
which is about times larger.
despite the slow start p athfinder eventually covers more branches than the baselines in tensorflow as well and the gap between pathfinder and the baselines widens over time.
unit testing vs. integration testing .unlike p athfinder that tests an individual target api titanfuzz using an llm large language model constructs a sequence of api calls that includes the target api.
this can be viewed as a form of integration testing.
in our experimental results we account for all executed branches whether or not they belong to the target api.
nevertheless p athfinder still outperforms titanfuzz demonstrating the effectiveness of our technique in exploring diverse execution paths.
similar to titanfuzz deeprel tests not only the target api e.g.
adaptiveavgpool3d but also other apis e.g.
adaptivemaxpool3d that are considered functionally similar to the target api.
deeprel effectively reuses the same input to test multiple apis.
p athfinder achieves higher branch coverage than deeprel without exploiting such additional information on api similarity.
note that exploiting api similarity and our efficient path exploration algorithm are orthogonal and combining them could further improve the performance of p athfinder .
fully automatic vs. semi automatic .acetest similar to pathfinder leverages path constraints for input generation.
however unlike p athfinder that infers path condition fully automatically acetest relies on manually defined rules for extracting path constraints.
despite these manual efforts required by acetest p athfinder outperforms for both py s48 s51 s48 s48 s54 s48 s48 s57 s48 s48 s49 s50 s48 s48 s48 s49 s48 s48 s48 s48 s50 s48 s48 s48 s48 s51 s48 s48 s48 s48 s52 s48 s48 s48 s48 s53 s48 s48 s48 s48 s54 s48 s48 s48 s48 s55 s48 s48 s48 s48 s56 s48 s48 s48 s48 s57 s48 s48 s48 s48 s49 s48 s48 s48 s48 s48 s49 s49 s48 s48 s48 s48 s80 s121 s84 s111 s114 s99 s104 s66 s114 s97 s110 s99 s104 s32 s67 s111 s118 s101 s114 s97 s103 s101 s84 s105 s109 s101 s32 s40 s115 s101 s99 s111 s110 s100 s115 s41 s32 s80 s97 s116 s104 s70 s105 s110 s100 s101 s114 s32 s80 s97 s116 s104 s70 s105 s110 s100 s101 s114 s32 s119 s47 s111 s32 s78 s66 s80 s32 s80 s97 s116 s104 s70 s105 s110 s100 s101 s114 s32 s119 s47 s111 s32 s83 s116 s97 s103 s101 s100 a s48 s51 s48 s48 s54 s48 s48 s57 s48 s48 s49 s50 s48 s48 s48 s49 s48 s48 s48 s48 s50 s48 s48 s48 s48 s51 s48 s48 s48 s48 s52 s48 s48 s48 s48 s53 s48 s48 s48 s48 s54 s48 s48 s48 s48 s55 s48 s48 s48 s48 s84 s101 s110 s115 s111 s114 s70 s108 s111 s119 s66 s114 s97 s110 s99 s104 s32 s67 s111 s118 s101 s114 s97 s103 s101 s84 s105 s109 s101 s32 s40 s115 s101 s99 s111 s110 s100 s115 s41 s32 s80 s97 s116 s104 s70 s105 s110 s100 s101 s114 s32 s80 s97 s116 s104 s70 s105 s110 s100 s101 s114 s32 s119 s47 s111 s32 s78 s66 s80 s32 s80 s97 s116 s104 s70 s105 s110 s100 s101 s114 s32 s119 s47 s111 s32 s83 s116 s97 s103 s101 s100 b fig.
results of rq2 on our two optimization strategies nondeterministic branch pruning nbp and staged synthesis torch and tensorflow with the performance gap being particularly significant for pytorch.
this gap is mainly due to the limitation of acetest s incomplete manual rules.
for example its rules cannot handle pytorch s certain code components e.g.
data type check of a tensor like tensor.is complex .
this leaves many branches uncovered by acetest.
although adding new rules could potentially increase coverage so would require significant additional manual efforts.
in contrast p athfinder can achieve high coverage without manual efforts.
rq1 pathfinder achieves higher branch coverage than state of the art dl testing tools demonstrating the effectiveness of our technique in exploring diverse execution paths.
b. rq2 ablation study to evaluate the effectiveness of p athfinder s optimization strategies we conduct an ablation study by comparing pathfinder with two variants p athfinder without nondeterministic branch pruning nbp and p athfinder without staged synthesis.
for this ablation study we use all available target apis for pytorch and tensorflow i.e.
pytorch apis and tensorflow apis see table ii with the 20minute time budget for each target api.
note that if we keep nondeterministic branches without pruning duet the synthesizer we use always fails because the same input appears both in the positive and negative examples.
rather than considering such a clearly inferior variant we here compare p athfinder with an alternative way to handle nondeterministic branches instead of pruning a nondeterministic branch we set true to its condition.
for example in figure if b1is nondeterministic we set c1jb1k totrue while keeping its both branches.
this is different from the original p athfinder which removes b1from the compact prefix tree.
as for disabling staged synthesis we experiment with a variant of p athfinder that directly employs level grammar without attempting level grammar refer to figure for these grammars .
recall that level grammar is simpler than level grammar and it is used in the original p athfinder to quickly find a solution when possible.
figure shows the results.
more branches are covered when pathfinder employs both nbp and staged synthesis than when it does not.
as mentioned tensorflow apis have moretable iii summary of bugs detected by p athfinder dl library total confirmed fixed rejected pytorch tensorflow total table iv type of bugs detected by p athfinder dl librarybug typetotal heap buffer overflowstack overflowsegfault fpeinternal assertion pytorch tensorflow total pathfinder deeprel titanfuzz freefuzz acetest ivysync is nc 1py is c nc nt c is impl nc 1py is c impl nc 16is impl is impl nc 19is impl a pytorch pathfinder deeprel titanfuzz freefuzz acetestnc py is impl nt 1nc py nt nc py is impl c nc py is impl b tensorflow fig.
bugs detected by p athfinder and baselines nondeterministic branches than pytorch apis which explains why nbp is more effective in tensorflow than in pytorch.
rq2 pathfinder performs better when both optimization strategies nondeterministic branch pruning and staged synthesis are employed than when either is omitted.
this demonstrates the effectiveness of our optimization strategies.
c. rq3 bug detection analysis table iii summarizes the statistics of bugs detected by pathfinder .
for this experiment we use all available target apis for pytorch and tensorflow in our benchmark.
pathfinder detected bugs with of them confirmed as previously unknown by developers.
among these confirmed bugs have been fixed.
two bug reports were rejected as false alarms.
notably for of the fixed bugs patches were applied in the kernel functions which demonstrates that pathfinder effectively explores deep and diverse execution paths.
besides table iv presents the distribution of different types of bugs for all confirmed bugs.
segfault and fpe refer to segmentation fault and floating point exception respectively.
the results show that p athfinder detects various types of severe bugs such as heap buffer overflow and stack overflow which might also lead to security vulnerabilities.
figure presents the comparison results with the baselines.
for the comparison we consider the set of common targettable v total number of inputs generated by each tool and their valid input rates.
dl lib pytorch tensorflow tool freefuzz ours acetest ours deeprel ours titanfuzz ours ivysyn ours freefuzz ours acetest ours deeprel ours titanfuzz ours total k k k k k k k k k k k k k k k k k k valid k k k k k k k k k k k k k k k k k k ratio .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
branch apis and kernel functions listed in table ii for each baseline.
for fair analysis we use the top frame information of a crash s stack trace.
we consider a crash as the same bug if the top frame of that crash is identical to that of the compared tool.
the results of figure show that p athfinder detects significantly more unique bugs than the compared tool pathfinder uniquely detects bugs for pytorch and for tensorflow while it misses only bugs for pytorch and for tensorflow .
we further analyze why those unique bugs have been missed by the compared tool i.e.
other tools for p athfinder and pathfinder for other tools .
we classified them into five categories nc c py is impl and nt and tagged in figure .
nc happens when the crash point is not covered by the compared tool due to its limited code coverage.
this is the most common category for the unique bugs detected by p athfinder which demonstrates p athfinder s high path exploration capability.
c pyincludes language specific bugs that are manifested exclusively in either the c or python api.
these bugs occur due to the inconsistent implementation between the c and python apis even though both are designed to function identically in principle as shown in figure .
isrefers to those bugs missed by the compared tool due to its limited input space.
for instance despite pathfinder s high path exploration capability it misses bugs arising from edge cases e.g.
extreme values existing the outside of the input space defined in table i. similarly deeprel freefuzz and ivysyn did not generate rarely used inputs in practice e.g.
quantized integers .
impl includes those bugs missed by the compared tool due to its limitation of implementation design.
for example p athfinder deeprel freefuzz and ivysyn terminate their fuzzing campaign upon encountering a crash preventing further discovery of additional bugs within the same api.
finally ntrefers to bugs located in non target apis.
as discussed in vi a deeprel and titanfuzz construct a sequence of apis so pathfinder cannot detect bugs that are executed exclusively by the compared tool.
rq3 pathfinder is highly effective in detecting severe bugs that require deep program exploration particularly within kernel functions and detects significantly more unique bugs that are not detected by the baselines.
vii.
d iscussion and threats to validity a. comparison with greybox fuzzing and concolic testing we have shown p athfinder s effectiveness for testing dl libraries it outperforms existing state of the art tools for dl s48 s51 s48 s48 s54 s48 s48 s57 s48 s48 s49 s50 s48 s48 s48 s49 s48 s48 s48 s48 s50 s48 s48 s48 s48 s51 s48 s48 s48 s48 s52 s48 s48 s48 s48 s53 s48 s48 s48 s48 s54 s48 s48 s48 s48 s55 s48 s48 s48 s48 s56 s48 s48 s48 s48 s57 s48 s48 s48 s48 s49 s48 s48 s48 s48 s48 s80 s121 s84 s111 s114 s99 s104 s66 s114 s97 s110 s99 s104 s32 s67 s111 s118 s101 s114 s97 s103 s101 s84 s105 s109 s101 s32 s40 s115 s101 s99 s111 s110 s100 s115 s41 s32 s80 s97 s116 s104 s70 s105 s110 s100 s101 s114 s32 s108 s105 s98 s102 s117 s122 s122 s101 s114 s32 s69 s99 s108 s105 s112 s115 s101 s114fig.
branch coverage of p athfinder compared with greybox fuzzing libfuzzer and concolic testing eclipser library testing.
in this section we discuss how p athfinder compares with greybox fuzzing and concolic testing two representative non blackbox testing techniques.
for greybox fuzzing we used libfuzzer a well known greybox api fuzzer.
for concolic testing we used eclipser the only concolic execution based tool that we could successfully run on pytorch.
eclipser is a state of the art binary based fuzzing tool that iterates between concolic testing and greybox fuzzing outperforming klee in terms of code coverage .
we ran p athfinder libfuzzer and eclipser on c apis of pytorch denoted as p athfinder in table ii with a minute time budget.
figure shows the results.
p athfinder substantially outperforms both eclipser and libfuzzer.
the poor performance of eclipser seems to be due to the slow runtime a typical drawback of concolic testing.
while libfuzzer performs better than eclipser it still lags behind p athfinder .
this result suggests that p athfinder s path exploration guided by path conditions is more effective than the conventional coverage guided approach of libfuzzer.
despite being guided by coverage feedback greybox fuzzing struggles to exercise new branches when code coverage does not change over input mutations.
this means that coverage feedback is only useful when the mutated input explores a new execution path.
in contrast p athfinder generates inputs capable of penetrating an approximate branch condition and exploring new paths.
b. input validity we have shown throughout the paper that p athfinder achieves substantially higher branch coverage than state ofthe art tools.
p athfinder achieves such outstanding performance despite the fact that our technique is agnostic to input validity our path condition synthesis technique does not aim to rule out invalid inputs but aims to explore diverse paths.
table v shows how many inputs each tool generated total the percentage of valid inputs valid and ratio and the number of covered branches branch .
we observe p athfinder covers more branches than the other tools even when its valid input ratio is lower.
this result suggests the effectiveness of fuzzing tools is not solely determined by the ratio of valid inputs.
p athfinder s ability to generate inputs that explore diverse execution paths appears to be a more critical factor in achieving high branch coverage.
c. threats to validity generality.
there is a potential threat to the generality of our approach.
to address this we evaluated p athfinder on the two most representative dl libraries pytorch and tensorflow which are widely used in literature.
bug detection.
when counting new bugs detected by pathfinder and the baselines we ensured all detected bugs were reproducible.
additionally in our experiments we only consider crashes as bugs and do not consider non crash bugs such as computation bugs.
these bugs may be detected with differential testing used in prior work .
viii.
r elated work a. deep learning library fuzzing api level fuzzing.
freefuzz mines usage examples of dl apis from open source and mutates inputs based on the observed values in the wild.
deeprel and tensorscope extract related apis within the same library and counterpart apis across different libraries respectively and borrow test inputs from other apis to generate inputs for target apis.
titanfuzz and fuzzgpt leverage large language models to generate a valid api sequence involving a target api s invocation.
ivysyn performs type aware mutation based fuzzing on kernel code.
docter and acetest extract input constraints for each api parameter to generate inputs that pass the input validity checks.
they focus on extracting input constraints before the fuzzing phase and perform fuzzing by generating random inputs satisfying those constratins.
although all the aforementioned techniques have shown effectiveness in testing dl library apis they either perform blackbox fuzzing without considering the internal source code or requires manually annotated rules to derive input preconditions or path conditions .
in contrast our technique leverages execution path feedback during input generation and does not require manual efforts.
model level fuzzing.
model level dl library or compiler testing aims to detect integration bugs of dl operators by testing computation graphs.
earlier studies directly use or mutate existing trained models.
recent research generates computational graphs for fuzzing to cover more dl operators.
these newer approaches handle constraints between computation nodes by either inserting reshape operators using handcrafted specification leveraging program synthesis or generating dl modelswith diverse layer api calls .
our work performs apilevel fuzzing and focuses on fuzzing a single api in isolation to thoroughly test and explore diverse api behaviors.
b. concolic testing concolic testing has been extensively studied for decades .
our work relates to those techniques that are aimed at addressing the overhead from heavyweight instrumentation and complex constraint solving challenges associated with concolic testing.
one well established strategy for addressing this challenge is hybrid fuzzing which combines concolic testing with greybox fuzzing .
this approach mitigates the overhead issue by reducing the computational cost through the alternating use of concolic testing and greybox fuzzing.
in contrast p athfinder addresses this overhead issue in a fundamentally different way.
first p athfinder does not require symbolic execution to obtain path conditions thus it eliminates the need for heavyweight instrumentation.
instead p athfinder requires as light instrumentation as greybox level to track executed branches.
additionally pathfinder mitigates the constraint solving overhead by using approximate path conditions rather than exact ones.
this trade off between precision and efficiency proves to be effective as demonstrated by our experimental results in fuzzing deep learning libraries.
ix.
c onclusion this paper presents a novel lightweight concolic testing technique for deep learning dl libraries.
unlike previous techniques that perform blackbox fuzzing without considering the internal structure of the program under test during input generation our approach explores diverse execution paths by inferring approximate path conditions.
while traditional concolic testing requires heavy overhead for maintaining and interpreting symbolic expressions along the execution path our technique quickly synthesizes branch conditions based on the observed behaviors of program executions.
the evaluation of our tool p athfinder on pytorch and tensorflow shows that p athfinder significantly outperforms existing api level dl fuzzing techniques by achieving higher branch coverage and detecting more unique bugs.
p athfinder found new crash bugs of which were confirmed by developers.
acknowledgement we thank the anonymous reviewers for their invaluable feedback.
this work is supported by the national research foundation of korea nrf grants funded by the korea government msit no.
rs nr069867 rs nr066503 rs nr064479 rs nr060080 and the institute for information communications technology planning evaluation iitp grants funded by the korea government msit no.
rs rs rs2020 ii201336 .