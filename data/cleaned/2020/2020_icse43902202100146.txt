pycg practical call graph generation in python vitalis salis xythodoris sotiropoulos xpanos louridas xdiomidis spinellisxand dimitris mitropoulosxz xathens university of economics and business ynational technical university of athens znational infrastructures for research and technology grnet vitsalis gmail.com ftheosotr louridas dds dimitrog aueb.gr abstract call graphs play an important role in different contexts such as profiling and vulnerability propagation analysis.
generating call graphs in an efficient manner can be a challenging task when it comes to high level languages that are modular and incorporate dynamic features and higher order functions.
despite the language s popularity there have been very few tools aiming to generate call graphs for python programs.
worse these tools suffer from several effectiveness issues that limit their practicality in realistic programs.
we propose a pragmatic static approach for call graph generation in python.
we compute all assignment relations between program identifiers of functions variables classes and modules through an inter procedural analysis.
based on these assignment relations we produce the resulting call graph by resolving all calls to potentially invoked functions.
notably the underlying analysis is designed to be efficient and scalable handling several python features such as modules generators function closures and multiple inheritance.
we have evaluated our prototype implementation which we call pycg using two benchmarks a micro benchmark suite containing small python programs and a set of macrobenchmarks with several popular real world python packages.
our results indicate that pycg can efficiently handle thousands of lines of code in less than a second .
seconds for 1k loc on average .
further it outperforms the state of the art for python in both precision and recall pycg achieves high rates of precision .
and adequate recall .
.
finally we demonstrate how pycg can aid dependency impact analysis by showcasing a potential enhancement to github s security advisory notification service using a real world example.
index terms call graph program analysis inter procedural analysis vulnerability propagation i. i ntroduction a call graph depicts calling relationships between subroutines in a computer program.
call graphs can be employed to perform a variety of tasks such as profiling vulnerability propagation and tool supported refactoring .
generating call graphs in an efficient way can be a complex endeavor especially when it comes to high level dynamic programming languages.
indeed to create precise call graphs for programs written in languages such as python and javascript one must deal with several challenges including higherorder functions dynamic and metaprogramming features e.g.
eval and modules.
addressing such challenges can play a significant role in the improvement of dependency impact analysis especially in the context of package managers such as npm and pip .
to support call graph generation in dynamic languages researchers have proposed different methods relying on staticanalysis.
the primary aim for many implementations is completeness i.e.
facts deduced by the system are indeed true .
however for dynamic languages completeness comes with a performance cost.
hence such approaches are rarely employed in practice due to scalability issues .
this has led to the emergence of practical approaches focusing on incomplete static analysis for achieving better performance .
sacrificing completeness is the key enabler for adopting these approaches in applications that interact with complex libraries or integrated development environments ides .
prior work primarily targets javascript programs and among other things attempts to address challenges related to events and the language s asynchronous nature .
despite python s popularity there have been surprisingly few tools aiming to generate call graphs for programs written in the language.
pyan parses the program s abstract syntax tree ast to extract its call graph.
nevertheless it has drawbacks in the way it handles the inter procedural flow of values and module imports.
code2graph visualizes pyan constructed call graphs so it has the same limitations.
depends infers syntactical relations among source code entities to generate call graphs.
however functions assigned to variables or passed to other functions are not handled by depends thus it does not perform well in the context of a language supporting higher order programming.
we will expand on the shortcomings of the existing tools in the remainder of this work.
that said developing an effective and efficient call graph generator for a dynamically typed language like python is no minor task.
we introduce a practical approach for generating call graphs for python programs and implement a corresponding prototype that we call pycg.
our approach works in two steps.
in the first step we compute the assignment graph a structure that shows the assignment relations among program identifiers.
to do so we design a context insensitive inter procedural analysis operating on a simple intermediate representation targeted for python.
contrary to the existing static analyzers our analysis is capable of handling intricate python features such as higher order functions modules function closures and multiple inheritance.
in the next step we build the call graph of the original program using the assignment graph.
specifically we utilize the graph to resolve all functions that can be potentially pointed to by callee variables.
such a programming pattern is particularly common in higher order programming.
ieee acm 43rd international conference on software engineering icse .
ieee similar to previous work our analysis follows a conservative approach meaning that the analysis does not reason about loops and conditionals.
to make our analysis more precise especially when dealing with features like inheritance modules or programming patterns such as duck typing we distinguish attribute accesses i.e e x based on the namespace where the attribute x is defined.
prior work uses a fieldbased approach that correlates attributes of the same name with a single global location without taking into account their namespace .
this leads to false positives.
our design choices make our approach achieve high rates of precision while remaining efficient and applicable to large scale python programs.
we evaluate the effectiveness of our method through a micro and a macro benchmarking suite.
also we compare it against pyan and depends .
our results indicate that our method achieves high levels of precision .
and adequate recall .
on average while the other analyzers demonstrate lower rates in both measures.
our method is able to handle medium sized projects in less than one second .
seconds for 1k loc on average .
finally we show how our method can accommodate the fine grained tracking of vulnerable dependencies through a real world case study.
contributions.
our work makes the following contributions.
we propose a static approach for pragmatic call graph generation in python.
our method performs inter procedural analysis on an intermediate language that records the assignment relations between program identifiers i.e.
functions variables classes and modules.
then it examines the documented associations to extract the call graph section iii .
we develop a micro benchmark suite that can be used as a standard to evaluate call graph generation methods in python.
our suite is modular easily extendable and covers a large fraction of python s functionality related to classes generators dictionaries and more section v a1 .
we evaluate the effectiveness of our approach through our micro benchmark and a set of macro benchmarks including several medium sized python projects.
in all cases our method achieves high rates of precision and recall outperforming the other available analyzers sections v b v c .
we demonstrate how our approach can aid dependency impact analysis through a potential enhancement of github s security advisory notification service section v e .
availability.
pycg is available as open source software under the apache .
licence at the research artifact is available at .
ii.
b ackground generating precise call graphs for python programs involves several challenges.
existing static approaches fail to address these challenges leaving opportunities for improvement.1import cryptops 3class crypto def init self key self .key key def apply self msg func return func self .key msg 10crp crypto secretkey 11encrypted crp.apply hello world cryptops .encrypt !
12decrypted crp.apply encrypted cryptops .decrypt !
fig.
the crypto module.
existing tools fail to generate a corresponding call graph effectively.
a. challenges higher order functions in a high level language such as python functions can be assigned to variables passed as parameters to other functions or serve as return values.
nested definitions function definitions can be nested meaning that a function can be defined and invoked within the context of another function.
classes as an object oriented language python allows for the creation of classes that inherit attributes and methods from other classes.
the resolution of inherited methods from parent classes requires the computation of the method resolution order mro of each class.
modules python is highly extensible allowing applications to import different modules.
keeping track of the different modules that are imported in an application as well as the resolution order of those imports can be a challenging task.
dynamic features python is dynamically typed allowing variables to take values of different types during execution.
also it allows for classes to be dynamically modified during runtime.
furthermore the eval function allows for a dynamically constructed string to be executed as code.
duck typing duck typing is a programming pattern that is particularly common in dynamic languages such as python .
through duck typing the suitability of an object is determined by the presence of specific methods and properties rather than the type of the object itself.
in this context given a method defined by two or more classes it is not trivial to identify its origins when it is invoked.
b. limitations of existing static approaches we focus on two open source static analyzers pyan anddepends .
we do not examine code2graph separately as it is based on pyan to generate call graphs.
we discuss the limitations of the two existing analyzers in terms of efficiency and practicality.
to do so we introduce a small python module named crypto see figure which is used to encrypt and decrypt a hello world message.
first it imports an external python module named cryptops which defines two functions namely encrypt key msg and decrypt key msg .
then the crypto class is defined.
to use it we instantiate it with an encryption key and we can encrypt or decrypt messages by calling apply self 1647cryptocrypto.crypto.
init crypto.crypto.applycryptops.encryptcryptops.decrypt a precise call graph.
cryptocrypto.cryptocrypto.crypto.
init crypto.crypto.applycryptops b pyan generated call graph.
cryptocrypto.crypto.apply c depends generated call graph.
fig.
call graphs for the crypto module.
msg func where func is one of encrypt key msg anddecrypt key msg .
figure 2a shows the call graph of the module.
pyan produces the imprecise call graph shown in figure 2b.
this graph does not contain all function calls because the tool does not track the inter procedural flow of values.
therefore it is unable to infer which functions are passed as arguments to apply self msg func .
in addition there are several features that lead to the addition of unrealized call edges.
specifically when pyan detects object initialization it creates call edges to both the class name and the init method of the class.1beyond that in the case of a module import pyan generates a call edge from the importing namespace to the module name.
depends produces the call graph presented in figure 2c.
depends does not track function calls originating from the module s namespace e.g.
crp.apply .
this in turn led to an empty call graph.
therefore to get a result we wrapped those function calls within a new function.
the resulting graph does not contain most of the calls included in the source program.
this is because depends does not capture the call to the init function of the crypto class.
furthermore like pyan depends does not track the interprocedural flow of functions leading to missing edges to the parameter functions.
compared to pyan depends follows a more conservative approach.
that is it only includes a call edge when it has all the necessary information it needs to anticipate that the call will be realized.
contrary to pyan this can lead to a call graph without false positives.
iii.
p ractical call graph generation our approach for generating call graphs employs a contextinsensitive inter procedural analysis operating on an intermediate representation of the input python program.
the analysis uses a fixed point iteration algorithm and gradually builds the assignment graph which is a structure that shows the assignment relations between program identifiers section iii a .
in a language supporting higher order programming the assignment graph is an essential component that we use for resolving functions pointed to by variables.
function resolution takes place at the final step where we build the 1in python init is the name of a special function called during object construction.e2expr ojxjx ejfunction x y. .
.
ejreturn ej e x e. .
.
jclass x y. .
.
eje.xje.x ej new x y e jimport xfrom masyj iterxje e o2obj n v v2de nition x 2identtype funcjvarjclsjmod n2namespace v x y2identi er is the set of program identifiers m2modules is the set of modules e jx ejreturn eje x e j o x e jnew x y e je.xje.x ej o.x ejiteroje ejo e fig.
the syntax for representing the input python programs along with the evaluation contexts.
call graph for the given program by exploiting the assignment graph stemming from the analysis step section iii b .
a. the core analysis the starting point of our approach is to compute the assignment graph using an inter procedural analysis working on an intermediate representation targeted for python programs.
one of the key elements of our analysis is that it examines attribute accesses based on the namespace where each attribute is defined.
for example consider the following code snippet 1class a def func pass 5class b def func pass 9a a 10b b 11a.func 12b.func our analysis is able to distinguish the two functions defined at lines and because they are members of two different classes i.e.
class aandbrespectively.
note that field based approaches focused on javascript will fail to treat the two invocations as different causing imprecision.
that is because a field based approach will match all accesses of identical attribute names e.g.
func with a single object.
syntax the intermediate representation where our analysis works on follows the syntax of a simple imperative and 2assigng obj !p obj s2scope de nition !p de nition h2classhier obj !obj 2state assigng scope namespace classhier fig.
domains of the analysis.
object oriented language which is shown in figure .
the last rule in this figure also shows the evaluation contexts for this language which we will explain shortly.
an important element of this model language is identifiers.
every identifier can be one of the following four types func corresponding to the name of a function var indicating the name of a variable clsfor class names and mod when the identifier is a module name.
every pair x 2identi er identtype forms a definition.
we represent every definition and its namespace as an object see theobj rule .
a namespace is a sequence of definitions and it is essential for distinguishing objects sharing the same identifier from each other.
for example consider the following python code fragment located in a module named main .
1var 2class a var the analysis distinguishes the objects created at lines and as the first one resides in the namespace while the second one lives in the namespace .
our approach treats every object as the value given from the evaluation of the expressions supported by the language.
in particular our representation contains expressions that capture the inter procedural flow assignment statements class and function definitions module imports and iterators generators see the expr rule .
note that the language is able to abstract different features including lambda expressions keyword arguments constructors multiple inheritance and more.
as with prior work focusing on javascript we use evaluation contexts that describe the order in which sub expressions are evaluated.
for example in an attribute assignment e x e theesymbol denotes that we are currently evaluating the receiver of the attribute x while o x eindicates that the receiver has been already evaluated to an object o2obj recall that evaluating expressions results in objects and the evaluation now proceeds to the right hand side of the assignment.
remarks.
when calling python functions that produce a generator i.e.
they contain a yield statement instead of return these calls take place only when the generator is actually used.
to model this effect when encountering such lazy calls e.g.
gen lazy call x we create a thunk e.g.
gen lambda lazy call x that is evaluated only when we iterate the generator through the iter construct .
furthermore dictionaries and lists are treated as regular objects.
for example we model a dictionary lookup x as an attribute access x key .
state after converting the original python program to our intermediate representation our analysis starts evaluating each expression and gradually constructs the assignment graph.
to do so the analysis maintains a state consistingof four domains as shown in figure namely scope class hierarchy assignment graph and current namespace .
a scope is a map of definitions to a set of definitions.
conceptually a scope is a tree where each node corresponds to a definition e.g.
a function and each edge shows the parent child relations between definitions i.e.
the target node is defined inside the definition of the source node.
the domain of scopes is useful for correctly resolving the definitions that are visible inside a specific namespace.
figure 5a illustrates the scope tree of the program depicted in figure and shows all program definitions and their inter relations.
orange nodes correspond to module definitions red nodes are class definitions black nodes indicate functions while blue nodes denote variables.
based on this scope tree we infer that the function apply is defined inside the class crypto which is in turn defined inside the module crypto i.e.
notice the path crypto!crypto!apply .
this domain enables us to properly deal with python features such as function closures and nested definitions.
a class hierarchy is a tree representing the inheritance relations among classes.
an edge from node uto nodev indicates that the class uis a child of the class v. the analysis uses this domain for resolving class attributes either methods or fields defined in the base classes of the receiver object.
through this domain we are able to handle the objectoriented nature of python addressing features such as multiple inheritance and the method resolution order.
the assignment graph is defined as a map of objects to an element of the power set of objects p obj .
this graph holds the assignment relations between objects capturing the assignments and the inter procedural flow of the program.
figure 5b illustrates the assignment graph corresponding to the program of figure .
each node in the graph e.g.
fcrypto.crypto.apply func g represents an object.
the first component of the node label e.g.
crypt.crypto.apply indicates the namespace where each identifier e.g.
func is defined.
colors reveal the type of the identifier as explained in a previous paragraph e.g.
the blue color implies variable definitions .
an edge shows the possible values that a variable may hold.
for example the variable func defined in the crypto.crypto.apply namespace may point to the functions decrypt and encrypt both defined in the cryptops namespace.
as another example notice the edge originating from the nodefcrypto.crypto.apply msg gand leading to fcrypto encrypted g. this edge shows that the parametermsg of the function crypto.crypto.apply points to the variable encrypted when the function is invoked on line .
the assignment graph domain enables us to address the challenge regarding higher order programming in python.
finally we use the current namespace to track the location where new variables classes modules and functions are defined.
this domain is important for establishing a more precise analysis than field based analysis employed by prior work.
through namespaces objects and attribute accesses are distinguished based on their namespace addressing challenges 1649cryptocryptopscrpencrypteddecryptedcryptoselfselfkeymsgfunc init apply a the scope tree of the crypto module.
cryptopscrypto crpcryptops encryptcryptops decryptcrypto.crypto.apply msg cryptops.encrypt virt ret cryptops.decrypt virt ret crypto.crypto.apply virt ret crypto encryptedcrypto.crypto.apply funccrypto cryptops crypto cryptocrypto decrypted b the assignment graph of the crypto module.
fig.
analyzing the crypto module.
such as duck typing.
analysis rules the analysis examines every expression found in the intermediate representation of the initial program and transitions the analysis state according to the semantics of each expression.
the algorithm repeats this procedure until the state converges and the assignment graph is given by the final state of the analysis.
figure demonstrates the state transition rules of our analysis.
the rules follow the form h s n h e i!h s0 n0 h0 e i in the following we describe each rule in detail.
according to the rule when we have an expression ein the evaluation context e an assignment graph a scope s a namespace n a class hierarchy h we can get an expression e0in the evaluation context e if the initial expression e evaluates to e0.
for what follows the binary operation x y stands for appending the element yto the listx.
the rule states that when we have a compound expression consisting of two objects o1 o2 we return the last object o2as the result of the evaluation.
observe that the evaluation of the compound expression requires each subterm to have been evaluated to an object according to the evaluation contexts shown in figure .
the rest of the rules also follow this behavior.
the rule describes the scenario when the initial expression is an identifier x. in this case the analysis retrieves the objectocorresponding to the identifier x in the namespace n based on the scope tree s. to do so the analysis uses the function getobject s n x which iterates every element yof the namespace nin the reverse order.
then by examining the scope tree s it checks whether the element node yhas any child matching the identifier x. in case of a mismatch the function getobject proceeds to the next element of the namespace.
notice that the rule does not have any side effect on the analysis state.
the rule assigns the object oto the identifierx.
first the analysis adds the identifier xin the current namespace nof the scope tree s using the function addscope s n x .
this function adds an edge from thenode accessed by the path nto the target node given by the definition x .
second this rule updates the assignment graph by adding an edge from the object corresponding to the left hand side of the assignment i.e.
o0 to that of the righthand side i.e.
o .
this update says that the variable xdefined in the namespace ncan point to the object o. updates the scope tree.
in particular it adds the functionxto the current namespace n leading to a new scope trees0.
then it creates a new namespace n0by adding the function definition x func to the top of the current namespace.
it adds all function parameters and a virtual variable named ret which stands for the variable holding the return value of the function to the newly created namespace n0.
this results in a new scope tree s .
finally the analysis proceeds to the evaluation of the body of the function xin the fresh namespace n0 i.e.
observe that the rule evaluates toe .
the new namespace n0correctly captures that any variable defined in e is actually defined in the body of the function.
assigns the object oto the virtual variable ret which is used for storing the return value of a function recall the rule .
to do so the analysis updates the assignment graph by adding a new edge from the object o0corresponding to the return variable ret to the object owhich is the operand ofreturn .
finally this rule evaluates to the object o0related to the return virtual variable ret.
the inter procedural flow is captured by the rule.
specifically when we encounter a call expression o1 y o2 we examine the callee object o1associated with a function fdefined in a namespace n0.
then the rule connects every parameter of fwith the appropriate argument passed during function invocation e.g.
the counterpart object of the parameter yat call site is o2 leading to a new assignment graph .
as an example consider again the graph of figure 5b.
the outgoing edges of the fcrypto.crypto.apply func gnode are created by this rule.
these edges imply that the parameter func of the crypto.crypto.apply function may hold the functions cryptops.encrypt andcryptops.decrypt passed when calling crypto.crypto.apply figure .
1650e ctx h s n h ei !h s0 n0 h0 e0i h s n h e i!h s0 n0 h0 e i compound h s n h e i!h s n h e i ident o getobject s n x h s n h e i!h s n h e i assign s0 addscope s n x var o0 n x var h s n h e i!h s0 n h e i func s0 addscope s n x func n0 n x func s00 addscope s0 n0 ret var s addscope s00 n0 y var h s n h e i!h s n0 h e i return o0 n x ret var h s n x h e i!h s n h e i call o1 n0 f func o0 n0 f y var o0 !
o0 h s n h e i!h s n h n0 f ret var i class s0 addscope s n x cls t hgetobject s n b jb2 y i h0 h n0 n x cls h s n h e i!h s0 n0 h0 e i attr o0 getclassattrobject o x h h s n h e i!h s c h e i new o3 getobject s n x o2 getclassattrobject o3 init h h s n h e i!h s n h e i attr assign o3 getclassattrobject o1 x h h s n h e i!h s n h e i import o2 getobject s m x s0 addscope s n y var o1 n y var h s n h e i!h s0 n h e i iter iterable o0 getclassattrobject o next h h s n h e i!h s n h e i iter generator getclassattrobject o next h undefined h s n h e i!h s n h e i fig.
rules of the analysis.
the rule handles class definitions.
the rule first adds the class xto the scope tree through the function addscope and then gets every object related to the base classes ofx i.e.
y .
to achieve this the rule consults the scope tree in the namespace n and gets a sequence of objectstthat respects the order in which base classes are passed during class definition.
we later explain why keeping the registration order of base classes is important.
the rule then updates the class hierarchy so that the freshly defined class xis a child of the base classes pointed to by the identifiers y .after this the analysis works on the body of the class ein a new namespace n0.
the new namespace contains the class definition to the top of the current namespace i.e.
n x cls .
then the analysis starts examining the body of the class using the new namespace.
the rule is similar to .
however this time in order to correctly retrieve the object corresponding to the attribute xof the receiver object o the analysis examines the hierarchy of classes hthrough the function getclassattrobject o x h .
this is the point where our analysis is able to distinguish attributes according to the location i.e.
o where they are defined.
to deal with multiple inheritance the function getclassattrobject respects the method resolution order implemented in python.
for example consider the following code snippet.
1class a def func pass 5class b def func pass 9class c b a pass 12c c 13c.func in the example above the method resolution order is c!
b!a because the class bis the first parent class of c while ais the second one.
as a result c.func leads to the invocation of function func defined in class b as it is the first matching function whose name is func in the method resolution order.
correctly resolving class members explains why the domain of the class hierarchy maps every object to asequence of objects rather than a set we need to track the order in which the parents of a class are registered.
for object initialization we introduce the rule.
this rule gets the object o3associated with the definition of the classx.
using the getclassattrobject function the rule inspects the method resolution order of the object o3to find the first object o2matching the function init .
recall that this function is called whenever a new object is created.
observe how the new evaluates it reduces to o2 y o1 o3.
that is we first call the constructor of the class with the same arguments passed as in the initial expression i.e.
o2 y o1 and then we return the object o3 corresponding to the class definition which is eventually the result of the new expression.
the rule for attribute assignment o1 x o2describes the case when the attribute xis defined somewhere in the class hierarchy of the receiver object o1.
in this case getclassattrobject returns the object o3associated with this attribute and the rule updates the assignment graph so thato3points to the object o2from the right hand side of the assignment.
if the attribute is not defined in the class hierachy i.e.
getclassattrobject returns?
the attribute assignment is similar to i.e.
we first add 1651algorithm call graph construction input p2program 2state output cg2callgraph 1foreacheinprogram do whilee62obj do 3h e i!h e i ife0 o1 y o2 then call expression s n f h c getreachablefuns o1 o3 getobject s n f cg cg add call edges end 10e e0 end 12end 13return cg the attribute xto the current scope through addscope and then update the graph.
this case is omitted for brevity.
when we encounter an importxfrommasyexpression we retrieve the object o2corresponding to the imported identifier x which is defined in the module m. then we create an alias yforx.
to do so we add yto the scope tree of the current namespace and update the assignment graph by adding an edge from the object of yto that ofx.
through this rule we are able to deal with python s module system.
consuming iterables and generators is supported through the iterxexpression.
when the identifier xpoints to an iterable i.e.
the object pointed to by xhas an attribute named next we get the object o0related to next .
then iterevaluates to a call of o0 see the rule .
if this is not the case we treat xas a generator iter generator .
in this case iterreduces to a call of x .
recall from section iii a1 that we model generators as thunks therefore this scenario describes the evaluation of these thunks generators when they are actually used iterated .
remark about analysis termination.
the analysis traverses expressions and transitions the analysis state based on the rules of figure until the state converges.
the analysis is guaranteed to terminate because the domains are finite.
even in the presence of the domain of class hierarchy h2classhier figure which is theoretically infinite the analysis eventually terminates because a python program cannot have an unbounded number of classes.
b. call graph construction after the termination of the analysis we build the call graph by performing a final pass on the intermediate representation of the given python program.
algorithm describes the details of this pass.
the algorithm takes two elements as input a programp2program of the model language whose syntax is shown in figure and the final state 2state stemming from the analysis step.
the algorithm produces a call graph cg2callgraph obj !p obj the graph contains only objects associated with functions.
an elemento2obj mapped to a set of objects t2 p obj means that the function omay call any function included in t. the algorithm inspects every expression efound in the program line and it evaluates ebased on the state transition rules described in figure .
the algorithm repeats the state transition rules until eeventually reduces to an object lines .
every time when ereduces to a call expression of the formo1 y o2 line the algorithm gets the namespace where this invocation happens and retrieves the top element of that namespace see n f line .
after that the algorithm gets all functions that the callee object o1may point to.
to do so it consults the assignment graph through the function getreachablefuns o which implements a simple depth first search dfs algorithm and gets the set of functionscthat are reachable from the source node o1.
in turn the algorithm updates the call graph cgby adding all edges from the top element of the current namespace to the set of the callee functions c lines .
in other words the object o3 line representing the top element of the namespace where the call occurs is actually the caller of the functions pointed to by the object o1.
c. discussion limitations one of our major design decisions is to ignore conditionals and loops.
for instance when we come across an ifstatement our analysis over approximates the program s behavior and considers both branches.
this design choice enables efficiency without highly compromising the analysis precision as we will discuss in section v .
other static analyzers choose to follow a more heavyweight approach and reason about conditionals.
these static analyzers though do not solely focus on call graph construction but rather they attempt to compute the set of all reachable states based on an initial one.
however for call graph generation providing such an initial state that exercises all feasible paths which is required in order to compute a complete call graph especially when analyzing libraries is not straightforward.
in python where object oriented features duck typing and modules are extensively used it is important to separate attribute accesses based on the namespace where each attribute is defined.
this design choice boosts contrary to prior work the precision of our analysis without sacrificing its scalability.
our analysis does not fully support all of python s features.
first we ignore code generation schemes such as calls to the eval built ins.
in general such dynamic constructs hinder the effectiveness of any static analysis and dynamic approaches are often employed as a countermeasure .
second our approach does not store information about variables builtin types and does not reason about the effects of built in functions.
therefore attribute calls that depend on a specific built in type e.g.
list.append are not resolved while the effects of functions such as getattr andsetattr are ignored.
third we can only analyze modules for which their source code has been provided.
when a function for which 1652its code definition is not available is called our method will add an edge to the function but no edges stemming from that function will ever be added and its return value will be ignored.
iv.
i mplementation we have developed pycg a prototype of our approach in python .
for each input module our tool creates its scope tree and its intermediate representation by employing thesymtable and ast modules respectively.
our prototype discovers the file locations of the different imported modules to further analyze them by using python s importlib module.
this is the module that python uses internally to resolve import statements.
we perform two steps.
first the file location of the imported module is identified and then a loader is used to import the module s code.
in python one can define custom loaders for import statements which allowed us to use a loader that logs the file locations discovered and then exit without loading the code.
then in the second step our tool takes over and uses the discovered file s contents to iterate its intermediate representation in a recursive manner.
this allows us to resolve imports in an efficient way.
currently we only analyze discovered modules that are contained in the package s namespace.
v. e valuation we evaluate our approach based on three research questions rq1 is the proposed approach effective in constructing call graphs for python programs?
sections v b and v c rq2 how does the proposed approach stand in comparison with existing open source static based approaches for python?
sections v b and v c rq3 what is the performance of our approach?
section v d further we show a potential application through the enhancement of github s security advisory notification service.
a. experimental setup we use two distinct benchmarks a micro benchmark suite containing minimal python programs and a macro benchmark suite of five popular real world python packages.
we ran our experiments on a debian host with cpus and gbs of ram .
micro benchmark suite we propose a test suite for benchmarking call graph generation in python.
based on this suite researchers can evaluate and compare their approaches against a common standard.
reif et al.
have provided a similar suite for java containing unique call graph test cases grouped into different categories.
our suite consists of unique and minimal microbenchmarks that cover a wide range of the language s features.
we organize our micro benchmarks into distinct categories ranging from simple function calls to more complex features such as twisted inheritance schemes.
each category contains a number of tests.
every test includes the source code the corresponding call graph in json format and a short description.
categorizing and adding a new test is relativelytable i micro benchmark suite categories.
category tests description parameters positional arguments that are functions assignments assignment of functions to variables built ins calls to built in functions and data types classes class construction attributes methods decorators function decorators dicts hashmap with values that are functions direct calls direct call of a returned function func exceptions exceptions functions vanilla function calls generators generators imports imported modules functions classes kwargs keyword arguments that are functions lambdas lambdas lists lists with values that are functions mro method resolution order mro returns returns that are functions easy.
the source code of each test implements only a single execution path i.e.
no conditionals and loops so there is a straightforward correspondence to its call graph.
table i lists the categories along with the number of benchmarks they incorporate and a corresponding description.
addressing validity threats the internal validity of the micro benchmark suite depends on the range of python features that it covers.
to address this threat we presented the suite to two researchers who have professionally worked as python developers other researchers have applied similar methods to verify their work .
then we asked them to rank the suite from to based on the following criteria completeness does it cover all python features?
code quality are the tests unique and minimal?
description quality does the description adequately describe the given test case?
the first reviewer provided a .
ranking in all cases.
the second indicated an excellent code and description quality but ranked lower the completeness of the benchmarks.
both reviewers provided corresponding feedback.
in their comments they suggested some code cleanups and asked for more comprehensive descriptions on some complex benchmarks.
regarding the completeness of the suite they pointed out missing tests for some common features such as built in functions and generators.
we applied the reviewers suggestions by refactoring the affected benchmarks and improving their descriptions.
furthermore we implemented more tests for some of the missing functionality.
macro benchmarks we have manually generated call graphs for five popular real world packages.
the packages were chosen as follows.
first we queried the github api for python repositories sorted by their number of stars.
then we downloaded each repository and counted the number of lines of python code.
if the repository contained less than .5k lines of python code we kept it.
table ii presents the github repositories we chose along with their lines of code github stars and forks together with a short description.
currently there is no acceptable implementation generating python call graphs in an effective manner so the first author manually inspected the projects and generated their call graphs injson format spending on average hours for each project.
1653table ii macro benchmark suite project details.
project loc stars forks description fabric .1k .8k remote execution deployment autojump .8k directory navigation tool asciinema .9k terminal session recorder face classification .7k .4k face detection classification sublist3r .4k .1k subdomains enumeration tool table iii micro benchmark results for pycgand pyan .
depends is unsound in all cases and complete in cases and is omitted.
category pycg pyan complete sound complete sound assignments built ins classes decorators dicts direct calls exceptions functions generators imports kwargs lambdas lists mro parameters returns total we opted for medium sized projects less than .5k loc so that we could minimize human errors.
to further verify the validity of the generated call graphs we examined the output ofpycgpyan and depends and identified missing edges from a total of .
b. micro benchmark suite results the benchmarks included in the micro test suite have a limited scope and are designed to cover specific functionalities such as decorators and lambdas .
table iii lists the results of our evaluation.
for each benchmark belonging to a specific category we show if our prototype and pyan generated complete or sound call graphs.
note that a call graph is complete when it does not contain any call edges that do not actually exist no false positives and sound when it contains every call edge that is realized no false negatives .
pycgproduces a complete call graph in almost all cases .
in addition it produces sound call graphs for out of benchmarks.
the lack of soundness is attributed to not fully covered functionalities i.e.
python s starred assignments.
pyan produces either complete or sound call graphs at a much lower rate.
however for assignments pyan turns out as a more sound method because it supports them in a better manner.
we performed a qualitative analysis on the call graphs generated by pyan to check the reasons behind its performance.
we observed that pyan produces incomplete call graphs because it creates call edges to class names as well as their init methods see also section ii b .
also it generates imprecise results because it does not support all oftable iv macro benchmark results and tool comparison.
project precision recall pycg pyan depends pycg pyan depends autojump fabric asciinema face classification sublist3r average .
.
.
.
.
.
python s functionality 6generators and 3exceptions ignores the inter procedural flow of functions 6parameters and0 4returns misses calls to imported ones and fails to support classes .
the evaluation of depends shows both its fundamental strengths and limitations.
recall that each benchmark implements a single execution path and includes a call coming from the module s namespace.
our results indicate that depends does not identify calls from module namespaces and therefore soundness is never achieved .
in terms of completeness depends achieves an almost perfect score due to its conservative nature i.e.
it adds an edge when it has high confidence that it will be realized.
c. macro benchmark results by using our macro benchmark we have examined the three tools in terms of precision and recall.
precision measures the percentage of valid generated calls over the total number of generated calls.
recall measures the percentage of valid generated calls over the total number of calls.
to do so we manually generated the call graphs of the examined packages.
table iv presents our results.
the missing entries for pyan indicate that the tool crashed during the execution.
our findings show that pycggenerates high precision call graphs.
on all cases more than of the generated call edges are true positives while on one case none of the generated call edges are false positives.
recall results show that on average of all call edges are successfully retrieved.
the missing call edges are attributed to the approach s limitations recall section iii c and missing support for some functionalities.
pyan shows average precision and low recall.
pyan s average precision appears because the tool adds call edges to class names instead of just their init methods.
also it does not track the inter procedural flow of functions which is the reason why it has low recall.
for instance the implementation of the face classification package mostly depends on functions declared in external packages.
pyan ignores such calls which in turn leads to a .
recall.
finally depends shows high precision .
and low recall.
the high precision of depends can be attributed to its conservative nature.
furthermore depends does not track higher order functions and does not include calls coming from module namespaces.
this in turn leads to its low recall.
d. time and memory performance we use the macro benchmark suite as a base for our time and memory evaluation.
table v presents the time and memory performance metrics of the three tools.
the execution time was calculated using the unix time command while the memory 1654table v time and memory comparison.
project time sec memory mb pycg pyan depends pycg pyan depends autojump .
.
.
.
.
.
fabric .
.
.
.
asciinema .
.
.
face classification .
.
.
.
.
.
sublist3r .
.
.
.
.
average .
.
.
.
.
consumption was measured using the unix pmap command.
the metrics presented are the average out of runs.
the results show that pyan is more time efficient and that depends is more memory efficient.
pycgandpyan generate a call graph for the programs in the benchmark .5k loc in under a second while depends requires more than two seconds on average.
furthermore all tools use a reasonable amount of memory with pycg pyan anddepends using on average .
.
and 22mbs of memory respectively.
overall pycgis on average times slower than pyan and uses .
times the amount of memory that depends uses.
we attribute the differences in execution time between pyan and pycgto the fact that pyan performs two passes of the ast in comparison to pycgperforming a fixpoint iteration section iii .
depends is overall slower because it spends most of its execution time parsing the source files.
in terms of memory pyan anddepends store less information about the state of the analysis leading to better memory performance.
e. case study a fine grained tracking of vulnerable dependencies github sends a notification to the contributors of a repository when it identifies a dependency to a vulnerable library.
however this notification does not indicate if the project invokes the function containing the defect.
we show that pycg can be employed to enhance the service with method level information that may further warn the contributors.
to highlight the usefulness of our method in this context we performed the following steps.
first we accessed github s advisory database .
then we searched for vulnerable python packages sorted by the severity of the defect.
in many occasions the accompanying cve common vulnerabilities and exposures entries did not include further details about the defects.
we disregarded such instances and focused on the first two cases that provided information about the functions that contained the vulnerability pyyaml versions before .
a yaml parser affected by cve and paramiko multiple versions before .
.
an implementation of the sshv2 protocol affected by cve .
both packages were imported by thousands of projects for pyyaml and for paramiko.
we could not clone all dependent repositories because some were private and others did not exist any more we managed to download pyyaml and paramiko dependent projects.
then we ran our tool on each project and generated corresponding call graphs for out of the pyyaml dependent projects and out of the paramiko dependent projects the projects that pycgfailed to generate call graphs were writtenin python .
finally we queried the generated call graphs to check if the vulnerable functions were included.
we found that the vulnerable function in pyyaml i.e.
load was invoked by projects.
in paramiko we found that the problem method start server was not utilized at all by any of the projects.
we also observed that projects did not invoke any library coming from paramiko.
paramiko was needlessly included in the requirement files of the dependents.
that was not a false negative from our part we manually checked that pycgdid not miss any invocation.
vi.
r elated work call graph generation.
methods that generate call graphs can be either dynamic or static .
dynamic approaches usually produce fewer false positives but suffer from performance issues.
also they are able to analyze a single execution path and their effectiveness relies on the program s input.
static approaches are more time efficient and can typically cover a wider range of execution paths trying to capture all possible program s behaviors.
several approaches try to combine the two so they can get improved results.
there are plenty of methods and tools targeting call graph generation for statically typed programming languages such as java.
doop and wala follow a context sensitive points to analysis method.
paddle a similar approach employs binary decision diagrams bdds .
finally opal is a lattice based approach written in scala.
ali et al.
implement cgc a partial call graph generator for java with the main focus being efficiency.
they ignore calls coming from externally imported libraries and only analyze the source code of a given package.
we are currently following a similar approach but we aim to efficiently analyze external dependencies in the future.
moving to dynamic languages ali et al.
convert python source code into jvm bytecode and use the existing implementations for java to generate its call graph.
however they argue that generating precise call graphs using this method is infeasible and sometimes the output has more than96 of false positives.
pycallgraph generates python call graphs by dynamically analyzing one execution path.
thus the analysis is not practical and one should pair it with another method e.g.
fuzzing to retrieve meaningful results.
on the javascript front feldthaus et al.
implement a flow based approach for the generation of call graphs.
they evaluate against call graphs generated by a dynamic approach paired with instrumentation achieving precision and recall.
other javascript call graph generators include ibm wala npm call graph google closure compiler approximate call graph acg and type analyzer for javascript tajs .
tajs implements a latticebased flow sensitive approach using abstract interpretation.
although such an approach yields more promising results it comes with a performance cost.
call graph benchmarking and comparison.
reif et al.
present judge a toolchain for analyzing call graph generators for java.
at its core the toolchain contains a test 1655suite with benchmarks for a range of java features.
the authors then proceed to compare java call graph generators namely soot wala doop and opal .
sui et al.
also present a test suite of java benchmarks and they use it to evaluate and compare soot wala and doop .
the above benchmark suites are very similar leading to judge consolidating them into one benchmark suite.
recall our very similar implementation of a micro benchmark suite from section v a. static analysis for dynamic languages.
numerous advanced frameworks aim for the static analysis of javascript programs.
safe provides a formally specified static analysis framework with the goal of being flexible scalable and pluggable.
jsai is a formally specified and provably sound platform using abstract interpretation.
other javascript approaches target different aspects of its functionality.
madsen et al.
implement radar a tool that identifies bugs in event driven javascript programs.
sotiropoulos et al.
propose an analysis targeting asynchronous functions.
bae et al.
implement safe wapi a tool aimed at identifying possible apimisuses.
park et al.
propose safe wapp a static analyzer for client side javascript.
fromherz et al.
implement a prototype that soundly identifies run time errors by evaluating the data types of python variables through abstract interpretation.
in comparison our approach does not infer the data types of variables and focuses on the generation of call graphs.
vii.
c onclusion we have introduced a practical static approach for generating python call graphs.
our method performs a context insensitive inter procedural analysis that identifies the flow of values through the construction of a graph that stores all assignment relationships among program identifiers.
we used two benchmarks to evaluate our method namely a microand a macro benchmark suite.
our prototype showed high rates of both precision and recall.
also our micro benchmark suite can serve as a standard for the evaluation of future methods.
finally we applied our approach in a real world case scenario to highlight how it can aid dependency impact analysis.