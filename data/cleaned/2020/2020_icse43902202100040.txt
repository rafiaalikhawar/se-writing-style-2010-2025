traceability transformed generating more accurate links with pre trained bert models jinfeng lin yalin liu qingkai zeng meng jiang jane cleland huang computer science and engineering university of notre dame notre dame in usa jlin6 yliu26 qzeng mjiang2 janehuang nd.edu abstract software traceability establishes and leverages associations between diverse development artifacts.
researchers have proposed the use of deep learning trace models to link natural language artifacts such as requirements and issue descriptions to source code however their effectiveness has been restricted by availability of labeled data and efficiency at runtime.
in this study we propose a novel framework called trace bert t bert to generate trace links between source code and natural language artifacts.
to address data sparsity we leverage a three step training strategy to enable trace models to transfer knowledge from a closely related software engineering challenge which has a rich dataset to produce trace links with much higher accuracy than has previously been achieved.
we then apply the t bert framework to recover links between issues and commits in open source projects.
we comparatively evaluated accuracy and efficiency of three bert architectures.
results show that a single bert architecture generated the most accurate links while a siamese bert architecture produced comparable results with significantly less execution time.
furthermore by learning and transferring knowledge all three models in the framework outperform classical ir trace models.
on the three evaluated real word oss projects the best t bert stably outperformed the vsm model with average improvements of .
measured using mean average precision map .
rnn severely underperformed on these projects due to insufficient training data while t bert overcame this problem by using pretrained language models and transfer learning.
index terms software traceability deep learning language models i. i ntroduction software and systems traceability is the ability to create and maintain relations between software artifacts and to leverage the resulting network of links to support queries about the product and its development process.
traceability is deemed essential in safety critical systems where it is prescribed by certifying bodies such as the usa federal aviation administration faa usa food and drug administration faa .
when present trace links support diverse software engineering activities such as impact analysis compliance validation and safety assurance.
unfortunately in practice the cost and effort of manually creating and maintaining trace links can be inhibitive and therefore trace links are typically incomplete and inaccurate .
as a result traceability data is often not trusted by developers and is often greatly underutilized.
software artifacts such as requirements design definitions code and test cases all include natural language text andtherefore over the past decades researchers have explored a wide variety of automated approaches for generating and evolving links automatically.
techniques have included probabilistic techniques the vector space model vsm latent semantic indexing latent dirichlet allocation lda ai swarm techniques recurrent neural networks to integrate semantics heuristic approaches combinations of techniques and the use of decision trees and support vector machines to integrate temporal dependencies and other process related information into the tracing task.
despite all of these efforts the accuracy of generated trace links has been unacceptably low and therefore industry has been reticent to integrate automated tracing solutions into their development life cycles.
the primary impedance is a semantic one as most existing techniques rely upon word matching either direct matches e.g.
vsm topic based matches e.g.
using lsi or lda or indirect matches based on building a domain specific ontology to bridge the terminology gap .
results have been mixed especially when applied to industrial sized datasets where acceptable recall levels above can often only be achieved at extremely low levels of precision .
one of the primary reasons that automated approaches have underperformed is the semantic gap that often exists between related artifacts .
techniques that are unable to reason about semantic associations and bridge this gap fail to establish accurate and relatively complete trace links.
recent work has proposed deep learning dl techniques for traceability but without providing effective solutions.
for example guo et al.
proposed an architecture based on a recurrent neural network rnn and evaluated two types of rnn tracing models lstm and gru for generating links between subsystem requirements and design definitions against a small dataset from an industrial project.
while their results showed that accuracy improved as the size of the training set increased their approach was not trained on large training sets and therefore was not shown to generalize across larger or more diverse projects.
we include both lstm and gru approaches for comparison purposes and refer to them collectively as tracenn tnn in this paper.
two primary factors impede the advancement of dl traceability solutions.
the first is the sparsity of training data given that dl techniques require large volumes of train ieee acm 43rd international conference on software engineering icse .
ieee ing data.
manually created trace links i.e.
golden answer sets available in individual software projects are usually not sufficient for training a dl model.
the second impedance is the practicality of applying multi layer neural networks in a large industrial project as training and utilizing deep neural networks is significantly slower than more traditional information retrieval or machine learning techniques.
fig.
an example commit message and code change set where green lines have been added and red ones removed.
the commit was tagged by the committer to the depicted issue.
the work reported in this paper addresses these two critical impedances in order to deliver fast and accurate automated traceability solutions for solving industrial problems.
more specifically our proposed language model lm approach to traceability is designed to deliver accurate and therefore more trustworthy trace links be applicable for projects with limited training data and scale up to support large industrial projects with low time complexity.
our approach leverages bert bidirectional encoder representations from transformers as its underlying language models.
bert which was introduced by google in has delivered marked improvements in diverse nlp tasks primarily because its bidirectional approach provides deeper contextual information than single direction language models.
in this paper we explore the use of bert in the traceability domain introducing what we refer to as trace bert t bert .
t bert is a framework for training a bert based relationship classifier to generate trace links.
three types of relation classification architectures are particularly well suited for traceability.
these are the single twin and siamese architectures which we describe in more depth later in the paper.
we compare the effectiveness of these three architectures for generating trace links between natural language artifacts nlas and programming language artifacts plas .
nlas are artifacts such as feature requests bug reports requirements and design definitions which are written primarily using natural language but may also include code snippets.
in contrast plas are primarily programming language artifacts such as code files code snippets function definitions and code change sets which also contain natural language commentsand descriptors.
we evaluated t bert by generating trace links from issues to code represented by change sets which we refer to as a nla pla traceability challenge.
the remainder of this paper is laid out as follows.
sec.
ii outlines the concrete research questions we address in this paper.
sec.
iii and sec.
iv provide a detailed description of our approach for achieving nla pla traceability while sec.
v describes the experiments we conducted to evaluate the effectiveness of our approach.
based on the results obtained from these experiments we derive answers for our research questions in sec.
vi.
finally sec.
vii to sec.
ix discuss related work threats to validity and conclusions.
ii.
p roblem statement researchers have addressed the data sparsity problem and the performance issues of training large models through the use of pre trained dl models for various nlp problems .
this approach divides the training stage into pre training and fine tuning phases.
in the pre training phase dl models are constructed using a huge amount of unlabeled data and selfsupervised training tasks.
then in the fine tuning phase the models are trained on smaller labeled datasets in order to perform more specialized downstream tasks.
the underlying notion is that knowledge learned from pre training a model on a larger and more generalized dataset can be effectively transferred to the downstream tasks which have limited labels for supervised training.
furthermore a pre trained model provides a better starting point for model optimization than a randomly seeded one.
it therefore reduces the likelihood of local optimization traps and improves overall performance.
fine tuning a pre trained model on a smaller dataset takes significantly less time than training a deep learning model from scratch.
while pre training a general model is extremely expensive the pre training phase only needs to be performed once and can then be reused for various downstream tasks.
bert based language models make use of transformers to learn contextual information from corpora in the pre training stage and then transfer learned knowledge to downstream nlp tasks such as question answering document classification and sentiment recognition .
to our knowledge this is the first study that has applied bert or other transformer based methods to the software traceability task.
we pose a series of research questions to evaluate whether t bert can effectively address the traceability problem.
our first question is defined as follows rq1 given three variants of t bert models based on single twin and siamese bert relation classifiers which is the best architecture for addressing nla pla traceability with respect to both accuracy and efficiency?
in addition to investigating the dl model architecture we also explore different training techniques for improving model accuracy.
as discussed by guo et al.
the dl trace model may hit a performance glass ceiling and converge at relatively low accuracy.
we therefore define our second research question as 325rq2 which training technique improves accuracy without suffering from the previously observed glass ceiling ?
gururangan et al.
in their study of domain adaptive pretraining dapt claim that a second phase of pre training using a domain corpus leads to performance gains.
this finding motivated us to explore the third and most important research question rq3 can t bert transfer knowledge from a resource rich retrieval task to enhance the accuracy and performance of the downstream nla pla tracing challenge?
feng et al.
demonstrated that a bert language model pre trained using large numbers of function definitions can effectively address the downstream code search problem.
in that study researchers provided doc strings i.e.
python comments as user queries and leveraged a bert model to retrieve related functions.
since doc strings and functions are always paired in the code base ample training data for the code search problem is available.
our rq3 explores whether the code search problem can be leveraged as a training task to improve t bert for the software traceability challenge.
because this step occurs between pre training and fine tuning we refer to it as intermediate training iii.
a pproach trace retrieval algorithms dynamically generate trace links between artifacts for example by linking a source artifact e.g.
a python file to a target artifact e.g.
an issue or requirement .
the traceability algorithm computes the relevance between pairs of source and target artifacts and proposes the most related pairs as trace links.
in this section we first introduce the fundamental architecture of the bert based model and its variances and then introduce t bert with three specific relation classifiers that are well suited for addressing this traceability problem.
a. introduction to bert and language models a language model represents a probability distribution over a word sequence which with proper training can effectively capture the semantics of individual words based on their surrounding context.
given the importance of general context dl models built upon pre trained language models usually achieve better results than those trained on taskspecific datasets directly.
the architecture of the bert based model is based on transformers in which each layer in the model is a transformer layer.
the transformer layers allow the bert model to focus on terms at any position in a sentence and training a bert model is accomplished through a novel technique called masked language modeling mlm .
in a mlm training task bert randomly masks the words in the input text and then optimizes itself to predict the masked terms based on the contextual information.
in this pre training step a massive amount of corpora are fed to the bert based model and the resulting model is leveraged to address different downstream tasks by fine tuning on task specific datasets.
a distinctive feature of bert is its unified architecture across fig.
a three step workflow applies t bert to nlapla traceability.
pre training data are functions collected from github projects a bert is trained as a language model for code with these functions and composed with a relation classifier as the t bert model functions are split as specifications and doc strings and used as intermediatetraining data t bert model is intermediate trained using code search data oss datasets are collected from github repo t bert model is fine tuned as a trace model using transferred knowledge different tasks as the architecture for lm pre training and task specific fine tuning are almost identical with only the last layer of the model customized according to the targeted downstream tasks.
this layer is usually referred to as a task header in a bert based model.
b. bert for software traceability the solution we propose represents a three fold procedure of pre training intermediate training and fine tuning as summarized in fig.
.
in the pre training phase a dedicated language model is trained on source code and then utilized to construct the t bert models.
in the intermediate training phase t bert is then trained to address the code search problem.
in this phase we provide adequate labeled training examples to t bert and expect it to learn general nl pl classification knowledge that can ultimately be transferred to the traceability challenge.
finally in the fine tuning phase the intermediate trained t bert model is applied to the issuecommit tracing challenge in real world open source projects.
c. t bert architectures the three variants of the t bert architecture that we investigate for software traceability have previously been applied to similar text based problems.
these variants are twin the twin bert architecture is shown in fig.
3a.
it leverages two bert models to encode the nl and pl artifacts separately.
the two artifacts are then transformed into two independent hidden state matrices in which tokens are represented by fixed length vectors.
we applied a pooling technique on these hidden state matrices to formulate feature vectors representing the artifacts.
finally we concatenated these two feature vectors for classification tasks.
siamese the siamese bert architecture is shown in fig.
3b.
it is a hybrid of the single and twin architecture.
it only uses one bert model however instead of creating a concatenated token sequence for an nl pl pair like single bert it passes each artifact sequentially to the bert model and creates separate hidden state matrices for each of the two artifact types i.e.
nl and pl .
the generated two hidden state matrices are then pooled and concatenated to produce a joint feature vector as in the twin bert architecture.
this joint feature vector is then sent to classification headers to accomplish the prediction task.
both siamese and twin t bert architectures concatenate artifact feature vectors to create a joint feature vector.
nils et al.
explored the impact of different concatenation approaches for the siamese bert architecture and showed that given two pooled feature vectors uandv siamese bert with a joint feature vector u v ju vj achieved the best performance on a sentence classification task.
we therefore apply this type of concatenation method to fuse the nl and pl feature vectors to create a joint feature vector.
single the single bert architecture is shown in fig.
3c.
nl and pl text are annotated with special tokens and then concatenated into a single sequence.
for example token is used to annotate the start end of a sentence.
a sentence s with tokens s1 s2 s3 sn and a piece of code c with tokens c1 c2 c3 cnwill be transformed into an input format of s1 s2 s3 sn c1 c2 c3 cn .
the annotated and concatenated sequence is fed to the single bert to generate a single hidden state matrix.
a subsequent pooling layer then reduces the dimension of the matrix to create a fused feature vector which is a counterpart of the joint feature vector in siamese and twin.
this feature vector is used by the classification header to predict whether the input nl pl pair is related or not.
iv.
m odel training in this section we describe the training strategies used for pre training intermediate training and fine tuning phases.
the dataset supporting pre training and intermediate training phases is provided by hamel et al.
from their study of the code search problem.
it includes function definitions and their associated doc strings scraped from numerous github projects and includes go java javascript php python and ruby programming languages.
the dataset used in the fine tuning phase was retrieved from oss by our team.
we extracted issues and commits through github s apis and mined ground truth trace links from the commit messages.
we show the data format in fig.
and explain details of the data collection process in sec.
v a. in this study we selected python as our target language for both training and evaluation due to the large number of active projects however our approach is not language dependent.
given sufficient time the same post training process could be applied to other programming languages.a.
three step training pre training code language model in the pre training step we leveraged the bert model to learn the word distribution among nl and pl documents and refer to this bert model as code bert to distinguish it from the plain bert model that handles only nl text.
in the plain bert model masked lm mlm tasks were used to pre train bert as a language model.
as previously explained in mlm tasks of tokens are selected and masked and then bert is trained to recover the masked tokens based on their surrounding context.
given that pre training a language model is very expensive three commercial organizations have released their own pretrained code bert models hugging face codistai and microsoft all of which were trained on the codesearchnet dataset.
of these we leverage microsoft s model referred to as ms codebert as our source code language model directly for t bert relation classification models depicted in fig.
as it has been shown to deliver improved language comprehension for diverse downstream software engineering tasks.
these improvements in ms codebert can be attributed to its replaced token detection training tasks which have been shown to be a more effective way of training lms .
this training task replaces a small portion of tokens in the corpus with random tokens and then requires the bert model to identify which tokens have been replaced.
intermediate training for intermediate training we trained t bert models to perform the code search problem as this problem is inherently similar to the nla pla traceability challenge.
in both cases we used t bert to retrieve related source code based on a nl description of code functionality.
the codesearchnet dataset1provides a benchmark for the code search problem as each function in the dataset is paired with a doc string.
for python the dataset includes functions for training functions for development and functions for testing.
this dataset is ideal for intermediate training purposes because it is large in size therefore the t bert model has adequate labeled data to learn general rules for identifying nl pl relevance the relationships between doc string and function are definitive meaning that there is minimal noise in the ground truth and the function definitions use only part of the python grammar which makes this task easier to handle than nlapla traceability.
we formulated the intermediate training as a binary classification task in which t bert was asked to identify whether a given doc string properly describes its paired function or not.
the loss function used in this intermediate training step was cross entropy loss and adam optimizer was used to update the parameters and optimize for the loss function.
the code search problem creates an unbalanced distribution of positive and negative docstring to code pairs we therefore created a balanced training dataset with an equal number of positive and negative samples.
guo et al.
adopted a dynamic under sampling strategy to avoid inflating training data 1codesearchnet dataset a twin b siamese c single fig.
the architectures of the three t bert models proposed and evaluated in our experiments.size while continually exposing the model to previously unseen negative samples.
we adopted a similar technique to construct our training samples.
in each epoch a balanced training set was constructed by including all function and doc string pairs from codesearchnet dataset as well as a randomly selected equal number of non related pairs.
we updated the training set at the beginning of each epoch so that the t bert model could learn from previously unseen negative examples.
we refer to this training strategy as dynamic random negative sampling drns and compare it to other training strategies described in sec.
iv b. fine tuning in fine tuning we utilized a similar training technique to that discussed in the previous step but addressed the traceability challenge of tracing issues to code commits using real world oss datasets.
although the input data is formatted differently to the intermediate training format tbert uses the same architecture for both tasks.
as shown in fig.
the issues are comprised of a short issue summary and a long issue description while the commit is composed of a commit message and code change set.
for each type of artifact we concatenated the text to formulate input sequences for the t bert model i.e.
issue summary issue description and then commit message code change set.
in contrast to the intermediate training step the dataset utilized in this step is limited and fuzzy.
as reported by rath et al.
link sets mined from oss projects are unlikely to be complete and entirely accurate as engineers may forget to tag issues or may commit multiple changes against multiple tags.
.
furthermore the number of links in the project specific fine tuning phase is significantly smaller than the number of function to doc string pairs used in post training.
as reported in table.
i we have approximately six hundred true links for fine tuning compared to pairs of function and doc string.
furthermore the code change set in commits has a more flexible and complex format than the short and succinct function definitions.
b. negative sampling guo et al.
observed a glass ceiling in terms of achieved trace link performance in which the accuracy of their neural trace model increased as the training epoch increased at the beginning however it then reached a peak value and started to decline with further training .
our hypothesis of this phenomenon is as follows.
at earlier stages of training the trace model can effectively learn rules for distinguishing positive and negative examples and the neural trace model was easily able to rule out many unrelated examples i.e.
cases where the source and target artifacts have little common vocabulary .
since those types of negative examples constitute the majority of negative examples the random negative sampling strategy experiences few challenging examples and therefore starts overfitting based on n aive rules because these n aive rules are applicable for the majority of simple cases.
this overfitting causes accuracy to decline after a few training epochs.
our approach adds high quality negative samples to alleviate this problem through our proposed online negative sampling ons as an alternative to dynamic random negative sam328pling drns .
the principle idea of ons is that instead of creating a training dataset at the beginning of each epoch the trace model will generate negative examples dynamically at the batch level.
for illustrative purposes imagine we want to create a batch of size containing positive links.
if we have nl artifacts and pl artifacts i.e.
a total of candidate links we include the positive links and then select negative links from the candidates in order to create a balanced batch.
by evaluating these negative links and ranking them by predicted score we can identify the false links which are more likely to be mistakenly classified.
then by incorporating the top scoring negative examples into the training set we improve the quality of negative examples and avoid early overfitting.
this approach is inspired by applications in the face recognition domain where face recognition models need to distinguish between people with similar appearances .
this negative example mining strategy is usually combined with triplet loss in the contrastive learning framework.
here we adopt it for our classification and combine it with the widely used cross entropy loss.
v. e xperimental evaluation a. data collection in this study we train t bert and evaluate it against two types of datasets.
the first dataset is codesearchnet which is publicly available .
it includes functions and their associated doc strings for six different programming languages.
as previously stated we focused on python functions.
the other datasets2we leveraged were mined from three oss projects in github and included pgcli flask and keras as described in table.
i. we selected these projects because they are popular actively maintained python projects with developers actively tagging commits with issue ids.
we retrieved issues and their discussions as the source artifacts and commits as target artifacts.
for each issue we included both the short issue summary and the longer issue description.
we automatically removed stack traces from issue discussions if highlighted as code block in markdown as we wanted to train our approach to perform the harder job of generating links between issues and code without the more explicit information provided by stack traces.
for each commit we included the commit message and change set.
however we removed very small commits with less than loc from our target artifact set.
finally due to the github api rate limit we retrieved a maximum of issues for each project.
after retrieving commits and issues we mined a golden link set from the commit messages by using issue tags embedded into commit messages added by committers.
in addition we leveraged pull requests as an accepted pull request automatically creates both an issue and commit in the oss project and connects them through an issue id embedded into the commit message.
tags were mined using regular expressions in order to build a link set connecting issues and commits.
one risk of mining links from commit message is that the link set may 2oss dataset incomplete.
liu et al.
partially addressed this problem by pruning the dataset and only retaining artifacts appearing in links set .
we adopted this process to construct our dataset and report results in table i table i the size of software project leveraged in traceability experiment.
we applied the cleaning procedures described in sec.
v a to clean artifacts and links.commits issues links type pgclioriginal database command line cleaned flaskoriginal 1159web frameworkcleaned kerasoriginal neural network library cleaned b. experiment setup we conducted our experiment on supermicro sys 7048grtr superserver with dual twelve core .2ghz intel xeon processors and 128gb ram.
we utilized nvidia geforce gtx ti gpu with gb memory to train and evaluate our model.
the t bert model was implemented with pytorch v .
.
.
and huggingface transformer library v .
.
.
.
we trained models for and epoch in intermediatetraining and fine tuning.
for each task we use a batch size of and a batch accumulation step of .
we set the initial learning rate as 1e and applied a linear scheduler to control the learning rate at run time.
regarding the model selection we split the dataset into training train development dev and test sets.
we trained the model using the training dataset and tested its performance on the dev dataset.
we then selected the best performing model based on the dev dataset and created an output model.
we finally evaluated and compared the performance of output models on the test dataset.
in the intermediate training stage the dataset was already split by the data provider.
in the fine tuning stage we split the dataset into ten folds of which eight were used for training one for development and one for testing.
c. evaluation metrics the metrics for our experiments include f scores mean average precision map mean reciprocal rank mrr and precision k. f scores f scores are composite metrics calculated from precision and recall and are frequently used to evaluate traceability results.
the f score assigns equal weights to precision and recall while the f score favors recall over precision.
although both precision and recall are important f2 is usually preferred for evaluating trace results where recall is considered more important than precision.
we report the best f scores in our experiments by enumerating the thresholds.
f precision recall precision recall mean average precision map evaluates the ranking of relevant artifacts over retrieved ones.
each source artifact is regarded as a query q for retrieving artifacts.
after ranking the retrieved target artifacts an average precision avep or ap score is obtained based on the position of all relevant target artifacts in the ranking.
the mean of avep scores is then computed to return the map.
in our study we apply a stricter metric known as map in which only artifacts ranked in the top positions contribute to avep score.
the formula for this metric is shown in following k represents the total relevant target artifacts in a query and rankirefer to the ranking a target artifact avep pk ix k x p i ifranki otherwise map pq javepj q mean reciprocal rank mrr is another measurement of the result ranking.
in each query the first related target artifact with a rank of n will provide a reciprocal rank of n. mrr accumulates by averaging the reciprocal rank for all the queries q. this focuses on the first effective results for a query while ignoring the overall ranking.
this is the standard metric used for the codesearchnet benchmark.
while map is more typical for trace retrieval tasks we include this metric to compare our intermediate trained model against the approaches in other studies for code search problem.
mrr qqx ji 1j1 1stranki precision k precision k evaluates how many related artifacts are retrieved and ranked in the top k. the formula for this metric is shown in eq.
.
we provide results with k values of to .
a trace model with high precision k means users are more likely to find at least one related target artifact in the top k results.
precision k pq ijreli kj jrelj as we can see mrr and precision k ignore recall and focus on evaluating whether the search result can find interesting results for a user.
they are ideal for the code search problem but not for traceability where recall is particularly important.
therefore we apply only f score and map to evaluate traceability results.as the majority of our queries have fewer than three correct links a perfect map score represents close to recall.
vi.
r esults anddiscussion we report performance results of t bert models for the code search problem and the nlas plas traceability problem and address the rqs defined in sec.
i.a.
evaluating the code search problem our first evaluation explores how well t bert models perform when datasets have adequate labeled examples.
we trained t bert models for the three architectures introduced in sec.
iii c using the training part of the codesearchnet dataset.
for the t bert models which are trained with ons technique we add a star sign after the model names to distinguish them from the t bert model trained with drns.
for example single refers to the model with single bert architecture and trained with online negative sampling.
the performance of these six types of models are reported in table.
ii.
in addition we compare t bert models against three classical tracing techniques of vsm lda lsi and also a deep learning trace model tracenn for this dataset.
other researchers such as hamel et al.
and feng leveraged the same dataset to conduct code search study and so we select the methods which achieved the best mrr scores in their study as a comparison to t bert and created our evaluation dataset for codesearchnet in the same way.
for each doc string we combined the related function with unrelated ones and charged the retrieval models with finding the correct function among one thousand candidates.
however the single models were not able to efficiently process the entire dataset and so in this case we evaluated only out of the total queries.
the comparison of mrr scores are shown in table.
ii.
to observe the learning process for each table ii evaluation of t bert models on the codesearchnet challenge datasetf1 f2 map mrr pr pr pr twin .
.
.
.
.
.
.
siamese .
.
.
.
.
.
.
single .
.
.
.
.
.
.
twin .
.
.
.
.
.
.
siamese .
.
.
.
.
.
.
single .
.
.
.
.
.
.
vsm .
.
.
.
.
.
.
lda .
.
.
.
.
.
.. lsi .
.
.
.
.
.
.
tnn lstm .
.
.
.
.
.
.
tnn bigru .
.
.
.
.
.
.
jv birnn .
jv selfatt .
msc .
jv joint vector msc ms codebert tnn tracenn previously reported results against same codesearch net challenge dataset.
table iii training and testing time for t bert models on code search problem.
the test time is recorded for a test set with queries.
strategy twin siamese single train hr drns 156h 138h 164h test sec drns 3254s 3264s 183357s train hr ons 146h 142h 283h test sec ons 3211s 3265s 193667s model we visualized the learning curve in fig .
for the first steps of optimizations.
we evaluate the performance of each model at intervals of steps during the training by applying the intermediate model against small testing sets composed of development examples.
b. evaluate nla pla traceability we then evaluated the t bert models on the nla pla traceability problem.
as previously described we used folds of trace links for training fold for developing and fold for testing.
to explore our rq3 we conducted a controlled experiment in which we trained two groups of t bert models.
in the first group we continued training the t bert model which had been intermediate trained in our previous experiment.
in the second group we trained the t bert models without applying transferred knowledge learned from intermediatetraining .
when we conducted model training we applied the same training dataset and ons techniques to the two groups.
to maintain consistency of abbreviations we name the models in the first group for example as single t and the models in the second group as single .
the result of this experiment are shown in table.
iv while the learning curve for the tbert models showing the fine tuning to traceability tasks is shown in fig.
.
we show only the learning curve for pgcli data due to space constraints.
c. rq2 how does ons alleviate the glass ceiling problem?
in this section we discuss how the effectiveness of ons for t bert models alleviates the glass ceiling problem.
this question helps us to identify the best approach for training t bert models.
to answer this question we apply both ons and drns to the same t bert architecture to create test and control groups.
fig.
shows the learning curve of t bert models on codesearchnet dataset during training.
the orange lines represent the models trained with ons while blue lines represent those trained with drns.
we find that for twin and single model the orange line is always above the blue line meaning that ons can accelerate the learning for tbert models but also let it converge at a higher value.
while for siamese we find the orange line is above blue line in the early steps but soon converges at a similar level.
this result indicates ons benefits the t bert model training by introducing harder negative examples.
the evaluation results shown in the first six rows of table.
ii also support this finding as the twin and single models line achieve better results than t bert models line from the perspectives of all metrics.
siamese line and siamese line have a very close result where the difference of all metrics are within .
except f2 score .
.
we report the training time for drns and ons in table iii.
ons introduces initial overheads in constructing each batch but then has fewer candidates to evaluate and sort.
in contrast drns has no upfront construction costs but must sample data from a large list creating a performance bottleneck.
the use of ons only significantly increased training time except for the single model which is particularly slow on evaluation.we conclude that ons delivers better accuracy than drns and only increases training times for models e.g.
single which have slow evaluation processes.
d. rq1 which t bert architecture is better?
this rq focuses on comparing the accuracy and efficiency of t bert when used for trace retrieval tasks.
performance comparisons were conducted on t bert models as we have shown in rq2 that t bert models returned better accuracy than t bert ones.
to answer this question we further divided our questions into three sub rqs as following.
rq1.
are t bert models capable of resolving the codesearchnet and nla pla traceability problem?
table.
ii shows that single twin and siamese line can achieve f scores around .
and map scores around .
.
the precision score for the three models are around .
which means t bert models can return related functions in around of user queries.
and in to of cases the correct answer definition is ranked at the first position.
this result shows that all three models are effective for the codesearchnet challenge.
among these three models single achieves the best performance with respect to all metrics.
however the gap between these three models is small and all three models clearly outperform the base line created by the three ir models of vsm lsi and lda.
in table.
iv the first three rows show that t bert models applied to the traceability challenge and trained without the benefit of transfer knowledge are ranked in the same way as for the code search problem.
however the performance gap between these three models increases.
this suggests that the size of training data has different impacts on the three types of architecture.
since twin model includes two inner bert models the parameters in this architecture are doubled and it therefore requires more training examples to tune the models.
nevertheless all t bert models achieved achieve better results than the ir model baselines.
especially in keras dataset siamese and single line2 and have an f score above .
and map of .
indicating that t bert can provide perfect tracing results in some scenarios.
rq1.
which t bert model most effectively addresses the two problems of data sparsity and performance ?
we need to take both accuracy and efficiency into consideration when selecting a model for use in production.
as discussed in rq1.
the single model achieves best performance however it is very slow for processing large scale datasets.
as shown in table.
iii twin and siamese need around seconds to evaluate queries while single needs around seconds.
we estimate that it will take around hours for single to evaluate the whole codesearchnet test with our current experiment setup.
but for twin and siamese it took us only around hours to evaluate the whole test set in practise.
in the traceability challenge the test set is relatively tiny.
taking pgcli for example it contains candidate links compose of source artifact and target artifacts.
twin and siamese both take around seconds to finish the task while the 331table iv evaluation of models on nlas plas traceability pgcli flask keras f1 f2 map f1 f2 map f1 f2 map twin .
.
.
.
.
.
.
.
.
siamese .
.
.
.
.
.
.
.
.
single .
.
.
.
.
.
.
.
.
twin t .
.
.
.
.
.
.
.
.
siamese t .
.
.
.
.
.
.
.
.
single t .
.
.
.
.
.
.
.
.
vsm .
.
.
.
.
.
.
.
.
lda .
.
.
.
.
.
.
.
.
lsi .
.
.
.
.
.
.
.
.
tnn lstm .
.
.
.
.
.
.
.
.
tnn bigru .
.
.
.
.
.
.
.
.
t transfer learning tnn tracenn a twin b siamese c single fig.
the learning curve for t bert and t bert models on code search challenge.
this figure shows the map scores y axis over the first 35k x axis adam optimization steps.
single model takes around one hour.
siamese and twin architectures accelerate the process by decoupling the feature vector creation steps.
in the single architecture nl and pl document pairs are fed to bert to create a joint feature vectors.
this step is extremely expensive and creates the main performance bottleneck for the single model.
assuming we have n source and n target artifacts.
single has a time complexity of o n2 k for creating feature vectors for all the candidate links where k refer to the time consumed by the bert model to convert an input token sequence into a feature vector.
twin and siamese only need o n k to convert artifacts into feature vectors and then o n2 time to concatenate the feature vectors together.
the time complexity of twin and siamese is one order of magnitude lower than the single model thus more scalable to projects with massive artifacts.
we argue that siamese is the most appropriate model for addressing nla pla traceability taking both accuracy and efficiency into consideration because it can achieve an accuracy close to the single architecture for the traceability challenge while maintaining the low time complexity of the twin architecture.
however in cases where accuracy is the primary concern e.g.
traceability for safety table v model performance on pgcli dataset for nla pla.
twin siamese single train hr 12h 12h 13h test sec 170s 163s 5395scritical projects users should adopt single model supported by high performance hardware.
rq1.
how do t bert models compare to other approaches ?
for the codesearchnet challenge we compared the performance of t bert models to joint vector embedding jve and ms codebert.
jve s architecture is similar to twin and leverages two encoders to create feature vectors for a classification network.
previous studies have reported as the highest mrr achieved by jve on the same dataset which is lower than t bert models.
ms codebert provided by microsoft used the same architecture as single in our experiment.
however ms codebert was trained with a batch size of on a cluster with tesla gpu and no special techniques were applied during training.
our machine only allows one small batch due to memory limitations but single model s mrr results were only .
lower than mscodebert indicating that our training techniques partially alleviate limitations introduced by less powerful hardware.
tnn is an rnn based trace model proposed by guo et al.
and designed for generating nla nla links.
we reconstructed the model according to the authors specifications and applied it to our nla pla problem for comparison purposes.
tnn utilizes word2vec embedding to transform tokens into vectors.
it uses two alternate rnn networks lstm or bidirectional gru bigru to generate semantic representations of nla and pla and feeds these semantic hidden states to the integration layer to generate a new hidden state representing 332fig.
learning curve of t bert models on pgcli dataset for nla pla trace challenge.
this figure shows the map scores y axix over 5k adam optimization steps x axis the correlations between the nla and pla from which links are generated.
our embedding layer was constructed by unsupervised training of a skip gram word2vec model using artifacts from the three oss reported in table i. we evaluated both lstm and bigru for the rnn layer in this study.
tnn results are shown at the bottom of table.
iv and show that it underperformed all bert models and vsm on all three oss projects.
we provide an illustrated example in fig.
showing t bert and vsm results for a commit issue pair tagged by the committer as related.
guo et al.
reported improvements over the vsm model for their nla nla dataset we were unable to replicate these for our nla pla problem.
an inspection of the tnn learning curve indicated that tnn effectively reduced the loss and improved the link prediction accuracy for all three training datasets in training dataset but converged early in the validation datasets and then decreased in accuracy indicating an overfitting problem.
there are several possible explanations for these results.
first the dataset used by guo et al.
contained positive links versus our links which could be insufficient for rnn training.
second programming languages have an open vocabulary in which new terms can be created as variable and function names and tnn may therefore need a larger training set to generate nla pla links versus nlanla ones.
our hypotheses are supported by the observation that tnn does not overfit when applied to the codesearchnet where larger numbers of training examples are provided.
tbert models leverage transferred knowledge from pretrained language models and adjacent problems to reduce the requirements of the training dataset size and are therefore able to handle tracing challenges which can not easily be addressed by classical deep learning trace models.
this characteristic makes t bert more practical for industrial applications.
e. rq3 to what extent can t bert leverage transfer knowledge from code search to software traceability table iv the t bert model trained with and without transferred knowledge from the post pretrained model.
theresults show that intermediate training t bert models on the code search task can significantly improve their performance on the traceability problem.
taking siamese on pgcli for example the f2 score increased from .
to .
while the map score increased from .
to .
.
similar results are observed for the other datasets with different t bert models.
this suggests that the knowledge learned from text to structure code function definition can be effectively transferred to cases where code formats are more fuzzy and training data has limited labels.
intermediate training improvements fig.
in this example a link is tagged by developers retrieved by the t bert model with a high score o .
due to semantic similarity and context and missed by vsm because the key terms request and json are common terms.
were observed to different extents across the three architecture types.
as shown in fig.
the blue line single converged at a very early stage showing that single needed only relatively few epochs on the smaller task specific dataset to localize its transferred knowledge.
siamese converged slower while twin converged slowest of all indicating that each architecture has a different capacity for transferring knowledge.
vii.
r elated work our study constructs t bert models using three different architectures all of which have previously been used to address related problems in other domains.
lu et al.
leveraged a twin like model named twinbert as a search engine to deliver ads alongside organic search results .
they used reinforcement training techniques and found that twinbert could return results with high accuracy and low latency.
reimers et al.
proposed a siamese architecture to address problems such as semantic textual similarity .
they trained their model to determine whether two sentences were related through contradiction or entailment and utilized snli and the multi genre nli dataset for training and evaluation.
their results showed that siamese bert could achieve a high spearman rank correlation score around .
.
they also found that use of averaging pooling was more effective than max pooling and first token the token pooling and that concatenating source and target hidden states as u v ku vk achieved best results.
we adopted 333these findings when we built t bert models for this study.
however no study has yet been conducted comparing the twin siamese and single architectures.
to address the nla pla challenge we adopted the code search problem as our intermediate solution.
several studies have addressed the code search problem using a recurrent neural network rnn .
we have already made comparisons to the work by feng et al.
and huian et al.
in table.
ii however in another study gu et al.
converted method specifications into api call sequences and then processed the sequence with rnn.
they reported achieving .
mrr in a test set with queries.
however we can not directly adapt this method to the traceability challenge because unlike api calls the statements in code change sets are not structured.
a related domain for addressing nla pla is source code embedding.
by converting both source code and documents into distributed representations the relevance between these two type of artifacts can be effectively calculated through distance metrics such as cosine and euclidean distance.
code2vec belong to this type of approach.
t bert models can adapt to this type of training by integrating cosine embedding loss in the classification header.
we leave this exploration for future work.
viii.
t hreats to validity there are several threats to validity in this study.
first our current experiments have only been conducted on python projects and results could differ when applied to other programming languages.
also due to time constraints we fine tuned and evaluated the t bert model performance on only three oss projects which may not be enough to draw generalized conclusions.
second we construct our experiment datasets from oss projects by mining the issues and commits whose ids are explicitly marked as related by project maintainers.
although this is a conventional way of leveraging oss projects for traceability true links may be missed.
for example a bug report may have hidden dependencies on several other issues such as a feature request or other bug report even though a commit addressing the parent bug report is not marked as related .
we alleviate the impact of this phenomena by adopting the data processing suggested by liu et.al.
.
another important threat is that while the single architecture trained for code search problem does not outperform codebert further improvements could be achieved using hyper parameter optimization.
our experiments were limited by hardware availability for conducting excessive hyper parameter tuning.
however the performance comparison across t bert models should still be valid because all experiments were conducted with the same parameters.
finally due to processing time constraints we evaluated the single model on queries whilst using the entire testing set for the other models in table.
ii .
although not reported we also evaluated twin and siamese on queries and observed that they achieved almost identical results to those obtained from the whole test set indicating that queries was a reasonable sample size for the single model.ix.
c onclusion and future work this study has explored several different bert architectures for generating trace links between natural language artifacts and programming language artifacts.
our experimental results showed that the single architecture achieved the best accuracy but at long execution times whilst the siamese architecture achieved similar accuracy with faster execution times.
second we showed that ons training based on negative sampling improved both performance and model convergence speed without incurring significant performance overheads when compared to drns.
third we found that tbert was able to effectively transfer knowledge learned from the code search problem to nla pla traceability meaning that intermediate trained t bert models can be effectively applied to software engineering projects with limited training examples alleviating the data sparsity problem for deep neural trace models.
regarding the training time we showed that the same intermediate trained t bert can be applied for oss projects in three different domains.
by avoiding the need for intermediate training on each individual project our approach was able to efficiently adapt to new domains.
in conclusion our results show that t bert generates trace links at far higher degrees of accuracy than existing information retrieval and rnn techniques bringing us closer to achieving the vision of practical and trustworthy traceability.
to support replication and reproducibility we have provided links throughout this paper to the datasets that we used and we provide a complete implementation of t bert and execution instructions on github3.
in future work we will evaluate our approach across more diverse project domains and programming languages and will explore its application to more diverse types of software artifacts such as requirements design and test cases.
acknowledgment this work has been partially funded under us national science foundation grant shf .