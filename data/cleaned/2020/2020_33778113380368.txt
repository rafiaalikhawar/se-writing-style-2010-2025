towards characterizing adversarial defects of deep learning software from the lens of uncertainty xiyue zhang peking university chinaxiaofei xie nanyang technological university singaporelei ma kyushu university japan xiaoning du nanyang technological university singaporeqiang hu kyushu university japanyang liu nanyang technological university singapore jianjun zhao kyushu university japanmeng sun peking university china abstract over the past decade deep learning dl has been successfully applied to many industrial domain specific tasks.
however the current state of the art dl software still suffers from quality issues which raises great concern especially in the context of safety and security critical scenarios.
adversarial examples aes represent a typical and important type of defects needed to be urgently addressed on which a dl software makes incorrect decisions.
such defects occur through either intentional attack or physical world noise perceived by input sensors potentially hindering further industry deployment.
the intrinsic uncertainty nature of deep learning decisions can be a fundamental reason for its incorrect behavior.
although some testing adversarial attack and defense techniques have been recently proposed it still lacks a systematic study to uncover the relationship between aes and dl uncertainty.
in this paper we conduct a large scale study towards bridging this gap.
we first investigate the capability of multiple uncertainty metrics in differentiating benign examples bes and aes which enables to characterize the uncertainty patterns of input data.
then we identify and categorize the uncertainty patterns of bes and aes and find that while bes and aes generated by existing methods do follow common uncertainty patterns some other uncertainty patterns are largely missed.
based on this we propose an automated testing technique to generate multiple types of uncommon aes and bes that are largely missed by existing techniques.
our further evaluation reveals that the uncommon data generated by our co first authors lei ma malei ait.kyushu u.ac.jp and meng sun sunm pku.edu.cn are the corresponding authors.
permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
copyrights for components of this work owned by others than acm must be honored.
abstracting with credit is permitted.
to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
request permissions from permissions acm.org.
icse may seoul republic of korea association for computing machinery.
acm isbn .
.
.
.
is hard to be defended by the existing defense techniques with the average defense success rate reduced by .
our results call for attention and necessity to generate more diverse data for evaluating quality assurance solutions of dl software.
ccs concepts software and its engineering software testing and debugging computing methodologies neural networks .
keywords deep learning uncertainty adversarial attack software testing acm reference format xiyue zhang xiaofei xie lei ma xiaoning du qiang hu yang liu jianjun zhao and meng sun.
.
towards characterizing adversarial defects of deep learning software from the lens of uncertainty.
in 42nd international conference on software engineering icse may seoul republic of korea.
acm new york ny usa pages.
https introduction in company with the booming of available domain specific big data and hardware acceleration deep learning dl experienced big performance leap in the past few years in achieving competitive performance in many cutting edge applications e.g.
image processing speech recognition sentiment analysis e commerce recommendation video game control .
however the state of the art dl software still suffers from quality issues.
a deep neural network dnn that achieves high prediction accuracy can still be vulnerable to adversarial examples aes .
for example an image recognition dl software can be easily fooled by pixel level noises or noises perceived in a physical world situation .
the quality and reliability issues without properly addressing or confining could potentially hinder more widespread adoption of dl software especially in the applications with higher requirements of safety and security e.g.
autonomous driving medical diagnosis .
the incorrect decision of a dl software can trace back to several typical sources and patterns e.g.
generalization capability issue robustness issue .
up to present aes remain to be one ieee acm 42nd international conference on software engineering icse icse may seoul republic of korea xiyue zhang xiaofei xie lei ma and et al.
a prediction confidence b bayesian uncertainty figure prediction confidence and bayesian uncertainty.
of the most notable types of dl defects which reveals the quality and robustness issues of the dl software.
although the arms races of many recently proposed adversarial attack defense and testing continuously escalate most of these techniques are rather ad hoc.
thus far research efforts on understanding and interpretation of aes and benign examples bes are still at an early stage .
uncertainty provides a new perspective to characterize aes and bes towards understanding and designing better quality assurance techniques for dl software e.g.
testing adversarial attack defense.
to bridge this gap in this paper we study state of the art bayesian uncertainty metrics based on the statistical analysis of multi shot executions along with the one shot execution metrics i.e.
prediction confidence score pcs of the dl software under analysis see fig.
and definitions in .
we perform a large scale comparative study to investigate the sensitivity capability of these metrics in differentiating aes and bes which are important indicators to characterize dl runtime behaviors.
we find that pcs and variation ratio in terms of original prediction vro are among the best candidates with such capability and they are selected for further input data characterization.
then an obvious question arises what is the relation between the aes bes generated by the state of the art adversarial attack testing techniques and these uncertainty metrics ?
in particular do these aes bes follow some patterns in terms of uncertainty ?
our in depth analysis reveals that aes bes generated by existing techniques largely fall into two common patterns that we refer as common input samples aes tend to have low pcs and high vro uncertainty and bes often come with high pcs and low vro.
based on the above observation further questions naturally arise what do those uncommon inputs look like and can we generate them possibly and automatically?
and would these uncommon data inputs differ from common inputs e.g.
are they even more challenging to be correctly handled by a dl software?
to answer these questions we propose a genetic algorithm ga based automated test generation technique that iteratively generates uncommon input samples guided by uncertainty metrics.
we implement the proposed technique as a tool named kuk toknow the unknown and demonstrate its effectiveness in generating uncommon inputs on a large benchmark including three datasets mnist cifar10 imagenet across four different dl model architectures lenet nin resnet mobilenet .
in line with existing adversarial defense techniques our comparative experiments against the state of the art adversarial attack testing techniques also reveal that the uncommon samples could be more challenging to be correctly handled by dl software in many cases.
such uncommon samples represent a new type of hazard and potential defects to dl software which so far lacks investigation and should draw further attention during future quality assurance solution design.
in summary this paper investigates the following research questions with the support of a large scale study rq1 what is the capability of the state of the art uncertainty metrics in differentiating aes and bes?
rq2 do the aes and bes generated by the state of the art adversarial attack testing techniques follow common uncertainty patterns?
if so what are such common patterns?
rq3 is it possible to generate those uncommon data that is missed by the state of the art attack testing techniques?
is kuk useful in generating uncommon data?
rq4 to what extent are the uncommon samples defended by existing adversarial defense techniques compared with the common ones?
through answering rq1 and rq2 we aim to characterize behaviors of dl software on aes and bes from the uncertainty perspective and investigate whether some common patterns are followed by data inputs generated through current state of the art adversarial attack testing techniques.
our study confirms the existence of the common patterns for such generated data i.e.
low pcs and high vro for aes high pcs and low vro for bes .
it also identifies new uncommon sample categories which are missed by existing techniques.
rq3 and rq4 focus on understanding the feasibility to obtain the uncommon samples i.e.
rq3 and the impact of such samples on the quality and reliability of dl software i.e.
rq4 .
our evaluation results confirm that the uncommon samples could be generated with proper testing guidance.
such uncommon samples representing a new type of generated test data could bypass a variety of adversarial defense techniques with higher success rates.
thus it is quite important to generate such uncommon inputs to reveal the hidden defects of dl software for vulnerability analysis and further enhancement especially for safety and security critical scenarios.
we believe such uncommon data could be an important clue towards building trustworthy dl solutions which should draw special attention for further quality assurance solution design.
the contributions of this paper are summarized as follows we perform an empirical study on four state of the art bayesian uncertainty metrics and one prediction confidence metric to investigate their ability to differentiate bes and aes i.e.
data inputs that can cannot be correctly handled by a dl software.
among these metrics pcs and vro outperform the others in achieving higher differentiating accuracy.
we perform a systematic study on the bes and aes generated by six state of the art adversarial attack testing techniques i.e.
fgsm bim deepfool c w deephunter tensorfuzz to identify potential uncertainty patterns in terms of pcs and vro.
our results reveal that aes and bes from existing techniques largely follow two common patterns 740characterizing adversarial defects of dl software from the lens of uncertainty icse may seoul republic of korea while the other patterns denoted as uncommon patterns are largely missed by existing methods and the characteristics of aes generated by the testing tools differ from those by the adversarial attack techniques.
we propose a ga based automated testing technique for dl software implemented as a tool kuk towards generating input samples with diverse uncertainty patterns.
especially our evaluation on three datasets mnist cifar10 imagenet across four different model architectures lenet nin resnet mobilenet demonstrates its effectiveness in generating uncommon input samples that are largely missed by existing techniques.
we further investigate how the adversarial defense techniques react to the uncommon samples in line with the samples generated by adversarial attack techniques.
our results indicate that the current defense techniques are often biased towards particular patterns of samples.
the generated uncommon samples can bypass such defense techniques with a high success rate potentially causing severe threats to the quality and reliability of dl software.
for example on the model nin the uncommon data achieve .
success rate on bypassing the mutation based defense while the common data only make it .
.
preliminaries and overview .
deep neural networks definition deep neural network .
a deep neural network dnn mis a function p m x that maps an input xto a predictive probability vector p. the output label of mon input data xislm x argmaxi cp where cis the set of classes and p m x .
in general a dnn learns to extract features from the distribution of training data layer by layer and provides the decision on each candidate class with some probabilistic confidence.
a higher predictive probability value of a class often indicates higher prediction confidence on that decision label.
definition benign example .
a benign example be xwith ground truth label yis an input sample such that the prediction decision of a dnn mis consistent with the ground truth label lm x y. benign examples refer to those inputs that could be correctly handled by a given dnn model m. definition adversarial example .
an adversarial example ae is an input x similar to a benign example xby adding some minor perturbation i.e.
x x but resulting in a different prediction decision of a dnn m i.e.
lm x lm x .
existing attack methods usually generate the aes by manipulating the output of the logit layer or softmax layer of a dnn m which gradually decreases in the output probability of ground truth label and increases in the probability of other labels.
in this way the prediction decision is shifted to other labels.
based on direct observations on the prediction results of such aes we identify that a typical type of unreliable prediction is usually accompanied by two classes that have close probability confidence values.
definition prediction confidence score .
given a dnn mand an input x the prediction confidence score pcs of the inputxonmis defined as pcs x m max i cp max i c c p where c is the set of classes c lm x andp m x .
intuitively pcsdepicts the probability difference between the two classes with the highest probabilities which provides an uncertainty proxy from the aspect of distance to the geometric boundary.
for an input x the smaller the pcs x m the closer xis to the decision boundary between the top two classes.
as a result it is more likely to cross the boundary with noise perturbations.
in the following sections we use pcs x m to denote pcs x m x x where xis a set of inputs.
.
bayesian uncertainty measures besides prediction confidence based metrics bayesian based methods are recently proposed to estimate dnn s uncertainty through multi shot execution analysis see fig.
.
from the principled bayesian perspective dnns are not regarded as deterministic functions with fixed parameters.
instead the parameters of dnns are treated as random variables which obey a prior distribution p .
the posterior distribution q d is then approximated given a training data set d based on which uncertainty estimates can be obtained.
the relationship between the uncertainty representative of prediction confidence score andbayesian uncertainty estimates is shown in fig.
.
intuitively prediction confidence score reflects a distance abstraction to the fixed geometric boundary w.r.t.
a point estimate neural network whose parameters are fixed while bayesian method ensembles a set of networks whose weights follow some probability distribution.
however due to the complexity of dnns it is often impractical to sample infinitely many weights from the distribution to perform the runtime execution.
to this end the state of the art approach to obtain uncertainty estimates makes use of the dropout technique from multiple runs monte carlo dropout .
although dropout is originally proposed as a regularization method in the training process to avoid over fitting in the context of uncertainty estimation dropout is leveraged in the testing process which samples weights from the distribution to obtain dnn instances.
as a result it ensembles a number of neural networks with different weights.
in each prediction execution it randomly drops out some units in the dnn which may cause different prediction results.
as a result it allows to obtain uncertainty estimates efficiently and scales to realworld neural networks.
specifically there are three commonly used metrics to estimate uncertainty i.e.
variation ratio predictive entropy and mutual information.
.
.
variation ratio.
variation ratio measures the dispersion from the dominant class of the prediction i.e.
the predicted class with the highest frequency in multiple predictions .
definition variation ratio .
given a model mand an input x the variation ratio vr of the input xis defined as v r x m k ... t lmk d x lmax t where mdis the model with dropout enable and lmk ddenotes the k thprediction result by md.tis the total number of prediction 741icse may seoul republic of korea xiyue zhang xiaofei xie lei ma and et al.
execution by md.lmax represents the dominant label from most of thetpredictions.
another variant of the variation ratio in terms of the original prediction the prediction of the model under analysis is defined as follows definition .
given a model mand an input x the variation ratio for original prediction denoted as vro of the input xis defined as v ro x m k ... t lmk d x lm x t where lm x is the prediction result from the original model m. intuitively vrmeasures the general uncertainty of the decision with the highest frequency i.e.
whether most predictions agree with the same result while vro represents the stability around the prediction mode of model m i.e.
whether the majority predictions agree with the original result .
the higher the vrorvro is the more uncertain the prediction is.
.
.
predictive entropy.
predictive entropy originates from information theory and measures the average amount of information contained in a stochastic source of predictive output.
when all classes are predicted with equal probability in the form of a uniform distribution the decision carries the most information indicating high uncertainty.
in contrast when one of the classes is predicted with high probability value e.g.
.
then the prediction is relatively certain.
definition .
given all the predictive probability distributions pk d mk d x k ... t of an input xacross tpredictions on dropout enabling model md the predictive entropy is defined as pe x m i c t kpk d i log t kpk d i where pk d i denotes the probability value of a particular class ion thek thprediction of model md.
.
.
mutual information.
mutual information quantifies the amount of information obtained about one random variable through the observations of the other random variable.
in the case of dnns the two random variables are prediction lm x and the posterior of the model parameters whose distribution is approximated through tstochastic forward passes of dropout enabled model md.
we use kto denote an instance of the model parameters sampled from the posterior distribution.
definition .
given the predictive probability distributions pk d mk d x k ... t of an input xintpredictions the mutual information of input xis defined as mi x m pe x m t i k pk d i logpk d i where pk d i is used to approximate pd i k in a similar way to predictive entropy based on the probability vectors obtained through different stochastic forward passes.table subject datasets and dnn models.
dataset dnn model neuron layer acc.
mnist lenet .
cifar 10nin .
resnet .
imagenet mobilenet .
the reported top test accuracy of pretrained dnn model in .
.
overview in this paper we aim to understand the capability of different uncertainty portrayals on which behaviors of aes and bes are further characterized.
fig.
shows an overview of our work summarized as two major components an empirical study about the uncertainty metrics and characteristics of the existing data inputs and the data generation algorithm that generates input samples with uncommon patterns and potential applications.
specifically we first perform an empirical study towards understanding the capability of different uncertainty metrics on distinguishing aes and bes .
.
then we propose a way of categorizing aes and bes based on two perspectives the prediction confidence score from the perspective of the single shot model execution and the uncertainty estimates from the statistical perspective of multi shot execution.
next we study the uncertainty patterns of the bes and aes generated by the existing adversarial attack testing tools .
.
from the empirical study we find that the existing aes and bes follow specific uncertainty patterns.
then we propose a geneticalgorithm based approach to generate the uncommon data inputs whose uncertainty patterns are different from the patterns that existing data fall into.
we identify and analyze the importance of data with diverse uncertainty patterns from a testing perspective.
finally we evaluate the capability of such uncommon data in bypassing a variety of defense techniques .
.
empirical study in this section we first perform a comparative study about the capability of different uncertainty metrics in distinguishing aes and bes.
then we conducted a follow up investigation of the characteristics of existing aes bes from the uncertainty perspective.
.
subject dataset and data preparation .
.
datasets.
we selected three popular publicly available datasets i.e.
mnist cifar and imagenet as the evaluation subject datasets see table .
mnist is for handwritten digit image recognition containing 000training data and 000test data with a total number of 000data categorized in classes i.e.
handwritten digits from to9 .
each mnist image is of size 1with a single channel.
cifar is a collection of images for general purpose image classification including 000training data and 000test data in10different classes e.g.
airplane bird cat and ship with images per class.
each cifar image is of size 3with three channels.
the classification task of cifar is generally difficult than that of mnist due to the data size and complexity.
742characterizing adversarial defects of dl software from the lens of uncertainty icse may seoul republic of korea adversarial datafgsm pcsvr low pcs high vr lh hl benign lh adv hhll hl adv ...bim deepfool c w benign test data data classification existing data study applicationspopulation initialization uncertainty based fitness calculation image crossover image mutationobjective?
bypass defensemodel analysisdeephunter tensorfuzztesting attack high pcs high vr hh low pcs low vr ll high pcs low vr hl uncertainty metrics studyvariation ratio variation ration original predictive entropy mutual information data generation... a empirical study b uncommon data generation and application prediction confidence figure the overview of our study and its application.
imagenet is a large scale practice sized dataset which is used as the database for large scale visual recognition challenge ilsvrc towards general purpose image classification.
the complexity of imagenet is characterized by a training set comprised of over million images together with a validation set comprised of images and a test set with 000images.
each image is of size .
for each dataset we study several popular dnn models used in previous work which achieve competitive test accuracy .
the dl models we study in this paper are all with convolutional architectures.
however our approach is generic and could be applied to other network architectures such as recurrent neural networks.
our approach focuses on the uncertainty nature of dnn.
whether the calculation methods of the uncertainty metrics are available determines the feasibility of applying our approach to dl models with other architectures.
basically the only requirement on the dl models is with a classification setting thus the model output would be a probability distribution among a set of classes and the uncertainty metrics can be obtained.
in a word our approach can be applied to dnn classification tasks independent of the model architectures.
.
.
adversarial example generation tools.
we chose four stateof the art adversarial attack tools i.e.
fgsm fast gradient sign method bim basic iterative method deepfool and c w attacks to generate adversarial examples.
specifically we used the existing python tool set foolbox to perform these attacks and each attack is configured with the default setting.
we also selected two state of the art automated testing tools for deep neuron networks i.e.
deephunter and tensorfuzz both of which adopt coverage based fuzzing techniques.
for deephunter we generated aes with the k multisection neuron coverage kmnc and neuron coverage nc as the guidance.
following the configuration in we set the parameter kas for kmnc and the threshold as .
for nc.
tensorfuzz is configured with the default setting used in .
.
.
data preparation.
overall we prepared the following three sets of data one set of benign examples one set of aes generatedtable number of adversarial examples generated by the testing tools and adversarial attacks.
model dh kmnc dh nc tensorfuzz adv attacks lenet nin resnet mobilenet by the attack methods and one set of aes generated by testing tools see table benigndata.
for each dataset we randomly sampled 000test data which can be correctly predicted by the models as the benign dataset for each model.
attackadv.
for each input in benigndata we generated four types of aes with the four attack methods resulting in a total of aes.
column adv attacks in table .
testadv.
for each dataset we randomly sampled benign examples as the initial seeds.
then we ran deephunter and tensorfuzz for each model with iterations.
the columns dh kmnc dh nc and tensorfuzz show the number of adversarial examples generated by deephunter with kmnc and nc guidance and tensorfuzz.
.
rq1 empirical study on uncertainty metrics the objective of rq1 is to study the relationship between uncertainty metrics and adversarial examples.
in particular we analyze the effectiveness of uncertainty metrics in distinguishing aes and bes.
we adopt auc roc to evaluate the classification performance of each metric.
we utilize the score as the evaluation criterion because it measures the performance without dependence on a pre setting threshold.
specifically auc roc is a performance measurement for classification problems at various threshold settings.
roc is short for receiver operating characteristic curve and auc represents degree or measure of separability.
it gives us detailed information on to what extent the evaluated model is capable 743icse may seoul republic of korea xiyue zhang xiaofei xie lei ma and et al.
of distinguishing between classes.
in our metric effectiveness evaluation the higher the auc roc score the better a metric is at distinguishing aes and bes.
table shows the auc roc scores achieved on different metrics across different data.
to be specific we used 000bes and aes generated from each attack to calculate the auc roc scores.
overall pcs achieves the best performance as it is a direct measure of the prediction confidence of the target model.
interestingly we found that aes often have low prediction confidence.
from the bayesian uncertainty perspective we found that vro achieves the best performance.
on mnist and cifar datasets all auc roc scores are over .
on imagenet the minimum aucroc score is .
in differentiating bes and aes generated by deepfool while the scores on other attacks are all above .
from the in depth analysis we found that vro refer to definition captures the difference between the prediction of the original model and multiple predictions of the randomized dropout enabled model.
on the other hand other metrics represent the uncertainty based on the stability of the multi shot predictions without considering the model under analysis.
for example given an input suppose the prediction of the original model is incorrect and all predictions of the dropout enabled model are correct the values of vr and vro would be and respectively.
intuitively vro shows that the model is quite uncertain but vr indicates that the model is very certain.
in other words vro is more sensitive to capture the uncertain behavior of the target model compared with other uncertainty metrics.
answer to rq1 pcs of the original model is often effective in distinguishing bes and aes generated by existing attacks.
for the bayesian uncertainty metrics vro is often more effective than others when comparing the prediction stability between the original model and multiple dropout enabled predictions.
.
characterizing data behavior pcs and bayesian uncertainty depict the prediction results of a dnn from different angles.
in particular existing studies demonstrate that high prediction confidence is not equal to low bayesian uncertainty and vice versa .
the prediction confidence i.e.
pcs represents the confidence of a single shot model execution while the bayesian uncertainty is measured by the statistical results from multi shot model executions.
from rq1 the results reveal that vro stands out to capture the different behaviors of bes and aes compared with other bayesian uncertainty metrics.
therefore we adopt a twodimensional metric i.e.
pcs vro to characterize the bes and aes on a specific dnn model.
based on this the data is classified into four patterns see fig.
a low pcsand high vro lh high pcsand high vro hh low pcsand low vro ll and high pcs and low vro hl .
the categorization provides a way to understand and analyze the behaviors of aes and bes.
.
rq2 categorization of existing data based on the categorization method we perform a study towards understanding the characteristics of bes and aes generated bytable the auc roc scores of classification models with different metrics.
model attacks pcs vro vr pe mi lenet 5bim .
.
.
.
.
c w .
.
.
.
.
deepfool .
.
.
.
.
fgsm .
.
.
.
.
ninbim .
.
.
.
.
c w .
.
.
.
.
deepfool .
.
.
.
.
fgsm .
.
.
.
.
resnet 20bim .
.
.
.
.
c w .
.
.
.
.
deepfool .
.
.
.
.
fgsm .
.
.
.
.
mobilenetbim .
.
.
.
.
c w .
.
.
.
.
deepfool .
.
.
.
.
fgsm .
.
.
.
.
adversarial attacks and testing tools.
to compute the vro we follow the parameter configuration suggested in and set t see definition as for mnist and for cifar and imagenet respectively.
table summarizes the quantitative results of bes and aes w.r.t.
the two dimensional metrics in four models.
note that the data in the columns benign aes from attacks andaes from testing tools are from the three sets of data presented in .
.
.
in each cell the two values represent the mean and variance of the corresponding pcs and vro metric results respectively.
overall benign data mostly have high pcs and low vro.
the mean values of pcs for the four models are .
.
.
and .
respectively while the mean values of vro are .
.
.
and .
.
the results are mostly in line with our expectations i.e.
bes are expected to be predicted by the model with high confidence and low uncertainty.
in the case of mobilenet the pcs is relatively smaller than others while the vro is larger than that of other models.
the reason is that mobilenet handles a more complex task i.e.
image classification for a large scale dataset imagenet .
it is more difficult to train a high quality dnn model.
mobilenet we used here is among the state of the art model for image classification in imagenet whose top accuracy is .
.
this result indicates that bes usually belong to the hl type.
for aes generated by different attacks the metric performance is mostly contrary to bes i.e.
aes generated by attacks usually come with low pcs and high vro.
except for the aes generated by deepfool on imagenet all the mean values of pcs are rather low e.g.
almost all pcs values are below .
and the mean values of vro are relatively high e.g.
all vro values are larger than .
.
it indicates that aes generated from state of the art adversarial attacks usually fall into the category with low confidence and high uncertainty.
from the results we find that aes usually belong to the lh type.
for the adversarial data generated from testing tools we found that the obtained metrics are between bes and aes generated from the adversarial attacks.
the mean values of pcs are smaller than 744characterizing adversarial defects of dl software from the lens of uncertainty icse may seoul republic of korea table results mean variance of benign adversarial data.
model metric benignaes from attacks aes from testing tools bim c w deepfool fgsm dh kmnc dh nc tensorfuzz lenet 5pcs .
.
.
.
.
.865e .
.
.
1e .
.
.
.
.
.
vro .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
ninpcs .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
vro .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
resnet 20pcs .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
vro .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
mobilenetpcs .
.
.
.598e .
.
.
.
.
.
.
.
.
.
.
.
vro .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
the pcs results of bes but often larger than the results of aes from attacks.
conversely the mean values of vro are larger than the vro results of bes but smaller than the results of aes from adversarial attacks.
for example consider the metric results of bes tensorfuzz aes and c w aes on resnet the pcs values are .
.
and .
respectively while the vro values are .
.
and .
.
compared with the results of bes we can still reach a similar conclusion that aes from testing tools also belong to the lh type.
even so the results of aes from adversarial attacks and testing tools have some differences.
this might be caused by their differences in the test generation methods.
current adversarial attacks usually adopt the gradient based or optimization based technique to gradually decrease the predictive probability or the logit value of the truth label until the decision result changes.
for example when the probability of the truth label is reduced to .
and the probability of another label becomes .
an adversarial example is found and the attack stops.
deephunter and tensorfuzz adopt the mutation based technique to generate new tests.
the random mutation can not guarantee that the predictive probability of the truth label is decreased gradually.
for example the probability may change from .
to .
by only one mutation resulting in a higher pcs.
in summary although both adversarial attacks and testing tools can generate aes the behaviors of such generated aes are different in terms of pcs and vro.
therefore this further confirms the difference between testing and adversarial attack from the perspective of software engineering.
testing can not only simulate real world scenarios to uncover potential issues of a dl software for deployment but also generate more diverse data to capture the behaviors of the dnn systematically in the applied context.
comparing the results of bes and aes we also found that there also exists a tentative inverse correlation between pcs and vro.
for example the pcs of bes is often large and the vro is small.
the pcs of aes from adversarial attacks is often small while the vro is large.
for aes generated from testing tools the pcs tends to be larger and the vro is smaller.
it is reasonable since high prediction confidence usually reflects that the prediction is relatively certain.
answer to rq2 bes and aes usually belong to the hl type and lh type respectively.
compared with state ofthe art adversarial attacks testing tools to some extent generate different aes.
uncommon data generation the results of rq2 reveal that bes and aes usually belong to the hl type and lh type respectively.
however several questions still remain i.e.whether there exist data samples with high pcs and high vro i.e.
the hh type data with low pcs and low vro i.e.
the ll type bes with low pcs and high vro i.e.
the lh bes and aes with high pcs and low vro i.e.
the hl aes .
these samples have the potential to uncover the unknown behaviors of dnn which are largely missed by existing methods.
to answer these questions we developed a tool kuk to generate such uncommon data.
as pcs and vro on existing data usually follow an inverse correlation it is non trivial to generate the uncommon data.
in fact the test data generation of specific types could be a complicated optimization problem.
in this paper we leverage the genetic algorithm ga to provide a solution.
fig.
b shows the workflow of our algorithm.
the inputs of kuk include a seed x i.e.
an initial image2 a model m the dropout enabled model mdand a target type c. the output is a set of data samples that satisfy the objective.
we elaborate on the details of each step as follows.
population initialization.
given an input image we first generate a set of images by randomly adding noise to it.
in order to generate high quality images i.e.
recognizable by human we abandon the affine transformation e.g.
translation and rotation as the crossover may generate invalid images.
we use l norm to constrain the allowable changes between the original seed and its generated counterpart.
objective and fitness calculation.
in each iteration we check whether some generated images in the population satisfy the objective which is specifically designed for each type based on pcs and vro.
the test generation continues until some desirable data inputs are obtained.
to satisfy the objective we design a set of piecewise fitness functions to generate different types of uncommon data such that the higher the corresponding fitness value the better the input.
we use xto denote the population i.e.
a set of images and use pcs x m to denote pcs x m x x .
given the input xand 1we refer to these data as uncommon in the sense that they are rarely uncovered by existing techniques rather than that they rarely exist.
such data could occur widely in the real world.
2in this paper although we mainly focus on the image domain the approach can also generalize to other domains.
745icse may seoul republic of korea xiyue zhang xiaofei xie lei ma and et al.
model m the objectives and the fitness functions are defined as follows for the ll type the objective is pcs x m p v ro x m v where pandvare configurable parameters and the fitness function is fitll x pcs x m min pcs x m p pcs x m p v ro x m otherwise if the minimum pcs of the population is larger than p we use pcs x m to decrease the pcs until there are some inputs whose pcss are below p. due to the custom inverse correlation between pcs and vro vro tends to increase when pcs decreases.
as for the fitness function in the other situation pcs x m p aims to ensure that the pcs is still below pwhile v ro x m stands out for a smaller vro.
for the hh type the objective is pcs x m p v ro x m v where pandvare configurable parameters and the fitness function is fith h x pcs x m max pcs x m p pcs x m p v ro x m otherwise if the maximum pcs of xis smaller than p we increase the pcs until some pcss are larger than p. in addition we ensure the pcss is larger than p pcs x m p and in the meantime attempt to increase vro v ro x m .
to generate aes which belong to the hl type the objective is set as pcs x m p v ro x m v xis an ae where pandv are the configurable parameters and the fitness function is fita h l x pcs x m x x x is be ae x pcs x m x x x is ae max pcs x m p ae x pcs x m p otherwise v ro x m where ae x is if xis an ae.
otherwise it is .
the generation of hl aes is extremely challenging since hl is the typical feature of bes.
to address the problem we design a three step approach.
if all images in the population are bes step we aim to generate aes by decreasing the pcs which is commonly used by state of the art attacks.
whenever any inputs become aes and all pcss become smaller than p step we increase pcs but still keep the high priority of ae i.e.
ae has a high fitness value with the support of ae x .
for example if an ae becomes be but achieves high pcs its fitness value will decrease.
in the last step we set ae and high pcs as the high priority then decrease vro.
to generate bes that belong to lh type the objective is set as pcs x m p v ro x m vandxis a be.
the fitness function is designed as follows fitb lh x be x pcs x m min pcs x m p be x pcs x m p otherwise v r x m where be x is if xis a be.
otherwise it is .
similarly the generation of lh bes is also challenging as lh is a typical feature of aes.
in the first step if all pcss are larger than p we first decrease the pcs but keep the high priority of be.
in .
.
.
.
.
.0pcs0.
.
.
.
.
.
vroninfigure the distribution of different types of data generated on nin bykuk .
the orange color represents aes while green color represents bes.
star circle triangle and diamond represent the data of hh ll lh and hl respectively.
the second step when there are some bes with low pcss we increase the vro but keep the high priority of be and low pcs.
crossover and mutation.
for the crossover we adopt the tournament selection strategy to select two tournaments.
from each tournament we select one image which has the largest fitness value.
the two selected images are used to perform the crossover by randomly exchanging the corresponding pixels.
after the crossover each image is randomly mutated by adding white noise to increase the diversity of the population.
the test generation continues until the objective is satisfied or the given computation resource e.g.
time limit exhausts.
evaluation we implemented the proposed test generation tool kuk in python based on keras .
.
with tensorflow .
.
as backend.
in this section we aim to evaluate the usefulness of kuk in generating uncommon data rq3 and the effectiveness of these data in bypassing the defense techniques rq4 .
all the experiments were run on a server with the ubuntu .
system with core .0ghz xeon cpu gb ram and nvidia tesla v100 16g gpus.
.
rq3 usefulness of test data generation setting.
we adopt kuk to generate different types of uncommon data on four widely used dl models lenet nin resnet and mobilenet .
in the genetic algorithm the size of the population is set as the crossover rate is set as .
and the mutation rate is .
.
for the mutation process the radius of l is set as .
.
for each dataset we randomly select bes as the initial seeds.
for each seed we generate four types of uncommon data.
the maximum number of the iterations in the genetic algorithm is set to .
threshold selection.
to perform the categorization we need to set the upper bound for the low pcs vro the lower bound for the high pcs vro i.e.
the configuration values of the parameters p andvin the objective and fitness functions.
actually in table the results of bes hl and aes lh generated from adversarial 746characterizing adversarial defects of dl software from the lens of uncertainty icse may seoul republic of korea attacks are the extreme cases which can act as the guidance to select the thresholds.
high pcs.
for the lower bound of high pcs we set it as .
as all high pcss from bes in the four models are above .
.
specifically the minimum value of high pcs of bes is .
in mobilenet .
intuitively if the pcs of a data sample is above .
we regard it as a data sample with high pcs.
low vro.
for the upper bound of the low vro we set the value as .
since the low vros of bes in the four models are below .
e.g.
.
and .
for lenet andmobilenet respectively .
if the vro of a data sample is below .
we categorize it into low vro type.
low pcs.
for the upper bound of the low pcs most of the low pcss of aes in table are below .
while the pcs of samples generated by deepfool for mobilenet has a larger value .
.
we made a compromise and set the value as .
.
if the pcs of a data sample is below .
we regard that it falls into low pcs category.
high vro.
for the lower bound of high vro we set it as .
because almost all of the high vros of aes in the four models are larger than .
one exception is .
in mobilenet .
if the vro is above .
we regard it as high vro.
results.
fig.
depicts the distribution of the generated data on the two dimension plane due to page limit the results of other models are put on our website .
note that there are some seeds from which we failed to generate the uncommon data satisfying the objective.
for each of these seeds we plot the best result from the population e.g.
for hh type we select the data which has the maximum of the sum of pcs and vro .
the results show that kuk enables to generate inputs with diverse uncertainty patterns.
table shows the number of uncommon data inputs that satisfy the objective and the mean pcs and vro value.
row type objective shows the objective setting for each uncommon uncertainty pattern in terms of upper and lower bound of pcs and vro.
for each model row total andpcs vro give the total number of uncommon data generated for each type and the mean value of pcs and vro respectively.
for ll and hh types the results of generated aes and bes are shown separately i.e.
column benand column adv .
the results demonstrate that kuk is effective in generating ll and hh data inputs that are rarely covered by existing methods.
for example for nin model kuk generated ll data in total of which data are bes and data are aes.
for resnet kuk generated the ll data and hh data for all seeds i.e.
.
from the quantitative result of ll data we could find that ll data tend to be bes e.g.
the number of ll bes is much larger than the number of ll aes .
considering the natural bes usually belong to hl refer to table it indicates that low vro is a better metric to represent the characteristics of bes.
for the hh data there is no such obvious trend.
in particular for lenet andmobilenet the number of hh bes is larger than the number of hh aes.
however the case in nin andresnet is on the contrary.
for lh bes and hl aes it is more challenging to generate them since they are completely opposite to the characteristics of the common data.
the results show that kuk is useful to generate such uncommon data.
for example we generated .
and lh bes for lenet nin resnet andmobilenet respectively.
for hl aes we found that kuk onlygenerated one hl ae for lenet .
for other models kuk generated .
.
and hl aes respectively.
the results indicate that generating lh bes and hl aes is more difficult and kuk can still generate them for a part of seeds.
we can see that the pcs and vro in table are consistent with those in table .
for example although we set the lower bound of high pcs as .
in the fitness functions and objectives kuk still generated very high pcs for hh and hl data.
the mean value of pcs is larger than .
in lenet nin and resnet which is very consistent with the high pcs of bes in table .
even we set the upper bound of low vro as .
kuk still generated data with pretty low vro e.g.
for nin andresnet the vros of ll data are .
and .
respectively.
comparing the results among the four models we could find that the difficulty in generating uncommon data varies for different models.
for example kuk is effective in generating ll and hh data for lenet nin and resnet but only generated and .
for mobilenet .
for lenet andmobilenet it is easier to generate lh bes than hl aes but the case in nin andresnet is on the contrary.
these differences show that the uncommon data generated through kuk can be used to characterize different behaviors of the models.
answ er to rq3 kuk is useful for generating different types of uncommon data.
the hl bes and hl aes are often more difficult to be generated.
.
rq4 evaluation on defense techniques to demonstrate the usefulness of the generated uncommon data in table this experiment intends to study whether the data can bypass the existing defense techniques.
setting.
since different defense techniques are proposed on different subject datasets we selected popular techniques based on the datasets.
for mnist and cifar10 dataset we selected the following defense techniques binary activation classifier mutationbased adversarial attack detection defensive distillation label smoothing and feature squeezing .
for imagenet we selected the mutation based adversarial attack detection input transformations and pixel deflection .
due to the space limit we put the details about the configuration and the introduction of each defense technique on our website .
to validate the performance of the defense techniques we selected the common data including bes and aes generated from the existing adversarial attacks .
.
and the uncommon data from table .
we use the success rate to evaluate the capability of the defense technique i.e.
divide the number of bes aes which can be correctly identified by the total number.
results.
table and show the results about the performance of the defense techniques on four models.
column row comm represents the success rate on existing common data.
the results show that the defense techniques are very effective in identifying bes and aes of the common data especially on the smaller models.
for example except for that the success rate of feature squeezing is .
on resnet the success rates of other defense techniques are above on nin resnet and lenet .
in particular the success rate is above on lenet .
for the larger model mobilenet the 747icse may seoul republic of korea xiyue zhang xiaofei xie lei ma and et al.
table results of different types of data generated by kuk .
type objectivell .
.
hh .
.
lh .
.
hl .
.
ben adv ben adv ben adv lenet 5total pcs vro .
.
.
.
.
.
.
.
.
.
.
.
nintotal pcs vro .
.
.
.
.
.
.
.
.
.
.
.
resnet 20total pcs vro .
.
.
.
.
.
.
.
.
.
.
.
mobilenettotal pcs vro .
.
.
.
.
.
.
.
.
.
.
.
success rate is relatively low as it is more difficult to perform the defense for the complex model.
column row unco represents the success rate on the uncommon data generated from kuk.
the overall result shows that the existing defense techniques perform poorly on the uncommon data we generated.
we could find that the success rate of the binary classifier andmutation based detection are reduced a lot.
for example on nin the success rate is reduced to .
and .
respectively.
the reason is that these two techniques mainly depend on the pcs and vro characteristics for detection.
specifically binary classifier is trained with the value of logit layer that is closely related to prediction confidence and the label change ratio in mutation based detection is similar to vro.
the uncommon data is very different from the common data w.r.t.
these two metrics.
as a result if they perform well on common data the success rate on the uncommon data could be low.
for other defense techniques the reduction in success rate appears smaller than that of binary classifier andmutation based detection.
for example the success rates drop to .
and .
for defensive distillation andlabel smoothing onnin.
the reason is that a new model is retrained with these defense techniques while the attacks are generated regarding to the original one making it a more challenging transfer attack scenario.
for example defensive distillation retrains a more robust model by reducing the gradients.
in this case some of the data which are uncommon for original model become common data w.r.t.
the retrained model because of some weight variation.
however it still can be seen from the results that the uncommon data reveal stronger transferability.
we also found that the uncommon data on lenet is not effective on defensive distillation and label smoothing.
we performed an investigation and found that it may be caused by the following reasons.
most of the data become common in the new model.
it confirms the usefulness of uncommon data in characterizing the different behaviors of multiple models.
most of the uncommon data generated on lenet are bes see table .
the success rate is reduced to .
and .
if we only use the uncommon aes.
answer to rq4 the uncommon data inputs are not well defended by existing defense techniques while the common data are relatively easier to be defended.
in particular the binary classifier andmutation based detection approaches are less useful in defending the uncommon data inputs e.g.
with only and on nin andresnet respectively .table success rate of the defense techniques on the generated data for nin resnet andlenet .
nin resnet lenet5 comm unco comm unco comm unco data binary classifier .
.
.
.
.
.
mutation based .
.
.
.
.
.
distillation .
.
.
.
.
.
label smoothing .
.
.
.
.
.
feature squezzing .
.
.
.
.
.
threat to validity the selection of the subject datasets and dnn models could be a threat to validity.
we try to counter this by using three publically available datasets with diverse scales and popular pre trained dnn models that achieve competitive performance.
the selection of the thresholds for the categorization may affect the results of table .
we carefully select the thresholds based on the results of table .
furthermore the results of table are relatively consistent with the results of table indicating that the selection basically does not affect the results of table .
a further threat would be the randomness factors for computing the vro i.e.
configuration parameter tin .
the previous work found that the result is not sensitive to the choice of tas long as tis greater than in cifar and mnist.
we follow the configuration in the existing paper i.e.
for mnist cifar and imagenet.
in addition we tested that the values are sufficient for computing the stable vro.
related work in this section we summarize the most relevant work to ours.
attack and defense.
ever since the demonstration of deep learning models being vulnerable to even a small perturbation of input data a sequence of attack techniques have been developed on the strand.
to date multiple types of attacks including fgsm jsma bim deepfool c w have been proposed a parallel research focus on improving the robustness of deep learning models.
goodfellow et al .
presented a method of introducing nonlinear model families into the training process.
defensive distillation was introduced to reduce the effectiveness of adversarial samples which was then broken by c w attack .
meanwhile a set of recent defense techniques was surveyed and shown 748characterizing adversarial defects of dl software from the lens of uncertainty icse may seoul republic of korea table success rate of the defense techniques on the generated data for mobilenet .
data mutation based input trans deflection comm .
.
.
unco .
.
.
that all could be defeated by constructing new loss functions .
a more recent work exploited the framework of robust optimization for network adversarial training to resist a wide range of attacks.
besides dealing with datasets like mnist and cifar10 defense techniques were also proposed to handle real world large scale datasets like imagenet.
however it still lacks a study on the characteristics of bes and aes generated through these methods which we attempt to attain from the uncertainty perspective.
uncertainty measures.
in general a deep learning model is trained with a dataset and results in a set of fixed parameters which further sets up a deterministic function mapping an input to a probability distribution.
bayesian approach however does not view deep learning models as deterministic functions instead they treat the parameters as random variables .
as a representative work to solve the scalability problem of obtaining uncertainty measures proposed a dropout based solution which allows us to calculate uncertainty estimates of existing deep learning models with a good trade off between uncertainty quality and computational complexity.
existing research on uncertainty measure applications mainly focuses on the adversary detection problem.
for example used both density estimates and bayesian uncertainty estimates to learn a regression model for adversarial example detection.
further an empirical study on two types of uncertainty measures predictive entropy and mutual information was proposed to understand the effectiveness of them for detection .
however in our work we perform a comparative study on both single shot and multi shot execution uncertainty estimates to dig out the uncertainty patterns that existing aes bes followed.
testing and debugging.
researchers have attempted to leverage decades of advances in the software engineering community to seek for solutions towards more secure and robust dl systems and have developed a set of fruitful results.
these approaches share a different spirit from those in the dl community and for the first time have been evidenced to be unique and promising without studies.
testing criteria come out as the first research focus.
a series of measurements have been adapted to evaluate the quality of dl test dataset including neuron coverage multi granularity coverage criteria mc dc test criteria combinatorial testing criteria surprise adequacy and uncertainty based metrics .
classic testing methodologies have also been incorporated for dnn testing including differential testing coverage guided testing mutation testing and concolic testing .
some advanced test generation methods have also been proposed to achieve better testing for different applications.
similar to samples generated by adversarial attacks it still lacks a study on the relationship of samples generated by testing techniques and uncertainty.
in addition the results of this paper confirm the difference between testing and adversarial attack in obtaining samples with different uncertainty behaviors.some recent efforts have been made to debug dl models and to study dl program bugs library bugs and dl software bugs across different frameworks and platforms .
the results of this paper provide a new angle to characterize dl model defects which could be useful for other quality assurance activities besides testing.
conclusion and future work this paper performed an empirical study to characterize the data inputs from the perspective of uncertainty.
we first presented an empirical study on the capability of uncertainty metrics in differentiating aes and bes.
then we performed a systematic study of the characteristics of bes and aes generated by existing attack testing methods in terms of uncertainty metrics.
the results reveal that existing bes and aes largely fall into two uncertainty patterns in terms of pcs and vro.
based on the investigation results we proposed a ga based automated test generation technique to generate data with more diverse uncertainty patterns especially those uncommon samples.
the results demonstrated the usefulness of the generated data in bypassing defense techniques.
in future we plan to perform more in depth investigations on the application of the uncommon data towards robustness enhancement.
we believe further understanding of these uncommon data is crucial for building reliable and trustworthy dl solutions.