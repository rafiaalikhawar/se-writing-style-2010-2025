plug the database play with automatic testing improving system testing by exploiting persistent data diego clerissi diego.clerissi unimib.it university of milano bicocca milano italygiovanni denaro giovanni.denaro unimib.it university of milano bicocca milano italy marco mobilio marco.mobilio unimib.it university of milano bicocca milano italyleonardo mariani leonardo.mariani unimib.it university of milano bicocca milano italy abstract a key challenge in automatic web testing is the generation of syntactically and semantically valid input values that can exercise the many functionalities that impose constraints on the validity of the inputs.
existing test case generation techniques either rely on manuallycuratedcatalogsofvalues orextractvaluesfromexternal data sources such as the web or publicly available knowledge bases.
unfortunately relying on manual effort is generally tooexpensive for most practical applications while domain specific andapplication specificdatacanbehardlyfoundeitherontheweb or in general purpose knowledge bases.
this paper proposes dbinputs a novel approach that reuses thedatafromthedatabaseofthetargetwebapplication toautomatically identify domain specific and application specific inputs andeffectivelyfulfillthevalidityconstraintspresentinthetested webpages.dbinputscanproperlycopewithsystemtestingand maintenancetestingefforts sincedatabasesarenaturallyandinexpensively available in those phases.
to extract valid inputs from the application databases dbinputs exploits the syntactic and semantic similarity between the identifiers of the input fields and the ones inthe tables of thedatabase automatically resolving the mismatchbetweentheuserinterfaceandtheschemaofthedatabase.
our experiments provide initial evidence that dbinputs can outperform both random input selection and link a competing approach for searching inputs from knowledge bases.
ccs concepts software and its engineering software testing and debugging.
keywords system testing web testing test inputs test generation.
permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation onthe firstpage.copyrights forcomponentsof thisworkowned byothersthan the author s mustbehonored.abstractingwithcreditispermitted.tocopyotherwise or republish topostonserversortoredistributetolists requirespriorspecificpermission and or a fee.
request permissions from permissions acm.org.
ase september virtual event australia copyright held by the owner author s .
publication rights licensed to acm.
acm isbn ... .
reference format diego clerissi giovanni denaro marco mobilio and leonardo mariani.
.
plug the database play with automatic testing improving systemtesting byexploitingpersistentdata.
in 35thieee acminternational conference on automated software engineering ase september virtual event australia.
acm new york ny usa pages.
introduction automatic web testingaims atgenerating testcases thatexercise a web application under test using its user interface .
in this context a crucial challenge is how to effectively assign theinputfieldsthatacceptfreetext whicharecommonlypartof the design of many web pages with input values.
the difficulty of generating suitable input values for these free text fields is a well known barrier to many automatic web testing techniques which may consequently fail to thoroughly test some functionality ormayevenoverlookentireareasoftheuserinterfacethatdepend on missed input values.
consider for instance the simple case of web applications that require the users to sign up before using any other functionality.failing to sign up due to the inability to enter valid inputs in the sign upforms e.g.
avalidusernameoremailaddress willseverely penalize the effectiveness of the test generator.
similarly a web applicationforhandlinguserinsurancerecordsmayremainlargely untestedifthetestgeneratorisunabletofulfilltherequirements on the inputs to file any valid insurance record.
to achieve adequate testing the test generator must be able to exercise the target operations such as the sign up operationexemplified above with both erroneous and valid inputs.
while producing erroneous inputs can be relatively easy such as generating a string that does not correspond to any valid email address or socialsecuritynumber generating validinputs likeavalidemail address or social security number can be particularly challenging.
someautomaticwebtestingtechniquescircumventthisproblem by allowing the testers to define a catalog of input values that test generators can exploit for input selection .
although thisisapossibleoption itisarguablyunattractive sinceitshiftsthe burdenofsolvingtheproblemtothemanualeffortofthetesters and thus lowers the degree of automation of the techniques.
it canalsobeextremelyexpensiveinthemanycaseswhereitdoes not suffice to define just a bunch of values to be used everywhere 35th ieee acm international conference on automated software engineering ase but rather testers should define ad hoc catalogs of values for the individual fields of many web pages.
thevalidityoftestinputsmaydependonsyntactic semanticand coherence constraints .syntactic constraints concern withtheformatofthestringsfilledintheinputfields.forinstance an input field of a web application may require dates expressed in the format mm dd yyyy and reject inputs in different formats suchas or .
semanticconstraints predicate onthemeaningoftheinputvalues.forinstance aninputfieldmay require a street address that truly exists because the application aims to show the address on a map rejecting any fake address even if syntactically valid.
coherence constraints predicate on a set of inputs that must be coherent with each other beyond being individuallyvalid.forinstance awebpagemayletusersconfigureseveralpropertiesofaproducttopurchase butletthemfinalizethe purchasesonlyifthecombinationofthepropertiescomplywith given business rules.
allthesolutionsproposedsofarinvestigatedtheautomaticgeneration of valid inputs by integrating the test generator with other servicesthatmaysupporttheretrievalofvalidinputvaluesfrom external publiclyavailablesources.bozkurtandharmanproposea technique that extracts values from web services that can act as dataprovidersbasedontheanalysisoftheirapis mcminnetal.
investigatetheeffectivenessofretrievingvaluesbyusingsearchengines .
mariani et al.
exploits the web of data to automatically obtain coherent sets of values .
a common drawback of these approaches is that they often fail to retrieve valid values for inputs that depend on domain specific concepts or application specific data.
domain specific concepts including non standard or even jargonic terminology synonyms and acronyms caneasilybepartoftheidentifiersoftheinputfieldsina webapplication.theygenerallywidenuptolargeextentthesyntactic and semantic mismatch between the keywords searched by the test generators and the keywords used in the external data sources severelyinhibitingtheidentificationofvalidinputs.forinstance inourexperimentsweconsideredabudgetmanagementwebapplication and tried to generate test inputs using link which exploits the web of data to obtain input values.
since the webof data does not cover well the budget management domain es pecially the budget related terms used in the application undertest link consistently failed in generating valid inputs for that application.
application specific data that is values that directly depend on thestateoftheapplicationundertest areanothercommoncauseof missed inputs.for instance anoperation may requirethe number ofapreviouslyfiled insurancecontract whichcan hardly befound in any external data source.
in this paper we propose dbinputs a novel technique for automaticwebtestingthat identifiesthetestinputsbydirectlyexploiting the database of the web application under test.
our approach leveragesontwokeyobservations i applicationdatabasesarenatively craftedwithapplication specificdataandnativelydesignedwith domain specific concepts and thus they can cope well with theabove discussed open issues of the current techniques ii au tomatic web testing addresses system testing and maintenance testingphases andthuswecangenerallycountontheexistenceapp database working copy app databasetest generator web app under test .
compute similarities .
identify top matches per input field .
select best matches and return datadbinputsexecute actions query for inputs figure automatic web testing with dbinputs.
of test databases or even production databases without requiring additional effort from the testers.
dbinputsiscapableofautomaticallymatchingtheidentifiersof theinputfieldsofthetargetwebapplicationwiththeidentifiersof the columns in the tables of the available database exploiting both the syntactic and the semantic similarity between the identifiers.
thedatabaselikelycontainsvaliddataformostoperationsofthe application thusmakingdbinputsfeasible effectiveanduseful.
weliketorefertothispracticalapproachasa plug play solution sincetestersshallonlyspecifytheconnectiontotheavailabledatabase and then dbinputs can pick useful data straightaway taking itself care of the possible naming mismatches.
weevaluateddbinputsbyequippingtheabtsystemtestgenerator withthecapabilitytoidentifytestinputsby i generating random values ii using the competing technique link thatexploitsthewebofdatatoidentifyvalidinputs and iii using dbinputs.
the results reported in this paper provide empirical evidence thatthe testcases generatedwith dbinputs explore the functionalityoftheapplicationundertestmoreextensivelythan the competingapproaches dbinputs almost doubledthe number of forms exercised with validinputs still comparably exercising the forms with invalidinputs too.
dbinputsisopen sourceandavailable alongwithalltheexperimental material and results reported in this paper at the paper is organized as follows.
section provides a quick overview of dbinputs.
section rigorously describes the dbinputs algorithm.
section reports experimental results about dbinputs and compares dbinputs to competing approaches.
section discusses related work.
finally section provides final remarks.
overview of dbinputs dbinputs generates test inputs for a web application under test inafullyautomaticfashion byexploitingthedataavailableinthe database of the application under test.
in this section we introduce thekeyintuitionsbehinddbinputsbyreferringtoasetofworkingexamples whilewerigorouslypresentthealgorithmsthatdescribe dbinputs in the next section.
figure1illustrateshowdbinputsintegrateswithautomaticweb testing.
the test generator queries dbinputs whenever it needs to !
!
!
figure results of dbinputs for a sample web form.
enter values in free text input fields.
to answer the queries dbinputs refers to a working copy of the application database that is created the first time the testers configure the connection of dbinputswithagivendatabase.
theworkingcopyclonestheschema oftheapplicationdatabaseandimportsasubsetoftherecordsin eachtable.theexactlyimportedrecordsmaydependondifferent strategies asdescribedandexperimentedinsection4.
dbinputs just needs to connect to the working copy and use its data regardless of the changes that the actual database may undergo while thetestgeneratorexecutestheapplicationundertest.noticethat dbinputs isnot constrainedto anydatabaseformat andsupports any sql based database.
to answer each query dbinputs goes through three steps i first itcomputesboth syntacticandsemanticsimilarities between the identifiers of the input fields and the names of the database columns ii then itselectsthe setofcolumns thatprovidesbest matchesforeachinputfield byexploitingthesimilarityscoreswith aclusteringalgorithm iii finally itchoosesa singlebestmatchingcolumn foreachinputfieldbypursuingthetradeoffbetween a achieving high mean similarity of the matches and b limiting theamountofdatabasetablestowhichthematchingcolumnsrefer to.
figure exemplifies the three steps of dbinputs with referencetotheregistrationformof mantisbugtracker mantisbt.org a web application that we considered in our experiments and the corresponding database available online.
in the first step dbinputs quantifies the similarity between the identifiers of the input fields in the web form and the names of the database columns.
dbinputs considers three identifiers for each input field i its label which is the text that is visually associated withtheinputfieldinthewebpage e.g.
thetextonitsleftside identified with an adapted version of the algorithm by becce et al.
ii thevalueofthe id propertyobtainedfromthedocument object model dom of the page and iii the value of the nameproperty still obtained from the dom of the page.
forinstance thethreeidentifiersofthefirstinputfieldinfigur e2ar e username label user name id and username name .
the final similarity between an input field and a database column is given by the average of the similarities computed from its identifiers.aswedescribeinfurtherdetailinthenextsection dbinputs computes similarity scores between identifiers and column names combiningasyntacticdistance namelythe editdistance witha semanticdistance namelythe word2vecmodel .theunderlying intuitionisthatthematchingbetweentheidentifiersshouldbothbe tolerant toirrelevant syntactic differences and take thesemantics of theidentifiersintoaccountregardlessoftheirsyntacticrepresentation.
in figure2 thevalues associatedwith blue red andgreen arrows indicatethesimilarityscoresthat inourexperiments dbinputs computedforthethreeinputfieldswithrespecttosomecolumns inthreedatabasetables namely login data usersandemails.
forinstance dbinputsmatchedalmostperfectly similarity0.
theinputfield username withthehomonymousdatabase column username but it matched very well similarity .
also the input fielde mailwith the database column email despite the slight syntactic difference between the corresponding identifiers.
yet for another web form of the application it matched well similarity .
the input field current issue with the syntactically different butsemanticallysimilardatabasecolumn bug id.thisflexibility allowsdbinputstoretrievemeaningfulinputvaluesdespitethe possible differences between the identifiers used in the application andthedatabase.differencesintheidentifiersareoftenintroduced by design decisions taken at different times e.g.
by different devel opers ortakenwithdifferentgoalsinmind e.g.
guilabelschosen to favor user friendliness and column names chosen to comply with naming conventions of data models .
in the second step dbinputs identifies a set of good enough matchingcolumnsforeachinputfield.todothis itclustersthesimi larityscorescomputedforeachinputfieldaccordingtotheirmutual strengths based on the st dbscan clustering method and then selects the columns that correspond to the top cluster that is theclusterthatincludesthebestsimilarityscores.thisclustering step allows dbinputs to focus on the most promising matching columnsonly whilestillkeepingthechoiceopenfortheinputfields that can match multiple columns with different but comparable similarities.
figure highlights the similarity values that belong to the same top cluster with a same colored background.
there is a single matching column in the top cluster for the field real name while there are two and three candidates for the fields username ande mail respectively.
68inthethirdstep dbinputschoosesafinalsolution consisting ofasinglematchingcolumnforeveryinputfield bypursuingboth the goal of choosing matches with high similarity and the goal of limiting as much as possible the number of involved database tables.
the intuition that underlies this latter goal is that by selectingmultiple inputvalues fromthesame databasetable weincrease the likelihood of finding values that are coherent with each other.
since the input fields that belong to the same web pages are often correlated e.g.
they represent information about the same domain entities dbinputsembracestheideathattheinputdatashouldbe selected from a limited set of tables since the information about a domain entity is usually stored in a single or few database tables .
to this end dbinputs first identifies the solutions a set of matchesbetweentheinputfieldsandthedatabasecolumnswith each input field occurring exactly once with the highest mean similarityscoresofthematches usingagainclustering.amongthe solutions in the top cluster dbinputs selects the one that involves theminimumnumberoftables.forexampleinfigure2 dbinputs finally chooses to match the three input fields with three columns of table users solid edges indicate the finally selected matches .
by querying the best three columns of table usersfor randomlyselectedrecords dbinputscouldfinallyreturntheinputs that correspond to the username real name and email data ofa true user tracked in the database e.g.
john.doe john doe and john.doe provider.com.
automatically extracting test inputs from a database this section presents dbinputs in detail.
the pseudocode in algorithm defines the inputs and the output of dbinputs and describes the organization of the algorithm in top down fashion.
algorithm dbinputs map each input field to a database column input f f1...fn the input fields t t1...tm the tables in the database output m f cols t a map that associates each input field with a database column according to our best match heuristics function dbinputs f t if m angbracketleftf m angbracketright cachethen return m mm s columnswithtopsimilarity f t alg.
m identifybestmatches f t mm s alg.
cache cache angbracketleftf m angbracketright returnm dbinputs receives as input both the list of input fields in the current web page input f and the tables in the database input t andreturns amap output m thatassociates eachfield witha database column according to the dbinputs best match heuristics.dbinputsusesacachetooptimizeperformancebyavoiding multiplecomputationsofthemappingforthesamesetsofinput fields line5 andsplitsthecomputationintotwomacrosteps.thefirststepidentifiesthedatabasecolumnsthatmatcheachfieldwith comparably high similarity function columnswithtopsimilarityat line while the second step computes the field column mapping with the best tradeoff between high similarity scores and low amountofinvolveddatabasetables function identifybestmatches at line7 .theresultsof columnswithtopsimilarity i.e.
themulti map mmof the best columns for each field and the corresponding similarity values s are passed as inputs to identifybestmatches.
each new result is fed to the cache line to enable reuse at subsequent queries andthenreturnedastheresultofthecurrentquery line9 .
the next sections define the algorithms of columnswithtopsimilarityandidentifybestmatches the core steps of dbinputs.
algorithm2 identifydatabasecolumnswithcomparablyhigh similarity for each input field input f f1...fn the input fields t t1...tm the tables in the database output mm f 2cols t a multi map that associates each input field with the set of most similar columns s f cols t similarity measurement forall angbracketleftfield column angbracketrightpairs inmm function columnswithtopsimilarity f t mm s for each f fdo simc angbracketleftc similarity f c angbracketright c cols t best c topclusterdbscan cols t clustered by simc mm mm angbracketleftf best c angbracketright s s angbracketleft angbracketleftf c angbracketright simc angbracketright c best c angbracketleftc simc angbracketright simc returnmm s function similarity f c tokens f lemmatizedtokens id f name f label f tokens c lemmatizedtokens c.name for each ti tokens fdo for each tj tokens cdo synij normalizedsyntacticsimilarity ti tj semij normalizedsemanticsimilarity ti tj sij max synij semij return summationtext.
i jsij tokens f tokens c .
finding matches algorithm2 definesfunction columnswithtopsimilarity thatidentifiesthedatabasecolumnsthatmatcheachinputfieldwithcomparably high similarity.
it takes in input the set of fields fand the set of database tables t and returns both a multi map mm that associateseachinputfieldwiththesetofmostsimilardatabasecolumns and the corresponding similarity measurements s .
the weighted edgesshowninfigure 2exemplifytheresultof columnswithtopsimilarity.
the algorithm first computes the similarity score foreach field column pair line and then clusters the similarity scores to identify the top scores for each field line .
69computingsimilarityscores.
thisstepisfurtherdetailedinfunctionsimilarity algorithm2 lines14 .itconsistsofdecomposing theidentifiersofinputfieldsandcolumnsintotokensthatrepresenttheindependentwords function lemmatizedtokens atlines15 and16 findingthebestsimilarityscoreofeachpairoffield column tokens lines17 bychoosingthebestoftheireithersyntactic or semantic similarity measurements and averaging the similarity scores across all pairs of tokens line .
forcomputingthesimilarity dbinputscharacterizeseachinput fieldf fasatriple angbracketleftid name label angbracketright whereidandnamearethe values of the id property and name property of the field obtained fromthedomofthewebpage and labelisthetextualcontentthat thewebpagevisuallyassociateswiththeinputfield.weidentify thelabelsassociated with the input fields by analyzing the web pages using an adapted version of the algorithm of becce et al.
whichexploitsgoodpracticesinuser interfacedesign e.g.
itlooks for labels located on the left or straight above the fields .
more specifically dbinputsusesthevalueofthe placeholder attribute of the input field as label.
if such attribute has no value dbinputs uses the value of the label tag element that explicitly points at the target input field that is the label element must include aforattribute whose value is the identifier of the input field as label.
if such anelement is not present dbinputs uses the text in theclosest label elementthatprecedesorfollowstheinputfield asvalueofthelabel.ifsuchanelementdoesnotexist dbinputs usesthetextintheheaderorfooterofthehtmlcellthatcontains theinputfield ifany.ifnoneoftheseoptionssucceeds theinput field is associated with no label.
figure shows the id name andlabelproperties for each input field of the web form in the figure.
for instance the input field username in blue at the top is characterized by user username as id username as name and username as label the text on its left side .
any of these properties may capture a relevant descriptor of an input field useful to find the best matching with the database columns.dbinputssimplycharacterizeseachcolumnwithitsname in the database schema.
lemmatizedtokens lines and extracts the tokens contained within the identifier in lemmatized form that is it splits the identifier in substrings delimited by separators e.g.
blank spaces underscores and dash symbols or with the camel case notation homogenizes inflection and variant forms e.g.
filling becomes fill and better becomes good and gets rid of any non alphanumeric character.
for instance the user username identifier gets split into the tokens userandusername.
dbinputs computes the syntactic similarities line as the editdistance ofthetokenstrings andthesemanticsimilarities line based on a semantic word2vec model that exploits wordembedding.thesyntacticsimilaritymatchestheidentifiers thatdifferforminordetails.forexample theeditdistanceyields .
for the identifiers e mailandemail.
the semantic similarity matchessyntacticallydifferentidentifiersthathavesimilarmeaning.
for example word2vec yields .
for the identifiers issueand bug.
dbinputs normalizes both the edit distance and word2vec measurements in the range .. 1b eing the highest possible similarity tofosterthecomparabilityofthescores.further dbinputs keeps the highestof the two scores line21 to embrace best similarity perspective in each case an identifier and a name of ausers.username login data.username users.realname users.emailemails.email .
.
emails.email idusername e mailrealname similarity score0 1input fields .
.
figure similarities top clusters in mantis bug tracker.
databasecolumnthatare eithersyntacticallyorsemanticallysimilar are likely to represent a same concept.
finally dbinputs identifies the similarity of a field column pair byaveragingthesimilarityscoresacrossallcorrespondingtoken pairs line to properly weight the collective contribution of all tokens.
for instance with reference to the example of figure the token useris part of the id property of both the username andemailinputfields andmatches withhigh similaritywith the column user id.however when consideringthecontributionofall tokens theoverallsimilarityscorewithrespecttocolumn user id is much higher for the former than for the latter input field.
clusteringtopsimilarityscores.
dbinputsclustersthesimilarity scoresassociatedwitheachinputfield f i.e.
thesetofsimilarity scores associated with each pair angbracketleftf ci angbracketrightwherefis a same input field in the form and ciis one of the columns in the database with the clustering algorithm st dbscan which is a version of theclassicdbscanalgorithmthatself tunestheparametersofthe algorithm based on the characteristics of the population of values that are analyzed.
our algorithm selects the matches that occur in thetopclusteridentifiedby st dbscan algorithm2 line10 that is the cluster of the values with the highest similarity scores.
figure illustrates the output of the clustering for the three input fields in the example of figure .
the x axis represents the possible similarity scores.
the blue red and green dots indicate the similarity scores that dbinputs computed comparing everydatabase column to the input fields username real name and e mail respectively.thedelimitedareashighlightthetop clusters of each field.
for instance the top cluster for the field username blue dots contains two similarity scores both of .
that associate the field with the database columns users.username and login data.username the top cluster for the field real name reddots includesasinglesimilarityvalueof0.75thatcorresponds tothedatabasecolumn users.realname .thetop clusterforthe field e mail green dots includes three similarity scores of .
.
and .
that correspond to the columns emails.email id users.email andemails.email respectively.
dbinputs incrementally collects the top clusters and the topsimilaritiesfortheinputfields algorithm2 lines11and12 and returns these results upon completing all iterations line .
.
selecting best matches algorithm3 definesfunction identifybestmatches thatidentifies the field columnmapping that may asa whole both yield highsimilarityscoreandrefertofewdatabasetables.
identifybestmatches 70algorithm3 identifythebest matchingcolumnforeachinput field input f f1...fn the input fields t t1...tm the tables in the database mm f 2cols t a multi map that associates each input field with the set of most similar columns s f cols t similarity measurementsfor all angbracketleftfield column angbracketrightpairs inmm output m f cols t a map that associates each input field with a database column according to our best match heuristics function identifybestmatches f t mm s all m angbracketleft angbracketleftf1 cf1 angbracketright... angbracketleftfn cfn angbracketright angbracketright cfi mm fi sim m angbracketleftm summationtext.1n 1s angbracketleftfi cfi angbracketrightm n angbracketright m all m top m topclusterdbscan all mclustered by sim m tabcount m angbracketleftm counttables m angbracketright m top m mintab m min top mmeasured by tabcount m best m max mintab mmeasured by sim m returnrandomchoice best m takes in input the set of fields f the set of database tables t and the results of function columnswithtopsimilarity algorithm thatis themulti map mmthatassociatestheinputfieldstotheir most similar database columns and the corresponding similarity scoress.
thus identifybestmatches limits its evaluation to the topscored field column mappings identified by algorithm .
identifybestmatches returns the map mthat associates each field to a single best matching database column.
the algorithm of identifybestmatches proceeds as follows.
first identifybestmatches generates the space of the candidate solutions line .
a candidate solutionconsists of a complete match that associates every input field with a single database column.
identifybestmatches obtains the candidate solutions by unfolding the high similaritycandidatematchingcolumnsthat dbinputscomputedsofarandthat identifybestmatches receivesininput.then identifybestmatches scores each candidate solution with a quality value computed as the mean of the similarity scores of the matchesinthesolution line8 andexploitsagainthealgorithm st dbscan toidentifythetopclusterofcandidatesolutionsbased onthisqualityvalue line9 .next identifybestmatches scoresagain thesolutionsinthetopclusteraccordingtothenumberoftables towhichthedatabasecolumnsineachsolutionreferto line10 and further selects the candidate solutions for which this scorehastheminimumvalue line11 .finally ifmultiplesolutionsinvolve the same minimal number of tables identifybestmatches selects the one with maximum mean similarity line and yet a randomsolutionoutoftheremainingones line13 .thisprocess privileges the usage of high quality matches while discriminating solutionsthatinvolvefewdatabasetablesoutoftheonesthathave comparable quality levels.
empirical evaluation toevaluatetheeffectivenessof dbinputs weintegratedourapproach in the abt test generator hereon abt dbinputs and webenchmarked the effectiveness of abt dbinputs across a set of experiments.
across the experiments with abt dbinputs we quantified the impact of dbinputs on the effectiveness of the test generationprocess both in absolute terms and incomparison to alternative strategies.inparticular wecompareddbinputstoboththebaseline strategy of selecting inputs as randomstrings and the strategy implementedbythelinkapproach whichexploitssemantic web technologiestogeneratesemanticallymeaningfulinputs .
semantic web has indeed demonstrated to be a useful source of semanticallymeaningfulandvalidvaluesfortesting .toexperiencethesealternativeapproachesweintegratedbotharandom input generator and link into abt namely obtaining the abtrandom and abt link respectively.
below we shortly introduce abt and link tools then we discuss the research questions the evaluation metrics the setup and the results of our experiments.
.
abt autoblacktest abt isaanautomatictestcasegenerationsolution for gui and web applications .
abt exercises the functionalities of the application under test by exploiting a q learning agent thatisresponsibleforselectingandexecutingactions whileincorporating theobservedresultsinto astate basedmodel.
the model represents the knowledge about the behavior of the application under test and is exploited to incrementally improve theeffectivenessofthechoicestakenbythetestgenerationtool.inparticular abtheuristicallyassociateshightesteffectivenesstothe observationofsignificantguichanges assumingthatsignificant gui changes imply the execution of significant computations.
this heuristic allows abt to learn the execution paths that are morelikelyto significantlyexercise thesoftware undertest andfocus thetestingactivityaroundthesepaths.theimplementationthat weusedinourexperimentsisbasedon.netandusestheselenium webdrivertestingframework1tointeractwiththewebapplication under test.
.
link link is a technique that can retrieve coherent sets of syntactically and semantically correct input values by exploiting the web of data .inparticular giventhedescriptorsassociatedwiththeinputfieldsandasourceknowledgebasethatcanbequeriedthroughasparqlendpoint linkssearchesforresourcesstoredinthe knowledge base that match the provided descriptors.
for instance link can detect that a source knowledge base hosts person data described by properties such as name surname and age that well fit input descriptors such as first name second name and age.
the inputdescriptorsandthedescriptorsusedintheknowledgebase are paired taking their semantics into consideration.
if suitable resourcesareidentified intheknowledgebase linkretrievesthe associatedinstancesandusestheextractedvaluestoexercisethe application under test.
.
research questions and evaluation metrics we experimented the test generator abt dbinputs with web applications with the aim of characterizing the effectiveness of the 71dbinputsinputgenerationalgorithm.wefurtherexperimented abt random and abt link with the same web applications to assess the significance of dbinputs compared to alternative approachesforinputgeneration.moreindetail ourexperimentswere driven by the following research questions rq1.
effectiveness to what extent can the inputs generated by dbinputs foster effective testing of web applications?
rq2 comparison does dbinputs significantly improve testing effectiveness with respect to inputs selected randomly or based on semantic web technologies?
to answer rq1 we studied the effectiveness of abt dbinputs whenconsideringdifferentwaysofseedingtheworkingcopydatabasethatdbinputsexploitsforselectingtheinputdata.specifically we studied three scenarios in which the database of dbinputs is respectively equalto abt dbinputs partiallyoverlapping with abt dbinputs orentirelydisjoint from abt dbinputs nequal the actual database that the application under test uses at runtime.
we aimed to both evaluate the sensitivity of dbinputs with respect to this configuration choice and find the configuration that makes dbinputs yield the best effectiveness of abt dbinputs.
in fact the initial configuration of the database may affect the capabil ity of dbinputs to produce new or existing values and thus the likelihood of exercising specific application constraints.
since a better capability to generate test inputs impacts on functionalities with input fields we focus our evaluation on forms withat leastan inputfield.
inparticular we quantify theeffectiveness of abt dbinputs in its three configurations based on the frequency with which it generates test inputs that produce either validor invalid outcomes for the exercised forms.
we say that a test case exercises an input form if it executes a sequence of actions that i visualizes the input form on the user screen ii enters appropriateinputsintotheform and iii makestheapplicationprocessthe inputs of the form.
we say that the outcome of exercising an input form by a test case is validorinvalid if the application does not or doesissue validations errors whileprocessing the inputsof theform respectively.
we executed each dbinputs configuration times per web application and measured the f oneandf oneat least once metrics which quantify the total number of forms that a technique exercised with at least a valid and an invalid value respectively.
more formally let fappbe the set of input forms in a web application under test and f the number of times abt dbinputs exercises a formf fappwith a validoutcome within an execution f oneis thenumberofdistinctforms fexercisedwithavalidinput f inanyofthe10executions.symmetrically f onecountsthenumber of distinct forms exercised with invalid inputs f in any of the executions.
to capture the power of a technique toconsistently exercise the forms with valid and invalid values we also computed the at least half metricsf half f half f half which count the number of forms that a technique tested with valid only thatis f invalid only thatis f andbothvalidand invalidvalues thatis f f withinasameexecution for at least half of the executions.
toanswerrq2 wecomparedtheeffectivenessof abt dbinputs in its three configurations with the effectiveness of abt randomtable statistics on web applications web app forms forms with inputs per form constraints min mean max tickets .
erp .
insurance .
budgets .
we excluded login forms and forms that may cause interactions with the outside world e.g.
forms that may send emails and thus also from the statistics.
andabt link.weusedthesamesettingsandmetricsdefinedin rq1 to measure the effectiveness of the approaches.
.
web applications we executed our experiments on web apps that cover different domains and include both open source and industrial applications tickets weselectedthemantisopen sourceissuetrackingsystem v. .
.
availableat which allows users and developers to create tickets and manage issuesofapplications andtoorganizeactivitiesintoprojectsand categories.
thisapplication has been usedalso in other paperson web testing .
erp we selected the dolibarr open source enterprise resourceplanning and customer relationship management system v. .
.
available at which provides a large set of functionalities including resource planning invoicing productandstoremanagement.alsothisapplicationhas been used in other papers on web testing .
insurance this is the tricentis vehicle insurance demo application availableat services for handling insurance data of vehicles.
it includes severalinputformswithchallengingconstraintsontheinputs and is thus relevant to our experiments.
budgets this is an application for planning and managing budgets that was developed jointly with an industrial partner.
we cannotdisclosespecificdetailsduetonondisclosureagreementwith theindustrialpartner butweregrantedtherighttoreportsummary statistics on the experiments that we did with this application.
all these applications maintain persistent data in a database intensively depend on form based interactions and include web formswithconstraintsonthevalidityoftheirinputs.thus these applicationsarerepresentativeoftheclassofwebapplicationsthat techniques for the generation of input values aim to address.
table1summarizesthemainstatisticsaboutthewebapplications considered in our experiments the number of input formsin each application column forms the number of forms that includeconstraintsontheinputs column formswithconstraints and the minimum mean and maximum number of input fields in a single form columns inputs per form .
the data in the table indicate that a relevant portion of the input forms includes constraints ontheinputs withpercentagerangingfrom25 inthe insurance applicationto65 inthe ticketsapplication.thisindicatesthat generatingvalidinputsis importanttothoroughlytesttheseweb applications.
the numberof input fields present in a single form with constraints ranges from a minimum of to a maximum of with the mean ranging from more than to more than input fields per form across the considered applications testifying the variability of the scenarios to be addressed.
.
experiment setup datacollection.tocollectthedataaboutthenumberofformsexercisedwithvalid f andinvalid f inputs wemanuallyinspected every form in the considered web applications.
for the forms with constraintsontheirinputswecollected i aformidentifier usually the title page ii the actions that make the application process theform e.g.
clickingthesubmitbutton and iii thepagesthat can be reached after processing the form identifying the graphical elements that allow us to distinguish if invalid or valid inputs have been submitted.
we used this information to augment abt with an application specific logger that tracks each time abt exercises a form with either valid or invalid inputs.
database preparation.
for the research question rq1 to study therelativeeffectivenessof abt dbinputs abt dbinputs and abt dbinputs nequal wegenerateddifferenttestdatabasesasfollows.
wesplittheoriginaldatabaseofeachconsideredwebapplicationin two parts of equal sizes.
in the experiments with abt dbinputs nequal weusedthefirstpartofthesplitofeachdatabaseastheworking databasefordbinputsandthesecondpartastheruntimedatabase of the application.
in the experiments with abt dbinputs w e usedthefirstpartastheworkingdatabasefordbinputsandthe union of a half of the first part and a half of the second part asthe runtime database of the application.
in the experiments with abt dbinputs weusedthefirstpartbothastheworkingdatabase for dbinputs and the runtime database of the application.
this procedure allowed us to use testing and runtime databases of the same size in all experiments while guaranteeing of using only datatakenfromtheoriginaldatabasesoftheapplications.across multiplerepetitionsoftheexperiments weswappedtherolesof theformerandthesecondpartofoursplitoftheoriginaldatabases to mitigate possible biases induced by the specific splits.
for all applications but insurance for which we had no access to its database we referred to the database available in produc tion budgets or included in the downloaded material erpand tickets in march2020.for the insurance applicationwe relied on a plausible database independently designed and populated bytwocomputersciencemasterstudentsofouruniversity.thedesign of the database required to map each functionality into a database table and each field into a table column whereas the database population was performed manually.
since we cannot control the databaseoftheapplication wecouldonlyexecute abt dbinputs nequal on the insurance application.
table2providesstatisticsaboutthedatabasesthatweused.the erpdolibarr web application has the database with the largest number of tables and columns per table.
budgets the industrial applicationforbudgetmanagement hasamedium sizedatabase butthehighestnumberofrecords.
tickets themantisapplication hasalsoamedium sizedatabasebutwithlimitednumberofrecords.
finally the insurance application has the smallest database but a good number of record.
authentication.
exploring functionalities that depend on authentication is a well known challenge for automatic test generators because it is generally impossible for the test generator to guessthe password of a user or even decoding the password from thetable statistics on databases used by dbinputs database tables cols per tablemean recordsmin mean max tickets .
.
erp .
.
insurance .
.
budgets .
.
corresponding encrypted format stored in the database.
in our experiments we worked around this problem by making abt aware of the password of a user for each of the considered applications.
setup of competing approaches.
we refer to the random generationofinputvaluesasthebaselineapproachtocomparedbinputs to.
it simply consists of producing a random string of randomlength every time an input is required.
link exploits the web of data to generate test inputs.
as in its original paper we used dbpedia which includes semantically annotated data extractedfrom wikipedia as source knowledge base.
for both approaches we added a cache management system working the same as in dbinputs for the fairness of the comparison.
execution of the experiments.
we executed each technique timesoneachapplication foratotalof180executions.inparticular we executedall the techniques the3 configurations of dbinputs andthe2competingapproaches onthe tickets erpandbudgets applications while we only executed abt dbinputs nequaland the competing approaches on insurance since only the disjoint database was available.
overall the empirical evidence collected for each technique amounts to the generation of test cases per application and thousands of automatic interactions with the various inputforms requiringintotalmorethanonemonthofcomputation.theexperimental material includingtheimplementationof the three compared approaches and the experimental results are available at .
results on rq1 effectiveness of dbinputs figure summarizes for each technique the measurements about the forms executed with valid and invalid inputs across the experiments with abt dbinputs nequal abt dbinputs and abt dbinputs .the barsin theplots showthe numberof forms thateachtechniqueexecutedwithvalid summationtext.
appsf one andinvalid summationtext.
appsf one inputsacrossthethreeapplicationsthatcanbetested with all the configurations of dbinputs.
the dotted lines on the barsindicatethenumberofformsexercisedwithvalid summationtext.
appsf half andinvalid summationtext.
appsf half inputswithhalf timeconsistency.the solid linesindicate the numberof formsexercised with bothvalid andinvalidvalues summationtext.
appsf half withhalf timeconsistency.the toppartofeachbardistinguishesthenumberofformsexercisedby two configurations only and uniquely exercised by a single configuration of dbinputs to quantify the unique capabilityof a configuration to test certain forms compared to the others.
overall these plots show that abt dbinputs nequaloutperformed abt dbinputs and abt dbinputs on every metric it covers the highest number of forms with valid values more forms than abt dbinputs and more forms than abt dbinputs forms with valid inputs f one forms with invalid inputs f one abt dbinputs abt dbinputs abt dbinputs abt dbinputs abt dbinputs abt dbinputs executed by every configuration executed by two configurations executed by a single configuration f halffhalff half figure forms exercised by dbinputs.
itcoversthehighestnumberofformswithinvalidvalues more forms than abt dbinputs and more forms than abt dbinputs itistheconfigurationthatcoversthehighestnumberofforms not exercised by the other configurations and of the formscoveredwithvalidvalues and23 and16 oftheforms covered with invalid values are covered by at most one andnone of the competing configurations respectively.
it is superior as for the ability of consistently exercising forms withvalidandinvalidvalues anditissignificantlybetteronconsistentlyusing bothvalidandinvalidinputs 16formsconsistently exercised by abt dbinputs nequalversus and consistently exercised by abt dbinputs and abt dbinputs respectively .
the data indeed indicate that working with a disjoint dataset facilitatesdbinputsinthegenerationofvalidoutcomesinmore casesthanwiththeothertwoconfigurations.thisisclear forinstance in forms that require entering new values such as a form forcreatinganew account whichmayrequireanon existingusername to be successfully submitted.
conversely when dbinputs works with a database that is nearly the same as the application database it can easily generate valid values for forms that require enteringexistingvalues.despitethisintrinsicduality usingadisjoint database bringssome advantages.
in fact adatabase with all existingvalueshasnochancetoproduceavalidvaluefortheforms that require new values.
on the contrary with a disjoint database dbinputscanfirstcreateadomainentity e.g.
anewissueinabug tracking system and then select the same values used for creating that entity as inputs in other forms e.g.
in a search form thus satisfyingconstraintsonusingexistingvalues.thisisareasonwhy abt dbinputs nequalperformed better than the other approaches.
although abt dbinputs mayinprincipleappeartobeagood compromise in between of the other two configurations since the workingcopydatabase includesbothnewand existingvalues its effectiveness inevitably dependson the luck of selecting theright type of value at the right time.
even ifabt dbinputs nequalis the configuration that performed better thetwoalternativeconfigurationscoveredformsnotcovered byabt dbinputs nequal.
thisrevealsthe expected complementarity of various configurations and calls for future work on studying dbinputs strategies that exploit this complementarity.
forms with valid inputs f one forms with invalid inputs f one abt dbinputs abt linkabt randomabt dbinputs abt linkabt random executed by every technique executed by two techniques executed by a single technique f halffhalff half figure forms exercised by dbinputs random and link.
.
results on rq2 comparison figure5comparestheresultsof abt dbinputs nequal thebestdbinputs configuration according to the results reported above to the results of the competing approaches abt random and abt link.
the plots in this figure refer to all the considered appli cations including insurance and this is why the new plot of abt dbinputs nequalshows larger measurements than in figure .
.
.
.
.
.
total add edit search other operation categoryportion of valid outcomes technique 7 qsxw 7 .
7 5dqgrp figure6 portionofvalidoutcomesgeneratedbydbinputs random and link per operation category the results in the plots confirm the main hypothesis of our research thatis dbinputsismoreeffectivethanthecompetingapproaches in the generation of valid test inputs.
the plot on the left sideofthefigureshowsthat abt dbinputs nequallargelyoutperformed both abt link and abt random in generating valid inputs exercising up to distinct forms with valid outcome while abt link and abt random exercised only24 and 25distinct forms respectively.
the higher effectiveness of dbinputs with respect to the competingtechniquesisconfirmedalsofocusingontheformsexer cisedwithhalf timeconsistency since abt dbinputs nequal abt link and abt random consistently exercised and forms with valid inputs respectively.
74theplotontherightsideshowsthat abt dbinputs nequalperformed comparably wellto abt link andabt random in generatinginvalid inputs.
abt dbinputs nequalexercised a higher number of total forms but abt random achieved slightly better consistency exercising 29forms withhalf time consistency 2more formsthan the other techniques.
finally with reference to the extent to which the approaches consistentlyexercisetheformswithbothvalidandinvalidinputs f half abt dbinputs nequaloutperformed the competing techniques.
abt dbinputs nequal abt linkandabt randomconsistentlyexercised18 6and7formswithbothvalidandinvalidinputs respectively.
weanalyzedthesedatainfurtherdetailbyinspectingtherelative portion of valid inputs generated in each execution of a technique with a considered application that is the ratio r summationtext.
ff summationtext.
ff f wherefare the forms of an application.
we computed this indicatorbothwithrespecttoallformsoftheapplications andatthelevel of the subsets of forms that represent different types of operations.
tothis end weclassifiedtheconsideredinput formsaccordingto fourpossiblecategoriesofoperations createoperations whose goal is creating new domain entities updateoperations whose goalisupdatingexistingdomainentities searchoperations whose goal is searching for domain entities and otheroperations i.e.
all remainingoperations.figure6visualizestheboxplot minimum maximum medianandquartiles ofthedistributionof r peroperationcategoryandintotalfor abt dbinputs nequal abt linkand abt random.
resultsshowthat abt dbinputs nequalgeneratesahighernumber ofvalidvaluesthanabt linkandabt randomconsistentlyon every class of functionality.
we tested the statistical significance of the results comparing abt dbinputs nequalto both abt link and abt randomusingthewilcoxontest.wecomputedtheeffect size to assess the magnitude of the difference and used a significant levelof0.05withbonferronicorrection consideringthatweperformed multiple tests.
the results indicate that abt dbinputs nequal performed significantly betterthanabt linkandabt randomin all cases but the comparison between abt dbinputs nequaland abtlink for searchoperations where the difference is not significant.
the effect size is always large effect size greater than .
withtheexceptionofthecomparisonsbetween abt dbinputs nequal and abt link for addoperations and the comparison between abt dbinputs nequaland abt random for searchoperations where the effect size is medium effect size between .
and .
.
thedualinterpretationoftheplotsinfigure6isthatthecompetingapproachesgeneratemoreinvalidvaluesthan abt dbinputs nequal.
however aswealreadydiscussedwithreferencetofigure5 the ability of abt dbinputs nequalof generating more valid inputs than the other approaches leads to exercising a larger number of forms of the applications which in turn results in an increased testing thoroughness withoutcompromisingthecapabilityofexercising forms with invalid inputs.
letusremarkthattheresults obtainedwith abt linkdepend on the domain specific characteristics of the applications undertest that are not well aligned with the dbpedia knowledge base thatlinkrefersto thusmakingabt linkdifferonlyslightlyfromabt random.
this confirms the main weakness of using semantic web technologies to identify input values.
we inspected the forms that only a technique exercised with eithervalidorinvalidinputstobetterunderstandandexemplifythe success cases.
dbinputs successfully entered domain specific and application specificvaluesthattheotherapproachescannotobtain.
for instance dbinputs successfully entered oda codes whichare unique codes that identify orders as well as iban bic and swiftcodesinthe budgetsapplication customeridentifiersinthe erpapplication alargesetofcoherentandheterogeneousvalues that span multiple forms as needed for filing an insurance in the insurance application issueidentifiersinthe tickets application.
notethatoftenthesevalueshavetosatisfybothdomain specific constraints and application specific checks implemented in the web forms that require these values e.g.
entering values that are new or already exist in the database of the application which are almost impossible for the competing approaches to fulfill.
nonetheless therearesomecomplementaritiesamongtheapproaches.forinstance abt linkmanagedtoenterinvaliddiscount valuesinthe erpapplication whichdbinputsfailedtocover.abtrandom easily entered invalid values in input fields that check for a specific syntax e.g.
date values in the erpapplication that were sometime hard to cover with dbinputs.
.
discussion the empirical results show that dbinputs can improve the ability of a test generator to exercise forms with valid values.
this is importanttoachieveagoodexploratoryabilityandbothreachand exercise the functionalities of the web application under test.
the configuration with a database that is disjunct from the one used by the application consistently produced the best results and thus it is also the recommended configuration to use.
whiledbinputsprovedtobeeffectiveinconsistentlyproviding the test cases with valid input data its main weakness depends on the database itself.
excluding the cases where the working copy database is populated with few rows or several empty null values thedatastoredinthedatabasearerarelyinvalidbyconstruction sincetheyreflectapossiblevalidstateoftheapplicationundertest making domain specific constraints hard to invalidate.
thismay still occur if the database schema or the web page itself are poorly designed e.g.
acolumnpresentsaverygeneric orunintelligible name or the input field has no relevant identifiers identifying bad matchesbetweentheinputsfieldsandthedatabasecolumnsand consequently likely returning invalid data.
whilegeneratingadominantnumberofinvalidvaluespenalizes the effectiveness of the exploration the results show that link andrandommanagedtogenerateuniqueinvalidvaluesforsome forms.
this suggests that dbinputs link and random can becomplementary especially in their capability to produce invalid values andanoptimaltestgenerationstrategycouldbe potentially derivedbycombiningthem.thisishoweveroutsidethescopeof this study.
.
threats to validity themaininternalthreatstothevalidityofourexperimentarerelatedto i themanualidentificationoftheinputformsthatevaluate 75constraints on their inputs and ii the design of the logger that collectsthedataonwhethertheseformsgetexercisedwithvalid and invalid values at runtime.
to mitigate these risks we carefully inspectedtheapplicationsmultipletimes andwethoroughlytested the logger with many executions and we are in the end confident of the accuracy of the current data.
the external validity threats concern the generality of our findings.ourresultsrefertoasignificantsampleofinputforms in total that consider different application domains and databases with different amounts of tables and columns.
we repeated each experiment times to control for the randomness in the input generation and test generation algorithms thus obtaining stableexperimental evidence.
however we are aware that we cannot claimthevalidityofourfindingsforanypossibleapplication application domain and type of database and we are working to new experiments to extend the current empirical data further on.
a specific threat concerns whether the effectiveness of dbinputscangeneralize totest generators otherthan abt.
inprinciple dbinputs works in the same way independently on the test generator that uses it and there is no obvious technical reason why the choice of the test generator should affect the results.
we see this as an interesting direction for extending our results in the future.
related work systemtestingtechniques andwebtestingtechniquesinparticular focusonthegenerationofsequencesofeventsthatcancovertheex ecutionspaceoftheapplicationundertest.theexistingtechniques embrace different strategies including the randomized model based andinvariant driven exploration oftheexecutionspace.complementaltoeventgeneration these techniques use different approaches to fill the input fields with test inputs while interacting with the application under test.
generating random inputs is inexpensive but may easilyfailwiththewebformsthatincludeconstraintsonthevalidityof the inputs.
indeed our experiments indicate that abt random interactswellwiththeformswithoutconstraints butabt dbinputs outperforms abt random with the many forms that do.
an approach is to prepare a manually curated set of values and pass them to the test generator .
a plain list of values is relativelyeffective sinceitdoesnotguaranteethattherightvalueisselected for the right input fields.
for instance the list may includedatevalues butthetestgeneratormayeasilyendupwithselecting other values in the list for the date constrained input fields.
a more sophisticated approach consists of associating a type to each value in the curated list .
while this may increase the effectivenessofthetestingprocess itrequiresdeveloperstoprepare an extensive set of values and associated types for the many forms of the application under test which limits the practical benefits of the approach.indeed dbinputs offers abetter compromise since it does not require manual effort.
some solutions address the problem of automatically generating syntacticallyandsemanticallyrelevantinputsbyrelyingon external sources.
mcminn et al.
exploit the web as source of data retrievingthe inputs with web searches .
bozkurt and harman define a strategy that searches for web services that can be stimulated to producevaluesofthetypesneededduringthetestingprocess.bothlink andtheapproachbywanwarangetal.
exploitedthe webofdataandsemantic webtechnologiestoretrievevaluesof the proper type that can be used to test applications.
as we already commented the techniques that rely on external sources can hardly produce application specific data e.g.
the identifierofanissueenteredintoanissuetrackingsystem .theycan producesomedomain specificdata butonlyiftheexternaldomain andthedomainoftheapplicationarealigned whichisnotoften the case.
for instance in our evaluation link struggled copying with the four web applications and their domains.
dbinputs successfully enriches automatic web testing with the abilityofautomaticallyidentifyingbothdomain andapplicationspecific data by reusing the application database for testing purposes.ourresultsshowthatdbinputscansignificantlyimprove thecapabilityofthetestgeneratortoexercisethefunctionalitiesof the application under test.
conclusions thegenerationofvalidinputvaluescanbeabarriertoautomatic webtesting.indeed itisoftennecessarytoenterdomain specific and application specific values into web forms to successfully executethecorrespondingfunctionalities.failingtoobtainthesevaluesmaysignificantlylimittheeffectivenessofthetestcasesthatwould not be able to exercise some of the functionalities consequently missing to explore part of the execution space of the application.
toalleviatethisproblem thispaperinvestigatestheideaofusing theapplicationdatabaseasdatabaseofvaluesthatcanbeexploitedfortestcasesgeneration.itpresentsthedbinputstechnique which originally embodies this intuition.
dbinputs automatically handlesthemismatchbetweenthecontentofthewebpagesandthe structure of the database extracting inputs useful for testing.
in particular dbinputsexploitssyntacticandsemanticdistanceswith matching heuristics that successfully map the input fields to thecolumns of the tables in the database.
this mapping enables the extractionofvaluesfromtherecordsinthedatabasewithwhich dbinputs fills the input fields of the application under test.
theempirical evaluation that we reported in the paper shows that dbinputs can outperform the existing approaches based on either randominputsoronretrievingdatafromexternalsourcesavailable on the web.
wearecurrentlyinvestigatinghowtoextenddbinputstoreuse databases across applications thus further improving its ability of obtaining heterogeneous inputs to reveal problems in the appli cations under test.
we are also considering to extend dbinputsto mobile applications to investigate the effectiveness of the so lution in the mobile domain.
finally we intend to evaluate the scalabilityandfeasibilityofthetechniquewhenlargerdatabases and applications are involved.