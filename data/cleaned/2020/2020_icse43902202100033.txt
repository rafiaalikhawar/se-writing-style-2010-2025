an empirical study of refactorings and technical debt in machine learning systems yiming tang raffi khatchadouriany mehdi bagherzadehz rhia singhx ajani stewarty anita rajay cuny graduate center ycuny hunter college zoakland university xcuny macaulay honors college email ytang3 gradcenter.cuny.edu raffi.khatchadourian hunter.cuny.edu mbagherzadeh oakland.edu rhia.singh macaulay.cuny.edu ajani.stewart42 myhunter.cuny.edu anita.raja hunter.cuny.edu abstract machine learning ml including deep learning dl systems i.e.
those with ml capabilities are pervasive in today s data driven society.
such systems are complex they are comprised of ml models and many subsystems that support learning processes.
as with other complex systems ml systems are prone to classic technical debt issues especially when such systems are long lived but they also exhibit debt specific to these systems.
unfortunately there is a gap of knowledge in how ml systems actually evolve and are maintained.
in this paper we fill this gap by studying refactorings i.e.
source to source semanticspreserving program transformations performed in real world open source software and the technical debt issues they alleviate.
we analyzed projects consisting of .
mloc along with manually examined code patches.
the results indicate that developers refactor these systems for a variety of reasons both specific and tangential to ml some refactorings correspond to established technical debt categories while others do not and code duplication is a major crosscutting theme that particularly involved ml configuration and model code which was also the most refactored.
we also introduce and new ml specific refactorings and technical debt categories respectively and put forth several recommendations best practices and anti patterns.
the results can potentially assist practitioners tool developers and educators in facilitating long term ml system usefulness.
index terms empirical studies refactoring machine learning systems technical debt software repository mining i. i ntroduction in the big data era machine learning ml including deep learning dl systems are pervasive in modern society.
central to these systems are dynamic ml models whose behavior is ultimately defined by their input data.
however such systems do not only consist of ml models instead ml systems typically encompass complex subsystems that support ml processes .
ml systems like other long lived complex systems are prone to classic technical debt issues yet they also exhibit debt specific to such systems .
while work exist on applying software engineering se rigor to ml systems there is generally a gap of knowledge in how ml systems actually evolve and are maintained.
as ml systems become more difficult and expensive to maintain understanding the kinds of modifications developers are required to make to such systems our overarching research question is of the utmost importance.
to fill this gap we performed an empirical study on common refactorings i.e.
source to source semantics preserving program transformations a widely accepted mechanism for effectively reducing technical debt in real world open source ml systems.
we set out to discover i the kinds of refactorings both specific and tangential to ml performed ii whether particular refactorings occurred more often in model code vs. other supporting subsystems iii the types of technical debt being addressed and whether they correspond to established ml specific technical debt and iv whether anynew potentially generalizable ml specific refactorings and technical debt categories could be derived.
knowing the kinds of refactorings and technical debt typically associated with ml systems can e.g.
help improve existing and drive new ml specific automated refactoring techniques ide code completion and automated refactoring mining approaches.
in general the results i advance knowledge of how and why technical debt is actually manifested in ml systems and how refactorings are employed to alleviate such debt ii help tool designers comprehend the struggles developers have with evolving ml systems iii propose preliminary recommendations best practices and anti patterns for practitioners in evolving long lasting ml systems effectively and iv assist educators in teaching techniques for combating technical debt in ml systems.
our study involved analyzing 26projects consisting of .2mloc along with 327manually examined code patches.
refactorings were taxonomized labeled as being performed in ml code or not and related to the ml specific debt they alleviated.
our study indicates that i duplicate code elimination largely performed by introducing inheritance was a major crosscutting theme in ml system refactoring that mainly involved ml configuration andmodel code which was also the most refactored code ii subtle variation of different yet related ml algorithms and their configurations were a major force driving code duplication iii code generalization reusability and external interoperability essential se concepts were among the least performed refactorings and iv configuration duplicate model code and plain old data types were the most addressed technical debt.
our contributions can be summarized as follows refactoring hierarchical taxonomy from 327patches of projects manually examined we build a rich hierarchical crosscutting taxonomy of common generic and mlspecific refactorings whether they occur in ml related code code specific to ml related tasks e.g.
classifiers feature extraction algorithm parameters and the mlspecific technical debt they address.
ieee acm 43rd international conference on software engineering icse .
ieee table i studied subjects.
subject dom appl kloc studied per cmts kws exe affectivetweets nlp social .
corenlp nlp speech .
datacleaner analyt.
vis.
.
deeplearning4j dl math .
digitrecognizer cv images .
elasticsearch search outliers .
elki data mine various .
foundry ml ai .
grobid nlp text .
jenetics gp optim.
.
knime core analyt.
vis.
.
liblevenshtein nlp text .
mahout dist.
ml math .
mallet nlp text .
moa data mine streams .
modernmt mt speech .
mutters nlp bots .
neo4j nlp nlp db .
neuronix cv biomed .
smile ml stats .
submarine dist.
dl workflow .
tablesaw analyt.
vis.
.
trainable seg cv images .
vespa dist.
dl vis.
.
weka ml stats .
total .
new ml specific refactorings technical debt categories we introduce 14and7new ml specific refactorings and technical debt categories respectively.
recommendations best practices anti patterns we propose preliminary recommendations best practices and anti patterns for long lasting ml system evolution from our statistical results as well as an in depth analysis.
complete results of our study are available in our dataset .
ii.
m ethodology we study common ml system refactorings using a mostly manual analysis.
refactorings unique to ml systems are extracted.
from this study we may find refactorings specific to ml systems that may assist both engineers and data scientists in effective evolution and management of ml technical debt.
a. subjects our study involves 26open source ml systems tab.
i comprising .2million lines of source code git commits and .
years of combined project history averaging .
years per subject.
they vary widely in their domain column dom and application column appl as well as size and popularity.
all subjects have their sources publicly available on github exhibit non trivial metrics including stars forks and number of collaborators and include a mix of ml libraries frameworks and applications.
they have also been used in previous studies .
subject criteria includes having at least one commit whose log message mentions refactor and at least a portion of the system must involve ml.
we favored ml systems that were mostly written in java which especially as a supporting language is popular for large scale ml .
however although supporting subsystems were mainly written in java model code may be written in other languages such as python and c .
this was done to facilitate refactoring determination statically typed single parent inheritance both manually andvia the aid of assisting tools 1regardless of language model and non model code alike were manually examined.
to find changesets patches representing refactorings we mined repositories for commit logs mentioning keywords column kws of tab.
i is the number of commits containing refactor in their log messages.
while this may represent a proper subset of actual refactorings this yielded commits across 26projects.
we then randomly selected a subset of these commits to examine manually as portrayed by column exe.
b. commit mining to discover commits with changesets that included refactorings we searched the commit logs which were extracted viagit log .
a single keyword refactor was queried via the regular expression b ?i refactor which matches strings containing the word refactor in a case insensitive ?i manor.
the bat the beginning of the expression indicates a word boundary at the start of the term.
this allows the expression to match the term refactor ing but not for example arabicfeatu refac tory a class in corenlp .
c. refactoring identification random matching commits were chosen for manual inspection to verify whether they contained one or more refactorings automated tools were not used in this process.
two of the authors are software engineering and programming language professors with extensive expertise in software evolution technical debt and empirical software engineering.
another author is a data mining and machine learning professor with substantial proficiency in artificial intelligence and software engineering.
although the researchers did not converse during the initial identification and classification process to avoid bias this mix of expertise is effective in studying software engineering tasks in machine learning systems.
the researchers convened regularly during the study as well as at the end for finalization to solidify the results.
cohen s kappa coefficients for refactoring identification classification and ml related code identification were .
.
and .
respectively.2as the authors did not always have detailed knowledge of the particular systems only changes where a refactoring was extremely likely were marked as such.
the authors also used commit comments and referenced bug databases to ascertain whether a change was a refactoring a common practice .
type annotations when available were also helpful in assessing semanticspreservation a key characteristic of refactorings.
only master branches were used.
refactorings in all parts of the system were considered as opposed to only modules responsible for ml.
this is done because only a small fraction of real world ml systems is composed of ml code .
d. refactoring classification once refactorings were identified to comprehend the kinds of refactorings performed in ml systems the authors studied the code changes to determine the refactoring category whether 1refactoringminer was only used for classification cf.
ii d .
2moderate agreement is expected the team has mixed ml se expertise.
239the refactoring took place in ml subsystems ml related code and the ml specific technical debt category if any the refactoring addresses.
the ml specific technical debt category may coincide with one put forth by sculley et al.
or it may be a new ml specific technical debt category of our own devise.
islam et al.
also make ml specific categorizations in their work.
categories were then formed into a hierarchy.
to assist in the classification fortunately many commits reference bug reports detailing the task at hand.
this information proved highly valuable in understanding the refactorings their motivations and how they relate to the system.
on several occasions we also contacted developers for clarification.
refactorings combat technical debt and different refactorings can reduce different kinds of debt.
therefore some categories may appear under different parent categories in the hierarchy.
also some of the refactorings were more isolated i.e.
a single changeset consisted mainly of one type of refactoring.
for such cases we used a more specific sub category where possible.
conversely changesets containing several intertwined related refactorings were grouped into more general parent categories.
for changesets that were difficult to generalize we relied more heavily on commit log messages and issue tracker discussions.
to aid the manual verification refactoringminer a tool for refactoring detection in commit history was occasionally used to help isolate larger commits by identifying fine grained refactoring clusters.
we used terms like cluster and train in the commit log messages to help identify whether the changesets were related to ml.
we also considered matrix operations to be ml related.
while such operations may be more general since the subjects were ml systems it is likely that they were being used for ml.
package names were also used to decipher whether code was related to ml e.g.
elasticsearch has a specific ml plug in which is directly reflected in the package name.
iii.
r esults in this section we mainly summarize the study results using data noting trends exceptions and unexpected outcomes.
iv on the other hand consolidates and comments on the main findings and connects the different parts of the results.
related discussion in iv is referenced where appropriate.
a. quantitative analysis from the commits manually examined column exe tab.
i we found 285true refactorings depicted in column cnt of tab.
ii.
of these 165appeared in ml related code column mlc tab.
ii .
finding these refactorings and understanding their relevance required a significant amount of manual labor that may not be feasible in more large scale automated studies.
false positives commits whose logs contained the keyword but were not refactorings amounted to .
.
reasons for false positives varied and included using the keyword in a different context e.g.
as a reminder hould refactor the training code though .
others include situations where developers liberally used the term refactor i.e.
they were actually adding or altering existing functionality .table ii discovered refactorings nonhierarchical .
group category abbr cnt mlc generic defer execution def make immutable imm make more reusable rus generalization gen make more interoperable int simplify regex rgx concurrency con safety saf dead code elimination ded make more extensible ext new language feature lng test tst unknown ukn improve performance prf duplicate code elimination dup clean up cln reorganization org total ml specific make algorithms more visible viz new make matrix variable names more verbose vrb monitor feature extraction progress mon push down hyperparameters hyp pull up policy plc remove unnecessary matrix operation rma replace flags with polymorphic classifier cls replace flags with polymorphic feature extraction fet replace primitive array with matrix amt replace with sparse matrix smt replace primitives with rich prediction prd replace rich model parameter with primitives rmp replace primitives with rich model parameter prm total grand total there were also two .
cases where we were not able to determine whether the commit was a refactoring due to a lack of domain knowledge and extremely large commit sizes.
refactoring categories from the manual changes we devise a set of common refactoring categories.
refactorings were then grouped into these categories as shown in fig.
and tab.
ii column abbr is the refactoring s abbreviation .
fig.
presents a hierarchical categorization with varying levels of detail of the refactorings found in the ml system subjects.
refactorings are represented by their category name followed by their refactoring counts.
categories without instances are considered abstract i.e.
they only group together other categories.
some refactoring categories are crosscutting appearing under multiple categories.
for this reason tab.
ii portrays a nonhierarchical view of fig.
including a column for each refactoring category regardless of its parent.
refactorings are separated into two top level categories column group of tab.
ii namely those specifically related to ml systems ml specific and those tangentially related i.e.
those that apply to general systems generic .
categories in the former division are novel they were formulated as a result of this study and are a key contribution of this work.
a generic refactorings generic refactorings are further categorized into those related to code reorganization org e.g.
modularization improving performance prf multi threading variable extraction those made within test code or making code more amenable to testing test tst and migration 3all ml specific refactorings were performed on ml related code as such column cnt column mlc for ml specific refactorings in tab.
ii.
240fig.
discovered refactorings hierarchical .
to new language features lng e.g.
diamond syntax multi catch blocks enumerated types replacing loops with streams .
others include duplicate code elimination dup i.e.
where redundant possibly scattered code is centralized making code more generally applicable generalization gen improving safety saf e.g.
allocating more memory for buffers holding tensors eliminating dead code ded improving concurrency con e.g.
adding asynchrony regular expression simplification rgx making code more interoperable int e.g.
making private apis public code de generalization e.g.
by removing generics and deferring execution def e.g.
making processing on demand .
clean up cln refactorings are general simplifications e.g.
removing unnecessary casts while unknown ukn see tab.
ii represents situations where the refactoring category was indeterminable without further domain knowledge or developer input.
only .
of refactorings had unknown categories.generic reorganization was the largest generic category its largest subcategory was duplicate code elimination .
generic reorganization duplicate code elimination differs from generic duplicate code elimination as duplicate code elimination may or may not be part of a reorganization.
for example removing duplicate code by introducing inheritance or extracting methods can be considered a reorganization.
duplicate code elimination was a major refactoring theme in ml system evolution and we conjecture such systems are more prone to duplication due to slight variations in learning algorithms see iv a .
in general categories crosscut e.g.
performance because there are different ways to accomplish technical debt reduction and there are different debt categories with the same fix refactoring .
performance improvement refactorings for instance were both generic prf e.g.
converting reference types to primitives and ml specific e.g.
making matrices sparse smt leading to finding in fig.
.
performance improvement and reorganization e.g.
inheritance introduction refactorings crosscut concerns affecting multiple categories both specifically and tangentially associated with ml systems and were among the most frequent .
.
duplicate code elimination .
was a major crosscutting ml system refactoring theme combating debt in various ways.
we expected more dead code elimination however though it crosscut it was notusual .
.
making code more generalizable reusable and interoperable with libraries are essential se tasks that were among the least performed refactorings .
.
inheritance introduction appearing under six categories the most of any other category was a common and crosscutting way to eliminate duplication in ml systems and may be key in coping with subtle variations intrinsic to various ml algorithms.
despite being the smallest subsystem ml related code was refactored the most .
.
the majority of performance .
duplicate code elimination .
and extensibility .
refactorings were in ml related code while new language feature migration .
and test related .
refactorings were among the least.
although .
of dead code elimination refactorings occurred in ml related code only one removed a dead experimental mlrelated code path.
configuration duplicate model code and plain old data type were the most tackled technical debt categories .
.
and .
respectively .
configuration duplicate model code and plain old data type debts were mainly tackled by reorganization .
duplication elimination .
and replacing primitives with rich model parameters .
dead experimental code paths .
abstraction .
and boundary erosion .
were among the least addressed debts introduced by sculley et al.
.
custom data types duplicate feature extraction code and model code reusability .
combined were among the least identified new categories.
configuration debt .
was the most significant category from sculley et al.
while duplicate model code was the most substantial of our newly introduced categories .
.
duplicate code elimination was a major refactoring .
in reducing ml specific technical debt overwhelming related to configuring and implementing different yet related ml algorithms .
.
inheritance and other reorganization refactorings were commonly .
used to reduce a variety of ml specific debt especially configuration .
.
fig.
findings.
at11.
duplicate code elimination was the largest category besides the umbrella like categories of clean up and reorganization and crosscut several categories meaning that it combated technical debt in several different ways.
this leads to finding fig.
further discussed in iv a. generic dead code elimination ded which may be accomplished via reorganization or deletion was another refactoring that crosscut categories but was not prevalent only .
.
however we expected to see more of this category as eliminating dead experimental code paths was a focal category of sculley et al.
.
ml systems typically use conditional branches for testing new experimental features and other ml algorithm improvements.
once branches are irrelevant either because they were incorporated or deemed unnecessary thecorresponding code should be removed leading to finding in fig.
.
the relation of finding to dead experimental code paths is discussed below with finding .
generic generalization gen refactorings introduced inheritance and generics and made code more extensible ext e.g.
via extracting parameters and interfaces .
such ext refactorings .
were also crosscutting under generalization de generalization and reorganization.
code was also made more interoperable int by externally exposing internal c functions extern and replacing custom data types with standard ones e.g.
to interface with tensorflow leading to finding fig.
.
b ml specific refactorings ml specific refactorings are further divided into several categories corresponding to whether they involved reorganization org improving performance prf e.g.
removing unnecessary matrix operations rma and many new refactorings that we categorized as specifically applicable to ml related code.
these include replacing primitive types representing learning model parameters with objects prm and the opposite rmp replacing primitive types representing model outcomes predictions with objects prd replacing primitive type arrays with matrix objects amt monitoring the progress of possibly lengthy feature extraction mon and improving program comprehension by making the names of variables related to matrix calculations more verbose vrb .
this last category emerged as we noticed many matrix calculations a data structure highly used in ml had numerous temporary variables.
improving these variable names can potentially facilitate matrix calculation evolution.
ml specific reorganization again involved inheritance introduction.
in fact the introduce inheritance category appears six times in fig.
the most of any other category and is mostly used for duplicate code elimination through reorganization.
this leads to finding of fig.
discussed in iv b. two refactoring categories both involving the conversion of flag i.e.
intermediate boolean values checking to polymorphism further divided ml specific inheritance introduction.
specifically the categories involve replacing many flags with polymorphic classifier cls and feature extraction fet objects respectively.
these refactorings simplify the future addition and usage of new classifiers and features.
ml specific reorganization also included two new mlspecific refactorings related to class hierarchy organization namely pulling up clustering policies plc and pushing down hyperparameters hyp .
learning algorithm variants may have similarities in their implementation.
as such plc refactorings similar to p ull upmembers ch.
centralize otherwise scattered and duplicated code among classes representing the different policies cf.
iii b 1a .
hyperparameters on the other hand are used to configure ml algorithms and hyp similar to p ush down members is an ml specific refactoring where hyperparameters are separated into individual algorithms.
while this adds some duplication it may improve cohesion and allow the hyperparameters to be used in ways more akin to the algorithms they configure cf.
iii b 2a .
both of these refactorings 242generic refactoringcount fig.
discovered generic refactorings nonhierarchical .
operated on code that previously used inheritance which is why there were not categorized under inheritance introduction.
generic refactorings performed on ml related code as seen in tab.
ii all ml specific refactorings were made to mlrelated code i.e.
the code directly involved with learning processes.
as there were a significant number of generic refactorings made to the ml systems we were also interested in understanding the kinds of generic refactorings that were being performed to model code in these systems.
while the ml specific refactoring categorization aims to unveil new refactorings specific to ml systems this section sets forth to understand which existing refactorings are made to this code.
such information may provide insight into the struggles that developers have in maintaining and evolving ml systems and the refactorings that can help.
for comparison purposes fig.
diagrammatically portrays only the generic refactorings including their overall counts left blue bars and counts of the refactorings appearing in ml related code right redbars .
larger more definitive categories with the most ml related code changes were performance improvements .
duplicate code elimination .
and extensibility improvements .
.
most of these took place in ml related code.
in some respects it surprising that the majority .
of allrefactorings were performed in ml related code as ml subsystems typically the smallest subsystem of ml systems leading to finding fig.
.
finding coincides with that of dilhara et al.
that developers update ml libraries more often than traditional libraries.
new language feature migration lng and test related tst refactorings were some of the least performed on ml code leading to finding in fig.
.
finding and its relation to finding is discussed in iv a .
per finding dead code elimination .
was minimal nevertheless most such refactorings occurred within ml related code .
.
one might expect these are the ml related code path eliminations discussed by sculley et al.
however only one of the four refactorings did indeed remove an experimental code path cf.
tab.
iii leading to finding fig.
.
ml specific technical debt vs. refactorings recall that refactorings were classified on three fronts i.e.
their categories whether they took place in ml subsystems tab.
ii and the ml specific technical debt category if any the refactoring addresses.
tab.
iii presents the identified ml specific debt categorization rows and juxtaposes them with their corresponding refactoring categories columns abbreviations from tab.
ii .
debt categories are grouped by existing and new categories that have been formulated as a result of our study.
a technical debt finding fig.
summarizes the most tackled debt categories.
configuration and plain old data type ml specific debt categories are classical while duplicate model code is new.
configuration debt deals with configurable ml system options including the features and data utilized algorithm specific learning settings pre and post processing and evaluation methods employed .
duplicate model code occurs when code duplication exists in core learning code e.g.
classification prediction and makes adding new and changing existing learning algorithms error prone.
it is especially prone to situations where many learning algorithm variants are utilized.
plain old data type debt occurs when rich information used and produced by ml systems is encoded using primitives making for example the purpose of hyperparameter indecipherable and predictions less explainable .
configuration debt was addressed by several refactorings e.g.
duplication elimination dup extensibility ext .
.
plain old data types was more even and widespread spanning six refactorings including replacing i primitives with rich predictions prd and ii primitive arrays with matrix objects amt leading to finding .
dead experimental code paths are those used to prototype new learning algorithm variants.
if successful they are eventually incorporated into the mainline logic making the experimental paths irrelevant and disabled .
leaving such paths in code hinders developers ability to later add new and modify existing algorithms.
abstraction debt arises from a lack of standard interfaces and constructs e.g.
those in relational databases that may be subtly corrupted or invalidated by the fact that data influences ml system behavior while boundary erosion amounts from a lack of modular boundaries between ml subsystems .
finding discussed in iv c summarizes the least tackled debt.
overall only three of the categories established by sculley et al.
were prevalent i.e.
configuration .
plainold data type .
and multiple language debt .
.
we also found that duplicate model code .
model code comprehension .
and model code modifiability .
were the only prevalent new categories leading to finding .
model code modifiability is specific to ml algorithm encapsulation as opposed to traditional data encapsulation.
ml developers must incorporate a variety of learning algorithms that are subsequently evaluated and compared.
the inability to abstract learning algorithm variations and make learning components extensible may be detrimental to ml systems.
b refactorings duplicate code elimination dup .
was among the refactorings that tackled the most technical debt spanning such categories as duplicate model code .
of dup refactorings configuration .
243table iii discovered ml specific technical debt vs. refactoring categories.
grouptechnical debtrefactoringamt cls fet gen hyp lng mon plc rma russmt viz vrb prd ded int prf saf cln prm ext dup org total existing dead experimental code paths abstraction boundary erosion glue code prototype monitoring and testing multiple languages plain old data type configuration total new custom data types duplicate feature extraction code model code reusability unnecessary model code model code comprehension model code modifiability duplicate model code total grand total listing commit 3eba6f26 inmahout refactored clusteringpolicies into hierarchy under new abstractclusteringpolicy .
.
.
public abstract class abstractclusteringpolicy implements clusteringpolicy public vector classify vector d clusterclassifier p list cluster models p.getmodels .. 5public class canopyclusteringpolicy implements clusteringpolicy extends abstractclusteringpolicy public vector classify vector d list cluster models vector pdfs new densevector models.size .. 10public class dirichletclusteringpolicy implements clusteringpolicy extends abstractclusteringpolicy public vector classify vector d list cluster models vector pdfs new densevector models.size .. duplicate feature extraction code .
and monitoring and testing .
which deals with ml evaluation.
from these results a central theme emerges code duplication is extensive in ml systems and presents itself mainly on two fronts in configuration and in model code.
in other words code duplication infects configuring learning algorithms and in the implementation of the learning algorithms themselves leading to finding of fig.
.
finding in the context of findings and is discussed in iv a. reorganization including inheritance introduction was also a common way to reduce technical debt in ml systems accounting for .
of refactorings combating ml specific technical debt.
reorganization also spanned 16technical debt categories with a major focus on configuration debt .
leading to finding .
finding along with its relation to finding is discussed in iv b. b. qualitative analysis we highlight refactorings and ml specific technical debt with examples summarize causes symptoms and fixes in tab.
iv and propose preliminary best practices and anti patterns.
rows in tab.
iv correspond to debt categories discussed below.
duplicate model code debt a ml org plc duplicate code elimination dominated the refactorings in ml related code and crosscut multiple1 favor inheritance to abstract learning algorithm variations thereby reducing redundant model code.
adding some duplicate code via class hierarchy reorganization may help focus ml algorithm configuration especially when using dependency injection.
favor polymorphism over flags when many ml algorithm variants exist to reduce to configuration debt.
to facilitate ml system evolution use descriptive temporary variable names especially for matrices.
since ml has many algorithms for similar tasks restructure code e.g.
method extraction for greater reusability among learning algorithm variants.
ml libraries imposing custom numeric data types should include conversion code to built in types.
fig.
best practices.
listing commit 59f39c7b indatacleaner refactored components to have a training analyzer per algorithm.
public class mltraininganalyzer ... public abstract class mltraininganalyzer ... configured numberproperty negative false zero false int epochs ... public class randomforesttraininganalyzer extends mltraininganalyzer configured numberproperty negative false zero false int epochs ... public class svmtraininganalyzer extends mltraininganalyzer configured numberproperty negative false zero false int epochs ... categories.
consider a p ull uppolicy plc refactoring in lst.
.
there are multiple classes e.g.
lines and representing different clustering algorithm policies.
each class previously implemented a common interface however as interfaces do not contain functionality an abstract class is introduced on line that encapsulates the common policy functionality.
as a result the duplicated model code on lines and are replaced with polymorphic calls to classify on line leading to best practice fig.
.
configuration debt a ml org hyp while plc refactorings centralize ml related code others do the opposite.
consider the p ush 244table iv common attributes of ml specific technical debt categories discussed in iii b. debt situation cause symptoms fixes duplicate model codecode duplication in learning code e.g.
classification prediction.learning algorithms have many variants with subtle differences.adding new changing existing model code is error prone.inheritance introduction class hierarchy reorganization.
configuration learning algorithms have many configurable options.configuration is treated as an afterthought .each configuration line has a potential for errors.class hierarchy reorganization duplicate code elimination etc.
model code comprehensionmany temporary matrix variables perf vs. comprehension trade offs.variables poorly named unnecessarily sacrificing comprehension.reasoning about and evolving model code is made difficult.more verbose matrix variable names inheritance introduction.
model code reusabilityadding new models requires duplicating existing code.model code is insufficiently modularized.reusing existing model code is made difficult and error prone.reorganization method extraction.
unnecessary model codematrix calculations may have performance bottlenecks.unnecessary matrix apis.
poor performance.
replace expensive apis with calculations in existing traversals.
custom data typesproject specific data types used instead of built in types in ml.library dependencies may impose custom data types.interoperating with other libraries can be difficult.widespread modifications involving type replacement or conversion.
listing commit incorenlp merged remote branch crfstochastic fix refactored crfclassifier.
crfclassifier corelabel choosecrfclassifier seqclassifierflags flags crfclassifier corelabel crf null if flags.usefloat crf new crfclassifierfloat corelabel flags else if flags.nonlinearcrf crf new crfclassifiernonlinear corelabel flags else if flags.numlopexpert crf new crfclassifierwithlop corelabel flags ... return crf ... properties props stringutils.argstoproperties args crfclassifier corelabel crf new crfclassifier props seqclassifierflags flags new seqclassifierflags props crfclassifier corelabel crf choosecrfclassifier flags down hyperparameters hyp refactoring snippet in lst.
.
several hyperparameters e.g.
line were de centralized from the parent and copied into subclasses of different learning algorithms lines and .
while adding some duplication it allows us to have much more specific hyperparameters apply to the particular algorithm instead of trying to make a one size fits all parameter selection .
though the field declarations above are identical note the annotations on lines and .
in this case inheritance may make it more difficult to configure hyperparameters when e.g.
using dependency injection and different hyperparameters require varying values leading to best practice in fig.
.
b ml org inh cls configuration debt was the largest discovered technical debt category.
especially interesting was the management of flags corresponding to ml configuration parameters as ml system configuration is increasingly unwieldy giving way to a configuration parameter server design pattern .
consider the r eplace flags with polymorphic classifier cls refactoring in lst.
where large portions of parameter flag code in crfclassifier were replaced with polymorphic objects.
the factory method choosecrfclassifier accepts flags and returns a subclass instance.
instead of passing flags directly to the constructor line a separate seqclassifierflags parameter object is passed to choosecrfclassifier line .
algorithmic flag checking is then replaced with polymorphism leading to best practice of fig.
.listing commit 5c3dcd35 inelki refactoring feature extraction for images.
for int k k dists.length k for int k k distances.length k int d dists int d distances horizontal horizontal neighbor todo pete what is sum?
sum listing commit 6dd54317 inelki huge pair refactoring.
1list integer currentcluster new arraylist for comparablepair d integer seed seeds for distanceresultpair d seed seeds integer nextid seed.getsecond integer nextid seed.getid model code comprehension debt a ml vrb matrix algebra is central to ml and matrix calculations often include the use of many temporary variables.
consider the m ake matrix variable names more verbose vrb refactoring snippet in lst.
that is performed on feature extraction code for image classification.
on lines and dists is renamed to distances .
while this is a minor refactoring dists may also have referred to distributions in such analytical based software.
although poor variable name quality can cause confusion and inhibit effective software evolution in general it is especially problematic in ml systems due to the high reliance on matrix calculations that may involve many temporary variables thus compounding the issue.
further refactoring motivation is on lines and where a comment is diluted and a variable clarification is requested leading to best practice fig.
.
b gen org inh model code is particularly performance sensitive due to the number of iterations ml systems typically perform on large datasets.
in such cases there may be trade offs between performance and comprehension however they can be misguided sacrificing readability unnecessarily.
consider the generic gen refactoring snippet in lst.
performed on ml related code.
on line comparablepair which was previously deemed to be more performant is replaced with the more specific distanceresultpair type allowing for the more readable getid accessor on line instead of the more ambiguous getsecond .
the author unnecessarily sacrificing ml model code clarity for performance gains.
expensive multidimensional matrix apis are used for singledimensional vectors.
project specific numeric data types are used in model code decreasing interoperability with ml libraries.
fig.
anti patterns.
listing commit 4432e319 inmahout mahout minor refactoring to eliminate unnecessary vector.times sqrt2pi .
1public double pdf vectorwritable vw ... vector s getradius .plus .
return math.exp divsquareandsum x.minus m s zprod s.times uncommondistribs.sqrt2pi zprodsqt2pi s private double zprod vector s private double zprodsqt2pi vector s double prod for int i i s.size i prod s.getquick i prod s.getquick i uncommondistribs.sqrt2pi proclaims the following leading to anti pattern fig.
java performance studies have shown no cost in making pair non final hotspot vms will optimize that very well.
since we can get getdistance andgetid for free we re go use them to increase readability of the code .
for anti pattern it is understandable that developers strive for peak runtime performance in model code it is beneficial for large datasets to be efficiently processed.
however performance improvements that degrade code clarify particularly in complex model code should be carefully scrutinized e.g.
via performance testing for whether they are in fact notably enhancing performance.
in the above example comparablepair is a general type containing general methods to retrieve consistent components getfirst andgetsecond .
these components can represent any entity in an ml algorithm but this type was previously deemed more performant than using a more specific type comparablepair isfinal thus disallowing any subtypes and forgoing multiple dispatch.
performance testing of multiple alternative constructs especially in model code may reveal particular vms optimizations e.g.
those that allow for nonfinal types that improve readability such as those with the more specific method getdistance that can be used instead of getsecond .
a consequence of anti pattern is that already complex model code is made more difficult to comprehend and consequently difficult to evolve.
model code reusability debt a gen org rus essential to ml system evolution is the addition of new models ideally via code reuse.
one generic m ake more reusable rus refactoring in mlrelated code uses method extraction for code reuse in other snn functions leading to best practice fig.
.
unnecessary model code debt a ml prf rma as model code is performancesensitive seeming innocuous refactorings in such regions canlisting commit indeeplearning4j refactored pad and mirror pad ops to conform with tf.
auto paddings ndarrayfactory create nd4jlong auto paddings ndarrayfactory create int 1ll 0ll impact performance .
consider the r emove unnecessary matrix operation rma refactoring snippet in lst.
.
this refactoring helped solve a performance issue related to gaussian clustering scalability by eliminat unnecessary call to vector.times sqrt2pi on line .
this matrix api implementation includes several layers of method calls dealing with multiple dimensions.
since sis a single dimensional vector the calculation can instead be inlined into the existing traversal line resulting in code that is significantly faster with no new ectors created.
.
this leads to anti pattern of fig.
.
the problem w.r.t.
anti pattern is an impedance mismatch between the expected api argument s complexity and the actual argument.
specifically apis processing multidimensional matrices may involve multiple layers of method calls which is unnecessary when the actual argument is singledimensional.
a consequence of anti pattern is that the added method call layers can degrade performance especially in model code which is hypersensitive to performance impact as many iterations of large datasets occur in such critical areas.
common contexts of anti pattern involve model code dealing with single dimensional vectors.
a common fix for antipattern is to replace the expensive api calls with calculations using operators e.g.
for multiplication inlining those calculations into existing loops.
custom data types debt a gen int ml systems may depended on learning libraries for which they must interoperate.
using project specific wrapped data types however can impede interoperability leading to anti pattern fig.
.
consider the generic m ake more interoperable int refactoring snippet in lst.
performed on ml related c code where line replaces a custom data type nd4jlong with a built in primitive int .
although specifying array literals in this case may be more cumbersome 1vs.1ll the code can now freely interoperate with tensorflow .
dependencies themselves may impose custom data types nd4jlong is from the highly related yet external nd4j scientific computing library in which case conversion code may be necessary.
the issue w.r.t.
anti pattern is that wrapper types like nd4jlong from scientific computing or native gpu oriented libraries are used in performance sensitive model code contexts to enhance performance in these critical areas.
however there is a trade off such types may not interoperate with other ml libraries and frameworks e.g.
tensorflow .
moreover the custom types may stem from other library dependencies possibly making their use necessary.
the consequences are that developers may need to i make a difficult choice to forgo depending on particular libraries ii make widespread modifications to replace or modify the type and iii write automated refactorings especially designed for migrating linear ml algorithm and configuration code to use inheritance constructs may be advantageous in avoiding code duplication.
more ml specific refactoring tool support may encourage more refactoring of model and configuration code potentially reducing technical debt.
more automated client side matrix calculation refactorings may replace manual model code performance enhancements.
fig.
recommendations.
their own conversation code.
to alleviate such consequences we suggest best practice of fig.
.
iv.
d iscussion a. code duplication in configuration model code with duplicate code elimination being one of the top overall and crosscutting refactoring categories finding as well as the top refactoring performed on ml related code finding ml systems seem to exhibit a significant amount of code duplication particularly in configuration and model code regions finding .
feasible explanations include i data scientists potentially untrained as software engineers and thus not fully aware of advanced modularization techniques may be responsible for model code ii model code is highly configurable containing a substantial number of different yet related hyperparameters which are configured in similar ways and iii many different ml algorithms share a significant amount of commonality giving way to code duplication.
further research is needed to uncover different developer roles in ml systems to fully understand the phenomenon underpinning item i .
as configuration debt was the largest technical debt category for item ii it is apparent that ml code involves many flags and developers are finding ways to deal with them so that both comprehension and extensibility are improved.
configuration debt was a major theme of sculley et al.
thus it was not surprising that the majority of refactorings aim at reducing it.
although parameter servers help without language level modularization techniques they are simply moving the problem.
as for item iii as demonstrated in iii b language level modularization techniques can help reduce some of the redundancy resulting from variant learning algorithm implementations.
while our findings coincide with those of lopes et al.
i.e.
there is a non trivial amount of code duplication their findings are inter project focused whereas ours are intra project.
also per finding we find that most duplication is addressed within ml code in ml systems a comparison between components.
b. combating code duplication debt in ml systems we identified the two ml system areas that exhibit the most duplication i.e.
configuration and model code.
amershi et al.
also note issues with model code reuse.
fortunately per finding inheritance was a centrally used technique in eliminating code duplication particularly with algorithm variations and finding shows that it was especially useful to reduce duplicate configuration code.
as such inheritance maybe a key in reducing duplicate code in ml systems.
a problem however is that model code is not always written in an objectoriented oo style as scripting languages are popular.
or if such code iswritten in oop developers may either not be aware i of inheritance techniques ii that inheritance can help avoid duplicate code or iii of or cannot use tool supported refactorings that can help with inheritance introduction.
as such for ml code currently taking advantage of oo and especially those either implementing ml algorithm variations or configuring hyperparameters more awareness and specialized tool support may be necessary leading to recommendation fig.
.
more tool support is also advocated by arpteg et al.
while bavota et al.
warn against hierarchy refactorings.
conversely for situations where code is not written in an oo style but oo is available recommendation may help promote inheritance usage.
for example although dynamic languages e.g.
python are popular for writing model code such languages may have inheritance mechanisms available e.g.
abc .
automated refactorings that are custom tailored to ml development may promote more usage of such packages.
unfortunately due to the static analysis typically required in such refactorings adapting existing automated refactoring algorithms to dynamic settings is non trivial.
a possible solution is to leverage a tractable speculative analysis that is customized to ml contexts to provide accurate and useful dynamic resolution.
c. generic vs. ml specific refactorings generic refactorings .
vastly outnumbered those of our new ml specific refactorings .
.
a feasible explanation is i model code is among the smallest ml subsystems thus we would expect less ml specific refactorings ii data scientists potentially not versed in refactoring may be responsible for ml related code maintenance and evolution and iii a lack of ml specific automated refactorings may deter developers as they must refactor manually leading to recommendation fig.
.
the lack of ml specific refactoring occurrences along with finding does not necessarily indicate that technical debt is not present it may be that it is simply not being addressed.
also good solutions for these problems may not yet exist .
nevertheless future work consists of extracting generalizable refactoring exemplars from the refactorings presented earlier that can serve as a basis for refactoring preconditions in varying contexts.
d. ml related code performance model code needs to be fast thus it is not surprising that .
of performance enhancements occurred in mlrelated code finding .
we came across several refactorings that converted reference types to primitives for performance reasons.
our findings coincide with that of kim and zhang et al.
i.e.
performance is essential yet challenging in ml systems.
additional client side tool support focused on improving matrix calculations e.g.
may alleviate developers from making manual performance enhancements leading to recommendation fig.
.
future work also consists 247of automating the rmp refactoring tab.
ii by reversing the approach taken by khatchadourian which converts primitives to reference types.
v. t hreats to validity subjects may not be representative of ml systems.
to mitigate this subjects encompass diverse domains and sizes and have been used in previous studies.
various github metrics and ml related keywords tags were used to assess popularity and in choosing subjects respectively.
although java was favored cf.
ii a many subjects were written in multiple languages particularly for model code which was also analyzed.
for example of deeplearning4j is written in c .
our study involved many hours of manual validation to understand and categorize the refactorings.
to mitigate bias we investigated referenced bug reports and other comments from developers to help us understand changes more fully.
larger refactorings may be non atomic spanning multiple commits .
in such cases it may be difficult to assess the task at hand for accurate categorization.
to mitigate this we examined referenced bug tracker reports which often mentioned multiple commits allowing us to understand the overall goals.
it is also possible that developers performed refactorings but did not mention so in commit log messages potentially causing us to miss refactorings.
nevertheless our study still involved manually examining commits.
the heuristics applied in determining whether refactorings were related to ml code may not be accurate however the researchers thoroughly examined each changeset and conversed regularly.
refactoringminer which aided some manual classification particularly with larger commits may not be accurate.
however allcommits were still manually analyzed and this tool has been used extensively .
vi.
r elated work sculley et al.
identify common se issues surrounding ml systems based on their experiences at google.
arpteg et al.
also detail several ml specific technical debt categories.
our work in part can be seen as an open source datadriven complement to theirs.
in addition to technical debt we also explore ml system refactorings correlate them to mlspecific technical debt and introduce 14and7new ml specific refactorings and technical debt categories respectively.
several studies involve ml and dl systems.
amershi et al.
conduct a study at microsoft observing software teams as they developed ai applications.
they also put forth best practices to address challenges specific to engineering ml systems albeit many are organizational or processbased.
lwakatare et al.
also classify se challenges for ml systems at six different companies focusing mainly on deployment issues.
zhang et al.
present a large scale empirical study of dl questions on stack overflow.
zhang et al.
and islam et al.
study dl bug characteristics and present anti patterns but to avoid bugs.
dilhara et al.
study ml library usage and evolution.
in contrast our focusis on the non functional qualities of ml systems the technical debt they cause and the refactorings that address them.
other work studies and categorizes refactorings.
tsantalis et al.
automatically detect refactorings in commit history however their approach is currently limited to fine grained analysis of classical refactorings supports only java which is problematic for multilanguage ml systems and does not correlate technical debt.
kim et al.
study refactoring challenges and benefits at microsoft while vassallo et al.
perform a large scale refactoring study on open source software and murphy hill et al.
study general refactoring at the ide level.
sousa et al.
characterize composite refactorings hora and robbes explore the characteristics of method extraction refactorings peruma et al.
investigate refactorings of unit tests in android and bavota et al.
and ferreira et al.
study fault inducing refactoring activities.
technical debt has also been studied.
tom et al.
propose the concept for general systems.
potdar and shihab explore self admitted e.g.
via code comments technical debt satd while bavota and russo investigate the diffusion and evolution of satd and its relationship with software quality.
huang et al.
and rantala et al.
identify satd using advanced techniques and christians examines the relation between satd and refactoring in general systems.
the refactorings we have identified that correlate to debt categories may be considered a form of ml specific satd.
code smells can also indicate technical debt and aversano et al.
study the evolution of smells and their tendencies to be refactored.
there are many empirical studies of software .
lopes et al.
study inter project code duplication.
mazinanian et al.
research lambda expressions in java khatchadourian and masuhara explore refactoring as a proactive tool for empirically assessing new language features bagherzadeh and khatchadourian investigate common questions asked by big data developers and khatchadourian et al.
examine the use and misuse of java streams.
vii.
c onclusion f uture work this study advances knowledge of refactorings performed and the technical debt they alleviate in ml systems.
we have explored refactorings specific and tangential to ml and occurring within and outside of ml related code.
a hierarchical taxonomy of refactorings in ml systems was formulated 14and 7new ml specific refactorings and technical debt categories respectively were introduced and preliminary recommendations best practices and anti patterns were proposed.
in the future we will explore juxtaposing our findings with developer specialties and expertise and integrating our results into automated refactoring detection techniques .