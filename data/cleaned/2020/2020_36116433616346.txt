commit level neural vulnerability detection and assessment yi li new jersey inst.
of technology new jersey usa yl622 njit.eduaashish yadavally university of texas at dallas texas usa aashish.yadavally utdallas.edujiaxing zhang new jersey inst.
of technology new jersey usa jz48 njit.edu shaohua wang new jersey inst.
of technology new jersey usa davidshwang ieee.orgtien n. nguyen university of texas at dallas texas usa tien.n.nguyen utdallas.edu abstract software vulnerabilities svs are security flaws that are exploitable in cyber attacks.
delay in the detection and assessment of svs might cause serious consequences due to the unknown impacts on the attacked systems.
the state of the art approaches have been proposed to work directly on the committed code changes for early detection.
however none of them could provide both commit level vulnerability detection and assessment at once.
moreover the assessment approaches still suffer low accuracy due to limited representations for code changes and surrounding contexts.
we propose a context aware graph based commit level vulnerability detection and assessment model vda that evaluates a code change detects any vulnerability and provides the cvss assessment grades.
to build vda we have key novel components.
first we design a novel context aware graph based representation learning model to learn the contextualized embeddings for the code changes that integrate program dependencies and the surrounding contexts of code changes facilitating the automated vulnerability detection and assessment.
second vda considers the mutual impact of learning to detect vulnerability and learning to assess each vulnerability assessment type.
to do so it leverages multi task learningamong the vulnerability detection and vulnerability assessment tasks improving all the tasks at the same time.
our empirical evaluation shows that on a c vulnerability dataset vda achieves .
and .
relatively higher than the baselines in vulnerability assessment regarding f score and mcc respectively.
in a java dataset it achieves and .
relatively higher than the baselines in f score and mcc respectively.
vda also relatively improves the vulnerability detection over the baselines from .
in f score.
ccs concepts computing methodologies neural networks security and privacy software security engineering .
corresponding author permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
copyrights for components of this work owned by others than the author s must be honored.
abstracting with credit is permitted.
to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission and or a fee.
request permissions from permissions acm.org.
esec fse december san francisco ca usa copyright held by the owner author s .
publication rights licensed to acm.
acm isbn .
neural networks deep learning software security vulnerability detection vulnerability assessment acm reference format yi li aashish yadavally jiaxing zhang shaohua wang and tien n. nguyen.
.
commit level neural vulnerability detection and assessment.
in proceedings of the 31st acm joint european software engineering conference and symposium on the foundations of software engineering esec fse december san francisco ca usa.
acm new york ny usa pages.
introduction software vulnerabilities svs are security weaknesses and flaws that one can exploit in cyber attacks.
such vulnerable code can be found and reported by scanning a version of a software project with the help of vulnerability detection tools .
however it is crucial to identify svs as soon as possible because late fixes and consequent damage due to affected systems are severe.
toward that commit level vulnerability detection vd approaches have been proposed to catch svs as soon as new code changes are committed to the code repositories during software development.
they are useful in warning developers early and isolating vulnerability inducing fine grained code change.
an alternative solution as using a vd tool running on the snapshot after a commit would not be able to isolate vulnerability inducing changes.
while addressing software vulnerabilities is crucial providing developers with the assessment on the impacts of the detected vulnerability in the system under development is of equal interest.
such knowledge will help better prioritize code review tasks while showing which areas need patching first.
the assessment could be on the severity of the attack and the levels of damage regarding confidentiality integrity availability etc.
however the commitlevel vd approaches do not support such automated assessment.
recognizing this the state of the art approaches proposed commit level software vulnerability assessment va tools to assess a committed code change.
they leveraged the common vulnerability scoring system cvss ratings i.e.
numerical scores which can be transformed into qualitative representations such as low medium high and critical manually provided by security analysts to build a learning based approach to predict assessment ratings for a code change possessing vulnerabilities.
however the existing va tools still have limitations.
first they work only on a committed code change that has already been identified as vulnerable by a vd tool.
this strategy that esec fse december san francisco ca usa yi li aashish yadavally jiaxing zhang shaohua wang and tien n. nguyen runs vd and then va i.e.
vd va is prone to cascading errors.
for instance in commits that have wrongly been identified as vulnerable by a vd tool the va tool would give incorrect assessments which should not be given at all.
moreover the va tool fails to predict assessment patterns in commits that are vulnerable but missed by the vd tool.
as a result the vd va strategy is limited and would not take advantage of the mutual benefits of the learning of detection on the learning of assessment and vice versa .
our philosophy is driven by this inter dependence wherein the former could help isolate the part of the code change that is vulnerability inducing which in turn could help assess it better.
specifically if a model learns that one of the assessment ratings is high e.g.
high severity or complete unavailability the vulnerability detection outcome must be positive.
if the detection outcome is negative the assessment ratings for all the aspects must be at the lowest e.g.
none .
thus it is more beneficial for a model to jointly learn to detect and assess vulnerabilities at the same time leading to performance enhancement in both detection and assessment.
second the state of the art va approaches are inept in their representation of code changes which are not sufficiently contextaware.
they learn an n gram representation for code changes that captures limited local context and is incapable of learning from vd va relevant program statements that are further apart from the changed statements.
as a result the statements in the n gram representation might not all contain important features for vd va. such a sequential representation learning also enforces an order in source code which might not be the order of execution e.g.
in the cases of loop branch condition or recursion which contributes to detecting vulnerabilities involving execution and exception flows.
moreover given that a vulnerability attack exploits the control and data flows a vd va tool needs to consider program dependencies.
this facet is ignored in the existing va tools.
finally the context of un changed code is indistinguishable and not represented separately from the changes.
as a result it can be confused by two training instances that have the same combination of change and context overall but with different changes and associated contexts.
in this work we present vda a context aware graph based commit level vulnerability detection and assessment model that evaluates a changed code to detect the presence of a vulnerability while also providing corresponding cvss assessment scores for the detected vulnerability.
we build vda via the novel integration of three key ideas.
first we integrate vulnerability detection and assessment vda processes such that our tool can directly be built into a repository to evaluate committed code changes and provide just in time assistance.
due to the inter dependence of these processes we adopt a multi task learning approach to propagate the learning between vd and va leading to better performance of both tasks.
moreover the assessments for different aspects could also affect one another e.g.
between the availability and integrity of a system.
thus our multi task learning scheme includes the vd task and the assessment tasks for different security aspects.
second we address the limitation of code change representations described earlier via a novel context aware graph based representation learning model that integrates the program dependencies and the surrounding contexts of code changes.
we leverage both versions of the program dependence graphs pdgs i.e.
before and after a commit via the multi version pdg .
to build suchembeddings for code changes vda explicitly represents the contexts surrounding the changed statements via the sub graphs in pdg.
it considers the impact of the context represented by a context vector on the building of the embeddings for the code changes.
it uses the contextualized embeddings to predict if the changes have any vulnerability and if yes to provide assessment grades.
third it utilizes the label graph convolution network to encode the program dependencies among the entities in the changed code and the ones in the surrounding un changed code.
this helps overcome the issues with n grams and capture the statements that might be far apart but still relevant to the vulnerability.
we have conducted experiments to evaluate vda on real world vulnerabilities.
our results on a c vulnerability dataset show that vda achieves .
and .
relatively higher than the state ofthe art va tool deepcva in f score and mcc respectively.
the vulnerability detection result from vda is improved over the state of the art ml dl based vd approaches from .
in precision .
in recall and .
in f score.
the results on a java dataset with vulnerabilities show that vda also achieves .
and .
relatively higher than deepcva in f score and mcc respectively.
to gain better insights we conducted experiments to show that the better performance of vda roots from our designed components.
our results show that our novel code change embeddings help vda learn better class separation i.e.
better in classifying the commits into the classes for vulnerability detection and assessment.
moreover we used explainable ai to show that vda indeed leverages the correct features in the dependencies among statements for its assessments.
the key contributions of our work include vda commit level vulnerability detection and assessment model vda that performs vd and va in tandem leveraging multi task learning to improve both detection and assessment.
our novel context aware graph based embeddings for code changes integrate program dependencies and contexts.
this embedding model is applicable for other down stream tasks.
empirical evaluation.
we evaluated vda against the stateof the art approach.
our model code are available at .
motivation .
motivating example let us present an example from an html parser named jsoup and our observations.
figure displays the information on the vulnerability cve that was reported on jsoup and published on .
the change that was deemed to contribute to the vulnerability were committed at version .
.
to the method process token htmltreebuilder of the htmltreebuilderstate class lines of figure .
that change directly uses the value returned from resetinsertionmode as the condition to insert starttag line .
with this change certain input html code with a specific start tag could make the program go to line with a recursive call to the method process ... .
that call resulted in an nullpointerexception at line .
in other cases the parser can get stuck i.e.
loop indefinitely until canceled as described in the official description of cve .
figure also shows the common vulnerability scoring system grades cvss given by security experts for various vulnerability assessment types vats for that cve.
due to the 1025commit level neural vulnerability detection and assessment esec fse december san francisco ca usa vulnerability details cve .
description jsoup is a java library for working with html.
those using jsoup versions prior to .
.
to parse untrusted html or xml may be vulnerable to dos attacks.
if the parser is run on user supplied input an attacker may supply content that causes the parser to get stuck loop indefinitely until cancelled to complete more slowly than usual or to throw an unexpected exception.
this effect may support a denial of service attack.
the issue is patched in version .
.
.
there are a few available workarounds.
users may rate limit input parsing limit the size of inputs based on system resources and or implement thread watchdogs to cap and timeout parse runtimes.
publish date last update date .
vulnerability type s denial of service .
cvss score ... .
detailed cvss grades vulner.
assess.
type value description confidentiality impact none no impact to the confidentiality integrity impact none no impact to the integrity availability impact complete there is reduced performance or interruptions in availability access complexity low specialized access conditions or extenuating circumstances do not exist little knowledge is required to exploit authentication not req authentication is not required to exploit the vulnerability gained access none no gained access with the vulnerability access vector local the vulnerability is in the local parser figure vulnerability details for jsoup cve ... jsoup parser htmltreebuilderstate.java boolean process token t htmltreebuilder tb ... if t.ischaracter insorted tb.currentelement .normalname intablefoster ... return tb.process t ... else tb.popstacktoclose name tb.resetinsertionmode if tb.state intable if !tb.resetinsertionmode tb.insert starttag return true return tb.process t inhead ... figure code change at version .
.
for cve above effects the availability impact for this vulnerability is rated ascomplete i.e.
for some inputs there will be reduced performance and interruptions in available services .
the above vulnerability is potentially damaging.
however in the existing workflow it was detected and reported late and finally assessed by the security experts in the cvss system .
in the meantime the similar vulnerabilities with the same assessments were also reported in other applications from netapp oracle and quarkus i.e.
more widespread damages were done.
in contrast by taking advantage of the records of vulnerabilities and their corresponding assessments in cvss via a learning based approach this could have been addressed as soon as the code change is committed.
such a commit level vda not only allows an early detection and assessment but also isolates the vulnerability inducing code change which cannot be achieved if a vd tool is run on the project s snapshot after changes.
for example the vulnerabilityinducing code change in jsoup at lines needs to be pinpointed among several other benign changes in the same commit.
in this work toward enabling such a learning process we make the following observations.
.
.
observation mutual impact of vulnerability detection and assessment .
in figure if a model learns that the availability assessment of this vulnerability is complete i.e.
system could be completely unavailable it could learn that this change is a vulnerabilityintroducing one i.e.
the detection outcome is positive .
on the other hand if a model learns that this is a vulnerability introducing change it could learn more about the semantics of the code change and consequently how the code change gives hints to the assessment.
in contrast if a model decides that this does not possess any vulnerability it can learn that all the vat outcomes must be none .
unfortunately none of existing vd and va approaches take advantage of this mutual impact.
the ml based vulnerability detection approaches focus only on vd without any va support.
in contrast the existing ml based va approaches works only on the vulnerability introducing change with the work flow that a vd tool is used first to detect such a commit.
.
.
observation .
to detect and assess a vulnerability a model needs to consider the program dependencies among the statements .
for example to assess availability one needs to check the potential infinite loop or null pointer exception and examine the control and data dependencies between the changed line and the line .
that is where the method process is recursively called which leads to the null pointer exception at line currentelement returns null .
unfortunately the state of the art vulnerability assessment models e.g.
deepcva learn only n gram representations n and do not consider long range dependencies.
however program statements that can help with automated assessment e.g.
line line line can be far apart.
deepcva is incapable of capturing such a flow.
.
.
observation .
by examining only the tokens involving in the changes e.g.
the tokens tb resetinsertionmode state and intable in the deleted lines and the inserted line a model can not decide on the vulnerability or its impacts on the system s availability or not.
generally the same similar changes occurring in different surrounding contexts might cause different effects .
for example adding a null check if p !
null is a common change in many places.
however it could prevent a null pointer exception in some context while does not in the others.
unfortunately deepcva does not capture well the contexts of the changes.
first the n gram representation learning is limited as explained.
second deepcva does not model the inter relationships between the context i.e.
the un changed code elements and the changed ones both pre change and post change .
this is essential in capturing code changes better resulting in improved detection and assessment.
.
key ideas we develop vda a context aware graph based commit level vulnerability detection and assessment model that detects any vulnerability in a committed change and provides the cvss assessment grades for it if any.
vda is designed with the following ideas .
.
key idea vulnerability detection and assessments with joint learning .
from the observations a commit level vda tool is desired.
we leverage multi task learning to propagate the mutual benefits of learning of vulnerability detection to that of assessment and vice versa.
moreover the learning of one type of 1026esec fse december san francisco ca usa yi li aashish yadavally jiaxing zhang shaohua wang and tien n. nguyen figure vda context aware graph based commit level vulnerability detection and assessment vulnerability assessment can affect the learning of another e.g.
between availability and access complexity .
thus our multi task learning scheme is designed with one task for vd and one task for each of the assessment types.
in training we optimize the joint loss function for all the tasks.
when the vd s outcome is positive vda provides assessments.
otherwise non impact scores are given.
.
.
key idea contextualized embeddings for code changes with graph based representation learning .
to overcome the limitation of code change representation we introduce a graph based model to build the contextualized embeddings for code changes that integrate both program dependencies andsurrounding contexts .
unlike existing code change embedding approaches where code changes are represented as sequences we explicitly represent code changes and the context of a change via a graph representation called multi version pdg .
the graph consists of the program entities of both versions before and after the changes and their dependencies.
the context is defined as the surrounding un changed nodes of the changed node.
we use label graph convolution network label gcn to build the contextualized embeddings for code changes considering the contexts as the weights in computation.
we use past vulnerabilities and experts ratings to train vda to build such embeddings and use them for classification.
.
.
key idea program dependencies in code change representation via graph based neural network .
we leverage label gcn to incorporate the program dependencies among the changed code elements and the surrounding un changed code elements into vda .
the graph enables a partial order among program entities in a pdg rather than enforcing a total order as in n gram learning.
this enables vda overcome the aforementioned issues and capture dependencies on distant yet vulnerability relevant statements.
approach overview vda has three key components working in three steps figure .
step .
representing code changes and contexts with multiversion pdg .program dependence graph pdg is a directed graph with a set nof nodes and a set eof edges in which a node n nrepresents a program statement or a conditional expression an edgee erepresents the data or control flow among the statements.
we adopt the multi version pdg pdgx y to represent the changes between two versions xandy before and after the commit .
a multi version pdg pdgx y is a directed graph generated from the disjoint union of all nodes and edges in the pdgs at versionsxandy.
pdgx y figure section allows us to capture the program dependencies including data control flows that are crucial in vulnerability detection and assessment key idea .
step .
contextualized embeddings for code changes with graph based representation learning .we develop our representation learning model to learn the contextualized embeddings for the code changes in a commit that integrate both program dependencies and the contexts.
to build the contextualized embeddings we leverage the label graph based convolution network to learn the vector vfor each node nin the graph whose nodes can have labels.
we use labels to denote the nodes at either the versions x before changes or y after changes or at both versions.
for a changed node nc we collect all the un changed nodes in the context of nc which is defined as the set of all the un changed nodes that are k hop neighbors of nc.
in figure for the changed statement at line if k the context of that change includes the statements at lines and i.e.
hop neighbors from line .
from the context nodes we compute the vector for the context for a changed node ncand use it as a weight to represent the impact of context to build the contextualized embedding for nc.
from those embeddings we compute the vector for the entire commit and feed it to a softmax layer acting as a classifier to perform vulnerability classification or assessment classification for each assessment type.
the softmax function is often used as the last activation function of a neural network to normalize the output of a network to a probability distribution over the predicted output classes.
step .
multi task learning for classification .for each assessment type we have a softmax layer working as an assessment classification model on the embedding of the entire commit.
we also have another softmax layer as the classifier for vulnerability detection.
to propagate the impact of the classification for one assessment type on one another we leverage multi task learning among all the classification models.
we use the uncertainty weighted multi task loss for each classification task as the final multi task learning loss function and use the maximum of the average f score from all the classification tasks as the training target.
training and predicting processes .the training and predicting processes share the above steps except that in training the classification labels for the vulnerable commit and vulnerability assessment types vats are known.
for a benign commit the output labels are negative and non impact.
when predicting vda takes a code change predicts vulnerability and provides the assessment classifications for seven vats.
next we will explain vda in details.
building multi version pdg pdgx y the first step in vda is to build the multi version pdg.
figure shows the vulnerable method rsvg io get file path .
the change at line into line was deemed as a vulnerability introducing change by a detection tool in which g file test filename g file test exists 1027commit level neural vulnerability detection and assessment esec fse december san francisco ca usa figure multi version program dependence graph was removed from the condition at line .
figure and figure display the pdgs of the method rsvg io get file path before and after the change.
all the nodes of the pdg before the change are marked with x and those of the pdg after the change are marked withy.
figure shows the multi version pdg pdgx y built from the two versions xandyof that method before and after the change.
in pdgx y the nodes labeled with either xoryappear only in the pdg of the version xory respectively.
the nodes labeled with x y appear in the pdgs at both versions.
we adopt the multi version graph building algorithm in flexeme .
specifically we generate the pdgs for both versions xand y. we run git diff tool on the source code to determine the changed and unchanged nodes for the statements.
the added nodes are kept in pdgx ywith the labels yas they appear in the newer version y. we also retain the deleted nodes and use the label xfor them.
the unchanged nodes between the versions are matched by using string similarity among the respective statements to filter the candidates and line span proximity to rank them.
when considering the edge changes we back propagate the delete nodes to the edges flowing into them.
we also add all unmatched edges in the newer version y to the pdgx yas the edges relevant to the added nodes.
after building pdgx y for each changed node in the graph vda collects all the unchanged nodes within the k hops and the inducing edges among them to build a sub graph as the context for the changed node.
pdgx yand the context for each changed node are used as the input of the label gcn.
building pdgx y and contexts is needed in both training and predicting.
graph based contextualized embeddings for code changes let us first explain how we extract the feature vectors for the nodes in pdgx yand build the code change contextualized embeddings that integrate both program dependencies and contexts via label gcn.
from those embeddings for code changes we build the embedding for the entire commit which will be later used in the classification tasks for vulnerability detection and assessment.
.
feature vectors vf nfor pdgx ynodes after the previous step we obtain pdgx yand the context subgraphs for the changed nodes in pdgx y. we leverage labelgcn to model pdgx yas follows.
we first build the node feature vector for each node nin pdgx y. to do so we use the sequence of the code tokens tnof the statement scorresponding ton.
we use a word embedding model to learn the vector vtfor each token when we consider the code token sequence for sas a sentence.
the node content vector fornis computed as the average vectorvavgof all the vectors vtof all the tokens in the statement s. to integrate the labels x y and x y into the node feature we use a one hot vector with the length of three for those labels.
by concatenating the node content vector with the one hot vector for the labels we have the node feature vector vf nfor the node n. .
contextualized embedding vnfor noden next we replace each node nin pdgx ywith the node feature vectorvf n. similar to the traditional gcn label gcn takes the graph with the node feature vectors as the input and generates the embeddings for each node in the graph.
in addition for the current node in the first layer label gcn considers the version labels x y x y of the neighboring nodes as part of the feature vectors which helps distinguish the old new nodes .
label gcn generates the vectors embeddings for the nodes in each layer as follows h l ax diag a k j 1ejet j w0 l ah l w l l a d a d a a i wherehis the output for hidden layers ais the adjacency matrix andiis the identity matrix dis the diagonal node degree matrix wis the weight matrix xis the input and x rnum d k num is the number of nodes dis the dimension of node features kis the number of types of node labels in the input k forx y and x y and diag a k j 1ejet jis used to eliminate the self loops for the components of the feature vectors for the labels.
the vectors h l at the output layer are used as the vectors vis for the nodes in the pdgx ygraph after label gcn in figure .
.
context integration for each changed node ncin pdgx y we build the sub graph containing all the un changed nodes in the k hop neighbors of nc and use that sub graph as the context for nc.
we merge the vectors vis in the context into a matrix.
we then use a fully connected layer on the matrix to build the context vector vctxfor the context.
to integrate the context into the embeddings we compute the final vector v ncfor the changed node ncby performing the crossproduct between vctxand the vector vncfornccomputed by the label gcn model as described in section .
v nc vctx vnc.
.
classification for each task to compute the vector for the entire commit we collect all the vectorsv ncs of the changed nodes ncin pdgx yinto a matrix.
we apply a fully connected layer to learn the vector vmifor a changed 1028esec fse december san francisco ca usa yi li aashish yadavally jiaxing zhang shaohua wang and tien n. nguyen figure context aware graph based representation learning for contextualized embeddings for code changes methodmi.
the vectors for all changed methods are passed through another fully connected layer to get the vector vcomfor the commit.
this vector is fed into each softmax classifier for each task.
.
illustrating example figure illustrates the vector building for the code changes in figure .
from pdgx y we compute the node feature vectors vf n section .
for all statement nodes s2 ... s7in that graph.
labelgcn takes that graph with node feature vectors to generate the embeddings v2 ... v7for the nodes section .
.
let us consider the changed nodes n3andn4.
the context for n3with one hop distance includes n2 n5 andn7.
similarly the context forn4includes the same nodes.
after merging those vectors into a matrix which is passed through a fully connected layer we obtain the context vectors vctxforn3.
similarly we obtain vctxfor n4.
then the final contextualized vector for the changed node n3 taking the context into account is computed as the cross product v vctx v3.
similarly v vctx v4.
we then put the vectors v andv 4together in a matrix and use a fully connected layer fcl to produce the method vector vm1.
all changed method vectors are passed through another fcl to get vcomfor the commit.
finally we passvcomto a softmax layer to perform vulnerability detection or the classification for an assessment type e.g.
none partial .
multi task learning for prediction and assessment classification in the previous sections we have explained how vda performs each classification task for detection or assessment.
in this section we will explain our multi task learning mechanism to perform the classification for vulnerability prediction and the classifications for seven vats with the following prediction classes for each vat confidentiality none partial complete integrity none partial complete availability none partial complete access vector local network access complexity low medium high authentication none single severity low medium high as explained in section .
the vector vcomrepresenting the entire commit is passed through a softmax layer for the classification for vulnerability detection or for a specific vat.
in vda the multi task learning mechanism uses the uncertainty weightedmulti task loss to learn all classification tasks at the same time.
specifically for each classification task vda uses a cross entropy loss function to do the classification as follows l log softmax y f x wheref x is the output of a classification task f y is the ground truth.
to get the joint loss function for all the tasks with uncertainty weighting following kendall et al.
s we have li w log softmax yi fw xi l w 2 ... i 2 2 ili w log 2 i wherewis the weight adding to the input iis theithnoise scalar andwand iare both trainable in the model.
with formula vda uses the multi task learning to train all classification models together with the features for each task.
for training we set as the objective the highest average f score section .
for all tasks.
for prediction the trained model produces the classification results for vulnerability detection and for all vats.
empirical evaluation to evaluate vda we seek to answer the following questions rq1.
comparison with state of the art ml based vulnerability detection approaches on c dataset.
how well does vda perform compared with the existing dl based vd approaches?
rq2.
comparison in vulnerability assessment on a c dataset.
how well does vda perform compared to the state of the art model in vulnerability assessment on a c dataset?
rq3.
contextualized embeddings for code changes.
dovda s embeddings help it improve over the baseline in classifications?
rq4.
explainable ai to study relevant features on program dependencies.
does vda use program dependencies in vulnerability detection and assessment?
in rq3 and rq4 we aim to evaluate the extent of contributions of two vda s key design choices i.e.
contextualized embeddings for code changes andprogram dependencies to its performance.
rq5.
ablation study on multi task learning and context.
how do multi task learning and context affect vda s performance in vulnerability detection and assessment?
rq6.
comparison in vulnerability assessment on a java dataset.
how does vda perform compared to the state of the art model in vulnerability assessment on a java dataset?
1029commit level neural vulnerability detection and assessment esec fse december san francisco ca usa table statistics of bigvul and cvad datasets datasets bigvul c cvad java of projects of vulnerabilities of vulnerability introducing commits .
datasets we used two vulnerability datasets in c and java bigvul .
and cvad .
both were manually checked and used in prior research .
our experiments were conducted on a server with core cpu and a single nvidia a100 gpu.
.
experimental methodology .
.
comparison on vulnerability detection on bigvul rq1 .
baselines .
we include vccfinder a commit level ml based vd and other ml vd tools vuldeepecker devign sysevr russell et al.
reveal and ivdetect .
except vccfinder we ran the others on the code after commit.
procedure.
we used all vulnerable methods and randomly selected the same number of non vulnerable methods from the fixed version projects to build a dataset with the vul non vul ratio of .
we also evaluated the tools with the real world ratio of .
we randomly split the data on the project basis without changing the vul non vul ratio for training tuning and testing.
parameter tuning.
forvda we used automl for tuning the following hyper parameters to have the best performance epoch size batch size learning rate .
.
.
.
word embeddings length .
we tuned deepcva s parameters from its documentation.
evaluation metrics.
we use the following metrics to measure the effectiveness of a model recall tp tp fn precision tp tp fp and f score recall precision recall precision.
where tp true positives fp false positives fn false negatives tn true negatives.
.
.
comparison on vulnerability assessment on bigvul rq2 .
baseline.
we compare vda with deepcva .
procedure.
we used bigvul dataset with the same longitudinal setting in for training validation and testing to mimic the real world scenario in which the older vulnerabilities are used for training to assess the newer.
specifically we sorted all the commits in a chronological order based on their absolute time.
we divided the commits into equal folds from oldest to newest.
for a fold k k we used all the folds to kfor training the k thand k thfolds for validation and testing.
models are tuned as in rq1.
evaluation metrics.
we use the same metrics in deepcva fscore and matthews correlation coefficient mcc .
f score ranges from to the best to evaluate classification tasks and to handle the class imbalance prevalent in some of the vats.
mcc ranges from to the best .
since we evaluate the classification models with multiple classes we used the macro f score and the multiclass version of mcc .
the overall mcc is computed as the average of the mccs for all classification tasks as in deepcva .
.
.
code change embedding analysis rq3 .
we aim to evaluate the impact of our novel graph based contextualized code change embedding model on vda s ability in class separation.table vulnerability detection on c dataset rq1 approach precision recall f score vccfinder .
.
.
vuldeepecker .
.
.
sysevr .
.
.
russell et al.
.
.
.
devign .
.
.
reveal .
.
.
ivdetect .
.
.
vda .
.
.
.
.
program dependencies rq4 .
we employ explainable ai xai to demonstrate the utilization of program dependencies by our vda model in vulnerability detection and assessment.
an xai model enables us to analyze the essential features within the input code that influence the model s predictive outcomes.
if xai highlights program dependencies within the input code we can subsequently investigate whether vda appropriately employs these program dependency related features for accurate predictions.
.
.
ablation study on multi task learning and context rq5 .
we evaluate the impacts of the following factors in vda multitask learning and change context.
we conducted an analysis by removing each factor from vda and made a comparison.
.
.
comparison on assessment on cvad java dataset rq6 .
baseline and procedure.
we compared vda with the baseline deepcva .
we used the same procedure tuning and longitudinal setting as in rq1 but on the java dataset.
experimental results .
comparison on vulnerability detection on bigvul c dataset rq1 as seen in table to detect vulnerability vda improves over all the baselines in all the metrics.
specifically vda relatively improves over the baseline models from .
in precision from .
in recall and from .
in f score.
vda performs much better than commit level vccfinder possibly because vccfinder only uses traditional svm.
we can also see that vda performs better than the snapshot baselines i.e.
reveal and ivdetect in the cases where the code changes are relevant to the vulnerability.
consider an example in which a statement e.g.
null check was removed leading to vulnerable code e.g.
null pointer exception .
due to its ability to examine changes as opposed to the baselines which only look at the modified version vda can detect the vulnerability inducing changes better.
in section .
we used explainable ai to display the changed statements in the code that contributes to the detected vulnerability figure .
this is another advantage from commit level vd pointing to the fine grained vulnerability inducing change that the vd tools working on the new version only do not have.
we also use a real world vulnerability setting with a nonvulnerability to vulnerability ratio.
we randomly selected of the vulnerable instances in the test set ten times and finally took the average of the f scores.
we report that the f scores for vda and the top baseline ivdetect are .
and .
respectively.
vda 1030esec fse december san francisco ca usa yi li aashish yadavally jiaxing zhang shaohua wang and tien n. nguyen table vulnerability assessment on c dataset rq2 cvss metric evaluation metricmodel deepcva vda confidentialitymacro f score .
.
mcc .
.
integritymacro f score .
.
mcc .
.
availabilitymacro f score .
.
mcc .
.
access vectormacro f score .
.
mcc .
.
access complexitymacro f score .
.
mcc .
.
authenticationmacro f score .
.
mcc .
.
severitymacro f score .
.
mcc .
.
averagemacro f score .
.
.
mcc .
.
.
exhibits a consistent trend with ivdetect while outperforming it by .
.
f score is lower than in table due to unbalanced data.
.
comparison on vulnerability assessment on bigvul c dataset rq2 in table vda relatively improves over deepcva by .
in macro f score and .
in multi class mcc on the overall multi class classification.
for individual vats vda improves upon deepcva by7.
.
in macro f score and .
.
in multi class mcc .
we can see that vda consistently outperforms deepcva on all vat types thus corroborating with the design choices in key ideas see section .
.
moreover we can see that the largest relative improvement in macro f score and multi class mcc happens for access complexity and access vector respectively.
such gains in performance can possibly be attributed to the nature of access vat the access information for which is more often than not extensively checked in the changed code context which is well represented in vda but not in deepcva.
.
class separability with code change embeddings rq3 in this study we aim to show that our embeddings for code changes helps vda have better class separation i.e.
better classification measures for detection and assessment than that of the baseline.
for each class cregarding a vulnerability assessment type vat we selected commits that are labeled with the class cin the oracle.
this was chosen based on the population of the data such that the sample size corresponded to a confidence level with a confidence interval of for each vat.
for example for confidentiality we randomly selected an equal number of commits i.e.
that are marked as none partial and complete .
for each type we took those commits and used vda s code change representation learning model anddeepcva sn gram based embedding model to produce the embeddings for those commits.
we projected the embeddings from these approaches into the vector space using t sne technique based on which we can visualizehigh dimensional data by giving each data point its projected location in a two dimensional vector space.
next in the silhouette plots we succinctly present the data points for these embeddings which represent how well they have been classified.
figure shows the comparison between the silhouette plots for the embeddings produced by vda and deepcva regarding classes of confidentiality.
figures 6a.
and c. display the t sne visualizations for the embeddings while figures 6b.
and d. display the silhouette plots for the data in these visualizations.
the silhouette coefficient value x axis in figures 6b.
d. e. is a measure of how similar an object is to its own class compared to other classes which ranges from .
here a higher value indicates that an object is well matched to its own class and poorly matched to neighboring classes.
if most objects have high values the class configuration is proper.
that corresponds to better formed classes facilitating a model to group the commits into the correct classes i.e.
none partial and complete .
if many points have low or negative values the class configuration is ill formed i.e.
does not help with classification.
let us consider the commits in the complete class in figures 6a.
and b. each line in complete class in figure 6b.
corresponds to a point in complete class in the vector space in figure 6a.
length of a line is equal to the silhouette coefficient for a point.
these lines are sorted from largest to smallest and drawn from top to bottom creating a knife shape.
as seen the knife shapes from deepcva have longer and thicker tails than those from vda which actually have no tail for the classes partial andnone .
thus deepcva produces embeddings that overlap more with their neighboring classes.
in figure 6e.
we place two silhouette plots in an overlay image.
the plot from vda is thicker than that from deepcva vda produces more points with positive values than deepcva.
in brief figures 6a e show that the embeddings for code changes from vda facilitates better classification for vulnerability assessment than the embeddings produced by deepcva .
figure and figure show the comparison among the silhouette plots for the embeddings from vda and deepcva on integrity andavailability remaining vat types are not shown here due to space limit .
we can see that the comparisons for all vats have the same trend i.e.
the knife shapes from vda have no or shorter tails and are thicker than those of deepcva.
in brief the silhouette plots indicate that vda produces embeddings that have more cohesion with the ones in the same class and more separation with the ones in the different classes.
thus our embeddings with more class separability help vda perform better classification .
we also performed the same plotting for the classification task for vulnerability detection.
considering the overlap between two plots in figure the knife shapes from vda for both classes vulnerability and benign are wider and have less negative values than those from the best baseline ivdetect.
specifically the average silhouette score in vda is .
while that of ivdetect is .
.
thus vda has better class separability leading to better performance.
.
key features in program dependencies for classification with explainable ai rq4 we aim to evaluate whether vda uses the vulnerable statements and their dependencies in its vulnerability prediction and assessment.
this also allows us to evaluate its ability to pinpoint the 1031commit level neural vulnerability detection and assessment esec fse december san francisco ca usa figure silhouette plots for the embeddings of commits produced by vda and deepcva on confidentiality rq3 figure silhouette plots for the embeddings of commits produced by vda and deepcva on integrity rq3 figure silhouette plots for the embeddings of commits produced by vda and deepcva on availablity rq3 figure silhouette plots for the embeddings of commits produced by vda and ivdetect for vulnerability detection vda has better class separability rq3 changed statements relevant to the detected vulnerability.
specifically for each vulnerability assessment type vat we randomlyselected samples of the commits in our dataset that vda predicts the correct classes of the vulnerability detection and vats e.g.
none partial complete .
that sample size gives us the confidence level of and the confidence interval of for each vat.
we use an explainable artificial intelligence xai model called gnnexplainer which takes a gnn based classification model mand a specific input iofm and produces an explanation on why marrives at its prediction ofor the input i. we fed vda and each commitcof those sample commits as the input for gnnexplainer.
the explanation produced by gnnexplainer is in the form of a sub graph in pdg that was built from the input commit c. the sub graph is referred to as the explanation sub graph forc regarding the classification of cfor the current assessment type.
the explanation sub graph is defined as the minimal sub graph in the input graph pdg that minimizes the prediction scores between using the entire graph pdg and using as the input for vda .
is minimal in the sense that if any node and edge is removed from it the decision of vda is affected i.e.
vda will produce a different class for the input commit c. that is the explanation sub graph 1032esec fse december san francisco ca usa yi li aashish yadavally jiaxing zhang shaohua wang and tien n. nguyen table vunerable statements dependencies as key features confidence integrity avail accessvec acccompl auth severity avg .
commits vda correctly uses vulnerable statements dependencies in vulnerability detection and assessment private status docompute opkernelcontext ctx ... datasetbase finalized dataset tf return if error finalizedataset ctx dataset finalized dataset std unique ptr iteratorbase iterator tf return if error dataset makeiterator iter ctx parent nullptr .
tf return if error finalized dataset makeiterator iter ctx parent.
std vector tensor components components.reserve dataset output dtypes .size components.reserve finalized dataset output dtypes .size ... figure contributions of different statements in correct vulnerability prediction and classification of vats by vda contains the statements and dependencies that are most decisive for vda to determine the class ofor the commit c. to evaluate whether vda via label gcn can capture the crucial statements and dependencies in deciding the class for an input commit we compared the explanation sub graph with the vulnerability inducing statements and dependencies in the ground truth of those commits.
if contains one of such statements nodes and dependencies edges we consider that vda uses the correct vulnerable statements and dependencies as the features for its correct classification detection and assessment .
table shows the percentages of the cases in which vda correctly uses the vulnerable statements and their dependencies in correctly predicting the vats.
for example among the commits thatvda successfully classified into none single for authentication gnnexplainer determines that in of them vda uses at least one actual vulnerable statement or dependency as key features in its prediction.
as seen the degree of vda s reliance on vulnerable statements dependencies for its assessment across different types is different.
while in vda relies on vulnerable statements dependencies to assess the impact of integrity in samples it relies on them for assessing that of severity .
for vulnerability detection in of samples vda uses the right statements dependencies in its correct prediction not shown .
on an average in .
samples vda correctly relies on the vulnerable statements dependencies.
in brief this result shows that program dependencies among vulnerable statements are key features to vda in its correct vulnerability detection and assessment which corroborates with our design choice with program dependencies.
example.
figure shows an example of the vulnerability introducing change for cve .
the change introduced the variable finalized dataset at line representing a dataset that was populated at line and used at lines and .
however the input was not validated and the code at line assumed only string inputs and interpreted numbers as valid strings.
when computing the crc of the record this resulted in heap buffer overflow.
vda correctly predicted this vulnerability and its assessment severity medium .
gnnexplainer pointed out that vda used the changed statements and their dependencies at lines and another line not shown totable impact of multi task learning and context rq5 detection vda w o multi task vda w o context vda f score .
.
.
table impact of multi task learning and context rq5 assessment vda w o multi task vda w o context vda f score .
.
.
table impact of num.
of hops kfor context size rq5 macro f score mcc vda k .
.
vda k .
.
vda k .
.
vda k .
.
vda k .
.
perform classification.
this is correct because despite line being a fixed line in a later version lines are parts of the control data flows leading to line .
thus vda correctly used the vulnerabilityrelevant statements and dependencies in correct prediction.
.
ablation study rq5 as seen in tables and without multi task learning the performance decreases .
in f score in detection and .
in macro f score in assessment.
without context it decreases .
in f score in detection and .
in macro f score in assessment.
this result confirms our hypotheses multi task learning helps improve both vulnerability detection and assessment adding multi task learning both vd and va improve .
to .
.
to .
.
note without multi task learning vda also improves over the baselines tables in both vd and va due to vda s code change embeddings section .
.
both multi task learning and context have positive contributions in which multi task learning contributes more.
multi task learning model performs better than cascading vd to va which has the cascading error due to false positives in vd.
table shows the impact of the context size k the number of hops from a changed node .
as seen when kincreases from the macro f score increases to its highest value of .
.
however when kcontinues to increase k both macro f score and multi class mcc decrease.
the rationale is that as the context size is too small the limited number of surrounding nodes cannot capture well the relevant statements for assessment.
as the context size gets larger the increasing number of the irrelevant statements will bring in biases.
thus we selected k in other studies on the c dataset.
.
comparative study on java dataset rq6 we aim to show that our approach also works for vulnerabilities in a different programming language.
table shows that it relatively improves deepcva by .
in macro f score and .
in multi class mcc on the overall multi class classification in java dataset.
for specific vats vda improves deepcva by .
.
in macro f score and .
in multi class mcc .
moreover the largest relative improvement in macro f score happens for availability and the largest one in multi class mcc happens for access vector .
the 1033commit level neural vulnerability detection and assessment esec fse december san francisco ca usa table vulnerability assessment on java dataset rq6 cvss metric evaluation metricmodel deepcva vda confidentialitymacro f score .
.
mcc .
.
integritymacro f score .
.
mcc .
.
availabilitymacro f score .
.
mcc .
.
access vectormacro f score .
.
mcc .
.
access complexitymacro f score .
.
mcc .
.
authenticationmacro f score .
.
mcc .
.
severitymacro f score .
.
mcc .
.
averagemacro f score .
.
.
mcc .
.
.
vulnerability detectionvccfinder cat f score .
.
absolute macro f score value .
for authentication is highest among all the vats.
the f score for detection from vda is also higher than that of the commit level vccfinder which uses svm.
other baselines in table do not work on java.
in brief this result is consistent with the trend as vda being run on the c dataset.
.
threats to validity and limitations the threats come from the following aspects programming languages pls .
our approach has been tested on java and c commits.
however the techniques used in vda are not tied to java or c. in principle our approach can applied to other pls.
generalization of the results.
our comparisons with deepcva were only carried out on the publicly available c and java datasets.
further comparisons with the baselines on other datasets should be done.
our approach also has room for further improvements.
first vda does not work well for the code changes that are common but have impacts on the far apart un changed parts of the project.
second vda fails in the assessment for complex changes that program dependencies cannot capture e.g.
event driven programs.
finally the detection component could be improved further with a more dedicated model on vulnerability detection.
related work ml based vulnerability prediction.
machine learning has been applied in commit level vulnerability detection .
vccfinder trains a svm classifier to flag suspicious commits.
we used only code change features for our experiment.
zhou and sarma s works on commit messages and bug reports.
it uses an ensemble model to combine multiple classifiers.
vda supports both vulnerability detection and assessment.
deep learning dl has been applied to detect vulnerabilities .
harer et al.
leverages rnn model.
lin et al.
learns function repreentations via ast for vd.
russell et al.
combine the neural features of functionswith random forest as a classifier.
harer et al.
compare the effectiveness in vd of using source code and the compiled code.
vuldeepecker uses a rnn trained on program slices from api calls for vd.
sysevr expands vuldeepecker by including the program slices from syntactic units.
devign uses gated graph recurrent layers on program graphs.
reveal uses cpg with ggnn.
ivdetect focuses on interpretation and directly uses pdg with gcn.
linevul use bigvul dataset to train a transformer based model which has over 150k training instances.
to avoid under training of linevul and an unfair comparison given that it has over 110m parameters we chose to not compare with it.
automated vulnerability assessment.
distinct software vulnerabilities can have different levels of threats and severity and require assessment .
the automated approaches have been recently proposed .
bozorgi et al.
propose a svmbased approach to predict whether a vulnerability will be exploited or not.
lamkanfi et al.
predict the severity of a reported bug using text mining algorithms on bug reports.
han et al.
propose a multi class text classification dl based model that is based on the description to predict the severity level of a vulnerability.
georgios et al.
adopt a multi target classification coupled with text analysis on vulnerability descriptions to predict their characteristics and scores.
le et al.
propose a ml based approach to learn the word features in vulnerability description and handle the extended concepts in the description.
other studies leverage code patterns in fixing commits of third party libraries to assess vulnerabilities.
in comparison vda supports commit level vulnerability detection and assessment using code changes.
code change embeddings.
our work is also related to code change embedding models .
those approaches mainly treat code as sequences and do not consider structures and or program dependencies.
the key departure points of vda include the use of graph representation to model the changes and dependencies as well as the surrounding context to build the embeddings.
conclusion this paper proposes vda a context aware graph based commitlevel vulnerability detection and assessment model that evaluates a commit detects any vulnerability and provides the cvss assessment grades.
the key advances in vda over the existing approaches include multi task learning between vulnerability detection and assessments of different aspects code change embedding model that integrates program dependencies and contexts and graphbased representations of dependencies and contexts.
our evaluation shows that on a c dataset vda achieves .
and .
relatively higher than the baselines in vulnerability assessment in f score and mcc.
in a java dataset vda achieves and .
relatively higher in f score and mcc.
vda also relatively improves the vulnerability detection over the baselines from .
in f score.
data availability our data and code are available at .