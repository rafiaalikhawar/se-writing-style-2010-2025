transmap pinpointing mistakes in neural codetranslation bowang bo wang u.nus.edu national university ofsingapore singapore singaporeruishi li liruishi u.nus.edu national university ofsingapore singapore singapore mingkaili t0927617 u.nus.edu national university ofsingapore singapore singaporeprateek saxena prateeks comp.nus.edu.sg national university ofsingapore singapore singapore abstract automated code translation between programming languages can greatly reduce the human effort needed in learning new languages or in migrating code.
recent neural machine translation models such as codex have been shown to be effective on many code generation tasks including translation.
however code produced by neural translators often has semantic mistakes.
these mistakes are difficulttoeliminatefromtheneuraltranslatoritselfbecausethe translator isa black box which isdifficult to interpret or control comparedtorule basedtranspilers.weproposethefirstautomated approachtopinpointsemanticmistakesincodeobtainedafterneuralcodetranslation.ourtechniquesareimplementedinaprototype tool called transmap whichtranslatespythontojavascript both of which are popular scripting languages.
on our created microbenchmarks of python programs with 648semantic mistakes in total transmap accurately pinpoints the correct location for a fix for87.
oftenhighlighting 2linesfortheusertoinspectper mistake.
we report on our experience in translating python librarieswithupto u1d458linesofcodewith transmap .ourpreliminary user study suggests that transmap can reduce the time for fixing semantic mistakes by around compared to using a standard ide with debuggers.
ccsconcepts computingmethodologies machinetranslation software andits engineering imperative languages .
keywords code translation large languagemodels semantic mistakes acm reference format bo wang ruishi li mingkai li and prateek saxena.
.
transmap pinpointing mistakes in neural code translation.
in proceedings of the 31stacmjointeuropeansoftwareengineeringconferenceand symposium on the foundations of software engineering esec fse december san francisco ca usa.
acm new york ny usa 13pages.https esec fse december san francisco ca usa copyright heldby theowner author s .
acm isbn .
introduction automated code translation is the process of transforming code fromoneprogramminglanguagetoanother.suchtechniquescan help developers express ideas in one language syntax and then easilytransferthemtootherlanguageswithouttheencumbrance of learning a new language syntax.
automatic code translation can also lower the cost of migrating code bases from a legacy language toamodern language orfrom one platform to another .
anewapproachtoprogrammigrationortranslationhasbecome possiblebasedonneuralnetworkmodels .thesetechniqueswereoriginallydevelopedfornaturallanguagegeneration tasks butalsoshowedpromisingresultsincode related tasks.
for example astate of the art neural code generator codex is fine tuned on a popular language model and it backs the ai pair programmer copilot in visual studio code.
it is a general purpose generative model trained on billions of lines of code from public repositories.
it has recently been utilized for translatingcode between programming languages .
neural code translation offers a promising approach for mostly automatic code translation.
these translators are trained in an unsupervised mannerfromexamplesonalargecorpus savingmanual effort in devising translation rules.
the translated code is often natural looking unlikecompiler generatedcode.thisisbecause neural code translators can capture the conventions seen in lots of trainingdata derived from real code.
furthermore state of the art neural translators are derived from large natural language models and can take into account natural language hints like comments or variable namingconventions duringtranslation.
in this work our goal is to improve neural code translation forcodewritteninscriptinglanguages.wespecificallytargetthe translationofpythonprogramstojavascript.boththeselanguages are popular and have many similarities being statically untyped andtherefore we believe offeraconcrete startingpoint.
however neural code translators can introduce errors in generatedcode.priorworkhasobservedthatcodeproducedfromneural code generators can have syntax mistakes operator precedence errors misuseofapis incorrectdatatypes andsoon .mistakesareeithersyntacticorsemantic.syntacticmistakesviolatethe target language syntax and can be easily detected by syntax checkers.semanticmistakes ontheotherhand canresultincodethat does not executeor executes but outputswrong values.
for many of these a fix location is also not immediately visible from running thiswork islicensedunderacreativecommonsattribution4.0international license.
esec fse december3 san francisco ca usa bowang ruishi li mingkaili andprateek saxena figure an example of translated code from a neural code generator.
the code contains 3translation mistakes two semantic mistakes andone syntax mistake.
the gray and whiteshading isthe visualization of thesource map generated by transmap .
tests or syntax checkers.
we call such mistakes hidden.
in microbenchmarks discussed later in section .
of all mistakes are semantic andmore thanhalfoftheseare hiddenmistakes.
inthispaper wethereforefocusontheproblemofautomatically pinpointing hiddenmistakesinthetranslatedcode.giventhesource code itstranslatedcodethatcontainssemanticmistakes anderrortriggeringtests thegoalistoautomaticallyfindthepositionsinthe translatedcodewheresmallmodificationsaresufficienttoproduce translated code that passes the tests.
these pinpointed locations serve as an aid to human programmers they can focus on lines of codeto fix instead of thewhole inputprogram.
whilewe believe our techniques can be combined with upstream tasks such as automated repair or test generation we consider these analyses as orthogonal and retain the human developer in the translation loop keeping withthe notionthat theuserknowsbest .
the challenge in pinpointing hidden mistakes when working with neural code generators is that their behaviour is difficult to interpretorexplain.accesstostate of the artmodelsisoftenblackbox andevenwithwhite boxaccess neuralnetworkswithbillions ofparametersare challengingtoanalyze.severalmechanismsdevised in the context of natural language translation tasks from which neural code translators are derived donot necessarily lend actionableinsightsforcodetranslationtasks.forexample theneural attention mechanism can identify which part of the input code themodelconcentratesontoproduceanoutputsnippet but thissignalistoonoisyanddoesnotexplainwheretheerrorsare introducediftheyare.furthermore littlemodificationinthesource codeorthe decoding algorithms of a modern neural generator like codex can result in unpredictable changes in the translated code makingthe processofpinpointing mistakesad hoc.
a key technical difficulty in pinpointing translation mistakes is that we have tests that run on two different programs one written in the source language and the other in the target.
this setup is unlike that in fault localization orrepair which works with the same program.
therefore we propose to reconstruct a line to line mapping between the source and target program analogous to source maps producedbytraditionalcompilers.suchmappingsallowustocompareexecutiontracesrunonthesourceandtargetprogramsand narrow down locations to focus on.
our solution requires only black boxaccesstotheneuralcodegeneratorandavoidsmaking manycomputationallyexpensivequeriestoit.thismakestheapproachcompatiblewithupdatesincodegeneratorsandlightweight.
it also avoids manually writing hard coded rules for specific types oftranslationmistakes heavy weightanalyses orformallanguage semantics.
our techniques are embodied in a prototype tool called transmap whichisshort for translationwithsource map.
we create a micro benchmark for quantitative evaluation derivedfrom 3sourcesofrealpythonprograms leetcode humanevalx and geeksforgeeks benchmarks .
each benchmarkcontainspythonsourcecode translatedjavascriptcodeobtained from querying codex passing failing tests and manually determined fixes to all the translation mistakes sufficient to pass thetests.thereare648identifiedsemanticmistakeswithmanually validatedfixesintotal.weevaluate transmap onourquantitative benchmarksanditcansuccessfullypinpoint .
ofallthe semantic mistakes and .
of all the hidden mistakes.
the final reported position ranges by transmap have an average length of .23lines which highlights that the developer only needs to focus theirattention onavery small range of the code to devise afix.
weconductapreliminaryuserstudytouse transmap fordebugging code translations with different lengths lines and find thattransmap can save around of the time for fixing the codecomparedtousinganindustry standardide vscode with python and javascript debuggers.
furthermore we report on aqualitativeexperiencebyauthorsinusing transmap totranslate 5larger pythonlibraries of about 120to1 u1d458linesof code.
1000transmap pinpointingmistakes in neural code translation esec fse december3 san francisco ca usa problem overview we begin byshowing an example for whichcodex astate of theart neural generator produces a useful initial python to javascript translation.ithasseveralmistakes thelocationsofwhicharenot straightforward to pinpoint by just running the given tests and observing theruntimeerrors.this motivatestheneedfor transmap .
.
motivating example the left part of figure 1is an executable python code that has one function with a list as the input and returns an integer.
the rightpartisthejavascriptcodetranslatedfromthepythoncode bycodex.therearesomecomplextasksduringthetranslationbut codexmanagestocorrectlytranslatethem.firstly thepythoncode createsa defaultdict typed1dictionaryandusesitonline5 line andline10.asjavascriptdoesnothavetheequivalentbuilt in datatype codex translates the defaultdict datatype inpython to theobjectdata type with a key existence check before access e.g.
atlines7 9injavascript.thistypeofcheckiscorrectlyomitted in codexoutput whenthekeyis presentin thedictionary e.g.
at lines .
secondly the python code has a list comprehension on line10 whichdoesnotnativelyexistinjavascript.codextranslates the list comprehension into statements with the same semantics a forloopinjavascriptatlines14 .thirdly pythonapis suchas len arr sum .. anddatatypeoperations suchas arr are correctly translated into arr.length arr.reduce ... and arr injavascript.
while codex translates most parts of the code correctly the full translatedcodeisnotsyntacticallycorrect asyntaxcheckercan discover a syntax mistake on line .
even if the syntax mistake is fixed thetranslatedcodestilloutputs differentresultsfromthe sourceunder thesametestcases.acarefulreader willnoticethat there are at least two other semantic mistakes for which small modificationstothejavascriptcodearesufficienttomakeitcorrect.
the3mistakeshighlightedinfigure 1are as follows syntacticmistake1 theif else toencodea ternaryexpressionviolatesjavascriptsyntaxonline23.thecorrecttranslation isreturn max conn ?
avg conn max conn .
semantic mistake thearr.sort has different semantics inpythonandjavascript.
the correspondingpythoncode arr.sort online11sorts arrinascendingnumericalorder whereas line of javascript sorts elements alphabetically as strings.
for example the sort of an array will return afterexecuting line10 ofthe pythoncodeand afterexecutingline18ofthejavascriptcode.the correcttranslatedcode should be arr.sort a b a b .
semanticmistake2 the operationinjavascripthasadifferent meaningwith operationinpython.line15ofpythoncode meansintegerdivision e.g.
butline21ofjavascript code is floating point division e.g.
.
.
the correct translatedcode should be avg conn math.floor .. .. .
figure2brieflysummarizesourevaluationonmorebenchmarks presented later in secion .
.
we find that .
of all mistakes are semantic among which more than half are hidden mistakes.
for such mistakes running the program either throws no runtime 1itprovides a default valuefor non existingkeys insteadof raising errors.
figure2 distributionoftranslationmistakesinourmicrobenchmarks presented later insection .
.
errors but produces wrong output values or it throws runtime errors but the error locations are not where the right fix is needed.
.
problemsetup andchallenges inoursetup wearegiventhesourceandtargetprogramsgenerated from the black box neural generator together with unit tests.
it is straightforward to translate test inputs and outputs across languages therefore assume the availability of such tests.
tests under which the outputs of the source and target programs are the samearedeemedas passing whereasthoseonwhichtheydifferare deemedas failing.ourgoalistopinpointlocationsinthetranslated code where fixes are sufficient to have allgiven test casespass.
black box neural code generators are neither explainable nor stable to input perturbations.
unlike compilers of which the behaviors can be explained in deterministic transpilation rules neural code generators can introduce unpredictable changes in the output on small changes in input.
for instance codex can produce totally differentresultsandmistakesforthesameinputevenwithsmall changes in its auxiliary inputs such as in sampling methods or samplingtemperatures.expressingthebehaviorofthegenerator indeterministic rulesfor further analysisisdifficult.
another challenge comes from the complexity of the contextdependentsemanticsofstatementsintheprogram.forexample in untypedlanguagessuchaspythonandjavascript thesemanticsofa statementmaydependontypesandpossiblevaluerangesofrelated variables and how a piece of code should be translated would also depend on the earlier translation of related variables.
for example while line of python g .append ... is semantically equivalenttolines7 10injavascript suchequivalenceisunderthe context that g s data type is mapped from defaultdict python toobject javascript and the value of uin javascript is equal tou 1in python due to the translation at line .
if gwere adictin python and uwere translated to represent the same value g .append ... in python would be equivalent to g .push ... injavascriptinsteadoflines7 .onepossible solutiontothischallengeisto modelsharedsemanticsacrossthe twolanguageswithcontextawareness.but suchspecificationsare labor intensive andchangeas the concernedlanguagesevolve.
inthispaper weaimtoprovidean automaticandlightweight proceduretopinpointsemanticmistakesinneuralcodetranslation that is largely agnostic to the internals of the neural generator.
the fewer the pinpointed locations the better we hope the user s attention can be drawn to as fewlocations to fixas possible.
our solution works on the following key principle rather than trying to reconstructexternally whythe generatorproduces a certain output we simply ask the neural code generator to explain itself i.e.
toproduceamappingbetweenthesourcecodeandits 1001esec fse december3 san francisco ca usa bowang ruishi li mingkaili andprateek saxena figure3 workflowof transmap topinpointandfixthetranslationmistakes.
transmap hastwokeycomponents theneural source map generator andthetrace comparator.
owntranslatedcodeinaformatwedesigned.weshowthatsuch mapping coupledwithanexecutiontracecomparisontechnique can automaticallypinpointmistakeswithhigh fidelity.
3transmap overview figure3showstheworkflowof transmap thatworksinaloopwith a userto pinpoint andfix the translationmistakes.
the translated codeispre translatedbytheneuralcodegeneratorfromthesource and they form a code pair.
1the code pair is given as input to our neural source map generator to generate its source map.
given the codepair itssourcemap andtheunittestsofthesourceandthe translated code the trace comparator reports the location of the firstsemanticmistakeinthetranslatedcodetotheuser.
2theuser fixesthetranslatedcodebasedonthemistakereportof transmap .
if the fixed code does not pass the unit tests it means that the translation has other semantic mistakes.
thus the translated code would be updated andthenextiteration ofthis processwould start from 1to pinpoint the next mistake.
the process stops when the translatedcode has nomistakesremaining i.e.
alltests pass.
source map generation.
the first component in transmap generates the source map a line to line mapping between the given source and translated code pair.
source map creation is standard incompiler basedtranslators butithasnotbeendemonstratedforneuralcodetranslationyet tothebestofourknowledge.
our main insight to solving this challenge is that we can ask the neural code generator to explain itself.
we propose a pre designed prompttoguide theneural codegeneratorto outputthemapping.
our observation stems from the in context learning capability of manymodernlargetransformer basedgenerativemodels which allows the model to learn a new task from only a few examples providedas prompts .we callthem promptexamples .
in context learningdoes not needto change the generative model andonlyrequiresblack boxaccesstoit.foroursourcemapping task the in context learning prompt starts with a fixedprompt example of the mapping task that we designed followed by the pair ofprograms u1d446 u1d447 for whichwe want to create a sourcemap.
our fixed prompt example has a hard coded pair of source and target programs and the corresponding source map between themfigure4 one shotin contextlearningprompttemplate part aandb forsource map generationand its output part c .
created manually.this example essentially illustrates or teaches the model how to create a source map.
when we provide this fixed prompt example together with the programs given as input to transmap u1d446 u1d447 totheneuralcodegenerator itmimicsthetask demonstratedinthefixedpromptexampleon u1d446 u1d447 .figure4briefly shows the prompt template and section .1details the mechanism.
onemaynaturallyaskwhydoesthisapproachtosourcemap generationwork.theexplanationstemsfromwhyin contextlearning works in context learning succeeds when the neural network model is able to infer some shared latent concepts in the 1002transmap pinpointingmistakes in neural code translation esec fse december3 san francisco ca usa providedpromptexamples.thelatentconceptlearntfortranslation is the mapping between semantically similar statements in the two languages.
such latent concepts if learnt for translation should alsobe abletoprovidesourcelinemaps.the fixedprompt exampleteachesthemodelhowtoexplicitlyrepresentitinoutputs.
when designing the prompt computational costs become a bottleneck.
while in context learning works better with more prompt examples the computational cost of the attention mechanism in moderntransformer basedneuralcodegeneratorsincreasesnonlinearlywithpromptlength.themodeltakeslongertotranslate longerinputsandtherefore themodelqueryinterfacelimitsthe number of lexical tokens.
for example codex can only process u1d458 tokens per query at most for the prompt plus the generated text.
toreducethelengthofthepromptandsavemoretokensforthe generatedsourcemap we only use one fixedprompt example.
with a single prompt example we cannot teach very complex taskstoneuralcodegeneratorssincetheirlimitedreasoningand arithmetic computation capability come into play .
thus even though our prompt example is short it is empirically selected to minimizeambiguityinthesourcemappingtask itonlyrequires the neural code generator to copy existing code and annotations to showthelinecorrespondence withoutgeneratinganynewcode or performing complex arithmetic computations.
additionally we alsosetthe samplingtemperature to 0since thetaskrequiresno creativity .withthesedesignchoices weempiricallyobserve that the noise in the generated source maps is quite low as shown in section .
.
figure1visualizes the source map automatically generatedusing our approach withwhite andgray shading.
trace comparison.
after we get the source map the next step intransmap is to execute the source and target programs with the given test inputs which results in execution traces.
transmap comparestheseexecutiontracestopinpointalocationwherethe executionstates i.e.
valuesoftracedprogramvariables differ.a simplisticapproachtotracecomparisonwouldbetotracethesource and translated program statement by statement.
this approach leadstoalargeamountoftracedata.furthermore theintermediate states at eachindividual statement inalarger block ofstatements canturnouttobedifferentbetweenthesourceandtargettraces while still producing the same output at the end of the block.
as an example afterline14injavascript thevariable arrisboundtoan emptyarray but arrisneveremptyinpython.however thevalue ofarrischangedmultipletimesbeforeline17whereitfinallyhas the same valueas inpythonafter line10.
we can improve the above simplistic approach by using our sourcemap.thesourcemapgivesus possiblynoisy line to line mappingwhichisanaturalsegmentationintheprogramstoperform comparisons.
code segments which cannot be sub divided basedonthesourcemaparecalled atomicpieces .wecannowrecord and compare program states between corresponding atomic pieces ofthesourceandthetranslatedcode.however thisnaiveapproach can identifyspuriouslocations to inspect.
toillustratewhy considerthetranslationexampleinfigure again.letusassumethatthesyntaxerroronline23hasbeenfixed by the userso that onlysemantic mistakes remain.
ifwe trace per atomicpiece wewillinsertapairoftracepointsbetweenline6and line in both python and javasript.
the line of the python codemaps to lines of the javascript code but the program values differ variable uon the python side is not equal to the variable uon the javascript side and that is because the translated code is assigning times rather than times tou.
thus the naive approach would report a trace discrepancy at lines as variables uandvhavedifferentvaluesunderalmostallexecutions.
however if we carefully inspect the behavior of the whole loop lines3 6areunnecessarytoinspectandwouldwasteuserattention.
this is because lines in the translated code consistently use u instead of u sothe valuesof local variables after the combined code block lines produce the same result as the python code.
further thisapproachcreates large traces as trace lengthgrows withalgorithmic complexityof the code e.g.
withnestedloops .
weproposeasimplesolutionwecall dynamicgranularitytracing toaddressthischallenge.dynamicgranularitytracingcompares executionstatesattheboundarieswherethesemanticsofthesource and the translated code reach an agreement hoping to skip past differences in intermediate states.
the intuition is to mimic the debugging process of a programmer to some extent where the granularityof breakpoints isincreasediterativelywhileweare gettingcloserandclosertotheexactpositionofthemistake.for example on the translation in figure the tracing starts with statements in the function scope at first to trace the program at lines etc.
of python and etc.
of javascript.
notice that it will not trace inside the first for loop but only compare theprogramstatesbeforeandafterit.thus thetracecomparator concludesthatthefirst forloopiscorrectandmovesontospot mistake at line .
once the user fixes that it will report mistake which is in a deeper block scope.
the translation passes all tests after mistake2isfixedbythe userinour example.
4transmap components two main components of transmap the source map generator andtracecomparator worktogethertopinpointlocationswhere the usercan focustheirattention.
.
sourcemapgenerator given the source and the translated code u1d446 u1d447 by the neural code generator the goal of the source map generator is to output a mappingbetweenatomicpiecesinthesourceand the translated code.
anatomicpieceisatuple u1d434 u1d434 where u1d434 and u1d434 are ordered lists ofstatements correspondingto theline number l u1d460in thesourceprogram and l u1d461inthetranslatedprogram respectively.
thesourcemap isan orderedlistof atomicpieces.
asbrieflyexplained weusein contextlearningwithprompts to the neural code generator for creating source maps.
figure shows the prompt template that is used for all input programs.
conceptually this promptcanbedividedintotwoparts.thefirst part is afixedpair of code fragments that is used to demonstrate the task of creating source maps.
specifically it has a fixed python codeanditsjavascriptequivalentwiththesourcemapannotations in comments as seen in figure part a. this is the one shot example of the task we want to teach the generator to perform .
note that part a of the prompt does not change for different u1d446 u1d447 .
the second part of the prompt template consists of the given pythonsourceprogram u1d446andthegivenjavascripttranslatedcode u1d447 1003esec fse december3 san francisco ca usa bowang ruishi li mingkaili andprateek saxena butwithoutanysourcemapannotations.theneuralcodegenerator is expected to learn how to perform the task demonstrated by partaoftheprompttemplateandauto completeit.theprompt completion if successfully done would copy the programs u1d446 u1d447 andaddannotationstothemwhichserveasthesourcemapping.
the output section of figure 4shows the part completed by the neural code generator.
it can be seen that the model has added code comments line by line to both the python program u1d446and javascript program u1d447providedto itinpart b of the template.
from this output it is straightforward to parse the programs create a list ofstatementscorrespondingtoeachlinenumberspecifiedinthe comments andobtain the sourcemap.
inordertoarriveatthisspecificprompttemplate weperformed promptengineeringempiricallyoftwokinds promptparaphrasing and prompt scoring .
for prompt paraphrasing we mutated both the source mapping instruction match ... and the comments before statement numbers py stmt to create prompt variations to select from.
they are highlighted in greeninfigure .wetried 32variationsonlysinceeachqueryto the code generatorincurs acost.
we then compared prompt variations using prompt scoring .
we define the score of a prompt output as the log probability of filling all the statement numbers correctly red circles in figure .
specifically let u1d436 u1d456 1be the event that the u1d456 u1d461hstatement in the output is correctly mapped else u1d436 u1d456 then we are interested intheeventthatall u1d436 u1d456equalto1.thescore u1d439 u1d443 u1d44b foraprompt variation u1d443onaspecific sourcemapexample u1d44biscomputedas u1d439 u1d443 u1d44b logpr bracketleftbig parenleftbig productdisplay.
u1d456c u1d456 parenrightbig bracketrightbig log productdisplay.
u1d456pr bracketleftbig c u1d456 parenleftbig productdisplay.
u1d457 u1d456c u1d457 parenrightbig bracketrightbig chain rule summationdisplay.
u1d456logpr bracketleftbig c u1d456 parenleftbig productdisplay.
u1d457 u1d456c u1d457 parenrightbig bracketrightbig summationdisplay.
u1d456token logprob u1d441 u1d456 full correct output thequantitiesinthelaststepareprovidedbytheneuralcode generatorand u1d441 u1d456isthe u1d456 u1d461hstatementnumbertoken.multiplevalues token logprob token output for the same outputcan be obtainedfromasinglequerytocodex.wetesteachofthe 32prompt variationson 10distinctsourcemapexamplesthatwemanuallycreated for validation.
for each source map example we obtain scores for all prompt variations.
for each example u1d44b u1d461 we compute the ranking of candidate u1d443 u1d458asrank u1d443 u1d458 u1d44b u1d461 where higher u1d439 u1d443 u1d458 u1d44b u1d461 is better.
we choose the prompt with the highest average rank across the10sourcemapexamples computedas1 summationtext.
u1d461 1rank u1d443 u1d458 u1d44b u1d461 .
.
tracecomparator oncewehavethesourcemap thetracecomparatorinstrumentsthe two given programs u1d446 u1d447 .
it then runs the test cases on them and comparestheirexecutiontraces.forexecutiontracing bothprograms u1d446 u1d447 are instrumented with 2kinds of logging tracepoints andline coverage .
the tracepoint instrumentation logs program statesatthebeginningstatementofeachatomicpiece.thetracepoint is thus a tuple l u1d460 l u1d461 u1d451 wherel u1d460is the line number of the firstsourcestatementofanatomicpiece l u1d461isthelinenumberof the first target statement of the same atomic piece and u1d451is thealgorithm1 dynamicgranularitytracingalgorithm procedure dynamicgranularitytracing u1d443 u1d461 u1d443 u1d460 u1d440 u1d447 l u1d45a u1d44e u1d465 l listhe currenttracing level u1d446 u1d460 ... line u1d443 u1d460 u1d446 u1d461 ... line u1d443 u1d461 whilel l u1d45a u1d44e u1d465do u1d447 filter u1d447 u1d465 u1d465.
u1d459 l u1d465.
u1d460 u1d446 u1d460 u1d465.
u1d461 u1d446 u1d461 u1d460 u1d461 runcollecttrace u1d443 u1d461 u1d443 u1d460 u1d447 u1d458 finddivergingstep u1d460 u1d461 if u1d458isnonethen return nodivergence code iscorrect u1d436 u1d460 getcoveredlinesinbetween u1d460 u1d458 u1d458 u1d436 u1d461 getcoveredlinesinbetween u1d461 u1d458 u1d458 u1d436 u1d461 mapsrclinestotgt u1d440 u1d436 u1d460 u1d436 u1d460 maptgtlinestosrc u1d440 u1d436 u1d461 u1d446 u1d461 u1d436 u1d461 u1d436 u1d461 u1d446 u1d460 u1d436 u1d460 u1d436 u1d460 l l increasetracing level return u1d446 u1d460 u1d446 u1d461 suspicious lines sourceandtarget levelofthetracepoint.thelevelofthetracepointisitslexicalscope depthandalllocalvariablesaccessibleinthatscopearelogged.for example line in python is at level 2and line is at the lowest level0 globalscope .foratracepointtobevalid thescopelevel forthesourcestatementandthetargetstatementareexpectedto be the same if not we do not trace thosestatements.
the instrumented logging statements before each tracepoint recordalllocalvariablesaccessibleinthatscopeandtheirvalues.
however thisisnotsufficienttoknowthesetofexecutedlinesafter hittingonetracepointandbeforehittinganother.theexecutedlines inbetweenarenotnecessarilythecodebetweentwotracepoints duetocontrol flowtransitionstatementsuchas break continue andthrow.
we therefore use line coverage instrumentation to get allthe executedlinesinbetween andhence the controlflow.
afterthecodeinstrumentation weobtainapairofinstrumented programs that are executed under given tests.
as briefly discussed earlier in section we employ dynamic granularity tracing to minimize spurious locations being reported to the user.
our proposed algorithm for such dynamic granularity tracing and trace comparison is showninalgorithm .
it performsmultiplerounds of tracing on instrumented programs with each round increasing thetracinggranularity.linecoverageinformationissmallandis alwaysturnedon.
the input to algorithm 1includes the instrumented source program u1d443 u1d460 theinstrumentedtranslatedprogram u1d443 u1d461 thesource map u1d440 staticmetadata u1d447forselectivelyturningtracepointsonoroff andthe maximum tracing level u1d43f u1d45a u1d44e u1d465.
specifically intheveryfirstround thealgorithmstartsattracing level1 u1d43f with all the lines marked suspicious i.e.
the set of suspiciouslines u1d44b u1d460and u1d44b u1d461areinitializedtoalllinesintheprograms lines2 3inalgorithm .inthisround allthetracepointsatlevel1 areenabledforloggingbuttracepointsathigherlevelsaredisabled checked in line .
for example this means all local variables at functionscopearetracedinjavascript.thetracingisperformedby running the instrumented program on unit tests and collecting the logs.
the enabled tracepoints in the program will record program states tologs line .thetrace logs represented by u1d460and u1d461 are 1004transmap pinpointingmistakes in neural code translation esec fse december3 san francisco ca usa sequences of log items where each log entry item consists of the tracepoint index and values of local variables.
the trace logs u1d460 and u1d461will then be compared step by step.
if no mismatch is found in the traces it implies that the programs behave the same thus the algorithm halts.
otherwise the algorithm will find the first mismatchinglogitemanditscorrespondingdivergingtracepoint line7 .
it then obtains the executed lines between the diverging tracepointandtheprevioustracepointwheretheprogramstates have not diverged from the line coverage information line .
onlythoselinesarenowmarkedsuspicious therefore theupdated u1d44b u1d460and u1d44b u1d461arereduced.thisfinishesoneroundoftracingandthe algorithm goes on to perform the next round of tracing with an increased tracing level line .
in the round with tracing level allthetracepointsoutsideofthesuspiciouslinesetwillbedisabled.
for tracepoints that are still within the reduced suspicious lines set tracepoints up to level will be enabled line .
the second round of tracing can further reduce the set of suspicious lines with more tracepoints concentrated around the unknown mistake.
this processrepeatsuntilthemaximumtracinglevelisreached andthe final setsofsuspiciouslinesare returnedas the result line .
when deciding if the source and translated code diverge at one tracepoint we resort to the notion observational equivalence up to the given tests rather thansemantic equivalence.we log the data types to their canonical forms and compare the canonical forms instead of the original data types.
the idea is to project various data types into a minimum set of simplest data types.
for example list array deque and other similar data typescan be mapped tojsonarray.
int float andothernumerictypescanbemapped to json number.
this tracing and comparison process does lose some information but it reconciles the difference in data types acrossthesourceandtargetlanguages.whileourtracingandvalue comparator implementation has been sufficient for our reported evaluation itcan be improvedinfuture versionsof transmap .
implementation transmap usescodexastheneuralcodegeneratorwiththetranslation prompt shown in figure .
it starts with a fixed pair of minimalistic code fragments that demonstrate the translation task.
the nextpartisthegivenpythonsourcecodethatneedstobetranslated left bottom .theneuralcodegeneratorcompletesthepromptwith translatedjavascript code right bottom as the output.
thesourcemapgeneratorqueriescodexforthesourcemapand weusethestandardgreedydecodingwiththetemperaturesetto and u1d45dto .it parses the generated text from codex to compute atomic pieces.
it assumes that every line in the translation belongs to some atomic piece and that the atomic pieces order the line numbers in python source and the javascript target in the same order withnodiscontinued atomicpiecethat ismixedwith other atomic pieces.
this assumption enables simpler implementation for our trace comparator andempirically it is satisfied most of the time.
the source map generator will abort if it cannot output a valid source map.
when updated programs u1d446 u1d447 are processed onlyfewlinesareupdatedandsotheupdatedsourcemapcanbe computedfrom cachedsourcemapswithoutqueryingcodex.
thetracecomparatorisimplementedassource levelcodeinstrumentationandoffline analysisontracefiles.
theinstrumentation figure5 one shotpromptfor theneuralcodegeneratorto translate python codeinto javascript code.
requires simple static analysis to get the list of local variables at the position of each tracepoint.
thisis implementedwiththe help of tree sitter ast queries and python s built in support for reflection at runtime e.g.
local .
transmap reports the suspicious lines as given by algorithm and the variables with diverging values.
the trace implementation includes runtime type information which is considered during value comparisons2.
when a trace mismatch is found transmap provides both the suspicious variable and the jump to definition utilitytotheuser.theusercanfixthevariabletypedeclaration its type definition orits use at the suspiciouslines.
intotal transmap isimplementedinaround u1d458linesofpython andjavascriptandanother u1d458linesofuicodeforeasierinteraction.
evaluation we evaluate transmap for identifying mistakes in neural code translationfrompythontojavascript.ourevaluationfocuseson the following fouraspects motivation section .
what kinds of translation mistakes does codex make for which transmap isof value?
effectiveness section .
how effective is transmap at pinpointing translation mistakes?
casestudy section .
howmuchhumaneffortdoesit take to translate real world programs using transmap ?
user study section .
how helpful is transmap for usersto pinpointandfixthe translation mistakes?
micro benchmarksforpinpointingneuraltranslationmistakes.pinpointingmistakesinneuralcodetranslationacrosslanguages is relatively new.
we thus created a set of benchmarks that extendsthoseusedinrecentworks .eachsampleprogramin the micro benchmarks contains the following sourceprogram aneuraltranslatedprogram from codex withmistakes test casesfor the sourceandtranslatedcode alistofmistakesinthe code withlinelocations andfixes the fixedtranslatedprogram that passesthe tests.
2similartypeslikearray queue andlistareclusteredasthesame simpletype for comparisonsin ourimplementation.
1005esec fse december3 san francisco ca usa bowang ruishi li mingkaili andprateek saxena wecreateourmicro benchmarksbasedon 3popularbenchmarks on code related tasks leetcode python to js benchmarks programs geeksforgeeksbenchmarks 699programs and humanevalx benchmarks 164programs .
taking the leetcode benchmarks as an example the process to create our micro benchmarks is shown below.
first we query codex to translateallprogramsintheleetcodebenchmarksintojavascriptusing thetranslation promptinfigure .
theprovided testcasesfor the source programs are simple thus we obtained their corresponding versions for translated code using straightforward string substitution.
next we run the translated code on unit tests and collect thefailingprograms.thisgivesus 424programs.thenwemanually check these failing programs and filter out those 132of them where the translated code is either unfixable or not corresponding to the source at all.
we consider a program as unfixable if completely rewriting it or implementing non existing functions and data types used by the translation is necessary to make it pass the tests.
further discussion on these is presented in section .
.
after the filtering we manually check the remaining 292programs pinpointtheirmistakes andwriteafixforeachmistake.intheend we validate459mistakesfrom 292programsonleetcodebenchmarks.
similarly we collect 235mistakes from 136programs on geeksforgeeksbenchmarksand 69mistakesfrom 51programsonhumanevalx benchmarks.
in total we have 479programs and mistakes with fixes 115syntax mistakes and 648semantic mistakes .
the translated programs are about .53lines on average as shown in column u1d434 u1d43f u1d436 u1d457 u1d460of table1and the longest program has 66lines.thedetailedcharacteristicsofthemicro benchmarksare providedinthe supplementary materials .
evaluationmetrics.
toevaluatetheeffectivenessof transmap we check if transmap can pinpoint the semantic mistakes in our micro benchmarks.
for the program with more than one semantic mistake we generate its partially fixed variant programs in which only one semantic mistake exists.
this gives us as many variant programs as semantic errors in this program.
we look at the suspicious lines highlighted at the end.
if the suspicious lines contain themistake wecountitassuccessful.wealsocomputetheaverage numberofsuspiciouslinesthattheuserneedstoinspect aswellas theaverageratiobetweenthesuspiciouslinesandthetotallinesin the program.
baseline.
the baseline approach is simply to run the given unit tests without transmap .
if a runtime error appears we check if that line number is the location where the fix is needed.
if not it is counted as a failure.
note that for hidden mistakes where programstatesdifferbutnoruntimeerrorsarethrown thebaseline approach cannotpinpointthem.
system specification.
we runall experiments ona desktopwith 32gb of ram and an i7 core cpu.
to query the codex modelforgeneratingtranslationsandsourcemaps wedirectlyuse openaiapi withoutlocal computation .
.1quantifying mistakes in codex translations it is useful to understand thekind of errors made by codex before wecanquantifywhere transmap providesmostvalue.figure shows the distribution of all the 763translation mistakes in all our45.
.
.
.
.
.
.
.
different result other runtime error runtime reference error runtime type error confused syntax minor syntax mistake semantic mistakes syntax mistakes figure distribution of mistakes in our micro benchmarks micro benchmarks.
among them syntax mistakes and semantic mistakesaccount for .
and84.
respectively.
asyntaxcheckerspotssyntaxmistakesevenwithout transmap .
mostsyntaxmistakes .
areduetocodexconfusingjavascript syntax with python syntax and producing python like expressions injavascript.forexample theexpression is wronglytranslatedintotheexpression .
thereisnolistcomprehensionsyntaxsupportinjavascriptthusthe correcttranslationshouldbe y.map x parseint x .these mistakes are not minor lexical edits but can often be resolved with an online search of the error description .
a minority of the syntax mistakes are due to minor errors e.g.
missing parentheses .
for example codex translates for loops for a b in arr into for let a b of arr ... but misses a pair of square bracketsaround a b i.e.
for let of ... .
around half of the semantic mistakes .
out of .
cause no runtime errors but result in different results from their corresponding python source.
for the other half of the semantic mistakes most of them cause either reference errors or type errors.
the detailed distributions of mistakes in each micro benchmark are showninthe supplementary materials .
semantic mistakes can be more subtle and can result in runtime errors .
of all mistakes .
we divide runtime errors caused by semantic mistakes into three types runtime reference error runtime type error and other runtime errors.
they account for .
.
.
of all mistakes respectively as shown in figure6.anexampleofruntimereferenceerrorisusingundeclared variablesornon existingfunctions.misuseofapiandoperators or accessing a numeric value as if it is an object will result in runtime type errors.
occasionally the translated program might not terminate and exceed the maximum call stack.
most of such mistakesthatcauseruntimeerrorscanbefixedbychangingtheapi calls operators oraddingvariabledeclarationsattheruntimeerror location.
however the locations of .
runtime errors .
of allsemantic mistakes do not matchthe correctfixlocations.
theother .
ofthesemanticmistakes .
ofallmistakes cause no runtime errors but make the translated code differ in outputoftheunittestsfromthesource.thistypeofmistakecan be further dividedintoseveral sub types 1006transmap pinpointingmistakes in neural code translation esec fse december3 san francisco ca usa table distributionsofmistakeson micro benchmarks andperformanceof transmap compared to the baseline approach micro benchmarksmistaken prog.
mistakes baseline transmap count u1d434 u1d43f u1d436 u1d457 u1d460syntax semantic u1d446 u1d460 u1d452 u1d45a u1d446 u1d460 u1d452 u1d45a u1d446h u1d456 u1d451 u1d446 u1d451 u1d456 u1d453 u1d43f u1d460 u1d462 u1d460 u1d445 u1d460 u1d462 u1d460 leetcode .
.
.
.
.
.
.
.
.
geeksforgeeks .
.
.
.
.
.
.
.
.
humanevalx .
.
.
.
.
.
.
.
.
total average .
.
.
.
.
.
.
semanticconfusion i.e.
confusingsimilarapisanddatatypes.
suchastranslatingfrom int x intomath.floor x ormath.
trunc x differentwhenx a toa.at i ora.get i .
wrong assumptions about the javascript runtime and apis.
suchastranslating a b c.popleft toa c.shift b c.shift shiftis not pure and will change c translate not arr to!arr theequivalentexpressionshould bearr.length whenarrisan array .
others i.e.
mistakesthatseemtobedifficulttoclusterorcategorize.
such as missing a function call in the translation assigning absurd values such as tovariables and introducing a temporary variable with the same name as a local variable.
.
of the semantic mistakes in our micro benchmarks cause runtimeerrorsatlocationsdifferentfromthemistakes.
.
of thesemanticmistakescausenoruntimeerrorsbutgivedifferent results.transmap isaimedatpinpointingsuch hiddenmistakes.
.
effectiveness of transmap we evaluate transmap onthe numberoflines that the user hasto inspecttofixeachmistakeinourmicro benchmarks.ifthelines highlighted by transmap contain the location to fix the pinpointingisdeemedsuccessfulandafailureotherwise.ourresultsonthe micro benchmarks are shown in table where u1d446 u1d460 u1d452 u1d45a u1d446h u1d456 u1d451 u1d446 u1d451 u1d456 u1d453 represent the ratio of successfully pinpointed mistakes to the total semantic mistakes hiddenmistakes and mistakesthat cause differentoutputresultsfromthesourcerespectively.thequantities u1d43f u1d460 u1d462 u1d460 and u1d445 u1d460 u1d462 u1d460represent the number of highlighted suspicious lines and its ratio totheprogram size averaged overthesemanticmistakes successfully pinpointedby transmap .
amongthe setofsemanticmistakes transmap canpinpoint .
ofthemsuccessfully.incontrast thebaselinesuccessfully pinpoints only .
of thesemantic mistakes.
thus transmap significantlyimprovesoverthebaseline.itssuccessratiocanachieve satisfactionrateamongdevelopersaccordingtothiswork .
thesuspiciouscodelines u1d43f u1d460 u1d462 u1d460bytransmap are .
lines which is .
of the program code lines on average.
this means that the useroftenonlyneedstofocuson 2linestounderstandthemistake and to fix it.
it shows that transmap can efficiently pinpoint thesemanticmistakesforshortcodefragmentswithhighaccuracy.
transmap performs well on the hidden mistakes that the baselineapproachcannotfindatall.asshownin u1d446h u1d456 u1d451columnoftable .
.
of hidden mistakes can be pinpointed among three micro benchmarks.
for semantic mistakes that do not cause any runtimeerrorsbutdifferentresultsfromthesourcecode transmap isabletosuccessfullydiagnose84.
mistakes u1d446 u1d451 u1d456 u1d453 onaverage.we also look at the quality of the generated source map specifically.we findthat .
ofthegeneratedsource mapsare correct.
failingcasesare discussedinsection .
.
.
ofsemanticmistakesinourmicro benchmarksarepinpointedsuccessfullyby transmap comparedto .
bybaseline.the userinspectsonly .23linesonaverageper mistake.
.
casestudies howmuchdoes transmap helpintranslatinglargerreal world python programs to javascript?
we report on the qualitative experience of translating python libraries using transmap as an aid.
theirloc excludingtests andthenumberofsemanticmistakes are shown in table .
we select those modules because they are standalone havenoexternaldependencies andtheircodecanbe segmented and translated function by function without significant lossofcontext.we hadnoapriorifamiliarity withtheselibraries.
we explain our methodology in detail using the first module strsimpy asanexample.the strsimpy libraryimplementsmany stringfunctionstocomputesimilarityanddistancemeasures.italso comes with unit tests.
it has stars on github and around u1d458 downloadsperweek3.itcontainsaround1klinesofcodedistributed in35 pythonfilesandhas nothird partydependencies.
before translating this python library to javascript we first merge the relatedpython program files into standaloneprograms andconvertunitteststojavascript.morespecifically wemanually mergethe35fileswiththeirunittestsinto5self containedprogram filesaccordingtotheirdependencyrelation.wefirstconvertunit tests in python into javascript using codex and manually postprocesstoensurethetestsaretranslatedcorrectly.thisisfairlyeasy sincetheunittestsaremostlyfunctioncallsandassertionsthatare straightforward to convert.
it is worth noting that all these manual efforts on merging files and converting unit tests can be further reducedwithsufficientengineeringwhenintegrating transmap intomodern ides orinotherbuildenvironments.
eachofthe 5self containedprogramfileisaround 200lines.ifwe translateonefileandcreateitssourcemapinoneattempt itwould exceed the token limit of the codex api.
we observe that 50is a feasiblelinenumberofthesourcecodetobetranslatedandmapped inonequery.thus wesplitthecodeintosegmentsofaround lineswhilepreservingtheboundariesofclassesandfunctions.then each segment is translated with codex source mapped separately bytransmap andthenmergedbackafterfinishingallsegments.
thesesteps are fully amenableto complete automation.
.thedownloadstatistics wereobtained from on28january2023.
1007esec fse december3 san francisco ca usa bowang ruishi li mingkaili andprateek saxena figure7 anexamplereport ofahidden semanticmistake pinpointed by transmap .
it contains the mistake location and variables with differing values in the source and the translated code.
we then run programs and fix the syntax mistakes caught by syntax checkers so that only semantic mistakes are remaining.
after that we start transmap to work with the user iteratively to pinpoint by transmap andfix bytheuser semanticmistakesfollowing the workflow shown in figure .
in each round transmap outputs the suspicious lines that contain the first semantic mistake found in the translated code together with the detailed information of the diverging tracepoint e.g.
the mismatching between the expected value in the source and the actual value in the translated code of variables and the corresponding source lines in python accordingtothesourcemap.forexample figure 7showstheinformation reported by transmap on one of the semantic mistakes in this case study.
transmap pinpoints the mistake atthe javascript codeline 194withthecorrespondingpythoncodeline .besides it gives the local variable values in two code and highlights the inequivalent variable offset arr .
with this report the human user is expected to figure out that the mistake is caused by the semantic confusion of pop ... in javascript and provide the fix line in javascript should be offset arr.splice i that removes the u1d456 th element from offset arr .
transmap correctlypinpointsthelocationofallofthe13hidden mistakes in the translated code automatically.
with those mistakes highlighted from transmap one of the authors of this work with noaprioriexperiencewiththelibrary fixedalloftheminabout1 hour.the final javascript translation passesallthe given tests.
inadditionto strsimpy resultsof4morecasestudiesareshown intable2.transmap correctlypinpoints128ofthe130hiddenmistakesandhas12falsepositives fps .fpsareduetotypedifferences ofsome variables.
the user can disable tracingthem to continue debugging.
the supplementary materialgives more details.
transmap pinpoints128ofthe130hiddenmistakesintranslationsof5pythonlibraries with12 false positives.table2 pythonlibrariesforcasestudies locmeanslinesof code sem.m.meansthenumberofsemanticmistakes hid.
meansthenumberofhiddenmistakes tpand fpmean truepositivesandfalsepositivesof transmap respectively.
module locsem.
m. hid.
tp fp strsimpy mathgen colorsys heapq html table3 thenumberofunfinishedtasksandthemediantime forusersto pinpoint hidden mistakesand finish tasks groupshortprogram longprogram u1d441unfin u1d447 u1d460 u1d45d u1d45c u1d461 u1d447 u1d461 u1d45c u1d461 u1d44e u1d459 u1d447 u1d460 u1d45d u1d45c u1d461 u1d447 u1d461 u1d45c u1d461 u1d44e u1d459 u1d43a u1d450452s739s1020s1255s7 u1d43a u1d452 60s235s286s365s2 .
user study weconductapreliminaryuserstudyontheusefulnessof transmap in the debugging taskof pinpointing and fixing hidden mistakes.
evaluation metrics are the time users spend pinpointing and fixing bugs andthenumberofunfinishedtasks.weinvite24computersciencegraduates4 whohavenopriorfamiliaritywith transmap and randomlydividethemintoacontrolgroup u1d43a u1d450 withouttransmap andanexperimentalgroup u1d43a u1d452 withtransmap .twogroupsare given the same set of programs consisting of randomly sampled short programs lines from our micro benchmarks and long code segments lines from strsimpy library.
each participant is randomly assigned debugging tasks short programs and 1long program and we make sure every program is assigned tothreeuserspergroup.eachprogramcontainsonemistakeand only a one line fix is needed to pass tests.
if they spend more than minutes they have the option to abandon that program which would be regarded as an unfinished task.
the results are presented in table3.
the u1d441unfincolumn shows the number of unfinished tasks out of tasks per group.
after removing these samples the medianofthetimetoconfirmthelineofmistakeandthemedianof thetotaltimetofinishthistaskispresentedas u1d447 u1d460 u1d45d u1d45c u1d461and u1d447 u1d461 u1d45c u1d461 u1d44e u1d459.we canseethatthemediantimetopinpointhiddenmistakesreduces on short code and on long code when using transmap compared to using the vs code debugger.
moreover the total time to pinpoint and fix mistakes also reduces by on short code and onlongcode.additionalresultsoftheuserstudyarepresented inthe supplementary material .
.
discussion unfixable cases when creating micro benchmarks.
we removed unfixable translations due to a known issue referred to ashallucination inlargelanguagemodels .
such unfixable translations typicallyhave aheavy relianceonnon existentapis data types and operators lacking javascript equivalents.
although 4all participants reported having at least some familiarity with python or javascript.
1008transmap pinpointingmistakes in neural code translation esec fse december3 san francisco ca usa table accuracy of source mapping and breakdown of failuresunder differentstyles ofthetranslated code scenario accuracyfailure breakdown neq.oob.diso.
fixed translation .
.
.
.
buggytranslation .
.
.
.
addedcomments .
.
.
.
renamedvariables .
.
.
.
multiple functions .
.
.
.
transmap can identify these mistakes fixing them is complicated andwefounditgenerallysimplertoentirelyrewritethetranslation.
transmap cannothelpmuchinsuchinstances examplesofwhich are providedinthe supplementary material .
the types of failures in source mapping.
in our evaluation of the micro benchmarks .
of the source mapping are counted as failures.
there are three types offailures code not equal neq .
.
some code linesin the mapping outputare differentfrom the input i.e.
part c andbinfig.
.
outofbound oob .
.someannotatedstatementnumbers inthetranslation javascript donotexistinthesource python .
disorder diso .
.somestatements are mappedwrongly.
wecountthefirsttwotypesasinvalidandthethirdtypeasinaccurate.mostofthefailurecasescanbefixedwithmanualmodificationsto several linesofthe mapping.
robustnessofsourcemapping.
toassesshowvaryingstylesof thetranslatedcodeaffecttheperformanceofsourcemapping we conduct additionalexperiments5on thesame leetcodeprograms fromourevaluation.weintroducedchangestothefixedjavascript translationsinvariousways commentinsertion variablerenaming andfunctionconcatenation.table 4showsthatthesetransformationsdegradetheaccuracyofsourcemappingbyabout1 .the supplementary material has amore detaileddiscussion.
possiblelimitationsofin contextlearningusingllms.
llms can typically generalize froma fewexamples yet the contextwindowrestrictsthecomplexityoftasksthattheycontextualize.
further their reasoning capability is token limited leading to a subparperformanceonsomefew shotreasoningtasksasindicated bybrown et al .however methods like chain of thoughts can be usedto enhance outcomes withincreasedoutputlength.
transmap vs. conventional code alignment approaches.
to our knowledge most of the conventional approaches to code andtracealignment focusondifferentversionsofthe code inthe same language.
we observe neural codetranslation can make unpredictable transformations such as breaking merging reorderingstatements transformingloopstructure andsoon.thus an llm based self explanatory approach is potentially easier to implementandmoreaccurateforcodetranslationsbythellmitself.
however theapproachhassomepitfalls includingnoisyoutputand the limiting context length inherent in llms.
enhancements could potentially come from imposing output restrictions on language models andexpandingthe contextwindow .
5weusedchatgpt3.
insteadofcodexforthisexperimentand4casestudies exceptstrsimpy since codexbecamepubliclyunavailable to us.
related work this is the first work on automatically pinpointing mistakes for neural code generator outputs when attempting to translate across programming languages.
this problem is related to non neural code translation andfaultlocalizationindifferentways.
codetranslation.
traditionalcompilersandtranspilationtools are the most common approaches used today.
the readability of thegeneratedcodeisoftenlimitedandtheefforttowritecompilers is significant.
to address these issues a recent line of work uses natural language processing tools for code generation and translation.
transcoder proposed unsupervised code translation using back translation.
szafraniec et al .proposed to train neural decompilerstotranslatebetweenlanguagesthatcanbecompiled tollvmir.largerstate of the artmodelssuchascodex are also trained in an unsupervised manner and can translate between multiplelanguages.however alloftheseapproachessufferfrom noisy outputs with mistakes.
our work on transmap is motivated from these observations and aims to augment existing neural code translators.anotherlineofworkwithalongerhistoryistousesymbolicapproachesforcodetranslation.txl isadomain specific languageforwritingcodetranslators.amorerecentworkintroduces duoglot a system that combines rule based translation with rule synthesis from user provided examples.
this approach has the benefits of being predictable but generally requires human effortandexpertisetowriterules.
transmap isanincomparable alternative it directs the user to a fix in the translated program ratherthangeneraltransformation rulesacrosslanguages.
faultlocalization.
fault location is a richareaof priorresearch whichalsopinpointserrorsinbuggyprogramsgiventests .the keydifferencefrom theseworksisthattests in ourproblemsetup runontwoprogramsindifferentlanguages.thenovelchallengeis thereforeinmappingexecutionsemanticsbetweentheprograms especiallyaftertheyhaveundergoneablack boxneuraltranslation.
transmap introduces generic capabilities such as source maps that can act as an important aid to adapt existing fault localization techniquestoneuralcodegeneratorsinthefuture.priortechniques have focused on different aspects improving statistical scoring functions ranking mechanisms better reasoning under mutations increase the quality of test suites improving trace analysis symbolic reasoning for root cause analysis andmore.
conclusion weprovidethefirstsystematicapproachtopinpointingerrorsin code translated from one program language to another by modern neural translators.
our transmap identifies mistakes with high fidelity inshort javascript fragments translatedfrom python.
data availability our code and datasets are available on zenodo .
the latest version and supplementary materials can be found on github.