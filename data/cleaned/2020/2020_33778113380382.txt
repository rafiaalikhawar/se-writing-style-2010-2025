combodroid generating high quality test inputs for android apps via use case combinations jue wang state key lab for novel software technology and department of computer science and technology nanjing university nanjing china juewang591 gmail.comyanyan jiang state key lab for novel software technology and department of computer science and technology nanjing university nanjing china jyy nju.edu.cnchang xu state key lab for novel software technology and department of computer science and technology nanjing university nanjing china changxu nju.edu.cn chun cao state key lab for novel software technology and department of computer science and technology nanjing university nanjing china caochun nju.edu.cnxiaoxing ma state key lab for novel software technology and department of computer science and technology nanjing university nanjing china xxm nju.edu.cnjian lu state key lab for novel software technology and department of computer science and technology nanjing university nanjing china lj nju.edu.cn abstract androidappsdemandhigh qualitytestinputs whosegenerationremainsanopenchallenge.existingtechniquesfallshortonexploring complex app functionalitiesreachable only by along meaningful andeffectivetestinput.observingthatsuchtestinputscanusually be decomposed into relatively independent short use cases this paperpresentscombodroid afundamentallydifferentandroidapp testing framework.
combodroid obtains use cases for manifesting a specific app functionality either manually provided or automaticallyextracted andsystematicallyenumeratesthecombinations of use cases yielding high quality test inputs.
the evaluation results of combodroid on real world apps are encouraging.
our fully automatic variant outperformed the bestexisting technique ape by covering .
more code ape only outperformedmonkeyby2.
andrevealedfourpreviouslyunknown bugs in extensively tested subjects.
our semi automatic variant boosts the manual use cases obtained with little manual labor achieving a comparable coverage only .
less with a white box human testing expert.
keywords software testing mobile apps acm reference format juewang yanyanjiang changxu chuncao xiaoxingma andjianlu.
.
combodroid generating high quality test inputs for android apps via use case combinations.
in 42nd international conference on software engineering icse may23 seoul republicofkorea.
acm new york ny usa 12pages.
permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation on the first page.
copyrights for components of this work owned by others than acmmustbehonored.abstractingwithcreditispermitted.tocopyotherwise orrepublish topostonserversortoredistributetolists requirespriorspecificpermissionand ora fee.
request permissions from permissions acm.org.
icse may seoul republic of korea association for computing machinery.
acm isbn ... .
introduction android apps are oftentimes inadequately tested due to the lack ofhigh quality test inputs1to thoroughly exercise an app s functionalities and manifest potential bugs .
existing automatic testing techniques fall short on exploring complex app functionalities that are only reachable by long and meaningful event sequences .
random or heuristic test input generation techniques can quickly cover superficial app functionalities but have difficulty in reaching deeper app statesto cover complex ones.
systematic input space exploration tech niques have severe scalability issues.
manual testing iseffective and thorough but also tedious labor intensive and time consuming and usually hinders the rapid release of an app.
to generate high quality test inputs to thoroughly explore an app sfunctionalities weobservethatalongandmeaningfultestinput can usually be decomposed into relatively independent use cases.
a use case is a short event sequence for manifesting a designatedapp sfunctionality e.g.
1togglingasetting 2switching to an activity or 3downloading a web content.
isalong andmeaningful testinput andisparticularlyusefulin manifestingdiverseappbehaviorswhentheapp sbehaviorin varies on different settings in .
conversely we can solve the problem of generating long and meaningful test inputs by a fundamentally different two phase approach which we call it the combodroid framework collecthigh qualityusecases thatcoverasmanybasicapp functionalities as possible.
concatenate a number of use cases to form a test input for covering complex functionalities.
use cases can be either manually provided e.g.
by an app s developer or automatically extracted from execution traces.
since developersclearlyknowhowtherequirementsareimplemented they can easily provide high quality use cases with little manuallabor.
to extract use cases automatically from execution traces 1in the context of testing android apps a test input is a sequence of the android system s atomic input events touching swiping etc.
.
ieee acm 42nd international conference on software engineering icse we leverage the insight that use cases by their definitions almost beginandendat quiescent appstates usuallywithastablegui.we accordingly designedan algorithmto automaticallyidentify such gui states and extract use cases from long event sequences.
to efficiently generate high quality use case combinations or combosforshort astestinputs wedeviseanalgorithmtotriage combosforamaximizedtestingdiversity.particularly wedefinethe aligns with relation which determines whether two use cases connected at the same quiescent state to prune likely invalid combos.
we also define the depends on relation which determines whether a use case can affect the behavior of another.
we generate only alignedcomboswithsufficientdata flowdiversitiesforaneffective test input generation.
we implemented these ideas as the combodroid tool including the fully automatic combodroid and semi automatic combodroid .theevaluationresultsareencouragingthatcombodroid is effective in both testing scenarios the fully automatic combodroid covered .
and .
more code on average compared with the most effective existingtechniqueape andmostwidelyusedtechnique monkey respectively.
combodroid also revealed four previouslyunknownbugsinextensivelytestedsubjects .
the semi automatic combodroid boosted the coverage of manually provided use cases by .
achieving a competitive code coverage the gap is only .
compared with a human testing expert but with much less manual labor.
the rest of this paper is organized as follows.
section 2presents anoverviewofourapproachwithanillustrativeexample.details of our approach are discussed in section .
section 4introduces thecombodroidimplementationandourextensiveevaluationis conductedinsection .section 6surveysrelatedwork andsection concludes this paper.
overview figure1displaysthecombodroidworkflow.combodroidtakesan app under test pand repeats the two phase testing procedure consistingofobtainingusecases theleftbox andenumeratingusecase combos therightbox .weexplaintheworkflowofcombodroid using a motivating example a previously unknown bug2found by combodroid in aard2 a popular dictionary app .
this bug requiresalong andmeaningful testinput to trigger.
obtainingusecases .
wefirstobservethatameaningfulusecase event sequence usually begins and ends at quiescent app states in which the app is idle completes handling of all received events onastablegui.quiescentstatesnaturallyindicatethatahuman can perform the next step of an action in the computer human interaction.inaard2 usefulusecasesincludeadding deletinga dictionary searching for a word view a word s detail explanations etc.
usecasescanbeprovidedbyahumandeveloper notedcd .
combodroid contains an auxiliary tool to help developers collectusescasesbyrecordingeventsequences bothuiandsystem 2aard2hasbeenextensivelyevaluatedintheexistingstudies .however combodroid is the first to uncover this bug.events ataspecifiedtimeinterval.combodroidautomatically identifies quiescent states and collects execution traces and gui snapshots along with the use cases.
in aard2 the app s developer would have no difficulty in providing meaningful use cases like ... and .
usecasescanalsobeextractedbyanautomaticanalysisofan app sexistingexecutiontraces notedcd .combodroidminesan extended labeledtransition system elts atruntime basedon the gui transitions using an existing algorithm .
similar stable guisareclusteredasasinglestateintheelts.eachinputevent between a pair of stable guis in the execution traces is added as a transition labeled with that event in the elts.
to bootstrap cd as there is no trace at first we implemented a baseline dfs alike state space exploration tool to generate initial testing traces.
unique acyclic transitional paths on the elts areextractedaslikelyusecases.inaard2 automaticallygenerated use cases are not as readable as manual ones but share similar features e.g.
starting from and ending at quiescent app states .
nevertheless combodroid successfully identified different pages e.g.
thedictionary search anddetailpage asdistinctstatesinthe elts andthegeneratedusecasescoverallfunctionalitiesin ... and .
enumerating use case combos .
either way combodroid enumerates the combinations combos of use cases to obtain high quality test inputs.
a combo is a sequence of use cases u1 u2 ... un whereu1startsfromtheapp sinitialstate.tomakecomboseffective in testing a combo should additionally satisfy deliverability for all i n uialigns with ui .
foruto be aligned with v the last gui layout in ushould be similar to the first one of v such that it is sane to deliver vto the appimmediatelyafter u .similarityischaracterizedbyan editing distance based measurement.
dataflow diversity there exists at least kdistinct pairs of ui uj whereuidepends on ujandi j. foruto be dependenton v thereshouldbesomesharedprogramstates used inuand modified in v. thereby we filter out loosely connected use case combos.
thesystematicenumerationincombodroidfirstsearchesfor data dependent pairs for a maximized data flow diversity and then addsrandomtransitionaluse casestosatisfythedeliverability.in aard2 2and4 5aredata dependent3.then combodroidgenerates 5asaskeleton whichisfilled with transitional use cases 3and s to yield the bug triggering combo in figure a combo of n k .
the feedback loop .
generatedcombosaredeliveredtotheapp withexecutiontracesbeingcollected.afterthedelivery combodroid terminates if there is no newly explored quiescent app state otherthanthoseidentifiedduringtheusecasegeneration.otherwise combodroidrestartsthefirstphasetoeitheraskahumanfor additional effective use cases concerning these states e.g.
visiting themduringtheexecution orextractmorepotentiallyprofitable 3use case delete a dictionary overwrites the dictionary object referred in add a dictionary and thus 2depends on .
for a similar reason on the shared webviewobject 5depends on .
470 figure combodroid overview and a motivating bug example usecasesfromtheeltsrefinedbythenewlycollectedexecution traces.
manifestationofthebug .
thecomboinfigure 1crashestheapp.
afterdeletingadictionary allofitsdetailwordexplanationsare removed.however the detail pageofapreviouslysearchedword isstillcachedintheapp.returningtosuchadetailpagedisplays a null blank webview.
a subsequent zoom in triggers the crash by a nullpointerexception .
all eight use cases events are necessary to trigger the bug and such a long event sequence is not likelyto begenerated byexisting techniques which indeedfailed to do so in our evaluation.
approach .
notations and definitions givenanandroidapp p ourgoalistogeneratehigh qualitytest inputs viause casecombinations.
androidapps aregui centered and event driven.
the runtime gui layout snapshot lscriptis a tree in whicheachnode w lscriptisaguiwidget e.g.
abuttonoratextfield object .
we use w.typeto refer to w s widget type e.g.
a button or atextfield .when pisinactive closedorpausedtobackground there is no gui layout and lscript .
anevent e angbracketleftt r z angbracketrightisarecordinwhich e.t e.r ande.zdenote e seventtype receiverwidget andassociateddata respectively.an event can be either a ui event or a system event and examples of t are ui click ui swipe or sys pause .forauievent thereceiver r lscript wdenotes that ecan be delivered to w lscriptat runtime.
r lscript indicates that this event cannot be delivered.
a system event sreceiverisalwaysthe system widget.otherevent specific information is stored in z e.g.
texts entered in a text field or the content of an added file.
executing pwithasequenceofevents e yields anexecution trace execute p e angbracketleftl m t angbracketright.as defined in algorithm l4 m andtdenotethedumpedguilayouts method invocationtrace andeachevent scorrespondingmethodinvocations respectively.
4forl lscriptiis the gui layout dump at a quiescent state after the firsti 1events ineare sent to the app.algorithm execution of a sequence of events 1function executep e lscript getgui l m t 3foreache edo ifr lscript nequal then ecan be sent on lscript m prime sendeventtoapp e.t e.r lscript e.z send eventetop wait for a quiescent state and return the corresponding method invocation sequence m m m prime t t angbracketlefte m prime angbracketright lscript getgui l l else return 10return angbracketleftl m t angbracketright a use case u is also an event sequence.
it is straightforward for a human developer to manually provide use cases in either way annotating use cases as substrings inan execution trace or feeding to the following automatic extraction algorithm.
.
use case extraction usecasesareextracteduponaminedextendedlabeledtransition system elts .
furthermore in the fully automatic settings in whichnotraceisprovided weuseastandarddepth firstexploration to obtain a bootstrapping trace.
mining an automaton .
given an execution trace angbracketleftl m t angbracketright fromexecutingeventsequence e itscorrespondingeltsisathreetupleg angbracketlefts e angbracketright in which sis a set of abstract states s s s is a partition of the gui layouts l and s e scontains the state transitions.
we adopt the existing algorithm in swifthand for miningaminimaleltsthatgroupssimilarguilayoutstogether i.e.
equivalent lscript1 lscript2 5holds for all gui layouts lscript1 lscript2in the same 5we use the lv.
gui comparison criteria guicc of amola to measure the similarity between guis i.e.
gui layouts lscript1and lscript2are equivalent if and only if e e.e.r lscript1 nequal e.r lscript2 nequal .
471algorithm elts mining 1function mineelts angbracketleft l m t angbracketright e 2s lscript lscript l initially no state is merged 3 angbracketleft lscripti ei lscripti angbracketright i n 4foreach si sj s sandsi nequalsjdo in the bluefringe ordering angbracketlefts prime prime angbracketright merge recursive si sj s if angbracketlefts prime prime angbracketright nequal then angbracketlefts angbracketright angbracketlefts prime prime angbracketright update merged states 8return angbracketlefts e angbracketright 9function merge recursive s t s 10if lscript1 s lscript2 t.equivalent lscript1 lscript2 then s prime s s t s t prime foreach angbracketlefts e t1 angbracketright angbracketlefts e t2 angbracketright wheret1 nequalt2do angbracketlefts prime prime angbracketright merge recursive t1 t2 s prime prime if angbracketlefts prime prime angbracketright then break return angbracketlefts prime prime angbracketright 17return merging failed states.
such an algorithm algorithm is originally used in the dynamic model extraction of android apps.
extractingusecases .
avalidpath p ong s e where si ei sifor all i mnaturally corresponds to the sequence of events u as a likely use case.
therefore the automatic use case extraction algorithm enumerates all acyclic paths in gand produces a use case for each of them.
notethatourautomaticalgorithmextracts likelyusecasesfrom the elts.
in such a manner we can maximize the chance of exhausting all possible use cases.
moreover most likely use cases can be real use cases while others share similar features with them e.g.
starting from and endingat quiescentapp states and can also be effective exploring the app s behavior.
bootstrapping the use casegeneration .
inthefully automatic setting of combodroid theuse case extraction is bootstrapped by a standard dfs alike state space exploration strategy similar to the a3e algorithm .
starting from the initial state we take the gui layout snapshot lscript analyze all widgets w lscriptfor all possible actions on w. for each action e.g.
clicking a button or entering a random text from a predefineddictionarytoatextfield wecreateanevent e6and addittoeui.wethensequentiallyexecute sendtheeventtotheapp andwaitforaquiescentstate alleventsin eui esys whereesysis a set of predefined system events.
if executing an event reaches an unexploredgui lscript prime theexplorationisrecursivelyconductedon lscript prime if all events are exercised or reaching an explored gui backtracking is performed thus this is a depth first exploration .
the depth first exploration yields a sequence of events edfs.
6fore angbracketleftt r z angbracketright e.tande.zare straightforward to determine.
the receiver e.ris determined by an editing distance based algorithm described later in section .
.
.
enumerating use case combos suppose that use cases u u1 u2 ... un are extracted from executiontrace angbracketleftl m t angbracketrightbyexecutingeventsequence e.ause case combination orcombo isa sequence ofuse cases denoted by .
sequentially concatenating the events in the use cases of a combo yields a runnable test input.
unfortunately randomlygeneratedcombosusuallystopearly inanexecutionbecausetherewilllikelyexistanevent ethathas no receiver on the deliver time gui lscript i.e.
e.r lscript .
consider the combo2 5inthemotivatingexample figure .the zooming in event has no receiver after deleting a dictionary because the current gui does not contain a listview menu containing the zoominbutton.
togeneratehigh qualityusecasecombos weleveragethefollowing two use case relations aligns with .
for two use cases u andv e prime e prime ... e primem wesaythat ualignswith v oru leadstov ifwehave witnessed once that e prime 1can be successfully delivered after en.i n otherwords u leadstovife prime .r lscriptn nequal where lscriptnistheguilayoutafter the execution of en ein the trace .
another issue in the use case alignment and replaying an event sequence istodeterminehowtodeliverauievent etoaparticular gui layout.
for lscript w1 w2 ... w lscript being the gui layouts right beforeewas sent in and an arbitrary lscript prime w prime w prime ... w prime lscript prime we know that there exists i lscript such that e.r lscript wi lscript becausewiise sreceiverwidgetin .therefore thewidget w prime j lscript prime that is most similar to wishould be the receiver of eon lscript prime i.e.
e.r lscript prime w prime j. to measure the similarity between gui layouts we compute theeditingdistance between lscriptand lscript primeusingthealgorithminrepdroid .wefindtheshortesteditingoperationsequence each editing operation is either inserting or removing a widget thattransforms lscriptto lscript prime.i fwiis not removed during the transformation it must have a unique correspondence w prime j lscript prime.
we thus let e.r lscript prime w prime j otherwise wiis removed and e.r lscript prime .
depends on .
forusecases uandv wesaythat vdependson u oru dashedarrowrightv ifthetwousecasesarepotentiallydata dependent.data dependencyismeasuredatamethodlevel.consideringthemethod invocation trace in if there exists a method m t e fore u andm prime t e prime fore prime vsuch that m primedata dependson m wesay thatu dashedarrowrightv.datadependenciesbetweenmethodsaredetermined byalightweightstaticanalysis.
m primedata dependson mifthereisan abstract object or resource write accessed in mand read accessed inm prime.
combogeneration .aligns with anddepends on relationsguide our use case combination combo generation.
to maximize the diversity of generated combos we enforce each combo c u1 u2 ... u c to satisfy eachcomboisanindependenttestcase e1.r lscript0 nequal for lscript0 l beingtheapp sinitialguilayoutand e1beingthefirstevent inu1 consecutiveusecasesinthecomboarealigned ui leadstoui 1for all i c and 472algorithm combo generation 1function randomcombo u lscript0 k 2g v e randomdag k random dag of e 2k 3f v randomchoice u v v randomly assign each v va use case in u 4if e e angbracketleftv1 v2 angbracketright e f v1 dashedarrowrightf v2 kthen foreach linear extension ofgdo foru0 u e1.r lscript0 nequal do c connect u0 f v1 u connect f v1 f v2 u ... connect f vn f v v u add paddings such that consecutive use cases are aligned if nelementcthen returnc 10return 11function connect u dst u depth 12ifu leadstodstthen return 14ifdepth max depth then return 16foru prime u u leadstou primedo seq conncet u prime dst u depth ifseq nequal then return seq 20return use casesin acombo exhibit k data flow diversity i.e.
there existskdistinct pairs of ui uj i j c such that ui dashedarrowrightuj.
the algorithm for generating a combo is presented in algorithm3.
given a set of use cases u the app s initial gui layout lscript0 andadata flowdiversitymetric k arandom skeletonisfirstsampled.
a skeleton is a directed acyclic graph g v e where e 2k.
ifthedata flowdiversityof gislessthan k line4 thegeneration should be restarted.
otherwise each vertex v vis assigned with a random use case f v inu lines alinerextensionoftheskeleton gcorrespondstoasequence of use cases .w et r yt opad use cases f vi andf vi i v with more use cases to obtain a combocsuchthatconsecutiveusecasesin carealigned line7 .
the padding use cases are depth first searched with a maximum length limit max depth lines .
we also add paddings before the first use case in c line such that the resulting combo can be delivered to the initial app state andthus ccanbeusedasanindependenttestcase .ifallaforementioned paddings exist7 we successfully obtained a use case combo satisfying our requirements lines .
such a combo is sent to the app for testing.
7a transition between each pair of guis naturally exist for a well designed app.
therefore it is highly like that all aforementioned paddings exist.
.
feedback loop of combodroid as figure 1shows there can be multiple iterations of use case generation and combo enumeration.
when enumerated combos are senttotheappanddiscoveredpreviouslyunknownstates anew iterationshouldbeinitiated.beforethenextiterationstarts adeveloper can manually inspect the testing report and provide annotate more use cases.
supposethatweconcatenatetheexecutiontracesinallprevious iterations of use case generation and combo enumeration.
conceptually this can be regarded as adding an extra restart event after sending all events in a combo8.
such a merged trace is used for the eltsminingandusecaseextractioninthenextroundofiteration.
implementation the combodroid framework is implemented using kotlin and java.
combodroid consists of a fully automatic variant combodroid and a semi automatic variant combodroid .
we extensivelyusedopen sourcetoolsinthe implementation andcombodroid is also open source available9 gui events are recorded by getevent guiandsystemeventsaredeliveredusingandroid debug bridge adb gui layouts are dumped by android ui automator methodtracesarecollectedbyprograminstrumentation with soot .
the implementation follows the descriptions insection .wefollowthecommonpracticeofexistingstate ofthe arttechniques andidentifyquiescentappstates bystabilizedguis.specifically wetakethesameimplementation as ape by dumping gui layouts every 200ms until it is stable using the lv.
guicc with a 1000ms upper bound.
for combodroid we implement the dfs alike exploration tool andfollowthesameimplementationasape byreplaying previous execution traces for backtracking.
for combodroid w e analyze the gui layouts where the human tester sends each event togetherwiththecorrespondingeventtodetermineeachevent s receiver.
inthelightweightstaticanalysistodeterminethedepends on relation we also model the android .
apis api level todetermineread writeaccessestoresources e.g.
wedetermine whether an sql command in sqlitedatabase.execsql is a read orwritetothedatabase.moreover foran abstract object ifany method whose name matches the regular expression get is read .
on .
changed iscalled weconsideritaread similarly callinganymethodwhose name matches set write change modify .
is considered a write.
the depth first exploration of combodroid was set with a time limit of minutes in each iteration.
in the combo generation bothcombodroid andcombodroid wesetdata flowdiversity k and max depth .
we generate d2random combos by randomcombo if there are ddepends on edges.
8a restart event is also added after elts mining.
evaluation thissectionpresentsourevaluationofcombodroid.theexperimental subjects and setup are described in section .
followed by evaluation results of combodroid the fully automatic variant andcombodroid thehumanaidedvariant insections .2and5.
respectively.discussionsincludingthreatstovalidityarepresented in section .
.
.
experimental subjects and setup the first column of table 1lists the evaluation subjects.
the appsareselectedusingthefollowingrules first weselectedthe threelargest inloc apps evaluatedin existingwork wordpress k mail and myexpense.second werandomly selected nine apps with at least 10k downloads evaluated in the existingwork wikipedia ankidroid amazefilemanager anymemo hackernewsreader callmeter aard2 worldclock andalogcat.additionally werandomlyselected five popular at least stars by open source apps from github antennapod pockethub simpletask simple draw and coolclock.
if an app s major functionalities cannot be accessed without a proper initial setup e.g.
user login we provide the app a script to complete the setup.
all evaluated techniques receive exactly the samescript andthescriptrunsautomaticallyoncetheinitialsetup gui is reached to ensure a fair comparison.
we did not mock any further functionality other than the initial setup script.
weusetwometricstomeasurethetestingthoroughness.the firstisbytecodeinstructioncoveragecollectedbyjacoco as ahighercodecoveragestronglycorrelatestoabetterexerciseof an app s functionalities.
second we study whether the techniques can manifest and reproduce previously known or unknown bugs by examining the android system s logs.
to evaluate combodroid we compare it with the state of theartautomatedtechniques monkey sapienz andape .
for each subject we ran each automatic testing technique for hoursto simulateanightly continuousintegration build and test cycle.werancombodroid forterminationor12hoursatmost.
for each subject we ran each techniques three times and reported the average results.
test coverage and bug manifestation results are then studied.
to evaluate combodroid we compare it with a human expert.
for manual use case generation of combodroid w eg a v ear e cruitedtesteroneworkday 8workhours foreachtestsubjectand thenraneachsubjectfor12hours.meanwhile weaskedanother independently recruited android testing expert a post graduatestudent who had published a few research papers on testing and analysis of android apps to cover as much code as possible given atimelimitofthreeworkdays 24workhours .thehumanexpert had access to an app s source code and was told to use coveragefeedback to maximize code coverage.
since manual labor is notscalable we only evaluated the subjects of top loc as shownin table3.
to reduce distractions as confirming and diagnosing 10since ape significantly outperforms stoat and other related work we did not show results of other techniques in this paper.bugs aretime consuming weasked thehuman expertnot toprovide any bug report.
therefore only test coverage is studied in the evaluation of combodroid .
allexperiments wereconducted onanocta core inteli7 4790u pcwith16gibramrunningubuntu16.04ltsandanandroid .
emulator.
.
evaluation results combodroid the hour coverage results and manifested bugs are listed intable1and table respectively.
the detailed coverage trends areplottedinfigure .theseresultsareconsistentwitharecent empirical study automated techniques by that time barely outperformthesimplestmonkey.thebestexistingtechnique ape marginally outperforms monkey by covering .
more code.
encouragingly combodroid consistently outperforms existing techniques in nearly allsubjects11.
for alogcat coolclock and callmeter combodroid terminated within hours while for other subjects it ran until the time limit exceeded.
compared with the best existing technique ape combodroid covered .
more code on average.
this improvement is even as much as theimprovementofapeovermonkey.consideringthattheape implementationgenerates .
moreeventsin12hours 120kfor combodroid v.s.
300kforape combodroid isconsiderably more effective in exploiting each event s merits.
the progressive coverage in figure 2shows that combodroid usually begins to outperform existing techniques after six hours.consider that the current combodroid implementation emits events at speed the result is also promising.
furthermore codecoveragegainofexistingtechniquesisusuallymarginal or zero in the last hours.
in contrast combodroid is consistently exploring useful use case combinations to cover more code.
thebugmanifestationevaluationresults arealsoencouraging.wemanuallyexaminedthetestlogsofalltechniques andfound12reproduciblebugswithanexplicitrootcause.excluding the bug in simple draw combodroid missed it due to an implementationlimitations combodroid manifested all11previously known or unknown bugs where the best existing technique ape manifested7 .wealsoreportedfour previouslyunknown bugs ape can discover only two of them to the developers.
all of themwereconfirmedandtwoofwhichhavebeenfixed.furthermore the two previously unknown bugs uniquely discovered by combodroid aredeepbugswhichrequirealong andmeaningful input sequence to trigger.
the motivating example figure i s such a case.
therefore we hold strong evidence that combodroid is more effective in automatically generating high quality test inputs for android apps compared with existing techniques.
.
evaluation results combodroid the evaluation results of combodroid are displayed in table .
for all subjects combodroid ran until the time limit exceeded.
it isexpectedthatthehumantestingexpertsignificantlyoutperforms 11apeandcombodroid coveredlesscodeforsimpledrawcomparedwithmonkey becausetheimplementationsdonotidentifycanvaswidgetsandthusnotsenddragging events.
we consider this an implementation limitation.
474020406080100wordpress antennapod k mail 020406080100myexpenses wikipedia ankidroid 020406080100amazefilemanager pockethub anymemo 020406080100hacker news reader callmeter simpletask 020406080100simple draw aard2 world clock 020406080100coolclock alogcat combodroid fully automatic monkey sapienz ape combodroid semi automatic human expert figure progressive coverage report of evaluated techniques averaged over three runs .
the xaxis is the time spent hours .
the yaxis indicates the percentage of code covered thus far.
475table evaluation results of combodroid test coverage subject category downloads loc monkey sapienz ape combodroid coverage trend wordpress wp social 5m 10m .
.
.
.
.
antennapod ap video 100k 500k .
.
.
.
.
k mail k9 communication 5m 10m .
.
.
.
.
myexpenses me finance 500k 1m .
.
.
.
.
wikipedia wiki books 10m 50m .
.
.
.
.
ankidroid ad education 1m 5m .
.
.
.
.
amazefilemanager afm tools 100k 500k .
.
.
.
.
pockethub ph tools 100k 500k .
.
.
.
.
anymemo am education 100k 500k .
.
.
.
.
hacker news reader hnr news 50k 100k .
.
.
.
.
callmeter cm tools 1m 5m .
.
.
.
.
simpletask st productivity 10k 50k .
.
.
.
.
simple draw sd tools 10k 50k .
.
.
.
.
aard2 aard books 10k 50k .
.
.
.
.
world clock wc bussiness 1m 5m .
.
.
.
.
coolclock cc tools 10k 50k .
.
.
.
.
alogcat alc tools 100k 500k .
.
.
.
.
average .
.
.
.
.
1columncoverage trend plots the coverage trend of each tool.
the red solid lines denote combodroid and dashed lines are existingtechniques.thedetailedcoveragetrendsaredisplayedinfigure .numberinabracketisthecoveragedifferencesbetween combodroid and the best existing technique monkey sapienz and ape .
table2 evaluationresultsofcombodroid bugmanifestation bug id cause discovered by wp infinite recursion ape cd ap atomicity violation cd ap null pointer dereference all k9 mismatched mime type sapienz cd afm null pointer dereference all afm lifecycleeventmishandling ape cd am lifecycleeventmishandling cd am null pointer dereference ape cd cm text input mishandling ape cd sd miss used local variables monkey aard null pointer dereference cd aard null pointer dereference all monkey sapienz ape cd 1bug idis theissue idinthe project sgithub repository.a starred bug id denotes a previously unknown bug.
automatedtechniques.eventhethebestautomatedtechniqueso far combodroid covered .
less code.
however this gap is reduced to .
when human knowledge is integrated into our framework use case combinations additionally covered13.
morecodethanmanualusecasesonly.combodroid greatly amplified the use cases covering .
code which is even .
less than combodroid to achieve a result nearly as goodtable evaluation results of combodroid test coverage subject uc cd combodroid expert wp 328k .
.
.
.
.
.
.
ap 262k .
.
.
.
.
.
.
k9 160k .
.
.
.
.
.
.
me 104k .
.
.
.
.
.
.
wiki 93k .
.
.
.
.
.
.
ad 67k .
.
.
.
.
.
.
afm 66k .
.
.
.
.
.
ph 48k .
.
.
.
.
.
.
am 41k .
.
.
.
.
.
.
hnr 38k .
.
.
.
.
.
.
average .
.
.
.
.
.
.
1the number in column subjectis the app s loc.
columns uc cd combodroid andexpertdisplay the code coverage of manual use cases combodroid combodroid andthehumanexpert respectively.thenumbersinthebracketsofcolumn combodroid indicate thecoveragedifferencesbetweencombodroid andmanualusecases and combodroid respectively.
the numbers in the brackets of columnexpertindicatethedifferencesbetweenthehumanexpertand combodroid .
as the human expert.
surprisingly the combodroid even outperformedthehumanexpertinhackernewsreader.afteranalyzing the code and coverage data we found that hacker news reader can enable data preload of news articles in the settings.
when itisenabled openinganarticleinanapplication internalformat 476 .
figure qualitative illustration of the state space exploration strategies in evaluated techniques.
invokesadditionalcodetoprocesspre loadeddata.suchasubtlede pendencyismissedbythehumanexpert ontheotherhand though also not covered by any single manual use case combodroid correctly pinpointed such a data dependency in the depends on relation and accordingly generated the use case combination.
though in a preliminary stage combodroid demonstrates the potential of automatically leveraging human insight in comple menting and boosting automated techniques in testing android apps.
.
discussions .
.
towards thorough automatic testing of android apps.
figure3illustratesthesearchstrategiesoftheevaluatedtechniques for giving a qualitatively explanation of why combodroid outperformed existing techniques.
random based techniques monkey and ape at each timedeliversexactlyoneeventtotheapp andthereforearecompletely unaware of the remaining state space.
their limitationsare obvious the search strategies are purely based on the noisyexploration history.
such strategies may easily lose a deep and profitable appstateonrandomtries e.g.
pressingabuttonreturns to the app s main menu .
sapienz thoughexploitsmotifsequencesinaguidedsearch failstoeffectivelyassemblingthem.first thereisnorationaleor quality guarantee of the motif sequences they are more or lessrandom event sequences.
second mutation and crossover operationsinthegeneticsearchareinefficientincreatingusefulmotif sequence combos randomly concatenating two event sequences willmostlyresultinauselesscombo.itisnotsurprisethatsapienz even covered less code than monkey in the long run.
this result is consistent with the existing studies .incontrast combodroid generatedbothhigh qualityusecases and their combos and thus is highly effective in covering app functionalities even if it delivers less events.
compared with manual testing automatic testing is still far less satisfactory thehumanexpertcovered12.
morecodeonaverage than combodroid .
the evaluation results of combodroid show that this gap is mainly due to the quality of use cases.
our usecase extraction algorithm simply cannot understand the app s functions andsemantics however meaningful usecases are quite naturalevenforanappuser.machinelearningoverlarge scaleapp usage data set may be a promising direction to address this issue.
.
.
leveraging human insights in semi automatic testing of android apps.
combodroid successfully amplified the manual use casestoachieveacompetitivecoveragecomparedwithahuman expert adding a little more human aid boosts the testing thorough ness.thispartiallyvalidatedourintuitionthathumansaregoodat sketchingthemajorfunctionalitiesoftheapp oncesuchinsights are extracted as use cases tedious and repetitive work can be offloaded to machines.
therefore combodroid asaconcept provingprototype opens anewresearchdirectiontowardsthehuman machinecollaborativetestingofandroidapps.automaticallygeneratingmeaningful and handy suggestions eitherbyprogram analysisormachine learning to help manual testers developers or even users to provide better use cases is a rewarding future direction.
.
.
threats to validity.
biasintheselectedsubjects .
therepresentativenessofselectedtestsubjectscanaffectthefidelityofourconclusions.tomitigatethisthreat weselectedevaluationsubjects from various sources popular benchmarks evaluated in existing workplusrandomonesfromgithub.thesesubjectsare largein size around kloc on average well maintained containing thousands of revisions and hundreds of issues on average popular all have 10k downloads and diverse in categories.
since combodroidconsistentlyandsignificantlyoutperformsexisting techniquesinallthesebenchmarks exceptforsimpledrawdueto the implementation limitation the conclusion that combodroid is more effective than existing techniques is evident.
randomnessandnon determinism .
theevaluatedtechniques including combodroid involve randomness and subjects may be non deterministic.
therefore for each subject and technique we reporttheaverageresultofthreeindependentrunsunderthesame settings theexperimentscostover2 400cpuhours toalleviate this issue.human factors .
the performance of human testers vary form persontoperson.therefore theevaluationresultsofcombodroid onlyapplytothathumantestingexpert.sincethepost graduate androidtesting analysisexpertknewusinadvance wearecertain that he she tried the best to cover as much code as possible.
related work many technologies have been proposed for input generation for android app testing including both fully automatic ones and semiautomaticones.moreover sometechnologiesgeneratingtestinputs for gui web testing also share similarities with combodroid.
477fully automatic test input generation for android apps .a majority of existing technologies aim to fully automatically generatetestinputsforandroidapps.manyofthemgeneratetestinputs for general testing purposes.
randomtestingisalightweightandpracticalapproachinwhich alargenumberofrandomeventsarequicklyfedtoanapp including monkey dynodroid droidfuzzer intentfuzzer etc.
usinga guimodel eitherpredefined ormined may guidethe explorationofanapp sstatespace.representativeworkincludes mobiguitar swifthand amola and the state ofthe artape .suchstatespaceexplorationisusuallydoneby a depth breadth first search e.g.
a3e gat and ehbdroid .
however even if with a model existing techniques fall short on generating long and meaningful test inputs.
search based software engineering techniques can also be applied suchasevodroid andsapienz whichemploygenetic programming to evolve generated test inputs or stoat which constructs a stochastic model and uses mcmc to guide the generation.
moreover some researchers propose to utilize machine learning to guide the input generation .
furthermore somepiecesof workutilizesymbolicor concolicexecutiontosystematicallygeneratetestinputsformaximizingbranchcoverage including sig droid the technology proposed by jensen et al.
synthesise and droidpf .
existing search based techniques barely scale to large apps.
finally combodroidisnotthefirsttointroducetheideaofcombinationinandroidapptesting.however existingcombinatorialbased strategies concern only combinations of single events and thus unable to generate long and meaningful test inputs.
in conclusion all existing technologies fall short on generating long and meaningful test inputs for practical apps which are essentialinmanifestingdeepappstatesandrevealingmanynontrivial bugs.
the limitation of existing techniques motivated the design of combodroid.
semi automatictestinputgenerationforandroidapps .
some technologies are proposed to utilize human intelligence to improve the quality of generated test inputs.
for instance polariz extracts common event sequences from crowd based testing to enhance sapienz.
appflow records short event sequences provided by human and utilizes machine learning to synthesize longeventsequences.moreover uga extendsmanualevent sequences exploring the skeleton of the app s state space.
though capable of utilizing human intelligence polariz and uga have no controloverthequalityofextractedmanualeventsequences.on the other hand appflow lacks an effective mechanism for reusing the event sequences in testing.
domain specifictestinputgenerationforandroidapps .
some technologiesaimtogeneratetestinputsforcertaintestingdomains orformanifestingcertainkindofbugs.forinstance eoedroid utilizes symbolic execution to generate inputs to testing webviews ofanapp whilesnowdrop aimstotestbackgroundservicesof an app.
apechecker and aatt generate test inputs to manifest potential concurrency bugs in android apps.
moreover sometechnologiesareproposedtodetectenergyinefficiencyinandroid apps such as greendroid and its extensions thesetechniquesaregenerallyorthogonaltocombodroid.they can be benefited by the high quality test inputs generated by combodroid.
testinputgenerationforgui webtesting .
sometechnologies utilize iterative gui exploration or program analysis to generate test inputs for gui web testing.
some pieces of work iteratively observes the execution of existing test inputs extractsadditionalknowledge e.g.
arefinedmodel andderives newtestinputs.forinstance nguyenetal.
proposestheoem paradigmthatautomaticallyidentifiesnewtestinputsduringthe execution of existing ones expands the current incomplete gui event model and generates additional test inputs based on current execution traces.
such iterative process resembles combodroid.however the knowledge extracted by these technologies mostlycomes from observations of gui transitions and other relations between test inputs such as data dependency are often neglected.
on the other hand some technologies utilize static analysis on program code to find data dependencies between events and thus generate effective test inputs .
however these technologiescannotbedirectlyappliedfortestingandroidapps sinceandroidappsarecomponent basedwithbrokencontrol dataflow and often invoke android specific apis to access shared data e.g.sharedpreference.getboolean.
incontrast combodroidextractsknowledgeoftheappunder test from both gui transitions and data dependencies and utilizelightweightstaticanalysisonexecutiontraceswithandroidspecificapimodelingtoinferdepends onrelationsbetweeninputs.
conclusion and future work leveraging the insight that long meaningful and effective test inputsareusuallytheconcatenationofshorteventsequencesfor manifesting a specific app functionality this paper presents the combodroid framework in which the android app test input generation problem is decomposed into a feedback loop of use casegeneration and use case combination.
the evaluation results are encouraging.thefullyautomaticcombodroid covered on average4.
morecodethanthebestexistingtechniqueandrevealed four previously unknown bugs.
with little human aid the semiautomatic combodroid achieved a comparable coverage only .
less on average with a human testing expert.
combodroid sheds light on a new research direction for obtaining high quality test inputs either fully automatic or with human aid.based onthisproof of concept prototype a diverserange of technologies can be applied in the future enhancement of combodroid.
promising research includes exploiting machine learning in usecasemining crowd sourcedusecasesacquisition andmodel checking combos.