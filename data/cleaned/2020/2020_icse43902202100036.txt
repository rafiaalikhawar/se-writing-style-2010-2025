reducing dnn properties to enable falsification with adversarial attacks david shriver department of computer science university of virginia charlottesville virginia usa dls2fc virginia.edusebastian elbaum department of computer science university of virginia charlottesville virginia usa selbaum virginia.edumatthew b. dwyer department of computer science university of virginia charlottesville virginia usa matthewbdwyer virginia.edu abstract deep neural networks dnn are increasingly being deployed in safety critical domains from autonomous vehicles to medical devices where the consequences of errors demand techniques that can provide stronger guarantees about behavior than just high test accuracy.
this paper explores broadening the application of existing adversarial attack techniques for the falsification of dnn safety properties.
we contend and later show that such attacks provide a powerful repertoire of scalable algorithms for property falsification.
to enable the broad application of falsification we introduce a semantics preserving reduction of multiple safety property types which subsume prior work into a set of equivalid correctness problems amenable to adversarial attacks.
we evaluate our reduction approach as an enabler of falsification on a range of dnn correctness problems and show its cost effectiveness and scalability.
index terms falsification formal methods neural nets i. i ntroduction as the performance and applicability of deep neural networks dnn continues to increase their deployment has been explored for use in safety critical domains such as autonomous vehicles and medicine .
as a result checking the correctness of dnns has emerged as a key challenge to ensuring the safety of these systems.
for example for the dronet dnn that predicts a steering angle and a probability of collision for an autonomous quadrotor system one such correctness property may specify that if the probability of collision is low then the steering angle should not be extremely large.
one approach to checking correctness of dnn models is verification.
in the past years alone dozens of dnn verification techniques have been introduced for proving properties of dnn models .
unfortunately these approaches are often limited in their applicability due to their simplifying assumptions about dnn structure or to high computational cost making it difficult to apply them to real models .
for example due to the large size and complex computation graph of dronet existing verifiers fail to run or cannot finish in a reasonable time.
a complementary approach to verification is that of falsification which attempts to find violations of a property.
while verifiers can show that a property is true falsifiers can often find violations more quickly than verifiers when the property isfalse.
falsification is an active area of research spanning property types and application domains .
in the context of dnns one can view adversarial attacks as falsifiers for dnn local robustness properties.
while these techniques often scale to real world dnns they are currently limited in the range of properties they can falsify.
for the dronet example adversarial attacks support the scale and complex structure of the dnn but are designed only to find violations of robustness properties and not safety properties like those relating speed and probability of collision.
as we discuss in ii a there is a broad range of properties that could benefit from the speed and applicability of these falsifiers.
driven in part by the cost of dnn verification and in part by the limited property support for dnn falsification we identify the key insight that many valuable property types could be reduced into the more commonly supported form of local robustness properties.
we build on this insight to develop an approach for reducing properties in an expressive general form to an equivalid set of local robustness properties which have wide support among both falsifiers and verifiers.
such translation has the potential to bring existing techniques to bear on falsifying dnn properties leaving verifiers to focus on proving that a property holds.
our community has exploited property reduction for verification and program analysis for decades.
perhaps best known is the reduction from stateful safety properties to reachability properties.
for example partial order reductions were broadened in applicability by reducing stateful properties to a form of deadlock and both data flow analyses and sat solving were applied to verify stateful properties by formulating the reachability of error states.
a second use of reductions is to enable more efficient algorithmic methods to be employed.
for instance the safety option of the spin model checker permits it to use a significantly faster reachability algorithm .
such reductions are now considered standard in verification and program analysis.
in the new domain of dnn verification and falsification however the lessons of such reductions have not yet taken root.
in this paper we introduce an approach for reducing a dnn and an associated safety property which we refer to as a correctness problem into an equivalid set of correctness ieee acm 43rd international conference on software engineering icse .
ieee fig.
proposed approach reduces a dnn and its safety property into an equivalid set of correctness problems formulated with robustness properties that can be processed by falsifiers.
problems formulated with robustness properties that can be processed by existing adversarial techniques.
figure provides an overview of the approach.
by preserving validity the translation supports both falsification approaches such as adversarial attack algorithms and existing verification techniques.
the approach is fully automated which allows developers to specify properties in a convenient form while leveraging the complementary strengths of falsification and verification algorithms.
the primary contributions of this work are an automated approach for the reduction of dnn correctness problems as an equivalid set of robustness problems an implementation of our approach that employs a portfolio of falsifiers and a study demonstrating that property reduction yields costeffective violations of general dnn correctness problems.
ii.
b ackground this section presents prior work on dnn property specification and approaches for their falsification.
a. properties of dnns given a dnn n rn!rm a property n defines a set of constraints over the inputs x the pre condition and a set of constraints over the outputs y the postcondition.
checking property n attempts to prove or falsify 8x2rn x x !
y n x .
a survey on verification of neural networks identifies different representations for the input and output constraints used by verification techniques two of these representations are particularly useful in this work.
a hyperrectangle is an n dimensional rectangle where constraints are formulated as xi lbi xi ubi wherelbi ubi2rand0 i n define the lower and upper bounds on the value of each dimension ofx respectively.
a special case of hyperrectangles used in our approach is the unit hypercube which is a hyperrectangle where8i lbi ubi ann dimensional hypercube is denoted n. ahalfspace polytope is a polytope which can be represented as a set of linear inequality constraints ax b wherea2rk n b2rk kis the number of constraints and nis the dimension of x. using such encodings researchers have specified a range of desirable properties of dnns.
here we distinguish three broad categories robustness reachability and differential properties.
robustness properties originated with the study of adversarial examples .
robustness properties apply to classification models and specify that inputs from a specificregion of the input space must all produce the same output class.
robustness properties can be further classified as either local or global robustness the former asserts robustness in a local region of the input domain and the latter over the entire input domain.
detecting violations of robustness properties has been widely studied and they are a common type of property for evaluating verifiers .
reachability properties define the post condition using constraints over output values rather than output classes and are thus not limited to classification models.
such properties have been used to evaluate dnn verifiers .
reachability properties specify that inputs from a given region of the input space must produce outputs that lie in a given region of the output space.
for example a dnn model controlling the velocity of an autonomous vehicle may have a safety property specifying that the model never produces a desired velocity value greater than the vehicles maximum physical speed for any input in the input domain.
similarly to robustness reachability properties can be further classified as local or global.
for example a global halfspace polytope reachability ghpr property would specify a halfspace polytope constraint on network output values that must hold for all inputs.
differential properties are the most recently introduced dnn property type .
these properties specify a difference or lack thereof between outputs of multiple dnns.
one type of differential property is equivalence which states that for every input two dnn models produce the same output.
such a property can be used to check that dnn semantics are preserved after some modification such as quantization or pruning.
differential properties can be supported by combining multiple dnns into a single network and expressing properties over their combined input and output domains.
in addition to these three categories and as alluded earlier properties can also be classified by the form of their input pre condition.
global properties have the most permissive precondition enforcing the post condition for any input in the input domain of the dnn.
for example a dnn that operates on images may accept values in n. the pre condition of a global property would not restrict this domain any further.
local properties only enforce the post condition for inputs within a designated region of the input domain.
for example a local property for an image processing network may have the precondition that inputs are within distance of some given inputx.
this is especially common in robustness properties.
b. adversarial attacks and fuzzing one approach to checking properties of dnns is through the use of algorithms that seek to find examples that violate a given specification for a given model.
two categories of techniques have been developed for dnns that can be used to falsify dnn property specifications.
adversarial attacks are methods that are optimized to detect violations of robustness properties .
in general adversarial attacks take in a dnn model and an initial input and attempt to produce a perturbation that when applied to the input will change the class predicted by the given model.
276these perturbations are often also subject to some constraints such as remaining within a given distance of some original input.
a perturbed input commonly known as an adversarial example is a violation to a local robustness property.
to our knowledge adversarial attacks are a method of falsification that only supports the falsification of robustness properties.
adversarial attacks can be classified based on characteristics of the attack such as if they are white box or black box targeted or untargeted iterative or one shot or by their perturbation constraint e.g.
l0 l2 orl1 .
a more exhaustive taxonomy and description of existing adversarial attacks is available in the literature .
fuzzing involves randomly generating inputs within a given input region often the full input space and checking whether the outputs they produce violate a specified post condition.
fuzzing is more general than adversarial attacks in that it can support the falsification of more than robustness properties but requires specifying input mutation functions and objective functions essentially an output oracle for every type of property that needs support.
examples of existing fuzzing techniques include tensorfuzz and deephunter .
iii.
a pproach the primary goal of our approach is to amplify the power of falsifiers such as adversarial attacks by increasing their applicability.
our approach takes in a correctness problem comprised of a dnn and a property and encodes it as an equivalid set of robustness problems which then enables us to run a portfolio of methods that are applicable to this restricted problem class to uncover general property violations.
a. defining property reduction acorrectness problem is a pair hn i of a dnn n and a property specification formed to determine whether nj isvalid orinvalid .
reduction reduce !p aims to transform a correctness problem hn i to an equivalid form reduce fhn1 1i hnk kig in which property specifications define robustness properties i 8x x2 n!n i x ni x and networks have input domains defined as unit hypercubes and output domains consist of two values indicating property satisfaction and falsification 8hni ii2reduce ni n!r2 as we demonstrate in iv reduction enables the application of a broad array of efficient dnn analysis techniques to compute problem validity and or invalidity.
as defined reduction has two key properties.
the first property is that the set of resulting problems is equivalid with the original correctness problem a proof of this theorem is included in appendix a .
dronet prefix suffix n0 n1 x. x n x n x fig.
one of the robustness problems generated by reduction.
theorem .
reduction maps an arbitrary correctness problem to an equivalid set of correctness problems.
nj 8hn i ii2reduce nij i the second property is that the resulting set of problems all use the same property type i.e.
robustness they all assert thatn x 0is the output class for all inputs.
applying reduction enables verifiers or falsifiers to support a large set of correctness problems by implementing support for this single property type.
we chose to reduce to robustness properties due to their broad support among existing falsifiers and verifiers.
b. overview to illustrate consider a property for dronet a dnn for controlling an autonomous quadrotor.
inputs to this network are by pixel grayscale images with pixel values between and .
for each image dronet predicts a steering angle and a probability that the drone is about to collide with an object.
the property states that for all inputs if the probability of collision is no greater than then the steering angle is capped at 5degrees and is specified as 8x x2 n x pcoll !
n x steer adversarial attacks cannot be used off the shelf to falsify this property since it is not a robustness property.
to enable the application of adversarial attacks we reduce the property to a set of correctness problems with robustness properties such as the one shown in figure .
this particular example is reduced to two correctness problems with robustness properties.
each of the problems pair a robustness property shown in the bottom of figure with a modified version of the original dnn.
the new dnn is created through two key transformations.
first incorporating a prefix network shown in green in figure to reduce the input domain to a unit hypercube.
this modification ensures that the properties for reduced problems can all use the same pre condition.
second incorporating a suffix network shown in blue in figure that takes in the inputs and outputs of the original dnn and classifies whether they constitute a violation of the original property.
this suffix transforms the network into a classifier for which violations of a robustness property correspond to violations of the original property.
c. reduction transformation we rely on three assumptions to transform a correctness problem into a reduced form.
first the constraints on the network inputs must be represented as a union of convex polytopes.
second the constraints on the outputs of the 277algorithm property reduction input correctness problem hn i output a set of robustenss problems fhn 1i hni iig 1begin dnf fordisjunct2 0do hpoly disjunct tohpolytope disjunct pre x construct pre x hpoly 7n0 n0 x7!concat n x x su x construct su x hpoly 9n00 su x n0 pre x 8x x2 n n00 x n00 x hn00 0i return algorithm disjunct tohpolytope input conjunction of linear inequalities i output halfspace polytope h 1begin 2h a b whereais an j ij m n matrix where columns 0tom 1correspond to output variables n x 0to n x m 1and columns mtom n 1correspond to input variablesx0toxn forineq j2 ido ifineq juses then swap lhs and rhs switch inequality to else ifineq juses then swap lhs and rhs switch inequality to move variables to lhs move constants to rhs ifineq juses then decrement rhs switch inequality to 11aj coefficients of variables on lhs 12bj rhs constant returnh network must be represented as a union of convex polytopes.
third we assume that each convex polytope is represented as a conjunction of linear inequalities.
complying with these assumptions still enables properties to retain a high degree of expressiveness as unions of polytopes are extremely general and subsume other geometric representations such as intervals and zonotopes.
iv a shows that these assumptions are sufficient to support existing dnn correctness problems.
algorithm defines the reduction transformation at a high level.
we present each step of the algorithm and describe their application to the dronet example described above.
reformat the property reduction first negates the original property specification and converts it to disjunctive normal form dnf line .
negating the specification means that a satisfying model falsifies the original property.
the dnf representation allows us to construct a property for each disjunct such that if any are violated the negated specification is satisfied and thus the original specification is falsified.
for each of these disjuncts the approach defines a new robustness problem as described below.
transform into halfspace polytopes constraints in each disjunct are converted to halfspace polytope constraints defined over the concatenation of the input and output do algorithm construct prefix input halfspace polytope h output a fully connected layer p 1begin 2lb 3ub forconstraint2hdo ifconstraint is over only input variables then forxi2xdo lbi maxfminxiconstraint lb ig ubi minfmax xiconstraint ub ig 9w diag ub lb 10b lb 11p fullyconnectedlayer w b returnp algorithm construct suffix input halfspace polytope h a b output a dnn with fully connected layers s 1begin 2sh relu fullyconnectedlayer a b 3w 4so fullyconnectedlayer w 5s so sh returns mains disjunct tohpolytope on line .
this conversion is described in algorithm .
a halfspace polytope can be represented in the form ax b whereais a matrix of k rows where each row represents constraint and dcolumns one for each variable.
in this case dis equal tom n the size of the output space plus the size of the input space.
this representation facilitates the transformation of constraints into network operations.
to build the matrix aand vectorb we first transform all inequalities in the conjunction to inequalities with variables on the left hand side and constants on the righthand side.
the transformation first converts to and to lines of algorithm .
then all variables are moved to the left hand side and all constants to the right hand side line .
next constraints are converted to constraints by decrementing the constant value on the right hand side lines .
this transformation assumes that there exists a representable number with greatest possible value that is less than the right hand side.
finally each inequality is converted to a row of aand value in b lines .
prefix construction using the constructed halfspacepolytope algorithm next constructs a prefix to the original network to ensure the input domain of the resulting network is n wherenis the input dimensionality of the original network construct pre x on line .
the algorithm to construct the prefix is shown in algorithm .
the prefix is constructed by first extracting lower and upper bounds for every input variable lines .
this extracts the minimal axis aligned bounding hyperrectangle.
the lower and upper bounds can then be used to construct the prefix network which is a single n dimensional fully connected layer with no activation function which has a diagonal weight matrix with values equal to the ranges of the input variables and biases 278equal to the lower bounds of each input.
the prefix operates on unit hypercubes reducing the input space to the correctness problems.
the prefix also encodes any interval constraints over the original input space allowing them to be removed before suffix construction which simplifies the suffix networks.
for the dronet example the diagonal of this matrix is a vector of ones while the biases are all .
next the original input values are forwarded to the end of the original network and concatenated with the original output layer line .
because constraints will be encoded as a network suffix that classifies whether inputs are property violations this step is necessary to enable the encoding of constraints over the inputs.
suffix construction the suffix subnetwork classifies whether inputs satisfy the specification construct su x on line .
the algorithm for constructing the suffix from the halfspace polytope constraints is shown in algorithm .
the constructed suffix has two layers a hidden fully connected layer with relu activations and dimension equal to the number of constraints in the halfspace polytope defined by the current disjunct and a final output layer of size .
the hidden layer of the suffix has a weight matrix equal to the constraint matrix a of the halfspace polytope representation and a bias equal to b line .
with this construction each neuron will only have a value greater than if the corresponding constraint is not satisfied otherwise it will have a value less than or equal to which becomes equal to after the relu activation is applied.
in the dronet problem for example one of the constraints for a disjunct is n x s .
for this conjunct we define the weights for one of the neurons to have a weight of from n x s a weight of fromn x p and a bias of .
the output layer of the suffix has neurons each with no activation function.
the first of these neurons is the sum of all neurons in the previous layer and has a bias value of .
because the neurons in the previous layer each represent a constraint and each of these neurons is only when the constraint is satisfied if the sum of all these neurons is then the conjunction of the constraints is satisfied indicating that a violation has been found.
the second of these neurons has a constant value of all incoming weights and bias are .
the resulting network will predict class if the input satisfies the corresponding disjunct and class otherwise.
correctness problem construction lines of algorithm define the reduced subproblem comprised of the network that we have constructed and a robustness property.
the robustness property specification is always the same and states that the network should classify all inputs in the ddimensional hypercube as class no violations.
if a violation is found to this property then according to theorem the original property is violated by the unreduced input that violated the robustness property.
in the end we have generated a set of correctness problems such that if any of the problems is violated then the original problem is also violated.
this comes from our construction of a property for each disjunct in the dnf of the negation of the original property.d.
properties over multiple networks while algorithm is defined over properties with a single network it can easily be applied to properties over multiple networks by combining those networks into a single large network.
this is specially relevant to check for equivalence properties.
this can be done by concatenating their input and output vectors.
this results in a single large network with a computation path for each network.
the transformation algorithm can then be applied as before.
e. implementation.
we implemented our approach in a system named dnnf1 which accepts a dnn property specification and corresponding dnn as input and returns whether a violation is found.
whereas the reduction algorithm in iii applies to properties with unions of polytopes as input constraints the current implementation works on unions of hyperrectangles in the input space.
this was a convenience choice to simplify the implementation while still accommodating most properties in the verification literature as demonstrated in iv a. iv.
e mpirical evaluation we now assess the cost effectiveness of reducing dnn properties for falsification by applying it to a range of dnn property benchmarks that provide diversity in terms of property types and dnn complexity.
our evaluation will attempt to answer the following research questions rq1 how expressive are the properties supported by property reduction?
rq2 how cost effective is falsification at finding property violations?
rq3 how scalable is falsification?
a. rq1 on the expressiveness of reduction we first evaluate whether the assumptions about the property specification required by reduction namely that the original property is specified as a logical formula of linear inequalities is expressive enough to support dnn correctness properties that have been proposed in existing work.
setup to evaluate the expressiveness of properties supported by our reduction we analyze and catalog the benchmarks used by the five verifiers used in our later study as well as the benchmarks of a recent dnn verifier competition vnn comp .
additionally we surveyed published papers on dnn verification in the past two years identifying additional works .
finally we include the new benchmarks introduced in this work.
results we summarize the results in table i which lists the benchmarks used in each work the type and number of properties in the benchmark and whether the properties are supported by algorithm and our current implementation.
the property types use abbreviated names with the following encoding the first symbol indicates whether the property is global g or local l the second symbol indicates whether 279the input constraint can be represented as a hyper rectangle or not the third symbol indicates whether the property is a robustness r property a reachability r property or a differential d property.
each cell under a property type indicates the number of properties in the corresponding benchmark of that type.
the bolded benchmarks are used later in the study for the evaluation of rq2 and rq3.
we describe the details of these benchmarks in more detail below.
the first benchmark is acas xu introduced for the study of the reluplex verifier and used extensively since .
the benchmark consists of properties.
properties 7and 8are reachability properties while and 10are traditional class robustness properties.
all properties have hyper rectangles constraints over the inputs and are fully supported by our property reduction.
the next benchmark is from the evaluation of the planet verifier.
first is the collision avoidance benchmark which consists of safety properties that check the robustness of a network that classifies whether simulated vehicles will collide given their current state.
all properties are l r properties and are all fully supported.
second is a set of properties on an mnist network.
the first of these are g r properties while the next are l r properties and the final property is an l r property.
in addition to restricting the amount of noise that can be added to each pixel in the input image the final property constrains the difference in the noise between neighboring pixels.
dnnf currently supports of these properties while the final is supported by algorithm .
the neurify verifier was evaluated on the acas xu benchmark and on properties of mnist networks android app malware classification networks and self driving car network.
the evaluation on mnist used l r properties across networks all of which we support.
neurify was also evaluated on networks trained on the drebin dataset to classify apps as benign or malicious.
this benchmark also includes l r properties which are fully supported.
finally neurify was evaluated on local reachability properties for a modified version of the da ve self driving car network .
this benchmark consists of local reachability properties with different types of input constraints properties of each type .
the first type of input constraint is an l1 constraint which is equivalent to a hyper rectangle constraint.
the second type of input constraint is an l1constraint which can be written as a halfspace polytope constraint.
the third and fourth type of input constraint is an image brightness and contrast which can also be written as a halfspace polytope constraints.
dnnf currently supports the first of these properties and the remainder are supported by algorithm .
the deepzono abstract domain of the eran verifier used in our study was evaluated on l r properties applied to a set of mnist networks and cifar10 networks.
all of the properties in this benchmark are fully supported by our approach.
the reludiff verifier was designed to support differential properties in order to show equivalance between two net works .
the verifier was evaluated on l d properties.
each property was defined over a network nand a modified version of the same network with quantized weights n0.
the property checked whether jn x n0 x j held in a local region of the input space.
of these properties were verified over networks from the acas xu benchmark properties on networks trained with the mnist dataset and properties on a network trained for human activity recognition .
all differencing properties are fully supported by our approach.
the recent vnn comp competition used benchmarks.
the first is a benchmark with properties applied to networks with piecewise linear activation functions.
this benchmark consists of the acas xu benchmark with l r properties and l r properties as well as a set of local robustness properties with hyper rectangle input constraints applied to mnist networks.
all of these properties are supported by our approach.
the second is a set of local robustness properties with hyper rectangle input constraints applied to convolutional neural networks trained on mnist and cifar10.
all of these properties are supported by our approach.
the final benchmark is a set of local robustness properties with hyper rectangle input constraints applied to neural networks with non linear activation functions sigmoid andtanh trained on mnist.
all of these properties are supported by our approach.
several dnn verifiers have been introduced recently.
the nnenum verifier and an abstraction refinement approach for dnn verification were evaluated on the acas xu benchmark.
the reachability set representation of imagestars was evaluated on two benchmarks of local robustness properties applied to mnist and imagenet networks.
the benchmark on the mnist networks used a version of local robustness where pixels could be independently darkened enabling input constraints to be represented as hyperrectangles.
the benchmark on the imagenet networks uses properties created from an original image and a corresponding adversarial example.
the properties specify that for a given region along the line between the original image and adversarial example all inputs along the segment are classified as the correct class.
while the mnist benchmark is supported by our current reduction implementation the imagenet benchmark requires polytope constraints in the input space and is therefore supported just by algorithm .
the nnv verifier also introduced a benchmark with an adaptive cruise control acc system.
it checks a temporal property not currently supported by algorithm but we see the potential to support such properties through unrolling in future work.
overall we find that the property specifications accepted by algorithm are rich enough to express of the property types found in the explored benchmarks.
when considering the listed benchmarks algorithm fully supports of the benchmarks.
our current implementation completely supports the properties from of the bench280table i property types of existing benchmarks and their support by reduction.
the property type names use the following encoding the first symbol indicates a global g or local l property the second symbol indicates whether the input constraint can be represented as a hyper rectangle or not the third symbol indicates the property class as robustness r reachability r or differential d .
bolded benchmarks are used later in the study to evaluate rq2 and rq3.
benchmark of property of each type support l r l r g r l r l r g d l d other algorithm implementation acas xu collision avoidance planet mnist neurify mnist neurify drebin neurify da ve eran mnist eran cifar reludiff acas reludiff mnist reludiff har vnn comp cnn vnn comp pwl vnn comp nln imagestars mnist imagestars imagenet nnv acc ghpr cifar eq marks and supports a subset of the properties in additional benchmarks.
our results also show that the current space of dnn properties has limited diversity with most benchmarks consisting primarily of local robustness properties.
this points to the value added of the new benchmarks we introduce.
it is also expected as has happened in the verification community in the past that as verification and falsification techniques improve developers will want to apply them to reason about a broader range of correctness properties.
the proposed algorithm will enable them to do that even if verifiers and falsifiers do not directly support them.
b. rq2 on the cost effectiveness of reduction enabled falsification to evaluate the cost effectiveness of falsification enabled by the proposed reduction we identify a set of falsifiers and verifiers to compare their complementary performance problem benchmarks and metrics that constitute the basis for the studies around rq2 and rq3.
setup falsifiers.
as falsification methods we will use several common adversarial techniques as well as a dnn fuzzing tool.
for adversarial attacks we choose a subset of the methods from two surveys .
we select the methods common to both surveys with l1input constraints which matches our implementation and with implementations available in the cleverhans tool .
the chosen adversarial attacks are lbfgs fgsm basic iterative method bim and deepfool .
of these attacks none use random initialization and thus will produce the same result over multiple runs.
in order to observe the potential benefits of random initialization we also include projected gradient descent pgd which was only included in one of the surveys.
therefore we run each attack except pgd once and if no adversarial example is found we return an unknown result.
for pgd if no adversarial example is found we tryagain until one is found or the given time limit is reached.
we use the default parameters for each attack as specified by cleverhans.
for dnn fuzzing we use tensorfuzz for its easily accessible implementation .
tensorfuzz requires the definition of an oracle for recognizing property violations.
we provide a version of tensorfuzz with an oracle that identifies violations by checking whether n x n x .
verifiers.
for comparison to verification we select four verifiers reluplex planet eran using the deepzono abstract domain and neurify .
neurify and eran have been shown to be fastest and most accurate in recent studies and all four verifiers are supported by dnnv which makes them easy to run and allows us to use a common property specification for all verifiers and falsifiers.
for differential properties we also consider reludiff since it is currently the only verifier built to handle such properties.
portfolios.
in addition to the individual falsifiers and verifiers we simulate portfolios of these methods which run analyses in parallel and return the first result.
we use portfolios all falsifiers which includes the falsifiers described above all verifiers which includes all verifiers run on each benchmark total which includes all methods used in this study.
to simulate running each portfolio we take the union of the violations found by each method in the portfolio and consider the time to find each violation to be the fastest time among the methods in the portfolio which found that violation.
problem benchmarks.
we evaluate our approach on two common and representative benchmarks from the verification literature and two created for this work to provide a range of networks and property types.
our selection criteria was meant to achieve two objectives.
first we wanted to select enough benchmarks to explore all property types with hyper rectangle input constraints.
second we wanted to select benchmarks a acas xu b neurify da ve c ghpr mnist d ghpr dronet e cifar eq fig.
the number of violations found by each falsifier and verifier reduced by the total number of potentially falsifiable properties.
the number above each bar gives the total number of violations found.
an exclamation point indicates that a verifier could not be run on a property due to the structure of the network.
with networks that varied in both size and structure since these factors have been shown to affect verifier performance .
from the verification literature we select acas xu the most commonly used benchmark and a slightly modified version of theneurify dave benchmark.
for neurify da ve we select the l r properties supported by our current implementation and we augment the benchmark with an additional network.
the new network is the original da ve dnn on which the smaller network in the benchmark was based.
while the small dnn has neurons the original da ve network that we add has neurons which will allow us to explore the scalability of reduction and falsification.
the two networks in this benchmark are convolutional networks and are much larger than the networks in the acas xu benchmark.
we developed new benchmarks to cover property types that are not yet covered by existing benchmarks.
the ghpr benchmark is a new dnn property benchmark that contains g r properties applied to several network architectures of varying size and structure.
it consists of correctness problems of which are ghpr properties applied to mnist networks and of which are ghpr properties applied to the dronet dnn described previously.
the dronet dnn is one of the largest in our study with more than neurons.
the mnist properties are of the form for all inputs the output values for classes aandbare closer to one another than either is to the output value of class c. the dronet properties are of the form for all inputs if the probability of collision is betweenpmin andpmax then the steering angle is within d degrees of .
these properties are described in more detail in the supplementary material3.
the cifar eq benchmark is a new dnn property benchmark with differential properties applied to large networks with complex structures.
it contains a mix of both global and local equivalence properties.
it is the only benchmark to contain g d properties which were absent in the property benchmarks that we found.
it consists of properties static appendix.pdf91 global equivalence properties and local equivalence properties.
of the global properties is untargeted while the other are targeted equivalence properties.
of the local properties are untargeted while the other are targeted equivalence properties.
the properties are applied to a pair of neural networks trained on the cifar dataset .
the first network is a large convolutional network with neurons and the second is a resnet network with over neurons.
these properties are described in more detail in the supplementary material.
because the verifiers do not support the multiple computation path structure formed during network composition we do not run them on this benchmark.
metrics.
for each verification and falsification approach we will measure the number of property violations found and the total time to find each violation.
the total time to find a violation includes both the time to transform the property as well as to run the falsifier on the resulting properties.
computing resources.
experiments were run on compute nodes with intel xeon silver processers at .
ghz and 512gb of memory.
jobs were allowed to use up to processor cores 64gb of memory with a time limit of hour.
results figure shows the number of violations found by each verifier and falsifier method on the five benchmarks.
the y axis is the proportion of non verified properties for which the techniques could find violations.
we eliminated correctness problems that were known to be unfalsifiable.
for acas this leaves correctness problems and does not reduce any of the other benchmarks.
the number above each bar in the plots indicates the number of violations found.
an exclamation point indicates that the verifier could not be run due to the architecture of the networks being verified.
the acas xu benchmark with its simple and small dnn models often used in verifier evaluation showcases where verifiers perform best today.
however even in this benchmark we notice that falsification can complement verification finding an additional violations.
on the neurify da ve benchmarks the verifiers find only violations from the dnn correctness problems while a acas xu b neurify da ve c ghpr mnist d ghpr dronet e cifar eq fig.
the times in seconds to find violations for each verifier and falsifier.
an exclamation point indicates that a verifier could not be run on a property due to the structure of the network.
the falsifiers find violations subsuming the violations from the verifiers.
the best performing falsification method on this benchmark was bim with violations found.
pgd and fgsm follow closely with and violations found respectively.
tensorfuzz the top performing falsification method on the acas benchmark does not find any violations.
we conjecture that this is due to the much larger input space.
while the acas xu networks have an input dimension of the da ve networks have an input dimension of which is more difficult to cover by random fuzzing.
on the ghpr mnist benchmark the verifiers can find violations for the properties while falsifiers bim pgd and tensorfuzz can find violations for every property.
on the ghpr dronet benchmark the verifiers cannot find any violations due to not supporting the residual block structures present in the dronet network.
many of the falsifiers also struggle on these properties except for pgd and bim which can find violations to all properties.
finally on the cifar eq benchmark the verifiers did not find any violations because they could not be run.
reluplex planet eran and neurify do not support properties over multiple networks or networks with multiple computation paths while reludiff is limited to networks with only fullyconnected layers.
additionally while pgd finds the most violations it is complemented by the other falsification approaches with bim deepfool and tensorfuzz each finding violations for at least unique property.
we conjecture that much of pgd s success is due to its random initialization which allows it to be run multiple times with different results increasing the chance of finding a violation.
note that the planet and eran verifiers find no violations for any benchmark.
for these benchmarks eran cannot find violations since its algorithmic approach focuses on proving that a property holds which suggests its complementarity with falsification methods.
planet fails to find violations due to the complexity of the problem and internal tool errors that cause planet to crash on almost of the correctness problems.
we also see that the reluplex verifier only finds violations for the acas xu benchmark.
it cannot find violations on the other benchmarks since it does not support the architecturesof the networks in those benchmarks.
overall we find that falsifiers can detect many property violations usually complementing those found by verification that applying them in a parallel portfolio can leverage their unique strengths and that they successfully scale to more complex benchmarks.
box plots of the distributions of time to find violations for each method are shown in figure .
figure 4a shows that the verifiers can be effective on the acas xu benchmark with neurify often out performing the falsifiers.
this is likely due to the extremely small size of the acas xu networks enabling verification to run efficiently.
these plots also show the efficiency struggle of the verifiers as the network get larger.
for example on the neurify da ve benchmark even when the verifiers can find a property violation the falsifiers can find violations an order of magnitude faster.
for more complex benchmarks the verifiers cannot find violations within the timeout so we only report the time for the falsifiers.
we find that falsification can efficiently find property violations even for the most complex benchmarks with a median time to find a violation across all benchmarks and falsifiers of seconds.
figures and also reveal that no single falsifier always outperforms the others.
while pgd performs well for the benchmarks studied here we can still increase the number of violations by running mutliple falsifiers.
additionally the falsifiers that find the most violations do not necessarily always find them the fastest.
based on these two observations we recommend using a portfolio approach running many falsifiers in parallel and stopping as soon as a violation is found by any technique such as the all falsifiers method shown in the previous figures.
this approach finds all the violations found by the verifiers as quickly as the fastest falsifier.
we also recommend using falsifiers in conjunction with verifiers since while falsifiers can often quickly find violations they cannot prove when a property holds.
a small da ve b large da ve c small da ve d large da ve fig.
the number of violations and time to find each violation for the neurify da ve benchmark.
the number above each bar gives the total number of property check results in the bar below it.
an exclamation point indicates that a verifier could not be run on a property due to the structure of the network.
c. rq3 on the scalability of reduction enabled falsification setup to explore the scalability of falsification with reduction we want to evaluate a set of properties across networks that vary in size.
to do this we applied the neurifyda ve properties to both the small da ve network and the original larger da ve network .
this will allow us to see how performance of the verifiers and falsifiers change with respect to the size of the network being verified.
results we present the results of checking the properties in figures 5a and 5b as well as the box plots of the times to find violations for each method in figures 5c and 5d.
on the smaller da ve network the verifiers struggle to verify the properties.
reluplex does not run at all due to its lack of support for convolutional layers while planet does run but reaches the timeout for all properties.
the eran verifier does not timeout on the small network but cannot verify any of the properties.
neurify was the only verifier that returned accurate results on the small network successfully falsifying of the properties and reaching the time limit on the other .
while only a single verifier was able to falsify any properties of the falsification approaches were able to falsify properties all of them finding more violations than neurify.
the falsifiers were also faster than neurify finding violations almost an order of magnitude faster than neurify on the small da ve network.
while one verifier was able to find violations on the smaller network none of the verifiers were able to find violations on the larger da ve network which has more than times more neurons.
similar to the small network reluplex does not support the network structure while planet reaches the time limit for all properties.
however eran and neurify both perform slightly differently.
while eran was previously able to finish its analysis on the small network it reaches the time limit for properties on the large network indicating that it could not scale to the larger network size.
similarly while neurify previously found property violations for the small network it reaches the memory limit on the large network before any violations are found.
the falsifiers on the otherhand still perform well with of the verifiers finding property violations.
surprisingly the deepfool falsifier goes from violations found on the small network to violations on the large da ve network.
we conjecture that this may be due to the use of the default parameters for deepfool and that adjusting these parameters may yield better results.
additionally the falsifiers show only a minor increase in the time needed to find a violation from a median time of .
seconds to .
seconds.
overall we find that on the benchmarks explored here dnn property reduction scales well to larger networks and enables the application of scalable falsification approaches such as adversarial example generation.
v. c onclusion in this work we present an approach for reducing dnn correctness problems to facilitate the application of falsifiers in particular adversarial attacks for finding dnn property violations.
we implement our approach and apply it to a range of correctness problem benchmarks and find that the reduction approach covers a rich set of properties reducing problems enables falsifiers to find property violations and since falsifiers tend to have different strengths a portfolio approach can increase the violation finding ability.
in future work we plan to extend dnnf to support the full range of properties supported by our algorithmic approach perform a systematic evaluation of what factors may influence falsifier performance and explore how reduction can also broaden the applicability of verifiers.
data availability we make dnnf available at dnnf and we provide an artifact containing the tool as well as the data and scripts required to replicate our study at https