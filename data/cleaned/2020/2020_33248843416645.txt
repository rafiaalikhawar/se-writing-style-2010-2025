multiplex symbolic execution exploring multiple paths by solving once yufeng zhang college of computer science and electronic engineering hunan university changsha china yufengzhang hnu.edu.cnzhenbang chen college of computer national university of defense technology changsha china zbchen nudt.edu.cnziqi shuai college of computer national university of defense technology changsha china szq nudt.edu.cn tianqi zhang college of computer national university of defense technology changsha china zhangtianqi18 nudt.edu.cnkenli li college of computer science and electronic engineering national supercomputing center in changsha hunan university changsha china lkl hnu.edu.cnji wang college of computer state key laboratory of high performance computing national university of defense technology changsha china wj nudt.edu.cn abstract pathexplosionandconstraintsolvingaretwochallengestosymbolicexecution sscalability.symbolicexecutionexplorestheprogram spathspacewithasearchingstrategyandinvokestheunderlyingconstraintsolverinablack boxmannertocheckthefeasibilityof a path.
inside the constraint solver another searching procedureis employed to prove or disprove the feasibility.
hence there exists the problem of double searchings in symbolic execution.
in this paper we propose to unify the double searching procedures to improve the scalability of symbolic execution.
we propose multiplex symbolic execution muse that utilizes the intermediate assignments during the constraint solving procedure to generate newprogram inputs.
musemaps the constraint solving procedure to the path exploration in symbolic execution and explores multiplepathsinonetimeofsolving.wehaveimplemented museon twosymbolicexecutiontools basedonkleeandjpf andthree commonlyusedconstraintsolvingalgorithms.theresultsoftheex tensive experiments on real world benchmarks indicate that muse has orders of magnitude speedup to achieve the same coverage.
ccs concepts software and its engineering software verification and validation the first two authors contributed equally to this work and are co first authors.
zhenbang chen and ji wang are the corresponding authors.
permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation on the first page.
copyrights for components of this work owned by others than acmmustbehonored.abstractingwithcreditispermitted.tocopyotherwise orrepublish topostonserversortoredistributetolists requirespriorspecificpermissionand ora fee.
request permissions from permissions acm.org.
ase september virtual event australia association for computing machinery.
acm isbn ... .
symbolic execution constraint solving mathematical optimization acm reference format yufengzhang zhenbangchen ziqishuai tianqizhang kenlili andji wang.
.
multiplex symbolic execution exploring multiple paths by solvingonce.in 35thieee acminternationalconferenceonautomatedsoftware engineering ase september virtual event australia.
acm newyork ny usa 12pages.
introduction symbolic execution is a precise program analysis technique that has been successfully applied to many software engineeringactivities includingautomaticsoftwaretesting bug finding program repair etc.
one challenge of symbolic executionisthescalabilityproblemcausedbypathexplosionand constraint solving.
during symbolic execution each variable in program phas a symbolicor concretevalue.
fornon branchstatements symbolic executiondoessymbolicorconcretecalculationsandupdatesthe symbolic or concrete values of the variables.
when executing a branch statement br symbolic execution generates the path condition pc foreachbranchof br.thepathconditionofabranch b denotedby pc b logicalandtext.1n i 1ci isaconstraintin qualifier free firstorder logic that encodes the feasibility of the program path to b andcnis the symbolic condition of b. symbolic execution invokes a constraint solver to check the satisfiability o f eachbranch s pc.ifpc b issatisfiable thentheprogrampathto bisfeasible andsymbolicexecutionwillcontinuetoexecutethe statementalong b otherwise itisinfeasible i.e.
noinputcandrive the program to b and symbolic execution abandons b. in this way symbolic execution systematically explores the path space of p. on one hand the path number explodes exponentially in the number of branch statements.
onthe other hand constraint solving is well known to be hard .
another complexity explosion occurs inside of the constraint solver.
as shown in figure there exist double explosions in symbolic execution.
such double explosions 35th ieee acm international conference on automated software engineering ase path space of program p solution space spc symbolic execution engineconstraint solversolution c1 c2 c3 partial solution c1 c2 bc1 c2 c3partial solution c1 c2 c3 figure double explosions in symbolic execution procedure.
musegenerates multiple test inputs from partial solutions with only one time of constraint solving.
partial so lutions can be used to trigger off the path branches on the current path.
obstruct the application of symbolic execution to larger real world programs.
symbolic execution explores the path space with a search strategy such as depth first search dfs and breadth first search bfs .
the underlying constraint solver also employs an internal searching procedure in the solution space to decide the satisfiability of pathconditions.essentially bothofthepathspaceandthesolution spacerepresent p sinputspace si.theconditionsof p sbranch statementssplit siintodifferentparts.eachpartcanberepresented byapath.forapathcondition pc b logicalandtext.1n i 1ci thesolutionspace spccontains all the possible assignments to the input variables in pc b .whensolving pc b theconstraintsolversearches spc and hencesearches si.duringthissearchingprocedure thesolvermay searchtheinputspacecorrespondingtootherpathsof p.however thesolveronlyreturnsthefinalsolutionsatisfying pc b ifsat or returns unsat.
therefore siis doubly searched in the stack of symbolicexecutionbythepathspaceexplorationandtheunderlying constraint solver.
it is desirable to unify the two searching procedures to improve the scalability.
in this paper we propose multiplex symbolic execution muse towards eliminating the redundant searching in dynamic symbolic execution dse .theprincipleofourmethodisthatweleverage theconstraintsolvertosearchthepathspacedirectlyviagenerating multiple test inputs in one time of solving.
for a path condition pc b logicalandtext.1ni 1ci we call a point in the solution space spca partialsolution if satisfiesasubsetoftheconstraintsin pc b .a s shown in figure the solver may touch plenty of partial solutions before finding a solution or concluding the unsatisfiability.
we can usepartialsolutionsasthetestinputsforexploring p sotherpaths.
in this way musemaps the constraint solving procedure to the path space exploration and reduces the redundant searching to boost the whole symbolic execution procedure.
partial solutions exist in a wide range of constraint solving algorithms.
we have instantiated the idea of museto three constraint solving methods to generate partial solutions i simplex based quantifier freelinearintegerarithmetic qf lia constraintsolving ii abstraction refinement based quantifier free array and bit vector qf abv constraint solving and iii optimizationbasedfloating pointconstraintsolving .besides wehave implemented museon two dse engines based on klee and symbolic pathfinder spf for c and java programs respectively.
we have applied our prototypes to real world c and java programs.
the evaluation results indicate the effectiveness and efficiency of muse.
the main contributions of this paper are wepropose musetoutilizethepartialsolutionsduringconstraint solving to generate multiple test inputs for exploring multiple paths by solving once.
we have instantiated the idea of partial solution to three constraint solving methods and implemented museon two dse engines for c and java programs.
we have carried out extensive experiments on real world c andjavaprograms.theexperimentalresultsindicatethat museachieves one or two orders of magnitude speedup on the three constraint solving methods for reaching the same code coverage.
we organize the remainders of this paper as follows.
section 2motivates musebyasimplex basedsolvingmethod.section3 presents museand its instantiations on three solving methods.
section explains the implementation of museand the experiments on real world benchmarks.
section reviews the related work.
section concludes the paper.
motivating example in this section we motivate the principle of muse.
figure shows a java function startthat receives two parameters and has four paths.
in each path the program prints a different number.
we call thesefourpathas p1 p4 respectively.nowweusedsetoexplore the path space.
suppose that the initial input is x y .
thenthefirstpathis p1thatcoversthelines .thepath condition of p1is 1 x y 2y x 2x y .
if we use dfssearching strategy thelast branch is flipped.the new path condition 2 x y 2y x 2x y is feed into off the shell constraint solver.
suppose that the solution of 2is x y then the second path is p2that covers the lines .
similarly p3andp4will be explored.
in total dse invokes the constraint solver three times for p2 p4.
sincealltheconstraintsarelineararithmetic wesupposethat thesolverusesthesimplex basedqf liatheorysolvingalgorithm .
the algorithm first considers all the integer variables in the constraints as real variables and uses simplex based linear realarithmeticsolvingalgorithmtosolvetheconstraints.ifthere is no solution the constraints are unsatisfiable.
if there exists asolution and the values in the solution are already integers the algorithmreturnsthesolution otherwise thealgorithmaddsthe integer requirement constraints gradually and employs simplex procedures again to find the integer solution.
thesimplexalgorithmmaintainsanassignment tostorethe values of variables1.
if the assignment does not satisfy the constraints the algorithm changes the assignment so that at least one unsatisfiedconstraintbecomestrue.thisprocedurecontinuesuntil 1details of simplex algorithm is discussed in section .
.
8471public void start int x inty float x float y 2if x y if y x if x y system.out.println else system.out.println else system.out.println else system.out.println figure motivating example figure branch statements split the input space into different parts corresponding to different paths.
the black ar rowsshowhowsimplexsearchesthesolutionspacefor x y 2y x 2x y .
the solving procedure covers three points corresponding to the paths p4 p3andp2 respectively.
alltheconstraintsaresatisfiedorreturns unsat.forexample supposethatthepathconditionis 2 x y 2y x 2x y and the initialassignment is 0 x y .
since 0does not satisfyx y 2and2y x simplex changestheassignment to 1 x y by the so called pivotoperation such that x y is satisfied.
now simplex validates assignment 1andfindsthat2 y x 1isviolated.inthenextstep thepivot operation changes assignment 1to 2 x y .
finally alltheconstraintsaresatisfiedand 2isalreadyanintegersolution.
so 2is returned to the dse engine for generating the input for pathp2.
in vanilla dse the constraint solver is used as a black box only 2is visible to the dse engine and the dse engine generates only one test case from one time of constraint solving.
in contrast museuses the constraint solver in a white box manner.asshowninfigure3 theinputspaceof start x yplane is split into parts by the three lines corresponding to the three branchstatements.eachofpaths p1 p3correspondstoonepart andp4corresponds to four parts.
simplex algorithm leverages the linearpropertyoftheconstraintsandsmartlyexploresthesolution space.
we can say that simplex algorithm is exploring the path spaceoftheprogram.sincetheintermediateassignments 0and 1satisfysubsetsoftheconstraintsin 2 theycantrigger p4andp3 respectively.theseintermediateassignmentsare partialsolutions.
dse can utilize these partial solutions to steer the exploration alongoff the pathbranchesonthecurrentpath.forexample whensolvingthefirstpathcondition 2 musegeneratestwoextrainputs from the partial solutions 0and 1 and the executions of these twoinputstrigger p4andp3 respectively.hence byutilizingpartial solutions museonly needs one time of constraint solving to explore all the paths.
withthesupportofpartialsolutions musemapstheconstraint solving procedure to thepath exploration in dse by releasingthe power ofconstraint solver.2the keyrequirement of museis that the underlying constraint solver can generate partial solutions.
actually partial solutions widely exist in the current constraint solvingmethods c.f.
section3.
.besides wewillseeintheexperiments c.f.
section4 that musecangeneratehundredsofpartial solutions with one time of constraint solving in practice.
method in this section we first show how museworks with dynamic symbolic execution framework.
then we elaborate on how to generate partial solutions in the existing constraint solving algorithms.
.
dse with muse algorithm1showstheprocedureofdsewith muse.theinputsare theprogram pandaninitialinputseed i0.tstoresallthegenerated test inputs yet to be executed.
the main body of the algorithm is a repeat until loop.
in the beginning the forloop selects all the test inputs in tand execute the program in a concolic manner line5 .duringtheexecution thealgorithmcancollectthecoverage information if needed.
the function saveunexploredbranches saves all the unexplored branches on the current path pintob line .
thenonebranch bisselectedfrom baccordingtoasearchstrategy line9 .hereanystrategiescanbeusedtoprioritizethebranchesin b suchasdfsandbfs.thenthefunction pathcondition generates thepathcondition alongb line10 .thekeyofourmethodisthat the algorithm uses an extended constraint solver which returnsa triple res solution partial solutions line .
when resissat solutionisthetargettestinputthatcansteertheexecutionalong b. then the solutionis stored into tfor future executions line .
otherwise resisunsatorunknown solutionis set asnull.w e assume that the underlying constraint solver may generate partial solutions no matter whether the final solution can be found or not.
therefore partial solutions are also stored into t if any line .
so the dse procedure can get multiple inputs by invoking the constraintsolveronce.evenforanunsatisfiablepathcondition the 2multiplex means reusing a shared scarce resource by sending multiple messages atonce whichisanalogtoexploringmultiplepathsbysolvingonce.sowecallour method multiplex symbolic execution muse .
848algorithm multiplex dynamic symbolic execution input program p initial input seed i0 t i0 test cases to be executed b open branches to be explored repeat for alli tdo p concolicexecute p i saveunexploredbranches p b end for b searchstrategy b pathcondition b res solution partial solutions solving ifres satthen t t solution end if savepartial solutions whethersator not if any t t partial solutions untilb stopcriterion expensivecomputationspentonconstraintsolvingwouldnotbe wasted.
the key to the success of our algorithm is that the constraint solver can generate partial solutions.
a wide range of constraint solving algorithms conform a trial and error mode.
thus we can extract plenty of partial solutions from the solving procedure.
in the following of this section we firstly focus on several commonly usedconstraintsolvingalgorithmsinsymbolicexecution.thenwebrieflydiscussmoreconstraintsolvingalgorithms.wewillseethatthenotionofpartialsolutionisauniversalprincipleapplicabletoa wide range of constraint solving algorithms.
.
partial solutions in simplex simplex is an old and efficient constraint solving method for linear arithmetic .althoughtheworstcaseofsimplex scomplexity isexponential itiswidelyusedinpractice.forexample oneofthe state of the art smt solver z3 uses simplex.
algorithm shows how partial solutions can be supported by the basic procedure of general simplex algorithm for quantifier freelinearrealarithmatic qf lra .theinputsofthealgorithm isasetof mlinearconstraints s.withoutconsideringthepreprocess of the constraint solver we assume that scorresponds to m pathconstraintsin .atthebeginningoftheprocedures the i th constraint xj naijxj triangleleftri triangleleft 3is transformed into the general form xj naijxj xi xi triangleleftr wherexiand xjare real variables.
for example x y is transformed into x y s s .afterthepreprocessing theconstraintsystem sis in the general form ax 0andm logicalanddisplay.
i 1li xi ui whereaisthem n m coefficientmatrixand xi b.theelements ofbandnare called basic variables and non basic variables with the real number set as domains.
the algorithm represents awith a 3strictinequalitiesanddisequalitiesareprocessedbyadditionaltricks.moredetails can be referred to .algorithm general simplex with partial solutions input a set of constraints in linear real arithmetic transform sinto general form initialize assignment partial solutions whiletruedo ifno basic variable violates bounds then return sat partial solutions else partial solutions partial solutions ifcan findxiandxjfor pivoting then pivot xi xj update else return unsat null partial solutions end if end if end while tableau where the columns and rows correspond to non basic and basic variables respectively.
simplex algorithm maintains an assignment b n q whereqis rational numbers set.
initially all variables are set to zero line3 .atline6 thealgorithmcheckswhetherallthebounds in equation are satisfied.
if yes the algorithm returns the current assignmentasthesolution.otherwise thecurrentassignment violatesatleastoneboundinequation1.herewealsoknowwhich constraints in are satisfied.
suppose that the first kconstraints aresatisfied andthe k 1constraintisnot.thecurrentassignment can be used as the test input steering the execution along the k thopenbranchinthecurrentpath p.therefore thecurrent assignmentisstoredinthepartialsolutionset line9 .simplexis bothsoundandcomplete.inthenextstep thealgorithmschecks whether there exist a basic variable xiand a non basic variable xjcan be pivoted.
if not the constraint system sis unsatisfiable andthealgorithmreturns unsatandthecurrentpartial solutions.
otherwise thesimplexalgorithmchanges ainthepivotoperation.
herexjis solved in the row ias xj xi aij summationdisplay.
xk n xj aikxk aij aij nequal0 in all other rows except row i xjis replaced by equation such thatxjbecomesbasicvariablesand xibecomesnon basicvariables.
heretheassignment xj ischangedsothat xisatisfiesitsbounds.
asthewhileloopcontinues moreandmoreboundsinequation 1maybesatisfied.therefore wecanrecordthecurrentassignment before each pivot operation as a partial solution.
in this paper we consider qf lia constraints which can be solved by a simplex based method .
the procedure first considersthevariablesasrealvariablesandusesimplextosolvethe constraint.ifnosolution theconstraintisunsatisfiable.ifthereisa solution the procedure return the solution if all the variables have integer values.
otherwise the procedure selects a variable that has anon integervalueandaddtheconstraintsofintegerrequirements.
then theprocedureemployssimplexagaintosearchtheinteger solution.
hence simplex is the underlying searching procedure for 849solving qf lia.
solving a qf lia constraint may invoke simplex procedure multiple times.
hence we record partial solutions for qf lia constraint solving in the underlying simplex procedures.
.
partial solutions in array theory solving arrayswidelyexistinprograms.existingsymbolicexecutors usearraytheoryforrepresentingthearrayoperationsinprograms.
reasoning about array can be very complex when both index and arrayelementsaresymbolicvalues.in thissubsection wefocuson how to generate partial solutions in array theory solving.
abstract refinement based array theory solving is the stateof the art solving method.
several mainstream qf abv smt tools implements this method such as stp and boolector .
it is natural to generate partial solutions in the abstraction refinement loop.
algorithm shows the procedure.
at the beginning formula fis converted to an abstract version faby the function abstract line .
in fact fais a relaxation of f where the constraints derived from array axioms are omitted so fimpliesfa.
here weassumethattheconstraintsareexpressedinbit vectortheory.
the algorithm feeds fainto a sat based bit vector solver.
if fa is unsatisfiable then fis unsatisfiable too.
otherwise the algorithm validates the solution maoffaonf.i fmais also a solution off then the algorithm returns maas the solution.
otherwise fais refined so that more constraints derived from array axioms are added as conjunctives to fa line .
the loop continues until the algorithmterminates.
the abstractversion fabecomes fif all constraints derived from array axioms are added into fa.s ot h e algorithm always terminates.
it is straightforward to extract partial solutions from this abstract refinementloop.ineachloopiteration westorethesolution maoftheabstractformula faaspartialsolution line13 .infact we can also modify the sat based bit vector solver to obtain more partialsolutionsatline5.wewilldiscussthistopicinsubsection .
.
.
partial solutions in optimization based solving floating pointarithmeticisa challengeforconstraintsolving.recently mathematicaloptimizationbasedsolvinghasbeenproposed forfloating pointarithmetic suchasxsat andcoral .
optimization basedconstraintsolvingintroducesthetechniques from search based testing where the constraintsaretransformed into an objective function for the optimization algorithms.
the global minimum of the objective function corresponds to the solutiontothesolvingproblem.thus anymathematicaloptimization algorithmscanbeused.forexample xsatusesmontecarlomarkov chain mcmc methodtofindtheglobalminimum .coral uses meta heuristic algorithms including random search or particle swarm optimization .
in this subsection we take xsat asanexampletoshowhowpartialsolutionscanbesupportedin optimization based constraint solving algorithms.
xsat transforms the constraints solving problem as follows.
given a conjuctive normal form of constraint f logicalanddisplay.
j j logicalordisplay.
i iei j trianglelefte prime i j triangleleft nequal algorithm abstract refinement based array theory solving with partial soltions input a conjunction of formulas fin bit vector and array theory partial solutions fa abstract f whiletruedo res ma bvsolver fa ifres unsatthen return unsat null partial solutions else v validate ma f ifv truethen return sat ma partial solutions else partial solutions partial solutions ma f primea refine fa iff primea fathen return unsat null partial solutions else fa f primea end if end if end if end while the objective function or fitness function corresponding to fis of summationdisplay.
j j productdisplay.
i id triangleleft ei j e prime i j wheredis defined in table .
table fitness function d x y x y d x y x y?
x y d x y x y?
x y d x y x y?
x y d x y x y?
x y d nequal x y x nequaly?
here x y is the number of floating point numbers between aandb representing the distance between xandy.
the fitness functionevaluateshowcloseatestinputsatisfiestheconstraints.
since ofequalsto0ifandonlyif fissatisfied.forexample supposethat xandyinfigure2arefloating pointvariables.the landscapeoftheobjectivefunctionforpathcondition 2 x y 2y x 2x y is shown in figure .
note that thelandscapeofmorecomplexpathconstraintscanbeverynonconvex.thereisnoguaranteethattheglobalminimumcanalways be found.
given the objective function we can use any mathematical optimization methods to find the global minimum including simulatedannealing particleswarmoptimization etc.forexample xsatuses simulatedannealingalgorithmtofindtheglobalminimum.simulated annealing specializes the general mcmc sampling method 850figure4 landscapeofthefitnessfunctioncorrespondingto pathcondition 2 x y 2y x 2x y .mcmc finds the global minimum after steps.
by using symmetric proposal distribution and exp f x t as the densityoftargetunnormalizeddistribution where fistheobjective function and tis the temperature .
in principle we can extract thelocalminimumortheintermediatepointsaspartial solutions directly.
as shown in figure we get the final solution .
.
in steps and also two partial solutions .
.
corresponding to path p4 andp3 respectively.
besides the mathematical optimizationproceduremayproducemanypartialsolutions and some of them may trigger the same path.
we can choose to extract partialsolutionsonlyfromlocalminimums whicharesupportedby modern optimization algorithms.
for example the basin hopping algorithmextendsmcmcmethodbyemployingalocaloptimization method in each monte carlo step .
note that due to the stochasticnatureofmcmcmethods itmaytakedifferentstepsbe forethefinalsolutionisfoundinmultipleruns.hence wemayget different partial solutions in different runs for the same constraint.
.
the ubiquitous partial solutions untilnow wehavediscussedhowpartialsolutionscanbesupported in three commonly used constraint solving algorithms in symbolic execution.inpractice symbolicexecutionbarelygeneratesdisjunction in path condition which is a hurdle to the general dpll t frameworkinsmtsolvers .forexample thedefaultconstraint solverstp usedbykleedoesnotsupportdisjunctions.therefore inthispaper webrieflydiscusshowpartialsolutionscanbe supported in several other constraint solving algorithms.
here we take some of them as instances.
cdclframework forsat.thepopularcdclframeworkused insatsolverssearchesthesolutionspacebyadecide backtrack loop .cdclmaintainsapartialassignmenttovariables.ineach loopiteration thedecidephasechoosesanassignmenttoaselected variable then the backtrackingphase erases some assignments to resolve conflicts.
the loop continues until the partial assignment is extended to a full assignment or return unsat.
obviously we can extract the partial assignments as partial solutions.
besides fixedsized bit vector theory solving uses sat solving as the underlying solver.nowadays bit vectortheory iswidelyusedinsymbolic executiontopreciselymodelthecomputationsofmachinenumbers in programs.
many mainstream smt solvers support bit vectortheory such as z3 and stp .
bit vector theory solvingconverts a bit vector constraint to a propositional formula and invokestheunderlyingsatsolverforsolving.therefore wecan record the partial solutions during the sat solving procedure and generatepartialsolutionsforbit vectorsolving.hence themethodinsection3.3forqf abvcanbeimprovedfurther whichisleftto be the future work.
dpll t for satisfiability modulo theories smt .
dpll t framework extends the cdcl framework with the decision proceduresof backgroundtheories .dpll t usescdclalgorithm tofindasolutiontothepropositionalskeletonoftheconstraints and then employs a constraint solver of background theories e.g.
simplex for linear arithmetic to find a solution.
we can extractpartial solutions as in cdcl framework and constraint solving algorithms for background theories.
congruence closure algorithm for equality logic and uninterpreted functions.
the congruence closure algorithm constructs the congruence closed equivalence classes for terms .
if a disequality constraint violates the equivalence relation the algorithmsreturnunsat.
we can construct partial solutions according to the equivalenceclassesatanypointduringtheconstructionprocedure.
jfsis a recent constraint solving algorithm for floating point arithmetic .
jfs transforms floating point constraints into a program having a list of branch statements.
the inputs satisfy the constraintsonlywhenthefinalstatementoftheprogramiscovered.
thus the constraint solving problem is transformed into a statementcoveringproblem.jfsemployscoverage guidedfuzzing to generatethetestcasestocoverthetargetstatement.therefore jfs is similar to the optimization based floating point solving methods where the optimization is implemented implicitly by the fuzzing method.
we can extract partial solutions as like in section .
.
.
discussion museisthefirststeptowardsunifyingthedoublesearchingprocedures in symbolic execution.
compared to vanilla symbolic execution musecangeneratemoretestinputswiththesameamountof constraintsolvings i.e.
exploringmultiplepathsbysolvingonce.
wehavenoguaranteethateachofthegeneratedtestinputsbypartialsolutionscantriggeradistinctpath.fromtheresultsinsection wewill seethat multiple partialsolutions indeedcorrespond to the same path.
a potential method to avoid expensive symbolic executionwithequivalentpartialsolutionsasinputsistoemploy lightweight concrete executions on these partial solutions.
suchadvanced synergy of concrete and symbolic execution can both exploitpartialsolutionsandavoidexpensiveredundantsymbolic computations.
we leave this as the future work.
experimental evaluation .
implementation inordertosupportpartialsolutions wehaveextendedthethree constraintsolvingmethodsdiscussedinsection3ontwostate ofthe art constraint solvers and one self implemented solver.
we use z3 for qf lia solving and modified z3 to generatepartialsolutions.z3employssimplex basedqf lra solving to find the real solution to a relaxed problem first andthenaddsconstraintsgraduallytofindintegersolutions .werecordthepartialsolutionsintheiterationsof 851simplex basedsolvingand converteachpartial solutionto its closest integer version.
weusestp forqf abvsolving.stpimplementsthe abstract refinement based approach for solving qf abv formulas.
we record the partial solution generated in stp s each refinement iteration.
we have implemented an optimization based floating point solverinjava.weusesimulatedannealing astheoptimization algorithm.
in each monte carlo step we check the assignments and extract them as partial solutions if needed.
toevaluate museextensively webuiltthedseenginesutilizing partialsolutionsforcandjavaprogramsbasedonthestate of theart symbolic executors.
we have implemented museon the dse engine for c programs based on klee .
the engine uses the stp enabled for providing partial solutions.
besides the dse enginesupportstheunder constrainedsymbolicexecution that can easily carry out the dse for a function.
we have implemented museon the dse engine for java programs based on spf .
the engine uses the z3 supportingpartialsolutionsforsolvingqf liaformulasand ouroptimization basedsolverforanalyzingfloating point programs.
.
research questions we carry out experiments to answer the following questions effectiveness how effective is museto test a program automatically compared with the existing search strategies?
we use code coverage to measure the effectiveness.
efficiency how efficient is museto accomplish a testing taskcomparedwiththeexistingsearchstrategies?weuse the time budget to achieve the same coverage to measure the efficiency.
.
setup we conduct three experiments to evaluate musewith the three constraintsolving methods.thesetups oftheseexperiments areas follows.
.
.
experiment simplex based qf lia solving.
we use the dseengineforjavaprogramsandz3enabledwithpartialsolutions during qf lia solving for evaluation.
table shows the benchmark programs.
all the programs are real world open source java programs.
the programs are file parsing libraries of different kinds offileformats includingbmp mp3 wav etc.fourprogramsare from imageja library which is a popular library for manipulating images andthetotallocofthelibraryis123783.twoprograms are from apache imaging library whose loc is .
for each program we countthe locof thefiles thatare directlyrelated to the tested parsing interface.
we create a driver program for each parsing library program to invokeitsmainparsinginterface.weuseavalidfileastheinitial input.
the file sizes range from tens to thousands of bytes.
we symbolize each byte in the file for dse.
note that not all symbolic bytesareinvolvedintheconstraintsduetothefunctionalityofthese programs.becausemanybitoperationsexistintheseprograms andtable the programs in the qf lia experiment.
programs locbrief description bmpdecorder 266bmp file decoder aviparser 2046imageja avi file decoder gifparser 439imageja gif parser bmpparser 205imageja bmp parser pgmparser 2736imageja pgm parser imgparserpcx 945imaging pcx decoder imgparserbmp 1123imaging bmp decoder jaadparser 115jaad mp3 decoder schroeder 1448schroeder wav decoder jmp3parser 1634javamp3 decoder toba 1060java bytecode decoder total open source programs qf liadoesnotsupportthemodelingofbitoperations weconvert bitoperationstoitsinteger implementedversion.weusedseto test these programs automatically in four configurations dfs dfs with partial solutions dfs p bfs and bfs with partial solutions bfs p .
since the initial inputs are valid files and cover a large portion of instructions we use the number of the new instructions coveredafterthefirstpathasthecriteriontoevaluatemethods.we test each program in each configuration for minutes.
.
.
experiment abstraction refinement based array theory solving.we use the dse engine for c programs and the partial solution enabled stp for evaluation.
table shows the benchmark programs which are from the gnu scientific library gsl .
floating point operations and array operations are extensive in theseprograms.thesecondcolumn locdisplaysthetotalnumber ofthellvminstructionsinsidethetestedfunctionanditscallee functions.
table the programs in the qf abv experiment.
loc lines of llvm instructions.
programs loc gsl function akimaei 2225akima eval integ bilinea 2075bilinear deriv y find 7706find eigengs 9150gsl eigen genv sort fft rrt 10199gsl fft real radix2 transform h2d ps 7919gsl histogram2d pdf sample sort 328gsl sort sum lum 2896gsl sum levin u minmax linear ed 1618linear eval deriv linear ei 2117linear eval integ solve ct 8066solve cyc tridiag solve ctn 8205solve cyc tridiag nonsym steffen ei 1815steffen eval integ total gsl functions to support floating point operations we have implemented the method in that converts each floating point instruction to itsintegersimulationimplementation.weusesoftfloat asthe 852table the programs in the experiment for optimizationbased floating point solving.
programs locbrief description eigend 1985la4j eigen decomposition jacobis 1210la4j jacobi solver choleskyd 1203la4j cholesky decomposition leasts 1264la4j least squares solver squarer 1224la4j square root solver edanalysis 1429colt eigen value decomposition mutil 1120colt linear matrix multiplication rankanalysis 1120colt rank for matrix svdanalysis 1139colt singular value decomposition tvsanalysis 1120colt several kinds of decomposition total open source programs library for floating point simulation.
we test these programs in six configurations dfswithpartialsolutions dfs p bfswithpartial solutions bfs p thedefaultrandom covernewsearch rcn the random state search rss dfs and bfs.
we test each program in each configuration for minutes.
.
.
experiment optimization based floating point solving.
similar to experiment we also evaluate museequipped with the partial solution enabled optimization based floating point constraint solver on the dse engine for java programs.
table shows the benchmark java programs.
all the programs are from two realworldlinearalgebrajavalibraries i.e.
la4jandcolt whichinclude verycomplexfloating pointarithmetics.sameastable2 wecount the loc of each benchmark s directly related files.
the locs of colt and la4j are and respectively.
we reuse the testing drivers that already exist in the libraries.
the drivers usually input double typed matrices to the library s interfaces.
we symbolize each element in the matrixes to test these programs.
allexperimentsarecarriedoutonaserverwith64gbramand one3.4ghz xeoncpu withsixcores.theresults arethe average of runs.
.
experimental results this sub section illustrates the results of the three experiments evaluating muse.
.
.
experiment simplex based lia solving.
table gives the experimental results of evaluating museon qf lia constraint solving.
the column tdisplays the number of the tests generated by dse.
the column nidisplays the number of new instructions thathavebeencoveredafterthefirstpath.boththesetwonumbersreflect the dse s ability of path exploration.
as shown by the table compared with the baseline search strategy i.e.
dfs or bfs muse can cover more new instructions and generate more tests for most of the programs which indicate the effectiveness of muse.
figure shows the trends of covered new instructions under different configurations for all the programs.
we record the wall timeaftereachpathiscovered.intheend wecomputethenumber of newly covered instructions after the first path y axis at eachtimestep x axis .asshowninthefigure5 underthesameperiod musecovers more new instructions consistently than the baseline search strategy.
we also evaluate the efficiency of musewith the time needed to cover the same amount of new instructions.
dfs achieves its largest number of new instructions i.e.
at .6s and dfs muse covers the closest number i.e.
at .4s and achieves at least .4x speedup.
on the other hand museachieves at least .9x .6s .2s speedup on bfs for covering instructionsthatarenolessthanbfs supperbound i.e.
.these results indicate that museis highly efficient.
.
.
experiment abstraction refinement based array theory solving.
table gives the experimental results.
we use several default strategies used in klee as the baselines including rcn random covernew rss randomstatesearch dfsandbfs.column psshows the number of partial solutions generated during analysis.column covshowsthecoverageresult.wecollectllvm codecoverageduringsymbolicexecution.asshownbythetable compared with the other configurations bfs p i.e.
museplus bfs achieves the best result in average.
compared with the last table experimental results of qf lia programsdfs p dfs bfs p bfs t ni t ni t ni t ni bmpdecorder aviparser gifparser bmpparser pgmparser imgparserpcx imgparserbmp jaadparser schroeder jmp3parser toba average 9000number of new instructions analysis time .1s bfs muse bfs dfs muse dfs figure trends of number of covered new instructions inexperiment on qf lia.
853four strategies in klee bfs pimproves more than coverage which indicates the effectiveness of muse.
figure6showsthecoveragetrendunderdifferentstrategies.the x axis shows the analysis time and the y axis shows the achieved averagecoverage.asshowninthefigure museperformsconsistentlybetterthanthebaselinestrategies.theresultsalsoindicate thatmusehas two orders of magnitude speedup to achieve the upper bound coverages of dfs and bfs respectively.
.
.
experiment optimization based floating point solving.
table 7showstheexperimental resultsof museonoptimizationbased floating point solving.
the meanings of the columns are the same as those in table .
compared with the baseline method musecovers moreinstructions and generatesmore tests.besides compared with bfs museimproves dfs more.
the reason is that dfs explored longer paths in priority.
longer paths have more complex pcs that are hard to resolve.
on the other hand bfs exploresshortpathsfirst whosepcsaremorelikelytobesolvedby optimization based solvers.
the results marked with an asterisk in table7meanthattheanalysesterminatebeforethetimelimit.this table experimental results of qf abv programsdfs p bfs p other stategies ps cov ps cov rcn rss dfs bfs akimaei .
.
.
.
.
.
bilinea .
.
.
.
.
.
find .
.
.
.
.
.
eigengs .
.
.
.
.
.
fft rrt .
.
.
.
.
.
h2d ps .
.
.
.
.
.
sort .
.
.
.
.
.
sum lu .
.
.
.
.
.
linear ed .
.
.
.
.
.
linear ei .
.
.
.
.
.
solve ct .
.
.
.
.
.
solve ctn .
.
.
.
.
.
steffen ei .
.
.
.
.
.
average .
.
.
.
.
.
9000average coverage analysis time .1s bfs muse dfs muse rcn rss dfs bfs figure trends of coverage in experiment on qf abv.isbecausethepathconditionsaretoocomplexfortheconstraint solver.symbolicexecutioncannotexpandtheexecutiontreewhen the constraint solver can not generate solutions.
figure shows the trend of newly covered instructions under different configurations.
the x axis is the analysis time and the y axis shows the number of newly covered instructions for all the programs after the first path.
as shown by the figure museis consistentlymoreefficientthanthebaselinemethod.besides muse with dfs finally covers more instructions than bfs which also indicatesthatpartialsolutionsimprovetheeffectiveness.similar toexperiment1 wealsoevaluatetheefficiencyof musebycomparing it with the baseline for covering the same amount of new instructions.
toachieve dfs s largest numberof new instructions i.e.
at .1s museuses .8s to cover instructions and gets99.1xspeedup.forbfs musegetsatleast4.6x .2s .2s speedup for covering instructions that are closest to bfs supper bound i.e.
.
these results indicate the efficiency of muse.
table experimental results of optimization based floating point solving.
results marked with asterisk meanthat symbolic execution can not generate more inputs forcomplexpathconditionsandstopsexpandingtheexecutiontree before time limit at that run.
programsdfs p dfs bfs p bfs t ni t ni t ni t ni eigend jacobis choleskyd leasts squarer edanalysis mutil rankanalysis svdanalysis tvsanalysis average 9000number of new instructions analysis time .1s bfs muse bfs dfs muse dfs figure trends of number of covered new instructions inexperiment on floating point solving.
a programs for qf lia b programs for qf abv c programs for floating point figure the average number of partial solutions ps per solvercall.thex axesaretheprogramsusedinexperiments.some non zero values are invisible due to scale.
.
.
partial solutions.
we also collect the results of constraint solving and the numbers of partial solutions.
figure shows the average number of partial solutions per solving in different experiments.duetothedifferencebetweenconstraintsolvingmethods the number of partial solutions can be very different.
for example inoneanalysison bmpdecorder usingqf liaunderdfsmode ourmethodgenerates923partialsolutionsin4timesofsolvings.
forfft frrtusing qf abv under dfs mode our method generates partial solutions in times of solvings.
it worth noting thatour method usually generates more partial solutions under dfs thanbfs.thereasonisthatthepathconditionunderdfscontains moreconstraintsandisusuallymorecomplicated sothesolving algorithms need more trials before finding the final solution.
.
threats to validity thethreatstothevalidityoftheexperimentalresultsaremainly external.
although we only applied the idea of partial solutions on three solving methods the idea is general and can be applied to otherconstraintsolvingmethods c.f.
section3.
.thebenchmarks weuseforevaluating museonthreeconstraintsolvingmethods arelimitedandthustheexperimentalresultscouldbebiased.we plan to evaluate museon other constraint solving methods and benchmarkprogramsforamoregeneralvalidation.theinternal threatsmainlycomefromthebugsinimplementationduetothe complexityofthesolversandthedseengines.wehavedesigned a set of test cases to test the partial solution enabled solvers and the dse engines utilizing partial solutions.
related work the key idea of museis that the underlying constraint solver supportspartialsolutions.weexpectthatthemainstreamconstraint solvers to provide a general interface to access partial solutions in the future.
the most related work to our method is the constraint optimization techniques.
in many symbolic execution engines solving result cache stores the previous solving results so that the same constraintsarenotrepeatedlysolved .thecounter example cache also stores the sets of unsatisfiable constraints.
when the query contains a subset stored in the counter example cache there is no need to invoke the constraint solver .
both of symbolic execution and constraint solving reduce constraints into simpler forms before querying the underlying constraint solver.
for example kleerewritesexpressionsbyfoldingconstantsandsimplifyinglinearexpressions .exeseparatesaqueryintoindependentsubsets of constraints so that the solving result cache can be reused better.
the green framework provides a unified facility so that the constraint solution can be reused across multiple programs and analysis .greenalsocanonicalizesconstraintstoimprovethe cachehitratio.in greenisextendedtosupportlogicalimplication relations between constraints.
speculative symbolic execution sse executesbranchstatementsspeculatively .theconstraint solverisinvokeduntilaspecifiednumberofconstraintsiscollectedon the current path.
the total invocation times of constraint solver is reduced.
sse also uses unsat core to help backtracking in wrong speculations.
another research track on boosting symbolic execution focuses on path explosion problem.
this research track can be classified into two classes.
the first class develops efficient path exploration strategiestoachievespecificgoalswithlimitedresources including branch statementcoverage statementreachability etc.forexample the sgs strategy steers the symbolic execution to less traveled paths toimprove statementcoverage .
directedsymbolic executionproposestwosearchstrategiestoreachaparticulartarget statement .
cgds strategy prioritizes branches with the shortestdistancetotheunexploredprogrampart aimingtoattainbetter 855branch coverage with fewer test inputs .
the recently proposed adaptivesearchheuristicusesmachinelearningtechniquestolearn searchstrategyonlinetoimprovethecoverage.thelearnedsearch strategy is adaptive with respect to the program under test.
experimentalresultsalsoshowthatthelearnedsearchstrategyoutperforms traditional fixed search strategy in both statement coverage and bug finding .
another class of research work reduces the pathspacesothatuninterestingpaths areabandoned.rgsecombines static data flow analysis and dynamic symbolic execution to find paths satisfying the given regular property as soon as possible .grammar basedwhite boxfuzzingusesthegrammar specification of valid inputs in order to avoid non parsable inputs andreachdeeperprogramparts .in theinputtemplateis automatically learned online to reduce the path space and hence improve the branch coverage.
the works proposed in use program slicing to reduce paths unrelated to the analysis target.for concurrent programs partial order reduction can be used to reducepathspace .mpi svcombinessymbolicexecution and model checking to prune equivalent paths satisfying the same propertyinlineartemporallogicproperty .statemergingtechniques also can reduce the number of paths effectively .
it worths noting that state merging with the iteoperator encodes multiple paths into one formula which is solved by the constraint solver.thisalsocanbeseenasusingconstraintsolvingtosearch thepathspacedirectly.however asfarasweknow wearethefirst to open up the constraint solver in symbolic execution.
searchbasedsoftwaretesting sbst techniquesusefitnessfunctiontomeasurehowcloseatestinputcanreachthetargetprogram part such asbranches andstatements andthen employoptimization algorithms to find the global minimum of the fitness function .
sbst transforms the test input generation problem into a mathematical optimization problem so that plenty of optimization algorithms can be used.
in section .
we discuss the optimizationbased constraint solving technique used in search based testing.
conclusion symbolic execution is facing the scalability problem caused by the path explosion and the complexity explosion inside the constraint solver.
we observe that there exist redundant searchings in thestack of symbolic execution.
in this paper we propose muse a general method to use the constraint solver to explore the path spacedirectly.
musemapsthesearchprocedure oftheconstraint solvingalgorithmtothesearchingsinthepathspaceviaextractingpartial solutions produced in the solving procedure.
we implement musein mainstream symbolic execution engines and the stateof the artconstraintsolvers.theexperimentalresultsshowthat museachieves one or two orders of magnitude speedups on the three constraint solving methods to reach the same code cover age.
we believe that museis the first step towards unifying the searchingproceduresinsymbolicexecution.thereareseveraldirections for future work implementing museon more theories andconductingmoreextensiveexperiments investigatingthe synergy of concrete and symbolic executions to leverage partialsolutions more efficiently exploring the methods for unifying the searching procedures under different backgrounds.