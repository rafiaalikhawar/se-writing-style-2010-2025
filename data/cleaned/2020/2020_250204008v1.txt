automating a complete software test process using llms an automotive case study shuai wang1 yinan yu1 robert feldt1 dhasarathy parthasarathy2 1chalmers university of technology2v olvo group gothenburg sweden shuaiwa chalmers.se yinan chalmers.se robert.feldt chalmers.se dhasarathy.parthasarathy volvo.com abstract vehicle api testing verifies whether the interactions between a vehicle s internal systems and external applications meet expectations ensuring that users can access and control various vehicle functions and data.
however this task is inherently complex requiring the alignment and coordination of api systems communication protocols and even vehicle simulation systems to develop valid test cases.
in practical industrial scenarios inconsistencies ambiguities and interdependencies across various documents and system specifications pose significant challenges.
this paper presents a system designed for the automated testing of in vehicle apis.
by clearly defining and segmenting the testing process we enable large language models llms to focus on specific tasks ensuring a stable and controlled testing workflow.
experiments conducted on over apis demonstrate that our system effectively automates vehicle api testing.
the results also confirm that llms can efficiently handle mundane tasks requiring human judgment making them suitable for complete automation in similar industrial contexts.
index terms software testing vehicle api testing test automation large language model i. i ntroduction large language models llms are revolutionizing software engineering.
in the past few years we have witnessed the application of llms for assisting or automating numerous software engineering tasks like requirements engineering software design coding and testing .
software testing in particular is one area where llms have been applied with vigor.
facing ever increasing needs for automation due to the volume and intensity of work involved testing is rapidly benefiting from the generative capabilities of llms.
as systematically surveyed in llms have been applied in many testing tasks including system input generation test case generation test oracle generation debugging and program repair.
while a considerable amount of recent literature has focused on applying llms in narrowly scoped tasks such as specific unit tests isolated integration tests or individual verification scenarios few have reported on their application to automate a complete test process.
practical testing processes are a diverse mix of steps that are mechanical creative and anything in between .
they also involve several teams of engineers and tools whose harmonious cooperation is essential to ensure the quality and cadence of testing.
the challenge is only greater when testing automotive embedded systems where software coexists with mechatronics and other physical systems.
under such fig.
.
we present the case of automatically testing spapi an in vehicle web server.
previously the multistep process of testing spapi was largely manual.
using llms to automate each manual step we achieve complete automation.
heterogeneous conditions it is not immediately apparent how one can effectively integrate llms into a testing process and gain efficiencies.
in response to these challenges we present a case study that focuses upon a real world test process in the automotive industry that is largely performed manually and automates it using a recipe that seamlessly combines selective use of llms with conventional automation.
the focus of this case study our system under test is spapi a web server that is deployed in trucks made by a leading vehicle manufacturer.
spapi exposes a set of rest apis which can be used by clients to read or write selected vehicle states.
for example spapi exposes speed that can be used to read the vehicle speed and climate that can be used to change the cabin climate.
essentially spapi serves as a gateway between web clients like apps on a tablet on one side and in vehicle control and monitoring applications on the other side.
more importantly for the purposes of this paper since spapi enables crucial customer facing applications considerable effort is spent in ensuring its quality.
testing spapi requires a dedicated team of full time engineers.
as shown in figure left when new apis are released the team first reviews the api specifications.
they then consult multiple documentation sources to understand the associated vehicle states organize this information to determine appropriate mocks and test inputs arxiv .04008v1 feb 2025and write and integrate test cases into a nightly regression suite.
finally they assess results particularly test failures to identify valid problems.
notably as highlighted in figure most of this process is still performed manually.
these observations prompt the question why is such intense manual effort needed to test an arguably simple gateway server?
the main reasons are structural.
first as a gateway spapi s engineering spans multiple teams with overlapping responsibilities.
the three core components the server vehicle state system and mocking system are developed by separate teams while testing falls to a fourth team that must interpret disparate documentation from each.
second spapi bridges web applications and traditional in vehicle systems which differ fundamentally in documentation style.
spapi apis are specified in swagger making them machine readable whereas vehicle states are documented in a mix of natural and formal languages often requiring human interpretation.
third spapi testers rely heavily on implicit knowledge built over years to manage inconsistencies across systems and teams leading to highly specialized expertise that intensifies manual effort and complicates team turnover.
in spapi testing the potential for full automation presents two significant benefits spapi testing can be fully automated increasing the cadence with which apis can be delivered to customers and spapi testers can be unburdened of their tedious job allowing their creative talents to be applied elsewhere.
our observations on spapi highlight that full automation is not only beneficial but essential under certain test process conditions.
specifically full automation is crucial in scenarios where testers function as a glue between tools systems and stakeholders in tasks that rely on judgment rather than creativity.
here automation enhances engineering quality while improving the testers experience.
additionally in testing workflows with extensive manual steps partial automation offers limited gains reinforcing the need for a comprehensive all or nothing automation approach.
furthermore when testers navigate legacy processes weighed down by technical debt partial debt mitigation falls short complete automation is necessary to address and eliminate debt effectively benefiting both testers and the organization as a whole.
recognizing these advantages and the rapid advancements in llms for automating manual processes we explore the central question can llms serve as the key to fully automating a largely manual test process?
to address this we make the following contributions we argue that a test process with clearly decomposed tasks many of which are executed manually is a prime candidate for complete automation based on llms.
when these criteria are satisfied we propose a recipe for full automation that involves a retaining the test process structure b leveraging llms as a general purpose tool to automate each manual step and c combining llms with conventional automation when required.
we present in vehicle web server testing as a case study illustrating how a real world testing process aligns with json xmlselected from requested dataclient server database api web api in classic three tier architecture json xmlgateway ecuin vehicle embedded system api spapi server in a real vehicle json xmlapi spapi server in a test rigecu x ecu ycan linkapp a app b gateway ecuvirtual vehicle vv system can link test api s responses test api s responses test api s responsestest virtual vehicle s statusfig.
.
a comparative illustration of the spapi architecture a web server in the classic three tier architecture spapi in a real in vehicle embedded system and spapi in a test rig with vehicle state mocked by a virtual vehicle vv system.
compared to traditional api testing vehicle api testing requires not only verifying the api s responses but also checking the vehicle s status.
our criteria and demonstrating its full automation using our proposed recipe.
as the test process structure remains largely intact we highlight how evaluating the quality of ai driven automation can be simplified by independently assessing each step where an llm is applied.
as the following sections will demonstrate using a real industrial example of in vehicle embedded software testing we show that a manual process like spapi testing can be fully automated see figure to deliver practical improvements.
ii.
b ackground since spapi is a web server that exposes rest apis our case study falls within the ambit of api testing .
aspects of the spapi test process are therefore recognizable within the larger universe of api testing but there are also several case specific adjustments which we now highlight.
a. system architecture as jointly illustrated in figures and spapi follows the typical tier architecture of decoupling presentation business logic and data each of which we discuss below.
presentation like any web server spapi presents restful endpoints with get and put methods and json payloads responses.
each api transacts an object of the form s ki vi n i with nattribute value pairs.
each pair ki vi in the object corresponds to some vehicle state k i v i that is managed by a control or monitoring application deployed in an electronic control unit ecu in the vehicle.
figure shows an example where speed endpoint provides a get method that returns the instantaneous speed of the vehicle which in turn is calculated by a speedestimation application in a vehicle master control ecu.
the same figure also illustrates the climate endpoint with a put method that sets different cabin climate states by communicating with an accontrol application in a climate control ecu.
thus the essence of spapi is presenting apis for reading or writing an object s ki vi n i .
this corresponds to interacting with vehiclefig.
.
three tiers of spapi operation presentation spapi objects data access can signals and data vehicle states.
statess k i v i n i 1managed by applications distributed across the in vehicle embedded system.
data and data access the typical web server may hold its data in a database but clearly data for spapi is vehicle state information managed by different in vehicle control applications.
as shown in figure these in vehicle applications are distributed across several ecus interconnected using controller area network can links.
while the typical web server may access data by executing database queries spapi accesses data by exchanging can signals s k i v i n i with in vehicle applications.
a can signal is a pre defined typed quantity sent through a can link between designated sender and receiver applications.
in the simplest case each vehicle state k i v i maps to one can signal and value pair k i v i which spapi sends or receives to access the state.
we also clarify that this case study focuses upon testing spapi in a rig and not in the real vehicle.
in the test rig see figure vehicle state is emulated by a virtual vehicle vv system which maintains the superset nof all vehicle statess k i v i n i 1in a single table emulating the state managed by distributed control applications.
to maintain consistency of interaction vv allows state k i v i to be accessed using the same can signal k i v i that spapi uses in the real vehicle.
in addition to easing testing using virtual means unlike many other api testing cases vv offers the advantage of being able to freely mock vehicle state for testing purposes.
due to the continuous evolution of can signals and the vv platform it is essential to monitor the vehicle s state to accurately capture relevant state changes.
api logic since spapi is a gateway the logic for each endpoint is relatively lean.
when a client invokes an endpoint spapi does the mapping ki vi k i v i of each attributevalue pair in the api object to the corresponding can signalvalue pair.
then by sending or receiving the can signal and value k i v i spapi reads or writes the corresponding vehicle state k i v i .
based upon the result of state manipulation spapi sends an appropriate response to the client.
b. current manual api testing the current manual workflow for api testing as shown in figure involves steps such as understand the apispecification look up related information write test cases run and access the test cases.
specifically the tester should first identify the specific object set sby understanding the documentation.
following this the tester will retrieve the corresponding can signal documentation s and the vv system documentation s .
it is crucial to ensure that each attribute in scan be mapped to both s ands .
this means verifying that every attribute can be converted into a can signal and can be simulated in the vv system and testers can write test cases based on the matched results.
typically two key aspects need to be checked during api testing.
the first aspect is to verify whether the virtual vehicle s state aligns with expectations after setting certain attributes to specific values via api s put s s ?
sexpected the second aspect is to check whether the api returns the expected values under a specific virtual vehicle state s get s?
sexpected in the following content we will introduce the details of each step.
understand api specification test engineers need to understand the api documentation to extract the basic objects about the api.
the documentation like swagger file always details each api s essential information such as all available endpoints expected request formats and possible response formats for each endpoint.
additionally swagger defines the data structures used in the api including objects properties and their types.
an example of a swagger file snippet describing the climate object is shown in figure a .
in this file testers should parse the object s acmode and its corresponding details in the pairs.
in summary a thorough understanding the api documentation manually is essential for constructing a comprehensive object set s ki vi n i 1from the original system documentations.
retrieve related information after obtaining the attributes and values corresponding to the object denoted as s it is necessary to search for related documentation including the information about can signals and the details about the virtual vehicle.
the search process is illustrated in figure .
first the tester needs to locate the relevant can signal documentation from can signal table.
then by matching the corresponding key and value the original state sis converted into the can signal s .
afterward the relevant virtual vehicle documentation is consulted and the corresponding key and value are mapped to obtain the specific operation s that needs to be performed on the vv .
look up information the three main components of spapi testing are the server vehicle state system and vv system.
correspondingly system information can signal specifications and mocking documentation are needed to be retrieved.api informationcan tablesvirtual vehicle s ki vi look up look up sample object s statestransform to can signalget put the states in vv s ki vi s ki vi fig.
.
the process of setting and getting vehicle status according to the api information.
when testing an attribute the corresponding values should be looked up in both the can signal and vv tables.
for example our goal is to set the vehicle s status to economy .
first we locate the relevant attribute acmode in the system documentation s. then we look up acmode in the can signal table s and find its corresponding value for economy which might be .
we then transmit this information to the vv system via the can signal.
subsequently in the vv system we read the corresponding can signal and look up the vv tables to find the value of the acmode under the economy state which might be .
finally we set the value of acmode to in the vv system.
finally the acmode in the vv system is set to to achieve the desired vehicle state of economy .
information organizing in automotive systems to transmit signals via can and utilize vv system correctly we need to ensure that each attribute and its corresponding value in the system document s ki vi n i 1can be looked up in the can signal specifications for getting s k i v i n i .
simultaneously each attribute and its value in s should be looked up in the mocking documentations to get s k i v i n i .
formally our goal is to find a mapping such that ki vi k j v j s where ki vi k j v j k i v i k k v k s where k i v i k k v k this ensures that every key kifromsmaps to a corresponding key in s and every key k ifroms maps to a corresponding key in s .
however these three components are developed by different teams and the corresponding document table may not match exactly e.g.
the names of the attributes in each table may not be consistent since some attributes is recorded using a mixture of natural language and formal language.
table i summarizes common types of records with different forms.
besides there can be discrepancies in the number of values for an attribute.
for example the acmode attribute may have two states standard andeconomy in the system document but there are modes also turbo in the can signal specification.
in such cases it is also needed to match the values with equivalent meanings.
moreover there are instances of missing attributes where a corresponding mapping key cannot be found.
since such issues are diverse and irregular testers need to carry out such fuzzy matching cautiously based on their own knowledge and experience.
table i 5types of problems that require fuzzy matching .
categoryexample key key spelling errors drivertimesetting drivertimeseting abbreviations standard std similar writing formats standard mode standardmode logical equivalents off not on semantic equivalents autostart autolaunch write test cases based on the organized information testers can write reasonable and comprehensive test cases.
specifically the two main methods of a vehicle api put and get need to be tested separately.
the put method is used to set the car s state while the get method is used to retrieve the car s current state.
to verify the effectiveness of the put method we set the car s state to susing the put method and then check whether all the virtual vehicle s states s in the vv system are as expected.
to verify whether the get method is valid we directly call the get method to retrieve the car s current states and check if the retrieved states smatch the expected states.
the process of writing test cases requires testers to have a comprehensive understanding of the organized information and a background in computer science such as ensuring the correctness of data types in test cases.
in addition testers need to consider all test situations consider as many test situations as possible to ensure high coverage of test cases.
finally testers write the test code to execute the test cases.
running code and evaluating results once the environment and code are prepared the code can be executed to automatically test the api.
existing test frameworks and tools can be used to organize the results allowing to directly obtain the final outcomes.
c. obstacles to automation based on the current api testing process the obstacles to achieving automated api testing can be summarized as follows fuzzy matching since the system information can bus specifications and vv documentations are recorded by different teams the names of the attributes i.e.
the key in the table are sometimes inconsistent as shown in table i. in addition the value also needs to be mapped based on the semantics of the key.
for instance the attribute isalarmactive may be true false in system files but active inactive in can specifications.
such inconsistency makes it difficult to achieve exact matching necessitating the implementation of a fuzzy matching mechanism.
informal pseudocoded mappings in the can signal table data is often represented in the form of informal pseudocode leading to situations where a single keyvalue pair maps to multiple counterparts.
for example activating the car s alarm clock requires setting theattribute and value as alarmactive true .
however the corresponding data in the can signal table could be represented as alarmclockstat active or alarmclockstat ringing or alarmclockstat snoozed .
in this scenario it is necessary not only to parse the can signal table but also to match the original key value pair with each entry in the can signal table.
this requires recognizing and parsing these pseudocode forms and being able to handle one to many mappings.
inconsistent units automotive values are often associated with units such as speed which can be measured inkm h orm s. when units are inconsistent direct mapping of values between tables is not possible.
values must be converted to the corresponding units before mapping.
thus the variety of units and the different conversions required between them make detecting unit inconsistencies and performing conversions a major challenge.
inter parameter dependencies parameters often have complex interdependencies requiring coordinated settings.
for example the attribute alarmtime might be represented as a date time string in system files but in can files it might need to be mapped separately to hours andminutes .
capturing and managing these parameter relationships is not an easy task.
iii.
f ully automated spapi testing with llm s this section presents the details of our automated testing tool spapi tester which can integrate with llms to fully automate the entire api testing process.
the overall process as shown in figure can be divided into four main steps.
these steps are detailed in process .
process overall workflow of spapi tester 1testtracker initializetesttracker 2for apispec inlist apisecifications s extracttestobjects apispec s apitocanmapping s cantable s cantovvmapping s vvtable testcases generatetestcase s s testcode writingtestcode testcases testtracker.analyzetestrun testcode 9testreport pushtotestrepo testtracker after initializing spapi line the entire testing process is divided into four parts documentation understanding line this part involves identifying test objects based on the api specifications.
information matching lines this part entails look up relevant can table and virtual vehicle documents to matching all these objects.
test case generation line using the matched data this step focuses on generating test cases for the api s return results and verifying the virtual vehicle s status.
executing test cases and generating test reports line .a.
documentation understanding the purpose of documentation understanding is to extract the test objects from the api documentation.
standard api documentation commonly in yaml or json format as shown in figure a is structured to list attributes and values associated with various objects.
this structured format lends itself well to template based parsing.
we parse these documents and use predefined templates to extract the relevant attributes and values.
based on existing templates we define a few simple and common rules to ensure the method s general applicability.
these templates focus on fundamental elements such as endpoint names attribute names and data types.
additionally if sample api calls are provided in the documentation we extract these directly to test the basic accessibility and functionality of the api.
however using templates alone is insufficient for determining reasonable attribute values.
we have identified the following issues with relying only on templates cannot utilize attribute description api documentation often includes natural language descriptions of attributes that templates cannot interpret or utilize.
these descriptions typically contain constraints on the attributes which are crucial to prevent generating incorrect values.
lack of robustness api documentation can sometimes be informal or inconsistent.
for instance attributes of enumeration types are usually presented as standard economy but some documents might incorrectly use standard or economy .
only using templates makes it difficult to address these random and informal issues effectively.
to overcome these two issues we introduce llms to enhance the process.
llms are utilized to analyze the entire api documentation leveraging natural language descriptions to understand attribute constraints more effectively.
since llms are capable of semantic understanding they also mitigate the impact of informal formatting or inconsistencies.
this allows the system not only to parse api properties but also to map them to can signals which is covered in detail in the subsequent section.
llms further generate constraints based on attribute descriptions producing reasonable values within these constraints.
the contextual insights provided by llms help create a broader set of valid test values thereby improving the coverage and reliability of our test cases.
in practice to ensure the stability of llm outputs and reduce the effect of the specific prompt formulations we employ dspy to automate prompt optimization.
dspy enables us to write declarative llm invocations as python code.
figure illustrates a simplified example of one of our prompts along with the dspy signature.
this apipropertytocansignal signature outlines the process of converting structured api properties to can signals which automates the time consuming task of constructing an api property ki vi and mapping it to a corresponding can signal k i v i .
to further improve the accuracy and ease of extracting structured data from the llm we format the llm inputsclimateobject type object description manipulate climate settings on the truck.
required type properties acmode type string enum standard economy autofanlevel type string enum low normal high isauxiliaryheateractivated type boolean climateobject api property acmode api property mappings can signal apiacmoderqst vv state apiacmode rqst api value mappings api value economy can value low vv state value api value standard can value high vv state value climateapiobject type climate acmode economy climatevvobject apiacmode rqst import pytest import json import time def test put climate spapi setup teardown api client vv response api client.put url api climate data json.dumps type climate acmode economy check for correct status cod e assert response.status code assert vv attributes to verify correct behavior assert vv.climate control.apiacmode rqst 1test rig a api specification b m atching results c test cases virtual vehicleapi response d test codedoc understanding matching test case gen test code writing test execution jinjafig.
.
architecture and workflow of spapi tester the pipeline largely preserves the manual process and selectively uses llms to automate discrete steps.
class api property tocansignal dspy.signature given an api table and an api property can signal map generate a list of api properties can signal s .
api to can dict dict dspy.inputfield desc a dictionary containing the mappings between an api attribute and its corresponding can signal.
input example dict dspy.inputfield output example list dspy.outputfield mapped api to can list dspy.outputfield desc a list of api properties with corresponding can signals .
fig.
.
a dspy signature for automating api to can lookup simplified .
api can input example abcobject valueone cansignal1 abcobject valuefour true aasignal bb or pv anothersignal cc abcobject valuefour false aasignal aa api can output example api property valueone can signals can name cansignal1 api property valuefour can signals can name aasignal can mappings api value true can value api value false can value can name pv anothersignal can mappings api value true can value fig.
.
templatized examples for guiding api to can look up.
and outputs as dictionaries.
we define dictionary based prompt templates to make tasks more comprehensible for the llm as demonstrated in figure .
by specifying the expected output fields the signature directs the llm to navigate inconsistencies in documentation and accurately associate api properties with can signal values.
furthermore by typing fields in the signature we enable the use of a typedpredictor in dspy which validates the llm response.
if the response does not conform to the specified types dspy re prompts the llm repeating this up to a maximum threshold until compliance is achieved.
this structured approach capitalizes on the improved format adherence of llms enhancing consistency and reliability.b.
information matching as illustrated in figure the mapping of information in our system encompasses two stages mapping api properties to can signals and mapping can signals to virtual vehicle vv signals.
these mappings are crucial for enabling signal transmission within the vehicle as well as setting or verifying the vehicle s state.
since the processes and methods for these two mappings are similar we will detail the approach for mapping api properties to can signals as an example.
first we retrieve a set of candidate can signal key value pairs k i v i from a can signal library through solely matching the name of endpoint.
subsequently we use the extracted api attributes s ki vi n i 1and the candidate can signals k i v i as input to an llm enabling manyto many matching between api properties and can signals.
in many cases attributes may have multiple enumerated values.
for instance as shown in figure an api property valuefour might take the values true or false while the corresponding can signal might represent these states as aa and bb .
this type of mapping is common and to increase the stability of spapi tester we utilize a separate dspy module specifically for matching enumerated values.
the input consists of enumerated values from both the api property and the can signal and the output is a mapping of these values.
as discussed in section ii.c there are several challenges in the mapping process.
first for fuzzy matching the llm s strong semantic understanding is well suited to handle these cases.
second for pseudocode mappings we enhance template robustness by embedding examples directly into the prompt as shown in figure .
for example we map aasignal bb or pvanothersignal cc to can value bb thereby minimizing document noise while extracting relevant information.
third for unit inconsistencies we apply a dedicated dspy module that uses a chain of thought cot approach to extract and normalize units within values.
this module converts units e.g.
kw to kilowatts ensuring unit alignment in the test case generation phase.the final output is structured as a list as defined in figure with each element containing a fully matched pair.
the same approach is then applied to map information between can signals and vv signals ultimately yielding complete matching results s ands .
c. test case generation let s think step by step to generate the values for the api properties.
.
identify dependencies and rules in the api spec such as a property setting the unit for another property.
.
set property values based on descriptions to maintain consistency among dependent properties.
.
set values for properties for strings follow the format e.g.
date time enum and choose a random value.
for numbers select a value based on can min can max and can resolution .
for properties with the same can signal set values using logical consistency and dependency rules.
fig.
.
chain of thought prompt for test case generation simplified .
after matching all the necessary information we integrate these details into a structured document as illustrated in figure b which then serves as the basis for generating test cases.
given the need to address multiple constraints during test case generation such as unit consistency we employ a stepwise cot approach to progressively incorporate these constraints.
specifically for inconsistent units we prompt the llm to identify relationships between units and perform any necessary conversions.
for inter parameter dependencies the llm captures relationships among parameters ensuring compatibility and avoiding value conflicts.
additionally the llm identifies property types and manages specialized formats such as date time strings.
finally we guide the llm in handling cases common in industrial contexts such as shared can signals among multiple properties or specific constraints on value ranges.
to ensure these constraints are applied consistently we leverage dspy s typedchainofthought method which consolidates all conditions within a single prompt.
figure provides a simplified example of this prompt.
for ease of use we specify that the module outputs test cases in dictionary format as depicted in figure c .
after generating the test cases we use them to create test code.
the test code generally consists of two sections a setup section which includes essential elements such as package imports and requests to enable program execution and a validation section containing assertions.
since the setup code remains consistent across tests we design distinct jinja1 templates for put and get test cases.
using a simple code renderer we inject the generated api and vv test objects into thejinja template to render the pytest test case.
figure d shows an example test case rendered by the test writing module.
executing test cases and generating test reports to ensure the automation of the entire process the system automatically executes the test code on the test rig and then generates a comprehensive test report.
this report documents the details of the automated testing process including the test objects the matching results the generated test cases and the execution logs.
such documentation ensures that our system maintains a high level of transparency rather than functioning as a black box.
iv.
e xperiments our evaluation investigates the following questions.
rq1 what are the pass rate coverage and failure detection capability of the test cases generated by the spapitester?
rq2 to what extent can llms overcome the obstacles outlined in section ii.c to achieve end to end automated testing?
rq3 how efficient is this automated api testing?
rq4 how effective is spapi tester in testing real world industrial apis?
specifically rq1 rq3 focus on ablation studies of spapitester using controlled experiments to evaluate its capabilities and performance.
rq4 examines the application of spapitester in the real world industrial setting with newly developed and thus guaranteed to be unseen apis to demonstrate the effectiveness of our end to end automated testing system.
a. experimental setup in this section we describe our experimental setup.
subjects our research focuses on automating vehicle api testing within an industrial setting addressing unique challenges such as inconsistencies across documentation and system specifications.
as no existing methods directly address these issues in vehicle api automation we could not compare our approach with general api testing techniques as they lack the capability to handle the specific requirements of our industrial setting.
we evaluated the quality of generated test cases for truck apis using metrics such as pass rate and coverage.
to assess spapi tester s error detection capabilities we annotated an additional apis developed by a leading vehicle manufacturer.
these apis were supported by system documentation from in house truck experts can signal protocols from the can bus team and virtual vehicle documentation from the virtual vehicle team.
we tested four llms two classic models gpt .
turbo openai preview and llama3 70b and two recent advancements gpt 4o and llama3.
70b .
to ensure flexibility and reduce maintenance we opted not to fine tune these models with company specific data allowing seamless adaptation to new models or data without retraining.table ii pass rate on different types of api s. api type num.llms gpt .
llama3 llama3.
gpt 4o energy .
.
.
.
driver settings .
.
.
.
visibility control .
.
.
.
software control .
.
.
.
vehicle condition .
.
.
.
other .
.
.
.
total average .
.
.
.
metrics we evaluate our spapi tester both at the api level and at the test case level.
at api level we use the pass rate of the apis as our metric.
if all generated test cases for a given api pass the tests we consider that api to have passed.
conversely if any test case fails the api is considered to have failed.
therefore the pass rate is defined as the proportion of apis that pass the tests.
at test case level we primarily assess the quality and coverage of the generated test cases.
for these evaluations we employ precision and recall as our key metrics.
precision measures the quality of the test cases generated while recall measures their coverage of api properties.
b. pass rate coverage and failure detection rq1 pass rate since apis with similar functions typically call the same electronic control unit ecu in embedded systems and thus share documentation within the same domain we grouped truck apis into categories based on their functions to present the results more clearly.
table ii details the pass rates for each category.
these apis are online and pre verified ensuring that any failures observed during testing were due to issues within the generated test cases or code.
results show that for the majority of categories all the apis can pass the tests successfully with all four llms achieving high pass rates.
notably spapitester achieved a pass rate when using llama3 and gpt 4o demonstrating the method s accuracy in generating valid test samples.
however gpt .
exhibited slightly lower performance in handling structured input output failing in two cases due to improper can connection settings.
additionally a common error across all llms stemmed from missing unit descriptions in api specifications.
for example when documentation omitted units for battery power llms incorrectly defaulted to watts w instead of kilowatts kw leading to test case failures.
broad patterns of errors like this could likely be addressed by further refining the prompts.
coverage in addition to pass rate analysis we evaluated the coverage of generated test cases to assess whether they adequately test each api.
a vehicle expert group was invited to create ground truth test cases for representative apis each including to test cases across categories.
the results are presented in table iii.
all llms demonstrated high precision with precision rates exceeding .
across the board and reaching .
for half of the apis showcasing the high quality of test cases generated by our model.
for cases whereprecision was below perfect errors originated from limitations in the fuzzy matching step.
however recall rates did not reach optimal levels primarily due to missing information in the api documentation such as absent units or variable types for some attributes.
to maintain high precision spapi tester skips samples that lack sufficient context for accurate matching resulting in a recall loss of approximately percentage points.
all untested attributes are logged in the testing report allowing developers to trace and address these underlying issues.
failure detection to further assess the effectiveness of the generated test cases in detecting failures vehicle experts labeled additional truck apis being developed identifying as buggy.
spapi tester created test cases that successfully detected all buggy apis with only four false positives achieving a accuracy rate.
all models performed comparably highlighting that our stepwise structured pipeline design reduces dependence on specific llm choices.
we seamlessly migrated spapi tester to different llms without requiring additional adaptation.
this largely model agnostic pipeline design allows us to focus on refining the testing process rather than selecting specific llms given the abundance of options.
c. llms ability of overcoming obstacles rq2 fuzzy matching presents a significant challenge in automated api testing.
we categorized common fuzzy matching examples into five classes selecting test samples per class supplementing with manually written samples if needed.
the results shown in table iv upper part indicate that all models achieved high precision rates highlighting the llms capability to accurately recognize and match fuzzy inputs a key requirement for full automation.
for semantic equivalents logical equivalents and similar writing formats all the models attained an accuracy of .
or nearly so demonstrating their strong pattern matching abilities in semantics and logic.
however for spelling errors accuracy slightly dropped as some errors altered word semantics like mistaking date fordata .
in the abbreviations category some abbreviations were too short to discern complicating the matching process.
for the inconsistent units issue we selected samples for experiment.
the results in table iv lower part indicate that while spapi tester achieves a high precision rate the recall remains suboptimal.
the reason is that some documentation explicitly annotates units for each attribute while others omit these details.
in these cases it becomes necessary to infer the units based on descriptions or other contextual information which can affect the performance.
another notable challenge is informal pseudocoded mappings where a single test case may correspond to multiple values.
we selected representative test cases for this experiment.
each test case consists of two sets with multiple key value pairs and the goal is to map elements between these sets as accurately and comprehensively as possible.
to increase complexity we intentionally selected test cases where the sets contained different numbers of elements creatingtable iii test case coverage of different types of api s. p isprecision r isrecall and f1 is the f1score .
api typegpt .
llama3 llama3.
gpt 4o p r f1 p r f1 p r f1 p r f1 energy .
.
.
.
.
.
.
.
.
.
.
.
visibility control .
.
.
.
.
.
.
.
.
.
.
.
vehicle condition .
.
.
.
.
.
.
.
.
.
.
.
other .
.
.
.
.
.
.
.
.
.
.
.
average .
.
.
.
.
.
.
.
.
.
.
.
table iv performance on different types of fuzzy matching upper part and inconsistent units lower part .
api typegpt .
llama3 llama3.
gpt 4o p r f1 p r f1 p r f1 p r f1 spelling errors .
.
.
.
.
.
.
.
.
.
.
.
abbreviations .
.
.
.
.
.
.
.
.
.
.
.
similar writing formats .
.
.
.
.
.
.
.
.
.
.
.
logical equivalents .
.
.
.
.
.
.
.
.
.
.
.
semantic equivalents .
.
.
.
.
.
.
.
.
.
.
.
average .
.
.
.
.
.
.
.
.
.
.
.
inconsistent units .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
recall0.
.
.
.
.
.
.00precision gpt .
llama3 70b gpt llama fig.
.
matching performance on informal pseudocoded mappings.
scenarios where matching was non trivial and recall could fluctuate.
to explore this we conducted experiments under both strict precision focused and relaxed recall focused matching conditions.
examples reflecting different levels of strictness were included in the prompts and the strictness level e.g.
strict moderate relaxed was explicitly stated in the prompts.
the results are presented in figure .
the experimental results indicate that under very strict conditions precision can reach up to however recall drops significantly even below .
as the conditions are relaxed precision slightly decreases but recall increases substantially reaching up to .
under the most relaxed conditions recall rates for all the models approach .
this demonstrates that our method can achieve high recall rates while maintaining a high level of precision.
d. time efficiency rq3 in practical industrial scenarios time consumption is an important criterion for measuring tool efficiency.
therefore we measured the total time and the time taken at each stage of the spapi tester in the testing process.
given that the llama model relies on local computational resources and that the processing speeds of gpt .
and gpt 4o do not significantly differ in this pipeline we report only the resultstable v time to generate test cases per step seconds .du is document understanding riis retrieval information tsg is test case generation run means running the test cases .
requests total du ri tsg run get .
.
.
.
put .
.
.
.
average .
.
.
for gpt .
.
we calculated the average time spent on testing all apis.
additionally we separately computed the time for the two major types of requests i.e.
put and get.
the results are shown in table v. the results indicate that most of the time is consumed during the execution of test cases with a significant portion dedicated to environment setup.
spapi s complexity requires the appropriate configuration of embedded system environments such as setting up the can bus for signal transmission.
additionally the vv system needs to read can signals and complete the reading or setting of the virtual vehicle s state which consumes a large amount of time.
the time required for put and get requests is almost identical as our approach batch generates matching results or test cases for these requests effectively minimizing time differences.
in the full pipeline the dspy module which leverages llm based capabilities is called six times once for documentation comprehension four times for information matching and once for test case generation.
additionally dspy s retry mechanism re calls the module if the output does not adhere to the predefined format.
on average the entire process from initial input to test case generation takes about seconds which is remarkably fast for automated api testing.
manual vehicle api testing in the automotive industry is traditionally a time consuming process as it requires consideration of numerous conditions.
to better understand the time demands of manual testing we surveyed experts in our industry including three senior engineers and one technical lead.
they estimated that creating test cases for each apitakes approximately .
to fte workdays with most apis requiring about two hours.
they generate to test cases for each api.
in contrast our spapi tester achieves remarkable efficiency improvements.
the system generates a complete set of test cases for a single api in just seconds representing a dramatic reduction in time and effort.
this substantial speedup not only reduces the time and effort required for api testing but also alleviates the traditionally high time burden associated with manual test case creation greatly enhancing the api testing process.
e. performance on real world industry apis rq4 to demonstrate the capability of spapi tester in an realworld setting we collected newly developed and unverified truck apis and their corresponding documentation from a leading truck manufacturing facility.
we then employed spapi tester to conduct end to end automated testing aiming to identify issues within these apis.
spapi tester identified test failures.
the test report indicates that test cases failed due to issues within the api implementation and one test case failed due to an error while parsing the api documentation.
on consultation with the api developers these were determined to be legitimate bugs in the api implementation.
the team has already started addressing these issues upon receiving the checking results.
in addition this demonstrates that spapi tester not only has a high accuracy in detecting api errors but also provides detailed reports that help quickly identify the root causes of failures.
even when spapi tester was unable to generate correct code the detailed reports can help to identify the failure causes quickly thereby minimizing misdiagnoses.
this capability significantly enhances the practical utility of spapitester by providing precise and actionable insights.
in summary these results underscore the robust practical applicability of spapi tester in real industrial environments.
f .
performance comparison with manual testing to illustrate the advantages of spapi tester over manual api testing we conducted a comparative evaluation.
as described in section iv .b an expert team created ground truth test cases for apis.
to measure the pass rate of manual testing two additional engineers independently created test cases for these apis.
results showed that one engineer s test cases passed apis while the other s passed .
both engineers missed one or two apis due to confusion over similar data entries.
for instance attributes like reducedweeklyrestsforcurrentweek and regularweeklyrestsforcurrentweek proved challenging for human testers to differentiate whereas spapitester s llms handled them effortlessly.
this led to an average pass rate of .
for manual testing at the api level while spapi tester with test cases generated by four different llms achieved pass rates between and .
in terms of coverage the average rate for manually created test cases was with human testers occasionally skippingproperties due to incomplete api documentation e.g.
missing units .
spapi tester reached coverage with gpt 4o while other models ranged between and .
to evaluate failure detection we selected apis of which contained known bugs from the apis mentioned in section iv .b.
both engineers identified all buggy apis although one created a test case that falsely flagged a correct api as erroneous resulting in a recall rate of and a precision rate of for manual testing.
similarly spapitester achieved a recall rate of with a slightly lower precision of .
in summary spapi tester consistently generates highquality test cases demonstrating comparable performance to manual testing in terms of pass rate coverage and failure detection.
v. d iscussion on complete test process automation perhaps the most significant finding from this case study is that our recipe is capable of completely automating a real world test process.
put simply spapi testing a process that currently takes ftes has effectively been substituted by spapi tester a fully automatic pipeline.
this success stems from combining llms with conventional automation allowing spapi testing to proceed without human intervention.
key to this achievement is the nature of the spapi test process it is well structured decomposable and requires human judgment but not creativity.
in such cases llms serve as the critical link to full automation by systematically replacing manual steps.
maintaining the existing process structure further aids automation in two ways.
first it defines clear verifiable steps where llms can be applied.
second preserving the status quo ensures that automation is achievable without imposing possibly unreasonable costs of changing the test process an observation that is crucial for real world application.
on the generality of llms as problem solvers preserving the design of the process no doubt identifies discrete tasks where llms can be used.
however the clear enabler for complete automation is that the llm automates all manual tasks with little practical regard to the actual nature of the task.
alternative automation methods exist such as using fuzzy matching for inconsistent key value mappings or a formal language to specify cardinality in key value relationships.
however llms as general problem solvers eliminate the need for multiple specialized solutions simplifying real world implementations.
while there is a cost to recast an llm to solve a specific problem like defining prompts or signatures the cost turns out to be manageable.
on implications on dependent processes if spapi testing can be fully automated its impact on adjacent processes becomes a natural consideration.
api implementation directly precedes spapi testing while integration within user facing subsystems follows it.
given spapi s simplicity llms could potentially automate these dependent processes extending automation across much of the development lifecycle an important step for in vehicle software engineering.
further automating spapi dependent applications could create a cascade of fully automated lifecycles reshaping automotive software development.
while promising this vision comes with challenges.
our results demonstrate llms ability to automate well defined tasks and connect dependent processes but also highlight the effort required to adapt them for specific verifiable problems.
these insights encourage further exploration toward realizing this ambitious potential.
on the transferability of this recipe we may have showcased completely automatic testing of an in vehicle embedded software application but it is clear that many of our observations and findings are transferable.
our proposed criteria for automation a decomposable process with steps requiring judgment but not creativity can extend to other domains.
additionally our approach involves six distinct llm interactions three align with general api testing workflows while the others though tailored to automotive scenarios require minimal adaptation for different contexts.
for example applying this method to another vehicle manufacturer would take roughly one full workday fte .
certain aspects may also benefit web server testing.
finally our recipe of largely preserving a test process and using llms to verifiably automate discrete manual steps is transferable to any test process that meets the criteria we propose.
vi.
r elated work existing research on api testing mainly focus on blackbox and white box testing depending on whether the source code of the api is accessible .
white box testing typically involves generating test cases to thoroughly test the logic within the code .
for example evomaster uses the many independent objective mio evolutionary algorithm to optimize multiple metrics simultaneously such as line coverage branch coverage http status coverage and the number of errors.
building on this some studies have employed additional tools for code instrumentation such as jvm and nodejs programs .
atlidakis et al.
calculate code coverage by pre configuring basic block locations and use this feedback to guide test generation.
currently most studies focus on black box api testing aiming to enhance test case coverage for more comprehensive api testing .
template based methods such as fixed test specifications and json schemas are commonly used for generating accurate test cases .
however these approaches struggle to capture parameter dependencies.
to address this stallenberg et al.
proposed a hierarchical clustering method while lin et al.
introduced a treebased representation of parameter relationships.
martin et al.
further improved test diversity by integrating external knowledge bases to generate reasonable values.
despite these advancements traditional methods often fail to achieve robust and comprehensive testing.
recently llms have emerged as a promising direction for api testing .
kim et al.
demonstrated the utility of llms in interpreting natural language api documentation to generate test values.
building on this leet al.
proposed constructing dependency graphs from documentation to enhance test coverage.
other studies finetuned llms using postman test cases or applied masking techniques to predict test values .
however these methods face challenges in ensuring the validity and robustness of generated test cases .
however existing methods focus solely on test case generation which is only one part of the api testing process and do not address the automation of the entire process.
in practical applications these methods require significant manual verification.
for instance some approaches need to retrieve relevant yet often ambiguous information from external databases.
moreover these methods lack robustness if the api specification is missing parameters or contains minor errors the process may fail.
unlike previous approaches we are the first to explore the automation of the entire api testing process focusing on current bottlenecks in api automation and considering how to leverage llms to address these challenges robustly.
vii.
c onclusion automated api testing is a critical process in software engineering essential for ensuring the reliability and functionality of software systems.
despite its importance api testing is often time consuming labor intensive and prone to errors.
in practical applications api testing involves retrieving and organizing relevant documents and writing test cases based on the organized information.
due to the fuzzy matching of information across documents manual intervention is required hindering the automation of the entire testing process.
in this paper we introduced spapi tester the first system designed for the automated testing of automotive apis.
we decomposed the api testing process into a series of steps identifying the obstacles to automation at each stage.
by leveraging llms we addressed these challenges enabling full automation of the testing workflow.
the results from realworld industrial api testing demonstrate that spapi tester achieves high detection accuracy.
our comprehensive experiments show that our system is highly robust and effective.
our system offers valuable insights for other automated api testing tasks and can be extended to web server api testing.
the findings underscore the potential of llms to transform api testing by reducing manual effort and improving efficiency paving the way for broader adoption and implementation in various testing environments.
acknowledgment this work was partially funded by the wallenberg ai autonomous systems and software program wasp supported by the knut and alice wallenberg foundation and the chalmers artificial intelligence research centre chair .
the authors also thank earl t. barr for his insightful discussions.